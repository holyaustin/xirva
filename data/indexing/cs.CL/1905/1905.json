[{"id": "1905.00052", "submitter": "Grigor Aslanyan", "authors": "Grigor Aslanyan, Aritra Mandal, Prathyusha Senthil Kumar, Amit\n  Jaiswal, Manojkumar Rangasamy Kannadasan", "title": "Personalized Ranking in eCommerce Search", "comments": "Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of personalization in the context of eCommerce search.\nSpecifically, we develop personalization ranking features that use in-session\ncontext to augment a generic ranker optimized for conversion and relevance. We\nuse a combination of latent features learned from item co-clicks in historic\nsessions and content-based features that use item title and price.\nPersonalization in search has been discussed extensively in the existing\nliterature. The novelty of our work is combining and comparing content-based\nand content-agnostic features and showing that they complement each other to\nresult in a significant improvement of the ranker. Moreover, our technique does\nnot require an explicit re-ranking step, does not rely on learning user\nprofiles from long term search behavior, and does not involve complex modeling\nof query-item-user features. Our approach captures item co-click propensity\nusing lightweight item embeddings. We experimentally show that our technique\nsignificantly outperforms a generic ranker in terms of Mean Reciprocal Rank\n(MRR). We also provide anecdotal evidence for the semantic similarity captured\nby the item embeddings on the eBay search engine.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 18:29:28 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Aslanyan", "Grigor", ""], ["Mandal", "Aritra", ""], ["Kumar", "Prathyusha Senthil", ""], ["Jaiswal", "Amit", ""], ["Kannadasan", "Manojkumar Rangasamy", ""]]}, {"id": "1905.00079", "submitter": "Jianlin Shi", "authors": "Jianlin Shi, John F. Hurdle", "title": "FastContext: an efficient and scalable implementation of the ConText\n  algorithm", "comments": null, "journal-ref": "Journal of Biomedical Informatics, August 6, 2018", "doi": "10.1016/j.jbi.2018.08.002", "report-no": null, "categories": "cs.CL cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Objective: To develop and evaluate FastContext, an efficient, scalable\nimplementation of the ConText algorithm suitable for very large-scale clinical\nnatural language processing. Background: The ConText algorithm performs with\nstate-of-art accuracy in detecting the experiencer, negation status, and\ntemporality of concept mentions in clinical narratives. However, the speed\nlimitation of its current implementations hinders its use in big data\nprocessing. Methods: We developed FastContext through hashing the ConText's\nrules, then compared its speed and accuracy with JavaConText and\nGeneralConText, two widely used Java implementations. Results: FastContext ran\ntwo orders of magnitude faster and was less decelerated by rule increase than\nthe other two implementations used in this study for comparison. Additionally,\nFastContext consistently gained accuracy improvement as the rules increased\n(the desired outcome of adding new rules), while the other two implementations\ndid not. Conclusions: FastContext is an efficient, scalable implementation of\nthe popular ConText algorithm, suitable for natural language applications on\nvery large clinical corpora.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 19:57:47 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Shi", "Jianlin", ""], ["Hurdle", "John F.", ""]]}, {"id": "1905.00195", "submitter": "Trung Trinh", "authors": "Trung Trinh, Tho Quan and Trung Mai", "title": "Nested Variational Autoencoder for Topic Modeling on Microtexts with\n  Word Vectors", "comments": "27 pages, 9 figures, under review at Expert Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most of the information on the Internet is represented in the form of\nmicrotexts, which are short text snippets such as news headlines or tweets.\nThese sources of information are abundant, and mining these data could uncover\nmeaningful insights. Topic modeling is one of the popular methods to extract\nknowledge from a collection of documents; however, conventional topic models\nsuch as latent Dirichlet allocation (LDA) are unable to perform well on short\ndocuments, mostly due to the scarcity of word co-occurrence statistics embedded\nin the data. The objective of our research is to create a topic model that can\nachieve great performances on microtexts while requiring a small runtime for\nscalability to large datasets. To solve the lack of information of microtexts,\nwe allow our method to take advantage of word embeddings for additional\nknowledge of relationships between words. For speed and scalability, we apply\nautoencoding variational Bayes, an algorithm that can perform efficient\nblack-box inference in probabilistic models. The result of our work is a novel\ntopic model called the nested variational autoencoder, which is a distribution\nthat takes into account word vectors and is parameterized by a neural network\narchitecture. For optimization, the model is trained to approximate the\nposterior distribution of the original LDA model. Experiments show the\nimprovements of our model on microtexts as well as its runtime advantage.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 06:03:56 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 10:40:37 GMT"}, {"version": "v3", "created": "Sun, 15 Sep 2019 18:36:47 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Trinh", "Trung", ""], ["Quan", "Tho", ""], ["Mai", "Trung", ""]]}, {"id": "1905.00198", "submitter": "Arindam Mitra", "authors": "Arindam Mitra, Peter Clark, Oyvind Tafjord and Chitta Baral", "title": "Declarative Question Answering over Knowledge Bases containing Natural\n  Language Text with Answer Set Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While in recent years machine learning (ML) based approaches have been the\npopular approach in developing end-to-end question answering systems, such\nsystems often struggle when additional knowledge is needed to correctly answer\nthe questions. Proposed alternatives involve translating the question and the\nnatural language text to a logical representation and then use logical\nreasoning. However, this alternative falters when the size of the text gets\nbigger. To address this we propose an approach that does logical reasoning over\npremises written in natural language text. The proposed method uses recent\nfeatures of Answer Set Programming (ASP) to call external NLP modules (which\nmay be based on ML) which perform simple textual entailment. To test our\napproach we develop a corpus based on the life cycle questions and showed that\nOur system achieves up to $18\\%$ performance gain when compared to standard MCQ\nsolvers.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 06:29:02 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Mitra", "Arindam", ""], ["Clark", "Peter", ""], ["Tafjord", "Oyvind", ""], ["Baral", "Chitta", ""]]}, {"id": "1905.00245", "submitter": "Charles Chen", "authors": "Charles Chen and Razvan Bunescu", "title": "Context-Dependent Semantic Parsing over Temporally Structured Data", "comments": "Accepted by NAACL 2019 (Oral presentation)", "journal-ref": "Proceedings of the 2019 Conference of the North American Chapter\n  of the Association for Computational Linguistics: Human Language Technologies\n  (NAACL 2019)", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a new semantic parsing setting that allows users to query the\nsystem using both natural language questions and actions within a graphical\nuser interface. Multiple time series belonging to an entity of interest are\nstored in a database and the user interacts with the system to obtain a better\nunderstanding of the entity's state and behavior, entailing sequences of\nactions and questions whose answers may depend on previous factual or\nnavigational interactions. We design an LSTM-based encoder-decoder architecture\nthat models context dependency through copying mechanisms and multiple levels\nof attention over inputs and previous outputs. When trained to predict tokens\nusing supervised learning, the proposed architecture substantially outperforms\nstandard sequence generation baselines. Training the architecture using policy\ngradient leads to further improvements in performance, reaching a\nsequence-level accuracy of 88.7% on artificial data and 74.8% on real data.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 10:16:46 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Chen", "Charles", ""], ["Bunescu", "Razvan", ""]]}, {"id": "1905.00270", "submitter": "Xin Liu", "authors": "Hongming Zhang and Xin Liu and Haojie Pan and Yangqiu Song and Cane\n  Wing-Ki Leung", "title": "ASER: A Large-scale Eventuality Knowledge Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding human's language requires complex world knowledge. However,\nexisting large-scale knowledge graphs mainly focus on knowledge about entities\nwhile ignoring knowledge about activities, states, or events, which are used to\ndescribe how entities or things act in the real world. To fill this gap, we\ndevelop ASER (activities, states, events, and their relations), a large-scale\neventuality knowledge graph extracted from more than 11-billion-token\nunstructured textual data. ASER contains 15 relation types belonging to five\ncategories, 194-million unique eventualities, and 64-million unique edges among\nthem. Both intrinsic and extrinsic evaluations demonstrate the quality and\neffectiveness of ASER.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 11:32:13 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 09:10:05 GMT"}, {"version": "v3", "created": "Sat, 25 Jan 2020 10:29:21 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Zhang", "Hongming", ""], ["Liu", "Xin", ""], ["Pan", "Haojie", ""], ["Song", "Yangqiu", ""], ["Leung", "Cane Wing-Ki", ""]]}, {"id": "1905.00422", "submitter": "Byungsoo Jeon", "authors": "Byungsoo Jeon, Eyal Shafran, Luke Breitfeller, Jason Levin, Carolyn P.\n  Rose", "title": "Time-series Insights into the Process of Passing or Failing Online\n  University Courses using Neural-Induced Interpretable Student States", "comments": "11 pages, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses a key challenge in Educational Data Mining, namely to\nmodel student behavioral trajectories in order to provide a means for\nidentifying students most at-risk, with the goal of providing supportive\ninterventions. While many forms of data including clickstream data or data from\nsensors have been used extensively in time series models for such purposes, in\nthis paper we explore the use of textual data, which is sometimes available in\nthe records of students at large, online universities. We propose a time series\nmodel that constructs an evolving student state representation using both\nclickstream data and a signal extracted from the textual notes recorded by\nhuman mentors assigned to each student. We explore how the addition of this\ntextual data improves both the predictive power of student states for the\npurpose of identifying students at risk for course failure as well as for\nproviding interpretable insights about student course engagement processes.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 16:04:12 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Jeon", "Byungsoo", ""], ["Shafran", "Eyal", ""], ["Breitfeller", "Luke", ""], ["Levin", "Jason", ""], ["Rose", "Carolyn P.", ""]]}, {"id": "1905.00470", "submitter": "Swagata Duari", "authors": "Swagata Duari and Vasudha Bhatnagar", "title": "Semi-automatic System for Title Construction", "comments": "12 pages, 2 figures, conference paper, accepted for publication", "journal-ref": "Gani A., Das P., Kharb L., Chahal D. (eds) Information,\n  Communication and Computing Technology. ICICCT 2019. Communications in\n  Computer and Information Science, vol 1025, 216-227. Springer, Singapore", "doi": "10.1007/978-981-15-1384-8_18", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a semi-automatic system for title construction from\nscientific abstracts. The system extracts and recommends impactful words from\nthe text, which the author can creatively use to construct an appropriate title\nfor the manuscript. The work is based on the hypothesis that keywords are good\ncandidates for title construction. We extract important words from the document\nby inducing a supervised keyword extraction model. The model is trained on\nnovel features extracted from graph-of-text representation of the document. We\nempirically show that these graph-based features are capable of discriminating\nkeywords from non-keywords. We further establish empirically that the proposed\napproach can be applied to any text irrespective of the training domain and\ncorpus. We evaluate the proposed system by computing the overlap between\nextracted keywords and the list of title-words for documents, and we observe a\nmacro-averaged precision of 82%.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 19:49:41 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Duari", "Swagata", ""], ["Bhatnagar", "Vasudha", ""]]}, {"id": "1905.00472", "submitter": "Victor Martinez Palacios", "authors": "Victor R Martinez, Anil Ramakrishna, Ming-Chang Chiu, Karan Singla,\n  Shrikanth Narayanan", "title": "A system for the 2019 Sentiment, Emotion and Cognitive State Task of\n  DARPAs LORELEI project", "comments": null, "journal-ref": "2019 8th International Conference on Affective Computing and\n  Intelligent Interaction (ACII)", "doi": "10.1109/ACII.2019.8925499", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the course of a Humanitarian Assistance-Disaster Relief (HADR) crisis,\nthat can happen anywhere in the world, real-time information is often posted\nonline by the people in need of help which, in turn, can be used by different\nstakeholders involved with management of the crisis. Automated processing of\nsuch posts can considerably improve the effectiveness of such efforts; for\nexample, understanding the aggregated emotion from affected populations in\nspecific areas may help inform decision-makers on how to best allocate\nresources for an effective disaster response. However, these efforts may be\nseverely limited by the availability of resources for the local language. The\nongoing DARPA project Low Resource Languages for Emergent Incidents (LORELEI)\naims to further language processing technologies for low resource languages in\nthe context of such a humanitarian crisis. In this work, we describe our\nsubmission for the 2019 Sentiment, Emotion and Cognitive state (SEC) pilot task\nof the LORELEI project. We describe a collection of sentiment analysis systems\nincluded in our submission along with the features extracted. Our fielded\nsystems obtained the best results in both English and Spanish language\nevaluations of the SEC pilot task.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 19:55:46 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Martinez", "Victor R", ""], ["Ramakrishna", "Anil", ""], ["Chiu", "Ming-Chang", ""], ["Singla", "Karan", ""], ["Narayanan", "Shrikanth", ""]]}, {"id": "1905.00537", "submitter": "Alex Wang", "authors": "Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian\n  Michael, Felix Hill, Omer Levy, Samuel R. Bowman", "title": "SuperGLUE: A Stickier Benchmark for General-Purpose Language\n  Understanding Systems", "comments": "NeurIPS 2019, super.gluebenchmark.com updating acknowledegments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last year, new models and methods for pretraining and transfer\nlearning have driven striking performance improvements across a range of\nlanguage understanding tasks. The GLUE benchmark, introduced a little over one\nyear ago, offers a single-number metric that summarizes progress on a diverse\nset of such tasks, but performance on the benchmark has recently surpassed the\nlevel of non-expert humans, suggesting limited headroom for further research.\nIn this paper we present SuperGLUE, a new benchmark styled after GLUE with a\nnew set of more difficult language understanding tasks, a software toolkit, and\na public leaderboard. SuperGLUE is available at super.gluebenchmark.com.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 00:41:50 GMT"}, {"version": "v2", "created": "Fri, 12 Jul 2019 14:53:39 GMT"}, {"version": "v3", "created": "Thu, 13 Feb 2020 00:28:00 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Wang", "Alex", ""], ["Pruksachatkun", "Yada", ""], ["Nangia", "Nikita", ""], ["Singh", "Amanpreet", ""], ["Michael", "Julian", ""], ["Hill", "Felix", ""], ["Levy", "Omer", ""], ["Bowman", "Samuel R.", ""]]}, {"id": "1905.00563", "submitter": "Pouya Pezeshkpour", "authors": "Pouya Pezeshkpour, Yifan Tian and Sameer Singh", "title": "Investigating Robustness and Interpretability of Link Prediction via\n  Adversarial Modifications", "comments": "Published at NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representing entities and relations in an embedding space is a well-studied\napproach for machine learning on relational data. Existing approaches, however,\nprimarily focus on improving accuracy and overlook other aspects such as\nrobustness and interpretability. In this paper, we propose adversarial\nmodifications for link prediction models: identifying the fact to add into or\nremove from the knowledge graph that changes the prediction for a target fact\nafter the model is retrained. Using these single modifications of the graph, we\nidentify the most influential fact for a predicted link and evaluate the\nsensitivity of the model to the addition of fake facts. We introduce an\nefficient approach to estimate the effect of such modifications by\napproximating the change in the embeddings when the knowledge graph changes. To\navoid the combinatorial search over all possible facts, we train a network to\ndecode embeddings to their corresponding graph components, allowing the use of\ngradient-based optimization to identify the adversarial modification. We use\nthese techniques to evaluate the robustness of link prediction models (by\nmeasuring sensitivity to additional facts), study interpretability through the\nfacts most responsible for predictions (by identifying the most influential\nneighbors), and detect incorrect facts in the knowledge base.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 03:30:17 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Pezeshkpour", "Pouya", ""], ["Tian", "Yifan", ""], ["Singh", "Sameer", ""]]}, {"id": "1905.00572", "submitter": "Vladimir Eidelman", "authors": "Vlad Eidelman and Brian Grom", "title": "Argument Identification in Public Comments from eRulemaking", "comments": "ICAIL 2019, extended version with examples", "journal-ref": null, "doi": "10.1145/3322640.3326714", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Administrative agencies in the United States receive millions of comments\neach year concerning proposed agency actions during the eRulemaking process.\nThese comments represent a diversity of arguments in support and opposition of\nthe proposals. While agencies are required to identify and respond to\nsubstantive comments, they have struggled to keep pace with the volume of\ninformation. In this work we address the tasks of identifying argumentative\ntext, classifying the type of argument claims employed, and determining the\nstance of the comment. First, we propose a taxonomy of argument claims based on\nan analysis of thousands of rules and millions of comments. Second, we collect\nand semi-automatically bootstrap annotations to create a dataset of millions of\nsentences with argument claim type annotation at the sentence level. Third, we\nbuild a system for automatically determining argumentative spans and claim type\nusing our proposed taxonomy in a hierarchical classification model.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 05:04:03 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 03:22:31 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Eidelman", "Vlad", ""], ["Grom", "Brian", ""]]}, {"id": "1905.00724", "submitter": "Aditya Saligrama", "authors": "Aditya Saligrama", "title": "KnowBias: A Novel AI Method to Detect Polarity in Online Content", "comments": "15 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel training and inference method for detecting political bias\nin long text content such as newspaper opinion articles. Obtaining long text\ndata and annotations at sufficient scale for training is difficult, but it is\nrelatively easy to extract political polarity from tweets through their\nauthorship; as such, we train on tweets and perform inference on articles.\nUniversal sentence encoders and other existing methods that aim to address this\ndomain-adaptation scenario deliver inaccurate and inconsistent predictions on\narticles, which we show is due to a difference in opinion concentration between\ntweets and articles. We propose a two-step classification scheme that utilizes\na neutral detector trained on tweets to remove neutral sentences from articles\nin order to align opinion concentration and therefore improve accuracy on that\ndomain.\n  We evaluate our two-step approach using a variety of test suites, including a\nset of tweets and long-form articles where annotations were crowd-sourced to\ndecrease label noise, measuring accuracy and Spearman-rho rank correlation. In\npractice, KnowBias achieves a high accuracy of 86 (rho = 0.65) on these tweets\nand 75 (rho = 0.69) on long-form articles. While we validate our method on\npolitical bias, our scheme is general and can be readily applied to other\nsettings, where there exist such domain mismatches between source and target\ndomains. Our implementation is available for public use at https://knowbias.ml.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 13:24:55 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 19:42:11 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Saligrama", "Aditya", ""]]}, {"id": "1905.00787", "submitter": "Christoph Benzm\\\"uller", "authors": "Daniel Kirchner, Christoph Benzm\\\"uller, Edward N. Zalta", "title": "Computer Science and Metaphysics: A Cross-Fertilization", "comments": "39 pages, 3 figures", "journal-ref": "Open Philosophy, 2019", "doi": "10.1515/opphil-2019-0015", "report-no": null, "categories": "cs.LO cs.AI cs.CL math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational philosophy is the use of mechanized computational techniques to\nunearth philosophical insights that are either difficult or impossible to find\nusing traditional philosophical methods. Computational metaphysics is\ncomputational philosophy with a focus on metaphysics. In this paper, we (a)\ndevelop results in modal metaphysics whose discovery was computer assisted, and\n(b) conclude that these results work not only to the obvious benefit of\nphilosophy but also, less obviously, to the benefit of computer science, since\nthe new computational techniques that led to these results may be more broadly\napplicable within computer science. The paper includes a description of our\nbackground methodology and how it evolved, and a discussion of our new results.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 16:51:32 GMT"}, {"version": "v2", "created": "Sat, 15 Jun 2019 07:23:18 GMT"}, {"version": "v3", "created": "Thu, 27 Jun 2019 08:32:06 GMT"}, {"version": "v4", "created": "Sun, 11 Aug 2019 12:47:34 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Kirchner", "Daniel", ""], ["Benzm\u00fcller", "Christoph", ""], ["Zalta", "Edward N.", ""]]}, {"id": "1905.00840", "submitter": "EPTCS", "authors": "Tiantian Gao (Stony Brook University)", "title": "Knowledge Authoring and Question Answering with KALM", "comments": "In Proceedings ICLP 2019, arXiv:1909.07646", "journal-ref": "EPTCS 306, 2019, pp. 389-395", "doi": "10.4204/EPTCS.306.52", "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge representation and reasoning (KRR) is one of the key areas in\nartificial intelligence (AI) field. It is intended to represent the world\nknowledge in formal languages (e.g., Prolog, SPARQL) and then enhance the\nexpert systems to perform querying and inference tasks. Currently, constructing\nlarge scale knowledge bases (KBs) with high quality is prohibited by the fact\nthat the construction process requires many qualified knowledge engineers who\nnot only understand the domain-specific knowledge but also have sufficient\nskills in knowledge representation. Unfortunately, qualified knowledge\nengineers are in short supply. Therefore, it would be very useful to build a\ntool that allows the user to construct and query the KB simply via text.\nAlthough there is a number of systems developed for knowledge extraction and\nquestion answering, they mainly fail in that these system don't achieve high\nenough accuracy whereas KRR is highly sensitive to erroneous data. In this\nthesis proposal, I will present Knowledge Authoring Logic Machine (KALM), a\nrule-based system which allows the user to author knowledge and query the KB in\ntext. The experimental results show that KALM achieved superior accuracy in\nknowledge authoring and question answering as compared to the state-of-the-art\nsystems.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 16:39:55 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2019 15:27:01 GMT"}, {"version": "v3", "created": "Wed, 18 Sep 2019 07:13:08 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Gao", "Tiantian", "", "Stony Brook University"]]}, {"id": "1905.00855", "submitter": "Bowen Shi", "authors": "Bowen Shi, Ming Sun, Chieh-Chi Kao, Viktor Rozgic, Spyros Matsoukas,\n  Chao Wang", "title": "Compression of Acoustic Event Detection Models with Low-rank Matrix\n  Factorization and Quantization Training", "comments": "NeuralPS 2018 CDNNRIA workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a compression approach based on the combination of\nlow-rank matrix factorization and quantization training, to reduce complexity\nfor neural network based acoustic event detection (AED) models. Our\nexperimental results show this combined compression approach is very effective.\nFor a three-layer long short-term memory (LSTM) based AED model, the original\nmodel size can be reduced to 1% with negligible loss of accuracy. Our approach\nenables the feasibility of deploying AED for resource-constraint applications.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 17:07:38 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Shi", "Bowen", ""], ["Sun", "Ming", ""], ["Kao", "Chieh-Chi", ""], ["Rozgic", "Viktor", ""], ["Matsoukas", "Spyros", ""], ["Wang", "Chao", ""]]}, {"id": "1905.00924", "submitter": "Jihwan Lee", "authors": "Jihwan Lee, Ruhi Sarikaya, Young-Bum Kim", "title": "Locale-agnostic Universal Domain Classification Model in Spoken Language\n  Understanding", "comments": "NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce an approach for leveraging available data across\nmultiple locales sharing the same language to 1) improve domain classification\nmodel accuracy in Spoken Language Understanding and user experience even if new\nlocales do not have sufficient data and 2) reduce the cost of scaling the\ndomain classifier to a large number of locales. We propose a locale-agnostic\nuniversal domain classification model based on selective multi-task learning\nthat learns a joint representation of an utterance over locales with different\nsets of domains and allows locales to share knowledge selectively depending on\nthe domains. The experimental results demonstrate the effectiveness of our\napproach on domain classification task in the scenario of multiple locales with\nimbalanced data and disparate domain sets. The proposed approach outperforms\nother baselines models especially when classifying locale-specific domains and\nalso low-resourced domains.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 18:23:47 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Lee", "Jihwan", ""], ["Sarikaya", "Ruhi", ""], ["Kim", "Young-Bum", ""]]}, {"id": "1905.00957", "submitter": "A\\'ecio Solano Rodrigues Santos", "authors": "Sonia Castelo, Thais Almeida, Anas Elghafari, A\\'ecio Santos, Kien\n  Pham, Eduardo Nakamura, Juliana Freire", "title": "A Topic-Agnostic Approach for Identifying Fake News Pages", "comments": "Accepted for publication in the Companion Proceedings of the 2019\n  World Wide Web Conference (WWW'19 Companion). Presented in the 2019\n  International Workshop on Misinformation, Computational Fact-Checking and\n  Credible Web (MisinfoWorkshop2019). 6 pages", "journal-ref": null, "doi": "10.1145/3308560.3316739", "report-no": null, "categories": "cs.CL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fake news and misinformation have been increasingly used to manipulate\npopular opinion and influence political processes. To better understand fake\nnews, how they are propagated, and how to counter their effect, it is necessary\nto first identify them. Recently, approaches have been proposed to\nautomatically classify articles as fake based on their content. An important\nchallenge for these approaches comes from the dynamic nature of news: as new\npolitical events are covered, topics and discourse constantly change and thus,\na classifier trained using content from articles published at a given time is\nlikely to become ineffective in the future. To address this challenge, we\npropose a topic-agnostic (TAG) classification strategy that uses linguistic and\nweb-markup features to identify fake news pages. We report experimental results\nusing multiple data sets which show that our approach attains high accuracy in\nthe identification of fake news, even as topics evolve over time.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 20:50:22 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Castelo", "Sonia", ""], ["Almeida", "Thais", ""], ["Elghafari", "Anas", ""], ["Santos", "A\u00e9cio", ""], ["Pham", "Kien", ""], ["Nakamura", "Eduardo", ""], ["Freire", "Juliana", ""]]}, {"id": "1905.00982", "submitter": "Shankai Yan", "authors": "Shankai Yan and Ka-Chun Wong", "title": "Context awareness and embedding for biomedical event extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: Biomedical event detection is fundamental for information\nextraction in molecular biology and biomedical research. The detected events\nform the central basis for comprehensive biomedical knowledge fusion,\nfacilitating the digestion of massive information influx from literature.\nLimited by the feature context, the existing event detection models are mostly\napplicable for a single task. A general and scalable computational model is\ndesiderated for biomedical knowledge management. Results: We consider and\npropose a bottom-up detection framework to identify the events from recognized\narguments. To capture the relations between the arguments, we trained a\nbi-directional Long Short-Term Memory (LSTM) network to model their context\nembedding. Leveraging the compositional attributes, we further derived the\ncandidate samples for training event classifiers. We built our models on the\ndatasets from BioNLP Shared Task for evaluations. Our method achieved the\naverage F-scores of 0.81 and 0.92 on BioNLPST-BGI and BioNLPST-BB datasets\nrespectively. Comparing with 7 state-of-the-art methods, our method nearly\ndoubled the existing F-score performance (0.92 vs 0.56) on the BioNLPST-BB\ndataset. Case studies were conducted to reveal the underlying reasons.\nAvailability: https://github.com/cskyan/evntextrc\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 22:01:57 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Yan", "Shankai", ""], ["Wong", "Ka-Chun", ""]]}, {"id": "1905.01152", "submitter": "Murali Karthick Baskar", "authors": "Murali Karthick Baskar, Shinji Watanabe, Ramon Astudillo, Takaaki\n  Hori, Luk\\'a\\v{s} Burget, Jan \\v{C}ernock\\'y", "title": "Semi-supervised Sequence-to-sequence ASR using Unpaired Speech and Text", "comments": "INTERSPEECH 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.IR cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sequence-to-sequence automatic speech recognition (ASR) models require large\nquantities of data to attain high performance. For this reason, there has been\na recent surge in interest for unsupervised and semi-supervised training in\nsuch models. This work builds upon recent results showing notable improvements\nin semi-supervised training using cycle-consistency and related techniques.\nSuch techniques derive training procedures and losses able to leverage unpaired\nspeech and/or text data by combining ASR with Text-to-Speech (TTS) models. In\nparticular, this work proposes a new semi-supervised loss combining an\nend-to-end differentiable ASR$\\rightarrow$TTS loss with TTS$\\rightarrow$ASR\nloss. The method is able to leverage both unpaired speech and text data to\noutperform recently proposed related techniques in terms of \\%WER. We provide\nextensive results analyzing the impact of data quantity and speech and text\nmodalities and show consistent gains across WSJ and Librispeech corpora. Our\ncode is provided in ESPnet to reproduce the experiments.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 16:13:41 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 08:54:20 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Baskar", "Murali Karthick", ""], ["Watanabe", "Shinji", ""], ["Astudillo", "Ramon", ""], ["Hori", "Takaaki", ""], ["Burget", "Luk\u00e1\u0161", ""], ["\u010cernock\u00fd", "Jan", ""]]}, {"id": "1905.01338", "submitter": "Avinash Madasu", "authors": "Avinash Madasu and Vijjini Anvesh Rao", "title": "Effectiveness of Self Normalizing Neural Networks for Text\n  Classification", "comments": "Accepted Long Paper at 20th International Conference on Computational\n  Linguistics and Intelligent Text Processing, April 2019, La Rochelle, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self Normalizing Neural Networks(SNN) proposed on Feed Forward Neural\nNetworks(FNN) outperform regular FNN architectures in various machine learning\ntasks. Particularly in the domain of Computer Vision, the activation function\nScaled Exponential Linear Units (SELU) proposed for SNNs, perform better than\nother non linear activations such as ReLU. The goal of SNN is to produce a\nnormalized output for a normalized input. Established neural network\narchitectures like feed forward networks and Convolutional Neural Networks(CNN)\nlack the intrinsic nature of normalizing outputs. Hence, requiring additional\nlayers such as Batch Normalization. Despite the success of SNNs, their\ncharacteristic features on other network architectures like CNN haven't been\nexplored, especially in the domain of Natural Language Processing. In this\npaper we aim to show the effectiveness of proposed, Self Normalizing\nConvolutional Neural Networks(SCNN) on text classification. We analyze their\nperformance with the standard CNN architecture used on several text\nclassification datasets. Our experiments demonstrate that SCNN achieves\ncomparable results to standard CNN model with significantly fewer parameters.\nFurthermore it also outperforms CNN with equal number of parameters.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 18:38:39 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Madasu", "Avinash", ""], ["Rao", "Vijjini Anvesh", ""]]}, {"id": "1905.01347", "submitter": "Chris Dulhanty", "authors": "Chris Dulhanty, Alexander Wong", "title": "Auditing ImageNet: Towards a Model-driven Framework for Annotating\n  Demographic Attributes of Large-Scale Image Datasets", "comments": "To appear in the Workshop on Fairness Accountability Transparency and\n  Ethics in Computer Vision (FATE CV) at CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ImageNet dataset ushered in a flood of academic and industry interest in\ndeep learning for computer vision applications. Despite its significant impact,\nthere has not been a comprehensive investigation into the demographic\nattributes of images contained within the dataset. Such a study could lead to\nnew insights on inherent biases within ImageNet, particularly important given\nit is frequently used to pretrain models for a wide variety of computer vision\ntasks. In this work, we introduce a model-driven framework for the automatic\nannotation of apparent age and gender attributes in large-scale image datasets.\nUsing this framework, we conduct the first demographic audit of the 2012\nImageNet Large Scale Visual Recognition Challenge (ILSVRC) subset of ImageNet\nand the \"person\" hierarchical category of ImageNet. We find that 41.62% of\nfaces in ILSVRC appear as female, 1.71% appear as individuals above the age of\n60, and males aged 15 to 29 account for the largest subgroup with 27.11%. We\nnote that the presented model-driven framework is not fair for all\nintersectional groups, so annotation are subject to bias. We present this work\nas the starting point for future development of unbiased annotation models and\nfor the study of downstream effects of imbalances in the demographics of\nImageNet. Code and annotations are available at:\nhttp://bit.ly/ImageNetDemoAudit\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 19:33:02 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 18:32:34 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Dulhanty", "Chris", ""], ["Wong", "Alexander", ""]]}, {"id": "1905.01386", "submitter": "Manojkumar Rangasamy Kannadasan", "authors": "Manojkumar Rangasamy Kannadasan, Grigor Aslanyan", "title": "Personalized Query Auto-Completion Through a Lightweight Representation\n  of the User Context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Query Auto-Completion (QAC) is a widely used feature in many domains,\nincluding web and eCommerce search, suggesting full queries based on a prefix\ntyped by the user. QAC has been extensively studied in the literature in the\nrecent years, and it has been consistently shown that adding personalization\nfeatures can significantly improve the performance of QAC. In this work we\npropose a novel method for personalized QAC that uses lightweight embeddings\nlearnt through fastText. We construct an embedding for the user context\nqueries, which are the last few queries issued by the user. We also use the\nsame model to get the embedding for the candidate queries to be ranked. We\nintroduce ranking features that compute the distance between the candidate\nqueries and the context queries in the embedding space. These features are then\ncombined with other commonly used QAC ranking features to learn a ranking\nmodel. We apply our method to a large eCommerce search engine (eBay) and show\nthat the ranker with our proposed feature significantly outperforms the\nbaselines on all of the offline metrics measured, which includes Mean\nReciprocal Rank (MRR), Success Rate (SR), Mean Average Precision (MAP), and\nNormalized Discounted Cumulative Gain (NDCG). Our baselines include the Most\nPopular Completion (MPC) model as well as a ranking model without our proposed\nfeatures. The ranking model with the proposed features results in a $20-30\\%$\nimprovement over the MPC model on all metrics. We obtain up to a $5\\%$\nimprovement over the baseline ranking model for all the sessions, which goes up\nto about $10\\%$ when we restrict to sessions that contain the user context.\nMoreover, our proposed features also significantly outperform text based\npersonalization features studied in the literature before, and adding text\nbased features on top of our proposed embedding based features results only in\nminor improvements.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 23:28:18 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Kannadasan", "Manojkumar Rangasamy", ""], ["Aslanyan", "Grigor", ""]]}, {"id": "1905.01420", "submitter": "Ekaterina Vylomova", "authors": "Ekaterina Vylomova, Ryan Cotterell, Timothy Baldwin, Trevor Cohn,\n  Jason Eisner", "title": "Contextualization of Morphological Inflection", "comments": "NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Critical to natural language generation is the production of correctly\ninflected text. In this paper, we isolate the task of predicting a fully\ninflected sentence from its partially lemmatized version. Unlike traditional\nmorphological inflection or surface realization, our task input does not\nprovide ``gold'' tags that specify what morphological features to realize on\neach lemmatized word; rather, such features must be inferred from sentential\ncontext. We develop a neural hybrid graphical model that explicitly\nreconstructs morphological features before predicting the inflected forms, and\ncompare this to a system that directly predicts the inflected forms without\nrelying on any morphological annotation. We experiment on several typologically\ndiverse languages from the Universal Dependencies treebanks, showing the\nutility of incorporating linguistically-motivated latent variables into NLP\nmodels.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 03:22:55 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Vylomova", "Ekaterina", ""], ["Cotterell", "Ryan", ""], ["Baldwin", "Timothy", ""], ["Cohn", "Trevor", ""], ["Eisner", "Jason", ""]]}, {"id": "1905.01566", "submitter": "Yasumasa Onoe", "authors": "Yasumasa Onoe, Greg Durrett", "title": "Learning to Denoise Distantly-Labeled Data for Entity Typing", "comments": "NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distantly-labeled data can be used to scale up training of statistical\nmodels, but it is typically noisy and that noise can vary with the distant\nlabeling technique. In this work, we propose a two-stage procedure for handling\nthis type of data: denoise it with a learned model, then train our final model\non clean and denoised distant data with standard supervised training. Our\ndenoising approach consists of two parts. First, a filtering function discards\nexamples from the distantly labeled data that are wholly unusable. Second, a\nrelabeling function repairs noisy labels for the retained examples. Each of\nthese components is a model trained on synthetically-noised examples generated\nfrom a small manually-labeled set. We investigate this approach on the\nultra-fine entity typing task of Choi et al. (2018). Our baseline model is an\nextension of their model with pre-trained ELMo representations, which already\nachieves state-of-the-art performance. Adding distant data that has been\ndenoised with our learned models gives further performance gains over this base\nmodel, outperforming models trained on raw distant data or\nheuristically-denoised distant data.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 23:22:51 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Onoe", "Yasumasa", ""], ["Durrett", "Greg", ""]]}, {"id": "1905.01647", "submitter": "Gijs Wijnholds", "authors": "Gijs Wijnholds and Mehrnoosh Sadrzadeh", "title": "A Typedriven Vector Semantics for Ellipsis with Anaphora using Lambek\n  Calculus with Limited Contraction", "comments": "Forthcoming in: Journal of Logic, Language and Information", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a vector space semantics for verb phrase ellipsis with anaphora\nusing type-driven compositional distributional semantics based on the Lambek\ncalculus with limited contraction (LCC) of J\\\"ager (2006). Distributional\nsemantics has a lot to say about the statistical collocation-based meanings of\ncontent words, but provides little guidance on how to treat function words.\nFormal semantics on the other hand, has powerful mechanisms for dealing with\nrelative pronouns, coordinators, and the like. Type-driven compositional\ndistributional semantics brings these two models together. We review previous\ncompositional distributional models of relative pronouns, coordination and a\nrestricted account of ellipsis in the DisCoCat framework of Coecke et al.\n(2010, 2013). We show how DisCoCat cannot deal with general forms of ellipsis,\nwhich rely on copying of information, and develop a novel way of connecting\ntypelogical grammar to distributional semantics by assigning vector\ninterpretable lambda terms to derivations of LCC in the style of Muskens &\nSadrzadeh (2016). What follows is an account of (verb phrase) ellipsis in which\nword meanings can be copied: the meaning of a sentence is now a program with\nnon-linear access to individual word embeddings. We present the theoretical\nsetting, work out examples, and demonstrate our results on a toy distributional\nmodel motivated by data.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 10:30:03 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Wijnholds", "Gijs", ""], ["Sadrzadeh", "Mehrnoosh", ""]]}, {"id": "1905.01712", "submitter": "Felipe Soares", "authors": "Felipe Soares and Martin Krallinger", "title": "BVS Corpus: A Multilingual Parallel Corpus of Biomedical Scientific\n  Texts", "comments": "Accepted at the Copora conference. arXiv admin note: text overlap\n  with arXiv:1905.01715", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The BVS database (Health Virtual Library) is a centralized source of\nbiomedical information for Latin America and Carib, created in 1998 and\ncoordinated by BIREME (Biblioteca Regional de Medicina) in agreement with the\nPan American Health Organization (OPAS). Abstracts are available in English,\nSpanish, and Portuguese, with a subset in more than one language, thus being a\npossible source of parallel corpora. In this article, we present the\ndevelopment of parallel corpora from BVS in three languages: English,\nPortuguese, and Spanish. Sentences were automatically aligned using the\nHunalign algorithm for EN/ES and EN/PT language pairs, and for a subset of\ntrilingual articles also. We demonstrate the capabilities of our corpus by\ntraining a Neural Machine Translation (OpenNMT) system for each language pair,\nwhich outperformed related works on scientific biomedical articles. Sentence\nalignment was also manually evaluated, presenting an average 96% of correctly\naligned sentences across all languages. Our parallel corpus is freely\navailable, with complementary information regarding article metadata.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 16:18:17 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Soares", "Felipe", ""], ["Krallinger", "Martin", ""]]}, {"id": "1905.01715", "submitter": "Felipe Soares", "authors": "Felipe Soares, Gabrielli Harumi Yamashita, Michel Jose Anzanello", "title": "A Parallel Corpus of Theses and Dissertations Abstracts", "comments": "Published in the PROPOR Conference. arXiv admin note: text overlap\n  with arXiv:1905.01712", "journal-ref": "Computational Processing of the Portuguese Language 2018", "doi": "10.1007/978-3-319-99722-3_35", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In Brazil, the governmental body responsible for overseeing and coordinating\npost-graduate programs, CAPES, keeps records of all theses and dissertations\npresented in the country. Information regarding such documents can be accessed\nonline in the Theses and Dissertations Catalog (TDC), which contains abstracts\nin Portuguese and English, and additional metadata. Thus, this database can be\na potential source of parallel corpora for the Portuguese and English\nlanguages. In this article, we present the development of a parallel corpus\nfrom TDC, which is made available by CAPES under the open data initiative.\nApproximately 240,000 documents were collected and aligned using the Hunalign\ntool. We demonstrate the capability of our developed corpus by training\nStatistical Machine Translation (SMT) and Neural Machine Translation (NMT)\nmodels for both language directions, followed by a comparison with Google\nTranslate (GT). Both translation models presented better BLEU scores than GT,\nwith NMT system being the most accurate one. Sentence alignment was also\nmanually evaluated, presenting an average of 82.30% correctly aligned\nsentences. Our parallel corpus is freely available in TMX format, with\ncomplementary information regarding document metadata\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 16:53:03 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Soares", "Felipe", ""], ["Yamashita", "Gabrielli Harumi", ""], ["Anzanello", "Michel Jose", ""]]}, {"id": "1905.01739", "submitter": "Dmitry Ustalov", "authors": "Saba Anwar and Dmitry Ustalov and Nikolay Arefyev and Simone Paolo\n  Ponzetto and Chris Biemann and Alexander Panchenko", "title": "HHMM at SemEval-2019 Task 2: Unsupervised Frame Induction using\n  Contextualized Word Embeddings", "comments": "5 pages, 3 tables, accepted at SemEval 2019", "journal-ref": null, "doi": "10.18653/v1/S19-2018", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present our system for semantic frame induction that showed the best\nperformance in Subtask B.1 and finished as the runner-up in Subtask A of the\nSemEval 2019 Task 2 on unsupervised semantic frame induction (QasemiZadeh et\nal., 2019). Our approach separates this task into two independent steps: verb\nclustering using word and their context embeddings and role labeling by\ncombining these embeddings with syntactical features. A simple combination of\nthese steps shows very competitive results and can be extended to process other\ndatasets and languages.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 19:57:32 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Anwar", "Saba", ""], ["Ustalov", "Dmitry", ""], ["Arefyev", "Nikolay", ""], ["Ponzetto", "Simone Paolo", ""], ["Biemann", "Chris", ""], ["Panchenko", "Alexander", ""]]}, {"id": "1905.01758", "submitter": "Hamed Zamani", "authors": "Harshith Padigela, Hamed Zamani, W. Bruce Croft", "title": "Investigating the Successes and Failures of BERT for Passage Re-Ranking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The bidirectional encoder representations from transformers (BERT) model has\nrecently advanced the state-of-the-art in passage re-ranking. In this paper, we\nanalyze the results produced by a fine-tuned BERT model to better understand\nthe reasons behind such substantial improvements. To this aim, we focus on the\nMS MARCO passage re-ranking dataset and provide potential reasons for the\nsuccesses and failures of BERT for retrieval. In more detail, we empirically\nstudy a set of hypotheses and provide additional analysis to explain the\nsuccessful performance of BERT.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 22:16:08 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Padigela", "Harshith", ""], ["Zamani", "Hamed", ""], ["Croft", "W. Bruce", ""]]}, {"id": "1905.01780", "submitter": "Bo Liu", "authors": "Bo Liu", "title": "Anonymized BERT: An Augmentation Approach to the Gendered Pronoun\n  Resolution Challenge", "comments": "6 pages; accepted by 1st ACL Workshop on Gender Bias for NLP at ACL\n  2019; code is at https://github.com/boliu61/gendered-pronoun-resolution", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present our 7th place solution to the Gendered Pronoun Resolution\nchallenge, which uses BERT without fine-tuning and a novel augmentation\nstrategy designed for contextual embedding token-level tasks. Our method\nanonymizes the referent by replacing candidate names with a set of common\nplaceholder names. Besides the usual benefits of effectively increasing\ntraining data size, this approach diversifies idiosyncratic information\nembedded in names. Using same set of common first names can also help the model\nrecognize names better, shorten token length, and remove gender and regional\nbiases associated with names. The system scored 0.1947 log loss in stage 2,\nwhere the augmentation contributed to an improvements of 0.04. Post-competition\nanalysis shows that, when using different embedding layers, the system scores\n0.1799 which would be third place.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 01:16:33 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 14:46:27 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Liu", "Bo", ""]]}, {"id": "1905.01799", "submitter": "Chih-Hao Wang", "authors": "Chih-Hao Wang, Sosuke Kato, Tetsuya Sakai", "title": "RSL19BD at DBDC4: Ensemble of Decision Tree-based and LSTM-based Models", "comments": "21 pages, 7 figures, Proceedings of Chatbots and Conversational\n  Agents and Dialogue Breakdown Detection Challenge (WOCHAT+DBDC), IWSDS 2019;\n  proceedings updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RSL19BD (Waseda University Sakai Laboratory) participated in the Fourth\nDialogue Breakdown Detection Challenge (DBDC4) and submitted five runs to both\nEnglish and Japanese subtasks. In these runs, we utilise the Decision\nTree-based model and the Long Short-Term Memory-based (LSTM-based) model\nfollowing the approaches of RSL17BD and KTH in the Third Dialogue Breakdown\nDetection Challenge (DBDC3) respectively. The Decision Tree-based model follows\nthe approach of RSL17BD but utilises RandomForestRegressor instead of\nExtraTreesRegressor. In addition, instead of predicting the mean and the\nvariance of the probability distribution of the three breakdown labels, it\npredicts the probability of each label directly. The LSTM-based model follows\nthe approach of KTH with some changes in the architecture and utilises\nConvolutional Neural Network (CNN) to perform text feature extraction. In\naddition, instead of targeting the single breakdown label and minimising the\ncategorical cross entropy loss, it targets the probability distribution of the\nthree breakdown labels and minimises the mean squared error. Run 1 utilises a\nDecision Tree-based model; Run 2 utilises an LSTM-based model; Run 3 performs\nan ensemble of 5 LSTM-based models; Run 4 performs an ensemble of Run 1 and Run\n2; Run 5 performs an ensemble of Run 1 and Run 3. Run 5 statistically\nsignificantly outperformed all other runs in terms of MSE (NB, PB, B) for the\nEnglish data and all other runs except Run 4 in terms of MSE (NB, PB, B) for\nthe Japanese data (alpha level = 0.05).\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 02:39:31 GMT"}, {"version": "v2", "created": "Sat, 11 May 2019 08:35:52 GMT"}, {"version": "v3", "created": "Mon, 18 Nov 2019 08:39:45 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Wang", "Chih-Hao", ""], ["Kato", "Sosuke", ""], ["Sakai", "Tetsuya", ""]]}, {"id": "1905.01852", "submitter": "Felipe Soares", "authors": "Felipe Soares, Viviane Pereira Moreira, Karin Becker", "title": "A Large Parallel Corpus of Full-Text Scientific Articles", "comments": "Published in Proceedings of the Eleventh International Conference on\n  Language Resources and Evaluation (LREC 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Scielo database is an important source of scientific information in Latin\nAmerica, containing articles from several research domains. A striking\ncharacteristic of Scielo is that many of its full-text contents are presented\nin more than one language, thus being a potential source of parallel corpora.\nIn this article, we present the development of a parallel corpus from Scielo in\nthree languages: English, Portuguese, and Spanish. Sentences were automatically\naligned using the Hunalign algorithm for all language pairs, and for a subset\nof trilingual articles also. We demonstrate the capabilities of our corpus by\ntraining a Statistical Machine Translation system (Moses) for each language\npair, which outperformed related works on scientific articles. Sentence\nalignment was also manually evaluated, presenting an average of 98.8% correctly\naligned sentences across all languages. Our parallel corpus is freely available\nin the TMX format, with complementary information regarding article metadata.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 07:33:00 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Soares", "Felipe", ""], ["Moreira", "Viviane Pereira", ""], ["Becker", "Karin", ""]]}, {"id": "1905.01855", "submitter": "Felipe Soares", "authors": "Felipe Soares, Karin Becker", "title": "UFRGS Participation on the WMT Biomedical Translation Shared Task", "comments": "Published on the Third Conference on Machine Translation (WMT18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes the machine translation systems developed by the\nUniversidade Federal do Rio Grande do Sul (UFRGS) team for the biomedical\ntranslation shared task. Our systems are based on statistical machine\ntranslation and neural machine translation, using the Moses and OpenNMT\ntoolkits, respectively. We participated in four translation directions for the\nEnglish/Spanish and English/Portuguese language pairs. To create our training\ndata, we concatenated several parallel corpora, both from in-domain and\nout-of-domain sources, as well as terminological resources from UMLS. Our\nsystems achieved the best BLEU scores according to the official shared task\nevaluation.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 07:36:59 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Soares", "Felipe", ""], ["Becker", "Karin", ""]]}, {"id": "1905.01896", "submitter": "Gemma Boleda", "authors": "Gemma Boleda", "title": "Distributional Semantics and Linguistic Theory", "comments": "22 pages, 4 figures; preprint version (minor modifications wrt\n  previous version). When citing this article, please use the journal\n  reference: Boleda, G. 2020. Distributional Semantics and Linguistic Theory.\n  Annu. Rev. Linguist. 6:213-34", "journal-ref": "Annu. Rev. Linguist. 6:213-34 (2020)", "doi": "10.1146/annurev-linguistics-011619-030303", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Distributional semantics provides multi-dimensional, graded, empirically\ninduced word representations that successfully capture many aspects of meaning\nin natural languages, as shown in a large body of work in computational\nlinguistics; yet, its impact in theoretical linguistics has so far been\nlimited. This review provides a critical discussion of the literature on\ndistributional semantics, with an emphasis on methods and results that are of\nrelevance for theoretical linguistics, in three areas: semantic change,\npolysemy and composition, and the grammar-semantics interface (specifically,\nthe interface of semantics with syntax and with derivational morphology). The\nreview aims at fostering greater cross-fertilization of theoretical and\ncomputational approaches to language, as a means to advance our collective\nknowledge of how it works.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 09:32:28 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 08:24:07 GMT"}, {"version": "v3", "created": "Thu, 4 Jul 2019 09:12:40 GMT"}, {"version": "v4", "created": "Wed, 18 Mar 2020 16:09:19 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Boleda", "Gemma", ""]]}, {"id": "1905.01957", "submitter": "Titouan Parcollet", "authors": "Titouan Parcollet, Mohamed Morchid, Xavier Bost, Georges Linar\\`es", "title": "M2H-GAN: A GAN-based Mapping from Machine to Human Transcripts for\n  Speech Understanding", "comments": "Submitted at INTERSPEECH 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is at the core of recent spoken language understanding (SLU)\nrelated tasks. More precisely, deep neural networks (DNNs) drastically\nincreased the performances of SLU systems, and numerous architectures have been\nproposed. In the real-life context of theme identification of telephone\nconversations, it is common to hold both a human, manual (TRS) and an\nautomatically transcribed (ASR) versions of the conversations. Nonetheless, and\ndue to production constraints, only the ASR transcripts are considered to build\nautomatic classifiers. TRS transcripts are only used to measure the\nperformances of ASR systems. Moreover, the recent performances in term of\nclassification accuracy, obtained by DNN related systems are close to the\nperformances reached by humans, and it becomes difficult to further increase\nthe performances by only considering the ASR transcripts. This paper proposes\nto distillates the TRS knowledge available during the training phase within the\nASR representation, by using a new generative adversarial network called\nM2H-GAN to generate a TRS-like version of an ASR document, to improve the theme\nidentification performances.\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2019 20:04:22 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Parcollet", "Titouan", ""], ["Morchid", "Mohamed", ""], ["Bost", "Xavier", ""], ["Linar\u00e8s", "Georges", ""]]}, {"id": "1905.01958", "submitter": "Alexandre Tomberg", "authors": "Rohollah Soltani and Alexandre Tomberg", "title": "Text2Node: a Cross-Domain System for Mapping Arbitrary Phrases to a\n  Taxonomy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic health record (EHR) systems are used extensively throughout the\nhealthcare domain. However, data interchangeability between EHR systems is\nlimited due to the use of different coding standards across systems. Existing\nmethods of mapping coding standards based on manual human experts mapping,\ndictionary mapping, symbolic NLP and classification are unscalable and cannot\naccommodate large scale EHR datasets.\n  In this work, we present Text2Node, a cross-domain mapping system capable of\nmapping medical phrases to concepts in a large taxonomy (such as SNOMED CT).\nThe system is designed to generalize from a limited set of training samples and\nmap phrases to elements of the taxonomy that are not covered by training data.\nAs a result, our system is scalable, robust to wording variants between coding\nsystems and can output highly relevant concepts when no exact concept exists in\nthe target taxonomy. Text2Node operates in three main stages: first, the\nlexicon is mapped to word embeddings; second, the taxonomy is vectorized using\nnode embeddings; and finally, the mapping function is trained to connect the\ntwo embedding spaces. We compared multiple algorithms and architectures for\neach stage of the training, including GloVe and FastText word embeddings, CNN\nand Bi-LSTM mapping functions, and node2vec for node embeddings. We confirmed\nthe robustness and generalisation properties of Text2Node by mapping ICD-9-CM\nDiagnosis phrases to SNOMED CT and by zero-shot training at comparable\naccuracy.\n  This system is a novel methodological contribution to the task of normalizing\nand linking phrases to a taxonomy, advancing data interchangeability in\nhealthcare. When applied, the system can use electronic health records to\ngenerate an embedding that incorporates taxonomical medical knowledge to\nimprove clinical predictive models.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 17:31:23 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Soltani", "Rohollah", ""], ["Tomberg", "Alexandre", ""]]}, {"id": "1905.01959", "submitter": "Yan Liang", "authors": "Yan Liang, Xin Liu, Jianwen Zhang, Yangqiu Song", "title": "Relation Discovery with Out-of-Relation Knowledge Base as Supervision", "comments": "Aceepted by NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unsupervised relation discovery aims to discover new relations from a given\ntext corpus without annotated data. However, it does not consider existing\nhuman annotated knowledge bases even when they are relevant to the relations to\nbe discovered. In this paper, we study the problem of how to use\nout-of-relation knowledge bases to supervise the discovery of unseen relations,\nwhere out-of-relation means that relations to discover from the text corpus and\nthose in knowledge bases are not overlapped. We construct a set of constraints\nbetween entity pairs based on the knowledge base embedding and then incorporate\nconstraints into the relation discovery by a variational auto-encoder based\nalgorithm. Experiments show that our new approach can improve the\nstate-of-the-art relation discovery performance by a large margin.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 02:30:59 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Liang", "Yan", ""], ["Liu", "Xin", ""], ["Zhang", "Jianwen", ""], ["Song", "Yangqiu", ""]]}, {"id": "1905.01961", "submitter": "Yuan Luo", "authors": "Prakash Adekkanattu, Guoqian Jiang, Yuan Luo, Paul R. Kingsbury,\n  Zhenxing Xu, Luke V. Rasmussen, Jennifer A. Pacheco, Richard C. Kiefer,\n  Daniel J. Stone, Pascal S. Brandt, Liang Yao, Yizhen Zhong, Yu Deng, Fei\n  Wang, Jessica S. Ancker, Thomas R. Campion, Jyotishman Pathak", "title": "Evaluating the Portability of an NLP System for Processing\n  Echocardiograms: A Retrospective, Multi-site Observational Study", "comments": "Under review with AMIA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While natural language processing (NLP) of unstructured clinical narratives\nholds the potential for patient care and clinical research, portability of NLP\napproaches across multiple sites remains a major challenge. This study\ninvestigated the portability of an NLP system developed initially at the\nDepartment of Veterans Affairs (VA) to extract 27 key cardiac concepts from\nfree-text or semi-structured echocardiograms from three academic medical\ncenters: Weill Cornell Medicine, Mayo Clinic and Northwestern Medicine. While\nthe NLP system showed high precision and recall measurements for four target\nconcepts (aortic valve regurgitation, left atrium size at end systole, mitral\nvalve regurgitation, tricuspid valve regurgitation) across all sites, we found\nmoderate or poor results for the remaining concepts and the NLP system\nperformance varied between individual sites.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 02:01:28 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Adekkanattu", "Prakash", ""], ["Jiang", "Guoqian", ""], ["Luo", "Yuan", ""], ["Kingsbury", "Paul R.", ""], ["Xu", "Zhenxing", ""], ["Rasmussen", "Luke V.", ""], ["Pacheco", "Jennifer A.", ""], ["Kiefer", "Richard C.", ""], ["Stone", "Daniel J.", ""], ["Brandt", "Pascal S.", ""], ["Yao", "Liang", ""], ["Zhong", "Yizhen", ""], ["Deng", "Yu", ""], ["Wang", "Fei", ""], ["Ancker", "Jessica S.", ""], ["Campion", "Thomas R.", ""], ["Pathak", "Jyotishman", ""]]}, {"id": "1905.01962", "submitter": "Pedro Sandoval Segura", "authors": "Mehdi Drissi, Pedro Sandoval, Vivaswat Ojha, Julie Medero", "title": "Harvey Mudd College at SemEval-2019 Task 4: The Clint Buchanan\n  Hyperpartisan News Detector", "comments": "Submitted to The 13th International Workshop on Semantic Evaluation\n  (SemEval 2019). 5 pages including references", "journal-ref": null, "doi": "10.18653/v1/S19-2165", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the recently developed Bidirectional Encoder Representations\nfrom Transformers (BERT) model for the hyperpartisan news detection task. Using\na subset of hand-labeled articles from SemEval as a validation set, we test the\nperformance of different parameters for BERT models. We find that accuracy from\ntwo different BERT models using different proportions of the articles is\nconsistently high, with our best-performing model on the validation set\nachieving 85% accuracy and the best-performing model on the test set achieving\n77%. We further determined that our model exhibits strong consistency, labeling\nindependent slices of the same article identically. Finally, we find that\nrandomizing the order of word pieces dramatically reduces validation accuracy\n(to approximately 60%), but that shuffling groups of four or more word pieces\nmaintains an accuracy of about 80%, indicating the model mainly gains value\nfrom local context.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 17:43:51 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Drissi", "Mehdi", ""], ["Sandoval", "Pedro", ""], ["Ojha", "Vivaswat", ""], ["Medero", "Julie", ""]]}, {"id": "1905.01963", "submitter": "Junxin Liu", "authors": "Junxin Liu, Fangzhao Wu, Chuhan Wu, Yongfeng Huang, Xing Xie", "title": "Neural Chinese Word Segmentation with Lexicon and Unlabeled Data via\n  Posterior Regularization", "comments": "7 pages, 11 figures, accepted by the 2019 World Wide Web Conference\n  (WWW '19)", "journal-ref": null, "doi": "10.1145/3308558.3313437", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing methods for CWS usually rely on a large number of labeled sentences\nto train word segmentation models, which are expensive and time-consuming to\nannotate. Luckily, the unlabeled data is usually easy to collect and many\nhigh-quality Chinese lexicons are off-the-shelf, both of which can provide\nuseful information for CWS. In this paper, we propose a neural approach for\nChinese word segmentation which can exploit both lexicon and unlabeled data.\nOur approach is based on a variant of posterior regularization algorithm, and\nthe unlabeled data and lexicon are incorporated into model training as indirect\nsupervision by regularizing the prediction space of CWS models. Extensive\nexperiments on multiple benchmark datasets in both in-domain and cross-domain\nscenarios validate the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 08:21:08 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Liu", "Junxin", ""], ["Wu", "Fangzhao", ""], ["Wu", "Chuhan", ""], ["Huang", "Yongfeng", ""], ["Xie", "Xing", ""]]}, {"id": "1905.01964", "submitter": "Junxin Liu", "authors": "Fangzhao Wu, Junxin Liu, Chuhan Wu, Yongfeng Huang, Xing Xie", "title": "Neural Chinese Named Entity Recognition via CNN-LSTM-CRF and Joint\n  Training with Word Segmentation", "comments": "7 pages, 3 figures, accepted by the 2019 World Wide Web Conference\n  (WWW'19)", "journal-ref": null, "doi": "10.1145/3308558.3313743", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chinese named entity recognition (CNER) is an important task in Chinese\nnatural language processing field. However, CNER is very challenging since\nChinese entity names are highly context-dependent. In addition, Chinese texts\nlack delimiters to separate words, making it difficult to identify the boundary\nof entities. Besides, the training data for CNER in many domains is usually\ninsufficient, and annotating enough training data for CNER is very expensive\nand time-consuming. In this paper, we propose a neural approach for CNER.\nFirst, we introduce a CNN-LSTM-CRF neural architecture to capture both local\nand long-distance contexts for CNER. Second, we propose a unified framework to\njointly train CNER and word segmentation models in order to enhance the ability\nof CNER model in identifying entity boundaries. Third, we introduce an\nautomatic method to generate pseudo labeled samples from existing labeled data\nwhich can enrich the training data. Experiments on two benchmark datasets show\nthat our approach can effectively improve the performance of Chinese named\nentity recognition, especially when training data is insufficient.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 08:09:56 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Wu", "Fangzhao", ""], ["Liu", "Junxin", ""], ["Wu", "Chuhan", ""], ["Huang", "Yongfeng", ""], ["Xie", "Xing", ""]]}, {"id": "1905.01965", "submitter": "Ali Fadel", "authors": "Ali Fadel, Ibraheem Tuffaha, Bara' Al-Jawarneh and Mahmoud Al-Ayyoub", "title": "Arabic Text Diacritization Using Deep Neural Networks", "comments": "7 pages, 4 figures, 15 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diacritization of Arabic text is both an interesting and a challenging\nproblem at the same time with various applications ranging from speech\nsynthesis to helping students learning the Arabic language. Like many other\ntasks or problems in Arabic language processing, the weak efforts invested into\nthis problem and the lack of available (open-source) resources hinder the\nprogress towards solving this problem. This work provides a critical review for\nthe currently existing systems, measures and resources for Arabic text\ndiacritization. Moreover, it introduces a much-needed free-for-all cleaned\ndataset that can be easily used to benchmark any work on Arabic diacritization.\nExtracted from the Tashkeela Corpus, the dataset consists of 55K lines\ncontaining about 2.3M words. After constructing the dataset, existing tools and\nsystems are tested on it. The results of the experiments show that the neural\nShakkala system significantly outperforms traditional rule-based approaches and\nother closed-source tools with a Diacritic Error Rate (DER) of 2.88% compared\nwith 13.78%, which the best DER for the non-neural approach (obtained by the\nMishkal tool).\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 12:29:06 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Fadel", "Ali", ""], ["Tuffaha", "Ibraheem", ""], ["Al-Jawarneh", "Bara'", ""], ["Al-Ayyoub", "Mahmoud", ""]]}, {"id": "1905.01966", "submitter": "Amirreza Shirani", "authors": "Amirreza Shirani, Bowen Xu, David Lo, Thamar Solorio and Amin Alipour", "title": "Question Relatedness on Stack Overflow: The Task, Dataset, and\n  Corpus-inspired Models", "comments": null, "journal-ref": "AAAI 2019 Reasoning for Complex Question Answering Workshop", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Domain-specific community question answering is becoming an integral part of\nprofessions. Finding related questions and answers in these communities can\nsignificantly improve the effectiveness and efficiency of information seeking.\nStack Overflow is one of the most popular communities that is being used by\nmillions of programmers. In this paper, we analyze the problem of predicting\nknowledge unit (question thread) relatedness in Stack Overflow. In particular,\nwe formulate the question relatedness task as a multi-class classification\nproblem with four degrees of relatedness. We present a large-scale dataset with\nmore than 300K pairs. To the best of our knowledge, this dataset is the largest\ndomain-specific dataset for Question-Question relatedness. We present the steps\nthat we took to collect, clean, process, and assure the quality of the dataset.\nThe proposed dataset Stack Overflow is a useful resource to develop novel\nsolutions, specifically data-hungry neural network models, for the prediction\nof relatedness in technical community question-answering forums. We adopt a\nneural network architecture and a traditional model for this task that\neffectively utilize information from different parts of knowledge units to\ncompute the relatedness between them. These models can be used to benchmark\nnovel models, as they perform well in our task and in a closely similar task.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 01:45:50 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 15:35:32 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Shirani", "Amirreza", ""], ["Xu", "Bowen", ""], ["Lo", "David", ""], ["Solorio", "Thamar", ""], ["Alipour", "Amin", ""]]}, {"id": "1905.01967", "submitter": "Ranjan Satapathy", "authors": "Ranjan Satapathy, Aalind Singh, Erik Cambria", "title": "PhonSenticNet: A Cognitive Approach to Microtext Normalization for\n  Concept-Level Sentiment Analysis", "comments": "This paper is submitted to INTERSPEECH2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the current upsurge in the usage of social media platforms, the trend of\nusing short text (microtext) in place of standard words has seen a significant\nrise. The usage of microtext poses a considerable performance issue in\nconcept-level sentiment analysis, since models are trained on standard words.\nThis paper discusses the impact of coupling sub-symbolic (phonetics) with\nsymbolic (machine learning) Artificial Intelligence to transform the\nout-of-vocabulary concepts into their standard in-vocabulary form. The phonetic\ndistance is calculated using the Sorensen similarity algorithm. The\nphonetically similar invocabulary concepts thus obtained are then used to\ncompute the correct polarity value, which was previously being miscalculated\nbecause of the presence of microtext. Our proposed framework increases the\naccuracy of polarity detection by 6% as compared to the earlier model. This\nalso validates the fact that microtext normalization is a necessary\npre-requisite for the sentiment analysis task.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 03:23:38 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Satapathy", "Ranjan", ""], ["Singh", "Aalind", ""], ["Cambria", "Erik", ""]]}, {"id": "1905.01969", "submitter": "Kurt Shuster", "authors": "Samuel Humeau, Kurt Shuster, Marie-Anne Lachaux, Jason Weston", "title": "Poly-encoders: Transformer Architectures and Pre-training Strategies for\n  Fast and Accurate Multi-sentence Scoring", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of deep pre-trained bidirectional transformers has led to remarkable\nprogress in a number of applications (Devlin et al., 2018). For tasks that make\npairwise comparisons between sequences, matching a given input with a\ncorresponding label, two approaches are common: Cross-encoders performing full\nself-attention over the pair and Bi-encoders encoding the pair separately. The\nformer often performs better, but is too slow for practical use. In this work,\nwe develop a new transformer architecture, the Poly-encoder, that learns global\nrather than token level self-attention features. We perform a detailed\ncomparison of all three approaches, including what pre-training and fine-tuning\nstrategies work best. We show our models achieve state-of-the-art results on\nthree existing tasks; that Poly-encoders are faster than Cross-encoders and\nmore accurate than Bi-encoders; and that the best results are obtained by\npre-training on large datasets similar to the downstream tasks.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 02:18:00 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 19:07:46 GMT"}, {"version": "v3", "created": "Wed, 12 Feb 2020 20:07:00 GMT"}, {"version": "v4", "created": "Wed, 25 Mar 2020 22:53:51 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Humeau", "Samuel", ""], ["Shuster", "Kurt", ""], ["Lachaux", "Marie-Anne", ""], ["Weston", "Jason", ""]]}, {"id": "1905.01971", "submitter": "Yong Liu", "authors": "Yong Liu, Pavel Dmitriev, Yifei Huang, Andrew Brooks, Li Dong", "title": "An Evaluation of Transfer Learning for Classifying Sales Engagement\n  Emails at Large Scale", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper conducts an empirical investigation to evaluate transfer learning\nfor classifying sales engagement emails arising from digital sales engagement\nplatforms. Given the complexity of content and context of sales engagement,\nlack of standardized large corpora and benchmarks, limited labeled examples and\nheterogenous context of intent, this real-world use case poses both a challenge\nand an opportunity for adopting a transfer learning approach. We propose an\nevaluation framework to assess a high performance transfer learning (HPTL)\napproach in three key areas in addition to commonly used accuracy metrics: 1)\neffective embeddings and pretrained language model usage, 2) minimum labeled\nsamples requirement and 3) transfer learning implementation strategies. We use\nin-house sales engagement email samples as the experiment dataset, which\nincludes over 3000 emails labeled as positive, objection, unsubscribe, or\nnot-sure. We discuss our findings on evaluating BERT, ELMo, Flair and GloVe\nembeddings with both feature-based and fine-tuning approaches and their\nscalability on a GPU cluster with increasingly larger labeled samples. Our\nresults show that fine-tuning of the BERT model outperforms with as few as 300\nlabeled samples, but underperforms with fewer than 300 labeled samples,\nrelative to all the feature-based approaches using different embeddings.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 18:11:54 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Liu", "Yong", ""], ["Dmitriev", "Pavel", ""], ["Huang", "Yifei", ""], ["Brooks", "Andrew", ""], ["Dong", "Li", ""]]}, {"id": "1905.01972", "submitter": "Kostantinos Papadamou Mr", "authors": "Harris Partaourides, Kostantinos Papadamou, Nicolas Kourtellis, Ilias\n  Leontiadis, and Sotirios Chatzis", "title": "A Self-Attentive Emotion Recognition Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep learning approaches have achieved groundbreaking performance in\nmodeling and classifying sequential data. Specifically, attention networks\nconstitute the state-of-the-art paradigm for capturing long temporal dynamics.\nThis paper examines the efficacy of this paradigm in the challenging task of\nemotion recognition in dyadic conversations. In contrast to existing\napproaches, our work introduces a novel attention mechanism capable of\ninferring the immensity of the effect of each past utterance on the current\nspeaker emotional state. The proposed attention mechanism performs this\ninference procedure without the need of a decoder network; this is achieved by\nmeans of innovative self-attention arguments. Our self-attention networks\ncapture the correlation patterns among consecutive encoder network states, thus\nallowing to robustly and effectively model temporal dynamics over arbitrary\nlong temporal horizons. Thus, we enable capturing strong affective patterns\nover the course of long discussions. We exhibit the effectiveness of our\napproach considering the challenging IEMOCAP benchmark. As we show, our devised\nmethodology outperforms state-of-the-art alternatives and commonly used\napproaches, giving rise to promising new research directions in the context of\nOnline Social Network (OSN) analysis tasks.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 09:46:58 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Partaourides", "Harris", ""], ["Papadamou", "Kostantinos", ""], ["Kourtellis", "Nicolas", ""], ["Leontiadis", "Ilias", ""], ["Chatzis", "Sotirios", ""]]}, {"id": "1905.01973", "submitter": "Simona Maggio", "authors": "B\\'eranger Dumont, Simona Maggio, Ghiles Sidi Said, Quoc-Tien Au", "title": "Who wrote this book? A challenge for e-commerce", "comments": "8 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern e-commerce catalogs contain millions of references, associated with\ntextual and visual information that is of paramount importance for the products\nto be found via search or browsing. Of particular significance is the book\ncategory, where the author name(s) field poses a significant challenge. Indeed,\nbooks written by a given author (such as F. Scott Fitzgerald) might be listed\nwith different authors' names in a catalog due to abbreviations and spelling\nvariants and mistakes, among others. To solve this problem at scale, we design\na composite system involving open data sources for books as well as machine\nlearning components leveraging deep learning-based techniques for natural\nlanguage processing. In particular, we use Siamese neural networks for an\napproximate match with known author names, and direct correction of the\nprovided author's name using sequence-to-sequence learning with neural\nnetworks. We evaluate this approach on product data from the e-commerce website\nRakuten France, and find that the top proposal of the system is the normalized\nauthor name with 72% accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 10:13:07 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Dumont", "B\u00e9ranger", ""], ["Maggio", "Simona", ""], ["Said", "Ghiles Sidi", ""], ["Au", "Quoc-Tien", ""]]}, {"id": "1905.01974", "submitter": "Dong Cao", "authors": "Dong Cao, Dongdong Zhang, HaiBo Chen", "title": "A Novel Task-Oriented Text Corpus in Silent Speech Recognition and its\n  Natural Language Generation Construction Method", "comments": "Accepted for publication in the 3rd International Conference on\n  Natural Language Processing and Information Retrieval, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millions of people with severe speech disorders around the world may regain\ntheir communication capabilities through techniques of silent speech\nrecognition (SSR). Using electroencephalography (EEG) as a biomarker for speech\ndecoding has been popular for SSR. However, the lack of SSR text corpus has\nimpeded the development of this technique. Here, we construct a novel\ntask-oriented text corpus, which is utilized in the field of SSR. In the\nprocess of construction, we propose a task-oriented hybrid construction method\nbased on natural language generation algorithm. The algorithm focuses on the\nstrategy of data-to-text generation, and has two advantages including\nlinguistic quality and high diversity. These two advantages use template-based\nmethod and deep neural networks respectively. In an SSR experiment with the\ngenerated text corpus, analysis results show that the performance of our hybrid\nconstruction method outperforms the pure method such as template-based natural\nlanguage generation or neural natural language generation models.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 08:21:01 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Cao", "Dong", ""], ["Zhang", "Dongdong", ""], ["Chen", "HaiBo", ""]]}, {"id": "1905.01975", "submitter": "David Rau", "authors": "Freek Boutkan, Jorn Ranzijn, David Rau, Eelco van der Wel", "title": "Point-less: More Abstractive Summarization with Pointer-Generator\n  Networks", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Pointer-Generator architecture has shown to be a big improvement for\nabstractive summarization seq2seq models. However, the summaries produced by\nthis model are largely extractive as over 30% of the generated sentences are\ncopied from the source text. This work proposes a multihead attention\nmechanism, pointer dropout, and two new loss functions to promote more\nabstractive summaries while maintaining similar ROUGE scores. Both the\nmultihead attention and dropout do not improve N-gram novelty, however, the\ndropout acts as a regularizer which improves the ROUGE score. The new loss\nfunction achieves significantly higher novel N-grams and sentences, at the cost\nof a slightly lower ROUGE score.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 22:17:21 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Boutkan", "Freek", ""], ["Ranzijn", "Jorn", ""], ["Rau", "David", ""], ["van der Wel", "Eelco", ""]]}, {"id": "1905.01976", "submitter": "Md. Akmal Haidar", "authors": "Md. Akmal Haidar, Mehdi Rezagholizadeh", "title": "TextKD-GAN: Text Generation using KnowledgeDistillation and Generative\n  Adversarial Networks", "comments": "arXiv admin note: text overlap with arXiv:1904.07293", "journal-ref": "32nd Canadian Conference on Artificial Intelligence 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text generation is of particular interest in many NLP applications such as\nmachine translation, language modeling, and text summarization. Generative\nadversarial networks (GANs) achieved a remarkable success in high quality image\ngeneration in computer vision,and recently, GANs have gained lots of interest\nfrom the NLP community as well. However, achieving similar success in NLP would\nbe more challenging due to the discrete nature of text. In this work, we\nintroduce a method using knowledge distillation to effectively exploit GAN\nsetup for text generation. We demonstrate how autoencoders (AEs) can be used\nfor providing a continuous representation of sentences, which is a smooth\nrepresentation that assign non-zero probabilities to more than one word. We\ndistill this representation to train the generator to synthesize similar smooth\nrepresentations. We perform a number of experiments to validate our idea using\ndifferent datasets and show that our proposed approach yields better\nperformance in terms of the BLEU score and Jensen-Shannon distance (JSD)\nmeasure compared to traditional GAN-based text generation approaches without\npre-training.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 15:15:12 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Haidar", "Md. Akmal", ""], ["Rezagholizadeh", "Mehdi", ""]]}, {"id": "1905.01978", "submitter": "Arthur Szlam", "authors": "Yacine Jernite, Kavya Srinet, Jonathan Gray, Arthur Szlam", "title": "CraftAssist Instruction Parsing: Semantic Parsing for a Minecraft\n  Assistant", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a large scale semantic parsing dataset focused on\ninstruction-driven communication with an agent in Minecraft. We describe the\ndata collection process which yields additional 35K human generated\ninstructions with their semantic annotations. We report the performance of\nthree baseline models and find that while a dataset of this size helps us train\na usable instruction parser, it still poses interesting generalization\nchallenges which we hope will help develop better and more robust models.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 19:55:20 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Jernite", "Yacine", ""], ["Srinet", "Kavya", ""], ["Gray", "Jonathan", ""], ["Szlam", "Arthur", ""]]}, {"id": "1905.01984", "submitter": "Bin Guo", "authors": "Qiuyun Zhang, Bin Guo, Hao Wang, Yunji Liang, Shaoyang Hao, Zhiwen Yu", "title": "AI-Powered Text Generation for Harmonious Human-Machine Interaction:\n  Current State and Future Directions", "comments": "Accepted by IEEE UIC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last two decades, the landscape of text generation has undergone\ntremendous changes and is being reshaped by the success of deep learning. New\ntechnologies for text generation ranging from template-based methods to neural\nnetwork-based methods emerged. Meanwhile, the research objectives have also\nchanged from generating smooth and coherent sentences to infusing personalized\ntraits to enrich the diversification of newly generated content. With the rapid\ndevelopment of text generation solutions, one comprehensive survey is urgent to\nsummarize the achievements and track the state of the arts. In this survey\npaper, we present the general systematical framework, illustrate the widely\nutilized models and summarize the classic applications of text generation.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 23:26:38 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Zhang", "Qiuyun", ""], ["Guo", "Bin", ""], ["Wang", "Hao", ""], ["Liang", "Yunji", ""], ["Hao", "Shaoyang", ""], ["Yu", "Zhiwen", ""]]}, {"id": "1905.01987", "submitter": "Fahim Faisal", "authors": "Fahim Faisal (1), Shafkat Ahmed Bhuiyan (1), Dr. Abu Raihan Mostofa\n  Kamal (1) ((1) Islamic University of Technology)", "title": "Disease Identification From Unstructured User Input", "comments": "This was an undergraduate research. The hypotheses it proposes is\n  based on a small number of samples and thus, can not be declared significant.\n  To declare it significant, a large number of sample testing is needed. After\n  that, it can be put through", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method to identify probable diseases from the unstructured textual input\n(eg, health forum posts) by incorporating a lexicographic and semantic feature\nbased two-phase text classification module and a symptom-disease\ncorrelation-based similarity measurement module. One notable aspect of my\napproach was to develop a competent algorithm to extract all inherent features\nfrom the data source to make a better decision.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 05:10:48 GMT"}, {"version": "v2", "created": "Fri, 10 May 2019 11:18:08 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Faisal", "Fahim", "", "Islamic University of Technology"], ["Bhuiyan", "Shafkat Ahmed", "", "Islamic University of Technology"], ["Kamal", "Dr. Abu Raihan Mostofa", "", "Islamic University of Technology"]]}, {"id": "1905.01988", "submitter": "Xianbin Hong", "authors": "Xianbin Hong, Gautam Pal, Sheng-Uei Guan, Prudence Wong, Dawei Liu, Ka\n  Lok Man, Xin Huang", "title": "Semi-Unsupervised Lifelong Learning for Sentiment Classification: Less\n  Manual Data Annotation and More Self-Studying", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lifelong machine learning is a novel machine learning paradigm which can\ncontinually accumulate knowledge during learning. The knowledge extracting and\nreusing abilities enable the lifelong machine learning to solve the related\nproblems. The traditional approaches like Na\\\"ive Bayes and some neural network\nbased approaches only aim to achieve the best performance upon a single task.\nUnlike them, the lifelong machine learning in this paper focuses on how to\naccumulate knowledge during learning and leverage them for further tasks.\nMeanwhile, the demand for labelled data for training also is significantly\ndecreased with the knowledge reusing. This paper suggests that the aim of the\nlifelong learning is to use less labelled data and computational cost to\nachieve the performance as well as or even better than the supervised learning.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 23:56:54 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 21:54:10 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Hong", "Xianbin", ""], ["Pal", "Gautam", ""], ["Guan", "Sheng-Uei", ""], ["Wong", "Prudence", ""], ["Liu", "Dawei", ""], ["Man", "Ka Lok", ""], ["Huang", "Xin", ""]]}, {"id": "1905.01992", "submitter": "Oluwatobi Olabiyi", "authors": "Oluwatobi Olabiyi, Anish Khazane, Alan Salimov, Erik T. Mueller", "title": "An Adversarial Learning Framework For A Persona-Based Multi-Turn\n  Dialogue Model", "comments": "NAACL NeuralGen Workshop 2019. arXiv admin note: substantial text\n  overlap with arXiv:1905.01998", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, we extend the persona-based sequence-to-sequence (Seq2Seq)\nneural network conversation model to a multi-turn dialogue scenario by\nmodifying the state-of-the-art hredGAN architecture to simultaneously capture\nutterance attributes such as speaker identity, dialogue topic, speaker\nsentiments and so on. The proposed system, phredGAN has a persona-based HRED\ngenerator (PHRED) and a conditional discriminator. We also explore two\napproaches to accomplish the conditional discriminator: (1) phredGAN_a, a\nsystem that passes the attribute representation as an additional input into a\ntraditional adversarial discriminator, and (2) phredGAN_d, a dual discriminator\nsystem which in addition to the adversarial discriminator, collaboratively\npredicts the attribute(s) that generated the input utterance. To demonstrate\nthe superior performance of phredGAN over the persona Seq2Seq model, we\nexperiment with two conversational datasets, the Ubuntu Dialogue Corpus (UDC)\nand TV series transcripts from the Big Bang Theory and Friends. Performance\ncomparison is made with respect to a variety of quantitative measures as well\nas crowd-sourced human evaluation. We also explore the trade-offs from using\neither variant of phredGAN on datasets with many but weak attribute modalities\n(such as with Big Bang Theory and Friends) and ones with few but strong\nattribute modalities (customer-agent interactions in Ubuntu dataset).\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 15:21:13 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 14:43:11 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Olabiyi", "Oluwatobi", ""], ["Khazane", "Anish", ""], ["Salimov", "Alan", ""], ["Mueller", "Erik T.", ""]]}, {"id": "1905.01994", "submitter": "Chenliang Li", "authors": "Shiqian Chen, Chenliang Li, Feng Ji, Wei Zhou, Haiqing Chen", "title": "Review-Driven Answer Generation for Product-Related Questions in\n  E-Commerce", "comments": null, "journal-ref": "WSDM 2019", "doi": null, "report-no": "https://dl.acm.org/citation.cfm?doid=3289600.3290971", "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The users often have many product-related questions before they make a\npurchase decision in E-commerce. However, it is often time-consuming to examine\neach user review to identify the desired information. In this paper, we propose\na novel review-driven framework for answer generation for product-related\nquestions in E-commerce, named RAGE. We develope RAGE on the basis of the\nmulti-layer convolutional architecture to facilitate speed-up of answer\ngeneration with the parallel computation. For each question, RAGE first\nextracts the relevant review snippets from the reviews of the corresponding\nproduct. Then, we devise a mechanism to identify the relevant information from\nthe noise-prone review snippets and incorporate this information to guide the\nanswer generation. The experiments on two real-world E-Commerce datasets show\nthat the proposed RAGE significantly outperforms the existing alternatives in\nproducing more accurate and informative answers in natural language. Moreover,\nRAGE takes much less time for both model training and answer generation than\nthe existing RNN based generation models.\n", "versions": [{"version": "v1", "created": "Sat, 27 Apr 2019 01:57:28 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Chen", "Shiqian", ""], ["Li", "Chenliang", ""], ["Ji", "Feng", ""], ["Zhou", "Wei", ""], ["Chen", "Haiqing", ""]]}, {"id": "1905.01995", "submitter": "Lin Li", "authors": "Lin Li, Mengjing Zhang, Zhaohui Chao, Jianwen Xiang", "title": "Using Context Information to Enhance Simple Question Answering", "comments": "under review World Wide Web Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of knowledge bases(KBs),question\nanswering(QA)based on KBs has become a hot research issue. In this paper,we\npropose two frameworks(i.e.,pipeline framework,an end-to-end framework)to focus\nanswering single-relation factoid question. In both of two frameworks,we study\nthe effect of context information on the quality of QA,such as the entity's\nnotable type,out-degree. In the end-to-end framework,we combine char-level\nencoding and self-attention mechanisms,using weight sharing and multi-task\nstrategies to enhance the accuracy of QA. Experimental results show that\ncontext information can get better results of simple QA whether it is the\npipeline framework or the end-to-end framework. In addition,we find that the\nend-to-end framework achieves results competitive with state-of-the-art\napproaches in terms of accuracy and take much shorter time than them.\n", "versions": [{"version": "v1", "created": "Sat, 27 Apr 2019 12:57:24 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Li", "Lin", ""], ["Zhang", "Mengjing", ""], ["Chao", "Zhaohui", ""], ["Xiang", "Jianwen", ""]]}, {"id": "1905.01996", "submitter": "Maulik Parmar", "authors": "Maulik Parmar, V.Susheela Devi", "title": "Neural Machine Translation with Recurrent Highway Networks", "comments": "International Conference on Mining Intelligence and Knowledge\n  Exploration", "journal-ref": "In: Groza A., Prasath R. (eds) Mining Intelligence and Knowledge\n  Exploration. MIKE 2018. Lecture Notes in Computer Science, vol 11308.\n  Springer, Cham", "doi": "10.1007/978-3-030-05918-7_27", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks have lately gained a lot of popularity in language\nmodelling tasks, especially in neural machine translation(NMT). Very recent NMT\nmodels are based on Encoder-Decoder, where a deep LSTM based encoder is used to\nproject the source sentence to a fixed dimensional vector and then another deep\nLSTM decodes the target sentence from the vector. However there has been very\nlittle work on exploring architectures that have more than one layer in\nspace(i.e. in each time step). This paper examines the effectiveness of the\nsimple Recurrent Highway Networks(RHN) in NMT tasks. The model uses Recurrent\nHighway Neural Network in encoder and decoder, with attention .We also explore\nthe reconstructor model to improve adequacy. We demonstrate the effectiveness\nof all three approaches on the IWSLT English-Vietnamese dataset. We see that\nRHN performs on par with LSTM based models and even better in some cases.We see\nthat deep RHN models are easy to train compared to deep LSTM based models\nbecause of highway connections. The paper also investigates the effects of\nincreasing recurrent depth in each time step.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 08:27:55 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Parmar", "Maulik", ""], ["Devi", "V. Susheela", ""]]}, {"id": "1905.01998", "submitter": "Oluwatobi Olabiyi", "authors": "Oluwatobi O. Olabiyi, Anish Khazane, Erik T. Mueller", "title": "A Persona-based Multi-turn Conversation Model in an Adversarial Learning\n  Framework", "comments": "2018 17th IEEE International Conference on Machine Learning and\n  Applications (ICMLA). arXiv admin note: substantial text overlap with\n  arXiv:1905.01992", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, we extend the persona-based sequence-to-sequence (Seq2Seq)\nneural network conversation model to multi-turn dialogue by modifying the\nstate-of-the-art hredGAN architecture. To achieve this, we introduce an\nadditional input modality into the encoder and decoder of hredGAN to capture\nother attributes such as speaker identity, location, sub-topics, and other\nexternal attributes that might be available from the corpus of human-to-human\ninteractions. The resulting persona hredGAN ($phredGAN$) shows better\nperformance than both the existing persona-based Seq2Seq and hredGAN models\nwhen those external attributes are available in a multi-turn dialogue corpus.\nThis superiority is demonstrated on TV drama series with character consistency\n(such as Big Bang Theory and Friends) and customer service interaction datasets\nsuch as Ubuntu dialogue corpus in terms of perplexity, BLEU, ROUGE, and\nDistinct n-gram scores.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 15:09:34 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Olabiyi", "Oluwatobi O.", ""], ["Khazane", "Anish", ""], ["Mueller", "Erik T.", ""]]}, {"id": "1905.02019", "submitter": "Heguang Liu", "authors": "Heguang Liu", "title": "Conditioning LSTM Decoder and Bi-directional Attention Based Question\n  Answering System", "comments": "7 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying neural-networks on Question Answering has gained increasing\npopularity in recent years. In this paper, I implemented a model with\nBi-directional attention flow layer, connected with a Multi-layer LSTM encoder,\nconnected with one start-index decoder and one conditioning end-index decoder.\nI introduce a new end-index decoder layer, conditioning on start-index output.\nThe Experiment shows this has increased model performance by 15.16%. For\nprediction, I proposed a new smart-span equation, rewarding both short answer\nlength and high probability in start-index and end-index, which further\nimproved the prediction accuracy. The best single model achieves an F1 score of\n73.97% and EM score of 64.95% on test set.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 01:07:20 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Liu", "Heguang", ""]]}, {"id": "1905.02239", "submitter": "Atul Kr. Ojha Dr", "authors": "Atul Kr. Ojha", "title": "English-Bhojpuri SMT System: Insights from the Karaka Model", "comments": "211 pages and Submitted at JNU New Delhi", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This thesis has been divided into six chapters namely: Introduction, Karaka\nModel and it impacts on Dependency Parsing, LT Resources for Bhojpuri,\nEnglish-Bhojpuri SMT System: Experiment, Evaluation of EB-SMT System, and\nConclusion. Chapter one introduces this PhD research by detailing the\nmotivation of the study, the methodology used for the study and the literature\nreview of the existing MT related work in Indian Languages. Chapter two talks\nof the theoretical background of Karaka and Karaka model. Along with this, it\ntalks about previous related work. It also discusses the impacts of the Karaka\nmodel in NLP and dependency parsing. It compares Karaka dependency and\nUniversal Dependency. It also presents a brief idea of the implementation of\nthese models in the SMT system for English-Bhojpuri language pair.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 19:04:57 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Ojha", "Atul Kr.", ""]]}, {"id": "1905.02265", "submitter": "Xusen Yin", "authors": "Xusen Yin and Jonathan May", "title": "Comprehensible Context-driven Text Game Playing", "comments": "IEEE Conference on Games 2019 Long Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to train a computer agent to play a text-based computer game, we\nmust represent each hidden state of the game. A Long Short-Term Memory (LSTM)\nmodel running over observed texts is a common choice for state construction.\nHowever, a normal Deep Q-learning Network (DQN) for such an agent requires\nmillions of steps of training or more to converge. As such, an LSTM-based DQN\ncan take tens of days to finish the training process. Though we can use a\nConvolutional Neural Network (CNN) as a text-encoder to construct states much\nfaster than the LSTM, doing so without an understanding of the syntactic\ncontext of the words being analyzed can slow convergence. In this paper, we use\na fast CNN to encode position- and syntax-oriented structures extracted from\nobserved texts as states. We additionally augment the reward signal in a\nuniversal and practical manner. Together, we show that our improvements can not\nonly speed up the process by one order of magnitude but also learn a superior\nagent.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 21:14:41 GMT"}, {"version": "v2", "created": "Sun, 2 Jun 2019 02:48:31 GMT"}, {"version": "v3", "created": "Thu, 29 Aug 2019 11:50:00 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Yin", "Xusen", ""], ["May", "Jonathan", ""]]}, {"id": "1905.02283", "submitter": "Li Yao", "authors": "Tobi Olatunji, Li Yao, Ben Covington, Alexander Rhodes, Anthony Upton", "title": "Caveats in Generating Medical Imaging Labels from Radiology Reports", "comments": "Accepted workshop contribution for Medical Imaging with Deep Learning\n  (MIDL), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acquiring high-quality annotations in medical imaging is usually a costly\nprocess. Automatic label extraction with natural language processing (NLP) has\nemerged as a promising workaround to bypass the need of expert annotation.\nDespite the convenience, the limitation of such an approximation has not been\ncarefully examined and is not well understood. With a challenging set of 1,000\nchest X-ray studies and their corresponding radiology reports, we show that\nthere exists a surprisingly large discrepancy between what radiologists\nvisually perceive and what they clinically report. Furthermore, with inherently\nflawed report as ground truth, the state-of-the-art medical NLP fails to\nproduce high-fidelity labels.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 22:38:18 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Olatunji", "Tobi", ""], ["Yao", "Li", ""], ["Covington", "Ben", ""], ["Rhodes", "Alexander", ""], ["Upton", "Anthony", ""]]}, {"id": "1905.02430", "submitter": "Iva Gornishka", "authors": "Iva Gornishka, Stevan Rudinac, Marcel Worring", "title": "Interactive Search and Exploration in Online Discussion Forums Using\n  Multimodal Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a novel interactive multimodal learning system,\nwhich facilitates search and exploration in large networks of social multimedia\nusers. It allows the analyst to identify and select users of interest, and to\nfind similar users in an interactive learning setting. Our approach is based on\nnovel multimodal representations of users, words and concepts, which we\nsimultaneously learn by deploying a general-purpose neural embedding model. We\nshow these representations to be useful not only for categorizing users, but\nalso for automatically generating user and community profiles. Inspired by\ntraditional summarization approaches, we create the profiles by selecting\ndiverse and representative content from all available modalities, i.e. the\ntext, image and user modality. The usefulness of the approach is evaluated\nusing artificial actors, which simulate user behavior in a relevance feedback\nscenario. Multiple experiments were conducted in order to evaluate the quality\nof our multimodal representations, to compare different embedding strategies,\nand to determine the importance of different modalities. We demonstrate the\ncapabilities of the proposed approach on two different multimedia collections\noriginating from the violent online extremism forum Stormfront and the\nmicroblogging platform Twitter, which are particularly interesting due to the\nhigh semantic level of the discussions they feature.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 09:23:12 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Gornishka", "Iva", ""], ["Rudinac", "Stevan", ""], ["Worring", "Marcel", ""]]}, {"id": "1905.02450", "submitter": "Kaitao Song", "authors": "Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, Tie-Yan Liu", "title": "MASS: Masked Sequence to Sequence Pre-training for Language Generation", "comments": "Accepted by ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-training and fine-tuning, e.g., BERT, have achieved great success in\nlanguage understanding by transferring knowledge from rich-resource\npre-training task to the low/zero-resource downstream tasks. Inspired by the\nsuccess of BERT, we propose MAsked Sequence to Sequence pre-training (MASS) for\nthe encoder-decoder based language generation tasks. MASS adopts the\nencoder-decoder framework to reconstruct a sentence fragment given the\nremaining part of the sentence: its encoder takes a sentence with randomly\nmasked fragment (several consecutive tokens) as input, and its decoder tries to\npredict this masked fragment. In this way, MASS can jointly train the encoder\nand decoder to develop the capability of representation extraction and language\nmodeling. By further fine-tuning on a variety of zero/low-resource language\ngeneration tasks, including neural machine translation, text summarization and\nconversational response generation (3 tasks and totally 8 datasets), MASS\nachieves significant improvements over the baselines without pre-training or\nwith other pre-training methods. Specially, we achieve the state-of-the-art\naccuracy (37.5 in terms of BLEU score) on the unsupervised English-French\ntranslation, even beating the early attention-based supervised model.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 10:13:04 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 06:46:26 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 11:43:27 GMT"}, {"version": "v4", "created": "Tue, 11 Jun 2019 03:43:41 GMT"}, {"version": "v5", "created": "Fri, 21 Jun 2019 04:36:52 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Song", "Kaitao", ""], ["Tan", "Xu", ""], ["Qin", "Tao", ""], ["Lu", "Jianfeng", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1905.02497", "submitter": "Sudip Mittal", "authors": "Aditya Pingle, Aritran Piplai, Sudip Mittal, Anupam Joshi, James Holt,\n  Richard Zak", "title": "RelExt: Relation Extraction using Deep Learning approaches for\n  Cybersecurity Knowledge Graph Improvement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security Analysts that work in a `Security Operations Center' (SoC) play a\nmajor role in ensuring the security of the organization. The amount of\nbackground knowledge they have about the evolving and new attacks makes a\nsignificant difference in their ability to detect attacks. Open source threat\nintelligence sources, like text descriptions about cyber-attacks, can be stored\nin a structured fashion in a cybersecurity knowledge graph. A cybersecurity\nknowledge graph can be paramount in aiding a security analyst to detect cyber\nthreats because it stores a vast range of cyber threat information in the form\nof semantic triples which can be queried. A semantic triple contains two\ncybersecurity entities with a relationship between them. In this work, we\npropose a system to create semantic triples over cybersecurity text, using deep\nlearning approaches to extract possible relationships. We use the set of\nsemantic triples generated through our system to assert in a cybersecurity\nknowledge graph. Security Analysts can retrieve this data from the knowledge\ngraph, and use this information to form a decision about a cyber-attack.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 12:30:55 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 13:49:36 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Pingle", "Aditya", ""], ["Piplai", "Aritran", ""], ["Mittal", "Sudip", ""], ["Joshi", "Anupam", ""], ["Holt", "James", ""], ["Zak", "Richard", ""]]}, {"id": "1905.02525", "submitter": "Gokce Keskin", "authors": "Gokce Keskin, Tyler Lee, Cory Stephenson and Oguz H. Elibol", "title": "Many-to-Many Voice Conversion with Out-of-Dataset Speaker Support", "comments": "Submitted to Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Cycle-GAN based many-to-many voice conversion method that can\nconvert between speakers that are not in the training set. This property is\nenabled through speaker embeddings generated by a neural network that is\njointly trained with the Cycle-GAN. In contrast to prior work in this domain,\nour method enables conversion between an out-of-dataset speaker and a target\nspeaker in either direction and does not require re-training. Out-of-dataset\nspeaker conversion quality is evaluated using an independently trained speaker\nidentification model, and shows good style conversion characteristics for\npreviously unheard speakers. Subjective tests on human listeners show style\nconversion quality for in-dataset speakers is comparable to the\nstate-of-the-art baseline model.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 15:35:25 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Keskin", "Gokce", ""], ["Lee", "Tyler", ""], ["Stephenson", "Cory", ""], ["Elibol", "Oguz H.", ""]]}, {"id": "1905.02545", "submitter": "Takuya Yoshioka", "authors": "Takuya Yoshioka, Zhuo Chen, Dimitrios Dimitriadis, William Hinthorn,\n  Xuedong Huang, Andreas Stolcke, Michael Zeng", "title": "Meeting Transcription Using Virtual Microphone Arrays", "comments": null, "journal-ref": null, "doi": null, "report-no": "MSR-TR-2019-11", "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a system that generates speaker-annotated transcripts of meetings\nby using a virtual microphone array, a set of spatially distributed\nasynchronous recording devices such as laptops and mobile phones. The system is\ncomposed of continuous audio stream alignment, blind beamforming, speech\nrecognition, speaker diarization using prior speaker information, and system\ncombination. When utilizing seven input audio streams, our system achieves a\nword error rate (WER) of 22.3% and comes within 3% of the close-talking\nmicrophone WER on the non-overlapping speech segments. The speaker-attributed\nWER (SAWER) is 26.7%. The relative gains in SAWER over the single-device system\nare 14.8%, 20.3%, and 22.4% for three, five, and seven microphones,\nrespectively. The presented system achieves a 13.6% diarization error rate when\n10% of the speech duration contains more than one speaker. The contribution of\neach component to the overall performance is also investigated, and we validate\nthe system with experiments on the NIST RT-07 conference meeting test set.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 10:30:17 GMT"}, {"version": "v2", "created": "Sun, 7 Jul 2019 11:23:21 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Yoshioka", "Takuya", ""], ["Chen", "Zhuo", ""], ["Dimitriadis", "Dimitrios", ""], ["Hinthorn", "William", ""], ["Huang", "Xuedong", ""], ["Stolcke", "Andreas", ""], ["Zeng", "Michael", ""]]}, {"id": "1905.02623", "submitter": "Nataliya Shakhovska Prof", "authors": "Nataliya Shakhovska, Taras Cherna", "title": "The method of automatic summarization from different sources", "comments": null, "journal-ref": "ECONTECHMOD. AN INTERNATIONAL QUARTERLY JOURNAL - 2016. Vol. 5.\n  No. 1. 103-109", "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article is analyzed technology of automatic text abstracting and\nannotation. The role of annotation in automatic search and classification for\ndifferent scientific articles is described. The algorithm of summarization of\nnatural language documents using the concept of importance coefficients is\ndeveloped. Such concept allows considering the peculiarity of subject areas and\ntopics that could be found in different kinds of documents. Method for\ngenerating abstracts of single document based on frequency analysis is\ndeveloped. The recognition elements for unstructured text analysis are given.\nThe method of pre-processing analysis of several documents is developed. This\ntechnique simultaneously considers both statistical approaches to abstracting\nand the importance of terms in a particular subject domain. The quality of\ngenerated abstract is evaluated. For the developed system there was conducted\nexperts evaluation. It was held only for texts in Ukrainian. The developed\nsystem concluding essay has higher aggregate score on all criteria. The\nsummarization system architecture is building. To build an information system\nmodel there is used CASE-tool AllFusion ERwin Data Modeler. The database scheme\nfor information saving was built. The system is designed to work primarily with\nUkrainian texts, which gives a significant advantage, since most modern systems\nstill oriented to English texts\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 02:56:14 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Shakhovska", "Nataliya", ""], ["Cherna", "Taras", ""]]}, {"id": "1905.02712", "submitter": "Emmi Bevensee", "authors": "Emmi Bevensee and Alexander Reid Ross", "title": "The Alt-Right and Global Information Warfare", "comments": "Presented and published through IEEE 2019 Big Data Conference", "journal-ref": "2018 IEEE International Conference on Big Data (Big Data),\n  4393-4402", "doi": "10.1109/BigData.2018.8622270", "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Alt-Right is a neo-fascist white supremacist movement that is involved in\nviolent extremism and shows signs of engagement in extensive disinformation\ncampaigns. Using social media data mining, this study develops a deeper\nunderstanding of such targeted disinformation campaigns and the ways they\nspread. It also adds to the available literature on the endogenous and\nexogenous influences within the US far right, as well as motivating factors\nthat drive disinformation campaigns, such as geopolitical strategy. This study\nis to be taken as a preliminary analysis to indicate future methods and\nfollow-on research that will help develop an integrated approach to\nunderstanding the strategies and associations of the modern fascist movement.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 17:53:21 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Bevensee", "Emmi", ""], ["Ross", "Alexander Reid", ""]]}, {"id": "1905.02851", "submitter": "Tomohide Shibata", "authors": "Wataru Sakata, Tomohide Shibata, Ribeka Tanaka, Sadao Kurohashi", "title": "FAQ Retrieval using Query-Question Similarity and BERT-Based\n  Query-Answer Relevance", "comments": "Accepted in SIGIR 2019 (short paper), camera ready, 4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Frequently Asked Question (FAQ) retrieval is an important task where the\nobjective is to retrieve an appropriate Question-Answer (QA) pair from a\ndatabase based on a user's query. We propose a FAQ retrieval system that\nconsiders the similarity between a user's query and a question as well as the\nrelevance between the query and an answer. Although a common approach to FAQ\nretrieval is to construct labeled data for training, it takes annotation costs.\nTherefore, we use a traditional unsupervised information retrieval system to\ncalculate the similarity between the query and question. On the other hand, the\nrelevance between the query and answer can be learned by using QA pairs in a\nFAQ database. The recently-proposed BERT model is used for the relevance\ncalculation. Since the number of QA pairs in FAQ page is not enough to train a\nmodel, we cope with this issue by leveraging FAQ sets that are similar to the\none in question. We evaluate our approach on two datasets. The first one is\nlocalgovFAQ, a dataset we construct in a Japanese administrative municipality\ndomain. The second is StackExchange dataset, which is the public dataset in\nEnglish. We demonstrate that our proposed method outperforms baseline methods\non these datasets.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 00:33:37 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 00:14:18 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Sakata", "Wataru", ""], ["Shibata", "Tomohide", ""], ["Tanaka", "Ribeka", ""], ["Kurohashi", "Sadao", ""]]}, {"id": "1905.02869", "submitter": "Sagar Indurkhya", "authors": "Sagar Indurkhya", "title": "Automatic Inference of Minimalist Grammars using an SMT-Solver", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce (1) a novel parser for Minimalist Grammars (MG), encoded as a\nsystem of first-order logic formulae that may be evaluated using an SMT-solver,\nand (2) a novel procedure for inferring Minimalist Grammars using this parser.\nThe input to this procedure is a sequence of sentences that have been annotated\nwith syntactic relations such as semantic role labels (connecting arguments to\npredicates) and subject-verb agreement. The output of this procedure is a set\nof minimalist grammars, each of which is able to parse the sentences in the\ninput sequence such that the parse for a sentence has the same syntactic\nrelations as those specified in the annotation for that sentence. We applied\nthis procedure to a set of sentences annotated with syntactic relations and\nevaluated the inferred grammars using cost functions inspired by the Minimum\nDescription Length principle and the Subset principle. Inferred grammars that\nwere optimal with respect to certain combinations of these cost functions were\nfound to align with contemporary theories of syntax.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 02:12:18 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Indurkhya", "Sagar", ""]]}, {"id": "1905.02878", "submitter": "Meishan Zhang", "authors": "Meishan Zhang, Zhenghua Li, Guohong Fu, Min Zhang", "title": "Syntax-Enhanced Neural Machine Translation with Syntax-Aware Word\n  Representations", "comments": "NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Syntax has been demonstrated highly effective in neural machine translation\n(NMT). Previous NMT models integrate syntax by representing 1-best tree outputs\nfrom a well-trained parsing system, e.g., the representative Tree-RNN and\nTree-Linearization methods, which may suffer from error propagation. In this\nwork, we propose a novel method to integrate source-side syntax implicitly for\nNMT. The basic idea is to use the intermediate hidden representations of a\nwell-trained end-to-end dependency parser, which are referred to as\nsyntax-aware word representations (SAWRs). Then, we simply concatenate such\nSAWRs with ordinary word embeddings to enhance basic NMT models. The method can\nbe straightforwardly integrated into the widely-used sequence-to-sequence\n(Seq2Seq) NMT models. We start with a representative RNN-based Seq2Seq baseline\nsystem, and test the effectiveness of our proposed method on two benchmark\ndatasets of the Chinese-English and English-Vietnamese translation tasks,\nrespectively. Experimental results show that the proposed approach is able to\nbring significant BLEU score improvements on the two datasets compared with the\nbaseline, 1.74 points for Chinese-English translation and 0.80 point for\nEnglish-Vietnamese translation, respectively. In addition, the approach also\noutperforms the explicit Tree-RNN and Tree-Linearization methods.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 02:56:43 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Zhang", "Meishan", ""], ["Li", "Zhenghua", ""], ["Fu", "Guohong", ""], ["Zhang", "Min", ""]]}, {"id": "1905.02895", "submitter": "Sudip Mittal", "authors": "Sudip Mittal, Anupam Joshi, Tim Finin", "title": "Cyber-All-Intel: An AI for Security related Threat Intelligence", "comments": "arXiv admin note: substantial text overlap with arXiv:1708.03310", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keeping up with threat intelligence is a must for a security analyst today.\nThere is a volume of information present in `the wild' that affects an\norganization. We need to develop an artificial intelligence system that scours\nthe intelligence sources, to keep the analyst updated about various threats\nthat pose a risk to her organization. A security analyst who is better `tapped\nin' can be more effective.\n  In this paper we present, Cyber-All-Intel an artificial intelligence system\nto aid a security analyst. It is a system for knowledge extraction,\nrepresentation and analytics in an end-to-end pipeline grounded in the\ncybersecurity informatics domain. It uses multiple knowledge representations\nlike, vector spaces and knowledge graphs in a 'VKG structure' to store incoming\nintelligence. The system also uses neural network models to pro-actively\nimprove its knowledge. We have also created a query engine and an alert system\nthat can be used by an analyst to find actionable cybersecurity insights.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 12:15:32 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Mittal", "Sudip", ""], ["Joshi", "Anupam", ""], ["Finin", "Tim", ""]]}, {"id": "1905.02925", "submitter": "Panos Achlioptas", "authors": "Panos Achlioptas, Judy Fan, Robert X.D. Hawkins, Noah D. Goodman,\n  Leonidas J. Guibas", "title": "ShapeGlot: Learning Language for Shape Differentiation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we explore how fine-grained differences between the shapes of\ncommon objects are expressed in language, grounded on images and 3D models of\nthe objects. We first build a large scale, carefully controlled dataset of\nhuman utterances that each refers to a 2D rendering of a 3D CAD model so as to\ndistinguish it from a set of shape-wise similar alternatives. Using this\ndataset, we develop neural language understanding (listening) and production\n(speaking) models that vary in their grounding (pure 3D forms via point-clouds\nvs. rendered 2D images), the degree of pragmatic reasoning captured (e.g.\nspeakers that reason about a listener or not), and the neural architecture\n(e.g. with or without attention). We find models that perform well with both\nsynthetic and human partners, and with held out utterances and objects. We also\nfind that these models are amenable to zero-shot transfer learning to novel\nobject classes (e.g. transfer from training on chairs to testing on lamps), as\nwell as to real-world images drawn from furniture catalogs. Lesion studies\nindicate that the neural listeners depend heavily on part-related words and\nassociate these words correctly with visual parts of objects (without any\nexplicit network training on object parts), and that transfer to novel classes\nis most successful when known part-words are available. This work illustrates a\npractical approach to language grounding, and provides a case study in the\nrelationship between object shape and linguistic structure when it comes to\nobject differentiation.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 06:01:33 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Achlioptas", "Panos", ""], ["Fan", "Judy", ""], ["Hawkins", "Robert X. D.", ""], ["Goodman", "Noah D.", ""], ["Guibas", "Leonidas J.", ""]]}, {"id": "1905.02947", "submitter": "Soujanya Poria", "authors": "Soujanya Poria, Navonil Majumder, Rada Mihalcea, Eduard Hovy", "title": "Emotion Recognition in Conversation: Research Challenges, Datasets, and\n  Recent Advances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Emotion is intrinsic to humans and consequently emotion understanding is a\nkey part of human-like artificial intelligence (AI). Emotion recognition in\nconversation (ERC) is becoming increasingly popular as a new research frontier\nin natural language processing (NLP) due to its ability to mine opinions from\nthe plethora of publicly available conversational data in platforms such as\nFacebook, Youtube, Reddit, Twitter, and others. Moreover, it has potential\napplications in health-care systems (as a tool for psychological analysis),\neducation (understanding student frustration) and more. Additionally, ERC is\nalso extremely important for generating emotion-aware dialogues that require an\nunderstanding of the user's emotions. Catering to these needs calls for\neffective and scalable conversational emotion-recognition algorithms. However,\nit is a strenuous problem to solve because of several research challenges. In\nthis paper, we discuss these challenges and shed light on the recent research\nin this field. We also describe the drawbacks of these approaches and discuss\nthe reasons why they fail to successfully overcome the research challenges in\nERC.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 07:46:30 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Poria", "Soujanya", ""], ["Majumder", "Navonil", ""], ["Mihalcea", "Rada", ""], ["Hovy", "Eduard", ""]]}, {"id": "1905.02973", "submitter": "Enrique Manjavacas Ar\\'evalo", "authors": "Enrique Manjavacas and Brian Long and Mike Kestemont", "title": "On the Feasibility of Automated Detection of Allusive Text Reuse", "comments": null, "journal-ref": "NAACL-HLT (LaTeCH-CLfL Workshop) 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The detection of allusive text reuse is particularly challenging due to the\nsparse evidence on which allusive references rely---commonly based on none or\nvery few shared words. Arguably, lexical semantics can be resorted to since\nuncovering semantic relations between words has the potential to increase the\nsupport underlying the allusion and alleviate the lexical sparsity. A further\nobstacle is the lack of evaluation benchmark corpora, largely due to the highly\ninterpretative character of the annotation process. In the present paper, we\naim to elucidate the feasibility of automated allusion detection. We approach\nthe matter from an Information Retrieval perspective in which referencing texts\nact as queries and referenced texts as relevant documents to be retrieved, and\nestimate the difficulty of benchmark corpus compilation by a novel\ninter-annotator agreement study on query segmentation. Furthermore, we\ninvestigate to what extent the integration of lexical semantic information\nderived from distributional models and ontologies can aid retrieving cases of\nallusive reuse. The results show that (i) despite low agreement scores, using\nmanual queries considerably improves retrieval performance with respect to a\nwindowing approach, and that (ii) retrieval performance can be moderately\nboosted with distributional semantics.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 09:24:48 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Manjavacas", "Enrique", ""], ["Long", "Brian", ""], ["Kestemont", "Mike", ""]]}, {"id": "1905.03042", "submitter": "Tien Huu Do", "authors": "Tien Huu Do, Xiao Luo, Duc Minh Nguyen, Nikos Deligiannis", "title": "Rumour Detection via News Propagation Dynamics and User Representation\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rumours have existed for a long time and have been known for serious\nconsequences. The rapid growth of social media platforms has multiplied the\nnegative impact of rumours; it thus becomes important to early detect them.\nMany methods have been introduced to detect rumours using the content or the\nsocial context of news. However, most existing methods ignore or do not explore\neffectively the propagation pattern of news in social media, including the\nsequence of interactions of social media users with news across time. In this\nwork, we propose a novel method for rumour detection based on deep learning.\nOur method leverages the propagation process of the news by learning the users'\nrepresentation and the temporal interrelation of users' responses. Experiments\nconducted on Twitter and Weibo datasets demonstrate the state-of-the-art\nperformance of the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 14:13:03 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Do", "Tien Huu", ""], ["Luo", "Xiao", ""], ["Nguyen", "Duc Minh", ""], ["Deligiannis", "Nikos", ""]]}, {"id": "1905.03072", "submitter": "Christoph L\\\"uscher", "authors": "Christoph L\\\"uscher, Eugen Beck, Kazuki Irie, Markus Kitza, Wilfried\n  Michel, Albert Zeyer, Ralf Schl\\\"uter, Hermann Ney", "title": "RWTH ASR Systems for LibriSpeech: Hybrid vs Attention -- w/o Data\n  Augmentation", "comments": "Proceedings of INTERSPEECH 2019", "journal-ref": null, "doi": "10.21437/Interspeech.2019-1780", "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present state-of-the-art automatic speech recognition (ASR) systems\nemploying a standard hybrid DNN/HMM architecture compared to an attention-based\nencoder-decoder design for the LibriSpeech task. Detailed descriptions of the\nsystem development, including model design, pretraining schemes, training\nschedules, and optimization approaches are provided for both system\narchitectures. Both hybrid DNN/HMM and attention-based systems employ\nbi-directional LSTMs for acoustic modeling/encoding. For language modeling, we\nemploy both LSTM and Transformer based architectures. All our systems are built\nusing RWTHs open-source toolkits RASR and RETURNN. To the best knowledge of the\nauthors, the results obtained when training on the full LibriSpeech training\nset, are the best published currently, both for the hybrid DNN/HMM and the\nattention-based systems. Our single hybrid system even outperforms previous\nresults obtained from combining eight single systems. Our comparison shows that\non the LibriSpeech 960h task, the hybrid DNN/HMM system outperforms the\nattention-based system by 15% relative on the clean and 40% relative on the\nother test sets in terms of word error rate. Moreover, experiments on a reduced\n100h-subset of the LibriSpeech training corpus even show a more pronounced\nmargin between the hybrid DNN/HMM and attention-based architectures.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 13:57:28 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 09:34:33 GMT"}, {"version": "v3", "created": "Thu, 25 Jul 2019 15:49:22 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["L\u00fcscher", "Christoph", ""], ["Beck", "Eugen", ""], ["Irie", "Kazuki", ""], ["Kitza", "Markus", ""], ["Michel", "Wilfried", ""], ["Zeyer", "Albert", ""], ["Schl\u00fcter", "Ralf", ""], ["Ney", "Hermann", ""]]}, {"id": "1905.03197", "submitter": "Li Dong", "authors": "Li Dong, Nan Yang, Wenhui Wang, Furu Wei, Xiaodong Liu, Yu Wang,\n  Jianfeng Gao, Ming Zhou, Hsiao-Wuen Hon", "title": "Unified Language Model Pre-training for Natural Language Understanding\n  and Generation", "comments": "Accepted by NeurIPS-19. Code and pre-trained models:\n  https://github.com/microsoft/unilm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new Unified pre-trained Language Model (UniLM) that can\nbe fine-tuned for both natural language understanding and generation tasks. The\nmodel is pre-trained using three types of language modeling tasks:\nunidirectional, bidirectional, and sequence-to-sequence prediction. The unified\nmodeling is achieved by employing a shared Transformer network and utilizing\nspecific self-attention masks to control what context the prediction conditions\non. UniLM compares favorably with BERT on the GLUE benchmark, and the SQuAD 2.0\nand CoQA question answering tasks. Moreover, UniLM achieves new\nstate-of-the-art results on five natural language generation datasets,\nincluding improving the CNN/DailyMail abstractive summarization ROUGE-L to\n40.51 (2.04 absolute improvement), the Gigaword abstractive summarization\nROUGE-L to 35.75 (0.86 absolute improvement), the CoQA generative question\nanswering F1 score to 82.5 (37.1 absolute improvement), the SQuAD question\ngeneration BLEU-4 to 22.12 (3.75 absolute improvement), and the DSTC7\ndocument-grounded dialog response generation NIST-4 to 2.67 (human performance\nis 2.65). The code and pre-trained models are available at\nhttps://github.com/microsoft/unilm.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 16:33:51 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 13:31:56 GMT"}, {"version": "v3", "created": "Tue, 15 Oct 2019 11:25:06 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Dong", "Li", ""], ["Yang", "Nan", ""], ["Wang", "Wenhui", ""], ["Wei", "Furu", ""], ["Liu", "Xiaodong", ""], ["Wang", "Yu", ""], ["Gao", "Jianfeng", ""], ["Zhou", "Ming", ""], ["Hon", "Hsiao-Wuen", ""]]}, {"id": "1905.03423", "submitter": "Jiaxin Pei", "authors": "Jiaxin Pei, Aixin Sun, Chenliang Li", "title": "Targeted Sentiment Analysis: A Data-Driven Categorization", "comments": "Draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Targeted sentiment analysis (TSA), also known as aspect based sentiment\nanalysis (ABSA), aims at detecting fine-grained sentiment polarity towards\ntargets in a given opinion document. Due to the lack of labeled datasets and\neffective technology, TSA had been intractable for many years. The newly\nreleased datasets and the rapid development of deep learning technologies are\nkey enablers for the recent significant progress made in this area. However,\nthe TSA tasks have been defined in various ways with different understandings\ntowards basic concepts like `target' and `aspect'. In this paper, we categorize\nthe different tasks and highlight the differences in the available datasets and\ntheir specific tasks. We then further discuss the challenges related to data\ncollection and data annotation which are overlooked in many previous studies.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 03:01:54 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Pei", "Jiaxin", ""], ["Sun", "Aixin", ""], ["Li", "Chenliang", ""]]}, {"id": "1905.03500", "submitter": "Tobias Menne", "authors": "Tobias Menne and Ilya Sklyar and Ralf Schl\\\"uter and Hermann Ney", "title": "Analysis of Deep Clustering as Preprocessing for Automatic Speech\n  Recognition of Sparsely Overlapping Speech", "comments": null, "journal-ref": "Proceedings of INTERSPEECH 2019", "doi": "10.21437/Interspeech.2019-1728", "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Significant performance degradation of automatic speech recognition (ASR)\nsystems is observed when the audio signal contains cross-talk. One of the\nrecently proposed approaches to solve the problem of multi-speaker ASR is the\ndeep clustering (DPCL) approach. Combining DPCL with a state-of-the-art hybrid\nacoustic model, we obtain a word error rate (WER) of 16.5 % on the commonly\nused wsj0-2mix dataset, which is the best performance reported thus far to the\nbest of our knowledge. The wsj0-2mix dataset contains simulated cross-talk\nwhere the speech of multiple speakers overlaps for almost the entire utterance.\nIn a more realistic ASR scenario the audio signal contains significant portions\nof single-speaker speech and only part of the signal contains speech of\nmultiple competing speakers. This paper investigates obstacles of applying DPCL\nas a preprocessing method for ASR in such a scenario of sparsely overlapping\nspeech. To this end we present a data simulation approach, closely related to\nthe wsj0-2mix dataset, generating sparsely overlapping speech datasets of\narbitrary overlap ratio. The analysis of applying DPCL to sparsely overlapping\nspeech is an important interim step between the fully overlapping datasets like\nwsj0-2mix and more realistic ASR datasets, such as CHiME-5 or AMI.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 09:22:40 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 12:07:45 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Menne", "Tobias", ""], ["Sklyar", "Ilya", ""], ["Schl\u00fcter", "Ralf", ""], ["Ney", "Hermann", ""]]}, {"id": "1905.03638", "submitter": "Ruixue Liu", "authors": "Ruixue Liu, Baoyang Chen, Meng Chen, Youzheng Wu, Zhijie Qiu, Xiaodong\n  He", "title": "Mappa Mundi: An Interactive Artistic Mind Map Generator with Artificial\n  Imagination", "comments": "Paper accepted by IJCAI 2019 Demo track", "journal-ref": null, "doi": null, "report-no": "978-0-9992411-4-1", "categories": "cs.AI cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel real-time, collaborative, and interactive AI painting\nsystem, Mappa Mundi, for artistic Mind Map creation. The system consists of a\nvoice-based input interface, an automatic topic expansion module, and an image\nprojection module. The key innovation is to inject Artificial Imagination into\npainting creation by considering lexical and phonological similarities of\nlanguage, learning and inheriting artist's original painting style, and\napplying the principles of Dadaism and impossibility of improvisation. Our\nsystem indicates that AI and artist can collaborate seamlessly to create\nimaginative artistic painting and Mappa Mundi has been applied in art\nexhibition in UCCA, Beijing\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 13:51:46 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 11:22:59 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Liu", "Ruixue", ""], ["Chen", "Baoyang", ""], ["Chen", "Meng", ""], ["Wu", "Youzheng", ""], ["Qiu", "Zhijie", ""], ["He", "Xiaodong", ""]]}, {"id": "1905.03640", "submitter": "Kit Kuksenok", "authors": "Kit Kuksenok, Nina Pra{\\ss}", "title": "Transparency in Maintenance of Recruitment Chatbots", "comments": "4 pages, 3 figures, prepared for CHI2019 (Glasgow) workshop: Where is\n  the Human? Bridging the Gap Between AI and HCI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on experiences with implementing conversational agents in the\nrecruitment domain based on a machine learning (ML) system. Recruitment\nchatbots mediate communication between job-seekers and recruiters by exposing\nML data to recruiter teams. Errors are difficult to understand, communicate,\nand resolve because they may span and combine UX, ML, and software issues. In\nan effort to improve organizational and technical transparency, we came to rely\non a key contact role. Though effective for design and development, the\ncentralization of this role poses challenges for transparency in sustained\nmaintenance of this kind of ML-based mediating system.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 14:04:44 GMT"}], "update_date": "2019-05-18", "authors_parsed": [["Kuksenok", "Kit", ""], ["Pra\u00df", "Nina", ""]]}, {"id": "1905.03813", "submitter": "Hongyu Li", "authors": "Jose Cambronero, Hongyu Li, Seohyun Kim, Koushik Sen and Satish\n  Chandra", "title": "When Deep Learning Met Code Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  There have been multiple recent proposals on using deep neural networks for\ncode search using natural language. Common across these proposals is the idea\nof $\\mathit{embedding}$ code and natural language queries, into real vectors\nand then using vector distance to approximate semantic correlation between code\nand the query. Multiple approaches exist for learning these embeddings,\nincluding $\\mathit{unsupervised}$ techniques, which rely only on a corpus of\ncode examples, and $\\mathit{supervised}$ techniques, which use an\n$\\mathit{aligned}$ corpus of paired code and natural language descriptions. The\ngoal of this supervision is to produce embeddings that are more similar for a\nquery and the corresponding desired code snippet. Clearly, there are choices in\nwhether to use supervised techniques at all, and if one does, what sort of\nnetwork and training to use for supervision. This paper is the first to\nevaluate these choices systematically. To this end, we assembled\nimplementations of state-of-the-art techniques to run on a common platform,\ntraining and evaluation corpora. To explore the design space in network\ncomplexity, we also introduced a new design point that is a $\\mathit{minimal}$\nsupervision extension to an existing unsupervised technique. Our evaluation\nshows that: 1. adding supervision to an existing unsupervised technique can\nimprove performance, though not necessarily by much; 2. simple networks for\nsupervision can be more effective that more sophisticated sequence-based\nnetworks for code search; 3. while it is common to use docstrings to carry out\nsupervision, there is a sizeable gap between the effectiveness of docstrings\nand a more query-appropriate supervision corpus.\n  The evaluation dataset is now available at arXiv:1908.09804\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 18:47:38 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 21:36:47 GMT"}, {"version": "v3", "created": "Fri, 4 Oct 2019 14:01:11 GMT"}, {"version": "v4", "created": "Tue, 15 Oct 2019 06:11:03 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Cambronero", "Jose", ""], ["Li", "Hongyu", ""], ["Kim", "Seohyun", ""], ["Sen", "Koushik", ""], ["Chandra", "Satish", ""]]}, {"id": "1905.03968", "submitter": "Yaman Kumar", "authors": "Nilay Shrivastava, Astitwa Saxena, Yaman Kumar, Rajiv Ratn Shah,\n  Debanjan Mahata, Amanda Stent", "title": "MobiVSR: A Visual Speech Recognition Solution for Mobile Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual speech recognition (VSR) is the task of recognizing spoken language\nfrom video input only, without any audio. VSR has many applications as an\nassistive technology, especially if it could be deployed in mobile devices and\nembedded systems. The need of intensive computational resources and large\nmemory footprint are two of the major obstacles in developing neural network\nmodels for VSR in a resource constrained environment. We propose a novel\nend-to-end deep neural network architecture for word level VSR called MobiVSR\nwith a design parameter that aids in balancing the model's accuracy and\nparameter count. We use depthwise-separable 3D convolution for the first time\nin the domain of VSR and show how it makes our model efficient. MobiVSR\nachieves an accuracy of 73\\% on a challenging Lip Reading in the Wild dataset\nwith 6 times fewer parameters and 20 times lesser memory footprint than the\ncurrent state of the art. MobiVSR can also be compressed to 6 MB by applying\npost training quantization.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 06:58:35 GMT"}, {"version": "v2", "created": "Sun, 26 May 2019 11:12:34 GMT"}, {"version": "v3", "created": "Wed, 5 Jun 2019 03:49:26 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Shrivastava", "Nilay", ""], ["Saxena", "Astitwa", ""], ["Kumar", "Yaman", ""], ["Shah", "Rajiv Ratn", ""], ["Mahata", "Debanjan", ""], ["Stent", "Amanda", ""]]}, {"id": "1905.03969", "submitter": "Wenmian Yang", "authors": "Wenmian Yang, Weijia Jia, XIaojie Zhou, Yutao Luo", "title": "Legal Judgment Prediction via Multi-Perspective Bi-Feedback Network", "comments": "Accepted for publication in the proceedings of IJCAI2019", "journal-ref": null, "doi": "10.24963/ijcai.2019/567", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Legal Judgment Prediction (LJP) is to determine judgment results based on\nthe fact descriptions of the cases. LJP usually consists of multiple subtasks,\nsuch as applicable law articles prediction, charges prediction, and the term of\nthe penalty prediction. These multiple subtasks have topological dependencies,\nthe results of which affect and verify each other. However, existing methods\nuse dependencies of results among multiple subtasks inefficiently. Moreover,\nfor cases with similar descriptions but different penalties, current methods\ncannot predict accurately because the word collocation information is ignored.\nIn this paper, we propose a Multi-Perspective Bi-Feedback Network with the Word\nCollocation Attention mechanism based on the topology structure among subtasks.\nSpecifically, we design a multi-perspective forward prediction and backward\nverification framework to utilize result dependencies among multiple subtasks\neffectively. To distinguish cases with similar descriptions but different\npenalties, we integrate word collocations features of fact descriptions into\nthe network via an attention mechanism. The experimental results show our model\nachieves significant improvements over baselines on all prediction tasks.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 07:04:12 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 11:19:12 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Yang", "Wenmian", ""], ["Jia", "Weijia", ""], ["Zhou", "XIaojie", ""], ["Luo", "Yutao", ""]]}, {"id": "1905.04035", "submitter": "Valeriu Codreanu", "authors": "Derya Cavdar, Valeriu Codreanu, Can Karakus, John A. Lockman III,\n  Damian Podareanu, Vikram Saletore, Alexander Sergeev, Don D. Smith II, Victor\n  Suthichai, Quy Ta, Srinivas Varadharajan, Lucas A. Wilson, Rengan Xu, Pei\n  Yang", "title": "Densifying Assumed-sparse Tensors: Improving Memory Efficiency and MPI\n  Collective Performance during Tensor Accumulation for Parallelized Training\n  of Neural Machine Translation Models", "comments": "18 pages, 10 figures, accepted at the 2019 International\n  Supercomputing Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation - using neural networks to translate human\nlanguage - is an area of active research exploring new neuron types and network\ntopologies with the goal of dramatically improving machine translation\nperformance. Current state-of-the-art approaches, such as the multi-head\nattention-based transformer, require very large translation corpuses and many\nepochs to produce models of reasonable quality. Recent attempts to parallelize\nthe official TensorFlow \"Transformer\" model across multiple nodes have hit\nroadblocks due to excessive memory use and resulting out of memory errors when\nperforming MPI collectives. This paper describes modifications made to the\nHorovod MPI-based distributed training framework to reduce memory usage for\ntransformer models by converting assumed-sparse tensors to dense tensors, and\nsubsequently replacing sparse gradient gather with dense gradient reduction.\nThe result is a dramatic increase in scale-out capability, with CPU-only\nscaling tests achieving 91% weak scaling efficiency up to 1200 MPI processes\n(300 nodes), and up to 65% strong scaling efficiency up to 400 MPI processes\n(200 nodes) using the Stampede2 supercomputer.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 09:44:35 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Cavdar", "Derya", ""], ["Codreanu", "Valeriu", ""], ["Karakus", "Can", ""], ["Lockman", "John A.", "III"], ["Podareanu", "Damian", ""], ["Saletore", "Vikram", ""], ["Sergeev", "Alexander", ""], ["Smith", "Don D.", "II"], ["Suthichai", "Victor", ""], ["Ta", "Quy", ""], ["Varadharajan", "Srinivas", ""], ["Wilson", "Lucas A.", ""], ["Xu", "Rengan", ""], ["Yang", "Pei", ""]]}, {"id": "1905.04051", "submitter": "Eric Laporte", "authors": "Alexis Amid Neme (LIGM), S\\'ebastien Paumier (LIGM)", "title": "Restoring Arabic vowels through omission-tolerant dictionary lookup", "comments": "Language Resources and Evaluation, Springer Verlag, 2019", "journal-ref": null, "doi": "10.1007/s10579-019-09464-6", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vowels in Arabic are optional orthographic symbols written as diacritics\nabove or below letters. In Arabic texts, typically more than 97 percent of\nwritten words do not explicitly show any of the vowels they contain; that is to\nsay, depending on the author, genre and field, less than 3 percent of words\ninclude any explicit vowel. Although numerous studies have been published on\nthe issue of restoring the omitted vowels in speech technologies, little\nattention has been given to this problem in papers dedicated to written Arabic\ntechnologies.f In this research, we present Arabic-Unitex, an Arabic Language\nResource, with emphasis on vowel representation and encoding. Specifically, we\npresent two dozens of rules formalizing a detailed description of vowel\nomission in written text. They are typographical rules integrated into\nlarge-coverage resources for morphological annotation. For restoring vowels,\nour resources are capable of identifying words in which the vowels are not\nshown, as well as words in which the vowels are partially or fully included. By\ntaking into account these rules, our resources are able to compute and restore\nfor each word form a list of compatible fully vowelized candidates through\nomission-tolerant dictionary lookup. Our program performs the analysis of 5000\nwords/second for running text (20 pages/second). Based on these comprehensive\nlinguistic resources, we created a spell checker that detects any\ninvalid/misplaced vowel in a fully or partially vowelized form. Finally, our\nresources provide a lexical coverage of more than 99 percent of the words used\nin popular newspapers, and restore vowels in words (out of context) simply and\nefficiently.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 10:14:41 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Neme", "Alexis Amid", "", "LIGM"], ["Paumier", "S\u00e9bastien", "", "LIGM"]]}, {"id": "1905.04071", "submitter": "Jan Deriu", "authors": "Jan Deriu, Alvaro Rodrigo, Arantxa Otegi, Guillermo Echegoyen, Sophie\n  Rosset, Eneko Agirre, Mark Cieliebak", "title": "Survey on Evaluation Methods for Dialogue Systems", "comments": null, "journal-ref": "Artificial Intelligence Review, June 2020", "doi": "10.1007/s10462-020-09866-x", "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we survey the methods and concepts developed for the evaluation\nof dialogue systems. Evaluation is a crucial part during the development\nprocess. Often, dialogue systems are evaluated by means of human evaluations\nand questionnaires. However, this tends to be very cost and time intensive.\nThus, much work has been put into finding methods, which allow to reduce the\ninvolvement of human labour. In this survey, we present the main concepts and\nmethods. For this, we differentiate between the various classes of dialogue\nsystems (task-oriented dialogue systems, conversational dialogue systems, and\nquestion-answering dialogue systems). We cover each class by introducing the\nmain technologies developed for the dialogue systems and then by presenting the\nevaluation methods regarding this class.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 11:14:12 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 08:07:53 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Deriu", "Jan", ""], ["Rodrigo", "Alvaro", ""], ["Otegi", "Arantxa", ""], ["Echegoyen", "Guillermo", ""], ["Rosset", "Sophie", ""], ["Agirre", "Eneko", ""], ["Cieliebak", "Mark", ""]]}, {"id": "1905.04226", "submitter": "Kazuki Irie", "authors": "Kazuki Irie, Albert Zeyer, Ralf Schl\\\"uter, Hermann Ney", "title": "Language Modeling with Deep Transformers", "comments": "To appear in the proceedings of INTERSPEECH 2019", "journal-ref": null, "doi": "10.21437/Interspeech.2019-2225", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore deep autoregressive Transformer models in language modeling for\nspeech recognition. We focus on two aspects. First, we revisit Transformer\nmodel configurations specifically for language modeling. We show that well\nconfigured Transformer models outperform our baseline models based on the\nshallow stack of LSTM recurrent neural network layers. We carry out experiments\non the open-source LibriSpeech 960hr task, for both 200K vocabulary word-level\nand 10K byte-pair encoding subword-level language modeling. We apply our\nword-level models to conventional hybrid speech recognition by lattice\nrescoring, and the subword-level models to attention based encoder-decoder\nmodels by shallow fusion. Second, we show that deep Transformer language models\ndo not require positional encoding. The positional encoding is an essential\naugmentation for the self-attention mechanism which is invariant to sequence\nordering. However, in autoregressive setup, as is the case for language\nmodeling, the amount of information increases along the position dimension,\nwhich is a positional signal by its own. The analysis of attention weights\nshows that deep autoregressive self-attention models can automatically make use\nof such positional information. We find that removing the positional encoding\neven slightly improves the performance of these models.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 15:50:00 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 15:45:32 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Irie", "Kazuki", ""], ["Zeyer", "Albert", ""], ["Schl\u00fcter", "Ralf", ""], ["Ney", "Hermann", ""]]}, {"id": "1905.04260", "submitter": "Demetris Paschalides", "authors": "Demetris Paschalides, Alexandros Kornilakis, Chrysovalantis\n  Christodoulou, Rafael Andreou, George Pallis, Marios D. Dikaiakos, Evangelos\n  Markatos", "title": "Check-It: A Plugin for Detecting and Reducing the Spread of Fake News\n  and Misinformation on the Web", "comments": "8 pages, 6 figures,", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past few years, we have been witnessing the rise of misinformation\non the Web. People fall victims of fake news during their daily lives and\nassist their further propagation knowingly and inadvertently. There have been\nmany initiatives that are trying to mitigate the damage caused by fake news,\nfocusing on signals from either domain flag-lists, online social networks or\nartificial intelligence. In this work, we present Check-It, a system that\ncombines, in an intelligent way, a variety of signals into a pipeline for fake\nnews identification. Check-It is developed as a web browser plugin with the\nobjective of efficient and timely fake news detection, respecting the user's\nprivacy. Experimental results show that Check-It is able to outperform the\nstate-of-the-art methods. On a dataset, consisting of 9 millions of articles\nlabeled as fake and real, Check-It obtains classification accuracies that\nexceed 99%.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 17:00:40 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Paschalides", "Demetris", ""], ["Kornilakis", "Alexandros", ""], ["Christodoulou", "Chrysovalantis", ""], ["Andreou", "Rafael", ""], ["Pallis", "George", ""], ["Dikaiakos", "Marios D.", ""], ["Markatos", "Evangelos", ""]]}, {"id": "1905.04422", "submitter": "Tiantian Gao", "authors": "Tiantian Gao", "title": "Controlled Natural Languages and Default Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Controlled natural languages (CNLs) are effective languages for knowledge\nrepresentation and reasoning. They are designed based on certain natural\nlanguages with restricted lexicon and grammar. CNLs are unambiguous and simple\nas opposed to their base languages. They preserve the expressiveness and\ncoherence of natural languages. In this report, we focus on a class of CNLs,\ncalled machine-oriented CNLs, which have well-defined semantics that can be\ndeterministically translated into formal languages, such as Prolog, to do\nlogical reasoning. Over the past 20 years, a number of machine-oriented CNLs\nemerged and have been used in many application domains for problem solving and\nquestion answering. However, few of them support non-monotonic inference. In\nour work, we propose non-monotonic extensions of CNL to support defeasible\nreasoning.\n  In the first part of this report, we survey CNLs and compare three\ninfluential systems: Attempto Controlled English (ACE), Processable English\n(PENG), and Computer-processable English (CPL). We compare their language\ndesign, semantic interpretations, and reasoning services. In the second part of\nthis report, we first identify typical non-monotonicity in natural languages,\nsuch as defaults, exceptions and conversational implicatures. Then, we propose\ntheir representation in CNL and the corresponding formalizations in a form of\ndefeasible reasoning known as Logic Programming with Defaults and Argumentation\nTheory (LPDA).\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 02:02:55 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Gao", "Tiantian", ""]]}, {"id": "1905.04554", "submitter": "Achintya Sarkar", "authors": "Achintya kr. Sarkar, Zheng-Hua Tan, Hao Tang, Suwon Shon and James\n  Glass", "title": "Time-Contrastive Learning Based Deep Bottleneck Features for\n  Text-Dependent Speaker Verification", "comments": "Copyright (c) 2019 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": "IEEE/ACM Transactions on Audio, Speech, and Language Processing,\n  2019", "doi": "10.1109/TASLP.2019.2915322", "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are a number of studies about extraction of bottleneck (BN) features\nfrom deep neural networks (DNNs)trained to discriminate speakers, pass-phrases\nand triphone states for improving the performance of text-dependent speaker\nverification (TD-SV). However, a moderate success has been achieved. A recent\nstudy [1] presented a time contrastive learning (TCL) concept to explore the\nnon-stationarity of brain signals for classification of brain states. Speech\nsignals have similar non-stationarity property, and TCL further has the\nadvantage of having no need for labeled data. We therefore present a TCL based\nBN feature extraction method. The method uniformly partitions each speech\nutterance in a training dataset into a predefined number of multi-frame\nsegments. Each segment in an utterance corresponds to one class, and class\nlabels are shared across utterances. DNNs are then trained to discriminate all\nspeech frames among the classes to exploit the temporal structure of speech. In\naddition, we propose a segment-based unsupervised clustering algorithm to\nre-assign class labels to the segments. TD-SV experiments were conducted on the\nRedDots challenge database. The TCL-DNNs were trained using speech data of\nfixed pass-phrases that were excluded from the TD-SV evaluation set, so the\nlearned features can be considered phrase-independent. We compare the\nperformance of the proposed TCL bottleneck (BN) feature with those of\nshort-time cepstral features and BN features extracted from DNNs discriminating\nspeakers, pass-phrases, speaker+pass-phrase, as well as monophones whose labels\nand boundaries are generated by three different automatic speech recognition\n(ASR) systems. Experimental results show that the proposed TCL-BN outperforms\ncepstral features and speaker+pass-phrase discriminant BN features, and its\nperformance is on par with those of ASR derived BN features. Moreover,....\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 17:20:19 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Sarkar", "Achintya kr.", ""], ["Tan", "Zheng-Hua", ""], ["Tang", "Hao", ""], ["Shon", "Suwon", ""], ["Glass", "James", ""]]}, {"id": "1905.04562", "submitter": "Noga Zaslavsky", "authors": "Noga Zaslavsky, Terry Regier, Naftali Tishby, Charles Kemp", "title": "Semantic categories of artifacts and animals reflect efficient coding", "comments": "To appear in the proceedings of the 41st Annual Conference of the\n  Cognitive Science Society (CogSci 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been argued that semantic categories across languages reflect pressure\nfor efficient communication. Recently, this idea has been cast in terms of a\ngeneral information-theoretic principle of efficiency, the Information\nBottleneck (IB) principle, and it has been shown that this principle accounts\nfor the emergence and evolution of named color categories across languages,\nincluding soft structure and patterns of inconsistent naming. However, it is\nnot yet clear to what extent this account generalizes to semantic domains other\nthan color. Here we show that it generalizes to two qualitatively different\nsemantic domains: names for containers, and for animals. First, we show that\ncontainer naming in Dutch and French is near-optimal in the IB sense, and that\nIB broadly accounts for soft categories and inconsistent naming patterns in\nboth languages. Second, we show that a hierarchy of animal categories derived\nfrom IB captures cross-linguistic tendencies in the growth of animal\ntaxonomies. Taken together, these findings suggest that fundamental\ninformation-theoretic principles of efficient coding may shape semantic\ncategories across languages and across domains.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 17:50:12 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Zaslavsky", "Noga", ""], ["Regier", "Terry", ""], ["Tishby", "Naftali", ""], ["Kemp", "Charles", ""]]}, {"id": "1905.04655", "submitter": "Nikhil Mehta", "authors": "Nikhil Mehta and Dan Goldwasser", "title": "Improving Natural Language Interaction with Robots Using Advice", "comments": "Accepted as a short paper at NAACL 2019 (8 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last few years, there has been growing interest in learning models\nfor physically grounded language understanding tasks, such as the popular\nblocks world domain. These works typically view this problem as a single-step\nprocess, in which a human operator gives an instruction and an automated agent\nis evaluated on its ability to execute it. In this paper we take the first step\ntowards increasing the bandwidth of this interaction, and suggest a protocol\nfor including advice, high-level observations about the task, which can help\nconstrain the agent's prediction. We evaluate our approach on the blocks world\ntask, and show that even simple advice can help lead to significant performance\nimprovements. To help reduce the effort involved in supplying the advice, we\nalso explore model self-generated advice which can still improve results.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 06:11:30 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Mehta", "Nikhil", ""], ["Goldwasser", "Dan", ""]]}, {"id": "1905.04705", "submitter": "Marcel Ausloos", "authors": "Valerio Ficcadenti, Roy Cerqueti, Marcel Ausloos", "title": "A joint text mining-rank size investigation of the rhetoric structures\n  of the US Presidents' speeches", "comments": "prepared for Expert Systems With Applications; 24 figures; 7 tables;\n  89 references", "journal-ref": "Expert Systems With Applications 123 (2019) 127-142", "doi": "10.1016/j.eswa.2018.12.049", "report-no": null, "categories": "cs.CL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a text mining context and its use for a deep analysis of\nthe messages delivered by the politicians. Specifically, we deal with an expert\nsystems-based exploration of the rhetoric dynamics of a large collection of US\nPresidents' speeches, ranging from Washington to Trump. In particular, speeches\nare viewed as complex expert systems whose structures can be effectively\nanalyzed through rank-size laws. The methodological contribution of the paper\nis twofold. First, we develop a text mining-based procedure for the\nconstruction of the dataset by using a web scraping routine on the Miller\nCenter website -- the repository collecting the speeches. Second, we explore\nthe implicit structure of the discourse data by implementing a rank-size\nprocedure over the individual speeches, being the words of each speech ranked\nin terms of their frequencies. The scientific significance of the proposed\ncombination of text-mining and rank-size approaches can be found in its\nflexibility and generality, which let it be reproducible to a wide set of\nexpert systems and text mining contexts. The usefulness of the proposed method\nand the speech subsequent analysis is demonstrated by the findings themselves.\nIndeed, in terms of impact, it is worth noting that interesting conclusions of\nsocial, political and linguistic nature on how 45 United States Presidents,\nfrom April 30, 1789 till February 28, 2017 delivered political messages can be\ncarried out. Indeed, the proposed analysis shows some remarkable regularities,\nnot only inside a given speech, but also among different speeches. Moreover,\nunder a purely methodological perspective, the presented contribution suggests\npossible ways of generating a linguistic decision-making algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 14:17:15 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Ficcadenti", "Valerio", ""], ["Cerqueti", "Roy", ""], ["Ausloos", "Marcel", ""]]}, {"id": "1905.04727", "submitter": "Milan Gritta", "authors": "Milan Gritta", "title": "A Comparison of Techniques for Sentiment Classification of Film Reviews", "comments": "A short paper from my MPhil in Advanced Computer Science (2014-15)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We undertake the task of comparing lexicon-based sentiment classification of\nfilm reviews with machine learning approaches. We look at existing\nmethodologies and attempt to emulate and improve on them using a 'given'\nlexicon and a bag-of-words approach. We also utilise syntactical information\nsuch as part-of-speech and dependency relations. We will show that a simple\nlexicon-based classification achieves good results however machine learning\ntechniques prove to be the superior tool. We also show that more features do\nnot necessarily deliver better performance as well as elaborate on three\nfurther enhancements not tested in this article.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 14:19:28 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Gritta", "Milan", ""]]}, {"id": "1905.04749", "submitter": "Md. Tawkat Islam Khondaker", "authors": "Junaed Younus Khan, Md. Tawkat Islam Khondaker, Sadia Afroz, Gias\n  Uddin, Anindya Iqbal", "title": "A Benchmark Study of Machine Learning Models for Online Fake News\n  Detection", "comments": "22 pages, 5 figures, to be published in Machine Learning with\n  Applications journal", "journal-ref": "Machine Learning with Applications: 4(2021).100032", "doi": "10.1016/j.mlwa.2021.100032", "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of fake news and its propagation on social media has become\na major concern due to its ability to create devastating impacts. Different\nmachine learning approaches have been suggested to detect fake news. However,\nmost of those focused on a specific type of news (such as political) which\nleads us to the question of dataset-bias of the models used. In this research,\nwe conducted a benchmark study to assess the performance of different\napplicable machine learning approaches on three different datasets where we\naccumulated the largest and most diversified one. We explored a number of\nadvanced pre-trained language models for fake news detection along with the\ntraditional and deep learning ones and compared their performances from\ndifferent aspects for the first time to the best of our knowledge. We find that\nBERT and similar pre-trained models perform the best for fake news detection,\nespecially with very small dataset. Hence, these models are significantly\nbetter option for languages with limited electronic contents, i.e., training\ndata. We also carried out several analysis based on the models' performance,\narticle's topic, article's length, and discussed different lessons learned from\nthem. We believe that this benchmark study will help the research community to\nexplore further and news sites/blogs to select the most appropriate fake news\ndetection method.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 17:15:11 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 05:30:08 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Khan", "Junaed Younus", ""], ["Khondaker", "Md. Tawkat Islam", ""], ["Afroz", "Sadia", ""], ["Uddin", "Gias", ""], ["Iqbal", "Anindya", ""]]}, {"id": "1905.04799", "submitter": "Junting Ye", "authors": "Junting Ye, Steven Skiena", "title": "The Secret Lives of Names? Name Embeddings from Social Media", "comments": "9 pages; accepted to 2019 ACM SIGKDD; dataset sharing:\n  www.name-prism.com;", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Your name tells a lot about you: your gender, ethnicity and so on. It has\nbeen shown that name embeddings are more effective in representing names than\ntraditional substring features. However, our previous name embedding model is\ntrained on private email data and are not publicly accessible. In this paper,\nwe explore learning name embeddings from public Twitter data. We argue that\nTwitter embeddings have two key advantages: \\textit{(i)} they can and will be\npublicly released to support research community. \\textit{(ii)} even with a\nsmaller training corpus, Twitter embeddings achieve similar performances on\nmultiple tasks comparing to email embeddings.\n  As a test case to show the power of name embeddings, we investigate the\nmodeling of lifespans. We find it interesting that adding name embeddings can\nfurther improve the performances of models using demographic features, which\nare traditionally used for lifespan modeling. Through residual analysis, we\nobserve that fine-grained groups (potentially reflecting socioeconomic status)\nare the latent contributing factors encoded in name embeddings. These were\npreviously hidden to demographic models, and may help to enhance the predictive\npower of a wide class of research studies.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 22:20:44 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Ye", "Junting", ""], ["Skiena", "Steven", ""]]}, {"id": "1905.04847", "submitter": "Long Zhou", "authors": "Long Zhou, Jiajun Zhang, Chengqing Zong", "title": "Synchronous Bidirectional Neural Machine Translation", "comments": "Published by TACL 2019, 15 pages, 9 figures, 9 tabels", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing approaches to neural machine translation (NMT) generate the target\nlanguage sequence token by token from left to right. However, this kind of\nunidirectional decoding framework cannot make full use of the target-side\nfuture contexts which can be produced in a right-to-left decoding direction,\nand thus suffers from the issue of unbalanced outputs. In this paper, we\nintroduce a synchronous bidirectional neural machine translation (SB-NMT) that\npredicts its outputs using left-to-right and right-to-left decoding\nsimultaneously and interactively, in order to leverage both of the history and\nfuture information at the same time. Specifically, we first propose a new\nalgorithm that enables synchronous bidirectional decoding in a single model.\nThen, we present an interactive decoding model in which left-to-right\n(right-to-left) generation does not only depend on its previously generated\noutputs, but also relies on future contexts predicted by right-to-left\n(left-to-right) decoding. We extensively evaluate the proposed SB-NMT model on\nlarge-scale NIST Chinese-English, WMT14 English-German, and WMT18\nRussian-English translation tasks. Experimental results demonstrate that our\nmodel achieves significant improvements over the strong Transformer model by\n3.92, 1.49 and 1.04 BLEU points respectively, and obtains the state-of-the-art\nperformance on Chinese-English and English-German translation tasks.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 03:34:14 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Zhou", "Long", ""], ["Zhang", "Jiajun", ""], ["Zong", "Chengqing", ""]]}, {"id": "1905.04877", "submitter": "Yangyang Guo", "authors": "Yangyang Guo and Zhiyong Cheng and Liqiang Nie and Yibing Liu and\n  Yinglong Wang and Mohan Kankanhalli", "title": "Quantifying and Alleviating the Language Prior Problem in Visual\n  Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Benefiting from the advancement of computer vision, natural language\nprocessing and information retrieval techniques, visual question answering\n(VQA), which aims to answer questions about an image or a video, has received\nlots of attentions over the past few years. Although some progress has been\nachieved so far, several studies have pointed out that current VQA models are\nheavily affected by the \\emph{language prior problem}, which means they tend to\nanswer questions based on the co-occurrence patterns of question keywords\n(e.g., how many) and answers (e.g., 2) instead of understanding images and\nquestions. Existing methods attempt to solve this problem by either balancing\nthe biased datasets or forcing models to better understand images. However,\nonly marginal effects and even performance deterioration are observed for the\nfirst and second solution, respectively. In addition, another important issue\nis the lack of measurement to quantitatively measure the extent of the language\nprior effect, which severely hinders the advancement of related techniques.\n  In this paper, we make contributions to solve the above problems from two\nperspectives. Firstly, we design a metric to quantitatively measure the\nlanguage prior effect of VQA models. The proposed metric has been demonstrated\nto be effective in our empirical studies. Secondly, we propose a regularization\nmethod (i.e., score regularization module) to enhance current VQA models by\nalleviating the language prior problem as well as boosting the backbone model\nperformance. The proposed score regularization module adopts a pair-wise\nlearning strategy, which makes the VQA models answer the question based on the\nreasoning of the image (upon this question) instead of basing on\nquestion-answer patterns observed in the biased training set. The score\nregularization module is flexible to be integrated into various VQA models.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 06:31:33 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Guo", "Yangyang", ""], ["Cheng", "Zhiyong", ""], ["Nie", "Liqiang", ""], ["Liu", "Yibing", ""], ["Wang", "Yinglong", ""], ["Kankanhalli", "Mohan", ""]]}, {"id": "1905.04914", "submitter": "Wei Hu", "authors": "Lingbing Guo and Zequn Sun and Wei Hu", "title": "Learning to Exploit Long-term Relational Dependencies in Knowledge\n  Graphs", "comments": "Accepted by the 36th International Conference on Machine Learning\n  (ICML 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of knowledge graph (KG) embedding. A widely-established\nassumption to this problem is that similar entities are likely to have similar\nrelational roles. However, existing related methods derive KG embeddings mainly\nbased on triple-level learning, which lack the capability of capturing\nlong-term relational dependencies of entities. Moreover, triple-level learning\nis insufficient for the propagation of semantic information among entities,\nespecially for the case of cross-KG embedding. In this paper, we propose\nrecurrent skipping networks (RSNs), which employ a skipping mechanism to bridge\nthe gaps between entities. RSNs integrate recurrent neural networks (RNNs) with\nresidual learning to efficiently capture the long-term relational dependencies\nwithin and between KGs. We design an end-to-end framework to support RSNs on\ndifferent tasks. Our experimental results showed that RSNs outperformed\nstate-of-the-art embedding-based methods for entity alignment and achieved\ncompetitive performance for KG completion.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 08:53:31 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Guo", "Lingbing", ""], ["Sun", "Zequn", ""], ["Hu", "Wei", ""]]}, {"id": "1905.04981", "submitter": "Maolin Li", "authors": "Maolin Li, Arvid Fahlstr\\\"om Myrman, Tingting Mu, Sophia Ananiadou", "title": "Modelling Instance-Level Annotator Reliability for Natural Language\n  Labelling Tasks", "comments": "9 pages, 1 figures, 10 tables, 2019 Annual Conference of the North\n  American Chapter of the Association for Computational Linguistics (NAACL2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When constructing models that learn from noisy labels produced by multiple\nannotators, it is important to accurately estimate the reliability of\nannotators. Annotators may provide labels of inconsistent quality due to their\nvarying expertise and reliability in a domain. Previous studies have mostly\nfocused on estimating each annotator's overall reliability on the entire\nannotation task. However, in practice, the reliability of an annotator may\ndepend on each specific instance. Only a limited number of studies have\ninvestigated modelling per-instance reliability and these only considered\nbinary labels. In this paper, we propose an unsupervised model which can handle\nboth binary and multi-class labels. It can automatically estimate the\nper-instance reliability of each annotator and the correct label for each\ninstance. We specify our model as a probabilistic model which incorporates\nneural networks to model the dependency between latent variables and instances.\nFor evaluation, the proposed method is applied to both synthetic and real data,\nincluding two labelling tasks: text classification and textual entailment.\nExperimental results demonstrate our novel method can not only accurately\nestimate the reliability of annotators across different instances, but also\nachieve superior performance in predicting the correct labels and detecting the\nleast reliable annotators compared to state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 11:40:09 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Li", "Maolin", ""], ["Myrman", "Arvid Fahlstr\u00f6m", ""], ["Mu", "Tingting", ""], ["Ananiadou", "Sophia", ""]]}, {"id": "1905.05044", "submitter": "Eirini Papagiannopoulou", "authors": "Eirini Papagiannopoulou and Grigorios Tsoumakas", "title": "A Review of Keyphrase Extraction", "comments": "author pre-print version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keyphrase extraction is a textual information processing task concerned with\nthe automatic extraction of representative and characteristic phrases from a\ndocument that express all the key aspects of its content. Keyphrases constitute\na succinct conceptual summary of a document, which is very useful in digital\ninformation management systems for semantic indexing, faceted search, document\nclustering and classification. This article introduces keyphrase extraction,\nprovides a well-structured review of the existing work, offers interesting\ninsights on the different evaluation approaches, highlights open issues and\npresents a comparative experimental study of popular unsupervised techniques on\nfive datasets.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 14:01:08 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 15:51:54 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Papagiannopoulou", "Eirini", ""], ["Tsoumakas", "Grigorios", ""]]}, {"id": "1905.05293", "submitter": "Shrimai Prabhumoye", "authors": "Shrimai Prabhumoye, Chris Quirk and Michel Galley", "title": "Towards Content Transfer through Grounded Text Generation", "comments": null, "journal-ref": "Proc. NAACL 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work in neural generation has attracted significant interest in\ncontrolling the form of text, such as style, persona, and politeness. However,\nthere has been less work on controlling neural text generation for content.\nThis paper introduces the notion of Content Transfer for long-form text\ngeneration, where the task is to generate a next sentence in a document that\nboth fits its context and is grounded in a content-rich external textual source\nsuch as a news story. Our experiments on Wikipedia data show significant\nimprovements against competitive baselines. As another contribution of this\npaper, we release a benchmark dataset of 640k Wikipedia referenced sentences\npaired with the source articles to encourage exploration of this new task.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 21:36:43 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Prabhumoye", "Shrimai", ""], ["Quirk", "Chris", ""], ["Galley", "Michel", ""]]}, {"id": "1905.05395", "submitter": "Prasanna Raj Noel Dabre", "authors": "Raj Dabre, Chenhui Chu, Anoop Kunchukuttan", "title": "A Brief Survey of Multilingual Neural Machine Translation", "comments": "We have substantially expanded this paper for a journal submission to\n  computing surveys [arXiv:2001.01115]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a survey on multilingual neural machine translation (MNMT), which\nhas gained a lot of traction in the recent years. MNMT has been useful in\nimproving translation quality as a result of knowledge transfer. MNMT is more\npromising and interesting than its statistical machine translation counterpart\nbecause end-to-end modeling and distributed representations open new avenues.\nMany approaches have been proposed in order to exploit multilingual parallel\ncorpora for improving translation quality. However, the lack of a comprehensive\nsurvey makes it difficult to determine which approaches are promising and hence\ndeserve further exploration. In this paper, we present an in-depth survey of\nexisting literature on MNMT. We categorize various approaches based on the\nresource scenarios as well as underlying modeling principles. We hope this\npaper will serve as a starting point for researchers and engineers interested\nin MNMT.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 05:20:41 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 07:32:22 GMT"}, {"version": "v3", "created": "Sat, 4 Jan 2020 19:27:34 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Dabre", "Raj", ""], ["Chu", "Chenhui", ""], ["Kunchukuttan", "Anoop", ""]]}, {"id": "1905.05407", "submitter": "Dmytro Krasnoshtan", "authors": "Dmytro Krasnoshtan", "title": "On the number of k-skip-n-grams", "comments": "2 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The paper proves that the number of k-skip-n-grams for a corpus of size $L$\nis $$\\frac{Ln + n + k' - n^2 - nk'}{n} \\cdot \\binom{n-1+k'}{n-1}$$ where $k' =\n\\min(L - n + 1, k)$.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 06:18:35 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Krasnoshtan", "Dmytro", ""]]}, {"id": "1905.05460", "submitter": "Ming Ding", "authors": "Ming Ding, Chang Zhou, Qibin Chen, Hongxia Yang, Jie Tang", "title": "Cognitive Graph for Multi-Hop Reading Comprehension at Scale", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new CogQA framework for multi-hop question answering in\nweb-scale documents. Inspired by the dual process theory in cognitive science,\nthe framework gradually builds a \\textit{cognitive graph} in an iterative\nprocess by coordinating an implicit extraction module (System 1) and an\nexplicit reasoning module (System 2). While giving accurate answers, our\nframework further provides explainable reasoning paths. Specifically, our\nimplementation based on BERT and graph neural network efficiently handles\nmillions of documents for multi-hop reasoning questions in the HotpotQA\nfullwiki dataset, achieving a winning joint $F_1$ score of 34.9 on the\nleaderboard, compared to 23.6 of the best competitor.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 08:55:04 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 09:44:29 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Ding", "Ming", ""], ["Zhou", "Chang", ""], ["Chen", "Qibin", ""], ["Yang", "Hongxia", ""], ["Tang", "Jie", ""]]}, {"id": "1905.05471", "submitter": "Richard Csaky", "authors": "Richard Csaky, Patrik Purgai, Gabor Recski", "title": "Improving Neural Conversational Models with Entropy-Based Data Filtering", "comments": "20 pages. same as ACL version:\n  https://www.aclweb.org/anthology/P19-1567", "journal-ref": "Proceedings of the 57th Conference of the ACL (2019) 5650-5669", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current neural network-based conversational models lack diversity and\ngenerate boring responses to open-ended utterances. Priors such as persona,\nemotion, or topic provide additional information to dialog models to aid\nresponse generation, but annotating a dataset with priors is expensive and such\nannotations are rarely available. While previous methods for improving the\nquality of open-domain response generation focused on either the underlying\nmodel or the training objective, we present a method of filtering dialog\ndatasets by removing generic utterances from training data using a simple\nentropy-based approach that does not require human supervision. We conduct\nextensive experiments with different variations of our method, and compare\ndialog models across 17 evaluation metrics to show that training on datasets\nfiltered this way results in better conversational quality as chatbots learn to\noutput more diverse responses.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 09:07:30 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 13:12:36 GMT"}, {"version": "v3", "created": "Fri, 2 Aug 2019 17:54:01 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Csaky", "Richard", ""], ["Purgai", "Patrik", ""], ["Recski", "Gabor", ""]]}, {"id": "1905.05475", "submitter": "Yunsu Kim", "authors": "Yunsu Kim, Yingbo Gao, Hermann Ney", "title": "Effective Cross-lingual Transfer of Neural Machine Translation Models\n  without Shared Vocabularies", "comments": "ACL 2019 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning or multilingual model is essential for low-resource neural\nmachine translation (NMT), but the applicability is limited to cognate\nlanguages by sharing their vocabularies. This paper shows effective techniques\nto transfer a pre-trained NMT model to a new, unrelated language without shared\nvocabularies. We relieve the vocabulary mismatch by using cross-lingual word\nembedding, train a more language-agnostic encoder by injecting artificial\nnoises, and generate synthetic data easily from the pre-training data without\nback-translation. Our methods do not require restructuring the vocabulary or\nretraining the model. We improve plain NMT transfer by up to +5.1% BLEU in five\nlow-resource translation tasks, outperforming multilingual joint training by a\nlarge margin. We also provide extensive ablation studies on pre-trained\nembedding, synthetic data, vocabulary size, and parameter freezing for a better\nunderstanding of NMT transfer.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 09:13:23 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 11:04:07 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Kim", "Yunsu", ""], ["Gao", "Yingbo", ""], ["Ney", "Hermann", ""]]}, {"id": "1905.05513", "submitter": "Nikolaos Pappas", "authors": "Nikolaos Pappas, James Henderson", "title": "Deep Residual Output Layers for Neural Language Generation", "comments": "To appear in ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many tasks, including language generation, benefit from learning the\nstructure of the output space, particularly when the space of output labels is\nlarge and the data is sparse. State-of-the-art neural language models\nindirectly capture the output space structure in their classifier weights since\nthey lack parameter sharing across output labels. Learning shared output label\nmappings helps, but existing methods have limited expressivity and are prone to\noverfitting. In this paper, we investigate the usefulness of more powerful\nshared mappings for output labels, and propose a deep residual output mapping\nwith dropout between layers to better capture the structure of the output space\nand avoid overfitting. Evaluations on three language generation tasks show that\nour output label mapping can match or improve state-of-the-art recurrent and\nself-attention architectures, and suggest that the classifier does not\nnecessarily need to be high-rank to better model natural language if it is\nbetter at capturing the structure of the output space.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 10:51:55 GMT"}, {"version": "v2", "created": "Wed, 22 May 2019 17:10:34 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Pappas", "Nikolaos", ""], ["Henderson", "James", ""]]}, {"id": "1905.05526", "submitter": "Jiwei Li", "authors": "Xiaoya Li, Yuxian Meng, Xiaofei Sun, Qinghong Han, Arianna Yuan and\n  Jiwei Li", "title": "Is Word Segmentation Necessary for Deep Learning of Chinese\n  Representations?", "comments": "to appear at ACL2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segmenting a chunk of text into words is usually the first step of processing\nChinese text, but its necessity has rarely been explored. In this paper, we ask\nthe fundamental question of whether Chinese word segmentation (CWS) is\nnecessary for deep learning-based Chinese Natural Language Processing. We\nbenchmark neural word-based models which rely on word segmentation against\nneural char-based models which do not involve word segmentation in four\nend-to-end NLP benchmark tasks: language modeling, machine translation,\nsentence matching/paraphrase and text classification. Through direct\ncomparisons between these two types of models, we find that char-based models\nconsistently outperform word-based models. Based on these observations, we\nconduct comprehensive experiments to study why word-based models underperform\nchar-based models in these deep learning-based NLP tasks. We show that it is\nbecause word-based models are more vulnerable to data sparsity and the presence\nof out-of-vocabulary (OOV) words, and thus more prone to overfitting. We hope\nthis paper could encourage researchers in the community to rethink the\nnecessity of word segmentation in deep learning-based Chinese Natural Language\nProcessing. \\footnote{Yuxian Meng and Xiaoya Li contributed equally to this\npaper.}\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 11:39:43 GMT"}, {"version": "v2", "created": "Sun, 6 Oct 2019 07:54:54 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Li", "Xiaoya", ""], ["Meng", "Yuxian", ""], ["Sun", "Xiaofei", ""], ["Han", "Qinghong", ""], ["Yuan", "Arianna", ""], ["Li", "Jiwei", ""]]}, {"id": "1905.05529", "submitter": "Jiwei Li", "authors": "Xiaoya Li, Fan Yin, Zijun Sun, Xiayu Li, Arianna Yuan, Duo Chai,\n  Mingxin Zhou and Jiwei Li", "title": "Entity-Relation Extraction as Multi-Turn Question Answering", "comments": "to appear at ACL2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new paradigm for the task of entity-relation\nextraction. We cast the task as a multi-turn question answering problem, i.e.,\nthe extraction of entities and relations is transformed to the task of\nidentifying answer spans from the context. This multi-turn QA formalization\ncomes with several key advantages: firstly, the question query encodes\nimportant information for the entity/relation class we want to identify;\nsecondly, QA provides a natural way of jointly modeling entity and relation;\nand thirdly, it allows us to exploit the well developed machine reading\ncomprehension (MRC) models. Experiments on the ACE and the CoNLL04 corpora\ndemonstrate that the proposed paradigm significantly outperforms previous best\nmodels. We are able to obtain the state-of-the-art results on all of the ACE04,\nACE05 and CoNLL04 datasets, increasing the SOTA results on the three datasets\nto 49.4 (+1.0), 60.2 (+0.6) and 68.9 (+2.1), respectively. Additionally, we\nconstruct a newly developed dataset RESUME in Chinese, which requires\nmulti-step reasoning to construct entity dependencies, as opposed to the\nsingle-step dependency extraction in the triplet exaction in previous datasets.\nThe proposed multi-turn QA model also achieves the best performance on the\nRESUME dataset.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 11:44:33 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 13:45:56 GMT"}, {"version": "v3", "created": "Fri, 24 May 2019 07:25:23 GMT"}, {"version": "v4", "created": "Wed, 4 Sep 2019 04:13:22 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Li", "Xiaoya", ""], ["Yin", "Fan", ""], ["Sun", "Zijun", ""], ["Li", "Xiayu", ""], ["Yuan", "Arianna", ""], ["Chai", "Duo", ""], ["Zhou", "Mingxin", ""], ["Li", "Jiwei", ""]]}, {"id": "1905.05532", "submitter": "Ganbin Zhou", "authors": "Ganbin Zhou, Ping Luo, Jingwu Chen, Fen Lin, Leyu Lin, Qing He", "title": "Atom Responding Machine for Dialog Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, improving the relevance and diversity of dialogue system has\nattracted wide attention. For a post x, the corresponding response y is usually\ndiverse in the real-world corpus, while the conventional encoder-decoder model\ntends to output the high-frequency (safe but trivial) responses and thus is\ndifficult to handle the large number of responding styles. To address these\nissues, we propose the Atom Responding Machine (ARM), which is based on a\nproposed encoder-composer-decoder network trained by a teacher-student\nframework. To enrich the generated responses, ARM introduces a large number of\nmolecule-mechanisms as various responding styles, which are conducted by taking\ndifferent combinations from a few atom-mechanisms. In other words, even a\nlittle of atom-mechanisms can make a mickle of molecule-mechanisms. The\nexperiments demonstrate diversity and quality of the responses generated by\nARM. We also present generating process to show underlying interpretability for\nthe result.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 11:44:54 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 10:42:14 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Zhou", "Ganbin", ""], ["Luo", "Ping", ""], ["Chen", "Jingwu", ""], ["Lin", "Fen", ""], ["Lin", "Leyu", ""], ["He", "Qing", ""]]}, {"id": "1905.05538", "submitter": "Maria Becker", "authors": "Maria Becker, Michael Staniek, Vivi Nastase, and Anette Frank", "title": "Assessing the Difficulty of Classifying ConceptNet Relations in a\n  Multi-Label Classification Setting", "comments": "RELATIONS - Workshop on meaning relations between phrases and\n  sentences (co-located with IWCS). May 2019, Gothenburg, Sweden", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Commonsense knowledge relations are crucial for advanced NLU tasks. We\nexamine the learnability of such relations as represented in CONCEPTNET, taking\ninto account their specific properties, which can make relation classification\ndifficult: a given concept pair can be linked by multiple relation types, and\nrelations can have multi-word arguments of diverse semantic types. We explore a\nneural open world multi-label classification approach that focuses on the\nevaluation of classification accuracy for individual relations. Based on an\nin-depth study of the specific properties of the CONCEPTNET resource, we\ninvestigate the impact of different relation representations and model\nvariations. Our analysis reveals that the complexity of argument types and\nrelation ambiguity are the most important challenges to address. We design a\ncustomized evaluation method to address the incompleteness of the resource that\ncan be expanded in future work.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 12:07:13 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Becker", "Maria", ""], ["Staniek", "Michael", ""], ["Nastase", "Vivi", ""], ["Frank", "Anette", ""]]}, {"id": "1905.05543", "submitter": "Daniel Hershcovich", "authors": "Leshem Choshen, Dan Eldad, Daniel Hershcovich, Elior Sulem and Omri\n  Abend", "title": "The Language of Legal and Illegal Activity on the Darknet", "comments": "ACL 2019 camera ready; code in https://github.com/huji-nlp/cyber", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The non-indexed parts of the Internet (the Darknet) have become a haven for\nboth legal and illegal anonymous activity. Given the magnitude of these\nnetworks, scalably monitoring their activity necessarily relies on automated\ntools, and notably on NLP tools. However, little is known about what\ncharacteristics texts communicated through the Darknet have, and how well\noff-the-shelf NLP tools do on this domain. This paper tackles this gap and\nperforms an in-depth investigation of the characteristics of legal and illegal\ntext in the Darknet, comparing it to a clear net website with similar content\nas a control condition. Taking drug-related websites as a test case, we find\nthat texts for selling legal and illegal drugs have several linguistic\ncharacteristics that distinguish them from one another, as well as from the\ncontrol condition, among them the distribution of POS tags, and the coverage of\ntheir named entities in Wikipedia.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 12:14:27 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 11:40:07 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Choshen", "Leshem", ""], ["Eldad", "Dan", ""], ["Hershcovich", "Daniel", ""], ["Sulem", "Elior", ""], ["Abend", "Omri", ""]]}, {"id": "1905.05547", "submitter": "Kamen Brestnichki", "authors": "Francisco Vargas, Kamen Brestnichki, Alex Papadopoulos-Korfiatis and\n  Nils Hammerla", "title": "Multilingual Factor Analysis", "comments": "Proceedings of the 57th Annual Meeting of the Association for\n  Computational Linguistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we approach the task of learning multilingual word\nrepresentations in an offline manner by fitting a generative latent variable\nmodel to a multilingual dictionary. We model equivalent words in different\nlanguages as different views of the same word generated by a common latent\nvariable representing their latent lexical meaning. We explore the task of\nalignment by querying the fitted model for multilingual embeddings achieving\ncompetitive results across a variety of tasks. The proposed model is robust to\nnoise in the embedding space making it a suitable method for distributed\nrepresentations learned from noisy corpora.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 12:22:39 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 22:49:02 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Vargas", "Francisco", ""], ["Brestnichki", "Kamen", ""], ["Papadopoulos-Korfiatis", "Alex", ""], ["Hammerla", "Nils", ""]]}, {"id": "1905.05550", "submitter": "Dongyun Liang", "authors": "Dongyun Liang, Guohua Wang, Jing Nie", "title": "A Dynamic Evolutionary Framework for Timeline Generation based on\n  Distributed Representations", "comments": "4 pages, next version will be submitted to a conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the collection of timestamped web documents related to the evolving\ntopic, timeline summarization (TS) highlights its most important events in the\nform of relevant summaries to represent the development of a topic over time.\nMost of the previous work focuses on fully-observable ranking models and\ndepends on hand-designed features or complex mechanisms that may not generalize\nwell. We present a novel dynamic framework for evolutionary timeline generation\nleveraging distributed representations, which dynamically finds the most likely\nsequence of evolutionary summaries in the timeline, called the Viterbi\ntimeline, and reduces the impact of events that irrelevant or repeated to the\ntopic. The assumptions of the coherence and the global view run through our\nmodel. We explore adjacent relevance to constrain timeline coherence and make\nsure the events evolve on the same topic with a global view. Experimental\nresults demonstrate that our framework is feasible to extract summaries for\ntimeline generation, outperforms various competitive baselines, and achieves\nthe state-of-the-art performance as an unsupervised approach.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 12:30:53 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 03:51:15 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Liang", "Dongyun", ""], ["Wang", "Guohua", ""], ["Nie", "Jing", ""]]}, {"id": "1905.05583", "submitter": "Chi Sun", "authors": "Chi Sun, Xipeng Qiu, Yige Xu, Xuanjing Huang", "title": "How to Fine-Tune BERT for Text Classification?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language model pre-training has proven to be useful in learning universal\nlanguage representations. As a state-of-the-art language model pre-training\nmodel, BERT (Bidirectional Encoder Representations from Transformers) has\nachieved amazing results in many language understanding tasks. In this paper,\nwe conduct exhaustive experiments to investigate different fine-tuning methods\nof BERT on text classification task and provide a general solution for BERT\nfine-tuning. Finally, the proposed solution obtains new state-of-the-art\nresults on eight widely-studied text classification datasets.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 13:17:26 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 10:49:47 GMT"}, {"version": "v3", "created": "Wed, 5 Feb 2020 12:00:32 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Sun", "Chi", ""], ["Qiu", "Xipeng", ""], ["Xu", "Yige", ""], ["Huang", "Xuanjing", ""]]}, {"id": "1905.05598", "submitter": "Rui Portocarrero Sarmento MSc", "authors": "Rui Portocarrero Sarmento, Vera Costa", "title": "Confirmatory Factor Analysis -- A Case study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Confirmatory Factor Analysis (CFA) is a particular form of factor analysis,\nmost commonly used in social research. In confirmatory factor analysis, the\nresearcher first develops a hypothesis about what factors they believe are\nunderlying the used measures and may impose constraints on the model based on\nthese a priori hypotheses. For example, if two factors are accounting for the\ncovariance in the measures, and these factors are unrelated to one another, we\ncan create a model where the correlation between factor X and factor Y is set\nto zero. Measures could then be obtained to assess how well the fitted model\ncaptured the covariance between all the items or measures in the model. Thus,\nif the results of statistical tests of the model fit indicate a poor fit, the\nmodel will be rejected. If the fit is weak, it may be due to a variety of\nreasons. We propose to introduce state of the art techniques to do CFA in R\nlanguage. Then, we propose to do some examples of CFA with R and some datasets,\nrevealing several scenarios where CFA is relevant.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 19:27:22 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Sarmento", "Rui Portocarrero", ""], ["Costa", "Vera", ""]]}, {"id": "1905.05605", "submitter": "Shi-Xiong Zhang", "authors": "Shi-Xiong Zhang, Yifan Gong and Dong Yu", "title": "Encrypted Speech Recognition using Deep Polynomial Networks", "comments": "ICASSP 2019, slides@\n  https://www.researchgate.net/publication/333005422_Encrypted_Speech_Recognition_using_deep_polynomial_networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cloud-based speech recognition/API provides developers or enterprises an\neasy way to create speech-enabled features in their applications. However,\nsending audios about personal or company internal information to the cloud,\nraises concerns about the privacy and security issues. The recognition results\ngenerated in cloud may also reveal some sensitive information. This paper\nproposes a deep polynomial network (DPN) that can be applied to the encrypted\nspeech as an acoustic model. It allows clients to send their data in an\nencrypted form to the cloud to ensure that their data remains confidential, at\nmean while the DPN can still make frame-level predictions over the encrypted\nspeech and return them in encrypted form. One good property of the DPN is that\nit can be trained on unencrypted speech features in the traditional way. To\nkeep the cloud away from the raw audio and recognition results, a cloud-local\njoint decoding framework is also proposed. We demonstrate the effectiveness of\nmodel and framework on the Switchboard and Cortana voice assistant tasks with\nsmall performance degradation and latency increased comparing with the\ntraditional cloud-based DNNs.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 00:14:09 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Zhang", "Shi-Xiong", ""], ["Gong", "Yifan", ""], ["Yu", "Dong", ""]]}, {"id": "1905.05615", "submitter": "Na Pang", "authors": "Na Pang, Li Qian, Weimin Lyu, Jin-Dong Yang", "title": "Transfer Learning for Scientific Data Chain Extraction in Small Chemical\n  Corpus with BERT-CRF Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational chemistry develops fast in recent years due to the rapid growth\nand breakthroughs in AI. Thanks for the progress in natural language\nprocessing, researchers can extract more fine-grained knowledge in publications\nto stimulate the development in computational chemistry. While the works and\ncorpora in chemical entity extraction have been restricted in the biomedicine\nor life science field instead of the chemistry field, we build a new corpus in\nchemical bond field annotated for 7 types of entities: compound, solvent,\nmethod, bond, reaction, pKa and pKa value. This paper presents a novel BERT-CRF\nmodel to build scientific chemical data chains by extracting 7 chemical\nentities and relations from publications. And we propose a joint model to\nextract the entities and relations simultaneously. Experimental results on our\nChemical Special Corpus demonstrate that we achieve state-of-art and\ncompetitive NER performance.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 03:18:38 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Pang", "Na", ""], ["Qian", "Li", ""], ["Lyu", "Weimin", ""], ["Yang", "Jin-Dong", ""]]}, {"id": "1905.05621", "submitter": "Ning Dai", "authors": "Ning Dai, Jianze Liang, Xipeng Qiu, Xuanjing Huang", "title": "Style Transformer: Unpaired Text Style Transfer without Disentangled\n  Latent Representation", "comments": null, "journal-ref": "ACL 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disentangling the content and style in the latent space is prevalent in\nunpaired text style transfer. However, two major issues exist in most of the\ncurrent neural models. 1) It is difficult to completely strip the style\ninformation from the semantics for a sentence. 2) The recurrent neural network\n(RNN) based encoder and decoder, mediated by the latent representation, cannot\nwell deal with the issue of the long-term dependency, resulting in poor\npreservation of non-stylistic semantic content. In this paper, we propose the\nStyle Transformer, which makes no assumption about the latent representation of\nsource sentence and equips the power of attention mechanism in Transformer to\nachieve better style transfer and better content preservation.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 14:03:21 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 09:02:28 GMT"}, {"version": "v3", "created": "Tue, 20 Aug 2019 12:49:12 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Dai", "Ning", ""], ["Liang", "Jianze", ""], ["Qiu", "Xipeng", ""], ["Huang", "Xuanjing", ""]]}, {"id": "1905.05644", "submitter": "Fei Mi", "authors": "Fei Mi, Minlie Huang, Jiyong Zhang, Boi Faltings", "title": "Meta-Learning for Low-resource Natural Language Generation in\n  Task-oriented Dialogue Systems", "comments": "Accepted as a full paper at IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language generation (NLG) is an essential component of task-oriented\ndialogue systems. Despite the recent success of neural approaches for NLG, they\nare typically developed for particular domains with rich annotated training\nexamples. In this paper, we study NLG in a low-resource setting to generate\nsentences in new scenarios with handful training examples. We formulate the\nproblem from a meta-learning perspective, and propose a generalized\noptimization-based approach (Meta-NLG) based on the well-recognized\nmodel-agnostic meta-learning (MAML) algorithm. Meta-NLG defines a set of meta\ntasks, and directly incorporates the objective of adapting to new low-resource\nNLG tasks into the meta-learning optimization process. Extensive experiments\nare conducted on a large multi-domain dataset (MultiWoz) with diverse\nlinguistic variations. We show that Meta-NLG significantly outperforms other\ntraining procedures in various low-resource configurations. We analyze the\nresults, and demonstrate that Meta-NLG adapts extremely fast and well to\nlow-resource situations.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 14:35:06 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Mi", "Fei", ""], ["Huang", "Minlie", ""], ["Zhang", "Jiyong", ""], ["Faltings", "Boi", ""]]}, {"id": "1905.05677", "submitter": "Lo\\\"ic Vial", "authors": "Lo\\\"ic Vial, Benjamin Lecouteux and Didier Schwab", "title": "Sense Vocabulary Compression through the Semantic Knowledge of WordNet\n  for Neural Word Sense Disambiguation", "comments": "In proceedings of the 10th Global WordNet Conference - GWC 2019.\n  arXiv admin note: text overlap with arXiv:1811.00960", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we tackle the issue of the limited quantity of manually\nsense annotated corpora for the task of word sense disambiguation, by\nexploiting the semantic relationships between senses such as synonymy,\nhypernymy and hyponymy, in order to compress the sense vocabulary of Princeton\nWordNet, and thus reduce the number of different sense tags that must be\nobserved to disambiguate all words of the lexical database. We propose two\ndifferent methods that greatly reduces the size of neural WSD models, with the\nbenefit of improving their coverage without additional training data, and\nwithout impacting their precision. In addition to our method, we present a WSD\nsystem which relies on pre-trained BERT word vectors in order to achieve\nresults that significantly outperform the state of the art on all WSD\nevaluation tasks.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 15:39:58 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 12:41:22 GMT"}, {"version": "v3", "created": "Tue, 27 Aug 2019 11:19:48 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Vial", "Lo\u00efc", ""], ["Lecouteux", "Benjamin", ""], ["Schwab", "Didier", ""]]}, {"id": "1905.05682", "submitter": "Xiang Lin", "authors": "Xiang Lin, Shafiq Joty, Prathyusha Jwalapuram and M Saiful Bari", "title": "A Unified Linear-Time Framework for Sentence-Level Discourse Parsing", "comments": "Accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an efficient neural framework for sentence-level discourse\nanalysis in accordance with Rhetorical Structure Theory (RST). Our framework\ncomprises a discourse segmenter to identify the elementary discourse units\n(EDU) in a text, and a discourse parser that constructs a discourse tree in a\ntop-down fashion. Both the segmenter and the parser are based on Pointer\nNetworks and operate in linear time. Our segmenter yields an $F_1$ score of\n95.4, and our parser achieves an $F_1$ score of 81.7 on the aggregated labeled\n(relation) metric, surpassing previous approaches by a good margin and\napproaching human agreement on both tasks (98.3 and 83.0 $F_1$).\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 15:54:57 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 05:05:06 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Lin", "Xiang", ""], ["Joty", "Shafiq", ""], ["Jwalapuram", "Prathyusha", ""], ["Bari", "M Saiful", ""]]}, {"id": "1905.05698", "submitter": "Baohua Sun", "authors": "Baohua Sun, Lin Yang, Michael Lin, Charles Young, Jason Dong, Wenhan\n  Zhang, Patrick Dong", "title": "SuperChat: Dialogue Generation by Transfer Learning from Vision to\n  Language using Two-dimensional Word Embedding and Pretrained ImageNet CNN\n  Models", "comments": "5 pages, 2 figures, 1 table. Accepted by CVPR2019 Language and Vision\n  Workshop", "journal-ref": null, "doi": "10.1145/3326937.3341264", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent work of Super Characters method using two-dimensional word\nembedding achieved state-of-the-art results in text classification tasks,\nshowcasing the promise of this new approach. This paper borrows the idea of\nSuper Characters method and two-dimensional embedding, and proposes a method of\ngenerating conversational response for open domain dialogues. The experimental\nresults on a public dataset shows that the proposed SuperChat method generates\nhigh quality responses. An interactive demo is ready to show at the workshop.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 08:36:27 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 01:26:25 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Sun", "Baohua", ""], ["Yang", "Lin", ""], ["Lin", "Michael", ""], ["Young", "Charles", ""], ["Dong", "Jason", ""], ["Zhang", "Wenhan", ""], ["Dong", "Patrick", ""]]}, {"id": "1905.05699", "submitter": "Adem Tekerek", "authors": "Baris Baburoglu, Adem Tekerek, Mehmet Tekerek", "title": "Development of Deep Learning Based Natural Language Processing Model for\n  Turkish", "comments": "8 pages, in Turkish, 5 figures, ICITS 2019 02-04 May 2019\n  K{\\i}r\\c{s}ehir T\\\"urkiye", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Natural language is one of the most fundamental features that distinguish\npeople from other living things and enable people to communicate each other.\nLanguage is a tool that enables people to express their feelings and thoughts\nand to transfers cultures through generations. Texts and audio are examples of\nnatural language in daily life. In the natural language, many words disappear\nin time, on the other hand new words are derived. Therefore, while the process\nof natural language processing (NLP) is complex even for human, it is difficult\nto process in computer system. The area of linguistics examines how people use\nlanguage. NLP, which requires the collaboration of linguists and computer\nscientists, plays an important role in human computer interaction. Studies in\nNLP have increased with the use of artificial intelligence technologies in the\nfield of linguistics. With the deep learning methods which are one of the\nartificial intelligence study areas, platforms close to natural language are\nbeing developed. Developed platforms for language comprehension, machine\ntranslation and part of speech (POS) tagging benefit from deep learning\nmethods. Recurrent Neural Network (RNN), one of the deep learning\narchitectures, is preferred for processing sequential data such as text or\naudio data. In this study, Turkish POS tagging model has been proposed by using\nBidirectional Long-Short Term Memory (BLSTM) which is an RNN type. The proposed\nPOS tagging model is provided to natural language researchers with a platform\nthat allows them to perform and use their own analysis. In the development\nphase of the platform developed by using BLSTM, the error rate of the POS\ntagger has been reduced by taking feedback with expert opinion.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 21:09:49 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Baburoglu", "Baris", ""], ["Tekerek", "Adem", ""], ["Tekerek", "Mehmet", ""]]}, {"id": "1905.05700", "submitter": "Waleed Yousef", "authors": "Waleed A. Yousef, Omar M. Ibrahime, Taha M. Madbouly, Moustafa A.\n  Mahmoud", "title": "Learning meters of Arabic and English poems with Recurrent Neural\n  Networks: a step forward for language understanding and synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing a piece of writing as a poem or prose is usually easy for the\nmajority of people; however, only specialists can determine which meter a poem\nbelongs to. In this paper, we build Recurrent Neural Network (RNN) models that\ncan classify poems according to their meters from plain text. The input text is\nencoded at the character level and directly fed to the models without feature\nhandcrafting. This is a step forward for machine understanding and synthesis of\nlanguages in general, and Arabic language in particular. Among the 16 poem\nmeters of Arabic and the 4 meters of English the networks were able to\ncorrectly classify poem with an overall accuracy of 96.38\\% and 82.31\\%\nrespectively. The poem datasets used to conduct this research were massive,\nover 1.5 million of verses, and were crawled from different nontechnical\nsources, almost Arabic and English literature sites, and in different\nheterogeneous and unstructured formats. These datasets are now made publicly\navailable in clean, structured, and documented format for other future\nresearch. To the best of the authors' knowledge, this research is the first to\naddress classifying poem meters in a machine learning approach, in general, and\nin RNN featureless based approach, in particular. In addition, the dataset is\nthe first publicly available dataset ready for the purpose of future\ncomputational research.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 21:14:03 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Yousef", "Waleed A.", ""], ["Ibrahime", "Omar M.", ""], ["Madbouly", "Taha M.", ""], ["Mahmoud", "Moustafa A.", ""]]}, {"id": "1905.05701", "submitter": "Aniruddha Uttam Tammewar", "authors": "Aniruddha Tammewar, Alessandra Cervone, Eva-Maria Messner, Giuseppe\n  Riccardi", "title": "Modeling user context for valence prediction from narratives", "comments": "To be published in Interspeech 2019", "journal-ref": "Interspeech 2019", "doi": "10.21437/Interspeech.2019-2489", "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated prediction of valence, one key feature of a person's emotional\nstate, from individuals' personal narratives may provide crucial information\nfor mental healthcare (e.g. early diagnosis of mental diseases, supervision of\ndisease course, etc.). In the Interspeech 2018 ComParE Self-Assessed Affect\nchallenge, the task of valence prediction was framed as a three-class\nclassification problem using 8 seconds fragments from individuals' narratives.\nAs such, the task did not allow for exploring contextual information of the\nnarratives. In this work, we investigate the intrinsic information from\nmultiple narratives recounted by the same individual in order to predict their\ncurrent state-of-mind. Furthermore, with generalizability in mind, we decided\nto focus our experiments exclusively on textual information as the public\navailability of audio narratives is limited compared to text. Our hypothesis\nis, that context modeling might provide insights about emotion triggering\nconcepts (e.g. events, people, places) mentioned in the narratives that are\nlinked to an individual's state of mind. We explore multiple machine learning\ntechniques to model narratives. We find that the models are able to capture\ninter-individual differences, leading to more accurate predictions of an\nindividual's emotional state, as compared to single narratives.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 20:57:14 GMT"}, {"version": "v2", "created": "Sun, 14 Jul 2019 15:03:53 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Tammewar", "Aniruddha", ""], ["Cervone", "Alessandra", ""], ["Messner", "Eva-Maria", ""], ["Riccardi", "Giuseppe", ""]]}, {"id": "1905.05702", "submitter": "Ben Peters", "authors": "Ben Peters, Vlad Niculae and Andr\\'e F.T. Martins", "title": "Sparse Sequence-to-Sequence Models", "comments": "ACL 2019 Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-to-sequence models are a powerful workhorse of NLP. Most variants\nemploy a softmax transformation in both their attention mechanism and output\nlayer, leading to dense alignments and strictly positive output probabilities.\nThis density is wasteful, making models less interpretable and assigning\nprobability mass to many implausible outputs. In this paper, we propose sparse\nsequence-to-sequence models, rooted in a new family of $\\alpha$-entmax\ntransformations, which includes softmax and sparsemax as particular cases, and\nis sparse for any $\\alpha > 1$. We provide fast algorithms to evaluate these\ntransformations and their gradients, which scale well for large vocabulary\nsizes. Our models are able to produce sparse alignments and to assign nonzero\nprobability to a short list of plausible outputs, sometimes rendering beam\nsearch exact. Experiments on morphological inflection and machine translation\nreveal consistent gains over dense models.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 16:21:34 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 18:20:25 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Peters", "Ben", ""], ["Niculae", "Vlad", ""], ["Martins", "Andr\u00e9 F. T.", ""]]}, {"id": "1905.05704", "submitter": "Felipe Salvatore", "authors": "Felipe Salvatore, Marcelo Finger, Roberto Hirata Jr", "title": "A logical-based corpus for cross-lingual evaluation", "comments": "To appear in the proceedings of the Deep Learning for low-resource\n  NLP (DeepLo) workshop at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  At present, different deep learning models are presenting high accuracy on\npopular inference datasets such as SNLI, MNLI, and SciTail. However, there are\ndifferent indicators that those datasets can be exploited by using some simple\nlinguistic patterns. This fact poses difficulties to our understanding of the\nactual capacity of machine learning models to solve the complex task of textual\ninference. We propose a new set of syntactic tasks focused on contradiction\ndetection that require specific capacities over linguistic logical forms such\nas: Boolean coordination, quantifiers, definite description, and counting\noperators. We evaluate two kinds of deep learning models that implicitly\nexploit language structure: recurrent models and the Transformer network BERT.\nWe show that although BERT is clearly more efficient to generalize over most\nlogical forms, there is space for improvement when dealing with counting\noperators. Since the syntactic tasks can be implemented in different languages,\nwe show a successful case of cross-lingual transfer learning between English\nand Portuguese.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 19:39:55 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 15:39:36 GMT"}, {"version": "v3", "created": "Wed, 25 Sep 2019 18:03:10 GMT"}, {"version": "v4", "created": "Tue, 1 Oct 2019 17:12:55 GMT"}, {"version": "v5", "created": "Thu, 24 Oct 2019 00:15:50 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Salvatore", "Felipe", ""], ["Finger", "Marcelo", ""], ["Hirata", "Roberto", "Jr"]]}, {"id": "1905.05708", "submitter": "Guillermo Puebla", "authors": "Guillermo Puebla, Andrea E. Martin, Leonidas A. A. Doumas", "title": "The relational processing limits of classic and contemporary neural\n  network models of language processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability of neural networks to capture relational knowledge is a matter of\nlong-standing controversy. Recently, some researchers in the PDP side of the\ndebate have argued that (1) classic PDP models can handle relational structure\n(Rogers & McClelland, 2008, 2014) and (2) the success of deep learning\napproaches to text processing suggests that structured representations are\nunnecessary to capture the gist of human language (Rabovsky et al., 2018). In\nthe present study we tested the Story Gestalt model (St. John, 1992), a classic\nPDP model of text comprehension, and a Sequence-to-Sequence with Attention\nmodel (Bahdanau et al., 2015), a contemporary deep learning architecture for\ntext processing. Both models were trained to answer questions about stories\nbased on the thematic roles that several concepts played on the stories. In\nthree critical test we varied the statistical structure of new stories while\nkeeping their relational structure constant with respect to the training data.\nEach model was susceptible to each statistical structure manipulation to a\ndifferent degree, with their performance failing below chance at least under\none manipulation. We argue that the failures of both models are due to the fact\nthat they cannotperform dynamic binding of independent roles and fillers.\nUltimately, these results cast doubts onthe suitability of traditional neural\nnetworks models for explaining phenomena based on relational reasoning,\nincluding language processing.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 11:19:25 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Puebla", "Guillermo", ""], ["Martin", "Andrea E.", ""], ["Doumas", "Leonidas A. A.", ""]]}, {"id": "1905.05709", "submitter": "Yaoqin Zhang", "authors": "Minlie Huang, Xiaoyan Zhu, and Jianfeng Gao", "title": "Challenges in Building Intelligent Open-domain Dialog Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a resurgent interest in developing intelligent open-domain dialog\nsystems due to the availability of large amounts of conversational data and the\nrecent progress on neural approaches to conversational AI. Unlike traditional\ntask-oriented bots, an open-domain dialog system aims to establish long-term\nconnections with users by satisfying the human need for communication,\naffection, and social belonging. This paper reviews the recent works on neural\napproaches that are devoted to addressing three challenges in developing such\nsystems: semantics, consistency, and interactiveness. Semantics requires a\ndialog system to not only understand the content of the dialog but also\nidentify user's social needs during the conversation. Consistency requires the\nsystem to demonstrate a consistent personality to win users trust and gain\ntheir long-term confidence. Interactiveness refers to the system's ability to\ngenerate interpersonal responses to achieve particular social goals such as\nentertainment, conforming, and task completion. The works we select to present\nhere is based on our unique views and are by no means complete. Nevertheless,\nwe hope that the discussion will inspire new research in developing more\nintelligent dialog systems.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 02:46:28 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 13:50:09 GMT"}, {"version": "v3", "created": "Fri, 28 Feb 2020 09:16:35 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Huang", "Minlie", ""], ["Zhu", "Xiaoyan", ""], ["Gao", "Jianfeng", ""]]}, {"id": "1905.05733", "submitter": "Shehzaad Dhuliawala", "authors": "Rajarshi Das, Shehzaad Dhuliawala, Manzil Zaheer, Andrew McCallum", "title": "Multi-step Retriever-Reader Interaction for Scalable Open-domain\n  Question Answering", "comments": "Published at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new framework for open-domain question answering in\nwhich the retriever and the reader iteratively interact with each other. The\nframework is agnostic to the architecture of the machine reading model, only\nrequiring access to the token-level hidden representations of the reader. The\nretriever uses fast nearest neighbor search to scale to corpora containing\nmillions of paragraphs. A gated recurrent unit updates the query at each step\nconditioned on the state of the reader and the reformulated query is used to\nre-rank the paragraphs by the retriever. We conduct analysis and show that\niterative interaction helps in retrieving informative paragraphs from the\ncorpus. Finally, we show that our multi-step-reasoning framework brings\nconsistent improvement when applied to two widely used reader architectures\nDrQA and BiDAF on various large open-domain datasets --- TriviaQA-unfiltered,\nQuasarT, SearchQA, and SQuAD-Open.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 17:27:08 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Das", "Rajarshi", ""], ["Dhuliawala", "Shehzaad", ""], ["Zaheer", "Manzil", ""], ["McCallum", "Andrew", ""]]}, {"id": "1905.05778", "submitter": "Shi Feng", "authors": "Shi Feng, Eric Wallace, Jordan Boyd-Graber", "title": "Misleading Failures of Partial-input Baselines", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work establishes dataset difficulty and removes annotation artifacts\nvia partial-input baselines (e.g., hypothesis-only models for SNLI or\nquestion-only models for VQA). When a partial-input baseline gets high\naccuracy, a dataset is cheatable. However, the converse is not necessarily\ntrue: the failure of a partial-input baseline does not mean a dataset is free\nof artifacts. To illustrate this, we first design artificial datasets which\ncontain trivial patterns in the full input that are undetectable by any\npartial-input model. Next, we identify such artifacts in the SNLI dataset - a\nhypothesis-only model augmented with trivial patterns in the premise can solve\n15% of the examples that are previously considered \"hard\". Our work provides a\ncaveat for the use of partial-input baselines for dataset verification and\ncreation.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 18:01:41 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 02:39:20 GMT"}, {"version": "v3", "created": "Tue, 18 Jun 2019 17:07:09 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Feng", "Shi", ""], ["Wallace", "Eric", ""], ["Boyd-Graber", "Jordan", ""]]}, {"id": "1905.05812", "submitter": "Md Shad Akhtar", "authors": "Md Shad Akhtar, Dushyant Singh Chauhan, Deepanway Ghosal, Soujanya\n  Poria, Asif Ekbal and Pushpak Bhattacharyya", "title": "Multi-task Learning for Multi-modal Emotion Recognition and Sentiment\n  Analysis", "comments": "Accepted for publication in NAACL:HLT-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Related tasks often have inter-dependence on each other and perform better\nwhen solved in a joint framework. In this paper, we present a deep multi-task\nlearning framework that jointly performs sentiment and emotion analysis both.\nThe multi-modal inputs (i.e., text, acoustic and visual frames) of a video\nconvey diverse and distinctive information, and usually do not have equal\ncontribution in the decision making. We propose a context-level inter-modal\nattention framework for simultaneously predicting the sentiment and expressed\nemotions of an utterance. We evaluate our proposed approach on CMU-MOSEI\ndataset for multi-modal sentiment and emotion analysis. Evaluation results\nsuggest that multi-task learning framework offers improvement over the\nsingle-task framework. The proposed approach reports new state-of-the-art\nperformance for both sentiment analysis and emotion analysis.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 19:42:43 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Akhtar", "Md Shad", ""], ["Chauhan", "Dushyant Singh", ""], ["Ghosal", "Deepanway", ""], ["Poria", "Soujanya", ""], ["Ekbal", "Asif", ""], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "1905.05816", "submitter": "Xuan Zhang", "authors": "Xuan Zhang, Pamela Shapiro, Gaurav Kumar, Paul McNamee, Marine\n  Carpuat, Kevin Duh", "title": "Curriculum Learning for Domain Adaptation in Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a curriculum learning approach to adapt generic neural machine\ntranslation models to a specific domain. Samples are grouped by their\nsimilarities to the domain of interest and each group is fed to the training\nalgorithm with a particular schedule. This approach is simple to implement on\ntop of any neural framework or architecture, and consistently outperforms both\nunadapted and adapted baselines in experiments with two distinct domains and\ntwo language pairs.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 20:03:54 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Zhang", "Xuan", ""], ["Shapiro", "Pamela", ""], ["Kumar", "Gaurav", ""], ["McNamee", "Paul", ""], ["Carpuat", "Marine", ""], ["Duh", "Kevin", ""]]}, {"id": "1905.05818", "submitter": "Sean MacAvaney", "authors": "Sean MacAvaney, Sajad Sotudeh, Arman Cohan, Nazli Goharian, Ish\n  Talati, Ross W. Filice", "title": "Ontology-Aware Clinical Abstractive Summarization", "comments": "4 pages; SIGIR 2019 Short Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatically generating accurate summaries from clinical reports could save\na clinician's time, improve summary coverage, and reduce errors. We propose a\nsequence-to-sequence abstractive summarization model augmented with\ndomain-specific ontological information to enhance content selection and\nsummary generation. We apply our method to a dataset of radiology reports and\nshow that it significantly outperforms the current state-of-the-art on this\ntask in terms of rouge scores. Extensive human evaluation conducted by a\nradiologist further indicates that this approach yields summaries that are less\nlikely to omit important details, without sacrificing readability or accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 20:09:18 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["MacAvaney", "Sean", ""], ["Sotudeh", "Sajad", ""], ["Cohan", "Arman", ""], ["Goharian", "Nazli", ""], ["Talati", "Ish", ""], ["Filice", "Ross W.", ""]]}, {"id": "1905.05877", "submitter": "Meliha Yetisgen", "authors": "Wilson Lau, Thomas H Payne, Ozlem Uzuner, Meliha Yetisgen", "title": "Extraction and Analysis of Clinically Important Follow-up\n  Recommendations in a Large Radiology Dataset", "comments": "Under Review at American Medical Informatics Association Fall\n  Symposium'2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication of follow-up recommendations when abnormalities are identified\non imaging studies is prone to error. In this paper, we present a natural\nlanguage processing approach based on deep learning to automatically identify\nclinically important recommendations in radiology reports. Our approach first\nidentifies the recommendation sentences and then extracts reason, test, and\ntime frame of the identified recommendations. To train our extraction models,\nwe created a corpus of 567 radiology reports annotated for recommendation\ninformation. Our extraction models achieved 0.92 f-score for recommendation\nsentence, 0.65 f-score for reason, 0.73 f-score for test, and 0.84 f-score for\ntime frame. We applied the extraction models to a set of over 3.3 million\nradiology reports and analyzed the adherence of follow-up recommendations.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 23:11:46 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Lau", "Wilson", ""], ["Payne", "Thomas H", ""], ["Uzuner", "Ozlem", ""], ["Yetisgen", "Meliha", ""]]}, {"id": "1905.05888", "submitter": "Christoph Salge", "authors": "Christoph Salge, Christian Guckelsberger, Michael Cerny Green, Rodrigo\n  Canaan and Julian Togelius", "title": "Generative Design in Minecraft: Chronicle Challenge", "comments": "5 pages, 1 Figure, accepted as late-breaking paper at ICCC 2019, 10th\n  International Conference on Computational Creativity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Chronicle Challenge as an optional addition to the\nSettlement Generation Challenge in Minecraft. One of the foci of the overall\ncompetition is adaptive procedural content generation (PCG), an arguably\nunder-explored problem in computational creativity. In the base challenge,\nparticipants must generate new settlements that respond to and ideally interact\nwith existing content in the world, such as the landscape or climate. The goal\nis to understand the underlying creative process, and to design better PCG\nsystems. The Chronicle Challenge in particular focuses on the generation of a\nnarrative based on the history of a generated settlement, expressed in natural\nlanguage. We discuss the unique features of the Chronicle Challenge in\ncomparison to other competitions, clarify the characteristics of a chronicle\neligible for submission and describe the evaluation criteria. We furthermore\ndraw on simulation-based approaches in computational storytelling as examples\nto how this challenge could be approached.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 23:53:57 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Salge", "Christoph", ""], ["Guckelsberger", "Christian", ""], ["Green", "Michael Cerny", ""], ["Canaan", "Rodrigo", ""], ["Togelius", "Julian", ""]]}, {"id": "1905.05910", "submitter": "Peng Xu", "authors": "Peng Xu, Xiaofei Ma, Ramesh Nallapati, Bing Xiang", "title": "Passage Ranking with Weak Supervision", "comments": "6 pages, 1 figure", "journal-ref": "ICLR 2019 LLD workshop", "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a \\textit{weak supervision} framework for neural\nranking tasks based on the data programming paradigm \\citep{Ratner2016}, which\nenables us to leverage multiple weak supervision signals from different\nsources. Empirically, we consider two sources of weak supervision signals,\nunsupervised ranking functions and semantic feature similarities. We train a\nBERT-based passage-ranking model (which achieves new state-of-the-art\nperformances on two benchmark datasets with full supervision) in our weak\nsupervision framework. Without using ground-truth training labels, BERT-PR\nmodels outperform BM25 baseline by a large margin on all three datasets and\neven beat the previous state-of-the-art results with full supervision on two of\nthe datasets.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 01:47:57 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 04:04:17 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Xu", "Peng", ""], ["Ma", "Xiaofei", ""], ["Nallapati", "Ramesh", ""], ["Xiang", "Bing", ""]]}, {"id": "1905.05950", "submitter": "Ian Tenney", "authors": "Ian Tenney, Dipanjan Das, Ellie Pavlick", "title": "BERT Rediscovers the Classical NLP Pipeline", "comments": "Presented at ACL 2019", "journal-ref": "Proceedings of the 57th Annual Meeting of the Association for\n  Computational Linguistics (2019) 4593-4601", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained text encoders have rapidly advanced the state of the art on many\nNLP tasks. We focus on one such model, BERT, and aim to quantify where\nlinguistic information is captured within the network. We find that the model\nrepresents the steps of the traditional NLP pipeline in an interpretable and\nlocalizable way, and that the regions responsible for each step appear in the\nexpected sequence: POS tagging, parsing, NER, semantic roles, then coreference.\nQualitative analysis reveals that the model can and often does adjust this\npipeline dynamically, revising lower-level decisions on the basis of\ndisambiguating information from higher-level representations.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 05:47:23 GMT"}, {"version": "v2", "created": "Fri, 9 Aug 2019 15:51:47 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Tenney", "Ian", ""], ["Das", "Dipanjan", ""], ["Pavlick", "Ellie", ""]]}, {"id": "1905.05961", "submitter": "Zijian Wang", "authors": "Zijian Wang, Scott A. Hale, David Adelani, Przemyslaw A. Grabowicz,\n  Timo Hartmann, Fabian Fl\\\"ock, David Jurgens", "title": "Demographic Inference and Representative Population Estimates from\n  Multilingual Social Media Data", "comments": "12 pages, 10 figures, Proceedings of the 2019 World Wide Web\n  Conference (WWW '19)", "journal-ref": "Proceedings of the 2019 World Wide Web Conference (WWW '19), May\n  13--17, 2019, San Francisco, CA, USA", "doi": "10.1145/3308558.3313684", "report-no": null, "categories": "cs.CY cs.CL cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Social media provide access to behavioural data at an unprecedented scale and\ngranularity. However, using these data to understand phenomena in a broader\npopulation is difficult due to their non-representativeness and the bias of\nstatistical inference tools towards dominant languages and groups. While\ndemographic attribute inference could be used to mitigate such bias, current\ntechniques are almost entirely monolingual and fail to work in a global\nenvironment. We address these challenges by combining multilingual demographic\ninference with post-stratification to create a more representative population\nsample. To learn demographic attributes, we create a new multimodal deep neural\narchitecture for joint classification of age, gender, and organization-status\nof social media users that operates in 32 languages. This method substantially\noutperforms current state of the art while also reducing algorithmic bias. To\ncorrect for sampling biases, we propose fully interpretable multilevel\nregression methods that estimate inclusion probabilities from inferred joint\npopulation counts and ground-truth population counts. In a large experiment\nover multilingual heterogeneous European regions, we show that our demographic\ninference and bias correction together allow for more accurate estimates of\npopulations and make a significant step towards representative social sensing\nin downstream applications with multilingual social media.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 06:15:16 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Wang", "Zijian", ""], ["Hale", "Scott A.", ""], ["Adelani", "David", ""], ["Grabowicz", "Przemyslaw A.", ""], ["Hartmann", "Timo", ""], ["Fl\u00f6ck", "Fabian", ""], ["Jurgens", "David", ""]]}, {"id": "1905.05979", "submitter": "Elena Voita", "authors": "Elena Voita, Rico Sennrich, Ivan Titov", "title": "When a Good Translation is Wrong in Context: Context-Aware Machine\n  Translation Improves on Deixis, Ellipsis, and Lexical Cohesion", "comments": "ACL 2019 (camera-ready)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though machine translation errors caused by the lack of context beyond one\nsentence have long been acknowledged, the development of context-aware NMT\nsystems is hampered by several problems. Firstly, standard metrics are not\nsensitive to improvements in consistency in document-level translations.\nSecondly, previous work on context-aware NMT assumed that the sentence-aligned\nparallel data consisted of complete documents while in most practical scenarios\nsuch document-level data constitutes only a fraction of the available parallel\ndata. To address the first issue, we perform a human study on an\nEnglish-Russian subtitles dataset and identify deixis, ellipsis and lexical\ncohesion as three main sources of inconsistency. We then create test sets\ntargeting these phenomena. To address the second shortcoming, we consider a\nset-up in which a much larger amount of sentence-level data is available\ncompared to that aligned at the document level. We introduce a model that is\nsuitable for this scenario and demonstrate major gains over a context-agnostic\nbaseline on our new benchmarks without sacrificing performance as measured with\nBLEU.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 07:05:46 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 09:57:03 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Voita", "Elena", ""], ["Sennrich", "Rico", ""], ["Titov", "Ivan", ""]]}, {"id": "1905.06109", "submitter": "Xiaosen Wang", "authors": "Kun He and Wu Wang and Xiaosen Wang and John E. Hopcroft", "title": "A New Anchor Word Selection Method for the Separable Topic Discovery", "comments": "18 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Separable Non-negative Matrix Factorization (SNMF) is an important method for\ntopic modeling, where \"separable\" assumes every topic contains at least one\nanchor word, defined as a word that has non-zero probability only on that\ntopic. SNMF focuses on the word co-occurrence patterns to reveal topics by two\nsteps: anchor word selection and topic recovery. The quality of the anchor\nwords strongly influences the quality of the extracted topics. Existing anchor\nword selection algorithm is to greedily find an approximate convex hull in a\nhigh-dimensional word co-occurrence space. In this work, we propose a new\nmethod for the anchor word selection by associating the word co-occurrence\nprobability with the words similarity and assuming that the most different\nwords on semantic are potential candidates for the anchor words. Therefore, if\nthe similarity of a word-pair is very low, then the two words are very likely\nto be the anchor words. According to the statistical information of text\ncorpora, we can get the similarity of all word-pairs. We build the word\nsimilarity graph where the nodes correspond to words and weights on edges stand\nfor the word-pair similarity. Following this way, we design a greedy method to\nfind a minimum edge-weight anchor clique of a given size in the graph for the\nanchor word selection. Extensive experiments on real-world corpus demonstrate\nthe effectiveness of the proposed anchor word selection method that outperforms\nthe common convex hull-based methods on the revealed topic quality. Meanwhile,\nour method is much faster than typical SNMF based method.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 12:16:10 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["He", "Kun", ""], ["Wang", "Wu", ""], ["Wang", "Xiaosen", ""], ["Hopcroft", "John E.", ""]]}, {"id": "1905.06139", "submitter": "Fenglin Liu", "authors": "Fenglin Liu, Yuanxin Liu, Xuancheng Ren, Xiaodong He, Xu Sun", "title": "Aligning Visual Regions and Textual Concepts for Semantic-Grounded Image\n  Representations", "comments": "Accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In vision-and-language grounding problems, fine-grained representations of\nthe image are considered to be of paramount importance. Most of the current\nsystems incorporate visual features and textual concepts as a sketch of an\nimage. However, plainly inferred representations are usually undesirable in\nthat they are composed of separate components, the relations of which are\nelusive. In this work, we aim at representing an image with a set of integrated\nvisual regions and corresponding textual concepts, reflecting certain\nsemantics. To this end, we build the Mutual Iterative Attention (MIA) module,\nwhich integrates correlated visual features and textual concepts, respectively,\nby aligning the two modalities. We evaluate the proposed approach on two\nrepresentative vision-and-language grounding tasks, i.e., image captioning and\nvisual question answering. In both tasks, the semantic-grounded image\nrepresentations consistently boost the performance of the baseline models under\nall metrics across the board. The results demonstrate that our approach is\neffective and generalizes well to a wide range of models for image-related\napplications. (The code is available at https://github.com/fenglinliu98/MIA)\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 12:39:49 GMT"}, {"version": "v2", "created": "Sun, 26 May 2019 08:10:43 GMT"}, {"version": "v3", "created": "Mon, 4 Nov 2019 17:10:36 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Liu", "Fenglin", ""], ["Liu", "Yuanxin", ""], ["Ren", "Xuancheng", ""], ["He", "Xiaodong", ""], ["Sun", "Xu", ""]]}, {"id": "1905.06175", "submitter": "Mohsin Munir", "authors": "Mohsin Munir, Shoaib Ahmed Siddiqui, Ferdinand K\\\"usters, Dominique\n  Mercier, Andreas Dengel, Sheraz Ahmed", "title": "TSXplain: Demystification of DNN Decisions for Time-Series using Natural\n  Language and Statistical Features", "comments": "Pre-print", "journal-ref": null, "doi": "10.1007/978-3-030-30493-5_43", "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks (NN) are considered as black-boxes due to the lack of\nexplainability and transparency of their decisions. This significantly hampers\ntheir deployment in environments where explainability is essential along with\nthe accuracy of the system. Recently, significant efforts have been made for\nthe interpretability of these deep networks with the aim to open up the\nblack-box. However, most of these approaches are specifically developed for\nvisual modalities. In addition, the interpretations provided by these systems\nrequire expert knowledge and understanding for intelligibility. This indicates\na vital gap between the explainability provided by the systems and the novice\nuser. To bridge this gap, we present a novel framework i.e. Time-Series\neXplanation (TSXplain) system which produces a natural language based\nexplanation of the decision taken by a NN. It uses the extracted statistical\nfeatures to describe the decision of a NN, merging the deep learning world with\nthat of statistics. The two-level explanation provides ample description of the\ndecision made by the network to aid an expert as well as a novice user alike.\nOur survey and reliability assessment test confirm that the generated\nexplanations are meaningful and correct. We believe that generating natural\nlanguage based descriptions of the network's decisions is a big step towards\nopening up the black-box.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 13:37:58 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Munir", "Mohsin", ""], ["Siddiqui", "Shoaib Ahmed", ""], ["K\u00fcsters", "Ferdinand", ""], ["Mercier", "Dominique", ""], ["Dengel", "Andreas", ""], ["Ahmed", "Sheraz", ""]]}, {"id": "1905.06196", "submitter": "Shang-Yu Su", "authors": "Shang-Yu Su, Chao-Wei Huang, and Yun-Nung Chen", "title": "Dual Supervised Learning for Natural Language Understanding and\n  Generation", "comments": "Accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language understanding (NLU) and natural language generation (NLG)\nare both critical research topics in the NLP field. Natural language\nunderstanding is to extract the core semantic meaning from the given\nutterances, while natural language generation is opposite, of which the goal is\nto construct corresponding sentences based on the given semantics. However,\nsuch dual relationship has not been investigated in the literature. This paper\nproposes a new learning framework for language understanding and generation on\ntop of dual supervised learning, providing a way to exploit the duality. The\npreliminary experiments show that the proposed approach boosts the performance\nfor both tasks.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 14:04:47 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 00:58:40 GMT"}, {"version": "v3", "created": "Tue, 28 May 2019 04:11:55 GMT"}, {"version": "v4", "created": "Thu, 30 Apr 2020 11:33:36 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Su", "Shang-Yu", ""], ["Huang", "Chao-Wei", ""], ["Chen", "Yun-Nung", ""]]}, {"id": "1905.06221", "submitter": "Guanhua Zhang", "authors": "Guanhua Zhang, Bing Bai, Jian Liang, Kun Bai, Shiyu Chang, Mo Yu,\n  Conghui Zhu, Tiejun Zhao", "title": "Selection Bias Explorations and Debias Methods for Natural Language\n  Sentence Matching Datasets", "comments": "Accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural Language Sentence Matching (NLSM) has gained substantial attention\nfrom both academics and the industry, and rich public datasets contribute a lot\nto this process. However, biased datasets can also hurt the generalization\nperformance of trained models and give untrustworthy evaluation results. For\nmany NLSM datasets, the providers select some pairs of sentences into the\ndatasets, and this sampling procedure can easily bring unintended pattern,\ni.e., selection bias. One example is the QuoraQP dataset, where some\ncontent-independent naive features are unreasonably predictive. Such features\nare the reflection of the selection bias and termed as the leakage features. In\nthis paper, we investigate the problem of selection bias on six NLSM datasets\nand find that four out of them are significantly biased. We further propose a\ntraining and evaluation framework to alleviate the bias. Experimental results\non QuoraQP suggest that the proposed framework can improve the generalization\nability of trained models, and give more trustworthy evaluation results for\nreal-world adoptions.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 14:51:33 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 09:40:00 GMT"}, {"version": "v3", "created": "Mon, 20 May 2019 03:11:20 GMT"}, {"version": "v4", "created": "Mon, 10 Jun 2019 03:12:43 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Zhang", "Guanhua", ""], ["Bai", "Bing", ""], ["Liang", "Jian", ""], ["Bai", "Kun", ""], ["Chang", "Shiyu", ""], ["Yu", "Mo", ""], ["Zhu", "Conghui", ""], ["Zhao", "Tiejun", ""]]}, {"id": "1905.06233", "submitter": "Horatiu Cirstea", "authors": "Horatiu Cirstea and Pierre-Etienne Moreau", "title": "Generic Encodings of Constructor Rewriting Systems", "comments": "Added appendix with proofs and extended examples", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rewriting is a formalism widely used in computer science and mathematical\nlogic. The classical formalism has been extended, in the context of functional\nlanguages, with an order over the rules and, in the context of rewrite based\nlanguages, with the negation over patterns. We propose in this paper a concise\nand clear algorithm computing the difference over patterns which can be used to\ndefine generic encodings of constructor term rewriting systems with negation\nand order into classical term rewriting systems. As a direct consequence,\nestablished methods used for term rewriting systems can be applied to analyze\nproperties of the extended systems. The approach can also be seen as a generic\ncompiler which targets any language providing basic pattern matching\nprimitives. The formalism provides also a new method for deciding if a set of\npatterns subsumes a given pattern and thus, for checking the presence of\nuseless patterns or the completeness of a set of patterns.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 14:06:09 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 11:07:38 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Cirstea", "Horatiu", ""], ["Moreau", "Pierre-Etienne", ""]]}, {"id": "1905.06241", "submitter": "Ben Bogin", "authors": "Ben Bogin, Matt Gardner and Jonathan Berant", "title": "Representing Schema Structure with Graph Neural Networks for Text-to-SQL\n  Parsing", "comments": "Accepted as a short paper at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on parsing language to SQL has largely ignored the structure of the\ndatabase (DB) schema, either because the DB was very simple, or because it was\nobserved at both training and test time. In Spider, a recently-released\ntext-to-SQL dataset, new and complex DBs are given at test time, and so the\nstructure of the DB schema can inform the predicted SQL query. In this paper,\nwe present an encoder-decoder semantic parser, where the structure of the DB\nschema is encoded with a graph neural network, and this representation is later\nused at both encoding and decoding time. Evaluation shows that encoding the\nschema structure improves our parser accuracy from 33.8% to 39.4%, dramatically\nabove the current state of the art, which is at 19.7%.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 15:22:01 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 05:30:41 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Bogin", "Ben", ""], ["Gardner", "Matt", ""], ["Berant", "Jonathan", ""]]}, {"id": "1905.06290", "submitter": "Vid Kocijan", "authors": "Vid Kocijan, Ana-Maria Cretu, Oana-Maria Camburu, Yordan Yordanov,\n  Thomas Lukasiewicz", "title": "A Surprisingly Robust Trick for Winograd Schema Challenge", "comments": "Appeared as part of the ACL 2019 conference", "journal-ref": null, "doi": "10.18653/v1/P19-1478", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Winograd Schema Challenge (WSC) dataset WSC273 and its inference\ncounterpart WNLI are popular benchmarks for natural language understanding and\ncommonsense reasoning. In this paper, we show that the performance of three\nlanguage models on WSC273 strongly improves when fine-tuned on a similar\npronoun disambiguation problem dataset (denoted WSCR). We additionally generate\na large unsupervised WSC-like dataset. By fine-tuning the BERT language model\nboth on the introduced and on the WSCR dataset, we achieve overall accuracies\nof 72.5% and 74.7% on WSC273 and WNLI, improving the previous state-of-the-art\nsolutions by 8.8% and 9.6%, respectively. Furthermore, our fine-tuned models\nare also consistently more robust on the \"complex\" subsets of WSC273,\nintroduced by Trichelair et al. (2018).\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 16:47:11 GMT"}, {"version": "v2", "created": "Sun, 4 Aug 2019 09:06:11 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Kocijan", "Vid", ""], ["Cretu", "Ana-Maria", ""], ["Camburu", "Oana-Maria", ""], ["Yordanov", "Yordan", ""], ["Lukasiewicz", "Thomas", ""]]}, {"id": "1905.06316", "submitter": "Ian Tenney", "authors": "Ian Tenney, Patrick Xia, Berlin Chen, Alex Wang, Adam Poliak, R Thomas\n  McCoy, Najoung Kim, Benjamin Van Durme, Samuel R. Bowman, Dipanjan Das, Ellie\n  Pavlick", "title": "What do you learn from context? Probing for sentence structure in\n  contextualized word representations", "comments": "ICLR 2019 camera-ready version, 17 pages including appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextualized representation models such as ELMo (Peters et al., 2018a) and\nBERT (Devlin et al., 2018) have recently achieved state-of-the-art results on a\ndiverse array of downstream NLP tasks. Building on recent token-level probing\nwork, we introduce a novel edge probing task design and construct a broad suite\nof sub-sentence tasks derived from the traditional structured NLP pipeline. We\nprobe word-level contextual representations from four recent models and\ninvestigate how they encode sentence structure across a range of syntactic,\nsemantic, local, and long-range phenomena. We find that existing models trained\non language modeling and translation produce strong representations for\nsyntactic phenomena, but only offer comparably small improvements on semantic\ntasks over a non-contextual baseline.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 17:48:56 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Tenney", "Ian", ""], ["Xia", "Patrick", ""], ["Chen", "Berlin", ""], ["Wang", "Alex", ""], ["Poliak", "Adam", ""], ["McCoy", "R Thomas", ""], ["Kim", "Najoung", ""], ["Van Durme", "Benjamin", ""], ["Bowman", "Samuel R.", ""], ["Das", "Dipanjan", ""], ["Pavlick", "Ellie", ""]]}, {"id": "1905.06319", "submitter": "Shijie Wu", "authors": "Shijie Wu and Ryan Cotterell", "title": "Exact Hard Monotonic Attention for Character-Level Transduction", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many common character-level, string-to-string transduction tasks, e.g.\ngraphemeto-phoneme conversion and morphological inflection, consist almost\nexclusively of monotonic transduction. Neural sequence-to-sequence models with\nsoft attention, which are non-monotonic, often outperform popular monotonic\nmodels. In this work, we ask the following question: Is monotonicity really a\nhelpful inductive bias in these tasks? We develop a hard attention\nsequence-to-sequence model that enforces strict monotonicity and learns a\nlatent alignment jointly while learning to transduce. With the help of dynamic\nprogramming, we are able to compute the exact marginalization over all\nmonotonic alignments. Our models achieve state-of-the-art performance on\nmorphological inflection. Furthermore, we find strong performance on two other\ncharacter-level transduction tasks. Code is available at\nhttps://github.com/shijie-wu/neural-transducer.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 17:51:09 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 08:09:37 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Wu", "Shijie", ""], ["Cotterell", "Ryan", ""]]}, {"id": "1905.06401", "submitter": "Grzegorz Chrupa{\\l}a", "authors": "Grzegorz Chrupa{\\l}a, Afra Alishahi", "title": "Correlating neural and symbolic representations of language", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Analysis methods which enable us to better understand the representations and\nfunctioning of neural models of language are increasingly needed as deep\nlearning becomes the dominant approach in NLP. Here we present two methods\nbased on Representational Similarity Analysis (RSA) and Tree Kernels (TK) which\nallow us to directly quantify how strongly the information encoded in neural\nactivation patterns corresponds to information represented by symbolic\nstructures such as syntax trees. We first validate our methods on the case of a\nsimple synthetic language for arithmetic expressions with clearly defined\nsyntax and semantics, and show that they exhibit the expected pattern of\nresults. We then apply our methods to correlate neural representations of\nEnglish sentences with their constituency parse trees.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 10:09:14 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 14:26:11 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Chrupa\u0142a", "Grzegorz", ""], ["Alishahi", "Afra", ""]]}, {"id": "1905.06407", "submitter": "Lei Shu", "authors": "Lei Shu and Hu Xu and Bing Liu", "title": "Controlled CNN-based Sequence Labeling for Aspect Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One key task of fine-grained sentiment analysis on reviews is to extract\naspects or features that users have expressed opinions on. This paper focuses\non supervised aspect extraction using a modified CNN called controlled CNN\n(Ctrl). The modified CNN has two types of control modules. Through asynchronous\nparameter updating, it prevents over-fitting and boosts CNN's performance\nsignificantly. This model achieves state-of-the-art results on standard aspect\nextraction datasets. To the best of our knowledge, this is the first paper to\napply control modules to aspect extraction.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 19:28:10 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 20:22:38 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Shu", "Lei", ""], ["Xu", "Hu", ""], ["Liu", "Bing", ""]]}, {"id": "1905.06512", "submitter": "Liner Yang", "authors": "Liner Yang, Cunliang Kong, Yun Chen, Yang Liu, Qinan Fan, Erhong Yang", "title": "Incorporating Sememes into Chinese Definition Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chinese definition modeling is a challenging task that generates a dictionary\ndefinition in Chinese for a given Chinese word. To accomplish this task, we\nconstruct the Chinese Definition Modeling Corpus (CDM), which contains triples\nof word, sememes and the corresponding definition. We present two novel models\nto improve Chinese definition modeling: the Adaptive-Attention model (AAM) and\nthe Self- and Adaptive-Attention Model (SAAM). AAM successfully incorporates\nsememes for generating the definition with an adaptive attention mechanism. It\nhas the capability to decide which sememes to focus on and when to pay\nattention to sememes. SAAM further replaces recurrent connections in AAM with\nself-attention and relies entirely on the attention mechanism, reducing the\npath length between word, sememes and definition. Experiments on CDM\ndemonstrate that by incorporating sememes, our best proposed model can\noutperform the state-of-the-art method by +6.0 BLEU.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 03:38:14 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Yang", "Liner", ""], ["Kong", "Cunliang", ""], ["Chen", "Yun", ""], ["Liu", "Yang", ""], ["Fan", "Qinan", ""], ["Yang", "Erhong", ""]]}, {"id": "1905.06533", "submitter": "Emre Yilmaz", "authors": "Emre Y{\\i}lmaz and Vikramjit Mitra and Ganesh Sivaraman and Horacio\n  Franco", "title": "Articulatory and bottleneck features for speaker-independent ASR of\n  dysarthric speech", "comments": "to appear in Computer Speech & Language -\n  https://doi.org/10.1016/j.csl.2019.05.002 - arXiv admin note: substantial\n  text overlap with arXiv:1807.10948", "journal-ref": null, "doi": "10.1016/j.csl.2019.05.002", "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The rapid population aging has stimulated the development of assistive\ndevices that provide personalized medical support to the needies suffering from\nvarious etiologies. One prominent clinical application is a computer-assisted\nspeech training system which enables personalized speech therapy to patients\nimpaired by communicative disorders in the patient's home environment. Such a\nsystem relies on the robust automatic speech recognition (ASR) technology to be\nable to provide accurate articulation feedback. With the long-term aim of\ndeveloping off-the-shelf ASR systems that can be incorporated in clinical\ncontext without prior speaker information, we compare the ASR performance of\nspeaker-independent bottleneck and articulatory features on dysarthric speech\nused in conjunction with dedicated neural network-based acoustic models that\nhave been shown to be robust against spectrotemporal deviations. We report ASR\nperformance of these systems on two dysarthric speech datasets of different\ncharacteristics to quantify the achieved performance gains. Despite the\nremaining performance gap between the dysarthric and normal speech, significant\nimprovements have been reported on both datasets using speaker-independent ASR\narchitectures.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 05:40:18 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 02:13:22 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Y\u0131lmaz", "Emre", ""], ["Mitra", "Vikramjit", ""], ["Sivaraman", "Ganesh", ""], ["Franco", "Horacio", ""]]}, {"id": "1905.06566", "submitter": "Xingxing Zhang", "authors": "Xingxing Zhang, Furu Wei, Ming Zhou", "title": "HIBERT: Document Level Pre-training of Hierarchical Bidirectional\n  Transformers for Document Summarization", "comments": "to appear in ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural extractive summarization models usually employ a hierarchical encoder\nfor document encoding and they are trained using sentence-level labels, which\nare created heuristically using rule-based methods. Training the hierarchical\nencoder with these \\emph{inaccurate} labels is challenging. Inspired by the\nrecent work on pre-training transformer sentence encoders\n\\cite{devlin:2018:arxiv}, we propose {\\sc Hibert} (as shorthand for {\\bf\nHI}erachical {\\bf B}idirectional {\\bf E}ncoder {\\bf R}epresentations from {\\bf\nT}ransformers) for document encoding and a method to pre-train it using\nunlabeled data. We apply the pre-trained {\\sc Hibert} to our summarization\nmodel and it outperforms its randomly initialized counterpart by 1.25 ROUGE on\nthe CNN/Dailymail dataset and by 2.0 ROUGE on a version of New York Times\ndataset. We also achieve the state-of-the-art performance on these two\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 07:20:21 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Zhang", "Xingxing", ""], ["Wei", "Furu", ""], ["Zhou", "Ming", ""]]}, {"id": "1905.06596", "submitter": "Jos\\'e A. R. Fonollosa", "authors": "Jos\\'e A. R. Fonollosa, Noe Casas, Marta R. Costa-juss\\`a", "title": "Joint Source-Target Self Attention with Locality Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dominant neural machine translation models are based on the\nencoder-decoder structure, and many of them rely on an unconstrained receptive\nfield over source and target sequences. In this paper we study a new\narchitecture that breaks with both conventions. Our simplified architecture\nconsists in the decoder part of a transformer model, based on self-attention,\nbut with locality constraints applied on the attention receptive field. As\ninput for training, both source and target sentences are fed to the network,\nwhich is trained as a language model. At inference time, the target tokens are\npredicted autoregressively starting with the source sequence as previous\ntokens. The proposed model achieves a new state of the art of 35.7 BLEU on\nIWSLT'14 German-English and matches the best reported results in the literature\non the WMT'14 English-German and WMT'14 English-French translation benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 08:35:12 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Fonollosa", "Jos\u00e9 A. R.", ""], ["Casas", "Noe", ""], ["Costa-juss\u00e0", "Marta R.", ""]]}, {"id": "1905.06597", "submitter": "Xiuyu Wu", "authors": "Xiuyu Wu and Yunfang Wu", "title": "A Simple Dual-decoder Model for Generating Response with Sentiment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to generate human like response is one of the most challenging tasks for\nartificial intelligence. In a real application, after reading the same post\ndifferent people might write responses with positive or negative sentiment\naccording to their own experiences and attitudes. To simulate this procedure,\nwe propose a simple but effective dual-decoder model to generate response with\na particular sentiment, by connecting two sentiment decoders to one encoder. To\nsupport this model training, we construct a new conversation dataset with the\nform of (post, resp1, resp2) where two responses contain opposite sentiment.\nExperiment results show that our dual-decoder model can generate diverse\nresponses with target sentiment, which obtains significant performance gain in\nsentiment accuracy and word diversity over the traditional single-decoder\nmodel. We will make our data and code publicly available for further study.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 08:40:47 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Wu", "Xiuyu", ""], ["Wu", "Yunfang", ""]]}, {"id": "1905.06638", "submitter": "Daniel Fleischer", "authors": "Alon Rozental, Zohar Kelrich, Daniel Fleischer", "title": "Latent Universal Task-Specific BERT", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a language representation model which combines the\nBidirectional Encoder Representations from Transformers (BERT) learning\nmechanism described in Devlin et al. (2018) with a generalization of the\nUniversal Transformer model described in Dehghani et al. (2018). We further\nimprove this model by adding a latent variable that represents the persona and\ntopics of interests of the writer for each training example. We also describe a\nsimple method to improve the usefulness of our language representation for\nsolving problems in a specific domain at the expense of its ability to\ngeneralize to other fields. Finally, we release a pre-trained language\nrepresentation model for social texts that was trained on 100 million tweets.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 10:21:51 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Rozental", "Alon", ""], ["Kelrich", "Zohar", ""], ["Fleischer", "Daniel", ""]]}, {"id": "1905.06643", "submitter": "Vuong M. Ngo", "authors": "T. N. T. Tran, L. K. N. Nguyen, V. M. Ngo", "title": "Machine Learning based English Sentiment Analysis", "comments": "6 pages, in Vietnamese", "journal-ref": "Journal of Science and Technology, Vietnam Academy of Science and\n  Technology, Vol. 52, No. 4D, pp. 142-155 (2014)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment analysis or opinion mining aims to determine attitudes, judgments\nand opinions of customers for a product or a service. This is a great system to\nhelp manufacturers or servicers know the satisfaction level of customers about\ntheir products or services. From that, they can have appropriate adjustments.\nWe use a popular machine learning method, being Support Vector Machine, combine\nwith the library in Waikato Environment for Knowledge Analysis (WEKA) to build\nJava web program which analyzes the sentiment of English comments belongs one\nin four types of woman products. That are dresses, handbags, shoes and rings.\nWe have developed and test our system with a training set having 300 comments\nand a test set having 400 comments. The experimental results of the system\nabout precision, recall and F measures for positive comments are 89.3%, 95.0%\nand 92,.1%; for negative comments are 97.1%, 78.5% and 86.8%; and for neutral\ncomments are 76.7%, 86.2% and 81.2%.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 10:27:17 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Tran", "T. N. T.", ""], ["Nguyen", "L. K. N.", ""], ["Ngo", "V. M.", ""]]}, {"id": "1905.06647", "submitter": "Vuong M. Ngo", "authors": "P.T. Nguyen, L. T. Le, V. M. Ngo, P. M. Nguyen", "title": "Using Entity Relations for Opinion Mining of Vietnamese Comments", "comments": "14 pages, in Vietnamese", "journal-ref": "Journal of Science and Technology, Vietnam Academy of Science and\n  Technology, Vol. 52, No. 4D, pp. 120-132 (2014)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose several novel techniques to extract and mining\nopinions of Vietnamese reviews of customers about a number of products traded\non e-commerce in Vietnam. The assessment is based on the emotional level of\ncustomers on a specific product such as mobile and laptop. We exploit the\nfeatures of the products because they are much interested by customers and have\nmany products in the Vietnam e-commerce market. Thence, it can be known the\nfavorites and dislikes of customers about exploited products.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 10:31:48 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Nguyen", "P. T.", ""], ["Le", "L. T.", ""], ["Ngo", "V. M.", ""], ["Nguyen", "P. M.", ""]]}, {"id": "1905.06649", "submitter": "Laura Aina", "authors": "Laura Aina, Carina Silberer, Matthijs Westera, Ionut-Teodor Sorodoc,\n  Gemma Boleda", "title": "What do Entity-Centric Models Learn? Insights from Entity Linking in\n  Multi-Party Dialogue", "comments": "To appear in Proceedings of NAACL 2019 Annual Conference of the North\n  American Chapter of the Association for Computational Linguistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Humans use language to refer to entities in the external world. Motivated by\nthis, in recent years several models that incorporate a bias towards learning\nentity representations have been proposed. Such entity-centric models have\nshown empirical success, but we still know little about why. In this paper we\nanalyze the behavior of two recently proposed entity-centric models in a\nreferential task, Entity Linking in Multi-party Dialogue (SemEval 2018 Task 4).\nWe show that these models outperform the state of the art on this task, and\nthat they do better on lower frequency entities than a counterpart model that\nis not entity-centric, with the same model size. We argue that making models\nentity-centric naturally fosters good architectural decisions. However, we also\nshow that these models do not really build entity representations and that they\nmake poor use of linguistic context. These negative results underscore the need\nfor model analysis, to test whether the motivations for particular\narchitectures are borne out in how models behave when deployed.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 10:43:58 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Aina", "Laura", ""], ["Silberer", "Carina", ""], ["Westera", "Matthijs", ""], ["Sorodoc", "Ionut-Teodor", ""], ["Boleda", "Gemma", ""]]}, {"id": "1905.06655", "submitter": "Joongbo Shin", "authors": "Joongbo Shin, Yoonhyung Lee, Kyomin Jung", "title": "Effective Sentence Scoring Method using Bidirectional Language Model for\n  Speech Recognition", "comments": "submitted to INTERSPEECH 2019, 5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In automatic speech recognition, many studies have shown performance\nimprovements using language models (LMs). Recent studies have tried to use\nbidirectional LMs (biLMs) instead of conventional unidirectional LMs (uniLMs)\nfor rescoring the $N$-best list decoded from the acoustic model. In spite of\ntheir theoretical benefits, the biLMs have not given notable improvements\ncompared to the uniLMs in their experiments. This is because their biLMs do not\nconsider the interaction between the two directions. In this paper, we propose\na novel sentence scoring method considering the interaction between the past\nand the future words on the biLM. Our experimental results on the LibriSpeech\ncorpus show that the biLM with the proposed sentence scoring outperforms the\nuniLM for the $N$-best list rescoring, consistently and significantly in all\nexperimental conditions. The analysis of WERs by word position demonstrates\nthat the biLM is more robust than the uniLM especially when a recognized\nsentence is short or a misrecognized word is at the beginning of the sentence.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 11:00:49 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Shin", "Joongbo", ""], ["Lee", "Yoonhyung", ""], ["Jung", "Kyomin", ""]]}, {"id": "1905.06777", "submitter": "Igor Ivkic", "authors": "Igor Ivkic, Alexander W\\\"ohrer, Markus Tauber", "title": "Towards Comparing Programming Paradigms", "comments": null, "journal-ref": "2017 12th International Conference for Internet Technology and\n  Secured Transactions (ICITST), Cambridge, UK", "doi": "10.23919/ICITST.2017.8356440", "report-no": null, "categories": "cs.HC cs.CL cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid technological progress in computer sciences finds solutions and at the\nsame time creates ever more complex requirements. Due to an evolving complexity\ntodays programming languages provide powerful frameworks which offer standard\nsolutions for recurring tasks to assist the programmer and to avoid the\nre-invention of the wheel with so-called out-of-the-box-features. In this\npaper, we propose a way of comparing different programming paradigms on a\ntheoretical, technical and practical level. Furthermore, the paper presents the\nresults of an initial comparison of two representative programming approaches,\nboth in the closed SAP environment.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 09:55:10 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Ivkic", "Igor", ""], ["W\u00f6hrer", "Alexander", ""], ["Tauber", "Markus", ""]]}, {"id": "1905.06791", "submitter": "Yi Ren", "authors": "Yi Ren, Xu Tan, Tao Qin, Sheng Zhao, Zhou Zhao, Tie-Yan Liu", "title": "Almost Unsupervised Text to Speech and Automatic Speech Recognition", "comments": "Accepted by ICML2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text to speech (TTS) and automatic speech recognition (ASR) are two dual\ntasks in speech processing and both achieve impressive performance thanks to\nthe recent advance in deep learning and large amount of aligned speech and text\ndata. However, the lack of aligned data poses a major practical problem for TTS\nand ASR on low-resource languages. In this paper, by leveraging the dual nature\nof the two tasks, we propose an almost unsupervised learning method that only\nleverages few hundreds of paired data and extra unpaired data for TTS and ASR.\nOur method consists of the following components: (1) a denoising auto-encoder,\nwhich reconstructs speech and text sequences respectively to develop the\ncapability of language modeling both in speech and text domain; (2) dual\ntransformation, where the TTS model transforms the text $y$ into speech\n$\\hat{x}$, and the ASR model leverages the transformed pair $(\\hat{x},y)$ for\ntraining, and vice versa, to boost the accuracy of the two tasks; (3)\nbidirectional sequence modeling, which addresses error propagation especially\nin the long speech and text sequence when training with few paired data; (4) a\nunified model structure, which combines all the above components for TTS and\nASR based on Transformer model. Our method achieves 99.84% in terms of word\nlevel intelligible rate and 2.68 MOS for TTS, and 11.7% PER for ASR on LJSpeech\ndataset, by leveraging only 200 paired speech and text data (about 20 minutes\naudio), together with extra unpaired speech and text data.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 13:20:57 GMT"}, {"version": "v2", "created": "Wed, 22 May 2019 01:07:17 GMT"}, {"version": "v3", "created": "Sun, 26 Jul 2020 09:31:42 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Ren", "Yi", ""], ["Tan", "Xu", ""], ["Qin", "Tao", ""], ["Zhao", "Sheng", ""], ["Zhao", "Zhou", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1905.06831", "submitter": "Marta R. Costa-juss\\`a", "authors": "Carlos Escolano, Marta R. Costa-juss\\`a, Jos\\'e A. R. Fonollosa", "title": "Towards Interlingua Neural Machine Translation", "comments": "arXiv admin note: substantial text overlap with arXiv:1810.06351", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Common intermediate language representation in neural machine translation can\nbe used to extend bilingual to multilingual systems by incremental training. In\nthis paper, we propose a new architecture based on introducing an interlingual\nloss as an additional training objective. By adding and forcing this\ninterlingual loss, we are able to train multiple encoders and decoders for each\nlanguage, sharing a common intermediate representation. Translation results on\nthe low-resourced tasks (Turkish-English and Kazakh-English tasks, from the\npopular Workshop on Machine Translation benchmark) show the following BLEU\nimprovements up to 2.8. However, results on a larger dataset (Russian-English\nand Kazakh-English, from the same baselines) show BLEU loses if the same\namount. While our system is only providing improvements for the low-resourced\ntasks in terms of translation quality, our system is capable of quickly\ndeploying new language pairs without retraining the rest of the system, which\nmay be a game-changer in some situations (i.e. in a disaster crisis where\ninternational help is required towards a small region or to develop some\ntranslation system for a client). Precisely, what is most relevant from our\narchitecture is that it is capable of: (1) reducing the number of production\nsystems, with respect to the number of languages, from quadratic to linear (2)\nincrementally adding a new language in the system without retraining languages\npreviously there and (3) allowing for translations from the new language to all\nthe others present in the system\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 13:52:53 GMT"}, {"version": "v2", "created": "Sun, 8 Dec 2019 17:24:01 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Escolano", "Carlos", ""], ["Costa-juss\u00e0", "Marta R.", ""], ["Fonollosa", "Jos\u00e9 A. R.", ""]]}, {"id": "1905.06837", "submitter": "Andrey Kutuzov", "authors": "Vadim Fomin, Daria Bakshandaeva, Julia Rodina, Andrey Kutuzov", "title": "Tracing cultural diachronic semantic shifts in Russian using word\n  embeddings: test sets and baselines", "comments": "Dialogue 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The paper introduces manually annotated test sets for the task of tracing\ndiachronic (temporal) semantic shifts in Russian. The two test sets are\ncomplementary in that the first one covers comparatively strong semantic\nchanges occurring to nouns and adjectives from pre-Soviet to Soviet times,\nwhile the second one covers comparatively subtle socially and culturally\ndetermined shifts occurring in years from 2000 to 2014. Additionally, the\nsecond test set offers more granular classification of shifts degree, but is\nlimited to only adjectives.\n  The introduction of the test sets allowed us to evaluate several\nwell-established algorithms of semantic shifts detection (posing this as a\nclassification problem), most of which have never been tested on Russian\nmaterial. All of these algorithms use distributional word embedding models\ntrained on the corresponding in-domain corpora. The resulting scores provide\nsolid comparison baselines for future studies tackling similar tasks. We\npublish the datasets, code and the trained models in order to facilitate\nfurther research in automatically detecting temporal semantic shifts for\nRussian words, with time periods of different granularities.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 15:27:19 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 22:12:13 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Fomin", "Vadim", ""], ["Bakshandaeva", "Daria", ""], ["Rodina", "Julia", ""], ["Kutuzov", "Andrey", ""]]}, {"id": "1905.06883", "submitter": "Chen Qian", "authors": "Chen Qian and Lijie Wen and Akhil Kumar", "title": "TraceWalk: Semantic-based Process Graph Embedding for Consistency\n  Checking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Process consistency checking (PCC), an interdiscipline of natural language\nprocessing (NLP) and business process management (BPM), aims to quantify the\ndegree of (in)consistencies between graphical and textual descriptions of a\nprocess. However, previous studies heavily depend on a great deal of complex\nexpert-defined knowledge such as alignment rules and assessment metrics, thus\nsuffer from the problems of low accuracy and poor adaptability when applied in\nopen-domain scenarios. To address the above issues, this paper makes the first\nattempt that uses deep learning to perform PCC. Specifically, we proposed\nTraceWalk, using semantic information of process graphs to learn latent node\nrepresentations, and integrates it into a convolutional neural network (CNN)\nbased model called TraceNet to predict consistencies. The theoretical proof\nformally provides the PCC's lower limit and experimental results demonstrate\nthat our approach performs more accurately than state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 16:15:01 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Qian", "Chen", ""], ["Wen", "Lijie", ""], ["Kumar", "Akhil", ""]]}, {"id": "1905.06906", "submitter": "Avinash Madasu", "authors": "Avinash Madasu and Vijjini Anvesh Rao", "title": "Gated Convolutional Neural Networks for Domain Adaptation", "comments": "Accepted Long Paper at 24th International Conference on Applications\n  of Natural Language to Information Systems, June 2019, MediaCityUK Campus,\n  United Kingdom", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain Adaptation explores the idea of how to maximize performance on a\ntarget domain, distinct from source domain, upon which the classifier was\ntrained. This idea has been explored for the task of sentiment analysis\nextensively. The training of reviews pertaining to one domain and evaluation on\nanother domain is widely studied for modeling a domain independent algorithm.\nThis further helps in understanding correlation between domains. In this paper,\nwe show that Gated Convolutional Neural Networks (GCN) perform effectively at\nlearning sentiment analysis in a manner where domain dependant knowledge is\nfiltered out using its gates. We perform our experiments on multiple gate\narchitectures: Gated Tanh ReLU Unit (GTRU), Gated Tanh Unit (GTU) and Gated\nLinear Unit (GLU). Extensive experimentation on two standard datasets relevant\nto the task, reveal that training with Gated Convolutional Neural Networks give\nsignificantly better performance on target domains than regular convolution and\nrecurrent based architectures. While complex architectures like attention,\nfilter domain specific knowledge as well, their complexity order is remarkably\nhigh as compared to gated architectures. GCNs rely on convolution hence gaining\nan upper hand through parallelization.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 16:57:35 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Madasu", "Avinash", ""], ["Rao", "Vijjini Anvesh", ""]]}, {"id": "1905.06933", "submitter": "Yunxuan Xiao", "authors": "Yunxuan Xiao, Yanru Qu, Lin Qiu, Hao Zhou, Lei Li, Weinan Zhang, Yong\n  Yu", "title": "Dynamically Fused Graph Network for Multi-hop Reasoning", "comments": "Accepted by ACL 19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text-based question answering (TBQA) has been studied extensively in recent\nyears. Most existing approaches focus on finding the answer to a question\nwithin a single paragraph. However, many difficult questions require multiple\nsupporting evidence from scattered text among two or more documents. In this\npaper, we propose Dynamically Fused Graph Network(DFGN), a novel method to\nanswer those questions requiring multiple scattered evidence and reasoning over\nthem. Inspired by human's step-by-step reasoning behavior, DFGN includes a\ndynamic fusion layer that starts from the entities mentioned in the given\nquery, explores along the entity graph dynamically built from the text, and\ngradually finds relevant supporting entities from the given documents. We\nevaluate DFGN on HotpotQA, a public TBQA dataset requiring multi-hop reasoning.\nDFGN achieves competitive results on the public board. Furthermore, our\nanalysis shows DFGN produces interpretable reasoning chains.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 17:51:44 GMT"}, {"version": "v2", "created": "Sun, 19 May 2019 03:17:53 GMT"}, {"version": "v3", "created": "Thu, 6 Jun 2019 15:54:21 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Xiao", "Yunxuan", ""], ["Qu", "Yanru", ""], ["Qiu", "Lin", ""], ["Zhou", "Hao", ""], ["Li", "Lei", ""], ["Zhang", "Weinan", ""], ["Yu", "Yong", ""]]}, {"id": "1905.06939", "submitter": "Sheshera Mysore", "authors": "Sheshera Mysore, Zach Jensen, Edward Kim, Kevin Huang, Haw-Shiuan\n  Chang, Emma Strubell, Jeffrey Flanigan, Andrew McCallum, Elsa Olivetti", "title": "The Materials Science Procedural Text Corpus: Annotating Materials\n  Synthesis Procedures with Shallow Semantic Structures", "comments": "Accepted as a long paper at the Linguistic Annotation Workshop (LAW)\n  at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Materials science literature contains millions of materials synthesis\nprocedures described in unstructured natural language text. Large-scale\nanalysis of these synthesis procedures would facilitate deeper scientific\nunderstanding of materials synthesis and enable automated synthesis planning.\nSuch analysis requires extracting structured representations of synthesis\nprocedures from the raw text as a first step. To facilitate the training and\nevaluation of synthesis extraction models, we introduce a dataset of 230\nsynthesis procedures annotated by domain experts with labeled graphs that\nexpress the semantics of the synthesis sentences. The nodes in this graph are\nsynthesis operations and their typed arguments, and labeled edges specify\nrelations between the nodes. We describe this new resource in detail and\nhighlight some specific challenges to annotating scientific text with shallow\nsemantic structure. We make the corpus available to the community to promote\nfurther research and development of scientific information extraction systems.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 17:57:35 GMT"}, {"version": "v2", "created": "Sat, 13 Jul 2019 21:52:48 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Mysore", "Sheshera", ""], ["Jensen", "Zach", ""], ["Kim", "Edward", ""], ["Huang", "Kevin", ""], ["Chang", "Haw-Shiuan", ""], ["Strubell", "Emma", ""], ["Flanigan", "Jeffrey", ""], ["McCallum", "Andrew", ""], ["Olivetti", "Elsa", ""]]}, {"id": "1905.07000", "submitter": "Christopher Hidey", "authors": "Tuhin Chakrabarty and Christopher Hidey and Kathleen McKeown", "title": "IMHO Fine-Tuning Improves Claim Detection", "comments": "NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Claims are the central component of an argument. Detecting claims across\ndifferent domains or data sets can often be challenging due to their varying\nconceptualization. We propose to alleviate this problem by fine tuning a\nlanguage model using a Reddit corpus of 5.5 million opinionated claims. These\nclaims are self-labeled by their authors using the internet acronyms IMO/IMHO\n(in my (humble) opinion). Empirical results show that using this approach\nimproves the state of art performance across four benchmark argumentation data\nsets by an average of 4 absolute F1 points in claim detection. As these data\nsets include diverse domains such as social media and student essays this\nimprovement demonstrates the robustness of fine-tuning on this novel corpus.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 19:13:44 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Chakrabarty", "Tuhin", ""], ["Hidey", "Christopher", ""], ["McKeown", "Kathleen", ""]]}, {"id": "1905.07002", "submitter": "Oren Melamud", "authors": "Oren Melamud and Chaitanya Shivade", "title": "Towards Automatic Generation of Shareable Synthetic Clinical Notes Using\n  Neural Language Models", "comments": "Clinical NLP Workshop 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale clinical data is invaluable to driving many computational\nscientific advances today. However, understandable concerns regarding patient\nprivacy hinder the open dissemination of such data and give rise to suboptimal\nsiloed research. De-identification methods attempt to address these concerns\nbut were shown to be susceptible to adversarial attacks. In this work, we focus\non the vast amounts of unstructured natural language data stored in clinical\nnotes and propose to automatically generate synthetic clinical notes that are\nmore amenable to sharing using generative models trained on real de-identified\nrecords. To evaluate the merit of such notes, we measure both their privacy\npreservation properties as well as utility in training clinical NLP models.\nExperiments using neural language models yield notes whose utility is close to\nthat of the real ones in some clinical NLP tasks, yet leave ample room for\nfuture improvements.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 19:14:18 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 19:36:35 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Melamud", "Oren", ""], ["Shivade", "Chaitanya", ""]]}, {"id": "1905.07075", "submitter": "Karan Sikka", "authors": "Karan Sikka and Lucas Van Bramer and Ajay Divakaran", "title": "Deep Unified Multimodal Embeddings for Understanding both Content and\n  Users in Social Media Networks", "comments": "Preprint submitted to IJCV", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.CV cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been an explosion of multimodal content generated on social media\nnetworks in the last few years, which has necessitated a deeper understanding\nof social media content and user behavior. We present a novel\ncontent-independent content-user-reaction model for social multimedia content\nanalysis. Compared to prior works that generally tackle semantic content\nunderstanding and user behavior modeling in isolation, we propose a generalized\nsolution to these problems within a unified framework. We embed users, images\nand text drawn from open social media in a common multimodal geometric space,\nusing a novel loss function designed to cope with distant and disparate\nmodalities, and thereby enable seamless three-way retrieval. Our model not only\noutperforms unimodal embedding based methods on cross-modal retrieval tasks but\nalso shows improvements stemming from jointly solving the two tasks on Twitter\ndata. We also show that the user embeddings learned within our joint multimodal\nembedding model are better at predicting user interests compared to those\nlearned with unimodal content on Instagram data. Our framework thus goes beyond\nthe prior practice of using explicit leader-follower link information to\nestablish affiliations by extracting implicit content-centric affiliations from\nisolated users. We provide qualitative results to show that the user clusters\nemerging from learned embeddings have consistent semantics and the ability of\nour model to discover fine-grained semantics from noisy and unstructured data.\nOur work reveals that social multimodal content is inherently multimodal and\npossesses a consistent structure because in social networks meaning is created\nthrough interactions between users and content.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 01:16:15 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 14:48:32 GMT"}, {"version": "v3", "created": "Tue, 11 Jun 2019 03:17:53 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Sikka", "Karan", ""], ["Van Bramer", "Lucas", ""], ["Divakaran", "Ajay", ""]]}, {"id": "1905.07098", "submitter": "Wenhan Xiong", "authors": "Wenhan Xiong, Mo Yu, Shiyu Chang, Xiaoxiao Guo, William Yang Wang", "title": "Improving Question Answering over Incomplete KBs with Knowledge-Aware\n  Reader", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new end-to-end question answering model, which learns to\naggregate answer evidence from an incomplete knowledge base (KB) and a set of\nretrieved text snippets. Under the assumptions that the structured KB is easier\nto query and the acquired knowledge can help the understanding of unstructured\ntext, our model first accumulates knowledge of entities from a question-related\nKB subgraph; then reformulates the question in the latent space and reads the\ntexts with the accumulated entity knowledge at hand. The evidence from KB and\ntexts are finally aggregated to predict answers. On the widely-used KBQA\nbenchmark WebQSP, our model achieves consistent improvements across settings\nwith different extents of KB incompleteness.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 03:00:46 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 04:35:36 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Xiong", "Wenhan", ""], ["Yu", "Mo", ""], ["Chang", "Shiyu", ""], ["Guo", "Xiaoxiao", ""], ["Wang", "William Yang", ""]]}, {"id": "1905.07129", "submitter": "Zhengyan Zhang", "authors": "Zhengyan Zhang, Xu Han, Zhiyuan Liu, Xin Jiang, Maosong Sun, Qun Liu", "title": "ERNIE: Enhanced Language Representation with Informative Entities", "comments": "Accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural language representation models such as BERT pre-trained on large-scale\ncorpora can well capture rich semantic patterns from plain text, and be\nfine-tuned to consistently improve the performance of various NLP tasks.\nHowever, the existing pre-trained language models rarely consider incorporating\nknowledge graphs (KGs), which can provide rich structured knowledge facts for\nbetter language understanding. We argue that informative entities in KGs can\nenhance language representation with external knowledge. In this paper, we\nutilize both large-scale textual corpora and KGs to train an enhanced language\nrepresentation model (ERNIE), which can take full advantage of lexical,\nsyntactic, and knowledge information simultaneously. The experimental results\nhave demonstrated that ERNIE achieves significant improvements on various\nknowledge-driven tasks, and meanwhile is comparable with the state-of-the-art\nmodel BERT on other common NLP tasks. The source code of this paper can be\nobtained from https://github.com/thunlp/ERNIE.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 06:24:16 GMT"}, {"version": "v2", "created": "Sun, 26 May 2019 02:42:16 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 11:35:58 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Zhang", "Zhengyan", ""], ["Han", "Xu", ""], ["Liu", "Zhiyuan", ""], ["Jiang", "Xin", ""], ["Sun", "Maosong", ""], ["Liu", "Qun", ""]]}, {"id": "1905.07149", "submitter": "Emiru Tsunoo", "authors": "Emiru Tsunoo, Yosuke Kashiwagi, Satoshi Asakawa, Toshiyuki Kumakura", "title": "End-to-end Adaptation with Backpropagation through WFST for On-device\n  Speech Recognition System", "comments": "accepted for Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An on-device DNN-HMM speech recognition system efficiently works with a\nlimited vocabulary in the presence of a variety of predictable noise. In such a\ncase, vocabulary and environment adaptation is highly effective. In this paper,\nwe propose a novel method of end-to-end (E2E) adaptation, which adjusts not\nonly an acoustic model (AM) but also a weighted finite-state transducer (WFST).\nWe convert a pretrained WFST to a trainable neural network and adapt the system\nto target environments/vocabulary by E2E joint training with an AM. We\nreplicate Viterbi decoding with forward--backward neural network computation,\nwhich is similar to recurrent neural networks (RNNs). By pooling output score\nsequences, a vocabulary posterior for each utterance is obtained and used for\ndiscriminative loss computation. Experiments using 2--10 hours of\nEnglish/Japanese adaptation datasets indicate that the fine-tuning of only\nWFSTs and that of only AMs are both comparable to a state-of-the-art adaptation\nmethod, and E2E joint training of the two components achieves the best\nrecognition performance. We also adapt each language system to the other\nlanguage using the adaptation data, and the results show that the proposed\nmethod also works well for language adaptations.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 07:49:33 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 01:47:03 GMT"}, {"version": "v3", "created": "Mon, 24 Jun 2019 09:50:16 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Tsunoo", "Emiru", ""], ["Kashiwagi", "Yosuke", ""], ["Asakawa", "Satoshi", ""], ["Kumakura", "Toshiyuki", ""]]}, {"id": "1905.07185", "submitter": "Mark Keane", "authors": "Kelleher Conor and Mark T. Keane", "title": "Plotting Markson's 'Mistress'", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The post-modern novel 'Wittgenstein's Mistress' by David Markson (1988)\npresents the reader with a very challenging non linear narrative, that itself\nappears to one of the novel's themes. We present a distant reading of this work\ndesigned to complement a close reading of it by David Foster Wallace (1990).\nUsing a combination of text analysis, entity recognition and networks, we plot\nrepetitive structures in the novel's narrative relating them to its critical\nanalysis.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 10:14:21 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Conor", "Kelleher", ""], ["Keane", "Mark T.", ""]]}, {"id": "1905.07189", "submitter": "Phong Le", "authors": "Phong Le and Ivan Titov", "title": "Distant Learning for Entity Linking with Automatic Noise Detection", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate entity linkers have been produced for domains and languages where\nannotated data (i.e., texts linked to a knowledge base) is available. However,\nlittle progress has been made for the settings where no or very limited amounts\nof labeled data are present (e.g., legal or most scientific domains). In this\nwork, we show how we can learn to link mentions without having any labeled\nexamples, only a knowledge base and a collection of unannotated texts from the\ncorresponding domain. In order to achieve this, we frame the task as a\nmulti-instance learning problem and rely on surface matching to create initial\nnoisy labels. As the learning signal is weak and our surrogate labels are\nnoisy, we introduce a noise detection component in our model: it lets the model\ndetect and disregard examples which are likely to be noisy. Our method, jointly\nlearning to detect noise and link entities, greatly outperforms the surface\nmatching baseline. For a subset of entity categories, it even approaches the\nperformance of supervised learning.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 10:49:47 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 07:43:50 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Le", "Phong", ""], ["Titov", "Ivan", ""]]}, {"id": "1905.07195", "submitter": "Chun-an Chan", "authors": "Vincent Wan, Chun-an Chan, Tom Kenter, Jakub Vit, Rob Clark", "title": "CHiVE: Varying Prosody in Speech Synthesis with a Linguistically Driven\n  Dynamic Hierarchical Conditional Variational Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prosodic aspects of speech signals produced by current text-to-speech\nsystems are typically averaged over training material, and as such lack the\nvariety and liveliness found in natural speech. To avoid monotony and averaged\nprosody contours, it is desirable to have a way of modeling the variation in\nthe prosodic aspects of speech, so audio signals can be synthesized in multiple\nways for a given text. We present a new, hierarchically structured conditional\nvariational autoencoder to generate prosodic features (fundamental frequency,\nenergy and duration) suitable for use with a vocoder or a generative model like\nWaveNet. At inference time, an embedding representing the prosody of a sentence\nmay be sampled from the variational layer to allow for prosodic variation. To\nefficiently capture the hierarchical nature of the linguistic input (words,\nsyllables and phones), both the encoder and decoder parts of the auto-encoder\nare hierarchical, in line with the linguistic structure, with layers being\nclocked dynamically at the respective rates. We show in our experiments that\nour dynamic hierarchical network outperforms a non-hierarchical\nstate-of-the-art baseline, and, additionally, that prosody transfer across\nsentences is possible by employing the prosody embedding of one sentence to\ngenerate the speech signal of another.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 11:03:58 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 11:16:49 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Wan", "Vincent", ""], ["Chan", "Chun-an", ""], ["Kenter", "Tom", ""], ["Vit", "Jakub", ""], ["Clark", "Rob", ""]]}, {"id": "1905.07213", "submitter": "Yuri Kuratov", "authors": "Yuri Kuratov and Mikhail Arkhipov", "title": "Adaptation of Deep Bidirectional Multilingual Transformers for Russian\n  Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper introduces methods of adaptation of multilingual masked language\nmodels for a specific language. Pre-trained bidirectional language models show\nstate-of-the-art performance on a wide range of tasks including reading\ncomprehension, natural language inference, and sentiment analysis. At the\nmoment there are two alternative approaches to train such models: monolingual\nand multilingual. While language specific models show superior performance,\nmultilingual models allow to perform a transfer from one language to another\nand solve tasks for different languages simultaneously. This work shows that\ntransfer learning from a multilingual model to monolingual model results in\nsignificant growth of performance on such tasks as reading comprehension,\nparaphrase detection, and sentiment analysis. Furthermore, multilingual\ninitialization of monolingual model substantially reduces training time.\nPre-trained models for the Russian language are open sourced.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 11:39:21 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Kuratov", "Yuri", ""], ["Arkhipov", "Mikhail", ""]]}, {"id": "1905.07289", "submitter": "Shunsuke Kitada", "authors": "Shunsuke Kitada, Hitoshi Iyatomi, Yoshifumi Seki", "title": "Conversion Prediction Using Multi-task Conditional Attention Networks to\n  Support the Creation of Effective Ad Creative", "comments": "9 pages, 6 figures. Accepted at The 25th ACM SIGKDD Conference on\n  Knowledge Discovery and Data Mining (KDD 2019) as an applied data science\n  paper", "journal-ref": "Proceedings of the 25th ACM SIGKDD International Conference on\n  Knowledge Discovery & Data Mining (KDD '19), August 4--8, 2019, Anchorage,\n  AK, USA", "doi": "10.1145/3292500.3330789", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately predicting conversions in advertisements is generally a\nchallenging task, because such conversions do not occur frequently. In this\npaper, we propose a new framework to support creating high-performing ad\ncreatives, including the accurate prediction of ad creative text conversions\nbefore delivering to the consumer. The proposed framework includes three key\nideas: multi-task learning, conditional attention, and attention highlighting.\nMulti-task learning is an idea for improving the prediction accuracy of\nconversion, which predicts clicks and conversions simultaneously, to solve the\ndifficulty of data imbalance. Furthermore, conditional attention focuses\nattention of each ad creative with the consideration of its genre and target\ngender, thus improving conversion prediction accuracy. Attention highlighting\nvisualizes important words and/or phrases based on conditional attention. We\nevaluated the proposed framework with actual delivery history data (14,000\ncreatives displayed more than a certain number of times from Gunosy Inc.), and\nconfirmed that these ideas improve the prediction performance of conversions,\nand visualize noteworthy words according to the creatives' attributes.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 14:25:27 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Kitada", "Shunsuke", ""], ["Iyatomi", "Hitoshi", ""], ["Seki", "Yoshifumi", ""]]}, {"id": "1905.07321", "submitter": "Meilin Zhan", "authors": "Meilin Zhan, Roger Levy", "title": "Availability-Based Production Predicts Speakers' Real-time Choices of\n  Mandarin Classifiers", "comments": "To appear in proceedings of CogSci 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speakers often face choices as to how to structure their intended message\ninto an utterance. Here we investigate the influence of contextual\npredictability on the encoding of linguistic content manifested by speaker\nchoice in a classifier language. In English, a numeral modifies a noun directly\n(e.g., three computers). In classifier languages such as Mandarin Chinese, it\nis obligatory to use a classifier (CL) with the numeral and the noun (e.g.,\nthree CL.machinery computer, three CL.general computer). While different nouns\nare compatible with different specific classifiers, there is a general\nclassifier \"ge\" (CL.general) that can be used with most nouns. When the\nupcoming noun is less predictable, the use of a more specific classifier would\nreduce surprisal at the noun thus potentially facilitate comprehension\n(predicted by Uniform Information Density, Levy & Jaeger, 2007), but the use of\nthat more specific classifier may be dispreferred from a production standpoint\nif accessing the general classifier is always available (predicted by\nAvailability-Based Production; Bock, 1987; Ferreira & Dell, 2000). Here we use\na picture-naming experiment showing that Availability-Based Production predicts\nspeakers' real-time choices of Mandarin classifiers.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 15:19:17 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Zhan", "Meilin", ""], ["Levy", "Roger", ""]]}, {"id": "1905.07356", "submitter": "Matthijs Westera", "authors": "Matthijs Westera and Gemma Boleda", "title": "Don't Blame Distributional Semantics if it can't do Entailment", "comments": "To appear in Proceedings of the 13th International Conference on\n  Computational Semantics (IWCS 2019), Gothenburg, Sweden", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributional semantics has had enormous empirical success in Computational\nLinguistics and Cognitive Science in modeling various semantic phenomena, such\nas semantic similarity, and distributional models are widely used in\nstate-of-the-art Natural Language Processing systems. However, the theoretical\nstatus of distributional semantics within a broader theory of language and\ncognition is still unclear: What does distributional semantics model? Can it\nbe, on its own, a fully adequate model of the meanings of linguistic\nexpressions? The standard answer is that distributional semantics is not fully\nadequate in this regard, because it falls short on some of the central aspects\nof formal semantic approaches: truth conditions, entailment, reference, and\ncertain aspects of compositionality. We argue that this standard answer rests\non a misconception: These aspects do not belong in a theory of expression\nmeaning, they are instead aspects of speaker meaning, i.e., communicative\nintentions in a particular context. In a slogan: words do not refer, speakers\ndo. Clearing this up enables us to argue that distributional semantics on its\nown is an adequate model of expression meaning. Our proposal sheds light on the\nrole of distributional semantics in a broader theory of language and cognition,\nits relationship to formal semantics, and its place in computational models.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 16:26:05 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Westera", "Matthijs", ""], ["Boleda", "Gemma", ""]]}, {"id": "1905.07358", "submitter": "Jose Camacho-Collados", "authors": "Jose Camacho-Collados, Yerai Doval, Eugenio Mart\\'inez-C\\'amara, Luis\n  Espinosa-Anke, Francesco Barbieri, and Steven Schockaert", "title": "Learning Cross-lingual Embeddings from Twitter via Distant Supervision", "comments": "Accepted to ICWSM 2020. 11 pages, 1 appendix. Pre-trained embeddings\n  available at https://github.com/pedrada88/crossembeddings-twitter", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual embeddings represent the meaning of words from different\nlanguages in the same vector space. Recent work has shown that it is possible\nto construct such representations by aligning independently learned monolingual\nembedding spaces, and that accurate alignments can be obtained even without\nexternal bilingual data. In this paper we explore a research direction that has\nbeen surprisingly neglected in the literature: leveraging noisy user-generated\ntext to learn cross-lingual embeddings particularly tailored towards social\nmedia applications. While the noisiness and informal nature of the social media\ngenre poses additional challenges to cross-lingual embedding methods, we find\nthat it also provides key opportunities due to the abundance of code-switching\nand the existence of a shared vocabulary of emoji and named entities. Our\ncontribution consists of a very simple post-processing step that exploits these\nphenomena to significantly improve the performance of state-of-the-art\nalignment methods.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 16:27:43 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 14:06:45 GMT"}, {"version": "v3", "created": "Tue, 31 Mar 2020 22:51:21 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Camacho-Collados", "Jose", ""], ["Doval", "Yerai", ""], ["Mart\u00ednez-C\u00e1mara", "Eugenio", ""], ["Espinosa-Anke", "Luis", ""], ["Barbieri", "Francesco", ""], ["Schockaert", "Steven", ""]]}, {"id": "1905.07374", "submitter": "Ming Tu", "authors": "Ming Tu, Guangtao Wang, Jing Huang, Yun Tang, Xiaodong He, Bowen Zhou", "title": "Multi-hop Reading Comprehension across Multiple Documents by Reasoning\n  over Heterogeneous Graphs", "comments": "To appear in ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-hop reading comprehension (RC) across documents poses new challenge\nover single-document RC because it requires reasoning over multiple documents\nto reach the final answer. In this paper, we propose a new model to tackle the\nmulti-hop RC problem. We introduce a heterogeneous graph with different types\nof nodes and edges, which is named as Heterogeneous Document-Entity (HDE)\ngraph. The advantage of HDE graph is that it contains different granularity\nlevels of information including candidates, documents and entities in specific\ndocument contexts. Our proposed model can do reasoning over the HDE graph with\nnodes representation initialized with co-attention and self-attention based\ncontext encoders. We employ Graph Neural Networks (GNN) based message passing\nalgorithms to accumulate evidences on the proposed HDE graph. Evaluated on the\nblind test set of the Qangaroo WikiHop data set, our HDE graph based single\nmodel delivers competitive result, and the ensemble model achieves the\nstate-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 17:03:11 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 23:22:05 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Tu", "Ming", ""], ["Wang", "Guangtao", ""], ["Huang", "Jing", ""], ["Tang", "Yun", ""], ["He", "Xiaodong", ""], ["Zhou", "Bowen", ""]]}, {"id": "1905.07408", "submitter": "EPTCS", "authors": "Giovanni de Felice (University of Oxford), Konstantinos Meichanetzidis\n  (University of Oxford, Cambridge Quantum Computing Ltd.), Alexis Toumi\n  (University of Oxford)", "title": "Functorial Question Answering", "comments": "In Proceedings ACT 2019, arXiv:2009.06334", "journal-ref": "EPTCS 323, 2020, pp. 84-94", "doi": "10.4204/EPTCS.323.6", "report-no": null, "categories": "cs.CL cs.DB cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributional compositional (DisCo) models are functors that compute the\nmeaning of a sentence from the meaning of its words. We show that DisCo models\nin the category of sets and relations correspond precisely to relational\ndatabases. As a consequence, we get complexity-theoretic reductions from\nsemantics and entailment of a fragment of natural language to evaluation and\ncontainment of conjunctive queries, respectively. Finally, we define question\nanswering as an NP-complete problem.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 15:23:39 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2019 14:35:12 GMT"}, {"version": "v3", "created": "Tue, 15 Sep 2020 02:14:18 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["de Felice", "Giovanni", "", "University of Oxford"], ["Meichanetzidis", "Konstantinos", "", "University of Oxford, Cambridge Quantum Computing Ltd."], ["Toumi", "Alexis", "", "University of Oxford"]]}, {"id": "1905.07458", "submitter": "Tung Tran", "authors": "Tung Tran and Ramakanth Kavuluru", "title": "Neural Metric Learning for Fast End-to-End Relation Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relation extraction (RE) is an indispensable information extraction task in\nseveral disciplines. RE models typically assume that named entity recognition\n(NER) is already performed in a previous step by another independent model.\nSeveral recent efforts, under the theme of end-to-end RE, seek to exploit\ninter-task correlations by modeling both NER and RE tasks jointly. Earlier work\nin this area commonly reduces the task to a table-filling problem wherein an\nadditional expensive decoding step involving beam search is applied to obtain\nglobally consistent cell labels. In efforts that do not employ table-filling,\nglobal optimization in the form of CRFs with Viterbi decoding for the NER\ncomponent is still necessary for competitive performance. We introduce a novel\nneural architecture utilizing the table structure, based on repeated\napplications of 2D convolutions for pooling local dependency and metric-based\nfeatures, that improves on the state-of-the-art without the need for global\noptimization. We validate our model on the ADE and CoNLL04 datasets for\nend-to-end RE and demonstrate $\\approx 1\\%$ gain (in F-score) over prior best\nresults with training and testing times that are seven to ten times faster ---\nthe latter highly advantageous for time-sensitive end user applications.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 20:20:22 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 19:29:54 GMT"}, {"version": "v3", "created": "Mon, 3 Jun 2019 22:37:19 GMT"}, {"version": "v4", "created": "Tue, 27 Aug 2019 20:15:56 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Tran", "Tung", ""], ["Kavuluru", "Ramakanth", ""]]}, {"id": "1905.07464", "submitter": "Tung Tran", "authors": "Tung Tran, Ramakanth Kavuluru, and Halil Kilicoglu", "title": "A Multi-Task Learning Framework for Extracting Drugs and Their\n  Interactions from Drug Labels", "comments": "To appear in TAC 2018 Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preventable adverse drug reactions as a result of medical errors present a\ngrowing concern in modern medicine. As drug-drug interactions (DDIs) may cause\nadverse reactions, being able to extracting DDIs from drug labels into\nmachine-readable form is an important effort in effectively deploying drug\nsafety information. The DDI track of TAC 2018 introduces two large\nhand-annotated test sets for the task of extracting DDIs from structured\nproduct labels with linkage to standard terminologies. Herein, we describe our\napproach to tackling tasks one and two of the DDI track, which corresponds to\nnamed entity recognition (NER) and sentence-level relation extraction\nrespectively. Namely, our approach resembles a multi-task learning framework\ndesigned to jointly model various sub-tasks including NER and interaction type\nand outcome prediction. On NER, our system ranked second (among eight teams) at\n33.00% and 38.25% F1 on Test Sets 1 and 2 respectively. On relation extraction,\nour system ranked second (among four teams) at 21.59% and 23.55% on Test Sets 1\nand 2 respectively.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 20:29:40 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Tran", "Tung", ""], ["Kavuluru", "Ramakanth", ""], ["Kilicoglu", "Halil", ""]]}, {"id": "1905.07471", "submitter": "Jacob Beckerman", "authors": "Jacob Beckerman and Theodore Christakis", "title": "Learning Open Information Extraction of Implicit Relations from Reading\n  Comprehension Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The relationship between two entities in a sentence is often implied by word\norder and common sense, rather than an explicit predicate. For example, it is\nevident that \"Fed chair Powell indicates rate hike\" implies (Powell, is a, Fed\nchair) and (Powell, works for, Fed). These tuples are just as significant as\nthe explicit-predicate tuple (Powell, indicates, rate hike), but have much\nlower recall under traditional Open Information Extraction (OpenIE) systems.\nImplicit tuples are our term for this type of extraction where the relation is\nnot present in the input sentence. There is very little OpenIE training data\navailable relative to other NLP tasks and none focused on implicit relations.\nWe develop an open source, parse-based tool for converting large reading\ncomprehension datasets to OpenIE datasets and release a dataset 35x larger than\npreviously available by sentence count. A baseline neural model trained on this\ndata outperforms previous methods on the implicit extraction task.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 19:02:35 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Beckerman", "Jacob", ""], ["Christakis", "Theodore", ""]]}, {"id": "1905.07504", "submitter": "Zhongyang Li", "authors": "Zhongyang Li, Xiao Ding and Ting Liu", "title": "Story Ending Prediction by Transferable BERT", "comments": "Accepted and to appear in IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances, such as GPT and BERT, have shown success in incorporating a\npre-trained transformer language model and fine-tuning operation to improve\ndownstream NLP systems. However, this framework still has some fundamental\nproblems in effectively incorporating supervised knowledge from other related\ntasks. In this study, we investigate a transferable BERT (TransBERT) training\nframework, which can transfer not only general language knowledge from\nlarge-scale unlabeled data but also specific kinds of knowledge from various\nsemantically related supervised tasks, for a target task. Particularly, we\npropose utilizing three kinds of transfer tasks, including natural language\ninference, sentiment classification, and next action prediction, to further\ntrain BERT based on a pre-trained model. This enables the model to get a better\ninitialization for the target task. We take story ending prediction as the\ntarget task to conduct experiments. The final result, an accuracy of 91.8%,\ndramatically outperforms previous state-of-the-art baseline methods. Several\ncomparative experiments give some helpful suggestions on how to select transfer\ntasks. Error analysis shows what are the strength and weakness of BERT-based\nmodels for story ending prediction.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 23:52:08 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 02:37:11 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Li", "Zhongyang", ""], ["Ding", "Xiao", ""], ["Liu", "Ting", ""]]}, {"id": "1905.07508", "submitter": "Piper Armstrong", "authors": "Jeffrey Lund, Piper Armstrong, Wilson Fearn, Stephen Cowley, Emily\n  Hales, and Kevin Seppi", "title": "Cross-referencing using Fine-grained Topic Modeling", "comments": "6 figures 1 table 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-referencing, which links passages of text to other related passages,\ncan be a valuable study aid for facilitating comprehension of a text. However,\ncross-referencing requires first, a comprehensive thematic knowledge of the\nentire corpus, and second, a focused search through the corpus specifically to\nfind such useful connections. Due to this, cross-reference resources are\nprohibitively expensive and exist only for the most well-studied texts (e.g.\nreligious texts). We develop a topic-based system for automatically producing\ncandidate cross-references which can be easily verified by human annotators.\nOur system utilizes fine-grained topic modeling with thousands of highly\nnuanced and specific topics to identify verse pairs which are topically\nrelated. We demonstrate that our system can be cost effective compared to\nhaving annotators acquire the expertise necessary to produce cross-reference\nresources unaided.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 00:28:37 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Lund", "Jeffrey", ""], ["Armstrong", "Piper", ""], ["Fearn", "Wilson", ""], ["Cowley", "Stephen", ""], ["Hales", "Emily", ""], ["Seppi", "Kevin", ""]]}, {"id": "1905.07562", "submitter": "Feng Qi", "authors": "Feng Qi and Wenchuan Wu", "title": "Human-like machine thinking: Language guided imagination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human thinking requires the brain to understand the meaning of language\nexpression and to properly organize the thoughts flow using the language.\nHowever, current natural language processing models are primarily limited in\nthe word probability estimation. Here, we proposed a Language guided\nimagination (LGI) network to incrementally learn the meaning and usage of\nnumerous words and syntaxes, aiming to form a human-like machine thinking\nprocess. LGI contains three subsystems: (1) vision system that contains an\nencoder to disentangle the input or imagined scenarios into abstract population\nrepresentations, and an imagination decoder to reconstruct imagined scenario\nfrom higher level representations; (2) Language system, that contains a\nbinarizer to transfer symbol texts into binary vectors, an IPS (mimicking the\nhuman IntraParietal Sulcus, implemented by an LSTM) to extract the quantity\ninformation from the input texts, and a textizer to convert binary vectors into\ntext symbols; (3) a PFC (mimicking the human PreFrontal Cortex, implemented by\nan LSTM) to combine inputs of both language and vision representations, and\npredict text symbols and manipulated images accordingly. LGI has incrementally\nlearned eight different syntaxes (or tasks), with which a machine thinking loop\nhas been formed and validated by the proper interaction between language and\nvision system. The paper provides a new architecture to let the machine learn,\nunderstand and use language in a human-like way that could ultimately enable a\nmachine to construct fictitious 'mental' scenario and possess intelligence.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 09:23:00 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 07:46:23 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Qi", "Feng", ""], ["Wu", "Wenchuan", ""]]}, {"id": "1905.07584", "submitter": "Yue Wang", "authors": "Yue Wang, Jing Li, Irwin King, Michael R. Lyu, Shuming Shi", "title": "Microblog Hashtag Generation via Encoding Conversation Contexts", "comments": "NAACL 2019 (10 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic hashtag annotation plays an important role in content understanding\nfor microblog posts. To date, progress made in this field has been restricted\nto phrase selection from limited candidates, or word-level hashtag discovery\nusing topic models. Different from previous work considering hashtags to be\ninseparable, our work is the first effort to annotate hashtags with a novel\nsequence generation framework via viewing the hashtag as a short sequence of\nwords. Moreover, to address the data sparsity issue in processing short\nmicroblog posts, we propose to jointly model the target posts and the\nconversation contexts initiated by them with bidirectional attention. Extensive\nexperimental results on two large-scale datasets, newly collected from English\nTwitter and Chinese Weibo, show that our model significantly outperforms\nstate-of-the-art models based on classification. Further studies demonstrate\nour ability to effectively generate rare and even unseen hashtags, which is\nhowever not possible for most existing methods.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 13:11:31 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Wang", "Yue", ""], ["Li", "Jing", ""], ["King", "Irwin", ""], ["Lyu", "Michael R.", ""], ["Shi", "Shuming", ""]]}, {"id": "1905.07588", "submitter": "Dongfang Li", "authors": "Dongfang Li and Yifei Yu and Qingcai Chen and Xinyu Li", "title": "BERTSel: Answer Selection with Pre-trained Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, pre-trained models have been the dominant paradigm in natural\nlanguage processing. They achieved remarkable state-of-the-art performance\nacross a wide range of related tasks, such as textual entailment, natural\nlanguage inference, question answering, etc. BERT, proposed by Devlin et.al.,\nhas achieved a better marked result in GLUE leaderboard with a deep transformer\narchitecture. Despite its soaring popularity, however, BERT has not yet been\napplied to answer selection. This task is different from others with a few\nnuances: first, modeling the relevance and correctness of candidates matters\ncompared to semantic relatedness and syntactic structure; second, the length of\nan answer may be different from other candidates and questions. In this paper.\nwe are the first to explore the performance of fine-tuning BERT for answer\nselection. We achieved STOA results across five popular datasets, demonstrating\nthe success of pre-trained models in this task.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 13:35:33 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Li", "Dongfang", ""], ["Yu", "Yifei", ""], ["Chen", "Qingcai", ""], ["Li", "Xinyu", ""]]}, {"id": "1905.07595", "submitter": "Diego Amancio Dr.", "authors": "Edilson A. Corr\\^ea Jr., Vanessa Q. Marinho and Diego R. Amancio", "title": "Semantic flow in language networks", "comments": null, "journal-ref": "Physica A, v. 557, p. 124895, 2020", "doi": "10.1016/j.physa.2020.124895", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study we propose a framework to characterize documents based on their\nsemantic flow. The proposed framework encompasses a network-based model that\nconnected sentences based on their semantic similarity. Semantic fields are\ndetected using standard community detection methods. as the story unfolds,\ntransitions between semantic fields are represent in Markov networks, which in\nturned are characterized via network motifs (subgraphs). Here we show that the\nproposed framework can be used to classify books according to their style and\npublication dates. Remarkably, even without a systematic optimization of\nparameters, philosophy and investigative books were discriminated with an\naccuracy rate of 92.5%. Because this model captures semantic features of texts,\nit could be used as an additional feature in traditional network-based models\nof texts that capture only syntactical/stylistic information, as it is the case\nof word adjacency (co-occurrence) networks.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 14:32:53 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Corr\u00eaa", "Edilson A.", "Jr."], ["Marinho", "Vanessa Q.", ""], ["Amancio", "Diego R.", ""]]}, {"id": "1905.07687", "submitter": "Chien-Sheng Wu", "authors": "Chien-Sheng Wu", "title": "Learning to Memorize in Neural Task-Oriented Dialogue Systems", "comments": "HKUST MPhil Thesis. 93 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this thesis, we leverage the neural copy mechanism and memory-augmented\nneural networks (MANNs) to address existing challenge of neural task-oriented\ndialogue learning. We show the effectiveness of our strategy by achieving good\nperformance in multi-domain dialogue state tracking, retrieval-based dialogue\nsystems, and generation-based dialogue systems. We first propose a transferable\ndialogue state generator (TRADE) that leverages its copy mechanism to get rid\nof dialogue ontology and share knowledge between domains. We also evaluate\nunseen domain dialogue state tracking and show that TRADE enables zero-shot\ndialogue state tracking and can adapt to new few-shot domains without\nforgetting the previous domains. Second, we utilize MANNs to improve\nretrieval-based dialogue learning. They are able to capture dialogue sequential\ndependencies and memorize long-term information. We also propose a recorded\ndelexicalization copy strategy to replace real entity values with ordered\nentity types. Our models are shown to surpass other retrieval baselines,\nespecially when the conversation has a large number of turns. Lastly, we tackle\ngeneration-based dialogue learning with two proposed models, the\nmemory-to-sequence (Mem2Seq) and global-to-local memory pointer network (GLMP).\nMem2Seq is the first model to combine multi-hop memory attention with the idea\nof the copy mechanism. GLMP further introduces the concept of response\nsketching and double pointers copying. We show that GLMP achieves the\nstate-of-the-art performance on human evaluation.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 04:00:08 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Wu", "Chien-Sheng", ""]]}, {"id": "1905.07689", "submitter": "Zhiqing Sun", "authors": "Zhiqing Sun, Jian Tang, Pan Du, Zhi-Hong Deng, Jian-Yun Nie", "title": "DivGraphPointer: A Graph Pointer Network for Extracting Diverse\n  Keyphrases", "comments": "Accepted to SIGIR 2019", "journal-ref": null, "doi": "10.1145/3331184.3331219", "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keyphrase extraction from documents is useful to a variety of applications\nsuch as information retrieval and document summarization. This paper presents\nan end-to-end method called DivGraphPointer for extracting a set of diversified\nkeyphrases from a document. DivGraphPointer combines the advantages of\ntraditional graph-based ranking methods and recent neural network-based\napproaches. Specifically, given a document, a word graph is constructed from\nthe document based on word proximity and is encoded with graph convolutional\nnetworks, which effectively capture document-level word salience by modeling\nlong-range dependency between words in the document and aggregating multiple\nappearances of identical words into one node. Furthermore, we propose a\ndiversified point network to generate a set of diverse keyphrases out of the\nword graph in the decoding process. Experimental results on five benchmark data\nsets show that our proposed method significantly outperforms the existing\nstate-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 05:17:12 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Sun", "Zhiqing", ""], ["Tang", "Jian", ""], ["Du", "Pan", ""], ["Deng", "Zhi-Hong", ""], ["Nie", "Jian-Yun", ""]]}, {"id": "1905.07695", "submitter": "Alexios Gidiotis", "authors": "Alexios Gidiotis and Grigorios Tsoumakas", "title": "Structured Summarization of Academic Publications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose SUSIE, a novel summarization method that can work with\nstate-of-the-art summarization models in order to produce structured scientific\nsummaries for academic articles. We also created PMC-SA, a new dataset of\nacademic publications, suitable for the task of structured summarization with\nneural networks. We apply SUSIE combined with three different summarization\nmodels on the new PMC-SA dataset and we show that the proposed method improves\nthe performance of all models by as much as 4 ROUGE points.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 07:12:22 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 18:51:53 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Gidiotis", "Alexios", ""], ["Tsoumakas", "Grigorios", ""]]}, {"id": "1905.07719", "submitter": "Bowen Xing", "authors": "Bowen Xing, Lejian Liao, Dandan Song, Jingang Wang, Fuzheng Zhang,\n  Zhongyuan Wang, Heyan Huang", "title": "Earlier Attention? Aspect-Aware LSTM for Aspect-Based Sentiment Analysis", "comments": "accepted by IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect-based sentiment analysis (ABSA) aims to predict fine-grained\nsentiments of comments with respect to given aspect terms or categories. In\nprevious ABSA methods, the importance of aspect has been realized and verified.\nMost existing LSTM-based models take aspect into account via the attention\nmechanism, where the attention weights are calculated after the context is\nmodeled in the form of contextual vectors. However, aspect-related information\nmay be already discarded and aspect-irrelevant information may be retained in\nclassic LSTM cells in the context modeling process, which can be improved to\ngenerate more effective context representations. This paper proposes a novel\nvariant of LSTM, termed as aspect-aware LSTM (AA-LSTM), which incorporates\naspect information into LSTM cells in the context modeling stage before the\nattention mechanism. Therefore, our AA-LSTM can dynamically produce\naspect-aware contextual representations. We experiment with several\nrepresentative LSTM-based models by replacing the classic LSTM cells with the\nAA-LSTM cells. Experimental results on SemEval-2014 Datasets demonstrate the\neffectiveness of AA-LSTM.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 10:20:09 GMT"}, {"version": "v2", "created": "Sun, 7 Jul 2019 09:02:41 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Xing", "Bowen", ""], ["Liao", "Lejian", ""], ["Song", "Dandan", ""], ["Wang", "Jingang", ""], ["Zhang", "Fuzheng", ""], ["Wang", "Zhongyuan", ""], ["Huang", "Heyan", ""]]}, {"id": "1905.07790", "submitter": "Vitalii Zhelezniak", "authors": "Vitalii Zhelezniak, Aleksandar Savkov, April Shen, Nils Y. Hammerla", "title": "Correlation Coefficients and Semantic Textual Similarity", "comments": "Accepted as a long paper at NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large body of research into semantic textual similarity has focused on\nconstructing state-of-the-art embeddings using sophisticated modelling, careful\nchoice of learning signals and many clever tricks. By contrast, little\nattention has been devoted to similarity measures between these embeddings,\nwith cosine similarity being used unquestionably in the majority of cases. In\nthis work, we illustrate that for all common word vectors, cosine similarity is\nessentially equivalent to the Pearson correlation coefficient, which provides\nsome justification for its use. We thoroughly characterise cases where Pearson\ncorrelation (and thus cosine similarity) is unfit as similarity measure.\nImportantly, we show that Pearson correlation is appropriate for some word\nvectors but not others. When it is not appropriate, we illustrate how common\nnon-parametric rank correlation coefficients can be used instead to\nsignificantly improve performance. We support our analysis with a series of\nevaluations on word-level and sentence-level semantic textual similarity\nbenchmarks. On the latter, we show that even the simplest averaged word vectors\ncompared by rank correlation easily rival the strongest deep representations\ncompared by cosine similarity.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 18:23:14 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Zhelezniak", "Vitalii", ""], ["Savkov", "Aleksandar", ""], ["Shen", "April", ""], ["Hammerla", "Nils Y.", ""]]}, {"id": "1905.07791", "submitter": "Yinfei Yang", "authors": "Yinfei Yang, Oshin Agarwal, Chris Tar, Byron C. Wallace, Ani Nenkova", "title": "Predicting Annotation Difficulty to Improve Task Routing and Model\n  Performance for Biomedical Information Extraction", "comments": "NAACL2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern NLP systems require high-quality annotated data. In specialized\ndomains, expert annotations may be prohibitively expensive. An alternative is\nto rely on crowdsourcing to reduce costs at the risk of introducing noise. In\nthis paper we demonstrate that directly modeling instance difficulty can be\nused to improve model performance, and to route instances to appropriate\nannotators. Our difficulty prediction model combines two learned\nrepresentations: a `universal' encoder trained on out-of-domain data, and a\ntask-specific encoder. Experiments on a complex biomedical information\nextraction task using expert and lay annotators show that: (i) simply excluding\nfrom the training data instances predicted to be difficult yields a small boost\nin performance; (ii) using difficulty scores to weight instances during\ntraining provides further, consistent gains; (iii) assigning instances\npredicted to be difficult to domain experts is an effective strategy for task\nrouting. Our experiments confirm the expectation that for specialized tasks\nexpert annotations are higher quality than crowd labels, and hence preferable\nto obtain if practical. Moreover, augmenting small amounts of expert data with\na larger set of lay annotations leads to further improvements in model\nperformance.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 18:28:34 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Yang", "Yinfei", ""], ["Agarwal", "Oshin", ""], ["Tar", "Chris", ""], ["Wallace", "Byron C.", ""], ["Nenkova", "Ani", ""]]}, {"id": "1905.07830", "submitter": "Rowan Zellers", "authors": "Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, Yejin Choi", "title": "HellaSwag: Can a Machine Really Finish Your Sentence?", "comments": "ACL 2019. Project page at https://rowanzellers.com/hellaswag", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work by Zellers et al. (2018) introduced a new task of commonsense\nnatural language inference: given an event description such as \"A woman sits at\na piano,\" a machine must select the most likely followup: \"She sets her fingers\non the keys.\" With the introduction of BERT, near human-level performance was\nreached. Does this mean that machines can perform human level commonsense\ninference?\n  In this paper, we show that commonsense inference still proves difficult for\neven state-of-the-art models, by presenting HellaSwag, a new challenge dataset.\nThough its questions are trivial for humans (>95% accuracy), state-of-the-art\nmodels struggle (<48%). We achieve this via Adversarial Filtering (AF), a data\ncollection paradigm wherein a series of discriminators iteratively select an\nadversarial set of machine-generated wrong answers. AF proves to be\nsurprisingly robust. The key insight is to scale up the length and complexity\nof the dataset examples towards a critical 'Goldilocks' zone wherein generated\ntext is ridiculous to humans, yet often misclassified by state-of-the-art\nmodels.\n  Our construction of HellaSwag, and its resulting difficulty, sheds light on\nthe inner workings of deep pretrained models. More broadly, it suggests a new\npath forward for NLP research, in which benchmarks co-evolve with the evolving\nstate-of-the-art in an adversarial way, so as to present ever-harder\nchallenges.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 23:57:23 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Zellers", "Rowan", ""], ["Holtzman", "Ari", ""], ["Bisk", "Yonatan", ""], ["Farhadi", "Ali", ""], ["Choi", "Yejin", ""]]}, {"id": "1905.07856", "submitter": "Shivashankar Subramanian", "authors": "Shivashankar Subramanian and Trevor Cohn and Timothy Baldwin", "title": "Target Based Speech Act Classification in Political Campaign Text", "comments": "Eighth Joint Conference on Lexical and Computational Semantics, *SEM\n  2019, Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study pragmatics in political campaign text, through analysis of speech\nacts and the target of each utterance. We propose a new annotation schema\nincorporating domain-specific speech acts, such as commissive-action, and\npresent a novel annotated corpus of media releases and speech transcripts from\nthe 2016 Australian election cycle. We show how speech acts and target\nreferents can be modeled as sequential classification, and evaluate several\ntechniques, exploiting contextualized word representations, semi-supervised\nlearning, task dependencies and speaker meta-data.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 03:14:11 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Subramanian", "Shivashankar", ""], ["Cohn", "Trevor", ""], ["Baldwin", "Timothy", ""]]}, {"id": "1905.07870", "submitter": "Qingyun Wang", "authors": "Qingyun Wang, Lifu Huang, Zhiying Jiang, Kevin Knight, Heng Ji, Mohit\n  Bansal and Yi Luan", "title": "PaperRobot: Incremental Draft Generation of Scientific Ideas", "comments": "12 pages. Accepted by ACL 2019 Code and resource is available at\n  https://github.com/EagleW/PaperRobot", "journal-ref": null, "doi": "10.18653/v1/P19-1191", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a PaperRobot who performs as an automatic research assistant by\n(1) conducting deep understanding of a large collection of human-written papers\nin a target domain and constructing comprehensive background knowledge graphs\n(KGs); (2) creating new ideas by predicting links from the background KGs, by\ncombining graph attention and contextual text attention; (3) incrementally\nwriting some key elements of a new paper based on memory-attention networks:\nfrom the input title along with predicted related entities to generate a paper\nabstract, from the abstract to generate conclusion and future work, and finally\nfrom future work to generate a title for a follow-on paper. Turing Tests, where\na biomedical domain expert is asked to compare a system output and a\nhuman-authored string, show PaperRobot generated abstracts, conclusion and\nfuture work sections, and new titles are chosen over human-written ones up to\n30%, 24% and 12% of the time, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 04:41:10 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 15:47:13 GMT"}, {"version": "v3", "created": "Wed, 29 May 2019 13:03:52 GMT"}, {"version": "v4", "created": "Fri, 31 May 2019 06:51:13 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Wang", "Qingyun", ""], ["Huang", "Lifu", ""], ["Jiang", "Zhiying", ""], ["Knight", "Kevin", ""], ["Ji", "Heng", ""], ["Bansal", "Mohit", ""], ["Luan", "Yi", ""]]}, {"id": "1905.07894", "submitter": "Noe Cecillon", "authors": "No\\'e Cecillon (LIA), Vincent Labatut (LIA), Richard Dufour (LIA),\n  Georges Linar\\`es (LIA)", "title": "Abusive Language Detection in Online Conversations by Combining\n  Content-and Graph-based Features", "comments": null, "journal-ref": "ICWSM International Workshop on Modeling and mining\n  Social-Media-driven Complex Networks (Soc2Net) 2019", "doi": "10.3389/fdata.2019.00008", "report-no": null, "categories": "cs.IR cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, online social networks have allowed worldwide users to meet\nand discuss. As guarantors of these communities, the administrators of these\nplatforms must prevent users from adopting inappropriate behaviors. This\nverification task, mainly done by humans, is more and more difficult due to the\never growing amount of messages to check. Methods have been proposed to\nautomatize this moderation process, mainly by providing approaches based on the\ntextual content of the exchanged messages. Recent work has also shown that\ncharacteristics derived from the structure of conversations, in the form of\nconversational graphs, can help detecting these abusive messages. In this\npaper, we propose to take advantage of both sources of information by proposing\nfusion methods integrating content-and graph-based features. Our experiments on\nraw chat logs show that the content of the messages, but also of their dynamics\nwithin a conversation contain partially complementary information, allowing\nperformance improvements on an abusive message classification task with a final\nF-measure of 93.26%.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 06:15:07 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Cecillon", "No\u00e9", "", "LIA"], ["Labatut", "Vincent", "", "LIA"], ["Dufour", "Richard", "", "LIA"], ["Linar\u00e8s", "Georges", "", "LIA"]]}, {"id": "1905.08063", "submitter": "Mark Keane", "authors": "Molly S Quinn, Kathleen Campbell, Mark T Keane", "title": "The Unexpected Unexpected and the Expected Unexpected: How People's\n  Conception of the Unexpected is Not That Unexpected", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The answers people give when asked to 'think of the unexpected' for everyday\nevent scenarios appear to be more expected than unexpected. There are expected\nunexpected outcomes that closely adhere to the given information in a scenario,\nbased on familiar disruptions and common plan-failures. There are also\nunexpected unexpected outcomes that are more inventive, that depart from given\ninformation, adding new concepts/actions. However, people seem to tend to\nconceive of the unexpected as the former more than the latter. Study 1 tests\nthese proposals by analysing the object-concepts people mention in their\nreports of the unexpected and the agreement between their answers. Study 2\nshows that object-choices are weakly influenced by recency, the order of\nsentences in the scenario. The implications of these results for ideas in\nphilosophy, psychology and computing is discussed\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 10:14:07 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Quinn", "Molly S", ""], ["Campbell", "Kathleen", ""], ["Keane", "Mark T", ""]]}, {"id": "1905.08067", "submitter": "Jason R.C. Nurse Dr", "authors": "Mariam Nouh and Jason R. C. Nurse and Michael Goldsmith", "title": "Understanding the Radical Mind: Identifying Signals to Detect Extremist\n  Content on Twitter", "comments": null, "journal-ref": "17th IEEE International Conference on Intelligence and Security\n  Informatics (ISI), 2019", "doi": "10.1109/ISI.2019.8823548", "report-no": null, "categories": "cs.SI cs.CL cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet and, in particular, Online Social Networks have changed the way\nthat terrorist and extremist groups can influence and radicalise individuals.\nRecent reports show that the mode of operation of these groups starts by\nexposing a wide audience to extremist material online, before migrating them to\nless open online platforms for further radicalization. Thus, identifying\nradical content online is crucial to limit the reach and spread of the\nextremist narrative. In this paper, our aim is to identify measures to\nautomatically detect radical content in social media. We identify several\nsignals, including textual, psychological and behavioural, that together allow\nfor the classification of radical messages. Our contribution is three-fold: (1)\nwe analyze propaganda material published by extremist groups and create a\ncontextual text-based model of radical content, (2) we build a model of\npsychological properties inferred from these material, and (3) we evaluate\nthese models on Twitter to determine the extent to which it is possible to\nautomatically identify online radical tweets. Our results show that radical\nusers do exhibit distinguishable textual, psychological, and behavioural\nproperties. We find that the psychological properties are among the most\ndistinguishing features. Additionally, our results show that textual models\nusing vector embedding features significantly improves the detection over\nTF-IDF features. We validate our approach on two experiments achieving high\naccuracy. Our findings can be utilized as signals for detecting online\nradicalization activities.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 17:14:34 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Nouh", "Mariam", ""], ["Nurse", "Jason R. C.", ""], ["Goldsmith", "Michael", ""]]}, {"id": "1905.08110", "submitter": "Yiyu Wang", "authors": "Yiyu Wang, Jungang Xu, Yingfei Sun, Ben He", "title": "Image Captioning based on Deep Learning Methods: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image captioning is a challenging task and attracting more and more attention\nin the field of Artificial Intelligence, and which can be applied to efficient\nimage retrieval, intelligent blind guidance and human-computer interaction,\netc. In this paper, we present a survey on advances in image captioning based\non Deep Learning methods, including Encoder-Decoder structure, improved methods\nin Encoder, improved methods in Decoder, and other improvements. Furthermore,\nwe discussed future research directions.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 13:43:52 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Wang", "Yiyu", ""], ["Xu", "Jungang", ""], ["Sun", "Yingfei", ""], ["He", "Ben", ""]]}, {"id": "1905.08160", "submitter": "Jasmijn Bastings", "authors": "Jasmijn Bastings, Wilker Aziz, Ivan Titov", "title": "Interpretable Neural Predictions with Differentiable Binary Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of neural networks comes hand in hand with a desire for more\ninterpretability. We focus on text classifiers and make them more interpretable\nby having them provide a justification, a rationale, for their predictions. We\napproach this problem by jointly training two neural network models: a latent\nmodel that selects a rationale (i.e. a short and informative part of the input\ntext), and a classifier that learns from the words in the rationale alone.\nPrevious work proposed to assign binary latent masks to input positions and to\npromote short selections via sparsity-inducing penalties such as L0\nregularisation. We propose a latent model that mixes discrete and continuous\nbehaviour allowing at the same time for binary selections and gradient-based\ntraining without REINFORCE. In our formulation, we can tractably compute the\nexpected value of penalties such as L0, which allows us to directly optimise\nthe model towards a pre-specified text selection rate. We show that our\napproach is competitive with previous work on rationale extraction, and explore\nfurther uses in attention mechanisms.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 15:07:36 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 17:14:31 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Bastings", "Jasmijn", ""], ["Aziz", "Wilker", ""], ["Titov", "Ivan", ""]]}, {"id": "1905.08181", "submitter": "\\'Alvaro Peris", "authors": "\\'Alvaro Peris and Francisco Casacuberta", "title": "A Neural, Interactive-predictive System for Multimodal Sequence to\n  Sequence Tasks", "comments": "ACL 2019 - System demonstrations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a demonstration of a neural interactive-predictive system for\ntackling multimodal sequence to sequence tasks. The system generates text\npredictions to different sequence to sequence tasks: machine translation, image\nand video captioning. These predictions are revised by a human agent, who\nintroduces corrections in the form of characters. The system reacts to each\ncorrection, providing alternative hypotheses, compelling with the feedback\nprovided by the user. The final objective is to reduce the human effort\nrequired during this correction process.\n  This system is implemented following a client-server architecture. For\naccessing the system, we developed a website, which communicates with the\nneural model, hosted in a local server. From this website, the different tasks\ncan be tackled following the interactive-predictive framework. We open-source\nall the code developed for building this system. The demonstration in hosted in\nhttp://casmacat.prhlt.upv.es/interactive-seq2seq.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 15:53:09 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 08:29:08 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Peris", "\u00c1lvaro", ""], ["Casacuberta", "Francisco", ""]]}, {"id": "1905.08205", "submitter": "Jiaqi Guo", "authors": "Jiaqi Guo, Zecheng Zhan, Yan Gao, Yan Xiao, Jian-Guang Lou, Ting Liu,\n  Dongmei Zhang", "title": "Towards Complex Text-to-SQL in Cross-Domain Database with Intermediate\n  Representation", "comments": "To appear in ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a neural approach called IRNet for complex and cross-domain\nText-to-SQL. IRNet aims to address two challenges: 1) the mismatch between\nintents expressed in natural language (NL) and the implementation details in\nSQL; 2) the challenge in predicting columns caused by the large number of\nout-of-domain words. Instead of end-to-end synthesizing a SQL query, IRNet\ndecomposes the synthesis process into three phases. In the first phase, IRNet\nperforms a schema linking over a question and a database schema. Then, IRNet\nadopts a grammar-based neural model to synthesize a SemQL query which is an\nintermediate representation that we design to bridge NL and SQL. Finally, IRNet\ndeterministically infers a SQL query from the synthesized SemQL query with\ndomain knowledge. On the challenging Text-to-SQL benchmark Spider, IRNet\nachieves 46.7% accuracy, obtaining 19.5% absolute improvement over previous\nstate-of-the-art approaches. At the time of writing, IRNet achieves the first\nposition on the Spider leaderboard.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 16:44:00 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 02:50:00 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Guo", "Jiaqi", ""], ["Zhan", "Zecheng", ""], ["Gao", "Yan", ""], ["Xiao", "Yan", ""], ["Lou", "Jian-Guang", ""], ["Liu", "Ting", ""], ["Zhang", "Dongmei", ""]]}, {"id": "1905.08212", "submitter": "Xinyi Wang", "authors": "Xinyi Wang, Graham Neubig", "title": "Target Conditioned Sampling: Optimizing Data Selection for Multilingual\n  Neural Machine Translation", "comments": "Accepted at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To improve low-resource Neural Machine Translation (NMT) with multilingual\ncorpora, training on the most related high-resource language only is often more\neffective than using all data available (Neubig and Hu, 2018). However, it is\npossible that an intelligent data selection strategy can further improve\nlow-resource NMT with data from other auxiliary languages. In this paper, we\nseek to construct a sampling distribution over all multilingual data, so that\nit minimizes the training loss of the low-resource language. Based on this\nformulation, we propose an efficient algorithm, Target Conditioned Sampling\n(TCS), which first samples a target sentence, and then conditionally samples\nits source sentence. Experiments show that TCS brings significant gains of up\nto 2 BLEU on three of four languages we test, with minimal training overhead.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 16:54:43 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Wang", "Xinyi", ""], ["Neubig", "Graham", ""]]}, {"id": "1905.08284", "submitter": "Shanchan Wu", "authors": "Shanchan Wu, Yifan He", "title": "Enriching Pre-trained Language Model with Entity Information for\n  Relation Classification", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relation classification is an important NLP task to extract relations between\nentities. The state-of-the-art methods for relation classification are\nprimarily based on Convolutional or Recurrent Neural Networks. Recently, the\npre-trained BERT model achieves very successful results in many NLP\nclassification / sequence labeling tasks. Relation classification differs from\nthose tasks in that it relies on information of both the sentence and the two\ntarget entities. In this paper, we propose a model that both leverages the\npre-trained BERT language model and incorporates information from the target\nentities to tackle the relation classification task. We locate the target\nentities and transfer the information through the pre-trained architecture and\nincorporate the corresponding encoding of the two entities. We achieve\nsignificant improvement over the state-of-the-art method on the SemEval-2010\ntask 8 relational dataset.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 18:22:18 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Wu", "Shanchan", ""], ["He", "Yifan", ""]]}, {"id": "1905.08300", "submitter": "Hansenclever Bassani", "authors": "Hansenclever F. Bassani, Aluizio F. R. Araujo", "title": "A Neural Network Architecture for Learning Word-Referent Associations in\n  Multiple Contexts", "comments": null, "journal-ref": null, "doi": "10.1016/j.neunet.2019.05.017", "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This article proposes a biologically inspired neurocomputational architecture\nwhich learns associations between words and referents in different contexts,\nconsidering evidence collected from the literature of Psycholinguistics and\nNeurolinguistics. The multi-layered architecture takes as input raw images of\nobjects (referents) and streams of word's phonemes (labels), builds an adequate\nrepresentation, recognizes the current context, and associates label with\nreferents incrementally, by employing a Self-Organizing Map which creates new\nassociation nodes (prototypes) as required, adjusts the existing prototypes to\nbetter represent the input stimuli and removes prototypes that become\nobsolete/unused. The model takes into account the current context to retrieve\nthe correct meaning of words with multiple meanings. Simulations show that the\nmodel can reach up to 78% of word-referent association accuracy in ambiguous\nsituations and approximates well the learning rates of humans as reported by\nthree different authors in five Cross-Situational Word Learning experiments,\nalso displaying similar learning patterns in the different learning conditions.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 19:05:12 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Bassani", "Hansenclever F.", ""], ["Araujo", "Aluizio F. R.", ""]]}, {"id": "1905.08377", "submitter": "Aina Gar\\'i Soler", "authors": "Aina Gar\\'i Soler, Marianna Apidianaki, Alexandre Allauzen", "title": "Word Usage Similarity Estimation with Sentence Representations and\n  Automatic Substitutes", "comments": "*SEM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Usage similarity estimation addresses the semantic proximity of word\ninstances in different contexts. We apply contextualized (ELMo and BERT) word\nand sentence embeddings to this task, and propose supervised models that\nleverage these representations for prediction. Our models are further assisted\nby lexical substitute annotations automatically assigned to word instances by\ncontext2vec, a neural model that relies on a bidirectional LSTM. We perform an\nextensive comparison of existing word and sentence representations on benchmark\ndatasets addressing both graded and binary similarity. The best performing\nmodels outperform previous methods in both settings.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 23:10:42 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Soler", "Aina Gar\u00ed", ""], ["Apidianaki", "Marianna", ""], ["Allauzen", "Alexandre", ""]]}, {"id": "1905.08392", "submitter": "Md. Iftekhar Tanveer", "authors": "Md Iftekhar Tanveer, Md Kamrul Hasan, Daniel Gildea, M. Ehsan Hoque", "title": "A Causality-Guided Prediction of the TED Talk Ratings from the\n  Speech-Transcripts using Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated prediction of public speaking performance enables novel systems for\ntutoring public speaking skills. We use the largest open repository---TED\nTalks---to predict the ratings provided by the online viewers. The dataset\ncontains over 2200 talk transcripts and the associated meta information\nincluding over 5.5 million ratings from spontaneous visitors to the website. We\ncarefully removed the bias present in the dataset (e.g., the speakers'\nreputations, popularity gained by publicity, etc.) by modeling the data\ngenerating process using a causal diagram. We use a word sequence based\nrecurrent architecture and a dependency tree based recursive architecture as\nthe neural networks for predicting the TED talk ratings. Our neural network\nmodels can predict the ratings with an average F-score of 0.77 which largely\noutperforms the competitive baseline method.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 00:32:21 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Tanveer", "Md Iftekhar", ""], ["Hasan", "Md Kamrul", ""], ["Gildea", "Daniel", ""], ["Hoque", "M. Ehsan", ""]]}, {"id": "1905.08407", "submitter": "Peter Shaw", "authors": "Peter Shaw, Philip Massey, Angelica Chen, Francesco Piccinno, Yasemin\n  Altun", "title": "Generating Logical Forms from Graph Representations of Text and Entities", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured information about entities is critical for many semantic parsing\ntasks. We present an approach that uses a Graph Neural Network (GNN)\narchitecture to incorporate information about relevant entities and their\nrelations during parsing. Combined with a decoder copy mechanism, this approach\nprovides a conceptually simple mechanism to generate logical forms with\nentities. We demonstrate that this approach is competitive with the\nstate-of-the-art across several tasks without pre-training, and outperforms\nexisting approaches when combined with BERT pre-training.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 02:13:03 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 19:00:45 GMT"}, {"version": "v3", "created": "Wed, 25 Sep 2019 21:45:33 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Shaw", "Peter", ""], ["Massey", "Philip", ""], ["Chen", "Angelica", ""], ["Piccinno", "Francesco", ""], ["Altun", "Yasemin", ""]]}, {"id": "1905.08454", "submitter": "Wei Jiang", "authors": "Wei Jiang and Yan Tang", "title": "A Seq-to-Seq Transformer Premised Temporal Convolutional Network for\n  Chinese Word Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prevalent approaches of Chinese word segmentation task almost rely on the\nBi-LSTM neural network. However, the methods based the Bi-LSTM have some\ninherent drawbacks: hard to parallel computing, little efficient in applying\nthe Dropout method to inhibit the Overfitting and little efficient in capturing\nthe character information at the more distant site of a long sentence for the\nword segmentation task. In this work, we propose a sequence-to-sequence\ntransformer model for Chinese word segmentation, which is premised a type of\nconvolutional neural network named temporal convolutional network. The model\nuses the temporal convolutional network to construct an encoder, and uses one\nlayer of fully-connected neural network to build a decoder, and applies the\nDropout method to inhibit the Overfitting, and captures the character\ninformation at the distant site of a sentence by adding the layers of the\nencoder, and binds Conditional Random Fields model to train parameters, and\nuses the Viterbi algorithm to infer the final result of the Chinese word\nsegmentation. The experiments on traditional Chinese corpora and simplified\nChinese corpora show that the performance of Chinese word segmentation of the\nmodel is equivalent to the performance of the methods based the Bi-LSTM, and\nthe model has a tremendous growth in parallel computing than the models based\nthe Bi-LSTM.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 06:12:47 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Jiang", "Wei", ""], ["Tang", "Yan", ""]]}, {"id": "1905.08459", "submitter": "Wei Ping", "authors": "Kainan Peng, Wei Ping, Zhao Song, Kexin Zhao", "title": "Non-Autoregressive Neural Text-to-Speech", "comments": "Published at ICML 2020. (v3 changed paper title)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose ParaNet, a non-autoregressive seq2seq model that\nconverts text to spectrogram. It is fully convolutional and brings 46.7 times\nspeed-up over the lightweight Deep Voice 3 at synthesis, while obtaining\nreasonably good speech quality. ParaNet also produces stable alignment between\ntext and speech on the challenging test sentences by iteratively improving the\nattention in a layer-by-layer manner. Furthermore, we build the parallel\ntext-to-speech system and test various parallel neural vocoders, which can\nsynthesize speech from text through a single feed-forward pass. We also explore\na novel VAE-based approach to train the inverse autoregressive flow (IAF) based\nparallel vocoder from scratch, which avoids the need for distillation from a\nseparately trained WaveNet as previous work.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 06:36:15 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 21:28:26 GMT"}, {"version": "v3", "created": "Mon, 29 Jun 2020 20:15:59 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Peng", "Kainan", ""], ["Ping", "Wei", ""], ["Song", "Zhao", ""], ["Zhao", "Kexin", ""]]}, {"id": "1905.08511", "submitter": "Kyosuke Nishida", "authors": "Kosuke Nishida, Kyosuke Nishida, Masaaki Nagata, Atsushi Otsuka,\n  Itsumi Saito, Hisako Asano, Junji Tomita", "title": "Answering while Summarizing: Multi-task Learning for Multi-hop QA with\n  Evidence Extraction", "comments": "Accepted as a long paper at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question answering (QA) using textual sources for purposes such as reading\ncomprehension (RC) has attracted much attention. This study focuses on the task\nof explainable multi-hop QA, which requires the system to return the answer\nwith evidence sentences by reasoning and gathering disjoint pieces of the\nreference texts. It proposes the Query Focused Extractor (QFE) model for\nevidence extraction and uses multi-task learning with the QA model. QFE is\ninspired by extractive summarization models; compared with the existing method,\nwhich extracts each evidence sentence independently, it sequentially extracts\nevidence sentences by using an RNN with an attention mechanism on the question\nsentence. It enables QFE to consider the dependency among the evidence\nsentences and cover important information in the question sentence.\nExperimental results show that QFE with a simple RC baseline model achieves a\nstate-of-the-art evidence extraction score on HotpotQA. Although designed for\nRC, it also achieves a state-of-the-art evidence extraction score on FEVER,\nwhich is a recognizing textual entailment task on a large textual database.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 09:23:56 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 02:37:53 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Nishida", "Kosuke", ""], ["Nishida", "Kyosuke", ""], ["Nagata", "Masaaki", ""], ["Otsuka", "Atsushi", ""], ["Saito", "Itsumi", ""], ["Asano", "Hisako", ""], ["Tomita", "Junji", ""]]}, {"id": "1905.08527", "submitter": "Roberto Dess\\'i", "authors": "Roberto Dess\\`i and Marco Baroni", "title": "CNNs found to jump around more skillfully than RNNs: Compositional\n  generalization in seq2seq convolutional networks", "comments": "accepted as a short paper at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lake and Baroni (2018) introduced the SCAN dataset probing the ability of\nseq2seq models to capture compositional generalizations, such as inferring the\nmeaning of \"jump around\" 0-shot from the component words. Recurrent networks\n(RNNs) were found to completely fail the most challenging generalization cases.\nWe test here a convolutional network (CNN) on these tasks, reporting hugely\nimproved performance with respect to RNNs. Despite the big improvement, the CNN\nhas however not induced systematic rules, suggesting that the difference\nbetween compositional and non-compositional behaviour is not clear-cut.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 10:14:12 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Dess\u00ec", "Roberto", ""], ["Baroni", "Marco", ""]]}, {"id": "1905.08622", "submitter": "Mingyuan Zhou", "authors": "Hao Zhang, Bo Chen, Long Tian, Zhengjue Wang, Mingyuan Zhou", "title": "Variational Hetero-Encoder Randomized GANs for Joint Image-Text Modeling", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For bidirectional joint image-text modeling, we develop variational\nhetero-encoder (VHE) randomized generative adversarial network (GAN), a\nversatile deep generative model that integrates a probabilistic text decoder,\nprobabilistic image encoder, and GAN into a coherent end-to-end multi-modality\nlearning framework. VHE randomized GAN (VHE-GAN) encodes an image to decode its\nassociated text, and feeds the variational posterior as the source of\nrandomness into the GAN image generator. We plug three off-the-shelf modules,\nincluding a deep topic model, a ladder-structured image encoder, and\nStackGAN++, into VHE-GAN, which already achieves competitive performance. This\nfurther motivates the development of VHE-raster-scan-GAN that generates\nphoto-realistic images in not only a multi-scale low-to-high-resolution manner,\nbut also a hierarchical-semantic coarse-to-fine fashion. By capturing and\nrelating hierarchical semantic and visual concepts with end-to-end training,\nVHE-raster-scan-GAN achieves state-of-the-art performance in a wide variety of\nimage-text multi-modality learning and generation tasks.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 13:58:12 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 16:43:14 GMT"}, {"version": "v3", "created": "Tue, 7 Jan 2020 20:51:34 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Zhang", "Hao", ""], ["Chen", "Bo", ""], ["Tian", "Long", ""], ["Wang", "Zhengjue", ""], ["Zhou", "Mingyuan", ""]]}, {"id": "1905.08633", "submitter": "Vinay Prabhu", "authors": "Vinay Uday Prabhu, Sanghyun Han, Dian Ang Yap, Mihail Douhaniaris,\n  Preethi Seshadri and John Whaley", "title": "Fonts-2-Handwriting: A Seed-Augment-Train framework for universal digit\n  classification", "comments": "Published as a workshop paper at ICLR 2019 (DeepGenStruct-2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a Seed-Augment-Train/Transfer (SAT) framework that\ncontains a synthetic seed image dataset generation procedure for languages with\ndifferent numeral systems using freely available open font file datasets. This\nseed dataset of images is then augmented to create a purely synthetic training\ndataset, which is in turn used to train a deep neural network and test on\nheld-out real world handwritten digits dataset spanning five Indic scripts,\nKannada, Tamil, Gujarati, Malayalam, and Devanagari. We showcase the efficacy\nof this approach both qualitatively, by training a Boundary-seeking GAN (BGAN)\nthat generates realistic digit images in the five languages, and also\nquantitatively by testing a CNN trained on the synthetic data on the real-world\ndatasets. This establishes not only an interesting nexus between the\nfont-datasets-world and transfer learning but also provides a recipe for\nuniversal-digit classification in any script.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 20:38:05 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Prabhu", "Vinay Uday", ""], ["Han", "Sanghyun", ""], ["Yap", "Dian Ang", ""], ["Douhaniaris", "Mihail", ""], ["Seshadri", "Preethi", ""], ["Whaley", "John", ""]]}, {"id": "1905.08635", "submitter": "Xuan-Son Vu", "authors": "Xuan-Son Vu, Abhishek Santra, Sharma Chakravarthy, Lili Jiang", "title": "Generic Multilayer Network Data Analysis with the Fusion of Content and\n  Structure", "comments": "18 pages", "journal-ref": "Proceedings of the 20th International Conference on Computational\n  Linguistics and Intelligent Text Processing, April, 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-feature data analysis (e.g., on Facebook, LinkedIn) is challenging\nespecially if one wants to do it efficiently and retain the flexibility by\nchoosing features of interest for analysis. Features (e.g., age, gender,\nrelationship, political view etc.) can be explicitly given from datasets, but\nalso can be derived from content (e.g., political view based on Facebook\nposts). Analysis from multiple perspectives is needed to understand the\ndatasets (or subsets of it) and to infer meaningful knowledge. For example, the\ninfluence of age, location, and marital status on political views may need to\nbe inferred separately (or in combination). In this paper, we adapt multilayer\nnetwork (MLN) analysis, a nontraditional approach, to model the Facebook\ndatasets, integrate content analysis, and conduct analysis, which is driven by\na list of desired application based queries. Our experimental analysis shows\nthe flexibility and efficiency of the proposed approach when modeling and\nanalyzing datasets with multiple features.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 13:41:47 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Vu", "Xuan-Son", ""], ["Santra", "Abhishek", ""], ["Chakravarthy", "Sharma", ""], ["Jiang", "Lili", ""]]}, {"id": "1905.08675", "submitter": "Simon Gottschalk", "authors": "Simon Gottschalk, Elena Demidova", "title": "MultiWiki: Interlingual Text Passage Alignment in Wikipedia", "comments": null, "journal-ref": "ACM Transactions on the Web 11 (1), 2017", "doi": "10.1145/3004296", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we address the problem of text passage alignment across\ninterlingual article pairs in Wikipedia. We develop methods that enable the\nidentification and interlinking of text passages written in different languages\nand containing overlapping information. Interlingual text passage alignment can\nenable Wikipedia editors and readers to better understand language-specific\ncontext of entities, provide valuable insights in cultural differences and\nbuild a basis for qualitative analysis of the articles. An important challenge\nin this context is the trade-off between the granularity of the extracted text\npassages and the precision of the alignment. Whereas short text passages can\nresult in more precise alignment, longer text passages can facilitate a better\noverview of the differences in an article pair. To better understand these\naspects from the user perspective, we conduct a user study at the example of\nthe German, Russian and the English Wikipedia and collect a user-annotated\nbenchmark. Then we propose MultiWiki -- a method that adopts an integrated\napproach to the text passage alignment using semantic similarity measures and\ngreedy algorithms and achieves precise results with respect to the user-defined\nalignment. MultiWiki demonstration is publicly available and currently supports\nfour language pairs.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 14:47:35 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Gottschalk", "Simon", ""], ["Demidova", "Elena", ""]]}, {"id": "1905.08701", "submitter": "Ananda Theertha Suresh", "authors": "Ananda Theertha Suresh, Brian Roark, Michael Riley, Vlad Schogol", "title": "Approximating probabilistic models as weighted finite automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.FL cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weighted finite automata (WFA) are often used to represent probabilistic\nmodels, such as $n$-gram language models, since they are efficient for\nrecognition tasks in time and space. The probabilistic source to be represented\nas a WFA, however, may come in many forms. Given a generic probabilistic model\nover sequences, we propose an algorithm to approximate it as a weighted finite\nautomaton such that the Kullback-Leiber divergence between the source model and\nthe WFA target model is minimized. The proposed algorithm involves a counting\nstep and a difference of convex optimization step, both of which can be\nperformed efficiently. We demonstrate the usefulness of our approach on various\ntasks, including distilling $n$-gram models from neural models, building\ncompact language models, and building open-vocabulary character models. The\nalgorithms used for these experiments are available in an open-source software\nlibrary.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 15:36:54 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 20:33:53 GMT"}, {"version": "v3", "created": "Fri, 29 Jan 2021 16:56:07 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Suresh", "Ananda Theertha", ""], ["Roark", "Brian", ""], ["Riley", "Michael", ""], ["Schogol", "Vlad", ""]]}, {"id": "1905.08704", "submitter": "Sheng Zhang", "authors": "Sheng Zhang and Xutai Ma and Kevin Duh and Benjamin Van Durme", "title": "AMR Parsing as Sequence-to-Graph Transduction", "comments": "Accepted at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an attention-based model that treats AMR parsing as\nsequence-to-graph transduction. Unlike most AMR parsers that rely on\npre-trained aligners, external semantic resources, or data augmentation, our\nproposed parser is aligner-free, and it can be effectively trained with limited\namounts of labeled AMR data. Our experimental results outperform all previously\nreported SMATCH scores, on both AMR 2.0 (76.3% F1 on LDC2017T10) and AMR 1.0\n(70.2% F1 on LDC2014T12).\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 15:41:18 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 00:18:47 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Zhang", "Sheng", ""], ["Ma", "Xutai", ""], ["Duh", "Kevin", ""], ["Van Durme", "Benjamin", ""]]}, {"id": "1905.08732", "submitter": "Ting-Shuo Yo", "authors": "Chu-Ren Huang, Ting-Shuo Yo, Petr Simon, Shu-Kai Hsieh", "title": "A realistic and robust model for Chinese word segmentation", "comments": "Proceedings of the 20th Conference on Computational Linguistics and\n  Speech Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A realistic Chinese word segmentation tool must adapt to textual variations\nwith minimal training input and yet robust enough to yield reliable\nsegmentation result for all variants. Various lexicon-driven approaches to\nChinese segmentation, e.g. [1,16], achieve high f-scores yet require massive\ntraining for any variation. Text-driven approach, e.g. [12], can be easily\nadapted for domain and genre changes yet has difficulty matching the high\nf-scores of the lexicon-driven approaches. In this paper, we refine and\nimplement an innovative text-driven word boundary decision (WBD) segmentation\nmodel proposed in [15]. The WBD model treats word segmentation simply and\nefficiently as a binary decision on whether to realize the natural textual\nbreak between two adjacent characters as a word boundary. The WBD model allows\nsimple and quick training data preparation converting characters as contextual\nvectors for learning the word boundary decision. Machine learning experiments\nwith four different classifiers show that training with 1,000 vectors and 1\nmillion vectors achieve comparable and reliable results. In addition, when\napplied to SigHAN Bakeoff 3 competition data, the WBD model produces OOV recall\nrates that are higher than all published results. Unlike all previous work, our\nOOV recall rate is comparable to our own F-score. Both experiments support the\nclaim that the WBD model is a realistic model for Chinese word segmentation as\nit can be easily adapted for new variants with the robust result. In\nconclusion, we will discuss linguistic ramifications as well as future\nimplications for the WBD approach.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 16:22:47 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Huang", "Chu-Ren", ""], ["Yo", "Ting-Shuo", ""], ["Simon", "Petr", ""], ["Hsieh", "Shu-Kai", ""]]}, {"id": "1905.08743", "submitter": "Chien-Sheng Wu", "authors": "Chien-Sheng Wu, Andrea Madotto, Ehsan Hosseini-Asl, Caiming Xiong,\n  Richard Socher, Pascale Fung", "title": "Transferable Multi-Domain State Generator for Task-Oriented Dialogue\n  Systems", "comments": "The 57th Annual Meeting of the Association for Computational\n  Linguistics (ACL 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over-dependence on domain ontology and lack of knowledge sharing across\ndomains are two practical and yet less studied problems of dialogue state\ntracking. Existing approaches generally fall short in tracking unknown slot\nvalues during inference and often have difficulties in adapting to new domains.\nIn this paper, we propose a Transferable Dialogue State Generator (TRADE) that\ngenerates dialogue states from utterances using a copy mechanism, facilitating\nknowledge transfer when predicting (domain, slot, value) triplets not\nencountered during training. Our model is composed of an utterance encoder, a\nslot gate, and a state generator, which are shared across domains. Empirical\nresults demonstrate that TRADE achieves state-of-the-art joint goal accuracy of\n48.62% for the five domains of MultiWOZ, a human-human dialogue dataset. In\naddition, we show its transferring ability by simulating zero-shot and few-shot\ndialogue state tracking for unseen domains. TRADE achieves 60.58% joint goal\naccuracy in one of the zero-shot domains, and is able to adapt to few-shot\ncases without forgetting already trained domains.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 16:43:54 GMT"}, {"version": "v2", "created": "Sun, 26 May 2019 14:36:57 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Wu", "Chien-Sheng", ""], ["Madotto", "Andrea", ""], ["Hosseini-Asl", "Ehsan", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""], ["Fung", "Pascale", ""]]}, {"id": "1905.08760", "submitter": "Martin Jansche", "authors": "Martin Jansche, Alexander Gutkin", "title": "Sampling from Stochastic Finite Automata with Applications to CTC\n  Decoding", "comments": null, "journal-ref": null, "doi": "10.21437/Interspeech.2019-2740", "report-no": null, "categories": "cs.CL cs.FL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Stochastic finite automata arise naturally in many language and speech\nprocessing tasks. They include stochastic acceptors, which represent certain\nprobability distributions over random strings. We consider the problem of\nefficient sampling: drawing random string variates from the probability\ndistribution represented by stochastic automata and transformations of those.\nWe show that path-sampling is effective and can be efficient if the\nepsilon-graph of a finite automaton is acyclic. We provide an algorithm that\nensures this by conflating epsilon-cycles within strongly connected components.\nSampling is also effective in the presence of non-injective transformations of\nstrings. We illustrate this in the context of decoding for Connectionist\nTemporal Classification (CTC), where the predictive probabilities yield\nauxiliary sequences which are transformed into shorter labeling strings. We can\nsample efficiently from the transformed labeling distribution and use this in\ntwo different strategies for finding the most probable CTC labeling.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 17:26:39 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Jansche", "Martin", ""], ["Gutkin", "Alexander", ""]]}, {"id": "1905.08772", "submitter": "Sergio Gast\\'on Burdisso", "authors": "Sergio G. Burdisso, Marcelo Errecalde, Manuel Montes-y-G\\'omez", "title": "A Text Classification Framework for Simple and Effective Early\n  Depression Detection Over Social Media Streams", "comments": "Highlights: (*) A novel text classifier having the ability to\n  visually explain its rationale; (*) Domain-independent classification that\n  does not require feature engineering; (*) Support for incremental learning\n  and text classification over streams; (*) Efficient framework for addressing\n  early risk detection problems; (*) State-of-the-art performance on early\n  depression detection task", "journal-ref": "18 May 2019, Volume 133, Expert Systems With Applications,\n  Elsevier", "doi": "10.1016/j.eswa.2019.05.023", "report-no": null, "categories": "cs.CY cs.CL cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rise of the Internet, there is a growing need to build intelligent\nsystems that are capable of efficiently dealing with early risk detection (ERD)\nproblems on social media, such as early depression detection, early rumor\ndetection or identification of sexual predators. These systems, nowadays mostly\nbased on machine learning techniques, must be able to deal with data streams\nsince users provide their data over time. In addition, these systems must be\nable to decide when the processed data is sufficient to actually classify\nusers. Moreover, since ERD tasks involve risky decisions by which people's\nlives could be affected, such systems must also be able to justify their\ndecisions. However, most standard and state-of-the-art supervised machine\nlearning models (such as SVM, MNB, Neural Networks, etc.) are not well suited\nto deal with this scenario. This is due to the fact that they either act as\nblack boxes or do not support incremental classification/learning. In this\npaper we introduce SS3, a novel supervised learning model for text\nclassification that naturally supports these aspects. SS3 was designed to be\nused as a general framework to deal with ERD problems. We evaluated our model\non the CLEF's eRisk2017 pilot task on early depression detection. Most of the\n30 contributions submitted to this competition used state-of-the-art methods.\nExperimental results show that our classifier was able to outperform these\nmodels and standard classifiers, despite being less computationally expensive\nand having the ability to explain its rationale.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 15:46:38 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Burdisso", "Sergio G.", ""], ["Errecalde", "Marcelo", ""], ["Montes-y-G\u00f3mez", "Manuel", ""]]}, {"id": "1905.08780", "submitter": "Miguel Angel Alvarez", "authors": "Miguel \\'A. \\'Alvarez-Carmona, Esa\\'u Villatoro-Tello and Manuel\n  Montes-y-G\\'omez and Luis Villase\\~nor-Pienda", "title": "A Comparative Analysis of Distributional Term Representations for Author\n  Profiling in Social Media", "comments": null, "journal-ref": "Journal of Intelligent & Fuzzy Systems, vol. 36, no. 5, pp.\n  4857-4868, 2019", "doi": "10.3233/JIFS-179033", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Author Profiling (AP) aims at predicting specific characteristics from a\ngroup of authors by analyzing their written documents. Many research has been\nfocused on determining suitable features for modeling writing patterns from\nauthors. Reported results indicate that content-based features continue to be\nthe most relevant and discriminant features for solving this task. Thus, in\nthis paper, we present a thorough analysis regarding the appropriateness of\ndifferent distributional term representations (DTR) for the AP task. In this\nregard, we introduce a novel framework for supervised AP using these\nrepresentations and, supported on it. We approach a comparative analysis of\nrepresentations such as DOR, TCOR, SSR, and word2vec in the AP problem. We also\ncompare the performance of the DTRs against classic approaches including\npopular topic-based methods. The obtained results indicate that DTRs are\nsuitable for solving the AP task in social media domains as they achieve\ncompetitive results while providing meaningful interpretability.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 17:54:09 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["\u00c1lvarez-Carmona", "Miguel \u00c1.", ""], ["Villatoro-Tello", "Esa\u00fa", ""], ["Montes-y-G\u00f3mez", "Manuel", ""], ["Villase\u00f1or-Pienda", "Luis", ""]]}, {"id": "1905.08794", "submitter": "Simon Gottschalk", "authors": "Simon Gottschalk, Elena Demidova", "title": "EventKG - the Hub of Event Knowledge on the Web - and Biographical\n  Timeline Generation", "comments": "arXiv admin note: text overlap with arXiv:1804.04526", "journal-ref": "Semantic Web Journal (2019)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key requirements to facilitate the semantic analytics of\ninformation regarding contemporary and historical events on the Web, in the\nnews and in social media is the availability of reference knowledge\nrepositories containing comprehensive representations of events, entities and\ntemporal relations. Existing knowledge graphs, with popular examples including\nDBpedia, YAGO and Wikidata, focus mostly on entity-centric information and are\ninsufficient in terms of their coverage and completeness with respect to events\nand temporal relations. In this article we address this limitation, formalise\nthe concept of a temporal knowledge graph and present its instantiation -\nEventKG. EventKG is a multilingual event-centric temporal knowledge graph that\nincorporates over 690 thousand events and over 2.3 million temporal relations\nobtained from several large-scale knowledge graphs and semi-structured sources\nand makes them available through a canonical RDF representation. Whereas\npopular entities often possess hundreds of relations within a temporal\nknowledge graph such as EventKG, generating a concise overview of the most\nimportant temporal relations for a given entity is a challenging task. In this\narticle we demonstrate an application of EventKG to biographical timeline\ngeneration, where we adopt a distant supervision method to identify relations\nmost relevant for an entity biography. Our evaluation results provide insights\non the characteristics of EventKG and demonstrate the effectiveness of the\nproposed biographical timeline generation method.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 15:14:34 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Gottschalk", "Simon", ""], ["Demidova", "Elena", ""]]}, {"id": "1905.08796", "submitter": "Suyoun Kim", "authors": "Suyoun Kim and Florian Metze", "title": "Acoustic-to-Word Models with Conversational Context Information", "comments": "NAACL 2019. arXiv admin note: text overlap with arXiv:1808.02171", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational context information, higher-level knowledge that spans across\nsentences, can help to recognize a long conversation. However, existing speech\nrecognition models are typically built at a sentence level, and thus it may not\ncapture important conversational context information. The recent progress in\nend-to-end speech recognition enables integrating context with other available\ninformation (e.g., acoustic, linguistic resources) and directly recognizing\nwords from speech. In this work, we present a direct acoustic-to-word,\nend-to-end speech recognition model capable of utilizing the conversational\ncontext to better process long conversations. We evaluate our proposed approach\non the Switchboard conversational speech corpus and show that our system\noutperforms a standard end-to-end speech recognition system.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 15:44:03 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Kim", "Suyoun", ""], ["Metze", "Florian", ""]]}, {"id": "1905.08836", "submitter": "Urvashi Khandelwal", "authors": "Urvashi Khandelwal, Kevin Clark, Dan Jurafsky and Lukasz Kaiser", "title": "Sample Efficient Text Summarization Using a Single Pre-Trained\n  Transformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language model (LM) pre-training has resulted in impressive performance and\nsample efficiency on a variety of language understanding tasks. However, it\nremains unclear how to best use pre-trained LMs for generation tasks such as\nabstractive summarization, particularly to enhance sample efficiency. In these\nsequence-to-sequence settings, prior work has experimented with loading\npre-trained weights into the encoder and/or decoder networks, but used\nnon-pre-trained encoder-decoder attention weights. We instead use a pre-trained\ndecoder-only network, where the same Transformer LM both encodes the source and\ngenerates the summary. This ensures that all parameters in the network,\nincluding those governing attention over source states, have been pre-trained\nbefore the fine-tuning step. Experiments on the CNN/Daily Mail dataset show\nthat our pre-trained Transformer LM substantially improves over pre-trained\nTransformer encoder-decoder networks in limited-data settings. For instance, it\nachieves 13.1 ROUGE-2 using only 1% of the training data (~3000 examples),\nwhile pre-trained encoder-decoder models score 2.3 ROUGE-2.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 19:13:16 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Khandelwal", "Urvashi", ""], ["Clark", "Kevin", ""], ["Jurafsky", "Dan", ""], ["Kaiser", "Lukasz", ""]]}, {"id": "1905.08868", "submitter": "Junlin Yang", "authors": "Yinchuan Xu and Junlin Yang", "title": "Look Again at the Syntax: Relational Graph Convolutional Network for\n  Gendered Ambiguous Pronoun Resolution", "comments": "Accepted by ACL 2019 Workshop on Gender Bias for Natural Language\n  Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gender bias has been found in existing coreference resolvers. In order to\neliminate gender bias, a gender-balanced dataset Gendered Ambiguous Pronouns\n(GAP) has been released and the best baseline model achieves only 66.9% F1.\nBidirectional Encoder Representations from Transformers (BERT) has broken\nseveral NLP task records and can be used on GAP dataset. However, fine-tune\nBERT on a specific task is computationally expensive. In this paper, we propose\nan end-to-end resolver by combining pre-trained BERT with Relational Graph\nConvolutional Network (R-GCN). R-GCN is used for digesting structural syntactic\ninformation and learning better task-specific embeddings. Empirical results\ndemonstrate that, under explicit syntactic supervision and without the need to\nfine tune BERT, R-GCN's embeddings outperform the original BERT embeddings on\nthe coreference task. Our work significantly improves the snippet-context\nbaseline F1 score on GAP dataset from 66.9% to 80.3%. We participated in the\n2019 GAP Coreference Shared Task, and our codes are available online.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 20:56:50 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 01:24:30 GMT"}, {"version": "v3", "created": "Fri, 31 May 2019 21:51:44 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Xu", "Yinchuan", ""], ["Yang", "Junlin", ""]]}, {"id": "1905.08920", "submitter": "Luisa M\\\"arz", "authors": "Luisa M\\\"arz and Dietrich Trautmann and Benjamin Roth", "title": "Domain adaptation for part-of-speech tagging of noisy user-generated\n  text", "comments": "6 pages, NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of a Part-of-speech (POS) tagger is highly dependent on the\ndomain ofthe processed text, and for many domains there is no or only very\nlittle training data available. This work addresses the problem of POS tagging\nnoisy user-generated text using a neural network. We propose an architecture\nthat trains an out-of-domain model on a large newswire corpus, and transfers\nthose weights by using them as a prior for a model trained on the target domain\n(a data-set of German Tweets) for which there is very little an-notations\navailable. The neural network has two standard bidirectional LSTMs at its core.\nHowever, we find it crucial to also encode a set of task-specific features, and\nto obtain reliable (source-domain and target-domain) word representations.\nExperiments with different regularization techniques such as early stopping,\ndropout and fine-tuning the domain adaptation prior weights are conducted. Our\nbest model uses external weights from the out-of-domain model, as well as\nfeature embeddings, pre-trained word and sub-word embeddings and achieves a\ntagging accuracy of slightly over 90%, improving on the previous state of the\nart for this task.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 10:33:06 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["M\u00e4rz", "Luisa", ""], ["Trautmann", "Dietrich", ""], ["Roth", "Benjamin", ""]]}, {"id": "1905.08937", "submitter": "Ranjan Satapathy", "authors": "Nidhi Mishra, Manoj Ramanathan, Ranjan Satapathy, Erik Cambria and\n  Nadia Magnenat-Thalmann", "title": "Can a Humanoid Robot be part of the Organizational Workforce? A User\n  Study Leveraging Sentiment Analysis", "comments": "Submitted to IEEE RO-MAN2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hiring robots for the workplaces is a challenging task as robots have to\ncater to customer demands, follow organizational protocols and behave with\nsocial etiquette. In this study, we propose to have a humanoid social robot,\nNadine, as a customer service agent in an open social work environment. The\nobjective of this study is to analyze the effects of humanoid robots on\ncustomers at work environment, and see if it can handle social scenarios. We\npropose to evaluate these objectives through two modes, namely, survey\nquestionnaire and customer feedback. We also propose a novel approach to\nanalyze customer feedback data (text) using sentic computing methods.\nSpecifically, we employ aspect extraction and sentiment analysis to analyze the\ndata. From our framework, we detect sentiment associated to the aspects that\nmainly concerned the customers during their interaction. This allows us to\nunderstand customers expectations and current limitations of robots as\nemployees.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 03:34:59 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 06:22:53 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Mishra", "Nidhi", ""], ["Ramanathan", "Manoj", ""], ["Satapathy", "Ranjan", ""], ["Cambria", "Erik", ""], ["Magnenat-Thalmann", "Nadia", ""]]}, {"id": "1905.08941", "submitter": "Hongyu Guo", "authors": "Hongyu Guo, Yongyi Mao, Richong Zhang", "title": "Augmenting Data with Mixup for Sentence Classification: An Empirical\n  Study", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixup, a recent proposed data augmentation method through linearly\ninterpolating inputs and modeling targets of random samples, has demonstrated\nits capability of significantly improving the predictive accuracy of the\nstate-of-the-art networks for image classification. However, how this technique\ncan be applied to and what is its effectiveness on natural language processing\n(NLP) tasks have not been investigated. In this paper, we propose two\nstrategies for the adaption of Mixup on sentence classification: one performs\ninterpolation on word embeddings and another on sentence embeddings. We conduct\nexperiments to evaluate our methods using several benchmark datasets. Our\nstudies show that such interpolation strategies serve as an effective, domain\nindependent data augmentation approach for sentence classification, and can\nresult in significant accuracy improvement for both CNN and LSTM models.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 03:55:54 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Guo", "Hongyu", ""], ["Mao", "Yongyi", ""], ["Zhang", "Richong", ""]]}, {"id": "1905.08945", "submitter": "Jinyi Zhang", "authors": "Jinyi Zhang, Tadahiro Matsumoto", "title": "Corpus Augmentation by Sentence Segmentation for Low-Resource Neural\n  Machine Translation", "comments": "4 pages. The version before Applied. Sciences", "journal-ref": null, "doi": "10.3390/app9102036", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) has been proven to achieve impressive\nresults. The NMT system translation results depend strongly on the size and\nquality of parallel corpora. Nevertheless, for many language pairs, no\nrich-resource parallel corpora exist. As described in this paper, we propose a\ncorpus augmentation method by segmenting long sentences in a corpus using\nback-translation and generating pseudo-parallel sentence pairs. The experiment\nresults of the Japanese-Chinese and Chinese-Japanese translation with\nJapanese-Chinese scientific paper excerpt corpus (ASPEC-JC) show that the\nmethod improves translation performance.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 04:11:13 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Zhang", "Jinyi", ""], ["Matsumoto", "Tadahiro", ""]]}, {"id": "1905.08949", "submitter": "Liangming Pan", "authors": "Liangming Pan, Wenqiang Lei, Tat-Seng Chua and Min-Yen Kan", "title": "Recent Advances in Neural Question Generation", "comments": "Survey of neural question generation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging research in Neural Question Generation (NQG) has started to\nintegrate a larger variety of inputs, and generating questions requiring higher\nlevels of cognition. These trends point to NQG as a bellwether for NLP, about\nhow human intelligence embodies the skills of curiosity and integration.\n  We present a comprehensive survey of neural question generation, examining\nthe corpora, methodologies, and evaluation methods. From this, we elaborate on\nwhat we see as emerging on NQG's trend: in terms of the learning paradigms,\ninput modalities, and cognitive levels considered by NQG. We end by pointing\nout the potential directions ahead.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 04:38:06 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 01:15:49 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 08:18:46 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Pan", "Liangming", ""], ["Lei", "Wenqiang", ""], ["Chua", "Tat-Seng", ""], ["Kan", "Min-Yen", ""]]}, {"id": "1905.08957", "submitter": "Helia Hashemi", "authors": "Helia Hashemi, Mohammad Aliannejadi, Hamed Zamani, W. Bruce Croft", "title": "ANTIQUE: A Non-Factoid Question Answering Benchmark", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Considering the widespread use of mobile and voice search, answer passage\nretrieval for non-factoid questions plays a critical role in modern information\nretrieval systems. Despite the importance of the task, the community still\nfeels the significant lack of large-scale non-factoid question answering\ncollections with real questions and comprehensive relevance judgments. In this\npaper, we develop and release a collection of 2,626 open-domain non-factoid\nquestions from a diverse set of categories. The dataset, called ANTIQUE,\ncontains 34,011 manual relevance annotations. The questions were asked by real\nusers in a community question answering service, i.e., Yahoo! Answers.\nRelevance judgments for all the answers to each question were collected through\ncrowdsourcing. To facilitate further research, we also include a brief analysis\nof the data as well as baseline results on both classical and recently\ndeveloped neural IR models.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 05:32:03 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 07:41:43 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Hashemi", "Helia", ""], ["Aliannejadi", "Mohammad", ""], ["Zamani", "Hamed", ""], ["Croft", "W. Bruce", ""]]}, {"id": "1905.09052", "submitter": "Gloria Feher", "authors": "Gloria Feher, Andreas Spitz, Michael Gertz", "title": "Retrieving Multi-Entity Associations: An Evaluation of Combination Modes\n  for Word Embeddings", "comments": "4 pages; Accepted at SIGIR'19", "journal-ref": null, "doi": "10.1145/3331184.3331366", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings have gained significant attention as learnable\nrepresentations of semantic relations between words, and have been shown to\nimprove upon the results of traditional word representations. However, little\neffort has been devoted to using embeddings for the retrieval of entity\nassociations beyond pairwise relations. In this paper, we use popular embedding\nmethods to train vector representations of an entity-annotated news corpus, and\nevaluate their performance for the task of predicting entity participation in\nnews events versus a traditional word cooccurrence network as a baseline. To\nsupport queries for events with multiple participating entities, we test a\nnumber of combination modes for the embedding vectors. While we find that even\nthe best combination modes for word embeddings do not quite reach the\nperformance of the full cooccurrence network, especially for rare entities, we\nobserve that different embedding methods model different types of relations,\nthereby indicating the potential for ensemble methods.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 10:13:48 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Feher", "Gloria", ""], ["Spitz", "Andreas", ""], ["Gertz", "Michael", ""]]}, {"id": "1905.09086", "submitter": "Nikola Milo\\v{s}evi\\'c Dr", "authors": "Nikola Milosevic, Dimitar Marinov, Abdullah Gok, and Goran Nenadic", "title": "From web crawled text to project descriptions: automatic summarizing of\n  social innovation projects", "comments": "Keywords: Summarization, evaluation metrics, text mining, natural\n  language processing, social innovation, SVM, neural networks Accepted for\n  publication in Proceedings of 24th International Conference on Applications\n  of Natural Language to Information Systems (NLDB2019)", "journal-ref": "Preceeding of 24th International Conference on Applications of\n  Natural Language to Information Systems (NLDB2019)", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In the past decade, social innovation projects have gained the attention of\npolicy makers, as they address important social issues in an innovative manner.\nA database of social innovation is an important source of information that can\nexpand collaboration between social innovators, drive policy and serve as an\nimportant resource for research. Such a database needs to have projects\ndescribed and summarized. In this paper, we propose and compare several methods\n(e.g. SVM-based, recurrent neural network based, ensambled) for describing\nprojects based on the text that is available on project websites. We also\naddress and propose a new metric for automated evaluation of summaries based on\ntopic modelling.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 11:49:37 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Milosevic", "Nikola", ""], ["Marinov", "Dimitar", ""], ["Gok", "Abdullah", ""], ["Nenadic", "Goran", ""]]}, {"id": "1905.09135", "submitter": "Oren Gilon", "authors": "Genady Beryozkin, Yoel Drori, Oren Gilon, Tzvika Hartman, Idan\n  Szpektor", "title": "A Joint Named-Entity Recognizer for Heterogeneous Tag-sets Using a Tag\n  Hierarchy", "comments": "Accepted at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a variant of domain adaptation for named-entity recognition where\nmultiple, heterogeneously tagged training sets are available. Furthermore, the\ntest tag-set is not identical to any individual training tag-set. Yet, the\nrelations between all tags are provided in a tag hierarchy, covering the test\ntags as a combination of training tags. This setting occurs when various\ndatasets are created using different annotation schemes. This is also the case\nof extending a tag-set with a new tag by annotating only the new tag in a new\ndataset. We propose to use the given tag hierarchy to jointly learn a neural\nnetwork that shares its tagging layer among all tag-sets. We compare this model\nto combining independent models and to a model based on the multitasking\napproach. Our experiments show the benefit of the tag-hierarchy model,\nespecially when facing non-trivial consolidation of tag-sets.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 13:40:38 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 06:22:35 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Beryozkin", "Genady", ""], ["Drori", "Yoel", ""], ["Gilon", "Oren", ""], ["Hartman", "Tzvika", ""], ["Szpektor", "Idan", ""]]}, {"id": "1905.09139", "submitter": "G\\'abor Borb\\'ely", "authors": "G\\'abor Borb\\'ely and Andr\\'as Kornai", "title": "Sentence Length", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The distribution of sentence length in ordinary language is not well captured\nby the existing models. Here we survey previous models of sentence length and\npresent our random walk model that offers both a better fit with the data and a\nbetter understanding of the distribution. We develop a generalization of KL\ndivergence, discuss measuring the noise inherent in a corpus, and present a\nhyperparameter-free Bayesian model comparison method that has strong conceptual\nties to Minimal Description Length modeling. The models we obtain require only\na few dozen bits, orders of magnitude less than the naive nonparametric MDL\nmodels would.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 13:45:05 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Borb\u00e9ly", "G\u00e1bor", ""], ["Kornai", "Andr\u00e1s", ""]]}, {"id": "1905.09153", "submitter": "Timothy Miller", "authors": "Timothy A Miller", "title": "Simplified Neural Unsupervised Domain Adaptation", "comments": "To be presented at NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain adaptation (UDA) is the task of modifying a statistical\nmodel trained on labeled data from a source domain to achieve better\nperformance on data from a target domain, with access to only unlabeled data in\nthe target domain. Existing state-of-the-art UDA approaches use neural networks\nto learn representations that can predict the values of subset of important\nfeatures called \"pivot features.\" In this work, we show that it is possible to\nimprove on these methods by jointly training the representation learner with\nthe task learner, and examine the importance of existing pivot selection\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 14:11:30 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Miller", "Timothy A", ""]]}, {"id": "1905.09217", "submitter": "Zhuyun Dai", "authors": "Zhuyun Dai and Jamie Callan", "title": "Deeper Text Understanding for IR with Contextual Neural Language\n  Modeling", "comments": "In proceedings of SIGIR 2019", "journal-ref": null, "doi": "10.1145/3331184.3331303", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks provide new possibilities to automatically learn complex\nlanguage patterns and query-document relations. Neural IR models have achieved\npromising results in learning query-document relevance patterns, but few\nexplorations have been done on understanding the text content of a query or a\ndocument. This paper studies leveraging a recently-proposed contextual neural\nlanguage model, BERT, to provide deeper text understanding for IR. Experimental\nresults demonstrate that the contextual text representations from BERT are more\neffective than traditional word embeddings. Compared to bag-of-words retrieval\nmodels, the contextual language model can better leverage language structures,\nbringing large improvements on queries written in natural languages. Combining\nthe text understanding ability with search knowledge leads to an enhanced\npre-trained BERT model that can benefit related search tasks where training\ndata are limited.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 16:11:47 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Dai", "Zhuyun", ""], ["Callan", "Jamie", ""]]}, {"id": "1905.09263", "submitter": "Yi Ren", "authors": "Yi Ren, Yangjun Ruan, Xu Tan, Tao Qin, Sheng Zhao, Zhou Zhao, Tie-Yan\n  Liu", "title": "FastSpeech: Fast, Robust and Controllable Text to Speech", "comments": "Accepted by NeurIPS2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network based end-to-end text to speech (TTS) has significantly\nimproved the quality of synthesized speech. Prominent methods (e.g., Tacotron\n2) usually first generate mel-spectrogram from text, and then synthesize speech\nfrom the mel-spectrogram using vocoder such as WaveNet. Compared with\ntraditional concatenative and statistical parametric approaches, neural network\nbased end-to-end models suffer from slow inference speed, and the synthesized\nspeech is usually not robust (i.e., some words are skipped or repeated) and\nlack of controllability (voice speed or prosody control). In this work, we\npropose a novel feed-forward network based on Transformer to generate\nmel-spectrogram in parallel for TTS. Specifically, we extract attention\nalignments from an encoder-decoder based teacher model for phoneme duration\nprediction, which is used by a length regulator to expand the source phoneme\nsequence to match the length of the target mel-spectrogram sequence for\nparallel mel-spectrogram generation. Experiments on the LJSpeech dataset show\nthat our parallel model matches autoregressive models in terms of speech\nquality, nearly eliminates the problem of word skipping and repeating in\nparticularly hard cases, and can adjust voice speed smoothly. Most importantly,\ncompared with autoregressive Transformer TTS, our model speeds up\nmel-spectrogram generation by 270x and the end-to-end speech synthesis by 38x.\nTherefore, we call our model FastSpeech.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 17:50:21 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 17:32:34 GMT"}, {"version": "v3", "created": "Sun, 26 May 2019 07:27:40 GMT"}, {"version": "v4", "created": "Wed, 29 May 2019 15:54:15 GMT"}, {"version": "v5", "created": "Wed, 20 Nov 2019 09:37:22 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Ren", "Yi", ""], ["Ruan", "Yangjun", ""], ["Tan", "Xu", ""], ["Qin", "Tao", ""], ["Zhao", "Sheng", ""], ["Zhao", "Zhou", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1905.09418", "submitter": "Elena Voita", "authors": "Elena Voita, David Talbot, Fedor Moiseev, Rico Sennrich, Ivan Titov", "title": "Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy\n  Lifting, the Rest Can Be Pruned", "comments": "ACL 2019 (camera-ready)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-head self-attention is a key component of the Transformer, a\nstate-of-the-art architecture for neural machine translation. In this work we\nevaluate the contribution made by individual attention heads in the encoder to\nthe overall performance of the model and analyze the roles played by them. We\nfind that the most important and confident heads play consistent and often\nlinguistically-interpretable roles. When pruning heads using a method based on\nstochastic gates and a differentiable relaxation of the L0 penalty, we observe\nthat specialized heads are last to be pruned. Our novel pruning method removes\nthe vast majority of heads without seriously affecting performance. For\nexample, on the English-Russian WMT dataset, pruning 38 out of 48 encoder heads\nresults in a drop of only 0.15 BLEU.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 01:13:24 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 14:00:58 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Voita", "Elena", ""], ["Talbot", "David", ""], ["Moiseev", "Fedor", ""], ["Sennrich", "Rico", ""], ["Titov", "Ivan", ""]]}, {"id": "1905.09438", "submitter": "Alexander Long", "authors": "Alex Long, Joel Mason, Alan Blair, Wei Wang", "title": "Multi-hop Reading Comprehension via Deep Reinforcement Learning based\n  Document Traversal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reading Comprehension has received significant attention in recent years as\nhigh quality Question Answering (QA) datasets have become available. Despite\nstate-of-the-art methods achieving strong overall accuracy, Multi-Hop (MH)\nreasoning remains particularly challenging. To address MH-QA specifically, we\npropose a Deep Reinforcement Learning based method capable of learning\nsequential reasoning across large collections of documents so as to pass a\nquery-aware, fixed-size context subset to existing models for answer\nextraction. Our method is comprised of two stages: a linker, which decomposes\nthe provided support documents into a graph of sentences, and an extractor,\nwhich learns where to look based on the current question and already-visited\nsentences. The result of the linker is a novel graph structure at the sentence\nlevel that preserves logical flow while still allowing rapid movement between\ndocuments. Importantly, we demonstrate that the sparsity of the resultant graph\nis invariant to context size. This translates to fewer decisions required from\nthe Deep-RL trained extractor, allowing the system to scale effectively to\nlarge collections of documents.\n  The importance of sequential decision making in the document traversal step\nis demonstrated by comparison to standard IE methods, and we additionally\nintroduce a BM25-based IR baseline that retrieves documents relevant to the\nquery only. We examine the integration of our method with existing models on\nthe recently proposed QAngaroo benchmark and achieve consistent increases in\naccuracy across the board, as well as a 2-3x reduction in training time.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 02:32:34 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Long", "Alex", ""], ["Mason", "Joel", ""], ["Blair", "Alan", ""], ["Wang", "Wei", ""]]}, {"id": "1905.09439", "submitter": "Shabnam Tafreshi", "authors": "Shabnam Tafreshi, Mona Diab", "title": "GWU NLP Lab at SemEval-2019 Task 3: EmoContext: Effective Contextual\n  Information in Models for Emotion Detection in Sentence-level in a Multigenre\n  Corpus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present an emotion classifier model submitted to the\nSemEval-2019 Task 3: EmoContext. The task objective is to classify emotion\n(i.e. happy, sad, angry) in a 3-turn conversational data set. We formulate the\ntask as a classification problem and introduce a Gated Recurrent Neural Network\n(GRU) model with attention layer, which is bootstrapped with contextual\ninformation and trained with a multigenre corpus. We utilize different word\nembeddings to empirically select the most suited one to represent our features.\nWe train the model with a multigenre emotion corpus to leverage using all\navailable training sets to bootstrap the results. We achieved overall %56.05\nf1-score and placed 144.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 02:52:10 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Tafreshi", "Shabnam", ""], ["Diab", "Mona", ""]]}, {"id": "1905.09531", "submitter": "Simon Ostermann", "authors": "Simon Ostermann and Michael Roth and Manfred Pinkal", "title": "MCScript2.0: A Machine Comprehension Corpus Focused on Script Events and\n  Participants", "comments": "Accepted at *SEM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce MCScript2.0, a machine comprehension corpus for the end-to-end\nevaluation of script knowledge. MCScript2.0 contains approx. 20,000 questions\non approx. 3,500 texts, crowdsourced based on a new collection process that\nresults in challenging questions. Half of the questions cannot be answered from\nthe reading texts, but require the use of commonsense and, in particular,\nscript knowledge. We give a thorough analysis of our corpus and show that while\nthe task is not challenging to humans, existing machine comprehension models\nfail to perform well on the data, even if they make use of a commonsense\nknowledge base. The dataset is available at\nhttp://www.sfb1102.uni-saarland.de/?page_id=2582\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 08:33:56 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 11:29:56 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Ostermann", "Simon", ""], ["Roth", "Michael", ""], ["Pinkal", "Manfred", ""]]}, {"id": "1905.09557", "submitter": "Jinkui Yao", "authors": "Jinkui Yao and Lianghua Xu", "title": "Knowledge Graph Embedding Bi-Vector Models for Symmetric Relation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph embedding (KGE) models have been proposed to improve the\nperformance of knowledge graph reasoning. However, there is a general\nphenomenon in most of KGEs, as the training progresses, the symmetric relations\ntend to zero vector, if the symmetric triples ratio is high enough in the\ndataset. This phenomenon causes subsequent tasks, e.g. link prediction etc., of\nsymmetric relations to fail. The root cause of the problem is that KGEs do not\nutilize the semantic information of symmetric relations. We propose KGE\nbi-vector models, which represent the symmetric relations as vector pair,\nsignificantly increasing the processing capability of the symmetry relations.\nWe generate the benchmark datasets based on FB15k and WN18 by completing the\nsymmetric relation triples to verify models. The experiment results of our\nmodels clearly affirm the effectiveness and superiority of our models against\nbaseline.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 09:44:50 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Yao", "Jinkui", ""], ["Xu", "Lianghua", ""]]}, {"id": "1905.09642", "submitter": "Enkhbold Bataa", "authors": "Enkhbold Bataa and Joshua Wu", "title": "An Investigation of Transfer Learning-Based Sentiment Analysis in\n  Japanese", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Text classification approaches have usually required task-specific model\narchitectures and huge labeled datasets. Recently, thanks to the rise of\ntext-based transfer learning techniques, it is possible to pre-train a language\nmodel in an unsupervised manner and leverage them to perform effective on\ndownstream tasks. In this work we focus on Japanese and show the potential use\nof transfer learning techniques in text classification. Specifically, we\nperform binary and multi-class sentiment classification on the Rakuten product\nreview and Yahoo movie review datasets. We show that transfer learning-based\napproaches perform better than task-specific models trained on 3 times as much\ndata. Furthermore, these approaches perform just as well for language modeling\npre-trained on only 1/30 of the data. We release our pre-trained models and\ncode as open source.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 13:24:15 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 02:07:41 GMT"}, {"version": "v3", "created": "Fri, 7 Jun 2019 08:58:17 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Bataa", "Enkhbold", ""], ["Wu", "Joshua", ""]]}, {"id": "1905.09755", "submitter": "Bora Edizel", "authors": "Bora Edizel, Aleksandra Piktus, Piotr Bojanowski, Rui Ferreira,\n  Edouard Grave, Fabrizio Silvestri", "title": "Misspelling Oblivious Word Embeddings", "comments": "9 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a method to learn word embeddings that are resilient\nto misspellings. Existing word embeddings have limited applicability to\nmalformed texts, which contain a non-negligible amount of out-of-vocabulary\nwords. We propose a method combining FastText with subwords and a supervised\ntask of learning misspelling patterns. In our method, misspellings of each word\nare embedded close to their correct variants. We train these embeddings on a\nnew dataset we are releasing publicly. Finally, we experimentally show the\nadvantages of this approach on both intrinsic and extrinsic NLP tasks using\npublic test sets.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 16:28:08 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Edizel", "Bora", ""], ["Piktus", "Aleksandra", ""], ["Bojanowski", "Piotr", ""], ["Ferreira", "Rui", ""], ["Grave", "Edouard", ""], ["Silvestri", "Fabrizio", ""]]}, {"id": "1905.09761", "submitter": "Md Faisal Mahbub Chowdhury", "authors": "Md Faisal Mahbub Chowdhury, Robert Farrell", "title": "An Efficient Approach for Super and Nested Term Indexing and Retrieval", "comments": "6 pages including references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes a new approach, called Terminological Bucket Indexing\n(TBI), for efficient indexing and retrieval of both nested and super terms\nusing a single method. We propose a hybrid data structure for facilitating\nfaster indexing building. An evaluation of our approach with respect to widely\nused existing approaches on several publicly available dataset is provided.\nCompared to Trie based approaches, TBI provides comparable performance on\nnested term retrieval and far superior performance on super term retrieval.\nCompared to traditional hash table, TBI needs 80\\% less time for indexing.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 16:33:30 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Chowdhury", "Md Faisal Mahbub", ""], ["Farrell", "Robert", ""]]}, {"id": "1905.09856", "submitter": "Andriy Drozdyuk", "authors": "Vasileios Lioutas and Andriy Drozdyuk", "title": "Copy this Sentence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention is an operation that selects some largest element from some set,\nwhere the notion of largest is defined elsewhere. Applying this operation to\nsequence to sequence mapping results in significant improvements to the task at\nhand. In this paper we provide the mathematical definition of attention and\nexamine its application to sequence to sequence models. We highlight the exact\ncorrespondences between machine learning implementations of attention and our\nmathematical definition. We provide clear evidence of effectiveness of\nattention mechanisms evaluating models with varying degrees of attention on a\nvery simple task: copying a sentence. We find that models that make greater use\nof attention perform much better on sequence to sequence mapping tasks,\nconverge faster and are more stable.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 18:25:35 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Lioutas", "Vasileios", ""], ["Drozdyuk", "Andriy", ""]]}, {"id": "1905.09864", "submitter": "Varun Kumar", "authors": "Varun Kumar, Alison Smith-Renner, Leah Findlater, Kevin Seppi and\n  Jordan Boyd-Graber", "title": "Why Didn't You Listen to Me? Comparing User Control of Human-in-the-Loop\n  Topic Models", "comments": "In proceedings of ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To address the lack of comparative evaluation of Human-in-the-Loop Topic\nModeling (HLTM) systems, we implement and evaluate three contrasting HLTM\nmodeling approaches using simulation experiments. These approaches extend\npreviously proposed frameworks, including constraints and informed prior-based\nmethods. Users should have a sense of control in HLTM systems, so we propose a\ncontrol metric to measure whether refinement operations' results match users'\nexpectations. Informed prior-based methods provide better control than\nconstraints, but constraints yield higher quality topics.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 18:40:57 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 02:24:03 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Kumar", "Varun", ""], ["Smith-Renner", "Alison", ""], ["Findlater", "Leah", ""], ["Seppi", "Kevin", ""], ["Boyd-Graber", "Jordan", ""]]}, {"id": "1905.09866", "submitter": "Rik van Noord", "authors": "Malvina Nissim, Rik van Noord and Rob van der Goot", "title": "Fair is Better than Sensational:Man is to Doctor as Woman is to Doctor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analogies such as \"man is to king as woman is to X\" are often used to\nillustrate the amazing power of word embeddings. Concurrently, they have also\nbeen used to expose how strongly human biases are encoded in vector spaces\nbuilt on natural language, like \"man is to computer programmer as woman is to\nhomemaker\". Recent work has shown that analogies are in fact not such a\ndiagnostic for bias, and other methods have been proven to be more apt to the\ntask. However, beside the intrinsic problems with the analogy task as a bias\ndetection tool, in this paper we show that a series of issues related to how\nanalogies have been implemented and used might have yielded a distorted picture\nof bias in word embeddings. Human biases are present in word embeddings and\nneed to be addressed. Analogies, though, are probably not the right tool to do\nso. Also, the way they have been most often used has exacerbated some possibly\nnon-existing biases and perhaps hid others. Because they are still widely\npopular, and some of them have become classics within and outside the NLP\ncommunity, we deem it important to provide a series of clarifications that\nshould put well-known, and potentially new cases into the right perspective.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 18:43:59 GMT"}, {"version": "v2", "created": "Sat, 9 Nov 2019 20:12:51 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Nissim", "Malvina", ""], ["van Noord", "Rik", ""], ["van der Goot", "Rob", ""]]}, {"id": "1905.09922", "submitter": "Mihaela Rosca", "authors": "Cyprien de Masson d'Autume, Mihaela Rosca, Jack Rae and Shakir Mohamed", "title": "Training language GANs from Scratch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) enjoy great success at image\ngeneration, but have proven difficult to train in the domain of natural\nlanguage. Challenges with gradient estimation, optimization instability, and\nmode collapse have lead practitioners to resort to maximum likelihood\npre-training, followed by small amounts of adversarial fine-tuning. The\nbenefits of GAN fine-tuning for language generation are unclear, as the\nresulting models produce comparable or worse samples than traditional language\nmodels. We show it is in fact possible to train a language GAN from scratch --\nwithout maximum likelihood pre-training. We combine existing techniques such as\nlarge batch sizes, dense rewards and discriminator regularization to stabilize\nand improve language GANs. The resulting model, ScratchGAN, performs comparably\nto maximum likelihood training on EMNLP2017 News and WikiText-103 corpora\naccording to quality and diversity metrics.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 21:01:24 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 16:43:40 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["d'Autume", "Cyprien de Masson", ""], ["Rosca", "Mihaela", ""], ["Rae", "Jack", ""], ["Mohamed", "Shakir", ""]]}, {"id": "1905.09998", "submitter": "Jialin Wu", "authors": "Jialin Wu and Raymond J. Mooney", "title": "Self-Critical Reasoning for Robust Visual Question Answering", "comments": "In NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual Question Answering (VQA) deep-learning systems tend to capture\nsuperficial statistical correlations in the training data because of strong\nlanguage priors and fail to generalize to test data with a significantly\ndifferent question-answer (QA) distribution. To address this issue, we\nintroduce a self-critical training objective that ensures that visual\nexplanations of correct answers match the most influential image regions more\nthan other competitive answer candidates. The influential regions are either\ndetermined from human visual/textual explanations or automatically from just\nsignificant words in the question and answer. We evaluate our approach on the\nVQA generalization task using the VQA-CP dataset, achieving a new\nstate-of-the-art i.e., 49.5% using textual explanations and 48.5% using\nautomatically annotated regions.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 01:52:31 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 17:47:23 GMT"}, {"version": "v3", "created": "Mon, 30 Dec 2019 06:33:21 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Wu", "Jialin", ""], ["Mooney", "Raymond J.", ""]]}, {"id": "1905.10024", "submitter": "Antonios Anastasopoulos", "authors": "Antonios Anastasopoulos", "title": "An Analysis of Source-Side Grammatical Errors in NMT", "comments": "Accepted and to be presented at BlackboxNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quality of Neural Machine Translation (NMT) has been shown to\nsignificantly degrade when confronted with source-side noise. We present the\nfirst large-scale study of state-of-the-art English-to-German NMT on real\ngrammatical noise, by evaluating on several Grammar Correction corpora. We\npresent methods for evaluating NMT robustness without true references, and we\nuse them for extensive analysis of the effects that different grammatical\nerrors have on the NMT output. We also introduce a technique for visualizing\nthe divergence distribution caused by a source-side error, which allows for\nadditional insights.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 04:16:46 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Anastasopoulos", "Antonios", ""]]}, {"id": "1905.10033", "submitter": "Andrea Madotto Mr", "authors": "Zhaojiang Lin, Andrea Madotto, Chien-Sheng Wu, Pascale Fung", "title": "Personalizing Dialogue Agents via Meta-Learning", "comments": "Accepted in ACL 2019. Zhaojiang Lin* and Andrea Madotto* contributed\n  equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing personalized dialogue models use human designed persona descriptions\nto improve dialogue consistency. Collecting such descriptions from existing\ndialogues is expensive and requires hand-crafted feature designs. In this\npaper, we propose to extend Model-Agnostic Meta-Learning (MAML)(Finn et al.,\n2017) to personalized dialogue learning without using any persona descriptions.\nOur model learns to quickly adapt to new personas by leveraging only a few\ndialogue samples collected from the same user, which is fundamentally different\nfrom conditioning the response on the persona descriptions. Empirical results\non Persona-chat dataset (Zhang et al., 2018) indicate that our solution\noutperforms non-meta-learning baselines using automatic evaluation metrics, and\nin terms of human-evaluated fluency and consistency.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 05:01:14 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Lin", "Zhaojiang", ""], ["Madotto", "Andrea", ""], ["Wu", "Chien-Sheng", ""], ["Fung", "Pascale", ""]]}, {"id": "1905.10039", "submitter": "Ruqing Zhang", "authors": "Ruqing Zhang, Jiafeng Guo, Yixing Fan, Yanyan Lan, and Xueqi Cheng", "title": "Outline Generation: Understanding the Inherent Content Structure of\n  Documents", "comments": "10 pages, Long paper accepted by SIGIR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce and tackle the Outline Generation (OG) task,\nwhich aims to unveil the inherent content structure of a multi-paragraph\ndocument by identifying its potential sections and generating the corresponding\nsection headings. Without loss of generality, the OG task can be viewed as a\nnovel structured summarization task. To generate a sound outline, an ideal OG\nmodel should be able to capture three levels of coherence, namely the coherence\nbetween context paragraphs, that between a section and its heading, and that\nbetween context headings. The first one is the foundation for section\nidentification, while the latter two are critical for consistent heading\ngeneration. In this work, we formulate the OG task as a hierarchical structured\nprediction problem, i.e., to first predict a sequence of section boundaries and\nthen a sequence of section headings accordingly. We propose a novel\nhierarchical structured neural generation model, named HiStGen, for the task.\nOur model attempts to capture the three-level coherence via the following ways.\nFirst, we introduce a Markov paragraph dependency mechanism between context\nparagraphs for section identification. Second, we employ a section-aware\nattention mechanism to ensure the semantic coherence between a section and its\nheading. Finally, we leverage a Markov heading dependency mechanism and a\nreview mechanism between context headings to improve the consistency and\neliminate duplication between section headings. Besides, we build a novel\nWIKIOG dataset, a public collection which consists of over 1.75 million\ndocument-outline pairs for research on the OG task. Experimental results on our\nbenchmark dataset demonstrate that our model can significantly outperform\nseveral state-of-the-art sequential generation models for the OG task.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 05:29:33 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Zhang", "Ruqing", ""], ["Guo", "Jiafeng", ""], ["Fan", "Yixing", ""], ["Lan", "Yanyan", ""], ["Cheng", "Xueqi", ""]]}, {"id": "1905.10044", "submitter": "Christopher Clark", "authors": "Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski,\n  Michael Collins, Kristina Toutanova", "title": "BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions", "comments": "In NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study yes/no questions that are naturally occurring ---\nmeaning that they are generated in unprompted and unconstrained settings. We\nbuild a reading comprehension dataset, BoolQ, of such questions, and show that\nthey are unexpectedly challenging. They often query for complex, non-factoid\ninformation, and require difficult entailment-like inference to solve. We also\nexplore the effectiveness of a range of transfer learning baselines. We find\nthat transferring from entailment data is more effective than transferring from\nparaphrase or extractive QA data, and that it, surprisingly, continues to be\nvery beneficial even when starting from massive pre-trained language models\nsuch as BERT. Our best method trains BERT on MultiNLI and then re-trains it on\nour train set. It achieves 80.4% accuracy compared to 90% accuracy of human\nannotators (and 62% majority-baseline), leaving a significant gap for future\nwork.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 05:48:49 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Clark", "Christopher", ""], ["Lee", "Kenton", ""], ["Chang", "Ming-Wei", ""], ["Kwiatkowski", "Tom", ""], ["Collins", "Michael", ""], ["Toutanova", "Kristina", ""]]}, {"id": "1905.10060", "submitter": "Fuli Luo", "authors": "Fuli Luo, Peng Li, Jie Zhou, Pengcheng Yang, Baobao Chang, Zhifang\n  Sui, Xu Sun", "title": "A Dual Reinforcement Learning Framework for Unsupervised Text Style\n  Transfer", "comments": "Accepted by IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised text style transfer aims to transfer the underlying style of\ntext but keep its main content unchanged without parallel data. Most existing\nmethods typically follow two steps: first separating the content from the\noriginal style, and then fusing the content with the desired style. However,\nthe separation in the first step is challenging because the content and style\ninteract in subtle ways in natural language. Therefore, in this paper, we\npropose a dual reinforcement learning framework to directly transfer the style\nof the text via a one-step mapping model, without any separation of content and\nstyle. Specifically, we consider the learning of the source-to-target and\ntarget-to-source mappings as a dual task, and two rewards are designed based on\nsuch a dual structure to reflect the style accuracy and content preservation,\nrespectively. In this way, the two one-step mapping models can be trained via\nreinforcement learning, without any use of parallel data. Automatic evaluations\nshow that our model outperforms the state-of-the-art systems by a large margin,\nespecially with more than 8 BLEU points improvement averaged on two benchmark\ndatasets. Human evaluations also validate the effectiveness of our model in\nterms of style accuracy, content preservation and fluency. Our code and data,\nincluding outputs of all baselines and our model are available at\nhttps://github.com/luofuli/DualLanST.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 07:02:05 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Luo", "Fuli", ""], ["Li", "Peng", ""], ["Zhou", "Jie", ""], ["Yang", "Pengcheng", ""], ["Chang", "Baobao", ""], ["Sui", "Zhifang", ""], ["Sun", "Xu", ""]]}, {"id": "1905.10072", "submitter": "Dayiheng Liu", "authors": "Dayiheng Liu, Xu Yang, Feng He, Yuanyuan Chen, Jiancheng Lv", "title": "mu-Forcing: Training Variational Recurrent Autoencoders for Text\n  Generation", "comments": "To appear in the ACM Transactions on Asian and Low-Resource Language\n  Information Processing (TALLIP)", "journal-ref": null, "doi": "10.1145/3341110", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been previously observed that training Variational Recurrent\nAutoencoders (VRAE) for text generation suffers from serious uninformative\nlatent variables problem. The model would collapse into a plain language model\nthat totally ignore the latent variables and can only generate repeating and\ndull samples. In this paper, we explore the reason behind this issue and\npropose an effective regularizer based approach to address it. The proposed\nmethod directly injects extra constraints on the posteriors of latent variables\ninto the learning process of VRAE, which can flexibly and stably control the\ntrade-off between the KL term and the reconstruction term, making the model\nlearn dense and meaningful latent representations. The experimental results\nshow that the proposed method outperforms several strong baselines and can make\nthe model learn interpretable latent variables and generate diverse meaningful\nsentences. Furthermore, the proposed method can perform well without using\nother strategies, such as KL annealing.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 07:32:37 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Liu", "Dayiheng", ""], ["Yang", "Xu", ""], ["He", "Feng", ""], ["Chen", "Yuanyuan", ""], ["Lv", "Jiancheng", ""]]}, {"id": "1905.10077", "submitter": "Lixin Su", "authors": "Lixin Su, Jiafeng Guo, Yixing Fan, Yanyan Lan, and Xueqi Cheng", "title": "Controlling Risk of Web Question Answering", "comments": "42nd International ACM SIGIR Conference on Research and Development\n  in Information Retrieval", "journal-ref": null, "doi": "10.1145/3331184.3331261", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web question answering (QA) has become an indispensable component in modern\nsearch systems, which can significantly improve users' search experience by\nproviding a direct answer to users' information need. This could be achieved by\napplying machine reading comprehension (MRC) models over the retrieved passages\nto extract answers with respect to the search query. With the development of\ndeep learning techniques, state-of-the-art MRC performances have been achieved\nby recent deep methods. However, existing studies on MRC seldom address the\npredictive uncertainty issue, i.e., how likely the prediction of an MRC model\nis wrong, leading to uncontrollable risks in real-world Web QA applications. In\nthis work, we first conduct an in-depth investigation over the risk of Web QA.\nWe then introduce a novel risk control framework, which consists of a qualify\nmodel for uncertainty estimation using the probe idea, and a decision model for\nselectively output. For evaluation, we introduce risk-related metrics, rather\nthan the traditional EM and F1 in MRC, for the evaluation of risk-aware Web QA.\nThe empirical results over both the real-world Web QA dataset and the academic\nMRC benchmark collection demonstrate the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 07:55:42 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 02:24:32 GMT"}, {"version": "v3", "created": "Thu, 11 Jul 2019 05:10:47 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Su", "Lixin", ""], ["Guo", "Jiafeng", ""], ["Fan", "Yixing", ""], ["Lan", "Yanyan", ""], ["Cheng", "Xueqi", ""]]}, {"id": "1905.10238", "submitter": "Hongming Zhang", "authors": "Hongming Zhang, Yan Song, Yangqiu Song", "title": "Incorporating Context and External Knowledge for Pronoun Coreference\n  Resolution", "comments": "Accepted by NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linking pronominal expressions to the correct references requires, in many\ncases, better analysis of the contextual information and external knowledge. In\nthis paper, we propose a two-layer model for pronoun coreference resolution\nthat leverages both context and external knowledge, where a knowledge attention\nmechanism is designed to ensure the model leveraging the appropriate source of\nexternal knowledge based on different context. Experimental results demonstrate\nthe validity and effectiveness of our model, where it outperforms\nstate-of-the-art models by a large margin.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 13:52:14 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Zhang", "Hongming", ""], ["Song", "Yan", ""], ["Song", "Yangqiu", ""]]}, {"id": "1905.10247", "submitter": "Igor Shalyminov", "authors": "Sungjin Lee, Igor Shalyminov", "title": "Contextual Out-of-Domain Utterance Handling With Counterfeit Data\n  Augmentation", "comments": "ICASSP 2019", "journal-ref": null, "doi": "10.1109/ICASSP.2019.8683019", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural dialog models often lack robustness to anomalous user input and\nproduce inappropriate responses which leads to frustrating user experience.\nAlthough there are a set of prior approaches to out-of-domain (OOD) utterance\ndetection, they share a few restrictions: they rely on OOD data or multiple\nsub-domains, and their OOD detection is context-independent which leads to\nsuboptimal performance in a dialog. The goal of this paper is to propose a\nnovel OOD detection method that does not require OOD data by utilizing\ncounterfeit OOD turns in the context of a dialog. For the sake of fostering\nfurther research, we also release new dialog datasets which are 3 publicly\navailable dialog corpora augmented with OOD turns in a controllable way. Our\nmethod outperforms state-of-the-art dialog models equipped with a conventional\nOOD detection mechanism by a large margin in the presence of OOD utterances.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 14:18:18 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Lee", "Sungjin", ""], ["Shalyminov", "Igor", ""]]}, {"id": "1905.10289", "submitter": "Yixing Fan", "authors": "Jiafeng Guo, Yixing Fan, Xiang Ji and Xueqi Cheng", "title": "MatchZoo: A Learning, Practicing, and Developing System for Neural Text\n  Matching", "comments": null, "journal-ref": "Proceedings of the 42nd International ACM SIGIR Conference on\n  Research and Development in Information Retrieval (SIGIR '19), July 21--25,\n  2019, Paris, France", "doi": "10.1145/3331184.3331403", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text matching is the core problem in many natural language processing (NLP)\ntasks, such as information retrieval, question answering, and conversation.\nRecently, deep leaning technology has been widely adopted for text matching,\nmaking neural text matching a new and active research domain. With a large\nnumber of neural matching models emerging rapidly, it becomes more and more\ndifficult for researchers, especially those newcomers, to learn and understand\nthese new models. Moreover, it is usually difficult to try these models due to\nthe tedious data pre-processing, complicated parameter configuration, and\nmassive optimization tricks, not to mention the unavailability of public codes\nsometimes. Finally, for researchers who want to develop new models, it is also\nnot an easy task to implement a neural text matching model from scratch, and to\ncompare with a bunch of existing models. In this paper, therefore, we present a\nnovel system, namely MatchZoo, to facilitate the learning, practicing and\ndesigning of neural text matching models. The system consists of a powerful\nmatching library and a user-friendly and interactive studio, which can help\nresearchers: 1) to learn state-of-the-art neural text matching models\nsystematically, 2) to train, test and apply these models with simple\nconfigurable steps; and 3) to develop their own models with rich APIs and\nassistance.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 15:34:54 GMT"}, {"version": "v2", "created": "Wed, 24 Jul 2019 10:08:49 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Guo", "Jiafeng", ""], ["Fan", "Yixing", ""], ["Ji", "Xiang", ""], ["Cheng", "Xueqi", ""]]}, {"id": "1905.10348", "submitter": "Andre Lage-Freitas Dr.", "authors": "Andr\\'e Lage-Freitas and H\\'ector Allende-Cid and Orivaldo Santana and\n  L\\'ivia de Oliveira-Lage", "title": "Predicting Brazilian court decisions", "comments": "4 double-column pages, 1 figure, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting case outcomes is useful but still an extremely hard task for\nattorneys and other Law professionals. It is not easy to search case\ninformation to extract valuable information as this requires dealing with huge\ndata sets and their complexity. For instance, the complexity of Brazil legal\nsystem along with the high litigation rates makes this problem even harder.\nThis paper introduces an approach for predicting Brazilian court decisions\nwhich is also able to predict whether the decision will be unanimous. We\ndeveloped a working prototype which performs 79% of accuracy (F1-score) on a\ndata set composed of 4,043 cases from a Brazilian court. To our knowledge, this\nis the first study to forecast judge decisions in Brazil.\n", "versions": [{"version": "v1", "created": "Sat, 20 Apr 2019 15:55:13 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Lage-Freitas", "Andr\u00e9", ""], ["Allende-Cid", "H\u00e9ctor", ""], ["Santana", "Orivaldo", ""], ["de Oliveira-Lage", "L\u00edvia", ""]]}, {"id": "1905.10412", "submitter": "Numa Dhamani", "authors": "Numa Dhamani, Paul Azunre, Jeffrey L. Gleason, Craig Corcoran, Garrett\n  Honke, Steve Kramer, Jonathon Morgan", "title": "Using Deep Networks and Transfer Learning to Address Disinformation", "comments": "AI for Social Good Workshop at the International Conference on\n  Machine Learning, Long Beach, United States (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply an ensemble pipeline composed of a character-level convolutional\nneural network (CNN) and a long short-term memory (LSTM) as a general tool for\naddressing a range of disinformation problems. We also demonstrate the ability\nto use this architecture to transfer knowledge from labeled data in one domain\nto related (supervised and unsupervised) tasks. Character-level neural networks\nand transfer learning are particularly valuable tools in the disinformation\nspace because of the messy nature of social media, lack of labeled data, and\nthe multi-channel tactics of influence campaigns. We demonstrate their\neffectiveness in several tasks relevant for detecting disinformation: spam\nemails, review bombing, political sentiment, and conversation clustering.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 19:10:18 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Dhamani", "Numa", ""], ["Azunre", "Paul", ""], ["Gleason", "Jeffrey L.", ""], ["Corcoran", "Craig", ""], ["Honke", "Garrett", ""], ["Kramer", "Steve", ""], ["Morgan", "Jonathon", ""]]}, {"id": "1905.10417", "submitter": "Haitian Sun", "authors": "William W. Cohen, Haitian Sun, R. Alex Hofer, Matthew Siegler", "title": "Differentiable Representations For Multihop Inference Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present efficient differentiable implementations of second-order multi-hop\nreasoning using a large symbolic knowledge base (KB). We introduce a new\noperation which can be used to compositionally construct second-order multi-hop\ntemplates in a neural model, and evaluate a number of alternative\nimplementations, with different time and memory trade offs. These techniques\nscale to KBs with millions of entities and tens of millions of triples, and\nlead to simple models with competitive performance on several learning tasks\nrequiring multi-hop reasoning.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 19:20:03 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Cohen", "William W.", ""], ["Sun", "Haitian", ""], ["Hofer", "R. Alex", ""], ["Siegler", "Matthew", ""]]}, {"id": "1905.10425", "submitter": "Nikita Nangia", "authors": "Nikita Nangia and Samuel R. Bowman", "title": "Human vs. Muppet: A Conservative Estimate of Human Performance on the\n  GLUE Benchmark", "comments": null, "journal-ref": "ACL 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The GLUE benchmark (Wang et al., 2019b) is a suite of language understanding\ntasks which has seen dramatic progress in the past year, with average\nperformance moving from 70.0 at launch to 83.9, state of the art at the time of\nwriting (May 24, 2019). Here, we measure human performance on the benchmark, in\norder to learn whether significant headroom remains for further progress. We\nprovide a conservative estimate of human performance on the benchmark through\ncrowdsourcing: Our annotators are non-experts who must learn each task from a\nbrief set of instructions and 20 examples. In spite of limited training, these\nannotators robustly outperform the state of the art on six of the nine GLUE\ntasks and achieve an average score of 87.1. Given the fast pace of progress\nhowever, the headroom we observe is quite limited. To reproduce the data-poor\nsetting that our annotators must learn in, we also train the BERT model (Devlin\net al., 2019) in limited-data regimes, and conclude that low-resource sentence\nclassification remains a challenge for modern neural network approaches to text\nunderstanding.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 19:55:34 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 16:36:05 GMT"}, {"version": "v3", "created": "Sat, 1 Jun 2019 20:35:31 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Nangia", "Nikita", ""], ["Bowman", "Samuel R.", ""]]}, {"id": "1905.10431", "submitter": "Ethan Wilcox", "authors": "Ethan Wilcox, Roger Levy, Richard Futrell", "title": "What Syntactic Structures block Dependencies in RNN Language Models?", "comments": "To Appear at the 41st Annual Meeting of the Cognitive Science\n  Society, Montreal, Canada, July 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) trained on a language modeling task have\nbeen shown to acquire a number of non-local grammatical dependencies with some\nsuccess. Here, we provide new evidence that RNN language models are sensitive\nto hierarchical syntactic structure by investigating the filler--gap dependency\nand constraints on it, known as syntactic islands. Previous work is\ninconclusive about whether RNNs learn to attenuate their expectations for gaps\nin island constructions in particular or in any sufficiently complex syntactic\nenvironment. This paper gives new evidence for the former by providing control\nstudies that have been lacking so far. We demonstrate that two state-of-the-art\nRNN models are are able to maintain the filler--gap dependency through\nunbounded sentential embeddings and are also sensitive to the hierarchical\nrelationship between the filler and the gap. Next, we demonstrate that the\nmodels are able to maintain possessive pronoun gender expectations through\nisland constructions---this control case rules out the possibility that island\nconstructions block all information flow in these networks. We also evaluate\nthree untested islands constraints: coordination islands, left branch islands,\nand sentential subject islands. Models are able to learn left branch islands\nand learn coordination islands gradiently, but fail to learn sentential subject\nislands. Through these controls and new tests, we provide evidence that model\nbehavior is due to finer-grained expectations than gross syntactic complexity,\nbut also that the models are conspicuously un-humanlike in some of their\nperformance characteristics.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 20:06:04 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Wilcox", "Ethan", ""], ["Levy", "Roger", ""], ["Futrell", "Richard", ""]]}, {"id": "1905.10453", "submitter": "Shuoyang Ding", "authors": "Shuoyang Ding, Adithya Renduchintala, Kevin Duh", "title": "A Call for Prudent Choice of Subword Merge Operations in Neural Machine\n  Translation", "comments": "Accepted to MT Summit 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most neural machine translation systems are built upon subword units\nextracted by methods such as Byte-Pair Encoding (BPE) or wordpiece. However,\nthe choice of number of merge operations is generally made by following\nexisting recipes. In this paper, we conduct a systematic exploration on\ndifferent numbers of BPE merge operations to understand how it interacts with\nthe model architecture, the strategy to build vocabularies and the language\npair. Our exploration could provide guidance for selecting proper BPE\nconfigurations in the future. Most prominently: we show that for LSTM-based\narchitectures, it is necessary to experiment with a wide range of different BPE\noperations as there is no typical optimal BPE configuration, whereas for\nTransformer architectures, smaller BPE size tends to be a typically optimal\nchoice. We urge the community to make prudent choices with subword merge\noperations, as our experiments indicate that a sub-optimal BPE configuration\nalone could easily reduce the system performance by 3-4 BLEU points.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 21:32:28 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 19:52:08 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Ding", "Shuoyang", ""], ["Renduchintala", "Adithya", ""], ["Duh", "Kevin", ""]]}, {"id": "1905.10464", "submitter": "Mamoru Komachi", "authors": "Tosho Hirasawa and Mamoru Komachi", "title": "Debiasing Word Embeddings Improves Multimodal Machine Translation", "comments": "11 pages; MT Summit 2019 (camera ready)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, pretrained word embeddings have proved useful for multimodal\nneural machine translation (NMT) models to address the shortage of available\ndatasets. However, the integration of pretrained word embeddings has not yet\nbeen explored extensively. Further, pretrained word embeddings in high\ndimensional spaces have been reported to suffer from the hubness problem.\nAlthough some debiasing techniques have been proposed to address this problem\nfor other natural language processing tasks, they have seldom been studied for\nmultimodal NMT models. In this study, we examine various kinds of word\nembeddings and introduce two debiasing techniques for three multimodal NMT\nmodels and two language pairs -- English-German translation and English-French\ntranslation. With our optimal settings, the overall performance of multimodal\nmodels was improved by up to +1.93 BLEU and +2.02 METEOR for English-German\ntranslation and +1.73 BLEU and +0.95 METEOR for English-French translation.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 22:11:57 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 22:46:58 GMT"}, {"version": "v3", "created": "Sat, 22 Jun 2019 07:50:03 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Hirasawa", "Tosho", ""], ["Komachi", "Mamoru", ""]]}, {"id": "1905.10486", "submitter": "Henry Elder", "authors": "Henry Elder, Jennifer Foster, James Barry, Alexander O'Connor", "title": "Designing a Symbolic Intermediate Representation for Neural Surface\n  Realization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generated output from neural NLG systems often contain errors such as\nhallucination, repetition or contradiction. This work focuses on designing a\nsymbolic intermediate representation to be used in multi-stage neural\ngeneration with the intention of reducing the frequency of failed outputs. We\nshow that surface realization from this intermediate representation is of high\nquality and when the full system is applied to the E2E dataset it outperforms\nthe winner of the E2E challenge. Furthermore, by breaking out the surface\nrealization step from typically end-to-end neural systems, we also provide a\nframework for non-neural content selection and planning systems to potentially\ntake advantage of semi-supervised pretraining of neural surface realization\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 23:57:11 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Elder", "Henry", ""], ["Foster", "Jennifer", ""], ["Barry", "James", ""], ["O'Connor", "Alexander", ""]]}, {"id": "1905.10515", "submitter": "Baohua Sun", "authors": "Baohua Sun, Lin Yang, Michael Lin, Charles Young, Patrick Dong, Wenhan\n  Zhang, Jason Dong", "title": "SuperCaptioning: Image Captioning Using Two-dimensional Word Embedding", "comments": "3 pages, 2 figures, modified typo. Accepted by CVPR2019 VQA workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language and vision are processed as two different modal in current work for\nimage captioning. However, recent work on Super Characters method shows the\neffectiveness of two-dimensional word embedding, which converts text\nclassification problem into image classification problem. In this paper, we\npropose the SuperCaptioning method, which borrows the idea of two-dimensional\nword embedding from Super Characters method, and processes the information of\nlanguage and vision together in one single CNN model. The experimental results\non Flickr30k data shows the proposed method gives high quality image captions.\nAn interactive demo is ready to show at the workshop.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 03:57:16 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 00:11:03 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Sun", "Baohua", ""], ["Yang", "Lin", ""], ["Lin", "Michael", ""], ["Young", "Charles", ""], ["Dong", "Patrick", ""], ["Zhang", "Wenhan", ""], ["Dong", "Jason", ""]]}, {"id": "1905.10523", "submitter": "Jinhua Zhu", "authors": "Jinhua Zhu, Fei Gao, Lijun Wu, Yingce Xia, Tao Qin, Wengang Zhou,\n  Xueqi Cheng and Tie-Yan Liu", "title": "Soft Contextual Data Augmentation for Neural Machine Translation", "comments": "Accepted by ACL 2019 as short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While data augmentation is an important trick to boost the accuracy of deep\nlearning methods in computer vision tasks, its study in natural language tasks\nis still very limited. In this paper, we present a novel data augmentation\nmethod for neural machine translation. Different from previous augmentation\nmethods that randomly drop, swap or replace words with other words in a\nsentence, we softly augment a randomly chosen word in a sentence by its\ncontextual mixture of multiple related words. More accurately, we replace the\none-hot representation of a word by a distribution (provided by a language\nmodel) over the vocabulary, i.e., replacing the embedding of this word by a\nweighted combination of multiple semantically similar words. Since the weights\nof those words depend on the contextual information of the word to be replaced,\nthe newly generated sentences capture much richer information than previous\naugmentation methods. Experimental results on both small scale and large scale\nmachine translation datasets demonstrate the superiority of our method over\nstrong baselines.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 05:28:03 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Zhu", "Jinhua", ""], ["Gao", "Fei", ""], ["Wu", "Lijun", ""], ["Xia", "Yingce", ""], ["Qin", "Tao", ""], ["Zhou", "Wengang", ""], ["Cheng", "Xueqi", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1905.10617", "submitter": "Tianxing He", "authors": "Tianxing He, Jingzhao Zhang, Zhiming Zhou, James Glass", "title": "Quantifying Exposure Bias for Open-ended Language Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exposure bias problem refers to the incrementally distorted generation\ninduced by the training-generation discrepancy, in teacher-forcing training for\nauto-regressive neural network language models (LM). It has been regarded as a\ncentral problem for LMs trained for open-ended language generation. Although a\nlot of algorithms have been proposed to avoid teacher forcing and therefore\nalleviate exposure bias, there is little work showing how serious the exposure\nbias problem actually is. In this work, we propose novel metrics to quantify\nthe impact of exposure bias in the generation of MLE-trained LMs. Our key\nintuition is that if we feed ground-truth data prefixes (instead of prefixes\ngenerated by the model itself) into the model and ask it to continue the\ngeneration, the performance should become much better because the\ntraining-generation discrepancy in the prefix is removed. We conduct both\nautomatic and human evaluation in our experiments, and our observations are\ntwo-fold: (1) We confirm that the prefix discrepancy indeed induces some level\nof performance loss. (2) However, the induced distortion seems to be limited,\nand is not incremental during the generation, which contradicts the claim of\nexposure bias.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 15:34:43 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 04:36:54 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 16:00:27 GMT"}, {"version": "v4", "created": "Sat, 8 Feb 2020 19:18:44 GMT"}, {"version": "v5", "created": "Fri, 17 Apr 2020 15:59:05 GMT"}, {"version": "v6", "created": "Thu, 24 Dec 2020 01:11:21 GMT"}, {"version": "v7", "created": "Thu, 31 Dec 2020 03:12:32 GMT"}, {"version": "v8", "created": "Wed, 31 Mar 2021 00:38:34 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["He", "Tianxing", ""], ["Zhang", "Jingzhao", ""], ["Zhou", "Zhiming", ""], ["Glass", "James", ""]]}, {"id": "1905.10625", "submitter": "Dongjun Wei", "authors": "Dongjun Wei and Yaxin Liu and Fuqing Zhu and Liangjun Zang and Wei\n  Zhou and Jizhong Han and Songlin Hu", "title": "ESA: Entity Summarization with Attention", "comments": "12pages, accepted in EYRE@CIKM'2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity summarization aims at creating brief but informative descriptions of\nentities from knowledge graphs. While previous work mostly focused on\ntraditional techniques such as clustering algorithms and graph models, we ask\nhow to apply deep learning methods into this task. In this paper we propose\nESA, a neural network with supervised attention mechanisms for entity\nsummarization. Specifically, we calculate attention weights for facts in each\nentity, and rank facts to generate reliable summaries. We explore techniques to\nsolve difficult learning problems presented by the ESA, and demonstrate the\neffectiveness of our model in comparison with the state-of-the-art methods.\nExperimental results show that our model improves the quality of the entity\nsummaries in both F-measure and MAP.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 16:06:42 GMT"}, {"version": "v2", "created": "Sun, 14 Jul 2019 00:50:53 GMT"}, {"version": "v3", "created": "Mon, 25 May 2020 09:17:55 GMT"}, {"version": "v4", "created": "Tue, 26 May 2020 01:06:47 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Wei", "Dongjun", ""], ["Liu", "Yaxin", ""], ["Zhu", "Fuqing", ""], ["Zang", "Liangjun", ""], ["Zhou", "Wei", ""], ["Han", "Jizhong", ""], ["Hu", "Songlin", ""]]}, {"id": "1905.10650", "submitter": "Paul Michel", "authors": "Paul Michel, Omer Levy, Graham Neubig", "title": "Are Sixteen Heads Really Better than One?", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention is a powerful and ubiquitous mechanism for allowing neural models\nto focus on particular salient pieces of information by taking their weighted\naverage when making predictions. In particular, multi-headed attention is a\ndriving force behind many recent state-of-the-art NLP models such as\nTransformer-based MT models and BERT. These models apply multiple attention\nmechanisms in parallel, with each attention \"head\" potentially focusing on\ndifferent parts of the input, which makes it possible to express sophisticated\nfunctions beyond the simple weighted average. In this paper we make the\nsurprising observation that even if models have been trained using multiple\nheads, in practice, a large percentage of attention heads can be removed at\ntest time without significantly impacting performance. In fact, some layers can\neven be reduced to a single head. We further examine greedy algorithms for\npruning down models, and the potential speed, memory efficiency, and accuracy\nimprovements obtainable therefrom. Finally, we analyze the results with respect\nto which parts of the model are more reliant on having multiple heads, and\nprovide precursory evidence that training dynamics play a role in the gains\nprovided by multi-head attention.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 18:27:28 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 21:22:49 GMT"}, {"version": "v3", "created": "Mon, 4 Nov 2019 15:49:01 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Michel", "Paul", ""], ["Levy", "Omer", ""], ["Neubig", "Graham", ""]]}, {"id": "1905.10702", "submitter": "Afshin Sadeghi", "authors": "Afshin Sadeghi, Damien Graux, Hamed Shariat Yazdi, Jens Lehmann", "title": "MDE: Multiple Distance Embeddings for Link Prediction in Knowledge\n  Graphs", "comments": "Accepted paper in ECAI 2020", "journal-ref": "24th European Conference on Artificial Intelligence (ECAI), 2020", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decade, knowledge graphs became popular for capturing\nstructured domain knowledge. Relational learning models enable the prediction\nof missing links inside knowledge graphs. More specifically, latent distance\napproaches model the relationships among entities via a distance between latent\nrepresentations. Translating embedding models (e.g., TransE) are among the most\npopular latent distance approaches which use one distance function to learn\nmultiple relation patterns. However, they are mostly inefficient in capturing\nsymmetric relations since the representation vector norm for all the symmetric\nrelations becomes equal to zero. They also lose information when learning\nrelations with reflexive patterns since they become symmetric and transitive.\nWe propose the Multiple Distance Embedding model (MDE) that addresses these\nlimitations and a framework to collaboratively combine variant latent\ndistance-based terms. Our solution is based on two principles: 1) we use a\nlimit-based loss instead of a margin ranking loss and, 2) by learning\nindependent embedding vectors for each of the terms we can collectively train\nand predict using contradicting distance terms. We further demonstrate that MDE\nallows modeling relations with (anti)symmetry, inversion, and composition\npatterns. We propose MDE as a neural network model that allows us to map\nnon-linear relations between the embedding vectors and the expected output of\nthe score function. Our empirical results show that MDE performs competitively\nto state-of-the-art embedding models on several benchmark datasets.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 23:48:00 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 10:36:32 GMT"}, {"version": "v3", "created": "Wed, 5 Jun 2019 17:19:34 GMT"}, {"version": "v4", "created": "Mon, 10 Jun 2019 20:57:08 GMT"}, {"version": "v5", "created": "Wed, 19 Jun 2019 18:38:58 GMT"}, {"version": "v6", "created": "Thu, 27 Jun 2019 12:40:11 GMT"}, {"version": "v7", "created": "Mon, 8 Jul 2019 11:54:43 GMT"}, {"version": "v8", "created": "Fri, 21 Feb 2020 13:09:08 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Sadeghi", "Afshin", ""], ["Graux", "Damien", ""], ["Yazdi", "Hamed Shariat", ""], ["Lehmann", "Jens", ""]]}, {"id": "1905.10718", "submitter": "Dong Xu", "authors": "Dong Xu and Wu-Jun Li", "title": "Hashing based Answer Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer selection is an important subtask of question answering (QA), where\ndeep models usually achieve better performance. Most deep models adopt\nquestion-answer interaction mechanisms, such as attention, to get vector\nrepresentations for answers. When these interaction based deep models are\ndeployed for online prediction, the representations of all answers need to be\nrecalculated for each question. This procedure is time-consuming for deep\nmodels with complex encoders like BERT which usually have better accuracy than\nsimple encoders. One possible solution is to store the matrix representation\n(encoder output) of each answer in memory to avoid recalculation. But this will\nbring large memory cost. In this paper, we propose a novel method, called\nhashing based answer selection (HAS), to tackle this problem. HAS adopts a\nhashing strategy to learn a binary matrix representation for each answer, which\ncan dramatically reduce the memory cost for storing the matrix representations\nof answers. Hence, HAS can adopt complex encoders like BERT in the model, but\nthe online prediction of HAS is still fast with a low memory cost. Experimental\nresults on three popular answer selection datasets show that HAS can outperform\nexisting models to achieve state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 03:33:42 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Xu", "Dong", ""], ["Li", "Wu-Jun", ""]]}, {"id": "1905.10720", "submitter": "Dong Xu", "authors": "Dong Xu and Jianhui Ji and Haikuan Huang and Hongbo Deng and Wu-Jun Li", "title": "Gated Group Self-Attention for Answer Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer selection (answer ranking) is one of the key steps in many kinds of\nquestion answering (QA) applications, where deep models have achieved\nstate-of-the-art performance. Among these deep models, recurrent neural network\n(RNN) based models are most popular, typically with better performance than\nconvolutional neural network (CNN) based models. Nevertheless, it is difficult\nfor RNN based models to capture the information about long-range dependency\namong words in the sentences of questions and answers. In this paper, we\npropose a new deep model, called gated group self-attention (GGSA), for answer\nselection. GGSA is inspired by global self-attention which is originally\nproposed for machine translation and has not been explored in answer selection.\nGGSA tackles the problem of global self-attention that local and global\ninformation cannot be well distinguished. Furthermore, an interaction mechanism\nbetween questions and answers is also proposed to enhance GGSA by a residual\nstructure. Experimental results on two popular QA datasets show that GGSA can\noutperform existing answer selection models to achieve state-of-the-art\nperformance. Furthermore, GGSA can also achieve higher accuracy than global\nself-attention for the answer selection task, with a lower computation cost.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 03:40:17 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Xu", "Dong", ""], ["Ji", "Jianhui", ""], ["Huang", "Haikuan", ""], ["Deng", "Hongbo", ""], ["Li", "Wu-Jun", ""]]}, {"id": "1905.10726", "submitter": "Linfeng Song", "authors": "Linfeng Song and Daniel Gildea", "title": "SemBleu: A Robust Metric for AMR Parsing Evaluation", "comments": "ACL 2019 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluating AMR parsing accuracy involves comparing pairs of AMR graphs. The\nmajor evaluation metric, SMATCH (Cai and Knight, 2013), searches for one-to-one\nmappings between the nodes of two AMRs with a greedy hill-climbing algorithm,\nwhich leads to search errors. We propose SEMBLEU, a robust metric that extends\nBLEU (Papineni et al., 2002) to AMRs. It does not suffer from search errors and\nconsiders non-local correspondences in addition to local ones. SEMBLEU is fully\ncontent-driven and punishes situations where a system's output does not\npreserve most information from the input. Preliminary experiments on both\nsentence and corpus levels show that SEMBLEU has slightly higher consistency\nwith human judgments than SMATCH. Our code is available at\nhttp://github.com/freesunshine0316/sembleu.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 04:49:29 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 14:16:05 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Song", "Linfeng", ""], ["Gildea", "Daniel", ""]]}, {"id": "1905.10752", "submitter": "Dayiheng Liu", "authors": "Dayiheng Liu, Jie Fu, Pengfei Liu, Jiancheng Lv", "title": "TIGS: An Inference Algorithm for Text Infilling with Gradient Search", "comments": "The 57th Annual Meeting of the Association for Computational\n  Linguistics (ACL 2019)", "journal-ref": null, "doi": "10.18653/v1/P19-1406", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text infilling is defined as a task for filling in the missing part of a\nsentence or paragraph, which is suitable for many real-world natural language\ngeneration scenarios. However, given a well-trained sequential generative\nmodel, generating missing symbols conditioned on the context is challenging for\nexisting greedy approximate inference algorithms. In this paper, we propose an\niterative inference algorithm based on gradient search, which is the first\ninference algorithm that can be broadly applied to any neural sequence\ngenerative models for text infilling tasks. We compare the proposed method with\nstrong baselines on three text infilling tasks with various mask ratios and\ndifferent mask strategies. The results show that our proposed method is\neffective and efficient for fill-in-the-blank tasks, consistently outperforming\nall baselines.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 07:45:44 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Liu", "Dayiheng", ""], ["Fu", "Jie", ""], ["Liu", "Pengfei", ""], ["Lv", "Jiancheng", ""]]}, {"id": "1905.10799", "submitter": "Weiyu Liu", "authors": "Weiyu Liu, Angel Daruna, Zsolt Kira and Sonia Chernova", "title": "Path Ranking with Attention to Type Hierarchies", "comments": "Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of the knowledge base completion problem is to infer missing\ninformation from existing facts in a knowledge base. Prior work has\ndemonstrated the effectiveness of path-ranking based methods, which solve the\nproblem by discovering observable patterns in knowledge graphs, consisting of\nnodes representing entities and edges representing relations. However, these\npatterns either lack accuracy because they rely solely on relations or cannot\neasily generalize due to the direct use of specific entity information. We\nintroduce Attentive Path Ranking, a novel path pattern representation that\nleverages type hierarchies of entities to both avoid ambiguity and maintain\ngeneralization. Then, we present an end-to-end trained attention-based RNN\nmodel to discover the new path patterns from data. Experiments conducted on\nbenchmark knowledge base completion datasets WN18RR and FB15k-237 demonstrate\nthat the proposed model outperforms existing methods on the fact prediction\ntask by statistically significant margins of 26% and 10%, respectively.\nFurthermore, quantitative and qualitative analyses show that the path patterns\nbalance between generalization and discrimination.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 12:57:47 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 18:18:20 GMT"}, {"version": "v3", "created": "Tue, 26 Nov 2019 17:34:15 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Liu", "Weiyu", ""], ["Daruna", "Angel", ""], ["Kira", "Zsolt", ""], ["Chernova", "Sonia", ""]]}, {"id": "1905.10802", "submitter": "Boli Chen", "authors": "Boli Chen, Xin Huang, Lin Xiao, Zixin Cai, Liping Jing", "title": "Hyperbolic Interaction Model For Hierarchical Multi-Label Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different from the traditional classification tasks which assume mutual\nexclusion of labels, hierarchical multi-label classification (HMLC) aims to\nassign multiple labels to every instance with the labels organized under\nhierarchical relations. Besides the labels, since linguistic ontologies are\nintrinsic hierarchies, the conceptual relations between words can also form\nhierarchical structures. Thus it can be a challenge to learn mappings from word\nhierarchies to label hierarchies. We propose to model the word and label\nhierarchies by embedding them jointly in the hyperbolic space. The main reason\nis that the tree-likeness of the hyperbolic space matches the complexity of\nsymbolic data with hierarchical structures. A new Hyperbolic Interaction Model\n(HyperIM) is designed to learn the label-aware document representations and\nmake predictions for HMLC. Extensive experiments are conducted on three\nbenchmark datasets. The results have demonstrated that the new model can\nrealistically capture the complex data structures and further improve the\nperformance for HMLC comparing with the state-of-the-art methods. To facilitate\nfuture research, our code is publicly available.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 13:20:11 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 15:36:22 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Chen", "Boli", ""], ["Huang", "Xin", ""], ["Xiao", "Lin", ""], ["Cai", "Zixin", ""], ["Jing", "Liping", ""]]}, {"id": "1905.10810", "submitter": "Szymon Rutkowski", "authors": "Szymon Rutkowski", "title": "Evaluation of basic modules for isolated spelling error correction in\n  Polish texts", "comments": "4 pages, LTC '19 Pozna\\'n", "journal-ref": "Human Language Technologies as a Challenge for Computer Science\n  and Linguistics. Ed. Zygmunt Vetulani and Patrick Paroubek. Pozna\\'n:\n  Wydawnictwo Nauka i Innowacje, 2019. Pp. 173-176", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spelling error correction is an important problem in natural language\nprocessing, as a prerequisite for good performance in downstream tasks as well\nas an important feature in user-facing applications. For texts in Polish\nlanguage, there exist works on specific error correction solutions, often\ndeveloped for dealing with specialized corpora, but not evaluations of many\ndifferent approaches on big resources of errors. We begin to address this\nproblem by testing some basic and promising methods on PlEWi, a corpus of\nannotated spelling extracted from Polish Wikipedia. These modules may be\nfurther combined with appropriate solutions for error detection and context\nawareness. Following our results, combining edit distance with cosine distance\nof semantic vectors may be suggested for interpretable systems, while an LSTM,\nparticularly enhanced by ELMo embeddings, seems to offer the best raw\nperformance.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 14:54:52 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Rutkowski", "Szymon", ""]]}, {"id": "1905.10847", "submitter": "Yi Tay", "authors": "Yi Tay, Shuohang Wang, Luu Anh Tuan, Jie Fu, Minh C. Phan, Xingdi\n  Yuan, Jinfeng Rao, Siu Cheung Hui, Aston Zhang", "title": "Simple and Effective Curriculum Pointer-Generator Networks for Reading\n  Comprehension over Long Narratives", "comments": "Accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper tackles the problem of reading comprehension over long narratives\nwhere documents easily span over thousands of tokens. We propose a curriculum\nlearning (CL) based Pointer-Generator framework for reading/sampling over large\ndocuments, enabling diverse training of the neural model based on the notion of\nalternating contextual difficulty. This can be interpreted as a form of domain\nrandomization and/or generative pretraining during training. To this end, the\nusage of the Pointer-Generator softens the requirement of having the answer\nwithin the context, enabling us to construct diverse training samples for\nlearning. Additionally, we propose a new Introspective Alignment Layer (IAL),\nwhich reasons over decomposed alignments using block-based self-attention. We\nevaluate our proposed method on the NarrativeQA reading comprehension\nbenchmark, achieving state-of-the-art performance, improving existing baselines\nby $51\\%$ relative improvement on BLEU-4 and $17\\%$ relative improvement on\nRouge-L. Extensive ablations confirm the effectiveness of our proposed IAL and\nCL components.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 17:56:11 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Tay", "Yi", ""], ["Wang", "Shuohang", ""], ["Tuan", "Luu Anh", ""], ["Fu", "Jie", ""], ["Phan", "Minh C.", ""], ["Yuan", "Xingdi", ""], ["Rao", "Jinfeng", ""], ["Hui", "Siu Cheung", ""], ["Zhang", "Aston", ""]]}, {"id": "1905.10851", "submitter": "Muthu Kumar Chandrasekaran", "authors": "Muthu Kumar Chandrasekaran and Min-Yen Kan", "title": "When to reply? Context Sensitive Models to Predict Instructor\n  Interventions in MOOC Forums", "comments": "preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to time constraints, course instructors often need to selectively\nparticipate in student discussion threads, due to their limited bandwidth and\nlopsided student--instructor ratio on online forums. We propose the first deep\nlearning models for this binary prediction problem. We propose novel attention\nbased models to infer the amount of latent context necessary to predict\ninstructor intervention. Such models also allow themselves to be tuned to\ninstructor's preference to intervene early or late. Our three proposed\nattentive model variants to infer the latent context improve over the\nstate-of-the-art by a significant, large margin of 11% in F1 and 10% in recall,\non average. Further, introspection of attention help us better understand what\naspects of a discussion post propagate through the discussion thread that\nprompts instructor intervention.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 18:40:06 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Chandrasekaran", "Muthu Kumar", ""], ["Kan", "Min-Yen", ""]]}, {"id": "1905.10886", "submitter": "Yanai Elazar", "authors": "Yanai Elazar and Yoav Goldberg", "title": "Where's My Head? Definition, Dataset and Models for Numeric Fused-Heads\n  Identification and Resolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide the first computational treatment of fused-heads constructions\n(FH), focusing on the numeric fused-heads (NFH). FHs constructions are noun\nphrases (NPs) in which the head noun is missing and is said to be `fused' with\nits dependent modifier. This missing information is implicit and is important\nfor sentence understanding. The missing references are easily filled in by\nhumans but pose a challenge for computational models. We formulate the handling\nof FH as a two stages process: identification of the FH construction and\nresolution of the missing head. We explore the NFH phenomena in large corpora\nof English text and create (1) a dataset and a highly accurate method for NFH\nidentification; (2) a 10k examples (1M tokens) crowd-sourced dataset of NFH\nresolution; and (3) a neural baseline for the NFH resolution task. We release\nour code and dataset, in hope to foster further research into this challenging\nproblem.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 21:35:21 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Elazar", "Yanai", ""], ["Goldberg", "Yoav", ""]]}, {"id": "1905.10892", "submitter": "Ilias Chalkidis", "authors": "Ilias Chalkidis and Manos Fergadiotis and Prodromos Malakasiotis and\n  Nikolaos Aletras and Ion Androutsopoulos", "title": "Extreme Multi-Label Legal Text Classification: A case study in EU\n  Legislation", "comments": "10 pages, long paper at NLLP Workshop of NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of Extreme Multi-Label Text Classification (XMTC) in the\nlegal domain. We release a new dataset of 57k legislative documents from\nEURLEX, the European Union's public document database, annotated with concepts\nfrom EUROVOC, a multidisciplinary thesaurus. The dataset is substantially\nlarger than previous EURLEX datasets and suitable for XMTC, few-shot and\nzero-shot learning. Experimenting with several neural classifiers, we show that\nBIGRUs with self-attention outperform the current multi-label state-of-the-art\nmethods, which employ label-wise attention. Replacing CNNs with BIGRUs in\nlabel-wise attention networks leads to the best overall performance.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 21:50:15 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Chalkidis", "Ilias", ""], ["Fergadiotis", "Manos", ""], ["Malakasiotis", "Prodromos", ""], ["Aletras", "Nikolaos", ""], ["Androutsopoulos", "Ion", ""]]}, {"id": "1905.10930", "submitter": "Sean Welleck", "authors": "Sean Welleck, Kyunghyun Cho", "title": "Sequential Graph Dependency Parser", "comments": "RANLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for non-projective dependency parsing by incrementally\npredicting a set of edges. Since the edges do not have a pre-specified order,\nwe propose a set-based learning method. Our method blends graph, transition,\nand easy-first parsing, including a prior state of the parser as a special\ncase. The proposed transition-based method successfully parses near the state\nof the art on both projective and non-projective languages, without assuming a\ncertain parsing order.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 01:42:30 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 20:55:31 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Welleck", "Sean", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1905.10949", "submitter": "Yu Yin", "authors": "Yu Yin, Qi Liu, Zhenya Huang, Enhong Chen, Wei Tong, Shijin Wang and\n  Yu Su", "title": "QuesNet: A Unified Representation for Heterogeneous Test Questions", "comments": null, "journal-ref": null, "doi": "10.1145/3292500.3330900", "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Understanding learning materials (e.g. test questions) is a crucial issue in\nonline learning systems, which can promote many applications in education\ndomain. Unfortunately, many supervised approaches suffer from the problem of\nscarce human labeled data, whereas abundant unlabeled resources are highly\nunderutilized. To alleviate this problem, an effective solution is to use\npre-trained representations for question understanding. However, existing\npre-training methods in NLP area are infeasible to learn test question\nrepresentations due to several domain-specific characteristics in education.\nFirst, questions usually comprise of heterogeneous data including content text,\nimages and side information. Second, there exists both basic linguistic\ninformation as well as domain logic and knowledge. To this end, in this paper,\nwe propose a novel pre-training method, namely QuesNet, for comprehensively\nlearning question representations. Specifically, we first design a unified\nframework to aggregate question information with its heterogeneous inputs into\na comprehensive vector. Then we propose a two-level hierarchical pre-training\nalgorithm to learn better understanding of test questions in an unsupervised\nway. Here, a novel holed language model objective is developed to extract\nlow-level linguistic features, and a domain-oriented objective is proposed to\nlearn high-level logic and knowledge. Moreover, we show that QuesNet has good\ncapability of being fine-tuned in many question-based tasks. We conduct\nextensive experiments on large-scale real-world question data, where the\nexperimental results clearly demonstrate the effectiveness of QuesNet for\nquestion understanding as well as its superior applicability.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 03:08:17 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Yin", "Yu", ""], ["Liu", "Qi", ""], ["Huang", "Zhenya", ""], ["Chen", "Enhong", ""], ["Tong", "Wei", ""], ["Wang", "Shijin", ""], ["Su", "Yu", ""]]}, {"id": "1905.10957", "submitter": "Song Cheng", "authors": "Song Cheng and Qi Liu", "title": "Enhancing Item Response Theory for Cognitive Diagnosis", "comments": "Accepted by CIKM'2019. https://github.com/chsong513/DIRT", "journal-ref": null, "doi": "10.1145/3357384.3358070", "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognitive diagnosis is a fundamental and crucial task in many educational\napplications, e.g., computer adaptive test and cognitive assignments. Item\nResponse Theory (IRT) is a classical cognitive diagnosis method which can\nprovide interpretable parameters (i.e., student latent trait, question\ndiscrimination, and difficulty) for analyzing student performance. However,\ntraditional IRT ignores the rich information in question texts, cannot diagnose\nknowledge concept proficiency, and it is inaccurate to diagnose the parameters\nfor the questions which only appear several times. To this end, in this paper,\nwe propose a general Deep Item Response Theory (DIRT) framework to enhance\ntraditional IRT for cognitive diagnosis by exploiting semantic representation\nfrom question texts with deep learning. In DIRT, we first use a proficiency\nvector to represent students' proficiency in knowledge concepts and embed\nquestion texts and knowledge concepts to dense vectors by Word2Vec. Then, we\ndesign a deep diagnosis module to diagnose parameters in traditional IRT by\ndeep learning techniques. Finally, with the diagnosed parameters, we input them\ninto the logistic-like formula of IRT to predict student performance. Extensive\nexperimental results on real-world data clearly demonstrate the effectiveness\nand interpretation power of DIRT framework.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 03:35:30 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 06:24:05 GMT"}, {"version": "v3", "created": "Sun, 1 Dec 2019 03:08:59 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Cheng", "Song", ""], ["Liu", "Qi", ""]]}, {"id": "1905.10971", "submitter": "Shuai Tang", "authors": "Shuai Tang, Mahta Mousavi, Virginia R. de Sa", "title": "An Empirical Study on Post-processing Methods for Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings learnt from large corpora have been adopted in various\napplications in natural language processing and served as the general input\nrepresentations to learning systems. Recently, a series of post-processing\nmethods have been proposed to boost the performance of word embeddings on\nsimilarity comparison and analogy retrieval tasks, and some have been adapted\nto compose sentence representations. The general hypothesis behind these\nmethods is that by enforcing the embedding space to be more isotropic, the\nsimilarity between words can be better expressed. We view these methods as an\napproach to shrink the covariance/gram matrix, which is estimated by learning\nword vectors, towards a scaled identity matrix. By optimising an objective in\nthe semi-Riemannian manifold with Centralised Kernel Alignment (CKA), we are\nable to search for the optimal shrinkage parameter, and provide a\npost-processing method to smooth the spectrum of learnt word vectors which\nyields improved performance on downstream tasks.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 04:49:45 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 00:54:16 GMT"}, {"version": "v3", "created": "Wed, 23 Oct 2019 20:21:49 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Tang", "Shuai", ""], ["Mousavi", "Mahta", ""], ["de Sa", "Virginia R.", ""]]}, {"id": "1905.10989", "submitter": "Simon Razniewski", "authors": "Julien Romero, Simon Razniewski, Koninika Pal, Jeff Z. Pan, Archit\n  Sakhadeo, Gerhard Weikum", "title": "Commonsense Properties from Query Logs and Question Answering Forums", "comments": "Updated appendix reporting on Quasimodo v4.3 (2/2021)", "journal-ref": "CIKM 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commonsense knowledge about object properties, human behavior and general\nconcepts is crucial for robust AI applications. However, automatic acquisition\nof this knowledge is challenging because of sparseness and bias in online\nsources. This paper presents Quasimodo, a methodology and tool suite for\ndistilling commonsense properties from non-standard web sources. We devise\nnovel ways of tapping into search-engine query logs and QA forums, and\ncombining the resulting candidate assertions with statistical cues from\nencyclopedias, books and image tags in a corroboration step. Unlike prior work\non commonsense knowledge bases, Quasimodo focuses on salient properties that\nare typically associated with certain objects or concepts. Extensive\nevaluations, including extrinsic use-case studies, show that Quasimodo provides\nbetter coverage than state-of-the-art baselines with comparable quality.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 06:12:56 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 07:01:43 GMT"}, {"version": "v3", "created": "Mon, 2 Sep 2019 08:52:21 GMT"}, {"version": "v4", "created": "Wed, 10 Feb 2021 21:40:55 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Romero", "Julien", ""], ["Razniewski", "Simon", ""], ["Pal", "Koninika", ""], ["Pan", "Jeff Z.", ""], ["Sakhadeo", "Archit", ""], ["Weikum", "Gerhard", ""]]}, {"id": "1905.11006", "submitter": "Jiatao Gu", "authors": "Jiatao Gu, Changhan Wang and Jake Zhao", "title": "Levenshtein Transformer", "comments": "17 pages (6 pages appendix). Camera ready, accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern neural sequence generation models are built to either generate tokens\nstep-by-step from scratch or (iteratively) modify a sequence of tokens bounded\nby a fixed length. In this work, we develop Levenshtein Transformer, a new\npartially autoregressive model devised for more flexible and amenable sequence\ngeneration. Unlike previous approaches, the atomic operations of our model are\ninsertion and deletion. The combination of them facilitates not only generation\nbut also sequence refinement allowing dynamic length changes. We also propose a\nset of new training techniques dedicated at them, effectively exploiting one as\nthe other's learning signal thanks to their complementary nature. Experiments\napplying the proposed model achieve comparable performance but much-improved\nefficiency on both generation (e.g. machine translation, text summarization)\nand refinement tasks (e.g. automatic post-editing). We further confirm the\nflexibility of our model by showing a Levenshtein Transformer trained by\nmachine translation can straightforwardly be used for automatic post-editing.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 07:08:12 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 07:52:19 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Gu", "Jiatao", ""], ["Wang", "Changhan", ""], ["Zhao", "Jake", ""]]}, {"id": "1905.11037", "submitter": "David Vilares", "authors": "David Vilares and Carlos G\\'omez-Rodr\\'iguez", "title": "Harry Potter and the Action Prediction Challenge from Natural Language", "comments": "NAACL 2019 (short papers)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the challenge of action prediction from textual descriptions of\nscenes, a testbed to approximate whether text inference can be used to predict\nupcoming actions. As a case of study, we consider the world of the Harry Potter\nfantasy novels and inferring what spell will be cast next given a fragment of a\nstory. Spells act as keywords that abstract actions (e.g. 'Alohomora' to open a\ndoor) and denote a response to the environment. This idea is used to\nautomatically build HPAC, a corpus containing 82,836 samples and 85 actions. We\nthen evaluate different baselines. Among the tested models, an LSTM-based\napproach obtains the best performance for frequent actions and large scene\ndescriptions, but approaches such as logistic regression behave well on\ninfrequent actions.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 08:28:51 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Vilares", "David", ""], ["G\u00f3mez-Rodr\u00edguez", "Carlos", ""]]}, {"id": "1905.11173", "submitter": "Jianwei Tai", "authors": "Xiaoqi Jia, Jianwei Tai, Hang Zhou, Yakai Li, Weijuan Zhang, Haichao\n  Du, Qingjia Huang", "title": "ET-GAN: Cross-Language Emotion Transfer Based on Cycle-Consistent\n  Generative Adversarial Networks", "comments": "Accepted by ECAI 2020, 8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the remarkable progress made in synthesizing emotional speech from\ntext, it is still challenging to provide emotion information to existing speech\nsegments. Previous methods mainly rely on parallel data, and few works have\nstudied the generalization ability for one model to transfer emotion\ninformation across different languages. To cope with such problems, we propose\nan emotion transfer system named ET-GAN, for learning language-independent\nemotion transfer from one emotion to another without parallel training samples.\nBased on cycle-consistent generative adversarial network, our method ensures\nthe transfer of only emotion information across speeches with simple loss\ndesigns. Besides, we introduce an approach for migrating emotion information\nacross different languages by using transfer learning. The experiment results\nshow that our method can efficiently generate high-quality emotional speech for\nany given emotion category, without aligned speech pairs.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 12:41:36 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 06:56:25 GMT"}, {"version": "v3", "created": "Thu, 5 Mar 2020 13:44:30 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Jia", "Xiaoqi", ""], ["Tai", "Jianwei", ""], ["Zhou", "Hang", ""], ["Li", "Yakai", ""], ["Zhang", "Weijuan", ""], ["Du", "Haichao", ""], ["Huang", "Qingjia", ""]]}, {"id": "1905.11235", "submitter": "Linhao Dong", "authors": "Linhao Dong, Bo Xu", "title": "CIF: Continuous Integrate-and-Fire for End-to-End Speech Recognition", "comments": "To appear at ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel soft and monotonic alignment mechanism used\nfor sequence transduction. It is inspired by the integrate-and-fire model in\nspiking neural networks and employed in the encoder-decoder framework consists\nof continuous functions, thus being named as: Continuous Integrate-and-Fire\n(CIF). Applied to the ASR task, CIF not only shows a concise calculation, but\nalso supports online recognition and acoustic boundary positioning, thus\nsuitable for various ASR scenarios. Several support strategies are also\nproposed to alleviate the unique problems of CIF-based model. With the joint\naction of these methods, the CIF-based model shows competitive performance.\nNotably, it achieves a word error rate (WER) of 2.86% on the test-clean of\nLibrispeech and creates new state-of-the-art result on Mandarin telephone ASR\nbenchmark.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 14:00:45 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 15:33:54 GMT"}, {"version": "v3", "created": "Sun, 10 Nov 2019 04:47:02 GMT"}, {"version": "v4", "created": "Wed, 12 Feb 2020 11:13:58 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Dong", "Linhao", ""], ["Xu", "Bo", ""]]}, {"id": "1905.11240", "submitter": "Shang-Yu Su", "authors": "Shang-Yu Su, Yun-Nung Chen", "title": "Bridging Dialogue Generation and Facial Expression Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spoken dialogue systems that assist users to solve complex tasks such as\nmovie ticket booking have become an emerging research topic in artificial\nintelligence and natural language processing areas. With a well-designed\ndialogue system as an intelligent personal assistant, people can accomplish\ncertain tasks more easily via natural language interactions. Today there are\nseveral virtual intelligent assistants in the market; however, most systems\nonly focus on single modality, such as textual or vocal interaction. A\nmultimodal interface has various advantages: (1) allowing human to communicate\nwith machines in a natural and concise form using the mixture of modalities\nthat most precisely convey the intention to satisfy communication needs, and\n(2) providing more engaging experience by natural and human-like feedback. This\npaper explores a brand new research direction, which aims at bridging dialogue\ngeneration and facial expression synthesis for better multimodal interaction.\nThe goal is to generate dialogue responses and simultaneously synthesize\ncorresponding visual expressions on faces, which is also an ultimate step\ntoward more human-like virtual assistants.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 10:22:16 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 05:32:21 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Su", "Shang-Yu", ""], ["Chen", "Yun-Nung", ""]]}, {"id": "1905.11259", "submitter": "Lu Chen", "authors": "Lu Chen, Zhi Chen, Bowen Tan, Sishan Long, Milica Gasic, Kai Yu", "title": "AgentGraph: Towards Universal Dialogue Management with Structured Deep\n  Reinforcement Learning", "comments": "14 pages, 8 figures; Accepted by IEEE/ACM TRANSACTIONS ON AUDIO,\n  SPEECH, AND LANGUAGE PROCESSING", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue policy plays an important role in task-oriented spoken dialogue\nsystems. It determines how to respond to users. The recently proposed deep\nreinforcement learning (DRL) approaches have been used for policy optimization.\nHowever, these deep models are still challenging for two reasons: 1) Many\nDRL-based policies are not sample-efficient. 2) Most models don't have the\ncapability of policy transfer between different domains. In this paper, we\npropose a universal framework, AgentGraph, to tackle these two problems. The\nproposed AgentGraph is the combination of GNN-based architecture and DRL-based\nalgorithm. It can be regarded as one of the multi-agent reinforcement learning\napproaches. Each agent corresponds to a node in a graph, which is defined\naccording to the dialogue domain ontology. When making a decision, each agent\ncan communicate with its neighbors on the graph. Under AgentGraph framework, we\nfurther propose Dual GNN-based dialogue policy, which implicitly decomposes the\ndecision in each turn into a high-level global decision and a low-level local\ndecision. Experiments show that AgentGraph models significantly outperform\ntraditional reinforcement learning approaches on most of the 18 tasks of the\nPyDial benchmark. Moreover, when transferred from the source task to a target\ntask, these models not only have acceptable initial performance but also\nconverge much faster on the target task.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 14:27:13 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Chen", "Lu", ""], ["Chen", "Zhi", ""], ["Tan", "Bowen", ""], ["Long", "Sishan", ""], ["Gasic", "Milica", ""], ["Yu", "Kai", ""]]}, {"id": "1905.11268", "submitter": "Danish Pruthi", "authors": "Danish Pruthi, Bhuwan Dhingra, Zachary C. Lipton", "title": "Combating Adversarial Misspellings with Robust Word Recognition", "comments": "ACL 2019, long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To combat adversarial spelling mistakes, we propose placing a word\nrecognition model in front of the downstream classifier. Our word recognition\nmodels build upon the RNN semi-character architecture, introducing several new\nbackoff strategies for handling rare and unseen words. Trained to recognize\nwords corrupted by random adds, drops, swaps, and keyboard mistakes, our method\nachieves 32% relative (and 3.3% absolute) error reduction over the vanilla\nsemi-character model. Notably, our pipeline confers robustness on the\ndownstream classifier, outperforming both adversarial training and\noff-the-shelf spell checkers. Against a BERT model fine-tuned for sentiment\nanalysis, a single adversarially-chosen character attack lowers accuracy from\n90.3% to 45.8%. Our defense restores accuracy to 75%. Surprisingly, better word\nrecognition does not always entail greater robustness. Our analysis reveals\nthat robustness also depends upon a quantity that we denote the sensitivity.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 14:35:35 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 15:20:17 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Pruthi", "Danish", ""], ["Dhingra", "Bhuwan", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "1905.11391", "submitter": "Diana Sousa", "authors": "Diana Sousa, Andre Lamurias, Francisco M. Couto", "title": "Using Neural Networks for Relation Extraction from Biomedical Literature", "comments": "Artificial Neural Networks book (Springer) - Chapter 14", "journal-ref": "Artificial Neural Networks. Methods in Molecular Biology, vol\n  2190. Humana, New York, NY. 2020. pp. 289-305", "doi": "10.1007/978-1-0716-0826-5_14", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using different sources of information to support automated extracting of\nrelations between biomedical concepts contributes to the development of our\nunderstanding of biological systems. The primary comprehensive source of these\nrelations is biomedical literature. Several relation extraction approaches have\nbeen proposed to identify relations between concepts in biomedical literature,\nnamely, using neural networks algorithms. The use of multichannel architectures\ncomposed of multiple data representations, as in deep neural networks, is\nleading to state-of-the-art results. The right combination of data\nrepresentations can eventually lead us to even higher evaluation scores in\nrelation extraction tasks. Thus, biomedical ontologies play a fundamental role\nby providing semantic and ancestry information about an entity. The\nincorporation of biomedical ontologies has already been proved to enhance\nprevious state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 09:33:29 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 13:40:39 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Sousa", "Diana", ""], ["Lamurias", "Andre", ""], ["Couto", "Francisco M.", ""]]}, {"id": "1905.11393", "submitter": "Jin Zeng", "authors": "Mengyang Chen, Jin Zeng, and Jie Lou", "title": "A Self-Attention Joint Model for Spoken Language Understanding in\n  Situational Dialog Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spoken language understanding (SLU) acts as a critical component in\ngoal-oriented dialog systems. It typically involves identifying the speakers\nintent and extracting semantic slots from user utterances, which are known as\nintent detection (ID) and slot filling (SF). SLU problem has been intensively\ninvestigated in recent years. However, these methods just constrain SF results\ngrammatically, solve ID and SF independently, or do not fully utilize the\nmutual impact of the two tasks. This paper proposes a multi-head self-attention\njoint model with a conditional random field (CRF) layer and a prior mask. The\nexperiments show the effectiveness of our model, as compared with\nstate-of-the-art models. Meanwhile, online education in China has made great\nprogress in the last few years. But there are few intelligent educational\ndialog applications for students to learn foreign languages. Hence, we design\nan intelligent dialog robot equipped with different scenario settings to help\nstudents learn communication skills.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 10:22:20 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Chen", "Mengyang", ""], ["Zeng", "Jin", ""], ["Lou", "Jie", ""]]}, {"id": "1905.11449", "submitter": "Andros Tjandra", "authors": "Andros Tjandra, Berrak Sisman, Mingyang Zhang, Sakriani Sakti, Haizhou\n  Li, Satoshi Nakamura", "title": "VQVAE Unsupervised Unit Discovery and Multi-scale Code2Spec Inverter for\n  Zerospeech Challenge 2019", "comments": "Submitted to Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe our submitted system for the ZeroSpeech Challenge 2019. The\ncurrent challenge theme addresses the difficulty of constructing a speech\nsynthesizer without any text or phonetic labels and requires a system that can\n(1) discover subword units in an unsupervised way, and (2) synthesize the\nspeech with a target speaker's voice. Moreover, the system should also balance\nthe discrimination score ABX, the bit-rate compression rate, and the\nnaturalness and the intelligibility of the constructed voice. To tackle these\nproblems and achieve the best trade-off, we utilize a vector quantized\nvariational autoencoder (VQ-VAE) and a multi-scale codebook-to-spectrogram\n(Code2Spec) inverter trained by mean square error and adversarial loss. The\nVQ-VAE extracts the speech to a latent space, forces itself to map it into the\nnearest codebook and produces compressed representation. Next, the inverter\ngenerates a magnitude spectrogram to the target voice, given the codebook\nvectors from VQ-VAE. In our experiments, we also investigated several other\nclustering algorithms, including K-Means and GMM, and compared them with the\nVQ-VAE result on ABX scores and bit rates. Our proposed approach significantly\nimproved the intelligibility (in CER), the MOS, and discrimination ABX scores\ncompared to the official ZeroSpeech 2019 baseline or even the topline.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 18:59:54 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 10:50:49 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Tjandra", "Andros", ""], ["Sisman", "Berrak", ""], ["Zhang", "Mingyang", ""], ["Sakti", "Sakriani", ""], ["Li", "Haizhou", ""], ["Nakamura", "Satoshi", ""]]}, {"id": "1905.11471", "submitter": "Jasdeep Singh", "authors": "Jasdeep Singh, Bryan McCann, Nitish Shirish Keskar, Caiming Xiong,\n  Richard Socher", "title": "XLDA: Cross-Lingual Data Augmentation for Natural Language Inference and\n  Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While natural language processing systems often focus on a single language,\nmultilingual transfer learning has the potential to improve performance,\nespecially for low-resource languages. We introduce XLDA, cross-lingual data\naugmentation, a method that replaces a segment of the input text with its\ntranslation in another language. XLDA enhances performance of all 14 tested\nlanguages of the cross-lingual natural language inference (XNLI) benchmark.\nWith improvements of up to $4.8\\%$, training with XLDA achieves\nstate-of-the-art performance for Greek, Turkish, and Urdu. XLDA is in contrast\nto, and performs markedly better than, a more naive approach that aggregates\nexamples in various languages in a way that each example is solely in one\nlanguage. On the SQuAD question answering task, we see that XLDA provides a\n$1.0\\%$ performance increase on the English evaluation set. Comprehensive\nexperiments suggest that most languages are effective as cross-lingual\naugmentors, that XLDA is robust to a wide range of translation quality, and\nthat XLDA is even more effective for randomly initialized models than for\npretrained models.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 19:44:33 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Singh", "Jasdeep", ""], ["McCann", "Bryan", ""], ["Keskar", "Nitish Shirish", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "1905.11499", "submitter": "Dongjun Lee", "authors": "Dongjun Lee, Jaesik Yoon, Jongyun Song, Sanggil Lee, Sungroh Yoon", "title": "One-Shot Learning for Text-to-SQL Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DB", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Most deep learning approaches for text-to-SQL generation are limited to the\nWikiSQL dataset, which only supports very simple queries. Recently,\ntemplate-based and sequence-to-sequence approaches were proposed to support\ncomplex queries, which contain join queries, nested queries, and other types.\nHowever, Finegan-Dollak et al. (2018) demonstrated that both the approaches\nlack the ability to generate SQL of unseen templates. In this paper, we propose\na template-based one-shot learning model for the text-to-SQL generation so that\nthe model can generate SQL of an untrained template based on a single example.\nFirst, we classify the SQL template using the Matching Network that is\naugmented by our novel architecture Candidate Search Network. Then, we fill the\nvariable slots in the predicted template using the Pointer Network. We show\nthat our model outperforms state-of-the-art approaches for various text-to-SQL\ndatasets in two aspects: 1) the SQL generation accuracy for the trained\ntemplates, and 2) the adaptability to the unseen SQL templates based on a\nsingle example without any additional training.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 06:29:29 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Lee", "Dongjun", ""], ["Yoon", "Jaesik", ""], ["Song", "Jongyun", ""], ["Lee", "Sanggil", ""], ["Yoon", "Sungroh", ""]]}, {"id": "1905.11531", "submitter": "Amir Ziai", "authors": "Amir Ziai", "title": "Compositional pre-training for neural semantic parsing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic parsing is the process of translating natural language utterances\ninto logical forms, which has many important applications such as question\nanswering and instruction following. Sequence-to-sequence models have been very\nsuccessful across many NLP tasks. However, a lack of task-specific prior\nknowledge can be detrimental to the performance of these models. Prior work has\nused frameworks for inducing grammars over the training examples, which capture\nconditional independence properties that the model can leverage. Inspired by\nthe recent success stories such as BERT we set out to extend this augmentation\nframework into two stages. The first stage is to pre-train using a corpus of\naugmented examples in an unsupervised manner. The second stage is to fine-tune\nto a domain-specific task. In addition, since the pre-training stage is\nseparate from the training on the main task we also expand the universe of\npossible augmentations without causing catastrophic inference. We also propose\na novel data augmentation strategy that interchanges tokens that co-occur in\nsimilar contexts to produce new training pairs. We demonstrate that the\nproposed two-stage framework is beneficial for improving the parsing accuracy\nin a standard dataset called GeoQuery for the task of generating logical forms\nfrom a set of questions about the US geography.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 22:51:39 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Ziai", "Amir", ""]]}, {"id": "1905.11553", "submitter": "Zhiting Hu", "authors": "Jianheng Tang, Tiancheng Zhao, Chenyan Xiong, Xiaodan Liang, Eric P.\n  Xing, Zhiting Hu", "title": "Target-Guided Open-Domain Conversation", "comments": "ACL 2019. Data and code available at\n  https://github.com/squareRoot3/Target-Guided-Conversation. fixed typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world open-domain conversation applications have specific goals to\nachieve during open-ended chats, such as recommendation, psychotherapy,\neducation, etc. We study the problem of imposing conversational goals on\nopen-domain chat agents. In particular, we want a conversational system to chat\nnaturally with human and proactively guide the conversation to a designated\ntarget subject. The problem is challenging as no public data is available for\nlearning such a target-guided strategy. We propose a structured approach that\nintroduces coarse-grained keywords to control the intended content of system\nresponses. We then attain smooth conversation transition through turn-level\nsupervised learning, and drive the conversation towards the target with\ndiscourse-level constraints. We further derive a keyword-augmented conversation\ndataset for the study. Quantitative and human evaluations show our system can\nproduce meaningful and effective conversations, significantly improving over\nother approaches.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 00:55:25 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 01:36:13 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Tang", "Jianheng", ""], ["Zhao", "Tiancheng", ""], ["Xiong", "Chenyan", ""], ["Liang", "Xiaodan", ""], ["Xing", "Eric P.", ""], ["Hu", "Zhiting", ""]]}, {"id": "1905.11558", "submitter": "Ting Huang", "authors": "Ting Huang, Gehui Shen and Zhi-Hong Deng", "title": "Leap-LSTM: Enhancing Long Short-Term Memory for Text Categorization", "comments": "Accepted by IJCAI 2019, 7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) are widely used in the field of natural\nlanguage processing (NLP), ranging from text categorization to question\nanswering and machine translation. However, RNNs generally read the whole text\nfrom beginning to end or vice versa sometimes, which makes it inefficient to\nprocess long texts. When reading a long document for a categorization task,\nsuch as topic categorization, large quantities of words are irrelevant and can\nbe skipped. To this end, we propose Leap-LSTM, an LSTM-enhanced model which\ndynamically leaps between words while reading texts. At each step, we utilize\nseveral feature encoders to extract messages from preceding texts, following\ntexts and the current word, and then determine whether to skip the current\nword. We evaluate Leap-LSTM on several text categorization tasks: sentiment\nanalysis, news categorization, ontology classification and topic\nclassification, with five benchmark data sets. The experimental results show\nthat our model reads faster and predicts better than standard LSTM. Compared to\nprevious models which can also skip words, our model achieves better trade-offs\nbetween performance and efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 01:15:11 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Huang", "Ting", ""], ["Shen", "Gehui", ""], ["Deng", "Zhi-Hong", ""]]}, {"id": "1905.11563", "submitter": "Andy T. Liu", "authors": "Andy T. Liu, Po-chun Hsu, Hung-yi Lee", "title": "Unsupervised End-to-End Learning of Discrete Linguistic Units for Voice\n  Conversion", "comments": "Accepted by Interspeech 2019, Graz, Austria", "journal-ref": "Interspeech 2019", "doi": "10.21437/Interspeech.2019-2048", "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an unsupervised end-to-end training scheme where we discover\ndiscrete subword units from speech without using any labels. The discrete\nsubword units are learned under an ASR-TTS autoencoder reconstruction setting,\nwhere an ASR-Encoder is trained to discover a set of common linguistic units\ngiven a variety of speakers, and a TTS-Decoder trained to project the\ndiscovered units back to the designated speech. We propose a discrete encoding\nmethod, Multilabel-Binary Vectors (MBV), to make the ASR-TTS autoencoder\ndifferentiable. We found that the proposed encoding method offers automatic\nextraction of speech content from speaker style, and is sufficient to cover\nfull linguistic content in a given language. Therefore, the TTS-Decoder can\nsynthesize speech with the same content as the input of ASR-Encoder but with\ndifferent speaker characteristics, which achieves voice conversion (VC). We\nfurther improve the quality of VC using adversarial training, where we train a\nTTS-Patcher that augments the output of TTS-Decoder. Objective and subjective\nevaluations show that the proposed approach offers strong VC results as it\neliminates speaker identity while preserving content within speech. In the\nZeroSpeech 2019 Challenge, we achieved outstanding performance in terms of low\nbitrate.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 01:36:31 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 09:32:39 GMT"}, {"version": "v3", "created": "Thu, 20 Jun 2019 16:05:26 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Liu", "Andy T.", ""], ["Hsu", "Po-chun", ""], ["Lee", "Hung-yi", ""]]}, {"id": "1905.11605", "submitter": "Kun Xu", "authors": "Kun Xu, Liwei Wang, Mo Yu, Yansong Feng, Yan Song, Zhiguo Wang and\n  Dong Yu", "title": "Cross-lingual Knowledge Graph Alignment via Graph Matching Neural\n  Network", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous cross-lingual knowledge graph (KG) alignment studies rely on entity\nembeddings derived only from monolingual KG structural information, which may\nfail at matching entities that have different facts in two KGs. In this paper,\nwe introduce the topic entity graph, a local sub-graph of an entity, to\nrepresent entities with their contextual information in KG. From this view, the\nKB-alignment task can be formulated as a graph matching problem; and we further\npropose a graph-attention based solution, which first matches all entities in\ntwo topic entity graphs, and then jointly model the local matching information\nto derive a graph-level matching vector. Experiments show that our model\noutperforms previous state-of-the-art methods by a large margin.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 04:37:49 GMT"}, {"version": "v2", "created": "Sun, 16 Jun 2019 08:04:55 GMT"}, {"version": "v3", "created": "Mon, 29 Jul 2019 20:55:42 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Xu", "Kun", ""], ["Wang", "Liwei", ""], ["Yu", "Mo", ""], ["Feng", "Yansong", ""], ["Song", "Yan", ""], ["Wang", "Zhiguo", ""], ["Yu", "Dong", ""]]}, {"id": "1905.11658", "submitter": "Jiwei Li", "authors": "Yuxian Meng, Muyu Li, Xiaoya Li, Wei Wu, Jiwei Li", "title": "DSReg: Using Distant Supervision as a Regularizer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we aim at tackling a general issue in NLP tasks where some of\nthe negative examples are highly similar to the positive examples, i.e.,\nhard-negative examples. We propose the distant supervision as a regularizer\n(DSReg) approach to tackle this issue. The original task is converted to a\nmulti-task learning problem, in which distant supervision is used to retrieve\nhard-negative examples. The obtained hard-negative examples are then used as a\nregularizer. The original target objective of distinguishing positive examples\nfrom negative examples is jointly optimized with the auxiliary task objective\nof distinguishing softened positive (i.e., hard-negative examples plus positive\nexamples) from easy-negative examples. In the neural context, this can be done\nby outputting the same representation from the last neural layer to different\n$softmax$ functions. Using this strategy, we can improve the performance of\nbaseline models in a range of different NLP tasks, including text\nclassification, sequence labeling and reading comprehension.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 07:46:50 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 03:48:20 GMT"}, {"version": "v3", "created": "Thu, 26 Sep 2019 04:04:16 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Meng", "Yuxian", ""], ["Li", "Muyu", ""], ["Li", "Xiaoya", ""], ["Wu", "Wei", ""], ["Li", "Jiwei", ""]]}, {"id": "1905.11684", "submitter": "Won Ik Cho", "authors": "Won Ik Cho, Ji Won Kim, Seok Min Kim, Nam Soo Kim", "title": "On Measuring Gender Bias in Translation of Gender-neutral Pronouns", "comments": "Accepted to 1st ACL Workshop on Gender Bias for Natural Language\n  Processing (GeBNLP 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ethics regarding social bias has recently thrown striking issues in natural\nlanguage processing. Especially for gender-related topics, the need for a\nsystem that reduces the model bias has grown in areas such as image captioning,\ncontent recommendation, and automated employment. However, detection and\nevaluation of gender bias in the machine translation systems are not yet\nthoroughly investigated, for the task being cross-lingual and challenging to\ndefine. In this paper, we propose a scheme for making up a test set that\nevaluates the gender bias in a machine translation system, with Korean, a\nlanguage with gender-neutral pronouns. Three word/phrase sets are primarily\nconstructed, each incorporating positive/negative expressions or occupations;\nall the terms are gender-independent or at least not biased to one side\nseverely. Then, additional sentence lists are constructed concerning formality\nof the pronouns and politeness of the sentences. With the generated sentence\nset of size 4,236 in total, we evaluate gender bias in conventional machine\ntranslation systems utilizing the proposed measure, which is termed here as\ntranslation gender bias index (TGBI). The corpus and the code for evaluation is\navailable on-line.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 08:46:56 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Cho", "Won Ik", ""], ["Kim", "Ji Won", ""], ["Kim", "Seok Min", ""], ["Kim", "Nam Soo", ""]]}, {"id": "1905.11716", "submitter": "Nikola Milo\\v{s}evi\\'c Dr", "authors": "Maksim Belousov, Nikola Milosevic, William Dixon, and Goran Nenadic", "title": "Extracting adverse drug reactions and their context using sequence\n  labelling ensembles in TAC2017", "comments": "Paper describing submission for TAC ADR shared task", "journal-ref": "Text Analytics Conference 2017", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Adverse drug reactions (ADRs) are unwanted or harmful effects experienced\nafter the administration of a certain drug or a combination of drugs,\npresenting a challenge for drug development and drug administration. In this\npaper, we present a set of taggers for extracting adverse drug reactions and\nrelated entities, including factors, severity, negations, drug class and\nanimal. The systems used a mix of rule-based, machine learning (CRF) and deep\nlearning (BLSTM with word2vec embeddings) methodologies in order to annotate\nthe data. The systems were submitted to adverse drug reaction shared task,\norganised during Text Analytics Conference in 2017 by National Institute for\nStandards and Technology, archiving F1-scores of 76.00 and 75.61 respectively.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 10:07:01 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Belousov", "Maksim", ""], ["Milosevic", "Nikola", ""], ["Dixon", "William", ""], ["Nenadic", "Goran", ""]]}, {"id": "1905.11806", "submitter": "Andrei Catalin Coman", "authors": "Andrei C. Coman, Koichiro Yoshino, Yukitoshi Murase, Satoshi Nakamura,\n  Giuseppe Riccardi", "title": "An Incremental Turn-Taking Model For Task-Oriented Dialog Systems", "comments": "Accepted to INTERSPEECH 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a human-machine dialog scenario, deciding the appropriate time for the\nmachine to take the turn is an open research problem. In contrast, humans\nengaged in conversations are able to timely decide when to interrupt the\nspeaker for competitive or non-competitive reasons. In state-of-the-art\nturn-by-turn dialog systems the decision on the next dialog action is taken at\nthe end of the utterance. In this paper, we propose a token-by-token prediction\nof the dialog state from incremental transcriptions of the user utterance. To\nidentify the point of maximal understanding in an ongoing utterance, we a)\nimplement an incremental Dialog State Tracker which is updated on a token basis\n(iDST) b) re-label the Dialog State Tracking Challenge 2 (DSTC2) dataset and c)\nadapt it to the incremental turn-taking experimental scenario. The re-labeling\nconsists of assigning a binary value to each token in the user utterance that\nallows to identify the appropriate point for taking the turn. Finally, we\nimplement an incremental Turn Taking Decider (iTTD) that is trained on these\nnew labels for the turn-taking decision. We show that the proposed model can\nachieve a better performance compared to a deterministic handcrafted\nturn-taking algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 13:38:29 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 13:08:09 GMT"}, {"version": "v3", "created": "Thu, 11 Jul 2019 06:37:54 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Coman", "Andrei C.", ""], ["Yoshino", "Koichiro", ""], ["Murase", "Yukitoshi", ""], ["Nakamura", "Satoshi", ""], ["Riccardi", "Giuseppe", ""]]}, {"id": "1905.11833", "submitter": "Mariya Toneva", "authors": "Mariya Toneva and Leila Wehbe", "title": "Interpreting and improving natural-language processing (in machines)\n  with natural language-processing (in the brain)", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks models for NLP are typically implemented without the explicit\nencoding of language rules and yet they are able to break one performance\nrecord after another. This has generated a lot of research interest in\ninterpreting the representations learned by these networks. We propose here a\nnovel interpretation approach that relies on the only processing system we have\nthat does understand language: the human brain. We use brain imaging recordings\nof subjects reading complex natural text to interpret word and sequence\nembeddings from 4 recent NLP models - ELMo, USE, BERT and Transformer-XL. We\nstudy how their representations differ across layer depth, context length, and\nattention type. Our results reveal differences in the context-related\nrepresentations across these models. Further, in the transformer models, we\nfind an interaction between layer depth and context length, and between layer\ndepth and attention type. We finally hypothesize that altering BERT to better\nalign with brain recordings would enable it to also better understand language.\nProbing the altered BERT using syntactic NLP tasks reveals that the model with\nincreased brain-alignment outperforms the original model. Cognitive\nneuroscientists have already begun using NLP networks to study the brain, and\nthis work closes the loop to allow the interaction between NLP and cognitive\nneuroscience to be a true cross-pollination.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 14:13:09 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 14:52:22 GMT"}, {"version": "v3", "created": "Thu, 31 Oct 2019 17:40:56 GMT"}, {"version": "v4", "created": "Wed, 13 Nov 2019 16:25:28 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Toneva", "Mariya", ""], ["Wehbe", "Leila", ""]]}, {"id": "1905.11836", "submitter": "Marie-Christine Bornes-Varol", "authors": "Marie-Christine Bornes-Varol (CERMOM EA 4091), Marie-Sol Ortola (MSH\n  Lorraine), Gronoff Jean-Daniel", "title": "Specific polysemy of the brief sapiential units", "comments": "version pr{\\'e}alable {\\`a} la publication", "journal-ref": "Annual Meeting of the German Society for Computer Science -\n  Informatik 2010, Sep 2010, Leipzig, Germany. pp.523 - 529", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explain how we deal with the problems related to the\nconstitution of the Aliento database, the complexity of which has to do with\nthe type of phrases we work with, the differences between languages, the type\nof information we want to see emerge. The correct tagging of the specific\npolysemy of brief sapiential units is an important step in the preparation of\nthe text within the corpus which will be submitted to compute similarities and\nposterity of the units.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 08:54:26 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Bornes-Varol", "Marie-Christine", "", "CERMOM EA 4091"], ["Ortola", "Marie-Sol", "", "MSH\n  Lorraine"], ["Jean-Daniel", "Gronoff", ""]]}, {"id": "1905.11871", "submitter": "Diane Bouchacourt", "authors": "Diane Bouchacourt and Marco Baroni", "title": "Miss Tools and Mr Fruit: Emergent communication in agents learning about\n  object affordances", "comments": "Association for Computational Linguistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research studies communication emergence in communities of deep\nnetwork agents assigned a joint task, hoping to gain insights on human language\nevolution. We propose here a new task capturing crucial aspects of the human\nenvironment, such as natural object affordances, and of human conversation,\nsuch as full symmetry among the participants. By conducting a thorough\npragmatic and semantic analysis of the emergent protocol, we show that the\nagents solve the shared task through genuine bilateral, referential\ncommunication. However, the agents develop multiple idiolects, which makes us\nconclude that full symmetry is not a sufficient condition for a common language\nto emerge.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 15:10:30 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Bouchacourt", "Diane", ""], ["Baroni", "Marco", ""]]}, {"id": "1905.11901", "submitter": "Rico Sennrich", "authors": "Rico Sennrich and Biao Zhang", "title": "Revisiting Low-Resource Neural Machine Translation: A Case Study", "comments": "to appear at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It has been shown that the performance of neural machine translation (NMT)\ndrops starkly in low-resource conditions, underperforming phrase-based\nstatistical machine translation (PBSMT) and requiring large amounts of\nauxiliary data to achieve competitive results. In this paper, we re-assess the\nvalidity of these results, arguing that they are the result of lack of system\nadaptation to low-resource settings. We discuss some pitfalls to be aware of\nwhen training low-resource NMT systems, and recent techniques that have shown\nto be especially helpful in low-resource settings, resulting in a set of best\npractices for low-resource NMT. In our experiments on German--English with\ndifferent amounts of IWSLT14 training data, we show that, without the use of\nany auxiliary monolingual or multilingual data, an optimized NMT system can\noutperform PBSMT with far less data than previously claimed. We also apply\nthese techniques to a low-resource Korean-English dataset, surpassing\npreviously reported results by 4 BLEU.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 15:59:21 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Sennrich", "Rico", ""], ["Zhang", "Biao", ""]]}, {"id": "1905.11912", "submitter": "Peng Xu", "authors": "Peng Xu, Hamidreza Saghir, Jin Sung Kang, Teng Long, Avishek Joey\n  Bose, Yanshuai Cao and Jackie Chi Kit Cheung", "title": "A Cross-Domain Transferable Neural Coherence Model", "comments": "Accepted at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coherence is an important aspect of text quality and is crucial for ensuring\nits readability. One important limitation of existing coherence models is that\ntraining on one domain does not easily generalize to unseen categories of text.\nPrevious work advocates for generative models for cross-domain generalization,\nbecause for discriminative models, the space of incoherent sentence orderings\nto discriminate against during training is prohibitively large. In this work,\nwe propose a local discriminative neural model with a much smaller negative\nsampling space that can efficiently learn against incorrect orderings. The\nproposed coherence model is simple in structure, yet it significantly\noutperforms previous state-of-art methods on a standard benchmark dataset on\nthe Wall Street Journal corpus, as well as in multiple new challenging settings\nof transfer to unseen categories of discourse on Wikipedia articles.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 16:17:41 GMT"}, {"version": "v2", "created": "Tue, 9 Jul 2019 17:24:56 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Xu", "Peng", ""], ["Saghir", "Hamidreza", ""], ["Kang", "Jin Sung", ""], ["Long", "Teng", ""], ["Bose", "Avishek Joey", ""], ["Cao", "Yanshuai", ""], ["Cheung", "Jackie Chi Kit", ""]]}, {"id": "1905.11975", "submitter": "Peng Xu", "authors": "Peng Xu, Jackie Chi Kit Cheung, Yanshuai Cao", "title": "On Variational Learning of Controllable Representations for Text without\n  Supervision", "comments": "ICML 2020 Camera Ready. Previous title: Unsupervised Controllable\n  Text Generation with Global Variation Discovery and Disentanglement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The variational autoencoder (VAE) can learn the manifold of natural images on\ncertain datasets, as evidenced by meaningful interpolating or extrapolating in\nthe continuous latent space. However, on discrete data such as text, it is\nunclear if unsupervised learning can discover similar latent space that allows\ncontrollable manipulation. In this work, we find that sequence VAEs trained on\ntext fail to properly decode when the latent codes are manipulated, because the\nmodified codes often land in holes or vacant regions in the aggregated\nposterior latent space, where the decoding network fails to generalize. Both as\na validation of the explanation and as a fix to the problem, we propose to\nconstrain the posterior mean to a learned probability simplex, and performs\nmanipulation within this simplex. Our proposed method mitigates the latent\nvacancy problem and achieves the first success in unsupervised learning of\ncontrollable representations for text. Empirically, our method outperforms\nunsupervised baselines and strong supervised approaches on text style transfer,\nand is capable of performing more flexible fine-grained control over text\ngeneration than existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 17:49:47 GMT"}, {"version": "v2", "created": "Sat, 12 Oct 2019 02:47:53 GMT"}, {"version": "v3", "created": "Fri, 7 Feb 2020 21:42:52 GMT"}, {"version": "v4", "created": "Fri, 7 Aug 2020 17:44:10 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Xu", "Peng", ""], ["Cheung", "Jackie Chi Kit", ""], ["Cao", "Yanshuai", ""]]}, {"id": "1905.11978", "submitter": "Peng Xu", "authors": "Yanshuai Cao and Peng Xu", "title": "Better Long-Range Dependency By Bootstrapping A Mutual Information\n  Regularizer", "comments": "Camera-ready for AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we develop a novel regularizer to improve the learning of\nlong-range dependency of sequence data. Applied on language modelling, our\nregularizer expresses the inductive bias that sequence variables should have\nhigh mutual information even though the model might not see abundant\nobservations for complex long-range dependency. We show how the `next sentence\nprediction (classification)' heuristic can be derived in a principled way from\nour mutual information estimation framework, and be further extended to\nmaximize the mutual information of sequence variables. The proposed approach\nnot only is effective at increasing the mutual information of segments under\nthe learned model but more importantly, leads to a higher likelihood on holdout\ndata, and improved generation quality. Code is released at\nhttps://github.com/BorealisAI/BMI.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 17:55:32 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 01:07:44 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Cao", "Yanshuai", ""], ["Xu", "Peng", ""]]}, {"id": "1905.12008", "submitter": "Tomasz Kornuta", "authors": "Tomasz Kornuta and Deepta Rajan and Chaitanya Shivade and Alexis\n  Asseman and Ahmet S. Ozcan", "title": "Leveraging Medical Visual Question Answering with Supporting Facts", "comments": "Working notes from the ImageCLEF 2019 VQA-Med competition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this working notes paper, we describe IBM Research AI (Almaden) team's\nparticipation in the ImageCLEF 2019 VQA-Med competition. The challenge consists\nof four question-answering tasks based on radiology images. The diversity of\nimaging modalities, organs and disease types combined with a small imbalanced\ntraining set made this a highly complex problem. To overcome these\ndifficulties, we implemented a modular pipeline architecture that utilized\ntransfer learning and multi-task learning. Our findings led to the development\nof a novel model called Supporting Facts Network (SFN). The main idea behind\nSFN is to cross-utilize information from upstream tasks to improve the accuracy\non harder downstream ones. This approach significantly improved the scores\nachieved in the validation set (18 point improvement in F-1 score). Finally, we\nsubmitted four runs to the competition and were ranked seventh.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 18:15:52 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Kornuta", "Tomasz", ""], ["Rajan", "Deepta", ""], ["Shivade", "Chaitanya", ""], ["Asseman", "Alexis", ""], ["Ozcan", "Ahmet S.", ""]]}, {"id": "1905.12065", "submitter": "Richard Sproat", "authors": "Richard Sproat, Jan van Santen", "title": "Automatic Ambiguity Detection", "comments": null, "journal-ref": "International Conference on Spoken Language Processing, 1998", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Most work on sense disambiguation presumes that one knows beforehand -- e.g.\nfrom a thesaurus -- a set of polysemous terms. But published lists invariably\ngive only partial coverage. For example, the English word tan has several\nobvious senses, but one may overlook the abbreviation for tangent. In this\npaper, we present an algorithm for identifying interesting polysemous terms and\nmeasuring their degree of polysemy, given an unlabeled corpus. The algorithm\ninvolves: (i) collecting all terms within a k-term window of the target term;\n(ii) computing the inter-term distances of the contextual terms, and reducing\nthe multi-dimensional distance space to two dimensions using standard methods;\n(iii) converting the two-dimensional representation into radial coordinates and\nusing isotonic/antitonic regression to compute the degree to which the\ndistribution deviates from a single-peak model. The amount of deviation is the\nproposed polysemy index\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 20:11:47 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Sproat", "Richard", ""], ["van Santen", "Jan", ""]]}, {"id": "1905.12069", "submitter": "Rafael Torres Anchieta", "authors": "Rafael T. Anchieta, Marco A. S. Cabezudo, Thiago A. S. Pardo", "title": "SEMA: an Extended Semantic Evaluation Metric for AMR", "comments": "Accepted by CICLing 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstract Meaning Representation (AMR) is a recently designed semantic\nrepresentation language intended to capture the meaning of a sentence, which\nmay be represented as a single-rooted directed acyclic graph with labeled nodes\nand edges. The automatic evaluation of this structure plays an important role\nin the development of better systems, as well as for semantic annotation.\nDespite there is one available metric, smatch, it has some drawbacks. For\ninstance, smatch creates a self-relation on the root of the graph, has weights\nfor different error types, and does not take into account the dependence of the\nelements in the AMR structure. With these drawbacks, smatch masks several\nproblems of the AMR parsers and distorts the evaluation of the AMRs. In view of\nthis, in this paper, we introduce an extended metric to evaluate AMR parsers,\nwhich deals with the drawbacks of the smatch metric. Finally, we compare both\nmetrics, using four well-known AMR parsers, and we argue that our metric is\nmore refined, robust, fairer, and faster than smatch.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 20:21:19 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Anchieta", "Rafael T.", ""], ["Cabezudo", "Marco A. S.", ""], ["Pardo", "Thiago A. S.", ""]]}, {"id": "1905.12099", "submitter": "Piero Molino", "authors": "Piero Molino, Yang Wang, Jiawei Zhang", "title": "Parallax: Visualizing and Understanding the Semantics of Embedding\n  Spaces via Algebraic Formulae", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embeddings are a fundamental component of many modern machine learning and\nnatural language processing models. Understanding them and visualizing them is\nessential for gathering insights about the information they capture and the\nbehavior of the models. State of the art in analyzing embeddings consists in\nprojecting them in two-dimensional planes without any interpretable semantics\nassociated to the axes of the projection, which makes detailed analyses and\ncomparison among multiple sets of embeddings challenging. In this work, we\npropose to use explicit axes defined as algebraic formulae over embeddings to\nproject them into a lower dimensional, but semantically meaningful subspace, as\na simple yet effective analysis and visualization methodology. This methodology\nassigns an interpretable semantics to the measures of variability and the axes\nof visualizations, allowing for both comparisons among different sets of\nembeddings and fine-grained inspection of the embedding spaces. We demonstrate\nthe power of the proposed methodology through a series of case studies that\nmake use of visualizations constructed around the underlying methodology and\nthrough a user study. The results show how the methodology is effective at\nproviding more profound insights than classical projection methods and how it\nis widely applicable to many other use cases.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 21:32:02 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Molino", "Piero", ""], ["Wang", "Yang", ""], ["Zhang", "Jiawei", ""]]}, {"id": "1905.12188", "submitter": "Haoyu Song", "authors": "Haoyu Song, Wei-Nan Zhang, Yiming Cui, Dong Wang and Ting Liu", "title": "Exploiting Persona Information for Diverse Generation of Conversational\n  Responses", "comments": "published as a conference paper at IJCAI 2019 (to appear). 7 pages, 1\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In human conversations, due to their personalities in mind, people can easily\ncarry out and maintain the conversations. Giving conversational context with\npersona information to a chatbot, how to exploit the information to generate\ndiverse and sustainable conversations is still a non-trivial task. Previous\nwork on persona-based conversational models successfully make use of predefined\npersona information and have shown great promise in delivering more realistic\nresponses. And they all learn with the assumption that given a source input,\nthere is only one target response. However, in human conversations, there are\nmassive appropriate responses to a given input message. In this paper, we\npropose a memory-augmented architecture to exploit persona information from\ncontext and incorporate a conditional variational autoencoder model together to\ngenerate diverse and sustainable conversations. We evaluate the proposed model\non a benchmark persona-chat dataset. Both automatic and human evaluations show\nthat our model can deliver more diverse and more engaging persona-based\nresponses than baseline approaches.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 02:50:50 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Song", "Haoyu", ""], ["Zhang", "Wei-Nan", ""], ["Cui", "Yiming", ""], ["Wang", "Dong", ""], ["Liu", "Ting", ""]]}, {"id": "1905.12198", "submitter": "Jiangjie Chen", "authors": "Jiangjie Chen, Ao Wang, Haiyun Jiang, Suo Feng, Chenguang Li and\n  Yanghua Xiao", "title": "Ensuring Readability and Data-fidelity using Head-modifier Templates in\n  Deep Type Description Generation", "comments": "ACL 2019", "journal-ref": "Proceedings of the 57th Annual Meeting of the Association for\n  Computational Linguistics. 2019", "doi": "10.18653/v1/P19-1196", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A type description is a succinct noun compound which helps human and machines\nto quickly grasp the informative and distinctive information of an entity.\nEntities in most knowledge graphs (KGs) still lack such descriptions, thus\ncalling for automatic methods to supplement such information. However, existing\ngenerative methods either overlook the grammatical structure or make factual\nmistakes in generated texts. To solve these problems, we propose a\nhead-modifier template-based method to ensure the readability and data fidelity\nof generated type descriptions. We also propose a new dataset and two automatic\nmetrics for this task. Experiments show that our method improves substantially\ncompared with baselines and achieves state-of-the-art performance on both\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 03:32:38 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Chen", "Jiangjie", ""], ["Wang", "Ao", ""], ["Jiang", "Haiyun", ""], ["Feng", "Suo", ""], ["Li", "Chenguang", ""], ["Xiao", "Yanghua", ""]]}, {"id": "1905.12230", "submitter": "Naoyuki Kanda", "authors": "Naoyuki Kanda, Christoph Boeddeker, Jens Heitkaemper, Yusuke Fujita,\n  Shota Horiguchi, Kenji Nagamatsu, Reinhold Haeb-Umbach", "title": "Guided Source Separation Meets a Strong ASR Backend: Hitachi/Paderborn\n  University Joint Investigation for Dinner Party ASR", "comments": "Accepted to INTERSPEECH 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present Hitachi and Paderborn University's joint effort for\nautomatic speech recognition (ASR) in a dinner party scenario. The main\nchallenges of ASR systems for dinner party recordings obtained by multiple\nmicrophone arrays are (1) heavy speech overlaps, (2) severe noise and\nreverberation, (3) very natural conversational content, and possibly (4)\ninsufficient training data. As an example of a dinner party scenario, we have\nchosen the data presented during the CHiME-5 speech recognition challenge,\nwhere the baseline ASR had a 73.3% word error rate (WER), and even the best\nperforming system at the CHiME-5 challenge had a 46.1% WER. We extensively\ninvestigated a combination of the guided source separation-based speech\nenhancement technique and an already proposed strong ASR backend and found that\na tight combination of these techniques provided substantial accuracy\nimprovements. Our final system achieved WERs of 39.94% and 41.64% for the\ndevelopment and evaluation data, respectively, both of which are the best\npublished results for the dataset. We also investigated with additional\ntraining data on the official small data in the CHiME-5 corpus to assess the\nintrinsic difficulty of this ASR task.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 05:50:35 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 05:59:57 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Kanda", "Naoyuki", ""], ["Boeddeker", "Christoph", ""], ["Heitkaemper", "Jens", ""], ["Fujita", "Yusuke", ""], ["Horiguchi", "Shota", ""], ["Nagamatsu", "Kenji", ""], ["Haeb-Umbach", "Reinhold", ""]]}, {"id": "1905.12255", "submitter": "Vihan Jain", "authors": "Vihan Jain, Gabriel Magalhaes, Alexander Ku, Ashish Vaswani, Eugene\n  Ie, Jason Baldridge", "title": "Stay on the Path: Instruction Fidelity in Vision-and-Language Navigation", "comments": "Accepted at ACL 2019 as long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Advances in learning and representations have reinvigorated work that\nconnects language to other modalities. A particularly exciting direction is\nVision-and-Language Navigation(VLN), in which agents interpret natural language\ninstructions and visual scenes to move through environments and reach goals.\nDespite recent progress, current research leaves unclear how much of a role\nlanguage understanding plays in this task, especially because dominant\nevaluation metrics have focused on goal completion rather than the sequence of\nactions corresponding to the instructions. Here, we highlight shortcomings of\ncurrent metrics for the Room-to-Room dataset (Anderson et al.,2018b) and\npropose a new metric, Coverage weighted by Length Score (CLS). We also show\nthat the existing paths in the dataset are not ideal for evaluating instruction\nfollowing because they are direct-to-goal shortest paths. We join existing\nshort paths to form more challenging extended paths to create a new data set,\nRoom-for-Room (R4R). Using R4R and CLS, we show that agents that receive\nrewards for instruction fidelity outperform agents that focus on goal\ncompletion.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 07:40:38 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 04:59:49 GMT"}, {"version": "v3", "created": "Fri, 21 Jun 2019 16:55:06 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Jain", "Vihan", ""], ["Magalhaes", "Gabriel", ""], ["Ku", "Alexander", ""], ["Vaswani", "Ashish", ""], ["Ie", "Eugene", ""], ["Baldridge", "Jason", ""]]}, {"id": "1905.12260", "submitter": "Karan Singhal", "authors": "Karan Singhal, Karthik Raman, Balder ten Cate", "title": "Learning Multilingual Word Embeddings Using Image-Text Data", "comments": null, "journal-ref": null, "doi": "10.18653/v1/W19-1807", "report-no": "W19-1807", "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been significant interest recently in learning multilingual word\nembeddings -- in which semantically similar words across languages have similar\nembeddings. State-of-the-art approaches have relied on expensive labeled data,\nwhich is unavailable for low-resource languages, or have involved post-hoc\nunification of monolingual embeddings. In the present paper, we investigate the\nefficacy of multilingual embeddings learned from weakly-supervised image-text\ndata. In particular, we propose methods for learning multilingual embeddings\nusing image-text data, by enforcing similarity between the representations of\nthe image and that of the text. Our experiments reveal that even without using\nany expensive labeled data, a bag-of-words-based embedding model trained on\nimage-text data achieves performance comparable to the state-of-the-art on\ncrosslingual semantic similarity tasks.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 07:55:17 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Singhal", "Karan", ""], ["Raman", "Karthik", ""], ["Cate", "Balder ten", ""]]}, {"id": "1905.12277", "submitter": "Minlong Peng", "authors": "Minlong Peng, Qi Zhang, Xiaoyu Xing, Tao Gui, Jinlan Fu, Xuanjing\n  Huang", "title": "Learning Task-specific Representation for Novel Words in Sequence\n  Labeling", "comments": "This work has been accepted by IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word representation is a key component in neural-network-based sequence\nlabeling systems. However, representations of unseen or rare words trained on\nthe end task are usually poor for appreciable performance. This is commonly\nreferred to as the out-of-vocabulary (OOV) problem. In this work, we address\nthe OOV problem in sequence labeling using only training data of the task. To\nthis end, we propose a novel method to predict representations for OOV words\nfrom their surface-forms (e.g., character sequence) and contexts. The method is\nspecifically designed to avoid the error propagation problem suffered by\nexisting approaches in the same paradigm. To evaluate its effectiveness, we\nperformed extensive empirical studies on four part-of-speech tagging (POS)\ntasks and four named entity recognition (NER) tasks. Experimental results show\nthat the proposed method can achieve better or competitive performance on the\nOOV problem compared with existing state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 08:58:52 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Peng", "Minlong", ""], ["Zhang", "Qi", ""], ["Xing", "Xiaoyu", ""], ["Gui", "Tao", ""], ["Fu", "Jinlan", ""], ["Huang", "Xuanjing", ""]]}, {"id": "1905.12304", "submitter": "Dayiheng Liu", "authors": "Dayiheng Liu, Jie Fu, Yidan Zhang, Chris Pal, Jiancheng Lv", "title": "Revision in Continuous Space: Unsupervised Text Style Transfer without\n  Adversarial Learning", "comments": "Association for the Advancement of Artificial Intelligence. AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typical methods for unsupervised text style transfer often rely on two key\ningredients: 1) seeking the explicit disentanglement of the content and the\nattributes, and 2) troublesome adversarial learning. In this paper, we show\nthat neither of these components is indispensable. We propose a new framework\nthat utilizes the gradients to revise the sentence in a continuous space during\ninference to achieve text style transfer. Our method consists of three key\ncomponents: a variational auto-encoder (VAE), some attribute predictors (one\nfor each attribute), and a content predictor. The VAE and the two types of\npredictors enable us to perform gradient-based optimization in the continuous\nspace, which is mapped from sentences in a discrete space, to find the\nrepresentation of a target sentence with the desired attributes and preserved\ncontent. Moreover, the proposed method naturally has the ability to\nsimultaneously manipulate multiple fine-grained attributes, such as sentence\nlength and the presence of specific words, when performing text style transfer\ntasks. Compared with previous adversarial learning based methods, the proposed\nmethod is more interpretable, controllable and easier to train. Extensive\nexperimental studies on three popular text style transfer tasks show that the\nproposed method significantly outperforms five state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 10:07:12 GMT"}, {"version": "v2", "created": "Sun, 2 Jun 2019 05:29:04 GMT"}, {"version": "v3", "created": "Tue, 19 Nov 2019 12:04:49 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Liu", "Dayiheng", ""], ["Fu", "Jie", ""], ["Zhang", "Yidan", ""], ["Pal", "Chris", ""], ["Lv", "Jiancheng", ""]]}, {"id": "1905.12330", "submitter": "Rahma Chaabouni", "authors": "Rahma Chaabouni, Eugene Kharitonov, Alessandro Lazaric, Emmanuel\n  Dupoux and Marco Baroni", "title": "Word-order biases in deep-agent emergent communication", "comments": "Conference: Association for Computational Linguistics (ACL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-processing neural networks led to remarkable progress on many NLP\ntasks. As a consequence, there has been increasing interest in understanding to\nwhat extent they process language as humans do. We aim here to uncover which\nbiases such models display with respect to \"natural\" word-order constraints. We\ntrain models to communicate about paths in a simple gridworld, using miniature\nlanguages that reflect or violate various natural language trends, such as the\ntendency to avoid redundancy or to minimize long-distance dependencies. We\nstudy how the controlled characteristics of our miniature languages affect\nindividual learning and their stability across multiple network generations.\nThe results draw a mixed picture. On the one hand, neural networks show a\nstrong tendency to avoid long-distance dependencies. On the other hand, there\nis no clear preference for the efficient, non-redundant encoding of information\nthat is widely attested in natural language. We thus suggest inoculating a\nnotion of \"effort\" into neural networks, as a possible way to make their\nlinguistic behavior more human-like.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 11:17:59 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 16:52:47 GMT"}, {"version": "v3", "created": "Fri, 14 Jun 2019 08:08:45 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Chaabouni", "Rahma", ""], ["Kharitonov", "Eugene", ""], ["Lazaric", "Alessandro", ""], ["Dupoux", "Emmanuel", ""], ["Baroni", "Marco", ""]]}, {"id": "1905.12335", "submitter": "Satya Almasian", "authors": "Andreas Spitz and Satya Almasian and Michael Gertz", "title": "TopExNet: Entity-Centric Network Topic Exploration in News Streams", "comments": "Published in Proceedings of the Twelfth ACM International Conference\n  on Web Search and Data Mining, WSDM 2019, Melbourne, VIC, Australia, February\n  11-15, 2019", "journal-ref": null, "doi": "10.1145/3289600.3290619", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent introduction of entity-centric implicit network representations of\nunstructured text offers novel ways for exploring entity relations in document\ncollections and streams efficiently and interactively. Here, we present\nTopExNet as a tool for exploring entity-centric network topics in streams of\nnews articles. The application is available as a web service at\nhttps://topexnet.ifi.uni-heidelberg.de/ .\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 11:28:37 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 12:36:06 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Spitz", "Andreas", ""], ["Almasian", "Satya", ""], ["Gertz", "Michael", ""]]}, {"id": "1905.12356", "submitter": "Ayten Ozge Akmandor", "authors": "Ayten Ozge Akmandor, Jorge Ortiz, Irene Manotas, Bongjun Ko, and Niraj\n  K. Jha", "title": "SECRET: Semantically Enhanced Classification of Real-world Tasks", "comments": "16 pages, 20 figures, 2 tables - IEEE Transactions on Computers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised machine learning (ML) algorithms are aimed at maximizing\nclassification performance under available energy and storage constraints. They\ntry to map the training data to the corresponding labels while ensuring\ngeneralizability to unseen data. However, they do not integrate meaning-based\nrelationships among labels in the decision process. On the other hand, natural\nlanguage processing (NLP) algorithms emphasize the importance of semantic\ninformation. In this paper, we synthesize the complementary advantages of\nsupervised ML and NLP algorithms into one method that we refer to as SECRET\n(Semantically Enhanced Classification of REal-world Tasks). SECRET performs\nclassifications by fusing the semantic information of the labels with the\navailable data: it combines the feature space of the supervised algorithms with\nthe semantic space of the NLP algorithms and predicts labels based on this\njoint space. Experimental results indicate that, compared to traditional\nsupervised learning, SECRET achieves up to 14.0% accuracy and 13.1% F1 score\nimprovements. Moreover, compared to ensemble methods, SECRET achieves up to\n12.7% accuracy and 13.3% F1 score improvements. This points to a new research\ndirection for supervised classification based on incorporation of semantic\ninformation.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 12:05:31 GMT"}, {"version": "v2", "created": "Sat, 26 Oct 2019 16:53:02 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2020 01:56:52 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Akmandor", "Ayten Ozge", ""], ["Ortiz", "Jorge", ""], ["Manotas", "Irene", ""], ["Ko", "Bongjun", ""], ["Jha", "Niraj K.", ""]]}, {"id": "1905.12480", "submitter": "Hongtao Liu", "authors": "Hongtao Liu, Fangzhao Wu, Wenjun Wang, Xianchen Wang, Pengfei Jiao,\n  Chuhan Wu, Xing Xie", "title": "NRPA: Neural Recommendation with Personalized Attention", "comments": "4 pages, 4 figures", "journal-ref": "sigir 2019", "doi": "10.1145/3331184.3331371", "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing review-based recommendation methods usually use the same model to\nlearn the representations of all users/items from reviews posted by users\ntowards items. However, different users have different preference and different\nitems have different characteristics. Thus, the same word or similar reviews\nmay have different informativeness for different users and items. In this paper\nwe propose a neural recommendation approach with personalized attention to\nlearn personalized representations of users and items from reviews. We use a\nreview encoder to learn representations of reviews from words, and a user/item\nencoder to learn representations of users or items from reviews. We propose a\npersonalized attention model, and apply it to both review and user/item\nencoders to select different important words and reviews for different\nusers/items. Experiments on five datasets validate our approach can effectively\nimprove the performance of neural recommendation.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 14:16:17 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Liu", "Hongtao", ""], ["Wu", "Fangzhao", ""], ["Wang", "Wenjun", ""], ["Wang", "Xianchen", ""], ["Jiao", "Pengfei", ""], ["Wu", "Chuhan", ""], ["Xie", "Xing", ""]]}, {"id": "1905.12516", "submitter": "Thomas Davidson", "authors": "Thomas Davidson, Debasmita Bhattacharya, Ingmar Weber", "title": "Racial Bias in Hate Speech and Abusive Language Detection Datasets", "comments": "To appear in the proceedings of the Third Abusive Language Workshop\n  (https://sites.google.com/view/alw3/) at the Annual Meeting for the\n  Association for Computational Linguistics 2019. Please cite the published\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technologies for abusive language detection are being developed and applied\nwith little consideration of their potential biases. We examine racial bias in\nfive different sets of Twitter data annotated for hate speech and abusive\nlanguage. We train classifiers on these datasets and compare the predictions of\nthese classifiers on tweets written in African-American English with those\nwritten in Standard American English. The results show evidence of systematic\nracial bias in all datasets, as classifiers trained on them tend to predict\nthat tweets written in African-American English are abusive at substantially\nhigher rates. If these abusive language detection systems are used in the field\nthey will therefore have a disproportionate negative impact on African-American\nsocial media users. Consequently, these systems may discriminate against the\ngroups who are often the targets of the abuse we are trying to detect.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 15:12:58 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Davidson", "Thomas", ""], ["Bhattacharya", "Debasmita", ""], ["Weber", "Ingmar", ""]]}, {"id": "1905.12561", "submitter": "Rahma Chaabouni", "authors": "Rahma Chaabouni, Eugene Kharitonov, Emmanuel Dupoux and Marco Baroni", "title": "Anti-efficient encoding in emergent communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite renewed interest in emergent language simulations with neural\nnetworks, little is known about the basic properties of the induced code, and\nhow they compare to human language. One fundamental characteristic of the\nlatter, known as Zipf's Law of Abbreviation (ZLA), is that more frequent words\nare efficiently associated to shorter strings. We study whether the same\npattern emerges when two neural networks, a \"speaker\" and a \"listener\", are\ntrained to play a signaling game. Surprisingly, we find that networks develop\nan \\emph{anti-efficient} encoding scheme, in which the most frequent inputs are\nassociated to the longest messages, and messages in general are skewed towards\nthe maximum length threshold. This anti-efficient code appears easier to\ndiscriminate for the listener, and, unlike in human communication, the speaker\ndoes not impose a contrasting least-effort pressure towards brevity. Indeed,\nwhen the cost function includes a penalty for longer messages, the resulting\nmessage distribution starts respecting ZLA. Our analysis stresses the\nimportance of studying the basic features of emergent communication in a highly\ncontrolled setup, to ensure the latter will not strand too far from human\nlanguage. Moreover, we present a concrete illustration of how different\nfunctional pressures can lead to successful communication codes that lack basic\nproperties of human language, thus highlighting the role such pressures play in\nthe latter.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 16:14:24 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 16:46:47 GMT"}, {"version": "v3", "created": "Thu, 13 Jun 2019 16:58:54 GMT"}, {"version": "v4", "created": "Tue, 15 Oct 2019 11:56:14 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Chaabouni", "Rahma", ""], ["Kharitonov", "Eugene", ""], ["Dupoux", "Emmanuel", ""], ["Baroni", "Marco", ""]]}, {"id": "1905.12595", "submitter": "Mihai P\\^irvu", "authors": "Mihai Cristian P\\^irvu and Alexandra Anghel", "title": "Predicting next shopping stage using Google Analytics data for\n  E-commerce applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  E-commerce web applications are almost ubiquitous in our day to day life,\nhowever as useful as they are, most of them have little to no adaptation to\nuser needs, which in turn can cause both lower conversion rates as well as\nunsatisfied customers. We propose a machine learning system which learns the\nuser behaviour from multiple previous sessions and predicts useful metrics for\nthe current session. In turn, these metrics can be used by the applications to\ncustomize and better target the customer, which can mean anything from offering\nbetter offers of specific products, targeted notifications or placing smart\nads. The data used for the learning algorithm is extracted from Google\nAnalytics Enhanced E-commerce, which is enabled by most e-commerce websites and\nthus the system can be used by any such merchant. In order to learn the user\npatterns, only its behaviour features were used, which don't include names,\ngender or any other personal information that could identify the user. The\nlearning model that was used is a double recurrent neural network which learns\nboth intra-session and inter-session features. The model predicts for each\nsession a probability score for each of the defined target classes.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 17:14:24 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["P\u00eervu", "Mihai Cristian", ""], ["Anghel", "Alexandra", ""]]}, {"id": "1905.12598", "submitter": "Asaf Amrami", "authors": "Asaf Amrami and Yoav Goldberg", "title": "Towards better substitution-based word sense induction", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word sense induction (WSI) is the task of unsupervised clustering of word\nusages within a sentence to distinguish senses. Recent work obtain strong\nresults by clustering lexical substitutes derived from pre-trained RNN language\nmodels (ELMo). Adapting the method to BERT improves the scores even further. We\nextend the previous method to support a dynamic rather than a fixed number of\nclusters as supported by other prominent methods, and propose a method for\ninterpreting the resulting clusters by associating them with their most\ninformative substitutes. We then perform extensive error analysis revealing the\nremaining sources of errors in the WSI task.\n  Our code is available at https://github.com/asafamr/bertwsi.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 17:20:11 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 06:46:55 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Amrami", "Asaf", ""], ["Goldberg", "Yoav", ""]]}, {"id": "1905.12616", "submitter": "Rowan Zellers", "authors": "Rowan Zellers, Ari Holtzman, Hannah Rashkin, Yonatan Bisk, Ali\n  Farhadi, Franziska Roesner, Yejin Choi", "title": "Defending Against Neural Fake News", "comments": "NeurIPS 2019 camera ready version. Project page/code/demo at\n  https://rowanzellers.com/grover", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in natural language generation has raised dual-use concerns.\nWhile applications like summarization and translation are positive, the\nunderlying technology also might enable adversaries to generate neural fake\nnews: targeted propaganda that closely mimics the style of real news.\n  Modern computer security relies on careful threat modeling: identifying\npotential threats and vulnerabilities from an adversary's point of view, and\nexploring potential mitigations to these threats. Likewise, developing robust\ndefenses against neural fake news requires us first to carefully investigate\nand characterize the risks of these models. We thus present a model for\ncontrollable text generation called Grover. Given a headline like `Link Found\nBetween Vaccines and Autism,' Grover can generate the rest of the article;\nhumans find these generations to be more trustworthy than human-written\ndisinformation.\n  Developing robust verification techniques against generators like Grover is\ncritical. We find that best current discriminators can classify neural fake\nnews from real, human-written, news with 73% accuracy, assuming access to a\nmoderate level of training data. Counterintuitively, the best defense against\nGrover turns out to be Grover itself, with 92% accuracy, demonstrating the\nimportance of public release of strong generators. We investigate these results\nfurther, showing that exposure bias -- and sampling strategies that alleviate\nits effects -- both leave artifacts that similar discriminators can pick up on.\nWe conclude by discussing ethical issues regarding the technology, and plan to\nrelease Grover publicly, helping pave the way for better detection of neural\nfake news.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 17:58:52 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 21:37:14 GMT"}, {"version": "v3", "created": "Fri, 11 Dec 2020 16:17:17 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Zellers", "Rowan", ""], ["Holtzman", "Ari", ""], ["Rashkin", "Hannah", ""], ["Bisk", "Yonatan", ""], ["Farhadi", "Ali", ""], ["Roesner", "Franziska", ""], ["Choi", "Yejin", ""]]}, {"id": "1905.12676", "submitter": "Agnieszka Fale\\'nska", "authors": "Agnieszka Falenska and Jonas Kuhn", "title": "The (Non-)Utility of Structural Features in BiLSTM-based Dependency\n  Parsers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical non-neural dependency parsers put considerable effort on the design\nof feature functions. Especially, they benefit from information coming from\nstructural features, such as features drawn from neighboring tokens in the\ndependency tree. In contrast, their BiLSTM-based successors achieve\nstate-of-the-art performance without explicit information about the structural\ncontext. In this paper we aim to answer the question: How much structural\ncontext are the BiLSTM representations able to capture implicitly? We show that\nfeatures drawn from partial subtrees become redundant when the BiLSTMs are\nused. We provide a deep insight into information flow in transition- and\ngraph-based neural architectures to demonstrate where the implicit information\ncomes from when the parsers make their decisions. Finally, with model ablations\nwe demonstrate that the structural context is not only present in the models,\nbut it significantly influences their performance.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 18:49:03 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 09:10:34 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Falenska", "Agnieszka", ""], ["Kuhn", "Jonas", ""]]}, {"id": "1905.12688", "submitter": "Graham Neubig", "authors": "Yu-Hsiang Lin, Chian-Yu Chen, Jean Lee, Zirui Li, Yuyan Zhang,\n  Mengzhou Xia, Shruti Rijhwani, Junxian He, Zhisong Zhang, Xuezhe Ma, Antonios\n  Anastasopoulos, Patrick Littell, Graham Neubig", "title": "Choosing Transfer Languages for Cross-Lingual Learning", "comments": "Proceedings of ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual transfer, where a high-resource transfer language is used to\nimprove the accuracy of a low-resource task language, is now an invaluable tool\nfor improving performance of natural language processing (NLP) on low-resource\nlanguages. However, given a particular task language, it is not clear which\nlanguage to transfer from, and the standard strategy is to select languages\nbased on ad hoc criteria, usually the intuition of the experimenter. Since a\nlarge number of features contribute to the success of cross-lingual transfer\n(including phylogenetic similarity, typological properties, lexical overlap, or\nsize of available data), even the most enlightened experimenter rarely\nconsiders all these factors for the particular task at hand. In this paper, we\nconsider this task of automatically selecting optimal transfer languages as a\nranking problem, and build models that consider the aforementioned features to\nperform this prediction. In experiments on representative NLP tasks, we\ndemonstrate that our model predicts good transfer languages much better than ad\nhoc baselines considering single features in isolation, and glean insights on\nwhat features are most informative for each different NLP tasks, which may\ninform future ad hoc selection even without use of our method. Code, data, and\npre-trained models are available at https://github.com/neulab/langrank\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 19:19:47 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 03:37:25 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Lin", "Yu-Hsiang", ""], ["Chen", "Chian-Yu", ""], ["Lee", "Jean", ""], ["Li", "Zirui", ""], ["Zhang", "Yuyan", ""], ["Xia", "Mengzhou", ""], ["Rijhwani", "Shruti", ""], ["He", "Junxian", ""], ["Zhang", "Zhisong", ""], ["Ma", "Xuezhe", ""], ["Anastasopoulos", "Antonios", ""], ["Littell", "Patrick", ""], ["Neubig", "Graham", ""]]}, {"id": "1905.12713", "submitter": "Andrew Halterman", "authors": "Andrew Halterman", "title": "Geolocating Political Events in Text", "comments": "NAACL 2019, NLP+CSS Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces a general method for automatically finding the locations\nwhere political events in text occurred. Using a novel set of 8,000 labeled\nsentences, I create a method to link automatically extracted events and\nlocations in text. The model achieves human level performance on the annotation\ntask and outperforms previous event geolocation systems. It can be applied to\nmost event extraction systems across geographic contexts. I formalize the\nevent--location linking task, describe the neural network model, describe the\npotential uses of such a system in political science, and demonstrate a\nworkflow to answer an open question on the role of conventional military\noffensives in causing civilian casualties in the Syrian civil war.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 20:40:24 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Halterman", "Andrew", ""]]}, {"id": "1905.12730", "submitter": "Rina Panigrahy", "authors": "Badih Ghazi, Rina Panigrahy, Joshua R. Wang", "title": "Recursive Sketches for Modular Deep Learning", "comments": "Published in ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a mechanism to compute a sketch (succinct summary) of how a\ncomplex modular deep network processes its inputs. The sketch summarizes\nessential information about the inputs and outputs of the network and can be\nused to quickly identify key components and summary statistics of the inputs.\nFurthermore, the sketch is recursive and can be unrolled to identify\nsub-components of these components and so forth, capturing a potentially\ncomplicated DAG structure. These sketches erase gracefully; even if we erase a\nfraction of the sketch at random, the remainder still retains the `high-weight'\ninformation present in the original sketch. The sketches can also be organized\nin a repository to implicitly form a `knowledge graph'; it is possible to\nquickly retrieve sketches in the repository that are related to a sketch of\ninterest; arranged in this fashion, the sketches can also be used to learn\nemerging concepts by looking for new clusters in sketch space. Finally, in the\nscenario where we want to learn a ground truth deep network, we show that\naugmenting input/output pairs with these sketches can theoretically make it\neasier to do so.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 21:10:58 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 22:36:23 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Ghazi", "Badih", ""], ["Panigrahy", "Rina", ""], ["Wang", "Joshua R.", ""]]}, {"id": "1905.12741", "submitter": "Victor Veitch", "authors": "Victor Veitch and Dhanya Sridhar and David M. Blei", "title": "Adapting Text Embeddings for Causal Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Does adding a theorem to a paper affect its chance of acceptance? Does\nlabeling a post with the author's gender affect the post popularity? This paper\ndevelops a method to estimate such causal effects from observational text data,\nadjusting for confounding features of the text such as the subject or writing\nquality. We assume that the text suffices for causal adjustment but that, in\npractice, it is prohibitively high-dimensional. To address this challenge, we\ndevelop causally sufficient embeddings, low-dimensional document\nrepresentations that preserve sufficient information for causal identification\nand allow for efficient estimation of causal effects. Causally sufficient\nembeddings combine two ideas. The first is supervised dimensionality reduction:\ncausal adjustment requires only the aspects of text that are predictive of both\nthe treatment and outcome. The second is efficient language modeling:\nrepresentations of text are designed to dispose of linguistically irrelevant\ninformation, and this information is also causally irrelevant. Our method\nadapts language models (specifically, word embeddings and topic models) to\nlearn document embeddings that are able to predict both treatment and outcome.\nWe study causally sufficient embeddings with semi-synthetic datasets and find\nthat they improve causal estimation over related embedding methods. We\nillustrate the methods by answering the two motivating questions---the effect\nof a theorem on paper acceptance and the effect of a gender label on post\npopularity. Code and data available at\nhttps://github.com/vveitch/causal-text-embeddings-tf2}{github.com/vveitch/causal-text-embeddings-tf2\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 21:29:37 GMT"}, {"version": "v2", "created": "Sat, 25 Jul 2020 21:00:39 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Veitch", "Victor", ""], ["Sridhar", "Dhanya", ""], ["Blei", "David M.", ""]]}, {"id": "1905.12752", "submitter": "Aurko Roy", "authors": "Aurko Roy and David Grangier", "title": "Unsupervised Paraphrasing without Translation", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Paraphrasing exemplifies the ability to abstract semantic content from\nsurface forms. Recent work on automatic paraphrasing is dominated by methods\nleveraging Machine Translation (MT) as an intermediate step. This contrasts\nwith humans, who can paraphrase without being bilingual. This work proposes to\nlearn paraphrasing models from an unlabeled monolingual corpus only. To that\nend, we propose a residual variant of vector-quantized variational\nauto-encoder.\n  We compare with MT-based approaches on paraphrase identification, generation,\nand training augmentation. Monolingual paraphrasing outperforms unsupervised\ntranslation in all settings. Comparisons with supervised translation are more\nmixed: monolingual paraphrasing is interesting for identification and\naugmentation; supervised translation is superior for generation.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 22:15:38 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Roy", "Aurko", ""], ["Grangier", "David", ""]]}, {"id": "1905.12777", "submitter": "Tianxiao Shen", "authors": "Tianxiao Shen, Jonas Mueller, Regina Barzilay, Tommi Jaakkola", "title": "Educating Text Autoencoders: Latent Representation Guidance via\n  Denoising", "comments": "ICML 2020 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative autoencoders offer a promising approach for controllable text\ngeneration by leveraging their latent sentence representations. However,\ncurrent models struggle to maintain coherent latent spaces required to perform\nmeaningful text manipulations via latent vector operations. Specifically, we\ndemonstrate by example that neural encoders do not necessarily map similar\nsentences to nearby latent vectors. A theoretical explanation for this\nphenomenon establishes that high capacity autoencoders can learn an arbitrary\nmapping between sequences and associated latent representations. To remedy this\nissue, we augment adversarial autoencoders with a denoising objective where\noriginal sentences are reconstructed from perturbed versions (referred to as\nDAAE). We prove that this simple modification guides the latent space geometry\nof the resulting model by encouraging the encoder to map similar texts to\nsimilar latent representations. In empirical comparisons with various types of\nautoencoders, our model provides the best trade-off between generation quality\nand reconstruction capacity. Moreover, the improved geometry of the DAAE latent\nspace enables zero-shot text style transfer via simple latent vector\narithmetic.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 23:22:56 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 04:33:41 GMT"}, {"version": "v3", "created": "Tue, 7 Jul 2020 17:51:30 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Shen", "Tianxiao", ""], ["Mueller", "Jonas", ""], ["Barzilay", "Regina", ""], ["Jaakkola", "Tommi", ""]]}, {"id": "1905.12786", "submitter": "Anjishnu Kumar", "authors": "Daniele Bonadiman, Anjishnu Kumar and Arpit Mittal", "title": "Large Scale Question Paraphrase Retrieval with Smoothed Deep Metric\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of a Question Paraphrase Retrieval (QPR) system is to retrieve\nequivalent questions that result in the same answer as the original question.\nSuch a system can be used to understand and answer rare and noisy\nreformulations of common questions by mapping them to a set of canonical forms.\nThis has large-scale applications for community Question Answering (cQA) and\nopen-domain spoken language question answering systems. In this paper we\ndescribe a new QPR system implemented as a Neural Information Retrieval (NIR)\nsystem consisting of a neural network sentence encoder and an approximate\nk-Nearest Neighbour index for efficient vector retrieval. We also describe our\nmechanism to generate an annotated dataset for question paraphrase retrieval\nexperiments automatically from question-answer logs via distant supervision. We\nshow that the standard loss function in NIR, triplet loss, does not perform\nwell with noisy labels. We propose smoothed deep metric loss (SDML) and with\nour experiments on two QPR datasets we show that it significantly outperforms\ntriplet loss in the noisy label setting.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 23:40:54 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Bonadiman", "Daniele", ""], ["Kumar", "Anjishnu", ""], ["Mittal", "Arpit", ""]]}, {"id": "1905.12790", "submitter": "Elman Mansimov", "authors": "Elman Mansimov, Alex Wang, Sean Welleck, Kyunghyun Cho", "title": "A Generalized Framework of Sequence Generation with Application to\n  Undirected Sequence Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Undirected neural sequence models such as BERT (Devlin et al., 2019) have\nreceived renewed interest due to their success on discriminative natural\nlanguage understanding tasks such as question-answering and natural language\ninference. The problem of generating sequences directly from these models has\nreceived relatively little attention, in part because generating from\nundirected models departs significantly from conventional monotonic generation\nin directed sequence models. We investigate this problem by proposing a\ngeneralized model of sequence generation that unifies decoding in directed and\nundirected models. The proposed framework models the process of generation\nrather than the resulting sequence, and under this framework, we derive various\nneural sequence models as special cases, such as autoregressive,\nsemi-autoregressive, and refinement-based non-autoregressive models. This\nunification enables us to adapt decoding algorithms originally developed for\ndirected sequence models to undirected sequence models. We demonstrate this by\nevaluating various handcrafted and learned decoding strategies on a BERT-like\nmachine translation model (Lample & Conneau, 2019). The proposed approach\nachieves constant-time translation results on par with linear-time translation\nresults from the same undirected sequence model, while both are competitive\nwith the state-of-the-art on WMT'14 English-German translation.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 23:47:17 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 13:18:42 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Mansimov", "Elman", ""], ["Wang", "Alex", ""], ["Welleck", "Sean", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1905.12801", "submitter": "Yusu Qian", "authors": "Yusu Qian, Urwa Muaz, Ben Zhang, Jae Won Hyun", "title": "Reducing Gender Bias in Word-Level Language Models with a\n  Gender-Equalizing Loss Function", "comments": "Accepted at ACL-SRW 2019. To appear in Proceedings of ACL-SRW 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gender bias exists in natural language datasets which neural language models\ntend to learn, resulting in biased text generation. In this research, we\npropose a debiasing approach based on the loss function modification. We\nintroduce a new term to the loss function which attempts to equalize the\nprobabilities of male and female words in the output. Using an array of bias\nevaluation metrics, we provide empirical evidence that our approach\nsuccessfully mitigates gender bias in language models without increasing\nperplexity. In comparison to existing debiasing strategies, data augmentation,\nand word embedding debiasing, our method performs better in several aspects,\nespecially in reducing gender bias in occupation words. Finally, we introduce a\ncombination of data augmentation and our approach, and show that it outperforms\nexisting strategies in all bias evaluation metrics.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 00:43:02 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 19:43:51 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Qian", "Yusu", ""], ["Muaz", "Urwa", ""], ["Zhang", "Ben", ""], ["Hyun", "Jae Won", ""]]}, {"id": "1905.12848", "submitter": "Kyosuke Nishida", "authors": "Yasuhito Ohsugi, Itsumi Saito, Kyosuke Nishida, Hisako Asano, Junji\n  Tomita", "title": "A Simple but Effective Method to Incorporate Multi-turn Context with\n  BERT for Conversational Machine Comprehension", "comments": "Accepted at ACL 2019 Workshop on NLP for Conversational AI\n  (NLP4ConvAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational machine comprehension (CMC) requires understanding the context\nof multi-turn dialogue. Using BERT, a pre-training language model, has been\nsuccessful for single-turn machine comprehension, while modeling multiple turns\nof question answering with BERT has not been established because BERT has a\nlimit on the number and the length of input sequences. In this paper, we\npropose a simple but effective method with BERT for CMC. Our method uses BERT\nto encode a paragraph independently conditioned with each question and each\nanswer in a multi-turn context. Then, the method predicts an answer on the\nbasis of the paragraph representations encoded with BERT. The experiments with\nrepresentative CMC datasets, QuAC and CoQA, show that our method outperformed\nrecently published methods (+0.8 F1 on QuAC and +2.1 F1 on CoQA). In addition,\nwe conducted a detailed analysis of the effects of the number and types of\ndialogue history on the accuracy of CMC, and we found that the gold answer\nhistory, which may not be given in an actual conversation, contributed to the\nmodel performance most on both datasets.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 04:28:19 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Ohsugi", "Yasuhito", ""], ["Saito", "Itsumi", ""], ["Nishida", "Kyosuke", ""], ["Asano", "Hisako", ""], ["Tomita", "Junji", ""]]}, {"id": "1905.12864", "submitter": "Samuel Barham", "authors": "Samuel Barham and Soheil Feizi", "title": "Interpretable Adversarial Training for Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating high-quality and interpretable adversarial examples in the text\ndomain is a much more daunting task than it is in the image domain. This is due\npartly to the discrete nature of text, partly to the problem of ensuring that\nthe adversarial examples are still probable and interpretable, and partly to\nthe problem of maintaining label invariance under input perturbations. In order\nto address some of these challenges, we introduce sparse projected gradient\ndescent (SPGD), a new approach to crafting interpretable adversarial examples\nfor text. SPGD imposes a directional regularization constraint on input\nperturbations by projecting them onto the directions to nearby word embeddings\nwith highest cosine similarities. This constraint ensures that perturbations\nmove each word embedding in an interpretable direction (i.e., towards another\nnearby word embedding). Moreover, SPGD imposes a sparsity constraint on\nperturbations at the sentence level by ignoring word-embedding perturbations\nwhose norms are below a certain threshold. This constraint ensures that our\nmethod changes only a few words per sequence, leading to higher quality\nadversarial examples. Our experiments with the IMDB movie review dataset show\nthat the proposed SPGD method improves adversarial example interpretability and\nlikelihood (evaluated by average per-word perplexity) compared to\nstate-of-the-art methods, while suffering little to no loss in training\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 05:55:58 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Barham", "Samuel", ""], ["Feizi", "Soheil", ""]]}, {"id": "1905.12866", "submitter": "Wenhu Chen", "authors": "Wenhu Chen, Jianshu Chen, Pengda Qin, Xifeng Yan and William Yang Wang", "title": "Semantically Conditioned Dialog Response Generation via Hierarchical\n  Disentangled Self-Attention", "comments": "Accepted to ACL 2019, 9 pages long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantically controlled neural response generation on limited-domain has\nachieved great performance. However, moving towards multi-domain large-scale\nscenarios are shown to be difficult because the possible combinations of\nsemantic inputs grow exponentially with the number of domains. To alleviate\nsuch scalability issue, we exploit the structure of dialog acts to build a\nmulti-layer hierarchical graph, where each act is represented as a root-to-leaf\nroute on the graph. Then, we incorporate such graph structure prior as an\ninductive bias to build a hierarchical disentangled self-attention network,\nwhere we disentangle attention heads to model designated nodes on the dialog\nact graph. By activating different (disentangled) heads at each layer,\ncombinatorially many dialog act semantics can be modeled to control the neural\nresponse generation. On the large-scale Multi-Domain-WOZ dataset, our model can\nyield a significant improvement over the baselines on various automatic and\nhuman evaluation metrics.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 05:57:27 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 05:09:33 GMT"}, {"version": "v3", "created": "Sun, 9 Jun 2019 18:11:47 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Chen", "Wenhu", ""], ["Chen", "Jianshu", ""], ["Qin", "Pengda", ""], ["Yan", "Xifeng", ""], ["Wang", "William Yang", ""]]}, {"id": "1905.12884", "submitter": "Fabio Paolizzo", "authors": "Fabio Paolizzo", "title": "M-GWAP: An Online and Multimodal Game With A Purpose in WordPress for\n  Mental States Annotation", "comments": "2 figures, 4 tables. The research is supported by the EU through the\n  MUSICAL-MOODS project funded by the Marie Sklodowska-Curie Actions Individual\n  Fellowships Global Fellowships (MSCA-IF-GF) of the Horizon 2020 Programme\n  H2020/2014-2020, REA grant agreement n.659434", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  M-GWAP is a multimodal game with a purpose of that leverages on the wisdom of\ncrowds phenomenon for the annotation of multimedia data in terms of mental\nstates. This game with a purpose is developed in WordPress to allow users\nimplementing the game without programming skills. The game adopts motivational\nstrategies for the player to remain engaged, such as a score system, text\nmotivators while playing, a ranking system to foster competition and mechanics\nfor identify building. The current version of the game was deployed after alpha\nand beta testing helped refining the game accordingly.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 07:07:52 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Paolizzo", "Fabio", ""]]}, {"id": "1905.12897", "submitter": "Seunghyun Yoon", "authors": "Seunghyun Yoon, Franck Dernoncourt, Doo Soon Kim, Trung Bui, Kyomin\n  Jung", "title": "A Compare-Aggregate Model with Latent Clustering for Answer Selection", "comments": "5 pages, Accepted as a conference paper at CIKM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel method for a sentence-level\nanswer-selection task that is a fundamental problem in natural language\nprocessing. First, we explore the effect of additional information by adopting\na pretrained language model to compute the vector representation of the input\ntext and by applying transfer learning from a large-scale corpus. Second, we\nenhance the compare-aggregate model by proposing a novel latent clustering\nmethod to compute additional information within the target corpus and by\nchanging the objective function from listwise to pointwise. To evaluate the\nperformance of the proposed approaches, experiments are performed with the\nWikiQA and TREC-QA datasets. The empirical results demonstrate the superiority\nof our proposed approach, which achieve state-of-the-art performance for both\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 07:44:34 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2019 08:12:51 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Yoon", "Seunghyun", ""], ["Dernoncourt", "Franck", ""], ["Kim", "Doo Soon", ""], ["Bui", "Trung", ""], ["Jung", "Kyomin", ""]]}, {"id": "1905.12926", "submitter": "Ke Wang", "authors": "Ke Wang, Hang Hua, Xiaojun Wan", "title": "Controllable Unsupervised Text Attribute Transfer via Editing Entangled\n  Latent Representation", "comments": "Neurips 2019 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised text attribute transfer automatically transforms a text to alter\na specific attribute (e.g. sentiment) without using any parallel data, while\nsimultaneously preserving its attribute-independent content. The dominant\napproaches are trying to model the content-independent attribute separately,\ne.g., learning different attributes' representations or using multiple\nattribute-specific decoders. However, it may lead to inflexibility from the\nperspective of controlling the degree of transfer or transferring over multiple\naspects at the same time. To address the above problems, we propose a more\nflexible unsupervised text attribute transfer framework which replaces the\nprocess of modeling attribute with minimal editing of latent representations\nbased on an attribute classifier. Specifically, we first propose a\nTransformer-based autoencoder to learn an entangled latent representation for a\ndiscrete text, then we transform the attribute transfer task to an optimization\nproblem and propose the Fast-Gradient-Iterative-Modification algorithm to edit\nthe latent representation until conforming to the target attribute. Extensive\nexperimental results demonstrate that our model achieves very competitive\nperformance on three public data sets. Furthermore, we also show that our model\ncan not only control the degree of transfer freely but also allow to transfer\nover multiple aspects at the same time.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 09:32:03 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 14:27:26 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Wang", "Ke", ""], ["Hua", "Hang", ""], ["Wan", "Xiaojun", ""]]}, {"id": "1905.12980", "submitter": "\\'Alvaro Peris", "authors": "\\'Alvaro Peris and Francisco Casacuberta", "title": "Interactive-predictive neural multimodal systems", "comments": "To appear at IbPRIA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Despite the advances achieved by neural models in sequence to sequence\nlearning, exploited in a variety of tasks, they still make errors. In many use\ncases, these are corrected by a human expert in a posterior revision process.\nThe interactive-predictive framework aims to minimize the human effort spent on\nthis process by considering partial corrections for iteratively refining the\nhypothesis. In this work, we generalize the interactive-predictive approach,\ntypically applied in to machine translation field, to tackle other multimodal\nproblems namely, image and video captioning. We study the application of this\nframework to multimodal neural sequence to sequence models. We show that,\nfollowing this framework, we approximately halve the effort spent for\ncorrecting the outputs generated by the automatic systems. Moreover, we deploy\nour systems in a publicly accessible demonstration, that allows to better\nunderstand the behavior of the interactive-predictive framework.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 11:47:04 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Peris", "\u00c1lvaro", ""], ["Casacuberta", "Francisco", ""]]}, {"id": "1905.13068", "submitter": "Ant\\'onio Vilarinho Lopes", "authors": "Ant\\'onio V. Lopes and M. Amin Farajian and Gon\\c{c}alo M. Correia and\n  Jonay Trenous and Andr\\'e F. T. Martins", "title": "Unbabel's Submission to the WMT2019 APE Shared Task: BERT-based\n  Encoder-Decoder for Automatic Post-Editing", "comments": "Updated sections 2.2 and 4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes Unbabel's submission to the WMT2019 APE Shared Task for\nthe English-German language pair. Following the recent rise of large, powerful,\npre-trained models, we adapt the BERT pretrained model to perform Automatic\nPost-Editing in an encoder-decoder framework. Analogously to dual-encoder\narchitectures we develop a BERT-based encoder-decoder (BED) model in which a\nsingle pretrained BERT encoder receives both the source src and machine\ntranslation tgt strings. Furthermore, we explore a conservativeness factor to\nconstrain the APE system to perform fewer edits. As the official results show,\nwhen trained on a weighted combination of in-domain and artificial training\ndata, our BED system with the conservativeness penalty improves significantly\nthe translations of a strong Neural Machine Translation system by $-0.78$ and\n$+1.23$ in terms of TER and BLEU, respectively. Finally, our submission\nachieves a new state-of-the-art, ex-aequo, in English-German APE of NMT.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 14:17:39 GMT"}, {"version": "v2", "created": "Sat, 29 Jun 2019 16:42:14 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Lopes", "Ant\u00f3nio V.", ""], ["Farajian", "M. Amin", ""], ["Correia", "Gon\u00e7alo M.", ""], ["Trenous", "Jonay", ""], ["Martins", "Andr\u00e9 F. T.", ""]]}, {"id": "1905.13126", "submitter": "Piper Armstrong", "authors": "Jeffrey Lund, Piper Armstrong, Wilson Fearn, Stephen Cowley, Courtni\n  Byun, Jordan Boyd-Graber, and Kevin Seppi", "title": "Automatic Evaluation of Local Topic Quality", "comments": "8 pages 4 figures 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic models are typically evaluated with respect to the global topic\ndistributions that they generate, using metrics such as coherence, but without\nregard to local (token-level) topic assignments. Token-level assignments are\nimportant for downstream tasks such as classification. Even recent models,\nwhich aim to improve the quality of these token-level topic assignments, have\nbeen evaluated only with respect to global metrics. We propose a task designed\nto elicit human judgments of token-level topic assignments. We use a variety of\ntopic model types and parameters and discover that global metrics agree poorly\nwith human assignments.\n  Since human evaluation is expensive we propose a variety of automated metrics\nto evaluate topic models at a local level. Finally, we correlate our proposed\nmetrics with human judgments from the task on several datasets. We show that an\nevaluation based on the percent of topic switches correlates most strongly with\nhuman judgment of local topic quality. We suggest that this new metric, which\nwe call consistency, be adopted alongside global metrics such as topic\ncoherence when evaluating new topic models.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 00:44:47 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Lund", "Jeffrey", ""], ["Armstrong", "Piper", ""], ["Fearn", "Wilson", ""], ["Cowley", "Stephen", ""], ["Byun", "Courtni", ""], ["Boyd-Graber", "Jordan", ""], ["Seppi", "Kevin", ""]]}, {"id": "1905.13150", "submitter": "Joachim Fainberg", "authors": "Joachim Fainberg, Ond\\v{r}ej Klejch, Steve Renals, Peter Bell", "title": "Lattice-based lightly-supervised acoustic model training", "comments": "Proc. INTERSPEECH 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the broadcast domain there is an abundance of related text data and\npartial transcriptions, such as closed captions and subtitles. This text data\ncan be used for lightly supervised training, in which text matching the audio\nis selected using an existing speech recognition model. Current approaches to\nlight supervision typically filter the data based on matching error rates\nbetween the transcriptions and biased decoding hypotheses. In contrast,\nsemi-supervised training does not require matching text data, instead\ngenerating a hypothesis using a background language model. State-of-the-art\nsemi-supervised training uses lattice-based supervision with the lattice-free\nMMI (LF-MMI) objective function. We propose a technique to combine inaccurate\ntranscriptions with the lattices generated for semi-supervised training, thus\npreserving uncertainty in the lattice where appropriate. We demonstrate that\nthis combined approach reduces the expected error rates over the lattices, and\nreduces the word error rate (WER) on a broadcast task.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 16:12:26 GMT"}, {"version": "v2", "created": "Sat, 13 Jul 2019 14:25:33 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Fainberg", "Joachim", ""], ["Klejch", "Ond\u0159ej", ""], ["Renals", "Steve", ""], ["Bell", "Peter", ""]]}, {"id": "1905.13153", "submitter": "Vanya Cohen", "authors": "Vanya Cohen, Benjamin Burchfiel, Thao Nguyen, Nakul Gopalan, Stefanie\n  Tellex, George Konidaris", "title": "Grounding Language Attributes to Objects using Bayesian Eigenobjects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a system to disambiguate object instances within the same class\nbased on simple physical descriptions. The system takes as input a natural\nlanguage phrase and a depth image containing a segmented object and predicts\nhow similar the observed object is to the object described by the phrase. Our\nsystem is designed to learn from only a small amount of human-labeled language\ndata and generalize to viewpoints not represented in the language-annotated\ndepth image training set. By decoupling 3D shape representation from language\nrepresentation, this method is able to ground language to novel objects using a\nsmall amount of language-annotated depth-data and a larger corpus of unlabeled\n3D object meshes, even when these objects are partially observed from unusual\nviewpoints. Our system is able to disambiguate between novel objects, observed\nvia depth images, based on natural language descriptions. Our method also\nenables view-point transfer; trained on human-annotated data on a small set of\ndepth images captured from frontal viewpoints, our system successfully\npredicted object attributes from rear views despite having no such depth images\nin its training set. Finally, we demonstrate our approach on a Baxter robot,\nenabling it to pick specific objects based on human-provided natural language\ndescriptions.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 16:15:36 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2019 19:07:02 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Cohen", "Vanya", ""], ["Burchfiel", "Benjamin", ""], ["Nguyen", "Thao", ""], ["Gopalan", "Nakul", ""], ["Tellex", "Stefanie", ""], ["Konidaris", "George", ""]]}, {"id": "1905.13164", "submitter": "Yang Liu", "authors": "Yang Liu and Mirella Lapata", "title": "Hierarchical Transformers for Multi-Document Summarization", "comments": "to appear at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a neural summarization model which can effectively\nprocess multiple input documents and distill Transformer architecture with the\nability to encode documents in a hierarchical manner. We represent\ncross-document relationships via an attention mechanism which allows to share\ninformation as opposed to simply concatenating text spans and processing them\nas a flat sequence. Our model learns latent dependencies among textual units,\nbut can also take advantage of explicit graph representations focusing on\nsimilarity or discourse relations. Empirical results on the WikiSum dataset\ndemonstrate that the proposed architecture brings substantial improvements over\nseveral strong baselines.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 16:49:11 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Liu", "Yang", ""], ["Lapata", "Mirella", ""]]}, {"id": "1905.13319", "submitter": "Aida Amini", "authors": "Aida Amini, Saadia Gabriel, Peter Lin, Rik Koncel-Kedziorski, Yejin\n  Choi and Hannaneh Hajishirzi", "title": "MathQA: Towards Interpretable Math Word Problem Solving with\n  Operation-Based Formalisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a large-scale dataset of math word problems and an interpretable\nneural math problem solver that learns to map problems to operation programs.\nDue to annotation challenges, current datasets in this domain have been either\nrelatively small in scale or did not offer precise operational annotations over\ndiverse problem types. We introduce a new representation language to model\nprecise operation programs corresponding to each math problem that aim to\nimprove both the performance and the interpretability of the learned models.\nUsing this representation language, our new dataset, MathQA, significantly\nenhances the AQuA dataset with fully-specified operational programs. We\nadditionally introduce a neural sequence-to-program model enhanced with\nautomatic problem categorization. Our experiments show improvements over\ncompetitive baselines in our MathQA as well as the AQuA dataset. The results\nare still significantly lower than human performance indicating that the\ndataset poses new challenges for future research. Our dataset is available at:\nhttps://math-qa.github.io/math-QA/\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 21:28:12 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Amini", "Aida", ""], ["Gabriel", "Saadia", ""], ["Lin", "Peter", ""], ["Koncel-Kedziorski", "Rik", ""], ["Choi", "Yejin", ""], ["Hajishirzi", "Hannaneh", ""]]}, {"id": "1905.13322", "submitter": "Vinay Rao", "authors": "Ben Goodrich and Vinay Rao and Mohammad Saleh and Peter J Liu", "title": "Assessing The Factual Accuracy of Generated Text", "comments": null, "journal-ref": "The 25th ACM SIGKDD Conference on Knowledge Discovery and Data\n  Mining (KDD '19), August 4--8, 2019, Anchorage, AK, USA", "doi": "10.1145/3292500.3330955", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose a model-based metric to estimate the factual accuracy of generated\ntext that is complementary to typical scoring schemes like ROUGE\n(Recall-Oriented Understudy for Gisting Evaluation) and BLEU (Bilingual\nEvaluation Understudy). We introduce and release a new large-scale dataset\nbased on Wikipedia and Wikidata to train relation classifiers and end-to-end\nfact extraction models. The end-to-end models are shown to be able to extract\ncomplete sets of facts from datasets with full pages of text. We then analyse\nmultiple models that estimate factual accuracy on a Wikipedia text\nsummarization task, and show their efficacy compared to ROUGE and other\nmodel-free variants by conducting a human evaluation study.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 21:37:45 GMT"}, {"version": "v2", "created": "Tue, 25 May 2021 19:33:29 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Goodrich", "Ben", ""], ["Rao", "Vinay", ""], ["Saleh", "Mohammad", ""], ["Liu", "Peter J", ""]]}, {"id": "1905.13324", "submitter": "Biao Zhang", "authors": "Biao Zhang and Rico Sennrich", "title": "A Lightweight Recurrent Network for Sequence Modeling", "comments": "ACL 2019, long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent networks have achieved great success on various sequential tasks\nwith the assistance of complex recurrent units, but suffer from severe\ncomputational inefficiency due to weak parallelization. One direction to\nalleviate this issue is to shift heavy computations outside the recurrence. In\nthis paper, we propose a lightweight recurrent network, or LRN. LRN uses input\nand forget gates to handle long-range dependencies as well as gradient\nvanishing and explosion, with all parameter related calculations factored\noutside the recurrence. The recurrence in LRN only manipulates the weight\nassigned to each token, tightly connecting LRN with self-attention networks. We\napply LRN as a drop-in replacement of existing recurrent units in several\nneural sequential models. Extensive experiments on six NLP tasks show that LRN\nyields the best running efficiency with little or no loss in model performance.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 21:40:46 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Zhang", "Biao", ""], ["Sennrich", "Rico", ""]]}, {"id": "1905.13326", "submitter": "Kevin Lin", "authors": "Kevin Lin, Ben Bogin, Mark Neumann, Jonathan Berant, Matt Gardner", "title": "Grammar-based Neural Text-to-SQL Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sequence-to-sequence paradigm employed by neural text-to-SQL models\ntypically performs token-level decoding and does not consider generating SQL\nhierarchically from a grammar. Grammar-based decoding has shown significant\nimprovements for other semantic parsing tasks, but SQL and other general\nprogramming languages have complexities not present in logical formalisms that\nmake writing hierarchical grammars difficult. We introduce techniques to handle\nthese complexities, showing how to construct a schema-dependent grammar with\nminimal over-generation. We analyze these techniques on ATIS and Spider, two\nchallenging text-to-SQL datasets, demonstrating that they yield 14--18\\%\nrelative reductions in error.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 21:43:57 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Lin", "Kevin", ""], ["Bogin", "Ben", ""], ["Neumann", "Mark", ""], ["Berant", "Jonathan", ""], ["Gardner", "Matt", ""]]}, {"id": "1905.13350", "submitter": "Sabine Wehnert", "authors": "Sabine Wehnert and Sayed Anisul Hoque and Wolfram Fenske and Gunter\n  Saake", "title": "Threshold-Based Retrieval and Textual Entailment Detection on Legal Bar\n  Exam Questions", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Getting an overview over the legal domain has become challenging, especially\nin a broad, international context. Legal question answering systems have the\npotential to alleviate this task by automatically retrieving relevant legal\ntexts for a specific statement and checking whether the meaning of the\nstatement can be inferred from the found documents. We investigate a\ncombination of the BM25 scoring method of Elasticsearch with word embeddings\ntrained on English translations of the German and Japanese civil law. For this,\nwe define criteria which select a dynamic number of relevant documents\naccording to threshold scores. Exploiting two deep learning classifiers and\ntheir respective prediction bias with a threshold-based answer inclusion\ncriterion has shown to be beneficial for the textual entailment task, when\ncompared to the baseline.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 23:17:26 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Wehnert", "Sabine", ""], ["Hoque", "Sayed Anisul", ""], ["Fenske", "Wolfram", ""], ["Saake", "Gunter", ""]]}, {"id": "1905.13354", "submitter": "Rachel Bawden", "authors": "Rachel Bawden, Sophie Rosset, Thomas Lavergne and Eric Bilinski", "title": "DiaBLa: A Corpus of Bilingual Spontaneous Written Dialogues for Machine\n  Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new English-French test set for the evaluation of Machine\nTranslation (MT) for informal, written bilingual dialogue. The test set\ncontains 144 spontaneous dialogues (5,700+ sentences) between native English\nand French speakers, mediated by one of two neural MT systems in a range of\nrole-play settings. The dialogues are accompanied by fine-grained\nsentence-level judgments of MT quality, produced by the dialogue participants\nthemselves, as well as by manually normalised versions and reference\ntranslations produced a posteriori. The motivation for the corpus is two-fold:\nto provide (i) a unique resource for evaluating MT models, and (ii) a corpus\nfor the analysis of MT-mediated communication. We provide a preliminary\nanalysis of the corpus to confirm that the participants' judgments reveal\nperceptible differences in MT quality between the two MT systems used.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 23:41:35 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Bawden", "Rachel", ""], ["Rosset", "Sophie", ""], ["Lavergne", "Thomas", ""], ["Bilinski", "Eric", ""]]}, {"id": "1905.13358", "submitter": "Vihan Jain", "authors": "Haoshuo Huang, Vihan Jain, Harsh Mehta, Jason Baldridge, Eugene Ie", "title": "Multi-modal Discriminative Model for Vision-and-Language Navigation", "comments": "Accepted at SpLU-RoboNLP 2019 (workshop at NAACL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Vision-and-Language Navigation (VLN) is a natural language grounding task\nwhere agents have to interpret natural language instructions in the context of\nvisual scenes in a dynamic environment to achieve prescribed navigation goals.\nSuccessful agents must have the ability to parse natural language of varying\nlinguistic styles, ground them in potentially unfamiliar scenes, plan and react\nwith ambiguous environmental feedback. Generalization ability is limited by the\namount of human annotated data. In particular, \\emph{paired} vision-language\nsequence data is expensive to collect. We develop a discriminator that\nevaluates how well an instruction explains a given path in VLN task using\nmulti-modal alignment. Our study reveals that only a small fraction of the\nhigh-quality augmented data from \\citet{Fried:2018:Speaker}, as scored by our\ndiscriminator, is useful for training VLN agents with similar performance on\npreviously unseen environments. We also show that a VLN agent warm-started with\npre-trained components from the discriminator outperforms the benchmark success\nrates of 35.5 by 10\\% relative measure on previously unseen environments.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 00:07:24 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Huang", "Haoshuo", ""], ["Jain", "Vihan", ""], ["Mehta", "Harsh", ""], ["Baldridge", "Jason", ""], ["Ie", "Eugene", ""]]}, {"id": "1905.13359", "submitter": "Fahad AlGhamdi", "authors": "Fahad AlGhamdi and Mona Diab", "title": "Leveraging Pretrained Word Embeddings for Part-of-Speech Tagging of Code\n  Switching Data", "comments": null, "journal-ref": null, "doi": "10.18653/v1/W19-1410", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linguistic Code Switching (CS) is a phenomenon that occurs when multilingual\nspeakers alternate between two or more languages/dialects within a single\nconversation. Processing CS data is especially challenging in intra-sentential\ndata given state-of-the-art monolingual NLP technologies since such\ntechnologies are geared toward the processing of one language at a time. In\nthis paper, we address the problem of Part-of-Speech tagging (POS) in the\ncontext of linguistic code switching (CS). We explore leveraging multiple\nneural network architectures to measure the impact of different pre-trained\nembeddings methods on POS tagging CS data. We investigate the landscape in four\nCS language pairs, Spanish-English, Hindi-English, Modern Standard Arabic-\nEgyptian Arabic dialect (MSA-EGY), and Modern Standard Arabic- Levantine Arabic\ndialect (MSA-LEV). Our results show that multilingual embedding (e.g., MSA-EGY\nand MSA-LEV) helps closely related languages (EGY/LEV) but adds noise to the\nlanguages that are distant (SPA/HIN). Finally, we show that our proposed models\noutperform state-of-the-art CS taggers for MSA-EGY language pair.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 00:08:27 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["AlGhamdi", "Fahad", ""], ["Diab", "Mona", ""]]}, {"id": "1905.13364", "submitter": "Bo Wang", "authors": "Bo Wang, Baixiang Xue, Anthony G. Greenwald", "title": "Can We Derive Explicit and Implicit Bias from Corpus?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language is a popular resource to mine speakers' attitude bias, supposing\nthat speakers' statements represent their bias on concepts. However, psychology\nstudies show that people's explicit bias in statements can be different from\ntheir implicit bias in mind. Although both explicit and implicit bias are\nuseful for different applications, current automatic techniques do not\ndistinguish them. Inspired by psychological measurements of explicit and\nimplicit bias, we develop an automatic language-based technique to reproduce\npsychological measurements on large population. By connecting each\npsychological measurement with the statements containing the certain\ncombination of special words, we derive explicit and implicit bias by\nunderstanding the sentiment of corresponding category of statements. Extensive\nexperiments on English and Chinese serious media (Wikipedia) and non-serious\nmedia (social media) show that our method successfully reproduce the\nsmall-scale psychological observations on large population and achieve new\nfindings.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 00:36:21 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Wang", "Bo", ""], ["Xue", "Baixiang", ""], ["Greenwald", "Anthony G.", ""]]}, {"id": "1905.13370", "submitter": "Tahira Naseem", "authors": "Tahira Naseem, Abhishek Shah, Hui Wan, Radu Florian, Salim Roukos,\n  Miguel Ballesteros", "title": "Rewarding Smatch: Transition-Based AMR Parsing with Reinforcement\n  Learning", "comments": "Accepted as short paper at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our work involves enriching the Stack-LSTM transition-based AMR parser\n(Ballesteros and Al-Onaizan, 2017) by augmenting training with Policy Learning\nand rewarding the Smatch score of sampled graphs. In addition, we also combined\nseveral AMR-to-text alignments with an attention mechanism and we supplemented\nthe parser with pre-processed concept identification, named entities and\ncontextualized embeddings. We achieve a highly competitive performance that is\ncomparable to the best published results. We show an in-depth study ablating\neach of the new components of the parser\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 01:15:36 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Naseem", "Tahira", ""], ["Shah", "Abhishek", ""], ["Wan", "Hui", ""], ["Florian", "Radu", ""], ["Roukos", "Salim", ""], ["Ballesteros", "Miguel", ""]]}, {"id": "1905.13413", "submitter": "Zhengbao Jiang", "authors": "Zhengbao Jiang, Pengcheng Yin, Graham Neubig", "title": "Improving Open Information Extraction via Iterative Rank-Aware Learning", "comments": "Proceedings of ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open information extraction (IE) is the task of extracting open-domain\nassertions from natural language sentences. A key step in open IE is confidence\nmodeling, ranking the extractions based on their estimated quality to adjust\nprecision and recall of extracted assertions. We found that the extraction\nlikelihood, a confidence measure used by current supervised open IE systems, is\nnot well calibrated when comparing the quality of assertions extracted from\ndifferent sentences. We propose an additional binary classification loss to\ncalibrate the likelihood to make it more globally comparable, and an iterative\nlearning process, where extractions generated by the open IE model are\nincrementally included as training samples to help the model learn from trial\nand error. Experiments on OIE2016 demonstrate the effectiveness of our method.\nCode and data are available at https://github.com/jzbjyb/oie_rank.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 05:02:50 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Jiang", "Zhengbao", ""], ["Yin", "Pengcheng", ""], ["Neubig", "Graham", ""]]}, {"id": "1905.13416", "submitter": "Mengting Wan", "authors": "Mengting Wan, Rishabh Misra, Ndapa Nakashole, Julian McAuley", "title": "Fine-Grained Spoiler Detection from Large-Scale Review Corpora", "comments": "6 pages; ACL'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents computational approaches for automatically detecting\ncritical plot twists in reviews of media products. First, we created a\nlarge-scale book review dataset that includes fine-grained spoiler annotations\nat the sentence-level, as well as book and (anonymized) user information.\nSecond, we carefully analyzed this dataset, and found that: spoiler language\ntends to be book-specific; spoiler distributions vary greatly across books and\nreview authors; and spoiler sentences tend to jointly appear in the latter part\nof reviews. Third, inspired by these findings, we developed an end-to-end\nneural network architecture to detect spoiler sentences in review corpora.\nQuantitative and qualitative results demonstrate that the proposed method\nsubstantially outperforms existing baselines.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 05:06:00 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Wan", "Mengting", ""], ["Misra", "Rishabh", ""], ["Nakashole", "Ndapa", ""], ["McAuley", "Julian", ""]]}, {"id": "1905.13418", "submitter": "Konstantinos Kogkalidis", "authors": "Konstantinos Kogkalidis, Michael Moortgat, Tejaswini Deoskar", "title": "Constructive Type-Logical Supertagging with Self-Attention Networks", "comments": "REPL4NLP 4, ACL 2019", "journal-ref": "Proceedings of the 4th Workshop on Representation Learning for NLP\n  (RepL4NLP-2019)", "doi": "10.18653/v1/W19-4314", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel application of self-attention networks towards grammar\ninduction. We present an attention-based supertagger for a refined type-logical\ngrammar, trained on constructing types inductively. In addition to achieving a\nhigh overall type accuracy, our model is able to learn the syntax of the\ngrammar's type system along with its denotational semantics. This lifts the\nclosed world assumption commonly made by lexicalized grammar supertaggers,\ngreatly enhancing its generalization potential. This is evidenced both by its\nadequate accuracy over sparse word types and its ability to correctly construct\ncomplex types never seen during training, which, to the best of our knowledge,\nwas as of yet unaccomplished.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 05:16:15 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Kogkalidis", "Konstantinos", ""], ["Moortgat", "Michael", ""], ["Deoskar", "Tejaswini", ""]]}, {"id": "1905.13438", "submitter": "Tianyu Zhao", "authors": "Tianyu Zhao, Shinsuke Mori and Tatsuya Kawahara", "title": "Content Word-based Sentence Decoding and Evaluating for Open-domain\n  Neural Response Generation", "comments": "13 pages, 2 figures, 8 tables (rejected by ACL 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various encoder-decoder models have been applied to response generation in\nopen-domain dialogs, but a majority of conventional models directly learn a\nmapping from lexical input to lexical output without explicitly modeling\nintermediate representations. Utilizing language hierarchy and modeling\nintermediate information have been shown to benefit many language understanding\nand generation tasks. Motivated by Broca's aphasia, we propose to use a content\nword sequence as an intermediate representation for open-domain response\ngeneration. Experimental results show that the proposed method improves content\nrelatedness of produced responses, and our models can often choose correct\ngrammar for generated content words. Meanwhile, instead of evaluating complete\nsentences, we propose to compute conventional metrics on content word\nsequences, which is a better indicator of content relevance.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 06:36:19 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 17:23:45 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Zhao", "Tianyu", ""], ["Mori", "Shinsuke", ""], ["Kawahara", "Tatsuya", ""]]}, {"id": "1905.13443", "submitter": "Yoshinobu Hagiwara Dr.", "authors": "Yoshinobu Hagiwara, Hiroyoshi Kobayashi, Akira Taniguchi and Tadahiro\n  Taniguchi", "title": "Symbol Emergence as an Interpersonal Multimodal Categorization", "comments": "21 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study focuses on category formation for individual agents and the\ndynamics of symbol emergence in a multi-agent system through semiotic\ncommunication. Semiotic communication is defined, in this study, as the\ngeneration and interpretation of signs associated with the categories formed\nthrough the agent's own sensory experience or by exchange of signs with other\nagents. From the viewpoint of language evolution and symbol emergence,\norganization of a symbol system in a multi-agent system is considered as a\nbottom-up and dynamic process, where individual agents share the meaning of\nsigns and categorize sensory experience. A constructive computational model can\nexplain the mutual dependency of the two processes and has mathematical support\nthat guarantees a symbol system's emergence and sharing within the multi-agent\nsystem. In this paper, we describe a new computational model that represents\nsymbol emergence in a two-agent system based on a probabilistic generative\nmodel for multimodal categorization. It models semiotic communication via a\nprobabilistic rejection based on the receiver's own belief. We have found that\nthe dynamics by which cognitively independent agents create a symbol system\nthrough their semiotic communication can be regarded as the inference process\nof a hidden variable in an interpersonal multimodal categorizer, if we define\nthe rejection probability based on the Metropolis-Hastings algorithm. The\nvalidity of the proposed model and algorithm for symbol emergence is also\nverified in an experiment with two agents observing daily objects in the\nreal-world environment. The experimental results demonstrate that our model\nreproduces the phenomena of symbol emergence, which does not require a teacher\nwho would know a pre-existing symbol system. Instead, the multi-agent system\ncan form and use a symbol system without having pre-existing categories.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 07:03:03 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Hagiwara", "Yoshinobu", ""], ["Kobayashi", "Hiroyoshi", ""], ["Taniguchi", "Akira", ""], ["Taniguchi", "Tadahiro", ""]]}, {"id": "1905.13448", "submitter": "Xuenan Xu", "authors": "Xuenan Xu, Heinrich Dinkel, Mengyue Wu, Kai Yu", "title": "Audio Caption in a Car Setting with a Sentence-Level Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Captioning has attracted much attention in image and video understanding\nwhile a small amount of work examines audio captioning. This paper contributes\na Mandarin-annotated dataset for audio captioning within a car scene. A\nsentence-level loss is proposed to be used in tandem with a GRU encoder-decoder\nmodel to generate captions with higher semantic similarity to human\nannotations. We evaluate the model on the newly-proposed Car dataset, a\npreviously published Mandarin Hospital dataset and the Joint dataset,\nindicating its generalization capability across different scenes. An\nimprovement in all metrics can be observed, including classical natural\nlanguage generation (NLG) metrics, sentence richness and human evaluation\nratings. However, though detailed audio captions can now be automatically\ngenerated, human annotations still outperform model captions on many aspects.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 07:30:15 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 06:58:36 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Xu", "Xuenan", ""], ["Dinkel", "Heinrich", ""], ["Wu", "Mengyue", ""], ["Yu", "Kai", ""]]}, {"id": "1905.13453", "submitter": "Alon Talmor", "authors": "Alon Talmor, Jonathan Berant", "title": "MultiQA: An Empirical Investigation of Generalization and Transfer in\n  Reading Comprehension", "comments": "accepted as a long paper at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large number of reading comprehension (RC) datasets has been created\nrecently, but little analysis has been done on whether they generalize to one\nanother, and the extent to which existing datasets can be leveraged for\nimproving performance on new ones. In this paper, we conduct such an\ninvestigation over ten RC datasets, training on one or more source RC datasets,\nand evaluating generalization, as well as transfer to a target RC dataset. We\nanalyze the factors that contribute to generalization, and show that training\non a source RC dataset and transferring to a target dataset substantially\nimproves performance, even in the presence of powerful contextual\nrepresentations from BERT (Devlin et al., 2019). We also find that training on\nmultiple source RC datasets leads to robust generalization and transfer, and\ncan reduce the cost of example collection for a new RC dataset. Following our\nanalysis, we propose MultiQA, a BERT-based model, trained on multiple RC\ndatasets, which leads to state-of-the-art performance on five RC datasets. We\nshare our infrastructure for the benefit of the research community.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 08:05:31 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Talmor", "Alon", ""], ["Berant", "Jonathan", ""]]}, {"id": "1905.13464", "submitter": "Tommi Gr\\\"ondahl", "authors": "Tommi Gr\\\"ondahl and N. Asokan", "title": "Effective writing style imitation via combinatorial paraphrasing", "comments": "16 pages, 1 figure, Accepted for publication in Privacy Enhancing\n  Technologies (PETS2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stylometry can be used to profile or deanonymize authors against their will\nbased on writing style. Style transfer provides a defence. Current techniques\ntypically use either encoder-decoder architectures or rule-based algorithms.\nCrucially, style transfer must reliably retain original semantic content to be\nactually deployable. We conduct a multifaceted evaluation of three\nstate-of-the-art encoder-decoder style transfer techniques, and show that all\nfail at semantic retainment. In particular, they do not produce appropriate\nparaphrases, but only retain original content in the trivial case of exactly\nreproducing the text. To mitigate this problem we propose ParChoice: a\ntechnique based on the combinatorial application of multiple paraphrasing\nalgorithms. ParChoice strongly outperforms the encoder-decoder baselines in\nsemantic retainment. Additionally, compared to baselines that achieve\nnon-negligible semantic retainment, ParChoice has superior style transfer\nperformance. We also apply ParChoice to multi-author style imitation (not\nconsidered by prior work), where we achieve up to 75% imitation success among\nfive authors. Furthermore, when compared to two state-of-the-art rule-based\nstyle transfer techniques, ParChoice has markedly better semantic retainment.\nCombining ParChoice with the best performing rule-based baseline (Mutant-X)\nalso reaches the highest style transfer success on the Brennan-Greenstadt and\nExtended-Brennan-Greenstadt corpora, with much less impact on original meaning\nthan when using the rule-based baseline techniques alone. Finally, we highlight\na critical problem that afflicts all current style transfer techniques: the\nadversary can use the same technique for thwarting style transfer via\nadversarial training. We show that adding randomness to style transfer helps to\nmitigate the effectiveness of adversarial training.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 08:42:27 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 14:02:31 GMT"}, {"version": "v3", "created": "Fri, 3 Jul 2020 12:36:28 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Gr\u00f6ndahl", "Tommi", ""], ["Asokan", "N.", ""]]}, {"id": "1905.13497", "submitter": "Tassilo Klein", "authors": "Tassilo Klein, Moin Nabi", "title": "Attention Is (not) All You Need for Commonsense Reasoning", "comments": "to appear at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently introduced BERT model exhibits strong performance on several\nlanguage understanding benchmarks. In this paper, we describe a simple\nre-implementation of BERT for commonsense reasoning. We show that the\nattentions produced by BERT can be directly utilized for tasks such as the\nPronoun Disambiguation Problem and Winograd Schema Challenge. Our proposed\nattention-guided commonsense reasoning method is conceptually simple yet\nempirically powerful. Experimental analysis on multiple datasets demonstrates\nthat our proposed system performs remarkably well on all cases while\noutperforming the previously reported state of the art by a margin. While\nresults suggest that BERT seems to implicitly learn to establish complex\nrelationships between entities, solving commonsense reasoning tasks might\nrequire more than unsupervised models learned from huge text corpora.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 10:27:58 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Klein", "Tassilo", ""], ["Nabi", "Moin", ""]]}, {"id": "1905.13561", "submitter": "Fuming Fang", "authors": "Fuming Fang, Xin Wang, Junichi Yamagishi, Isao Echizen, Massimiliano\n  Todisco, Nicholas Evans, Jean-Francois Bonastre", "title": "Speaker Anonymization Using X-vector and Neural Waveform Models", "comments": "Submitted to the 10th ISCA Speech Synthesis Workshop (SSW10)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The social media revolution has produced a plethora of web services to which\nusers can easily upload and share multimedia documents. Despite the popularity\nand convenience of such services, the sharing of such inherently personal data,\nincluding speech data, raises obvious security and privacy concerns. In\nparticular, a user's speech data may be acquired and used with speech synthesis\nsystems to produce high-quality speech utterances which reflect the same user's\nspeaker identity. These utterances may then be used to attack speaker\nverification systems. One solution to mitigate these concerns involves the\nconcealing of speaker identities before the sharing of speech data. For this\npurpose, we present a new approach to speaker anonymization. The idea is to\nextract linguistic and speaker identity features from an utterance and then to\nuse these with neural acoustic and waveform models to synthesize anonymized\nspeech. The original speaker identity, in the form of timbre, is suppressed and\nreplaced with that of an anonymous pseudo identity. The approach exploits\nstate-of-the-art x-vector speaker representations. These are used to derive\nanonymized pseudo speaker identities through the combination of multiple,\nrandom speaker x-vectors. Experimental results show that the proposed approach\nis effective in concealing speaker identities. It increases the equal error\nrate of a speaker verification system while maintaining high quality,\nanonymized speech.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 01:33:31 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Fang", "Fuming", ""], ["Wang", "Xin", ""], ["Yamagishi", "Junichi", ""], ["Echizen", "Isao", ""], ["Todisco", "Massimiliano", ""], ["Evans", "Nicholas", ""], ["Bonastre", "Jean-Francois", ""]]}, {"id": "1905.13601", "submitter": "Tomoyuki Kajiwara", "authors": "Tomoyuki Kajiwara, Chihiro Tanikawa, Yuujin Shimizu, Chenhui Chu,\n  Takashi Yamashiro, Hajime Nagahara", "title": "Using Natural Language Processing to Develop an Automated Orthodontic\n  Diagnostic System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We work on the task of automatically designing a treatment plan from the\nfindings included in the medical certificate written by the dentist. To develop\nan artificial intelligence system that deals with free-form certificates\nwritten by dentists, we annotate the findings and utilized the natural language\nprocessing approach. As a result of the experiment using 990 certificates,\n0.585 F1-score was achieved for the task of extracting orthodontic problems\nfrom findings, and 0.584 correlation coefficient with the human ranking was\nachieved for the treatment prioritization task.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 13:13:51 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Kajiwara", "Tomoyuki", ""], ["Tanikawa", "Chihiro", ""], ["Shimizu", "Yuujin", ""], ["Chu", "Chenhui", ""], ["Yamashiro", "Takashi", ""], ["Nagahara", "Hajime", ""]]}, {"id": "1905.13618", "submitter": "Roman Klinger", "authors": "Enrica Troiano and Sebastian Pad\\'o and Roman Klinger", "title": "Crowdsourcing and Validating Event-focused Emotion Corpora for German\n  and English", "comments": "14 pages, 1 figure, accepted for publication at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sentiment analysis has a range of corpora available across multiple\nlanguages. For emotion analysis, the situation is more limited, which hinders\npotential research on cross-lingual modeling and the development of predictive\nmodels for other languages. In this paper, we fill this gap for German by\nconstructing deISEAR, a corpus designed in analogy to the well-established\nEnglish ISEAR emotion dataset. Motivated by Scherer's appraisal theory, we\nimplement a crowdsourcing experiment which consists of two steps. In step 1,\nparticipants create descriptions of emotional events for a given emotion. In\nstep 2, five annotators assess the emotion expressed by the texts. We show that\ntransferring an emotion classification model from the original English ISEAR to\nthe German crowdsourced deISEAR via machine translation does not, on average,\ncause a performance drop.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 13:54:54 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Troiano", "Enrica", ""], ["Pad\u00f3", "Sebastian", ""], ["Klinger", "Roman", ""]]}, {"id": "1905.13637", "submitter": "Wenpeng Hu", "authors": "Wenpeng Hu, Zhangming Chan, Bing Liu, Dongyan Zhao, Jinwen Ma, Rui Yan", "title": "GSN: A Graph-Structured Network for Multi-Party Dialogues", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Existing neural models for dialogue response generation assume that\nutterances are sequentially organized. However, many real-world dialogues\ninvolve multiple interlocutors (i.e., multi-party dialogues), where the\nassumption does not hold as utterances from different interlocutors can occur\n\"in parallel.\" This paper generalizes existing sequence-based models to a\nGraph-Structured neural Network (GSN) for dialogue modeling. The core of GSN is\na graph-based encoder that can model the information flow along the\ngraph-structured dialogues (two-party sequential dialogues are a special case).\nExperimental results show that GSN significantly outperforms existing\nsequence-based models.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 14:30:49 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Hu", "Wenpeng", ""], ["Chan", "Zhangming", ""], ["Liu", "Bing", ""], ["Zhao", "Dongyan", ""], ["Ma", "Jinwen", ""], ["Yan", "Rui", ""]]}, {"id": "1905.13649", "submitter": "Sarthika Dhawan", "authors": "Sarthika Dhawan, Siva Charan Reddy Gangireddy, Shiv Kumar and Tanmoy\n  Chakraborty", "title": "Spotting Collective Behaviour of Online Frauds in Customer Reviews", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online reviews play a crucial role in deciding the quality before purchasing\nany product. Unfortunately, spammers often take advantage of online review\nforums by writing fraud reviews to promote/demote certain products. It may turn\nout to be more detrimental when such spammers collude and collectively inject\nspam reviews as they can take complete control of users' sentiment due to the\nvolume of fraud reviews they inject. Group spam detection is thus more\nchallenging than individual-level fraud detection due to unclear definition of\na group, variation of inter-group dynamics, scarcity of labeled group-level\nspam data, etc. Here, we propose DeFrauder, an unsupervised method to detect\nonline fraud reviewer groups. It first detects candidate fraud groups by\nleveraging the underlying product review graph and incorporating several\nbehavioral signals which model multi-faceted collaboration among reviewers. It\nthen maps reviewers into an embedding space and assigns a spam score to each\ngroup such that groups comprising spammers with highly similar behavioral\ntraits achieve high spam score. While comparing with five baselines on four\nreal-world datasets (two of them were curated by us), DeFrauder shows superior\nperformance by outperforming the best baseline with 17.11% higher NDCG@50 (on\naverage) across datasets.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 14:49:30 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 10:18:13 GMT"}, {"version": "v3", "created": "Sat, 8 Jun 2019 11:06:08 GMT"}, {"version": "v4", "created": "Wed, 12 Jun 2019 21:18:02 GMT"}, {"version": "v5", "created": "Sun, 16 Jun 2019 13:23:51 GMT"}, {"version": "v6", "created": "Sat, 27 Jul 2019 11:54:07 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Dhawan", "Sarthika", ""], ["Gangireddy", "Siva Charan Reddy", ""], ["Kumar", "Shiv", ""], ["Chakraborty", "Tanmoy", ""]]}, {"id": "1905.13656", "submitter": "Won Ik Cho", "authors": "Won Ik Cho, Seok Min Kim, Nam Soo Kim", "title": "Investigating an Effective Character-level Embedding in Korean Sentence\n  Classification", "comments": "PACLIC 33 Camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different from the writing systems of many Romance and Germanic languages,\nsome languages or language families show complex conjunct forms in character\ncomposition. For such cases where the conjuncts consist of the components\nrepresenting consonant(s) and vowel, various character encoding schemes can be\nadopted beyond merely making up a one-hot vector. However, there has been\nlittle work done on intra-language comparison regarding performances using each\nrepresentation. In this study, utilizing the Korean language which is\ncharacter-rich and agglutinative, we investigate an encoding scheme that is the\nmost effective among Jamo-level one-hot, character-level one-hot,\ncharacter-level dense, and character-level multi-hot. Classification\nperformance with each scheme is evaluated on two corpora: one on binary\nsentiment analysis of movie reviews, and the other on multi-class\nidentification of intention types. The result displays that the character-level\nfeatures show higher performance in general, although the Jamo-level features\nmay show compatibility with the attention-based models if guaranteed adequate\nparameter set size.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 14:54:46 GMT"}, {"version": "v2", "created": "Wed, 17 Jul 2019 02:26:30 GMT"}, {"version": "v3", "created": "Thu, 19 Sep 2019 01:06:46 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Cho", "Won Ik", ""], ["Kim", "Seok Min", ""], ["Kim", "Nam Soo", ""]]}, {"id": "1905.13687", "submitter": "Eugene Kharitonov", "authors": "Eugene Kharitonov and Rahma Chaabouni and Diane Bouchacourt and Marco\n  Baroni", "title": "Entropy Minimization In Emergent Languages", "comments": "Accepted at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is growing interest in studying the languages that emerge when neural\nagents are jointly trained to solve tasks requiring communication through a\ndiscrete channel. We investigate here the information-theoretic complexity of\nsuch languages, focusing on the basic two-agent, one-exchange setup. We find\nthat, under common training procedures, the emergent languages are subject to\nan entropy minimization pressure that has also been detected in human language,\nwhereby the mutual information between the communicating agent's inputs and the\nmessages is minimized, within the range afforded by the need for successful\ncommunication. That is, emergent languages are (nearly) as simple as the task\nthey are developed for allow them to be. This pressure is amplified as we\nincrease communication channel discreteness. Further, we observe that stronger\ndiscrete-channel-driven entropy minimization leads to representations with\nincreased robustness to overfitting and adversarial attacks. We conclude by\ndiscussing the implications of our findings for the study of natural and\nartificial communication systems.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 15:54:41 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 15:08:33 GMT"}, {"version": "v3", "created": "Fri, 26 Jun 2020 10:03:02 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Kharitonov", "Eugene", ""], ["Chaabouni", "Rahma", ""], ["Bouchacourt", "Diane", ""], ["Baroni", "Marco", ""]]}, {"id": "1905.13714", "submitter": "Julia Strout", "authors": "Julia Strout, Ye Zhang and Raymond J. Mooney", "title": "Do Human Rationales Improve Machine Explanations?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Work on \"learning with rationales\" shows that humans providing explanations\nto a machine learning system can improve the system's predictive accuracy.\nHowever, this work has not been connected to work in \"explainable AI\" which\nconcerns machines explaining their reasoning to humans. In this work, we show\nthat learning with rationales can also improve the quality of the machine's\nexplanations as evaluated by human judges. Specifically, we present experiments\nshowing that, for CNN- based text classification, explanations generated using\n\"supervised attention\" are judged superior to explanations generated using\nnormal unsupervised attention.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 16:49:57 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Strout", "Julia", ""], ["Zhang", "Ye", ""], ["Mooney", "Raymond J.", ""]]}]