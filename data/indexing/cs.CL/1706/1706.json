[{"id": "1706.00130", "submitter": "Huan Ling", "authors": "Huan Ling, Sanja Fidler", "title": "Teaching Machines to Describe Images via Natural Language Feedback", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots will eventually be part of every household. It is thus critical to\nenable algorithms to learn from and be guided by non-expert users. In this\npaper, we bring a human in the loop, and enable a human teacher to give\nfeedback to a learning agent in the form of natural language. We argue that a\ndescriptive sentence can provide a much stronger learning signal than a numeric\nreward in that it can easily point to where the mistakes are and how to correct\nthem. We focus on the problem of image captioning in which the quality of the\noutput can easily be judged by non-experts. We propose a hierarchical\nphrase-based captioning model trained with policy gradients, and design a\nfeedback network that provides reward to the learner by conditioning on the\nhuman-provided feedback. We show that by exploiting descriptive feedback our\nmodel learns to perform better than when given independently written human\ncaptions.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 00:24:55 GMT"}, {"version": "v2", "created": "Mon, 5 Jun 2017 16:47:40 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Ling", "Huan", ""], ["Fidler", "Sanja", ""]]}, {"id": "1706.00134", "submitter": "Van-Khanh Tran", "authors": "Van-Khanh Tran, Le-Minh Nguyen", "title": "Semantic Refinement GRU-based Neural Language Generation for Spoken\n  Dialogue Systems", "comments": "To be appear at PACLING 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language generation (NLG) plays a critical role in spoken dialogue\nsystems. This paper presents a new approach to NLG by using recurrent neural\nnetworks (RNN), in which a gating mechanism is applied before RNN computation.\nThis allows the proposed model to generate appropriate sentences. The RNN-based\ngenerator can be learned from unaligned data by jointly training sentence\nplanning and surface realization to produce natural language responses. The\nmodel was extensively evaluated on four different NLG domains. The results show\nthat the proposed generator achieved better performance on all the NLG domains\ncompared to previous generators.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 00:37:46 GMT"}, {"version": "v2", "created": "Sat, 3 Jun 2017 00:45:11 GMT"}, {"version": "v3", "created": "Thu, 6 Jul 2017 15:32:59 GMT"}, {"version": "v4", "created": "Tue, 11 Jul 2017 14:40:56 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Tran", "Van-Khanh", ""], ["Nguyen", "Le-Minh", ""]]}, {"id": "1706.00139", "submitter": "Van-Khanh Tran", "authors": "Van-Khanh Tran, Le-Minh Nguyen", "title": "Natural Language Generation for Spoken Dialogue System using RNN\n  Encoder-Decoder Networks", "comments": "has been accepted to appear at CoNLL 2017. arXiv admin note: text\n  overlap with arXiv:1706.06714", "journal-ref": null, "doi": "10.18653/v1/K17-1044", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language generation (NLG) is a critical component in a spoken\ndialogue system. This paper presents a Recurrent Neural Network based\nEncoder-Decoder architecture, in which an LSTM-based decoder is introduced to\nselect, aggregate semantic elements produced by an attention mechanism over the\ninput elements, and to produce the required utterances. The proposed generator\ncan be jointly trained both sentence planning and surface realization to\nproduce natural language sentences. The proposed model was extensively\nevaluated on four different NLG datasets. The experimental results showed that\nthe proposed generators not only consistently outperform the previous methods\nacross all the NLG domains but also show an ability to generalize from a new,\nunseen domain and learn from multi-domain datasets.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 01:06:17 GMT"}, {"version": "v2", "created": "Tue, 20 Jun 2017 05:54:56 GMT"}, {"version": "v3", "created": "Sat, 12 Aug 2017 15:41:14 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Tran", "Van-Khanh", ""], ["Nguyen", "Le-Minh", ""]]}, {"id": "1706.00188", "submitter": "Pinkesh Badjatiya", "authors": "Pinkesh Badjatiya, Shashank Gupta, Manish Gupta, Vasudeva Varma", "title": "Deep Learning for Hate Speech Detection in Tweets", "comments": "In Proceedings of ACM WWW'17 Companion, Perth, Western Australia, Apr\n  2017 (WWW'17), 2 pages", "journal-ref": null, "doi": "10.1145/3041021.3054223", "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Hate speech detection on Twitter is critical for applications like\ncontroversial event extraction, building AI chatterbots, content\nrecommendation, and sentiment analysis. We define this task as being able to\nclassify a tweet as racist, sexist or neither. The complexity of the natural\nlanguage constructs makes this task very challenging. We perform extensive\nexperiments with multiple deep learning architectures to learn semantic word\nembeddings to handle this complexity. Our experiments on a benchmark dataset of\n16K annotated tweets show that such deep learning methods outperform\nstate-of-the-art char/word n-gram methods by ~18 F1 points.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 07:25:22 GMT"}], "update_date": "2017-06-02", "authors_parsed": [["Badjatiya", "Pinkesh", ""], ["Gupta", "Shashank", ""], ["Gupta", "Manish", ""], ["Varma", "Vasudeva", ""]]}, {"id": "1706.00245", "submitter": "Danijel Korzinek", "authors": "Danijel Kor\\v{z}inek, Krzysztof Marasek, {\\L}ukasz Brocki and\n  Krzysztof Wo{\\l}k", "title": "Polish Read Speech Corpus for Speech Tools and Services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the speech processing activities conducted at the Polish\nconsortium of the CLARIN project. The purpose of this segment of the project\nwas to develop specific tools that would allow for automatic and semi-automatic\nprocessing of large quantities of acoustic speech data. The tools include the\nfollowing: grapheme-to-phoneme conversion, speech-to-text alignment, voice\nactivity detection, speaker diarization, keyword spotting and automatic speech\ntranscription. Furthermore, in order to develop these tools, a large\nhigh-quality studio speech corpus was recorded and released under an open\nlicense, to encourage development in the area of Polish speech research.\nAnother purpose of the corpus was to serve as a reference for studies in\nphonetics and pronunciation. All the tools and resources were released on the\nthe Polish CLARIN website. This paper discusses the current status and future\nplans for the project.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 10:27:07 GMT"}], "update_date": "2017-06-02", "authors_parsed": [["Kor\u017einek", "Danijel", ""], ["Marasek", "Krzysztof", ""], ["Brocki", "\u0141ukasz", ""], ["Wo\u0142k", "Krzysztof", ""]]}, {"id": "1706.00286", "submitter": "Dzmitry Bahdanau", "authors": "Dzmitry Bahdanau, Tom Bosc, Stanis{\\l}aw Jastrz\\k{e}bski, Edward\n  Grefenstette, Pascal Vincent, Yoshua Bengio", "title": "Learning to Compute Word Embeddings On the Fly", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Words in natural language follow a Zipfian distribution whereby some words\nare frequent but most are rare. Learning representations for words in the \"long\ntail\" of this distribution requires enormous amounts of data. Representations\nof rare words trained directly on end tasks are usually poor, requiring us to\npre-train embeddings on external data, or treat all rare words as\nout-of-vocabulary words with a unique representation. We provide a method for\npredicting embeddings of rare words on the fly from small amounts of auxiliary\ndata with a network trained end-to-end for the downstream task. We show that\nthis improves results against baselines where embeddings are trained on the end\ntask for reading comprehension, recognizing textual entailment and language\nmodeling.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 13:12:15 GMT"}, {"version": "v2", "created": "Mon, 5 Jun 2017 20:18:27 GMT"}, {"version": "v3", "created": "Wed, 7 Mar 2018 16:07:10 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Bahdanau", "Dzmitry", ""], ["Bosc", "Tom", ""], ["Jastrz\u0119bski", "Stanis\u0142aw", ""], ["Grefenstette", "Edward", ""], ["Vincent", "Pascal", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1706.00290", "submitter": "Julius Kunze", "authors": "Julius Kunze, Louis Kirsch, Ilia Kurenkov, Andreas Krug, Jens\n  Johannsmeier and Sebastian Stober", "title": "Transfer Learning for Speech Recognition on a Budget", "comments": "Accepted for 2nd ACL Workshop on Representation Learning for NLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end training of automated speech recognition (ASR) systems requires\nmassive data and compute resources. We explore transfer learning based on model\nadaptation as an approach for training ASR models under constrained GPU memory,\nthroughput and training data. We conduct several systematic experiments\nadapting a Wav2Letter convolutional neural network originally trained for\nEnglish ASR to the German language. We show that this technique allows faster\ntraining on consumer-grade resources while requiring less training data in\norder to achieve the same accuracy, thereby lowering the cost of training ASR\nmodels in other languages. Model introspection revealed that small adaptations\nto the network's weights were sufficient for good performance, especially for\ninner layers.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 13:33:54 GMT"}], "update_date": "2017-06-02", "authors_parsed": [["Kunze", "Julius", ""], ["Kirsch", "Louis", ""], ["Kurenkov", "Ilia", ""], ["Krug", "Andreas", ""], ["Johannsmeier", "Jens", ""], ["Stober", "Sebastian", ""]]}, {"id": "1706.00321", "submitter": "Jan Trmal", "authors": "Jan Trmal, Gaurav Kumar, Vimal Manohar, Sanjeev Khudanpur, Matt Post,\n  Paul McNamee", "title": "Using of heterogeneous corpora for training of an ASR system", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper summarizes the development of the LVCSR system built as a part of\nthe Pashto speech-translation system at the SCALE (Summer Camp for Applied\nLanguage Exploration) 2015 workshop on \"Speech-to-text-translation for\nlow-resource languages\". The Pashto language was chosen as a good \"proxy\"\nlow-resource language, exhibiting multiple phenomena which make the\nspeech-recognition and and speech-to-text-translation systems development hard.\n  Even when the amount of data is seemingly sufficient, given the fact that the\ndata originates from multiple sources, the preliminary experiments reveal that\nthere is little to no benefit in merging (concatenating) the corpora and more\nelaborate ways of making use of all of the data must be worked out.\n  This paper concentrates only on the LVCSR part and presents a range of\ndifferent techniques that were found to be useful in order to benefit from\nmultiple different corpora\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 14:30:19 GMT"}], "update_date": "2017-06-02", "authors_parsed": [["Trmal", "Jan", ""], ["Kumar", "Gaurav", ""], ["Manohar", "Vimal", ""], ["Khudanpur", "Sanjeev", ""], ["Post", "Matt", ""], ["McNamee", "Paul", ""]]}, {"id": "1706.00359", "submitter": "Yishu Miao", "authors": "Yishu Miao, Edward Grefenstette, Phil Blunsom", "title": "Discovering Discrete Latent Topics with Neural Variational Inference", "comments": "ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic models have been widely explored as probabilistic generative models of\ndocuments. Traditional inference methods have sought closed-form derivations\nfor updating the models, however as the expressiveness of these models grows,\nso does the difficulty of performing fast and accurate inference over their\nparameters. This paper presents alternative neural approaches to topic\nmodelling by providing parameterisable distributions over topics which permit\ntraining by backpropagation in the framework of neural variational inference.\nIn addition, with the help of a stick-breaking construction, we propose a\nrecurrent network that is able to discover a notionally unbounded number of\ntopics, analogous to Bayesian non-parametric topic models. Experimental results\non the MXM Song Lyrics, 20NewsGroups and Reuters News datasets demonstrate the\neffectiveness and efficiency of these neural topic models.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 15:55:42 GMT"}, {"version": "v2", "created": "Mon, 21 May 2018 19:00:21 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Miao", "Yishu", ""], ["Grefenstette", "Edward", ""], ["Blunsom", "Phil", ""]]}, {"id": "1706.00374", "submitter": "Nikola Mrk\\v{s}i\\'c", "authors": "Nikola Mrk\\v{s}i\\'c, Ivan Vuli\\'c, Diarmuid \\'O S\\'eaghdha, Ira\n  Leviant, Roi Reichart, Milica Ga\\v{s}i\\'c, Anna Korhonen and Steve Young", "title": "Semantic Specialisation of Distributional Word Vector Spaces using\n  Monolingual and Cross-Lingual Constraints", "comments": "Accepted for publication at TACL (to be presented at EMNLP 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Attract-Repel, an algorithm for improving the semantic quality of\nword vectors by injecting constraints extracted from lexical resources.\nAttract-Repel facilitates the use of constraints from mono- and cross-lingual\nresources, yielding semantically specialised cross-lingual vector spaces. Our\nevaluation shows that the method can make use of existing cross-lingual\nlexicons to construct high-quality vector spaces for a plethora of different\nlanguages, facilitating semantic transfer from high- to lower-resource ones.\nThe effectiveness of our approach is demonstrated with state-of-the-art results\non semantic similarity datasets in six languages. We next show that\nAttract-Repel-specialised vectors boost performance in the downstream task of\ndialogue state tracking (DST) across multiple languages. Finally, we show that\ncross-lingual vector spaces produced by our algorithm facilitate the training\nof multilingual DST models, which brings further performance improvements.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 16:29:47 GMT"}], "update_date": "2017-06-02", "authors_parsed": [["Mrk\u0161i\u0107", "Nikola", ""], ["Vuli\u0107", "Ivan", ""], ["S\u00e9aghdha", "Diarmuid \u00d3", ""], ["Leviant", "Ira", ""], ["Reichart", "Roi", ""], ["Ga\u0161i\u0107", "Milica", ""], ["Korhonen", "Anna", ""], ["Young", "Steve", ""]]}, {"id": "1706.00377", "submitter": "Ivan Vuli\\'c", "authors": "Ivan Vuli\\'c, Nikola Mrk\\v{s}i\\'c, Roi Reichart, Diarmuid \\'O\n  S\\'eaghdha, Steve Young, and Anna Korhonen", "title": "Morph-fitting: Fine-Tuning Word Vector Spaces with Simple\n  Language-Specific Rules", "comments": "ACL 2017 (Long paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Morphologically rich languages accentuate two properties of distributional\nvector space models: 1) the difficulty of inducing accurate representations for\nlow-frequency word forms; and 2) insensitivity to distinct lexical relations\nthat have similar distributional signatures. These effects are detrimental for\nlanguage understanding systems, which may infer that 'inexpensive' is a\nrephrasing for 'expensive' or may not associate 'acquire' with 'acquires'. In\nthis work, we propose a novel morph-fitting procedure which moves past the use\nof curated semantic lexicons for improving distributional vector spaces.\nInstead, our method injects morphological constraints generated using simple\nlanguage-specific rules, pulling inflectional forms of the same word close\ntogether and pushing derivational antonyms far apart. In intrinsic evaluation\nover four languages, we show that our approach: 1) improves low-frequency word\nestimates; and 2) boosts the semantic quality of the entire word vector\ncollection. Finally, we show that morph-fitted vectors yield large gains in the\ndownstream task of dialogue state tracking, highlighting the importance of\nmorphology for tackling long-tail phenomena in language understanding tasks.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 16:31:20 GMT"}], "update_date": "2017-06-02", "authors_parsed": [["Vuli\u0107", "Ivan", ""], ["Mrk\u0161i\u0107", "Nikola", ""], ["Reichart", "Roi", ""], ["S\u00e9aghdha", "Diarmuid \u00d3", ""], ["Young", "Steve", ""], ["Korhonen", "Anna", ""]]}, {"id": "1706.00457", "submitter": "Ozan Caglayan", "authors": "Ozan Caglayan, Mercedes Garc\\'ia-Mart\\'inez, Adrien Bardet, Walid\n  Aransa, Fethi Bougares, Lo\\\"ic Barrault", "title": "NMTPY: A Flexible Toolkit for Advanced Neural Machine Translation\n  Systems", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": "10.1515/pralin-2017-0035", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present nmtpy, a flexible Python toolkit based on Theano\nfor training Neural Machine Translation and other neural sequence-to-sequence\narchitectures. nmtpy decouples the specification of a network from the training\nand inference utilities to simplify the addition of a new architecture and\nreduce the amount of boilerplate code to be written. nmtpy has been used for\nLIUM's top-ranked submissions to WMT Multimodal Machine Translation and News\nTranslation tasks in 2016 and 2017.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 18:57:39 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Caglayan", "Ozan", ""], ["Garc\u00eda-Mart\u00ednez", "Mercedes", ""], ["Bardet", "Adrien", ""], ["Aransa", "Walid", ""], ["Bougares", "Fethi", ""], ["Barrault", "Lo\u00efc", ""]]}, {"id": "1706.00465", "submitter": "Laurent Besacier", "authors": "Elodie Gauthier, Laurent Besacier, Sylvie Voisin", "title": "Machine Assisted Analysis of Vowel Length Contrasts in Wolof", "comments": "Accepted to Interspeech 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Growing digital archives and improving algorithms for automatic analysis of\ntext and speech create new research opportunities for fundamental research in\nphonetics. Such empirical approaches allow statistical evaluation of a much\nlarger set of hypothesis about phonetic variation and its conditioning factors\n(among them geographical / dialectal variants). This paper illustrates this\nvision and proposes to challenge automatic methods for the analysis of a not\neasily observable phenomenon: vowel length contrast. We focus on Wolof, an\nunder-resourced language from Sub-Saharan Africa. In particular, we propose\nmultiple features to make a fine evaluation of the degree of length contrast\nunder different factors such as: read vs semi spontaneous speech ; standard vs\ndialectal Wolof. Our measures made fully automatically on more than 20k vowel\ntokens show that our proposed features can highlight different degrees of\ncontrast for each vowel considered. We notably show that contrast is weaker in\nsemi-spontaneous speech and in a non standard semi-spontaneous dialect.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 19:20:50 GMT"}], "update_date": "2017-06-05", "authors_parsed": [["Gauthier", "Elodie", ""], ["Besacier", "Laurent", ""], ["Voisin", "Sylvie", ""]]}, {"id": "1706.00468", "submitter": "Kyle Richardson", "authors": "Kyle Richardson and Jonas Kuhn", "title": "Function Assistant: A Tool for NL Querying of APIs", "comments": "in Proceedings of EMNLP-2017 (system demonstrations)", "journal-ref": null, "doi": "10.18653/v1/D17-2012", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe Function Assistant, a lightweight Python-based\ntoolkit for querying and exploring source code repositories using natural\nlanguage. The toolkit is designed to help end-users of a target API quickly\nfind information about functions through high-level natural language queries\nand descriptions. For a given text query and background API, the tool finds\ncandidate functions by performing a translation from the text to known\nrepresentations in the API using the semantic parsing approach of Richardson\nand Kuhn (2017). Translations are automatically learned from example text-code\npairs in example APIs. The toolkit includes features for building translation\npipelines and query engines for arbitrary source code projects. To explore this\nlast feature, we perform new experiments on 27 well-known Python projects\nhosted on Github.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 19:26:32 GMT"}, {"version": "v2", "created": "Fri, 15 Sep 2017 11:57:36 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Richardson", "Kyle", ""], ["Kuhn", "Jonas", ""]]}, {"id": "1706.00506", "submitter": "Onur G\\\"ung\\\"or", "authors": "Onur Gungor, Eray Yildiz, Suzan Uskudarli, Tunga Gungor", "title": "Morphological Embeddings for Named Entity Recognition in Morphologically\n  Rich Languages", "comments": "Working draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present new state-of-the-art results of 93.59,% and 79.59,%\nfor Turkish and Czech named entity recognition based on the model of (Lample et\nal., 2016). We contribute by proposing several schemes for representing the\nmorphological analysis of a word in the context of named entity recognition. We\nshow that a concatenation of this representation with the word and character\nembeddings improves the performance. The effect of these representation schemes\non the tagging performance is also investigated.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 21:59:47 GMT"}], "update_date": "2017-06-05", "authors_parsed": [["Gungor", "Onur", ""], ["Yildiz", "Eray", ""], ["Uskudarli", "Suzan", ""], ["Gungor", "Tunga", ""]]}, {"id": "1706.00593", "submitter": "Jooyeon Kim", "authors": "Jooyeon Kim, Dongwoo Kim, Alice Oh", "title": "Joint Modeling of Topics, Citations, and Topical Authority in Academic\n  Corpora", "comments": "Accepted by Transactions of the Association for Computational\n  Linguistics (TACL); to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of scientific progress stems from previously published findings, but\nsearching through the vast sea of scientific publications is difficult. We\noften rely on metrics of scholarly authority to find the prominent authors but\nthese authority indices do not differentiate authority based on research\ntopics. We present Latent Topical-Authority Indexing (LTAI) for jointly\nmodeling the topics, citations, and topical authority in a corpus of academic\npapers. Compared to previous models, LTAI differs in two main aspects. First,\nit explicitly models the generative process of the citations, rather than\ntreating the citations as given. Second, it models each author's influence on\ncitations of a paper based on the topics of the cited papers, as well as the\nciting papers. We fit LTAI to four academic corpora: CORA, Arxiv Physics, PNAS,\nand Citeseer. We compare the performance of LTAI against various baselines,\nstarting with the latent Dirichlet allocation, to the more advanced models\nincluding author-link topic model and dynamic author citation topic model. The\nresults show that LTAI achieves improved accuracy over other similar models\nwhen predicting words, citations and authors of publications.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jun 2017 08:52:47 GMT"}], "update_date": "2017-06-05", "authors_parsed": [["Kim", "Jooyeon", ""], ["Kim", "Dongwoo", ""], ["Oh", "Alice", ""]]}, {"id": "1706.00612", "submitter": "Michael Neumann", "authors": "Michael Neumann, Ngoc Thang Vu", "title": "Attentive Convolutional Neural Network based Speech Emotion Recognition:\n  A Study on the Impact of Input Features, Signal Length, and Acted Speech", "comments": "to appear in the proceedings of Interspeech 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech emotion recognition is an important and challenging task in the realm\nof human-computer interaction. Prior work proposed a variety of models and\nfeature sets for training a system. In this work, we conduct extensive\nexperiments using an attentive convolutional neural network with multi-view\nlearning objective function. We compare system performance using different\nlengths of the input signal, different types of acoustic features and different\ntypes of emotion speech (improvised/scripted). Our experimental results on the\nInteractive Emotional Motion Capture (IEMOCAP) database reveal that the\nrecognition performance strongly depends on the type of speech data independent\nof the choice of input features. Furthermore, we achieved state-of-the-art\nresults on the improvised speech data of IEMOCAP.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jun 2017 10:12:52 GMT"}], "update_date": "2017-06-05", "authors_parsed": [["Neumann", "Michael", ""], ["Vu", "Ngoc Thang", ""]]}, {"id": "1706.00741", "submitter": "Sabrina Stehwien", "authors": "Sabrina Stehwien and Ngoc Thang Vu", "title": "Prosodic Event Recognition using Convolutional Neural Networks with\n  Context Information", "comments": "Interspeech 2017 4 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper demonstrates the potential of convolutional neural networks (CNN)\nfor detecting and classifying prosodic events on words, specifically pitch\naccents and phrase boundary tones, from frame-based acoustic features. Typical\napproaches use not only feature representations of the word in question but\nalso its surrounding context. We show that adding position features indicating\nthe current word benefits the CNN. In addition, this paper discusses the\ngeneralization from a speaker-dependent modelling approach to a\nspeaker-independent setup. The proposed method is simple and efficient and\nyields strong results not only in speaker-dependent but also\nspeaker-independent cases.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jun 2017 16:20:19 GMT"}], "update_date": "2017-06-05", "authors_parsed": [["Stehwien", "Sabrina", ""], ["Vu", "Ngoc Thang", ""]]}, {"id": "1706.00884", "submitter": "Xintao Wu", "authors": "Shuhan Yuan, Xintao Wu, Yang Xiang", "title": "Task-specific Word Identification from Short Texts Using a Convolutional\n  Neural Network", "comments": "accepted by Intelligent Data Analysis, an International Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task-specific word identification aims to choose the task-related words that\nbest describe a short text. Existing approaches require well-defined seed words\nor lexical dictionaries (e.g., WordNet), which are often unavailable for many\napplications such as social discrimination detection and fake review detection.\nHowever, we often have a set of labeled short texts where each short text has a\ntask-related class label, e.g., discriminatory or non-discriminatory, specified\nby users or learned by classification algorithms. In this paper, we focus on\nidentifying task-specific words and phrases from short texts by exploiting\ntheir class labels rather than using seed words or lexical dictionaries. We\nconsider the task-specific word and phrase identification as feature learning.\nWe train a convolutional neural network over a set of labeled texts and use\nscore vectors to localize the task-specific words and phrases. Experimental\nresults on sentiment word identification show that our approach significantly\noutperforms existing methods. We further conduct two case studies to show the\neffectiveness of our approach. One case study on a crawled tweets dataset\ndemonstrates that our approach can successfully capture the\ndiscrimination-related words/phrases. The other case study on fake review\ndetection shows that our approach can identify the fake-review words/phrases.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jun 2017 02:15:44 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Yuan", "Shuhan", ""], ["Wu", "Xintao", ""], ["Xiang", "Yang", ""]]}, {"id": "1706.00887", "submitter": "Xintao Wu", "authors": "Shuhan Yuan, Panpan Zheng, Xintao Wu, Yang Xiang", "title": "Wikipedia Vandal Early Detection: from User Behavior to User Embedding", "comments": "14 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wikipedia is the largest online encyclopedia that allows anyone to edit\narticles. In this paper, we propose the use of deep learning to detect vandals\nbased on their edit history. In particular, we develop a multi-source\nlong-short term memory network (M-LSTM) to model user behaviors by using a\nvariety of user edit aspects as inputs, including the history of edit reversion\ninformation, edit page titles and categories. With M-LSTM, we can encode each\nuser into a low dimensional real vector, called user embedding. Meanwhile, as a\nsequential model, M-LSTM updates the user embedding each time after the user\ncommits a new edit. Thus, we can predict whether a user is benign or vandal\ndynamically based on the up-to-date user embedding. Furthermore, those user\nembeddings are crucial to discover collaborative vandals.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jun 2017 02:42:40 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Yuan", "Shuhan", ""], ["Zheng", "Panpan", ""], ["Wu", "Xintao", ""], ["Xiang", "Yang", ""]]}, {"id": "1706.00927", "submitter": "Su Zhu", "authors": "Su Zhu and Kai Yu", "title": "Concept Transfer Learning for Adaptive Language Understanding", "comments": "9 pages, 5 figures; SIGDial 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concept definition is important in language understanding (LU) adaptation\nsince literal definition difference can easily lead to data sparsity even if\ndifferent data sets are actually semantically correlated. To address this\nissue, in this paper, a novel concept transfer learning approach is proposed.\nHere, substructures within literal concept definition are investigated to\nreveal the relationship between concepts. A hierarchical semantic\nrepresentation for concepts is proposed, where a semantic slot is represented\nas a composition of {\\em atomic concepts}. Based on this new hierarchical\nrepresentation, transfer learning approaches are developed for adaptive LU. The\napproaches are applied to two tasks: value set mismatch and domain adaptation,\nand evaluated on two LU benchmarks: ATIS and DSTC 2\\&3. Thorough empirical\nstudies validate both the efficiency and effectiveness of the proposed method.\nIn particular, we achieve state-of-the-art performance ($F_1$-score 96.08\\%) on\nATIS by only using lexicon features.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jun 2017 10:46:50 GMT"}, {"version": "v2", "created": "Sun, 8 Oct 2017 01:40:08 GMT"}, {"version": "v3", "created": "Thu, 4 Jul 2019 07:10:37 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Zhu", "Su", ""], ["Yu", "Kai", ""]]}, {"id": "1706.01038", "submitter": "Van-Khanh Tran", "authors": "Danilo S. Carvalho, Duc-Vu Tran, Van-Khanh Tran, Le-Nguyen Minh", "title": "Improving Legal Information Retrieval by Distributional Composition with\n  Term Order Probabilities", "comments": "wrong version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Legal professionals worldwide are currently trying to get up-to-pace with the\nexplosive growth in legal document availability through digital means. This\ndrives a need for high efficiency Legal Information Retrieval (IR) and Question\nAnswering (QA) methods. The IR task in particular has a set of unique\nchallenges that invite the use of semantic motivated NLP techniques. In this\nwork, a two-stage method for Legal Information Retrieval is proposed, combining\nlexical statistics and distributional sentence representations in the context\nof Competition on Legal Information Extraction/Entailment (COLIEE). The\ncombination is done with the use of disambiguation rules, applied over the\nrankings obtained through n-gram statistics. After the ranking is done, its\nresults are evaluated for ambiguity, and disambiguation is done if a result is\ndecided to be unreliable for a given query. Competition and experimental\nresults indicate small gains in overall retrieval performance using the\nproposed approach. Additionally, an analysis of error and improvement cases is\npresented for a better understanding of the contributions.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jun 2017 06:57:09 GMT"}, {"version": "v2", "created": "Sat, 10 Jun 2017 10:49:15 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Carvalho", "Danilo S.", ""], ["Tran", "Duc-Vu", ""], ["Tran", "Van-Khanh", ""], ["Minh", "Le-Nguyen", ""]]}, {"id": "1706.01069", "submitter": "Xinyu Fu", "authors": "Xinyu Fu, Eugene Ch'ng, Uwe Aickelin, Simon See", "title": "CRNN: A Joint Neural Network for Redundancy Detection", "comments": "Conference paper accepted at IEEE SMARTCOMP 2017, Hong Kong", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel framework for detecting redundancy in supervised\nsentence categorisation. Unlike traditional singleton neural network, our model\nincorporates character-aware convolutional neural network (Char-CNN) with\ncharacter-aware recurrent neural network (Char-RNN) to form a convolutional\nrecurrent neural network (CRNN). Our model benefits from Char-CNN in that only\nsalient features are selected and fed into the integrated Char-RNN. Char-RNN\neffectively learns long sequence semantics via sophisticated update mechanism.\nWe compare our framework against the state-of-the-art text classification\nalgorithms on four popular benchmarking corpus. For instance, our model\nachieves competing precision rate, recall ratio, and F1 score on the\nGoogle-news data-set. For twenty-news-groups data stream, our algorithm obtains\nthe optimum on precision rate, recall ratio, and F1 score. For Brown Corpus,\nour framework obtains the best F1 score and almost equivalent precision rate\nand recall ratio over the top competitor. For the question classification\ncollection, CRNN produces the optimal recall rate and F1 score and comparable\nprecision rate. We also analyse three different RNN hidden recurrent cells'\nimpact on performance and their runtime efficiency. We observe that MGU\nachieves the optimal runtime and comparable performance against GRU and LSTM.\nFor TFIDF based algorithms, we experiment with word2vec, GloVe, and sent2vec\nembeddings and report their performance differences.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jun 2017 13:12:45 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Fu", "Xinyu", ""], ["Ch'ng", "Eugene", ""], ["Aickelin", "Uwe", ""], ["See", "Simon", ""]]}, {"id": "1706.01084", "submitter": "Ting Chen", "authors": "Ting Chen, Liangjie Hong, Yue Shi, Yizhou Sun", "title": "Joint Text Embedding for Personalized Content-based Recommendation", "comments": "typo fixes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a good representation of text is key to many recommendation\napplications. Examples include news recommendation where texts to be\nrecommended are constantly published everyday. However, most existing\nrecommendation techniques, such as matrix factorization based methods, mainly\nrely on interaction histories to learn representations of items. While latent\nfactors of items can be learned effectively from user interaction data, in many\ncases, such data is not available, especially for newly emerged items.\n  In this work, we aim to address the problem of personalized recommendation\nfor completely new items with text information available. We cast the problem\nas a personalized text ranking problem and propose a general framework that\ncombines text embedding with personalized recommendation. Users and textual\ncontent are embedded into latent feature space. The text embedding function can\nbe learned end-to-end by predicting user interactions with items. To alleviate\nsparsity in interaction data, and leverage large amount of text data with\nlittle or no user interactions, we further propose a joint text embedding model\nthat incorporates unsupervised text embedding with a combination module.\nExperimental results show that our model can significantly improve the\neffectiveness of recommendation systems on real-world datasets.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jun 2017 14:48:28 GMT"}, {"version": "v2", "created": "Fri, 23 Jun 2017 21:55:56 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Chen", "Ting", ""], ["Hong", "Liangjie", ""], ["Shi", "Yue", ""], ["Sun", "Yizhou", ""]]}, {"id": "1706.01206", "submitter": "Ji Ho Park", "authors": "Ji Ho Park and Pascale Fung", "title": "One-step and Two-step Classification for Abusive Language Detection on\n  Twitter", "comments": "ALW1: 1st Workshop on Abusive Language Online to be held at the\n  annual meeting of the Association of Computational Linguistics (ACL) 2017\n  (Vancouver, Canada), August 4th, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic abusive language detection is a difficult but important task for\nonline social media. Our research explores a two-step approach of performing\nclassification on abusive language and then classifying into specific types and\ncompares it with one-step approach of doing one multi-class classification for\ndetecting sexist and racist languages. With a public English Twitter corpus of\n20 thousand tweets in the type of sexism and racism, our approach shows a\npromising performance of 0.827 F-measure by using HybridCNN in one-step and\n0.824 F-measure by using logistic regression in two-steps.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jun 2017 06:20:23 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Park", "Ji Ho", ""], ["Fung", "Pascale", ""]]}, {"id": "1706.01322", "submitter": "Alexander Kuhnle", "authors": "Alexander Kuhnle and Ann Copestake", "title": "Deep learning evaluation using deep linguistic processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss problems with the standard approaches to evaluation for tasks like\nvisual question answering, and argue that artificial data can be used to\naddress these as a complement to current practice. We demonstrate that with the\nhelp of existing 'deep' linguistic processing technology we are able to create\nchallenging abstract datasets, which enable us to investigate the language\nunderstanding abilities of multimodal deep learning models in detail, as\ncompared to a single performance value on a static and monolithic dataset.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jun 2017 13:53:56 GMT"}, {"version": "v2", "created": "Sat, 12 May 2018 10:37:02 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Kuhnle", "Alexander", ""], ["Copestake", "Ann", ""]]}, {"id": "1706.01331", "submitter": "Mark Riedl", "authors": "Lara J. Martin, Prithviraj Ammanabrolu, Xinyu Wang, William Hancock,\n  Shruti Singh, Brent Harrison, Mark O. Riedl", "title": "Event Representations for Automated Story Generation with Deep Neural\n  Nets", "comments": "Submitted to AAAI'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated story generation is the problem of automatically selecting a\nsequence of events, actions, or words that can be told as a story. We seek to\ndevelop a system that can generate stories by learning everything it needs to\nknow from textual story corpora. To date, recurrent neural networks that learn\nlanguage models at character, word, or sentence levels have had little success\ngenerating coherent stories. We explore the question of event representations\nthat provide a mid-level of abstraction between words and sentences in order to\nretain the semantic information of the original data while minimizing event\nsparsity. We present a technique for preprocessing textual story data into\nevent sequences. We then present a technique for automated story generation\nwhereby we decompose the problem into the generation of successive events\n(event2event) and the generation of natural language sentences from events\n(event2sentence). We give empirical results comparing different event\nrepresentations and their effects on event successor generation and the\ntranslation of events to natural language.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jun 2017 14:04:48 GMT"}, {"version": "v2", "created": "Mon, 14 Aug 2017 18:14:02 GMT"}, {"version": "v3", "created": "Tue, 12 Sep 2017 14:45:22 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Martin", "Lara J.", ""], ["Ammanabrolu", "Prithviraj", ""], ["Wang", "Xinyu", ""], ["Hancock", "William", ""], ["Singh", "Shruti", ""], ["Harrison", "Brent", ""], ["Riedl", "Mark O.", ""]]}, {"id": "1706.01340", "submitter": "Robin Ruede", "authors": "Robin Ruede, Markus M\\\"uller, Sebastian St\\\"uker, Alex Waibel", "title": "Yeah, Right, Uh-Huh: A Deep Learning Backchannel Predictor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.HC cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using supporting backchannel (BC) cues can make human-computer interaction\nmore social. BCs provide a feedback from the listener to the speaker indicating\nto the speaker that he is still listened to. BCs can be expressed in different\nways, depending on the modality of the interaction, for example as gestures or\nacoustic cues. In this work, we only considered acoustic cues. We are proposing\nan approach towards detecting BC opportunities based on acoustic input features\nlike power and pitch. While other works in the field rely on the use of a\nhand-written rule set or specialized features, we made use of artificial neural\nnetworks. They are capable of deriving higher order features from input\nfeatures themselves. In our setup, we first used a fully connected feed-forward\nnetwork to establish an updated baseline in comparison to our previously\nproposed setup. We also extended this setup by the use of Long Short-Term\nMemory (LSTM) networks which have shown to outperform feed-forward based setups\non various tasks. Our best system achieved an F1-Score of 0.37 using power and\npitch features. Adding linguistic information using word2vec, the score\nincreased to 0.39.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jun 2017 17:05:26 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Ruede", "Robin", ""], ["M\u00fcller", "Markus", ""], ["St\u00fcker", "Sebastian", ""], ["Waibel", "Alex", ""]]}, {"id": "1706.01399", "submitter": "Ofir Press", "authors": "Ofir Press, Amir Bar, Ben Bogin, Jonathan Berant, Lior Wolf", "title": "Language Generation with Recurrent Generative Adversarial Networks\n  without Pre-training", "comments": "Presented at the 1st Workshop on Learning to Generate Natural\n  Language at ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have shown great promise recently in\nimage generation. Training GANs for language generation has proven to be more\ndifficult, because of the non-differentiable nature of generating text with\nrecurrent neural networks. Consequently, past work has either resorted to\npre-training with maximum-likelihood or used convolutional networks for\ngeneration. In this work, we show that recurrent neural networks can be trained\nto generate text with GANs from scratch using curriculum learning, by slowly\nteaching the model to generate sequences of increasing and variable length. We\nempirically show that our approach vastly improves the quality of generated\nsequences compared to a convolutional baseline.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jun 2017 16:10:58 GMT"}, {"version": "v2", "created": "Mon, 12 Jun 2017 17:22:19 GMT"}, {"version": "v3", "created": "Thu, 21 Dec 2017 16:10:31 GMT"}], "update_date": "2017-12-22", "authors_parsed": [["Press", "Ofir", ""], ["Bar", "Amir", ""], ["Bogin", "Ben", ""], ["Berant", "Jonathan", ""], ["Wolf", "Lior", ""]]}, {"id": "1706.01427", "submitter": "Adam Santoro", "authors": "Adam Santoro, David Raposo, David G.T. Barrett, Mateusz Malinowski,\n  Razvan Pascanu, Peter Battaglia, Timothy Lillicrap", "title": "A simple neural network module for relational reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relational reasoning is a central component of generally intelligent\nbehavior, but has proven difficult for neural networks to learn. In this paper\nwe describe how to use Relation Networks (RNs) as a simple plug-and-play module\nto solve problems that fundamentally hinge on relational reasoning. We tested\nRN-augmented networks on three tasks: visual question answering using a\nchallenging dataset called CLEVR, on which we achieve state-of-the-art,\nsuper-human performance; text-based question answering using the bAbI suite of\ntasks; and complex reasoning about dynamic physical systems. Then, using a\ncurated dataset called Sort-of-CLEVR we show that powerful convolutional\nnetworks do not have a general capacity to solve relational questions, but can\ngain this capacity when augmented with RNs. Our work shows how a deep learning\narchitecture equipped with an RN module can implicitly discover and learn to\nreason about entities and their relations.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jun 2017 17:17:18 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Santoro", "Adam", ""], ["Raposo", "David", ""], ["Barrett", "David G. T.", ""], ["Malinowski", "Mateusz", ""], ["Pascanu", "Razvan", ""], ["Battaglia", "Peter", ""], ["Lillicrap", "Timothy", ""]]}, {"id": "1706.01450", "submitter": "Tong Wang", "authors": "Tong Wang and Xingdi Yuan and Adam Trischler", "title": "A Joint Model for Question Answering and Question Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a generative machine comprehension model that learns jointly to\nask and answer questions based on documents. The proposed model uses a\nsequence-to-sequence framework that encodes the document and generates a\nquestion (answer) given an answer (question). Significant improvement in model\nperformance is observed empirically on the SQuAD corpus, confirming our\nhypothesis that the model benefits from jointly learning to perform both tasks.\nWe believe the joint model's novelty offers a new perspective on machine\ncomprehension beyond architectural engineering, and serves as a first step\ntowards autonomous information seeking.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jun 2017 17:58:52 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Wang", "Tong", ""], ["Yuan", "Xingdi", ""], ["Trischler", "Adam", ""]]}, {"id": "1706.01554", "submitter": "Jiasen Lu", "authors": "Jiasen Lu, Anitha Kannan, Jianwei Yang, Devi Parikh, Dhruv Batra", "title": "Best of Both Worlds: Transferring Knowledge from Discriminative Learning\n  to a Generative Visual Dialog Model", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel training framework for neural sequence models,\nparticularly for grounded dialog generation. The standard training paradigm for\nthese models is maximum likelihood estimation (MLE), or minimizing the\ncross-entropy of the human responses. Across a variety of domains, a recurring\nproblem with MLE trained generative neural dialog models (G) is that they tend\nto produce 'safe' and generic responses (\"I don't know\", \"I can't tell\"). In\ncontrast, discriminative dialog models (D) that are trained to rank a list of\ncandidate human responses outperform their generative counterparts; in terms of\nautomatic metrics, diversity, and informativeness of the responses. However, D\nis not useful in practice since it cannot be deployed to have real\nconversations with users.\n  Our work aims to achieve the best of both worlds -- the practical usefulness\nof G and the strong performance of D -- via knowledge transfer from D to G. Our\nprimary contribution is an end-to-end trainable generative visual dialog model,\nwhere G receives gradients from D as a perceptual (not adversarial) loss of the\nsequence sampled from G. We leverage the recently proposed Gumbel-Softmax (GS)\napproximation to the discrete distribution -- specifically, an RNN augmented\nwith a sequence of GS samplers, coupled with the straight-through gradient\nestimator to enable end-to-end differentiability. We also introduce a stronger\nencoder for visual dialog, and employ a self-attention mechanism for answer\nencoding along with a metric learning loss to aid D in better capturing\nsemantic similarities in answer responses. Overall, our proposed model\noutperforms state-of-the-art on the VisDial dataset by a significant margin\n(2.67% on recall@10). The source code can be downloaded from\nhttps://github.com/jiasenlu/visDial.pytorch.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jun 2017 22:50:37 GMT"}, {"version": "v2", "created": "Fri, 27 Oct 2017 20:27:07 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Lu", "Jiasen", ""], ["Kannan", "Anitha", ""], ["Yang", "Jianwei", ""], ["Parikh", "Devi", ""], ["Batra", "Dhruv", ""]]}, {"id": "1706.01556", "submitter": "Yifan Peng", "authors": "Yifan Peng and Zhiyong Lu", "title": "Deep learning for extracting protein-protein interactions from\n  biomedical literature", "comments": "Accepted for publication in Proceedings of the 2017 Workshop on\n  Biomedical Natural Language Processing, 10 pages, 2 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art methods for protein-protein interaction (PPI) extraction are\nprimarily feature-based or kernel-based by leveraging lexical and syntactic\ninformation. But how to incorporate such knowledge in the recent deep learning\nmethods remains an open question. In this paper, we propose a multichannel\ndependency-based convolutional neural network model (McDepCNN). It applies one\nchannel to the embedding vector of each word in the sentence, and another\nchannel to the embedding vector of the head of the corresponding word.\nTherefore, the model can use richer information obtained from different\nchannels. Experiments on two public benchmarking datasets, AIMed and BioInfer,\ndemonstrate that McDepCNN compares favorably to the state-of-the-art\nrich-feature and single-kernel based methods. In addition, McDepCNN achieves\n24.4% relative improvement in F1-score over the state-of-the-art methods on\ncross-corpus evaluation and 12% improvement in F1-score over kernel-based\nmethods on \"difficult\" instances. These results suggest that McDepCNN\ngeneralizes more easily over different corpora, and is capable of capturing\nlong distance features in the sentences.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jun 2017 23:09:06 GMT"}, {"version": "v2", "created": "Wed, 7 Jun 2017 00:28:21 GMT"}], "update_date": "2017-06-08", "authors_parsed": [["Peng", "Yifan", ""], ["Lu", "Zhiyong", ""]]}, {"id": "1706.01570", "submitter": "Michael Bloodgood", "authors": "Michael Bloodgood and Benjamin Strauss", "title": "Acquisition of Translation Lexicons for Historically Unwritten Languages\n  via Bridging Loanwords", "comments": "5 pages, 1 figure, 1 table; published in the Proceedings of the 10th\n  Workshop on Building and Using Comparable Corpora, pages 21-25, Vancouver,\n  Canada, August 2017", "journal-ref": "In Proceedings of the 10th Workshop on Building and Using\n  Comparable Corpora, pages 21-25, Vancouver, Canada, August 2017. Association\n  for Computational Linguistics", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of informal electronic communications such as social media,\ncolloquial languages that were historically unwritten are being written for the\nfirst time in heavily code-switched environments. We present a method for\ninducing portions of translation lexicons through the use of expert knowledge\nin these settings where there are approximately zero resources available other\nthan a language informant, potentially not even large amounts of monolingual\ndata. We investigate inducing a Moroccan Darija-English translation lexicon via\nFrench loanwords bridging into English and find that a useful lexicon is\ninduced for human-assisted translation and statistical machine translation.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jun 2017 00:55:25 GMT"}, {"version": "v2", "created": "Sun, 20 Aug 2017 20:09:30 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Bloodgood", "Michael", ""], ["Strauss", "Benjamin", ""]]}, {"id": "1706.01678", "submitter": "Shibhansh Dohare", "authors": "Shibhansh Dohare, Harish Karnick, Vivek Gupta", "title": "Text Summarization using Abstract Meaning Representation", "comments": "10 pages, 4 figures, Update: Added more results , corrected figures\n  and tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With an ever increasing size of text present on the Internet, automatic\nsummary generation remains an important problem for natural language\nunderstanding. In this work we explore a novel full-fledged pipeline for text\nsummarization with an intermediate step of Abstract Meaning Representation\n(AMR). The pipeline proposed by us first generates an AMR graph of an input\nstory, through which it extracts a summary graph and finally, generate summary\nsentences from this summary graph. Our proposed method achieves\nstate-of-the-art results compared to the other text summarization routines\nbased on AMR. We also point out some significant problems in the existing\nevaluation methods, which make them unsuitable for evaluating summary quality.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jun 2017 10:04:45 GMT"}, {"version": "v2", "created": "Sun, 9 Jul 2017 20:48:14 GMT"}, {"version": "v3", "created": "Mon, 17 Jul 2017 21:27:44 GMT"}], "update_date": "2017-07-19", "authors_parsed": [["Dohare", "Shibhansh", ""], ["Karnick", "Harish", ""], ["Gupta", "Vivek", ""]]}, {"id": "1706.01690", "submitter": "Hannes Schulz", "authors": "Hannes Schulz, Jeremie Zumer, Layla El Asri, Shikhar Sharma", "title": "A Frame Tracking Model for Memory-Enhanced Dialogue Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, resources and tasks were proposed to go beyond state tracking in\ndialogue systems. An example is the frame tracking task, which requires\nrecording multiple frames, one for each user goal set during the dialogue. This\nallows a user, for instance, to compare items corresponding to different goals.\nThis paper proposes a model which takes as input the list of frames created so\nfar during the dialogue, the current user utterance as well as the dialogue\nacts, slot types, and slot values associated with this utterance. The model\nthen outputs the frame being referenced by each triple of dialogue act, slot\ntype, and slot value. We show that on the recently published Frames dataset,\nthis model significantly outperforms a previously proposed rule-based baseline.\nIn addition, we propose an extensive analysis of the frame tracking task by\ndividing it into sub-tasks and assessing their difficulty with respect to our\nmodel.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jun 2017 10:48:29 GMT"}], "update_date": "2017-06-07", "authors_parsed": [["Schulz", "Hannes", ""], ["Zumer", "Jeremie", ""], ["Asri", "Layla El", ""], ["Sharma", "Shikhar", ""]]}, {"id": "1706.01723", "submitter": "Xiang Yu", "authors": "Xiang Yu and Agnieszka Fale\\'nska and Ngoc Thang Vu", "title": "A General-Purpose Tagger with Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general-purpose tagger based on convolutional neural networks\n(CNN), used for both composing word vectors and encoding context information.\nThe CNN tagger is robust across different tagging tasks: without task-specific\ntuning of hyper-parameters, it achieves state-of-the-art results in\npart-of-speech tagging, morphological tagging and supertagging. The CNN tagger\nis also robust against the out-of-vocabulary problem, it performs well on\nartificially unnormalized texts.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jun 2017 12:11:50 GMT"}], "update_date": "2017-06-07", "authors_parsed": [["Yu", "Xiang", ""], ["Fale\u0144ska", "Agnieszka", ""], ["Vu", "Ngoc Thang", ""]]}, {"id": "1706.01740", "submitter": "Marco Dinarelli", "authors": "Yoann Dupont and Marco Dinarelli and Isabelle Tellier", "title": "Label-Dependencies Aware Recurrent Neural Networks", "comments": "22 pages, 3 figures. Accepted at CICling 2017 conference. Best\n  Verifiability, Reproducibility, and Working Description award", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last few years, Recurrent Neural Networks (RNNs) have proved effective\non several NLP tasks. Despite such great success, their ability to model\n\\emph{sequence labeling} is still limited. This lead research toward solutions\nwhere RNNs are combined with models which already proved effective in this\ndomain, such as CRFs. In this work we propose a solution far simpler but very\neffective: an evolution of the simple Jordan RNN, where labels are re-injected\nas input into the network, and converted into embeddings, in the same way as\nwords. We compare this RNN variant to all the other RNN models, Elman and\nJordan RNN, LSTM and GRU, on two well-known tasks of Spoken Language\nUnderstanding (SLU). Thanks to label embeddings and their combination at the\nhidden layer, the proposed variant, which uses more parameters than Elman and\nJordan RNNs, but far fewer than LSTM and GRU, is more effective than other\nRNNs, but also outperforms sophisticated CRF models.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jun 2017 13:10:49 GMT"}], "update_date": "2017-06-07", "authors_parsed": [["Dupont", "Yoann", ""], ["Dinarelli", "Marco", ""], ["Tellier", "Isabelle", ""]]}, {"id": "1706.01758", "submitter": "Ming Li", "authors": "Ming Li, Peilun Xiao, Ju Zhang", "title": "A WL-SPPIM Semantic Model for Document Classification", "comments": "7pages, 5figures, Keywords: LDA, SPPIM, word embedding, low\n  frequency, document classification", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore SPPIM-based text classification method, and the\nexperiment reveals that the SPPIM method is equal to or even superior than SGNS\nmethod in text classification task on three international and standard text\ndatasets, namely 20newsgroups, Reuters52 and WebKB. Comparing to SGNS, although\nSPPMI provides a better solution, it is not necessarily better than SGNS in\ntext classification tasks. Based on our analysis, SGNS takes into the\nconsideration of weight calculation during decomposition process, so it has\nbetter performance than SPPIM in some standard datasets. Inspired by this, we\npropose a WL-SPPIM semantic model based on SPPIM model, and experiment shows\nthat WL-SPPIM approach has better classification and higher scalability in the\ntext classification task compared with LDA, SGNS and SPPIM approaches.\n", "versions": [{"version": "v1", "created": "Fri, 26 May 2017 08:03:10 GMT"}], "update_date": "2017-06-07", "authors_parsed": [["Li", "Ming", ""], ["Xiao", "Peilun", ""], ["Zhang", "Ju", ""]]}, {"id": "1706.01839", "submitter": "Lawrence Phillips", "authors": "Lawrence Phillips and Nathan Hodas", "title": "Assessing the Linguistic Productivity of Unsupervised Deep Neural\n  Networks", "comments": "To be presented at the 39th Annual Meeting of the Cognitive Science\n  Society", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasingly, cognitive scientists have demonstrated interest in applying\ntools from deep learning. One use for deep learning is in language acquisition\nwhere it is useful to know if a linguistic phenomenon can be learned through\ndomain-general means. To assess whether unsupervised deep learning is\nappropriate, we first pose a smaller question: Can unsupervised neural networks\napply linguistic rules productively, using them in novel situations? We draw\nfrom the literature on determiner/noun productivity by training an\nunsupervised, autoencoder network measuring its ability to combine nouns with\ndeterminers. Our simple autoencoder creates combinations it has not previously\nencountered and produces a degree of overlap matching adults. While this\npreliminary work does not provide conclusive evidence for productivity, it\nwarrants further investigation with more complex models. Further, this work\nhelps lay the foundations for future collaboration between the deep learning\nand cognitive science communities.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jun 2017 16:16:51 GMT"}], "update_date": "2017-06-07", "authors_parsed": [["Phillips", "Lawrence", ""], ["Hodas", "Nathan", ""]]}, {"id": "1706.01847", "submitter": "John Wieting", "authors": "John Wieting, Jonathan Mallinson, Kevin Gimpel", "title": "Learning Paraphrastic Sentence Embeddings from Back-Translated Bitext", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning general-purpose, paraphrastic sentence\nembeddings in the setting of Wieting et al. (2016b). We use neural machine\ntranslation to generate sentential paraphrases via back-translation of\nbilingual sentence pairs. We evaluate the paraphrase pairs by their ability to\nserve as training data for learning paraphrastic sentence embeddings. We find\nthat the data quality is stronger than prior work based on bitext and on par\nwith manually-written English paraphrase pairs, with the advantage that our\napproach can scale up to generate large training sets for many languages and\ndomains. We experiment with several language pairs and data sources, and\ndevelop a variety of data filtering techniques. In the process, we explore how\nneural machine translation output differs from human-written sentences, finding\nclear differences in length, the amount of repetition, and the use of rare\nwords.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jun 2017 16:36:41 GMT"}], "update_date": "2017-06-07", "authors_parsed": [["Wieting", "John", ""], ["Mallinson", "Jonathan", ""], ["Gimpel", "Kevin", ""]]}, {"id": "1706.01863", "submitter": "Peter Sch\\\"uller", "authors": "Peter Sch\\\"uller and K\\\"ubra C{\\i}ng{\\i}ll{\\i} and Ferit Tun\\c{c}er\n  and Bar{\\i}\\c{s} G\\\"un S\\\"urmeli and Ay\\c{s}eg\\\"ul Pekel and Ay\\c{s}e Hande\n  Karatay and Hacer Ezgi Karaka\\c{s}", "title": "Marmara Turkish Coreference Corpus and Coreference Resolution Baseline", "comments": "Submitted to Natural Language Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the Marmara Turkish Coreference Corpus, which is an annotation of\nthe whole METU-Sabanci Turkish Treebank with mentions and coreference chains.\nCollecting eight or more independent annotations for each document allowed for\nfully automatic adjudication. We provide a baseline system for Turkish mention\ndetection and coreference resolution and evaluate it on the corpus.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jun 2017 17:25:36 GMT"}, {"version": "v2", "created": "Tue, 31 Jul 2018 15:15:05 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Sch\u00fcller", "Peter", ""], ["C\u0131ng\u0131ll\u0131", "K\u00fcbra", ""], ["Tun\u00e7er", "Ferit", ""], ["S\u00fcrmeli", "Bar\u0131\u015f G\u00fcn", ""], ["Pekel", "Ay\u015feg\u00fcl", ""], ["Karatay", "Ay\u015fe Hande", ""], ["Karaka\u015f", "Hacer Ezgi", ""]]}, {"id": "1706.01875", "submitter": "Rishab Nithyanand", "authors": "Rishab Nithyanand, Brian Schaffner, Phillipa Gill", "title": "Measuring Offensive Speech in Online Political Discourse", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet and online forums such as Reddit have become an increasingly\npopular medium for citizens to engage in political conversations. However, the\nonline disinhibition effect resulting from the ability to use pseudonymous\nidentities may manifest in the form of offensive speech, consequently making\npolitical discussions more aggressive and polarizing than they already are.\nSuch environments may result in harassment and self-censorship from its\ntargets. In this paper, we present preliminary results from a large-scale\ntemporal measurement aimed at quantifying offensiveness in online political\ndiscussions.\n  To enable our measurements, we develop and evaluate an offensive speech\nclassifier. We then use this classifier to quantify and compare offensiveness\nin the political and general contexts. We perform our study using a database of\nover 168M Reddit comments made by over 7M pseudonyms between January 2015 and\nJanuary 2017 -- a period covering several divisive political events including\nthe 2016 US presidential elections.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jun 2017 21:29:23 GMT"}, {"version": "v2", "created": "Wed, 19 Jul 2017 17:24:51 GMT"}], "update_date": "2017-07-20", "authors_parsed": [["Nithyanand", "Rishab", ""], ["Schaffner", "Brian", ""], ["Gill", "Phillipa", ""]]}, {"id": "1706.01967", "submitter": "Keet Sugathadasa Mr", "authors": "Keet Sugathadasa, Buddhi Ayesha, Nisansa de Silva, Amal Shehan Perera,\n  Vindula Jayawardana, Dimuthu Lakmal, Madhavi Perera", "title": "Synergistic Union of Word2Vec and Lexicon for Domain Specific Semantic\n  Similarity", "comments": "6 Pages, 3 figures", "journal-ref": null, "doi": "10.1109/ICIINFS.2017.8300343", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic similarity measures are an important part in Natural Language\nProcessing tasks. However Semantic similarity measures built for general use do\nnot perform well within specific domains. Therefore in this study we introduce\na domain specific semantic similarity measure that was created by the\nsynergistic union of word2vec, a word embedding method that is used for\nsemantic similarity calculation and lexicon based (lexical) semantic similarity\nmethods. We prove that this proposed methodology out performs word embedding\nmethods trained on generic corpus and methods trained on domain specific corpus\nbut do not use lexical semantic similarity methods to augment the results.\nFurther, we prove that text lemmatization can improve the performance of word\nembedding methods.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jun 2017 20:45:30 GMT"}, {"version": "v2", "created": "Fri, 9 Jun 2017 01:54:32 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Sugathadasa", "Keet", ""], ["Ayesha", "Buddhi", ""], ["de Silva", "Nisansa", ""], ["Perera", "Amal Shehan", ""], ["Jayawardana", "Vindula", ""], ["Lakmal", "Dimuthu", ""], ["Perera", "Madhavi", ""]]}, {"id": "1706.02027", "submitter": "Duyu Tang", "authors": "Duyu Tang, Nan Duan, Tao Qin, Zhao Yan and Ming Zhou", "title": "Question Answering and Question Generation as Dual Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of joint question answering (QA) and question generation\n(QG) in this paper.\n  Our intuition is that QA and QG have intrinsic connections and these two\ntasks could improve each other.\n  On one side, the QA model judges whether the generated question of a QG model\nis relevant to the answer.\n  On the other side, the QG model provides the probability of generating a\nquestion given the answer, which is a useful evidence that in turn facilitates\nQA.\n  In this paper we regard QA and QG as dual tasks.\n  We propose a training framework that trains the models of QA and QG\nsimultaneously, and explicitly leverages their probabilistic correlation to\nguide the training process of both models.\n  We implement a QG model based on sequence-to-sequence learning, and a QA\nmodel based on recurrent neural network.\n  As all the components of the QA and QG models are differentiable, all the\nparameters involved in these two models could be conventionally learned with\nback propagation.\n  We conduct experiments on three datasets. Empirical results show that our\ntraining framework improves both QA and QG tasks.\n  The improved QA model performs comparably with strong baseline approaches on\nall three datasets.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 02:06:58 GMT"}, {"version": "v2", "created": "Fri, 4 Aug 2017 07:25:53 GMT"}], "update_date": "2017-08-07", "authors_parsed": [["Tang", "Duyu", ""], ["Duan", "Nan", ""], ["Qin", "Tao", ""], ["Yan", "Zhao", ""], ["Zhou", "Ming", ""]]}, {"id": "1706.02095", "submitter": "Diego Molla-Aliod", "authors": "Diego Molla-Aliod", "title": "Macquarie University at BioASQ 5b -- Query-based Summarisation\n  Techniques for Selecting the Ideal Answers", "comments": "As published in BioNLP2017. 9 pages, 5 figures, 4 tables", "journal-ref": "Proceedings of the BioNLP 2017 Workshop (Vancouver, Canada), pages\n  67-75 (2017)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Macquarie University's contribution to the BioASQ challenge (Task 5b Phase B)\nfocused on the use of query-based extractive summarisation techniques for the\ngeneration of the ideal answers. Four runs were submitted, with approaches\nranging from a trivial system that selected the first $n$ snippets, to the use\nof deep learning approaches under a regression framework. Our experiments and\nthe ROUGE results of the five test batches of BioASQ indicate surprisingly good\nresults for the trivial approach. Overall, most of our runs on the first three\ntest batches achieved the best ROUGE-SU4 results in the challenge.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 09:04:29 GMT"}, {"version": "v2", "created": "Fri, 11 Aug 2017 07:11:19 GMT"}], "update_date": "2017-08-14", "authors_parsed": [["Molla-Aliod", "Diego", ""]]}, {"id": "1706.02124", "submitter": "Marian Tietz", "authors": "Marian Tietz, Tayfun Alpay, Johannes Twiefel, Stefan Wermter", "title": "Semi-Supervised Phoneme Recognition with Recurrent Ladder Networks", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-319-68600-4_1", "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ladder networks are a notable new concept in the field of semi-supervised\nlearning by showing state-of-the-art results in image recognition tasks while\nbeing compatible with many existing neural architectures. We present the\nrecurrent ladder network, a novel modification of the ladder network, for\nsemi-supervised learning of recurrent neural networks which we evaluate with a\nphoneme recognition task on the TIMIT corpus. Our results show that the model\nis able to consistently outperform the baseline and achieve fully-supervised\nbaseline performance with only 75% of all labels which demonstrates that the\nmodel is capable of using unsupervised data as an effective regulariser.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 10:50:47 GMT"}, {"version": "v2", "created": "Mon, 18 Sep 2017 18:49:26 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Tietz", "Marian", ""], ["Alpay", "Tayfun", ""], ["Twiefel", "Johannes", ""], ["Wermter", "Stefan", ""]]}, {"id": "1706.02141", "submitter": "Carlos G\\'omez-Rodr\\'iguez", "authors": "Carlos G\\'omez-Rodr\\'iguez, Iago Alonso-Alonso, David Vilares", "title": "How Important is Syntactic Parsing Accuracy? An Empirical Evaluation on\n  Rule-Based Sentiment Analysis", "comments": "19 pages. Accepted for publication in Artificial Intelligence Review.\n  This update only adds the DOI link to comply with journal's terms", "journal-ref": null, "doi": "10.1007/s10462-017-9584-0", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Syntactic parsing, the process of obtaining the internal structure of\nsentences in natural languages, is a crucial task for artificial intelligence\napplications that need to extract meaning from natural language text or speech.\nSentiment analysis is one example of application for which parsing has recently\nproven useful.\n  In recent years, there have been significant advances in the accuracy of\nparsing algorithms. In this article, we perform an empirical, task-oriented\nevaluation to determine how parsing accuracy influences the performance of a\nstate-of-the-art rule-based sentiment analysis system that determines the\npolarity of sentences from their parse trees. In particular, we evaluate the\nsystem using four well-known dependency parsers, including both current models\nwith state-of-the-art accuracy and more innacurate models which, however,\nrequire less computational resources.\n  The experiments show that all of the parsers produce similarly good results\nin the sentiment analysis task, without their accuracy having any relevant\ninfluence on the results. Since parsing is currently a task with a relatively\nhigh computational cost that varies strongly between algorithms, this suggests\nthat sentiment analysis researchers and users should prioritize speed over\naccuracy when choosing a parser; and parsing researchers should investigate\nmodels that improve speed further, even at some cost to accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 12:03:07 GMT"}, {"version": "v2", "created": "Mon, 2 Oct 2017 09:17:39 GMT"}, {"version": "v3", "created": "Tue, 24 Oct 2017 08:13:38 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["G\u00f3mez-Rodr\u00edguez", "Carlos", ""], ["Alonso-Alonso", "Iago", ""], ["Vilares", "David", ""]]}, {"id": "1706.02222", "submitter": "Andros Tjandra", "authors": "Andros Tjandra, Sakriani Sakti, Ruli Manurung, Mirna Adriani and\n  Satoshi Nakamura", "title": "Gated Recurrent Neural Tensor Network", "comments": "Accepted at IJCNN 2016 URL :\n  http://ieeexplore.ieee.org/document/7727233/", "journal-ref": null, "doi": "10.1109/IJCNN.2016.7727233", "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs), which are a powerful scheme for modeling\ntemporal and sequential data need to capture long-term dependencies on datasets\nand represent them in hidden layers with a powerful model to capture more\ninformation from inputs. For modeling long-term dependencies in a dataset, the\ngating mechanism concept can help RNNs remember and forget previous\ninformation. Representing the hidden layers of an RNN with more expressive\noperations (i.e., tensor products) helps it learn a more complex relationship\nbetween the current input and the previous hidden layer information. These\nideas can generally improve RNN performances. In this paper, we proposed a\nnovel RNN architecture that combine the concepts of gating mechanism and the\ntensor product into a single model. By combining these two concepts into a\nsingle RNN, our proposed models learn long-term dependencies by modeling with\ngating units and obtain more expressive and direct interaction between input\nand hidden layers using a tensor product on 3-dimensional array (tensor) weight\nparameters. We use Long Short Term Memory (LSTM) RNN and Gated Recurrent Unit\n(GRU) RNN and combine them with a tensor product inside their formulations. Our\nproposed RNNs, which are called a Long-Short Term Memory Recurrent Neural\nTensor Network (LSTMRNTN) and Gated Recurrent Unit Recurrent Neural Tensor\nNetwork (GRURNTN), are made by combining the LSTM and GRU RNN models with the\ntensor product. We conducted experiments with our proposed models on word-level\nand character-level language modeling tasks and revealed that our proposed\nmodels significantly improved their performance compared to our baseline\nmodels.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 15:05:39 GMT"}], "update_date": "2017-06-08", "authors_parsed": [["Tjandra", "Andros", ""], ["Sakti", "Sakriani", ""], ["Manurung", "Ruli", ""], ["Adriani", "Mirna", ""], ["Nakamura", "Satoshi", ""]]}, {"id": "1706.02241", "submitter": "Denis Newman-Griffis", "authors": "Denis Newman-Griffis, Albert M Lai, Eric Fosler-Lussier", "title": "Insights into Analogy Completion from the Biomedical Domain", "comments": "Accepted to BioNLP 2017. (10 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analogy completion has been a popular task in recent years for evaluating the\nsemantic properties of word embeddings, but the standard methodology makes a\nnumber of assumptions about analogies that do not always hold, either in recent\nbenchmark datasets or when expanding into other domains. Through an analysis of\nanalogies in the biomedical domain, we identify three assumptions: that of a\nSingle Answer for any given analogy, that the pairs involved describe the Same\nRelationship, and that each pair is Informative with respect to the other. We\npropose modifying the standard methodology to relax these assumptions by\nallowing for multiple correct answers, reporting MAP and MRR in addition to\naccuracy, and using multiple example pairs. We further present BMASS, a novel\ndataset for evaluating linguistic regularities in biomedical embeddings, and\ndemonstrate that the relationships described in the dataset pose significant\nsemantic challenges to current word embedding methods.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 16:24:32 GMT"}], "update_date": "2017-06-08", "authors_parsed": [["Newman-Griffis", "Denis", ""], ["Lai", "Albert M", ""], ["Fosler-Lussier", "Eric", ""]]}, {"id": "1706.02256", "submitter": "Ana Marasovi\\'c", "authors": "Ana Marasovi\\'c, Leo Born, Juri Opitz and Anette Frank", "title": "A Mention-Ranking Model for Abstract Anaphora Resolution", "comments": "In Proceedings of the 2017 Conference on Empirical Methods in Natural\n  Language Processing (EMNLP). Copenhagen, Denmark", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resolving abstract anaphora is an important, but difficult task for text\nunderstanding. Yet, with recent advances in representation learning this task\nbecomes a more tangible aim. A central property of abstract anaphora is that it\nestablishes a relation between the anaphor embedded in the anaphoric sentence\nand its (typically non-nominal) antecedent. We propose a mention-ranking model\nthat learns how abstract anaphors relate to their antecedents with an\nLSTM-Siamese Net. We overcome the lack of training data by generating\nartificial anaphoric sentence--antecedent pairs. Our model outperforms\nstate-of-the-art results on shell noun resolution. We also report first\nbenchmark results on an abstract anaphora subset of the ARRAU corpus. This\ncorpus presents a greater challenge due to a mixture of nominal and pronominal\nanaphors and a greater range of confounders. We found model variants that\noutperform the baselines for nominal anaphors, without training on individual\nanaphor data, but still lag behind for pronominal anaphors. Our model selects\nsyntactically plausible candidates and -- if disregarding syntax --\ndiscriminates candidates using deeper features.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 16:58:59 GMT"}, {"version": "v2", "created": "Fri, 21 Jul 2017 12:12:04 GMT"}], "update_date": "2017-07-24", "authors_parsed": [["Marasovi\u0107", "Ana", ""], ["Born", "Leo", ""], ["Opitz", "Juri", ""], ["Frank", "Anette", ""]]}, {"id": "1706.02427", "submitter": "Duyu Tang", "authors": "Zhao Yan and Duyu Tang and Nan Duan and Junwei Bao and Yuanhua Lv and\n  Ming Zhou and Zhoujun Li", "title": "Content-Based Table Retrieval for Web Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the connections between unstructured text and semi-structured\ntable is an important yet neglected problem in natural language processing. In\nthis work, we focus on content-based table retrieval. Given a query, the task\nis to find the most relevant table from a collection of tables. Further\nprogress towards improving this area requires powerful models of semantic\nmatching and richer training and evaluation resources. To remedy this, we\npresent a ranking based approach, and implement both carefully designed\nfeatures and neural network architectures to measure the relevance between a\nquery and the content of a table. Furthermore, we release an open-domain\ndataset that includes 21,113 web queries for 273,816 tables. We conduct\ncomprehensive experiments on both real world and synthetic datasets. Results\nverify the effectiveness of our approach and present the challenges for this\ntask.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 02:03:32 GMT"}], "update_date": "2017-06-09", "authors_parsed": [["Yan", "Zhao", ""], ["Tang", "Duyu", ""], ["Duan", "Nan", ""], ["Bao", "Junwei", ""], ["Lv", "Yuanhua", ""], ["Zhou", "Ming", ""], ["Li", "Zhoujun", ""]]}, {"id": "1706.02459", "submitter": "Shuming Ma", "authors": "Shuming Ma, Xu Sun, Jingjing Xu, Houfeng Wang, Wenjie Li, Qi Su", "title": "Improving Semantic Relevance for Sequence-to-Sequence Learning of\n  Chinese Social Media Text Summarization", "comments": "Accepted by ACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current Chinese social media text summarization models are based on an\nencoder-decoder framework. Although its generated summaries are similar to\nsource texts literally, they have low semantic relevance. In this work, our\ngoal is to improve semantic relevance between source texts and summaries for\nChinese social media summarization. We introduce a Semantic Relevance Based\nneural model to encourage high semantic similarity between texts and summaries.\nIn our model, the source text is represented by a gated attention encoder,\nwhile the summary representation is produced by a decoder. Besides, the\nsimilarity score between the representations is maximized during training. Our\nexperiments show that the proposed model outperforms baseline systems on a\nsocial media corpus.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 07:05:56 GMT"}], "update_date": "2017-06-09", "authors_parsed": [["Ma", "Shuming", ""], ["Sun", "Xu", ""], ["Xu", "Jingjing", ""], ["Wang", "Houfeng", ""], ["Li", "Wenjie", ""], ["Su", "Qi", ""]]}, {"id": "1706.02490", "submitter": "Matej Hoffmann", "authors": "Karla Stepanova and Matej Hoffmann and Zdenek Straka and Frederico B.\n  Klein and Angelo Cangelosi and Michal Vavrecka", "title": "Where is my forearm? Clustering of body parts from simultaneous tactile\n  and linguistic input using sequential mapping", "comments": "pp. 155-162", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CL cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans and animals are constantly exposed to a continuous stream of sensory\ninformation from different modalities. At the same time, they form more\ncompressed representations like concepts or symbols. In species that use\nlanguage, this process is further structured by this interaction, where a\nmapping between the sensorimotor concepts and linguistic elements needs to be\nestablished. There is evidence that children might be learning language by\nsimply disambiguating potential meanings based on multiple exposures to\nutterances in different contexts (cross-situational learning). In existing\nmodels, the mapping between modalities is usually found in a single step by\ndirectly using frequencies of referent and meaning co-occurrences. In this\npaper, we present an extension of this one-step mapping and introduce a newly\nproposed sequential mapping algorithm together with a publicly available Matlab\nimplementation. For demonstration, we have chosen a less typical scenario:\ninstead of learning to associate objects with their names, we focus on body\nrepresentations. A humanoid robot is receiving tactile stimulations on its\nbody, while at the same time listening to utterances of the body part names\n(e.g., hand, forearm and torso). With the goal at arriving at the correct \"body\ncategories\", we demonstrate how a sequential mapping algorithm outperforms\none-step mapping. In addition, the effect of data set size and noise in the\nlinguistic input are studied.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 09:31:42 GMT"}], "update_date": "2017-06-09", "authors_parsed": [["Stepanova", "Karla", ""], ["Hoffmann", "Matej", ""], ["Straka", "Zdenek", ""], ["Klein", "Frederico B.", ""], ["Cangelosi", "Angelo", ""], ["Vavrecka", "Michal", ""]]}, {"id": "1706.02496", "submitter": "Franziska Horn", "authors": "Franziska Horn", "title": "Context encoders as a simple but powerful extension of word2vec", "comments": "ACL 2017 2nd Workshop on Representation Learning for NLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With a simple architecture and the ability to learn meaningful word\nembeddings efficiently from texts containing billions of words, word2vec\nremains one of the most popular neural language models used today. However, as\nonly a single embedding is learned for every word in the vocabulary, the model\nfails to optimally represent words with multiple meanings. Additionally, it is\nnot possible to create embeddings for new (out-of-vocabulary) words on the\nspot. Based on an intuitive interpretation of the continuous bag-of-words\n(CBOW) word2vec model's negative sampling training objective in terms of\npredicting context based similarities, we motivate an extension of the model we\ncall context encoders (ConEc). By multiplying the matrix of trained word2vec\nembeddings with a word's average context vector, out-of-vocabulary (OOV)\nembeddings and representations for a word with multiple meanings can be created\nbased on the word's local contexts. The benefits of this approach are\nillustrated by using these word embeddings as features in the CoNLL 2003 named\nentity recognition (NER) task.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 09:56:11 GMT"}], "update_date": "2017-06-09", "authors_parsed": [["Horn", "Franziska", ""]]}, {"id": "1706.02551", "submitter": "Timur Sadykov", "authors": "T.M. Sadykov and T.A. Zhukov", "title": "The Algorithmic Inflection of Russian and Generation of Grammatically\n  Correct Text", "comments": "9 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deterministic algorithm for Russian inflection. This algorithm\nis implemented in a publicly available web-service www.passare.ru which\nprovides functions for inflection of single words, word matching and synthesis\nof grammatically correct Russian text. The inflectional functions have been\ntested against the annotated corpus of Russian language OpenCorpora.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 12:48:15 GMT"}], "update_date": "2017-06-09", "authors_parsed": [["Sadykov", "T. M.", ""], ["Zhukov", "T. A.", ""]]}, {"id": "1706.02596", "submitter": "Dirk Weissenborn", "authors": "Dirk Weissenborn, Tom\\'a\\v{s} Ko\\v{c}isk\\'y, Chris Dyer", "title": "Dynamic Integration of Background Knowledge in Neural NLU Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Common-sense and background knowledge is required to understand natural\nlanguage, but in most neural natural language understanding (NLU) systems, this\nknowledge must be acquired from training corpora during learning, and then it\nis static at test time. We introduce a new architecture for the dynamic\nintegration of explicit background knowledge in NLU models. A general-purpose\nreading module reads background knowledge in the form of free-text statements\n(together with task-specific text inputs) and yields refined word\nrepresentations to a task-specific NLU architecture that reprocesses the task\ninputs with these representations. Experiments on document question answering\n(DQA) and recognizing textual entailment (RTE) demonstrate the effectiveness\nand flexibility of the approach. Analysis shows that our model learns to\nexploit knowledge in a semantically appropriate way.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 14:10:22 GMT"}, {"version": "v2", "created": "Wed, 25 Oct 2017 14:54:53 GMT"}, {"version": "v3", "created": "Tue, 21 Aug 2018 08:57:43 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Weissenborn", "Dirk", ""], ["Ko\u010disk\u00fd", "Tom\u00e1\u0161", ""], ["Dyer", "Chris", ""]]}, {"id": "1706.02737", "submitter": "Takaaki Hori", "authors": "Takaaki Hori, Shinji Watanabe, Yu Zhang, William Chan", "title": "Advances in Joint CTC-Attention based End-to-End Speech Recognition with\n  a Deep CNN Encoder and RNN-LM", "comments": "Accepted for INTERSPEECH 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a state-of-the-art end-to-end Automatic Speech Recognition (ASR)\nmodel. We learn to listen and write characters with a joint Connectionist\nTemporal Classification (CTC) and attention-based encoder-decoder network. The\nencoder is a deep Convolutional Neural Network (CNN) based on the VGG network.\nThe CTC network sits on top of the encoder and is jointly trained with the\nattention-based decoder. During the beam search process, we combine the CTC\npredictions, the attention-based decoder predictions and a separately trained\nLSTM language model. We achieve a 5-10\\% error reduction compared to prior\nsystems on spontaneous Japanese and Chinese speech, and our end-to-end model\nbeats out traditional hybrid ASR systems.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 19:30:02 GMT"}], "update_date": "2017-06-12", "authors_parsed": [["Hori", "Takaaki", ""], ["Watanabe", "Shinji", ""], ["Zhang", "Yu", ""], ["Chan", "William", ""]]}, {"id": "1706.02757", "submitter": "Jekaterina Novikova Dr.", "authors": "Jekaterina Novikova, Christian Dondrup, Ioannis Papaioannou and Oliver\n  Lemon", "title": "Sympathy Begins with a Smile, Intelligence Begins with a Word: Use of\n  Multimodal Features in Spoken Human-Robot Interaction", "comments": "Robo-NLP workshop at ACL 2017. 9 pages, 5 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognition of social signals, from human facial expressions or prosody of\nspeech, is a popular research topic in human-robot interaction studies. There\nis also a long line of research in the spoken dialogue community that\ninvestigates user satisfaction in relation to dialogue characteristics.\nHowever, very little research relates a combination of multimodal social\nsignals and language features detected during spoken face-to-face human-robot\ninteraction to the resulting user perception of a robot. In this paper we show\nhow different emotional facial expressions of human users, in combination with\nprosodic characteristics of human speech and features of human-robot dialogue,\ncorrelate with users' impressions of the robot after a conversation. We find\nthat happiness in the user's recognised facial expression strongly correlates\nwith likeability of a robot, while dialogue-related features (such as number of\nhuman turns or number of sentences per robot utterance) correlate with\nperceiving a robot as intelligent. In addition, we show that facial expression,\nemotional features, and prosody are better predictors of human ratings related\nto perceived robot likeability and anthropomorphism, while linguistic and\nnon-linguistic features more often predict perceived robot intelligence and\ninterpretability. As such, these characteristics may in future be used as an\nonline reward signal for in-situ Reinforcement Learning based adaptive\nhuman-robot dialogue systems.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 20:33:00 GMT"}], "update_date": "2017-06-12", "authors_parsed": [["Novikova", "Jekaterina", ""], ["Dondrup", "Christian", ""], ["Papaioannou", "Ioannis", ""], ["Lemon", "Oliver", ""]]}, {"id": "1706.02776", "submitter": "Matt Shannon", "authors": "Matt Shannon", "title": "Optimizing expected word error rate via sampling for speech recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-level minimum Bayes risk (sMBR) training has become the de facto\nstandard for sequence-level training of speech recognition acoustic models. It\nhas an elegant formulation using the expectation semiring, and gives large\nimprovements in word error rate (WER) over models trained solely using\ncross-entropy (CE) or connectionist temporal classification (CTC). sMBR\ntraining optimizes the expected number of frames at which the reference and\nhypothesized acoustic states differ. It may be preferable to optimize the\nexpected WER, but WER does not interact well with the expectation semiring, and\nprevious approaches based on computing expected WER exactly involve expanding\nthe lattices used during training. In this paper we show how to perform\noptimization of the expected WER by sampling paths from the lattices used\nduring conventional sMBR training. The gradient of the expected WER is itself\nan expectation, and so may be approximated using Monte Carlo sampling. We show\nexperimentally that optimizing WER during acoustic model training gives 5%\nrelative improvement in WER over a well-tuned sMBR baseline on a 2-channel\nquery recognition task (Google Home).\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 21:14:48 GMT"}], "update_date": "2017-06-12", "authors_parsed": [["Shannon", "Matt", ""]]}, {"id": "1706.02807", "submitter": "Lifu Tu", "authors": "Lifu Tu, Kevin Gimpel, Karen Livescu", "title": "Learning to Embed Words in Context for Syntactic Tasks", "comments": "Accepted by ACL 2017 Repl4NLP workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present models for embedding words in the context of surrounding words.\nSuch models, which we refer to as token embeddings, represent the\ncharacteristics of a word that are specific to a given context, such as word\nsense, syntactic category, and semantic role. We explore simple, efficient\ntoken embedding models based on standard neural network architectures. We learn\ntoken embeddings on a large amount of unannotated text and evaluate them as\nfeatures for part-of-speech taggers and dependency parsers trained on much\nsmaller amounts of annotated data. We find that predictors endowed with token\nembeddings consistently outperform baseline predictors across a range of\ncontext window and training set sizes.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jun 2017 01:39:12 GMT"}, {"version": "v2", "created": "Mon, 12 Jun 2017 01:42:12 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Tu", "Lifu", ""], ["Gimpel", "Kevin", ""], ["Livescu", "Karen", ""]]}, {"id": "1706.02861", "submitter": "Qiao Qian", "authors": "Qiao Qian, Minlie Huang, Haizhou Zhao, Jingfang Xu, Xiaoyan Zhu", "title": "Assigning personality/identity to a chatting machine for coherent\n  conversation generation", "comments": "an error on author information", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Endowing a chatbot with personality or an identity is quite challenging but\ncritical to deliver more realistic and natural conversations. In this paper, we\naddress the issue of generating responses that are coherent to a pre-specified\nagent profile. We design a model consisting of three modules: a profile\ndetector to decide whether a post should be responded using the profile and\nwhich key should be addressed, a bidirectional decoder to generate responses\nforward and backward starting from a selected profile value, and a position\ndetector that predicts a word position from which decoding should start given a\nselected profile value. We show that general conversation data from social\nmedia can be used to generate profile-coherent responses. Manual and automatic\nevaluation shows that our model can deliver more coherent, natural, and\ndiversified responses.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jun 2017 08:13:21 GMT"}, {"version": "v2", "created": "Mon, 12 Jun 2017 06:17:45 GMT"}, {"version": "v3", "created": "Wed, 21 Jun 2017 07:40:57 GMT"}], "update_date": "2017-06-22", "authors_parsed": [["Qian", "Qiao", ""], ["Huang", "Minlie", ""], ["Zhao", "Haizhou", ""], ["Xu", "Jingfang", ""], ["Zhu", "Xiaoyan", ""]]}, {"id": "1706.02883", "submitter": "Jingjing Gong", "authors": "Xipeng Qiu, Jingjing Gong, Xuanjing Huang", "title": "Overview of the NLPCC 2017 Shared Task: Chinese News Headline\n  Categorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we give an overview for the shared task at the CCF Conference\non Natural Language Processing \\& Chinese Computing (NLPCC 2017): Chinese News\nHeadline Categorization. The dataset of this shared task consists 18 classes,\n12,000 short texts along with corresponded labels for each class. The dataset\nand example code can be accessed at\nhttps://github.com/FudanNLP/nlpcc2017_news_headline_categorization.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jun 2017 10:17:24 GMT"}], "update_date": "2017-06-12", "authors_parsed": [["Qiu", "Xipeng", ""], ["Gong", "Jingjing", ""], ["Huang", "Xuanjing", ""]]}, {"id": "1706.02901", "submitter": "Che-Wei Huang", "authors": "Che-Wei Huang, Shrikanth. S. Narayanan", "title": "Characterizing Types of Convolution in Deep Convolutional Recurrent\n  Neural Networks for Robust Speech Emotion Recognition", "comments": "Revised Submission to IEEE Transactions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.MM cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks are being actively investigated in a wide\nrange of speech and audio processing applications including speech recognition,\naudio event detection and computational paralinguistics, owing to their ability\nto reduce factors of variations, for learning from speech. However, studies\nhave suggested to favor a certain type of convolutional operations when\nbuilding a deep convolutional neural network for speech applications although\nthere has been promising results using different types of convolutional\noperations. In this work, we study four types of convolutional operations on\ndifferent input features for speech emotion recognition under noisy and clean\nconditions in order to derive a comprehensive understanding. Since affective\nbehavioral information has been shown to reflect temporally varying of mental\nstate and convolutional operation are applied locally in time, all deep neural\nnetworks share a deep recurrent sub-network architecture for further temporal\nmodeling. We present detailed quantitative module-wise performance analysis to\ngain insights into information flows within the proposed architectures. In\nparticular, we demonstrate the interplay of affective information and the other\nirrelevant information during the progression from one module to another.\nFinally we show that all of our deep neural networks provide state-of-the-art\nperformance on the eNTERFACE'05 corpus.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 15:17:21 GMT"}, {"version": "v2", "created": "Sat, 13 Jan 2018 19:38:21 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Huang", "Che-Wei", ""], ["Narayanan", "Shrikanth. S.", ""]]}, {"id": "1706.02909", "submitter": "Vindula Jayawardana Mr", "authors": "Vindula Jayawardana, Dimuthu Lakmal, Nisansa de Silva, Amal Shehan\n  Perera, Keet Sugathadasa, Buddhi Ayesha", "title": "Deriving a Representative Vector for Ontology Classes with Instance Word\n  Vector Embeddings", "comments": null, "journal-ref": null, "doi": "10.1109/INTECH.2017.8102426", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selecting a representative vector for a set of vectors is a very common\nrequirement in many algorithmic tasks. Traditionally, the mean or median vector\nis selected. Ontology classes are sets of homogeneous instance objects that can\nbe converted to a vector space by word vector embeddings. This study proposes a\nmethodology to derive a representative vector for ontology classes whose\ninstances were converted to the vector space. We start by deriving five\ncandidate vectors which are then used to train a machine learning model that\nwould calculate a representative vector for the class. We show that our\nmethodology out-performs the traditional mean and median vector\nrepresentations.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 03:01:37 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Jayawardana", "Vindula", ""], ["Lakmal", "Dimuthu", ""], ["de Silva", "Nisansa", ""], ["Perera", "Amal Shehan", ""], ["Sugathadasa", "Keet", ""], ["Ayesha", "Buddhi", ""]]}, {"id": "1706.03059", "submitter": "{\\L}ukasz Kaiser", "authors": "Lukasz Kaiser, Aidan N. Gomez, Francois Chollet", "title": "Depthwise Separable Convolutions for Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Depthwise separable convolutions reduce the number of parameters and\ncomputation used in convolutional operations while increasing representational\nefficiency. They have been shown to be successful in image classification\nmodels, both in obtaining better models than previously possible for a given\nparameter count (the Xception architecture) and considerably reducing the\nnumber of parameters required to perform at a given level (the MobileNets\nfamily of architectures). Recently, convolutional sequence-to-sequence networks\nhave been applied to machine translation tasks with good results. In this work,\nwe study how depthwise separable convolutions can be applied to neural machine\ntranslation. We introduce a new architecture inspired by Xception and ByteNet,\ncalled SliceNet, which enables a significant reduction of the parameter count\nand amount of computation needed to obtain results like ByteNet, and, with a\nsimilar parameter count, achieves new state-of-the-art results. In addition to\nshowing that depthwise separable convolutions perform well for machine\ntranslation, we investigate the architectural changes that they enable: we\nobserve that thanks to depthwise separability, we can increase the length of\nconvolution windows, removing the need for filter dilation. We also introduce a\nnew \"super-separable\" convolution operation that further reduces the number of\nparameters and computational cost for obtaining state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jun 2017 17:59:16 GMT"}, {"version": "v2", "created": "Fri, 16 Jun 2017 02:35:48 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["Kaiser", "Lukasz", ""], ["Gomez", "Aidan N.", ""], ["Chollet", "Francois", ""]]}, {"id": "1706.03146", "submitter": "Shuai Tang", "authors": "Shuai Tang, Hailin Jin, Chen Fang, Zhaowen Wang, Virginia R. de Sa", "title": "Rethinking Skip-thought: A Neighborhood based Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the skip-thought model with neighborhood information as weak\nsupervision. More specifically, we propose a skip-thought neighbor model to\nconsider the adjacent sentences as a neighborhood. We train our skip-thought\nneighbor model on a large corpus with continuous sentences, and then evaluate\nthe trained model on 7 tasks, which include semantic relatedness, paraphrase\ndetection, and classification benchmarks. Both quantitative comparison and\nqualitative investigation are conducted. We empirically show that, our\nskip-thought neighbor model performs as well as the skip-thought model on\nevaluation tasks. In addition, we found that, incorporating an autoencoder path\nin our model didn't aid our model to perform better, while it hurts the\nperformance of the skip-thought model.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jun 2017 22:39:31 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Tang", "Shuai", ""], ["Jin", "Hailin", ""], ["Fang", "Chen", ""], ["Wang", "Zhaowen", ""], ["de Sa", "Virginia R.", ""]]}, {"id": "1706.03148", "submitter": "Shuai Tang", "authors": "Shuai Tang, Hailin Jin, Chen Fang, Zhaowen Wang, Virginia R. de Sa", "title": "Trimming and Improving Skip-thought Vectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The skip-thought model has been proven to be effective at learning sentence\nrepresentations and capturing sentence semantics. In this paper, we propose a\nsuite of techniques to trim and improve it. First, we validate a hypothesis\nthat, given a current sentence, inferring the previous and inferring the next\nsentence provide similar supervision power, therefore only one decoder for\npredicting the next sentence is preserved in our trimmed skip-thought model.\nSecond, we present a connection layer between encoder and decoder to help the\nmodel to generalize better on semantic relatedness tasks. Third, we found that\na good word embedding initialization is also essential for learning better\nsentence representations. We train our model unsupervised on a large corpus\nwith contiguous sentences, and then evaluate the trained model on 7 supervised\ntasks, which includes semantic relatedness, paraphrase detection, and text\nclassification benchmarks. We empirically show that, our proposed model is a\nfaster, lighter-weight and equally powerful alternative to the original\nskip-thought model.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jun 2017 22:44:31 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Tang", "Shuai", ""], ["Jin", "Hailin", ""], ["Fang", "Chen", ""], ["Wang", "Zhaowen", ""], ["de Sa", "Virginia R.", ""]]}, {"id": "1706.03191", "submitter": "Shadi Diab", "authors": "Shadi Diab and Badie Sartawi", "title": "Classification of Questions and Learning Outcome Statements (LOS) Into\n  Blooms Taxonomy (BT) By Similarity Measurements Towards Extracting Of\n  Learning Outcome from Learning Material", "comments": "12 pages, 5 figures, 2 tables, Journal paper, typos added", "journal-ref": "International Journal of Managing Information Technology (IJMIT)\n  Vol.9, No.2, May 2017", "doi": "10.5121/ijmit.2017.9201", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Blooms Taxonomy (BT) have been used to classify the objectives of learning\noutcome by dividing the learning into three different domains; the cognitive\ndomain, the effective domain and the psychomotor domain. In this paper, we are\nintroducing a new approach to classify the questions and learning outcome\nstatements (LOS) into Blooms taxonomy (BT) and to verify BT verb lists, which\nare being cited and used by academicians to write questions and (LOS). An\nexperiment was designed to investigate the semantic relationship between the\naction verbs used in both questions and LOS to obtain more accurate\nclassification of the levels of BT. A sample of 775 different action verbs\ncollected from different universities allows us to measure an accurate and\nclear-cut cognitive level for the action verb. It is worth mentioning that\nnatural language processing techniques were used to develop our rules as to\ninduce the questions into chunks in order to extract the action verbs. Our\nproposed solution was able to classify the action verb into a precise level of\nthe cognitive domain. We, on our side, have tested and evaluated our proposed\nsolution using confusion matrix. The results of evaluation tests yielded 97%\nfor the macro average of precision and 90% for F1. Thus, the outcome of the\nresearch suggests that it is crucial to analyse and verify the action verbs\ncited and used by academicians to write LOS and classify their questions based\non blooms taxonomy in order to obtain a definite and more accurate\nclassification.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jun 2017 07:02:57 GMT"}, {"version": "v2", "created": "Sat, 23 Feb 2019 11:00:31 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Diab", "Shadi", ""], ["Sartawi", "Badie", ""]]}, {"id": "1706.03196", "submitter": "\\'Alvaro Peris", "authors": "\\'Alvaro Peris, Luis Cebri\\'an and Francisco Casacuberta", "title": "Online Learning for Neural Machine Translation Post-editing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation has meant a revolution of the field. Nevertheless,\npost-editing the outputs of the system is mandatory for tasks requiring high\ntranslation quality. Post-editing offers a unique opportunity for improving\nneural machine translation systems, using online learning techniques and\ntreating the post-edited translations as new, fresh training data. We review\nclassical learning methods and propose a new optimization algorithm. We\nthoroughly compare online learning algorithms in a post-editing scenario.\nResults show significant improvements in translation quality and effort\nreduction.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jun 2017 07:41:22 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Peris", "\u00c1lvaro", ""], ["Cebri\u00e1n", "Luis", ""], ["Casacuberta", "Francisco", ""]]}, {"id": "1706.03216", "submitter": "Johan Sjons", "authors": "Johan Sjons, Thomas H\\\"orberg, Robert \\\"Ostling, Johannes Bjerva", "title": "Articulation rate in Swedish child-directed speech increases as a\n  function of the age of the child even when surprisal is controlled for", "comments": "5 pages, Interspeech 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In earlier work, we have shown that articulation rate in Swedish\nchild-directed speech (CDS) increases as a function of the age of the child,\neven when utterance length and differences in articulation rate between\nsubjects are controlled for. In this paper we show on utterance level in\nspontaneous Swedish speech that i) for the youngest children, articulation rate\nin CDS is lower than in adult-directed speech (ADS), ii) there is a significant\nnegative correlation between articulation rate and surprisal (the negative log\nprobability) in ADS, and iii) the increase in articulation rate in Swedish CDS\nas a function of the age of the child holds, even when surprisal along with\nutterance length and differences in articulation rate between speakers are\ncontrolled for. These results indicate that adults adjust their articulation\nrate to make it fit the linguistic capacity of the child.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jun 2017 10:25:20 GMT"}, {"version": "v2", "created": "Fri, 24 Nov 2017 11:48:32 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Sjons", "Johan", ""], ["H\u00f6rberg", "Thomas", ""], ["\u00d6stling", "Robert", ""], ["Bjerva", "Johannes", ""]]}, {"id": "1706.03335", "submitter": "Amber Nigam", "authors": "Amber Nigam", "title": "Exploring Automated Essay Scoring for Nonnative English Speakers", "comments": "Accepted for publication at EUROPHRAS 2017", "journal-ref": null, "doi": "10.26615/978-2-9701095-2-5_004", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated Essay Scoring (AES) has been quite popular and is being widely\nused. However, lack of appropriate methodology for rating nonnative English\nspeakers' essays has meant a lopsided advancement in this field. In this paper,\nwe report initial results of our experiments with nonnative AES that learns\nfrom manual evaluation of nonnative essays. For this purpose, we conducted an\nexercise in which essays written by nonnative English speakers in test\nenvironment were rated both manually and by the automated system designed for\nthe experiment. In the process, we experimented with a few features to learn\nabout nuances linked to nonnative evaluation. The proposed methodology of\nautomated essay evaluation has yielded a correlation coefficient of 0.750 with\nthe manual evaluation.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jun 2017 10:18:46 GMT"}, {"version": "v2", "created": "Wed, 14 Jun 2017 09:52:35 GMT"}, {"version": "v3", "created": "Fri, 29 Sep 2017 07:08:50 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Nigam", "Amber", ""]]}, {"id": "1706.03357", "submitter": "Carlos G\\'omez-Rodr\\'iguez", "authors": "Anssi Yli-Jyr\\\"a, Carlos G\\'omez-Rodr\\'iguez", "title": "Generic Axiomatization of Families of Noncrossing Graphs in Dependency\n  Parsing", "comments": "11 pages. Accepted for publication at ACL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple encoding for unlabeled noncrossing graphs and show how\nits latent counterpart helps us to represent several families of directed and\nundirected graphs used in syntactic and semantic parsing of natural language as\ncontext-free languages. The families are separated purely on the basis of\nforbidden patterns in latent encoding, eliminating the need to differentiate\nthe families of non-crossing graphs in inference algorithms: one algorithm\nworks for all when the search space can be controlled in parser input.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jun 2017 14:37:22 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Yli-Jyr\u00e4", "Anssi", ""], ["G\u00f3mez-Rodr\u00edguez", "Carlos", ""]]}, {"id": "1706.03367", "submitter": "Carlos G\\'omez-Rodr\\'iguez", "authors": "Daniel Fern\\'andez-Gonz\\'alez, Carlos G\\'omez-Rodr\\'iguez", "title": "A Full Non-Monotonic Transition System for Unrestricted Non-Projective\n  Parsing", "comments": "11 pages. Accepted for publication at ACL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Restricted non-monotonicity has been shown beneficial for the projective\narc-eager dependency parser in previous research, as posterior decisions can\nrepair mistakes made in previous states due to the lack of information. In this\npaper, we propose a novel, fully non-monotonic transition system based on the\nnon-projective Covington algorithm. As a non-monotonic system requires\nexploration of erroneous actions during the training process, we develop\nseveral non-monotonic variants of the recently defined dynamic oracle for the\nCovington parser, based on tight approximations of the loss. Experiments on\ndatasets from the CoNLL-X and CoNLL-XI shared tasks show that a non-monotonic\ndynamic oracle outperforms the monotonic version in the majority of languages.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jun 2017 16:04:42 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Fern\u00e1ndez-Gonz\u00e1lez", "Daniel", ""], ["G\u00f3mez-Rodr\u00edguez", "Carlos", ""]]}, {"id": "1706.03441", "submitter": "Vinodkumar Prabhakaran", "authors": "Vinodkumar Prabhakaran, Owen Rambow", "title": "Dialog Structure Through the Lens of Gender, Gender Environment, and\n  Power", "comments": null, "journal-ref": "Journal for Dialogue & Discourse 8(2) (2017) 21-55", "doi": "10.5087/dad.2017.202", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding how the social context of an interaction affects our dialog\nbehavior is of great interest to social scientists who study human behavior, as\nwell as to computer scientists who build automatic methods to infer those\nsocial contexts. In this paper, we study the interaction of power, gender, and\ndialog behavior in organizational interactions. In order to perform this study,\nwe first construct the Gender Identified Enron Corpus of emails, in which we\nsemi-automatically assign the gender of around 23,000 individuals who authored\naround 97,000 email messages in the Enron corpus. This corpus, which is made\nfreely available, is orders of magnitude larger than previously existing gender\nidentified corpora in the email domain. Next, we use this corpus to perform a\nlarge-scale data-oriented study of the interplay of gender and manifestations\nof power. We argue that, in addition to one's own gender, the \"gender\nenvironment\" of an interaction, i.e., the gender makeup of one's interlocutors,\nalso affects the way power is manifested in dialog. We focus especially on\nmanifestations of power in the dialog structure --- both, in a shallow sense\nthat disregards the textual content of messages (e.g., how often do the\nparticipants contribute, how often do they get replies etc.), as well as the\nstructure that is expressed within the textual content (e.g., who issues\nrequests and how are they made, whose requests get responses etc.). We find\nthat both gender and gender environment affect the ways power is manifested in\ndialog, resulting in patterns that reveal the underlying factors. Finally, we\nshow the utility of gender information in the problem of automatically\npredicting the direction of power between pairs of participants in email\ninteractions.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 02:24:33 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Prabhakaran", "Vinodkumar", ""], ["Rambow", "Owen", ""]]}, {"id": "1706.03449", "submitter": "Arman Cohan", "authors": "Arman Cohan, Nazli Goharian", "title": "Scientific document summarization via citation contextualization and\n  scientific discourse", "comments": "Preprint. The final publication is available at Springer via\n  http://dx.doi.org/10.1007/s00799-017-0216-8, International Journal on Digital\n  Libraries (IJDL) 2017", "journal-ref": null, "doi": "10.1007/s00799-017-0216-8", "report-no": null, "categories": "cs.CL cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid growth of scientific literature has made it difficult for the\nresearchers to quickly learn about the developments in their respective fields.\nScientific document summarization addresses this challenge by providing\nsummaries of the important contributions of scientific papers. We present a\nframework for scientific summarization which takes advantage of the citations\nand the scientific discourse structure. Citation texts often lack the evidence\nand context to support the content of the cited paper and are even sometimes\ninaccurate. We first address the problem of inaccuracy of the citation texts by\nfinding the relevant context from the cited paper. We propose three approaches\nfor contextualizing citations which are based on query reformulation, word\nembeddings, and supervised learning. We then train a model to identify the\ndiscourse facets for each citation. We finally propose a method for summarizing\nscientific papers by leveraging the faceted citations and their corresponding\ncontexts. We evaluate our proposed method on two scientific summarization\ndatasets in the biomedical and computational linguistics domains. Extensive\nevaluation results show that our methods can improve over the state of the art\nby large margins.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 03:21:38 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Cohan", "Arman", ""], ["Goharian", "Nazli", ""]]}, {"id": "1706.03499", "submitter": "Johannes Bjerva", "authors": "Robert \\\"Ostling and Johannes Bjerva", "title": "SU-RUG at the CoNLL-SIGMORPHON 2017 shared task: Morphological\n  Inflection with Attentional Sequence-to-Sequence Models", "comments": "4 pages, to appear at CoNLL-SIGMORPHON 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes the Stockholm University/University of Groningen\n(SU-RUG) system for the SIGMORPHON 2017 shared task on morphological\ninflection. Our system is based on an attentional sequence-to-sequence neural\nnetwork model using Long Short-Term Memory (LSTM) cells, with joint training of\nmorphological inflection and the inverse transformation, i.e. lemmatization and\nmorphological analysis. Our system outperforms the baseline with a large\nmargin, and our submission ranks as the 4th best team for the track we\nparticipate in (task 1, high-resource).\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 08:08:00 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["\u00d6stling", "Robert", ""], ["Bjerva", "Johannes", ""]]}, {"id": "1706.03530", "submitter": "Ildik\\'o Pil\\'an", "authors": "Ildik\\'o Pil\\'an and Elena Volodina and Lars Borin", "title": "Candidate sentence selection for language learning exercises: from a\n  comprehensive framework to an empirical evaluation", "comments": "To appear in Traitement Automatique des Langues (TAL) Journal,\n  Special issue on NLP for Learning and Teaching", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework and its implementation relying on Natural Language\nProcessing methods, which aims at the identification of exercise item\ncandidates from corpora. The hybrid system combining heuristics and machine\nlearning methods includes a number of relevant selection criteria. We focus on\ntwo fundamental aspects: linguistic complexity and the dependence of the\nextracted sentences on their original context. Previous work on exercise\ngeneration addressed these two criteria only to a limited extent, and a refined\noverall candidate sentence selection framework appears also to be lacking. In\naddition to a detailed description of the system, we present the results of an\nempirical evaluation conducted with language teachers and learners which\nindicate the usefulness of the system for educational purposes. We have\nintegrated our system into a freely available online learning platform.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 09:21:45 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Pil\u00e1n", "Ildik\u00f3", ""], ["Volodina", "Elena", ""], ["Borin", "Lars", ""]]}, {"id": "1706.03542", "submitter": "Tal Linzen", "authors": "Emile Enguehard, Yoav Goldberg and Tal Linzen", "title": "Exploring the Syntactic Abilities of RNNs with Multi-task Learning", "comments": "To appear in CoNLL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has explored the syntactic abilities of RNNs using the\nsubject-verb agreement task, which diagnoses sensitivity to sentence structure.\nRNNs performed this task well in common cases, but faltered in complex\nsentences (Linzen et al., 2016). We test whether these errors are due to\ninherent limitations of the architecture or to the relatively indirect\nsupervision provided by most agreement dependencies in a corpus. We trained a\nsingle RNN to perform both the agreement task and an additional task, either\nCCG supertagging or language modeling. Multi-task training led to significantly\nlower error rates, in particular on complex sentences, suggesting that RNNs\nhave the ability to evolve more sophisticated syntactic representations than\nshown before. We also show that easily available agreement training data can\nimprove performance on other syntactic tasks, in particular when only a limited\namount of training data is available for those tasks. The multi-task paradigm\ncan also be leveraged to inject grammatical knowledge into language models.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 10:00:47 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Enguehard", "Emile", ""], ["Goldberg", "Yoav", ""], ["Linzen", "Tal", ""]]}, {"id": "1706.03610", "submitter": "Georg Wiese", "authors": "Georg Wiese, Dirk Weissenborn, Mariana Neves", "title": "Neural Domain Adaptation for Biomedical Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Factoid question answering (QA) has recently benefited from the development\nof deep learning (DL) systems. Neural network models outperform traditional\napproaches in domains where large datasets exist, such as SQuAD (ca. 100,000\nquestions) for Wikipedia articles. However, these systems have not yet been\napplied to QA in more specific domains, such as biomedicine, because datasets\nare generally too small to train a DL system from scratch. For example, the\nBioASQ dataset for biomedical QA comprises less then 900 factoid (single\nanswer) and list (multiple answers) QA instances. In this work, we adapt a\nneural QA system trained on a large open-domain dataset (SQuAD, source) to a\nbiomedical dataset (BioASQ, target) by employing various transfer learning\ntechniques. Our network architecture is based on a state-of-the-art QA system,\nextended with biomedical word embeddings and a novel mechanism to answer list\nquestions. In contrast to existing biomedical QA systems, our system does not\nrely on domain-specific ontologies, parsers or entity taggers, which are\nexpensive to create. Despite this fact, our systems achieve state-of-the-art\nresults on factoid questions and competitive results on list questions.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 13:08:21 GMT"}, {"version": "v2", "created": "Thu, 15 Jun 2017 15:16:18 GMT"}], "update_date": "2017-06-16", "authors_parsed": [["Wiese", "Georg", ""], ["Weissenborn", "Dirk", ""], ["Neves", "Mariana", ""]]}, {"id": "1706.03747", "submitter": "Xiaohui Zhang", "authors": "Xiaohui Zhang, Vimal Manohar, Daniel Povey, Sanjeev Khudanpur", "title": "Acoustic data-driven lexicon learning based on a greedy pronunciation\n  selection framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech recognition systems for irregularly-spelled languages like English\nnormally require hand-written pronunciations. In this paper, we describe a\nsystem for automatically obtaining pronunciations of words for which\npronunciations are not available, but for which transcribed data exists. Our\nmethod integrates information from the letter sequence and from the acoustic\nevidence. The novel aspect of the problem that we address is the problem of how\nto prune entries from such a lexicon (since, empirically, lexicons with too\nmany entries do not tend to be good for ASR performance). Experiments on\nvarious ASR tasks show that, with the proposed framework, starting with an\ninitial lexicon of several thousand words, we are able to learn a lexicon which\nperforms close to a full expert lexicon in terms of WER performance on test\ndata, and is better than lexicons built using G2P alone or with a pruning\ncriterion based on pronunciation probability.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 17:35:41 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Zhang", "Xiaohui", ""], ["Manohar", "Vimal", ""], ["Povey", "Daniel", ""], ["Khudanpur", "Sanjeev", ""]]}, {"id": "1706.03757", "submitter": "Christophe Van Gysel", "authors": "Christophe Van Gysel, Maarten de Rijke, Evangelos Kanoulas", "title": "Semantic Entity Retrieval Toolkit", "comments": "SIGIR 2017 Workshop on Neural Information Retrieval (Neu-IR'17). 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised learning of low-dimensional, semantic representations of words\nand entities has recently gained attention. In this paper we describe the\nSemantic Entity Retrieval Toolkit (SERT) that provides implementations of our\npreviously published entity representation models. The toolkit provides a\nunified interface to different representation learning algorithms, fine-grained\nparsing configuration and can be used transparently with GPUs. In addition,\nusers can easily modify existing models or implement their own models in the\nframework. After model training, SERT can be used to rank entities according to\na textual query and extract the learned entity/word representation for use in\ndownstream algorithms, such as clustering or recommendation.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 17:51:05 GMT"}, {"version": "v2", "created": "Mon, 17 Jul 2017 14:30:49 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Van Gysel", "Christophe", ""], ["de Rijke", "Maarten", ""], ["Kanoulas", "Evangelos", ""]]}, {"id": "1706.03762", "submitter": "Ashish Vaswani", "authors": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion\n  Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin", "title": "Attention Is All You Need", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dominant sequence transduction models are based on complex recurrent or\nconvolutional neural networks in an encoder-decoder configuration. The best\nperforming models also connect the encoder and decoder through an attention\nmechanism. We propose a new simple network architecture, the Transformer, based\nsolely on attention mechanisms, dispensing with recurrence and convolutions\nentirely. Experiments on two machine translation tasks show these models to be\nsuperior in quality while being more parallelizable and requiring significantly\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\nEnglish-to-German translation task, improving over the existing best results,\nincluding ensembles by over 2 BLEU. On the WMT 2014 English-to-French\ntranslation task, our model establishes a new single-model state-of-the-art\nBLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction\nof the training costs of the best models from the literature. We show that the\nTransformer generalizes well to other tasks by applying it successfully to\nEnglish constituency parsing both with large and limited training data.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 17:57:34 GMT"}, {"version": "v2", "created": "Mon, 19 Jun 2017 16:49:45 GMT"}, {"version": "v3", "created": "Tue, 20 Jun 2017 05:20:02 GMT"}, {"version": "v4", "created": "Fri, 30 Jun 2017 17:29:30 GMT"}, {"version": "v5", "created": "Wed, 6 Dec 2017 03:30:32 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Vaswani", "Ashish", ""], ["Shazeer", "Noam", ""], ["Parmar", "Niki", ""], ["Uszkoreit", "Jakob", ""], ["Jones", "Llion", ""], ["Gomez", "Aidan N.", ""], ["Kaiser", "Lukasz", ""], ["Polosukhin", "Illia", ""]]}, {"id": "1706.03799", "submitter": "Maxwell Forbes", "authors": "Maxwell Forbes, Yejin Choi", "title": "Verb Physics: Relative Physical Knowledge of Actions and Objects", "comments": "11 pages, published in Proceedings of ACL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning commonsense knowledge from natural language text is nontrivial due\nto reporting bias: people rarely state the obvious, e.g., \"My house is bigger\nthan me.\" However, while rarely stated explicitly, this trivial everyday\nknowledge does influence the way people talk about the world, which provides\nindirect clues to reason about the world. For example, a statement like, \"Tyler\nentered his house\" implies that his house is bigger than Tyler.\n  In this paper, we present an approach to infer relative physical knowledge of\nactions and objects along five dimensions (e.g., size, weight, and strength)\nfrom unstructured natural language text. We frame knowledge acquisition as\njoint inference over two closely related problems: learning (1) relative\nphysical knowledge of object pairs and (2) physical implications of actions\nwhen applied to those object pairs. Empirical results demonstrate that it is\npossible to extract knowledge of actions and objects from language and that\njoint inference over different types of knowledge improves performance.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 18:24:25 GMT"}, {"version": "v2", "created": "Thu, 13 Jul 2017 02:19:45 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Forbes", "Maxwell", ""], ["Choi", "Yejin", ""]]}, {"id": "1706.03815", "submitter": "Grzegorz Chrupa{\\l}a", "authors": "Afra Alishahi, Marie Barking, Grzegorz Chrupa{\\l}a", "title": "Encoding of phonology in a recurrent neural model of grounded speech", "comments": "Accepted at CoNLL 2017", "journal-ref": null, "doi": "10.18653/v1/K17-1037", "report-no": null, "categories": "cs.CL cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the representation and encoding of phonemes in a recurrent neural\nnetwork model of grounded speech. We use a model which processes images and\ntheir spoken descriptions, and projects the visual and auditory representations\ninto the same semantic space. We perform a number of analyses on how\ninformation about individual phonemes is encoded in the MFCC features extracted\nfrom the speech signal, and the activations of the layers of the model. Via\nexperiments with phoneme decoding and phoneme discrimination we show that\nphoneme representations are most salient in the lower layers of the model,\nwhere low-level signals are processed at a fine-grained level, although a large\namount of phonological information is retain at the top recurrent layer. We\nfurther find out that the attention mechanism following the top recurrent layer\nsignificantly attenuates encoding of phonology and makes the utterance\nembeddings much more invariant to synonymy. Moreover, a hierarchical clustering\nof phoneme representations learned by the network shows an organizational\nstructure of phonemes similar to those proposed in linguistics.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 19:07:02 GMT"}, {"version": "v2", "created": "Fri, 16 Jun 2017 08:35:44 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Alishahi", "Afra", ""], ["Barking", "Marie", ""], ["Chrupa\u0142a", "Grzegorz", ""]]}, {"id": "1706.03818", "submitter": "Shane Settle", "authors": "Shane Settle, Keith Levin, Herman Kamper, Karen Livescu", "title": "Query-by-Example Search with Discriminative Neural Acoustic Word\n  Embeddings", "comments": "To appear Interspeech 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Query-by-example search often uses dynamic time warping (DTW) for comparing\nqueries and proposed matching segments. Recent work has shown that comparing\nspeech segments by representing them as fixed-dimensional vectors --- acoustic\nword embeddings --- and measuring their vector distance (e.g., cosine distance)\ncan discriminate between words more accurately than DTW-based approaches. We\nconsider an approach to query-by-example search that embeds both the query and\ndatabase segments according to a neural model, followed by nearest-neighbor\nsearch to find the matching segments. Earlier work on embedding-based\nquery-by-example, using template-based acoustic word embeddings, achieved\ncompetitive performance. We find that our embeddings, based on recurrent neural\nnetworks trained to optimize word discrimination, achieve substantial\nimprovements in performance and run-time efficiency over the previous\napproaches.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 19:30:57 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Settle", "Shane", ""], ["Levin", "Keith", ""], ["Kamper", "Herman", ""], ["Livescu", "Karen", ""]]}, {"id": "1706.03824", "submitter": "Baskaran Sankaran", "authors": "Baskaran Sankaran, Markus Freitag and Yaser Al-Onaizan", "title": "Attention-based Vocabulary Selection for NMT Decoding", "comments": "Submitted to Second Conference on Machine Translation (WMT-17); 7\n  pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) models usually use large target vocabulary\nsizes to capture most of the words in the target language. The vocabulary size\nis a big factor when decoding new sentences as the final softmax layer\nnormalizes over all possible target words. To address this problem, it is\nwidely common to restrict the target vocabulary with candidate lists based on\nthe source sentence. Usually, the candidate lists are a combination of external\nword-to-word aligner, phrase table entries or most frequent words. In this\nwork, we propose a simple and yet novel approach to learn candidate lists\ndirectly from the attention layer during NMT training. The candidate lists are\nhighly optimized for the current NMT model and do not need any external\ncomputation of the candidate pool. We show significant decoding speedup\ncompared with using the entire vocabulary, without losing any translation\nquality for two language pairs.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 19:51:00 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Sankaran", "Baskaran", ""], ["Freitag", "Markus", ""], ["Al-Onaizan", "Yaser", ""]]}, {"id": "1706.03850", "submitter": "Yizhe Zhang", "authors": "Yizhe Zhang, Zhe Gan, Kai Fan, Zhi Chen, Ricardo Henao, Dinghan Shen,\n  Lawrence Carin", "title": "Adversarial Feature Matching for Text Generation", "comments": "Accepted by ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Generative Adversarial Network (GAN) has achieved great success in\ngenerating realistic (real-valued) synthetic data. However, convergence issues\nand difficulties dealing with discrete data hinder the applicability of GAN to\ntext. We propose a framework for generating realistic text via adversarial\ntraining. We employ a long short-term memory network as generator, and a\nconvolutional network as discriminator. Instead of using the standard objective\nof GAN, we propose matching the high-dimensional latent feature distributions\nof real and synthetic sentences, via a kernelized discrepancy metric. This\neases adversarial training by alleviating the mode-collapsing problem. Our\nexperiments show superior performance in quantitative evaluation, and\ndemonstrate that our model can generate realistic-looking sentences.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 20:55:51 GMT"}, {"version": "v2", "created": "Sat, 29 Jul 2017 05:50:13 GMT"}, {"version": "v3", "created": "Sat, 18 Nov 2017 18:40:04 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Zhang", "Yizhe", ""], ["Gan", "Zhe", ""], ["Fan", "Kai", ""], ["Chen", "Zhi", ""], ["Henao", "Ricardo", ""], ["Shen", "Dinghan", ""], ["Carin", "Lawrence", ""]]}, {"id": "1706.03872", "submitter": "Philipp Koehn", "authors": "Philipp Koehn and Rebecca Knowles", "title": "Six Challenges for Neural Machine Translation", "comments": "12 pages; First Workshop on Neural Machine Translation, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore six challenges for neural machine translation: domain mismatch,\namount of training data, rare words, long sentences, word alignment, and beam\nsearch. We show both deficiencies and improvements over the quality of\nphrase-based statistical machine translation.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 23:57:48 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Koehn", "Philipp", ""], ["Knowles", "Rebecca", ""]]}, {"id": "1706.03946", "submitter": "Isabelle Augenstein", "authors": "Ed Collins and Isabelle Augenstein and Sebastian Riedel", "title": "A Supervised Approach to Extractive Summarisation of Scientific Papers", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic summarisation is a popular approach to reduce a document to its\nmain arguments. Recent research in the area has focused on neural approaches to\nsummarisation, which can be very data-hungry. However, few large datasets exist\nand none for the traditionally popular domain of scientific publications, which\nopens up challenging research avenues centered on encoding large, complex\ndocuments. In this paper, we introduce a new dataset for summarisation of\ncomputer science publications by exploiting a large resource of author provided\nsummaries and show straightforward ways of extending it further. We develop\nmodels on the dataset making use of both neural sentence encoding and\ntraditionally used summarisation features and show that models which encode\nsentences as well as their local and global context perform best, significantly\noutperforming well-established baseline methods.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 08:15:25 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Collins", "Ed", ""], ["Augenstein", "Isabelle", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1706.03952", "submitter": "Charalambos Themistocleous", "authors": "Jean-Philippe Bernardy and Charalambos Themistocleous", "title": "Modelling prosodic structure using Artificial Neural Networks", "comments": "4 pages, 3 figures, Experimental linguistics 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to accurately perceive whether a speaker is asking a question or\nis making a statement is crucial for any successful interaction. However,\nlearning and classifying tonal patterns has been a challenging task for\nautomatic speech recognition and for models of tonal representation, as tonal\ncontours are characterized by significant variation. This paper provides a\nclassification model of Cypriot Greek questions and statements. We evaluate two\nstate-of-the-art network architectures: a Long Short-Term Memory (LSTM) network\nand a convolutional network (ConvNet). The ConvNet outperforms the LSTM in the\nclassification task and exhibited an excellent performance with 95%\nclassification accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 08:28:39 GMT"}, {"version": "v2", "created": "Thu, 15 Jun 2017 12:49:57 GMT"}], "update_date": "2017-06-16", "authors_parsed": [["Bernardy", "Jean-Philippe", ""], ["Themistocleous", "Charalambos", ""]]}, {"id": "1706.04115", "submitter": "Omer Levy", "authors": "Omer Levy, Minjoon Seo, Eunsol Choi, Luke Zettlemoyer", "title": "Zero-Shot Relation Extraction via Reading Comprehension", "comments": "CoNLL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that relation extraction can be reduced to answering simple reading\ncomprehension questions, by associating one or more natural-language questions\nwith each relation slot. This reduction has several advantages: we can (1)\nlearn relation-extraction models by extending recent neural\nreading-comprehension techniques, (2) build very large training sets for those\nmodels by combining relation-specific crowd-sourced questions with distant\nsupervision, and even (3) do zero-shot learning by extracting new relation\ntypes that are only specified at test-time, for which we have no labeled\ntraining examples. Experiments on a Wikipedia slot-filling task demonstrate\nthat the approach can generalize to new questions for known relation types with\nhigh accuracy, and that zero-shot generalization to unseen relation types is\npossible, at lower accuracy levels, setting the bar for future work on this\ntask.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 15:17:42 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Levy", "Omer", ""], ["Seo", "Minjoon", ""], ["Choi", "Eunsol", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1706.04138", "submitter": "Marcin Junczys-Dowmunt", "authors": "Marcin Junczys-Dowmunt and Roman Grundkiewicz", "title": "An Exploration of Neural Sequence-to-Sequence Architectures for\n  Automatic Post-Editing", "comments": "Accepted for presentation at IJCNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we explore multiple neural architectures adapted for the task\nof automatic post-editing of machine translation output. We focus on neural\nend-to-end models that combine both inputs $mt$ (raw MT output) and $src$\n(source language input) in a single neural architecture, modeling $\\{mt, src\\}\n\\rightarrow pe$ directly. Apart from that, we investigate the influence of\nhard-attention models which seem to be well-suited for monolingual tasks, as\nwell as combinations of both ideas. We report results on data sets provided\nduring the WMT-2016 shared task on automatic post-editing and can demonstrate\nthat dual-attention models that incorporate all available data in the APE\nscenario in a single model improve on the best shared task system and on all\nother published results after the shared task. Dual-attention models that are\ncombined with hard attention remain competitive despite applying fewer changes\nto the input.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 15:55:02 GMT"}, {"version": "v2", "created": "Sat, 30 Sep 2017 13:03:33 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Junczys-Dowmunt", "Marcin", ""], ["Grundkiewicz", "Roman", ""]]}, {"id": "1706.04206", "submitter": "Hossein Hematialam", "authors": "Hossein Hematialam, Wlodek Zadrozny", "title": "Identifying Condition-Action Statements in Medical Guidelines Using\n  Domain-Independent Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper advances the state of the art in text understanding of medical\nguidelines by releasing two new annotated clinical guidelines datasets, and\nestablishing baselines for using machine learning to extract condition-action\npairs. In contrast to prior work that relies on manually created rules, we\nreport experiment with several supervised machine learning techniques to\nclassify sentences as to whether they express conditions and actions. We show\nthe limitations and possible extensions of this work on text mining of medical\nguidelines.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 18:02:27 GMT"}, {"version": "v2", "created": "Wed, 21 Jun 2017 18:35:26 GMT"}], "update_date": "2017-06-23", "authors_parsed": [["Hematialam", "Hossein", ""], ["Zadrozny", "Wlodek", ""]]}, {"id": "1706.04223", "submitter": "Junbo Zhao", "authors": "Jake Zhao (Junbo), Yoon Kim, Kelly Zhang, Alexander M. Rush and Yann\n  LeCun", "title": "Adversarially Regularized Autoencoders", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep latent variable models, trained using variational autoencoders or\ngenerative adversarial networks, are now a key technique for representation\nlearning of continuous structures. However, applying similar methods to\ndiscrete structures, such as text sequences or discretized images, has proven\nto be more challenging. In this work, we propose a flexible method for training\ndeep latent variable models of discrete structures. Our approach is based on\nthe recently-proposed Wasserstein autoencoder (WAE) which formalizes the\nadversarial autoencoder (AAE) as an optimal transport problem. We first extend\nthis framework to model discrete sequences, and then further explore different\nlearned priors targeting a controllable representation. This adversarially\nregularized autoencoder (ARAE) allows us to generate natural textual outputs as\nwell as perform manipulations in the latent space to induce change in the\noutput space. Finally we show that the latent representation can be trained to\nperform unaligned textual style transfer, giving improvements both in\nautomatic/human evaluation compared to existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 19:00:53 GMT"}, {"version": "v2", "created": "Wed, 15 Nov 2017 05:41:04 GMT"}, {"version": "v3", "created": "Fri, 29 Jun 2018 00:07:16 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Zhao", "Jake", "", "Junbo"], ["Kim", "Yoon", ""], ["Zhang", "Kelly", ""], ["Rush", "Alexander M.", ""], ["LeCun", "Yann", ""]]}, {"id": "1706.04326", "submitter": "Lambert Mathias", "authors": "Xing Fan, Emilio Monti, Lambert Mathias, Markus Dreyer", "title": "Transfer Learning for Neural Semantic Parsing", "comments": "Accepted for ACL Repl4NLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of semantic parsing is to map natural language to a machine\ninterpretable meaning representation language (MRL). One of the constraints\nthat limits full exploration of deep learning technologies for semantic parsing\nis the lack of sufficient annotation training data. In this paper, we propose\nusing sequence-to-sequence in a multi-task setup for semantic parsing with a\nfocus on transfer learning. We explore three multi-task architectures for\nsequence-to-sequence modeling and compare their performance with an\nindependently trained model. Our experiments show that the multi-task setup\naids transfer learning from an auxiliary task with large labeled data to a\ntarget task with smaller labeled data. We see absolute accuracy gains ranging\nfrom 1.0% to 4.4% in our in- house data set, and we also see good gains ranging\nfrom 2.5% to 7.0% on the ATIS semantic parsing tasks with syntactic and\nsemantic auxiliary tasks.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jun 2017 05:53:51 GMT"}], "update_date": "2017-06-15", "authors_parsed": [["Fan", "Xing", ""], ["Monti", "Emilio", ""], ["Mathias", "Lambert", ""], ["Dreyer", "Markus", ""]]}, {"id": "1706.04389", "submitter": "Antonio Toral", "authors": "Filip Klubi\\v{c}ka, Antonio Toral, V\\'ictor M. S\\'anchez-Cartagena", "title": "Fine-grained human evaluation of neural versus phrase-based machine\n  translation", "comments": "12 pages, 2 figures, The Prague Bulletin of Mathematical Linguistics", "journal-ref": "The Prague Bulletin of Mathematical Linguistics No. 108, pp.\n  121-132 (2017)", "doi": "10.1515/pralin-2017-0014", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare three approaches to statistical machine translation (pure\nphrase-based, factored phrase-based and neural) by performing a fine-grained\nmanual evaluation via error annotation of the systems' outputs. The error types\nin our annotation are compliant with the multidimensional quality metrics\n(MQM), and the annotation is performed by two annotators. Inter-annotator\nagreement is high for such a task, and results show that the best performing\nsystem (neural) reduces the errors produced by the worst system (phrase-based)\nby 54%.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jun 2017 09:59:47 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Klubi\u010dka", "Filip", ""], ["Toral", "Antonio", ""], ["S\u00e1nchez-Cartagena", "V\u00edctor M.", ""]]}, {"id": "1706.04432", "submitter": "{\\L}ukasz D\\k{e}bowski", "authors": "{\\L}ukasz D\\k{e}bowski", "title": "Is Natural Language a Perigraphic Process? The Theorem about Facts and\n  Words Revisited", "comments": "29 pages, 1 figure", "journal-ref": "Entropy 20(2):85, 2018", "doi": "10.3390/e20020085", "report-no": null, "categories": "cs.IT cs.CL math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As we discuss, a stationary stochastic process is nonergodic when a random\npersistent topic can be detected in the infinite random text sampled from the\nprocess, whereas we call the process strongly nonergodic when an infinite\nsequence of independent random bits, called probabilistic facts, is needed to\ndescribe this topic completely. Replacing probabilistic facts with an\nalgorithmically random sequence of bits, called algorithmic facts, we adapt\nthis property back to ergodic processes. Subsequently, we call a process\nperigraphic if the number of algorithmic facts which can be inferred from a\nfinite text sampled from the process grows like a power of the text length. We\npresent a simple example of such a process. Moreover, we demonstrate an\nassertion which we call the theorem about facts and words. This proposition\nstates that the number of probabilistic or algorithmic facts which can be\ninferred from a text drawn from a process must be roughly smaller than the\nnumber of distinct word-like strings detected in this text by means of the PPM\ncompression algorithm. We also observe that the number of the word-like strings\nfor a sample of plays by Shakespeare follows an empirical stepwise power law,\nin a stark contrast to Markov processes. Hence we suppose that natural language\nconsidered as a process is not only non-Markov but also perigraphic.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jun 2017 12:22:38 GMT"}, {"version": "v2", "created": "Tue, 21 Nov 2017 12:45:39 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["D\u0119bowski", "\u0141ukasz", ""]]}, {"id": "1706.04473", "submitter": "Kairit Sirts", "authors": "Kairit Sirts, Olivier Piguet, Mark Johnson", "title": "Idea density for predicting Alzheimer's disease from transcribed speech", "comments": "CoNLL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Idea Density (ID) measures the rate at which ideas or elementary predications\nare expressed in an utterance or in a text. Lower ID is found to be associated\nwith an increased risk of developing Alzheimer's disease (AD) (Snowdon et al.,\n1996; Engelman et al., 2010). ID has been used in two different versions:\npropositional idea density (PID) counts the expressed ideas and can be applied\nto any text while semantic idea density (SID) counts pre-defined information\ncontent units and is naturally more applicable to normative domains, such as\npicture description tasks. In this paper, we develop DEPID, a novel\ndependency-based method for computing PID, and its version DEPID-R that enables\nto exclude repeating ideas---a feature characteristic to AD speech. We conduct\nthe first comparison of automatically extracted PID and SID in the diagnostic\nclassification task on two different AD datasets covering both closed-topic and\nfree-recall domains. While SID performs better on the normative dataset, adding\nPID leads to a small but significant improvement (+1.7 F-score). On the\nfree-topic dataset, PID performs better than SID as expected (77.6 vs 72.3 in\nF-score) but adding the features derived from the word embedding clustering\nunderlying the automatic SID increases the results considerably, leading to an\nF-score of 84.8.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jun 2017 13:18:08 GMT"}], "update_date": "2017-06-15", "authors_parsed": [["Sirts", "Kairit", ""], ["Piguet", "Olivier", ""], ["Johnson", "Mark", ""]]}, {"id": "1706.04560", "submitter": "Tong Wang", "authors": "Sandeep Subramanian, Tong Wang, Xingdi Yuan, Saizheng Zhang, Yoshua\n  Bengio, Adam Trischler", "title": "Neural Models for Key Phrase Detection and Question Generation", "comments": "Machine Reading for Question Answering workshop at ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a two-stage neural model to tackle question generation from\ndocuments. First, our model estimates the probability that word sequences in a\ndocument are ones that a human would pick when selecting candidate answers by\ntraining a neural key-phrase extractor on the answers in a question-answering\ncorpus. Predicted key phrases then act as target answers and condition a\nsequence-to-sequence question-generation model with a copy mechanism.\nEmpirically, our key-phrase extraction model significantly outperforms an\nentity-tagging baseline and existing rule-based approaches. We further\ndemonstrate that our question generation system formulates fluent, answerable\nquestions from key phrases. This two-stage system could be used to augment or\ngenerate reading comprehension datasets, which may be leveraged to improve\nmachine reading systems or in educational settings.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jun 2017 16:06:18 GMT"}, {"version": "v2", "created": "Thu, 14 Sep 2017 17:43:48 GMT"}, {"version": "v3", "created": "Wed, 30 May 2018 17:57:41 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Subramanian", "Sandeep", ""], ["Wang", "Tong", ""], ["Yuan", "Xingdi", ""], ["Zhang", "Saizheng", ""], ["Bengio", "Yoshua", ""], ["Trischler", "Adam", ""]]}, {"id": "1706.04815", "submitter": "Chuanqi Tan", "authors": "Chuanqi Tan, Furu Wei, Nan Yang, Bowen Du, Weifeng Lv, Ming Zhou", "title": "S-Net: From Answer Extraction to Answer Generation for Machine Reading\n  Comprehension", "comments": "AAAI18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel approach to machine reading comprehension\nfor the MS-MARCO dataset. Unlike the SQuAD dataset that aims to answer a\nquestion with exact text spans in a passage, the MS-MARCO dataset defines the\ntask as answering a question from multiple passages and the words in the answer\nare not necessary in the passages. We therefore develop an\nextraction-then-synthesis framework to synthesize answers from extraction\nresults. Specifically, the answer extraction model is first employed to predict\nthe most important sub-spans from the passage as evidence, and the answer\nsynthesis model takes the evidence as additional features along with the\nquestion and passage to further elaborate the final answers. We build the\nanswer extraction model with state-of-the-art neural networks for single\npassage reading comprehension, and propose an additional task of passage\nranking to help answer extraction in multiple passages. The answer synthesis\nmodel is based on the sequence-to-sequence neural networks with extracted\nevidences as features. Experiments show that our extraction-then-synthesis\nmethod outperforms state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jun 2017 11:10:33 GMT"}, {"version": "v2", "created": "Tue, 5 Sep 2017 11:55:01 GMT"}, {"version": "v3", "created": "Mon, 25 Sep 2017 01:41:07 GMT"}, {"version": "v4", "created": "Mon, 9 Oct 2017 06:58:31 GMT"}, {"version": "v5", "created": "Mon, 20 Nov 2017 06:10:03 GMT"}, {"version": "v6", "created": "Tue, 2 Jan 2018 07:49:08 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Tan", "Chuanqi", ""], ["Wei", "Furu", ""], ["Yang", "Nan", ""], ["Du", "Bowen", ""], ["Lv", "Weifeng", ""], ["Zhou", "Ming", ""]]}, {"id": "1706.04872", "submitter": "Ramon Ferrer i Cancho", "authors": "Ramon Ferrer-i-Cancho", "title": "Towards a theory of word order. Comment on \"Dependency distance: a new\n  perspective on syntactic patterns in natural language\" by Haitao Liu et al", "comments": null, "journal-ref": null, "doi": "10.1016/j.plrev.2017.06.019", "report-no": null, "categories": "cs.CL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comment on \"Dependency distance: a new perspective on syntactic patterns in\nnatural language\" by Haitao Liu et al\n", "versions": [{"version": "v1", "created": "Thu, 15 Jun 2017 14:01:40 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Ferrer-i-Cancho", "Ramon", ""]]}, {"id": "1706.04902", "submitter": "Sebastian Ruder", "authors": "Sebastian Ruder, Ivan Vuli\\'c, Anders S{\\o}gaard", "title": "A Survey Of Cross-lingual Word Embedding Models", "comments": "Published in Journal of Artificial Intelligence Research", "journal-ref": "JAIR 65 (2019) 569-631", "doi": "10.1613/jair.1.11640", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual representations of words enable us to reason about word meaning\nin multilingual contexts and are a key facilitator of cross-lingual transfer\nwhen developing natural language processing models for low-resource languages.\nIn this survey, we provide a comprehensive typology of cross-lingual word\nembedding models. We compare their data requirements and objective functions.\nThe recurring theme of the survey is that many of the models presented in the\nliterature optimize for the same objectives, and that seemingly different\nmodels are often equivalent modulo optimization strategies, hyper-parameters,\nand such. We also discuss the different ways cross-lingual word embeddings are\nevaluated, as well as future challenges and research horizons.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jun 2017 14:46:56 GMT"}, {"version": "v2", "created": "Wed, 18 Oct 2017 10:44:06 GMT"}, {"version": "v3", "created": "Thu, 30 May 2019 08:59:16 GMT"}, {"version": "v4", "created": "Sun, 6 Oct 2019 10:01:48 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Ruder", "Sebastian", ""], ["Vuli\u0107", "Ivan", ""], ["S\u00f8gaard", "Anders", ""]]}, {"id": "1706.04922", "submitter": "Gia-Hung Nguyen", "authors": "Gia-Hung Nguyen, Laure Soulier, Lynda Tamine, Nathalie Bricon-Souf", "title": "DSRIM: A Deep Neural Information Retrieval Model Enhanced by a Knowledge\n  Resource Driven Representation of Documents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state-of-the-art solutions to the vocabulary mismatch in information\nretrieval (IR) mainly aim at leveraging either the relational semantics\nprovided by external resources or the distributional semantics, recently\ninvestigated by deep neural approaches. Guided by the intuition that the\nrelational semantics might improve the effectiveness of deep neural approaches,\nwe propose the Deep Semantic Resource Inference Model (DSRIM) that relies on:\n1) a representation of raw-data that models the relational semantics of text by\njointly considering objects and relations expressed in a knowledge resource,\nand 2) an end-to-end neural architecture that learns the query-document\nrelevance by leveraging the distributional and relational semantics of\ndocuments and queries. The experimental evaluation carried out on two TREC\ndatasets from TREC Terabyte and TREC CDS tracks relying respectively on WordNet\nand MeSH resources, indicates that our model outperforms state-of-the-art\nsemantic and deep neural IR models.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jun 2017 15:24:32 GMT"}, {"version": "v2", "created": "Thu, 27 Jul 2017 12:32:30 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Nguyen", "Gia-Hung", ""], ["Soulier", "Laure", ""], ["Tamine", "Lynda", ""], ["Bricon-Souf", "Nathalie", ""]]}, {"id": "1706.04971", "submitter": "Dominik Schlechtweg", "authors": "Dominik Schlechtweg, Stefanie Eckmann, Enrico Santus, Sabine Schulte\n  im Walde, Daniel Hole", "title": "German in Flux: Detecting Metaphoric Change via Word Entropy", "comments": "CoNLL 2017. 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper explores the information-theoretic measure entropy to detect\nmetaphoric change, transferring ideas from hypernym detection to research on\nlanguage change. We also build the first diachronic test set for German as a\nstandard for metaphoric change annotation. Our model shows high performance, is\nunsupervised, language-independent and generalizable to other processes of\nsemantic change.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jun 2017 17:14:17 GMT"}], "update_date": "2017-06-16", "authors_parsed": [["Schlechtweg", "Dominik", ""], ["Eckmann", "Stefanie", ""], ["Santus", "Enrico", ""], ["Walde", "Sabine Schulte im", ""], ["Hole", "Daniel", ""]]}, {"id": "1706.04997", "submitter": "John J. Camilleri", "authors": "John J. Camilleri and Normunds Gr\\=uz\\={\\i}tis and Gerardo Schneider", "title": "Extracting Formal Models from Normative Texts", "comments": "Extended version of conference paper at the 21st International\n  Conference on Applications of Natural Language to Information Systems (NLDB\n  2016). arXiv admin note: substantial text overlap with arXiv:1607.01485", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are concerned with the analysis of normative texts - documents based on\nthe deontic notions of obligation, permission, and prohibition. Our goal is to\nmake queries about these notions and verify that a text satisfies certain\nproperties concerning causality of actions and timing constraints. This\nrequires taking the original text and building a representation (model) of it\nin a formal language, in our case the C-O Diagram formalism. We present an\nexperimental, semi-automatic aid that helps to bridge the gap between a\nnormative text in natural language and its C-O Diagram representation. Our\napproach consists of using dependency structures obtained from the\nstate-of-the-art Stanford Parser, and applying our own rules and heuristics in\norder to extract the relevant components. The result is a tabular data\nstructure where each sentence is split into suitable fields, which can then be\nconverted into a C-O Diagram. The process is not fully automatic however, and\nsome post-editing is generally required of the user. We apply our tool and\nperform experiments on documents from different domains, and report an initial\nevaluation of the accuracy and feasibility of our approach.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jun 2017 07:24:23 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["Camilleri", "John J.", ""], ["Gr\u016bz\\=\u0131tis", "Normunds", ""], ["Schneider", "Gerardo", ""]]}, {"id": "1706.05075", "submitter": "Peng Zhou", "authors": "Suncong Zheng, Feng Wang, Hongyun Bao, Yuexing Hao, Peng Zhou, Bo Xu", "title": "Joint Extraction of Entities and Relations Based on a Novel Tagging\n  Scheme", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Joint extraction of entities and relations is an important task in\ninformation extraction. To tackle this problem, we firstly propose a novel\ntagging scheme that can convert the joint extraction task to a tagging problem.\nThen, based on our tagging scheme, we study different end-to-end models to\nextract entities and their relations directly, without identifying entities and\nrelations separately. We conduct experiments on a public dataset produced by\ndistant supervision method and the experimental results show that the tagging\nbased methods are better than most of the existing pipelined and joint learning\nmethods. What's more, the end-to-end model proposed in this paper, achieves the\nbest results on the public dataset.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 03:14:23 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["Zheng", "Suncong", ""], ["Wang", "Feng", ""], ["Bao", "Hongyun", ""], ["Hao", "Yuexing", ""], ["Zhou", "Peng", ""], ["Xu", "Bo", ""]]}, {"id": "1706.05083", "submitter": "Chris Hokamp", "authors": "Chris Hokamp", "title": "Ensembling Factored Neural Machine Translation Models for Automatic\n  Post-Editing and Quality Estimation", "comments": "APE/QE System Description Paper for WMT/CMT 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a novel approach to Automatic Post-Editing (APE) and\nWord-Level Quality Estimation (QE) using ensembles of specialized Neural\nMachine Translation (NMT) systems. Word-level features that have proven\neffective for QE are included as input factors, expanding the representation of\nthe original source and the machine translation hypothesis, which are used to\ngenerate an automatically post-edited hypothesis. We train a suite of NMT\nmodels that use different input representations, but share the same output\nspace. These models are then ensembled together, and tuned for both the APE and\nthe QE task. We thus attempt to connect the state-of-the-art approaches to APE\nand QE within a single framework. Our models achieve state-of-the-art results\nin both tasks, with the only difference in the tuning step which learns weights\nfor each component of the ensemble.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jun 2017 20:47:03 GMT"}, {"version": "v2", "created": "Sat, 15 Jul 2017 12:38:48 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Hokamp", "Chris", ""]]}, {"id": "1706.05084", "submitter": "James Wilson", "authors": "Kelsey MacMillan and James D. Wilson", "title": "Topic supervised non-negative matrix factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic models have been extensively used to organize and interpret the\ncontents of large, unstructured corpora of text documents. Although topic\nmodels often perform well on traditional training vs. test set evaluations, it\nis often the case that the results of a topic model do not align with human\ninterpretation. This interpretability fallacy is largely due to the\nunsupervised nature of topic models, which prohibits any user guidance on the\nresults of a model. In this paper, we introduce a semi-supervised method called\ntopic supervised non-negative matrix factorization (TS-NMF) that enables the\nuser to provide labeled example documents to promote the discovery of more\nmeaningful semantic structure of a corpus. In this way, the results of TS-NMF\nbetter match the intuition and desired labeling of the user. The core of TS-NMF\nrelies on solving a non-convex optimization problem for which we derive an\niterative algorithm that is shown to be monotonic and convergent to a local\noptimum. We demonstrate the practical utility of TS-NMF on the Reuters and\nPubMed corpora, and find that TS-NMF is especially useful for conceptual or\nbroad topics, where topic key terms are not well understood. Although\nidentifying an optimal latent structure for the data is not a primary objective\nof the proposed approach, we find that TS-NMF achieves higher weighted Jaccard\nsimilarity scores than the contemporary methods, (unsupervised) NMF and latent\nDirichlet allocation, at supervision rates as low as 10% to 20%.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 04:20:04 GMT"}, {"version": "v2", "created": "Sun, 2 Jul 2017 16:00:27 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["MacMillan", "Kelsey", ""], ["Wilson", "James D.", ""]]}, {"id": "1706.05087", "submitter": "\\c{C}a\\u{g}lar G\\\"ul\\c{c}ehre", "authors": "Caglar Gulcehre, Francis Dutil, Adam Trischler, Yoshua Bengio", "title": "Plan, Attend, Generate: Character-level Neural Machine Translation with\n  Planning in the Decoder", "comments": "Accepted to Rep4NLP 2017 Workshop at ACL 2017 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the integration of a planning mechanism into an\nencoder-decoder architecture with an explicit alignment for character-level\nmachine translation. We develop a model that plans ahead when it computes\nalignments between the source and target sequences, constructing a matrix of\nproposed future alignments and a commitment vector that governs whether to\nfollow or recompute the plan. This mechanism is inspired by the strategic\nattentive reader and writer (STRAW) model. Our proposed model is end-to-end\ntrainable with fully differentiable operations. We show that it outperforms a\nstrong baseline on three character-level decoder neural machine translation on\nWMT'15 corpus. Our analysis demonstrates that our model can compute\nqualitatively intuitive alignments and achieves superior performance with fewer\nparameters.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 23:11:04 GMT"}, {"version": "v2", "created": "Fri, 23 Jun 2017 06:31:05 GMT"}], "update_date": "2017-06-26", "authors_parsed": [["Gulcehre", "Caglar", ""], ["Dutil", "Francis", ""], ["Trischler", "Adam", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1706.05089", "submitter": "Go Sugimoto", "authors": "Go Sugimoto (ACDH-\\\"OAW)", "title": "Number game", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CLARIN (Common Language Resources and Technology Infrastructure) is regarded\nas one of the most important European research infrastructures, offering and\npromoting a wide array of useful services for (digital) research in linguistics\nand humanities. However, the assessment of the users for its core technical\ndevelopment has been highly limited, therefore, it is unclear if the community\nis thoroughly aware of the status-quo of the growing infrastructure. In\naddition, CLARIN does not seem to be fully materialised marketing and business\nplans and strategies despite its strong technical assets. This article analyses\nthe web traffic of the Virtual Language Observatory, one of the main web\napplications of CLARIN and a symbol of pan-European re-search cooperation, to\nevaluate the users and performance of the service in a transparent and\nscientific way. It is envisaged that the paper can raise awareness of the\npressing issues on objective and transparent operation of the infrastructure\nthough Open Evaluation, and the synergy between marketing and technical\ndevelopment. It also investigates the \"science of web analytics\" in an attempt\nto document the research process for the purpose of reusability and\nreproducibility, thus to find universal lessons for the use of a web analytics,\nrather than to merely produce a statistical report of a particular website\nwhich loses its value outside its context.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jun 2017 13:00:08 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["Sugimoto", "Go", "", "ACDH-\u00d6AW"]]}, {"id": "1706.05111", "submitter": "Dai Quoc Nguyen", "authors": "Dai Quoc Nguyen, Dat Quoc Nguyen, Ashutosh Modi, Stefan Thater and\n  Manfred Pinkal", "title": "A Mixture Model for Learning Multi-Sense Word Embeddings", "comments": "*SEM 2017", "journal-ref": null, "doi": "10.18653/v1/S17-1015", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings are now a standard technique for inducing meaning\nrepresentations for words. For getting good representations, it is important to\ntake into account different senses of a word. In this paper, we propose a\nmixture model for learning multi-sense word embeddings. Our model generalizes\nthe previous works in that it allows to induce different weights of different\nsenses of a word. The experimental results show that our model outperforms\nprevious models on standard evaluation tasks.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jun 2017 23:07:06 GMT"}], "update_date": "2017-08-14", "authors_parsed": [["Nguyen", "Dai Quoc", ""], ["Nguyen", "Dat Quoc", ""], ["Modi", "Ashutosh", ""], ["Thater", "Stefan", ""], ["Pinkal", "Manfred", ""]]}, {"id": "1706.05122", "submitter": "Takuma Yoneda", "authors": "Takuma Yoneda and Koki Mori and Makoto Miwa and Yutaka Sasaki", "title": "Bib2vec: An Embedding-based Search System for Bibliographic Information", "comments": "EACL2017 extended version. The demonstration is available at\n  http://tti-coin.jp/demo/bib2vec/", "journal-ref": "Proceedings of the EACL 2017 Software Demonstrations, Valencia,\n  Spain, April 3-7 2017, pages 112-115", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel embedding model that represents relationships among\nseveral elements in bibliographic information with high representation ability\nand flexibility. Based on this model, we present a novel search system that\nshows the relationships among the elements in the ACL Anthology Reference\nCorpus. The evaluation results show that our model can achieve a high\nprediction ability and produce reasonable search results.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jun 2017 00:53:28 GMT"}, {"version": "v2", "created": "Tue, 17 Oct 2017 16:33:20 GMT"}, {"version": "v3", "created": "Thu, 5 Apr 2018 09:19:57 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Yoneda", "Takuma", ""], ["Mori", "Koki", ""], ["Miwa", "Makoto", ""], ["Sasaki", "Yutaka", ""]]}, {"id": "1706.05125", "submitter": "Yann Dauphin", "authors": "Mike Lewis, Denis Yarats, Yann N. Dauphin, Devi Parikh and Dhruv Batra", "title": "Deal or No Deal? End-to-End Learning for Negotiation Dialogues", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of human dialogue occurs in semi-cooperative settings, where agents with\ndifferent goals attempt to agree on common decisions. Negotiations require\ncomplex communication and reasoning skills, but success is easy to measure,\nmaking this an interesting task for AI. We gather a large dataset of\nhuman-human negotiations on a multi-issue bargaining task, where agents who\ncannot observe each other's reward functions must reach an agreement (or a\ndeal) via natural language dialogue. For the first time, we show it is possible\nto train end-to-end models for negotiation, which must learn both linguistic\nand reasoning skills with no annotated dialogue states. We also introduce\ndialogue rollouts, in which the model plans ahead by simulating possible\ncomplete continuations of the conversation, and find that this technique\ndramatically improves performance. Our code and dataset are publicly available\n(https://github.com/facebookresearch/end-to-end-negotiator).\n", "versions": [{"version": "v1", "created": "Fri, 16 Jun 2017 01:26:09 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["Lewis", "Mike", ""], ["Yarats", "Denis", ""], ["Dauphin", "Yann N.", ""], ["Parikh", "Devi", ""], ["Batra", "Dhruv", ""]]}, {"id": "1706.05140", "submitter": "Jey Han Lau", "authors": "Shraey Bhatia and Jey Han Lau and Timothy Baldwin", "title": "An Automatic Approach for Document-level Topic Model Evaluation", "comments": "10 pages; accepted for the Twenty First Conference on Computational\n  Natural Language Learning (CoNLL 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic models jointly learn topics and document-level topic distribution.\nExtrinsic evaluation of topic models tends to focus exclusively on topic-level\nevaluation, e.g. by assessing the coherence of topics. We demonstrate that\nthere can be large discrepancies between topic- and document-level model\nquality, and that basing model evaluation on topic-level analysis can be highly\nmisleading. We propose a method for automatically predicting topic model\nquality based on analysis of document-level topic allocations, and provide\nempirical evidence for its robustness.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jun 2017 03:53:38 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["Bhatia", "Shraey", ""], ["Lau", "Jey Han", ""], ["Baldwin", "Timothy", ""]]}, {"id": "1706.05349", "submitter": "Jean-Val\\`ere Cossu", "authors": "Jean-Val\\`ere Cossu, Alejandro Molina-Villegas, Mariana Tello-Signoret", "title": "Active learning in annotating micro-blogs dealing with e-reputation", "comments": "Journal of Interdisciplinary Methodologies and Issues in Science -\n  Vol 3 - Contextualisation digitale - 2017", "journal-ref": "Journal of Interdisciplinary Methodologies and Issues in Sciences,\n  Digital Contextualization (October 3, 2017) jimis:3970", "doi": "10.18713/JIMIS-010917-3-2", "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Elections unleash strong political views on Twitter, but what do people\nreally think about politics? Opinion and trend mining on micro blogs dealing\nwith politics has recently attracted researchers in several fields including\nInformation Retrieval and Machine Learning (ML). Since the performance of ML\nand Natural Language Processing (NLP) approaches are limited by the amount and\nquality of data available, one promising alternative for some tasks is the\nautomatic propagation of expert annotations. This paper intends to develop a\nso-called active learning process for automatically annotating French language\ntweets that deal with the image (i.e., representation, web reputation) of\npoliticians. Our main focus is on the methodology followed to build an original\nannotated dataset expressing opinion from two French politicians over time. We\ntherefore review state of the art NLP-based ML algorithms to automatically\nannotate tweets using a manual initiation step as bootstrap. This paper focuses\non key issues about active learning while building a large annotated data set\nfrom noise. This will be introduced by human annotators, abundance of data and\nthe label distribution across data and entities. In turn, we show that Twitter\ncharacteristics such as the author's name or hashtags can be considered as the\nbearing point to not only improve automatic systems for Opinion Mining (OM) and\nTopic Classification but also to reduce noise in human annotations. However, a\nlater thorough analysis shows that reducing noise might induce the loss of\ncrucial information.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jun 2017 17:07:24 GMT"}, {"version": "v2", "created": "Mon, 26 Jun 2017 18:09:57 GMT"}, {"version": "v3", "created": "Mon, 3 Jul 2017 13:55:08 GMT"}, {"version": "v4", "created": "Mon, 25 Sep 2017 21:58:04 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Cossu", "Jean-Val\u00e8re", ""], ["Molina-Villegas", "Alejandro", ""], ["Tello-Signoret", "Mariana", ""]]}, {"id": "1706.05549", "submitter": "Andrey Ignatov", "authors": "Liliya Akhtyamova, Andrey Ignatov, John Cardiff", "title": "A Large-Scale CNN Ensemble for Medication Safety Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Revealing Adverse Drug Reactions (ADR) is an essential part of post-marketing\ndrug surveillance, and data from health-related forums and medical communities\ncan be of a great significance for estimating such effects. In this paper, we\npropose an end-to-end CNN-based method for predicting drug safety on user\ncomments from healthcare discussion forums. We present an architecture that is\nbased on a vast ensemble of CNNs with varied structural parameters, where the\nprediction is determined by the majority vote. To evaluate the performance of\nthe proposed solution, we present a large-scale dataset collected from a\nmedical website that consists of over 50 thousand reviews for more than 4000\ndrugs. The results demonstrate that our model significantly outperforms\nconventional approaches and predicts medicine safety with an accuracy of 87.17%\nfor binary and 62.88% for multi-classification tasks.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jun 2017 15:06:58 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Akhtyamova", "Liliya", ""], ["Ignatov", "Andrey", ""], ["Cardiff", "John", ""]]}, {"id": "1706.05565", "submitter": "Po-Sen Huang", "authors": "Po-Sen Huang, Chong Wang, Sitao Huang, Dengyong Zhou, Li Deng", "title": "Towards Neural Phrase-based Machine Translation", "comments": "in International Conference on Learning Representations (ICLR) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present Neural Phrase-based Machine Translation (NPMT). Our\nmethod explicitly models the phrase structures in output sequences using\nSleep-WAke Networks (SWAN), a recently proposed segmentation-based sequence\nmodeling method. To mitigate the monotonic alignment requirement of SWAN, we\nintroduce a new layer to perform (soft) local reordering of input sequences.\nDifferent from existing neural machine translation (NMT) approaches, NPMT does\nnot use attention-based decoding mechanisms. Instead, it directly outputs\nphrases in a sequential order and can decode in linear time. Our experiments\nshow that NPMT achieves superior performances on IWSLT 2014\nGerman-English/English-German and IWSLT 2015 English-Vietnamese machine\ntranslation tasks compared with strong NMT baselines. We also observe that our\nmethod produces meaningful phrases in output languages.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jun 2017 17:36:23 GMT"}, {"version": "v2", "created": "Tue, 20 Jun 2017 00:42:37 GMT"}, {"version": "v3", "created": "Mon, 31 Jul 2017 18:01:35 GMT"}, {"version": "v4", "created": "Sat, 28 Oct 2017 02:56:01 GMT"}, {"version": "v5", "created": "Mon, 29 Jan 2018 23:31:39 GMT"}, {"version": "v6", "created": "Wed, 18 Apr 2018 22:57:38 GMT"}, {"version": "v7", "created": "Wed, 18 Jul 2018 21:57:45 GMT"}, {"version": "v8", "created": "Mon, 24 Sep 2018 10:34:16 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Huang", "Po-Sen", ""], ["Wang", "Chong", ""], ["Huang", "Sitao", ""], ["Zhou", "Dengyong", ""], ["Deng", "Li", ""]]}, {"id": "1706.05585", "submitter": "Tom Hope", "authors": "Tom Hope, Joel Chan, Aniket Kittur, Dafna Shahaf", "title": "Accelerating Innovation Through Analogy Mining", "comments": "KDD 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The availability of large idea repositories (e.g., the U.S. patent database)\ncould significantly accelerate innovation and discovery by providing people\nwith inspiration from solutions to analogous problems. However, finding useful\nanalogies in these large, messy, real-world repositories remains a persistent\nchallenge for either human or automated methods. Previous approaches include\ncostly hand-created databases that have high relational structure (e.g.,\npredicate calculus representations) but are very sparse. Simpler\nmachine-learning/information-retrieval similarity metrics can scale to large,\nnatural-language datasets, but struggle to account for structural similarity,\nwhich is central to analogy. In this paper we explore the viability and value\nof learning simpler structural representations, specifically, \"problem\nschemas\", which specify the purpose of a product and the mechanisms by which it\nachieves that purpose. Our approach combines crowdsourcing and recurrent neural\nnetworks to extract purpose and mechanism vector representations from product\ndescriptions. We demonstrate that these learned vectors allow us to find\nanalogies with higher precision and recall than traditional\ninformation-retrieval methods. In an ideation experiment, analogies retrieved\nby our models significantly increased people's likelihood of generating\ncreative ideas compared to analogies retrieved by traditional methods. Our\nresults suggest a promising approach to enabling computational analogy at scale\nis to learn and leverage weaker structural representations.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jun 2017 22:29:37 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Hope", "Tom", ""], ["Chan", "Joel", ""], ["Kittur", "Aniket", ""], ["Shahaf", "Dafna", ""]]}, {"id": "1706.05656", "submitter": "Stefan Frank", "authors": "Stefan Frank, Jinbiao Yang", "title": "Lexical representation explains cortical entrainment during speech\n  comprehension", "comments": "Submitted for publication", "journal-ref": null, "doi": "10.1371/journal.pone.0197304", "report-no": null, "categories": "q-bio.NC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Results from a recent neuroimaging study on spoken sentence comprehension\nhave been interpreted as evidence for cortical entrainment to hierarchical\nsyntactic structure. We present a simple computational model that predicts the\npower spectra from this study, even though the model's linguistic knowledge is\nrestricted to the lexical level, and word-level representations are not\ncombined into higher-level units (phrases or sentences). Hence, the cortical\nentrainment results can also be explained from the lexical properties of the\nstimuli, without recourse to hierarchical syntax.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jun 2017 14:04:09 GMT"}, {"version": "v2", "created": "Wed, 12 Jul 2017 07:33:02 GMT"}, {"version": "v3", "created": "Thu, 20 Jul 2017 11:26:48 GMT"}, {"version": "v4", "created": "Mon, 9 Oct 2017 14:24:45 GMT"}, {"version": "v5", "created": "Wed, 3 Jan 2018 13:53:14 GMT"}, {"version": "v6", "created": "Wed, 10 Jan 2018 13:35:26 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Frank", "Stefan", ""], ["Yang", "Jinbiao", ""]]}, {"id": "1706.05674", "submitter": "Takuo Hamaguchi", "authors": "Takuo Hamaguchi, Hidekazu Oiwa, Masashi Shimbo, and Yuji Matsumoto", "title": "Knowledge Transfer for Out-of-Knowledge-Base Entities: A Graph Neural\n  Network Approach", "comments": "This paper has been accepted by IJCAI17", "journal-ref": null, "doi": "10.1527/tjsai.F-H72", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge base completion (KBC) aims to predict missing information in a\nknowledge base.In this paper, we address the out-of-knowledge-base (OOKB)\nentity problem in KBC:how to answer queries concerning test entities not\nobserved at training time. Existing embedding-based KBC models assume that all\ntest entities are available at training time, making it unclear how to obtain\nembeddings for new entities without costly retraining. To solve the OOKB entity\nproblem without retraining, we use graph neural networks (Graph-NNs) to compute\nthe embeddings of OOKB entities, exploiting the limited auxiliary knowledge\nprovided at test time.The experimental results show the effectiveness of our\nproposed model in the OOKB setting.Additionally, in the standard KBC setting in\nwhich OOKB entities are not involved, our model achieves state-of-the-art\nperformance on the WordNet dataset. The code and dataset are available at\nhttps://github.com/takuo-h/GNN-for-OOKB\n", "versions": [{"version": "v1", "created": "Sun, 18 Jun 2017 15:53:59 GMT"}, {"version": "v2", "created": "Tue, 20 Jun 2017 01:33:33 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Hamaguchi", "Takuo", ""], ["Oiwa", "Hidekazu", ""], ["Shimbo", "Masashi", ""], ["Matsumoto", "Yuji", ""]]}, {"id": "1706.05719", "submitter": "Thomas Krause", "authors": "Thomas Krause", "title": "Towards the Improvement of Automated Scientific Document Categorization\n  by Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This master thesis describes an algorithm for automated categorization of\nscientific documents using deep learning techniques and compares the results to\nthe results of existing classification algorithms. As an additional goal a\nreusable API is to be developed allowing the automation of classification tasks\nin existing software. A design will be proposed using a convolutional neural\nnetwork as a classifier and integrating this into a REST based API. This is\nthen used as the basis for an actual proof of concept implementation presented\nas well in this thesis. It will be shown that the deep learning classifier\nprovides very good result in the context of multi-class document categorization\nand that it is feasible to integrate such classifiers into a larger ecosystem\nusing REST based services.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jun 2017 20:29:15 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Krause", "Thomas", ""]]}, {"id": "1706.05723", "submitter": "Louis Chartrand", "authors": "Louis Chartrand, Jackie C.K. Cheung, Mohamed Bouguessa", "title": "Detecting Large Concept Extensions for Conceptual Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When performing a conceptual analysis of a concept, philosophers are\ninterested in all forms of expression of a concept in a text---be it direct or\nindirect, explicit or implicit. In this paper, we experiment with topic-based\nmethods of automating the detection of concept expressions in order to\nfacilitate philosophical conceptual analysis. We propose six methods based on\nLDA, and evaluate them on a new corpus of court decision that we had annotated\nby experts and non-experts. Our results indicate that these methods can yield\nimportant improvements over the keyword heuristic, which is often used as a\nconcept detection heuristic in many contexts. While more work remains to be\ndone, this indicates that detecting concepts through topics can serve as a\ngeneral-purpose method for at least some forms of concept expression that are\nnot captured using naive keyword approaches.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jun 2017 20:39:24 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Chartrand", "Louis", ""], ["Cheung", "Jackie C. K.", ""], ["Bouguessa", "Mohamed", ""]]}, {"id": "1706.05765", "submitter": "Makoto Morishita", "authors": "Makoto Morishita, Yusuke Oda, Graham Neubig, Koichiro Yoshino,\n  Katsuhito Sudoh, Satoshi Nakamura", "title": "An Empirical Study of Mini-Batch Creation Strategies for Neural Machine\n  Translation", "comments": "8 pages, accepted to the First Workshop on Neural Machine Translation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training of neural machine translation (NMT) models usually uses mini-batches\nfor efficiency purposes. During the mini-batched training process, it is\nnecessary to pad shorter sentences in a mini-batch to be equal in length to the\nlongest sentence therein for efficient computation. Previous work has noted\nthat sorting the corpus based on the sentence length before making mini-batches\nreduces the amount of padding and increases the processing speed. However,\ndespite the fact that mini-batch creation is an essential step in NMT training,\nwidely used NMT toolkits implement disparate strategies for doing so, which\nhave not been empirically validated or compared. This work investigates\nmini-batch creation strategies with experiments over two different datasets.\nOur results suggest that the choice of a mini-batch creation strategy has a\nlarge effect on NMT training and some length-based sorting strategies do not\nalways work well compared with simple shuffling.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jun 2017 02:38:01 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Morishita", "Makoto", ""], ["Oda", "Yusuke", ""], ["Neubig", "Graham", ""], ["Yoshino", "Koichiro", ""], ["Sudoh", "Katsuhito", ""], ["Nakamura", "Satoshi", ""]]}, {"id": "1706.06177", "submitter": "Efsun Kayi", "authors": "Efsun Sarioglu Kayi, Kabir Yadav, James M. Chamberlain, Hyeong-Ah Choi", "title": "Topic Modeling for Classification of Clinical Reports", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic health records (EHRs) contain important clinical information about\npatients. Efficient and effective use of this information could supplement or\neven replace manual chart review as a means of studying and improving the\nquality and safety of healthcare delivery. However, some of these clinical data\nare in the form of free text and require pre-processing before use in automated\nsystems. A common free text data source is radiology reports, typically\ndictated by radiologists to explain their interpretations. We sought to\ndemonstrate machine learning classification of computed tomography (CT) imaging\nreports into binary outcomes, i.e. positive and negative for fracture, using\nregular text classification and classifiers based on topic modeling. Topic\nmodeling provides interpretable themes (topic distributions) in reports, a\nrepresentation that is more compact than the commonly used bag-of-words\nrepresentation and can be processed faster than raw text in subsequent\nautomated processes. We demonstrate new classifiers based on this topic\nmodeling representation of the reports. Aggregate topic classifier (ATC) and\nconfidence-based topic classifier (CTC) use a single topic that is determined\nfrom the training dataset based on different measures to classify the reports\non the test dataset. Alternatively, similarity-based topic classifier (STC)\nmeasures the similarity between the reports' topic distributions to determine\nthe predicted class. Our proposed topic modeling-based classifier systems are\nshown to be competitive with existing text classification techniques and\nprovides an efficient and interpretable representation.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jun 2017 21:04:22 GMT"}], "update_date": "2017-06-21", "authors_parsed": [["Kayi", "Efsun Sarioglu", ""], ["Yadav", "Kabir", ""], ["Chamberlain", "James M.", ""], ["Choi", "Hyeong-Ah", ""]]}, {"id": "1706.06197", "submitter": "Xu Sun", "authors": "Xu Sun, Xuancheng Ren, Shuming Ma, Houfeng Wang", "title": "meProp: Sparsified Back Propagation for Accelerated Deep Learning with\n  Reduced Overfitting", "comments": "Accepted by the 34th International Conference on Machine Learning\n  (ICML 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple yet effective technique for neural network learning. The\nforward propagation is computed as usual. In back propagation, only a small\nsubset of the full gradient is computed to update the model parameters. The\ngradient vectors are sparsified in such a way that only the top-$k$ elements\n(in terms of magnitude) are kept. As a result, only $k$ rows or columns\n(depending on the layout) of the weight matrix are modified, leading to a\nlinear reduction ($k$ divided by the vector dimension) in the computational\ncost. Surprisingly, experimental results demonstrate that we can update only\n1-4% of the weights at each back propagation pass. This does not result in a\nlarger number of training iterations. More interestingly, the accuracy of the\nresulting models is actually improved rather than degraded, and a detailed\nanalysis is given. The code is available at https://github.com/lancopku/meProp\n", "versions": [{"version": "v1", "created": "Mon, 19 Jun 2017 22:36:33 GMT"}, {"version": "v2", "created": "Wed, 5 Jul 2017 01:34:50 GMT"}, {"version": "v3", "created": "Mon, 30 Oct 2017 09:48:41 GMT"}, {"version": "v4", "created": "Tue, 31 Oct 2017 02:04:52 GMT"}, {"version": "v5", "created": "Mon, 11 Mar 2019 02:57:03 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Sun", "Xu", ""], ["Ren", "Xuancheng", ""], ["Ma", "Shuming", ""], ["Wang", "Houfeng", ""]]}, {"id": "1706.06210", "submitter": "Pawe{\\l} Budzianowski", "authors": "Pawe{\\l} Budzianowski, Stefan Ultes, Pei-Hao Su, Nikola Mrk\\v{s}i\\'c,\n  Tsung-Hsien Wen, I\\~nigo Casanueva, Lina Rojas-Barahona, Milica Ga\\v{s}i\\'c", "title": "Sub-domain Modelling for Dialogue Management with Hierarchical\n  Reinforcement Learning", "comments": "Update of the section 4 and the bibliography", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human conversation is inherently complex, often spanning many different\ntopics/domains. This makes policy learning for dialogue systems very\nchallenging. Standard flat reinforcement learning methods do not provide an\nefficient framework for modelling such dialogues. In this paper, we focus on\nthe under-explored problem of multi-domain dialogue management. First, we\npropose a new method for hierarchical reinforcement learning using the option\nframework. Next, we show that the proposed architecture learns faster and\narrives at a better policy than the existing flat ones do. Moreover, we show\nhow pretrained policies can be adapted to more complex systems with an\nadditional set of new actions. In doing that, we show that our approach has the\npotential to facilitate policy optimisation for more sophisticated multi-domain\ndialogue systems.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jun 2017 23:15:22 GMT"}, {"version": "v2", "created": "Mon, 17 Jul 2017 13:01:09 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Budzianowski", "Pawe\u0142", ""], ["Ultes", "Stefan", ""], ["Su", "Pei-Hao", ""], ["Mrk\u0161i\u0107", "Nikola", ""], ["Wen", "Tsung-Hsien", ""], ["Casanueva", "I\u00f1igo", ""], ["Rojas-Barahona", "Lina", ""], ["Ga\u0161i\u0107", "Milica", ""]]}, {"id": "1706.06363", "submitter": "Krzysztof Wr\\'obel", "authors": "Krzysztof Wr\\'obel, Maciej Wielgosz, Marcin Pietro\\'n, Micha{\\l}\n  Karwatowski, Aleksander Smywi\\'nski-Pohl", "title": "Improving text classification with vectors of reduced precision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the analysis of the impact of a floating-point number\nprecision reduction on the quality of text classification. The precision\nreduction of the vectors representing the data (e.g. TF-IDF representation in\nour case) allows for a decrease of computing time and memory footprint on\ndedicated hardware platforms. The impact of precision reduction on the\nclassification quality was performed on 5 corpora, using 4 different\nclassifiers. Also, dimensionality reduction was taken into account. Results\nindicate that the precision reduction improves classification accuracy for most\ncases (up to 25% of error reduction). In general, the reduction from 64 to 4\nbits gives the best scores and ensures that the results will not be worse than\nwith the full floating-point representation.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 11:13:06 GMT"}], "update_date": "2017-06-21", "authors_parsed": [["Wr\u00f3bel", "Krzysztof", ""], ["Wielgosz", "Maciej", ""], ["Pietro\u0144", "Marcin", ""], ["Karwatowski", "Micha\u0142", ""], ["Smywi\u0144ski-Pohl", "Aleksander", ""]]}, {"id": "1706.06415", "submitter": "Yang Liu", "authors": "Jiacheng Zhang, Yanzhuo Ding, Shiqi Shen, Yong Cheng, Maosong Sun,\n  Huanbo Luan, Yang Liu", "title": "THUMT: An Open Source Toolkit for Neural Machine Translation", "comments": "4 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces THUMT, an open-source toolkit for neural machine\ntranslation (NMT) developed by the Natural Language Processing Group at\nTsinghua University. THUMT implements the standard attention-based\nencoder-decoder framework on top of Theano and supports three training\ncriteria: maximum likelihood estimation, minimum risk training, and\nsemi-supervised training. It features a visualization tool for displaying the\nrelevance between hidden states in neural networks and contextual words, which\nhelps to analyze the internal workings of NMT. Experiments on Chinese-English\ndatasets show that THUMT using minimum risk training significantly outperforms\nGroundHog, a state-of-the-art toolkit for NMT.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 13:29:16 GMT"}], "update_date": "2017-06-21", "authors_parsed": [["Zhang", "Jiacheng", ""], ["Ding", "Yanzhuo", ""], ["Shen", "Shiqi", ""], ["Cheng", "Yong", ""], ["Sun", "Maosong", ""], ["Luan", "Huanbo", ""], ["Liu", "Yang", ""]]}, {"id": "1706.06428", "submitter": "Chung-Cheng Chiu", "authors": "Chung-Cheng Chiu, Dieterich Lawson, Yuping Luo, George Tucker, Kevin\n  Swersky, Ilya Sutskever, Navdeep Jaitly", "title": "An online sequence-to-sequence model for noisy speech recognition", "comments": "arXiv admin note: substantial text overlap with arXiv:1608.01281", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models have long been the dominant approach for speech\nrecognition. The success of these models however relies on the use of\nsophisticated recipes and complicated machinery that is not easily accessible\nto non-practitioners. Recent innovations in Deep Learning have given rise to an\nalternative - discriminative models called Sequence-to-Sequence models, that\ncan almost match the accuracy of state of the art generative models. While\nthese models are easy to train as they can be trained end-to-end in a single\nstep, they have a practical limitation that they can only be used for offline\nrecognition. This is because the models require that the entirety of the input\nsequence be available at the beginning of inference, an assumption that is not\nvalid for instantaneous speech recognition. To address this problem, online\nsequence-to-sequence models were recently introduced. These models are able to\nstart producing outputs as data arrives, and the model feels confident enough\nto output partial transcripts. These models, like sequence-to-sequence are\ncausal - the output produced by the model until any time, $t$, affects the\nfeatures that are computed subsequently. This makes the model inherently more\npowerful than generative models that are unable to change features that are\ncomputed from the data. This paper highlights two main contributions - an\nimprovement to online sequence-to-sequence model training, and its application\nto noisy settings with mixed speech from two speakers.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jun 2017 20:58:43 GMT"}], "update_date": "2017-06-21", "authors_parsed": [["Chiu", "Chung-Cheng", ""], ["Lawson", "Dieterich", ""], ["Luo", "Yuping", ""], ["Tucker", "George", ""], ["Swersky", "Kevin", ""], ["Sutskever", "Ilya", ""], ["Jaitly", "Navdeep", ""]]}, {"id": "1706.06542", "submitter": "Mir Tafseer Nayeem", "authors": "Mir Tafseer Nayeem, Yllias Chali", "title": "Extract with Order for Coherent Multi-Document Summarization", "comments": "TextGraphs-11 at ACL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we aim at developing an extractive summarizer in the\nmulti-document setting. We implement a rank based sentence selection using\ncontinuous vector representations along with key-phrases. Furthermore, we\npropose a model to tackle summary coherence for increasing readability. We\nconduct experiments on the Document Understanding Conference (DUC) 2004\ndatasets using ROUGE toolkit. Our experiments demonstrate that the methods\nbring significant improvements over the state of the art methods in terms of\ninformativity and coherence.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 04:54:41 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 15:25:52 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Nayeem", "Mir Tafseer", ""], ["Chali", "Yllias", ""]]}, {"id": "1706.06551", "submitter": "Karl Moritz Hermann", "authors": "Karl Moritz Hermann, Felix Hill, Simon Green, Fumin Wang, Ryan\n  Faulkner, Hubert Soyer, David Szepesvari, Wojciech Marian Czarnecki, Max\n  Jaderberg, Denis Teplyashin, Marcus Wainwright, Chris Apps, Demis Hassabis,\n  Phil Blunsom", "title": "Grounded Language Learning in a Simulated 3D World", "comments": "16 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are increasingly surrounded by artificially intelligent technology that\ntakes decisions and executes actions on our behalf. This creates a pressing\nneed for general means to communicate with, instruct and guide artificial\nagents, with human language the most compelling means for such communication.\nTo achieve this in a scalable fashion, agents must be able to relate language\nto the world and to actions; that is, their understanding of language must be\ngrounded and embodied. However, learning grounded language is a notoriously\nchallenging problem in artificial intelligence research. Here we present an\nagent that learns to interpret language in a simulated 3D environment where it\nis rewarded for the successful execution of written instructions. Trained via a\ncombination of reinforcement and unsupervised learning, and beginning with\nminimal prior knowledge, the agent learns to relate linguistic symbols to\nemergent perceptual representations of its physical surroundings and to\npertinent sequences of actions. The agent's comprehension of language extends\nbeyond its prior experience, enabling it to apply familiar language to\nunfamiliar situations and to interpret entirely novel instructions. Moreover,\nthe speed with which this agent learns new words increases as its semantic\nknowledge grows. This facility for generalising and bootstrapping semantic\nknowledge indicates the potential of the present approach for reconciling\nambiguous natural language with the complexity of the physical world.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 17:09:29 GMT"}, {"version": "v2", "created": "Mon, 26 Jun 2017 09:47:36 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Hermann", "Karl Moritz", ""], ["Hill", "Felix", ""], ["Green", "Simon", ""], ["Wang", "Fumin", ""], ["Faulkner", "Ryan", ""], ["Soyer", "Hubert", ""], ["Szepesvari", "David", ""], ["Czarnecki", "Wojciech Marian", ""], ["Jaderberg", "Max", ""], ["Teplyashin", "Denis", ""], ["Wainwright", "Marcus", ""], ["Apps", "Chris", ""], ["Hassabis", "Demis", ""], ["Blunsom", "Phil", ""]]}, {"id": "1706.06613", "submitter": "Chenyan Xiong", "authors": "Chenyan Xiong, Zhuyun Dai, Jamie Callan, Zhiyuan Liu, and Russell\n  Power", "title": "End-to-End Neural Ad-hoc Ranking with Kernel Pooling", "comments": null, "journal-ref": null, "doi": "10.1145/3077136.3080809", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes K-NRM, a kernel based neural model for document ranking.\nGiven a query and a set of documents, K-NRM uses a translation matrix that\nmodels word-level similarities via word embeddings, a new kernel-pooling\ntechnique that uses kernels to extract multi-level soft match features, and a\nlearning-to-rank layer that combines those features into the final ranking\nscore. The whole model is trained end-to-end. The ranking layer learns desired\nfeature patterns from the pairwise ranking loss. The kernels transfer the\nfeature patterns into soft-match targets at each similarity level and enforce\nthem on the translation matrix. The word embeddings are tuned accordingly so\nthat they can produce the desired soft matches. Experiments on a commercial\nsearch engine's query log demonstrate the improvements of K-NRM over prior\nfeature-based and neural-based states-of-the-art, and explain the source of\nK-NRM's advantage: Its kernel-guided embedding encodes a similarity metric\ntailored for matching query words to document words, and provides effective\nmulti-level soft matches.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 18:19:54 GMT"}], "update_date": "2017-06-22", "authors_parsed": [["Xiong", "Chenyan", ""], ["Dai", "Zhuyun", ""], ["Callan", "Jamie", ""], ["Liu", "Zhiyuan", ""], ["Power", "Russell", ""]]}, {"id": "1706.06681", "submitter": "Michihiro Yasunaga", "authors": "Michihiro Yasunaga, Rui Zhang, Kshitijh Meelu, Ayush Pareek, Krishnan\n  Srinivasan and Dragomir Radev", "title": "Graph-based Neural Multi-Document Summarization", "comments": "In CoNLL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a neural multi-document summarization (MDS) system that\nincorporates sentence relation graphs. We employ a Graph Convolutional Network\n(GCN) on the relation graphs, with sentence embeddings obtained from Recurrent\nNeural Networks as input node features. Through multiple layer-wise\npropagation, the GCN generates high-level hidden sentence features for salience\nestimation. We then use a greedy heuristic to extract salient sentences while\navoiding redundancy. In our experiments on DUC 2004, we consider three types of\nsentence relation graphs and demonstrate the advantage of combining sentence\nrelations in graphs with the representation power of deep neural networks. Our\nmodel improves upon traditional graph-based extractive approaches and the\nvanilla GRU sequence model with no graph, and it achieves competitive results\nagainst other state-of-the-art multi-document summarization systems.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 22:12:14 GMT"}, {"version": "v2", "created": "Wed, 19 Jul 2017 01:11:00 GMT"}, {"version": "v3", "created": "Wed, 23 Aug 2017 08:46:52 GMT"}], "update_date": "2017-08-24", "authors_parsed": [["Yasunaga", "Michihiro", ""], ["Zhang", "Rui", ""], ["Meelu", "Kshitijh", ""], ["Pareek", "Ayush", ""], ["Srinivasan", "Krishnan", ""], ["Radev", "Dragomir", ""]]}, {"id": "1706.06714", "submitter": "Van-Khanh Tran", "authors": "Van-Khanh Tran and Le-Minh Nguyen", "title": "Neural-based Natural Language Generation in Dialogue using RNN\n  Encoder-Decoder with Semantic Aggregation", "comments": "To be appear at SIGDIAL 2017. arXiv admin note: text overlap with\n  arXiv:1706.00134, arXiv:1706.00139", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language generation (NLG) is an important component in spoken\ndialogue systems. This paper presents a model called Encoder-Aggregator-Decoder\nwhich is an extension of an Recurrent Neural Network based Encoder-Decoder\narchitecture. The proposed Semantic Aggregator consists of two components: an\nAligner and a Refiner. The Aligner is a conventional attention calculated over\nthe encoded input information, while the Refiner is another attention or gating\nmechanism stacked over the attentive Aligner in order to further select and\naggregate the semantic elements. The proposed model can be jointly trained both\nsentence planning and surface realization to produce natural language\nutterances. The model was extensively assessed on four different NLG domains,\nin which the experimental results showed that the proposed generator\nconsistently outperforms the previous methods on all the NLG domains.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jun 2017 01:07:02 GMT"}, {"version": "v2", "created": "Sun, 25 Jun 2017 09:31:34 GMT"}, {"version": "v3", "created": "Tue, 11 Jul 2017 14:47:13 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Tran", "Van-Khanh", ""], ["Nguyen", "Le-Minh", ""]]}, {"id": "1706.06749", "submitter": "Preslav Nakov", "authors": "Shafiq Joty, Preslav Nakov, Llu\\'is M\\`arquez and Israa Jaradat", "title": "Cross-language Learning with Adversarial Neural Networks: Application to\n  Community Question Answering", "comments": "CoNLL-2017: The SIGNLL Conference on Computational Natural Language\n  Learning; cross-language adversarial neural network (CLANN) model;\n  adversarial training; cross-language adaptation; community question\n  answering; question-question similarity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of cross-language adaptation for question-question\nsimilarity reranking in community question answering, with the objective to\nport a system trained on one input language to another input language given\nlabeled training data for the first language and only unlabeled data for the\nsecond language. In particular, we propose to use adversarial training of\nneural networks to learn high-level features that are discriminative for the\nmain learning task, and at the same time are invariant across the input\nlanguages. The evaluation results show sizable improvements for our\ncross-language adversarial neural network (CLANN) model over a strong\nnon-adversarial system.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jun 2017 06:11:59 GMT"}], "update_date": "2017-06-22", "authors_parsed": [["Joty", "Shafiq", ""], ["Nakov", "Preslav", ""], ["M\u00e0rquez", "Llu\u00eds", ""], ["Jaradat", "Israa", ""]]}, {"id": "1706.06802", "submitter": "Alejandro Moreo Fern\\'andez", "authors": "Andrea Esuli, Tiziano Fagni, Alejandro Moreo Fernandez", "title": "JaTeCS an open-source JAva TExt Categorization System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  JaTeCS is an open source Java library that supports research on automatic\ntext categorization and other related problems, such as ordinal regression and\nquantification, which are of special interest in opinion mining applications.\nIt covers all the steps of an experimental activity, from reading the corpus to\nthe evaluation of the experimental results. As JaTeCS is focused on text as the\nmain input data, it provides the user with many text-dedicated tools, e.g.:\ndata readers for many formats, including the most commonly used text corpora\nand lexical resources, natural language processing tools, multi-language\nsupport, methods for feature selection and weighting, the implementation of\nmany machine learning algorithms as well as wrappers for well-known external\nsoftware (e.g., SVM_light) which enable their full control from code. JaTeCS\nsupport its expansion by abstracting through interfaces many of the typical\ntools and procedures used in text processing tasks. The library also provides a\nnumber of \"template\" implementations of typical experimental setups (e.g.,\ntrain-test, k-fold validation, grid-search optimization, randomized runs) which\nenable fast realization of experiments just by connecting the templates with\ndata readers, learning algorithms and evaluation measures.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jun 2017 09:14:02 GMT"}], "update_date": "2017-06-22", "authors_parsed": [["Esuli", "Andrea", ""], ["Fagni", "Tiziano", ""], ["Fernandez", "Alejandro Moreo", ""]]}, {"id": "1706.06894", "submitter": "Dilek K\\\"u\\c{c}\\\"uk", "authors": "Dilek K\\\"u\\c{c}\\\"uk", "title": "Stance Detection in Turkish Tweets", "comments": "Accepted to be presented at the 3rd International Workshop on Social\n  Media World Sensors (SIDEWAYS) of the 28th ACM Conference on Hypertext and\n  Social Media (2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stance detection is a classification problem in natural language processing\nwhere for a text and target pair, a class result from the set {Favor, Against,\nNeither} is expected. It is similar to the sentiment analysis problem but\ninstead of the sentiment of the text author, the stance expressed for a\nparticular target is investigated in stance detection. In this paper, we\npresent a stance detection tweet data set for Turkish comprising stance\nannotations of these tweets for two popular sports clubs as targets.\nAdditionally, we provide the evaluation results of SVM classifiers for each\ntarget on this data set, where the classifiers use unigram, bigram, and hashtag\nfeatures. This study is significant as it presents one of the initial stance\ndetection data sets proposed so far and the first one for Turkish language, to\nthe best of our knowledge. The data set and the evaluation results of the\ncorresponding SVM-based approaches will form plausible baselines for the\ncomparison of future studies on stance detection.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jun 2017 13:32:21 GMT"}], "update_date": "2017-06-22", "authors_parsed": [["K\u00fc\u00e7\u00fck", "Dilek", ""]]}, {"id": "1706.06896", "submitter": "Marco Dinarelli", "authors": "Marco Dinarelli, Yoann Dupont, Isabelle Tellier", "title": "Effective Spoken Language Labeling with Deep Recurrent Neural Networks", "comments": "8 pages. Rejected from IJCAI 2017, good remarks overall, but slightly\n  off-topic as from global meta-reviews. Recommendations: 8, 6, 6, 4. arXiv\n  admin note: text overlap with arXiv:1706.01740", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding spoken language is a highly complex problem, which can be\ndecomposed into several simpler tasks. In this paper, we focus on Spoken\nLanguage Understanding (SLU), the module of spoken dialog systems responsible\nfor extracting a semantic interpretation from the user utterance. The task is\ntreated as a labeling problem. In the past, SLU has been performed with a wide\nvariety of probabilistic models. The rise of neural networks, in the last\ncouple of years, has opened new interesting research directions in this domain.\nRecurrent Neural Networks (RNNs) in particular are able not only to represent\nseveral pieces of information as embeddings but also, thanks to their recurrent\narchitecture, to encode as embeddings relatively long contexts. Such long\ncontexts are in general out of reach for models previously used for SLU. In\nthis paper we propose novel RNNs architectures for SLU which outperform\nprevious ones. Starting from a published idea as base block, we design new deep\nRNNs achieving state-of-the-art results on two widely used corpora for SLU:\nATIS (Air Traveling Information System), in English, and MEDIA (Hotel\ninformation and reservation in France), in French.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 09:44:52 GMT"}], "update_date": "2017-06-22", "authors_parsed": [["Dinarelli", "Marco", ""], ["Dupont", "Yoann", ""], ["Tellier", "Isabelle", ""]]}, {"id": "1706.06987", "submitter": "Hannah Morrison", "authors": "Hannah Morrison, Chris Martens", "title": "A Generative Model of Group Conversation", "comments": "Accepted submission for the Workshop on Non-Player Characters and\n  Social Believability in Games at FDG 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversations with non-player characters (NPCs) in games are typically\nconfined to dialogue between a human player and a virtual agent, where the\nconversation is initiated and controlled by the player. To create richer, more\nbelievable environments for players, we need conversational behavior to reflect\ninitiative on the part of the NPCs, including conversations that include\nmultiple NPCs who interact with one another as well as the player. We describe\na generative computational model of group conversation between agents, an\nabstract simulation of discussion in a small group setting. We define\nconversational interactions in terms of rules for turn taking and interruption,\nas well as belief change, sentiment change, and emotional response, all of\nwhich are dependent on agent personality, context, and relationships. We\nevaluate our model using a parameterized expressive range analysis, observing\ncorrelations between simulation parameters and features of the resulting\nconversations. This analysis confirms, for example, that character\npersonalities will predict how often they speak, and that heterogeneous groups\nof characters will generate more belief change.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jun 2017 16:19:59 GMT"}], "update_date": "2017-06-22", "authors_parsed": [["Morrison", "Hannah", ""], ["Martens", "Chris", ""]]}, {"id": "1706.06996", "submitter": "Nicolas Pr\\\"ollochs", "authors": "Nicolas Pr\\\"ollochs, Stefan Feuerriegel, Dirk Neumann", "title": "Statistical Inferences for Polarity Identification in Natural Language", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0209323", "report-no": null, "categories": "cs.CL stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information forms the basis for all human behavior, including the ubiquitous\ndecision-making that people constantly perform in their every day lives. It is\nthus the mission of researchers to understand how humans process information to\nreach decisions. In order to facilitate this task, this work proposes a novel\nmethod of studying the reception of granular expressions in natural language.\nThe approach utilizes LASSO regularization as a statistical tool to extract\ndecisive words from textual content and draw statistical inferences based on\nthe correspondence between the occurrences of words and an exogenous response\nvariable. Accordingly, the method immediately suggests significant implications\nfor social sciences and Information Systems research: everyone can now identify\ntext segments and word choices that are statistically relevant to authors or\nreaders and, based on this knowledge, test hypotheses from behavioral research.\nWe demonstrate the contribution of our method by examining how authors\ncommunicate subjective information through narrative materials. This allows us\nto answer the question of which words to choose when communicating negative\ninformation. On the other hand, we show that investors trade not only upon\nfacts in financial disclosures but are distracted by filler words and\nnon-informative language. Practitioners - for example those in the fields of\ninvestor communications or marketing - can exploit our insights to enhance\ntheir writings based on the true perception of word choice.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jun 2017 16:37:54 GMT"}, {"version": "v2", "created": "Thu, 5 Apr 2018 23:45:33 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Pr\u00f6llochs", "Nicolas", ""], ["Feuerriegel", "Stefan", ""], ["Neumann", "Dirk", ""]]}, {"id": "1706.07179", "submitter": "Trapit Bansal", "authors": "Trapit Bansal, Arvind Neelakantan, Andrew McCallum", "title": "RelNet: End-to-End Modeling of Entities & Relations", "comments": "Accepted in AKBC 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce RelNet: a new model for relational reasoning. RelNet is a memory\naugmented neural network which models entities as abstract memory slots and is\nequipped with an additional relational memory which models relations between\nall memory pairs. The model thus builds an abstract knowledge graph on the\nentities and relations present in a document which can then be used to answer\nquestions about the document. It is trained end-to-end: only supervision to the\nmodel is in the form of correct answers to the questions. We test the model on\nthe 20 bAbI question-answering tasks with 10k examples per task and find that\nit solves all the tasks with a mean error of 0.3%, achieving 0% error on 11 of\nthe 20 tasks.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jun 2017 06:59:07 GMT"}, {"version": "v2", "created": "Thu, 16 Nov 2017 02:39:58 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Bansal", "Trapit", ""], ["Neelakantan", "Arvind", ""], ["McCallum", "Andrew", ""]]}, {"id": "1706.07206", "submitter": "Wojciech Samek", "authors": "Leila Arras, Gr\\'egoire Montavon, Klaus-Robert M\\\"uller, Wojciech\n  Samek", "title": "Explaining Recurrent Neural Network Predictions in Sentiment Analysis", "comments": "9 pages, 4 figures, accepted for EMNLP'17 Workshop on Computational\n  Approaches to Subjectivity, Sentiment & Social Media Analysis (WASSA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a technique called Layer-wise Relevance Propagation (LRP) was shown\nto deliver insightful explanations in the form of input space relevances for\nunderstanding feed-forward neural network classification decisions. In the\npresent work, we extend the usage of LRP to recurrent neural networks. We\npropose a specific propagation rule applicable to multiplicative connections as\nthey arise in recurrent network architectures such as LSTMs and GRUs. We apply\nour technique to a word-based bi-directional LSTM model on a five-class\nsentiment prediction task, and evaluate the resulting LRP relevances both\nqualitatively and quantitatively, obtaining better results than a\ngradient-based related method which was used in previous work.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jun 2017 08:24:59 GMT"}, {"version": "v2", "created": "Fri, 4 Aug 2017 20:01:33 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Arras", "Leila", ""], ["Montavon", "Gr\u00e9goire", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Samek", "Wojciech", ""]]}, {"id": "1706.07230", "submitter": "Devendra Singh Chaplot", "authors": "Devendra Singh Chaplot, Kanthashree Mysore Sathyendra, Rama Kumar\n  Pasumarthi, Dheeraj Rajagopal, Ruslan Salakhutdinov", "title": "Gated-Attention Architectures for Task-Oriented Language Grounding", "comments": "To appear in AAAI-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To perform tasks specified by natural language instructions, autonomous\nagents need to extract semantically meaningful representations of language and\nmap it to visual elements and actions in the environment. This problem is\ncalled task-oriented language grounding. We propose an end-to-end trainable\nneural architecture for task-oriented language grounding in 3D environments\nwhich assumes no prior linguistic or perceptual knowledge and requires only raw\npixels from the environment and the natural language instruction as input. The\nproposed model combines the image and text representations using a\nGated-Attention mechanism and learns a policy to execute the natural language\ninstruction using standard reinforcement and imitation learning methods. We\nshow the effectiveness of the proposed model on unseen instructions as well as\nunseen maps, both quantitatively and qualitatively. We also introduce a novel\nenvironment based on a 3D game engine to simulate the challenges of\ntask-oriented language grounding over a rich set of instructions and\nenvironment states.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jun 2017 09:39:17 GMT"}, {"version": "v2", "created": "Tue, 9 Jan 2018 03:24:06 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["Chaplot", "Devendra Singh", ""], ["Sathyendra", "Kanthashree Mysore", ""], ["Pasumarthi", "Rama Kumar", ""], ["Rajagopal", "Dheeraj", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1706.07238", "submitter": "Daniele Falavigna", "authors": "Shahab Jalalvand and Matteo Negri and Daniele Falavigna and Marco\n  Matassoni and Marco Turchi", "title": "Automatic Quality Estimation for ASR System Combination", "comments": null, "journal-ref": null, "doi": "10.1016/j.csl.2017.06.003", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizer Output Voting Error Reduction (ROVER) has been widely used for\nsystem combination in automatic speech recognition (ASR). In order to select\nthe most appropriate words to insert at each position in the output\ntranscriptions, some ROVER extensions rely on critical information such as\nconfidence scores and other ASR decoder features. This information, which is\nnot always available, highly depends on the decoding process and sometimes\ntends to over estimate the real quality of the recognized words. In this paper\nwe propose a novel variant of ROVER that takes advantage of ASR quality\nestimation (QE) for ranking the transcriptions at \"segment level\" instead of:\ni) relying on confidence scores, or ii) feeding ROVER with randomly ordered\nhypotheses. We first introduce an effective set of features to compensate for\nthe absence of ASR decoder information. Then, we apply QE techniques to perform\naccurate hypothesis ranking at segment-level before starting the fusion\nprocess. The evaluation is carried out on two different tasks, in which we\nrespectively combine hypotheses coming from independent ASR systems and\nmulti-microphone recordings. In both tasks, it is assumed that the ASR decoder\ninformation is not available. The proposed approach significantly outperforms\nstandard ROVER and it is competitive with two strong oracles that e xploit\nprior knowledge about the real quality of the hypotheses to be combined.\nCompared to standard ROVER, the abs olute WER improvements in the two\nevaluation scenarios range from 0.5% to 7.3%.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jun 2017 10:11:34 GMT"}], "update_date": "2017-06-23", "authors_parsed": [["Jalalvand", "Shahab", ""], ["Negri", "Matteo", ""], ["Falavigna", "Daniele", ""], ["Matassoni", "Marco", ""], ["Turchi", "Marco", ""]]}, {"id": "1706.07276", "submitter": "Bei Shi", "authors": "Bei Shi, Wai Lam, Shoaib Jameel, Steven Schockaert, Kwun Ping Lai", "title": "Jointly Learning Word Embeddings and Latent Topics", "comments": "10 pagess, 2 figures, full paper. To appear in the proceedings of The\n  40th International ACM SIGIR Conference on Research and Development in\n  Information Retrieval (SIGIR '17)", "journal-ref": null, "doi": "10.1145/3077136.3080806", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embedding models such as Skip-gram learn a vector-space representation\nfor each word, based on the local word collocation patterns that are observed\nin a text corpus. Latent topic models, on the other hand, take a more global\nview, looking at the word distributions across the corpus to assign a topic to\neach word occurrence. These two paradigms are complementary in how they\nrepresent the meaning of word occurrences. While some previous works have\nalready looked at using word embeddings for improving the quality of latent\ntopics, and conversely, at using latent topics for improving word embeddings,\nsuch \"two-step\" methods cannot capture the mutual interaction between the two\nparadigms. In this paper, we propose STE, a framework which can learn word\nembeddings and latent topics in a unified manner. STE naturally obtains\ntopic-specific word embeddings, and thus addresses the issue of polysemy. At\nthe same time, it also learns the term distributions of the topics, and the\ntopic distributions of the documents. Our experimental results demonstrate that\nthe STE model can indeed generate useful topic-specific word embeddings and\ncoherent latent topics in an effective and efficient way.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jun 2017 06:19:24 GMT"}], "update_date": "2017-06-23", "authors_parsed": [["Shi", "Bei", ""], ["Lam", "Wai", ""], ["Jameel", "Shoaib", ""], ["Schockaert", "Steven", ""], ["Lai", "Kwun Ping", ""]]}, {"id": "1706.07440", "submitter": "Chiori Hori Dr.", "authors": "Chiori Hori, Takaaki Hori", "title": "End-to-end Conversation Modeling Track in DSTC6", "comments": "Spoken dialog systems, End-to-End, conversation modeling, DSTC, DSTC6", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end training of neural networks is a promising approach to automatic\nconstruction of dialog systems using a human-to-human dialog corpus. Recently,\nVinyals et al. tested neural conversation models using OpenSubtitles. Lowe et\nal. released the Ubuntu Dialogue Corpus for researching unstructured multi-turn\ndialogue systems. Furthermore, the approach has been extended to accomplish\ntask oriented dialogs to provide information properly with natural\nconversation. For example, Ghazvininejad et al. proposed a knowledge grounded\nneural conversation model [3], where the research is aiming at combining\nconversational dialogs with task-oriented knowledge using unstructured data\nsuch as Twitter data for conversation and Foursquare data for external\nknowledge.However, the task is still limited to a restaurant information\nservice, and has not yet been tested with a wide variety of dialog tasks. In\naddition, it is still unclear how to create intelligent dialog systems that can\nrespond like a human agent.\n  In consideration of these problems, we proposed a challenge track to the 6th\ndialog system technology challenges (DSTC6) using human-to-human dialog data to\nmimic human dialog behaviors. The focus of the challenge track is to train\nend-to-end conversation models from human-to-human conversation and accomplish\nend-to-end dialog tasks in various situations assuming a customer service, in\nwhich a system plays a role of human agent and generates natural and\ninformative sentences in response to user's questions or comments given dialog\ncontext.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jun 2017 18:00:34 GMT"}, {"version": "v2", "created": "Tue, 30 Jan 2018 17:33:49 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Hori", "Chiori", ""], ["Hori", "Takaaki", ""]]}, {"id": "1706.07503", "submitter": "Chaitanya K. Joshi", "authors": "Chaitanya K. Joshi, Fei Mi and Boi Faltings", "title": "Personalization in Goal-Oriented Dialog", "comments": "Accepted at NIPS 2017 Conversational AI Workshop; Code and data at\n  https://github.com/chaitjo/personalized-dialog", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main goal of modeling human conversation is to create agents which can\ninteract with people in both open-ended and goal-oriented scenarios. End-to-end\ntrained neural dialog systems are an important line of research for such\ngeneralized dialog models as they do not resort to any situation-specific\nhandcrafting of rules. However, incorporating personalization into such systems\nis a largely unexplored topic as there are no existing corpora to facilitate\nsuch work. In this paper, we present a new dataset of goal-oriented dialogs\nwhich are influenced by speaker profiles attached to them. We analyze the\nshortcomings of an existing end-to-end dialog system based on Memory Networks\nand propose modifications to the architecture which enable personalization. We\nalso investigate personalization in dialog as a multi-task learning problem,\nand show that a single model which shares features among various profiles\noutperforms separate models for each profile.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jun 2017 22:09:14 GMT"}, {"version": "v2", "created": "Tue, 31 Oct 2017 11:19:48 GMT"}, {"version": "v3", "created": "Fri, 15 Dec 2017 06:28:24 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Joshi", "Chaitanya K.", ""], ["Mi", "Fei", ""], ["Faltings", "Boi", ""]]}, {"id": "1706.07518", "submitter": "Jiatao Gu", "authors": "Jiatao Gu, Daniel Jiwoong Im and Victor O.K. Li", "title": "Neural Machine Translation with Gumbel-Greedy Decoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous neural machine translation models used some heuristic search\nalgorithms (e.g., beam search) in order to avoid solving the maximum a\nposteriori problem over translation sentences at test time. In this paper, we\npropose the Gumbel-Greedy Decoding which trains a generative network to predict\ntranslation under a trained model. We solve such a problem using the\nGumbel-Softmax reparameterization, which makes our generative network\ndifferentiable and trainable through standard stochastic gradient methods. We\nempirically demonstrate that our proposed model is effective for generating\nsequences of discrete words.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jun 2017 22:54:25 GMT"}], "update_date": "2017-06-26", "authors_parsed": [["Gu", "Jiatao", ""], ["Im", "Daniel Jiwoong", ""], ["Li", "Victor O. K.", ""]]}, {"id": "1706.07598", "submitter": "Antonio Jose Jimeno Yepes", "authors": "Quan Tran, Andrew MacKinlay and Antonio Jimeno Yepes", "title": "Named Entity Recognition with stack residual LSTM and trainable bias\n  decoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Network models are the state-of-the-art for Named Entity\nRecognition (NER). We present two innovations to improve the performance of\nthese models. The first innovation is the introduction of residual connections\nbetween the Stacked Recurrent Neural Network model to address the degradation\nproblem of deep neural networks. The second innovation is a bias decoding\nmechanism that allows the trained system to adapt to non-differentiable and\nexternally computed objectives, such as the entity-based F-measure. Our work\nimproves the state-of-the-art results for both Spanish and English languages on\nthe standard train/development/test split of the CoNLL 2003 Shared Task NER\ndataset.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jun 2017 08:33:38 GMT"}, {"version": "v2", "created": "Tue, 11 Jul 2017 11:57:13 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Tran", "Quan", ""], ["MacKinlay", "Andrew", ""], ["Yepes", "Antonio Jimeno", ""]]}, {"id": "1706.07786", "submitter": "Ismail Rusli", "authors": "Ismail Rusli", "title": "Comparison of Modified Kneser-Ney and Witten-Bell Smoothing Techniques\n  in Statistical Language Model of Bahasa Indonesia", "comments": "9 pages, 3 figures, 2nd International Conference on Information and\n  Communication Technology (ICoICT), Bandung, 2014", "journal-ref": null, "doi": "10.1109/ICoICT.2014.6914097", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smoothing is one technique to overcome data sparsity in statistical language\nmodel. Although in its mathematical definition there is no explicit dependency\nupon specific natural language, different natures of natural languages result\nin different effects of smoothing techniques. This is true for Russian language\nas shown by Whittaker (1998). In this paper, We compared Modified Kneser-Ney\nand Witten-Bell smoothing techniques in statistical language model of Bahasa\nIndonesia. We used train sets of totally 22M words that we extracted from\nIndonesian version of Wikipedia. As far as we know, this is the largest train\nset used to build statistical language model for Bahasa Indonesia. The\nexperiments with 3-gram, 5-gram, and 7-gram showed that Modified Kneser-Ney\nconsistently outperforms Witten-Bell smoothing technique in term of perplexity\nvalues. It is interesting to note that our experiments showed 5-gram model for\nModified Kneser-Ney smoothing technique outperforms that of 7-gram. Meanwhile,\nWitten-Bell smoothing is consistently improving over the increase of n-gram\norder.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jun 2017 17:43:20 GMT"}], "update_date": "2017-06-26", "authors_parsed": [["Rusli", "Ismail", ""]]}, {"id": "1706.07859", "submitter": "Lantian Li Mr.", "authors": "Dong Wang and Lantian Li and Zhiyuan Tang and Thomas Fang Zheng", "title": "Deep Speaker Verification: Do We Need End to End?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end learning treats the entire system as a whole adaptable black box,\nwhich, if sufficient data are available, may learn a system that works very\nwell for the target task. This principle has recently been applied to several\nprototype research on speaker verification (SV), where the feature learning and\nclassifier are learned together with an objective function that is consistent\nwith the evaluation metric. An opposite approach to end-to-end is feature\nlearning, which firstly trains a feature learning model, and then constructs a\nback-end classifier separately to perform SV. Recently, both approaches\nachieved significant performance gains on SV, mainly attributed to the smart\nutilization of deep neural networks. However, the two approaches have not been\ncarefully compared, and their respective advantages have not been well\ndiscussed. In this paper, we compare the end-to-end and feature learning\napproaches on a text-independent SV task. Our experiments on a dataset sampled\nfrom the Fisher database and involving 5,000 speakers demonstrated that the\nfeature learning approach outperformed the end-to-end approach. This is a\nstrong support for the feature learning approach, at least with data and\ncomputation resources similar to ours.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jun 2017 04:33:59 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Wang", "Dong", ""], ["Li", "Lantian", ""], ["Tang", "Zhiyuan", ""], ["Zheng", "Thomas Fang", ""]]}, {"id": "1706.07860", "submitter": "Lantian Li Mr.", "authors": "Miao Zhang and Yixiang Chen and Lantian Li and Dong Wang", "title": "Speaker Recognition with Cough, Laugh and \"Wei\"", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a speaker recognition (SRE) task with trivial speech\nevents, such as cough and laugh. These trivial events are ubiquitous in\nconversations and less subjected to intentional change, therefore offering\nvaluable particularities to discover the genuine speaker from disguised speech.\nHowever, trivial events are often short and idiocratic in spectral patterns,\nmaking SRE extremely difficult. Fortunately, we found a very powerful deep\nfeature learning structure that can extract highly speaker-sensitive features.\nBy employing this tool, we studied the SRE performance on three types of\ntrivial events: cough, laugh and \"Wei\" (a short Chinese \"Hello\"). The results\nshow that there is rich speaker information within these trivial events, even\nfor cough that is intuitively less speaker distinguishable. With the deep\nfeature approach, the EER can reach 10%-14% with the three trivial events,\ndespite their extremely short durations (0.2-1.0 seconds).\n", "versions": [{"version": "v1", "created": "Thu, 22 Jun 2017 04:26:39 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Zhang", "Miao", ""], ["Chen", "Yixiang", ""], ["Li", "Lantian", ""], ["Wang", "Dong", ""]]}, {"id": "1706.07861", "submitter": "Lantian Li Mr.", "authors": "Lantian Li and Dong Wang and Askar Rozi and Thomas Fang Zheng", "title": "Cross-lingual Speaker Verification with Deep Feature Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing speaker verification (SV) systems often suffer from performance\ndegradation if there is any language mismatch between model training, speaker\nenrollment, and test. A major cause of this degradation is that most existing\nSV methods rely on a probabilistic model to infer the speaker factor, so any\nsignificant change on the distribution of the speech signal will impact the\ninference. Recently, we proposed a deep learning model that can learn how to\nextract the speaker factor by a deep neural network (DNN). By this feature\nlearning, an SV system can be constructed with a very simple back-end model. In\nthis paper, we investigate the robustness of the feature-based SV system in\nsituations with language mismatch. Our experiments were conducted on a complex\ncross-lingual scenario, where the model training was in English, and the\nenrollment and test were in Chinese or Uyghur. The experiments demonstrated\nthat the feature-based system outperformed the i-vector system with a large\nmargin, particularly with language mismatch between enrollment and test.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jun 2017 04:32:40 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Li", "Lantian", ""], ["Wang", "Dong", ""], ["Rozi", "Askar", ""], ["Zheng", "Thomas Fang", ""]]}, {"id": "1706.07905", "submitter": "Jiangming Liu", "authors": "Jiangming Liu and Yue Zhang", "title": "Encoder-Decoder Shift-Reduce Syntactic Parsing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Starting from NMT, encoder-decoder neu- ral networks have been used for many\nNLP problems. Graph-based models and transition-based models borrowing the en-\ncoder components achieve state-of-the-art performance on dependency parsing and\nconstituent parsing, respectively. How- ever, there has not been work\nempirically studying the encoder-decoder neural net- works for transition-based\nparsing. We apply a simple encoder-decoder to this end, achieving comparable\nresults to the parser of Dyer et al. (2015) on standard de- pendency parsing,\nand outperforming the parser of Vinyals et al. (2015) on con- stituent parsing.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jun 2017 04:08:11 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Liu", "Jiangming", ""], ["Zhang", "Yue", ""]]}, {"id": "1706.07912", "submitter": "Mahamad Suhil", "authors": "Lavanya Narayana Raju, Mahamad Suhil, D S Guru and Harsha S Gowda", "title": "Cluster Based Symbolic Representation for Skewed Text Categorization", "comments": "14 Pages, 15 Figures, 1 Table, Conference: RTIP2R", "journal-ref": null, "doi": "10.1007/978-981-10-4859-3_19", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, a problem associated with imbalanced text corpora is addressed.\nA method of converting an imbalanced text corpus into a balanced one is\npresented. The presented method employs a clustering algorithm for conversion.\nInitially to avoid curse of dimensionality, an effective representation scheme\nbased on term class relevancy measure is adapted, which drastically reduces the\ndimension to the number of classes in the corpus. Subsequently, the samples of\nlarger sized classes are grouped into a number of subclasses of smaller sizes\nto make the entire corpus balanced. Each subclass is then given a single\nsymbolic vector representation by the use of interval valued features. This\nsymbolic representation in addition to being compact helps in reducing the\nspace requirement and also the classification time. The proposed model has been\nempirically demonstrated for its superiority on bench marking datasets viz.,\nReuters 21578 and TDT2. Further, it has been compared against several other\nexisting contemporary models including model based on support vector machine.\nThe comparative analysis indicates that the proposed model outperforms the\nother existing models.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jun 2017 06:04:21 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Raju", "Lavanya Narayana", ""], ["Suhil", "Mahamad", ""], ["Guru", "D S", ""], ["Gowda", "Harsha S", ""]]}, {"id": "1706.07913", "submitter": "Mahamad Suhil", "authors": "Harsha S. Gowda, Mahamad Suhil, D.S. Guru, and Lavanya Narayana Raju", "title": "Semi-supervised Text Categorization Using Recursive K-means Clustering", "comments": "11 Pages, 8 Figures, Conference: RTIP2R", "journal-ref": null, "doi": "10.1007/978-981-10-4859-3_20", "report-no": null, "categories": "cs.LG cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a semi-supervised learning algorithm for\nclassification of text documents. A method of labeling unlabeled text documents\nis presented. The presented method is based on the principle of divide and\nconquer strategy. It uses recursive K-means algorithm for partitioning both\nlabeled and unlabeled data collection. The K-means algorithm is applied\nrecursively on each partition till a desired level partition is achieved such\nthat each partition contains labeled documents of a single class. Once the\ndesired clusters are obtained, the respective cluster centroids are considered\nas representatives of the clusters and the nearest neighbor rule is used for\nclassifying an unknown text document. Series of experiments have been conducted\nto bring out the superiority of the proposed model over other recent state of\nthe art models on 20Newsgroups dataset.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jun 2017 06:08:27 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Gowda", "Harsha S.", ""], ["Suhil", "Mahamad", ""], ["Guru", "D. S.", ""], ["Raju", "Lavanya Narayana", ""]]}, {"id": "1706.08032", "submitter": "Huy Nguyen Thanh", "authors": "Huy Nguyen and Minh-Le Nguyen", "title": "A Deep Neural Architecture for Sentence-level Sentiment Classification\n  in Twitter Social Networking", "comments": "PACLING Conference 2017, 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper introduces a novel deep learning framework including a\nlexicon-based approach for sentence-level prediction of sentiment label\ndistribution. We propose to first apply semantic rules and then use a Deep\nConvolutional Neural Network (DeepCNN) for character-level embeddings in order\nto increase information for word-level embedding. After that, a Bidirectional\nLong Short-Term Memory Network (Bi-LSTM) produces a sentence-wide feature\nrepresentation from the word-level embedding. We evaluate our approach on three\nTwitter sentiment classification datasets. Experimental results show that our\nmodel can improve the classification accuracy of sentence-level sentiment\nanalysis in Twitter social networking.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jun 2017 04:05:09 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Nguyen", "Huy", ""], ["Nguyen", "Minh-Le", ""]]}, {"id": "1706.08160", "submitter": "Shyam Upadhyay", "authors": "Shyam Upadhyay and Kai-Wei Chang and Matt Taddy and Adam Kalai and\n  James Zou", "title": "Beyond Bilingual: Multi-sense Word Embeddings using Multilingual Context", "comments": "ACL 2017 Repl4NLP workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings, which represent a word as a point in a vector space, have\nbecome ubiquitous to several NLP tasks. A recent line of work uses bilingual\n(two languages) corpora to learn a different vector for each sense of a word,\nby exploiting crosslingual signals to aid sense identification. We present a\nmulti-view Bayesian non-parametric algorithm which improves multi-sense word\nembeddings by (a) using multilingual (i.e., more than two languages) corpora to\nsignificantly improve sense embeddings beyond what one achieves with bilingual\ninformation, and (b) uses a principled approach to learn a variable number of\nsenses per word, in a data-driven manner. Ours is the first approach with the\nability to leverage multilingual corpora efficiently for multi-sense\nrepresentation learning. Experiments show that multilingual training\nsignificantly improves performance over monolingual and bilingual training, by\nallowing us to combine different parallel corpora to leverage multilingual\ncontext. Multilingual training yields comparable performance to a state of the\nart mono-lingual model trained on five times more training data.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jun 2017 20:00:54 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Upadhyay", "Shyam", ""], ["Chang", "Kai-Wei", ""], ["Taddy", "Matt", ""], ["Kalai", "Adam", ""], ["Zou", "James", ""]]}, {"id": "1706.08162", "submitter": "Abeed Sarker", "authors": "Abeed Sarker, Diego Molla, Cecile Paris", "title": "Automated text summarisation and evidence-based medicine: A survey of\n  two domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The practice of evidence-based medicine (EBM) urges medical practitioners to\nutilise the latest research evidence when making clinical decisions. Because of\nthe massive and growing volume of published research on various medical topics,\npractitioners often find themselves overloaded with information. As such,\nnatural language processing research has recently commenced exploring\ntechniques for performing medical domain-specific automated text summarisation\n(ATS) techniques-- targeted towards the task of condensing large medical texts.\nHowever, the development of effective summarisation techniques for this task\nrequires cross-domain knowledge. We present a survey of EBM, the\ndomain-specific needs for EBM, automated summarisation techniques, and how they\nhave been applied hitherto. We envision that this survey will serve as a first\nresource for the development of future operational text summarisation\ntechniques for EBM.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jun 2017 20:12:28 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Sarker", "Abeed", ""], ["Molla", "Diego", ""], ["Paris", "Cecile", ""]]}, {"id": "1706.08186", "submitter": "Meng Qu", "authors": "Meng Qu, Xiang Ren, Jiawei Han", "title": "Automatic Synonym Discovery with Knowledge Bases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing entity synonyms from text has become a crucial task in many\nentity-leveraging applications. However, discovering entity synonyms from\ndomain-specific text corpora (e.g., news articles, scientific papers) is rather\nchallenging. Current systems take an entity name string as input to find out\nother names that are synonymous, ignoring the fact that often times a name\nstring can refer to multiple entities (e.g., \"apple\" could refer to both Apple\nInc and the fruit apple). Moreover, most existing methods require training data\nmanually created by domain experts to construct supervised-learning systems. In\nthis paper, we study the problem of automatic synonym discovery with knowledge\nbases, that is, identifying synonyms for knowledge base entities in a given\ndomain-specific corpus. The manually-curated synonyms for each entity stored in\na knowledge base not only form a set of name strings to disambiguate the\nmeaning for each other, but also can serve as \"distant\" supervision to help\ndetermine important features for the task. We propose a novel framework, called\nDPE, to integrate two kinds of mutually-complementing signals for synonym\ndiscovery, i.e., distributional features based on corpus-level statistics and\ntextual patterns based on local contexts. In particular, DPE jointly optimizes\nthe two kinds of signals in conjunction with distant supervision, so that they\ncan mutually enhance each other in the training stage. At the inference stage,\nboth signals will be utilized to discover synonyms for the given entities.\nExperimental results prove the effectiveness of the proposed framework.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jun 2017 23:10:26 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Qu", "Meng", ""], ["Ren", "Xiang", ""], ["Han", "Jiawei", ""]]}, {"id": "1706.08198", "submitter": "Mamoru Komachi", "authors": "Yukio Matsumura, Takayuki Sato, Mamoru Komachi", "title": "English-Japanese Neural Machine Translation with\n  Encoder-Decoder-Reconstructor", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Neural machine translation (NMT) has recently become popular in the field of\nmachine translation. However, NMT suffers from the problem of repeating or\nmissing words in the translation. To address this problem, Tu et al. (2017)\nproposed an encoder-decoder-reconstructor framework for NMT using\nback-translation. In this method, they selected the best forward translation\nmodel in the same manner as Bahdanau et al. (2015), and then trained a\nbi-directional translation model as fine-tuning. Their experiments show that it\noffers significant improvement in BLEU scores in Chinese-English translation\ntask. We confirm that our re-implementation also shows the same tendency and\nalleviates the problem of repeating and missing words in the translation on a\nEnglish-Japanese task too. In addition, we evaluate the effectiveness of\npre-training by comparing it with a jointly-trained model of forward\ntranslation and back-translation.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 00:55:04 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Matsumura", "Yukio", ""], ["Sato", "Takayuki", ""], ["Komachi", "Mamoru", ""]]}, {"id": "1706.08476", "submitter": "Tiancheng Zhao", "authors": "Tiancheng Zhao, Allen Lu, Kyusong Lee and Maxine Eskenazi", "title": "Generative Encoder-Decoder Models for Task-Oriented Spoken Dialog\n  Systems with Chatting Capability", "comments": "Accepted as a long paper in SIGIDIAL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative encoder-decoder models offer great promise in developing\ndomain-general dialog systems. However, they have mainly been applied to\nopen-domain conversations. This paper presents a practical and novel framework\nfor building task-oriented dialog systems based on encoder-decoder models. This\nframework enables encoder-decoder models to accomplish slot-value independent\ndecision-making and interact with external databases. Moreover, this paper\nshows the flexibility of the proposed method by interleaving chatting\ncapability with a slot-filling system for better out-of-domain recovery. The\nmodels were trained on both real-user data from a bus information system and\nhuman-human chat data. Results show that the proposed framework achieves good\nperformance in both offline evaluation metrics and in task success rate with\nhuman users.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 16:52:42 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Zhao", "Tiancheng", ""], ["Lu", "Allen", ""], ["Lee", "Kyusong", ""], ["Eskenazi", "Maxine", ""]]}, {"id": "1706.08502", "submitter": "Satwik Kottur", "authors": "Satwik Kottur, Jos\\'e M.F. Moura, Stefan Lee, Dhruv Batra", "title": "Natural Language Does Not Emerge 'Naturally' in Multi-Agent Dialog", "comments": "9 pages, 7 figures, 2 tables, accepted at EMNLP 2017 as short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of recent works have proposed techniques for end-to-end learning of\ncommunication protocols among cooperative multi-agent populations, and have\nsimultaneously found the emergence of grounded human-interpretable language in\nthe protocols developed by the agents, all learned without any human\nsupervision!\n  In this paper, using a Task and Tell reference game between two agents as a\ntestbed, we present a sequence of 'negative' results culminating in a\n'positive' one -- showing that while most agent-invented languages are\neffective (i.e. achieve near-perfect task rewards), they are decidedly not\ninterpretable or compositional.\n  In essence, we find that natural language does not emerge 'naturally',\ndespite the semblance of ease of natural-language-emergence that one may gather\nfrom recent literature. We discuss how it is possible to coax the invented\nlanguages to become more and more human-like and compositional by increasing\nrestrictions on how two agents may communicate.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 17:47:46 GMT"}, {"version": "v2", "created": "Thu, 3 Aug 2017 03:37:00 GMT"}, {"version": "v3", "created": "Sun, 20 Aug 2017 04:41:15 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Kottur", "Satwik", ""], ["Moura", "Jos\u00e9 M. F.", ""], ["Lee", "Stefan", ""], ["Batra", "Dhruv", ""]]}, {"id": "1706.08568", "submitter": "Georg Wiese", "authors": "Georg Wiese, Dirk Weissenborn, Mariana Neves", "title": "Neural Question Answering at BioASQ 5B", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes our submission to the 2017 BioASQ challenge. We\nparticipated in Task B, Phase B which is concerned with biomedical question\nanswering (QA). We focus on factoid and list question, using an extractive QA\nmodel, that is, we restrict our system to output substrings of the provided\ntext snippets. At the core of our system, we use FastQA, a state-of-the-art\nneural QA system. We extended it with biomedical word embeddings and changed\nits answer layer to be able to answer list questions in addition to factoid\nquestions. We pre-trained the model on a large-scale open-domain QA dataset,\nSQuAD, and then fine-tuned the parameters on the BioASQ training set. With our\napproach, we achieve state-of-the-art results on factoid questions and\ncompetitive results on list questions.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 19:14:10 GMT"}], "update_date": "2017-06-28", "authors_parsed": [["Wiese", "Georg", ""], ["Weissenborn", "Dirk", ""], ["Neves", "Mariana", ""]]}, {"id": "1706.08609", "submitter": "Artemy Kolchinsky", "authors": "Artemy Kolchinsky, Nakul Dhande, Kengjeun Park, Yong-Yeol Ahn", "title": "The Minor Fall, the Major Lift: Inferring Emotional Valence of Musical\n  Chords through Lyrics", "comments": "Royal Society Open Science, 2017", "journal-ref": null, "doi": "10.1098/rsos.150081", "report-no": null, "categories": "cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the association between musical chords and lyrics by analyzing\na large dataset of user-contributed guitar tablatures. Motivated by the idea\nthat the emotional content of chords is reflected in the words used in\ncorresponding lyrics, we analyze associations between lyrics and chord\ncategories. We also examine the usage patterns of chords and lyrics in\ndifferent musical genres, historical eras, and geographical regions. Our\noverall results confirms a previously known association between Major chords\nand positive valence. We also report a wide variation in this association\nacross regions, genres, and eras. Our results suggest possible existence of\ndifferent emotional associations for other types of chords.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 21:34:29 GMT"}, {"version": "v2", "created": "Mon, 4 Dec 2017 05:07:37 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Kolchinsky", "Artemy", ""], ["Dhande", "Nakul", ""], ["Park", "Kengjeun", ""], ["Ahn", "Yong-Yeol", ""]]}, {"id": "1706.08683", "submitter": "Dong Wang", "authors": "Shiyue Zhang and Gulnigar Mahmut and Dong Wang and Askar Hamdulla", "title": "Memory-augmented Chinese-Uyghur Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT) has achieved notable performance recently.\nHowever, this approach has not been widely applied to the translation task\nbetween Chinese and Uyghur, partly due to the limited parallel data resource\nand the large proportion of rare words caused by the agglutinative nature of\nUyghur. In this paper, we collect ~200,000 sentence pairs and show that with\nthis middle-scale database, an attention-based NMT can perform very well on\nChinese-Uyghur/Uyghur-Chinese translation. To tackle rare words, we propose a\nnovel memory structure to assist the NMT inference. Our experiments\ndemonstrated that the memory-augmented NMT (M-NMT) outperforms both the vanilla\nNMT and the phrase-based statistical machine translation (SMT). Interestingly,\nthe memory structure provides an elegant way for dealing with words that are\nout of vocabulary.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jun 2017 06:33:52 GMT"}], "update_date": "2017-06-28", "authors_parsed": [["Zhang", "Shiyue", ""], ["Mahmut", "Gulnigar", ""], ["Wang", "Dong", ""], ["Hamdulla", "Askar", ""]]}, {"id": "1706.08746", "submitter": "Andrew Yates", "authors": "Andrew Yates, Kai Hui", "title": "DE-PACRR: Exploring Layers Inside the PACRR Model", "comments": "Neu-IR 2017 SIGIR Workshop on Neural Information Retrieval", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent neural IR models have demonstrated deep learning's utility in ad-hoc\ninformation retrieval. However, deep models have a reputation for being black\nboxes, and the roles of a neural IR model's components may not be obvious at\nfirst glance. In this work, we attempt to shed light on the inner workings of a\nrecently proposed neural IR model, namely the PACRR model, by visualizing the\noutput of intermediate layers and by investigating the relationship between\nintermediate weights and the ultimate relevance score produced. We highlight\nseveral insights, hoping that such insights will be generally applicable.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jun 2017 09:23:37 GMT"}, {"version": "v2", "created": "Mon, 24 Jul 2017 16:03:03 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Yates", "Andrew", ""], ["Hui", "Kai", ""]]}, {"id": "1706.09031", "submitter": "Ryan Cotterell Ryan D Cotterell", "authors": "Ryan Cotterell, Christo Kirov, John Sylak-Glassman, G\\'eraldine\n  Walther, Ekaterina Vylomova, Patrick Xia, Manaal Faruqui, Sandra K\\\"ubler,\n  David Yarowsky, Jason Eisner and Mans Hulden", "title": "CoNLL-SIGMORPHON 2017 Shared Task: Universal Morphological Reinflection\n  in 52 Languages", "comments": "CoNLL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The CoNLL-SIGMORPHON 2017 shared task on supervised morphological generation\nrequired systems to be trained and tested in each of 52 typologically diverse\nlanguages. In sub-task 1, submitted systems were asked to predict a specific\ninflected form of a given lemma. In sub-task 2, systems were given a lemma and\nsome of its specific inflected forms, and asked to complete the inflectional\nparadigm by predicting all of the remaining inflected forms. Both sub-tasks\nincluded high, medium, and low-resource conditions. Sub-task 1 received 24\nsystem submissions, while sub-task 2 received 3 system submissions. Following\nthe success of neural sequence-to-sequence models in the SIGMORPHON 2016 shared\ntask, all but one of the submissions included a neural component. The results\nshow that high performance can be achieved with small training datasets, so\nlong as models have appropriate inductive bias or make use of additional\nunlabeled data or synthetic data. However, different biasing and data\naugmentation resulted in disjoint sets of inflected forms being predicted\ncorrectly, suggesting that there is room for future improvement.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jun 2017 20:02:34 GMT"}, {"version": "v2", "created": "Tue, 4 Jul 2017 18:12:34 GMT"}], "update_date": "2017-07-06", "authors_parsed": [["Cotterell", "Ryan", ""], ["Kirov", "Christo", ""], ["Sylak-Glassman", "John", ""], ["Walther", "G\u00e9raldine", ""], ["Vylomova", "Ekaterina", ""], ["Xia", "Patrick", ""], ["Faruqui", "Manaal", ""], ["K\u00fcbler", "Sandra", ""], ["Yarowsky", "David", ""], ["Eisner", "Jason", ""], ["Hulden", "Mans", ""]]}, {"id": "1706.09055", "submitter": "Christopher Shulby", "authors": "Christopher Dane Shulby, Martha Dais Ferreira, Rodrigo F. de Mello,\n  Sandra Maria Aluisio", "title": "Acoustic Modeling Using a Shallow CNN-HTSVM Architecture", "comments": "Pre-review version of Bracis 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-accuracy speech recognition is especially challenging when large\ndatasets are not available. It is possible to bridge this gap with careful and\nknowledge-driven parsing combined with the biologically inspired CNN and the\nlearning guarantees of the Vapnik Chervonenkis (VC) theory. This work presents\na Shallow-CNN-HTSVM (Hierarchical Tree Support Vector Machine classifier)\narchitecture which uses a predefined knowledge-based set of rules with\nstatistical machine learning techniques. Here we show that gross errors present\neven in state-of-the-art systems can be avoided and that an accurate acoustic\nmodel can be built in a hierarchical fashion. The CNN-HTSVM acoustic model\noutperforms traditional GMM-HMM models and the HTSVM structure outperforms a\nMLP multi-class classifier. More importantly we isolate the performance of the\nacoustic model and provide results on both the frame and phoneme level\nconsidering the true robustness of the model. We show that even with a small\namount of data accurate and robust recognition rates can be obtained.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jun 2017 21:28:31 GMT"}], "update_date": "2017-06-29", "authors_parsed": [["Shulby", "Christopher Dane", ""], ["Ferreira", "Martha Dais", ""], ["de Mello", "Rodrigo F.", ""], ["Aluisio", "Sandra Maria", ""]]}, {"id": "1706.09147", "submitter": "Yogtam Eshel", "authors": "Yotam Eshel, Noam Cohen, Kira Radinsky, Shaul Markovitch, Ikuya\n  Yamada, Omer Levy", "title": "Named Entity Disambiguation for Noisy Text", "comments": "Accepted to CoNLL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the task of Named Entity Disambiguation (NED) for noisy text. We\npresent WikilinksNED, a large-scale NED dataset of text fragments from the web,\nwhich is significantly noisier and more challenging than existing news-based\ndatasets. To capture the limited and noisy local context surrounding each\nmention, we design a neural model and train it with a novel method for sampling\ninformative negative examples. We also describe a new way of initializing word\nand entity embeddings that significantly improves performance. Our model\nsignificantly outperforms existing state-of-the-art methods on WikilinksNED\nwhile achieving comparable performance on a smaller newswire dataset.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jun 2017 07:26:55 GMT"}, {"version": "v2", "created": "Sat, 1 Jul 2017 22:43:09 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Eshel", "Yotam", ""], ["Cohen", "Noam", ""], ["Radinsky", "Kira", ""], ["Markovitch", "Shaul", ""], ["Yamada", "Ikuya", ""], ["Levy", "Omer", ""]]}, {"id": "1706.09254", "submitter": "Ond\\v{r}ej Du\\v{s}ek", "authors": "Jekaterina Novikova, Ond\\v{r}ej Du\\v{s}ek, Verena Rieser", "title": "The E2E Dataset: New Challenges For End-to-End Generation", "comments": "Accepted as a short paper for SIGDIAL 2017 (final submission\n  including supplementary material)", "journal-ref": "Proceedings of the SIGDIAL 2017 Conference, pages 201-206,\n  Saarbr\\\"ucken, Germany, 15-17 August 2017", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the E2E data, a new dataset for training end-to-end,\ndata-driven natural language generation systems in the restaurant domain, which\nis ten times bigger than existing, frequently used datasets in this area. The\nE2E dataset poses new challenges: (1) its human reference texts show more\nlexical richness and syntactic variation, including discourse phenomena; (2)\ngenerating from this set requires content selection. As such, learning from\nthis dataset promises more natural, varied and less template-like system\nutterances. We also establish a baseline on this dataset, which illustrates\nsome of the difficulties associated with this data.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jun 2017 12:38:53 GMT"}, {"version": "v2", "created": "Thu, 6 Jul 2017 11:51:09 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Novikova", "Jekaterina", ""], ["Du\u0161ek", "Ond\u0159ej", ""], ["Rieser", "Verena", ""]]}, {"id": "1706.09335", "submitter": "Harsh Jhamtani", "authors": "Gaurush Hiranandani, Pranav Maneriker, Harsh Jhamtani", "title": "Generating Appealing Brand Names", "comments": "Has been accepted to and presented in CICLING 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Providing appealing brand names to newly launched products, newly formed\ncompanies or for renaming existing companies is highly important as it can play\na crucial role in deciding its success or failure. In this work, we propose a\ncomputational method to generate appealing brand names based on the description\nof such entities. We use quantitative scores for readability, pronounceability,\nmemorability and uniqueness of the generated names to rank order them. A set of\ndiverse appealing names is recommended to the user for the brand naming task.\nExperimental results show that the names generated by our approach are more\nappealing than names which prior approaches and recruited humans could come up.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jun 2017 15:50:26 GMT"}], "update_date": "2017-06-29", "authors_parsed": [["Hiranandani", "Gaurush", ""], ["Maneriker", "Pranav", ""], ["Jhamtani", "Harsh", ""]]}, {"id": "1706.09433", "submitter": "Jekaterina Novikova Dr.", "authors": "Jekaterina Novikova, Ond\\v{r}ej Du\\v{s}ek and Verena Rieser", "title": "Data-driven Natural Language Generation: Paving the Road to Success", "comments": "WiNLP workshop at ACL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We argue that there are currently two major bottlenecks to the commercial use\nof statistical machine learning approaches for natural language generation\n(NLG): (a) The lack of reliable automatic evaluation metrics for NLG, and (b)\nThe scarcity of high quality in-domain corpora. We address the first problem by\nthoroughly analysing current evaluation metrics and motivating the need for a\nnew, more reliable metric. The second problem is addressed by presenting a\nnovel framework for developing and evaluating a high quality corpus for NLG\ntraining.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jun 2017 18:17:30 GMT"}], "update_date": "2017-06-30", "authors_parsed": [["Novikova", "Jekaterina", ""], ["Du\u0161ek", "Ond\u0159ej", ""], ["Rieser", "Verena", ""]]}, {"id": "1706.09453", "submitter": "Liang Lu", "authors": "Liang Lu", "title": "Toward Computation and Memory Efficient Neural Network Acoustic Models\n  with Binary Weights and Activations", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network acoustic models have significantly advanced state of the art\nspeech recognition over the past few years. However, they are usually\ncomputationally expensive due to the large number of matrix-vector\nmultiplications and nonlinearity operations. Neural network models also require\nsignificant amounts of memory for inference because of the large model size.\nFor these two reasons, it is challenging to deploy neural network based speech\nrecognizers on resource-constrained platforms such as embedded devices. This\npaper investigates the use of binary weights and activations for computation\nand memory efficient neural network acoustic models. Compared to real-valued\nweight matrices, binary weights require much fewer bits for storage, thereby\ncutting down the memory footprint. Furthermore, with binary weights or\nactivations, the matrix-vector multiplications are turned into addition and\nsubtraction operations, which are computationally much faster and more energy\nefficient for hardware platforms. In this paper, we study the applications of\nbinary weights and activations for neural network acoustic modeling, reporting\nencouraging results on the WSJ and AMI corpora.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jun 2017 19:41:25 GMT"}, {"version": "v2", "created": "Tue, 4 Jul 2017 17:03:20 GMT"}], "update_date": "2017-07-05", "authors_parsed": [["Lu", "Liang", ""]]}, {"id": "1706.09528", "submitter": "Swabha Swayamdipta", "authors": "Swabha Swayamdipta, Sam Thomson, Chris Dyer, Noah A. Smith", "title": "Frame-Semantic Parsing with Softmax-Margin Segmental RNNs and a\n  Syntactic Scaffold", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new, efficient frame-semantic parser that labels semantic\narguments to FrameNet predicates. Built using an extension to the segmental RNN\nthat emphasizes recall, our basic system achieves competitive performance\nwithout any calls to a syntactic parser. We then introduce a method that uses\nphrase-syntactic annotations from the Penn Treebank during training only,\nthrough a multitask objective; no parsing is required at training or test time.\nThis \"syntactic scaffold\" offers a cheaper alternative to traditional syntactic\npipelining, and achieves state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jun 2017 00:42:10 GMT"}], "update_date": "2017-06-30", "authors_parsed": [["Swayamdipta", "Swabha", ""], ["Thomson", "Sam", ""], ["Dyer", "Chris", ""], ["Smith", "Noah A.", ""]]}, {"id": "1706.09562", "submitter": "Adam Poliak", "authors": "Francis Ferraro, Adam Poliak, Ryan Cotterell, Benjamin Van Durme", "title": "Frame-Based Continuous Lexical Semantics through Exponential Family\n  Tensor Factorization and Semantic Proto-Roles", "comments": "Accepted at the Sixth Joint Conference on Lexical and Computational\n  Semantics (*SEM). Association for Computational Linguistics, Vancouver,\n  Canada. 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study how different frame annotations complement one another when learning\ncontinuous lexical semantics. We learn the representations from a tensorized\nskip-gram model that consistently encodes syntactic-semantic content better,\nwith multiple 10% gains over baselines.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jun 2017 03:19:39 GMT"}], "update_date": "2017-06-30", "authors_parsed": [["Ferraro", "Francis", ""], ["Poliak", "Adam", ""], ["Cotterell", "Ryan", ""], ["Van Durme", "Benjamin", ""]]}, {"id": "1706.09569", "submitter": "Inigo Jauregi Unanue", "authors": "Inigo Jauregi Unanue, Ehsan Zare Borzeshi, Massimo Piccardi", "title": "Recurrent neural networks with specialized word embeddings for\n  health-domain named-entity recognition", "comments": "Journal of Biomedical Informatics (2017)", "journal-ref": null, "doi": "10.1016/j.jbi.2017.11.007", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background. Previous state-of-the-art systems on Drug Name Recognition (DNR)\nand Clinical Concept Extraction (CCE) have focused on a combination of text\n\"feature engineering\" and conventional machine learning algorithms such as\nconditional random fields and support vector machines. However, developing good\nfeatures is inherently heavily time-consuming. Conversely, more modern machine\nlearning approaches such as recurrent neural networks (RNNs) have proved\ncapable of automatically learning effective features from either random\nassignments or automated word \"embeddings\". Objectives. (i) To create a highly\naccurate DNR and CCE system that avoids conventional, time-consuming feature\nengineering. (ii) To create richer, more specialized word embeddings by using\nhealth domain datasets such as MIMIC-III. (iii) To evaluate our systems over\nthree contemporary datasets. Methods. Two deep learning methods, namely the\nBidirectional LSTM and the Bidirectional LSTM-CRF, are evaluated. A CRF model\nis set as the baseline to compare the deep learning systems to a traditional\nmachine learning approach. The same features are used for all the models.\nResults. We have obtained the best results with the Bidirectional LSTM-CRF\nmodel, which has outperformed all previously proposed systems. The specialized\nembeddings have helped to cover unusual words in DDI-DrugBank and DDI-MedLine,\nbut not in the 2010 i2b2/VA IRB Revision dataset. Conclusion. We present a\nstate-of-the-art system for DNR and CCE. Automated word embeddings has allowed\nus to avoid costly feature engineering and achieve higher accuracy.\nNevertheless, the embeddings need to be retrained over datasets that are\nadequate for the domain, in order to adequately cover the domain-specific\nvocabulary.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jun 2017 03:53:55 GMT"}, {"version": "v2", "created": "Mon, 25 Jun 2018 01:44:25 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Unanue", "Inigo Jauregi", ""], ["Borzeshi", "Ehsan Zare", ""], ["Piccardi", "Massimo", ""]]}, {"id": "1706.09588", "submitter": "Naoya Takahashi", "authors": "Naoya Takahashi, Yuki Mitsufuji", "title": "Multi-scale Multi-band DenseNets for Audio Source Separation", "comments": "to appear at WASPAA 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the problem of audio source separation. To handle the\ncomplex and ill-posed nature of the problems of audio source separation, the\ncurrent state-of-the-art approaches employ deep neural networks to obtain\ninstrumental spectra from a mixture. In this study, we propose a novel network\narchitecture that extends the recently developed densely connected\nconvolutional network (DenseNet), which has shown excellent results on image\nclassification tasks. To deal with the specific problem of audio source\nseparation, an up-sampling layer, block skip connection and band-dedicated\ndense blocks are incorporated on top of DenseNet. The proposed approach takes\nadvantage of long contextual information and outperforms state-of-the-art\nresults on SiSEC 2016 competition by a large margin in terms of\nsignal-to-distortion ratio. Moreover, the proposed architecture requires\nsignificantly fewer parameters and considerably less training time compared\nwith other methods.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jun 2017 05:56:06 GMT"}], "update_date": "2017-06-30", "authors_parsed": [["Takahashi", "Naoya", ""], ["Mitsufuji", "Yuki", ""]]}, {"id": "1706.09673", "submitter": "Ganesh J", "authors": "Ganesh J", "title": "Improving Distributed Representations of Tweets - Present and Future", "comments": "To be presented in Student Research Workshop (SRW) at ACL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised representation learning for tweets is an important research\nfield which helps in solving several business applications such as sentiment\nanalysis, hashtag prediction, paraphrase detection and microblog ranking. A\ngood tweet representation learning model must handle the idiosyncratic nature\nof tweets which poses several challenges such as short length, informal words,\nunusual grammar and misspellings. However, there is a lack of prior work which\nsurveys the representation learning models with a focus on tweets. In this\nwork, we organize the models based on its objective function which aids the\nunderstanding of the literature. We also provide interesting future directions,\nwhich we believe are fruitful in advancing this field by building high-quality\ntweet representation learning models.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jun 2017 10:54:43 GMT"}], "update_date": "2017-06-30", "authors_parsed": [["J", "Ganesh", ""]]}, {"id": "1706.09733", "submitter": "Graham Neubig", "authors": "Michael Denkowski and Graham Neubig", "title": "Stronger Baselines for Trustable Results in Neural Machine Translation", "comments": "To appear at the Workshop on Neural Machine Translation (WNMT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interest in neural machine translation has grown rapidly as its effectiveness\nhas been demonstrated across language and data scenarios. New research\nregularly introduces architectural and algorithmic improvements that lead to\nsignificant gains over \"vanilla\" NMT implementations. However, these new\ntechniques are rarely evaluated in the context of previously published\ntechniques, specifically those that are widely used in state-of-theart\nproduction and shared-task systems. As a result, it is often difficult to\ndetermine whether improvements from research will carry over to systems\ndeployed for real-world use. In this work, we recommend three specific methods\nthat are relatively easy to implement and result in much stronger experimental\nsystems. Beyond reporting significantly higher BLEU scores, we conduct an\nin-depth analysis of where improvements originate and what inherent weaknesses\nof basic NMT models are being addressed. We then compare the relative gains\nafforded by several other techniques proposed in the literature when starting\nwith vanilla systems versus our stronger baselines, showing that experimental\nconclusions may change depending on the baseline chosen. This indicates that\nchoosing a strong baseline is crucial for reporting reliable experimental\nresults.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jun 2017 13:02:46 GMT"}], "update_date": "2017-06-30", "authors_parsed": [["Denkowski", "Michael", ""], ["Neubig", "Graham", ""]]}, {"id": "1706.09742", "submitter": "Zhiyuan Tang", "authors": "Zhiyuan Tang, Dong Wang, Yixiang Chen, Qing Chen", "title": "AP17-OLR Challenge: Data, Plan, and Baseline", "comments": "Submitted to APSIPA ASC 2017. arXiv admin note: text overlap with\n  arXiv:1609.08445", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the data profile and the evaluation plan of the second oriental\nlanguage recognition (OLR) challenge AP17-OLR. Compared to the event last year\n(AP16-OLR), the new challenge involves more languages and focuses more on short\nutterances. The data is offered by SpeechOcean and the NSFC M2ASR project. Two\ntypes of baselines are constructed to assist the participants, one is based on\nthe i-vector model and the other is based on various neural networks. We report\nthe baseline results evaluated with various metrics defined by the AP17-OLR\nevaluation plan and demonstrate that the combined database is a reasonable data\nresource for multilingual research. All the data is free for participants, and\nthe Kaldi recipes for the baselines have been published online.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jun 2017 13:37:29 GMT"}], "update_date": "2017-06-30", "authors_parsed": [["Tang", "Zhiyuan", ""], ["Wang", "Dong", ""], ["Chen", "Yixiang", ""], ["Chen", "Qing", ""]]}, {"id": "1706.09789", "submitter": "David Golub", "authors": "David Golub, Po-Sen Huang, Xiaodong He, Li Deng", "title": "Two-Stage Synthesis Networks for Transfer Learning in Machine\n  Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a technique for transfer learning in machine comprehension (MC)\nusing a novel two-stage synthesis network (SynNet). Given a high-performing MC\nmodel in one domain, our technique aims to answer questions about documents in\nanother domain, where we use no labeled data of question-answer pairs. Using\nthe proposed SynNet with a pretrained model from the SQuAD dataset on the\nchallenging NewsQA dataset, we achieve an F1 measure of 44.3% with a single\nmodel and 46.6% with an ensemble, approaching performance of in-domain models\n(F1 measure of 50.0%) and outperforming the out-of-domain baseline of 7.6%,\nwithout use of provided annotations.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jun 2017 14:58:47 GMT"}, {"version": "v2", "created": "Thu, 13 Jul 2017 18:09:11 GMT"}, {"version": "v3", "created": "Sat, 23 Sep 2017 03:54:25 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Golub", "David", ""], ["Huang", "Po-Sen", ""], ["He", "Xiaodong", ""], ["Deng", "Li", ""]]}, {"id": "1706.09799", "submitter": "Shikhar Sharma", "authors": "Shikhar Sharma, Layla El Asri, Hannes Schulz, Jeremie Zumer", "title": "Relevance of Unsupervised Metrics in Task-Oriented Dialogue for\n  Evaluating Natural Language Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated metrics such as BLEU are widely used in the machine translation\nliterature. They have also been used recently in the dialogue community for\nevaluating dialogue response generation. However, previous work in dialogue\nresponse generation has shown that these metrics do not correlate strongly with\nhuman judgment in the non task-oriented dialogue setting. Task-oriented\ndialogue responses are expressed on narrower domains and exhibit lower\ndiversity. It is thus reasonable to think that these automated metrics would\ncorrelate well with human judgment in the task-oriented setting where the\ngeneration task consists of translating dialogue acts into a sentence. We\nconduct an empirical study to confirm whether this is the case. Our findings\nindicate that these automated metrics have stronger correlation with human\njudgments in the task-oriented setting compared to what has been observed in\nthe non task-oriented setting. We also observe that these metrics correlate\neven better for datasets which provide multiple ground truth reference\nsentences. In addition, we show that some of the currently available corpora\nfor task-oriented language generation can be solved with simple models and\nadvocate for more challenging datasets.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jun 2017 15:14:07 GMT"}], "update_date": "2017-06-30", "authors_parsed": [["Sharma", "Shikhar", ""], ["Asri", "Layla El", ""], ["Schulz", "Hannes", ""], ["Zumer", "Jeremie", ""]]}, {"id": "1706.09856", "submitter": "Majid Laali", "authors": "Majid Laali and Leila Kosseim", "title": "Automatic Mapping of French Discourse Connectives to PDTB Discourse\n  Relations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an approach to exploit phrase tables generated by\nstatistical machine translation in order to map French discourse connectives to\ndiscourse relations. Using this approach, we created ConcoLeDisCo, a lexicon of\nFrench discourse connectives and their PDTB relations. When evaluated against\nLEXCONN, ConcoLeDisCo achieves a recall of 0.81 and an Average Precision of\n0.68 for the Concession and Condition relations.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jun 2017 17:04:48 GMT"}], "update_date": "2017-06-30", "authors_parsed": [["Laali", "Majid", ""], ["Kosseim", "Leila", ""]]}, {"id": "1706.10006", "submitter": "Konstantinos Drossos", "authors": "Konstantinos Drossos, Sharath Adavanne, Tuomas Virtanen", "title": "Automated Audio Captioning with Recurrent Neural Networks", "comments": "Presented at the 11th IEEE Workshop on Applications of Signal\n  Processing to Audio and Acoustics (WASPAA), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first approach to automated audio captioning. We employ an\nencoder-decoder scheme with an alignment model in between. The input to the\nencoder is a sequence of log mel-band energies calculated from an audio file,\nwhile the output is a sequence of words, i.e. a caption. The encoder is a\nmulti-layered, bi-directional gated recurrent unit (GRU) and the decoder a\nmulti-layered GRU with a classification layer connected to the last GRU of the\ndecoder. The classification layer and the alignment model are fully connected\nlayers with shared weights between timesteps. The proposed method is evaluated\nusing data drawn from a commercial sound effects library, ProSound Effects. The\nresulting captions were rated through metrics utilized in machine translation\nand image captioning fields. Results from metrics show that the proposed method\ncan predict words appearing in the original caption, but not always correctly\nordered.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jun 2017 02:55:55 GMT"}, {"version": "v2", "created": "Tue, 24 Oct 2017 11:36:08 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Drossos", "Konstantinos", ""], ["Adavanne", "Sharath", ""], ["Virtanen", "Tuomas", ""]]}, {"id": "1706.10192", "submitter": "Andrew Yates", "authors": "Kai Hui, Andrew Yates, Klaus Berberich, Gerard de Melo", "title": "Co-PACRR: A Context-Aware Neural IR Model for Ad-hoc Retrieval", "comments": "To appear in WSDM 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural IR models, such as DRMM and PACRR, have achieved strong results by\nsuccessfully capturing relevance matching signals. We argue that the context of\nthese matching signals is also important. Intuitively, when extracting,\nmodeling, and combining matching signals, one would like to consider the\nsurrounding text (local context) as well as other signals from the same\ndocument that can contribute to the overall relevance score. In this work, we\nhighlight three potential shortcomings caused by not considering context\ninformation and propose three neural ingredients to address them: a\ndisambiguation component, cascade k-max pooling, and a shuffling combination\nlayer. Incorporating these components into the PACRR model yields Co-PACRR, a\nnovel context-aware neural IR model. Extensive comparisons with established\nmodels on Trec Web Track data confirm that the proposed model can achieve\nsuperior search results. In addition, an ablation analysis is conducted to gain\ninsights into the impact of and interactions between different components. We\nrelease our code to enable future comparisons.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jun 2017 13:39:03 GMT"}, {"version": "v2", "created": "Mon, 24 Jul 2017 13:42:11 GMT"}, {"version": "v3", "created": "Tue, 28 Nov 2017 13:43:56 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Hui", "Kai", ""], ["Yates", "Andrew", ""], ["Berberich", "Klaus", ""], ["de Melo", "Gerard", ""]]}]