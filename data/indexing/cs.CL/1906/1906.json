[{"id": "1906.00038", "submitter": "Stephanie Lukin", "authors": "Stephanie M. Lukin, Claire Bonial, and Clare R. Voss", "title": "Visual Understanding and Narration: A Deeper Understanding and\n  Explanation of Visual Scenes", "comments": "2-page extended abstract, presented at the Workshop on Shortcomings\n  in Vision and Language (SiVL), 2019, at the North American Association for\n  Computational Linguistics (NAACL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the task of Visual Understanding and Narration, in which a robot\n(or agent) generates text for the images that it collects when navigating its\nenvironment, by answering open-ended questions, such as 'what happens, or might\nhave happened, here?'\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 19:12:55 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 20:27:47 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Lukin", "Stephanie M.", ""], ["Bonial", "Claire", ""], ["Voss", "Clare R.", ""]]}, {"id": "1906.00041", "submitter": "Shuo Zhang", "authors": "Li Deng, Shuo Zhang, and Krisztian Balog", "title": "Table2Vec: Neural Word and Entity Embeddings for Table Population and\n  Retrieval", "comments": "Proceedings of the 42nd International ACM SIGIR Conference on\n  Research and Development in Information Retrieval (SIGIR '19), 2019", "journal-ref": null, "doi": "10.1145/3331184.3331333", "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tables contain valuable knowledge in a structured form. We employ neural\nlanguage modeling approaches to embed tabular data into vector spaces.\nSpecifically, we consider different table elements, such caption, column\nheadings, and cells, for training word and entity embeddings. These embeddings\nare then utilized in three particular table-related tasks, row population,\ncolumn population, and table retrieval, by incorporating them into existing\nretrieval models as additional semantic similarity signals. Evaluation results\nshow that table embeddings can significantly improve upon the performance of\nstate-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 19:22:29 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Deng", "Li", ""], ["Zhang", "Shuo", ""], ["Balog", "Krisztian", ""]]}, {"id": "1906.00048", "submitter": "Colin Cherry", "authors": "Colin Cherry and George Foster", "title": "Thinking Slow about Latency Evaluation for Simultaneous Machine\n  Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simultaneous machine translation attempts to translate a source sentence\nbefore it is finished being spoken, with applications to translation of spoken\nlanguage for live streaming and conversation. Since simultaneous systems trade\nquality to reduce latency, having an effective and interpretable latency metric\nis crucial. We introduce a variant of the recently proposed Average Lagging\n(AL) metric, which we call Differentiable Average Lagging (DAL). It\ndistinguishes itself by being differentiable and internally consistent to its\nunderlying mathematical model.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 19:57:49 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Cherry", "Colin", ""], ["Foster", "George", ""]]}, {"id": "1906.00067", "submitter": "Kenneth Marino", "authors": "Kenneth Marino, Mohammad Rastegari, Ali Farhadi, Roozbeh Mottaghi", "title": "OK-VQA: A Visual Question Answering Benchmark Requiring External\n  Knowledge", "comments": "CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual Question Answering (VQA) in its ideal form lets us study reasoning in\nthe joint space of vision and language and serves as a proxy for the AI task of\nscene understanding. However, most VQA benchmarks to date are focused on\nquestions such as simple counting, visual attributes, and object detection that\ndo not require reasoning or knowledge beyond what is in the image. In this\npaper, we address the task of knowledge-based visual question answering and\nprovide a benchmark, called OK-VQA, where the image content is not sufficient\nto answer the questions, encouraging methods that rely on external knowledge\nresources. Our new dataset includes more than 14,000 questions that require\nexternal knowledge to answer. We show that the performance of the\nstate-of-the-art VQA models degrades drastically in this new setting. Our\nanalysis shows that our knowledge-based VQA task is diverse, difficult, and\nlarge compared to previous knowledge-based VQA datasets. We hope that this\ndataset enables researchers to open up new avenues for research in this domain.\nSee http://okvqa.allenai.org to download and browse the dataset.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 20:29:01 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 10:43:20 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Marino", "Kenneth", ""], ["Rastegari", "Mohammad", ""], ["Farhadi", "Ali", ""], ["Mottaghi", "Roozbeh", ""]]}, {"id": "1906.00072", "submitter": "Fei Liu", "authors": "Sangwoo Cho and Logan Lebanoff and Hassan Foroosh and Fei Liu", "title": "Improving the Similarity Measure of Determinantal Point Processes for\n  Extractive Multi-Document Summarization", "comments": "ACL 2019 (Long Paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most important obstacles facing multi-document summarization include\nexcessive redundancy in source descriptions and the looming shortage of\ntraining data. These obstacles prevent encoder-decoder models from being used\ndirectly, but optimization-based methods such as determinantal point processes\n(DPPs) are known to handle them well. In this paper we seek to strengthen a\nDPP-based method for extractive multi-document summarization by presenting a\nnovel similarity measure inspired by capsule networks. The approach measures\nredundancy between a pair of sentences based on surface form and semantic\ninformation. We show that our DPP system with improved similarity measure\nperforms competitively, outperforming strong summarization baselines on\nbenchmark datasets. Our findings are particularly meaningful for summarizing\ndocuments created by multiple authors containing redundant yet lexically\ndiverse expressions.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 20:45:15 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Cho", "Sangwoo", ""], ["Lebanoff", "Logan", ""], ["Foroosh", "Hassan", ""], ["Liu", "Fei", ""]]}, {"id": "1906.00077", "submitter": "Fei Liu", "authors": "Logan Lebanoff and Kaiqiang Song and Franck Dernoncourt and Doo Soon\n  Kim and Seokhwan Kim and Walter Chang and Fei Liu", "title": "Scoring Sentence Singletons and Pairs for Abstractive Summarization", "comments": "ACL 2019 (Long Paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When writing a summary, humans tend to choose content from one or two\nsentences and merge them into a single summary sentence. However, the\nmechanisms behind the selection of one or multiple source sentences remain\npoorly understood. Sentence fusion assumes multi-sentence input; yet sentence\nselection methods only work with single sentences and not combinations of them.\nThere is thus a crucial gap between sentence selection and fusion to support\nsummarizing by both compressing single sentences and fusing pairs. This paper\nattempts to bridge the gap by ranking sentence singletons and pairs together in\na unified space. Our proposed framework attempts to model human methodology by\nselecting either a single sentence or a pair of sentences, then compressing or\nfusing the sentence(s) to produce a summary sentence. We conduct extensive\nexperiments on both single- and multi-document summarization datasets and\nreport findings on sentence selection and abstraction.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 20:58:08 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Lebanoff", "Logan", ""], ["Song", "Kaiqiang", ""], ["Dernoncourt", "Franck", ""], ["Kim", "Doo Soon", ""], ["Kim", "Seokhwan", ""], ["Chang", "Walter", ""], ["Liu", "Fei", ""]]}, {"id": "1906.00080", "submitter": "Mia Chen", "authors": "Mia Xu Chen, Benjamin N Lee, Gagan Bansal, Yuan Cao, Shuyuan Zhang,\n  Justin Lu, Jackie Tsay, Yinan Wang, Andrew M. Dai, Zhifeng Chen, Timothy\n  Sohn, Yonghui Wu", "title": "Gmail Smart Compose: Real-Time Assisted Writing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present Smart Compose, a novel system for generating\ninteractive, real-time suggestions in Gmail that assists users in writing mails\nby reducing repetitive typing. In the design and deployment of such a\nlarge-scale and complicated system, we faced several challenges including model\nselection, performance evaluation, serving and other practical issues. At the\ncore of Smart Compose is a large-scale neural language model. We leveraged\nstate-of-the-art machine learning techniques for language model training which\nenabled high-quality suggestion prediction, and constructed novel serving\ninfrastructure for high-throughput and real-time inference. Experimental\nresults show the effectiveness of our proposed system design and deployment\napproach. This system is currently being served in Gmail.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 07:58:44 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Chen", "Mia Xu", ""], ["Lee", "Benjamin N", ""], ["Bansal", "Gagan", ""], ["Cao", "Yuan", ""], ["Zhang", "Shuyuan", ""], ["Lu", "Justin", ""], ["Tsay", "Jackie", ""], ["Wang", "Yinan", ""], ["Dai", "Andrew M.", ""], ["Chen", "Zhifeng", ""], ["Sohn", "Timothy", ""], ["Wu", "Yonghui", ""]]}, {"id": "1906.00112", "submitter": "Armin Seyeditabari", "authors": "Armin Seyeditabari, Narges Tabari, Shafie Gholizade, Wlodek Zadrozny", "title": "Emotional Embeddings: Refining Word Embeddings to Capture Emotional\n  Content of Words", "comments": "5 pages, 1 figure, 2 tables, $ equations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings are one of the most useful tools in any modern natural\nlanguage processing expert's toolkit. They contain various types of information\nabout each word which makes them the best way to represent the terms in any NLP\ntask. But there are some types of information that cannot be learned by these\nmodels. Emotional information of words are one of those. In this paper, we\npresent an approach to incorporate emotional information of words into these\nmodels. We accomplish this by adding a secondary training stage which uses an\nemotional lexicon and a psychological model of basic emotions. We show that\nfitting an emotional model into pre-trained word vectors can increase the\nperformance of these models in emotional similarity metrics. Retrained models\nperform better than their original counterparts from 13% improvement for\nWord2Vec model, to 29% for GloVe vectors. This is the first such model\npresented in the literature, and although preliminary, these emotion sensitive\nmodels can open the way to increase performance in variety of emotion detection\ntechniques.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 22:46:03 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 15:43:27 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Seyeditabari", "Armin", ""], ["Tabari", "Narges", ""], ["Gholizade", "Shafie", ""], ["Zadrozny", "Wlodek", ""]]}, {"id": "1906.00114", "submitter": "Tom\\'a\\v{s} Musil", "authors": "Tom\\'a\\v{s} Musil", "title": "Examining Structure of Word Embeddings with PCA", "comments": "12 pages, 6 figures, accepted to The 22th International Conference of\n  Text, Speech and Dialogue (TSD2019) in Ljubljana", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we compare structure of Czech word embeddings for English-Czech\nneural machine translation (NMT), word2vec and sentiment analysis. We show that\nalthough it is possible to successfully predict part of speech (POS) tags from\nword embeddings of word2vec and various translation models, not all of the\nembedding spaces show the same structure. The information about POS is present\nin word2vec embeddings, but the high degree of organization by POS in the NMT\ndecoder suggests that this information is more important for machine\ntranslation and therefore the NMT model represents it in more direct way. Our\nmethod is based on correlation of principal component analysis (PCA) dimensions\nwith categorical linguistic data. We also show that further examining\nhistograms of classes along the principal component is important to understand\nthe structure of representation of information in embeddings.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 22:47:56 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Musil", "Tom\u00e1\u0161", ""]]}, {"id": "1906.00138", "submitter": "Antoine Bosselut", "authors": "Andrew Hoang, Antoine Bosselut, Asli Celikyilmaz, Yejin Choi", "title": "Efficient Adaptation of Pretrained Transformers for Abstractive\n  Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale learning of transformer language models has yielded improvements\non a variety of natural language understanding tasks. Whether they can be\neffectively adapted for summarization, however, has been less explored, as the\nlearned representations are less seamlessly integrated into existing neural\ntext production architectures. In this work, we propose two solutions for\nefficiently adapting pretrained transformer language models as text\nsummarizers: source embeddings and domain-adaptive training. We test these\nsolutions on three abstractive summarization datasets, achieving new state of\nthe art performance on two of them. Finally, we show that these improvements\nare achieved by producing more focused summaries with fewer superfluous and\nthat performance improvements are more pronounced on more abstractive datasets.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 03:05:31 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Hoang", "Andrew", ""], ["Bosselut", "Antoine", ""], ["Celikyilmaz", "Asli", ""], ["Choi", "Yejin", ""]]}, {"id": "1906.00141", "submitter": "Ilia Kulikov", "authors": "Ilia Kulikov, Jason Lee, Kyunghyun Cho", "title": "Multi-Turn Beam Search for Neural Dialogue Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In neural dialogue modeling, a neural network is trained to predict the next\nutterance, and at inference time, an approximate decoding algorithm is used to\ngenerate next utterances given previous ones. While this autoregressive\nframework allows us to model the whole conversation during training, inference\nis highly suboptimal, as a wrong utterance can affect future utterances. While\nbeam search yields better results than greedy search does, we argue that it is\nstill greedy in the context of the entire conversation, in that it does not\nconsider future utterances. We propose a novel approach for conversation-level\ninference by explicitly modeling the dialogue partner and running beam search\nacross multiple conversation turns. Given a set of candidates for next\nutterance, we unroll the conversation for a number of turns and identify the\ncandidate utterance in the initial hypothesis set that gives rise to the most\nlikely sequence of future utterances. We empirically validate our approach by\nconducting human evaluation using the Persona-Chat dataset, and find that our\nmulti-turn beam search generates significantly better dialogue responses. We\npropose three approximations to the partner model, and observe that more\ninformed partner models give better performance.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 03:31:26 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 14:16:25 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Kulikov", "Ilia", ""], ["Lee", "Jason", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1906.00156", "submitter": "Binbin Jin", "authors": "Binbin Jin, Enhong Chen, Hongke Zhao, Zhenya Huang, Qi Liu, Hengshu\n  Zhu, Shui Yu", "title": "Promotion of Answer Value Measurement with Domain Effects in Community\n  Question Answering Systems", "comments": "IEEE Transactions on Systems, Man, and Cybernetics: Systems", "journal-ref": null, "doi": "10.1109/TSMC.2019.2917673", "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the area of community question answering (CQA), answer selection and\nanswer ranking are two tasks which are applied to help users quickly access\nvaluable answers. Existing solutions mainly exploit the syntactic or semantic\ncorrelation between a question and its related answers (Q&A), where the\nmulti-facet domain effects in CQA are still underexplored. In this paper, we\npropose a unified model, Enhanced Attentive Recurrent Neural Network (EARNN),\nfor both answer selection and answer ranking tasks by taking full advantages of\nboth Q&A semantics and multi-facet domain effects (i.e., topic effects and\ntimeliness). Specifically, we develop a serialized LSTM to learn the unified\nrepresentations of Q&A, where two attention mechanisms at either sentence-level\nor word-level are designed for capturing the deep effects of topics. Meanwhile,\nthe emphasis of Q&A can be automatically distinguished. Furthermore, we design\na time-sensitive ranking function to model the timeliness in CQA. To\neffectively train EARNN, a question-dependent pairwise learning strategy is\nalso developed. Finally, we conduct extensive experiments on a real-world\ndataset from Quora. Experimental results validate the effectiveness and\ninterpretability of our proposed EARNN model.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 05:55:52 GMT"}, {"version": "v2", "created": "Sun, 14 Jul 2019 06:46:16 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Jin", "Binbin", ""], ["Chen", "Enhong", ""], ["Zhao", "Hongke", ""], ["Huang", "Zhenya", ""], ["Liu", "Qi", ""], ["Zhu", "Hengshu", ""], ["Yu", "Shui", ""]]}, {"id": "1906.00180", "submitter": "Mathijs Mul", "authors": "Mathijs Mul, Willem Zuidema", "title": "Siamese recurrent networks learn first-order logic reasoning and exhibit\n  zero-shot compositional generalization", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can neural nets learn logic? We approach this classic question with current\nmethods, and demonstrate that recurrent neural networks can learn to recognize\nfirst order logical entailment relations between expressions. We define an\nartificial language in first-order predicate logic, generate a large dataset of\nsample 'sentences', and use an automatic theorem prover to infer the relation\nbetween random pairs of such sentences. We describe a Siamese neural\narchitecture trained to predict the logical relation, and experiment with\nrecurrent and recursive networks. Siamese Recurrent Networks are surprisingly\nsuccessful at the entailment recognition task, reaching near perfect\nperformance on novel sentences (consisting of known words), and even\noutperforming recursive networks. We report a series of experiments to test the\nability of the models to perform compositional generalization. In particular,\nwe study how they deal with sentences of unseen length, and sentences\ncontaining unseen words. We show that set-ups using LSTMs and GRUs obtain high\nscores on these tests, demonstrating a form of compositionality.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 08:17:42 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Mul", "Mathijs", ""], ["Zuidema", "Willem", ""]]}, {"id": "1906.00238", "submitter": "Alon Rozental", "authors": "Alon Rozental", "title": "Adversarial Generation and Encoding of Nested Texts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a new language model called AGENT, which stands for\nAdversarial Generation and Encoding of Nested Texts. AGENT is designed for\nencoding, generating and refining documents that consist of a long and coherent\ntext, such as an entire book, provided they are hierarchically annotated\n(nested). i.e. divided into sentences, paragraphs and chapters. The core idea\nof our system is learning vector representations for each level of the text\nhierarchy (sentences, paragraphs, etc...), and train each such representation\nto perform 3 tasks: The task of reconstructing the sequence of vectors from a\nlower level that was used to create the representation, and generalized\nversions of the Masked Language Modeling (MLM) and \"Next Sentence Prediction\"\ntasks from BERT Devlin et al. [2018]. Additionally we present a new adversarial\nmodel for long text generation and suggest a way to improve the coherence of\nthe generated text by traversing its vector representation tree.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 15:01:16 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Rozental", "Alon", ""]]}, {"id": "1906.00247", "submitter": "Junjie Huang", "authors": "Junjie Huang, Fanchao Qi, Chenghao Yang, Zhiyuan Liu, Maosong Sun", "title": "COS960: A Chinese Word Similarity Dataset of 960 Word Pairs", "comments": "Final", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word similarity computation is a widely recognized task in the field of\nlexical semantics. Most proposed tasks test on similarity of word pairs of\nsingle morpheme, while few works focus on words of two morphemes or more\nmorphemes. In this work, we propose COS960, a benchmark dataset with 960 pairs\nof Chinese wOrd Similarity, where all the words have two morphemes in three\nPart of Speech (POS) tags with their human annotated similarity rather than\nrelatedness. We give a detailed description of dataset construction and\nannotation process, and test on a range of word embedding models. The dataset\nof this paper can be obtained from https://github.com/thunlp/COS960.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 15:37:19 GMT"}, {"version": "v2", "created": "Sun, 30 Jun 2019 12:10:52 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Huang", "Junjie", ""], ["Qi", "Fanchao", ""], ["Yang", "Chenghao", ""], ["Liu", "Zhiyuan", ""], ["Sun", "Maosong", ""]]}, {"id": "1906.00266", "submitter": "Yufei Wang", "authors": "Yufei Wang and Mark Johnson and Stephen Wan and Yifang Sun and Wei\n  Wang", "title": "How to best use Syntax in Semantic Role Labelling", "comments": "ACL-2019 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many different ways in which external information might be used in\nan NLP task. This paper investigates how external syntactic information can be\nused most effectively in the Semantic Role Labeling (SRL) task. We evaluate\nthree different ways of encoding syntactic parses and three different ways of\ninjecting them into a state-of-the-art neural ELMo-based SRL sequence labelling\nmodel. We show that using a constituency representation as input features\nimproves performance the most, achieving a new state-of-the-art for\nnon-ensemble SRL models on the in-domain CoNLL'05 and CoNLL'12 benchmarks.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 18:35:12 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Wang", "Yufei", ""], ["Johnson", "Mark", ""], ["Wan", "Stephen", ""], ["Sun", "Yifang", ""], ["Wang", "Wei", ""]]}, {"id": "1906.00274", "submitter": "Nabil Hossain", "authors": "Nabil Hossain, John Krumm, Michael Gamon", "title": "\"President Vows to Cut <Taxes> Hair\": Dataset and Analysis of Creative\n  Text Editing for Humorous Headlines", "comments": "Accepted in NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce, release, and analyze a new dataset, called Humicroedit, for\nresearch in computational humor. Our publicly available data consists of\nregular English news headlines paired with versions of the same headlines that\ncontain simple replacement edits designed to make them funny. We carefully\ncurated crowdsourced editors to create funny headlines and judges to score a to\na total of 15,095 edited headlines, with five judges per headline. The simple\nedits, usually just a single word replacement, mean we can apply\nstraightforward analysis techniques to determine what makes our edited\nheadlines humorous. We show how the data support classic theories of humor,\nsuch as incongruity, superiority, and setup/punchline. Finally, we develop\nbaseline classifiers that can predict whether or not an edited headline is\nfunny, which is a first step toward automatically generating humorous headlines\nas an approach to creating topical humor.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 19:17:03 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Hossain", "Nabil", ""], ["Krumm", "John", ""], ["Gamon", "Michael", ""]]}, {"id": "1906.00282", "submitter": "Joel Mathew", "authors": "Joel Mathew, Shobeir Fakhraei, Jos\\'e Luis Ambite", "title": "Biomedical Named Entity Recognition via Reference-Set Augmented\n  Bootstrapping", "comments": "5 pages, 1 Figure, 2 Table, ICML 2019 Workshop on Computational\n  Biology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We present a weakly-supervised data augmentation approach to improve Named\nEntity Recognition (NER) in a challenging domain: extracting biomedical\nentities (e.g., proteins) from the scientific literature. First, we train a\nneural NER (NNER) model over a small seed of fully-labeled examples. Second, we\nuse a reference set of entity names (e.g., proteins in UniProt) to identify\nentity mentions with high precision, but low recall, on an unlabeled corpus.\nThird, we use the NNER model to assign weak labels to the corpus. Finally, we\nretrain our NNER model iteratively over the augmented training set, including\nthe seed, the reference-set examples, and the weakly-labeled examples, which\nimproves model performance. We show empirically that this augmented\nbootstrapping process significantly improves NER performance, and discuss the\nfactors impacting the efficacy of the approach.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 20:07:11 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Mathew", "Joel", ""], ["Fakhraei", "Shobeir", ""], ["Ambite", "Jos\u00e9 Luis", ""]]}, {"id": "1906.00283", "submitter": "Chih-Yao Ma", "authors": "Chih-Yao Ma, Yannis Kalantidis, Ghassan AlRegib, Peter Vajda, Marcus\n  Rohrbach, Zsolt Kira", "title": "Learning to Generate Grounded Visual Captions without Localization\n  Supervision", "comments": "ECCV 2020. Code is available at\n  https://github.com/chihyaoma/cyclical-visual-captioning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When automatically generating a sentence description for an image or video,\nit often remains unclear how well the generated caption is grounded, that is\nwhether the model uses the correct image regions to output particular words, or\nif the model is hallucinating based on priors in the dataset and/or the\nlanguage model. The most common way of relating image regions with words in\ncaption models is through an attention mechanism over the regions that are used\nas input to predict the next word. The model must therefore learn to predict\nthe attentional weights without knowing the word it should localize. This is\ndifficult to train without grounding supervision since recurrent models can\npropagate past information and there is no explicit signal to force the\ncaptioning model to properly ground the individual decoded words. In this work,\nwe help the model to achieve this via a novel cyclical training regimen that\nforces the model to localize each word in the image after the sentence decoder\ngenerates it, and then reconstruct the sentence from the localized image\nregion(s) to match the ground-truth. Our proposed framework only requires\nlearning one extra fully-connected layer (the localizer), a layer that can be\nremoved at test time. We show that our model significantly improves grounding\naccuracy without relying on grounding supervision or introducing extra\ncomputation during inference, for both image and video captioning tasks. Code\nis available at https://github.com/chihyaoma/cyclical-visual-captioning .\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 20:21:24 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 22:25:36 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2020 23:56:28 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Ma", "Chih-Yao", ""], ["Kalantidis", "Yannis", ""], ["AlRegib", "Ghassan", ""], ["Vajda", "Peter", ""], ["Rohrbach", "Marcus", ""], ["Kira", "Zsolt", ""]]}, {"id": "1906.00295", "submitter": "Yao-Hung Tsai", "authors": "Yao-Hung Hubert Tsai and Shaojie Bai and Paul Pu Liang and J. Zico\n  Kolter and Louis-Philippe Morency and Ruslan Salakhutdinov", "title": "Multimodal Transformer for Unaligned Multimodal Language Sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human language is often multimodal, which comprehends a mixture of natural\nlanguage, facial gestures, and acoustic behaviors. However, two major\nchallenges in modeling such multimodal human language time-series data exist:\n1) inherent data non-alignment due to variable sampling rates for the sequences\nfrom each modality; and 2) long-range dependencies between elements across\nmodalities. In this paper, we introduce the Multimodal Transformer (MulT) to\ngenerically address the above issues in an end-to-end manner without explicitly\naligning the data. At the heart of our model is the directional pairwise\ncrossmodal attention, which attends to interactions between multimodal\nsequences across distinct time steps and latently adapt streams from one\nmodality to another. Comprehensive experiments on both aligned and non-aligned\nmultimodal time-series show that our model outperforms state-of-the-art methods\nby a large margin. In addition, empirical analysis suggests that correlated\ncrossmodal signals are able to be captured by the proposed crossmodal attention\nmechanism in MulT.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 21:29:20 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Tsai", "Yao-Hung Hubert", ""], ["Bai", "Shaojie", ""], ["Liang", "Paul Pu", ""], ["Kolter", "J. Zico", ""], ["Morency", "Louis-Philippe", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1906.00300", "submitter": "Kenton Lee", "authors": "Kenton Lee, Ming-Wei Chang, Kristina Toutanova", "title": "Latent Retrieval for Weakly Supervised Open Domain Question Answering", "comments": "Accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on open domain question answering (QA) assumes strong supervision\nof the supporting evidence and/or assumes a blackbox information retrieval (IR)\nsystem to retrieve evidence candidates. We argue that both are suboptimal,\nsince gold evidence is not always available, and QA is fundamentally different\nfrom IR. We show for the first time that it is possible to jointly learn the\nretriever and reader from question-answer string pairs and without any IR\nsystem. In this setting, evidence retrieval from all of Wikipedia is treated as\na latent variable. Since this is impractical to learn from scratch, we\npre-train the retriever with an Inverse Cloze Task. We evaluate on open\nversions of five QA datasets. On datasets where the questioner already knows\nthe answer, a traditional IR system such as BM25 is sufficient. On datasets\nwhere a user is genuinely seeking an answer, we show that learned retrieval is\ncrucial, outperforming BM25 by up to 19 points in exact match.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 22:02:39 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 19:45:44 GMT"}, {"version": "v3", "created": "Thu, 27 Jun 2019 21:06:12 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Lee", "Kenton", ""], ["Chang", "Ming-Wei", ""], ["Toutanova", "Kristina", ""]]}, {"id": "1906.00318", "submitter": "Tal Baumel", "authors": "Matan Eyal, Tal Baumel, Michael Elhadad", "title": "Question Answering as an Automatic Evaluation Metric for News Article\n  Summarization", "comments": "Accepted to NAACL2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work in the field of automatic summarization and headline generation\nfocuses on maximizing ROUGE scores for various news datasets. We present an\nalternative, extrinsic, evaluation metric for this task, Answering Performance\nfor Evaluation of Summaries. APES utilizes recent progress in the field of\nreading-comprehension to quantify the ability of a summary to answer a set of\nmanually created questions regarding central entities in the source article. We\nfirst analyze the strength of this metric by comparing it to known manual\nevaluation metrics. We then present an end-to-end neural abstractive model that\nmaximizes APES, while increasing ROUGE scores to competitive results.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 00:29:05 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Eyal", "Matan", ""], ["Baumel", "Tal", ""], ["Elhadad", "Michael", ""]]}, {"id": "1906.00346", "submitter": "Junyuan Shang", "authors": "Junyuan Shang, Tengfei Ma, Cao Xiao, Jimeng Sun", "title": "Pre-training of Graph Augmented Transformers for Medication\n  Recommendation", "comments": "IJCAI2019; fix some undefined problems; provide more intuitive\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Medication recommendation is an important healthcare application. It is\ncommonly formulated as a temporal prediction task. Hence, most existing works\nonly utilize longitudinal electronic health records (EHRs) from a small number\nof patients with multiple visits ignoring a large number of patients with a\nsingle visit (selection bias). Moreover, important hierarchical knowledge such\nas diagnosis hierarchy is not leveraged in the representation learning process.\nTo address these challenges, we propose G-BERT, a new model to combine the\npower of Graph Neural Networks (GNNs) and BERT (Bidirectional Encoder\nRepresentations from Transformers) for medical code representation and\nmedication recommendation. We use GNNs to represent the internal hierarchical\nstructures of medical codes. Then we integrate the GNN representation into a\ntransformer-based visit encoder and pre-train it on EHR data from patients only\nwith a single visit. The pre-trained visit encoder and representation are then\nfine-tuned for downstream predictive tasks on longitudinal EHRs from patients\nwith multiple visits. G-BERT is the first to bring the language model\npre-training schema into the healthcare domain and it achieved state-of-the-art\nperformance on the medication recommendation task.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 05:11:38 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 02:36:05 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Shang", "Junyuan", ""], ["Ma", "Tengfei", ""], ["Xiao", "Cao", ""], ["Sun", "Jimeng", ""]]}, {"id": "1906.00347", "submitter": "Ronghang Hu", "authors": "Ronghang Hu, Daniel Fried, Anna Rohrbach, Dan Klein, Trevor Darrell\n  and Kate Saenko", "title": "Are You Looking? Grounding to Multiple Modalities in Vision-and-Language\n  Navigation", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vision-and-Language Navigation (VLN) requires grounding instructions, such as\n\"turn right and stop at the door\", to routes in a visual environment. The\nactual grounding can connect language to the environment through multiple\nmodalities, e.g. \"stop at the door\" might ground into visual objects, while\n\"turn right\" might rely only on the geometric structure of a route. We\ninvestigate where the natural language empirically grounds under two recent\nstate-of-the-art VLN models. Surprisingly, we discover that visual features may\nactually hurt these models: models which only use route structure, ablating\nvisual features, outperform their visual counterparts in unseen new\nenvironments on the benchmark Room-to-Room dataset. To better use all the\navailable modalities, we propose to decompose the grounding procedure into a\nset of expert models with access to different modalities (including object\ndetections) and ensemble them at prediction time, improving the performance of\nstate-of-the-art models on the VLN task.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 05:16:06 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 02:09:28 GMT"}, {"version": "v3", "created": "Mon, 10 Jun 2019 00:21:23 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Hu", "Ronghang", ""], ["Fried", "Daniel", ""], ["Rohrbach", "Anna", ""], ["Klein", "Dan", ""], ["Darrell", "Trevor", ""], ["Saenko", "Kate", ""]]}, {"id": "1906.00363", "submitter": "Cunxiang Wang", "authors": "Cunxiang Wang, Shuailong Liang, Yue Zhang, Xiaonan Li and Tian Gao", "title": "Does It Make Sense? And Why? A Pilot Study for Sense Making and\n  Explanation", "comments": "This paper has been accepted by ACL2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Introducing common sense to natural language understanding systems has\nreceived increasing research attention. It remains a fundamental question on\nhow to evaluate whether a system has a sense making capability. Existing\nbenchmarks measures commonsense knowledge indirectly and without explanation.\nIn this paper, we release a benchmark to directly test whether a system can\ndifferentiate natural language statements that make sense from those that do\nnot make sense. In addition, a system is asked to identify the most crucial\nreason why a statement does not make sense. We evaluate models trained over\nlarge-scale language modeling tasks as well as human performance, showing that\nthere are different challenges for system sense making.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 08:03:21 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 06:55:11 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Wang", "Cunxiang", ""], ["Liang", "Shuailong", ""], ["Zhang", "Yue", ""], ["Li", "Xiaonan", ""], ["Gao", "Tian", ""]]}, {"id": "1906.00376", "submitter": "Junjie Hu", "authors": "Junjie Hu, Mengzhou Xia, Graham Neubig, Jaime Carbonell", "title": "Domain Adaptation of Neural Machine Translation by Lexicon Induction", "comments": null, "journal-ref": "published at the 57th Annual Meeting of the Association for\n  Computational Linguistics (ACL). July 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been previously noted that neural machine translation (NMT) is very\nsensitive to domain shift. In this paper, we argue that this is a dual effect\nof the highly lexicalized nature of NMT, resulting in failure for sentences\nwith large numbers of unknown words, and lack of supervision for\ndomain-specific words. To remedy this problem, we propose an unsupervised\nadaptation method which fine-tunes a pre-trained out-of-domain NMT model using\na pseudo-in-domain corpus. Specifically, we perform lexicon induction to\nextract an in-domain lexicon, and construct a pseudo-parallel in-domain corpus\nby performing word-for-word back-translation of monolingual in-domain target\nsentences. In five domains over twenty pairwise adaptation settings and two\nmodel architectures, our method achieves consistent improvements without using\nany in-domain parallel sentences, improving up to 14 BLEU over unadapted\nmodels, and up to 2 BLEU over strong back-translation baselines.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 09:50:12 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Hu", "Junjie", ""], ["Xia", "Mengzhou", ""], ["Neubig", "Graham", ""], ["Carbonell", "Jaime", ""]]}, {"id": "1906.00378", "submitter": "Shizhe Chen", "authors": "Shizhe Chen, Qin Jin and Alexander Hauptmann", "title": "Unsupervised Bilingual Lexicon Induction from Mono-lingual Multimodal\n  Data", "comments": "Accepted by AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bilingual lexicon induction, translating words from the source language to\nthe target language, is a long-standing natural language processing task.\nRecent endeavors prove that it is promising to employ images as pivot to learn\nthe lexicon induction without reliance on parallel corpora. However, these\nvision-based approaches simply associate words with entire images, which are\nconstrained to translate concrete words and require object-centered images. We\nhumans can understand words better when they are within a sentence with\ncontext. Therefore, in this paper, we propose to utilize images and their\nassociated captions to address the limitations of previous approaches. We\npropose a multi-lingual caption model trained with different mono-lingual\nmultimodal data to map words in different languages into joint spaces. Two\ntypes of word representation are induced from the multi-lingual caption model:\nlinguistic features and localized visual features. The linguistic feature is\nlearned from the sentence contexts with visual semantic constraints, which is\nbeneficial to learn translation for words that are less visual-relevant. The\nlocalized visual feature is attended to the region in the image that correlates\nto the word, so that it alleviates the image restriction for salient visual\nrepresentation. The two types of features are complementary for word\ntranslation. Experimental results on multiple language pairs demonstrate the\neffectiveness of our proposed method, which substantially outperforms previous\nvision-based approaches without using any parallel sentences or supervision of\nseed word pairs.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 10:05:26 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Chen", "Shizhe", ""], ["Jin", "Qin", ""], ["Hauptmann", "Alexander", ""]]}, {"id": "1906.00408", "submitter": "Danielle Saunders", "authors": "Danielle Saunders, Felix Stahlberg, Adria de Gispert, Bill Byrne", "title": "Domain Adaptive Inference for Neural Machine Translation", "comments": "To appear at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate adaptive ensemble weighting for Neural Machine Translation,\naddressing the case of improving performance on a new and potentially unknown\ndomain without sacrificing performance on the original domain. We adapt\nsequentially across two Spanish-English and three English-German tasks,\ncomparing unregularized fine-tuning, L2 and Elastic Weight Consolidation. We\nthen report a novel scheme for adaptive NMT ensemble decoding by extending\nBayesian Interpolation with source information, and show strong improvements\nacross test domains without access to the domain label.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 14:00:05 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Saunders", "Danielle", ""], ["Stahlberg", "Felix", ""], ["de Gispert", "Adria", ""], ["Byrne", "Bill", ""]]}, {"id": "1906.00411", "submitter": "Serhad Sarica", "authors": "Serhad Sarica, Jianxi Luo and Kristin L. Wood", "title": "TechNet: Technology Semantic Network Based on Patent Data", "comments": "Expert Systems With Applications", "journal-ref": null, "doi": "10.1016/j.eswa.2019.112995", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing developments in general semantic networks, knowledge graphs and\nontology databases have motivated us to build a large-scale comprehensive\nsemantic network of technology-related data for engineering knowledge\ndiscovery, technology search and retrieval, and artificial intelligence for\nengineering design and innovation. Specially, we constructed a technology\nsemantic network (TechNet) that covers the elemental concepts in all domains of\ntechnology and their semantic associations by mining the complete U.S. patent\ndatabase from 1976. To derive the TechNet, natural language processing\ntechniques were utilized to extract terms from massive patent texts and recent\nword embedding algorithms were employed to vectorize such terms and establish\ntheir semantic relationships. We report and evaluate the TechNet for retrieving\nterms and their pairwise relevance that is meaningful from a technology and\nengineering design perspective. The TechNet may serve as an infrastructure to\nsupport a wide range of applications, e.g., technical text summaries, search\nquery predictions, relational knowledge discovery, and design ideation support,\nin the context of engineering and technology, and complement or enrich existing\nsemantic databases. To enable such applications, the TechNet is made public via\nan online interface and APIs for public users to retrieve technology-related\nterms and their relevancies.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 14:11:37 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 07:45:57 GMT"}, {"version": "v3", "created": "Wed, 7 Aug 2019 06:49:27 GMT"}, {"version": "v4", "created": "Fri, 4 Oct 2019 17:28:20 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Sarica", "Serhad", ""], ["Luo", "Jianxi", ""], ["Wood", "Kristin L.", ""]]}, {"id": "1906.00414", "submitter": "Shikib Mehri", "authors": "Shikib Mehri, Evgeniia Razumovskaia, Tiancheng Zhao and Maxine\n  Eskenazi", "title": "Pretraining Methods for Dialog Context Representation Learning", "comments": "Accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines various unsupervised pretraining objectives for learning\ndialog context representations. Two novel methods of pretraining dialog context\nencoders are proposed, and a total of four methods are examined. Each\npretraining objective is fine-tuned and evaluated on a set of downstream dialog\ntasks using the MultiWoz dataset and strong performance improvement is\nobserved. Further evaluation shows that our pretraining objectives result in\nnot only better performance, but also better convergence, models that are less\ndata hungry and have better domain generalizability.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 14:57:25 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 02:09:30 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Mehri", "Shikib", ""], ["Razumovskaia", "Evgeniia", ""], ["Zhao", "Tiancheng", ""], ["Eskenazi", "Maxine", ""]]}, {"id": "1906.00424", "submitter": "Laura Manor", "authors": "Laura Manor and Junyi Jessy Li", "title": "Plain English Summarization of Contracts", "comments": "The first Workshop on Natural Legal Language Processing (NLLP) will\n  be co-located with NAACL 2019 in Minneapolis, Minnesota, USA", "journal-ref": null, "doi": null, "report-no": "W19-2201", "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Unilateral contracts, such as terms of service, play a substantial role in\nmodern digital life. However, few users read these documents before accepting\nthe terms within, as they are too long and the language too complicated. We\npropose the task of summarizing such legal documents in plain English, which\nwould enable users to have a better understanding of the terms they are\naccepting.\n  We propose an initial dataset of legal text snippets paired with summaries\nwritten in plain English. We verify the quality of these summaries manually and\nshow that they involve heavy abstraction, compression, and simplification.\nInitial experiments show that unsupervised extractive summarization methods do\nnot perform well on this task due to the level of abstraction and style\ndifferences. We conclude with a call for resource and technique development for\nsimplification and style transfer for legal language.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 15:27:51 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Manor", "Laura", ""], ["Li", "Junyi Jessy", ""]]}, {"id": "1906.00434", "submitter": "Ting-En Lin", "authors": "Ting-En Lin, Hua Xu", "title": "Deep Unknown Intent Detection with Margin Loss", "comments": "To appear in ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying the unknown (novel) user intents that have never appeared in the\ntraining set is a challenging task in the dialogue system. In this paper, we\npresent a two-stage method for detecting unknown intents. We use bidirectional\nlong short-term memory (BiLSTM) network with the margin loss as the feature\nextractor. With margin loss, we can learn discriminative deep features by\nforcing the network to maximize inter-class variance and to minimize\nintra-class variance. Then, we feed the feature vectors to the density-based\nnovelty detection algorithm, local outlier factor (LOF), to detect unknown\nintents. Experiments on two benchmark datasets show that our method can yield\nconsistent improvements compared with the baseline methods.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 16:14:46 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Lin", "Ting-En", ""], ["Xu", "Hua", ""]]}, {"id": "1906.00499", "submitter": "Xiujun Li", "authors": "Zhirui Zhang and Xiujun Li and Jianfeng Gao and Enhong Chen", "title": "Budgeted Policy Learning for Task-Oriented Dialogue Systems", "comments": "10 pages, 7 figures, ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new approach that extends Deep Dyna-Q (DDQ) by\nincorporating a Budget-Conscious Scheduling (BCS) to best utilize a fixed,\nsmall amount of user interactions (budget) for learning task-oriented dialogue\nagents. BCS consists of (1) a Poisson-based global scheduler to allocate budget\nover different stages of training; (2) a controller to decide at each training\nstep whether the agent is trained using real or simulated experiences; (3) a\nuser goal sampling module to generate the experiences that are most effective\nfor policy learning. Experiments on a movie-ticket booking task with simulated\nand real users show that our approach leads to significant improvements in\nsuccess rate over the state-of-the-art baselines given the fixed budget.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 22:53:33 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Zhang", "Zhirui", ""], ["Li", "Xiujun", ""], ["Gao", "Jianfeng", ""], ["Chen", "Enhong", ""]]}, {"id": "1906.00500", "submitter": "Sashank Santhanam", "authors": "Sashank Santhanam, Samira Shaikh", "title": "A Survey of Natural Language Generation Techniques with a Focus on\n  Dialogue Systems - Past, Present and Future Directions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the hardest problems in the area of Natural Language Processing and\nArtificial Intelligence is automatically generating language that is coherent\nand understandable to humans. Teaching machines how to converse as humans do\nfalls under the broad umbrella of Natural Language Generation. Recent years\nhave seen unprecedented growth in the number of research articles published on\nthis subject in conferences and journals both by academic and industry\nresearchers. There have also been several workshops organized alongside\ntop-tier NLP conferences dedicated specifically to this problem. All this\nactivity makes it hard to clearly define the state of the field and reason\nabout its future directions. In this work, we provide an overview of this\nimportant and thriving area, covering traditional approaches, statistical\napproaches and also approaches that use deep neural networks. We provide a\ncomprehensive review towards building open domain dialogue systems, an\nimportant application of natural language generation. We find that,\npredominantly, the approaches for building dialogue systems use seq2seq or\nlanguage models architecture. Notably, we identify three important areas of\nfurther research towards building more effective dialogue systems: 1)\nincorporating larger context, including conversation context and world\nknowledge; 2) adding personae or personality in the NLG system; and 3)\novercoming dull and generic responses that affect the quality of\nsystem-produced responses. We provide pointers on how to tackle these open\nproblems through the use of cognitive architectures that mimic human language\nunderstanding and generation capabilities.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 22:55:14 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Santhanam", "Sashank", ""], ["Shaikh", "Samira", ""]]}, {"id": "1906.00513", "submitter": "Jialin Wu", "authors": "Jialin Wu, Zeyuan Hu and Raymond J. Mooney", "title": "Generating Question Relevant Captions to Aid Visual Question Answering", "comments": "ACL 2019 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual question answering (VQA) and image captioning require a shared body of\ngeneral knowledge connecting language and vision. We present a novel approach\nto improve VQA performance that exploits this connection by jointly generating\ncaptions that are targeted to help answer a specific visual question. The model\nis trained using an existing caption dataset by automatically determining\nquestion-relevant captions using an online gradient-based method. Experimental\nresults on the VQA v2 challenge demonstrates that our approach obtains\nstate-of-the-art VQA performance (e.g. 68.4% on the Test-standard set using a\nsingle model) by simultaneously generating question-relevant captions.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 00:42:08 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 14:41:07 GMT"}, {"version": "v3", "created": "Fri, 3 Jan 2020 19:12:39 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Wu", "Jialin", ""], ["Hu", "Zeyuan", ""], ["Mooney", "Raymond J.", ""]]}, {"id": "1906.00534", "submitter": "Xiao Zhang", "authors": "Xiao Zhang and Dan Goldwasser", "title": "Sentiment Tagging with Partial Labels using Modular Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Many NLP learning tasks can be decomposed into several distinct sub-tasks,\neach associated with a partial label. In this paper we focus on a popular class\nof learning problems, sequence prediction applied to several sentiment analysis\ntasks, and suggest a modular learning approach in which different sub-tasks are\nlearned using separate functional modules, combined to perform the final task\nwhile sharing information. Our experiments show this approach helps constrain\nthe learning process and can alleviate some of the supervision efforts.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 02:33:01 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 02:10:40 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Zhang", "Xiao", ""], ["Goldwasser", "Dan", ""]]}, {"id": "1906.00549", "submitter": "Siqi Bao", "authors": "Siqi Bao, Huang He, Fan Wang, Rongzhong Lian and Hua Wu", "title": "Know More about Each Other: Evolving Dialogue Strategy via Compound\n  Assessment", "comments": "Accepted for publication at ACL2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a novel Generation-Evaluation framework is developed for\nmulti-turn conversations with the objective of letting both participants know\nmore about each other. For the sake of rational knowledge utilization and\ncoherent conversation flow, a dialogue strategy which controls knowledge\nselection is instantiated and continuously adapted via reinforcement learning.\nUnder the deployed strategy, knowledge grounded conversations are conducted\nwith two dialogue agents. The generated dialogues are comprehensively evaluated\non aspects like informativeness and coherence, which are aligned with our\nobjective and human instinct. These assessments are integrated as a compound\nreward to guide the evolution of dialogue strategy via policy gradient.\nComprehensive experiments have been carried out on the publicly available\ndataset, demonstrating that the proposed method outperforms the other\nstate-of-the-art approaches significantly.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 03:45:15 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Bao", "Siqi", ""], ["He", "Huang", ""], ["Wang", "Fan", ""], ["Lian", "Rongzhong", ""], ["Wu", "Hua", ""]]}, {"id": "1906.00550", "submitter": "Zhiyu Chen", "authors": "Zhiyu Chen, Hanwen Zha, Honglei Liu, Wenhu Chen, Xifeng Yan, Yu Su", "title": "Global Textual Relation Embedding for Relational Understanding", "comments": "Accepted to ACL 2019. 5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained embeddings such as word embeddings and sentence embeddings are\nfundamental tools facilitating a wide range of downstream NLP tasks. In this\nwork, we investigate how to learn a general-purpose embedding of textual\nrelations, defined as the shortest dependency path between entities. Textual\nrelation embedding provides a level of knowledge between word/phrase level and\nsentence level, and we show that it can facilitate downstream tasks requiring\nrelational understanding of the text. To learn such an embedding, we create the\nlargest distant supervision dataset by linking the entire English ClueWeb09\ncorpus to Freebase. We use global co-occurrence statistics between textual and\nknowledge base relations as the supervision signal to train the embedding.\nEvaluation on two relational understanding tasks demonstrates the usefulness of\nthe learned textual relation embedding. The data and code can be found at\nhttps://github.com/czyssrs/GloREPlus\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 03:47:37 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Chen", "Zhiyu", ""], ["Zha", "Hanwen", ""], ["Liu", "Honglei", ""], ["Chen", "Wenhu", ""], ["Yan", "Xifeng", ""], ["Su", "Yu", ""]]}, {"id": "1906.00556", "submitter": "Elizabeth Salesky", "authors": "Elizabeth Salesky, Matthias Sperber, Alex Waibel", "title": "Fluent Translations from Disfluent Speech in End-to-End Speech\n  Translation", "comments": "Accepted at NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spoken language translation applications for speech suffer due to\nconversational speech phenomena, particularly the presence of disfluencies.\nWith the rise of end-to-end speech translation models, processing steps such as\ndisfluency removal that were previously an intermediate step between speech\nrecognition and machine translation need to be incorporated into model\narchitectures. We use a sequence-to-sequence model to translate from noisy,\ndisfluent speech to fluent text with disfluencies removed using the recently\ncollected `copy-edited' references for the Fisher Spanish-English dataset. We\nare able to directly generate fluent translations and introduce considerations\nabout how to evaluate success on this task. This work provides a baseline for a\nnew task, the translation of conversational speech with joint removal of\ndisfluencies.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 03:57:11 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Salesky", "Elizabeth", ""], ["Sperber", "Matthias", ""], ["Waibel", "Alex", ""]]}, {"id": "1906.00565", "submitter": "Mingda Chen", "authors": "Mingda Chen, Qingming Tang, Sam Wiseman, Kevin Gimpel", "title": "Controllable Paraphrase Generation with a Syntactic Exemplar", "comments": "ACL 2019 Long", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior work on controllable text generation usually assumes that the\ncontrolled attribute can take on one of a small set of values known a priori.\nIn this work, we propose a novel task, where the syntax of a generated sentence\nis controlled rather by a sentential exemplar. To evaluate quantitatively with\nstandard metrics, we create a novel dataset with human annotations. We also\ndevelop a variational model with a neural module specifically designed for\ncapturing syntactic knowledge and several multitask training objectives to\npromote disentangled representation learning. Empirically, the proposed model\nis observed to achieve improvements over baselines and learn to capture\ndesirable characteristics.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 04:29:22 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Chen", "Mingda", ""], ["Tang", "Qingming", ""], ["Wiseman", "Sam", ""], ["Gimpel", "Kevin", ""]]}, {"id": "1906.00575", "submitter": "Hai Ye", "authors": "Hai Ye, Wenjie Li and Lu Wang", "title": "Jointly Learning Semantic Parser and Natural Language Generator via Dual\n  Information Maximization", "comments": "Accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic parsing aims to transform natural language (NL) utterances into\nformal meaning representations (MRs), whereas an NL generator achieves the\nreverse: producing a NL description for some given MRs. Despite this intrinsic\nconnection, the two tasks are often studied separately in prior work. In this\npaper, we model the duality of these two tasks via a joint learning framework,\nand demonstrate its effectiveness of boosting the performance on both tasks.\nConcretely, we propose a novel method of dual information maximization (DIM) to\nregularize the learning process, where DIM empirically maximizes the\nvariational lower bounds of expected joint distributions of NL and MRs. We\nfurther extend DIM to a semi-supervision setup (SemiDIM), which leverages\nunlabeled data of both tasks. Experiments on three datasets of dialogue\nmanagement and code generation (and summarization) show that performance on\nboth semantic parsing and NL generation can be consistently improved by DIM, in\nboth supervised and semi-supervised setups.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 05:00:09 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 01:28:29 GMT"}, {"version": "v3", "created": "Thu, 13 Jun 2019 22:25:11 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Ye", "Hai", ""], ["Li", "Wenjie", ""], ["Wang", "Lu", ""]]}, {"id": "1906.00579", "submitter": "Johanes Effendi", "authors": "Johanes Effendi, Andros Tjandra, Sakriani Sakti, Satoshi Nakamura", "title": "Listening while Speaking and Visualizing: Improving ASR through\n  Multimodal Chain", "comments": "Accepted in IEEE ASRU 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previously, a machine speech chain, which is based on sequence-to-sequence\ndeep learning, was proposed to mimic speech perception and production behavior.\nSuch chains separately processed listening and speaking by automatic speech\nrecognition (ASR) and text-to-speech synthesis (TTS) and simultaneously enabled\nthem to teach each other in semi-supervised learning when they received\nunpaired data. Unfortunately, this speech chain study is limited to speech and\ntextual modalities. In fact, natural communication is actually multimodal and\ninvolves both auditory and visual sensory systems. Although the said speech\nchain reduces the requirement of having a full amount of paired data, in this\ncase we still need a large amount of unpaired data. In this research, we take a\nfurther step and construct a multimodal chain and design a closely knit chain\narchitecture that combines ASR, TTS, image captioning, and image production\nmodels into a single framework. The framework allows the training of each\ncomponent without requiring a large number of parallel multimodal data. Our\nexperimental results also show that an ASR can be further trained without\nspeech and text data and cross-modal data augmentation remains possible through\nour proposed chain, which improves the ASR performance.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 05:25:42 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 05:09:27 GMT"}, {"version": "v3", "created": "Thu, 14 Nov 2019 12:05:12 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Effendi", "Johanes", ""], ["Tjandra", "Andros", ""], ["Sakti", "Sakriani", ""], ["Nakamura", "Satoshi", ""]]}, {"id": "1906.00580", "submitter": "Hongyu Zang", "authors": "Hongyu Zang and Xiaojun Wan", "title": "Massive Styles Transfer with Limited Labeled Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language style transfer has attracted more and more attention in the past few\nyears. Recent researches focus on improving neural models targeting at\ntransferring from one style to the other with labeled data. However,\ntransferring across multiple styles is often very useful in real-life\napplications. Previous researches of language style transfer have two main\ndeficiencies: dependency on massive labeled data and neglect of mutual\ninfluence among different style transfer tasks. In this paper, we propose a\nmulti-agent style transfer system (MAST) for addressing multiple style transfer\ntasks with limited labeled data, by leveraging abundant unlabeled data and the\nmutual benefit among the multiple styles. A style transfer agent in our system\nnot only learns from unlabeled data by using techniques like denoising\nauto-encoder and back-translation, but also learns to cooperate with other\nstyle transfer agents in a self-organization manner. We conduct our experiments\nby simulating a set of real-world style transfer tasks with multiple versions\nof the Bible. Our model significantly outperforms the other competitive\nmethods. Extensive results and analysis further verify the efficacy of our\nproposed system.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 05:27:05 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Zang", "Hongyu", ""], ["Wan", "Xiaojun", ""]]}, {"id": "1906.00584", "submitter": "Hongyu Zang", "authors": "Hongyu Zang and Xiaojun Wan", "title": "A Semi-Supervised Approach for Low-Resourced Text Generation", "comments": "Finished in 2017, a foundation work for \"Massive Styles Transfer with\n  Limited Labeled Data\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, encoder-decoder neural models have achieved great success on text\ngeneration tasks. However, one problem of this kind of models is that their\nperformances are usually limited by the scale of well-labeled data, which are\nvery expensive to get. The low-resource (of labeled data) problem is quite\ncommon in different task generation tasks, but unlabeled data are usually\nabundant. In this paper, we propose a method to make use of the unlabeled data\nto improve the performance of such models in the low-resourced circumstances.\nWe use denoising auto-encoder (DAE) and language model (LM) based reinforcement\nlearning (RL) to enhance the training of encoder and decoder with unlabeled\ndata. Our method shows adaptability for different text generation tasks, and\nmakes significant improvements over basic text generation models.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 05:42:33 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Zang", "Hongyu", ""], ["Wan", "Xiaojun", ""]]}, {"id": "1906.00591", "submitter": "Gabriel Stanovsky", "authors": "Gabriel Stanovsky, Noah A. Smith, Luke Zettlemoyer", "title": "Evaluating Gender Bias in Machine Translation", "comments": "Accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present the first challenge set and evaluation protocol for the analysis\nof gender bias in machine translation (MT). Our approach uses two recent\ncoreference resolution datasets composed of English sentences which cast\nparticipants into non-stereotypical gender roles (e.g., \"The doctor asked the\nnurse to help her in the operation\"). We devise an automatic gender bias\nevaluation method for eight target languages with grammatical gender, based on\nmorphological analysis (e.g., the use of female inflection for the word\n\"doctor\"). Our analyses show that four popular industrial MT systems and two\nrecent state-of-the-art academic MT models are significantly prone to\ngender-biased translation errors for all tested target languages. Our data and\ncode are made publicly available.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 06:21:38 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Stanovsky", "Gabriel", ""], ["Smith", "Noah A.", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1906.00592", "submitter": "Baosong Yang", "authors": "Baosong Yang, Longyue Wang, Derek F. Wong, Lidia S. Chao, Zhaopeng Tu", "title": "Assessing the Ability of Self-Attention Networks to Learn Word Order", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-attention networks (SAN) have attracted a lot of interests due to their\nhigh parallelization and strong performance on a variety of NLP tasks, e.g.\nmachine translation. Due to the lack of recurrence structure such as recurrent\nneural networks (RNN), SAN is ascribed to be weak at learning positional\ninformation of words for sequence modeling. However, neither this speculation\nhas been empirically confirmed, nor explanations for their strong performances\non machine translation tasks when \"lacking positional information\" have been\nexplored. To this end, we propose a novel word reordering detection task to\nquantify how well the word order information learned by SAN and RNN.\nSpecifically, we randomly move one word to another position, and examine\nwhether a trained model can detect both the original and inserted positions.\nExperimental results reveal that: 1) SAN trained on word reordering detection\nindeed has difficulty learning the positional information even with the\nposition embedding; and 2) SAN trained on machine translation learns better\npositional information than its RNN counterpart, in which position embedding\nplays a critical role. Although recurrence structure make the model more\nuniversally-effective on learning word order, learning objectives matter more\nin the downstream tasks such as machine translation.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 06:32:29 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Yang", "Baosong", ""], ["Wang", "Longyue", ""], ["Wong", "Derek F.", ""], ["Chao", "Lidia S.", ""], ["Tu", "Zhaopeng", ""]]}, {"id": "1906.00638", "submitter": "Hankz Hankui Zhuo", "authors": "Feng Liao and Hankz Hankui Zhuo and Xiaoling Huang and Yu Zhang", "title": "Federated Hierarchical Hybrid Networks for Clickbait Detection", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Online media outlets adopt clickbait techniques to lure readers to click on\narticles in a bid to expand their reach and subsequently increase revenue\nthrough ad monetization. As the adverse effects of clickbait attract more and\nmore attention, researchers have started to explore machine learning techniques\nto automatically detect clickbaits. Previous work on clickbait detection\nassumes that all the training data is available locally during training. In\nmany real-world applications, however, training data is generally distributedly\nstored by different parties (e.g., different parties maintain data with\ndifferent feature spaces), and the parties cannot share their data with each\nother due to data privacy issues. It is challenging to build models of\nhigh-quality federally for detecting clickbaits effectively without data\nsharing. In this paper, we propose a federated training framework, which is\ncalled federated hierarchical hybrid networks, to build clickbait detection\nmodels, where the titles and contents are stored by different parties, whose\nrelationships must be exploited for clickbait detection. We empirically\ndemonstrate that our approach is effective by comparing our approach to the\nstate-of-the-art approaches using datasets from social media.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 08:50:04 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Liao", "Feng", ""], ["Zhuo", "Hankz Hankui", ""], ["Huang", "Xiaoling", ""], ["Zhang", "Yu", ""]]}, {"id": "1906.00663", "submitter": "Jakob Prange", "authors": "Jakob Prange, Nathan Schneider, Omri Abend", "title": "Semantically Constrained Multilayer Annotation: The Case of Coreference", "comments": "Accepted to The First International Workshop on Designing Meaning\n  Representations (DMR), 2019 (in conjunction with ACL 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a coreference annotation scheme as a layer on top of the Universal\nConceptual Cognitive Annotation foundational layer, treating units in\npredicate-argument structure as a basis for entity and event mentions. We argue\nthat this allows coreference annotators to sidestep some of the challenges\nfaced in other schemes, which do not enforce consistency with\npredicate-argument structure and vary widely in what kinds of mentions they\nannotate and how. The proposed approach is examined with a pilot annotation\nstudy and compared with annotations from other schemes.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 09:39:33 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 12:02:31 GMT"}, {"version": "v3", "created": "Tue, 11 Jun 2019 13:37:11 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Prange", "Jakob", ""], ["Schneider", "Nathan", ""], ["Abend", "Omri", ""]]}, {"id": "1906.00671", "submitter": "Casper Hansen", "authors": "Casper Hansen and Christian Hansen and Jakob Grue Simonsen and Stephen\n  Alstrup and Christina Lioma", "title": "Unsupervised Neural Generative Semantic Hashing", "comments": "SIGIR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast similarity search is a key component in large-scale information\nretrieval, where semantic hashing has become a popular strategy for\nrepresenting documents as binary hash codes. Recent advances in this area have\nbeen obtained through neural network based models: generative models trained by\nlearning to reconstruct the original documents. We present a novel unsupervised\ngenerative semantic hashing approach, \\textit{Ranking based Semantic Hashing}\n(RBSH) that consists of both a variational and a ranking based component.\nSimilarly to variational autoencoders, the variational component is trained to\nreconstruct the original document conditioned on its generated hash code, and\nas in prior work, it only considers documents individually. The ranking\ncomponent solves this limitation by incorporating inter-document similarity\ninto the hash code generation, modelling document ranking through a hinge loss.\nTo circumvent the need for labelled data to compute the hinge loss, we use a\nweak labeller and thus keep the approach fully unsupervised.\n  Extensive experimental evaluation on four publicly available datasets against\ntraditional baselines and recent state-of-the-art methods for semantic hashing\nshows that RBSH significantly outperforms all other methods across all\nevaluated hash code lengths. In fact, RBSH hash codes are able to perform\nsimilarly to state-of-the-art hash codes while using 2-4x fewer bits.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 09:52:17 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Hansen", "Casper", ""], ["Hansen", "Christian", ""], ["Simonsen", "Jakob Grue", ""], ["Alstrup", "Stephen", ""], ["Lioma", "Christina", ""]]}, {"id": "1906.00672", "submitter": "Mutian He", "authors": "Mutian He, Yan Deng, Lei He", "title": "Robust Sequence-to-Sequence Acoustic Modeling with Stepwise Monotonic\n  Attention for Neural TTS", "comments": "Accepted by Interspeech 2019, Graz, Austria; v3: typo fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural TTS has demonstrated strong capabilities to generate human-like speech\nwith high quality and naturalness, while its generalization to out-of-domain\ntexts is still a challenging task, with regard to the design of attention-based\nsequence-to-sequence acoustic modeling. Various errors occur in those inputs\nwith unseen context, including attention collapse, skipping, repeating, etc.,\nwhich limits the broader applications. In this paper, we propose a novel\nstepwise monotonic attention method in sequence-to-sequence acoustic modeling\nto improve the robustness on out-of-domain inputs. The method utilizes the\nstrict monotonic property in TTS with constraints on monotonic hard attention\nthat the alignments between inputs and outputs sequence must be not only\nmonotonic but allowing no skipping on inputs. Soft attention could be used to\nevade mismatch between training and inference. The experimental results show\nthat the proposed method could achieve significant improvements in robustness\non out-of-domain scenarios for phoneme-based models, without any regression on\nthe in-domain naturalness test.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 09:52:19 GMT"}, {"version": "v2", "created": "Sat, 29 Jun 2019 15:00:29 GMT"}, {"version": "v3", "created": "Tue, 6 Aug 2019 06:50:33 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["He", "Mutian", ""], ["Deng", "Yan", ""], ["He", "Lei", ""]]}, {"id": "1906.00674", "submitter": "Casper Hansen", "authors": "Casper Hansen and Christian Hansen and Stephen Alstrup and Jakob Grue\n  Simonsen and Christina Lioma", "title": "Contextually Propagated Term Weights for Document Representation", "comments": "SIGIR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings predict a word from its neighbours by learning small, dense\nembedding vectors. In practice, this prediction corresponds to a semantic score\ngiven to the predicted word (or term weight). We present a novel model that,\ngiven a target word, redistributes part of that word's weight (that has been\ncomputed with word embeddings) across words occurring in similar contexts as\nthe target word. Thus, our model aims to simulate how semantic meaning is\nshared by words occurring in similar contexts, which is incorporated into\nbag-of-words document representations. Experimental evaluation in an\nunsupervised setting against 8 state of the art baselines shows that our model\nyields the best micro and macro F1 scores across datasets of increasing\ndifficulty.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 09:52:47 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Hansen", "Casper", ""], ["Hansen", "Christian", ""], ["Alstrup", "Stephen", ""], ["Simonsen", "Jakob Grue", ""], ["Lioma", "Christina", ""]]}, {"id": "1906.00687", "submitter": "Canran Xu", "authors": "Canran Xu, Ruijiang Li", "title": "Relation Embedding with Dihedral Group in Knowledge Graph", "comments": "ACL 2019", "journal-ref": null, "doi": "10.18653/v1/P19-1026", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Link prediction is critical for the application of incomplete knowledge graph\n(KG) in the downstream tasks. As a family of effective approaches for link\npredictions, embedding methods try to learn low-rank representations for both\nentities and relations such that the bilinear form defined therein is a\nwell-behaved scoring function. Despite of their successful performances,\nexisting bilinear forms overlook the modeling of relation compositions,\nresulting in lacks of interpretability for reasoning on KG. To fulfill this\ngap, we propose a new model called DihEdral, named after dihedral symmetry\ngroup. This new model learns knowledge graph embeddings that can capture\nrelation compositions by nature. Furthermore, our approach models the relation\nembeddings parametrized by discrete values, thereby decrease the solution space\ndrastically. Our experiments show that DihEdral is able to capture all desired\nproperties such as (skew-) symmetry, inversion and (non-) Abelian composition,\nand outperforms existing bilinear form based approach and is comparable to or\nbetter than deep learning models such as ConvE.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 10:13:32 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Xu", "Canran", ""], ["Li", "Ruijiang", ""]]}, {"id": "1906.00742", "submitter": "Danushka Bollegala", "authors": "Masahiro Kaneko and Danushka Bollegala", "title": "Gender-preserving Debiasing for Pre-trained Word Embeddings", "comments": "Accepted as a long paper to the 57th Annual Conference of the\n  Association for Computational Linguistics (ACL-2019)", "journal-ref": "Association for Computational Linguistics (ACL-2019)", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings learnt from massive text collections have demonstrated\nsignificant levels of discriminative biases such as gender, racial or ethnic\nbiases, which in turn bias the down-stream NLP applications that use those word\nembeddings. Taking gender-bias as a working example, we propose a debiasing\nmethod that preserves non-discriminative gender-related information, while\nremoving stereotypical discriminative gender biases from pre-trained word\nembeddings. Specifically, we consider four types of information:\n\\emph{feminine}, \\emph{masculine}, \\emph{gender-neutral} and\n\\emph{stereotypical}, which represent the relationship between gender vs. bias,\nand propose a debiasing method that (a) preserves the gender-related\ninformation in feminine and masculine words, (b) preserves the neutrality in\ngender-neutral words, and (c) removes the biases from stereotypical words.\nExperimental results on several previously proposed benchmark datasets show\nthat our proposed method can debias pre-trained word embeddings better than\nexisting SoTA methods proposed for debiasing word embeddings while preserving\ngender-related but non-discriminative information.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 12:26:25 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Kaneko", "Masahiro", ""], ["Bollegala", "Danushka", ""]]}, {"id": "1906.00744", "submitter": "Denis Yarats", "authors": "Hengyuan Hu, Denis Yarats, Qucheng Gong, Yuandong Tian, Mike Lewis", "title": "Hierarchical Decision Making by Generating and Following Natural\n  Language Instructions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore using latent natural language instructions as an expressive and\ncompositional representation of complex actions for hierarchical decision\nmaking. Rather than directly selecting micro-actions, our agent first generates\na latent plan in natural language, which is then executed by a separate model.\nWe introduce a challenging real-time strategy game environment in which the\nactions of a large number of units must be coordinated across long time scales.\nWe gather a dataset of 76 thousand pairs of instructions and executions from\nhuman play, and train instructor and executor models. Experiments show that\nmodels using natural language as a latent variable significantly outperform\nmodels that directly imitate human actions. The compositional structure of\nlanguage proves crucial to its effectiveness for action representation. We also\nrelease our code, models and data.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 12:28:50 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 08:46:09 GMT"}, {"version": "v3", "created": "Tue, 20 Aug 2019 20:53:30 GMT"}, {"version": "v4", "created": "Tue, 27 Aug 2019 19:24:48 GMT"}, {"version": "v5", "created": "Wed, 2 Oct 2019 16:10:21 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Hu", "Hengyuan", ""], ["Yarats", "Denis", ""], ["Gong", "Qucheng", ""], ["Tian", "Yuandong", ""], ["Lewis", "Mike", ""]]}, {"id": "1906.00790", "submitter": "Mounica Maddela", "authors": "Mounica Maddela, Wei Xu, Daniel Preo\\c{t}iuc-Pietro", "title": "Multi-task Pairwise Neural Ranking for Hashtag Segmentation", "comments": "12 pages, ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hashtags are often employed on social media and beyond to add metadata to a\ntextual utterance with the goal of increasing discoverability, aiding search,\nor providing additional semantics. However, the semantic content of hashtags is\nnot straightforward to infer as these represent ad-hoc conventions which\nfrequently include multiple words joined together and can include abbreviations\nand unorthodox spellings. We build a dataset of 12,594 hashtags split into\nindividual segments and propose a set of approaches for hashtag segmentation by\nframing it as a pairwise ranking problem between candidate segmentations. Our\nnovel neural approaches demonstrate 24.6% error reduction in hashtag\nsegmentation accuracy compared to the current state-of-the-art method. Finally,\nwe demonstrate that a deeper understanding of hashtag semantics obtained\nthrough segmentation is useful for downstream applications such as sentiment\nanalysis, for which we achieved a 2.6% increase in average recall on the\nSemEval 2017 sentiment analysis dataset.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 13:28:33 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 20:07:28 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Maddela", "Mounica", ""], ["Xu", "Wei", ""], ["Preo\u0163iuc-Pietro", "Daniel", ""]]}, {"id": "1906.00800", "submitter": "Artem Artemov", "authors": "A.Artemov, I.Bolokhov, D.Kem, I.Khasenevich", "title": "Neural Network-based Object Classification by Known and Unknown Features\n  (Based on Text Queries)", "comments": "7 pages, 3 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article presents a method that improves the quality of classification of\nobjects described by a combination of known and unknown features. The method is\nbased on modernized Informational Neurobayesian Approach with consideration of\nunknown features. The proposed method was developed and trained on 1500 text\nqueries of Promobot users in Russian to classify them into 20 categories\n(classes). As a result, the use of the method allowed to completely solve the\nproblem of misclassification for queries with combining known and unknown\nfeatures of the model. The theoretical substantiation of the method is\npresented by the formulated and proved theorem On the Model with Limited\nKnowledge. It states, that in conditions of limited data, an equal number of\nequally unknown features of an object cannot have different significance for\nthe classification problem.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 13:38:20 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Artemov", "A.", ""], ["Bolokhov", "I.", ""], ["Kem", "D.", ""], ["Khasenevich", "I.", ""]]}, {"id": "1906.00839", "submitter": "Sandeep Attree", "authors": "Sandeep Attree", "title": "Gendered Ambiguous Pronouns Shared Task: Boosting Model Confidence by\n  Evidence Pooling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a strong set of results for resolving gendered ambiguous\npronouns on the Gendered Ambiguous Pronouns shared task. The model presented\nhere draws upon the strengths of state-of-the-art language and coreference\nresolution models, and introduces a novel evidence-based deep learning\narchitecture. Injecting evidence from the coreference models compliments the\nbase architecture, and analysis shows that the model is not hindered by their\nweaknesses, specifically gender bias. The modularity and simplicity of the\narchitecture make it very easy to extend for further improvement and applicable\nto other NLP problems. Evaluation on GAP test data results in a\nstate-of-the-art performance at 92.5% F1 (gender bias of 0.97), edging closer\nto the human performance of 96.6%. The end-to-end solution presented here\nplaced 1st in the Kaggle competition, winning by a significant lead. The code\nis available at https://github.com/sattree/gap.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 14:37:57 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Attree", "Sandeep", ""]]}, {"id": "1906.00872", "submitter": "Shizhe Chen", "authors": "Shizhe Chen, Qin Jin and Jianlong Fu", "title": "From Words to Sentences: A Progressive Learning Approach for\n  Zero-resource Machine Translation with Visual Pivots", "comments": "Accepted by IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The neural machine translation model has suffered from the lack of\nlarge-scale parallel corpora. In contrast, we humans can learn multi-lingual\ntranslations even without parallel texts by referring our languages to the\nexternal world. To mimic such human learning behavior, we employ images as\npivots to enable zero-resource translation learning. However, a picture tells a\nthousand words, which makes multi-lingual sentences pivoted by the same image\nnoisy as mutual translations and thus hinders the translation model learning.\nIn this work, we propose a progressive learning approach for image-pivoted\nzero-resource machine translation. Since words are less diverse when grounded\nin the image, we first learn word-level translation with image pivots, and then\nprogress to learn the sentence-level translation by utilizing the learned word\ntranslation to suppress noises in image-pivoted multi-lingual sentences.\nExperimental results on two widely used image-pivot translation datasets,\nIAPR-TC12 and Multi30k, show that the proposed approach significantly\noutperforms other state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 15:28:48 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Chen", "Shizhe", ""], ["Jin", "Qin", ""], ["Fu", "Jianlong", ""]]}, {"id": "1906.00908", "submitter": "Cristiano Chesi", "authors": "Cristiano Chesi", "title": "Phase-based Minimalist Parsing and complexity in non-local dependencies", "comments": null, "journal-ref": "Proceedings of CLiC-it 2017. CEUR WORKSHOP PROCEEDINGS, ROMA:CEUR\n  Workshop Proceedings, ISBN: 9788899982768, ISSN: 1613-0073, Rome, 11-13\n  December 2017", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A cognitively plausible parsing algorithm should perform like the human\nparser in critical contexts. Here I propose an adaptation of Earley's parsing\nalgorithm, suitable for Phase-based Minimalist Grammars (PMG, Chesi 2012), that\nis able to predict complexity effects in performance. Focusing on self-paced\nreading experiments of object clefts sentences (Warren & Gibson 2005) I will\nassociate to parsing a complexity metric based on cued features to be retrieved\nat the verb segment (Feature Retrieval & Encoding Cost, FREC). FREC is\ncrucially based on the usage of memory predicted by the discussed parsing\nalgorithm and it correctly fits with the reading time revealed.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 16:20:04 GMT"}, {"version": "v2", "created": "Sat, 17 Jul 2021 14:03:08 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Chesi", "Cristiano", ""]]}, {"id": "1906.00923", "submitter": "Michael Fromm", "authors": "Michael Fromm, Evgeniy Faerman, Thomas Seidl", "title": "TACAM: Topic And Context Aware Argument Mining", "comments": null, "journal-ref": null, "doi": "10.1145/3350546.3352506", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we address the problem of argument search. The purpose of\nargument search is the distillation of pro and contra arguments for requested\ntopics from large text corpora. In previous works, the usual approach is to use\na standard search engine to extract text parts which are relevant to the given\ntopic and subsequently use an argument recognition algorithm to select\narguments from them. The main challenge in the argument recognition task, which\nis also known as argument mining, is that often sentences containing arguments\nare structurally similar to purely informative sentences without any stance\nabout the topic. In fact, they only differ semantically. Most approaches use\ntopic or search term information only for the first search step and therefore\nassume that arguments can be classified independently of a topic. We argue that\ntopic information is crucial for argument mining, since the topic defines the\nsemantic context of an argument. Precisely, we propose different models for the\nclassification of arguments, which take information about a topic of an\nargument into account. Moreover, to enrich the context of a topic and to let\nmodels understand the context of the potential argument better, we integrate\ninformation from different external sources such as Knowledge Graphs or\npre-trained NLP models. Our evaluation shows that considering topic\ninformation, especially in connection with external information, provides a\nsignificant performance boost for the argument mining task.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 07:06:58 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2019 12:33:44 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Fromm", "Michael", ""], ["Faerman", "Evgeniy", ""], ["Seidl", "Thomas", ""]]}, {"id": "1906.01010", "submitter": "Glorianna Jagfeld", "authors": "Glorianna Jagfeld", "title": "A computational linguistic study of personal recovery in bipolar\n  disorder", "comments": "ACL Student Research Workshop 2019, research proposal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mental health research can benefit increasingly fruitfully from computational\nlinguistics methods, given the abundant availability of language data in the\ninternet and advances of computational tools. This interdisciplinary project\nwill collect and analyse social media data of individuals diagnosed with\nbipolar disorder with regard to their recovery experiences. Personal recovery -\nliving a satisfying and contributing life along symptoms of severe mental\nhealth issues - so far has only been investigated qualitatively with structured\ninterviews and quantitatively with standardised questionnaires with mainly\nEnglish-speaking participants in Western countries. Complementary to this\nevidence, computational linguistic methods allow us to analyse first-person\naccounts shared online in large quantities, representing unstructured settings\nand a more heterogeneous, multilingual population, to draw a more complete\npicture of the aspects and mechanisms of personal recovery in bipolar disorder.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 18:17:09 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Jagfeld", "Glorianna", ""]]}, {"id": "1906.01032", "submitter": "Ben Gelman", "authors": "Ben Gelman, Bryan Hoyle, Jessica Moore, Joshua Saxe, David Slater", "title": "A Language-Agnostic Model for Semantic Source Code Labeling", "comments": "MASES 2018 Publication", "journal-ref": null, "doi": "10.1145/3243127.3243132", "report-no": null, "categories": "cs.LG cs.CL cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code search and comprehension have become more difficult in recent years due\nto the rapid expansion of available source code. Current tools lack a way to\nlabel arbitrary code at scale while maintaining up-to-date representations of\nnew programming languages, libraries, and functionalities. Comprehensive\nlabeling of source code enables users to search for documents of interest and\nobtain a high-level understanding of their contents. We use Stack Overflow code\nsnippets and their tags to train a language-agnostic, deep convolutional neural\nnetwork to automatically predict semantic labels for source code documents. On\nStack Overflow code snippets, we demonstrate a mean area under ROC of 0.957\nover a long-tailed list of 4,508 tags. We also manually validate the model\noutputs on a diverse set of unlabeled source code documents retrieved from\nGithub, and we obtain a top-1 accuracy of 86.6%. This strongly indicates that\nthe model successfully transfers its knowledge from Stack Overflow snippets to\narbitrary source code documents.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 19:21:42 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Gelman", "Ben", ""], ["Hoyle", "Bryan", ""], ["Moore", "Jessica", ""], ["Saxe", "Joshua", ""], ["Slater", "David", ""]]}, {"id": "1906.01037", "submitter": "Terra Blevins", "authors": "Terra Blevins and Luke Zettlemoyer", "title": "Better Character Language Modeling Through Morphology", "comments": "Accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We incorporate morphological supervision into character language models\n(CLMs) via multitasking and show that this addition improves bits-per-character\n(BPC) performance across 24 languages, even when the morphology data and\nlanguage modeling data are disjoint. Analyzing the CLMs shows that inflected\nwords benefit more from explicitly modeling morphology than uninflected words,\nand that morphological supervision improves performance even as the amount of\nlanguage modeling data grows. We then transfer morphological supervision across\nlanguages to improve language modeling performance in the low-resource setting.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 19:30:51 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 21:13:01 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Blevins", "Terra", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1906.01038", "submitter": "Christina Niklaus", "authors": "Christina Niklaus, Matthias Cetto, Andre Freitas, Siegfried Handschuh", "title": "Transforming Complex Sentences into a Semantic Hierarchy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present an approach for recursively splitting and rephrasing complex\nEnglish sentences into a novel semantic hierarchy of simplified sentences, with\neach of them presenting a more regular structure that may facilitate a wide\nvariety of artificial intelligence tasks, such as machine translation (MT) or\ninformation extraction (IE). Using a set of hand-crafted transformation rules,\ninput sentences are recursively transformed into a two-layered hierarchical\nrepresentation in the form of core sentences and accompanying contexts that are\nlinked via rhetorical relations. In this way, the semantic relationship of the\ndecomposed constituents is preserved in the output, maintaining its\ninterpretability for downstream applications. Both a thorough manual analysis\nand automatic evaluation across three datasets from two different domains\ndemonstrate that the proposed syntactic simplification approach outperforms the\nstate of the art in structural text simplification. Moreover, an extrinsic\nevaluation shows that when applying our framework as a preprocessing step the\nperformance of state-of-the-art Open IE systems can be improved by up to 346%\nin precision and 52% in recall. To enable reproducible research, all code is\nprovided online.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 19:33:13 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Niklaus", "Christina", ""], ["Cetto", "Matthias", ""], ["Freitas", "Andre", ""], ["Handschuh", "Siegfried", ""]]}, {"id": "1906.01040", "submitter": "Melody Guan", "authors": "Melody Y. Guan, Gregory Valiant", "title": "A Surprising Density of Illusionable Natural Speech", "comments": "CogSci 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on adversarial examples has demonstrated that most natural inputs\ncan be perturbed to fool even state-of-the-art machine learning systems. But\ndoes this happen for humans as well? In this work, we investigate: what\nfraction of natural instances of speech can be turned into \"illusions\" which\neither alter humans' perception or result in different people having\nsignificantly different perceptions? We first consider the McGurk effect, the\nphenomenon by which adding a carefully chosen video clip to the audio channel\naffects the viewer's perception of what is said (McGurk and MacDonald, 1976).\nWe obtain empirical estimates that a significant fraction of both words and\nsentences occurring in natural speech have some susceptibility to this effect.\nWe also learn models for predicting McGurk illusionability. Finally we\ndemonstrate that the Yanny or Laurel auditory illusion (Pressnitzer et al.,\n2018) is not an isolated occurrence by generating several very different new\ninstances. We believe that the surprising density of illusionable natural\nspeech warrants further investigation, from the perspectives of both security\nand cognitive science. Supplementary videos are available at:\nhttps://www.youtube.com/playlist?list=PLaX7t1K-e_fF2iaenoKznCatm0RC37B_k.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 19:33:43 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 00:37:28 GMT"}, {"version": "v3", "created": "Mon, 19 Aug 2019 05:52:13 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Guan", "Melody Y.", ""], ["Valiant", "Gregory", ""]]}, {"id": "1906.01076", "submitter": "Dani Yogatama", "authors": "Cyprien de Masson d'Autume, Sebastian Ruder, Lingpeng Kong, Dani\n  Yogatama", "title": "Episodic Memory in Lifelong Language Learning", "comments": "Proceedings of NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a lifelong language learning setup where a model needs to learn\nfrom a stream of text examples without any dataset identifier. We propose an\nepisodic memory model that performs sparse experience replay and local\nadaptation to mitigate catastrophic forgetting in this setup. Experiments on\ntext classification and question answering demonstrate the complementary\nbenefits of sparse experience replay and local adaptation to allow the model to\ncontinuously learn from new datasets. We also show that the space complexity of\nthe episodic memory module can be reduced significantly (~50-90%) by randomly\nchoosing which examples to store in memory with a minimal decrease in\nperformance. We consider an episodic memory component as a crucial building\nblock of general linguistic intelligence and see our model as a first step in\nthat direction.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 20:50:58 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 09:33:28 GMT"}, {"version": "v3", "created": "Tue, 26 Nov 2019 00:57:40 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["d'Autume", "Cyprien de Masson", ""], ["Ruder", "Sebastian", ""], ["Kong", "Lingpeng", ""], ["Yogatama", "Dani", ""]]}, {"id": "1906.01081", "submitter": "Bhuwan Dhingra", "authors": "Bhuwan Dhingra, Manaal Faruqui, Ankur Parikh, Ming-Wei Chang, Dipanjan\n  Das, William W. Cohen", "title": "Handling Divergent Reference Texts when Evaluating Table-to-Text\n  Generation", "comments": "To appear at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatically constructed datasets for generating text from semi-structured\ndata (tables), such as WikiBio, often contain reference texts that diverge from\nthe information in the corresponding semi-structured data. We show that metrics\nwhich rely solely on the reference texts, such as BLEU and ROUGE, show poor\ncorrelation with human judgments when those references diverge. We propose a\nnew metric, PARENT, which aligns n-grams from the reference and generated texts\nto the semi-structured data before computing their precision and recall.\nThrough a large scale human evaluation study of table-to-text models for\nWikiBio, we show that PARENT correlates with human judgments better than\nexisting text generation metrics. We also adapt and evaluate the information\nextraction based evaluation proposed by Wiseman et al (2017), and show that\nPARENT has comparable correlation to it, while being easier to use. We show\nthat PARENT is also applicable when the reference texts are elicited from\nhumans using the data from the WebNLG challenge.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 21:13:07 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Dhingra", "Bhuwan", ""], ["Faruqui", "Manaal", ""], ["Parikh", "Ankur", ""], ["Chang", "Ming-Wei", ""], ["Das", "Dipanjan", ""], ["Cohen", "William W.", ""]]}, {"id": "1906.01105", "submitter": "Georgiana Dinu", "authors": "Georgiana Dinu, Prashant Mathur, Marcello Federico, Yaser Al-Onaizan", "title": "Training Neural Machine Translation To Apply Terminology Constraints", "comments": "Accepted as a short paper at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel method to inject custom terminology into neural\nmachine translation at run time. Previous works have mainly proposed\nmodifications to the decoding algorithm in order to constrain the output to\ninclude run-time-provided target terms. While being effective, these\nconstrained decoding methods add, however, significant computational overhead\nto the inference step, and, as we show in this paper, can be brittle when\ntested in realistic conditions. In this paper we approach the problem by\ntraining a neural MT system to learn how to use custom terminology when\nprovided with the input. Comparative experiments show that our method is not\nonly more effective than a state-of-the-art implementation of constrained\ndecoding, but is also as fast as constraint-free decoding.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 22:33:22 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 19:41:06 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Dinu", "Georgiana", ""], ["Mathur", "Prashant", ""], ["Federico", "Marcello", ""], ["Al-Onaizan", "Yaser", ""]]}, {"id": "1906.01130", "submitter": "Wei Wang", "authors": "Wei Wang and Isaac Caswell and Ciprian Chelba", "title": "Dynamically Composing Domain-Data Selection with Clean-Data Selection by\n  \"Co-Curricular Learning\" for Neural Machine Translation", "comments": "11 pages", "journal-ref": "The 57th Annual Meeting of the Association for Computational\n  Linguistics (ACL2019)", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noise and domain are important aspects of data quality for neural machine\ntranslation. Existing research focus separately on domain-data selection,\nclean-data selection, or their static combination, leaving the dynamic\ninteraction across them not explicitly examined. This paper introduces a\n\"co-curricular learning\" method to compose dynamic domain-data selection with\ndynamic clean-data selection, for transfer learning across both capabilities.\nWe apply an EM-style optimization procedure to further refine the\n\"co-curriculum\". Experiment results and analysis with two domains demonstrate\nthe effectiveness of the method and the properties of data scheduled by the\nco-curriculum.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 23:47:43 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Wang", "Wei", ""], ["Caswell", "Isaac", ""], ["Chelba", "Ciprian", ""]]}, {"id": "1906.01135", "submitter": "Baigong Zheng", "authors": "Baigong Zheng, Renjie Zheng, Mingbo Ma, Liang Huang", "title": "Simultaneous Translation with Flexible Policy via Restricted Imitation\n  Learning", "comments": null, "journal-ref": "ACL 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simultaneous translation is widely useful but remains one of the most\ndifficult tasks in NLP. Previous work either uses fixed-latency policies, or\ntrain a complicated two-staged model using reinforcement learning. We propose a\nmuch simpler single model that adds a `delay' token to the target vocabulary,\nand design a restricted dynamic oracle to greatly simplify training.\nExperiments on Chinese<->English simultaneous translation show that our work\nleads to flexible policies that achieve better BLEU scores and lower latencies\ncompared to both fixed and RL-learned policies.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 00:11:52 GMT"}, {"version": "v2", "created": "Sat, 22 Jun 2019 00:37:00 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Zheng", "Baigong", ""], ["Zheng", "Renjie", ""], ["Ma", "Mingbo", ""], ["Huang", "Liang", ""]]}, {"id": "1906.01145", "submitter": "Baohua Sun", "authors": "Baohua Sun, Lin Yang, Michael Lin, Wenhan Zhang, Patrick Dong, Charles\n  Young, Jason Dong", "title": "System Demo for Transfer Learning across Vision and Text using Domain\n  Specific CNN Accelerator for On-Device NLP Applications", "comments": "Four pages, four figures, one table. Accepted by IJCAI2019 Tusion\n  Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Power-efficient CNN Domain Specific Accelerator (CNN-DSA) chips are currently\navailable for wide use in mobile devices. These chips are mainly used in\ncomputer vision applications. However, the recent work of Super Characters\nmethod for text classification and sentiment analysis tasks using\ntwo-dimensional CNN models has also achieved state-of-the-art results through\nthe method of transfer learning from vision to text. In this paper, we\nimplemented the text classification and sentiment analysis applications on\nmobile devices using CNN-DSA chips. Compact network representations using\none-bit and three-bits precision for coefficients and five-bits for activations\nare used in the CNN-DSA chip with power consumption less than 300mW. For edge\ndevices under memory and compute constraints, the network is further compressed\nby approximating the external Fully Connected (FC) layers within the CNN-DSA\nchip. At the workshop, we have two system demonstrations for NLP tasks. The\nfirst demo classifies the input English Wikipedia sentence into one of the 14\nontologies. The second demo classifies the Chinese online-shopping review into\npositive or negative.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 00:51:23 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Sun", "Baohua", ""], ["Yang", "Lin", ""], ["Lin", "Michael", ""], ["Zhang", "Wenhan", ""], ["Dong", "Patrick", ""], ["Young", "Charles", ""], ["Dong", "Jason", ""]]}, {"id": "1906.01149", "submitter": "Chetan Naik", "authors": "Tongfei Chen, Chetan Naik, Hua He, Pushpendre Rastogi, Lambert Mathias", "title": "Improving Long Distance Slot Carryover in Spoken Dialogue Systems", "comments": "Accepted at ACL 2019 workshop on NLP for Conversational AI\n  (NLP4ConvAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tracking the state of the conversation is a central component in\ntask-oriented spoken dialogue systems. One such approach for tracking the\ndialogue state is slot carryover, where a model makes a binary decision if a\nslot from the context is relevant to the current turn. Previous work on the\nslot carryover task used models that made independent decisions for each slot.\nA close analysis of the results show that this approach results in poor\nperformance over longer context dialogues. In this paper, we propose to jointly\nmodel the slots. We propose two neural network architectures, one based on\npointer networks that incorporate slot ordering information, and the other\nbased on transformer networks that uses self attention mechanism to model the\nslot interdependencies. Our experiments on an internal dialogue benchmark\ndataset and on the public DSTC2 dataset demonstrate that our proposed models\nare able to resolve longer distance slot references and are able to achieve\ncompetitive performance.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 01:13:20 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Chen", "Tongfei", ""], ["Naik", "Chetan", ""], ["He", "Hua", ""], ["Rastogi", "Pushpendre", ""], ["Mathias", "Lambert", ""]]}, {"id": "1906.01154", "submitter": "Allen Schmaltz", "authors": "Allen Schmaltz", "title": "Detecting Local Insights from Global Labels: Supervised & Zero-Shot\n  Sequence Labeling via a Convolutional Decomposition", "comments": "Condensed version; 33 pages + appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new, more actionable view of neural network interpretability and\ndata analysis by leveraging the remarkable matching effectiveness of\nrepresentations derived from deep networks, guided by an approach for\nclass-conditional feature detection. The decomposition of the filter-ngram\ninteractions of a convolutional neural network and a linear layer over a\npre-trained deep network yields a strong binary sequence labeler, with\nflexibility in producing predictions at -- and defining loss functions for --\nvarying label granularities, from the fully-supervised sequence labeling\nsetting to the challenging zero-shot sequence labeling setting, in which we\nseek token-level predictions but only have document-level labels for training.\nFrom this sequence-labeling layer we derive dense representations of the input\nthat can then be matched to instances from training, or a support set with\nknown labels. Such introspection with inference-time decision rules provides a\nmeans, in some settings, of making local updates to the model by altering the\nlabels or instances in the support set without re-training the full model.\nFinally, we construct a particular K-nearest neighbors (K-NN) model from\nmatched exemplar representations that approximates the original model's\npredictions and is at least as effective a predictor with respect to the\nground-truth labels. This additionally yields interpretable heuristics at the\ntoken level for determining when predictions are less likely to be reliable,\nand for screening input dissimilar to the support set. In effect, we show that\nwe can transform the deep network into a simple weighting over exemplars and\nassociated labels, yielding an introspectable -- and modestly updatable --\nversion of the original model.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 01:54:42 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2019 05:27:01 GMT"}, {"version": "v3", "created": "Fri, 6 Sep 2019 05:49:07 GMT"}, {"version": "v4", "created": "Sat, 14 Dec 2019 07:58:48 GMT"}, {"version": "v5", "created": "Sat, 23 May 2020 04:02:46 GMT"}, {"version": "v6", "created": "Sat, 12 Jun 2021 04:41:14 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Schmaltz", "Allen", ""]]}, {"id": "1906.01155", "submitter": "Paria Jamshid Lou", "authors": "Omid Mohamad Nezami, Paria Jamshid Lou, Mansoureh Karami", "title": "ShEMO -- A Large-Scale Validated Database for Persian Speech Emotion\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a large-scale, validated database for Persian called\nSharif Emotional Speech Database (ShEMO). The database includes 3000\nsemi-natural utterances, equivalent to 3 hours and 25 minutes of speech data\nextracted from online radio plays. The ShEMO covers speech samples of 87\nnative-Persian speakers for five basic emotions including anger, fear,\nhappiness, sadness and surprise, as well as neutral state. Twelve annotators\nlabel the underlying emotional state of utterances and majority voting is used\nto decide on the final labels. According to the kappa measure, the\ninter-annotator agreement is 64% which is interpreted as \"substantial\nagreement\". We also present benchmark results based on common classification\nmethods in speech emotion detection task. According to the experiments, support\nvector machine achieves the best results for both gender-independent (58.2%)\nand gender-dependent models (female=59.4%, male=57.6%). The ShEMO is available\nfor academic purposes free of charge to provide a baseline for further research\non Persian emotional speech.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 01:58:58 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 07:58:03 GMT"}, {"version": "v3", "created": "Tue, 11 Jun 2019 03:06:30 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Nezami", "Omid Mohamad", ""], ["Lou", "Paria Jamshid", ""], ["Karami", "Mansoureh", ""]]}, {"id": "1906.01157", "submitter": "Rohit Voleti", "authors": "Rohit Voleti, Julie M. Liss, Visar Berisha", "title": "A Review of Automated Speech and Language Features for Assessment of\n  Cognitive and Thought Disorders", "comments": "\\c{opyright} 2019 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": null, "doi": "10.1109/JSTSP.2019.2952087", "report-no": "J-STSP-AAHD-00183-2019", "categories": "cs.CL cs.SD eess.AS eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is widely accepted that information derived from analyzing speech (the\nacoustic signal) and language production (words and sentences) serves as a\nuseful window into the health of an individual's cognitive ability. In fact,\nmost neuropsychological testing batteries have a component related to speech\nand language where clinicians elicit speech from patients for subjective\nevaluation across a broad set of dimensions. With advances in speech signal\nprocessing and natural language processing, there has been recent interest in\ndeveloping tools to detect more subtle changes in cognitive-linguistic\nfunction. This work relies on extracting a set of features from recorded and\ntranscribed speech for objective assessments of speech and language, early\ndiagnosis of neurological disease, and tracking of disease after diagnosis.\nWith an emphasis on cognitive and thought disorders, in this paper we provide a\nreview of existing speech and language features used in this domain, discuss\ntheir clinical application, and highlight their advantages and disadvantages.\nBroadly speaking, the review is split into two categories: language features\nbased on natural language processing and speech features based on speech signal\nprocessing. Within each category, we consider features that aim to measure\ncomplementary dimensions of cognitive-linguistics, including language\ndiversity, syntactic complexity, semantic coherence, and timing. We conclude\nthe review with a proposal of new research directions to further advance the\nfield.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 02:17:18 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 04:23:20 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Voleti", "Rohit", ""], ["Liss", "Julie M.", ""], ["Berisha", "Visar", ""]]}, {"id": "1906.01161", "submitter": "Yury Kashnitsky", "authors": "Matei Ionita, Yury Kashnitsky, Ken Krige, Vladimir Larin, Denis\n  Logvinenko, and Atanas Atanasov", "title": "Resolving Gendered Ambiguous Pronouns with BERT", "comments": "accepted to 1st ACL Workshop on Gender Bias for Natural Language\n  Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pronoun resolution is part of coreference resolution, the task of pairing an\nexpression to its referring entity. This is an important task for natural\nlanguage understanding and a necessary component of machine translation\nsystems, chat bots and assistants. Neural machine learning systems perform far\nfrom ideally in this task, reaching as low as 73% F1 scores on modern benchmark\ndatasets. Moreover, they tend to perform better for masculine pronouns than for\nfeminine ones. Thus, the problem is both challenging and important for NLP\nresearchers and practitioners. In this project, we describe our BERT-based\napproach to solving the problem of gender-balanced pronoun resolution. We are\nable to reach 92% F1 score and a much lower gender bias on the benchmark\ndataset shared by Google AI Language team.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 11:10:10 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 11:26:56 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Ionita", "Matei", ""], ["Kashnitsky", "Yury", ""], ["Krige", "Ken", ""], ["Larin", "Vladimir", ""], ["Logvinenko", "Denis", ""], ["Atanasov", "Atanas", ""]]}, {"id": "1906.01181", "submitter": "Jiatao Gu", "authors": "Jiatao Gu, Yong Wang, Kyunghyun Cho and Victor O.K. Li", "title": "Improved Zero-shot Neural Machine Translation via Ignoring Spurious\n  Correlations", "comments": "Accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-shot translation, translating between language pairs on which a Neural\nMachine Translation (NMT) system has never been trained, is an emergent\nproperty when training the system in multilingual settings. However, naive\ntraining for zero-shot NMT easily fails, and is sensitive to hyper-parameter\nsetting. The performance typically lags far behind the more conventional\npivot-based approach which translates twice using a third language as a pivot.\nIn this work, we address the degeneracy problem due to capturing spurious\ncorrelations by quantitatively analyzing the mutual information between\nlanguage IDs of the source and decoded sentences. Inspired by this analysis, we\npropose to use two simple but effective approaches: (1) decoder pre-training;\n(2) back-translation. These methods show significant improvement (4~22 BLEU\npoints) over the vanilla zero-shot translation on three challenging\nmultilingual datasets, and achieve similar or better results than the\npivot-based approach.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 03:30:22 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Gu", "Jiatao", ""], ["Wang", "Yong", ""], ["Cho", "Kyunghyun", ""], ["Li", "Victor O. K.", ""]]}, {"id": "1906.01183", "submitter": "Linghao Sun", "authors": "Shengfei Lyu, Linghao Sun, Huixiong Yi, Yong Liu, Huanhuan Chen,\n  Chunyan Miao", "title": "Back Attention Knowledge Transfer for Low-Resource Named Entity\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, great success has been achieved in the field of natural\nlanguage processing (NLP), thanks in part to the considerable amount of\nannotated resources. For named entity recognition (NER), most languages do not\nhave such an abundance of labeled data as English, so the performances of those\nlanguages are relatively lower. To improve the performance, we propose a\ngeneral approach called Back Attention Network (BAN). BAN uses a translation\nsystem to translate other language sentences into English and then applies a\nnew mechanism named back attention knowledge transfer to obtain task-specific\ninformation from pre-trained high-resource languages NER model. This strategy\ncan transfer high-layer features of well-trained model and enrich the semantic\nrepresentations of the original language. Experiments on three different\nlanguage datasets indicate that the proposed approach outperforms other\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 03:33:51 GMT"}, {"version": "v2", "created": "Sun, 8 Sep 2019 14:45:53 GMT"}, {"version": "v3", "created": "Fri, 18 Jun 2021 08:49:21 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Lyu", "Shengfei", ""], ["Sun", "Linghao", ""], ["Yi", "Huixiong", ""], ["Liu", "Yong", ""], ["Chen", "Huanhuan", ""], ["Miao", "Chunyan", ""]]}, {"id": "1906.01185", "submitter": "Xingshan Zeng", "authors": "Xingshan Zeng, Jing Li, Lu Wang, Kam-Fai Wong", "title": "Joint Effects of Context and User History for Predicting Online\n  Conversation Re-entries", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the online world continues its exponential growth, interpersonal\ncommunication has come to play an increasingly central role in opinion\nformation and change. In order to help users better engage with each other\nonline, we study a challenging problem of re-entry prediction foreseeing\nwhether a user will come back to a conversation they once participated in. We\nhypothesize that both the context of the ongoing conversations and the users'\nprevious chatting history will affect their continued interests in future\nengagement. Specifically, we propose a neural framework with three main layers,\neach modeling context, user history, and interactions between them, to explore\nhow the conversation context and user chatting history jointly result in their\nre-entry behavior. We experiment with two large-scale datasets collected from\nTwitter and Reddit. Results show that our proposed framework with bi-attention\nachieves an F1 score of 61.1 on Twitter conversations, outperforming the\nstate-of-the-art methods from previous work.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 03:43:37 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Zeng", "Xingshan", ""], ["Li", "Jing", ""], ["Wang", "Lu", ""], ["Wong", "Kam-Fai", ""]]}, {"id": "1906.01195", "submitter": "Deepak Nathani", "authors": "Deepak Nathani, Jatin Chauhan, Charu Sharma, Manohar Kaul", "title": "Learning Attention-based Embeddings for Relation Prediction in Knowledge\n  Graphs", "comments": "accepted as long paper in ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent proliferation of knowledge graphs (KGs) coupled with incomplete or\npartial information, in the form of missing relations (links) between entities,\nhas fueled a lot of research on knowledge base completion (also known as\nrelation prediction). Several recent works suggest that convolutional neural\nnetwork (CNN) based models generate richer and more expressive feature\nembeddings and hence also perform well on relation prediction. However, we\nobserve that these KG embeddings treat triples independently and thus fail to\ncover the complex and hidden information that is inherently implicit in the\nlocal neighborhood surrounding a triple. To this effect, our paper proposes a\nnovel attention based feature embedding that captures both entity and relation\nfeatures in any given entity's neighborhood. Additionally, we also encapsulate\nrelation clusters and multihop relations in our model. Our empirical study\noffers insights into the efficacy of our attention based model and we show\nmarked performance gains in comparison to state of the art methods on all\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 04:59:08 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Nathani", "Deepak", ""], ["Chauhan", "Jatin", ""], ["Sharma", "Charu", ""], ["Kaul", "Manohar", ""]]}, {"id": "1906.01199", "submitter": "Elizabeth Salesky", "authors": "Elizabeth Salesky, Matthias Sperber, Alan W Black", "title": "Exploring Phoneme-Level Speech Representations for End-to-End Speech\n  Translation", "comments": "Accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work on end-to-end translation from speech has primarily used\nframe-level features as speech representations, which creates longer, sparser\nsequences than text. We show that a naive method to create compressed\nphoneme-like speech representations is far more effective and efficient for\ntranslation than traditional frame-level speech features. Specifically, we\ngenerate phoneme labels for speech frames and average consecutive frames with\nthe same label to create shorter, higher-level source sequences for\ntranslation. We see improvements of up to 5 BLEU on both our high and low\nresource language pairs, with a reduction in training time of 60%. Our\nimprovements hold across multiple data sizes and two language pairs.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 05:12:31 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Salesky", "Elizabeth", ""], ["Sperber", "Matthias", ""], ["Black", "Alan W", ""]]}, {"id": "1906.01205", "submitter": "Fangyu Liu", "authors": "Fangyu Liu, Rongtian Ye", "title": "A Strong and Robust Baseline for Text-Image Matching", "comments": "6 pages (excluding references); 2019 ACL Student Research Workshop\n  (to appear)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We review the current schemes of text-image matching models and propose\nimprovements for both training and inference. First, we empirically show\nlimitations of two popular loss (sum and max-margin loss) widely used in\ntraining text-image embeddings and propose a trade-off: a kNN-margin loss which\n1) utilizes information from hard negatives and 2) is robust to noise as all\n$K$-most hardest samples are taken into account, tolerating \\emph{pseudo}\nnegatives and outliers. Second, we advocate the use of Inverted Softmax\n(\\textsc{Is}) and Cross-modal Local Scaling (\\textsc{Csls}) during inference to\nmitigate the so-called hubness problem in high-dimensional embedding space,\nenhancing scores of all metrics by a large margin.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 05:42:58 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Liu", "Fangyu", ""], ["Ye", "Rongtian", ""]]}, {"id": "1906.01213", "submitter": "Jialong Tang", "authors": "Jialong Tang and Ziyao Lu and Jinsong Su and Yubin Ge and Linfeng Song\n  and Le Sun and Jiebo Luo", "title": "Progressive Self-Supervised Attention Learning for Aspect-Level\n  Sentiment Analysis", "comments": "10 pages", "journal-ref": "ACL 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In aspect-level sentiment classification (ASC), it is prevalent to equip\ndominant neural models with attention mechanisms, for the sake of acquiring the\nimportance of each context word on the given aspect. However, such a mechanism\ntends to excessively focus on a few frequent words with sentiment polarities,\nwhile ignoring infrequent ones. In this paper, we propose a progressive\nself-supervised attention learning approach for neural ASC models, which\nautomatically mines useful attention supervision information from a training\ncorpus to refine attention mechanisms. Specifically, we iteratively conduct\nsentiment predictions on all training instances. Particularly, at each\niteration, the context word with the maximum attention weight is extracted as\nthe one with active/misleading influence on the correct/incorrect prediction of\nevery instance, and then the word itself is masked for subsequent iterations.\nFinally, we augment the conventional training objective with a regularization\nterm, which enables ASC models to continue equally focusing on the extracted\nactive context words while decreasing weights of those misleading ones.\nExperimental results on multiple datasets show that our proposed approach\nyields better attention mechanisms, leading to substantial improvements over\nthe two state-of-the-art neural ASC models. Source code and trained models are\navailable at https://github.com/DeepLearnXMU/PSSAttention.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 06:07:56 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 02:03:55 GMT"}, {"version": "v3", "created": "Thu, 6 Jun 2019 03:41:34 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Tang", "Jialong", ""], ["Lu", "Ziyao", ""], ["Su", "Jinsong", ""], ["Ge", "Yubin", ""], ["Song", "Linfeng", ""], ["Sun", "Le", ""], ["Luo", "Jiebo", ""]]}, {"id": "1906.01230", "submitter": "Rui Xia", "authors": "Zixiang Ding, Huihui He, Mengran Zhang, Rui Xia", "title": "From Independent Prediction to Re-ordered Prediction: Integrating\n  Relative Position and Global Label Information to Emotion Cause\n  Identification", "comments": "Accepted by AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion cause identification aims at identifying the potential causes that\nlead to a certain emotion expression in text. Several techniques including rule\nbased methods and traditional machine learning methods have been proposed to\naddress this problem based on manually designed rules and features. More\nrecently, some deep learning methods have also been applied to this task, with\nthe attempt to automatically capture the causal relationship of emotion and its\ncauses embodied in the text. In this work, we find that in addition to the\ncontent of the text, there are another two kinds of information, namely\nrelative position and global labels, that are also very important for emotion\ncause identification. To integrate such information, we propose a model based\non the neural network architecture to encode the three elements ($i.e.$, text\ncontent, relative position and global label), in an unified and end-to-end\nfashion. We introduce a relative position augmented embedding learning\nalgorithm, and transform the task from an independent prediction problem to a\nreordered prediction problem, where the dynamic global label information is\nincorporated. Experimental results on a benchmark emotion cause dataset show\nthat our model achieves new state-of-the-art performance and performs\nsignificantly better than a number of competitive baselines. Further analysis\nshows the effectiveness of the relative position augmented embedding learning\nalgorithm and the reordered prediction mechanism with dynamic global labels.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 07:02:22 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Ding", "Zixiang", ""], ["He", "Huihui", ""], ["Zhang", "Mengran", ""], ["Xia", "Rui", ""]]}, {"id": "1906.01231", "submitter": "Wei Li", "authors": "Wei Li, Jingjing Xu, Yancheng He, Shengli Yan, Yunfang Wu, Xu sun", "title": "Coherent Comment Generation for Chinese Articles with a\n  Graph-to-Sequence Model", "comments": "Accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic article commenting is helpful in encouraging user engagement and\ninteraction on online news platforms. However, the news documents are usually\ntoo long for traditional encoder-decoder based models, which often results in\ngeneral and irrelevant comments. In this paper, we propose to generate comments\nwith a graph-to-sequence model that models the input news as a topic\ninteraction graph. By organizing the article into graph structure, our model\ncan better understand the internal structure of the article and the connection\nbetween topics, which makes it better able to understand the story. We collect\nand release a large scale news-comment corpus from a popular Chinese online\nnews platform Tencent Kuaibao. Extensive experiment results show that our model\ncan generate much more coherent and informative comments compared with several\nstrong baseline models.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 07:03:04 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Li", "Wei", ""], ["Xu", "Jingjing", ""], ["He", "Yancheng", ""], ["Yan", "Shengli", ""], ["Wu", "Yunfang", ""], ["sun", "Xu", ""]]}, {"id": "1906.01234", "submitter": "Dieuwke Hupkes", "authors": "Kris Korrel, Dieuwke Hupkes, Verna Dankers and Elia Bruni", "title": "Transcoding compositionally: using attention to find more generalizable\n  solutions", "comments": "to appear at BlackboxNLP 2019, ACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While sequence-to-sequence models have shown remarkable generalization power\nacross several natural language tasks, their construct of solutions are argued\nto be less compositional than human-like generalization. In this paper, we\npresent seq2attn, a new architecture that is specifically designed to exploit\nattention to find compositional patterns in the input. In seq2attn, the two\nstandard components of an encoder-decoder model are connected via a transcoder,\nthat modulates the information flow between them. We show that seq2attn can\nsuccessfully generalize, without requiring any additional supervision, on two\ntasks which are specifically constructed to challenge the compositional skills\nof neural networks. The solutions found by the model are highly interpretable,\nallowing easy analysis of both the types of solutions that are found and\npotential causes for mistakes. We exploit this opportunity to introduce a new\nparadigm to test compositionality that studies the extent to which a model\novergeneralizes when confronted with exceptions. We show that seq2attn exhibits\nsuch overgeneralization to a larger degree than a standard sequence-to-sequence\nmodel.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 07:07:56 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 08:34:09 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Korrel", "Kris", ""], ["Hupkes", "Dieuwke", ""], ["Dankers", "Verna", ""], ["Bruni", "Elia", ""]]}, {"id": "1906.01236", "submitter": "Rui Xia", "authors": "Rui Xia, Mengran Zhang, Zixiang Ding", "title": "RTHN: A RNN-Transformer Hierarchical Network for Emotion Cause\n  Extraction", "comments": "Accepted by IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emotion cause extraction (ECE) task aims at discovering the potential\ncauses behind a certain emotion expression in a document. Techniques including\nrule-based methods, traditional machine learning methods and deep neural\nnetworks have been proposed to solve this task. However, most of the previous\nwork considered ECE as a set of independent clause classification problems and\nignored the relations between multiple clauses in a document. In this work, we\npropose a joint emotion cause extraction framework, named RNN-Transformer\nHierarchical Network (RTHN), to encode and classify multiple clauses\nsynchronously. RTHN is composed of a lower word-level encoder based on RNNs to\nencode multiple words in each clause, and an upper clause-level encoder based\non Transformer to learn the correlation between multiple clauses in a document.\nWe furthermore propose ways to encode the relative position and global\npredication information into Transformer that can capture the causality between\nclauses and make RTHN more efficient. We finally achieve the best performance\namong 12 compared systems and improve the F1 score of the state-of-the-art from\n72.69\\% to 76.77\\%.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 07:10:16 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Xia", "Rui", ""], ["Zhang", "Mengran", ""], ["Ding", "Zixiang", ""]]}, {"id": "1906.01239", "submitter": "Shuhei Kurita", "authors": "Shuhei Kurita and Anders S{\\o}gaard", "title": "Multi-Task Semantic Dependency Parsing with Policy Gradient for Learning\n  Easy-First Strategies", "comments": "ACL2019 Long accepted. 9 pages for the paper and the additional 2\n  pages for the supplemental material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Semantic Dependency Parsing (SDP), semantic relations form directed\nacyclic graphs, rather than trees. We propose a new iterative predicate\nselection (IPS) algorithm for SDP. Our IPS algorithm combines the graph-based\nand transition-based parsing approaches in order to handle multiple semantic\nhead words. We train the IPS model using a combination of multi-task learning\nand task-specific policy gradient training. Trained this way, IPS achieves a\nnew state of the art on the SemEval 2015 Task 18 datasets. Furthermore, we\nobserve that policy gradient training learns an easy-first strategy.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 07:13:49 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Kurita", "Shuhei", ""], ["S\u00f8gaard", "Anders", ""]]}, {"id": "1906.01243", "submitter": "Allen Nie", "authors": "Allen Nie, Erin D. Bennett, Noah D. Goodman", "title": "Learning to Explain: Answering Why-Questions via Rephrasing", "comments": "8 pages, 5 figures. 1st ConvAI Workshop at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Providing plausible responses to why questions is a challenging but critical\ngoal for language based human-machine interaction. Explanations are challenging\nin that they require many different forms of abstract knowledge and reasoning.\nPrevious work has either relied on human-curated structured knowledge bases or\ndetailed domain representation to generate satisfactory explanations. They are\nalso often limited to ranking pre-existing explanation choices. In our work, we\ncontribute to the under-explored area of generating natural language\nexplanations for general phenomena. We automatically collect large datasets of\nexplanation-phenomenon pairs which allow us to train sequence-to-sequence\nmodels to generate natural language explanations. We compare different training\nstrategies and evaluate their performance using both automatic scores and human\nratings. We demonstrate that our strategy is sufficient to generate highly\nplausible explanations for general open-domain phenomena compared to other\nmodels trained on different datasets.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 07:27:35 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Nie", "Allen", ""], ["Bennett", "Erin D.", ""], ["Goodman", "Noah D.", ""]]}, {"id": "1906.01250", "submitter": "Phong Le", "authors": "Phong Le and Ivan Titov", "title": "Boosting Entity Linking Performance by Leveraging Unlabeled Documents", "comments": "ACL2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern entity linking systems rely on large collections of documents\nspecifically annotated for the task (e.g., AIDA CoNLL). In contrast, we propose\nan approach which exploits only naturally occurring information: unlabeled\ndocuments and Wikipedia. Our approach consists of two stages. First, we\nconstruct a high recall list of candidate entities for each mention in an\nunlabeled document. Second, we use the candidate lists as weak supervision to\nconstrain our document-level entity linking model. The model treats entities as\nlatent variables and, when estimated on a collection of unlabelled texts,\nlearns to choose entities relying both on local context of each mention and on\ncoherence with other entities in the document. The resulting approach rivals\nfully-supervised state-of-the-art systems on standard test sets. It also\napproaches their performance in the very challenging setting: when tested on a\ntest set sampled from the data used to estimate the supervised systems. By\ncomparing to Wikipedia-only training of our model, we demonstrate that modeling\nunlabeled documents is beneficial.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 07:49:46 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Le", "Phong", ""], ["Titov", "Ivan", ""]]}, {"id": "1906.01265", "submitter": "Chujie Zheng", "authors": "Chujie Zheng, Minlie Huang, Aixin Sun", "title": "ChID: A Large-scale Chinese IDiom Dataset for Cloze Test", "comments": "Accepted to ACL 2019 (long paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloze-style reading comprehension in Chinese is still limited due to the lack\nof various corpora. In this paper we propose a large-scale Chinese cloze test\ndataset ChID, which studies the comprehension of idiom, a unique language\nphenomenon in Chinese. In this corpus, the idioms in a passage are replaced by\nblank symbols and the correct answer needs to be chosen from well-designed\ncandidate idioms. We carefully study how the design of candidate idioms and the\nrepresentation of idioms affect the performance of state-of-the-art models.\nResults show that the machine accuracy is substantially worse than that of\nhuman, indicating a large space for further research.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 08:29:00 GMT"}, {"version": "v2", "created": "Sat, 8 Jun 2019 05:48:04 GMT"}, {"version": "v3", "created": "Mon, 27 Jan 2020 16:43:59 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Zheng", "Chujie", ""], ["Huang", "Minlie", ""], ["Sun", "Aixin", ""]]}, {"id": "1906.01267", "submitter": "Rui Xia", "authors": "Rui Xia, Zixiang Ding", "title": "Emotion-Cause Pair Extraction: A New Task to Emotion Analysis in Texts", "comments": "Accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion cause extraction (ECE), the task aimed at extracting the potential\ncauses behind certain emotions in text, has gained much attention in recent\nyears due to its wide applications. However, it suffers from two shortcomings:\n1) the emotion must be annotated before cause extraction in ECE, which greatly\nlimits its applications in real-world scenarios; 2) the way to first annotate\nemotion and then extract the cause ignores the fact that they are mutually\nindicative. In this work, we propose a new task: emotion-cause pair extraction\n(ECPE), which aims to extract the potential pairs of emotions and corresponding\ncauses in a document. We propose a 2-step approach to address this new ECPE\ntask, which first performs individual emotion extraction and cause extraction\nvia multi-task learning, and then conduct emotion-cause pairing and filtering.\nThe experimental results on a benchmark emotion cause corpus prove the\nfeasibility of the ECPE task as well as the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 08:29:26 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Xia", "Rui", ""], ["Ding", "Zixiang", ""]]}, {"id": "1906.01268", "submitter": "Xing Wang", "authors": "Xing Wang, Zhaopeng Tu, Longyue Wang, Shuming Shi", "title": "Exploiting Sentential Context for Neural Machine Translation", "comments": "Accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this work, we present novel approaches to exploit sentential context for\nneural machine translation (NMT). Specifically, we first show that a shallow\nsentential context extracted from the top encoder layer only, can improve\ntranslation performance via contextualizing the encoding representations of\nindividual words. Next, we introduce a deep sentential context, which\naggregates the sentential context representations from all the internal layers\nof the encoder to form a more comprehensive context representation.\nExperimental results on the WMT14 English-to-German and English-to-French\nbenchmarks show that our model consistently improves performance over the\nstrong TRANSFORMER model (Vaswani et al., 2017), demonstrating the necessity\nand effectiveness of exploiting sentential context for NMT.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 08:29:33 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Wang", "Xing", ""], ["Tu", "Zhaopeng", ""], ["Wang", "Longyue", ""], ["Shi", "Shuming", ""]]}, {"id": "1906.01280", "submitter": "Maria Corkery", "authors": "Maria Corkery, Yevgen Matusevych, Sharon Goldwater", "title": "Are we there yet? Encoder-decoder neural networks as cognitive models of\n  English past tense inflection", "comments": "Accepted at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cognitive mechanisms needed to account for the English past tense have\nlong been a subject of debate in linguistics and cognitive science. Neural\nnetwork models were proposed early on, but were shown to have clear flaws.\nRecently, however, Kirov and Cotterell (2018) showed that modern\nencoder-decoder (ED) models overcome many of these flaws. They also presented\nevidence that ED models demonstrate humanlike performance in a nonce-word task.\nHere, we look more closely at the behaviour of their model in this task. We\nfind that (1) the model exhibits instability across multiple simulations in\nterms of its correlation with human data, and (2) even when results are\naggregated across simulations (treating each simulation as an individual human\nparticipant), the fit to the human data is not strong---worse than an older\nrule-based model. These findings hold up through several alternative training\nregimes and evaluation measures. Although other neural architectures might do\nbetter, we conclude that there is still insufficient evidence to claim that\nneural nets are a good cognitive model for this task.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 08:56:56 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Corkery", "Maria", ""], ["Matusevych", "Yevgen", ""], ["Goldwater", "Sharon", ""]]}, {"id": "1906.01282", "submitter": "Fengshun Xiao", "authors": "Fengshun Xiao, Jiangtong Li, Hai Zhao, Rui Wang, Kehai Chen", "title": "Lattice-Based Transformer Encoder for Neural Machine Translation", "comments": "Accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT) takes deterministic sequences for source\nrepresentations. However, either word-level or subword-level segmentations have\nmultiple choices to split a source sequence with different word segmentors or\ndifferent subword vocabulary sizes. We hypothesize that the diversity in\nsegmentations may affect the NMT performance. To integrate different\nsegmentations with the state-of-the-art NMT model, Transformer, we propose\nlattice-based encoders to explore effective word or subword representation in\nan automatic way during training. We propose two methods: 1) lattice positional\nencoding and 2) lattice-aware self-attention. These two methods can be used\ntogether and show complementary to each other to further improve translation\nperformance. Experiment results show superiorities of lattice-based encoders in\nword-level and subword-level representations over conventional Transformer\nencoder.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 08:58:14 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Xiao", "Fengshun", ""], ["Li", "Jiangtong", ""], ["Zhao", "Hai", ""], ["Wang", "Rui", ""], ["Chen", "Kehai", ""]]}, {"id": "1906.01327", "submitter": "Yanai Elazar", "authors": "Yanai Elazar and Abhijit Mahabal and Deepak Ramachandran and Tania\n  Bedrax-Weiss and Dan Roth", "title": "How Large Are Lions? Inducing Distributions over Quantitative Attributes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most current NLP systems have little knowledge about quantitative attributes\nof objects and events. We propose an unsupervised method for collecting\nquantitative information from large amounts of web data, and use it to create a\nnew, very large resource consisting of distributions over physical quantities\nassociated with objects, adjectives, and verbs which we call Distributions over\nQuantitative (DoQ). This contrasts with recent work in this area which has\nfocused on making only relative comparisons such as \"Is a lion bigger than a\nwolf?\". Our evaluation shows that DoQ compares favorably with state of the art\nresults on existing datasets for relative comparisons of nouns and adjectives,\nand on a new dataset we introduce.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 10:34:33 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Elazar", "Yanai", ""], ["Mahabal", "Abhijit", ""], ["Ramachandran", "Deepak", ""], ["Bedrax-Weiss", "Tania", ""], ["Roth", "Dan", ""]]}, {"id": "1906.01334", "submitter": "Shereen Oraby", "authors": "Shereen Oraby, Vrindavan Harrison, Abteen Ebrahimi, and Marilyn Walker", "title": "Curate and Generate: A Corpus and Method for Joint Control of Semantics\n  and Style in Neural NLG", "comments": "To appear at ACL 19. 9 content pages, 3 appendix pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural natural language generation (NNLG) from structured meaning\nrepresentations has become increasingly popular in recent years. While we have\nseen progress with generating syntactically correct utterances that preserve\nsemantics, various shortcomings of NNLG systems are clear: new tasks require\nnew training data which is not available or straightforward to acquire, and\nmodel outputs are simple and may be dull and repetitive. This paper addresses\nthese two critical challenges in NNLG by: (1) scalably (and at no cost)\ncreating training datasets of parallel meaning representations and reference\ntexts with rich style markup by using data from freely available and naturally\ndescriptive user reviews, and (2) systematically exploring how the style markup\nenables joint control of semantic and stylistic aspects of neural model output.\nWe present YelpNLG, a corpus of 300,000 rich, parallel meaning representations\nand highly stylistically varied reference texts spanning different restaurant\nattributes, and describe a novel methodology that can be scalably reused to\ngenerate NLG datasets for other domains. The experiments show that the models\ncontrol important aspects, including lexical choice of adjectives, output\nlength, and sentiment, allowing the models to successfully hit multiple style\ntargets without sacrificing semantics.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 10:51:32 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 18:09:46 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Oraby", "Shereen", ""], ["Harrison", "Vrindavan", ""], ["Ebrahimi", "Abteen", ""], ["Walker", "Marilyn", ""]]}, {"id": "1906.01343", "submitter": "Jihun Choi", "authors": "Jihun Choi, Taeuk Kim, Sang-goo Lee", "title": "A Cross-Sentence Latent Variable Model for Semi-Supervised Text Sequence\n  Matching", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a latent variable model for predicting the relationship between a\npair of text sequences. Unlike previous auto-encoding--based approaches that\nconsider each sequence separately, our proposed framework utilizes both\nsequences within a single model by generating a sequence that has a given\nrelationship with a source sequence. We further extend the cross-sentence\ngenerating framework to facilitate semi-supervised training. We also define\nnovel semantic constraints that lead the decoder network to generate\nsemantically plausible and diverse sequences. We demonstrate the effectiveness\nof the proposed model from quantitative and qualitative experiments, while\nachieving state-of-the-art results on semi-supervised natural language\ninference and paraphrase identification.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 11:03:49 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Choi", "Jihun", ""], ["Kim", "Taeuk", ""], ["Lee", "Sang-goo", ""]]}, {"id": "1906.01351", "submitter": "Guy Lev", "authors": "Guy Lev, Michal Shmueli-Scheuer, Jonathan Herzig, Achiya Jerbi, David\n  Konopnicki", "title": "TalkSumm: A Dataset and Scalable Annotation Method for Scientific Paper\n  Summarization Based on Conference Talks", "comments": "Accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, no large-scale training data is available for the task of\nscientific paper summarization. In this paper, we propose a novel method that\nautomatically generates summaries for scientific papers, by utilizing videos of\ntalks at scientific conferences. We hypothesize that such talks constitute a\ncoherent and concise description of the papers' content, and can form the basis\nfor good summaries. We collected 1716 papers and their corresponding videos,\nand created a dataset of paper summaries. A model trained on this dataset\nachieves similar performance as models trained on a dataset of summaries\ncreated manually. In addition, we validated the quality of our summaries by\nhuman experts.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 11:25:14 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 12:16:00 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Lev", "Guy", ""], ["Shmueli-Scheuer", "Michal", ""], ["Herzig", "Jonathan", ""], ["Jerbi", "Achiya", ""], ["Konopnicki", "David", ""]]}, {"id": "1906.01359", "submitter": "Xiang Dai", "authors": "Nicky Ringland and Xiang Dai and Ben Hachey and Sarvnaz Karimi and\n  Cecile Paris and James R. Curran", "title": "NNE: A Dataset for Nested Named Entity Recognition in English Newswire", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Named entity recognition (NER) is widely used in natural language processing\napplications and downstream tasks. However, most NER tools target flat\nannotation from popular datasets, eschewing the semantic information available\nin nested entity mentions. We describe NNE---a fine-grained, nested named\nentity dataset over the full Wall Street Journal portion of the Penn Treebank\n(PTB). Our annotation comprises 279,795 mentions of 114 entity types with up to\n6 layers of nesting. We hope the public release of this large dataset for\nEnglish newswire will encourage development of new techniques for nested NER.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 11:46:37 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Ringland", "Nicky", ""], ["Dai", "Xiang", ""], ["Hachey", "Ben", ""], ["Karimi", "Sarvnaz", ""], ["Paris", "Cecile", ""], ["Curran", "James R.", ""]]}, {"id": "1906.01361", "submitter": "Hardy Hardy", "authors": "Hardy, Shashi Narayan, Andreas Vlachos", "title": "HighRES: Highlight-based Reference-less Evaluation of Summarization", "comments": "Accepted for ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been substantial progress in summarization research enabled by the\navailability of novel, often large-scale, datasets and recent advances on\nneural network-based approaches. However, manual evaluation of the system\ngenerated summaries is inconsistent due to the difficulty the task poses to\nhuman non-expert readers. To address this issue, we propose a novel approach\nfor manual evaluation, Highlight-based Reference-less Evaluation of\nSummarization (HighRES), in which summaries are assessed by multiple annotators\nagainst the source document via manually highlighted salient content in the\nlatter. Thus summary assessment on the source document by human judges is\nfacilitated, while the highlights can be used for evaluating multiple systems.\nTo validate our approach we employ crowd-workers to augment with highlights a\nrecently proposed dataset and compare two state-of-the-art systems. We\ndemonstrate that HighRES improves inter-annotator agreement in comparison to\nusing the source document directly, while they help emphasize differences among\nsystems that would be ignored under other evaluation approaches.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 11:47:23 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Hardy", "", ""], ["Narayan", "Shashi", ""], ["Vlachos", "Andreas", ""]]}, {"id": "1906.01373", "submitter": "Jose Camacho-Collados", "authors": "Jose Camacho-Collados and Luis Espinosa-Anke and Steven Schockaert", "title": "Relational Word Embeddings", "comments": "To appear at ACL 2019. 11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While word embeddings have been shown to implicitly encode various forms of\nattributional knowledge, the extent to which they capture relational\ninformation is far more limited. In previous work, this limitation has been\naddressed by incorporating relational knowledge from external knowledge bases\nwhen learning the word embedding. Such strategies may not be optimal, however,\nas they are limited by the coverage of available resources and conflate\nsimilarity with other forms of relatedness. As an alternative, in this paper we\npropose to encode relational knowledge in a separate word embedding, which is\naimed to be complementary to a given standard word embedding. This relational\nword embedding is still learned from co-occurrence statistics, and can thus be\nused even when no external knowledge base is available. Our analysis shows that\nrelational word vectors do indeed capture information that is complementary to\nwhat is encoded in standard word embeddings.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 12:30:02 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Camacho-Collados", "Jose", ""], ["Espinosa-Anke", "Luis", ""], ["Schockaert", "Steven", ""]]}, {"id": "1906.01378", "submitter": "Minlong Peng", "authors": "Minlong Peng, Xiaoyu Xing, Qi Zhang, Jinlan Fu, Xuanjing Huang", "title": "Distantly Supervised Named Entity Recognition using Positive-Unlabeled\n  Learning", "comments": "to appear at ACL 2019 (revise expression of equation (4))", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we explore the way to perform named entity recognition (NER)\nusing only unlabeled data and named entity dictionaries. To this end, we\nformulate the task as a positive-unlabeled (PU) learning problem and\naccordingly propose a novel PU learning algorithm to perform the task. We prove\nthat the proposed algorithm can unbiasedly and consistently estimate the task\nloss as if there is fully labeled data. A key feature of the proposed method is\nthat it does not require the dictionaries to label every entity within a\nsentence, and it even does not require the dictionaries to label all of the\nwords constituting an entity. This greatly reduces the requirement on the\nquality of the dictionaries and makes our method generalize well with quite\nsimple dictionaries. Empirical studies on four public NER datasets demonstrate\nthe effectiveness of our proposed method. We have published the source code at\n\\url{https://github.com/v-mipeng/LexiconNER}.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 12:39:10 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 02:05:37 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Peng", "Minlong", ""], ["Xing", "Xiaoyu", ""], ["Zhang", "Qi", ""], ["Fu", "Jinlan", ""], ["Huang", "Xuanjing", ""]]}, {"id": "1906.01392", "submitter": "Chang Xu", "authors": "Chang Xu, Cecile Paris, Surya Nepal, Ross Sparks", "title": "Recognising Agreement and Disagreement between Stances with Reason\n  Comparing Networks", "comments": "To appear at the 57th Annual Meeting of the Association for\n  Computational Linguistics (ACL 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identify agreement and disagreement between utterances that express\nstances towards a topic of discussion. Existing methods focus mainly on\nconversational settings, where dialogic features are used for (dis)agreement\ninference. We extend this scope and seek to detect stance (dis)agreement in a\nbroader setting, where independent stance-bearing utterances, which prevail in\nmany stance corpora and real-world scenarios, are compared. To cope with such\nnon-dialogic utterances, we find that the reasons uttered to back up a specific\nstance can help predict stance (dis)agreements. We propose a reason comparing\nnetwork (RCN) to leverage reason information for stance comparison. Empirical\nresults on a well-known stance corpus show that our method can discover useful\nreason information, enabling it to outperform several baselines in stance\n(dis)agreement detection.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 13:04:38 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Xu", "Chang", ""], ["Paris", "Cecile", ""], ["Nepal", "Surya", ""], ["Sparks", "Ross", ""]]}, {"id": "1906.01393", "submitter": "Martin Schmitt", "authors": "Martin Schmitt and Hinrich Sch\\\"utze", "title": "SherLIiC: A Typed Event-Focused Lexical Inference Benchmark for\n  Evaluating Natural Language Inference", "comments": "Accepted as a long paper to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present SherLIiC, a testbed for lexical inference in context (LIiC),\nconsisting of 3985 manually annotated inference rule candidates (InfCands),\naccompanied by (i) ~960k unlabeled InfCands, and (ii) ~190k typed textual\nrelations between Freebase entities extracted from the large entity-linked\ncorpus ClueWeb09. Each InfCand consists of one of these relations, expressed as\na lemmatized dependency path, and two argument placeholders, each linked to one\nor more Freebase types. Due to our candidate selection process based on strong\ndistributional evidence, SherLIiC is much harder than existing testbeds because\ndistributional evidence is of little utility in the classification of InfCands.\nWe also show that, due to its construction, many of SherLIiC's correct InfCands\nare novel and missing from existing rule bases. We evaluate a number of strong\nbaselines on SherLIiC, ranging from semantic vector space models to state of\nthe art neural models of natural language inference (NLI). We show that\nSherLIiC poses a tough challenge to existing NLI systems.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 13:07:35 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Schmitt", "Martin", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1906.01440", "submitter": "Rocco Tripodi", "authors": "Rocco Tripodi, Massimo Warglien, Simon Levis Sullam and Deborah Paci", "title": "Tracing Antisemitic Language Through Diachronic Embedding Projections:\n  France 1789-1914", "comments": "Accepted to the 1st International Workshop on Computational\n  Approaches to Historical Language Change 2019 (ACL 2019). 11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We investigate some aspects of the history of antisemitism in France, one of\nthe cradles of modern antisemitism, using diachronic word embeddings. We\nconstructed a large corpus of French books and periodicals issues that contain\na keyword related to Jews and performed a diachronic word embedding over the\n1789-1914 period. We studied the changes over time in the semantic spaces of 4\ntarget words and performed embedding projections over 6 streams of antisemitic\ndiscourse. This allowed us to track the evolution of antisemitic bias in the\nreligious, economic, socio-politic, racial, ethic and conspiratorial domains.\nProjections show a trend of growing antisemitism, especially in the years\nstarting in the mid-80s and culminating in the Dreyfus affair. Our analysis\nalso allows us to highlight the peculiar adverse bias towards Judaism in the\nbroader context of other religions.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 13:54:47 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Tripodi", "Rocco", ""], ["Warglien", "Massimo", ""], ["Sullam", "Simon Levis", ""], ["Paci", "Deborah", ""]]}, {"id": "1906.01472", "submitter": "Elisa Ferracane", "authors": "Elisa Ferracane, Greg Durrett, Junyi Jessy Li, Katrin Erk", "title": "Evaluating Discourse in Structured Text Representations", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Discourse structure is integral to understanding a text and is helpful in\nmany NLP tasks. Learning latent representations of discourse is an attractive\nalternative to acquiring expensive labeled discourse data. Liu and Lapata\n(2018) propose a structured attention mechanism for text classification that\nderives a tree over a text, akin to an RST discourse tree. We examine this\nmodel in detail, and evaluate on additional discourse-relevant tasks and\ndatasets, in order to assess whether the structured attention improves\nperformance on the end task and whether it captures a text's discourse\nstructure. We find the learned latent trees have little to no structure and\ninstead focus on lexical cues; even after obtaining more structured trees with\nproposed model modifications, the trees are still far from capturing discourse\nstructure when compared to discourse dependency trees from an existing\ndiscourse parser. Finally, ablation studies show the structured attention\nprovides little benefit, sometimes even hurting performance.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 14:21:22 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 17:34:10 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Ferracane", "Elisa", ""], ["Durrett", "Greg", ""], ["Li", "Junyi Jessy", ""], ["Erk", "Katrin", ""]]}, {"id": "1906.01496", "submitter": "Navid Rekabsaz", "authors": "Navid Rekabsaz, Nikolaos Pappas, James Henderson, Banriskhem K.\n  Khonglah, Srikanth Madikeri", "title": "Regularization Advantages of Multilingual Neural Language Models for Low\n  Resource Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural language modeling (LM) has led to significant improvements in several\napplications, including Automatic Speech Recognition. However, they typically\nrequire large amounts of training data, which is not available for many domains\nand languages. In this study, we propose a multilingual neural language model\narchitecture, trained jointly on the domain-specific data of several\nlow-resource languages. The proposed multilingual LM consists of language\nspecific word embeddings in the encoder and decoder, and one language specific\nLSTM layer, plus two LSTM layers with shared parameters across the languages.\nThis multilingual LM model facilitates transfer learning across the languages,\nacting as an extra regularizer in very low-resource scenarios. We integrate our\nproposed multilingual approach with a state-of-the-art highly-regularized\nneural LM, and evaluate on the conversational data domain for four languages\nover a range of training data sizes. Compared to monolingual LMs, the results\nshow significant improvements of our proposed multilingual LM when the amount\nof available training data is limited, indicating the advantages of\ncross-lingual parameter sharing in very low-resource language modeling.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 13:27:11 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Rekabsaz", "Navid", ""], ["Pappas", "Nikolaos", ""], ["Henderson", "James", ""], ["Khonglah", "Banriskhem K.", ""], ["Madikeri", "Srikanth", ""]]}, {"id": "1906.01498", "submitter": "Bonggun Shin", "authors": "Bonggun Shin, Julien Hogan, Andrew B. Adams, Raymond J. Lynch, Rachel\n  E. Patzer, Jinho D. Choi", "title": "Multimodal Ensemble Approach to Incorporate Various Types of Clinical\n  Notes for Predicting Readmission", "comments": "4 pages, IEEE BHI 2019", "journal-ref": "Proceedings of the IEEE-EMBS International Conference on\n  Biomedical and Health Informatics, 2019 (BHI'19)", "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic Health Records (EHRs) have been heavily used to predict various\ndownstream clinical tasks such as readmission or mortality. One of the\nmodalities in EHRs, clinical notes, has not been fully explored for these tasks\ndue to its unstructured and inexplicable nature. Although recent advances in\ndeep learning (DL) enables models to extract interpretable features from\nunstructured data, they often require a large amount of training data. However,\nmany tasks in medical domains inherently consist of small sample data with\nlengthy documents; for a kidney transplant as an example, data from only a few\nthousand of patients are available and each patient's document consists of a\ncouple of millions of words in major hospitals. Thus, complex DL methods cannot\nbe applied to these kinds of domains. In this paper, we present a comprehensive\nensemble model using vector space modeling and topic modeling. Our proposed\nmodel is evaluated on the readmission task of kidney transplant patients and\nimproves 0.0211 in terms of c-statistics from the previous state-of-the-art\napproach using structured data, while typical DL methods fail to beat this\napproach. The proposed architecture provides the interpretable score for each\nfeature from both modalities, structured and unstructured data, which is shown\nto be meaningful through a physician's evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 20:25:06 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Shin", "Bonggun", ""], ["Hogan", "Julien", ""], ["Adams", "Andrew B.", ""], ["Lynch", "Raymond J.", ""], ["Patzer", "Rachel E.", ""], ["Choi", "Jinho D.", ""]]}, {"id": "1906.01502", "submitter": "Telmo Pires", "authors": "Telmo Pires, Eva Schlinger and Dan Garrette", "title": "How multilingual is Multilingual BERT?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show that Multilingual BERT (M-BERT), released by Devlin et\nal. (2018) as a single language model pre-trained from monolingual corpora in\n104 languages, is surprisingly good at zero-shot cross-lingual model transfer,\nin which task-specific annotations in one language are used to fine-tune the\nmodel for evaluation in another language. To understand why, we present a large\nnumber of probing experiments, showing that transfer is possible even to\nlanguages in different scripts, that transfer works best between typologically\nsimilar languages, that monolingual corpora can train models for\ncode-switching, and that the model can find translation pairs. From these\nresults, we can conclude that M-BERT does create multilingual representations,\nbut that these representations exhibit systematic deficiencies affecting\ncertain language pairs.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 15:12:47 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Pires", "Telmo", ""], ["Schlinger", "Eva", ""], ["Garrette", "Dan", ""]]}, {"id": "1906.01511", "submitter": "Hongtao Liu", "authors": "Xianchen Wang, Hongtao Liu, Peiyi Wang, Fangzhao Wu, Hongyan Xu,\n  Wenjun Wang, Xing Xie", "title": "Neural Review Rating Prediction with Hierarchical Attentions and Latent\n  Factors", "comments": "4pages, 1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text reviews can provide rich useful semantic information for modeling users\nand items, which can benefit rating prediction in recommendation. Different\nwords and reviews may have different informativeness for users or items.\nBesides, different users and items should be personalized. Most existing works\nregard all reviews equally or utilize a general attention mechanism. In this\npaper, we propose a hierarchical attention model fusing latent factor model for\nrating prediction with reviews, which can focus on important words and\ninformative reviews. Specially, we use the factor vectors of Latent Factor\nModel to guide the attention network and combine the factor vectors with\nfeature representation learned from reviews to predict the final ratings.\nExperiments on real-world datasets validate the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 14:16:28 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Wang", "Xianchen", ""], ["Liu", "Hongtao", ""], ["Wang", "Peiyi", ""], ["Wu", "Fangzhao", ""], ["Xu", "Hongyan", ""], ["Wang", "Wenjun", ""], ["Xie", "Xing", ""]]}, {"id": "1906.01512", "submitter": "Tian Shi", "authors": "Tian Shi, Ping Wang, Chandan K. Reddy", "title": "LeafNATS: An Open-Source Toolkit and Live Demo System for Neural\n  Abstractive Text Summarization", "comments": "Accepted by NAACL-HLT 2019 demo track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural abstractive text summarization (NATS) has received a lot of attention\nin the past few years from both industry and academia. In this paper, we\nintroduce an open-source toolkit, namely LeafNATS, for training and evaluation\nof different sequence-to-sequence based models for the NATS task, and for\ndeploying the pre-trained models to real-world applications. The toolkit is\nmodularized and extensible in addition to maintaining competitive performance\nin the NATS task. A live news blogging system has also been implemented to\ndemonstrate how these models can aid blog/news editors by providing them\nsuggestions of headlines and summaries of their articles.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 23:53:02 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Shi", "Tian", ""], ["Wang", "Ping", ""], ["Reddy", "Chandan K.", ""]]}, {"id": "1906.01514", "submitter": "Liuyu Xiang", "authors": "Liuyu Xiang, Xiaoming Jin, Lan Yi, Guiguang Ding", "title": "Adaptive Region Embedding for Text Classification", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models such as convolutional neural networks and recurrent\nnetworks are widely applied in text classification. In spite of their great\nsuccess, most deep learning models neglect the importance of modeling context\ninformation, which is crucial to understanding texts. In this work, we propose\nthe Adaptive Region Embedding to learn context representation to improve text\nclassification. Specifically, a metanetwork is learned to generate a context\nmatrix for each region, and each word interacts with its corresponding context\nmatrix to produce the regional representation for further classification.\nCompared to previous models that are designed to capture context information,\nour model contains less parameters and is more flexible. We extensively\nevaluate our method on 8 benchmark datasets for text classification. The\nexperimental results prove that our method achieves state-of-the-art\nperformances and effectively avoids word ambiguity.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 13:11:23 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Xiang", "Liuyu", ""], ["Jin", "Xiaoming", ""], ["Yi", "Lan", ""], ["Ding", "Guiguang", ""]]}, {"id": "1906.01515", "submitter": "Piotr Niewinski", "authors": "Piotr Niewinski, Aleksander Wawer, Maria Pszona, Maria Janicka", "title": "TMLab SRPOL at SemEval-2019 Task 8: Fact Checking in Community Question\n  Answering Forums", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article describes our submission to SemEval 2019 Task 8 on Fact-Checking\nin Community Forums. The systems under discussion participated in Subtask A:\ndecide whether a question asks for factual information, opinion/advice or is\njust socializing. Our primary submission was ranked as the second one among all\nparticipants in the official evaluation phase. The article presents our primary\nsolution: Deeply Regularized Residual Neural Network (DRR NN) with Universal\nSentence Encoder embeddings. This is followed by a description of two\ncontrastive solutions based on ensemble methods.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 09:31:26 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Niewinski", "Piotr", ""], ["Wawer", "Aleksander", ""], ["Pszona", "Maria", ""], ["Janicka", "Maria", ""]]}, {"id": "1906.01530", "submitter": "Janosch Haber", "authors": "Janosch Haber, Tim Baumg\\\"artner, Ece Takmaz, Lieke Gelderloos, Elia\n  Bruni and Raquel Fern\\'andez", "title": "The PhotoBook Dataset: Building Common Ground through Visually-Grounded\n  Dialogue", "comments": "Updates 26-06-2019: Changed caption sizes to comply with the ACL\n  style guidelines and corrected some references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the PhotoBook dataset, a large-scale collection of\nvisually-grounded, task-oriented dialogues in English designed to investigate\nshared dialogue history accumulating during conversation. Taking inspiration\nfrom seminal work on dialogue analysis, we propose a data-collection task\nformulated as a collaborative game prompting two online participants to refer\nto images utilising both their visual context as well as previously established\nreferring expressions. We provide a detailed description of the task setup and\na thorough analysis of the 2,500 dialogues collected. To further illustrate the\nnovel features of the dataset, we propose a baseline model for reference\nresolution which uses a simple method to take into account shared information\naccumulated in a reference chain. Our results show that this information is\nparticularly important to resolve later descriptions and underline the need to\ndevelop more sophisticated models of common ground in dialogue interaction.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 15:41:32 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 17:36:47 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Haber", "Janosch", ""], ["Baumg\u00e4rtner", "Tim", ""], ["Takmaz", "Ece", ""], ["Gelderloos", "Lieke", ""], ["Bruni", "Elia", ""], ["Fern\u00e1ndez", "Raquel", ""]]}, {"id": "1906.01539", "submitter": "Samira Abnar", "authors": "Samira Abnar, Lisa Beinborn, Rochelle Choenni, Willem Zuidema", "title": "Blackbox meets blackbox: Representational Similarity and Stability\n  Analysis of Neural Language Models and Brains", "comments": null, "journal-ref": "2nd BlackBoxNLP workshop @ACL2019", "doi": null, "report-no": null, "categories": "cs.AI cs.CL q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we define and apply representational stability analysis\n(ReStA), an intuitive way of analyzing neural language models. ReStA is a\nvariant of the popular representational similarity analysis (RSA) in cognitive\nneuroscience. While RSA can be used to compare representations in models, model\ncomponents, and human brains, ReStA compares instances of the same model, while\nsystematically varying single model parameter. Using ReStA, we study four\nrecent and successful neural language models, and evaluate how sensitive their\ninternal representations are to the amount of prior context. Using RSA, we\nperform a systematic study of how similar the representational spaces in the\nfirst and second (or higher) layers of these models are to each other and to\npatterns of activation in the human brain. Our results reveal surprisingly\nstrong differences between language models, and give insights into where the\ndeep linguistic processing, that integrates information over multiple\nsentences, is happening in these models. The combination of ReStA and RSA on\nmodels and brains allows us to start addressing the important question of what\nkind of linguistic processes we can hope to observe in fMRI brain imaging data.\nIn particular, our results suggest that the data on story reading from Wehbe et\nal. (2014) contains a signal of shallow linguistic processing, but show no\nevidence on the more interesting deep linguistic processing.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 15:52:46 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 09:58:34 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Abnar", "Samira", ""], ["Beinborn", "Lisa", ""], ["Choenni", "Rochelle", ""], ["Zuidema", "Willem", ""]]}, {"id": "1906.01543", "submitter": "Ivan Vuli\\'c", "authors": "Matthew Henderson, Ivan Vuli\\'c, Daniela Gerz, I\\~nigo Casanueva,\n  Pawe{\\l} Budzianowski, Sam Coope, Georgios Spithourakis, Tsung-Hsien Wen,\n  Nikola Mrk\\v{s}i\\'c, Pei-Hao Su", "title": "Training Neural Response Selection for Task-Oriented Dialogue Systems", "comments": "ACL 2019 long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite their popularity in the chatbot literature, retrieval-based models\nhave had modest impact on task-oriented dialogue systems, with the main\nobstacle to their application being the low-data regime of most task-oriented\ndialogue tasks. Inspired by the recent success of pretraining in language\nmodelling, we propose an effective method for deploying response selection in\ntask-oriented dialogue. To train response selection models for task-oriented\ndialogue tasks, we propose a novel method which: 1) pretrains the response\nselection model on large general-domain conversational corpora; and then 2)\nfine-tunes the pretrained model for the target dialogue domain, relying only on\nthe small in-domain dataset to capture the nuances of the given dialogue\ndomain. Our evaluation on six diverse application domains, ranging from\ne-commerce to banking, demonstrates the effectiveness of the proposed training\nmethod.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 15:58:54 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 15:03:25 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Henderson", "Matthew", ""], ["Vuli\u0107", "Ivan", ""], ["Gerz", "Daniela", ""], ["Casanueva", "I\u00f1igo", ""], ["Budzianowski", "Pawe\u0142", ""], ["Coope", "Sam", ""], ["Spithourakis", "Georgios", ""], ["Wen", "Tsung-Hsien", ""], ["Mrk\u0161i\u0107", "Nikola", ""], ["Su", "Pei-Hao", ""]]}, {"id": "1906.01545", "submitter": "Ramon Ferrer i Cancho", "authors": "Ramon Ferrer-i-Cancho, Christian Bentz and Caio Seguin", "title": "Optimal coding and the origins of Zipfian laws", "comments": "in press in the Journal of Quantitative Linguistics; definition of\n  concordant pair corrected, proofs polished, references updated", "journal-ref": null, "doi": "10.1080/09296174.2020.1778387", "report-no": null, "categories": "cs.CL cs.IT math.IT physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of compression in standard information theory consists of\nassigning codes as short as possible to numbers. Here we consider the problem\nof optimal coding -- under an arbitrary coding scheme -- and show that it\npredicts Zipf's law of abbreviation, namely a tendency in natural languages for\nmore frequent words to be shorter. We apply this result to investigate optimal\ncoding also under so-called non-singular coding, a scheme where unique\nsegmentation is not warranted but codes stand for a distinct number. Optimal\nnon-singular coding predicts that the length of a word should grow\napproximately as the logarithm of its frequency rank, which is again consistent\nwith Zipf's law of abbreviation. Optimal non-singular coding in combination\nwith the maximum entropy principle also predicts Zipf's rank-frequency\ndistribution. Furthermore, our findings on optimal non-singular coding\nchallenge common beliefs about random typing. It turns out that random typing\nis in fact an optimal coding process, in stark contrast with the common\nassumption that it is detached from cost cutting considerations. Finally, we\ndiscuss the implications of optimal coding for the construction of a compact\ntheory of Zipfian laws and other linguistic laws.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 16:03:18 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 06:29:57 GMT"}, {"version": "v3", "created": "Thu, 19 Dec 2019 16:09:39 GMT"}, {"version": "v4", "created": "Fri, 29 May 2020 16:32:11 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Ferrer-i-Cancho", "Ramon", ""], ["Bentz", "Christian", ""], ["Seguin", "Caio", ""]]}, {"id": "1906.01546", "submitter": "Chanyoung Park", "authors": "Chanyoung Park, Donghyun Kim, Qi Zhu, Jiawei Han, Hwanjo Yu", "title": "Task-Guided Pair Embedding in Heterogeneous Network", "comments": "CIKM 2019 Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world tasks solved by heterogeneous network embedding methods can\nbe cast as modeling the likelihood of pairwise relationship between two nodes.\nFor example, the goal of author identification task is to model the likelihood\nof a paper being written by an author (paper-author pairwise relationship).\nExisting task-guided embedding methods are node-centric in that they simply\nmeasure the similarity between the node embeddings to compute the likelihood of\na pairwise relationship between two nodes. However, we claim that for\ntask-guided embeddings, it is crucial to focus on directly modeling the\npairwise relationship. In this paper, we propose a novel task-guided pair\nembedding framework in heterogeneous network, called TaPEm, that directly\nmodels the relationship between a pair of nodes that are related to a specific\ntask (e.g., paper-author relationship in author identification). To this end,\nwe 1) propose to learn a pair embedding under the guidance of its associated\ncontext path, i.e., a sequence of nodes between the pair, and 2) devise the\npair validity classifier to distinguish whether the pair is valid with respect\nto the specific task at hand. By introducing pair embeddings that capture the\nsemantics behind the pairwise relationships, we are able to learn the\nfine-grained pairwise relationship between two nodes, which is paramount for\ntask-guided embedding methods. Extensive experiments on author identification\ntask demonstrate that TaPEm outperforms the state-of-the-art methods,\nespecially for authors with few publication records.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 16:04:04 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 21:21:49 GMT"}, {"version": "v3", "created": "Thu, 29 Aug 2019 16:32:35 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Park", "Chanyoung", ""], ["Kim", "Donghyun", ""], ["Zhu", "Qi", ""], ["Han", "Jiawei", ""], ["Yu", "Hwanjo", ""]]}, {"id": "1906.01569", "submitter": "Benjamin Heinzerling", "authors": "Benjamin Heinzerling and Michael Strube", "title": "Sequence Tagging with Contextual and Non-Contextual Subword\n  Representations: A Multilingual Evaluation", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pretrained contextual and non-contextual subword embeddings have become\navailable in over 250 languages, allowing massively multilingual NLP. However,\nwhile there is no dearth of pretrained embeddings, the distinct lack of\nsystematic evaluations makes it difficult for practitioners to choose between\nthem. In this work, we conduct an extensive evaluation comparing non-contextual\nsubword embeddings, namely FastText and BPEmb, and a contextual representation\nmethod, namely BERT, on multilingual named entity recognition and\npart-of-speech tagging. We find that overall, a combination of BERT, BPEmb, and\ncharacter representations works best across languages and tasks. A more\ndetailed analysis reveals different strengths and weaknesses: Multilingual BERT\nperforms well in medium- to high-resource languages, but is outperformed by\nnon-contextual subword embeddings in a low-resource setting.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 16:36:53 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Heinzerling", "Benjamin", ""], ["Strube", "Michael", ""]]}, {"id": "1906.01573", "submitter": "Avinash Madasu", "authors": "Avinash Madasu and Sivasankar E", "title": "A Study of Feature Extraction techniques for Sentiment Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment Analysis refers to the study of systematically extracting the\nmeaning of subjective text . When analysing sentiments from the subjective text\nusing Machine Learning techniques,feature extraction becomes a significant\npart. We perform a study on the performance of feature extraction techniques\nTF-IDF(Term Frequency-Inverse Document Frequency) and Doc2vec (Document to\nVector) using Cornell movie review datasets, UCI sentiment labeled datasets,\nstanford movie review datasets,effectively classifying the text into positive\nand negative polarities by using various pre-processing methods like\neliminating StopWords and Tokenization which increases the performance of\nsentiment analysis in terms of accuracy and time taken by the classifier.The\nfeatures obtained after applying feature extraction techniques on the text\nsentences are trained and tested using the classifiers Logistic\nRegression,Support Vector Machines,K-Nearest Neighbours , Decision Tree and\nBernoulli Nave Bayes\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 16:37:44 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Madasu", "Avinash", ""], ["E", "Sivasankar", ""]]}, {"id": "1906.01575", "submitter": "Steffen Eger", "authors": "Steffen Eger and Andreas R\\\"uckl\\'e and Iryna Gurevych", "title": "Pitfalls in the Evaluation of Sentence Embeddings", "comments": "Accepted at Repl4NLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models continuously break new records across different NLP\ntasks. At the same time, their success exposes weaknesses of model evaluation.\nHere, we compile several key pitfalls of evaluation of sentence embeddings, a\ncurrently very popular NLP paradigm. These pitfalls include the comparison of\nembeddings of different sizes, normalization of embeddings, and the low (and\ndiverging) correlations between transfer and probing tasks. Our motivation is\nto challenge the current evaluation of sentence embeddings and to provide an\neasy-to-access reference for future research. Based on our insights, we also\nrecommend better practices for better future evaluations of sentence\nembeddings.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 16:41:15 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Eger", "Steffen", ""], ["R\u00fcckl\u00e9", "Andreas", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1906.01594", "submitter": "Yiding Hao", "authors": "William Merrill, Lenny Khazan, Noah Amsel, Yiding Hao, Simon\n  Mendelsohn, Robert Frank", "title": "Finding Syntactic Representations in Neural Stacks", "comments": "To appear in the Proceedings of the 2019 ACL Workshop BlackboxNLP:\n  Analyzing and Interpreting Neural Networks for NLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network architectures have been augmented with differentiable stacks\nin order to introduce a bias toward learning hierarchy-sensitive regularities.\nIt has, however, proven difficult to assess the degree to which such a bias is\neffective, as the operation of the differentiable stack is not always\ninterpretable. In this paper, we attempt to detect the presence of latent\nrepresentations of hierarchical structure through an exploration of the\nunsupervised learning of constituency structure. Using a technique due to Shen\net al. (2018a,b), we extract syntactic trees from the pushing behavior of stack\nRNNs trained on language modeling and classification objectives. We find that\nour models produce parses that reflect natural language syntactic\nconstituencies, demonstrating that stack RNNs do indeed infer linguistically\nrelevant hierarchical structure.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 17:14:26 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Merrill", "William", ""], ["Khazan", "Lenny", ""], ["Amsel", "Noah", ""], ["Hao", "Yiding", ""], ["Mendelsohn", "Simon", ""], ["Frank", "Robert", ""]]}, {"id": "1906.01603", "submitter": "Chinnadhurai Sankar", "authors": "Chinnadhurai Sankar, Sandeep Subramanian, Christopher Pal, Sarath\n  Chandar, Yoshua Bengio", "title": "Do Neural Dialog Systems Use the Conversation History Effectively? An\n  Empirical Study", "comments": "To appear at ACL 2019(oral; nominated for best paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural generative models have been become increasingly popular when building\nconversational agents. They offer flexibility, can be easily adapted to new\ndomains, and require minimal domain engineering. A common criticism of these\nsystems is that they seldom understand or use the available dialog history\neffectively. In this paper, we take an empirical approach to understanding how\nthese models use the available dialog history by studying the sensitivity of\nthe models to artificially introduced unnatural changes or perturbations to\ntheir context at test time. We experiment with 10 different types of\nperturbations on 4 multi-turn dialog datasets and find that commonly used\nneural dialog architectures like recurrent and transformer-based seq2seq models\nare rarely sensitive to most perturbations such as missing or reordering\nutterances, shuffling words, etc. Also, by open-sourcing our code, we believe\nthat it will serve as a useful diagnostic tool for evaluating dialog systems in\nthe future.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 17:32:35 GMT"}, {"version": "v2", "created": "Thu, 25 Jul 2019 20:27:46 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Sankar", "Chinnadhurai", ""], ["Subramanian", "Sandeep", ""], ["Pal", "Christopher", ""], ["Chandar", "Sarath", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1906.01604", "submitter": "Mitchell Stern", "authors": "William Chan, Nikita Kitaev, Kelvin Guu, Mitchell Stern, Jakob\n  Uszkoreit", "title": "KERMIT: Generative Insertion-Based Modeling for Sequences", "comments": "William Chan, Nikita Kitaev, Kelvin Guu, and Mitchell Stern\n  contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present KERMIT, a simple insertion-based approach to generative modeling\nfor sequences and sequence pairs. KERMIT models the joint distribution and its\ndecompositions (i.e., marginals and conditionals) using a single neural network\nand, unlike much prior work, does not rely on a prespecified factorization of\nthe data distribution. During training, one can feed KERMIT paired data $(x,\ny)$ to learn the joint distribution $p(x, y)$, and optionally mix in unpaired\ndata $x$ or $y$ to refine the marginals $p(x)$ or $p(y)$. During inference, we\nhave access to the conditionals $p(x \\mid y)$ and $p(y \\mid x)$ in both\ndirections. We can also sample from the joint distribution or the marginals.\nThe model supports both serial fully autoregressive decoding and parallel\npartially autoregressive decoding, with the latter exhibiting an empirically\nlogarithmic runtime. We demonstrate through experiments in machine translation,\nrepresentation learning, and zero-shot cloze question answering that our\nunified approach is capable of matching or exceeding the performance of\ndedicated state-of-the-art systems across a wide range of tasks without the\nneed for problem-specific architectural adaptation.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 17:35:35 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Chan", "William", ""], ["Kitaev", "Nikita", ""], ["Guu", "Kelvin", ""], ["Stern", "Mitchell", ""], ["Uszkoreit", "Jakob", ""]]}, {"id": "1906.01605", "submitter": "Chinnadhurai Sankar", "authors": "Chinnadhurai Sankar, Sujith Ravi, Zornitsa Kozareva", "title": "Transferable Neural Projection Representations", "comments": null, "journal-ref": "Proc. of NAACL 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural word representations are at the core of many state-of-the-art natural\nlanguage processing models. A widely used approach is to pre-train, store and\nlook up word or character embedding matrices. While useful, such\nrepresentations occupy huge memory making it hard to deploy on-device and often\ndo not generalize to unknown words due to vocabulary pruning.\n  In this paper, we propose a skip-gram based architecture coupled with\nLocality-Sensitive Hashing (LSH) projections to learn efficient dynamically\ncomputable representations. Our model does not need to store lookup tables as\nrepresentations are computed on-the-fly and require low memory footprint. The\nrepresentations can be trained in an unsupervised fashion and can be easily\ntransferred to other NLP tasks. For qualitative evaluation, we analyze the\nnearest neighbors of the word representations and discover semantically similar\nwords even with misspellings. For quantitative evaluation, we plug our\ntransferable projections into a simple LSTM and run it on multiple NLP tasks\nand show how our transferable projections achieve better performance compared\nto prior work.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 17:39:52 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Sankar", "Chinnadhurai", ""], ["Ravi", "Sujith", ""], ["Kozareva", "Zornitsa", ""]]}, {"id": "1906.01615", "submitter": "William Merrill", "authors": "William Merrill", "title": "Sequential Neural Networks as Automata", "comments": "To appear in the proceedings of the Deep Learning and Formal\n  Languages workshop at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.FL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work attempts to explain the types of computation that neural networks\ncan perform by relating them to automata. We first define what it means for a\nreal-time network with bounded precision to accept a language. A measure of\nnetwork memory follows from this definition. We then characterize the classes\nof languages acceptable by various recurrent networks, attention, and\nconvolutional networks. We find that LSTMs function like counter machines and\nrelate convolutional networks to the subregular hierarchy. Overall, this work\nattempts to increase our understanding and ability to interpret neural networks\nthrough the lens of theory. These theoretical insights help explain neural\ncomputation, as well as the relationship between neural networks and natural\nlanguage grammar.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 17:47:34 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 03:40:56 GMT"}, {"version": "v3", "created": "Mon, 4 Jan 2021 23:45:44 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Merrill", "William", ""]]}, {"id": "1906.01617", "submitter": "Matthias Sperber", "authors": "Matthias Sperber, Graham Neubig, Ngoc-Quan Pham, Alex Waibel", "title": "Self-Attentional Models for Lattice Inputs", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lattices are an efficient and effective method to encode ambiguity of\nupstream systems in natural language processing tasks, for example to compactly\ncapture multiple speech recognition hypotheses, or to represent multiple\nlinguistic analyses. Previous work has extended recurrent neural networks to\nmodel lattice inputs and achieved improvements in various tasks, but these\nmodels suffer from very slow computation speeds. This paper extends the\nrecently proposed paradigm of self-attention to handle lattice inputs.\nSelf-attention is a sequence modeling technique that relates inputs to one\nanother by computing pairwise similarities and has gained popularity for both\nits strong results and its computational efficiency. To extend such models to\nhandle lattices, we introduce probabilistic reachability masks that incorporate\nlattice structure into the model and support lattice scores if available. We\nalso propose a method for adapting positional embeddings to lattice structures.\nWe apply the proposed model to a speech translation task and find that it\noutperforms all examined baselines while being much faster to compute than\nprevious neural lattice models during both training and inference.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 17:51:03 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Sperber", "Matthias", ""], ["Neubig", "Graham", ""], ["Pham", "Ngoc-Quan", ""], ["Waibel", "Alex", ""]]}, {"id": "1906.01622", "submitter": "Mozhi Zhang", "authors": "Mozhi Zhang, Keyulu Xu, Ken-ichi Kawarabayashi, Stefanie Jegelka,\n  Jordan Boyd-Graber", "title": "Are Girls Neko or Sh\\=ojo? Cross-Lingual Alignment of Non-Isomorphic\n  Embeddings with Iterative Normalization", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual word embeddings (CLWE) underlie many multilingual natural\nlanguage processing systems, often through orthogonal transformations of\npre-trained monolingual embeddings. However, orthogonal mapping only works on\nlanguage pairs whose embeddings are naturally isomorphic. For non-isomorphic\npairs, our method (Iterative Normalization) transforms monolingual embeddings\nto make orthogonal alignment easier by simultaneously enforcing that (1)\nindividual word vectors are unit length, and (2) each language's average vector\nis zero. Iterative Normalization consistently improves word translation\naccuracy of three CLWE methods, with the largest improvement observed on\nEnglish-Japanese (from 2% to 44% test accuracy).\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 17:56:22 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 01:34:19 GMT"}, {"version": "v3", "created": "Mon, 11 Nov 2019 07:36:47 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Zhang", "Mozhi", ""], ["Xu", "Keyulu", ""], ["Kawarabayashi", "Ken-ichi", ""], ["Jegelka", "Stefanie", ""], ["Boyd-Graber", "Jordan", ""]]}, {"id": "1906.01634", "submitter": "Dieuwke Hupkes", "authors": "Joris Baan, Jana Leible, Mitja Nikolaus, David Rau, Dennis Ulmer, Tim\n  Baumg\\\"artner, Dieuwke Hupkes and Elia Bruni", "title": "On the Realization of Compositionality in Neural Networks", "comments": "To appear at BlackboxNLP 2019, ACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a detailed comparison of two types of sequence to sequence models\ntrained to conduct a compositional task. The models are architecturally\nidentical at inference time, but differ in the way that they are trained: our\nbaseline model is trained with a task-success signal only, while the other\nmodel receives additional supervision on its attention mechanism (Attentive\nGuidance), which has shown to be an effective method for encouraging more\ncompositional solutions (Hupkes et al.,2019). We first confirm that the models\nwith attentive guidance indeed infer more compositional solutions than the\nbaseline, by training them on the lookup table task presented by Li\\v{s}ka et\nal. (2019). We then do an in-depth analysis of the structural differences\nbetween the two model types, focusing in particular on the organisation of the\nparameter space and the hidden layer activations and find noticeable\ndifferences in both these aspects. Guided networks focus more on the components\nof the input rather than the sequence as a whole and develop small functional\ngroups of neurons with specific purposes that use their gates more selectively.\nResults from parameter heat maps, component swapping and graph analysis also\nindicate that guided networks exhibit a more modular structure with a small\nnumber of specialized, strongly connected neurons.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 07:30:48 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 08:42:25 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Baan", "Joris", ""], ["Leible", "Jana", ""], ["Nikolaus", "Mitja", ""], ["Rau", "David", ""], ["Ulmer", "Dennis", ""], ["Baumg\u00e4rtner", "Tim", ""], ["Hupkes", "Dieuwke", ""], ["Bruni", "Elia", ""]]}, {"id": "1906.01635", "submitter": "Stephan Sloth Lorenzen", "authors": "Magnus Stavngaard, August S{\\o}rensen, Stephan Lorenzen, Niklas\n  Hjuler, Stephen Alstrup", "title": "Detecting Ghostwriters in High Schools", "comments": "Presented at ESANN 2019", "journal-ref": "Proceedings. ESANN 2019: 27th European Symposium on Artificial\n  Neural Networks, Computational Intelligence and Machine Learning. ed. Michel\n  Verleysen. 2019. p 197-202", "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Students hiring ghostwriters to write their assignments is an increasing\nproblem in educational institutions all over the world, with companies selling\nthese services as a product. In this work, we develop automatic techniques with\nspecial focus on detecting such ghostwriting in high school assignments. This\nis done by training deep neural networks on an unprecedented large amount of\ndata supplied by the Danish company MaCom, which covers 90% of Danish high\nschools. We achieve an accuracy of 0.875 and a AUC score of 0.947 on an evenly\nsplit data set.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 13:03:38 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Stavngaard", "Magnus", ""], ["S\u00f8rensen", "August", ""], ["Lorenzen", "Stephan", ""], ["Hjuler", "Niklas", ""], ["Alstrup", "Stephen", ""]]}, {"id": "1906.01659", "submitter": "Gabriele Prato", "authors": "Gabriele Prato, Mathieu Duchesneau, Sarath Chandar, Alain Tapp", "title": "Towards Lossless Encoding of Sentences", "comments": "Accepted at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A lot of work has been done in the field of image compression via machine\nlearning, but not much attention has been given to the compression of natural\nlanguage. Compressing text into lossless representations while making features\neasily retrievable is not a trivial task, yet has huge benefits. Most methods\ndesigned to produce feature rich sentence embeddings focus solely on performing\nwell on downstream tasks and are unable to properly reconstruct the original\nsequence from the learned embedding. In this work, we propose a near lossless\nmethod for encoding long sequences of texts as well as all of their\nsub-sequences into feature rich representations. We test our method on\nsentiment analysis and show good performance across all sub-sentence and\nsentence embeddings.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 18:03:13 GMT"}, {"version": "v2", "created": "Fri, 2 Aug 2019 09:08:41 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Prato", "Gabriele", ""], ["Duchesneau", "Mathieu", ""], ["Chandar", "Sarath", ""], ["Tapp", "Alain", ""]]}, {"id": "1906.01661", "submitter": "William Merrill", "authors": "William Merrill, Gigi Felice Stark, Robert Frank", "title": "Detecting Syntactic Change Using a Neural Part-of-Speech Tagger", "comments": "To appear in the proceedings of the Computational Approaches to\n  Historical Language Change workshop at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We train a diachronic long short-term memory (LSTM) part-of-speech tagger on\na large corpus of American English from the 19th, 20th, and 21st centuries. We\nanalyze the tagger's ability to implicitly learn temporal structure between\nyears, and the extent to which this knowledge can be transferred to date new\nsentences. The learned year embeddings show a strong linear correlation between\ntheir first principal component and time. We show that temporal information\nencoded in the model can be used to predict novel sentences' years of\ncomposition relatively well. Comparisons to a feedforward baseline suggest that\nthe temporal change learned by the LSTM is syntactic rather than purely\nlexical. Thus, our results suggest that our tagger is implicitly learning to\nmodel syntactic change in American English over the course of the 19th, 20th,\nand early 21st centuries.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 18:04:14 GMT"}, {"version": "v2", "created": "Tue, 9 Jul 2019 18:02:02 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Merrill", "William", ""], ["Stark", "Gigi Felice", ""], ["Frank", "Robert", ""]]}, {"id": "1906.01675", "submitter": "Robert Wagner", "authors": "Robert Wagner, Daniel Crispell, Patrick Feeney, Joe Mundy", "title": "4-D Scene Alignment in Surveillance Video", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing robust activity detectors for fixed camera surveillance video\nrequires knowledge of the 3-D scene. This paper presents an automatic camera\ncalibration process that provides a mechanism to reason about the spatial\nproximity between objects at different times. It combines a CNN-based camera\npose estimator with a vertical scale provided by pedestrian observations to\nestablish the 4-D scene geometry. Unlike some previous methods, the people do\nnot need to be tracked nor do the head and feet need to be explicitly detected.\nIt is robust to individual height variations and camera parameter estimation\nerrors.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 18:39:20 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 14:16:19 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Wagner", "Robert", ""], ["Crispell", "Daniel", ""], ["Feeney", "Patrick", ""], ["Mundy", "Joe", ""]]}, {"id": "1906.01685", "submitter": "Samuel L\\\"aubli", "authors": "Samuel L\\\"aubli, Chantal Amrhein, Patrick D\\\"uggelin, Beatriz\n  Gonzalez, Alena Zwahlen, Martin Volk", "title": "Post-editing Productivity with Neural Machine Translation: An Empirical\n  Assessment of Speed and Quality in the Banking and Finance Domain", "comments": "MT Summit 2019 (Research Track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT) has set new quality standards in automatic\ntranslation, yet its effect on post-editing productivity is still pending\nthorough investigation. We empirically test how the inclusion of NMT, in\naddition to domain-specific translation memories and termbases, impacts speed\nand quality in professional translation of financial texts. We find that even\nwith language pairs that have received little attention in research settings\nand small amounts of in-domain data for system adaptation, NMT post-editing\nallows for substantial time savings and leads to equal or slightly better\nquality.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 19:05:11 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["L\u00e4ubli", "Samuel", ""], ["Amrhein", "Chantal", ""], ["D\u00fcggelin", "Patrick", ""], ["Gonzalez", "Beatriz", ""], ["Zwahlen", "Alena", ""], ["Volk", "Martin", ""]]}, {"id": "1906.01688", "submitter": "Nina Tahmasebi", "authors": "Haim Dubossarsky, Simon Hengchen, Nina Tahmasebi and Dominik\n  Schlechtweg", "title": "Time-Out: Temporal Referencing for Robust Modeling of Lexical Semantic\n  Change", "comments": "To appear in the 57th Annual Meeting of the Association for\n  Computational Linguistics (ACL2019)", "journal-ref": null, "doi": "10.18653/v1/P19-1044", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art models of lexical semantic change detection suffer from\nnoise stemming from vector space alignment. We have empirically tested the\nTemporal Referencing method for lexical semantic change and show that, by\navoiding alignment, it is less affected by this noise. We show that, trained on\na diachronic corpus, the skip-gram with negative sampling architecture with\ntemporal referencing outperforms alignment models on a synthetic task as well\nas a manual testset. We introduce a principled way to simulate lexical semantic\nchange and systematically control for possible biases.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 19:19:46 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Dubossarsky", "Haim", ""], ["Hengchen", "Simon", ""], ["Tahmasebi", "Nina", ""], ["Schlechtweg", "Dominik", ""]]}, {"id": "1906.01698", "submitter": "Yongjie Lin", "authors": "Yongjie Lin, Yi Chern Tan and Robert Frank", "title": "Open Sesame: Getting Inside BERT's Linguistic Knowledge", "comments": "To appear in the Proceedings of the 2019 ACL Workshop BlackboxNLP:\n  Analyzing and Interpreting Neural Networks for NLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How and to what extent does BERT encode syntactically-sensitive hierarchical\ninformation or positionally-sensitive linear information? Recent work has shown\nthat contextual representations like BERT perform well on tasks that require\nsensitivity to linguistic structure. We present here two studies which aim to\nprovide a better understanding of the nature of BERT's representations. The\nfirst of these focuses on the identification of structurally-defined elements\nusing diagnostic classifiers, while the second explores BERT's representation\nof subject-verb agreement and anaphor-antecedent dependencies through a\nquantitative assessment of self-attention vectors. In both cases, we find that\nBERT encodes positional information about word tokens well on its lower layers,\nbut switches to a hierarchically-oriented encoding on higher layers. We\nconclude then that BERT's representations do indeed model linguistically\nrelevant aspects of hierarchical structure, though they do not appear to show\nthe sharp sensitivity to hierarchical structure that is found in human\nprocessing of reflexive anaphora.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 19:41:10 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Lin", "Yongjie", ""], ["Tan", "Yi Chern", ""], ["Frank", "Robert", ""]]}, {"id": "1906.01702", "submitter": "Hongyin Luo", "authors": "Hongyin Luo, Lan Jiang, Yonatan Belinkov, James Glass", "title": "Improving Neural Language Models by Segmenting, Attending, and\n  Predicting the Future", "comments": "Accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Common language models typically predict the next word given the context. In\nthis work, we propose a method that improves language modeling by learning to\nalign the given context and the following phrase. The model does not require\nany linguistic annotation of phrase segmentation. Instead, we define syntactic\nheights and phrase segmentation rules, enabling the model to automatically\ninduce phrases, recognize their task-specific heads, and generate phrase\nembeddings in an unsupervised learning manner. Our method can easily be applied\nto language models with different network architectures since an independent\nmodule is used for phrase induction and context-phrase alignment, and no change\nis required in the underlying language modeling network. Experiments have shown\nthat our model outperformed several strong baseline models on different data\nsets. We achieved a new state-of-the-art performance of 17.4 perplexity on the\nWikitext-103 dataset. Additionally, visualizing the outputs of the phrase\ninduction module showed that our model is able to learn approximate\nphrase-level structural knowledge without any annotation.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 19:58:05 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Luo", "Hongyin", ""], ["Jiang", "Lan", ""], ["Belinkov", "Yonatan", ""], ["Glass", "James", ""]]}, {"id": "1906.01726", "submitter": "Naiereh Elyasi", "authors": "Naiereh Elyasi, Mehdi Hosseini Moghadam", "title": "An Introduction to a New Text Classification and Visualization for\n  Natural Language Processing Using Topological Data Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topological Data Analysis (TDA) is a novel new and fast growing field of data\nscience providing a set of new topological and geometric tools to derive\nrelevant features out of complex high-dimensional data. In this paper we apply\ntwo of best methods in topological data analysis, \"Persistent Homology\" and\n\"Mapper\", in order to classify persian poems which has been composed by two of\nthe best Iranian poets namely \"Ferdowsi\" and \"Hafez\". This article has two main\nparts, in the first part we explain the mathematics behind these two methods\nwhich is easy to understand for general audience and in the second part we\ndescribe our models and the results of applying TDA tools to NLP.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 08:06:39 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Elyasi", "Naiereh", ""], ["Moghadam", "Mehdi Hosseini", ""]]}, {"id": "1906.01727", "submitter": "Ramy Baly", "authors": "Tsvetomila Mihaylova (1), Georgi Karadjov (2), Pepa Atanasova (3),\n  Ramy Baly (4), Mitra Mohtarami (4), Preslav Nakov (5) ((1) Instituto de\n  Telecomunica\\c{c}\\~oes, Lisbon, Portugal, (2) SiteGround Hosting EOOD,\n  Bulgaria, (3) University of Copenhagen, Denmark, (4) MIT Computer Science and\n  Artificial Intelligence Laboratory, Cambridge, MA, (5) Qatar Computing\n  Research Institute, HBKU)", "title": "SemEval-2019 Task 8: Fact Checking in Community Question Answering\n  Forums", "comments": "Fact checking, community question answering, community fora,\n  semeval-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present SemEval-2019 Task 8 on Fact Checking in Community Question\nAnswering Forums, which features two subtasks. Subtask A is about deciding\nwhether a question asks for factual information vs. an opinion/advice vs. just\nsocializing. Subtask B asks to predict whether an answer to a factual question\nis true, false or not a proper answer. We received 17 official submissions for\nsubtask A and 11 official submissions for Subtask B. For subtask A, all systems\nimproved over the majority class baseline. For Subtask B, all systems were\nbelow a majority class baseline, but several systems were very close to it. The\nleaderboard and the data from the competition can be found at\nhttp://competitions.codalab.org/competitions/20022\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 16:46:49 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Mihaylova", "Tsvetomila", ""], ["Karadjov", "Georgi", ""], ["Atanasova", "Pepa", ""], ["Baly", "Ramy", ""], ["Mohtarami", "Mitra", ""], ["Nakov", "Preslav", ""]]}, {"id": "1906.01733", "submitter": "Dimitrios Alikaniotis", "authors": "Dimitrios Alikaniotis and Vipul Raheja", "title": "The Unreasonable Effectiveness of Transformer Language Models in\n  Grammatical Error Correction", "comments": "7 pages, 3 tables, accepted at the 14th Workshop on Innovative Use of\n  NLP for Building Educational Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Recent work on Grammatical Error Correction (GEC) has highlighted the\nimportance of language modeling in that it is certainly possible to achieve\ngood performance by comparing the probabilities of the proposed edits. At the\nsame time, advancements in language modeling have managed to generate\nlinguistic output, which is almost indistinguishable from that of\nhuman-generated text. In this paper, we up the ante by exploring the potential\nof more sophisticated language models in GEC and offer some key insights on\ntheir strengths and weaknesses. We show that, in line with recent results in\nother NLP tasks, Transformer architectures achieve consistently high\nperformance and provide a competitive baseline for future machine learning\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 21:28:31 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Alikaniotis", "Dimitrios", ""], ["Raheja", "Vipul", ""]]}, {"id": "1906.01738", "submitter": "Eshwar Chandrasekharan", "authors": "David Jurgens, Eshwar Chandrasekharan, Libby Hemphill", "title": "A Just and Comprehensive Strategy for Using NLP to Address Online Abuse", "comments": "9 pages; Accepted to be published at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online abusive behavior affects millions and the NLP community has attempted\nto mitigate this problem by developing technologies to detect abuse. However,\ncurrent methods have largely focused on a narrow definition of abuse to\ndetriment of victims who seek both validation and solutions. In this position\npaper, we argue that the community needs to make three substantive changes: (1)\nexpanding our scope of problems to tackle both more subtle and more serious\nforms of abuse, (2) developing proactive technologies that counter or inhibit\nabuse before it harms, and (3) reframing our effort within a framework of\njustice to promote healthy communities.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 21:54:08 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 17:12:52 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Jurgens", "David", ""], ["Chandrasekharan", "Eshwar", ""], ["Hemphill", "Libby", ""]]}, {"id": "1906.01749", "submitter": "Alexander Fabbri", "authors": "Alexander R. Fabbri, Irene Li, Tianwei She, Suyi Li, Dragomir R. Radev", "title": "Multi-News: a Large-Scale Multi-Document Summarization Dataset and\n  Abstractive Hierarchical Model", "comments": "ACL 2019, 57th Annual Meeting of the Association for Computational\n  Linguistics, Florence, Italy, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic generation of summaries from multiple news articles is a valuable\ntool as the number of online publications grows rapidly. Single document\nsummarization (SDS) systems have benefited from advances in neural\nencoder-decoder model thanks to the availability of large datasets. However,\nmulti-document summarization (MDS) of news articles has been limited to\ndatasets of a couple of hundred examples. In this paper, we introduce\nMulti-News, the first large-scale MDS news dataset. Additionally, we propose an\nend-to-end model which incorporates a traditional extractive summarization\nmodel with a standard SDS model and achieves competitive results on MDS\ndatasets. We benchmark several methods on Multi-News and release our data and\ncode in hope that this work will promote advances in summarization in the\nmulti-document setting.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 23:00:43 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 01:22:24 GMT"}, {"version": "v3", "created": "Wed, 19 Jun 2019 20:26:03 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Fabbri", "Alexander R.", ""], ["Li", "Irene", ""], ["She", "Tianwei", ""], ["Li", "Suyi", ""], ["Radev", "Dragomir R.", ""]]}, {"id": "1906.01753", "submitter": "Vered Shwartz", "authors": "Shany Barhom, Vered Shwartz, Alon Eirew, Michael Bugert, Nils Reimers,\n  Ido Dagan", "title": "Revisiting Joint Modeling of Cross-document Entity and Event Coreference\n  Resolution", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing coreferring events and entities across multiple texts is crucial\nfor many NLP applications. Despite the task's importance, research focus was\ngiven mostly to within-document entity coreference, with rather little\nattention to the other variants. We propose a neural architecture for\ncross-document coreference resolution. Inspired by Lee et al (2012), we jointly\nmodel entity and event coreference. We represent an event (entity) mention\nusing its lexical span, surrounding context, and relation to entity (event)\nmentions via predicate-arguments structures. Our model outperforms the previous\nstate-of-the-art event coreference model on ECB+, while providing the first\nentity coreference results on this corpus. Our analysis confirms that all our\nrepresentation elements, including the mention span itself, its context, and\nthe relation to other mentions contribute to the model's success.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 23:36:50 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Barhom", "Shany", ""], ["Shwartz", "Vered", ""], ["Eirew", "Alon", ""], ["Bugert", "Michael", ""], ["Reimers", "Nils", ""], ["Dagan", "Ido", ""]]}, {"id": "1906.01762", "submitter": "Anjalie Field", "authors": "Anjalie Field and Yulia Tsvetkov", "title": "Entity-Centric Contextual Affective Analysis", "comments": "Accepted as a full paper at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While contextualized word representations have improved state-of-the-art\nbenchmarks in many NLP tasks, their potential usefulness for social-oriented\ntasks remains largely unexplored. We show how contextualized word embeddings\ncan be used to capture affect dimensions in portrayals of people. We evaluate\nour methodology quantitatively, on held-out affect lexicons, and qualitatively,\nthrough case examples. We find that contextualized word representations do\nencode meaningful affect information, but they are heavily biased towards their\ntraining data, which limits their usefulness to in-domain analyses. We\nultimately use our method to examine differences in portrayals of men and\nwomen.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 00:23:50 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Field", "Anjalie", ""], ["Tsvetkov", "Yulia", ""]]}, {"id": "1906.01764", "submitter": "Ting-Yao Hsu", "authors": "Ting-Yao Hsu, Chieh-Yang Huang, Yen-Chia Hsu, Ting-Hao 'Kenneth' Huang", "title": "Visual Story Post-Editing", "comments": "Accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the first dataset for human edits of machine-generated visual\nstories and explore how these collected edits may be used for the visual story\npost-editing task. The dataset, VIST-Edit, includes 14,905 human edited\nversions of 2,981 machine-generated visual stories. The stories were generated\nby two state-of-the-art visual storytelling models, each aligned to 5\nhuman-edited versions. We establish baselines for the task, showing how a\nrelatively small set of human edits can be leveraged to boost the performance\nof large visual storytelling models. We also discuss the weak correlation\nbetween automatic evaluation scores and human ratings, motivating the need for\nnew automatic metrics.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 00:33:47 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Hsu", "Ting-Yao", ""], ["Huang", "Chieh-Yang", ""], ["Hsu", "Yen-Chia", ""], ["Huang", "Ting-Hao 'Kenneth'", ""]]}, {"id": "1906.01781", "submitter": "Fan Wang Mr.", "authors": "Chaotao Chen, Jinhua Peng, Fan Wang, Jun Xu and Hua Wu", "title": "Generating Multiple Diverse Responses with Multi-Mapping and Posterior\n  Mapping Selection", "comments": "Accepted in IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In human conversation an input post is open to multiple potential responses,\nwhich is typically regarded as a one-to-many problem. Promising approaches\nmainly incorporate multiple latent mechanisms to build the one-to-many\nrelationship. However, without accurate selection of the latent mechanism\ncorresponding to the target response during training, these methods suffer from\na rough optimization of latent mechanisms. In this paper, we propose a\nmulti-mapping mechanism to better capture the one-to-many relationship, where\nmultiple mapping modules are employed as latent mechanisms to model the\nsemantic mappings from an input post to its diverse responses. For accurate\noptimization of latent mechanisms, a posterior mapping selection module is\ndesigned to select the corresponding mapping module according to the target\nresponse for further optimization. We also introduce an auxiliary matching loss\nto facilitate the optimization of posterior mapping selection. Empirical\nresults demonstrate the superiority of our model in generating multiple diverse\nand informative responses over the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 01:56:50 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Chen", "Chaotao", ""], ["Peng", "Jinhua", ""], ["Wang", "Fan", ""], ["Xu", "Jun", ""], ["Wu", "Hua", ""]]}, {"id": "1906.01787", "submitter": "Qiang Wang", "authors": "Qiang Wang, Bei Li, Tong Xiao, Jingbo Zhu, Changliang Li, Derek F.\n  Wong, Lidia S. Chao", "title": "Learning Deep Transformer Models for Machine Translation", "comments": "Accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer is the state-of-the-art model in recent machine translation\nevaluations. Two strands of research are promising to improve models of this\nkind: the first uses wide networks (a.k.a. Transformer-Big) and has been the de\nfacto standard for the development of the Transformer system, and the other\nuses deeper language representation but faces the difficulty arising from\nlearning deep networks. Here, we continue the line of research on the latter.\nWe claim that a truly deep Transformer model can surpass the Transformer-Big\ncounterpart by 1) proper use of layer normalization and 2) a novel way of\npassing the combination of previous layers to the next. On WMT'16 English-\nGerman, NIST OpenMT'12 Chinese-English and larger WMT'18 Chinese-English tasks,\nour deep system (30/25-layer encoder) outperforms the shallow\nTransformer-Big/Base baseline (6-layer encoder) by 0.4-2.4 BLEU points. As\nanother bonus, the deep model is 1.6X smaller in size and 3X faster in training\nthan Transformer-Big.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 02:24:12 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Wang", "Qiang", ""], ["Li", "Bei", ""], ["Xiao", "Tong", ""], ["Zhu", "Jingbo", ""], ["Li", "Changliang", ""], ["Wong", "Derek F.", ""], ["Chao", "Lidia S.", ""]]}, {"id": "1906.01788", "submitter": "He Bai", "authors": "He Bai, Yu Zhou, Jiajun Zhang, Chengqing Zong", "title": "Memory Consolidation for Contextual Spoken Language Understanding with\n  Dialogue Logistic Inference", "comments": "ACL2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue contexts are proven helpful in the spoken language understanding\n(SLU) system and they are typically encoded with explicit memory\nrepresentations. However, most of the previous models learn the context memory\nwith only one objective to maximizing the SLU performance, leaving the context\nmemory under-exploited. In this paper, we propose a new dialogue logistic\ninference (DLI) task to consolidate the context memory jointly with SLU in the\nmulti-task framework. DLI is defined as sorting a shuffled dialogue session\ninto its original logical order and shares the same memory encoder and\nretrieval mechanism as the SLU model. Our experimental results show that\nvarious popular contextual SLU models can benefit from our approach, and\nimprovements are quite impressive, especially in slot filling.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 02:24:15 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Bai", "He", ""], ["Zhou", "Yu", ""], ["Zhang", "Jiajun", ""], ["Zong", "Chengqing", ""]]}, {"id": "1906.01794", "submitter": "Huaishao Luo", "authors": "Huaishao Luo, Tianrui Li, Bing Liu, Junbo Zhang", "title": "DOER: Dual Cross-Shared RNN for Aspect Term-Polarity Co-Extraction", "comments": "Accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on two related subtasks of aspect-based sentiment\nanalysis, namely aspect term extraction and aspect sentiment classification,\nwhich we call aspect term-polarity co-extraction. The former task is to extract\naspects of a product or service from an opinion document, and the latter is to\nidentify the polarity expressed in the document about these extracted aspects.\nMost existing algorithms address them as two separate tasks and solve them one\nby one, or only perform one task, which can be complicated for real\napplications. In this paper, we treat these two tasks as two sequence labeling\nproblems and propose a novel Dual crOss-sharEd RNN framework (DOER) to generate\nall aspect term-polarity pairs of the input sentence simultaneously.\nSpecifically, DOER involves a dual recurrent neural network to extract the\nrespective representation of each task, and a cross-shared unit to consider the\nrelationship between them. Experimental results demonstrate that the proposed\nframework outperforms state-of-the-art baselines on three benchmark datasets.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 02:45:06 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Luo", "Huaishao", ""], ["Li", "Tianrui", ""], ["Liu", "Bing", ""], ["Zhang", "Junbo", ""]]}, {"id": "1906.01815", "submitter": "Santiago Castro", "authors": "Santiago Castro, Devamanyu Hazarika, Ver\\'onica P\\'erez-Rosas, Roger\n  Zimmermann, Rada Mihalcea and Soujanya Poria", "title": "Towards Multimodal Sarcasm Detection (An _Obviously_ Perfect Paper)", "comments": "Accepted at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sarcasm is often expressed through several verbal and non-verbal cues, e.g.,\na change of tone, overemphasis in a word, a drawn-out syllable, or a straight\nlooking face. Most of the recent work in sarcasm detection has been carried out\non textual data. In this paper, we argue that incorporating multimodal cues can\nimprove the automatic classification of sarcasm. As a first step towards\nenabling the development of multimodal approaches for sarcasm detection, we\npropose a new sarcasm dataset, Multimodal Sarcasm Detection Dataset (MUStARD),\ncompiled from popular TV shows. MUStARD consists of audiovisual utterances\nannotated with sarcasm labels. Each utterance is accompanied by its context of\nhistorical utterances in the dialogue, which provides additional information on\nthe scenario where the utterance occurs. Our initial results show that the use\nof multimodal information can reduce the relative error rate of sarcasm\ndetection by up to 12.9% in F-score when compared to the use of individual\nmodalities. The full dataset is publicly available for use at\nhttps://github.com/soujanyaporia/MUStARD\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 04:08:47 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Castro", "Santiago", ""], ["Hazarika", "Devamanyu", ""], ["P\u00e9rez-Rosas", "Ver\u00f3nica", ""], ["Zimmermann", "Roger", ""], ["Mihalcea", "Rada", ""], ["Poria", "Soujanya", ""]]}, {"id": "1906.01830", "submitter": "Ramy Baly", "authors": "Ramy Baly (1), Alaa Khaddaj (2), Hazem Hajj (2), Wassim El-Hajj (3),\n  Khaled Bashir Shaban (4) ((1) MIT Computer Science and Artificial\n  Intelligence Laboratory, Cambridge, MA, USA, (2) American University of\n  Beirut, Electrical and Computer Engineering Department, Beirut, Lebanon, (3)\n  American University of Beirut, Computer Science Department, Beirut, Lebanon,\n  (4) Qatar University, Computer Science and Engineering Department, Doha,\n  Qatar)", "title": "ArSentD-LEV: A Multi-Topic Corpus for Target-based Sentiment Analysis in\n  Arabic Levantine Tweets", "comments": "Corpus development, Levantine tweets, multi-topic, sentiment\n  analysis, sentiment target, LREC-2018, OSACT-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment analysis is a highly subjective and challenging task. Its\ncomplexity further increases when applied to the Arabic language, mainly\nbecause of the large variety of dialects that are unstandardized and widely\nused in the Web, especially in social media. While many datasets have been\nreleased to train sentiment classifiers in Arabic, most of these datasets\ncontain shallow annotation, only marking the sentiment of the text unit, as a\nword, a sentence or a document. In this paper, we present the Arabic Sentiment\nTwitter Dataset for the Levantine dialect (ArSenTD-LEV). Based on findings from\nanalyzing tweets from the Levant region, we created a dataset of 4,000 tweets\nwith the following annotations: the overall sentiment of the tweet, the target\nto which the sentiment was expressed, how the sentiment was expressed, and the\ntopic of the tweet. Results confirm the importance of these annotations at\nimproving the performance of a baseline sentiment classifier. They also confirm\nthe gap of training in a certain domain, and testing in another domain.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 13:31:52 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Baly", "Ramy", ""], ["Khaddaj", "Alaa", ""], ["Hajj", "Hazem", ""], ["El-Hajj", "Wassim", ""], ["Shaban", "Khaled Bashir", ""]]}, {"id": "1906.01833", "submitter": "Chen Wu", "authors": "Chen Wu, Xuancheng Ren, Fuli Luo, Xu Sun", "title": "A Hierarchical Reinforced Sequence Operation Method for Unsupervised\n  Text Style Transfer", "comments": "Accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised text style transfer aims to alter text styles while preserving\nthe content, without aligned data for supervision. Existing seq2seq methods\nface three challenges: 1) the transfer is weakly interpretable, 2) generated\noutputs struggle in content preservation, and 3) the trade-off between content\nand style is intractable. To address these challenges, we propose a\nhierarchical reinforced sequence operation method, named Point-Then-Operate\n(PTO), which consists of a high-level agent that proposes operation positions\nand a low-level agent that alters the sentence. We provide comprehensive\ntraining objectives to control the fluency, style, and content of the outputs\nand a mask-based inference algorithm that allows for multi-step revision based\non the single-step trained agents. Experimental results on two text style\ntransfer datasets show that our method significantly outperforms recent methods\nand effectively addresses the aforementioned challenges.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 05:27:31 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Wu", "Chen", ""], ["Ren", "Xuancheng", ""], ["Luo", "Fuli", ""], ["Sun", "Xu", ""]]}, {"id": "1906.01834", "submitter": "Masashi Yoshikawa", "authors": "Masashi Yoshikawa, Hiroshi Noji, Koji Mineshima, Daisuke Bekki", "title": "Automatic Generation of High Quality CCGbanks for Parser Domain\n  Adaptation", "comments": "11 pages, accepted as long paper to ACL 2019 Italy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new domain adaptation method for Combinatory Categorial Grammar\n(CCG) parsing, based on the idea of automatic generation of CCG corpora\nexploiting cheaper resources of dependency trees. Our solution is conceptually\nsimple, and not relying on a specific parser architecture, making it applicable\nto the current best-performing parsers. We conduct extensive parsing\nexperiments with detailed discussion; on top of existing benchmark datasets on\n(1) biomedical texts and (2) question sentences, we create experimental\ndatasets of (3) speech conversation and (4) math problems. When applied to the\nproposed method, an off-the-shelf CCG parser shows significant performance\ngains, improving from 90.7% to 96.6% on speech conversation, and from 88.5% to\n96.8% on math problems.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 05:40:26 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Yoshikawa", "Masashi", ""], ["Noji", "Hiroshi", ""], ["Mineshima", "Koji", ""], ["Bekki", "Daisuke", ""]]}, {"id": "1906.01840", "submitter": "Liqun Chen", "authors": "Liqun Chen, Guoyin Wang, Chenyang Tao, Dinghan Shen, Pengyu Cheng,\n  Xinyuan Zhang, Wenlin Wang, Yizhe Zhang, Lawrence Carin", "title": "Improving Textual Network Embedding with Global Attention via Optimal\n  Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constituting highly informative network embeddings is an important tool for\nnetwork analysis. It encodes network topology, along with other useful side\ninformation, into low-dimensional node-based feature representations that can\nbe exploited by statistical modeling. This work focuses on learning\ncontext-aware network embeddings augmented with text data. We reformulate the\nnetwork-embedding problem, and present two novel strategies to improve over\ntraditional attention mechanisms: ($i$) a content-aware sparse attention module\nbased on optimal transport, and ($ii$) a high-level attention parsing module.\nOur approach yields naturally sparse and self-normalized relational inference.\nIt can capture long-term interactions between sequences, thus addressing the\nchallenges faced by existing textual network embedding schemes. Extensive\nexperiments are conducted to demonstrate our model can consistently outperform\nalternative state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 05:59:07 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Chen", "Liqun", ""], ["Wang", "Guoyin", ""], ["Tao", "Chenyang", ""], ["Shen", "Dinghan", ""], ["Cheng", "Pengyu", ""], ["Zhang", "Xinyuan", ""], ["Wang", "Wenlin", ""], ["Zhang", "Yizhe", ""], ["Carin", "Lawrence", ""]]}, {"id": "1906.01873", "submitter": "Luka Nenadovic", "authors": "Luka Nenadovi\\'c, Vladimir Prelovac", "title": "Towards conceptual generalization in the embedding space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are able to conceive physical reality by jointly learning different\nfacets thereof. To every pair of notions related to a perceived reality may\ncorrespond a mutual relation, which is a notion on its own, but one-level\nhigher. Thus, we may have a description of perceived reality on at least two\nlevels and the translation map between them is in general, due to their\ndifferent content corpus, one-to-many. Following success of the unsupervised\nneural machine translation models, which are essentially one-to-one mappings\ntrained separately on monolingual corpora, we examine further capabilities of\nthe unsupervised deep learning methods used there and apply some of these\nmethods to sets of notions of different level and measure. Using the graph and\nword embedding-like techniques, we build one-to-many map without parallel data\nin order to establish a unified vector representation of the outer world by\ncombining notions of different kind into a unique conceptual framework. Due to\ntheir latent similarity, by aligning the two embedding spaces in purely\nunsupervised way, one obtains a geometric relation between objects of cognition\non the two levels, making it possible to express a natural knowledge using one\ndescription in the context of the other.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 08:11:12 GMT"}, {"version": "v2", "created": "Thu, 15 Aug 2019 12:58:36 GMT"}, {"version": "v3", "created": "Fri, 16 Aug 2019 14:24:58 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Nenadovi\u0107", "Luka", ""], ["Prelovac", "Vladimir", ""]]}, {"id": "1906.01874", "submitter": "Hamid Mirisaee", "authors": "Hamid Mirisaee, Eric Gaussier, Cedric Lagnier, Agnes Guerraz", "title": "Terminology-based Text Embedding for Computing Document Similarities on\n  Technical Content", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose in this paper a new, hybrid document embedding approach in order\nto address the problem of document similarities with respect to the technical\ncontent. To do so, we employ a state-of-the-art graph techniques to first\nextract the keyphrases (composite keywords) of documents and, then, use them to\nscore the sentences. Using the ranked sentences, we propose two approaches to\nembed documents and show their performances with respect to two baselines. With\ndomain expert annotations, we illustrate that the proposed methods can find\nmore relevant documents and outperform the baselines up to 27% in terms of\nNDCG.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 08:16:42 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 08:19:47 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Mirisaee", "Hamid", ""], ["Gaussier", "Eric", ""], ["Lagnier", "Cedric", ""], ["Guerraz", "Agnes", ""]]}, {"id": "1906.01910", "submitter": "Kit Kuksenok", "authors": "Kit Kuksenok and Andriy Martyniv", "title": "Evaluation and Improvement of Chatbot Text Classification Data Quality\n  Using Plausible Negative Examples", "comments": "Included in the ACL2019 1st workshop on NLP for Conversational AI\n  (Florence, Italy). Code available: https://github.com/jobpal/nex-cv", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe and validate a metric for estimating multi-class classifier\nperformance based on cross-validation and adapted for improvement of small,\nunbalanced natural-language datasets used in chatbot design. Our experiences\ndraw upon building recruitment chatbots that mediate communication between\njob-seekers and recruiters by exposing the ML/NLP dataset to the recruiting\nteam. Evaluation approaches must be understandable to various stakeholders, and\nuseful for improving chatbot performance. The metric, nex-cv, uses negative\nexamples in the evaluation of text classification, and fulfils three\nrequirements. First, it is actionable: it can be used by non-developer staff.\nSecond, it is not overly optimistic compared to human ratings, making it a fast\nmethod for comparing classifiers. Third, it allows model-agnostic comparison,\nmaking it useful for comparing systems despite implementation differences. We\nvalidate the metric based on seven recruitment-domain datasets in English and\nGerman over the course of one year.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 09:52:22 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Kuksenok", "Kit", ""], ["Martyniv", "Andriy", ""]]}, {"id": "1906.01926", "submitter": "Yoshinari Fujinuma", "authors": "Yoshinari Fujinuma, Jordan Boyd-Graber, Michael J. Paul", "title": "A Resource-Free Evaluation Metric for Cross-Lingual Word Embeddings\n  Based on Graph Modularity", "comments": "Accepted to ACL 2019, camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual word embeddings encode the meaning of words from different\nlanguages into a shared low-dimensional space. An important requirement for\nmany downstream tasks is that word similarity should be independent of language\n- i.e., word vectors within one language should not be more similar to each\nother than to words in another language. We measure this characteristic using\nmodularity, a network measurement that measures the strength of clusters in a\ngraph. Modularity has a moderate to strong correlation with three downstream\ntasks, even though modularity is based only on the structure of embeddings and\ndoes not require any external resources. We show through experiments that\nmodularity can serve as an intrinsic validation metric to improve unsupervised\ncross-lingual word embeddings, particularly on distant language pairs in\nlow-resource settings.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 10:34:56 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Fujinuma", "Yoshinari", ""], ["Boyd-Graber", "Jordan", ""], ["Paul", "Michael J.", ""]]}, {"id": "1906.01942", "submitter": "Yunsu Kim", "authors": "Yunsu Kim, Hendrik Rosendahl, Nick Rossenbach, Jan Rosendahl, Shahram\n  Khadivi, Hermann Ney", "title": "Learning Bilingual Sentence Embeddings via Autoencoding and Computing\n  Similarities with a Multilayer Perceptron", "comments": "ACL 2019 Repl4NLP camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel model architecture and training algorithm to learn\nbilingual sentence embeddings from a combination of parallel and monolingual\ndata. Our method connects autoencoding and neural machine translation to force\nthe source and target sentence embeddings to share the same space without the\nhelp of a pivot language or an additional transformation. We train a multilayer\nperceptron on top of the sentence embeddings to extract good bilingual sentence\npairs from nonparallel or noisy parallel data. Our approach shows promising\nperformance on sentence alignment recovery and the WMT 2018 parallel corpus\nfiltering tasks with only a single model.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 11:16:33 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Kim", "Yunsu", ""], ["Rosendahl", "Hendrik", ""], ["Rossenbach", "Nick", ""], ["Rosendahl", "Jan", ""], ["Khadivi", "Shahram", ""], ["Ney", "Hermann", ""]]}, {"id": "1906.01946", "submitter": "Joseph Bullock", "authors": "Joseph Bullock, Miguel Luengo-Oroz", "title": "Automated Speech Generation from UN General Assembly Statements: Mapping\n  Risks in AI Generated Texts", "comments": "5 pages", "journal-ref": "International Conference on Machine Learning AI for Social Good\n  Workshop, Long Beach, United States, 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated text generation has been applied broadly in many domains such as\nmarketing and robotics, and used to create chatbots, product reviews and write\npoetry. The ability to synthesize text, however, presents many potential risks,\nwhile access to the technology required to build generative models is becoming\nincreasingly easy. This work is aligned with the efforts of the United Nations\nand other civil society organisations to highlight potential political and\nsocietal risks arising through the malicious use of text generation software,\nand their potential impact on human rights. As a case study, we present the\nfindings of an experiment to generate remarks in the style of political leaders\nby fine-tuning a pretrained AWD- LSTM model on a dataset of speeches made at\nthe UN General Assembly. This work highlights the ease with which this can be\naccomplished, as well as the threats of combining these techniques with other\ntechnologies.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 11:23:14 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Bullock", "Joseph", ""], ["Luengo-Oroz", "Miguel", ""]]}, {"id": "1906.01958", "submitter": "David Mare\\v{c}ek", "authors": "David Mare\\v{c}ek and Rudolf Rosa", "title": "From Balustrades to Pierre Vinken: Looking for Syntax in Transformer\n  Self-Attentions", "comments": "Accepted at BlackboxNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We inspect the multi-head self-attention in Transformer NMT encoders for\nthree source languages, looking for patterns that could have a syntactic\ninterpretation. In many of the attention heads, we frequently find sequences of\nconsecutive states attending to the same position, which resemble syntactic\nphrases. We propose a transparent deterministic method of quantifying the\namount of syntactic information present in the self-attentions, based on\nautomatically building and evaluating phrase-structure trees from the\nphrase-like sequences. We compare the resulting trees to existing constituency\ntreebanks, both manually and by computing precision and recall.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 11:53:38 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Mare\u010dek", "David", ""], ["Rosa", "Rudolf", ""]]}, {"id": "1906.01965", "submitter": "Yaoming Zhu", "authors": "Yaoming Zhu, Juncheng Wan, Zhiming Zhou, Liheng Chen, Lin Qiu, Weinan\n  Zhang, Xin Jiang, Yong Yu", "title": "Triple-to-Text: Converting RDF Triples into High-Quality Natural\n  Languages via Optimizing an Inverse KL Divergence", "comments": null, "journal-ref": null, "doi": "10.1145/3331184.3331232", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge base is one of the main forms to represent information in a\nstructured way. A knowledge base typically consists of Resource Description\nFrameworks (RDF) triples which describe the entities and their relations.\nGenerating natural language description of the knowledge base is an important\ntask in NLP, which has been formulated as a conditional language generation\ntask and tackled using the sequence-to-sequence framework. Current works mostly\ntrain the language models by maximum likelihood estimation, which tends to\ngenerate lousy sentences. In this paper, we argue that such a problem of\nmaximum likelihood estimation is intrinsic, which is generally irrevocable via\nchanging network structures. Accordingly, we propose a novel Triple-to-Text\n(T2T) framework, which approximately optimizes the inverse Kullback-Leibler\n(KL) divergence between the distributions of the real and generated sentences.\nDue to the nature that inverse KL imposes large penalty on fake-looking\nsamples, the proposed method can significantly reduce the probability of\ngenerating low-quality sentences. Our experiments on three real-world datasets\ndemonstrate that T2T can generate higher-quality sentences and outperform\nbaseline models in several evaluation metrics.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 03:05:15 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Zhu", "Yaoming", ""], ["Wan", "Juncheng", ""], ["Zhou", "Zhiming", ""], ["Chen", "Liheng", ""], ["Qiu", "Lin", ""], ["Zhang", "Weinan", ""], ["Jiang", "Xin", ""], ["Yu", "Yong", ""]]}, {"id": "1906.01973", "submitter": "Sanjeev Kumar Karn", "authors": "Sanjeev Kumar Karn, Francine Chen, Yan-Ying Chen, Ulli Waltinger and\n  Hinrich Sch\\\"utze", "title": "A Hierarchical Decoder with Three-level Hierarchical Attention to\n  Generate Abstractive Summaries of Interleaved Texts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interleaved texts, where posts belonging to different threads occur in one\nsequence, are a common occurrence, e.g., online chat conversations. To quickly\nobtain an overview of such texts, existing systems first disentangle the posts\nby threads and then extract summaries from those threads. The major issues with\nsuch systems are error propagation and non-fluent summary. To address those, we\npropose an end-to-end trainable hierarchical encoder-decoder system. We also\nintroduce a novel hierarchical attention mechanism which combines three levels\nof information from an interleaved text, i.e, posts, phrases and words, and\nimplicitly disentangles the threads. We evaluated the proposed system on\nmultiple interleaved text datasets, and it out-performs a SOTA two-step system\nby 20-40%.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 12:28:00 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 16:26:52 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Karn", "Sanjeev Kumar", ""], ["Chen", "Francine", ""], ["Chen", "Yan-Ying", ""], ["Waltinger", "Ulli", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1906.01983", "submitter": "Mark Ho", "authors": "Mark K. Ho and Joanna Korman and Thomas L. Griffiths", "title": "The Computational Structure of Unintentional Meaning", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.MA stat.AP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Speech-acts can have literal meaning as well as pragmatic meaning, but these\nboth involve consequences typically intended by a speaker. Speech-acts can also\nhave unintentional meaning, in which what is conveyed goes above and beyond\nwhat was intended. Here, we present a Bayesian analysis of how, to a listener,\nthe meaning of an utterance can significantly differ from a speaker's intended\nmeaning. Our model emphasizes how comprehending the intentional and\nunintentional meaning of speech-acts requires listeners to engage in\nsophisticated model-based perspective-taking and reasoning about the history of\nthe state of the world, each other's actions, and each other's observations. To\ntest our model, we have human participants make judgments about vignettes where\nspeakers make utterances that could be interpreted as intentional insults or\nunintentional faux pas. In elucidating the mechanics of speech-acts with\nunintentional meanings, our account provides insight into how communication\nboth functions and malfunctions.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 17:26:36 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Ho", "Mark K.", ""], ["Korman", "Joanna", ""], ["Griffiths", "Thomas L.", ""]]}, {"id": "1906.02002", "submitter": "Rami Aly", "authors": "Rami Aly, Shantanu Acharya, Alexander Ossa, Arne K\\\"ohn, Chris\n  Biemann, and Alexander Panchenko", "title": "Every child should have parents: a taxonomy refinement algorithm based\n  on hyperbolic term embeddings", "comments": "7 pages (5 + 2 pages references), 2 Figures, 3 Tables, Accepted to\n  the ACL 2019 conference. Will appear in its proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the use of Poincar\\'e embeddings to improve existing\nstate-of-the-art approaches to domain-specific taxonomy induction from text as\na signal for both relocating wrong hyponym terms within a (pre-induced)\ntaxonomy as well as for attaching disconnected terms in a taxonomy. This method\nsubstantially improves previous state-of-the-art results on the SemEval-2016\nTask 13 on taxonomy extraction. We demonstrate the superiority of Poincar\\'e\nembeddings over distributional semantic representations, supporting the\nhypothesis that they can better capture hierarchical lexical-semantic\nrelationships than embeddings in the Euclidean space.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 12:54:14 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Aly", "Rami", ""], ["Acharya", "Shantanu", ""], ["Ossa", "Alexander", ""], ["K\u00f6hn", "Arne", ""], ["Biemann", "Chris", ""], ["Panchenko", "Alexander", ""]]}, {"id": "1906.02041", "submitter": "Bingzhen Wei", "authors": "Bingzhen Wei, Mingxuan Wang, Hao Zhou, Junyang Lin, Jun Xie, Xu Sun", "title": "Imitation Learning for Non-Autoregressive Neural Machine Translation", "comments": "Accepted by ACL 2019. arXiv admin note: text overlap with\n  arXiv:1902.10245, arXiv:1812.09664 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-autoregressive translation models (NAT) have achieved impressive\ninference speedup. A potential issue of the existing NAT algorithms, however,\nis that the decoding is conducted in parallel, without directly considering\nprevious context. In this paper, we propose an imitation learning framework for\nnon-autoregressive machine translation, which still enjoys the fast translation\nspeed but gives comparable translation performance compared to its\nauto-regressive counterpart. We conduct experiments on the IWSLT16, WMT14 and\nWMT16 datasets. Our proposed model achieves a significant speedup over the\nautoregressive models, while keeping the translation quality comparable to the\nautoregressive models. By sampling sentence length in parallel at inference\ntime, we achieve the performance of 31.85 BLEU on WMT16 Ro$\\rightarrow$En and\n30.68 BLEU on IWSLT16 En$\\rightarrow$De.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 14:15:47 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 10:43:33 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Wei", "Bingzhen", ""], ["Wang", "Mingxuan", ""], ["Zhou", "Hao", ""], ["Lin", "Junyang", ""], ["Xie", "Jun", ""], ["Sun", "Xu", ""]]}, {"id": "1906.02045", "submitter": "Nikola Ljube\\v{s}i\\'c", "authors": "Nikola Ljube\\v{s}i\\'c, Darja Fi\\v{s}er, Toma\\v{z} Erjavec", "title": "The FRENK Datasets of Socially Unacceptable Discourse in Slovene and\n  English", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present datasets of Facebook comment threads to mainstream\nmedia posts in Slovene and English developed inside the Slovene national\nproject FRENK which cover two topics, migrants and LGBT, and are manually\nannotated for different types of socially unacceptable discourse (SUD). The\nmain advantages of these datasets compared to the existing ones are identical\nsampling procedures, producing comparable data across languages and an\nannotation schema that takes into account six types of SUD and five targets at\nwhich SUD is directed. We describe the sampling and annotation procedures, and\nanalyze the annotation distributions and inter-annotator agreements. We\nconsider this dataset to be an important milestone in understanding and\ncombating SUD for both languages.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 14:23:01 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 10:43:59 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Ljube\u0161i\u0107", "Nikola", ""], ["Fi\u0161er", "Darja", ""], ["Erjavec", "Toma\u017e", ""]]}, {"id": "1906.02053", "submitter": "Nikola Ljube\\v{s}i\\'c", "authors": "Nikola Ljube\\v{s}i\\'c, Darja Fi\\v{s}er, Toma\\v{z} Erjavec", "title": "KAS-term: Extracting Slovene Terms from Doctoral Theses via Supervised\n  Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a dataset and supervised learning experiments for term\nextraction from Slovene academic texts. Term candidates in the dataset were\nextracted via morphosyntactic patterns and annotated for their termness by four\nannotators. Experiments on the dataset show that most co-occurrence statistics,\napplied after morphosyntactic patterns and a frequency threshold, perform close\nto random and that the results can be significantly improved by combining, with\nsupervised machine learning, all the seven statistic measures included in the\ndataset. On multi-word terms the model using all statistics obtains an AUC of\n0.736 while the best single statistic produces only AUC 0.590. Among many\nadditional candidate features, only adding multi-word morphosyntactic pattern\ninformation and length of the single-word term candidates achieves further\nimprovements of the results.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 14:36:59 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Ljube\u0161i\u0107", "Nikola", ""], ["Fi\u0161er", "Darja", ""], ["Erjavec", "Toma\u017e", ""]]}, {"id": "1906.02057", "submitter": "Luca Maria Aiello", "authors": "Alexander Robertson, Luca Maria Aiello, Daniele Quercia", "title": "The Language of Dialogue Is Complex", "comments": "12 pages, 9 figures, 10 tables", "journal-ref": "In proceedings of the 13th International Conference on Web and\n  Social Media (ICWSM). Munich, 2019", "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integrative Complexity (IC) is a psychometric that measures the ability of a\nperson to recognize multiple perspectives and connect them, thus identifying\npaths for conflict resolution. IC has been linked to a wide variety of\npolitical, social and personal outcomes but evaluating it is a time-consuming\nprocess requiring skilled professionals to manually score texts, a fact which\naccounts for the limited exploration of IC at scale on social media.We combine\nnatural language processing and machine learning to train an IC classification\nmodel that achieves state-of-the-art performance on unseen data and more\nclosely adheres to the established structure of the IC coding process than\nprevious automated approaches. When applied to the content of 400k+ comments\nfrom online fora about depression and knowledge exchange, our model was capable\nof replicating key findings of prior work, thus providing the first example of\nusing IC tools for large-scale social media analytics.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 14:51:31 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Robertson", "Alexander", ""], ["Aiello", "Luca Maria", ""], ["Quercia", "Daniele", ""]]}, {"id": "1906.02059", "submitter": "Ilias Chalkidis", "authors": "Ilias Chalkidis, Ion Androutsopoulos, Nikolaos Aletras", "title": "Neural Legal Judgment Prediction in English", "comments": "7 pages, short paper at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Legal judgment prediction is the task of automatically predicting the outcome\nof a court case, given a text describing the case's facts. Previous work on\nusing neural models for this task has focused on Chinese; only feature-based\nmodels (e.g., using bags of words and topics) have been considered in English.\nWe release a new English legal judgment prediction dataset, containing cases\nfrom the European Court of Human Rights. We evaluate a broad variety of neural\nmodels on the new dataset, establishing strong baselines that surpass previous\nfeature-based models in three tasks: (1) binary violation classification; (2)\nmulti-label classification; (3) case importance prediction. We also explore if\nmodels are biased towards demographic information via data anonymization. As a\nside-product, we propose a hierarchical version of BERT, which bypasses BERT's\nlength limitation.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 14:56:06 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Chalkidis", "Ilias", ""], ["Androutsopoulos", "Ion", ""], ["Aletras", "Nikolaos", ""]]}, {"id": "1906.02079", "submitter": "Zhongyang Li", "authors": "Zhongyang Li, Tongfei Chen and Benjamin Van Durme", "title": "Learning to Rank for Plausible Plausibility", "comments": "To appear in ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers illustrate improvements in contextual encoding strategies via\nresultant performance on a battery of shared Natural Language Understanding\n(NLU) tasks. Many of these tasks are of a categorical prediction variety: given\na conditioning context (e.g., an NLI premise), provide a label based on an\nassociated prompt (e.g., an NLI hypothesis). The categorical nature of these\ntasks has led to common use of a cross entropy log-loss objective during\ntraining. We suggest this loss is intuitively wrong when applied to\nplausibility tasks, where the prompt by design is neither categorically\nentailed nor contradictory given the context. Log-loss naturally drives models\nto assign scores near 0.0 or 1.0, in contrast to our proposed use of a\nmargin-based loss. Following a discussion of our intuition, we describe a\nconfirmation study based on an extreme, synthetically curated task derived from\nMultiNLI. We find that a margin-based loss leads to a more plausible model of\nplausibility. Finally, we illustrate improvements on the Choice Of Plausible\nAlternative (COPA) task through this change in loss.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 15:41:22 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Li", "Zhongyang", ""], ["Chen", "Tongfei", ""], ["Van Durme", "Benjamin", ""]]}, {"id": "1906.02121", "submitter": "Jo\\~ao Paulo Aires", "authors": "Jo\\~ao Paulo Aires, Roger Granada, Juarez Monteiro, Rodrigo C. Barros,\n  Felipe Meneguzzi", "title": "Classifying Norm Conflicts using Learned Semantic Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While most social norms are informal, they are often formalized by companies\nin contracts to regulate trades of goods and services. When poorly written,\ncontracts may contain normative conflicts resulting from opposing deontic\nmeanings or contradict specifications. As contracts tend to be long and contain\nmany norms, manually identifying such conflicts requires human-effort, which is\ntime-consuming and error-prone. Automating such task benefits contract makers\nincreasing productivity and making conflict identification more reliable. To\naddress this problem, we introduce an approach to detect and classify norm\nconflicts in contracts by converting them into latent representations that\npreserve both syntactic and semantic information and training a model to\nclassify norm conflicts in four conflict types. Our results reach the new state\nof the art when compared to a previous approach.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 19:43:54 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Aires", "Jo\u00e3o Paulo", ""], ["Granada", "Roger", ""], ["Monteiro", "Juarez", ""], ["Barros", "Rodrigo C.", ""], ["Meneguzzi", "Felipe", ""]]}, {"id": "1906.02123", "submitter": "Hongming Zhang", "authors": "Hongming Zhang, Hantian Ding, Yangqiu Song", "title": "SP-10K: A Large-scale Evaluation Set for Selectional Preference\n  Acquisition", "comments": "Accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selectional Preference (SP) is a commonly observed language phenomenon and\nproved to be useful in many natural language processing tasks. To provide a\nbetter evaluation method for SP models, we introduce SP-10K, a large-scale\nevaluation set that provides human ratings for the plausibility of 10,000 SP\npairs over five SP relations, covering 2,500 most frequent verbs, nouns, and\nadjectives in American English. Three representative SP acquisition methods\nbased on pseudo-disambiguation are evaluated with SP-10K. To demonstrate the\nimportance of our dataset, we investigate the relationship between SP-10K and\nthe commonsense knowledge in ConceptNet5 and show the potential of using SP to\nrepresent the commonsense knowledge. We also use the Winograd Schema Challenge\nto prove that the proposed new SP relations are essential for the hard pronoun\ncoreference resolution problem.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 08:32:39 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Zhang", "Hongming", ""], ["Ding", "Hantian", ""], ["Song", "Yangqiu", ""]]}, {"id": "1906.02124", "submitter": "Jieh-Sheng Lee", "authors": "Jieh-Sheng Lee and Jieh Hsiang", "title": "PatentBERT: Patent Classification with Fine-Tuning a pre-trained BERT\n  Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we focus on fine-tuning a pre-trained BERT model and applying it\nto patent classification. When applied to large datasets of over two millions\npatents, our approach outperforms the state of the art by an approach using CNN\nwith word embeddings. In addition, we focus on patent claims without other\nparts in patent documents. Our contributions include: (1) a new\nstate-of-the-art method based on pre-trained BERT model and fine-tuning for\npatent classification, (2) a large dataset USPTO-3M at the CPC subclass level\nwith SQL statements that can be used by future researchers, (3) showing that\npatent claims alone are sufficient for classification task, in contrast to\nconventional wisdom.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 10:33:08 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 01:48:38 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Lee", "Jieh-Sheng", ""], ["Hsiang", "Jieh", ""]]}, {"id": "1906.02125", "submitter": "Paul Pu Liang", "authors": "Paul Pu Liang, Yao Chong Lim, Yao-Hung Hubert Tsai, Ruslan\n  Salakhutdinov, Louis-Philippe Morency", "title": "Strong and Simple Baselines for Multimodal Utterance Embeddings", "comments": "NAACL 2019 oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human language is a rich multimodal signal consisting of spoken words, facial\nexpressions, body gestures, and vocal intonations. Learning representations for\nthese spoken utterances is a complex research problem due to the presence of\nmultiple heterogeneous sources of information. Recent advances in multimodal\nlearning have followed the general trend of building more complex models that\nutilize various attention, memory and recurrent components. In this paper, we\npropose two simple but strong baselines to learn embeddings of multimodal\nutterances. The first baseline assumes a conditional factorization of the\nutterance into unimodal factors. Each unimodal factor is modeled using the\nsimple form of a likelihood function obtained via a linear transformation of\nthe embedding. We show that the optimal embedding can be derived in closed form\nby taking a weighted average of the unimodal features. In order to capture\nricher representations, our second baseline extends the first by factorizing\ninto unimodal, bimodal, and trimodal factors, while retaining simplicity and\nefficiency during learning and inference. From a set of experiments across two\ntasks, we show strong performance on both supervised and semi-supervised\nmultimodal prediction, as well as significant (10 times) speedups over neural\nmodels during inference. Overall, we believe that our strong baseline models\noffer new benchmarking options for future research in multimodal learning.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 13:44:37 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 07:01:32 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Liang", "Paul Pu", ""], ["Lim", "Yao Chong", ""], ["Tsai", "Yao-Hung Hubert", ""], ["Salakhutdinov", "Ruslan", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "1906.02126", "submitter": "Ryohto Sawada", "authors": "Ryohto Sawada", "title": "Extractive Summarization via Weighted Dissimilarity and Importance\n  Aligned Key Iterative Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present importance aligned key iterative algorithm for extractive\nsummarization that is faster than conventional algorithms keeping its accuracy.\nThe computational complexity of our algorithm is O($SNlogN$) to summarize\noriginal $N$ sentences into final $S$ sentences. Our algorithm maximizes the\nweighted dissimilarity defined by the product of importance and cosine\ndissimilarity so that the summary represents the document and at the same time\nthe sentences of the summary are not similar to each other. The weighted\ndissimilarity is heuristically maximized by iterative greedy search and binary\nsearch to the sentences ordered by importance. We finally show a benchmark\nscore based on summarization of customer reviews of products, which highlights\nthe quality of our algorithm comparable to human and existing algorithms. We\nprovide the source code of our algorithm on github\nhttps://github.com/qhapaq-49/imakita .\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 12:42:42 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Sawada", "Ryohto", ""]]}, {"id": "1906.02127", "submitter": "Chen Qian", "authors": "Chen Qian, Lijie Wen, Akhil Kumar, Leilei Lin, Li Lin, Zan Zong,\n  Shuang Li, Jianmin Wang", "title": "An Approach for Process Model Extraction By Multi-Grained Text\n  Classification", "comments": "Accepted to CAiSE-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Process model extraction (PME) is a recently emerged interdiscipline between\nnatural language processing (NLP) and business process management (BPM), which\naims to extract process models from textual descriptions. Previous process\nextractors heavily depend on manual features and ignore the potential relations\nbetween clues of different text granularities. In this paper, we formalize the\nPME task into the multi-grained text classification problem, and propose a\nhierarchical neural network to effectively model and extract multi-grained\ninformation without manually-defined procedural features. Under this structure,\nwe accordingly propose the coarse-to-fine (grained) learning mechanism,\ntraining multi-grained tasks in coarse-to-fine grained order to share the\nhigh-level knowledge for the low-level tasks. To evaluate our approach, we\nconstruct two multi-grained datasets from two different domains and conduct\nextensive experiments from different dimensions. The experimental results\ndemonstrate that our approach outperforms the state-of-the-art methods with\nstatistical significance and further investigations demonstrate its\neffectiveness.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 16:04:49 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 13:06:30 GMT"}, {"version": "v3", "created": "Fri, 20 Mar 2020 00:39:22 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Qian", "Chen", ""], ["Wen", "Lijie", ""], ["Kumar", "Akhil", ""], ["Lin", "Leilei", ""], ["Lin", "Li", ""], ["Zong", "Zan", ""], ["Li", "Shuang", ""], ["Wang", "Jianmin", ""]]}, {"id": "1906.02128", "submitter": "Jingxuan Yang", "authors": "Jingxuan Yang, Jianzhuo Tong, Si Li, Sheng Gao, Jun Guo, Nianwen Xue", "title": "Recovering Dropped Pronouns in Chinese Conversations via Modeling Their\n  Referents", "comments": "accepted by NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pronouns are often dropped in Chinese sentences, and this happens more\nfrequently in conversational genres as their referents can be easily understood\nfrom context. Recovering dropped pronouns is essential to applications such as\nInformation Extraction where the referents of these dropped pronouns need to be\nresolved, or Machine Translation when Chinese is the source language. In this\nwork, we present a novel end-to-end neural network model to recover dropped\npronouns in conversational data. Our model is based on a structured attention\nmechanism that models the referents of dropped pronouns utilizing both\nsentence-level and word-level information. Results on three different\nconversational genres show that our approach achieves a significant improvement\nover the current state of the art.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 05:13:22 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Yang", "Jingxuan", ""], ["Tong", "Jianzhuo", ""], ["Li", "Si", ""], ["Gao", "Sheng", ""], ["Guo", "Jun", ""], ["Xue", "Nianwen", ""]]}, {"id": "1906.02132", "submitter": "Tunazzina Islam", "authors": "Tunazzina Islam", "title": "Ex-Twit: Explainable Twitter Mining on Health Data", "comments": "In SocialNLP 2019 @ IJCAI-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since most machine learning models provide no explanations for the\npredictions, their predictions are obscure for the human. The ability to\nexplain a model's prediction has become a necessity in many applications\nincluding Twitter mining. In this work, we propose a method called Explainable\nTwitter Mining (Ex-Twit) combining Topic Modeling and Local Interpretable\nModel-agnostic Explanation (LIME) to predict the topic and explain the model\npredictions. We demonstrate the effectiveness of Ex-Twit on Twitter\nhealth-related data.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 15:26:18 GMT"}, {"version": "v2", "created": "Sat, 22 Jun 2019 21:42:59 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Islam", "Tunazzina", ""]]}, {"id": "1906.02134", "submitter": "Jie Wang", "authors": "Jie Wang, Xinyan Zhao", "title": "Theme-aware generation model for chinese lyrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With rapid development of neural networks, deep-learning has been extended to\nvarious natural language generation fields, such as machine translation,\ndialogue generation and even literature creation. In this paper, we propose a\ntheme-aware language generation model for Chinese music lyrics, which improves\nthe theme-connectivity and coherence of generated paragraphs greatly. A\nmulti-channel sequence-to-sequence (seq2seq) model encodes themes and previous\nsentences as global and local contextual information. Moreover, attention\nmechanism is incorporated for sequence decoding, enabling to fuse context into\npredicted next texts. To prepare appropriate train corpus, LDA (Latent\nDirichlet Allocation) is applied for theme extraction. Generated lyrics is\ngrammatically correct and semantically coherent with selected themes, which\noffers a valuable modelling method in other fields including multi-turn\nchatbots, long paragraph generation and etc.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 08:50:15 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Wang", "Jie", ""], ["Zhao", "Xinyan", ""]]}, {"id": "1906.02135", "submitter": "Jie Wang", "authors": "Jie Wang, Yilin Yang", "title": "Deep learning based mood tagging for Chinese song lyrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, listening music has been and will always be an indispensable part\nof our daily life. In recent years, sentiment analysis of music has been widely\nused in the information retrieval systems, personalized recommendation systems\nand so on. Due to the development of deep learning, this paper commits to find\nan effective approach for mood tagging of Chinese song lyrics. To achieve this\ngoal, both machine-learning and deep-learning models have been studied and\ncompared. Eventually, a CNN-based model with pre-trained word embedding has\nbeen demonstrated to effectively extract the distribution of emotional features\nof Chinese lyrics, with at least 15 percentage points higher than traditional\nmachine-learning methods (i.e. TF-IDF+SVM and LIWC+SVM), and 7 percentage\npoints higher than other deep-learning models (i.e. RNN, LSTM). In this paper,\nmore than 160,000 lyrics corpus has been leveraged for pre-training word\nembedding for mood tagging boost.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 09:12:59 GMT"}, {"version": "v2", "created": "Sat, 15 Jun 2019 09:45:07 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Wang", "Jie", ""], ["Yang", "Yilin", ""]]}, {"id": "1906.02136", "submitter": "Mohamed Khemakhem", "authors": "Laurent Romary (ALMAnaCH), Mohamed Khemakhem (ALMAnaCH, UPD7, CMB),\n  Fahad Khan (CNR-ILC), Jack Bowers (ALMAnaCH), Nicoletta Calzolari (CNR-ILC),\n  Monte George (ANSI), Mandy Pet (ANSI), Piotr Ba\\'nski (IDS)", "title": "LMF Reloaded", "comments": "AsiaLex 2019: Past, Present and Future, Jun 2019, Istanbul, Turkey", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lexical Markup Framework (LMF) or ISO 24613 [1] is a de jure standard that\nprovides a framework for modelling and encoding lexical information in\nretrodigitised print dictionaries and NLP lexical databases. An in-depth review\nis currently underway within the standardisation subcommittee ,\nISO-TC37/SC4/WG4, to find a more modular, flexible and durable follow up to the\noriginal LMF standard published in 2008. In this paper we will present some of\nthe major improvements which have so far been implemented in the new version of\nLMF.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 14:48:39 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Romary", "Laurent", "", "ALMAnaCH"], ["Khemakhem", "Mohamed", "", "ALMAnaCH, UPD7, CMB"], ["Khan", "Fahad", "", "CNR-ILC"], ["Bowers", "Jack", "", "ALMAnaCH"], ["Calzolari", "Nicoletta", "", "CNR-ILC"], ["George", "Monte", "", "ANSI"], ["Pet", "Mandy", "", "ANSI"], ["Ba\u0144ski", "Piotr", "", "IDS"]]}, {"id": "1906.02181", "submitter": "Xinyuan Zhang", "authors": "Xinyuan Zhang, Yi Yang, Siyang Yuan, Dinghan Shen, Lawrence Carin", "title": "Syntax-Infused Variational Autoencoder for Text Generation", "comments": "Accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a syntax-infused variational autoencoder (SIVAE), that integrates\nsentences with their syntactic trees to improve the grammar of generated\nsentences. Distinct from existing VAE-based text generative models, SIVAE\ncontains two separate latent spaces, for sentences and syntactic trees. The\nevidence lower bound objective is redesigned correspondingly, by optimizing a\njoint distribution that accommodates two encoders and two decoders. SIVAE works\nwith long short-term memory architectures to simultaneously generate sentences\nand syntactic trees. Two versions of SIVAE are proposed: one captures the\ndependencies between the latent variables through a conditional prior network,\nand the other treats the latent variables independently such that\nsyntactically-controlled sentence generation can be performed. Experimental\nresults demonstrate the generative superiority of SIVAE on both reconstruction\nand targeted syntactic evaluations. Finally, we show that the proposed models\ncan be used for unsupervised paraphrasing given different syntactic tree\ntemplates.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 22:48:08 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Zhang", "Xinyuan", ""], ["Yang", "Yi", ""], ["Yuan", "Siyang", ""], ["Shen", "Dinghan", ""], ["Carin", "Lawrence", ""]]}, {"id": "1906.02192", "submitter": "Ilias Chalkidis", "authors": "Ilias Chalkidis, Manos Fergadiotis, Prodromos Malakasiotis, Ion\n  Androutsopoulos", "title": "Large-Scale Multi-Label Text Classification on EU Legislation", "comments": "9 pages, short paper at ACL 2019. arXiv admin note: text overlap with\n  arXiv:1905.10892", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Large-Scale Multi-Label Text Classification (LMTC) in the legal\ndomain. We release a new dataset of 57k legislative documents from EURLEX,\nannotated with ~4.3k EUROVOC labels, which is suitable for LMTC, few- and\nzero-shot learning. Experimenting with several neural classifiers, we show that\nBIGRUs with label-wise attention perform better than other current state of the\nart methods. Domain-specific WORD2VEC and context-sensitive ELMO embeddings\nfurther improve performance. We also find that considering only particular\nzones of the documents is sufficient. This allows us to bypass BERT's maximum\ntext length limit and fine-tune BERT, obtaining the best results in all but\nzero-shot learning cases.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 14:41:01 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Chalkidis", "Ilias", ""], ["Fergadiotis", "Manos", ""], ["Malakasiotis", "Prodromos", ""], ["Androutsopoulos", "Ion", ""]]}, {"id": "1906.02239", "submitter": "Izhak Shafran", "authors": "Nan Du, Kai Chen, Anjuli Kannan, Linh Tran, Yuhui Chen, Izhak Shafran", "title": "Extracting Symptoms and their Status from Clinical Conversations", "comments": null, "journal-ref": "Proceedings of the Annual Meeting of the Association of\n  Computational Linguistics, 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes novel models tailored for a new application, that of\nextracting the symptoms mentioned in clinical conversations along with their\nstatus. Lack of any publicly available corpus in this privacy-sensitive domain\nled us to develop our own corpus, consisting of about 3K conversations\nannotated by professional medical scribes. We propose two novel deep learning\napproaches to infer the symptom names and their status: (1) a new hierarchical\nspan-attribute tagging (\\SAT) model, trained using curriculum learning, and (2)\na variant of sequence-to-sequence model which decodes the symptoms and their\nstatus from a few speaker turns within a sliding window over the conversation.\nThis task stems from a realistic application of assisting medical providers in\ncapturing symptoms mentioned by patients from their clinical conversations. To\nreflect this application, we define multiple metrics. From inter-rater\nagreement, we find that the task is inherently difficult. We conduct\ncomprehensive evaluations on several contrasting conditions and observe that\nthe performance of the models range from an F-score of 0.5 to 0.8 depending on\nthe condition. Our analysis not only reveals the inherent challenges of the\ntask, but also provides useful directions to improve the models.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 18:34:16 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Du", "Nan", ""], ["Chen", "Kai", ""], ["Kannan", "Anjuli", ""], ["Tran", "Linh", ""], ["Chen", "Yuhui", ""], ["Shafran", "Izhak", ""]]}, {"id": "1906.02242", "submitter": "Suchin Gururangan", "authors": "Suchin Gururangan, Tam Dang, Dallas Card, and Noah A. Smith", "title": "Variational Pretraining for Semi-supervised Text Classification", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce VAMPIRE, a lightweight pretraining framework for effective text\nclassification when data and computing resources are limited. We pretrain a\nunigram document model as a variational autoencoder on in-domain, unlabeled\ndata and use its internal states as features in a downstream classifier.\nEmpirically, we show the relative strength of VAMPIRE against computationally\nexpensive contextual embeddings and other popular semi-supervised baselines\nunder low resource settings. We also find that fine-tuning to in-domain data is\ncrucial to achieving decent performance from contextual embeddings when working\nwith limited supervision. We accompany this paper with code to pretrain and use\nVAMPIRE embeddings in downstream tasks.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 18:40:37 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Gururangan", "Suchin", ""], ["Dang", "Tam", ""], ["Card", "Dallas", ""], ["Smith", "Noah A.", ""]]}, {"id": "1906.02243", "submitter": "Emma Strubell", "authors": "Emma Strubell, Ananya Ganesh, Andrew McCallum", "title": "Energy and Policy Considerations for Deep Learning in NLP", "comments": "In the 57th Annual Meeting of the Association for Computational\n  Linguistics (ACL). Florence, Italy. July 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in hardware and methodology for training neural networks has\nushered in a new generation of large networks trained on abundant data. These\nmodels have obtained notable gains in accuracy across many NLP tasks. However,\nthese accuracy improvements depend on the availability of exceptionally large\ncomputational resources that necessitate similarly substantial energy\nconsumption. As a result these models are costly to train and develop, both\nfinancially, due to the cost of hardware and electricity or cloud compute time,\nand environmentally, due to the carbon footprint required to fuel modern tensor\nprocessing hardware. In this paper we bring this issue to the attention of NLP\nresearchers by quantifying the approximate financial and environmental costs of\ntraining a variety of recently successful neural network models for NLP. Based\non these findings, we propose actionable recommendations to reduce costs and\nimprove equity in NLP research and practice.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 18:40:53 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Strubell", "Emma", ""], ["Ganesh", "Ananya", ""], ["McCallum", "Andrew", ""]]}, {"id": "1906.02246", "submitter": "Izhak Shafran", "authors": "Izhak Shafran, Tom Bagby, and R. J. Skerry-Ryan", "title": "Complex Evolution Recurrent Neural Networks (ceRNNs)", "comments": null, "journal-ref": "Proc. International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP), pages 5854-5858, 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unitary Evolution Recurrent Neural Networks (uRNNs) have three attractive\nproperties: (a) the unitary property, (b) the complex-valued nature, and (c)\ntheir efficient linear operators. The literature so far does not address -- how\ncritical is the unitary property of the model? Furthermore, uRNNs have not been\nevaluated on large tasks. To study these shortcomings, we propose the complex\nevolution Recurrent Neural Networks (ceRNNs), which is similar to uRNNs but\ndrops the unitary property selectively. On a simple multivariate linear\nregression task, we illustrate that dropping the constraints improves the\nlearning trajectory. In copy memory task, ceRNNs and uRNNs perform identically,\ndemonstrating that their superior performance over LSTMs is due to\ncomplex-valued nature and their linear operators. In a large scale real-world\nspeech recognition, we find that pre-pending a uRNN degrades the performance of\nour baseline LSTM acoustic models, while pre-pending a ceRNN improves the\nperformance over the baseline by 0.8% absolute WER.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 18:51:26 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Shafran", "Izhak", ""], ["Bagby", "Tom", ""], ["Skerry-Ryan", "R. J.", ""]]}, {"id": "1906.02276", "submitter": "Bowen Li", "authors": "Bowen Li, Lili Mou, Frank Keller", "title": "An Imitation Learning Approach to Unsupervised Parsing", "comments": "ACL2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been an increasing interest in unsupervised parsers that\noptimize semantically oriented objectives, typically using reinforcement\nlearning. Unfortunately, the learned trees often do not match actual syntax\ntrees well. Shen et al. (2018) propose a structured attention mechanism for\nlanguage modeling (PRPN), which induces better syntactic structures but relies\non ad hoc heuristics. Also, their model lacks interpretability as it is not\ngrounded in parsing actions. In our work, we propose an imitation learning\napproach to unsupervised parsing, where we transfer the syntactic knowledge\ninduced by the PRPN to a Tree-LSTM model with discrete parsing actions. Its\npolicy is then refined by Gumbel-Softmax training towards a semantically\noriented objective. We evaluate our approach on the All Natural Language\nInference dataset and show that it achieves a new state of the art in terms of\nparsing $F$-score, outperforming our base models, including the PRPN.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 19:45:21 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Li", "Bowen", ""], ["Mou", "Lili", ""], ["Keller", "Frank", ""]]}, {"id": "1906.02285", "submitter": "Tao Yu", "authors": "Tao Yu, Rui Zhang, Michihiro Yasunaga, Yi Chern Tan, Xi Victoria Lin,\n  Suyi Li, Heyang Er, Irene Li, Bo Pang, Tao Chen, Emily Ji, Shreya Dixit,\n  David Proctor, Sungrok Shim, Jonathan Kraft, Vincent Zhang, Caiming Xiong,\n  Richard Socher and Dragomir Radev", "title": "SParC: Cross-Domain Semantic Parsing in Context", "comments": "Accepted to ACL 2019, long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present SParC, a dataset for cross-domainSemanticParsing inContext that\nconsists of 4,298 coherent question sequences (12k+ individual questions\nannotated with SQL queries). It is obtained from controlled user interactions\nwith 200 complex databases over 138 domains. We provide an in-depth analysis of\nSParC and show that it introduces new challenges compared to existing datasets.\nSParC demonstrates complex contextual dependencies, (2) has greater semantic\ndiversity, and (3) requires generalization to unseen domains due to its\ncross-domain nature and the unseen databases at test time. We experiment with\ntwo state-of-the-art text-to-SQL models adapted to the context-dependent,\ncross-domain setup. The best model obtains an exact match accuracy of 20.2%\nover all questions and less than10% over all interaction sequences, indicating\nthat the cross-domain setting and the con-textual phenomena of the dataset\npresent significant challenges for future research. The dataset, baselines, and\nleaderboard are released at https://yale-lily.github.io/sparc.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 20:05:18 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Yu", "Tao", ""], ["Zhang", "Rui", ""], ["Yasunaga", "Michihiro", ""], ["Tan", "Yi Chern", ""], ["Lin", "Xi Victoria", ""], ["Li", "Suyi", ""], ["Er", "Heyang", ""], ["Li", "Irene", ""], ["Pang", "Bo", ""], ["Chen", "Tao", ""], ["Ji", "Emily", ""], ["Dixit", "Shreya", ""], ["Proctor", "David", ""], ["Shim", "Sungrok", ""], ["Kraft", "Jonathan", ""], ["Zhang", "Vincent", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""], ["Radev", "Dragomir", ""]]}, {"id": "1906.02358", "submitter": "Nisansa de Silva", "authors": "Nisansa de Silva", "title": "Survey on Publicly Available Sinhala Natural Language Processing Tools\n  and Research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sinhala is the native language of the Sinhalese people who make up the\nlargest ethnic group of Sri Lanka. The language belongs to the globe-spanning\nlanguage tree, Indo-European. However, due to poverty in both linguistic and\neconomic capital, Sinhala, in the perspective of Natural Language Processing\ntools and research, remains a resource-poor language which has neither the\neconomic drive its cousin English has nor the sheer push of the law of numbers\na language such as Chinese has. A number of research groups from Sri Lanka have\nnoticed this dearth and the resultant dire need for proper tools and research\nfor Sinhala natural language processing. However, due to various reasons, these\nattempts seem to lack coordination and awareness of each other. The objective\nof this paper is to fill that gap of a comprehensive literature survey of the\npublicly available Sinhala natural language tools and research so that the\nresearchers working in this field can better utilize contributions of their\npeers. As such, we shall be uploading this paper to arXiv and perpetually\nupdate it periodically to reflect the advances made in the field.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 23:36:06 GMT"}, {"version": "v2", "created": "Sun, 9 Jun 2019 20:03:25 GMT"}, {"version": "v3", "created": "Fri, 5 Jul 2019 06:33:19 GMT"}, {"version": "v4", "created": "Mon, 22 Jul 2019 02:21:31 GMT"}, {"version": "v5", "created": "Mon, 13 Jan 2020 07:07:39 GMT"}, {"version": "v6", "created": "Sun, 4 Oct 2020 04:59:22 GMT"}, {"version": "v7", "created": "Sun, 13 Dec 2020 21:48:32 GMT"}, {"version": "v8", "created": "Fri, 2 Apr 2021 09:38:15 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["de Silva", "Nisansa", ""]]}, {"id": "1906.02361", "submitter": "Nazneen Fatema Rajani", "authors": "Nazneen Fatema Rajani and Bryan McCann and Caiming Xiong and Richard\n  Socher", "title": "Explain Yourself! Leveraging Language Models for Commonsense Reasoning", "comments": "Accepted at ACL, 11 pages total", "journal-ref": "In Proceedings of the Association for Computational Linguistics\n  (ACL), 2019. Florence, Italy", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models perform poorly on tasks that require commonsense\nreasoning, which often necessitates some form of world-knowledge or reasoning\nover information not immediately present in the input. We collect human\nexplanations for commonsense reasoning in the form of natural language\nsequences and highlighted annotations in a new dataset called Common Sense\nExplanations (CoS-E). We use CoS-E to train language models to automatically\ngenerate explanations that can be used during training and inference in a novel\nCommonsense Auto-Generated Explanation (CAGE) framework. CAGE improves the\nstate-of-the-art by 10% on the challenging CommonsenseQA task. We further study\ncommonsense reasoning in DNNs using both human and auto-generated explanations\nincluding transfer to out-of-domain tasks. Empirical results indicate that we\ncan effectively leverage language models for commonsense reasoning.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 00:02:37 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Rajani", "Nazneen Fatema", ""], ["McCann", "Bryan", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "1906.02376", "submitter": "Federico Bianchi", "authors": "Valerio Di Carlo, Federico Bianchi, Matteo Palmonari", "title": "Training Temporal Word Embeddings with a Compass", "comments": "Accepted at AAAI2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal word embeddings have been proposed to support the analysis of word\nmeaning shifts during time and to study the evolution of languages. Different\napproaches have been proposed to generate vector representations of words that\nembed their meaning during a specific time interval. However, the training\nprocess used in these approaches is complex, may be inefficient or it may\nrequire large text corpora. As a consequence, these approaches may be difficult\nto apply in resource-scarce domains or by scientists with limited in-depth\nknowledge of embedding models. In this paper, we propose a new heuristic to\ntrain temporal word embeddings based on the Word2vec model. The heuristic\nconsists in using atemporal vectors as a reference, i.e., as a compass, when\ntraining the representations specific to a given time interval. The use of the\ncompass simplifies the training process and makes it more efficient.\nExperiments conducted using state-of-the-art datasets and methodologies suggest\nthat our approach outperforms or equals comparable approaches while being more\nrobust in terms of the required corpus size.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 09:40:25 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Di Carlo", "Valerio", ""], ["Bianchi", "Federico", ""], ["Palmonari", "Matteo", ""]]}, {"id": "1906.02390", "submitter": "Wei Hu", "authors": "Qingheng Zhang and Zequn Sun and Wei Hu and Muhao Chen and Lingbing\n  Guo and Yuzhong Qu", "title": "Multi-view Knowledge Graph Embedding for Entity Alignment", "comments": "Accepted by the 28th International Joint Conference on Artificial\n  Intelligence (IJCAI 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of embedding-based entity alignment between knowledge\ngraphs (KGs). Previous works mainly focus on the relational structure of\nentities. Some further incorporate another type of features, such as\nattributes, for refinement. However, a vast of entity features are still\nunexplored or not equally treated together, which impairs the accuracy and\nrobustness of embedding-based entity alignment. In this paper, we propose a\nnovel framework that unifies multiple views of entities to learn embeddings for\nentity alignment. Specifically, we embed entities based on the views of entity\nnames, relations and attributes, with several combination strategies.\nFurthermore, we design some cross-KG inference methods to enhance the alignment\nbetween two KGs. Our experiments on real-world datasets show that the proposed\nframework significantly outperforms the state-of-the-art embedding-based entity\nalignment methods. The selected views, cross-KG inference and combination\nstrategies all contribute to the performance improvement.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 02:52:12 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Zhang", "Qingheng", ""], ["Sun", "Zequn", ""], ["Hu", "Wei", ""], ["Chen", "Muhao", ""], ["Guo", "Lingbing", ""], ["Qu", "Yuzhong", ""]]}, {"id": "1906.02402", "submitter": "Roman Klinger", "authors": "Evgeny Kim and Roman Klinger", "title": "An Analysis of Emotion Communication Channels in Fan Fiction: Towards\n  Emotional Storytelling", "comments": "Accepted for the Storytelling Workshop at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Centrality of emotion for the stories told by humans is underpinned by\nnumerous studies in literature and psychology. The research in automatic\nstorytelling has recently turned towards emotional storytelling, in which\ncharacters' emotions play an important role in the plot development. However,\nthese studies mainly use emotion to generate propositional statements in the\nform \"A feels affection towards B\" or \"A confronts B\". At the same time,\nemotional behavior does not boil down to such propositional descriptions, as\nhumans display complex and highly variable patterns in communicating their\nemotions, both verbally and non-verbally. In this paper, we analyze how\nemotions are expressed non-verbally in a corpus of fan fiction short stories.\nOur analysis shows that stories written by humans convey character emotions\nalong various non-verbal channels. We find that some non-verbal channels, such\nas facial expressions and voice characteristics of the characters, are more\nstrongly associated with joy, while gestures and body postures are more likely\nto occur with trust. Based on our analysis, we argue that automatic\nstorytelling systems should take variability of emotion into account when\ngenerating descriptions of characters' emotions.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 03:53:58 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Kim", "Evgeny", ""], ["Klinger", "Roman", ""]]}, {"id": "1906.02403", "submitter": "Fushan Li", "authors": "Fushan Li, Michael Bowling", "title": "Ease-of-Teaching and Language Structure from Emergent Communication", "comments": "Accepted at Neural Information Processing Systems (NeurIPS) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial agents have been shown to learn to communicate when needed to\ncomplete a cooperative task. Some level of language structure (e.g.,\ncompositionality) has been found in the learned communication protocols. This\nobserved structure is often the result of specific environmental pressures\nduring training. By introducing new agents periodically to replace old ones,\nsequentially and within a population, we explore such a new pressure -- ease of\nteaching -- and show its impact on the structure of the resulting language.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 03:59:37 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 22:51:26 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Li", "Fushan", ""], ["Bowling", "Michael", ""]]}, {"id": "1906.02416", "submitter": "Alexander Terenin", "authors": "Alexander Terenin, M{\\aa}ns Magnusson, Leif Jonsson", "title": "Sparse Parallel Training of Hierarchical Dirichlet Process Topic Models", "comments": null, "journal-ref": "Conference on Empirical Methods in Natural Language Processing,\n  2020", "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To scale non-parametric extensions of probabilistic topic models such as\nLatent Dirichlet allocation to larger data sets, practitioners rely\nincreasingly on parallel and distributed systems. In this work, we study\ndata-parallel training for the hierarchical Dirichlet process (HDP) topic\nmodel. Based upon a representation of certain conditional distributions within\nan HDP, we propose a doubly sparse data-parallel sampler for the HDP topic\nmodel. This sampler utilizes all available sources of sparsity found in natural\nlanguage - an important way to make computation efficient. We benchmark our\nmethod on a well-known corpus (PubMed) with 8m documents and 768m tokens, using\na single multi-core machine in under four days.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 05:04:08 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 12:00:09 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Terenin", "Alexander", ""], ["Magnusson", "M\u00e5ns", ""], ["Jonsson", "Leif", ""]]}, {"id": "1906.02430", "submitter": "Menuka Warushavithana", "authors": "Gathika Ratnayaka, Thejan Rupasinghe, Nisansa de Silva, Viraj Salaka\n  Gamage, Menuka Warushavithana, Amal Shehan Perera", "title": "Shift-of-Perspective Identification Within Legal Cases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arguments, counter-arguments, facts, and evidence obtained via documents\nrelated to previous court cases are of essential need for legal professionals.\nTherefore, the process of automatic information extraction from documents\ncontaining legal opinions related to court cases can be considered to be of\nsignificant importance. This study is focused on the identification of\nsentences in legal opinion texts which convey different perspectives on a\ncertain topic or entity. We combined several approaches based on semantic\nanalysis, open information extraction, and sentiment analysis to achieve our\nobjective. Then, our methodology was evaluated with the help of human judges.\nThe outcomes of the evaluation demonstrate that our system is successful in\ndetecting situations where two sentences deliver different opinions on the same\ntopic or entity. The proposed methodology can be used to facilitate other\ninformation extraction tasks related to the legal domain. One such task is the\nautomated detection of counter arguments for a given argument. Another is the\nidentification of opponent parties in a court case.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 05:58:42 GMT"}, {"version": "v2", "created": "Sun, 7 Jul 2019 18:57:55 GMT"}, {"version": "v3", "created": "Wed, 17 Jul 2019 04:45:14 GMT"}, {"version": "v4", "created": "Sat, 17 Aug 2019 18:17:28 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Ratnayaka", "Gathika", ""], ["Rupasinghe", "Thejan", ""], ["de Silva", "Nisansa", ""], ["Gamage", "Viraj Salaka", ""], ["Warushavithana", "Menuka", ""], ["Perera", "Amal Shehan", ""]]}, {"id": "1906.02437", "submitter": "Yijin Liu", "authors": "Yijin Liu, Fandong Meng, Jinchao Zhang, Jinan Xu, Yufeng Chen and Jie\n  Zhou", "title": "GCDT: A Global Context Enhanced Deep Transition Architecture for\n  Sequence Labeling", "comments": "Accepted as a long paper at ACL 2019. Code is available at:\n  https://github.com/Adaxry/GCDT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current state-of-the-art systems for sequence labeling are typically based on\nthe family of Recurrent Neural Networks (RNNs). However, the shallow\nconnections between consecutive hidden states of RNNs and insufficient modeling\nof global information restrict the potential performance of those models. In\nthis paper, we try to address these issues, and thus propose a Global Context\nenhanced Deep Transition architecture for sequence labeling named GCDT. We\ndeepen the state transition path at each position in a sentence, and further\nassign every token with a global representation learned from the entire\nsentence. Experiments on two standard sequence labeling tasks show that, given\nonly training data and the ubiquitous word embeddings (Glove), our GCDT\nachieves 91.96 F1 on the CoNLL03 NER task and 95.43 F1 on the CoNLL2000\nChunking task, which outperforms the best reported results under the same\nsettings. Furthermore, by leveraging BERT as an additional resource, we\nestablish new state-of-the-art results with 93.47 F1 on NER and 97.30 F1 on\nChunking.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 06:31:21 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Liu", "Yijin", ""], ["Meng", "Fandong", ""], ["Zhang", "Jinchao", ""], ["Xu", "Jinan", ""], ["Chen", "Yufeng", ""], ["Zhou", "Jie", ""]]}, {"id": "1906.02443", "submitter": "Yong Cheng", "authors": "Yong Cheng, Lu Jiang, and Wolfgang Macherey", "title": "Robust Neural Machine Translation with Doubly Adversarial Inputs", "comments": "Accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT) often suffers from the vulnerability to\nnoisy perturbations in the input. We propose an approach to improving the\nrobustness of NMT models, which consists of two parts: (1) attack the\ntranslation model with adversarial source examples; (2) defend the translation\nmodel with adversarial target inputs to improve its robustness against the\nadversarial source inputs.For the generation of adversarial inputs, we propose\na gradient-based method to craft adversarial examples informed by the\ntranslation loss over the clean inputs.Experimental results on Chinese-English\nand English-German translation tasks demonstrate that our approach achieves\nsignificant improvements ($2.8$ and $1.6$ BLEU points) over Transformer on\nstandard clean benchmarks as well as exhibiting higher robustness on noisy\ndata.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 07:02:04 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Cheng", "Yong", ""], ["Jiang", "Lu", ""], ["Macherey", "Wolfgang", ""]]}, {"id": "1906.02448", "submitter": "Wen Zhang", "authors": "Wen Zhang, Yang Feng, Fandong Meng, Di You and Qun Liu", "title": "Bridging the Gap between Training and Inference for Neural Machine\n  Translation", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) generates target words sequentially in the\nway of predicting the next word conditioned on the context words. At training\ntime, it predicts with the ground truth words as context while at inference it\nhas to generate the entire sequence from scratch. This discrepancy of the fed\ncontext leads to error accumulation among the way. Furthermore, word-level\ntraining requires strict matching between the generated sequence and the ground\ntruth sequence which leads to overcorrection over different but reasonable\ntranslations. In this paper, we address these issues by sampling context words\nnot only from the ground truth sequence but also from the predicted sequence by\nthe model during training, where the predicted sequence is selected with a\nsentence-level optimum. Experiment results on Chinese->English and WMT'14\nEnglish->German translation tasks demonstrate that our approach can achieve\nsignificant improvements on multiple datasets.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 07:15:52 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 11:54:01 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Zhang", "Wen", ""], ["Feng", "Yang", ""], ["Meng", "Fandong", ""], ["You", "Di", ""], ["Liu", "Qun", ""]]}, {"id": "1906.02461", "submitter": "Yichong Leng", "authors": "Yichong Leng, Xu Tan, Tao Qin, Xiang-Yang Li and Tie-Yan Liu", "title": "Unsupervised Pivot Translation for Distant Languages", "comments": "Accepted by ACL-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised neural machine translation (NMT) has attracted a lot of\nattention recently. While state-of-the-art methods for unsupervised translation\nusually perform well between similar languages (e.g., English-German\ntranslation), they perform poorly between distant languages, because\nunsupervised alignment does not work well for distant languages. In this work,\nwe introduce unsupervised pivot translation for distant languages, which\ntranslates a language to a distant language through multiple hops, and the\nunsupervised translation on each hop is relatively easier than the original\ndirect translation. We propose a learning to route (LTR) method to choose the\ntranslation path between the source and target languages. LTR is trained on\nlanguage pairs whose best translation path is available and is applied on the\nunseen language pairs for path selection. Experiments on 20 languages and 294\ndistant language pairs demonstrate the advantages of the unsupervised pivot\ntranslation for distant languages, as well as the effectiveness of the proposed\nLTR for path selection. Specifically, in the best case, LTR achieves an\nimprovement of 5.58 BLEU points over the conventional direct unsupervised\nmethod.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 07:48:36 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 05:07:08 GMT"}, {"version": "v3", "created": "Tue, 25 Jun 2019 02:58:06 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Leng", "Yichong", ""], ["Tan", "Xu", ""], ["Qin", "Tao", ""], ["Li", "Xiang-Yang", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1906.02479", "submitter": "Dominik Schlechtweg", "authors": "Dominik Schlechtweg, Cennet Oguz, Sabine Schulte im Walde", "title": "Second-order Co-occurrence Sensitivity of Skip-Gram with Negative\n  Sampling", "comments": "BlackboxNLP 2019, 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We simulate first- and second-order context overlap and show that Skip-Gram\nwith Negative Sampling is similar to Singular Value Decomposition in capturing\nsecond-order co-occurrence information, while Pointwise Mutual Information is\nagnostic to it. We support the results with an empirical study finding that the\nmodels react differently when provided with additional second-order\ninformation. Our findings reveal a basic property of Skip-Gram with Negative\nSampling and point towards an explanation of its success on a variety of tasks.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 08:44:10 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 07:19:37 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Schlechtweg", "Dominik", ""], ["Oguz", "Cennet", ""], ["Walde", "Sabine Schulte im", ""]]}, {"id": "1906.02505", "submitter": "Federico L\\'opez", "authors": "Federico L\\'opez, Benjamin Heinzerling and Michael Strube", "title": "Fine-Grained Entity Typing in Hyperbolic Space", "comments": "12 pages, 4 figures, final version, accepted at the 4th Workshop on\n  Representation Learning for NLP (RepL4NLP), held in conjunction with ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we represent hierarchical information present in large type\ninventories for entity typing? We study the ability of hyperbolic embeddings to\ncapture hierarchical relations between mentions in context and their target\ntypes in a shared vector space. We evaluate on two datasets and investigate two\ndifferent techniques for creating a large hierarchical entity type inventory:\nfrom an expert-generated ontology and by automatically mining type\nco-occurrences. We find that the hyperbolic model yields improvements over its\nEuclidean counterpart in some, but not all cases. Our analysis suggests that\nthe adequacy of this geometry depends on the granularity of the type inventory\nand the way hierarchical relations are inferred.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 10:22:24 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["L\u00f3pez", "Federico", ""], ["Heinzerling", "Benjamin", ""], ["Strube", "Michael", ""]]}, {"id": "1906.02510", "submitter": "Tom\\'a\\v{s} Musil", "authors": "Tom\\'a\\v{s} Musil, Jon\\'a\\v{s} Vidra, David Mare\\v{c}ek", "title": "Derivational Morphological Relations in Word Embeddings", "comments": "8 pages, accepted to BlackBox NLP workshop collocated with ACL 2019\n  in Florence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Derivation is a type of a word-formation process which creates new words from\nexisting ones by adding, changing or deleting affixes. In this paper, we\nexplore the potential of word embeddings to identify properties of word\nderivations in the morphologically rich Czech language. We extract derivational\nrelations between pairs of words from DeriNet, a Czech lexical network, which\norganizes almost one million Czech lemmata into derivational trees. For each\nsuch pair, we compute the difference of the embeddings of the two words, and\nperform unsupervised clustering of the resulting vectors. Our results show that\nthese clusters largely match manually annotated semantic categories of the\nderivational relations (e.g. the relation 'bake--baker' belongs to category\n'actor', and a correct clustering puts it into the same cluster as\n'govern--governor').\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 10:44:41 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Musil", "Tom\u00e1\u0161", ""], ["Vidra", "Jon\u00e1\u0161", ""], ["Mare\u010dek", "David", ""]]}, {"id": "1906.02525", "submitter": "Vishwajeet Kumar", "authors": "Vishwajeet Kumar, Nitish Joshi, Arijit Mukherjee, Ganesh Ramakrishnan,\n  Preethi Jyothi", "title": "Cross-Lingual Training for Automatic Question Generation", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic question generation (QG) is a challenging problem in natural\nlanguage understanding. QG systems are typically built assuming access to a\nlarge number of training instances where each instance is a question and its\ncorresponding answer. For a new language, such training instances are hard to\nobtain making the QG problem even more challenging. Using this as our\nmotivation, we study the reuse of an available large QG dataset in a secondary\nlanguage (e.g. English) to learn a QG model for a primary language (e.g. Hindi)\nof interest. For the primary language, we assume access to a large amount of\nmonolingual text but only a small QG dataset. We propose a cross-lingual QG\nmodel which uses the following training regime: (i) Unsupervised pretraining of\nlanguage models in both primary and secondary languages and (ii) joint\nsupervised training for QG in both languages. We demonstrate the efficacy of\nour proposed approach using two different primary languages, Hindi and Chinese.\nWe also create and release a new question answering dataset for Hindi\nconsisting of 6555 sentences.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 11:31:24 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Kumar", "Vishwajeet", ""], ["Joshi", "Nitish", ""], ["Mukherjee", "Arijit", ""], ["Ramakrishnan", "Ganesh", ""], ["Jyothi", "Preethi", ""]]}, {"id": "1906.02563", "submitter": "Janis Pagel", "authors": "Prajit Dhar and Janis Pagel and Lonneke van der Plas", "title": "Measuring the compositionality of noun-noun compounds over time", "comments": "6 pages, 3 figures, To appear in the proceedings of the 1st\n  International Workshop on Computational Approaches to Historical Language\n  Change 2019 @ ACL 2019, Fixed typos, Increased figure sizes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present work in progress on the temporal progression of compositionality\nin noun-noun compounds. Previous work has proposed computational methods for\ndetermining the compositionality of compounds. These methods try to\nautomatically determine how transparent the meaning of the compound as a whole\nis with respect to the meaning of its parts. We hypothesize that such a\nproperty might change over time. We use the time-stamped Google Books corpus\nfor our diachronic investigations, and first examine whether the vector-based\nsemantic spaces extracted from this corpus are able to predict compositionality\nratings, despite their inherent limitations. We find that using temporal\ninformation helps predicting the ratings, although correlation with the ratings\nis lower than reported for other corpora. Finally, we show changes in\ncompositionality over time for a selection of compounds.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 13:12:35 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 14:20:15 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Dhar", "Prajit", ""], ["Pagel", "Janis", ""], ["van der Plas", "Lonneke", ""]]}, {"id": "1906.02564", "submitter": "Claudia Schulz", "authors": "Claudia Schulz, Christian M. Meyer, Jan Kiesewetter, Michael Sailer,\n  Elisabeth Bauer, Martin R. Fischer, Frank Fischer, Iryna Gurevych", "title": "Analysis of Automatic Annotation Suggestions for Hard Discourse-Level\n  Tasks in Expert Domains", "comments": "To appear in Proceedings of the 57th Annual Meeting of the\n  Association for Computational Linguistics (ACL 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many complex discourse-level tasks can aid domain experts in their work but\nrequire costly expert annotations for data creation. To speed up and ease\nannotations, we investigate the viability of automatically generated annotation\nsuggestions for such tasks. As an example, we choose a task that is\nparticularly hard for both humans and machines: the segmentation and\nclassification of epistemic activities in diagnostic reasoning texts. We create\nand publish a new dataset covering two domains and carefully analyse the\nsuggested annotations. We find that suggestions have positive effects on\nannotation speed and performance, while not introducing noteworthy biases.\nEnvisioning suggestion models that improve with newly annotated texts, we\ncontrast methods for continuous model adjustment and suggest the most effective\nsetup for suggestions in future expert tasks.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 13:13:46 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Schulz", "Claudia", ""], ["Meyer", "Christian M.", ""], ["Kiesewetter", "Jan", ""], ["Sailer", "Michael", ""], ["Bauer", "Elisabeth", ""], ["Fischer", "Martin R.", ""], ["Fischer", "Frank", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1906.02622", "submitter": "Kalpesh Krishna", "authors": "Kalpesh Krishna, Mohit Iyyer", "title": "Generating Question-Answer Hierarchies", "comments": "ACL camera ready + technical note on pipeline modifications for demo\n  (15 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The process of knowledge acquisition can be viewed as a question-answer game\nbetween a student and a teacher in which the student typically starts by asking\nbroad, open-ended questions before drilling down into specifics (Hintikka,\n1981; Hakkarainen and Sintonen, 2002). This pedagogical perspective motivates a\nnew way of representing documents. In this paper, we present SQUASH\n(Specificity-controlled Question-Answer Hierarchies), a novel and challenging\ntext generation task that converts an input document into a hierarchy of\nquestion-answer pairs. Users can click on high-level questions (e.g., \"Why did\nFrodo leave the Fellowship?\") to reveal related but more specific questions\n(e.g., \"Who did Frodo leave with?\"). Using a question taxonomy loosely based on\nLehnert (1978), we classify questions in existing reading comprehension\ndatasets as either \"general\" or \"specific\". We then use these labels as input\nto a pipelined system centered around a conditional neural language model. We\nextensively evaluate the quality of the generated QA hierarchies through\ncrowdsourced experiments and report strong empirical results.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 14:53:04 GMT"}, {"version": "v2", "created": "Sun, 21 Jul 2019 20:44:23 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Krishna", "Kalpesh", ""], ["Iyyer", "Mohit", ""]]}, {"id": "1906.02656", "submitter": "Junxian He", "authors": "Junxian He, Zhisong Zhang, Taylor Berg-Kirkpatrick, Graham Neubig", "title": "Cross-Lingual Syntactic Transfer through Unsupervised Adaptation of\n  Invertible Projections", "comments": "ACL 2019 long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual transfer is an effective way to build syntactic analysis tools\nin low-resource languages. However, transfer is difficult when transferring to\ntypologically distant languages, especially when neither annotated target data\nnor parallel corpora are available. In this paper, we focus on methods for\ncross-lingual transfer to distant languages and propose to learn a generative\nmodel with a structured prior that utilizes labeled source data and unlabeled\ntarget data jointly. The parameters of source model and target model are softly\nshared through a regularized log likelihood objective. An invertible projection\nis employed to learn a new interlingual latent embedding space that compensates\nfor imperfect cross-lingual word embedding input. We evaluate our method on two\nsyntactic tasks: part-of-speech (POS) tagging and dependency parsing. On the\nUniversal Dependency Treebanks, we use English as the only source corpus and\ntransfer to a wide range of target languages. On the 10 languages in this\ndataset that are distant from English, our method yields an average of 5.2%\nabsolute improvement on POS tagging and 8.3% absolute improvement on dependency\nparsing over a direct transfer method using state-of-the-art discriminative\nmodels.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 15:46:17 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 03:09:17 GMT"}, {"version": "v3", "created": "Wed, 7 Aug 2019 22:01:33 GMT"}, {"version": "v4", "created": "Thu, 29 Apr 2021 03:36:13 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["He", "Junxian", ""], ["Zhang", "Zhisong", ""], ["Berg-Kirkpatrick", "Taylor", ""], ["Neubig", "Graham", ""]]}, {"id": "1906.02671", "submitter": "Nicholas Waytowich", "authors": "Nicholas Waytowich, Sean L. Barton, Vernon Lawhern, Ethan Stump and\n  Garrett Warnell", "title": "Grounding Natural Language Commands to StarCraft II Game States for\n  Narration-Guided Reinforcement Learning", "comments": "10 pages, 3 figures. Published at SPIE 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CL cs.LG cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep reinforcement learning techniques have led to agents that are\nsuccessfully able to learn to perform a number of tasks that had been\npreviously unlearnable, these techniques are still susceptible to the\nlongstanding problem of {\\em reward sparsity}. This is especially true for\ntasks such as training an agent to play StarCraft II, a real-time strategy game\nwhere reward is only given at the end of a game which is usually very long.\nWhile this problem can be addressed through reward shaping, such approaches\ntypically require a human expert with specialized knowledge. Inspired by the\nvision of enabling reward shaping through the more-accessible paradigm of\nnatural-language narration, we investigate to what extent we can contextualize\nthese narrations by grounding them to the goal-specific states. We present a\nmutual-embedding model using a multi-input deep-neural network that projects a\nsequence of natural language commands into the same high-dimensional\nrepresentation space as corresponding goal states. We show that using this\nmodel we can learn an embedding space with separable and distinct clusters that\naccurately maps natural-language commands to corresponding game states . We\nalso discuss how this model can allow for the use of narrations as a robust\nform of reward shaping to improve RL performance and efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 17:43:40 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Waytowich", "Nicholas", ""], ["Barton", "Sean L.", ""], ["Lawhern", "Vernon", ""], ["Stump", "Ethan", ""], ["Warnell", "Garrett", ""]]}, {"id": "1906.02688", "submitter": "Vihari Piratla Mr.", "authors": "Vihari Piratla, Sunita Sarawagi, Soumen Chakrabarti", "title": "Topic Sensitive Attention on Generic Corpora Corrects Sense Bias in\n  Pretrained Embeddings", "comments": "Accepted at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a small corpus $\\mathcal D_T$ pertaining to a limited set of focused\ntopics, our goal is to train embeddings that accurately capture the sense of\nwords in the topic in spite of the limited size of $\\mathcal D_T$. These\nembeddings may be used in various tasks involving $\\mathcal D_T$. A popular\nstrategy in limited data settings is to adapt pre-trained embeddings $\\mathcal\nE$ trained on a large corpus. To correct for sense drift, fine-tuning,\nregularization, projection, and pivoting have been proposed recently. Among\nthese, regularization informed by a word's corpus frequency performed well, but\nwe improve upon it using a new regularizer based on the stability of its\ncooccurrence with other words. However, a thorough comparison across ten\ntopics, spanning three tasks, with standardized settings of hyper-parameters,\nreveals that even the best embedding adaptation strategies provide small gains\nbeyond well-tuned baselines, which many earlier comparisons ignored. In a bold\ndeparture from adapting pretrained embeddings, we propose using $\\mathcal D_T$\nto probe, attend to, and borrow fragments from any large, topic-rich source\ncorpus (such as Wikipedia), which need not be the corpus used to pretrain\nembeddings. This step is made scalable and practical by suitable indexing. We\nreach the surprising conclusion that even limited corpus augmentation is more\nuseful than adapting embeddings, which suggests that non-dominant sense\ninformation may be irrevocably obliterated from pretrained embeddings and\ncannot be salvaged by adaptation.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 07:15:06 GMT"}, {"version": "v2", "created": "Wed, 24 Jul 2019 10:59:36 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Piratla", "Vihari", ""], ["Sarawagi", "Sunita", ""], ["Chakrabarti", "Soumen", ""]]}, {"id": "1906.02715", "submitter": "Ann Yuan", "authors": "Andy Coenen, Emily Reif, Ann Yuan, Been Kim, Adam Pearce, Fernanda\n  Vi\\'egas, Martin Wattenberg", "title": "Visualizing and Measuring the Geometry of BERT", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer architectures show significant promise for natural language\nprocessing. Given that a single pretrained model can be fine-tuned to perform\nwell on many different tasks, these networks appear to extract generally useful\nlinguistic features. A natural question is how such networks represent this\ninformation internally. This paper describes qualitative and quantitative\ninvestigations of one particularly effective model, BERT. At a high level,\nlinguistic features seem to be represented in separate semantic and syntactic\nsubspaces. We find evidence of a fine-grained geometric representation of word\nsenses. We also present empirical descriptions of syntactic representations in\nboth attention matrices and individual word embeddings, as well as a\nmathematical argument to explain the geometry of these representations.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 17:33:22 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 17:53:14 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Coenen", "Andy", ""], ["Reif", "Emily", ""], ["Yuan", "Ann", ""], ["Kim", "Been", ""], ["Pearce", "Adam", ""], ["Vi\u00e9gas", "Fernanda", ""], ["Wattenberg", "Martin", ""]]}, {"id": "1906.02738", "submitter": "Lianhui Qin", "authors": "Lianhui Qin, Michel Galley, Chris Brockett, Xiaodong Liu, Xiang Gao,\n  Bill Dolan, Yejin Choi and Jianfeng Gao", "title": "Conversing by Reading: Contentful Neural Conversation with On-demand\n  Machine Reading", "comments": "ACL 2019 long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although neural conversation models are effective in learning how to produce\nfluent responses, their primary challenge lies in knowing what to say to make\nthe conversation contentful and non-vacuous. We present a new end-to-end\napproach to contentful neural conversation that jointly models response\ngeneration and on-demand machine reading. The key idea is to provide the\nconversation model with relevant long-form text on the fly as a source of\nexternal knowledge. The model performs QA-style reading comprehension on this\ntext in response to each conversational turn, thereby allowing for more focused\nintegration of external knowledge than has been possible in prior approaches.\nTo support further research on knowledge-grounded conversation, we introduce a\nnew large-scale conversation dataset grounded in external web pages (2.8M\nturns, 7.4M sentences of grounding). Both human evaluation and automated\nmetrics show that our approach results in more contentful responses compared to\na variety of previous methods, improving both the informativeness and diversity\nof generated output.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 17:55:37 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 03:10:20 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Qin", "Lianhui", ""], ["Galley", "Michel", ""], ["Brockett", "Chris", ""], ["Liu", "Xiaodong", ""], ["Gao", "Xiang", ""], ["Dolan", "Bill", ""], ["Choi", "Yejin", ""], ["Gao", "Jianfeng", ""]]}, {"id": "1906.02762", "submitter": "Zhuohan Li", "authors": "Yiping Lu, Zhuohan Li, Di He, Zhiqing Sun, Bin Dong, Tao Qin, Liwei\n  Wang, Tie-Yan Liu", "title": "Understanding and Improving Transformer From a Multi-Particle Dynamic\n  System Point of View", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Transformer architecture is widely used in natural language processing.\nDespite its success, the design principle of the Transformer remains elusive.\nIn this paper, we provide a novel perspective towards understanding the\narchitecture: we show that the Transformer can be mathematically interpreted as\na numerical Ordinary Differential Equation (ODE) solver for a\nconvection-diffusion equation in a multi-particle dynamic system. In\nparticular, how words in a sentence are abstracted into contexts by passing\nthrough the layers of the Transformer can be interpreted as approximating\nmultiple particles' movement in the space using the Lie-Trotter splitting\nscheme and the Euler's method. Given this ODE's perspective, the rich\nliterature of numerical analysis can be brought to guide us in designing\neffective structures beyond the Transformer. As an example, we propose to\nreplace the Lie-Trotter splitting scheme by the Strang-Marchuk splitting\nscheme, a scheme that is more commonly used and with much lower local\ntruncation errors. The Strang-Marchuk splitting scheme suggests that the\nself-attention and position-wise feed-forward network (FFN) sub-layers should\nnot be treated equally. Instead, in each layer, two position-wise FFN\nsub-layers should be used, and the self-attention sub-layer is placed in\nbetween. This leads to a brand new architecture. Such an FFN-attention-FFN\nlayer is \"Macaron-like\", and thus we call the network with this new\narchitecture the Macaron Net. Through extensive experiments, we show that the\nMacaron Net is superior to the Transformer on both supervised and unsupervised\nlearning tasks. The reproducible codes and pretrained models can be found at\nhttps://github.com/zhuohan123/macaron-net\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 18:10:08 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Lu", "Yiping", ""], ["Li", "Zhuohan", ""], ["He", "Di", ""], ["Sun", "Zhiqing", ""], ["Dong", "Bin", ""], ["Qin", "Tao", ""], ["Wang", "Liwei", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1906.02780", "submitter": "Nader Akoury", "authors": "Nader Akoury, Kalpesh Krishna, Mohit Iyyer", "title": "Syntactically Supervised Transformers for Faster Neural Machine\n  Translation", "comments": "9 pages, 5 figures, accepted to ACL 2019", "journal-ref": "Association for Computational Linguistics (2019) 1269-1281", "doi": "10.18653/v1/P19-1122", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard decoders for neural machine translation autoregressively generate a\nsingle target token per time step, which slows inference especially for long\noutputs. While architectural advances such as the Transformer fully parallelize\nthe decoder computations at training time, inference still proceeds\nsequentially. Recent developments in non- and semi- autoregressive decoding\nproduce multiple tokens per time step independently of the others, which\nimproves inference speed but deteriorates translation quality. In this work, we\npropose the syntactically supervised Transformer (SynST), which first\nautoregressively predicts a chunked parse tree before generating all of the\ntarget tokens in one shot conditioned on the predicted parse. A series of\ncontrolled experiments demonstrates that SynST decodes sentences ~ 5x faster\nthan the baseline autoregressive Transformer while achieving higher BLEU scores\nthan most competing methods on En-De and En-Fr datasets.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 19:16:16 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Akoury", "Nader", ""], ["Krishna", "Kalpesh", ""], ["Iyyer", "Mohit", ""]]}, {"id": "1906.02782", "submitter": "Chieh-Yang Huang", "authors": "Chieh-Yang Huang, Yi-Ting Huang, Mei-Hua Chen, and Lun-Wei Ku", "title": "From Receptive to Productive: Learning to Use Confusing Words through\n  Automatically Selected Example Sentences", "comments": "Accepted by BEA 14th", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Knowing how to use words appropriately has been a key to improving language\nproficiency. Previous studies typically discuss how students learn receptively\nto select the correct candidate from a set of confusing words in the\nfill-in-the-blank task where specific context is given. In this paper, we go\none step further, assisting students to learn to use confusing words\nappropriately in a productive task: sentence translation. We leverage the\nGiveMeExample system, which suggests example sentences for each confusing word,\nto achieve this goal. In this study, students learn to differentiate the\nconfusing words by reading the example sentences, and then choose the\nappropriate word(s) to complete the sentence translation task. Results show\nstudents made substantial progress in terms of sentence structure. In addition,\nhighly proficient students better managed to learn confusing words. In view of\nthe influence of the first language on learners, we further propose an\neffective approach to improve the quality of the suggested sentences.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 19:25:30 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Huang", "Chieh-Yang", ""], ["Huang", "Yi-Ting", ""], ["Chen", "Mei-Hua", ""], ["Ku", "Lun-Wei", ""]]}, {"id": "1906.02829", "submitter": "Wei Zhao", "authors": "Wei Zhao, Haiyun Peng, Steffen Eger, Erik Cambria and Min Yang", "title": "Towards Scalable and Reliable Capsule Networks for Challenging NLP\n  Applications", "comments": "11 pages, ACL19 Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obstacles hindering the development of capsule networks for challenging NLP\napplications include poor scalability to large output spaces and less reliable\nrouting processes. In this paper, we introduce: 1) an agreement score to\nevaluate the performance of routing processes at instance level; 2) an adaptive\noptimizer to enhance the reliability of routing; 3) capsule compression and\npartial routing to improve the scalability of capsule networks. We validate our\napproach on two NLP tasks, namely: multi-label text classification and question\nanswering. Experimental results show that our approach considerably improves\nover strong competitors on both tasks. In addition, we gain the best results in\nlow-resource settings with few training instances.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 21:53:53 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Zhao", "Wei", ""], ["Peng", "Haiyun", ""], ["Eger", "Steffen", ""], ["Cambria", "Erik", ""], ["Yang", "Min", ""]]}, {"id": "1906.02850", "submitter": "Charles Chen", "authors": "Charles Chen, Ruiyi Zhang, Eunyee Koh, Sungchul Kim, Scott Cohen, Tong\n  Yu, Ryan Rossi, Razvan Bunescu", "title": "Figure Captioning with Reasoning and Sequence-Level Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Figures, such as bar charts, pie charts, and line plots, are widely used to\nconvey important information in a concise format. They are usually\nhuman-friendly but difficult for computers to process automatically. In this\nwork, we investigate the problem of figure captioning where the goal is to\nautomatically generate a natural language description of the figure. While\nnatural image captioning has been studied extensively, figure captioning has\nreceived relatively little attention and remains a challenging problem. First,\nwe introduce a new dataset for figure captioning, FigCAP, based on FigureQA.\nSecond, we propose two novel attention mechanisms. To achieve accurate\ngeneration of labels in figures, we propose Label Maps Attention. To model the\nrelations between figure labels, we propose Relation Maps Attention. Third, we\nuse sequence-level training with reinforcement learning in order to directly\noptimizes evaluation metrics, which alleviates the exposure bias issue and\nfurther improves the models in generating long captions. Extensive experiments\nshow that the proposed method outperforms the baselines, thus demonstrating a\nsignificant potential for the automatic captioning of vast repositories of\nfigures.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 00:54:53 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Chen", "Charles", ""], ["Zhang", "Ruiyi", ""], ["Koh", "Eunyee", ""], ["Kim", "Sungchul", ""], ["Cohen", "Scott", ""], ["Yu", "Tong", ""], ["Rossi", "Ryan", ""], ["Bunescu", "Razvan", ""]]}, {"id": "1906.02868", "submitter": "Katherine Keith", "authors": "Katherine A. Keith and Amanda Stent", "title": "Modeling financial analysts' decision making via the pragmatics and\n  semantics of earnings calls", "comments": "Accepted at ACL 2019. Revised version includes appendix and NSF\n  funding acknowledgment", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Every fiscal quarter, companies hold earnings calls in which company\nexecutives respond to questions from analysts. After these calls, analysts\noften change their price target recommendations, which are used in equity\nresearch reports to help investors make decisions. In this paper, we examine\nanalysts' decision making behavior as it pertains to the language content of\nearnings calls. We identify a set of 20 pragmatic features of analysts'\nquestions which we correlate with analysts' pre-call investor recommendations.\nWe also analyze the degree to which semantic and pragmatic features from an\nearnings call complement market data in predicting analysts' post-call changes\nin price targets. Our results show that earnings calls are moderately\npredictive of analysts' decisions even though these decisions are influenced by\na number of other factors including private communication with company\nexecutives and market conditions. A breakdown of model errors indicates\ndisparate performance on calls from different market sectors.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 02:30:31 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 17:30:09 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Keith", "Katherine A.", ""], ["Stent", "Amanda", ""]]}, {"id": "1906.02882", "submitter": "Hussein Alrubaye", "authors": "Hussein Alrubaye, Mohamed Wiem Mkaouer, Igor Khokhlov, Leon Reznik,\n  Ali Ouni, Jason Mcgoff", "title": "Learning to Recommend Third-Party Library Migration Opportunities at the\n  API Level", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The manual migration between different third-party libraries represents a\nchallenge for software developers. Developers typically need to explore both\nlibraries Application Programming Interfaces, along with reading their\ndocumentation, in order to locate the suitable mappings between replacing and\nreplaced methods. In this paper, we introduce RAPIM, a novel machine learning\napproach that recommends mappings between methods from two different libraries.\nOur model learns from previous migrations, manually performed in mined software\nsystems, and extracts a set of features related to the similarity between\nmethod signatures and method textual documentation. We evaluate our model using\n8 popular migrations, collected from 57,447 open-source Java projects. Results\nshow that RAPIM is able to recommend relevant library API mappings with an\naverage accuracy score of 87%. Finally, we provide the community with an API\nrecommendation web service that could be used to support the migration process.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 03:20:46 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Alrubaye", "Hussein", ""], ["Mkaouer", "Mohamed Wiem", ""], ["Khokhlov", "Igor", ""], ["Reznik", "Leon", ""], ["Ouni", "Ali", ""], ["Mcgoff", "Jason", ""]]}, {"id": "1906.02890", "submitter": "Haoyue Shi", "authors": "Haoyue Shi, Jiayuan Mao, Kevin Gimpel, Karen Livescu", "title": "Visually Grounded Neural Syntax Acquisition", "comments": "ACL 2019. Project page:\n  https://ttic.uchicago.edu/~freda/project/vgnsl/", "journal-ref": null, "doi": "10.18653/v1/P19-1180", "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Visually Grounded Neural Syntax Learner (VG-NSL), an approach\nfor learning syntactic representations and structures without any explicit\nsupervision. The model learns by looking at natural images and reading paired\ncaptions. VG-NSL generates constituency parse trees of texts, recursively\ncomposes representations for constituents, and matches them with images. We\ndefine concreteness of constituents by their matching scores with images, and\nuse it to guide the parsing of text. Experiments on the MSCOCO data set show\nthat VG-NSL outperforms various unsupervised parsing approaches that do not use\nvisual grounding, in terms of F1 scores against gold parse trees. We find that\nVGNSL is much more stable with respect to the choice of random initialization\nand the amount of training data. We also find that the concreteness acquired by\nVG-NSL correlates well with a similar measure defined by linguists. Finally, we\nalso apply VG-NSL to multiple languages in the Multi30K data set, showing that\nour model consistently outperforms prior unsupervised approaches.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 04:03:53 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 18:29:51 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Shi", "Haoyue", ""], ["Mao", "Jiayuan", ""], ["Gimpel", "Kevin", ""], ["Livescu", "Karen", ""]]}, {"id": "1906.02897", "submitter": "Yitong Li", "authors": "Yitong Li, Timothy Baldwin, Trevor Cohn", "title": "Semi-supervised Stochastic Multi-Domain Learning using Variational\n  Inference", "comments": "ACL 2019 (9 pages + 2 references + 1 appendices)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised models of NLP rely on large collections of text which closely\nresemble the intended testing setting. Unfortunately matching text is often not\navailable in sufficient quantity, and moreover, within any domain of text, data\nis often highly heterogenous. In this paper we propose a method to distill the\nimportant domain signal as part of a multi-domain learning system, using a\nlatent variable model in which parts of a neural model are stochastically gated\nbased on the inferred domain. We compare the use of discrete versus continuous\nlatent variables, operating in a domain-supervised or a domain semi-supervised\nsetting, where the domain is known only for a subset of training inputs. We\nshow that our model leads to substantial performance improvements over\ncompetitive benchmark domain adaptation methods, including methods using\nadversarial learning.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 05:01:47 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Li", "Yitong", ""], ["Baldwin", "Timothy", ""], ["Cohn", "Trevor", ""]]}, {"id": "1906.02900", "submitter": "Sewon Min", "authors": "Sewon Min, Eric Wallace, Sameer Singh, Matt Gardner, Hannaneh\n  Hajishirzi, Luke Zettlemoyer", "title": "Compositional Questions Do Not Necessitate Multi-hop Reasoning", "comments": "Published as a conference paper at ACL 2019 (short). Code available\n  at https://github.com/shmsw25/single-hop-rc", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-hop reading comprehension (RC) questions are challenging because they\nrequire reading and reasoning over multiple paragraphs. We argue that it can be\ndifficult to construct large multi-hop RC datasets. For example, even highly\ncompositional questions can be answered with a single hop if they target\nspecific entity types, or the facts needed to answer them are redundant. Our\nanalysis is centered on HotpotQA, where we show that single-hop reasoning can\nsolve much more of the dataset than previously thought. We introduce a\nsingle-hop BERT-based RC model that achieves 67 F1---comparable to\nstate-of-the-art multi-hop models. We also design an evaluation setting where\nhumans are not shown all of the necessary paragraphs for the intended multi-hop\nreasoning but can still answer over 80% of questions. Together with detailed\nerror analysis, these results suggest there should be an increasing focus on\nthe role of evidence in multi-hop reasoning and possibly even a shift towards\ninformation retrieval style evaluations with large and diverse evidence\ncollections.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 05:10:15 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Min", "Sewon", ""], ["Wallace", "Eric", ""], ["Singh", "Sameer", ""], ["Gardner", "Matt", ""], ["Hajishirzi", "Hannaneh", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1906.02916", "submitter": "Sewon Min", "authors": "Sewon Min, Victor Zhong, Luke Zettlemoyer, Hannaneh Hajishirzi", "title": "Multi-hop Reading Comprehension through Question Decomposition and\n  Rescoring", "comments": "Published as a conference paper at ACL 2019 (long). Code available at\n  https://github.com/shmsw25/DecompRC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-hop Reading Comprehension (RC) requires reasoning and aggregation\nacross several paragraphs. We propose a system for multi-hop RC that decomposes\na compositional question into simpler sub-questions that can be answered by\noff-the-shelf single-hop RC models. Since annotations for such decomposition\nare expensive, we recast sub-question generation as a span prediction problem\nand show that our method, trained using only 400 labeled examples, generates\nsub-questions that are as effective as human-authored sub-questions. We also\nintroduce a new global rescoring approach that considers each decomposition\n(i.e. the sub-questions and their answers) to select the best final answer,\ngreatly improving overall performance. Our experiments on HotpotQA show that\nthis approach achieves the state-of-the-art results, while providing\nexplainable evidence for its decision making in the form of sub-questions.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 06:22:17 GMT"}, {"version": "v2", "created": "Sun, 30 Jun 2019 22:30:19 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Min", "Sewon", ""], ["Zhong", "Victor", ""], ["Zettlemoyer", "Luke", ""], ["Hajishirzi", "Hannaneh", ""]]}, {"id": "1906.02923", "submitter": "Yang Gao", "authors": "Yang Gao, Christian M. Meyer, Iryna Gurevych", "title": "Preference-based Interactive Multi-Document Summarisation", "comments": "Submitted to the special issue on \"Learning from User Interactions\",\n  Information Retrieval Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive NLP is a promising paradigm to close the gap between automatic\nNLP systems and the human upper bound. Preference-based interactive learning\nhas been successfully applied, but the existing methods require several\nthousand interaction rounds even in simulations with perfect user feedback. In\nthis paper, we study preference-based interactive summarisation. To reduce the\nnumber of interaction rounds, we propose the Active Preference-based\nReInforcement Learning (APRIL) framework. APRIL uses Active Learning to query\nthe user, Preference Learning to learn a summary ranking function from the\npreferences, and neural Reinforcement Learning to efficiently search for the\n(near-)optimal summary. Our results show that users can easily provide reliable\npreferences over summaries and that APRIL outperforms the state-of-the-art\npreference-based interactive method in both simulation and real-user\nexperiments.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 06:42:24 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Gao", "Yang", ""], ["Meyer", "Christian M.", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1906.02979", "submitter": "Dominik Schlechtweg", "authors": "Dominik Schlechtweg, Anna H\\\"atty, Marco del Tredici, Sabine Schulte\n  im Walde", "title": "A Wind of Change: Detecting and Evaluating Lexical Semantic Change\n  across Times and Domains", "comments": "ACL 2019, 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We perform an interdisciplinary large-scale evaluation for detecting lexical\nsemantic divergences in a diachronic and in a synchronic task: semantic sense\nchanges across time, and semantic sense changes across domains. Our work\naddresses the superficialness and lack of comparison in assessing models of\ndiachronic lexical change, by bringing together and extending benchmark models\non a common state-of-the-art evaluation task. In addition, we demonstrate that\nthe same evaluation task and modelling approaches can successfully be utilised\nfor the synchronic detection of domain-specific sense divergences in the field\nof term extraction.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 09:19:47 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Schlechtweg", "Dominik", ""], ["H\u00e4tty", "Anna", ""], ["del Tredici", "Marco", ""], ["Walde", "Sabine Schulte im", ""]]}, {"id": "1906.03007", "submitter": "Abhik Jana", "authors": "Abhik Jana, Dmitry Puzyrev, Alexander Panchenko, Pawan Goyal, Chris\n  Biemann and Animesh Mukherjee", "title": "On the Compositionality Prediction of Noun Phrases using Poincar\\'e\n  Embeddings", "comments": "Accepted in ACL 2019 [Long Paper]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The compositionality degree of multiword expressions indicates to what extent\nthe meaning of a phrase can be derived from the meaning of its constituents and\ntheir grammatical relations. Prediction of (non)-compositionality is a task\nthat has been frequently addressed with distributional semantic models. We\nintroduce a novel technique to blend hierarchical information with\ndistributional information for predicting compositionality. In particular, we\nuse hypernymy information of the multiword and its constituents encoded in the\nform of the recently introduced Poincar\\'e embeddings in addition to the\ndistributional information to detect compositionality for noun phrases. Using a\nweighted average of the distributional similarity and a Poincar\\'e similarity\nfunction, we obtain consistent and substantial, statistically significant\nimprovement across three gold standard datasets over state-of-the-art models\nbased on distributional information only. Unlike traditional approaches that\nsolely use an unsupervised setting, we have also framed the problem as a\nsupervised task, obtaining comparable improvements. Further, we publicly\nrelease our Poincar\\'e embeddings, which are trained on the output of\nhandcrafted lexical-syntactic patterns on a large corpus.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 11:05:30 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Jana", "Abhik", ""], ["Puzyrev", "Dmitry", ""], ["Panchenko", "Alexander", ""], ["Goyal", "Pawan", ""], ["Biemann", "Chris", ""], ["Mukherjee", "Animesh", ""]]}, {"id": "1906.03008", "submitter": "Bernhard Kratzwald", "authors": "Bernhard Kratzwald, Anna Eigenmann and Stefan Feuerriegel", "title": "RankQA: Neural Question Answering with Answer Re-Ranking", "comments": "Accepted at ACL 2019; GitHub: https://github.com/bernhard2202/rankqa", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The conventional paradigm in neural question answering (QA) for narrative\ncontent is limited to a two-stage process: first, relevant text passages are\nretrieved and, subsequently, a neural network for machine comprehension\nextracts the likeliest answer. However, both stages are largely isolated in the\nstatus quo and, hence, information from the two phases is never properly fused.\nIn contrast, this work proposes RankQA: RankQA extends the conventional\ntwo-stage process in neural QA with a third stage that performs an additional\nanswer re-ranking. The re-ranking leverages different features that are\ndirectly extracted from the QA pipeline, i.e., a combination of retrieval and\ncomprehension features. While our intentionally simple design allows for an\nefficient, data-sparse estimation, it nevertheless outperforms more complex QA\nsystems by a significant margin: in fact, RankQA achieves state-of-the-art\nperformance on 3 out of 4 benchmark datasets. Furthermore, its performance is\nespecially superior in settings where the size of the corpus is dynamic. Here\nthe answer re-ranking provides an effective remedy against the underlying\nnoise-information trade-off due to a variable corpus size. As a consequence,\nRankQA represents a novel, powerful, and thus challenging baseline for future\nresearch in content-based QA.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 11:06:11 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 09:48:30 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Kratzwald", "Bernhard", ""], ["Eigenmann", "Anna", ""], ["Feuerriegel", "Stefan", ""]]}, {"id": "1906.03072", "submitter": "Stephan Sloth Lorenzen", "authors": "Stephan Lorenzen, Niklas Hjuler, Stephen Alstrup", "title": "Investigating Writing Style Development in High School", "comments": "A short version of this paper will be presented at EDM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we do the first large scale analysis of writing style\ndevelopment among Danish high school students. More than 10K students with more\nthan 100K essays are analyzed. Writing style itself is often studied in the\nnatural language processing community, but usually with the goal of verifying\nauthorship, assessing quality or popularity, or other kinds of predictions.\n  In this work, we analyze writing style changes over time, with the goal of\ndetecting global development trends among students, and identifying at-risk\nstudents. We train a Siamese neural network to compute the similarity between\ntwo texts. Using this similarity measure, a student's newer essays are compared\nto their first essays, and a writing style development profile is constructed\nfor the student. We cluster these student profiles and analyze the resulting\nclusters in order to detect general development patterns. We evaluate clusters\nwith respect to writing style quality indicators, and identify optimal\nclusters, showing significant improvement in writing style, while also\nobserving suboptimal clusters, exhibiting periods of limited development and\neven setbacks.\n  Furthermore, we identify general development trends between high school\nstudents, showing that as students progress through high school, their writing\nstyle deviates, leaving students less similar when they finish high school,\nthan when they start.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 13:20:40 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Lorenzen", "Stephan", ""], ["Hjuler", "Niklas", ""], ["Alstrup", "Stephen", ""]]}, {"id": "1906.03088", "submitter": "Marc H\\\"ubner", "authors": "Christoph Alt, Marc H\\\"ubner, Leonhard Hennig", "title": "Improving Relation Extraction by Pre-trained Language Representations", "comments": "Code and models available at: https://github.com/DFKI-NLP/TRE", "journal-ref": "Proceedings of AKBC 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current state-of-the-art relation extraction methods typically rely on a set\nof lexical, syntactic, and semantic features, explicitly computed in a\npre-processing step. Training feature extraction models requires additional\nannotated language resources, which severely restricts the applicability and\nportability of relation extraction to novel languages. Similarly,\npre-processing introduces an additional source of error. To address these\nlimitations, we introduce TRE, a Transformer for Relation Extraction, extending\nthe OpenAI Generative Pre-trained Transformer [Radford et al., 2018]. Unlike\nprevious relation extraction models, TRE uses pre-trained deep language\nrepresentations instead of explicit linguistic features to inform the relation\nclassification and combines it with the self-attentive Transformer architecture\nto effectively model long-range dependencies between entity mentions. TRE\nallows us to learn implicit linguistic features solely from plain text corpora\nby unsupervised pre-training, before fine-tuning the learned language\nrepresentations on the relation extraction task. TRE obtains a new\nstate-of-the-art result on the TACRED and SemEval 2010 Task 8 datasets,\nachieving a test F1 of 67.4 and 87.1, respectively. Furthermore, we observe a\nsignificant increase in sample efficiency. With only 20% of the training\nexamples, TRE matches the performance of our baselines and our model trained\nfrom scratch on 100% of the TACRED dataset. We open-source our trained models,\nexperiments, and source code.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 13:31:09 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Alt", "Christoph", ""], ["H\u00fcbner", "Marc", ""], ["Hennig", "Leonhard", ""]]}, {"id": "1906.03100", "submitter": "Xuebo Liu", "authors": "Xuebo Liu, Derek F. Wong, Yang Liu, Lidia S. Chao, Tong Xiao, Jingbo\n  Zhu", "title": "Shared-Private Bilingual Word Embeddings for Neural Machine Translation", "comments": "Accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embedding is central to neural machine translation (NMT), which has\nattracted intensive research interest in recent years. In NMT, the source\nembedding plays the role of the entrance while the target embedding acts as the\nterminal. These layers occupy most of the model parameters for representation\nlearning. Furthermore, they indirectly interface via a soft-attention\nmechanism, which makes them comparatively isolated. In this paper, we propose\nshared-private bilingual word embeddings, which give a closer relationship\nbetween the source and target embeddings, and which also reduce the number of\nmodel parameters. For similar source and target words, their embeddings tend to\nshare a part of the features and they cooperatively learn these common\nrepresentation units. Experiments on 5 language pairs belonging to 6 different\nlanguage families and written in 5 different alphabets demonstrate that the\nproposed model provides a significant performance boost over the strong\nbaselines with dramatically fewer model parameters.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 13:48:46 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Liu", "Xuebo", ""], ["Wong", "Derek F.", ""], ["Liu", "Yang", ""], ["Chao", "Lidia S.", ""], ["Xiao", "Tong", ""], ["Zhu", "Jingbo", ""]]}, {"id": "1906.03129", "submitter": "Shahram Khadivi", "authors": "Shen Yan, Leonard Dahlmann, Pavel Petrushkov, Sanjika Hewavitharana,\n  Shahram Khadivi", "title": "Word-based Domain Adaptation for Neural Machine Translation", "comments": "Published on the proceedings of the International Workshop on Spoken\n  Language Translation (IWSLT), 2018", "journal-ref": "Proceedings of the 15th International Workshop on Spoken Language\n  Translation, Bruges, Belgium, October 29-30, 2018", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we empirically investigate applying word-level weights to\nadapt neural machine translation to e-commerce domains, where small e-commerce\ndatasets and large out-of-domain datasets are available. In order to mine\nin-domain like words in the out-of-domain datasets, we compute word weights by\nusing a domain-specific and a non-domain-specific language model followed by\nsmoothing and binary quantization. The baseline model is trained on mixed\nin-domain and out-of-domain datasets. Experimental results on English to\nChinese e-commerce domain translation show that compared to continuing training\nwithout word weights, it improves MT quality by up to 2.11% BLEU absolute and\n1.59% TER. We have also trained models using fine-tuning on the in-domain data.\nPre-training a model with word weights improves fine-tuning up to 1.24% BLEU\nabsolute and 1.64% TER, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 14:32:17 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Yan", "Shen", ""], ["Dahlmann", "Leonard", ""], ["Petrushkov", "Pavel", ""], ["Hewavitharana", "Sanjika", ""], ["Khadivi", "Shahram", ""]]}, {"id": "1906.03134", "submitter": "Tsolak Ghukasyan", "authors": "Karen Avetisyan, Tsolak Ghukasyan", "title": "Word Embeddings for the Armenian Language: Intrinsic and Extrinsic\n  Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we intrinsically and extrinsically evaluate and compare\nexisting word embedding models for the Armenian language. Alongside, new\nembeddings are presented, trained using GloVe, fastText, CBOW, SkipGram\nalgorithms. We adapt and use the word analogy task in intrinsic evaluation of\nembeddings. For extrinsic evaluation, two tasks are employed: morphological\ntagging and text classification. Tagging is performed on a deep neural network,\nusing ArmTDP v2.3 dataset. For text classification, we propose a corpus of news\narticles categorized into 7 classes. The datasets are made public to serve as\nbenchmarks for future models.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 14:45:49 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Avetisyan", "Karen", ""], ["Ghukasyan", "Tsolak", ""]]}, {"id": "1906.03158", "submitter": "Livio Baldini Soares", "authors": "Livio Baldini Soares, Nicholas FitzGerald, Jeffrey Ling, Tom\n  Kwiatkowski", "title": "Matching the Blanks: Distributional Similarity for Relation Learning", "comments": "To appear at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  General purpose relation extractors, which can model arbitrary relations, are\na core aspiration in information extraction. Efforts have been made to build\ngeneral purpose extractors that represent relations with their surface forms,\nor which jointly embed surface forms with relations from an existing knowledge\ngraph. However, both of these approaches are limited in their ability to\ngeneralize. In this paper, we build on extensions of Harris' distributional\nhypothesis to relations, as well as recent advances in learning text\nrepresentations (specifically, BERT), to build task agnostic relation\nrepresentations solely from entity-linked text. We show that these\nrepresentations significantly outperform previous work on exemplar based\nrelation extraction (FewRel) even without using any of that task's training\ndata. We also show that models initialized with our task agnostic\nrepresentations, and then tuned on supervised relation extraction datasets,\nsignificantly outperform the previous methods on SemEval 2010 Task 8, KBP37,\nand TACRED.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 15:26:50 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Soares", "Livio Baldini", ""], ["FitzGerald", "Nicholas", ""], ["Ling", "Jeffrey", ""], ["Kwiatkowski", "Tom", ""]]}, {"id": "1906.03183", "submitter": "Amir Karami", "authors": "Amir Karami, Mehdi Ghasemi, Souvik Sen, Marcos Moraes, Vishal Shah", "title": "Exploring Diseases and Syndromes in Neurology Case Reports from 1955 to\n  2017 with Text Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CL cs.IR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: A large number of neurology case reports have been published, but\nit is a challenging task for human medical experts to explore all of these\npublications. Text mining offers a computational approach to investigate\nneurology literature and capture meaningful patterns. The overarching goal of\nthis study is to provide a new perspective on case reports of neurological\ndisease and syndrome analysis over the last six decades using text mining.\n  Methods: We extracted diseases and syndromes (DsSs) from more than 65,000\nneurology case reports from 66 journals in PubMed over the last six decades\nfrom 1955 to 2017. Text mining was applied to reports on the detected DsSs to\ninvestigate high-frequency DsSs, categorize them, and explore the linear trends\nover the 63-year time frame.\n  Results: The text mining methods explored high-frequency neurologic DsSs and\ntheir trends and the relationships between them from 1955 to 2017. We detected\nmore than 18,000 unique DsSs and found 10 categories of neurologic DsSs. While\nthe trend analysis showed the increasing trends in the case reports for top-10\nhigh-frequency DsSs, the categories had mixed trends.\n  Conclusion: Our study provided new insights into the application of text\nmining methods to investigate DsSs in a large number of medical case reports\nthat occur over several decades. The proposed approach can be used to provide a\nmacro level analysis of medical literature by discovering interesting patterns\nand tracking them over several years to help physicians explore these case\nreports more efficiently.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 17:38:06 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Karami", "Amir", ""], ["Ghasemi", "Mehdi", ""], ["Sen", "Souvik", ""], ["Moraes", "Marcos", ""], ["Shah", "Vishal", ""]]}, {"id": "1906.03209", "submitter": "Kyle Swanson", "authors": "Kyle Swanson, Lili Yu, Christopher Fox, Jeremy Wohlwend, Tao Lei", "title": "Building a Production Model for Retrieval-Based Chatbots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Response suggestion is an important task for building human-computer\nconversation systems. Recent approaches to conversation modeling have\nintroduced new model architectures with impressive results, but relatively\nlittle attention has been paid to whether these models would be practical in a\nproduction setting. In this paper, we describe the unique challenges of\nbuilding a production retrieval-based conversation system, which selects\noutputs from a whitelist of candidate responses. To address these challenges,\nwe propose a dual encoder architecture which performs rapid inference and\nscales well with the size of the whitelist. We also introduce and compare two\nmethods for generating whitelists, and we carry out a comprehensive analysis of\nthe model and whitelists. Experimental results on a large, proprietary help\ndesk chat dataset, including both offline metrics and a human evaluation,\nindicate production-quality performance and illustrate key lessons about\nconversation modeling in practice.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 16:17:31 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2019 18:50:15 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Swanson", "Kyle", ""], ["Yu", "Lili", ""], ["Fox", "Christopher", ""], ["Wohlwend", "Jeremy", ""], ["Lei", "Tao", ""]]}, {"id": "1906.03221", "submitter": "Ratish Puduppully", "authors": "Ratish Puduppully and Li Dong and Mirella Lapata", "title": "Data-to-text Generation with Entity Modeling", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent approaches to data-to-text generation have shown great promise thanks\nto the use of large-scale datasets and the application of neural network\narchitectures which are trained end-to-end. These models rely on representation\nlearning to select content appropriately, structure it coherently, and\nverbalize it grammatically, treating entities as nothing more than vocabulary\ntokens. In this work we propose an entity-centric neural architecture for\ndata-to-text generation. Our model creates entity-specific representations\nwhich are dynamically updated. Text is generated conditioned on the data input\nand entity memory representations using hierarchical attention at each time\nstep. We present experiments on the RotoWire benchmark and a (five times\nlarger) new dataset on the baseball domain which we create. Our results show\nthat the proposed model outperforms competitive baselines in automatic and\nhuman evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 16:41:52 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Puduppully", "Ratish", ""], ["Dong", "Li", ""], ["Lapata", "Mirella", ""]]}, {"id": "1906.03249", "submitter": "Guoyin Wang", "authors": "Guoyin Wang, Yan Song, Yue Zhang, Dong Yu", "title": "Learning Word Embeddings with Domain Awareness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings are traditionally trained on a large corpus in an\nunsupervised setting, with no specific design for incorporating domain\nknowledge. This can lead to unsatisfactory performances when training data\noriginate from heterogeneous domains. In this paper, we propose two novel\nmechanisms for domain-aware word embedding training, namely domain indicator\nand domain attention, which integrate domain-specific knowledge into the widely\nused SG and CBOW models, respectively. The two methods are based on a joint\nlearning paradigm and ensure that words in a target domain are intensively\nfocused when trained on a source domain corpus. Qualitative and quantitative\nevaluation confirm the validity and effectiveness of our models. Compared to\nbaseline methods, our method is particularly effective in near-cold-start\nscenarios.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 17:29:18 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 18:37:59 GMT"}, {"version": "v3", "created": "Fri, 21 Jun 2019 03:43:12 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Wang", "Guoyin", ""], ["Song", "Yan", ""], ["Zhang", "Yue", ""], ["Yu", "Dong", ""]]}, {"id": "1906.03293", "submitter": "Dieuwke Hupkes", "authors": "Dennis Ulmer, Dieuwke Hupkes and Elia Bruni", "title": "Assessing incrementality in sequence-to-sequence models", "comments": "Accepted at Repl4NLP, ACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since their inception, encoder-decoder models have successfully been applied\nto a wide array of problems in computational linguistics. The most recent\nsuccesses are predominantly due to the use of different variations of attention\nmechanisms, but their cognitive plausibility is questionable. In particular,\nbecause past representations can be revisited at any point in time,\nattention-centric methods seem to lack an incentive to build up incrementally\nmore informative representations of incoming sentences. This way of processing\nstands in stark contrast with the way in which humans are believed to process\nlanguage: continuously and rapidly integrating new information as it is\nencountered. In this work, we propose three novel metrics to assess the\nbehavior of RNNs with and without an attention mechanism and identify key\ndifferences in the way the different model types process sentences.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 18:45:51 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Ulmer", "Dennis", ""], ["Hupkes", "Dieuwke", ""], ["Bruni", "Elia", ""]]}, {"id": "1906.03338", "submitter": "Juri Opitz", "authors": "Juri Opitz and Anette Frank", "title": "Dissecting Content and Context in Argumentative Relation Analysis", "comments": "accepted at 6th Workshop on Argument Mining", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When assessing relations between argumentative units (e.g., support or\nattack), computational systems often exploit disclosing indicators or markers\nthat are not part of elementary argumentative units (EAUs) themselves, but are\ngained from their context (position in paragraph, preceding tokens, etc.). We\nshow that this dependency is much stronger than previously assumed. In fact, we\nshow that by completely masking the EAU text spans and only feeding information\nfrom their context, a competitive system may function even better. We argue\nthat an argument analysis system that relies more on discourse context than the\nargument's content is unsafe, since it can easily be tricked. To alleviate this\nissue, we separate argumentative units from their context such that the system\nis forced to model and rely on an EAU's content. We show that the resulting\nclassification system is more robust, and argue that such models are better\nsuited for predicting argumentative relations across documents.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 21:36:49 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Opitz", "Juri", ""], ["Frank", "Anette", ""]]}, {"id": "1906.03348", "submitter": "Denis Newman-Griffis", "authors": "Denis Newman-Griffis, Ayah Zirikly, Guy Divita, Bart Desmet", "title": "Classifying the reported ability in clinical mobility descriptions", "comments": "Appearing in BioNLP 2019. 10 pages; 6 tables, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assessing how individuals perform different activities is key information for\nmodeling health states of individuals and populations. Descriptions of activity\nperformance in clinical free text are complex, including syntactic negation and\nsimilarities to textual entailment tasks. We explore a variety of methods for\nthe novel task of classifying four types of assertions about activity\nperformance: Able, Unable, Unclear, and None (no information). We find that\nensembling an SVM trained with lexical features and a CNN achieves 77.9% macro\nF1 score on our task, and yields nearly 80% recall on the rare Unclear and\nUnable samples. Finally, we highlight several challenges in classifying\nperformance assertions, including capturing information about sources of\nassistance, incorporating syntactic structure and negation scope, and handling\nnew modalities at test time. Our findings establish a strong baseline for this\nnovel task, and identify intriguing areas for further research.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 22:26:29 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Newman-Griffis", "Denis", ""], ["Zirikly", "Ayah", ""], ["Divita", "Guy", ""], ["Desmet", "Bart", ""]]}, {"id": "1906.03351", "submitter": "Marc'Aurelio Ranzato", "authors": "Anton Bakhtin, Sam Gross, Myle Ott, Yuntian Deng, Marc'Aurelio\n  Ranzato, Arthur Szlam", "title": "Real or Fake? Learning to Discriminate Machine from Human Generated Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy-based models (EBMs), a.k.a. un-normalized models, have had recent\nsuccesses in continuous spaces. However, they have not been successfully\napplied to model text sequences. While decreasing the energy at training\nsamples is straightforward, mining (negative) samples where the energy should\nbe increased is difficult. In part, this is because standard gradient-based\nmethods are not readily applicable when the input is high-dimensional and\ndiscrete. Here, we side-step this issue by generating negatives using\npre-trained auto-regressive language models. The EBM then works in the residual\nof the language model; and is trained to discriminate real text from text\ngenerated by the auto-regressive models. We investigate the generalization\nability of residual EBMs, a pre-requisite for using them in other applications.\nWe extensively analyze generalization for the task of classifying whether an\ninput is machine or human generated, a natural task given the training loss and\nhow we mine negatives. Overall, we observe that EBMs can generalize remarkably\nwell to changes in the architecture of the generators producing negatives.\nHowever, EBMs exhibit more sensitivity to the training set used by such\ngenerators.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 22:45:33 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 16:21:00 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Bakhtin", "Anton", ""], ["Gross", "Sam", ""], ["Ott", "Myle", ""], ["Deng", "Yuntian", ""], ["Ranzato", "Marc'Aurelio", ""], ["Szlam", "Arthur", ""]]}, {"id": "1906.03360", "submitter": "Qiao Jin", "authors": "Qiao Jin, Jinling Liu, Xinghua Lu", "title": "Deep Contextualized Biomedical Abbreviation Expansion", "comments": "BioNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic identification and expansion of ambiguous abbreviations are\nessential for biomedical natural language processing applications, such as\ninformation retrieval and question answering systems. In this paper, we present\nDEep Contextualized Biomedical. Abbreviation Expansion (DECBAE) model. DECBAE\nautomatically collects substantial and relatively clean annotated contexts for\n950 ambiguous abbreviations from PubMed abstracts using a simple heuristic.\nThen it utilizes BioELMo to extract the contextualized features of words, and\nfeed those features to abbreviation-specific bidirectional LSTMs, where the\nhidden states of the ambiguous abbreviations are used to assign the exact\ndefinitions. Our DECBAE model outperforms other baselines by large margins,\nachieving average accuracy of 0.961 and macro-F1 of 0.917 on the dataset. It\nalso surpasses human performance for expanding a sample abbreviation, and\nremains robust in imbalanced, low-resources and clinical settings.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 00:01:08 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Jin", "Qiao", ""], ["Liu", "Jinling", ""], ["Lu", "Xinghua", ""]]}, {"id": "1906.03380", "submitter": "Sarah Wiegreffe", "authors": "Sarah Wiegreffe, Edward Choi, Sherry Yan, Jimeng Sun, Jacob Eisenstein", "title": "Clinical Concept Extraction for Document-Level Coding", "comments": "ACL BioNLP workshop (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The text of clinical notes can be a valuable source of patient information\nand clinical assessments. Historically, the primary approach for exploiting\nclinical notes has been information extraction: linking spans of text to\nconcepts in a detailed domain ontology. However, recent work has demonstrated\nthe potential of supervised machine learning to extract document-level codes\ndirectly from the raw text of clinical notes. We propose to bridge the gap\nbetween the two approaches with two novel syntheses: (1) treating extracted\nconcepts as features, which are used to supplement or replace the text of the\nnote; (2) treating extracted concepts as labels, which are used to learn a\nbetter representation of the text. Unfortunately, the resulting concepts do not\nyield performance gains on the document-level clinical coding task. We explore\npossible explanations and future research directions.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 03:32:00 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Wiegreffe", "Sarah", ""], ["Choi", "Edward", ""], ["Yan", "Sherry", ""], ["Sun", "Jimeng", ""], ["Eisenstein", "Jacob", ""]]}, {"id": "1906.03392", "submitter": "Trung Hieu Tran", "authors": "Hieu Tran, Maxim Shcherbakov", "title": "Detection and Prediction of Users Attitude Based on Real-Time and Batch\n  Sentiment Analysis of Facebook Comments", "comments": "12 pages, 6 figures, CSoNet 2016", "journal-ref": null, "doi": "10.1007/978-3-319-42345-6_24", "report-no": null, "categories": "cs.SI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most of the people have their account on social networks (e.g. Facebook,\nVkontakte) where they express their attitude to different situations and\nevents. Facebook provides only the positive mark as a like button and share.\nHowever, it is important to know the position of a certain user on posts even\nthough the opinion is negative. Positive, negative and neutral attitude can be\nextracted from the comments of users. Overall information about positive,\nnegative and neutral opinion can bring the understanding of how people react in\na position. Moreover, it is important to know how attitude is changing during\nthe time period. The contribution of the paper is a new method based on\nsentiment text analysis for detection and prediction negative and positive\npatterns for Facebook comments which combines (i) real-time sentiment text\nanalysis for pattern discovery and (ii) batch data processing for creating\nopinion forecasting algorithm. To perform forecast we propose two-steps\nalgorithm where: (i) patterns are clustered using unsupervised clustering\ntechniques and (ii) trend prediction is performed based on finding the nearest\npattern from the certain cluster. Case studies show the efficiency and accuracy\n(Avg. MAE = 0.008) of the proposed method and its practical applicability.\nAlso, we discovered three types of users attitude patterns and described them.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 05:10:28 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Tran", "Hieu", ""], ["Shcherbakov", "Maxim", ""]]}, {"id": "1906.03402", "submitter": "Eric Battenberg", "authors": "Eric Battenberg, Soroosh Mariooryad, Daisy Stanton, RJ Skerry-Ryan,\n  Matt Shannon, David Kao, Tom Bagby", "title": "Effective Use of Variational Embedding Capacity in Expressive End-to-End\n  Speech Synthesis", "comments": "Submitted to ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has explored sequence-to-sequence latent variable models for\nexpressive speech synthesis (supporting control and transfer of prosody and\nstyle), but has not presented a coherent framework for understanding the\ntrade-offs between the competing methods. In this paper, we propose embedding\ncapacity (the amount of information the embedding contains about the data) as a\nunified method of analyzing the behavior of latent variable models of speech,\ncomparing existing heuristic (non-variational) methods to variational methods\nthat are able to explicitly constrain capacity using an upper bound on\nrepresentational mutual information. In our proposed model (Capacitron), we\nshow that by adding conditional dependencies to the variational posterior such\nthat it matches the form of the true posterior, the same model can be used for\nhigh-precision prosody transfer, text-agnostic style transfer, and generation\nof natural-sounding prior samples. For multi-speaker models, Capacitron is able\nto preserve target speaker identity during inter-speaker prosody transfer and\nwhen drawing samples from the latent prior. Lastly, we introduce a method for\ndecomposing embedding capacity hierarchically across two sets of latents,\nallowing a portion of the latent variability to be specified and the remaining\nvariability sampled from a learned prior. Audio examples are available on the\nweb.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 06:59:56 GMT"}, {"version": "v2", "created": "Tue, 9 Jul 2019 00:02:06 GMT"}, {"version": "v3", "created": "Fri, 25 Oct 2019 23:53:38 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Battenberg", "Eric", ""], ["Mariooryad", "Soroosh", ""], ["Stanton", "Daisy", ""], ["Skerry-Ryan", "RJ", ""], ["Shannon", "Matt", ""], ["Kao", "David", ""], ["Bagby", "Tom", ""]]}, {"id": "1906.03423", "submitter": "Maryam Ramezani", "authors": "Maryam Ramezani, Mina Rafiei, Soroush Omranpour, and Hamid R. Rabiee", "title": "News Labeling as Early as Possible: Real or Fake?", "comments": null, "journal-ref": null, "doi": "10.1145/3341161.3342957", "report-no": null, "categories": "cs.SI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making disguise between real and fake news propagation through online social\nnetworks is an important issue in many applications. The time gap between the\nnews release time and detection of its label is a significant step towards\nbroadcasting the real information and avoiding the fake. Therefore, one of the\nchallenging tasks in this area is to identify fake and real news in early\nstages of propagation. However, there is a trade-off between minimizing the\ntime gap and maximizing accuracy. Despite recent efforts in detection of fake\nnews, there has been no significant work that explicitly incorporates early\ndetection in its model. In this paper, we focus on accurate early labeling of\nnews, and propose a model by considering earliness both in modeling and\nprediction. The proposed method utilizes recurrent neural networks with a novel\nloss function, and a new stopping rule. Given the context of news, we first\nembed it with a class-specific text representation. Then, we utilize the\navailable public profile of users, and speed of news diffusion, for early\nlabeling of the news. Experiments on real datasets demonstrate the\neffectiveness of our model both in terms of early labelling and accuracy,\ncompared to the state of the art baseline and models.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 08:56:02 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Ramezani", "Maryam", ""], ["Rafiei", "Mina", ""], ["Omranpour", "Soroush", ""], ["Rabiee", "Hamid R.", ""]]}, {"id": "1906.03492", "submitter": "Rui Zhang", "authors": "Rui Zhang, Caitlin Westerfield, Sungrok Shim, Garrett Bingham,\n  Alexander Fabbri, Neha Verma, William Hu, Dragomir Radev", "title": "Improving Low-Resource Cross-lingual Document Retrieval by Reranking\n  with Deep Bilingual Representations", "comments": "ACL 2019, short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose to boost low-resource cross-lingual document\nretrieval performance with deep bilingual query-document representations. We\nmatch queries and documents in both source and target languages with four\ncomponents, each of which is implemented as a term interaction-based deep\nneural network with cross-lingual word embeddings as input. By including query\nlikelihood scores as extra features, our model effectively learns to rerank the\nretrieved documents by using a small number of relevance labels for\nlow-resource language pairs. Due to the shared cross-lingual word embedding\nspace, the model can also be directly applied to another language pair without\nany training label. Experimental results on the MATERIAL dataset show that our\nmodel outperforms the competitive translation-based baselines on\nEnglish-Swahili, English-Tagalog, and English-Somali cross-lingual information\nretrieval tasks.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 17:40:33 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Zhang", "Rui", ""], ["Westerfield", "Caitlin", ""], ["Shim", "Sungrok", ""], ["Bingham", "Garrett", ""], ["Fabbri", "Alexander", ""], ["Verma", "Neha", ""], ["Hu", "William", ""], ["Radev", "Dragomir", ""]]}, {"id": "1906.03496", "submitter": "Alham Fikri Aji", "authors": "Alham Fikri Aji, Kenneth Heafield", "title": "Making Asynchronous Stochastic Gradient Descent Work for Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asynchronous stochastic gradient descent (SGD) is attractive from a speed\nperspective because workers do not wait for synchronization. However, the\nTransformer model converges poorly with asynchronous SGD, resulting in\nsubstantially lower quality compared to synchronous SGD. To investigate why\nthis is the case, we isolate differences between asynchronous and synchronous\nmethods to investigate batch size and staleness effects. We find that summing\nseveral asynchronous updates, rather than applying them immediately, restores\nconvergence behavior. With this hybrid method, Transformer training for neural\nmachine translation task reaches a near-convergence level 1.36x faster in\nsingle-node multi-GPU training with no impact on model quality.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 18:19:50 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Aji", "Alham Fikri", ""], ["Heafield", "Kenneth", ""]]}, {"id": "1906.03497", "submitter": "Rui Zhang", "authors": "Rui Zhang, Joel Tetreault", "title": "This Email Could Save Your Life: Introducing the Task of Email Subject\n  Line Generation", "comments": "ACL 2019, long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the overwhelming number of emails, an effective subject line becomes\nessential to better inform the recipient of the email's content. In this paper,\nwe propose and study the task of email subject line generation: automatically\ngenerating an email subject line from the email body. We create the first\ndataset for this task and find that email subject line generation favor\nextremely abstractive summary which differentiates it from news headline\ngeneration or news single document summarization. We then develop a novel deep\nlearning method and compare it to several baselines as well as recent\nstate-of-the-art text summarization systems. We also investigate the efficacy\nof several automatic metrics based on correlations with human judgments and\npropose a new automatic evaluation metric. Our system outperforms competitive\nbaselines given both automatic and human evaluations. To our knowledge, this is\nthe first work to tackle the problem of effective email subject line\ngeneration.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 18:31:33 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Zhang", "Rui", ""], ["Tetreault", "Joel", ""]]}, {"id": "1906.03506", "submitter": "Hao Wang", "authors": "Hao Wang, Bing Liu, Shuai Wang, Nianzu Ma, Yan Yang", "title": "Forward and Backward Knowledge Transfer for Sentiment Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of learning a sequence of sentiment\nclassification tasks. The learned knowledge from each task is retained and used\nto help future or subsequent task learning. This learning paradigm is called\nLifelong Learning (LL). However, existing LL methods either only transfer\nknowledge forward to help future learning and do not go back to improve the\nmodel of a previous task or require the training data of the previous task to\nretrain its model to exploit backward/reverse knowledge transfer. This paper\nstudies reverse knowledge transfer of LL in the context of naive Bayesian (NB)\nclassification. It aims to improve the model of a previous task by leveraging\nfuture knowledge without retraining using its training data. This is done by\nexploiting a key characteristic of the generative model of NB. That is, it is\npossible to improve the NB classifier for a task by improving its model\nparameters directly by using the retained knowledge from other tasks.\nExperimental results show that the proposed method markedly outperforms\nexisting LL baselines.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 19:18:18 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Wang", "Hao", ""], ["Liu", "Bing", ""], ["Wang", "Shuai", ""], ["Ma", "Nianzu", ""], ["Yang", "Yan", ""]]}, {"id": "1906.03508", "submitter": "Hao Zheng", "authors": "Hao Zheng and Mirella Lapata", "title": "Sentence Centrality Revisited for Unsupervised Summarization", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single document summarization has enjoyed renewed interests in recent years\nthanks to the popularity of neural network models and the availability of\nlarge-scale datasets. In this paper we develop an unsupervised approach arguing\nthat it is unrealistic to expect large-scale and high-quality training data to\nbe available or created for different types of summaries, domains, or\nlanguages. We revisit a popular graph-based ranking algorithm and modify how\nnode (aka sentence) centrality is computed in two ways: (a)~we employ BERT, a\nstate-of-the-art neural representation learning model to better capture\nsentential meaning and (b)~we build graphs with directed edges arguing that the\ncontribution of any two nodes to their respective centrality is influenced by\ntheir relative position in a document. Experimental results on three news\nsummarization datasets representative of different languages and writing styles\nshow that our approach outperforms strong baselines by a wide margin.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 19:27:31 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Zheng", "Hao", ""], ["Lapata", "Mirella", ""]]}, {"id": "1906.03520", "submitter": "Kun Qian", "authors": "Kun Qian, Zhou Yu", "title": "Domain Adaptive Dialog Generation via Meta Learning", "comments": "Accepted as a long paper in ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation is an essential task in dialog system building because\nthere are so many new dialog tasks created for different needs every day.\nCollecting and annotating training data for these new tasks is costly since it\ninvolves real user interactions. We propose a domain adaptive dialog generation\nmethod based on meta-learning (DAML). DAML is an end-to-end trainable dialog\nsystem model that learns from multiple rich-resource tasks and then adapts to\nnew domains with minimal training samples. We train a dialog system model using\nmultiple rich-resource single-domain dialog data by applying the model-agnostic\nmeta-learning algorithm to dialog domain. The model is capable of learning a\ncompetitive dialog system on a new domain with only a few training examples in\nan efficient manner. The two-step gradient updates in DAML enable the model to\nlearn general features across multiple tasks. We evaluate our method on a\nsimulated dialog dataset and achieve state-of-the-art performance, which is\ngeneralizable to new tasks.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 20:54:02 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2019 22:17:35 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Qian", "Kun", ""], ["Yu", "Zhou", ""]]}, {"id": "1906.03538", "submitter": "Sihao Chen", "authors": "Sihao Chen and Daniel Khashabi and Wenpeng Yin and Chris\n  Callison-Burch and Dan Roth", "title": "Seeing Things from a Different Angle: Discovering Diverse Perspectives\n  about Claims", "comments": "In Proceedings of the 2019 Annual Conference of the North American\n  Chapter of the Association for Computational Linguistics (NAACL 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  One key consequence of the information revolution is a significant increase\nand a contamination of our information supply. The practice of fact checking\nwon't suffice to eliminate the biases in text data we observe, as the degree of\nfactuality alone does not determine whether biases exist in the spectrum of\nopinions visible to us. To better understand controversial issues, one needs to\nview them from a diverse yet comprehensive set of perspectives. For example,\nthere are many ways to respond to a claim such as \"animals should have lawful\nrights\", and these responses form a spectrum of perspectives, each with a\nstance relative to this claim and, ideally, with evidence supporting it.\nInherently, this is a natural language understanding task, and we propose to\naddress it as such. Specifically, we propose the task of substantiated\nperspective discovery where, given a claim, a system is expected to discover a\ndiverse set of well-corroborated perspectives that take a stance with respect\nto the claim. Each perspective should be substantiated by evidence paragraphs\nwhich summarize pertinent results and facts. We construct PERSPECTRUM, a\ndataset of claims, perspectives and evidence, making use of online debate\nwebsites to create the initial data collection, and augmenting it using search\nengines in order to expand and diversify our dataset. We use crowd-sourcing to\nfilter out noise and ensure high-quality data. Our dataset contains 1k claims,\naccompanied with pools of 10k and 8k perspective sentences and evidence\nparagraphs, respectively. We provide a thorough analysis of the dataset to\nhighlight key underlying language understanding challenges, and show that human\nbaselines across multiple subtasks far outperform ma-chine baselines built upon\nstate-of-the-art NLP techniques. This poses a challenge and opportunity for the\nNLP community to address.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 23:18:07 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Chen", "Sihao", ""], ["Khashabi", "Daniel", ""], ["Yin", "Wenpeng", ""], ["Callison-Burch", "Chris", ""], ["Roth", "Dan", ""]]}, {"id": "1906.03588", "submitter": "Achintya Sarkar", "authors": "Zheng-Hua Tan, Achintya kr. Sarkar, Najim Dehak", "title": "rVAD: An Unsupervised Segment-Based Robust Voice Activity Detection\n  Method", "comments": "Paper is to appear in CSL", "journal-ref": "Computer Speech & Language, volume 59, January 2020, Pages 1-21", "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an unsupervised segment-based method for robust voice\nactivity detection (rVAD). The method consists of two passes of denoising\nfollowed by a voice activity detection (VAD) stage. In the first pass,\nhigh-energy segments in a speech signal are detected by using a posteriori\nsignal-to-noise ratio (SNR) weighted energy difference and if no pitch is\ndetected within a segment, the segment is considered as a high-energy noise\nsegment and set to zero. In the second pass, the speech signal is denoised by a\nspeech enhancement method, for which several methods are explored. Next,\nneighbouring frames with pitch are grouped together to form pitch segments, and\nbased on speech statistics, the pitch segments are further extended from both\nends in order to include both voiced and unvoiced sounds and likely non-speech\nparts as well. In the end, a posteriori SNR weighted energy difference is\napplied to the extended pitch segments of the denoised speech signal for\ndetecting voice activity. We evaluate the VAD performance of the proposed\nmethod using two databases, RATS and Aurora-2, which contain a large variety of\nnoise conditions. The rVAD method is further evaluated, in terms of speaker\nverification performance, on the RedDots 2016 challenge database and its\nnoise-corrupted versions. Experiment results show that rVAD is compared\nfavourably with a number of existing methods. In addition, we present a\nmodified version of rVAD where computationally intensive pitch extraction is\nreplaced by computationally efficient spectral flatness calculation. The\nmodified version significantly reduces the computational complexity at the cost\nof moderately inferior VAD performance, which is an advantage when processing a\nlarge amount of data and running on low resource devices. The source code of\nrVAD is made publicly available.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 07:51:23 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Tan", "Zheng-Hua", ""], ["Sarkar", "Achintya kr.", ""], ["Dehak", "Najim", ""]]}, {"id": "1906.03591", "submitter": "Kun Jing", "authors": "Kun Jing and Jungang Xu", "title": "A Survey on Neural Network Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the core component of Natural Language Processing (NLP) system, Language\nModel (LM) can provide word representation and probability indication of word\nsequences. Neural Network Language Models (NNLMs) overcome the curse of\ndimensionality and improve the performance of traditional LMs. A survey on\nNNLMs is performed in this paper. The structure of classic NNLMs is described\nfirstly, and then some major improvements are introduced and analyzed. We\nsummarize and compare corpora and toolkits of NNLMs. Further, some research\ndirections of NNLMs are discussed.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 08:15:53 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 01:49:23 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Jing", "Kun", ""], ["Xu", "Jungang", ""]]}, {"id": "1906.03608", "submitter": "Yadollah Yaghoobzadeh", "authors": "Yadollah Yaghoobzadeh, Katharina Kann, Timothy J. Hazen, Eneko Agirre\n  and Hinrich Sch\\\"utze", "title": "Probing for Semantic Classes: Diagnosing the Meaning Content of Word\n  Embeddings", "comments": "14 pages, Accepted at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings typically represent different meanings of a word in a single\nconflated vector. Empirical analysis of embeddings of ambiguous words is\ncurrently limited by the small size of manually annotated resources and by the\nfact that word senses are treated as unrelated individual concepts. We present\na large dataset based on manual Wikipedia annotations and word senses, where\nword senses from different words are related by semantic classes. This is the\nbasis for novel diagnostic tests for an embedding's content: we probe word\nembeddings for semantic classes and analyze the embedding space by classifying\nembeddings into semantic classes. Our main findings are: (i) Information about\na sense is generally represented well in a single-vector embedding - if the\nsense is frequent. (ii) A classifier can accurately predict whether a word is\nsingle-sense or multi-sense, based only on its embedding. (iii) Although rare\nsenses are not well represented in single-vector embeddings, this does not have\nnegative impact on an NLP application whose performance depends on frequent\nsenses.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 09:45:24 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Yaghoobzadeh", "Yadollah", ""], ["Kann", "Katharina", ""], ["Hazen", "Timothy J.", ""], ["Agirre", "Eneko", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1906.03634", "submitter": "Prajit Dhar", "authors": "Prajit Dhar and Lonneke van der Plas", "title": "Learning to Predict Novel Noun-Noun Compounds", "comments": "9 pages, 3 figures, To appear at Joint Workshop on Multiword\n  Expressions and WordNet (MWE-WN 2019) at ACL 2019. V3 - Fixed some typos and\n  updated the Data Preprocessing section", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce temporally and contextually-aware models for the novel task of\npredicting unseen but plausible concepts, as conveyed by noun-noun compounds in\na time-stamped corpus. We train compositional models on observed compounds,\nmore specifically the composed distributed representations of their\nconstituents across a time-stamped corpus, while giving it corrupted instances\n(where head or modifier are replaced by a random constituent) as negative\nevidence. The model captures generalisations over this data and learns what\ncombinations give rise to plausible compounds and which ones do not. After\ntraining, we query the model for the plausibility of automatically generated\nnovel combinations and verify whether the classifications are accurate. For our\nbest model, we find that in around 85% of the cases, the novel compounds\ngenerated are attested in previously unseen data. An additional estimated 5%\nare plausible despite not being attested in the recent corpus, based on\njudgments from independent human raters.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 13:12:45 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 05:06:47 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Dhar", "Prajit", ""], ["van der Plas", "Lonneke", ""]]}, {"id": "1906.03648", "submitter": "Mirac Suzgun", "authors": "Mirac Suzgun, Sebastian Gehrmann, Yonatan Belinkov, Stuart M. Shieber", "title": "LSTM Networks Can Perform Dynamic Counting", "comments": "ACL 2019 Workshop on Deep Learning and Formal Languages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.FL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we systematically assess the ability of standard recurrent\nnetworks to perform dynamic counting and to encode hierarchical\nrepresentations. All the neural models in our experiments are designed to be\nsmall-sized networks both to prevent them from memorizing the training sets and\nto visualize and interpret their behaviour at test time. Our results\ndemonstrate that the Long Short-Term Memory (LSTM) networks can learn to\nrecognize the well-balanced parenthesis language (Dyck-$1$) and the shuffles of\nmultiple Dyck-$1$ languages, each defined over different parenthesis-pairs, by\nemulating simple real-time $k$-counter machines. To the best of our knowledge,\nthis work is the first study to introduce the shuffle languages to analyze the\ncomputational power of neural networks. We also show that a single-layer LSTM\nwith only one hidden unit is practically sufficient for recognizing the\nDyck-$1$ language. However, none of our recurrent networks was able to yield a\ngood performance on the Dyck-$2$ language learning task, which requires a model\nto have a stack-like mechanism for recognition.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 14:30:00 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Suzgun", "Mirac", ""], ["Gehrmann", "Sebastian", ""], ["Belinkov", "Yonatan", ""], ["Shieber", "Stuart M.", ""]]}, {"id": "1906.03656", "submitter": "Tu Vu", "authors": "Tu Vu and Mohit Iyyer", "title": "Encouraging Paragraph Embeddings to Remember Sentence Identity Improves\n  Classification", "comments": "Accepted as a conference paper at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While paragraph embedding models are remarkably effective for downstream\nclassification tasks, what they learn and encode into a single vector remains\nopaque. In this paper, we investigate a state-of-the-art paragraph embedding\nmethod proposed by Zhang et al. (2017) and discover that it cannot reliably\ntell whether a given sentence occurs in the input paragraph or not. We\nformulate a sentence content task to probe for this basic linguistic property\nand find that even a much simpler bag-of-words method has no trouble solving\nit. This result motivates us to replace the reconstruction-based objective of\nZhang et al. (2017) with our sentence content probe objective in a\nsemi-supervised setting. Despite its simplicity, our objective improves over\nparagraph reconstruction in terms of (1) downstream classification accuracies\non benchmark datasets, (2) faster training, and (3) better generalization\nability.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 15:18:53 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Vu", "Tu", ""], ["Iyyer", "Mohit", ""]]}, {"id": "1906.03672", "submitter": "Daniel Khashabi Mr.", "authors": "Daniel Khashabi, Tushar Khot, Ashish Sabharwal, Dan Roth", "title": "Question Answering as Global Reasoning over Semantic Abstractions", "comments": "Appeared in AAAI'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method for exploiting the semantic structure of text to\nanswer multiple-choice questions. The approach is especially suitable for\ndomains that require reasoning over a diverse set of linguistic constructs but\nhave limited training data. To address these challenges, we present the first\nsystem, to the best of our knowledge, that reasons over a wide range of\nsemantic abstractions of the text, which are derived using off-the-shelf,\ngeneral-purpose, pre-trained natural language modules such as semantic role\nlabelers, coreference resolvers, and dependency parsers. Representing multiple\nabstractions as a family of graphs, we translate question answering (QA) into a\nsearch for an optimal subgraph that satisfies certain global and local\nproperties. This formulation generalizes several prior structured QA systems.\nOur system, SEMANTICILP, demonstrates strong performance on two domains\nsimultaneously. In particular, on a collection of challenging science QA\ndatasets, it outperforms various state-of-the-art approaches, including neural\nmodels, broad coverage information retrieval, and specialized techniques using\nstructured knowledge bases, by 2%-6%.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 16:56:31 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Khashabi", "Daniel", ""], ["Khot", "Tushar", ""], ["Sabharwal", "Ashish", ""], ["Roth", "Dan", ""]]}, {"id": "1906.03674", "submitter": "Katerina Margatina", "authors": "Katerina Margatina, Christos Baziotis, Alexandros Potamianos", "title": "Attention-based Conditioning Methods for External Knowledge Integration", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel approach for incorporating external\nknowledge in Recurrent Neural Networks (RNNs). We propose the integration of\nlexicon features into the self-attention mechanism of RNN-based architectures.\nThis form of conditioning on the attention distribution, enforces the\ncontribution of the most salient words for the task at hand. We introduce three\nmethods, namely attentional concatenation, feature-based gating and affine\ntransformation. Experiments on six benchmark datasets show the effectiveness of\nour methods. Attentional feature-based gating yields consistent performance\nimprovement across tasks. Our approach is implemented as a simple add-on module\nfor RNN-based models with minimal computational overhead and can be adapted to\nany deep neural architecture.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 17:06:28 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Margatina", "Katerina", ""], ["Baziotis", "Christos", ""], ["Potamianos", "Alexandros", ""]]}, {"id": "1906.03677", "submitter": "Arun Rajendran", "authors": "Arun Rajendran, Chiyu Zhang, and Muhammad Abdul-Mageed", "title": "Happy Together: Learning and Understanding Appraisal From Natural\n  Language", "comments": "11 pages, 5 figures, Proceedings of the 2nd Workshop on Affective\n  Content Analysis@ AAAI (AffCon2019), Honolulu, Hawaii (January 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore various approaches for learning two types of\nappraisal components from happy language. We focus on 'agency' of the author\nand the 'sociality' involved in happy moments based on the HappyDB dataset. We\ndevelop models based on deep neural networks for the task, including uni- and\nbi-directional long short-term memory networks, with and without attention. We\nalso experiment with a number of novel embedding methods, such as embedding\nfrom neural machine translation (as in CoVe) and embedding from language models\n(as in ELMo). We compare our results to those acquired by several traditional\nmachine learning methods. Our best models achieve 87.97% accuracy on agency and\n93.13% accuracy on sociality, both of which are significantly higher than our\nbaselines.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 17:28:37 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Rajendran", "Arun", ""], ["Zhang", "Chiyu", ""], ["Abdul-Mageed", "Muhammad", ""]]}, {"id": "1906.03692", "submitter": "Arun Rajendran", "authors": "Arun Rajendran, Chiyu Zhang and Muhammad Abdul-Mageed", "title": "UBC-NLP at SemEval-2019 Task 6:Ensemble Learning of Offensive Content\n  With Enhanced Training Data", "comments": "7 pages, 2 figures, Proceedings of the 13th International Workshop on\n  Semantic Evaluation (SemEval)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine learning offensive content on Twitter with limited, imbalanced\ndata. For the purpose, we investigate the utility of using various data\nenhancement methods with a host of classical ensemble classifiers. Among the 75\nparticipating teams in SemEval-2019 sub-task B, our system ranks 6th (with\n0.706 macro F1-score). For sub-task C, among the 65 participating teams, our\nsystem ranks 9th (with 0.587 macro F1-score).\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 19:14:18 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Rajendran", "Arun", ""], ["Zhang", "Chiyu", ""], ["Abdul-Mageed", "Muhammad", ""]]}, {"id": "1906.03695", "submitter": "Rakesh Chada", "authors": "Rakesh Chada", "title": "Gendered Pronoun Resolution using BERT and an extractive question\n  answering formulation", "comments": "1st ACL workshop on Gender Bias for Natural Language Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The resolution of ambiguous pronouns is a longstanding challenge in Natural\nLanguage Understanding. Recent studies have suggested gender bias among\nstate-of-the-art coreference resolution systems. As an example, Google AI\nLanguage team recently released a gender-balanced dataset and showed that\nperformance of these coreference resolvers is significantly limited on the\ndataset. In this paper, we propose an extractive question answering (QA)\nformulation of pronoun resolution task that overcomes this limitation and shows\nmuch lower gender bias (0.99) on their dataset. This system uses fine-tuned\nrepresentations from the pre-trained BERT model and outperforms the existing\nbaseline by a significant margin (22.2% absolute improvement in F1 score)\nwithout using any hand-engineered features. This QA framework is equally\nperformant even without the knowledge of the candidate antecedents of the\npronoun. An ensemble of QA and BERT-based multiple choice and sequence\nclassification models further improves the F1 (23.3% absolute improvement upon\nthe baseline). This ensemble model was submitted to the shared task for the 1st\nACL workshop on Gender Bias for Natural Language Processing. It ranked 9th on\nthe final official leaderboard. Source code is available at\nhttps://github.com/rakeshchada/corefqa\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 19:25:27 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Chada", "Rakesh", ""]]}, {"id": "1906.03717", "submitter": "Xinyu Hua", "authors": "Xinyu Hua, Zhe Hu, and Lu Wang", "title": "Argument Generation with Retrieval, Planning, and Realization", "comments": "Accepted as a long paper to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic argument generation is an appealing but challenging task. In this\npaper, we study the specific problem of counter-argument generation, and\npresent a novel framework, CANDELA. It consists of a powerful retrieval system\nand a novel two-step generation model, where a text planning decoder first\ndecides on the main talking points and a proper language style for each\nsentence, then a content realization decoder reflects the decisions and\nconstructs an informative paragraph-level argument. Furthermore, our generation\nmodel is empowered by a retrieval system indexed with 12 million articles\ncollected from Wikipedia and popular English news media, which provides access\nto high-quality content with diversity. Automatic evaluation on a large-scale\ndataset collected from Reddit shows that our model yields significantly higher\nBLEU, ROUGE, and METEOR scores than the state-of-the-art and non-trivial\ncomparisons. Human evaluation further indicates that our system arguments are\nmore appropriate for refutation and richer in content.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 21:39:46 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Hua", "Xinyu", ""], ["Hu", "Zhe", ""], ["Wang", "Lu", ""]]}, {"id": "1906.03731", "submitter": "Sofia Serrano", "authors": "Sofia Serrano, Noah A. Smith", "title": "Is Attention Interpretable?", "comments": "To appear at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention mechanisms have recently boosted performance on a range of NLP\ntasks. Because attention layers explicitly weight input components'\nrepresentations, it is also often assumed that attention can be used to\nidentify information that models found important (e.g., specific contextualized\nword tokens). We test whether that assumption holds by manipulating attention\nweights in already-trained text classification models and analyzing the\nresulting differences in their predictions. While we observe some ways in which\nhigher attention weights correlate with greater impact on model predictions, we\nalso find many ways in which this does not hold, i.e., where gradient-based\nrankings of attention weights better predict their effects than their\nmagnitudes. We conclude that while attention noisily predicts input components'\noverall importance to a model, it is by no means a fail-safe indicator.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 22:46:12 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Serrano", "Sofia", ""], ["Smith", "Noah A.", ""]]}, {"id": "1906.03741", "submitter": "Eva Sharma", "authors": "Eva Sharma, Chen Li, and Lu Wang", "title": "BIGPATENT: A Large-Scale Dataset for Abstractive and Coherent\n  Summarization", "comments": "Proceedings of the 57th Annual Meeting of the Association for\n  Computational Linguistics. ACL 2019 (10 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing text summarization datasets are compiled from the news domain,\nwhere summaries have a flattened discourse structure. In such datasets,\nsummary-worthy content often appears in the beginning of input articles.\nMoreover, large segments from input articles are present verbatim in their\nrespective summaries. These issues impede the learning and evaluation of\nsystems that can understand an article's global content structure as well as\nproduce abstractive summaries with high compression ratio. In this work, we\npresent a novel dataset, BIGPATENT, consisting of 1.3 million records of U.S.\npatent documents along with human written abstractive summaries. Compared to\nexisting summarization datasets, BIGPATENT has the following properties: i)\nsummaries contain a richer discourse structure with more recurring entities,\nii) salient content is evenly distributed in the input, and iii) lesser and\nshorter extractive fragments are present in the summaries. Finally, we train\nand evaluate baselines and popular learning models on BIGPATENT to shed light\non new challenges and motivate future directions for summarization research.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 00:24:26 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Sharma", "Eva", ""], ["Li", "Chen", ""], ["Wang", "Lu", ""]]}, {"id": "1906.03753", "submitter": "Ziyi Yang", "authors": "Ziyi Yang, Chenguang Zhu, Vin Sachidananda, Eric Darve", "title": "Out-of-Vocabulary Embedding Imputation with Grounded Language\n  Information by Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the ubiquitous use of embeddings as input representations for a wide\nrange of natural language tasks, imputation of embeddings for rare and unseen\nwords is a critical problem in language processing. Embedding imputation\ninvolves learning representations for rare or unseen words during the training\nof an embedding model, often in a post-hoc manner. In this paper, we propose an\napproach for embedding imputation which uses grounded information in the form\nof a knowledge graph. This is in contrast to existing approaches which\ntypically make use of vector space properties or subword information. We\npropose an online method to construct a graph from grounded information and\ndesign an algorithm to map from the resulting graphical structure to the space\nof the pre-trained embeddings. Finally, we evaluate our approach on a range of\nrare and unseen word tasks across various domains and show that our model can\nlearn better representations. For example, on the Card-660 task our method\nimproves Pearson's and Spearman's correlation coefficients upon the\nstate-of-the-art by 11% and 17.8% respectively using GloVe embeddings.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 01:10:34 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 21:42:06 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Yang", "Ziyi", ""], ["Zhu", "Chenguang", ""], ["Sachidananda", "Vin", ""], ["Darve", "Eric", ""]]}, {"id": "1906.03783", "submitter": "Hongyu Lin", "authors": "Hongyu Lin, Yaojie Lu, Xianpei Han, Le Sun", "title": "Sequence-to-Nuggets: Nested Entity Mention Detection via Anchor-Region\n  Networks", "comments": "Accepted by ACL2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential labeling-based NER approaches restrict each word belonging to at\nmost one entity mention, which will face a serious problem when recognizing\nnested entity mentions. In this paper, we propose to resolve this problem by\nmodeling and leveraging the head-driven phrase structures of entity mentions,\ni.e., although a mention can nest other mentions, they will not share the same\nhead word. Specifically, we propose Anchor-Region Networks (ARNs), a\nsequence-to-nuggets architecture for nested mention detection. ARNs first\nidentify anchor words (i.e., possible head words) of all mentions, and then\nrecognize the mention boundaries for each anchor word by exploiting regular\nphrase structures. Furthermore, we also design Bag Loss, an objective function\nwhich can train ARNs in an end-to-end manner without using any anchor word\nannotation. Experiments show that ARNs achieve the state-of-the-art performance\non three standard nested entity mention detection benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 03:15:00 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Lin", "Hongyu", ""], ["Lu", "Yaojie", ""], ["Han", "Xianpei", ""], ["Sun", "Le", ""]]}, {"id": "1906.03785", "submitter": "Mengzhou Xia", "authors": "Mengzhou Xia, Xiang Kong, Antonios Anastasopoulos, Graham Neubig", "title": "Generalized Data Augmentation for Low-Resource Translation", "comments": "Accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Translation to or from low-resource languages LRLs poses challenges for\nmachine translation in terms of both adequacy and fluency. Data augmentation\nutilizing large amounts of monolingual data is regarded as an effective way to\nalleviate these problems. In this paper, we propose a general framework for\ndata augmentation in low-resource machine translation that not only uses\ntarget-side monolingual data, but also pivots through a related high-resource\nlanguage HRL. Specifically, we experiment with a two-step pivoting method to\nconvert high-resource data to the LRL, making use of available resources to\nbetter approximate the true data distribution of the LRL. First, we inject LRL\nwords into HRL sentences through an induced bilingual dictionary. Second, we\nfurther edit these modified sentences using a modified unsupervised machine\ntranslation framework. Extensive experiments on four low-resource datasets show\nthat under extreme low-resource settings, our data augmentation techniques\nimprove translation quality by up to~1.5 to~8 BLEU points compared to\nsupervised back-translation baselines\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 03:28:57 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Xia", "Mengzhou", ""], ["Kong", "Xiang", ""], ["Anastasopoulos", "Antonios", ""], ["Neubig", "Graham", ""]]}, {"id": "1906.03805", "submitter": "Dilin Wang", "authors": "Dilin Wang, Chengyue Gong, Qiang Liu", "title": "Improving Neural Language Modeling via Adversarial Training", "comments": null, "journal-ref": "International Conference on Machine Learning 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, substantial progress has been made in language modeling by using\ndeep neural networks. However, in practice, large scale neural language models\nhave been shown to be prone to overfitting. In this paper, we present a simple\nyet highly effective adversarial training mechanism for regularizing neural\nlanguage models. The idea is to introduce adversarial noise to the output\nembedding layer while training the models. We show that the optimal adversarial\nnoise yields a simple closed-form solution, thus allowing us to develop a\nsimple and time efficient algorithm. Theoretically, we show that our\nadversarial mechanism effectively encourages the diversity of the embedding\nvectors, helping to increase the robustness of models. Empirically, we show\nthat our method improves on the single model state-of-the-art results for\nlanguage modeling on Penn Treebank (PTB) and Wikitext-2, achieving test\nperplexity scores of 46.01 and 38.07, respectively. When applied to machine\ntranslation, our method improves over various transformer-based translation\nbaselines in BLEU scores on the WMT14 English-German and IWSLT14 German-English\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 05:55:08 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 16:04:21 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Wang", "Dilin", ""], ["Gong", "Chengyue", ""], ["Liu", "Qiang", ""]]}, {"id": "1906.03820", "submitter": "Minghao Hu", "authors": "Minghao Hu, Yuxing Peng, Zhen Huang, Dongsheng Li and Yiwei Lv", "title": "Open-Domain Targeted Sentiment Analysis via Span-Based Extraction and\n  Classification", "comments": "To appear at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open-domain targeted sentiment analysis aims to detect opinion targets along\nwith their sentiment polarities from a sentence. Prior work typically\nformulates this task as a sequence tagging problem. However, such formulation\nsuffers from problems such as huge search space and sentiment inconsistency. To\naddress these problems, we propose a span-based extract-then-classify\nframework, where multiple opinion targets are directly extracted from the\nsentence under the supervision of target span boundaries, and corresponding\npolarities are then classified using their span representations. We further\ninvestigate three approaches under this framework, namely the pipeline, joint,\nand collapsed models. Experiments on three benchmark datasets show that our\napproach consistently outperforms the sequence tagging baseline. Moreover, we\nfind that the pipeline model achieves the best performance compared with the\nother two models.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 07:22:05 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Hu", "Minghao", ""], ["Peng", "Yuxing", ""], ["Huang", "Zhen", ""], ["Li", "Dongsheng", ""], ["Lv", "Yiwei", ""]]}, {"id": "1906.03824", "submitter": "Xu Chen", "authors": "Boyu Qiu, Xu Chen, Jungang Xu, Yingfei Sun", "title": "A Survey on Neural Machine Reading Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enabling a machine to read and comprehend the natural language documents so\nthat it can answer some questions remains an elusive challenge. In recent\nyears, the popularity of deep learning and the establishment of large-scale\ndatasets have both promoted the prosperity of Machine Reading Comprehension.\nThis paper aims to present how to utilize the Neural Network to build a Reader\nand introduce some classic models, analyze what improvements they make.\nFurther, we also point out the defects of existing models and future research\ndirections\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 07:49:14 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Qiu", "Boyu", ""], ["Chen", "Xu", ""], ["Xu", "Jungang", ""], ["Sun", "Yingfei", ""]]}, {"id": "1906.03889", "submitter": "Yue Wang", "authors": "Yue Wang, Jing Li, Hou Pong Chan, Irwin King, Michael R. Lyu, Shuming\n  Shi", "title": "Topic-Aware Neural Keyphrase Generation for Social Media Language", "comments": "ACL 2019 (11 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A huge volume of user-generated content is daily produced on social media. To\nfacilitate automatic language understanding, we study keyphrase prediction,\ndistilling salient information from massive posts. While most existing methods\nextract words from source posts to form keyphrases, we propose a\nsequence-to-sequence (seq2seq) based neural keyphrase generation framework,\nenabling absent keyphrases to be created. Moreover, our model, being\ntopic-aware, allows joint modeling of corpus-level latent topic\nrepresentations, which helps alleviate the data sparsity that widely exhibited\nin social media language. Experiments on three datasets collected from English\nand Chinese social media platforms show that our model significantly\noutperforms both extraction and generation models that do not exploit latent\ntopics. Further discussions show that our model learns meaningful topics, which\ninterprets its superiority in social media keyphrase generation.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 10:40:39 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Wang", "Yue", ""], ["Li", "Jing", ""], ["Chan", "Hou Pong", ""], ["King", "Irwin", ""], ["Lyu", "Michael R.", ""], ["Shi", "Shuming", ""]]}, {"id": "1906.03890", "submitter": "Nikolaos Aletras", "authors": "Daniel Preotiuc-Pietro, Mihaela Gaman and Nikolaos Aletras", "title": "Automatically Identifying Complaints in Social Media", "comments": "Accepted at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Complaining is a basic speech act regularly used in human and computer\nmediated communication to express a negative mismatch between reality and\nexpectations in a particular situation. Automatically identifying complaints in\nsocial media is of utmost importance for organizations or brands to improve the\ncustomer experience or in developing dialogue systems for handling and\nresponding to complaints. In this paper, we introduce the first systematic\nanalysis of complaints in computational linguistics. We collect a new annotated\ndata set of written complaints expressed in English on Twitter.\\footnote{Data\nand code is available here:\n\\url{https://github.com/danielpreotiuc/complaints-social-media}} We present an\nextensive linguistic analysis of complaining as a speech act in social media\nand train strong feature-based and neural models of complaints across nine\ndomains achieving a predictive performance of up to 79 F1 using distant\nsupervision.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 10:44:23 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Preotiuc-Pietro", "Daniel", ""], ["Gaman", "Mihaela", ""], ["Aletras", "Nikolaos", ""]]}, {"id": "1906.03897", "submitter": "Leshem Choshen", "authors": "Yoav Kantor and Yoav Katz and Leshem Choshen and Edo Cohen-Karlik and\n  Naftali Liberman and Assaf Toledo and Amir Menczel and Noam Slonim", "title": "Learning to combine Grammatical Error Corrections", "comments": "BEA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of Grammatical Error Correction (GEC) has produced various systems\nto deal with focused phenomena or general text editing. We propose an automatic\nway to combine black-box systems. Our method automatically detects the strength\nof a system or the combination of several systems per error type, improving\nprecision and recall while optimizing $F$ score directly. We show consistent\nimprovement over the best standalone system in all the configurations tested.\nThis approach also outperforms average ensembling of different RNN models with\nrandom initializations.\n  In addition, we analyze the use of BERT for GEC - reporting promising results\non this end. We also present a spellchecker created for this task which\noutperforms standard spellcheckers tested on the task of spellchecking.\n  This paper describes a system submission to Building Educational Applications\n2019 Shared Task: Grammatical Error Correction.\n  Combining the output of top BEA 2019 shared task systems using our approach,\ncurrently holds the highest reported score in the open phase of the BEA 2019\nshared task, improving F0.5 by 3.7 points over the best result reported.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 10:57:47 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Kantor", "Yoav", ""], ["Katz", "Yoav", ""], ["Choshen", "Leshem", ""], ["Cohen-Karlik", "Edo", ""], ["Liberman", "Naftali", ""], ["Toledo", "Assaf", ""], ["Menczel", "Amir", ""], ["Slonim", "Noam", ""]]}, {"id": "1906.03926", "submitter": "Nantas Nardelli", "authors": "Jelena Luketina, Nantas Nardelli, Gregory Farquhar, Jakob Foerster,\n  Jacob Andreas, Edward Grefenstette, Shimon Whiteson, Tim Rockt\\\"aschel", "title": "A Survey of Reinforcement Learning Informed by Natural Language", "comments": "Published at IJCAI'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To be successful in real-world tasks, Reinforcement Learning (RL) needs to\nexploit the compositional, relational, and hierarchical structure of the world,\nand learn to transfer it to the task at hand. Recent advances in representation\nlearning for language make it possible to build models that acquire world\nknowledge from text corpora and integrate this knowledge into downstream\ndecision making problems. We thus argue that the time is right to investigate a\ntight integration of natural language understanding into RL in particular. We\nsurvey the state of the field, including work on instruction following, text\ngames, and learning from textual domain knowledge. Finally, we call for the\ndevelopment of new environments as well as further investigation into the\npotential uses of recent Natural Language Processing (NLP) techniques for such\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 12:17:45 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Luketina", "Jelena", ""], ["Nardelli", "Nantas", ""], ["Farquhar", "Gregory", ""], ["Foerster", "Jakob", ""], ["Andreas", "Jacob", ""], ["Grefenstette", "Edward", ""], ["Whiteson", "Shimon", ""], ["Rockt\u00e4schel", "Tim", ""]]}, {"id": "1906.03940", "submitter": "Md. Iftekhar Tanveer", "authors": "Md Iftekhar Tanveer, Md Kamrul Hassan, Daniel Gildea, M. Ehsan Hoque", "title": "Predicting TED Talk Ratings from Language and Prosody", "comments": "arXiv admin note: substantial text overlap with arXiv:1905.08392", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use the largest open repository of public speaking---TED Talks---to\npredict the ratings of the online viewers. Our dataset contains over 2200 TED\nTalk transcripts (includes over 200 thousand sentences), audio features and the\nassociated meta information including about 5.5 Million ratings from\nspontaneous visitors of the website. We propose three neural network\narchitectures and compare with statistical machine learning. Our experiments\nreveal that it is possible to predict all the 14 different ratings with an\naverage AUC of 0.83 using the transcripts and prosody features only. The\ndataset and the complete source code is available for further analysis.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 00:38:33 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Tanveer", "Md Iftekhar", ""], ["Hassan", "Md Kamrul", ""], ["Gildea", "Daniel", ""], ["Hoque", "M. Ehsan", ""]]}, {"id": "1906.03952", "submitter": "Riko Suzuki", "authors": "Riko Suzuki, Hitomi Yanaka, Masashi Yoshikawa, Koji Mineshima, Daisuke\n  Bekki", "title": "Multimodal Logical Inference System for Visual-Textual Entailment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large amount of research about multimodal inference across text and vision\nhas been recently developed to obtain visually grounded word and sentence\nrepresentations. In this paper, we use logic-based representations as unified\nmeaning representations for texts and images and present an unsupervised\nmultimodal logical inference system that can effectively prove entailment\nrelations between them. We show that by combining semantic parsing and theorem\nproving, the system can handle semantically complex sentences for\nvisual-textual inference.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 12:57:56 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Suzuki", "Riko", ""], ["Yanaka", "Hitomi", ""], ["Yoshikawa", "Masashi", ""], ["Mineshima", "Koji", ""], ["Bekki", "Daisuke", ""]]}, {"id": "1906.04040", "submitter": "Aarne Talman", "authors": "Aarne Talman, Umut Sulubacak, Ra\\'ul V\\'azquez, Yves Scherrer, Sami\n  Virpioja, Alessandro Raganato, Arvi Hurskainen, J\\\"org Tiedemann", "title": "The University of Helsinki submissions to the WMT19 news translation\n  task", "comments": "To appear in WMT19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present the University of Helsinki submissions to the WMT\n2019 shared task on news translation in three language pairs: English-German,\nEnglish-Finnish and Finnish-English. This year, we focused first on cleaning\nand filtering the training data using multiple data-filtering approaches,\nresulting in much smaller and cleaner training sets. For English-German, we\ntrained both sentence-level transformer models and compared different\ndocument-level translation approaches. For Finnish-English and English-Finnish\nwe focused on different segmentation approaches, and we also included a\nrule-based system for English-Finnish.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 14:48:10 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Talman", "Aarne", ""], ["Sulubacak", "Umut", ""], ["V\u00e1zquez", "Ra\u00fal", ""], ["Scherrer", "Yves", ""], ["Virpioja", "Sami", ""], ["Raganato", "Alessandro", ""], ["Hurskainen", "Arvi", ""], ["Tiedemann", "J\u00f6rg", ""]]}, {"id": "1906.04041", "submitter": "Genta Indra Winata", "authors": "Genta Indra Winata, Andrea Madotto, Zhaojiang Lin, Jamin Shin, Yan Xu,\n  Peng Xu, Pascale Fung", "title": "CAiRE_HKUST at SemEval-2019 Task 3: Hierarchical Attention for Dialogue\n  Emotion Classification", "comments": "Accepted by SemEval 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting emotion from dialogue is a challenge that has not yet been\nextensively surveyed. One could consider the emotion of each dialogue turn to\nbe independent, but in this paper, we introduce a hierarchical approach to\nclassify emotion, hypothesizing that the current emotional state depends on\nprevious latent emotions. We benchmark several feature-based classifiers using\npre-trained word and emotion embeddings, state-of-the-art end-to-end neural\nnetwork models, and Gaussian processes for automatic hyper-parameter search. In\nour experiments, hierarchical architectures consistently give significant\nimprovements, and our best model achieves a 76.77% F1-score on the test set.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 14:48:54 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Winata", "Genta Indra", ""], ["Madotto", "Andrea", ""], ["Lin", "Zhaojiang", ""], ["Shin", "Jamin", ""], ["Xu", "Yan", ""], ["Xu", "Peng", ""], ["Fung", "Pascale", ""]]}, {"id": "1906.04043", "submitter": "Sebastian Gehrmann", "authors": "Sebastian Gehrmann and Hendrik Strobelt and Alexander M. Rush", "title": "GLTR: Statistical Detection and Visualization of Generated Text", "comments": "ACL 2019 Demo Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid improvement of language models has raised the specter of abuse of\ntext generation systems. This progress motivates the development of simple\nmethods for detecting generated text that can be used by and explained to\nnon-experts. We develop GLTR, a tool to support humans in detecting whether a\ntext was generated by a model. GLTR applies a suite of baseline statistical\nmethods that can detect generation artifacts across common sampling schemes. In\na human-subjects study, we show that the annotation scheme provided by GLTR\nimproves the human detection-rate of fake text from 54% to 72% without any\nprior training. GLTR is open-source and publicly deployed, and has already been\nwidely used to detect generated outputs\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 14:52:41 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Gehrmann", "Sebastian", ""], ["Strobelt", "Hendrik", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1906.04068", "submitter": "Ethan Wilcox", "authors": "Ethan Wilcox, Roger Levy, and Richard Futrell", "title": "Hierarchical Representation in Neural Language Models: Suppression and\n  Recovery of Expectations", "comments": "Proceedings of BlackboxNLP 2019, ACL, Florence, Italy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning sequence models have led to a marked increase in performance\nfor a range of Natural Language Processing tasks, but it remains an open\nquestion whether they are able to induce proper hierarchical generalizations\nfor representing natural language from linear input alone. Work using\nartificial languages as training input has shown that LSTMs are capable of\ninducing the stack-like data structures required to represent context-free and\ncertain mildly context-sensitive languages---formal language classes which\ncorrespond in theory to the hierarchical structures of natural language. Here\nwe present a suite of experiments probing whether neural language models\ntrained on linguistic data induce these stack-like data structures and deploy\nthem while incrementally predicting words. We study two natural language\nphenomena: center embedding sentences and syntactic island constraints on the\nfiller--gap dependency. In order to properly predict words in these structures,\na model must be able to temporarily suppress certain expectations and then\nrecover those expectations later, essentially pushing and popping these\nexpectations on a stack. Our results provide evidence that models can\nsuccessfully suppress and recover expectations in many cases, but do not fully\nrecover their previous grammatical state.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 15:20:32 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Wilcox", "Ethan", ""], ["Levy", "Roger", ""], ["Futrell", "Richard", ""]]}, {"id": "1906.04082", "submitter": "Maria Ponomareva", "authors": "Ekaterina Chernyak and Maria Ponomareva and Kirill Milintsevich", "title": "Char-RNN for Word Stress Detection in East Slavic Languages", "comments": "Proceedings of the Sixth Workshop on NLP for Similar Languages,\n  Varieties and Dialects at NAACL-2019", "journal-ref": "2019, In Proceedings of the Sixth Workshop on NLP for Similar\n  Languages, Varieties and Dialects, pages 35-41,TOBEFILLED-Ann Arbor,\n  Michigan, Association for Computational Linguistics", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore how well a sequence labeling approach, namely, recurrent neural\nnetwork, is suited for the task of resource-poor and POS tagging free word\nstress detection in the Russian, Ukranian, Belarusian languages. We present new\ndatasets, annotated with the word stress, for the three languages and compare\nseveral RNN models trained on three languages and explore possible applications\nof the transfer learning for the task. We show that it is possible to train a\nmodel in a cross-lingual setting and that using additional languages improves\nthe quality of the results.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 15:53:20 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Chernyak", "Ekaterina", ""], ["Ponomareva", "Maria", ""], ["Milintsevich", "Kirill", ""]]}, {"id": "1906.04099", "submitter": "Maria Ponomareva", "authors": "Maria Ponomareva and Kira Droganova and Ivan Smurov and Tatiana\n  Shavrina", "title": "AGRR-2019: A Corpus for Gapping Resolution in Russian", "comments": "Accepted to BSNLP at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a comprehensive overview of the gapping dataset for\nRussian that consists of 7.5k sentences with gapping (as well as 15k relevant\nnegative sentences) and comprises data from various genres: news, fiction,\nsocial media and technical texts. The dataset was prepared for the Automatic\nGapping Resolution Shared Task for Russian (AGRR-2019) - a competition aimed at\nstimulating the development of NLP tools and methods for processing of\nellipsis.\n  In this paper, we pay special attention to the gapping resolution methods\nthat were introduced within the shared task as well as an alternative test set\nthat illustrates that our corpus is a diverse and representative subset of\nRussian language gapping sufficient for effective utilization of machine\nlearning techniques.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 16:20:48 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Ponomareva", "Maria", ""], ["Droganova", "Kira", ""], ["Smurov", "Ivan", ""], ["Shavrina", "Tatiana", ""]]}, {"id": "1906.04102", "submitter": "Lilian Wanzare", "authors": "Lilian D.A. Wanzare and Michael Roth and Manfred Pinkal", "title": "Detecting Everyday Scenarios in Narrative Texts", "comments": "Storytelling workshop 2019@ACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Script knowledge consists of detailed information on everyday activities.\nSuch information is often taken for granted in text and needs to be inferred by\nreaders. Therefore, script knowledge is a central component to language\ncomprehension. Previous work on representing scripts is mostly based on\nextensive manual work or limited to scenarios that can be found with sufficient\nredundancy in large corpora. We introduce the task of scenario detection, in\nwhich we identify references to scripts. In this task, we address a wide range\nof different scripts (200 scenarios) and we attempt to identify all references\nto them in a collection of narrative texts. We present a first benchmark data\nset and a baseline model that tackles scenario detection using techniques from\ntopic segmentation and text classification.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 16:23:07 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Wanzare", "Lilian D. A.", ""], ["Roth", "Michael", ""], ["Pinkal", "Manfred", ""]]}, {"id": "1906.04106", "submitter": "Hou Pong Chan", "authors": "Hou Pong Chan, Wang Chen, Lu Wang, Irwin King", "title": "Neural Keyphrase Generation via Reinforcement Learning with Adaptive\n  Rewards", "comments": "Accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating keyphrases that summarize the main points of a document is a\nfundamental task in natural language processing. Although existing generative\nmodels are capable of predicting multiple keyphrases for an input document as\nwell as determining the number of keyphrases to generate, they still suffer\nfrom the problem of generating too few keyphrases. To address this problem, we\npropose a reinforcement learning (RL) approach for keyphrase generation, with\nan adaptive reward function that encourages a model to generate both sufficient\nand accurate keyphrases. Furthermore, we introduce a new evaluation method that\nincorporates name variations of the ground-truth keyphrases using the Wikipedia\nknowledge base. Thus, our evaluation method can more robustly evaluate the\nquality of predicted keyphrases. Extensive experiments on five real-world\ndatasets of different scales demonstrate that our RL approach consistently and\nsignificantly improves the performance of the state-of-the-art generative\nmodels with both conventional and new evaluation methods.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 16:27:34 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Chan", "Hou Pong", ""], ["Chen", "Wang", ""], ["Wang", "Lu", ""], ["King", "Irwin", ""]]}, {"id": "1906.04129", "submitter": "Gustavo Aguilar", "authors": "Gustavo Aguilar, A. Pastor L\\'opez-Monroy, Fabio A. Gonz\\'alez and\n  Thamar Solorio", "title": "Modeling Noisiness to Recognize Named Entities using Multitask Neural\n  Networks on Social Media", "comments": "NAACL 2018", "journal-ref": "Proceedings of the 2018 Conference of the North American Chapter\n  of the Association for Computational Linguistics: Human Language\n  Technologies, Volume 1 (Long Papers), 1401-1412", "doi": "10.18653/v1/N18-1127", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing named entities in a document is a key task in many NLP\napplications. Although current state-of-the-art approaches to this task reach a\nhigh performance on clean text (e.g. newswire genres), those algorithms\ndramatically degrade when they are moved to noisy environments such as social\nmedia domains. We present two systems that address the challenges of processing\nsocial media data using character-level phonetics and phonology, word\nembeddings, and Part-of-Speech tags as features. The first model is a multitask\nend-to-end Bidirectional Long Short-Term Memory (BLSTM)-Conditional Random\nField (CRF) network whose output layer contains two CRF classifiers. The second\nmodel uses a multitask BLSTM network as feature extractor that transfers the\nlearning to a CRF classifier for the final prediction. Our systems outperform\nthe current F1 scores of the state of the art on the Workshop on Noisy\nUser-generated Text 2017 dataset by 2.45% and 3.69%, establishing a more\nsuitable approach for social media environments.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 17:08:29 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Aguilar", "Gustavo", ""], ["L\u00f3pez-Monroy", "A. Pastor", ""], ["Gonz\u00e1lez", "Fabio A.", ""], ["Solorio", "Thamar", ""]]}, {"id": "1906.04135", "submitter": "Gustavo Aguilar", "authors": "Gustavo Aguilar, Suraj Maharjan, Adrian Pastor L\\'opez-Monroy and\n  Thamar Solorio", "title": "A Multi-task Approach for Named Entity Recognition in Social Media Data", "comments": "EMNLP 2017 (W-NUT)", "journal-ref": "Proceedings of the 3rd Workshop on Noisy User-generated Text,\n  2017, 148-153", "doi": "10.18653/v1/W17-4419", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named Entity Recognition for social media data is challenging because of its\ninherent noisiness. In addition to improper grammatical structures, it contains\nspelling inconsistencies and numerous informal abbreviations. We propose a\nnovel multi-task approach by employing a more general secondary task of Named\nEntity (NE) segmentation together with the primary task of fine-grained NE\ncategorization. The multi-task neural network architecture learns higher order\nfeature representations from word and character sequences along with basic\nPart-of-Speech tags and gazetteer information. This neural network acts as a\nfeature extractor to feed a Conditional Random Fields classifier. We were able\nto obtain the first position in the 3rd Workshop on Noisy User-generated Text\n(WNUT-2017) with a 41.86% entity F1-score and a 40.24% surface F1-score.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 17:12:30 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Aguilar", "Gustavo", ""], ["Maharjan", "Suraj", ""], ["L\u00f3pez-Monroy", "Adrian Pastor", ""], ["Solorio", "Thamar", ""]]}, {"id": "1906.04138", "submitter": "Gustavo Aguilar", "authors": "Gustavo Aguilar, Fahad AlGhamdi, Victor Soto, Mona Diab, Julia\n  Hirschberg and Thamar Solorio", "title": "Named Entity Recognition on Code-Switched Data: Overview of the CALCS\n  2018 Shared Task", "comments": "ACL 2018 (CALCS)", "journal-ref": "Proceedings of the Third Workshop on Computational Approaches to\n  Linguistic Code-Switching, 2018, 138-147", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the third shared task of the Computational Approaches to Linguistic\nCode-Switching (CALCS) workshop, we focus on Named Entity Recognition (NER) on\ncode-switched social-media data. We divide the shared task into two\ncompetitions based on the English-Spanish (ENG-SPA) and Modern Standard\nArabic-Egyptian (MSA-EGY) language pairs. We use Twitter data and 9 entity\ntypes to establish a new dataset for code-switched NER benchmarks. In addition\nto the CS phenomenon, the diversity of the entities and the social media\nchallenges make the task considerably hard to process. As a result, the best\nscores of the competitions are 63.76% and 71.61% for ENG-SPA and MSA-EGY,\nrespectively. We present the scores of 9 participants and discuss the most\ncommon challenges among submissions.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 17:17:45 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Aguilar", "Gustavo", ""], ["AlGhamdi", "Fahad", ""], ["Soto", "Victor", ""], ["Diab", "Mona", ""], ["Hirschberg", "Julia", ""], ["Solorio", "Thamar", ""]]}, {"id": "1906.04164", "submitter": "Moin Nadeem", "authors": "Moin Nadeem, Wei Fang, Brian Xu, Mitra Mohtarami, James Glass", "title": "FAKTA: An Automatic End-to-End Fact Checking System", "comments": "Accepted to NAACL '19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present FAKTA which is a unified framework that integrates various\ncomponents of a fact checking process: document retrieval from media sources\nwith various types of reliability, stance detection of documents with respect\nto given claims, evidence extraction, and linguistic analysis. FAKTA predicts\nthe factuality of given claims and provides evidence at the document and\nsentence level to explain its predictions\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 18:49:38 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Nadeem", "Moin", ""], ["Fang", "Wei", ""], ["Xu", "Brian", ""], ["Mohtarami", "Mitra", ""], ["Glass", "James", ""]]}, {"id": "1906.04165", "submitter": "Derek Miller", "authors": "Derek Miller", "title": "Leveraging BERT for Extractive Text Summarization on Lectures", "comments": "7 Pages, First Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last two decades, automatic extractive text summarization on lectures\nhas demonstrated to be a useful tool for collecting key phrases and sentences\nthat best represent the content. However, many current approaches utilize dated\napproaches, producing sub-par outputs or requiring several hours of manual\ntuning to produce meaningful results. Recently, new machine learning\narchitectures have provided mechanisms for extractive summarization through the\nclustering of output embeddings from deep learning models. This paper reports\non the project called Lecture Summarization Service, a python based RESTful\nservice that utilizes the BERT model for text embeddings and KMeans clustering\nto identify sentences closes to the centroid for summary selection. The purpose\nof the service was to provide students a utility that could summarize lecture\ncontent, based on their desired number of sentences. On top of the summary\nwork, the service also includes lecture and summary management, storing content\non the cloud which can be used for collaboration. While the results of\nutilizing BERT for extractive summarization were promising, there were still\nareas where the model struggled, providing feature research opportunities for\nfurther improvement.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 19:50:30 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Miller", "Derek", ""]]}, {"id": "1906.04177", "submitter": "Dhanya Sridhar", "authors": "Dhanya Sridhar and Lise Getoor", "title": "Estimating Causal Effects of Tone in Online Debates", "comments": "Accepted at International Joint Conference on Artificial Intelligence\n  (IJCAI) 2019 for oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical methods applied to social media posts shed light on the dynamics\nof online dialogue. For example, users' wording choices predict their\npersuasiveness and users adopt the language patterns of other dialogue\nparticipants. In this paper, we estimate the causal effect of reply tones in\ndebates on linguistic and sentiment changes in subsequent responses. The\nchallenge for this estimation is that a reply's tone and subsequent responses\nare confounded by the users' ideologies on the debate topic and their emotions.\nTo overcome this challenge, we learn representations of ideology using\ngenerative models of text. We study debates from 4Forums and compare annotated\ntones of replying such as emotional versus factual, or reasonable versus\nattacking. We show that our latent confounder representation reduces bias in\nATE estimation. Our results suggest that factual and asserting tones affect\ndialogue and provide a methodology for estimating causal effects from text.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 16:39:16 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 15:38:14 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Sridhar", "Dhanya", ""], ["Getoor", "Lise", ""]]}, {"id": "1906.04225", "submitter": "Sam Wiseman", "authors": "Sam Wiseman, Karl Stratos", "title": "Label-Agnostic Sequence Labeling by Copying Nearest Neighbors", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Retrieve-and-edit based approaches to structured prediction, where structures\nassociated with retrieved neighbors are edited to form new structures, have\nrecently attracted increased interest. However, much recent work merely\nconditions on retrieved structures (e.g., in a sequence-to-sequence framework),\nrather than explicitly manipulating them. We show we can perform accurate\nsequence labeling by explicitly (and only) copying labels from retrieved\nneighbors. Moreover, because this copying is label-agnostic, we can achieve\nimpressive performance in zero-shot sequence-labeling tasks. We additionally\nconsider a dynamic programming approach to sequence labeling in the presence of\nretrieved neighbors, which allows for controlling the number of distinct\n(copied) segments used to form a prediction, and leads to both more\ninterpretable and accurate predictions.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 18:53:18 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Wiseman", "Sam", ""], ["Stratos", "Karl", ""]]}, {"id": "1906.04229", "submitter": "Claudio Greco", "authors": "Claudio Greco, Barbara Plank, Raquel Fern\\'andez, Raffaella Bernardi", "title": "Psycholinguistics meets Continual Learning: Measuring Catastrophic\n  Forgetting in Visual Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the issue of catastrophic forgetting in the context of neural\nmultimodal approaches to Visual Question Answering (VQA). Motivated by evidence\nfrom psycholinguistics, we devise a set of linguistically-informed VQA tasks,\nwhich differ by the types of questions involved (Wh-questions and polar\nquestions). We test what impact task difficulty has on continual learning, and\nwhether the order in which a child acquires question types facilitates\ncomputational models. Our results show that dramatic forgetting is at play and\nthat task difficulty and order matter. Two well-known current continual\nlearning methods mitigate the problem only to a limiting degree.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 19:00:59 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Greco", "Claudio", ""], ["Plank", "Barbara", ""], ["Fern\u00e1ndez", "Raquel", ""], ["Bernardi", "Raffaella", ""]]}, {"id": "1906.04233", "submitter": "Zack Hodari", "authors": "Zack Hodari, Oliver Watts, Simon King", "title": "Using generative modelling to produce varied intonation for speech\n  synthesis", "comments": "Accepted for the 10th ISCA Speech Synthesis Workshop (SSW10)", "journal-ref": null, "doi": "10.21437/SSW.2019-43", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unlike human speakers, typical text-to-speech (TTS) systems are unable to\nproduce multiple distinct renditions of a given sentence. This has previously\nbeen addressed by adding explicit external control. In contrast, generative\nmodels are able to capture a distribution over multiple renditions and thus\nproduce varied renditions using sampling. Typical neural TTS models learn the\naverage of the data because they minimise mean squared error. In the context of\nprosody, taking the average produces flatter, more boring speech: an \"average\nprosody\". A generative model that can synthesise multiple prosodies will, by\ndesign, not model average prosody. We use variational autoencoders (VAEs) which\nexplicitly place the most \"average\" data close to the mean of the Gaussian\nprior. We propose that by moving towards the tails of the prior distribution,\nthe model will transition towards generating more idiosyncratic, varied\nrenditions. Focusing here on intonation, we investigate the trade-off between\nnaturalness and intonation variation and find that typical acoustic models can\neither be natural, or varied, but not both. However, sampling from the tails of\nthe VAE prior produces much more varied intonation than the traditional\napproaches, whilst maintaining the same level of naturalness.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 19:05:03 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 10:14:38 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Hodari", "Zack", ""], ["Watts", "Oliver", ""], ["King", "Simon", ""]]}, {"id": "1906.04236", "submitter": "Oana Ignat", "authors": "Oana Ignat, Laura Burdick, Jia Deng, Rada Mihalcea", "title": "Identifying Visible Actions in Lifestyle Vlogs", "comments": "Accepted at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of identifying human actions visible in online videos.\nWe focus on the widely spread genre of lifestyle vlogs, which consist of videos\nof people performing actions while verbally describing them. Our goal is to\nidentify if actions mentioned in the speech description of a video are visually\npresent. We construct a dataset with crowdsourced manual annotations of visible\nactions, and introduce a multimodal algorithm that leverages information\nderived from visual and linguistic clues to automatically infer which actions\nare visible in a video. We demonstrate that our multimodal algorithm\noutperforms algorithms based only on one modality at a time.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 19:11:01 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Ignat", "Oana", ""], ["Burdick", "Laura", ""], ["Deng", "Jia", ""], ["Mihalcea", "Rada", ""]]}, {"id": "1906.04284", "submitter": "Jesse Vig", "authors": "Jesse Vig and Yonatan Belinkov", "title": "Analyzing the Structure of Attention in a Transformer Language Model", "comments": "To appear in ACL BlackboxNLP workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Transformer is a fully attention-based alternative to recurrent networks\nthat has achieved state-of-the-art results across a range of NLP tasks. In this\npaper, we analyze the structure of attention in a Transformer language model,\nthe GPT-2 small pretrained model. We visualize attention for individual\ninstances and analyze the interaction between attention and syntax over a large\ncorpus. We find that attention targets different parts of speech at different\nlayer depths within the model, and that attention aligns with dependency\nrelations most strongly in the middle layers. We also find that the deepest\nlayers of the model capture the most distant relationships. Finally, we extract\nexemplar sentences that reveal highly specific patterns targeted by particular\nattention heads.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 13:58:49 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 19:42:31 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Vig", "Jesse", ""], ["Belinkov", "Yonatan", ""]]}, {"id": "1906.04287", "submitter": "Hanqing Tao", "authors": "Hanqing Tao, Shiwei Tong, Tong Xu, Qi Liu, Enhong Chen", "title": "Chinese Embedding via Stroke and Glyph Information: A Dual-channel View", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have consistently given positive hints that morphology is\nhelpful in enriching word embeddings. In this paper, we argue that Chinese word\nembeddings can be substantially enriched by the morphological information\nhidden in characters which is reflected not only in strokes order sequentially,\nbut also in character glyphs spatially. Then, we propose a novel Dual-channel\nWord Embedding (DWE) model to realize the joint learning of sequential and\nspatial information of characters. Through the evaluation on both word\nsimilarity and word analogy tasks, our model shows its rationality and\nsuperiority in modelling the morphology of Chinese.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 13:47:40 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Tao", "Hanqing", ""], ["Tong", "Shiwei", ""], ["Xu", "Tong", ""], ["Liu", "Qi", ""], ["Chen", "Enhong", ""]]}, {"id": "1906.04291", "submitter": "Wen Wang", "authors": "Hao Lang and Wen Wang", "title": "Automated Curriculum Learning for Turn-level Spoken Language\n  Understanding with Weak Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a learning approach for turn-level spoken language understanding,\nwhich facilitates a user to speak one or more utterances compositionally in a\nturn for completing a task (e.g., voice ordering). A typical pipelined approach\nfor these understanding tasks requires non-trivial annotation effort for\ndeveloping its multiple components. Also, the pipeline is difficult to port to\na new domain or scale up. To address these problems, we propose an end-to-end\nstatistical model with weak supervision. We employ randomized beam search with\nmemory augmentation (RBSMA) to solve complicated problems for which long\npromising trajectories are usually difficult to explore. Furthermore,\nconsidering the diversity of problem complexity, we explore automated\ncurriculum learning (CL) for weak supervision to accelerate exploration and\nlearning. We evaluate the proposed approach on real-world user logs of a\ncommercial voice ordering system. Results demonstrate that when trained on a\nsmall number of end-to-end annotated sessions collected with low cost, our\nmodel performs comparably to the deployed pipelined system, saving the\ndevelopment labor over an order of magnitude. The RBSMA algorithm improves the\ntest set accuracy by 7.8% relative compared to the standard beam search.\nAutomated CL leads to better generalization and further improves the test set\naccuracy by 5% relative.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 21:54:33 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Lang", "Hao", ""], ["Wang", "Wen", ""]]}, {"id": "1906.04301", "submitter": "Mohammad Hamed Mozaffari", "authors": "M. Hamed Mozaffari and Won-Sook Lee", "title": "Transfer Learning for Ultrasound Tongue Contour Extraction with\n  Different Domains", "comments": "3 figures, 9 pages, 1 table, 16 references", "journal-ref": "The Journal of the Acoustical Society of America 146, 2940 (2019)", "doi": "10.1121/1.5137211", "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical ultrasound technology is widely used in routine clinical applications\nsuch as disease diagnosis and treatment as well as other applications like\nreal-time monitoring of human tongue shapes and motions as visual feedback in\nsecond language training. Due to the low-contrast characteristic and noisy\nnature of ultrasound images, it might require expertise for non-expert users to\nrecognize tongue gestures. Manual tongue segmentation is a cumbersome,\nsubjective, and error-prone task. Furthermore, it is not a feasible solution\nfor real-time applications. In the last few years, deep learning methods have\nbeen used for delineating and tracking tongue dorsum. Deep convolutional neural\nnetworks (DCNNs), which have shown to be successful in medical image analysis\ntasks, are typically weak for the same task on different domains. In many\ncases, DCNNs trained on data acquired with one ultrasound device, do not\nperform well on data of varying ultrasound device or acquisition protocol.\nDomain adaptation is an alternative solution for this difficulty by\ntransferring the weights from the model trained on a large annotated legacy\ndataset to a new model for adapting on another different dataset using\nfine-tuning. In this study, after conducting extensive experiments, we\naddressed the problem of domain adaptation on small ultrasound datasets for\ntongue contour extraction. We trained a U-net network comprises of an\nencoder-decoder path from scratch, and then with several surrogate scenarios,\nsome parts of the trained network were fine-tuned on another dataset as the\ndomain-adapted networks. We repeat scenarios from target to source domains to\nfind a balance point for knowledge transfer from source to target and vice\nversa. The performance of new fine-tuned networks was evaluated on the same\ntask with images from different domains.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 22:17:08 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Mozaffari", "M. Hamed", ""], ["Lee", "Won-Sook", ""]]}, {"id": "1906.04323", "submitter": "Ronan Collobert", "authors": "Ronan Collobert and Awni Hannun and Gabriel Synnaeve", "title": "Word-level Speech Recognition with a Letter to Word Encoder", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a direct-to-word sequence model which uses a word network to learn\nword embeddings from letters. The word network can be integrated seamlessly\nwith arbitrary sequence models including Connectionist Temporal Classification\nand encoder-decoder models with attention. We show our direct-to-word model can\nachieve word error rate gains over sub-word level models for speech\nrecognition. We also show that our direct-to-word approach retains the ability\nto predict words not seen at training time without any retraining. Finally, we\ndemonstrate that a word-level model can use a larger stride than a sub-word\nlevel model while maintaining accuracy. This makes the model more efficient\nboth for training and inference.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 23:31:56 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 22:14:04 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Collobert", "Ronan", ""], ["Hannun", "Awni", ""], ["Synnaeve", "Gabriel", ""]]}, {"id": "1906.04329", "submitter": "Swaroop Ramaswamy", "authors": "Swaroop Ramaswamy, Rajiv Mathews, Kanishka Rao, Fran\\c{c}oise Beaufays", "title": "Federated Learning for Emoji Prediction in a Mobile Keyboard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We show that a word-level recurrent neural network can predict emoji from\ntext typed on a mobile keyboard. We demonstrate the usefulness of transfer\nlearning for predicting emoji by pretraining the model using a language\nmodeling task. We also propose mechanisms to trigger emoji and tune the\ndiversity of candidates. The model is trained using a distributed on-device\nlearning framework called federated learning. The federated model is shown to\nachieve better performance than a server-trained model. This work demonstrates\nthe feasibility of using federated learning to train production-quality models\nfor natural language understanding tasks while keeping users' data on their\ndevices.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 00:40:33 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Ramaswamy", "Swaroop", ""], ["Mathews", "Rajiv", ""], ["Rao", "Kanishka", ""], ["Beaufays", "Fran\u00e7oise", ""]]}, {"id": "1906.04331", "submitter": "Daniel Duckworth", "authors": "Daniel Duckworth, Arvind Neelakantan, Ben Goodrich, Lukasz Kaiser,\n  Samy Bengio", "title": "Parallel Scheduled Sampling", "comments": "2nd submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Auto-regressive models are widely used in sequence generation problems. The\noutput sequence is typically generated in a predetermined order, one discrete\nunit (pixel or word or character) at a time. The models are trained by\nteacher-forcing where ground-truth history is fed to the model as input, which\nat test time is replaced by the model prediction. Scheduled Sampling aims to\nmitigate this discrepancy between train and test time by randomly replacing\nsome discrete units in the history with the model's prediction. While\nteacher-forced training works well with ML accelerators as the computation can\nbe parallelized across time, Scheduled Sampling involves undesirable sequential\nprocessing. In this paper, we introduce a simple technique to parallelize\nScheduled Sampling across time. Experimentally, we find the proposed technique\nleads to equivalent or better performance on image generation, summarization,\ndialog generation, and translation compared to teacher-forced training. In\ndialog response generation task, Parallel Scheduled Sampling achieves 1.6 BLEU\nscore (11.5%) improvement over teacher-forcing while in image generation it\nachieves 20% and 13.8% improvement in Frechet Inception Distance (FID) and\nInception Score (IS) respectively. Further, we discuss the effects of different\nhyper-parameters associated with Scheduled Sampling on the model performance.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 00:43:38 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 18:41:37 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Duckworth", "Daniel", ""], ["Neelakantan", "Arvind", ""], ["Goodrich", "Ben", ""], ["Kaiser", "Lukasz", ""], ["Bengio", "Samy", ""]]}, {"id": "1906.04341", "submitter": "Kevin Clark", "authors": "Kevin Clark, Urvashi Khandelwal, Omer Levy, Christopher D. Manning", "title": "What Does BERT Look At? An Analysis of BERT's Attention", "comments": "BlackBoxNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large pre-trained neural networks such as BERT have had great recent success\nin NLP, motivating a growing body of research investigating what aspects of\nlanguage they are able to learn from unlabeled data. Most recent analysis has\nfocused on model outputs (e.g., language model surprisal) or internal vector\nrepresentations (e.g., probing classifiers). Complementary to these works, we\npropose methods for analyzing the attention mechanisms of pre-trained models\nand apply them to BERT. BERT's attention heads exhibit patterns such as\nattending to delimiter tokens, specific positional offsets, or broadly\nattending over the whole sentence, with heads in the same layer often\nexhibiting similar behaviors. We further show that certain attention heads\ncorrespond well to linguistic notions of syntax and coreference. For example,\nwe find heads that attend to the direct objects of verbs, determiners of nouns,\nobjects of prepositions, and coreferent mentions with remarkably high accuracy.\nLastly, we propose an attention-based probing classifier and use it to further\ndemonstrate that substantial syntactic information is captured in BERT's\nattention.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 01:31:41 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Clark", "Kevin", ""], ["Khandelwal", "Urvashi", ""], ["Levy", "Omer", ""], ["Manning", "Christopher D.", ""]]}, {"id": "1906.04362", "submitter": "Chongyang Tao", "authors": "Xueliang Zhao, Chongyang Tao, Wei Wu, Can Xu, Dongyan Zhao, Rui Yan", "title": "A Document-grounded Matching Network for Response Selection in\n  Retrieval-based Chatbots", "comments": null, "journal-ref": "IJCAI 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a document-grounded matching network (DGMN) for response selection\nthat can power a knowledge-aware retrieval-based chatbot system. The challenges\nof building such a model lie in how to ground conversation contexts with\nbackground documents and how to recognize important information in the\ndocuments for matching. To overcome the challenges, DGMN fuses information in a\ndocument and a context into representations of each other, and dynamically\ndetermines if grounding is necessary and importance of different parts of the\ndocument and the context through hierarchical interaction with a response at\nthe matching step. Empirical studies on two public data sets indicate that DGMN\ncan significantly improve upon state-of-the-art methods and at the same time\nenjoys good interpretability.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 03:00:34 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Zhao", "Xueliang", ""], ["Tao", "Chongyang", ""], ["Wu", "Wei", ""], ["Xu", "Can", ""], ["Zhao", "Dongyan", ""], ["Yan", "Rui", ""]]}, {"id": "1906.04382", "submitter": "Yichong Xu", "authors": "Yichong Xu and Xiaodong Liu and Chunyuan Li and Hoifung Poon and\n  Jianfeng Gao", "title": "DoubleTransfer at MEDIQA 2019: Multi-Source Transfer Learning for\n  Natural Language Understanding in the Medical Domain", "comments": "Proceedings of the BioNLP 2019 workshop, ACL 2019; 7 pages, 5 tables,\n  1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes our competing system to enter the MEDIQA-2019\ncompetition. We use a multi-source transfer learning approach to transfer the\nknowledge from MT-DNN and SciBERT to natural language understanding tasks in\nthe medical domain. For transfer learning fine-tuning, we use multi-task\nlearning on NLI, RQE and QA tasks on general and medical domains to improve\nperformance. The proposed methods are proved effective for natural language\nunderstanding in the medical domain, and we rank the first place on the QA\ntask.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 04:07:37 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Xu", "Yichong", ""], ["Liu", "Xiaodong", ""], ["Li", "Chunyuan", ""], ["Poon", "Hoifung", ""], ["Gao", "Jianfeng", ""]]}, {"id": "1906.04393", "submitter": "Yi Tay", "authors": "Yi Tay, Aston Zhang, Luu Anh Tuan, Jinfeng Rao, Shuai Zhang, Shuohang\n  Wang, Jie Fu, Siu Cheung Hui", "title": "Lightweight and Efficient Neural Natural Language Processing with\n  Quaternion Networks", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many state-of-the-art neural models for NLP are heavily parameterized and\nthus memory inefficient. This paper proposes a series of lightweight and memory\nefficient neural architectures for a potpourri of natural language processing\n(NLP) tasks. To this end, our models exploit computation using Quaternion\nalgebra and hypercomplex spaces, enabling not only expressive inter-component\ninteractions but also significantly ($75\\%$) reduced parameter size due to\nlesser degrees of freedom in the Hamilton product. We propose Quaternion\nvariants of models, giving rise to new architectures such as the Quaternion\nattention Model and Quaternion Transformer. Extensive experiments on a battery\nof NLP tasks demonstrates the utility of proposed Quaternion-inspired models,\nenabling up to $75\\%$ reduction in parameter size without significant loss in\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 04:56:17 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Tay", "Yi", ""], ["Zhang", "Aston", ""], ["Tuan", "Luu Anh", ""], ["Rao", "Jinfeng", ""], ["Zhang", "Shuai", ""], ["Wang", "Shuohang", ""], ["Fu", "Jie", ""], ["Hui", "Siu Cheung", ""]]}, {"id": "1906.04413", "submitter": "Chongyang Tao", "authors": "Jiazhan Feng, Chongyang Tao, Wei Wu, Yansong Feng, Dongyan Zhao, Rui\n  Yan", "title": "Learning a Matching Model with Co-teaching for Multi-turn Response\n  Selection in Retrieval-based Dialogue Systems", "comments": null, "journal-ref": "ACL 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study learning of a matching model for response selection in\nretrieval-based dialogue systems. The problem is equally important with\ndesigning the architecture of a model, but is less explored in existing\nliterature. To learn a robust matching model from noisy training data, we\npropose a general co-teaching framework with three specific teaching strategies\nthat cover both teaching with loss functions and teaching with data curriculum.\nUnder the framework, we simultaneously learn two matching models with\nindependent training sets. In each iteration, one model transfers the knowledge\nlearned from its training set to the other model, and at the same time receives\nthe guide from the other model on how to overcome noise in training. Through\nbeing both a teacher and a student, the two models learn from each other and\nget improved together. Evaluation results on two public data sets indicate that\nthe proposed learning approach can generally and significantly improve the\nperformance of existing matching models.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 06:55:04 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Feng", "Jiazhan", ""], ["Tao", "Chongyang", ""], ["Wu", "Wei", ""], ["Feng", "Yansong", ""], ["Zhao", "Dongyan", ""], ["Yan", "Rui", ""]]}, {"id": "1906.04447", "submitter": "Peter beim Graben", "authors": "Peter beim Graben, Ronald R\\\"omer, Werner Meyer, Markus Huber, and\n  Matthias Wolff", "title": "Reinforcement Learning of Minimalist Numeral Grammars", "comments": "13 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech-controlled user interfaces facilitate the operation of devices and\nhousehold functions to laymen. State-of-the-art language technology scans the\nacoustically analyzed speech signal for relevant keywords that are subsequently\ninserted into semantic slots to interpret the user's intent. In order to\ndevelop proper cognitive information and communication technologies, simple\nslot-filling should be replaced by utterance meaning transducers (UMT) that are\nbased on semantic parsers and a \\emph{mental lexicon}, comprising syntactic,\nphonetic and semantic features of the language under consideration. This\nlexicon must be acquired by a cognitive agent during interaction with its\nusers. We outline a reinforcement learning algorithm for the acquisition of the\nsyntactic morphology and arithmetic semantics of English numerals, based on\nminimalist grammar (MG), a recent computational implementation of generative\nlinguistics. Number words are presented to the agent by a teacher in form of\nutterance meaning pairs (UMP) where the meanings are encoded as arithmetic\nterms from a suitable term algebra. Since MG encodes universal linguistic\ncompetence through inference rules, thereby separating innate linguistic\nknowledge from the contingently acquired lexicon, our approach unifies\ngenerative grammar and reinforcement learning, hence potentially resolving the\nstill pending Chomsky-Skinner controversy.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 08:54:23 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Graben", "Peter beim", ""], ["R\u00f6mer", "Ronald", ""], ["Meyer", "Werner", ""], ["Huber", "Markus", ""], ["Wolff", "Matthias", ""]]}, {"id": "1906.04464", "submitter": "Sibei Yang", "authors": "Sibei Yang, Guanbin Li, Yizhou Yu", "title": "Relationship-Embedded Representation Learning for Grounding Referring\n  Expressions", "comments": "This paper is going to appear in TPAMI. Code is available at\n  https://github.com/sibeiyang/sgmn/tree/master/lib/cmrin_models", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grounding referring expressions in images aims to locate the object instance\nin an image described by a referring expression. It involves a joint\nunderstanding of natural language and image content, and is essential for a\nrange of visual tasks related to human-computer interaction. As a\nlanguage-to-vision matching task, the core of this problem is to not only\nextract all the necessary information (i.e., objects and the relationships\namong them) in both the image and referring expression, but also make full use\nof context information to align cross-modal semantic concepts in the extracted\ninformation. Unfortunately, existing work on grounding referring expressions\nfails to accurately extract multi-order relationships from the referring\nexpression and associate them with the objects and their related contexts in\nthe image. In this paper, we propose a Cross-Modal Relationship Extractor\n(CMRE) to adaptively highlight objects and relationships (spatial and semantic\nrelations) related to the given expression with a cross-modal attention\nmechanism, and represent the extracted information as a language-guided visual\nrelation graph. In addition, we propose a Gated Graph Convolutional Network\n(GGCN) to compute multimodal semantic contexts by fusing information from\ndifferent modes and propagating multimodal information in the structured\nrelation graph. Experimental results on three common benchmark datasets show\nthat our Cross-Modal Relationship Inference Network, which consists of CMRE and\nGGCN, significantly surpasses all existing state-of-the-art methods. Code is\navailable at https://github.com/sibeiyang/sgmn/tree/master/lib/cmrin_models\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 09:47:26 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 03:45:41 GMT"}, {"version": "v3", "created": "Sun, 19 Apr 2020 11:04:35 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Yang", "Sibei", ""], ["Li", "Guanbin", ""], ["Yu", "Yizhou", ""]]}, {"id": "1906.04466", "submitter": "Hong Wang", "authors": "Hong Wang, Xin Wang, Wenhan Xiong, Mo Yu, Xiaoxiao Guo, Shiyu Chang,\n  William Yang Wang", "title": "Self-Supervised Learning for Contextualized Extractive Summarization", "comments": "Accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing models for extractive summarization are usually trained from scratch\nwith a cross-entropy loss, which does not explicitly capture the global context\nat the document level. In this paper, we aim to improve this task by\nintroducing three auxiliary pre-training tasks that learn to capture the\ndocument-level context in a self-supervised fashion. Experiments on the\nwidely-used CNN/DM dataset validate the effectiveness of the proposed auxiliary\ntasks. Furthermore, we show that after pre-training, a clean model with simple\nbuilding blocks is able to outperform previous state-of-the-art that are\ncarefully designed.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 09:53:17 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Wang", "Hong", ""], ["Wang", "Xin", ""], ["Xiong", "Wenhan", ""], ["Yu", "Mo", ""], ["Guo", "Xiaoxiao", ""], ["Chang", "Shiyu", ""], ["Wang", "William Yang", ""]]}, {"id": "1906.04501", "submitter": "Pinlong Zhao", "authors": "Pinlong Zhaoa, Linlin Houb, Ou Wua", "title": "Modeling Sentiment Dependencies with Graph Convolutional Networks for\n  Aspect-level Sentiment Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect-level sentiment classification aims to distinguish the sentiment\npolarities over one or more aspect terms in a sentence. Existing approaches\nmostly model different aspects in one sentence independently, which ignore the\nsentiment dependencies between different aspects. However, we find such\ndependency information between different aspects can bring additional valuable\ninformation. In this paper, we propose a novel aspect-level sentiment\nclassification model based on graph convolutional networks (GCN) which can\neffectively capture the sentiment dependencies between multi-aspects in one\nsentence. Our model firstly introduces bidirectional attention mechanism with\nposition encoding to model aspect-specific representations between each aspect\nand its context words, then employs GCN over the attention mechanism to capture\nthe sentiment dependencies between different aspects in one sentence. We\nevaluate the proposed approach on the SemEval 2014 datasets. Experiments show\nthat our model outperforms the state-of-the-art methods. We also conduct\nexperiments to evaluate the effectiveness of GCN module, which indicates that\nthe dependencies between different aspects is highly helpful in aspect-level\nsentiment classification.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 11:26:25 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Zhaoa", "Pinlong", ""], ["Houb", "Linlin", ""], ["Wua", "Ou", ""]]}, {"id": "1906.04571", "submitter": "Hanna Wallach", "authors": "Ran Zmigrod and Sabrina J. Mielke and Hanna Wallach and Ryan Cotterell", "title": "Counterfactual Data Augmentation for Mitigating Gender Stereotypes in\n  Languages with Rich Morphology", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gender stereotypes are manifest in most of the world's languages and are\nconsequently propagated or amplified by NLP systems. Although research has\nfocused on mitigating gender stereotypes in English, the approaches that are\ncommonly employed produce ungrammatical sentences in morphologically rich\nlanguages. We present a novel approach for converting between\nmasculine-inflected and feminine-inflected sentences in such languages. For\nSpanish and Hebrew, our approach achieves F1 scores of 82% and 73% at the level\nof tags and accuracies of 90% and 87% at the level of forms. By evaluating our\napproach using four different languages, we show that, on average, it reduces\ngender stereotyping by a factor of 2.5 without any sacrifice to grammaticality.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 13:22:24 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 18:36:41 GMT"}, {"version": "v3", "created": "Wed, 27 May 2020 15:46:45 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Zmigrod", "Ran", ""], ["Mielke", "Sabrina J.", ""], ["Wallach", "Hanna", ""], ["Cotterell", "Ryan", ""]]}, {"id": "1906.04580", "submitter": "Qiran Gong", "authors": "Hao Peng, Jianxin Li, Qiran Gong, Yangqiu Song, Yuanxing Ning, Kunfeng\n  Lai, Philip S. Yu", "title": "Fine-grained Event Categorization with Heterogeneous Graph Convolutional\n  Networks", "comments": "Accepted by IJCAI'19(International Joint Conference on Artificial\n  Intelligence)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Events are happening in real-world and real-time, which can be planned and\norganized occasions involving multiple people and objects. Social media\nplatforms publish a lot of text messages containing public events with\ncomprehensive topics. However, mining social events is challenging due to the\nheterogeneous event elements in texts and explicit and implicit social network\nstructures. In this paper, we design an event meta-schema to characterize the\nsemantic relatedness of social events and build an event-based heterogeneous\ninformation network (HIN) integrating information from external knowledge base,\nand propose a novel Pair-wise Popularity Graph Convolutional Network (PP-GCN)\nbased fine-grained social event categorization model. We propose a\nKnowledgeable meta-paths Instances based social Event Similarity (KIES) between\nevents and build a weighted adjacent matrix as input to the PP-GCN model.\nComprehensive experiments on real data collections are conducted to compare\nvarious social event detection and clustering tasks. Experimental results\ndemonstrate that our proposed framework outperforms other alternative social\nevent categorization techniques.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 07:08:20 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Peng", "Hao", ""], ["Li", "Jianxin", ""], ["Gong", "Qiran", ""], ["Song", "Yangqiu", ""], ["Ning", "Yuanxing", ""], ["Lai", "Kunfeng", ""], ["Yu", "Philip S.", ""]]}, {"id": "1906.04618", "submitter": "Minghao Hu", "authors": "Minghao Hu, Yuxing Peng, Zhen Huang and Dongsheng Li", "title": "Retrieve, Read, Rerank: Towards End-to-End Multi-Document Reading\n  Comprehension", "comments": "To appear at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the reading comprehension task in which multiple\ndocuments are given as input. Prior work has shown that a pipeline of\nretriever, reader, and reranker can improve the overall performance. However,\nthe pipeline system is inefficient since the input is re-encoded within each\nmodule, and is unable to leverage upstream components to help downstream\ntraining. In this work, we present RE$^3$QA, a unified question answering model\nthat combines context retrieving, reading comprehension, and answer reranking\nto predict the final answer. Unlike previous pipelined approaches, RE$^3$QA\nshares contextualized text representation across different components, and is\ncarefully designed to use high-quality upstream outputs (e.g., retrieved\ncontext or candidate answers) for directly supervising downstream modules\n(e.g., the reader or the reranker). As a result, the whole network can be\ntrained end-to-end to avoid the context inconsistency problem. Experiments show\nthat our model outperforms the pipelined baseline and achieves state-of-the-art\nresults on two versions of TriviaQA and two variants of SQuAD.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 14:18:43 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Hu", "Minghao", ""], ["Peng", "Yuxing", ""], ["Huang", "Zhen", ""], ["Li", "Dongsheng", ""]]}, {"id": "1906.04655", "submitter": "Mitsuo Yoshida", "authors": "Masato Kikuchi, Mitsuo Yoshida, Kyoji Umemura", "title": "Journal Name Extraction from Japanese Scientific News Articles", "comments": "The Asia-Pacific Signal and Information Processing Association Annual\n  Summit and Conference 2018 (APSIPA ASC 2018)", "journal-ref": null, "doi": "10.23919/APSIPA.2018.8659765", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Japanese scientific news articles, although the research results are\ndescribed clearly, the article's sources tend to be uncited. This makes it\ndifficult for readers to know the details of the research. In this paper, we\naddress the task of extracting journal names from Japanese scientific news\narticles. We hypothesize that a journal name is likely to occur in a specific\ncontext. To support the hypothesis, we construct a character-based method and\nextract journal names using this method. This method only uses the left and\nright context features of journal names. The results of the journal name\nextractions suggest that the distribution hypothesis plays an important role in\nidentifying the journal names.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 15:35:43 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Kikuchi", "Masato", ""], ["Yoshida", "Mitsuo", ""], ["Umemura", "Kyoji", ""]]}, {"id": "1906.04684", "submitter": "Fenia Christopoulou", "authors": "Sunil Kumar Sahu, Fenia Christopoulou, Makoto Miwa, Sophia Ananiadou", "title": "Inter-sentence Relation Extraction with Document-level Graph\n  Convolutional Neural Network", "comments": "Accepted in Association for Computational Linguistics (ACL) 2019 8\n  pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inter-sentence relation extraction deals with a number of complex semantic\nrelationships in documents, which require local, non-local, syntactic and\nsemantic dependencies. Existing methods do not fully exploit such dependencies.\nWe present a novel inter-sentence relation extraction model that builds a\nlabelled edge graph convolutional neural network model on a document-level\ngraph. The graph is constructed using various inter- and intra-sentence\ndependencies to capture local and non-local dependency information. In order to\npredict the relation of an entity pair, we utilise multi-instance learning with\nbi-affine pairwise scoring. Experimental results show that our model achieves\ncomparable performance to the state-of-the-art neural models on two\nbiochemistry datasets. Our analysis shows that all the types in the graph are\neffective for inter-sentence relation extraction.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 16:30:27 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Sahu", "Sunil Kumar", ""], ["Christopoulou", "Fenia", ""], ["Miwa", "Makoto", ""], ["Ananiadou", "Sophia", ""]]}, {"id": "1906.04687", "submitter": "Laura Perez-Beltrachini", "authors": "Laura Perez-Beltrachini, Yang Liu, and Mirella Lapata", "title": "Generating Summaries with Topic Templates and Structured Convolutional\n  Decoders", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing neural generation approaches create multi-sentence text as a single\nsequence. In this paper we propose a structured convolutional decoder that is\nguided by the content structure of target summaries. We compare our model with\nexisting sequential decoders on three data sets representing different domains.\nAutomatic and human evaluation demonstrate that our summaries have better\ncontent coverage.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 16:39:11 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Perez-Beltrachini", "Laura", ""], ["Liu", "Yang", ""], ["Lapata", "Mirella", ""]]}, {"id": "1906.04701", "submitter": "David Vilares", "authors": "David Vilares and Carlos G\\'omez-Rodr\\'iguez", "title": "HEAD-QA: A Healthcare Dataset for Complex Reasoning", "comments": "ACL 2019 (short papers)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present HEAD-QA, a multi-choice question answering testbed to encourage\nresearch on complex reasoning. The questions come from exams to access a\nspecialized position in the Spanish healthcare system, and are challenging even\nfor highly specialized humans. We then consider monolingual (Spanish) and\ncross-lingual (to English) experiments with information retrieval and neural\ntechniques. We show that: (i) HEAD-QA challenges current methods, and (ii) the\nresults lag well behind human performance, demonstrating its usefulness as a\nbenchmark for future work.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 17:06:49 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Vilares", "David", ""], ["G\u00f3mez-Rodr\u00edguez", "Carlos", ""]]}, {"id": "1906.04706", "submitter": "Amita Misra", "authors": "Amita Misra, Mansurul Bhuiyan, Jalal Mahmud, and Saurabh Tripathy", "title": "Using Structured Representation and Data: A Hybrid Model for Negation\n  and Sentiment in Customer Service Conversations", "comments": null, "journal-ref": "Proceedings of the 10th Workshop on Computational Approaches to\n  Subjectivity, Sentiment and Social Media Analysis, 2019", "doi": null, "report-no": "https://www.aclweb.org/anthology/W19-1306", "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Twitter customer service interactions have recently emerged as an effective\nplatform to respond and engage with customers. In this work, we explore the\nrole of negation in customer service interactions, particularly applied to\nsentiment analysis. We define rules to identify true negation cues and scope\nmore suited to conversational data than existing general review data. Using\nsemantic knowledge and syntactic structure from constituency parse trees, we\npropose an algorithm for scope detection that performs comparable to state of\nthe art BiLSTM. We further investigate the results of negation scope detection\nfor the sentiment prediction task on customer service conversation data using\nboth a traditional SVM and a Neural Network. We propose an antonym dictionary\nbased method for negation applied to a CNN-LSTM combination model for sentiment\nanalysis. Experimental results show that the antonym-based method outperforms\nthe previous lexicon-based and neural network methods.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 17:15:32 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Misra", "Amita", ""], ["Bhuiyan", "Mansurul", ""], ["Mahmud", "Jalal", ""], ["Tripathy", "Saurabh", ""]]}, {"id": "1906.04726", "submitter": "Sabrina Mielke", "authors": "Sabrina J. Mielke, Ryan Cotterell, Kyle Gorman, Brian Roark, Jason\n  Eisner", "title": "What Kind of Language Is Hard to Language-Model?", "comments": "Published at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How language-agnostic are current state-of-the-art NLP tools? Are there some\ntypes of language that are easier to model with current methods? In prior work\n(Cotterell et al., 2018) we attempted to address this question for language\nmodeling, and observed that recurrent neural network language models do not\nperform equally well over all the high-resource European languages found in the\nEuroparl corpus. We speculated that inflectional morphology may be the primary\nculprit for the discrepancy. In this paper, we extend these earlier experiments\nto cover 69 languages from 13 language families using a multilingual Bible\ncorpus. Methodologically, we introduce a new paired-sample multiplicative\nmixed-effects model to obtain language difficulty coefficients from\nat-least-pairwise parallel corpora. In other words, the model is aware of\ninter-sentence variation and can handle missing data. Exploiting this model, we\nshow that \"translationese\" is not any easier to model than natively written\nlanguage in a fair comparison. Trying to answer the question of what features\ndifficult languages have in common, we try and fail to reproduce our earlier\n(Cotterell et al., 2018) observation about morphological complexity and instead\nreveal far simpler statistics of the data that seem to drive complexity in a\nmuch larger sample.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 17:56:08 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 18:38:57 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Mielke", "Sabrina J.", ""], ["Cotterell", "Ryan", ""], ["Gorman", "Kyle", ""], ["Roark", "Brian", ""], ["Eisner", "Jason", ""]]}, {"id": "1906.04760", "submitter": "Alexander Hoyle", "authors": "Alexander Hoyle, Wolf-Sonkin, Hanna Wallach, Isabelle Augenstein, and\n  Ryan Cotterell", "title": "Unsupervised Discovery of Gendered Language through Latent-Variable\n  Modeling", "comments": "To appear in ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studying the ways in which language is gendered has long been an area of\ninterest in sociolinguistics. Studies have explored, for example, the speech of\nmale and female characters in film and the language used to describe male and\nfemale politicians. In this paper, we aim not to merely study this phenomenon\nqualitatively, but instead to quantify the degree to which the language used to\ndescribe men and women is different and, moreover, different in a positive or\nnegative way. To that end, we introduce a generative latent-variable model that\njointly represents adjective (or verb) choice, with its sentiment, given the\nnatural gender of a head (or dependent) noun. We find that there are\nsignificant differences between descriptions of male and female nouns and that\nthese differences align with common gender stereotypes: Positive adjectives\nused to describe women are more often related to their bodies than adjectives\nused to describe men.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 18:18:29 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Hoyle", "Alexander", ""], ["Wolf-Sonkin", "", ""], ["Wallach", "Hanna", ""], ["Augenstein", "Isabelle", ""], ["Cotterell", "Ryan", ""]]}, {"id": "1906.04761", "submitter": "Sihao Chen", "authors": "Sihao Chen and Daniel Khashabi and Chris Callison-Burch and Dan Roth", "title": "PerspectroScope: A Window to the World of Diverse Perspectives", "comments": "To appear in ACL 2019 system demonstration track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This work presents PerspectroScope, a web-based system which lets users query\na discussion-worthy natural language claim, and extract and visualize various\nperspectives in support or against the claim, along with evidence supporting\neach perspective. The system thus lets users explore various perspectives that\ncould touch upon aspects of the issue at hand.The system is built as a\ncombination of retrieval engines and learned textual-entailment-like\nclassifiers built using a few recent developments in natural language\nunderstanding. To make the system more adaptive, expand its coverage, and\nimprove its decisions over time, our platform employs various mechanisms to get\ncorrections from the users.\n  PerspectroScope is available at github.com/CogComp/perspectroscope.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 18:18:39 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Chen", "Sihao", ""], ["Khashabi", "Daniel", ""], ["Callison-Burch", "Chris", ""], ["Roth", "Dan", ""]]}, {"id": "1906.04772", "submitter": "Vered Shwartz", "authors": "Vered Shwartz", "title": "A Systematic Comparison of English Noun Compound Representations", "comments": "MWE workshop @ ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building meaningful representations of noun compounds is not trivial since\nmany of them scarcely appear in the corpus. To that end, composition functions\napproximate the distributional representation of a noun compound by combining\nits constituent distributional vectors. In the more general case, phrase\nembeddings have been trained by minimizing the distance between the vectors\nrepresenting paraphrases. We compare various types of noun compound\nrepresentations, including distributional, compositional, and paraphrase-based\nrepresentations, through a series of tasks and analyses, and with an extensive\nnumber of underlying word embeddings. We find that indeed, in most cases,\ncomposition functions produce higher quality representations than\ndistributional ones, and they improve with computational power. No single\nfunction performs best in all scenarios, suggesting that a joint training\nobjective may produce improved representations.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 19:03:09 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Shwartz", "Vered", ""]]}, {"id": "1906.04836", "submitter": "Javier S\\'anchez-Junquera", "authors": "Javier S\\'anchez-Junquera, Paolo Rosso, Manuel Montes-y-G\\'omez, and\n  Simone Paolo Ponzetto", "title": "Unmasking Bias in News", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present experiments on detecting hyperpartisanship in news using a\n'masking' method that allows us to assess the role of style vs. content for the\ntask at hand. Our results corroborate previous research on this task in that\ntopic related features yield better results than stylistic ones. We\nadditionally show that competitive results can be achieved by simply including\nhigher-length n-grams, which suggests the need to develop more challenging\ndatasets and tasks that address implicit and more subtle forms of bias.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 21:37:51 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["S\u00e1nchez-Junquera", "Javier", ""], ["Rosso", "Paolo", ""], ["Montes-y-G\u00f3mez", "Manuel", ""], ["Ponzetto", "Simone Paolo", ""]]}, {"id": "1906.04903", "submitter": "Hieu Tran", "authors": "Ngoc Tran, Hieu Tran, Son Nguyen, Hoan Nguyen, Tien N. Nguyen", "title": "Does BLEU Score Work for Code Migration?", "comments": "12 pages, 5 figures, ICPC '19 Proceedings of the 27th International\n  Conference on Program Comprehension", "journal-ref": null, "doi": "10.1109/ICPC.2019.00034", "report-no": null, "categories": "cs.SE cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical machine translation (SMT) is a fast-growing sub-field of\ncomputational linguistics. Until now, the most popular automatic metric to\nmeasure the quality of SMT is BiLingual Evaluation Understudy (BLEU) score.\nLately, SMT along with the BLEU metric has been applied to a Software\nEngineering task named code migration. (In)Validating the use of BLEU score\ncould advance the research and development of SMT-based code migration tools.\nUnfortunately, there is no study to approve or disapprove the use of BLEU score\nfor source code. In this paper, we conducted an empirical study on BLEU score\nto (in)validate its suitability for the code migration task due to its\ninability to reflect the semantics of source code. In our work, we use human\njudgment as the ground truth to measure the semantic correctness of the\nmigrated code. Our empirical study demonstrates that BLEU does not reflect\ntranslation quality due to its weak correlation with the semantic correctness\nof translated code. We provided counter-examples to show that BLEU is\nineffective in comparing the translation quality between SMT-based models. Due\nto BLEU's ineffectiveness for code migration task, we propose an alternative\nmetric RUBY, which considers lexical, syntactical, and semantic representations\nof source code. We verified that RUBY achieves a higher correlation coefficient\nwith the semantic correctness of migrated code, 0.775 in comparison with 0.583\nof BLEU score. We also confirmed the effectiveness of RUBY in reflecting the\nchanges in translation quality of SMT-based translation models. With its\nadvantages, RUBY can be used to evaluate SMT-based code migration models.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 02:48:57 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Tran", "Ngoc", ""], ["Tran", "Hieu", ""], ["Nguyen", "Son", ""], ["Nguyen", "Hoan", ""], ["Nguyen", "Tien N.", ""]]}, {"id": "1906.04908", "submitter": "Sumith Kulal", "authors": "Sumith Kulal, Panupong Pasupat, Kartik Chandra, Mina Lee, Oded Padon,\n  Alex Aiken, Percy Liang", "title": "SPoC: Search-based Pseudocode to Code", "comments": "Under submission to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of mapping pseudocode to long programs that are\nfunctionally correct. Given test cases as a mechanism to validate programs, we\nsearch over the space of possible translations of the pseudocode to find a\nprogram that passes the validation. However, without proper credit assignment\nto localize the sources of program failures, it is difficult to guide search\ntoward more promising programs. We propose to perform credit assignment based\non signals from compilation errors, which constitute 88.7% of program failures.\nConcretely, we treat the translation of each pseudocode line as a discrete\nportion of the program, and whenever a synthesized program fails to compile, an\nerror localization method tries to identify the portion of the program\nresponsible for the failure. We then focus search over alternative translations\nof the pseudocode for those portions. For evaluation, we collected the SPoC\ndataset (Search-based Pseudocode to Code) containing 18,356 programs with\nhuman-authored pseudocode and test cases. Under a budget of 100 program\ncompilations, performing search improves the synthesis success rate over using\nthe top-one translation of the pseudocode from 25.6% to 44.7%.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 03:13:18 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Kulal", "Sumith", ""], ["Pasupat", "Panupong", ""], ["Chandra", "Kartik", ""], ["Lee", "Mina", ""], ["Padon", "Oded", ""], ["Aiken", "Alex", ""], ["Liang", "Percy", ""]]}, {"id": "1906.04914", "submitter": "Suraj Tripathi", "authors": "Abhay Kumar, Nishant Jain, Suraj Tripathi, Chirag Singh", "title": "From Fully Supervised to Zero Shot Settings for Twitter Hashtag\n  Recommendation", "comments": "Accepted in CICLing 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a comprehensive end-to-end pipeline for Twitter hashtags\nrecommendation system including data collection, supervised training setting\nand zero shot training setting. In the supervised training setting, we have\nproposed and compared the performance of various deep learning architectures,\nnamely Convolutional Neural Network (CNN), Recurrent Neural Network (RNN) and\nTransformer Network. However, it is not feasible to collect data for all\npossible hashtag labels and train a classifier model on them. To overcome this\nlimitation, we propose a Zero Shot Learning (ZSL) paradigm for predicting\nunseen hashtag labels by learning the relationship between the semantic space\nof tweets and the embedding space of hashtag labels. We evaluated various\nstate-of-the-art ZSL methods like Convex combination of Semantic Embedding\n(ConSE), Embarrassingly Simple Zero-Shot Learning (ESZSL) and Deep Embedding\nModel for Zero-Shot Learning (DEM-ZSL) for the hashtag recommendation task. We\ndemonstrate the effectiveness and scalability of ZSL methods for the\nrecommendation of unseen hashtags. To the best of our knowledge, this is the\nfirst quantitative evaluation of ZSL methods to date for unseen hashtags\nrecommendations from tweet text.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 17:38:28 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Kumar", "Abhay", ""], ["Jain", "Nishant", ""], ["Tripathi", "Suraj", ""], ["Singh", "Chirag", ""]]}, {"id": "1906.04937", "submitter": "Qiang Ning", "authors": "Qiang Ning, Hangfeng He, Chuchu Fan, Dan Roth", "title": "Partial Or Complete, That's The Question", "comments": "Long paper accepted by NAACL'19. 11 pages and 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many structured learning tasks, the data annotation process is complex\nand costly. Existing annotation schemes usually aim at acquiring completely\nannotated structures, under the common perception that partial structures are\nof low quality and could hurt the learning process. This paper questions this\ncommon perception, motivated by the fact that structures consist of\ninterdependent sets of variables. Thus, given a fixed budget, partly annotating\neach structure may provide the same level of supervision, while allowing for\nmore structures to be annotated. We provide an information theoretic\nformulation for this perspective and use it, in the context of three diverse\nstructured learning tasks, to show that learning from partial structures can\nsometimes outperform learning from complete ones. Our findings may provide\nimportant insights into structured data annotation schemes and could support\nprogress in learning protocols for structured tasks.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 04:35:11 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Ning", "Qiang", ""], ["He", "Hangfeng", ""], ["Fan", "Chuchu", ""], ["Roth", "Dan", ""]]}, {"id": "1906.04940", "submitter": "Qiang Ning", "authors": "Qiang Ning, Ben Zhou, Zhili Feng, Haoruo Peng, Dan Roth", "title": "CogCompTime: A Tool for Understanding Time in Natural Language Text", "comments": "Demo paper appeared in EMNLP'18. 6 pages and 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic extraction of temporal information in text is an important\ncomponent of natural language understanding. It involves two basic tasks: (1)\nUnderstanding time expressions that are mentioned explicitly in text (e.g.,\nFebruary 27, 1998 or tomorrow), and (2) Understanding temporal information that\nis conveyed implicitly via relations. In this paper, we introduce CogCompTime,\na system that has these two important functionalities. It incorporates the most\nrecent progress, achieves state-of-the-art performance, and is publicly\navailable.1 We believe that this demo will be useful for multiple time-aware\napplications and provide valuable insight for future research in temporal\nunderstanding.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 04:48:27 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Ning", "Qiang", ""], ["Zhou", "Ben", ""], ["Feng", "Zhili", ""], ["Peng", "Haoruo", ""], ["Roth", "Dan", ""]]}, {"id": "1906.04941", "submitter": "Qiang Ning", "authors": "Qiang Ning, Zhili Feng, Hao Wu, Dan Roth", "title": "Joint Reasoning for Temporal and Causal Relations", "comments": "Long paper appeared in ACL'18. 11 pages and 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding temporal and causal relations between events is a fundamental\nnatural language understanding task. Because a cause must be before its effect\nin time, temporal and causal relations are closely related and one relation\neven dictates the other one in many cases. However, limited attention has been\npaid to studying these two relations jointly. This paper presents a joint\ninference framework for them using constrained conditional models (CCMs).\nSpecifically, we formulate the joint problem as an integer linear programming\n(ILP) problem, enforcing constraints inherently in the nature of time and\ncausality. We show that the joint inference framework results in statistically\nsignificant improvement in the extraction of both temporal and causal relations\nfrom text.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 04:58:51 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Ning", "Qiang", ""], ["Feng", "Zhili", ""], ["Wu", "Hao", ""], ["Roth", "Dan", ""]]}, {"id": "1906.04943", "submitter": "Qiang Ning", "authors": "Qiang Ning, Zhili Feng, Dan Roth", "title": "A Structured Learning Approach to Temporal Relation Extraction", "comments": "Long paper appeared in EMNLP'17. 11 pages and 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying temporal relations between events is an essential step towards\nnatural language understanding. However, the temporal relation between two\nevents in a story depends on, and is often dictated by, relations among other\nevents. Consequently, effectively identifying temporal relations between events\nis a challenging problem even for human annotators. This paper suggests that it\nis important to take these dependencies into account while learning to identify\nthese relations and proposes a structured learning approach to address this\nchallenge. As a byproduct, this provides a new perspective on handling missing\nrelations, a known issue that hurts existing methods. As we show, the proposed\napproach results in significant improvements on the two commonly used data sets\nfor this problem.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 05:07:42 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Ning", "Qiang", ""], ["Feng", "Zhili", ""], ["Roth", "Dan", ""]]}, {"id": "1906.04960", "submitter": "Hussein S. Al-Olimat", "authors": "Hussein S. Al-Olimat, Valerie L. Shalin, Krishnaprasad Thirunarayan\n  and Joy Prakash Sain", "title": "Towards Geocoding Spatial Expressions", "comments": "In Proceedings of the 27th ACM SIGSPATIAL International Conference on\n  Advances in Geographic Information Systems (SIGSPATIAL '19)", "journal-ref": null, "doi": "10.1145/3347146.3359356", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Imprecise composite location references formed using ad hoc spatial\nexpressions in English text makes the geocoding task challenging for both\ninference and evaluation. Typically such spatial expressions fill in\nunestablished areas with new toponyms for finer spatial referents. For example,\nthe spatial extent of the ad hoc spatial expression \"north of\" or \"50 minutes\naway from\" in relation to the toponym \"Dayton, OH\" refers to an ambiguous,\nimprecise area, requiring translation from this qualitative representation to a\nquantitative one with precise semantics using systems such as WGS84. Here we\nhighlight the challenges of geocoding such referents and propose a formal\nrepresentation that employs background knowledge, semantic approximations and\nrules, and fuzzy linguistic variables. We also discuss an appropriate\nevaluation technique for the task that is based on human contextualized and\nsubjective judgment.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 06:30:01 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 18:27:59 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Al-Olimat", "Hussein S.", ""], ["Shalin", "Valerie L.", ""], ["Thirunarayan", "Krishnaprasad", ""], ["Sain", "Joy Prakash", ""]]}, {"id": "1906.04980", "submitter": "Patrick Lewis", "authors": "Patrick Lewis, Ludovic Denoyer, Sebastian Riedel", "title": "Unsupervised Question Answering by Cloze Translation", "comments": "To appear in ACL 2019", "journal-ref": "Proceedings of the 57th Annual Meeting of the Association for\n  Computational Linguistics, 2019", "doi": "10.18653/v1/P19-1484", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obtaining training data for Question Answering (QA) is time-consuming and\nresource-intensive, and existing QA datasets are only available for limited\ndomains and languages. In this work, we explore to what extent high quality\ntraining data is actually required for Extractive QA, and investigate the\npossibility of unsupervised Extractive QA. We approach this problem by first\nlearning to generate context, question and answer triples in an unsupervised\nmanner, which we then use to synthesize Extractive QA training data\nautomatically. To generate such triples, we first sample random context\nparagraphs from a large corpus of documents and then random noun phrases or\nnamed entity mentions from these paragraphs as answers. Next we convert answers\nin context to \"fill-in-the-blank\" cloze questions and finally translate them\ninto natural questions. We propose and compare various unsupervised ways to\nperform cloze-to-natural question translation, including training an\nunsupervised NMT model using non-aligned corpora of natural questions and cloze\nquestions as well as a rule-based approach. We find that modern QA models can\nlearn to answer human questions surprisingly well using only synthetic training\ndata. We demonstrate that, without using the SQuAD training data at all, our\napproach achieves 56.4 F1 on SQuAD v1 (64.5 F1 when the answer is a Named\nentity mention), outperforming early supervised models.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 07:30:32 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 09:43:46 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Lewis", "Patrick", ""], ["Denoyer", "Ludovic", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1906.04991", "submitter": "Weikang Wang", "authors": "Weikang Wang, Jiajun Zhang, Qian Li, Mei-Yuh Hwang, Chengqing Zong,\n  Zhifei Li", "title": "Incremental Learning from Scratch for Task-Oriented Dialogue Systems", "comments": "ACL2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clarifying user needs is essential for existing task-oriented dialogue\nsystems. However, in real-world applications, developers can never guarantee\nthat all possible user demands are taken into account in the design phase.\nConsequently, existing systems will break down when encountering unconsidered\nuser needs. To address this problem, we propose a novel incremental learning\nframework to design task-oriented dialogue systems, or for short Incremental\nDialogue System (IDS), without pre-defining the exhaustive list of user needs.\nSpecifically, we introduce an uncertainty estimation module to evaluate the\nconfidence of giving correct responses. If there is high confidence, IDS will\nprovide responses to users. Otherwise, humans will be involved in the dialogue\nprocess, and IDS can learn from human intervention through an online learning\nmodule. To evaluate our method, we propose a new dataset which simulates\nunanticipated user needs in the deployment stage. Experiments show that IDS is\nrobust to unconsidered user actions, and can update itself online by smartly\nselecting only the most effective training data, and hence attains better\nperformance with less annotation cost.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 08:08:38 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Wang", "Weikang", ""], ["Zhang", "Jiajun", ""], ["Li", "Qian", ""], ["Hwang", "Mei-Yuh", ""], ["Zong", "Chengqing", ""], ["Li", "Zhifei", ""]]}, {"id": "1906.05000", "submitter": "Arne K\\\"ohn", "authors": "Max Friedrich, Arne K\\\"ohn, Gregor Wiedemann, Chris Biemann", "title": "Adversarial Learning of Privacy-Preserving Text Representations for\n  De-Identification of Medical Records", "comments": "Accepted at ACL 2019; camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  De-identification is the task of detecting protected health information (PHI)\nin medical text. It is a critical step in sanitizing electronic health records\n(EHRs) to be shared for research. Automatic de-identification classifierscan\nsignificantly speed up the sanitization process. However, obtaining a large and\ndiverse dataset to train such a classifier that works wellacross many types of\nmedical text poses a challenge as privacy laws prohibit the sharing of raw\nmedical records. We introduce a method to create privacy-preserving shareable\nrepresentations of medical text (i.e. they contain no PHI) that does not\nrequire expensive manual pseudonymization. These representations can be shared\nbetween organizations to create unified datasets for training de-identification\nmodels. Our representation allows training a simple LSTM-CRF de-identification\nmodel to an F1 score of 97.4%, which is comparable to a strong baseline that\nexposes private information in its representation. A robust, widely available\nde-identification classifier based on our representation could potentially\nenable studies for which de-identification would otherwise be too costly.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 08:29:24 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Friedrich", "Max", ""], ["K\u00f6hn", "Arne", ""], ["Wiedemann", "Gregor", ""], ["Biemann", "Chris", ""]]}, {"id": "1906.05012", "submitter": "Xiaojun Quan", "authors": "Kai Wang, Xiaojun Quan and Rui Wang", "title": "BiSET: Bi-directional Selective Encoding with Template for Abstractive\n  Summarization", "comments": "The 57th Annual Meeting of the Association for Computational\n  Linguistics (ACL 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The success of neural summarization models stems from the meticulous\nencodings of source articles. To overcome the impediments of limited and\nsometimes noisy training data, one promising direction is to make better use of\nthe available training data by applying filters during summarization. In this\npaper, we propose a novel Bi-directional Selective Encoding with Template\n(BiSET) model, which leverages template discovered from training data to softly\nselect key information from each source article to guide its summarization\nprocess. Extensive experiments on a standard summarization dataset were\nconducted and the results show that the template-equipped BiSET model manages\nto improve the summarization performance significantly with a new state of the\nart.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 09:03:26 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Wang", "Kai", ""], ["Quan", "Xiaojun", ""], ["Wang", "Rui", ""]]}, {"id": "1906.05039", "submitter": "Tharindu Ranasinghe Mr", "authors": "Nadeesha Pathirana, Sandaru Seneviratne, Rangika Samarawickrama, Shane\n  Wolff, Charith Chitraranjan, Uthayasanker Thayasivam, Tharindu Ranasinghe", "title": "Concept Discovery through Information Extraction in Restaurant Domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concept identification is a crucial step in understanding and building a\nknowledge base for any particular domain. However, it is not a simple task in\nvery large domains such as restaurants and hotel. In this paper, a novel\napproach of identifying a concept hierarchy and classifying unseen words into\nidentified concepts related to restaurant domain is presented. Sorting,\nidentifying, classifying of domain-related words manually is tedious and\ntherefore, the proposed process is automated to a great extent. Word embedding,\nhierarchical clustering, classification algorithms are effectively used to\nobtain concepts related to the restaurant domain. Further, this approach can\nalso be extended to create a semi-automatic ontology on restaurant domain.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 09:55:20 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Pathirana", "Nadeesha", ""], ["Seneviratne", "Sandaru", ""], ["Samarawickrama", "Rangika", ""], ["Wolff", "Shane", ""], ["Chitraranjan", "Charith", ""], ["Thayasivam", "Uthayasanker", ""], ["Ranasinghe", "Tharindu", ""]]}, {"id": "1906.05061", "submitter": "Vinit Ravishankar", "authors": "Vinit Ravishankar, Lilja {\\O}vrelid, Erik Velldal", "title": "Probing Multilingual Sentence Representations With X-Probe", "comments": "To appear at RepL4NLP '19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper extends the task of probing sentence representations for\nlinguistic insight in a multilingual domain. In doing so, we make two\ncontributions: first, we provide datasets for multilingual probing, derived\nfrom Wikipedia, in five languages, viz. English, French, German, Spanish and\nRussian. Second, we evaluate six sentence encoders for each language, each\ntrained by mapping sentence representations to English sentence\nrepresentations, using sentences in a parallel corpus. We discover that\ncross-lingually mapped representations are often better at retaining certain\nlinguistic information than representations derived from English encoders\ntrained on natural language inference (NLI) as a downstream task.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 11:21:05 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Ravishankar", "Vinit", ""], ["\u00d8vrelid", "Lilja", ""], ["Velldal", "Erik", ""]]}, {"id": "1906.05062", "submitter": "Priyanka Agrawal", "authors": "Priyanka Agrawal, Parag Jain, Ayushi Dalmia, Abhishek Bansal, Ashish\n  Mittal, Karthik Sankaranarayanan", "title": "Unified Semantic Parsing with Weak Supervision", "comments": "Association for Computational Linguistics (ACL) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic parsing over multiple knowledge bases enables a parser to exploit\nstructural similarities of programs across the multiple domains. However, the\nfundamental challenge lies in obtaining high-quality annotations of (utterance,\nprogram) pairs across various domains needed for training such models. To\novercome this, we propose a novel framework to build a unified multi-domain\nenabled semantic parser trained only with weak supervision (denotations).\nWeakly supervised training is particularly arduous as the program search space\ngrows exponentially in a multi-domain setting. To solve this, we incorporate a\nmulti-policy distillation mechanism in which we first train domain-specific\nsemantic parsers (teachers) using weak supervision in the absence of the ground\ntruth programs, followed by training a single unified parser (student) from the\ndomain specific policies obtained from these teachers. The resultant semantic\nparser is not only compact but also generalizes better, and generates more\naccurate programs. It further does not require the user to provide a domain\nlabel while querying. On the standard Overnight dataset (containing multiple\ndomains), we demonstrate that the proposed model improves performance by 20% in\nterms of denotation accuracy in comparison to baseline techniques.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 11:27:38 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Agrawal", "Priyanka", ""], ["Jain", "Parag", ""], ["Dalmia", "Ayushi", ""], ["Bansal", "Abhishek", ""], ["Mittal", "Ashish", ""], ["Sankaranarayanan", "Karthik", ""]]}, {"id": "1906.05149", "submitter": "Laura Aina", "authors": "Laura Aina, Kristina Gulordava, Gemma Boleda", "title": "Putting words in context: LSTM language models and lexical ambiguity", "comments": "To appear in Proceedings of the 57th Annual Meeting of the\n  Association for Computational Linguistics (ACL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In neural network models of language, words are commonly represented using\ncontext-invariant representations (word embeddings) which are then put in\ncontext in the hidden layers. Since words are often ambiguous, representing the\ncontextually relevant information is not trivial. We investigate how an LSTM\nlanguage model deals with lexical ambiguity in English, designing a method to\nprobe its hidden representations for lexical and contextual information about\nwords. We find that both types of information are represented to a large\nextent, but also that there is room for improvement for contextual information.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 14:07:40 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Aina", "Laura", ""], ["Gulordava", "Kristina", ""], ["Boleda", "Gemma", ""]]}, {"id": "1906.05190", "submitter": "Xin Li", "authors": "Xin Li, Rui Cao, Dongxiao Zhu", "title": "Vispi: Automatic Visual Perception and Interpretation of Chest X-rays", "comments": "In the proceeding of Medical Imaging with Deep Learning (MIDL-20)", "journal-ref": null, "doi": null, "report-no": "MIDL/2020/ExtendedAbstract/otswIbmgYA", "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical imaging contains the essential information for rendering diagnostic\nand treatment decisions. Inspecting (visual perception) and interpreting image\nto generate a report are tedious clinical routines for a radiologist where\nautomation is expected to greatly reduce the workload. Despite rapid\ndevelopment of natural image captioning, computer-aided medical image visual\nperception and interpretation remain a challenging task, largely due to the\nlack of high-quality annotated image-report pairs and tailor-made generative\nmodels for sufficient extraction and exploitation of localized semantic\nfeatures, particularly those associated with abnormalities. To tackle these\nchallenges, we present Vispi, an automatic medical image interpretation system,\nwhich first annotates an image via classifying and localizing common thoracic\ndiseases with visual support and then followed by report generation from an\nattentive LSTM model. Analyzing an open IU X-ray dataset, we demonstrate a\nsuperior performance of Vispi in disease classification, localization and\nreport generation using automatic performance evaluation metrics ROUGE and\nCIDEr.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 15:01:31 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 07:26:27 GMT"}, {"version": "v3", "created": "Fri, 29 May 2020 15:53:06 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Li", "Xin", ""], ["Cao", "Rui", ""], ["Zhu", "Dongxiao", ""]]}, {"id": "1906.05210", "submitter": "Yichen Jiang", "authors": "Yichen Jiang, Nitish Joshi, Yen-Chun Chen, Mohit Bansal", "title": "Explore, Propose, and Assemble: An Interpretable Model for Multi-Hop\n  Reading Comprehension", "comments": "ACL 2019 (12 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-hop reading comprehension requires the model to explore and connect\nrelevant information from multiple sentences/documents in order to answer the\nquestion about the context. To achieve this, we propose an interpretable\n3-module system called Explore-Propose-Assemble reader (EPAr). First, the\nDocument Explorer iteratively selects relevant documents and represents\ndivergent reasoning chains in a tree structure so as to allow assimilating\ninformation from all chains. The Answer Proposer then proposes an answer from\nevery root-to-leaf path in the reasoning tree. Finally, the Evidence Assembler\nextracts a key sentence containing the proposed answer from every path and\ncombines them to predict the final answer. Intuitively, EPAr approximates the\ncoarse-to-fine-grained comprehension behavior of human readers when facing\nmultiple long documents. We jointly optimize our 3 modules by minimizing the\nsum of losses from each stage conditioned on the previous stage's output. On\ntwo multi-hop reading comprehension datasets WikiHop and MedHop, our EPAr model\nachieves significant improvements over the baseline and competitive results\ncompared to the state-of-the-art model. We also present multiple\nreasoning-chain-recovery tests and ablation studies to demonstrate our system's\nability to perform interpretable and accurate reasoning.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 15:26:59 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Jiang", "Yichen", ""], ["Joshi", "Nitish", ""], ["Chen", "Yen-Chun", ""], ["Bansal", "Mohit", ""]]}, {"id": "1906.05218", "submitter": "Colin Cherry", "authors": "Naveen Arivazhagan, Colin Cherry, Wolfgang Macherey, Chung-Cheng Chiu,\n  Semih Yavuz, Ruoming Pang, Wei Li and Colin Raffel", "title": "Monotonic Infinite Lookback Attention for Simultaneous Machine\n  Translation", "comments": "Accepted for publication at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simultaneous machine translation begins to translate each source sentence\nbefore the source speaker is finished speaking, with applications to live and\nstreaming scenarios. Simultaneous systems must carefully schedule their reading\nof the source sentence to balance quality against latency. We present the first\nsimultaneous translation system to learn an adaptive schedule jointly with a\nneural machine translation (NMT) model that attends over all source tokens read\nthus far. We do so by introducing Monotonic Infinite Lookback (MILk) attention,\nwhich maintains both a hard, monotonic attention head to schedule the reading\nof the source sentence, and a soft attention head that extends from the\nmonotonic head back to the beginning of the source. We show that MILk's\nadaptive schedule allows it to arrive at latency-quality trade-offs that are\nfavorable to those of a recently proposed wait-k strategy for many latency\nvalues.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 15:49:31 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Arivazhagan", "Naveen", ""], ["Cherry", "Colin", ""], ["Macherey", "Wolfgang", ""], ["Chiu", "Chung-Cheng", ""], ["Yavuz", "Semih", ""], ["Pang", "Ruoming", ""], ["Li", "Wei", ""], ["Raffel", "Colin", ""]]}, {"id": "1906.05226", "submitter": "Ramakanth Pasunuru", "authors": "Ramakanth Pasunuru, Mohit Bansal", "title": "Continual and Multi-Task Architecture Search", "comments": "ACL 2019 (12 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Architecture search is the process of automatically learning the neural model\nor cell structure that best suits the given task. Recently, this approach has\nshown promising performance improvements (on language modeling and image\nclassification) with reasonable training speed, using a weight sharing strategy\ncalled Efficient Neural Architecture Search (ENAS). In our work, we first\nintroduce a novel continual architecture search (CAS) approach, so as to\ncontinually evolve the model parameters during the sequential training of\nseveral tasks, without losing performance on previously learned tasks (via\nblock-sparsity and orthogonality constraints), thus enabling life-long\nlearning. Next, we explore a multi-task architecture search (MAS) approach over\nENAS for finding a unified, single cell structure that performs well across\nmultiple tasks (via joint controller rewards), and hence allows more\ngeneralizable transfer of the cell structure knowledge to an unseen new task.\nWe empirically show the effectiveness of our sequential continual learning and\nparallel multi-task learning based architecture search approaches on diverse\nsentence-pair classification tasks (GLUE) and multimodal-generation based video\ncaptioning tasks. Further, we present several ablations and analyses on the\nlearned cell structures.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 16:01:35 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Pasunuru", "Ramakanth", ""], ["Bansal", "Mohit", ""]]}, {"id": "1906.05275", "submitter": "Ryan Benmalek", "authors": "Ryan Y. Benmalek, Madian Khabsa, Suma Desu, Claire Cardie, Michele\n  Banko", "title": "Keeping Notes: Conditional Natural Language Generation with a Scratchpad\n  Mechanism", "comments": "Accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Scratchpad Mechanism, a novel addition to the\nsequence-to-sequence (seq2seq) neural network architecture and demonstrate its\neffectiveness in improving the overall fluency of seq2seq models for natural\nlanguage generation tasks. By enabling the decoder at each time step to write\nto all of the encoder output layers, Scratchpad can employ the encoder as a\n\"scratchpad\" memory to keep track of what has been generated so far and thereby\nguide future generation. We evaluate Scratchpad in the context of three\nwell-studied natural language generation tasks --- Machine Translation,\nQuestion Generation, and Text Summarization --- and obtain state-of-the-art or\ncomparable performance on standard datasets for each task. Qualitative\nassessments in the form of human judgements (question generation), attention\nvisualization (MT), and sample output (summarization) provide further evidence\nof the ability of Scratchpad to generate fluent and expressive output.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 17:58:27 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 17:01:20 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Benmalek", "Ryan Y.", ""], ["Khabsa", "Madian", ""], ["Desu", "Suma", ""], ["Cardie", "Claire", ""], ["Banko", "Michele", ""]]}, {"id": "1906.05317", "submitter": "Antoine Bosselut", "authors": "Antoine Bosselut, Hannah Rashkin, Maarten Sap, Chaitanya Malaviya,\n  Asli Celikyilmaz, Yejin Choi", "title": "COMET: Commonsense Transformers for Automatic Knowledge Graph\n  Construction", "comments": "Accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first comprehensive study on automatic knowledge base\nconstruction for two prevalent commonsense knowledge graphs: ATOMIC (Sap et\nal., 2019) and ConceptNet (Speer et al., 2017). Contrary to many conventional\nKBs that store knowledge with canonical templates, commonsense KBs only store\nloosely structured open-text descriptions of knowledge. We posit that an\nimportant step toward automatic commonsense completion is the development of\ngenerative models of commonsense knowledge, and propose COMmonsEnse\nTransformers (COMET) that learn to generate rich and diverse commonsense\ndescriptions in natural language. Despite the challenges of commonsense\nmodeling, our investigation reveals promising results when implicit knowledge\nfrom deep pre-trained language models is transferred to generate explicit\nknowledge in commonsense knowledge graphs. Empirical results demonstrate that\nCOMET is able to generate novel knowledge that humans rate as high quality,\nwith up to 77.5% (ATOMIC) and 91.7% (ConceptNet) precision at top 1, which\napproaches human performance for these resources. Our findings suggest that\nusing generative commonsense models for automatic commonsense KB completion\ncould soon be a plausible alternative to extractive methods.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 18:11:20 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 20:13:16 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Bosselut", "Antoine", ""], ["Rashkin", "Hannah", ""], ["Sap", "Maarten", ""], ["Malaviya", "Chaitanya", ""], ["Celikyilmaz", "Asli", ""], ["Choi", "Yejin", ""]]}, {"id": "1906.05373", "submitter": "Victor Zhong", "authors": "Victor Zhong and Luke Zettlemoyer", "title": "E3: Entailment-driven Extracting and Editing for Conversational Machine\n  Reading", "comments": "Published at the Annual Meeting of the Association for Computational\n  Linguistics (ACL) 2019. Source code: https://github.com/vzhong/e3. 10 pages,\n  5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational machine reading systems help users answer high-level questions\n(e.g. determine if they qualify for particular government benefits) when they\ndo not know the exact rules by which the determination is made(e.g. whether\nthey need certain income levels or veteran status). The key challenge is that\nthese rules are only provided in the form of a procedural text (e.g. guidelines\nfrom government website) which the system must read to figure out what to ask\nthe user. We present a new conversational machine reading model that jointly\nextracts a set of decision rules from the procedural text while reasoning about\nwhich are entailed by the conversational history and which still need to be\nedited to create questions for the user. On the recently introduced ShARC\nconversational machine reading dataset, our Entailment-driven Extract and Edit\nnetwork (E3) achieves a new state-of-the-art, outperforming existing systems as\nwell as a new BERT-based baseline. In addition, by explicitly highlighting\nwhich information still needs to be gathered, E3 provides a more explainable\nalternative to prior work. We release source code for our models and\nexperiments at https://github.com/vzhong/e3.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 20:49:48 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 06:20:11 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Zhong", "Victor", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1906.05381", "submitter": "Brenden Lake", "authors": "Brenden M. Lake", "title": "Compositional generalization through meta sequence-to-sequence learning", "comments": "This paper appears in the 33rd Conference on Neural Information\n  Processing Systems (NeurIPS 2019), Vancouver, Canada", "journal-ref": "Advances in Neural Information Processing Systems 33 (2019)", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People can learn a new concept and use it compositionally, understanding how\nto \"blicket twice\" after learning how to \"blicket.\" In contrast, powerful\nsequence-to-sequence (seq2seq) neural networks fail such tests of\ncompositionality, especially when composing new concepts together with existing\nconcepts. In this paper, I show how memory-augmented neural networks can be\ntrained to generalize compositionally through meta seq2seq learning. In this\napproach, models train on a series of seq2seq problems to acquire the\ncompositional skills needed to solve new seq2seq problems. Meta se2seq learning\nsolves several of the SCAN tests for compositional learning and can learn to\napply implicit rules to variables.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 21:25:09 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 22:03:19 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Lake", "Brenden M.", ""]]}, {"id": "1906.05394", "submitter": "Hussein Mozannar", "authors": "Hussein Mozannar, Karl El Hajal, Elie Maamary, Hazem Hajj", "title": "Neural Arabic Question Answering", "comments": "WANLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper tackles the problem of open domain factual Arabic question\nanswering (QA) using Wikipedia as our knowledge source. This constrains the\nanswer of any question to be a span of text in Wikipedia. Open domain QA for\nArabic entails three challenges: annotated QA datasets in Arabic, large scale\nefficient information retrieval and machine reading comprehension. To deal with\nthe lack of Arabic QA datasets we present the Arabic Reading Comprehension\nDataset (ARCD) composed of 1,395 questions posed by crowdworkers on Wikipedia\narticles, and a machine translation of the Stanford Question Answering Dataset\n(Arabic-SQuAD). Our system for open domain question answering in Arabic (SOQAL)\nis based on two components: (1) a document retriever using a hierarchical\nTF-IDF approach and (2) a neural reading comprehension model using the\npre-trained bi-directional transformer BERT. Our experiments on ARCD indicate\nthe effectiveness of our approach with our BERT-based reader achieving a 61.3\nF1 score, and our open domain system SOQAL achieving a 27.6 F1 score.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 21:49:06 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Mozannar", "Hussein", ""], ["Hajal", "Karl El", ""], ["Maamary", "Elie", ""], ["Hajj", "Hazem", ""]]}, {"id": "1906.05407", "submitter": "Mikel Artetxe", "authors": "Aitor Ormazabal, Mikel Artetxe, Gorka Labaka, Aitor Soroa, Eneko\n  Agirre", "title": "Analyzing the Limitations of Cross-lingual Word Embedding Mappings", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research in cross-lingual word embeddings has almost exclusively\nfocused on offline methods, which independently train word embeddings in\ndifferent languages and map them to a shared space through linear\ntransformations. While several authors have questioned the underlying\nisomorphism assumption, which states that word embeddings in different\nlanguages have approximately the same structure, it is not clear whether this\nis an inherent limitation of mapping approaches or a more general issue when\nlearning cross-lingual embeddings. So as to answer this question, we experiment\nwith parallel corpora, which allows us to compare offline mapping to an\nextension of skip-gram that jointly learns both embedding spaces. We observe\nthat, under these ideal conditions, joint learning yields to more isomorphic\nembeddings, is less sensitive to hubness, and obtains stronger results in\nbilingual lexicon induction. We thus conclude that current mapping methods do\nhave strong limitations, calling for further research to jointly learn\ncross-lingual embeddings with a weaker cross-lingual signal.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 22:19:26 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Ormazabal", "Aitor", ""], ["Artetxe", "Mikel", ""], ["Labaka", "Gorka", ""], ["Soroa", "Aitor", ""], ["Agirre", "Eneko", ""]]}, {"id": "1906.05416", "submitter": "Chris Alberti", "authors": "Chris Alberti, Daniel Andor, Emily Pitler, Jacob Devlin, Michael\n  Collins", "title": "Synthetic QA Corpora Generation with Roundtrip Consistency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel method of generating synthetic question answering\ncorpora by combining models of question generation and answer extraction, and\nby filtering the results to ensure roundtrip consistency. By pretraining on the\nresulting corpora we obtain significant improvements on SQuAD2 and NQ,\nestablishing a new state-of-the-art on the latter. Our synthetic data\ngeneration models, for both question generation and answer extraction, can be\nfully reproduced by finetuning a publicly available BERT model on the\nextractive subsets of SQuAD2 and NQ. We also describe a more powerful variant\nthat does full sequence-to-sequence pretraining for question generation,\nobtaining exact match and F1 at less than 0.1% and 0.4% from human performance\non SQuAD2.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 22:50:31 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Alberti", "Chris", ""], ["Andor", "Daniel", ""], ["Pitler", "Emily", ""], ["Devlin", "Jacob", ""], ["Collins", "Michael", ""]]}, {"id": "1906.05447", "submitter": "Felix Stahlberg", "authors": "Felix Stahlberg and Danielle Saunders and Adria de Gispert and Bill\n  Byrne", "title": "Cued@wmt19:ewc&lms", "comments": "WMT2019 system description (University of Cambridge)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two techniques provide the fabric of the Cambridge University Engineering\nDepartment's (CUED) entry to the WMT19 evaluation campaign: elastic weight\nconsolidation (EWC) and different forms of language modelling (LMs). We report\nsubstantial gains by fine-tuning very strong baselines on former WMT test sets\nusing a combination of checkpoint averaging and EWC. A sentence-level\nTransformer LM and a document-level LM based on a modified Transformer\narchitecture yield further gains. As in previous years, we also extract\n$n$-gram probabilities from SMT lattices which can be seen as a\nsource-conditioned $n$-gram LM.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 17:49:57 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Stahlberg", "Felix", ""], ["Saunders", "Danielle", ""], ["de Gispert", "Adria", ""], ["Byrne", "Bill", ""]]}, {"id": "1906.05466", "submitter": "Aditya Joshi", "authors": "Adith Iyer, Aditya Joshi, Sarvnaz Karimi, Ross Sparks, Cecile Paris", "title": "Figurative Usage Detection of Symptom Words to Improve Personal Health\n  Mention Detection", "comments": "To appear at the 57th Annual Meeting of the Association for\n  Computational Linguistics (ACL 2019) (The second version updates the name of\n  a cited paper. A detailed note from the cited author is here :\n  https://github.com/commonsense/conceptnet5/wiki/Citation-complications )", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personal health mention detection deals with predicting whether or not a\ngiven sentence is a report of a health condition. Past work mentions errors in\nthis prediction when symptom words, i.e. names of symptoms of interest, are\nused in a figurative sense. Therefore, we combine a state-of-the-art figurative\nusage detection with CNN-based personal health mention detection. To do so, we\npresent two methods: a pipeline-based approach and a feature augmentation-based\napproach. The introduction of figurative usage detection results in an average\nimprovement of 2.21% F-score of personal health mention detection, in the case\nof the feature augmentation-based approach. This paper demonstrates the promise\nof using figurative usage detection to improve personal health mention\ndetection.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 03:42:34 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 00:16:01 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Iyer", "Adith", ""], ["Joshi", "Aditya", ""], ["Karimi", "Sarvnaz", ""], ["Sparks", "Ross", ""], ["Paris", "Cecile", ""]]}, {"id": "1906.05468", "submitter": "Aditya Joshi PhD", "authors": "Aditya Joshi, Sarvnaz Karimi, Ross Sparks, Cecile Paris, C Raina\n  MacIntyre", "title": "A Comparison of Word-based and Context-based Representations for\n  Classification Problems in Health Informatics", "comments": "To Appear in the 18th ACL Workshop on Biomedical Natural Language\n  Processing (BioNLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed representations of text can be used as features when training a\nstatistical classifier. These representations may be created as a composition\nof word vectors or as context-based sentence vectors. We compare the two kinds\nof representations (word versus context) for three classification problems:\ninfluenza infection classification, drug usage classification and personal\nhealth mention classification. For statistical classifiers trained for each of\nthese problems, context-based representations based on ELMo, Universal Sentence\nEncoder, Neural-Net Language Model and FLAIR are better than Word2Vec, GloVe\nand the two adapted using the MESH ontology. There is an improvement of 2-4% in\nthe accuracy when these context-based representations are used instead of\nword-based representations.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 03:48:34 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Joshi", "Aditya", ""], ["Karimi", "Sarvnaz", ""], ["Sparks", "Ross", ""], ["Paris", "Cecile", ""], ["MacIntyre", "C Raina", ""]]}, {"id": "1906.05474", "submitter": "Yifan Peng", "authors": "Yifan Peng and Shankai Yan and Zhiyong Lu", "title": "Transfer Learning in Biomedical Natural Language Processing: An\n  Evaluation of BERT and ELMo on Ten Benchmarking Datasets", "comments": "Accepted by BioNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the success of the General Language Understanding Evaluation\nbenchmark, we introduce the Biomedical Language Understanding Evaluation (BLUE)\nbenchmark to facilitate research in the development of pre-training language\nrepresentations in the biomedicine domain. The benchmark consists of five tasks\nwith ten datasets that cover both biomedical and clinical texts with different\ndataset sizes and difficulties. We also evaluate several baselines based on\nBERT and ELMo and find that the BERT model pre-trained on PubMed abstracts and\nMIMIC-III clinical notes achieves the best results. We make the datasets,\npre-trained models, and codes publicly available at\nhttps://github.com/ncbi-nlp/BLUE_Benchmark.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 04:07:12 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 13:49:35 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Peng", "Yifan", ""], ["Yan", "Shankai", ""], ["Lu", "Zhiyong", ""]]}, {"id": "1906.05483", "submitter": "Natalie Parde", "authors": "Flavio Di Palo and Natalie Parde", "title": "Enriching Neural Models with Targeted Features for Dementia Detection", "comments": "Accepted to the ACL 2019 Student Research Workshop (ACL SRW)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alzheimer's disease (AD) is an irreversible brain disease that can\ndramatically reduce quality of life, most commonly manifesting in older adults\nand eventually leading to the need for full-time care. Early detection is\nfundamental to slowing its progression; however, diagnosis can be expensive,\ntime-consuming, and invasive. In this work we develop a neural model based on a\nCNN-LSTM architecture that learns to detect AD and related dementias using\ntargeted and implicitly-learned features from conversational transcripts. Our\napproach establishes the new state of the art on the DementiaBank dataset,\nachieving an F1 score of 0.929 when classifying participants into AD and\ncontrol groups.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 05:15:25 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Di Palo", "Flavio", ""], ["Parde", "Natalie", ""]]}, {"id": "1906.05489", "submitter": "Zhengxiao Du", "authors": "Zhengxiao Du, Chang Zhou, Ming Ding, Hongxia Yang, Jie Tang", "title": "Cognitive Knowledge Graph Reasoning for One-shot Relational Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring new facts from existing knowledge graphs (KG) with explainable\nreasoning processes is a significant problem and has received much attention\nrecently. However, few studies have focused on relation types unseen in the\noriginal KG, given only one or a few instances for training. To bridge this\ngap, we propose CogKR for one-shot KG reasoning. The one-shot relational\nlearning problem is tackled through two modules: the summary module summarizes\nthe underlying relationship of the given instances, based on which the\nreasoning module infers the correct answers. Motivated by the dual process\ntheory in cognitive science, in the reasoning module, a cognitive graph is\nbuilt by iteratively coordinating retrieval (System 1, collecting relevant\nevidence intuitively) and reasoning (System 2, conducting relational reasoning\nover collected information). The structural information offered by the\ncognitive graph enables our model to aggregate pieces of evidence from multiple\nreasoning paths and explain the reasoning process graphically. Experiments show\nthat CogKR substantially outperforms previous state-of-the-art models on\none-shot KG reasoning benchmarks, with relative improvements of 24.3%-29.7% on\nMRR. The source code is available at https://github.com/THUDM/CogKR.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 05:39:42 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Du", "Zhengxiao", ""], ["Zhou", "Chang", ""], ["Ding", "Ming", ""], ["Yang", "Hongxia", ""], ["Tang", "Jie", ""]]}, {"id": "1906.05491", "submitter": "Alberto Calderone Dr.", "authors": "Alberto Calderone", "title": "A Computational Analysis of Natural Languages to Build a Sentence\n  Structure Aware Artificial Neural Network", "comments": null, "journal-ref": null, "doi": "10.6084/m9.figshare.8796725.v1", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Natural languages are complexly structured entities. They exhibit\ncharacterising regularities that can be exploited to link them one another. In\nthis work, I compare two morphological aspects of languages: Written Patterns\nand Sentence Structure. I show how languages spontaneously group by similarity\nin both analyses and derive an average language distance. Finally, exploiting\nSentence Structure I developed an Artificial Neural Network capable of\ndistinguishing languages suggesting that not only word roots but also\ngrammatical sentence structure is a characterising trait which alone suffice to\nidentify them.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 05:44:16 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Calderone", "Alberto", ""]]}, {"id": "1906.05506", "submitter": "Sho Takase", "authors": "Sho Takase, Jun Suzuki, Masaaki Nagata", "title": "Character n-gram Embeddings to Improve RNN Language Models", "comments": "AAAI 2019 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel Recurrent Neural Network (RNN) language model\nthat takes advantage of character information. We focus on character n-grams\nbased on research in the field of word embedding construction (Wieting et al.\n2016). Our proposed method constructs word embeddings from character n-gram\nembeddings and combines them with ordinary word embeddings. We demonstrate that\nthe proposed method achieves the best perplexities on the language modeling\ndatasets: Penn Treebank, WikiText-2, and WikiText-103. Moreover, we conduct\nexperiments on application tasks: machine translation and headline generation.\nThe experimental results indicate that our proposed method also positively\naffects these tasks.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 06:52:45 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Takase", "Sho", ""], ["Suzuki", "Jun", ""], ["Nagata", "Masaaki", ""]]}, {"id": "1906.05518", "submitter": "Sina Zarriess", "authors": "Sina Zarrie{\\ss}, David Schlangen", "title": "Know What You Don't Know: Modeling a Pragmatic Speaker that Refers to\n  Objects of Unknown Categories", "comments": "Accepted at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-shot learning in Language & Vision is the task of correctly labelling\n(or naming) objects of novel categories. Another strand of work in L&V aims at\npragmatically informative rather than ``correct'' object descriptions, e.g. in\nreference games. We combine these lines of research and model zero-shot\nreference games, where a speaker needs to successfully refer to a novel object\nin an image. Inspired by models of \"rational speech acts\", we extend a neural\ngenerator to become a pragmatic speaker reasoning about uncertain object\ncategories. As a result of this reasoning, the generator produces fewer nouns\nand names of distractor categories as compared to a literal speaker. We show\nthat this conversational strategy for dealing with novel objects often improves\ncommunicative success, in terms of resolution accuracy of an automatic\nlistener.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 07:35:05 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Zarrie\u00df", "Sina", ""], ["Schlangen", "David", ""]]}, {"id": "1906.05551", "submitter": "Kai Fan Dr", "authors": "Pei Zhang, Boxing Chen, Niyu Ge, Kai Fan", "title": "Lattice Transformer for Speech Translation", "comments": "accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in sequence modeling have highlighted the strengths of the\ntransformer architecture, especially in achieving state-of-the-art machine\ntranslation results. However, depending on the up-stream systems, e.g., speech\nrecognition, or word segmentation, the input to translation system can vary\ngreatly. The goal of this work is to extend the attention mechanism of the\ntransformer to naturally consume the lattice in addition to the traditional\nsequential input. We first propose a general lattice transformer for speech\ntranslation where the input is the output of the automatic speech recognition\n(ASR) which contains multiple paths and posterior scores. To leverage the extra\ninformation from the lattice structure, we develop a novel controllable lattice\nattention mechanism to obtain latent representations. On the LDC\nSpanish-English speech translation corpus, our experiments show that lattice\ntransformer generalizes significantly better and outperforms both a transformer\nbaseline and a lattice LSTM. Additionally, we validate our approach on the WMT\n2017 Chinese-English translation task with lattice inputs from different BPE\nsegmentations. In this task, we also observe the improvements over strong\nbaselines.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 08:55:06 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Zhang", "Pei", ""], ["Chen", "Boxing", ""], ["Ge", "Niyu", ""], ["Fan", "Kai", ""]]}, {"id": "1906.05572", "submitter": "Wenquan Wu", "authors": "Wenquan Wu, Zhen Guo, Xiangyang Zhou, Hua Wu, Xiyuan Zhang, Rongzhong\n  Lian and Haifeng Wang", "title": "Proactive Human-Machine Conversation with Explicit Conversation Goals", "comments": "Accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though great progress has been made for human-machine conversation, current\ndialogue system is still in its infancy: it usually converses passively and\nutters words more as a matter of response, rather than on its own initiatives.\nIn this paper, we take a radical step towards building a human-like\nconversational agent: endowing it with the ability of proactively leading the\nconversation (introducing a new topic or maintaining the current topic). To\nfacilitate the development of such conversation systems, we create a new\ndataset named DuConv where one acts as a conversation leader and the other acts\nas the follower. The leader is provided with a knowledge graph and asked to\nsequentially change the discussion topics, following the given conversation\ngoal, and meanwhile keep the dialogue as natural and engaging as possible.\nDuConv enables a very challenging task as the model needs to both understand\ndialogue and plan over the given knowledge graph. We establish baseline results\non this dataset (about 270K utterances and 30k dialogues) using several\nstate-of-the-art models. Experimental results show that dialogue models that\nplan over the knowledge graph can make full use of related knowledge to\ngenerate more diverse multi-turn conversations. The baseline systems along with\nthe dataset are publicly available\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 09:42:51 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 07:03:04 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Wu", "Wenquan", ""], ["Guo", "Zhen", ""], ["Zhou", "Xiangyang", ""], ["Wu", "Hua", ""], ["Zhang", "Xiyuan", ""], ["Lian", "Rongzhong", ""], ["Wang", "Haifeng", ""]]}, {"id": "1906.05612", "submitter": "Muhammad Asif Ali", "authors": "Muhammad Asif Ali, Yifang Sun, Xiaoling Zhou, Wei Wang, Xiang Zhao", "title": "Antonym-Synonym Classification Based on New Sub-space Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Distinguishing antonyms from synonyms is a key challenge for many NLP\napplications focused on the lexical-semantic relation extraction. Existing\nsolutions relying on large-scale corpora yield low performance because of huge\ncontextual overlap of antonym and synonym pairs. We propose a novel approach\nentirely based on pre-trained embeddings. We hypothesize that the pre-trained\nembeddings comprehend a blend of lexical-semantic information and we may\ndistill the task-specific information using Distiller, a model proposed in this\npaper. Later, a classifier is trained based on features constructed from the\ndistilled sub-spaces along with some word level features to distinguish\nantonyms from synonyms. Experimental results show that the proposed model\noutperforms existing research on antonym synonym distinction in both speed and\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 11:46:12 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Ali", "Muhammad Asif", ""], ["Sun", "Yifang", ""], ["Zhou", "Xiaoling", ""], ["Wang", "Wei", ""], ["Zhao", "Xiang", ""]]}, {"id": "1906.05651", "submitter": "Pushpendre Rastogi", "authors": "Pushpendre Rastogi", "title": "Representation Learning for Words and Entities", "comments": "phd thesis, Machine Learning, Natural Language Processing,\n  Representation Learning, Knowledge Graphs, Entities, Word Embeddings, Entity\n  Embeddings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis presents new methods for unsupervised learning of distributed\nrepresentations of words and entities from text and knowledge bases. The first\nalgorithm presented in the thesis is a multi-view algorithm for learning\nrepresentations of words called Multiview Latent Semantic Analysis (MVLSA). By\nincorporating up to 46 different types of co-occurrence statistics for the same\nvocabulary of english words, I show that MVLSA outperforms other\nstate-of-the-art word embedding models. Next, I focus on learning entity\nrepresentations for search and recommendation and present the second method of\nthis thesis, Neural Variational Set Expansion (NVSE). NVSE is also an\nunsupervised learning method, but it is based on the Variational Autoencoder\nframework. Evaluations with human annotators show that NVSE can facilitate\nbetter search and recommendation of information gathered from noisy, automatic\nannotation of unstructured natural language corpora. Finally, I move from\nunstructured data and focus on structured knowledge graphs. I present novel\napproaches for learning embeddings of vertices and edges in a knowledge graph\nthat obey logical constraints.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 17:29:22 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Rastogi", "Pushpendre", ""]]}, {"id": "1906.05659", "submitter": "Xishuang Dong", "authors": "Xishuang Dong, Uboho Victor, Shanta Chowdhury, Lijun Qian", "title": "Deep Two-path Semi-supervised Learning for Fake News Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  News in social media such as Twitter has been generated in high volume and\nspeed. However, very few of them can be labeled (as fake or true news) in a\nshort time. In order to achieve timely detection of fake news in social media,\na novel deep two-path semi-supervised learning model is proposed, where one\npath is for supervised learning and the other is for unsupervised learning.\nThese two paths implemented with convolutional neural networks are jointly\noptimized to enhance detection performance. In addition, we build a shared\nconvolutional neural networks between these two paths to share the low level\nfeatures. Experimental results using Twitter datasets show that the proposed\nmodel can recognize fake news effectively with very few labeled data.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 21:19:41 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Dong", "Xishuang", ""], ["Victor", "Uboho", ""], ["Chowdhury", "Shanta", ""], ["Qian", "Lijun", ""]]}, {"id": "1906.05664", "submitter": "Yi Zhang", "authors": "Mark Braverman, Xinyi Chen, Sham M. Kakade, Karthik Narasimhan, Cyril\n  Zhang, Yi Zhang", "title": "Calibration, Entropy Rates, and Memory in Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building accurate language models that capture meaningful long-term\ndependencies is a core challenge in natural language processing. Towards this\nend, we present a calibration-based approach to measure long-term discrepancies\nbetween a generative sequence model and the true distribution, and use these\ndiscrepancies to improve the model. Empirically, we show that state-of-the-art\nlanguage models, including LSTMs and Transformers, are \\emph{miscalibrated}:\nthe entropy rates of their generations drift dramatically upward over time. We\nthen provide provable methods to mitigate this phenomenon. Furthermore, we show\nhow this calibration-based approach can also be used to measure the amount of\nmemory that language models use for prediction.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 17:00:49 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Braverman", "Mark", ""], ["Chen", "Xinyi", ""], ["Kakade", "Sham M.", ""], ["Narasimhan", "Karthik", ""], ["Zhang", "Cyril", ""], ["Zhang", "Yi", ""]]}, {"id": "1906.05667", "submitter": "Junyi Li", "authors": "Junyi Li, Wayne Xin Zhao, Ji-Rong Wen, and Yang Song", "title": "Generating Long and Informative Reviews with Aspect-Aware Coarse-to-Fine\n  Decoding", "comments": "Accepted by ACL 2019 Long Paper", "journal-ref": null, "doi": "10.18653/v1/P19-1190", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating long and informative review text is a challenging natural language\ngeneration task. Previous work focuses on word-level generation, neglecting the\nimportance of topical and syntactic characteristics from natural languages. In\nthis paper, we propose a novel review generation model by characterizing an\nelaborately designed aspect-aware coarse-to-fine generation process. First, we\nmodel the aspect transitions to capture the overall content flow. Then, to\ngenerate a sentence, an aspect-aware sketch will be predicted using an\naspect-aware decoder. Finally, another decoder fills in the semantic slots by\ngenerating corresponding words. Our approach is able to jointly utilize aspect\nsemantics, syntactic sketch, and context information. Extensive experiments\nresults have demonstrated the effectiveness of the proposed model.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 06:59:56 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 08:38:09 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Li", "Junyi", ""], ["Zhao", "Wayne Xin", ""], ["Wen", "Ji-Rong", ""], ["Song", "Yang", ""]]}, {"id": "1906.05670", "submitter": "Sheng Lin", "authors": "Sheng Lin, Luye Zheng, Bo Chen, Siliang Tang, Yueting Zhuang, Fei Wu,\n  Zhigang Chen, Guoping Hu, Xiang Ren", "title": "KCAT: A Knowledge-Constraint Typing Annotation Tool", "comments": "6 pages, acl2019 demo paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-grained Entity Typing is a tough task which suffers from noise samples\nextracted from distant supervision. Thousands of manually annotated samples can\nachieve greater performance than millions of samples generated by the previous\ndistant supervision method. Whereas, it's hard for human beings to\ndifferentiate and memorize thousands of types, thus making large-scale human\nlabeling hardly possible. In this paper, we introduce a Knowledge-Constraint\nTyping Annotation Tool (KCAT), which is efficient for fine-grained entity\ntyping annotation. KCAT reduces the size of candidate types to an acceptable\nrange for human beings through entity linking and provides a Multi-step Typing\nscheme to revise the entity linking result. Moreover, KCAT provides an\nefficient Annotator Client to accelerate the annotation process and a\ncomprehensive Manager Module to analyse crowdsourcing annotations. Experiment\nshows that KCAT can significantly improve annotation efficiency, the time\nconsumption increases slowly as the size of type set expands.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 13:33:22 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Lin", "Sheng", ""], ["Zheng", "Luye", ""], ["Chen", "Bo", ""], ["Tang", "Siliang", ""], ["Zhuang", "Yueting", ""], ["Wu", "Fei", ""], ["Chen", "Zhigang", ""], ["Hu", "Guoping", ""], ["Ren", "Xiang", ""]]}, {"id": "1906.05678", "submitter": "Chris Larson", "authors": "Chris Larson, Tarek Lahlou, Diana Mingels, Zachary Kulis, Erik Mueller", "title": "Telephonetic: Making Neural Language Models Robust to ASR and Semantic\n  Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech processing systems rely on robust feature extraction to handle\nphonetic and semantic variations found in natural language. While techniques\nexist for desensitizing features to common noise patterns produced by\nSpeech-to-Text (STT) and Text-to-Speech (TTS) systems, the question remains how\nto best leverage state-of-the-art language models (which capture rich semantic\nfeatures, but are trained on only written text) on inputs with ASR errors. In\nthis paper, we present Telephonetic, a data augmentation framework that helps\nrobustify language model features to ASR corrupted inputs. To capture phonetic\nalterations, we employ a character-level language model trained using\nprobabilistic masking. Phonetic augmentations are generated in two stages: a\nTTS encoder (Tacotron 2, WaveGlow) and a STT decoder (DeepSpeech). Similarly,\nsemantic perturbations are produced by sampling from nearby words in an\nembedding space, which is computed using the BERT language model. Words are\nselected for augmentation according to a hierarchical grammar sampling\nstrategy. Telephonetic is evaluated on the Penn Treebank (PTB) corpus, and\ndemonstrates its effectiveness as a bootstrapping technique for transferring\nneural language models to the speech domain. Notably, our language model\nachieves a test perplexity of 37.49 on PTB, which to our knowledge is\nstate-of-the-art among models trained only on PTB.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 17:04:46 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Larson", "Chris", ""], ["Lahlou", "Tarek", ""], ["Mingels", "Diana", ""], ["Kulis", "Zachary", ""], ["Mueller", "Erik", ""]]}, {"id": "1906.05681", "submitter": "Suraj Tripathi", "authors": "Suraj Tripathi, Abhay Kumar, Abhiram Ramesh, Chirag Singh, Promod\n  Yenigalla", "title": "Deep Learning based Emotion Recognition System Using Speech Features and\n  Transcriptions", "comments": "Accepted in CICLing 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a speech emotion recognition method based on speech\nfeatures and speech transcriptions (text). Speech features such as Spectrogram\nand Mel-frequency Cepstral Coefficients (MFCC) help retain emotion-related\nlow-level characteristics in speech whereas text helps capture semantic\nmeaning, both of which help in different aspects of emotion detection. We\nexperimented with several Deep Neural Network (DNN) architectures, which take\nin different combinations of speech features and text as inputs. The proposed\nnetwork architectures achieve higher accuracies when compared to\nstate-of-the-art methods on a benchmark dataset. The combined MFCC-Text\nConvolutional Neural Network (CNN) model proved to be the most accurate in\nrecognizing emotions in IEMOCAP data.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 17:35:02 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Tripathi", "Suraj", ""], ["Kumar", "Abhay", ""], ["Ramesh", "Abhiram", ""], ["Singh", "Chirag", ""], ["Yenigalla", "Promod", ""]]}, {"id": "1906.05683", "submitter": "Nima Pourdamghani", "authors": "Nima Pourdamghani, Nada Aldarrab, Marjan Ghazvininejad, Kevin Knight,\n  Jonathan May", "title": "Translating Translationese: A Two-Step Approach to Unsupervised Machine\n  Translation", "comments": "Accepted in ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a rough, word-by-word gloss of a source language sentence, target\nlanguage natives can uncover the latent, fully-fluent rendering of the\ntranslation. In this work we explore this intuition by breaking translation\ninto a two step process: generating a rough gloss by means of a dictionary and\nthen `translating' the resulting pseudo-translation, or `Translationese' into a\nfully fluent translation. We build our Translationese decoder once from a\nmish-mash of parallel data that has the target language in common and then can\nbuild dictionaries on demand using unsupervised techniques, resulting in\nrapidly generated unsupervised neural MT systems for many source languages. We\napply this process to 14 test languages, obtaining better or comparable\ntranslation results on high-resource languages than previously published\nunsupervised MT studies, and obtaining good quality results for low-resource\nlanguages that have never been used in an unsupervised MT scenario.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 17:56:29 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Pourdamghani", "Nima", ""], ["Aldarrab", "Nada", ""], ["Ghazvininejad", "Marjan", ""], ["Knight", "Kevin", ""], ["May", "Jonathan", ""]]}, {"id": "1906.05685", "submitter": "Laura Martinus", "authors": "Laura Martinus and Jade Z. Abbott", "title": "A Focus on Neural Machine Translation for African Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  African languages are numerous, complex and low-resourced. The datasets\nrequired for machine translation are difficult to discover, and existing\nresearch is hard to reproduce. Minimal attention has been given to machine\ntranslation for African languages so there is scant research regarding the\nproblems that arise when using machine translation techniques. To begin\naddressing these problems, we trained models to translate English to five of\nthe official South African languages (Afrikaans, isiZulu, Northern Sotho,\nSetswana, Xitsonga), making use of modern neural machine translation\ntechniques. The results obtained show the promise of using neural machine\ntranslation techniques for African languages. By providing reproducible\npublicly-available data, code and results, this research aims to provide a\nstarting point for other researchers in African machine translation to compare\nto and build upon.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 15:38:34 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 12:48:25 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Martinus", "Laura", ""], ["Abbott", "Jade Z.", ""]]}, {"id": "1906.05691", "submitter": "Masaru Isonuma", "authors": "Masaru Isonuma, Junichiro Mori, Ichiro Sakata", "title": "Unsupervised Neural Single-Document Summarization of Reviews via\n  Learning Latent Discourse Structure and its Ranking", "comments": "13 pages, ACL 2019 (long paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the end-to-end abstractive summarization of a single\nproduct review without supervision. We assume that a review can be described as\na discourse tree, in which the summary is the root, and the child sentences\nexplain their parent in detail. By recursively estimating a parent from its\nchildren, our model learns the latent discourse tree without an external parser\nand generates a concise summary. We also introduce an architecture that ranks\nthe importance of each sentence on the tree to support summary generation\nfocusing on the main review point. The experimental results demonstrate that\nour model is competitive with or outperforms other unsupervised approaches. In\nparticular, for relatively long reviews, it achieves a competitive or better\nperformance than supervised models. The induced tree shows that the child\nsentences provide additional information about their parent, and the generated\nsummary abstracts the entire review.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 13:53:10 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Isonuma", "Masaru", ""], ["Mori", "Junichiro", ""], ["Sakata", "Ichiro", ""]]}, {"id": "1906.05714", "submitter": "Jesse Vig", "authors": "Jesse Vig", "title": "A Multiscale Visualization of Attention in the Transformer Model", "comments": "To appear in ACL 2019 (System Demonstrations). arXiv admin note:\n  substantial text overlap with arXiv:1904.02679", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Transformer is a sequence model that forgoes traditional recurrent\narchitectures in favor of a fully attention-based approach. Besides improving\nperformance, an advantage of using attention is that it can also help to\ninterpret a model by showing how the model assigns weight to different input\nelements. However, the multi-layer, multi-head attention mechanism in the\nTransformer model can be difficult to decipher. To make the model more\naccessible, we introduce an open-source tool that visualizes attention at\nmultiple scales, each of which provides a unique perspective on the attention\nmechanism. We demonstrate the tool on BERT and OpenAI GPT-2 and present three\nexample use cases: detecting model bias, locating relevant attention heads, and\nlinking neurons to model behavior.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 15:45:26 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Vig", "Jesse", ""]]}, {"id": "1906.05725", "submitter": "Bidisha Samanta", "authors": "Bidisha Samanta, Niloy Ganguly and Soumen Chakrabarti", "title": "Improved Sentiment Detection via Label Transfer from Monolingual to\n  Synthetic Code-Switched Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual writers and speakers often alternate between two languages in a\nsingle discourse, a practice called \"code-switching\". Existing sentiment\ndetection methods are usually trained on sentiment-labeled monolingual text.\nManually labeled code-switched text, especially involving minority languages,\nis extremely rare. Consequently, the best monolingual methods perform\nrelatively poorly on code-switched text. We present an effective technique for\nsynthesizing labeled code-switched text from labeled monolingual text, which is\nmore readily available. The idea is to replace carefully selected subtrees of\nconstituency parses of sentences in the resource-rich language with suitable\ntoken spans selected from automatic translations to the resource-poor language.\nBy augmenting scarce human-labeled code-switched text with plentiful synthetic\ncode-switched text, we achieve significant improvements in sentiment labeling\naccuracy (1.5%, 5.11%, 7.20%) for three different language pairs\n(English-Hindi, English-Spanish and English-Bengali). We also get significant\ngains for hate speech detection: 4% improvement using only synthetic text and\n6% if augmented with real text.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 14:41:00 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Samanta", "Bidisha", ""], ["Ganguly", "Niloy", ""], ["Chakrabarti", "Soumen", ""]]}, {"id": "1906.05760", "submitter": "Claire Bowern", "authors": "Claire Bowern", "title": "Semantic Change and Semantic Stability: Variation is Key", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I survey some recent approaches to studying change in the lexicon,\nparticularly change in meaning across phylogenies. I briefly sketch an\nevolutionary approach to language change and point out some issues in recent\napproaches to studying semantic change that rely on temporally stratified word\nembeddings. I draw illustrations from lexical cognate models in Pama-Nyungan to\nidentify meaning classes most appropriate for lexical phylogenetic inference,\nparticularly highlighting the importance of variation in studying change over\ntime.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 15:40:50 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Bowern", "Claire", ""]]}, {"id": "1906.05765", "submitter": "Ramon Ferrer i Cancho", "authors": "Ramon Ferrer-i-Cancho and Carlos G\\'omez-Rodr\\'iguez", "title": "Anti dependency distance minimization in short sequences. A graph\n  theoretic approach", "comments": "Little corrections before submitting the sources to production\n  (English, format and typos); Journal of Quantitative Linguistics, in press", "journal-ref": "Ferrer-i-Cancho, R. & G\\'omez-Rodr\\'iguez (2021). Anti dependency\n  distance minimization in short sequences. A graph theoretic approach. Journal\n  of Quantitative Linguistics 28 (1), 50-76", "doi": "10.1080/09296174.2019.1645547", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dependency distance minimization (DDm) is a word order principle favouring\nthe placement of syntactically related words close to each other in sentences.\nMassive evidence of the principle has been reported for more than a decade with\nthe help of syntactic dependency treebanks where long sentences abound.\nHowever, it has been predicted theoretically that the principle is more likely\nto be beaten in short sequences by the principle of surprisal minimization\n(predictability maximization). Here we introduce a simple binomial test to\nverify such a hypothesis. In short sentences, we find anti-DDm for some\nlanguages from different families. Our analysis of the syntactic dependency\nstructures suggests that anti-DDm is produced by star trees.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 15:49:56 GMT"}, {"version": "v2", "created": "Sun, 14 Jul 2019 07:21:22 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Ferrer-i-Cancho", "Ramon", ""], ["G\u00f3mez-Rodr\u00edguez", "Carlos", ""]]}, {"id": "1906.05786", "submitter": "Danielle Saunders", "authors": "Danielle Saunders and Felix Stahlberg and Bill Byrne", "title": "UCAM Biomedical translation at WMT19: Transfer learning multi-domain\n  ensembles", "comments": "To appear at WMT19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 2019 WMT Biomedical translation task involved translating Medline\nabstracts. We approached this using transfer learning to obtain a series of\nstrong neural models on distinct domains, and combining them into multi-domain\nensembles. We further experiment with an adaptive language-model ensemble\nweighting scheme. Our submission achieved the best submitted results on both\ndirections of English-Spanish.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 16:22:44 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Saunders", "Danielle", ""], ["Stahlberg", "Felix", ""], ["Byrne", "Bill", ""]]}, {"id": "1906.05807", "submitter": "Minjoon Seo", "authors": "Minjoon Seo, Jinhyuk Lee, Tom Kwiatkowski, Ankur P. Parikh, Ali\n  Farhadi, Hannaneh Hajishirzi", "title": "Real-Time Open-Domain Question Answering with Dense-Sparse Phrase Index", "comments": "ACL 2019; Code & demo available at\n  https://nlp.cs.washington.edu/denspi/ ; Added comparison to Weaver (Raison et\n  al., 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing open-domain question answering (QA) models are not suitable for\nreal-time usage because they need to process several long documents on-demand\nfor every input query. In this paper, we introduce the query-agnostic indexable\nrepresentation of document phrases that can drastically speed up open-domain QA\nand also allows us to reach long-tail targets. In particular, our dense-sparse\nphrase encoding effectively captures syntactic, semantic, and lexical\ninformation of the phrases and eliminates the pipeline filtering of context\ndocuments. Leveraging optimization strategies, our model can be trained in a\nsingle 4-GPU server and serve entire Wikipedia (up to 60 billion phrases) under\n2TB with CPUs only. Our experiments on SQuAD-Open show that our model is more\naccurate than DrQA (Chen et al., 2017) with 6000x reduced computational cost,\nwhich translates into at least 58x faster end-to-end inference benchmark on\nCPUs.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 16:49:35 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 16:37:40 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Seo", "Minjoon", ""], ["Lee", "Jinhyuk", ""], ["Kwiatkowski", "Tom", ""], ["Parikh", "Ankur P.", ""], ["Farhadi", "Ali", ""], ["Hajishirzi", "Hannaneh", ""]]}, {"id": "1906.05833", "submitter": "Barry Smith", "authors": "J. Landgrebe and B. Smith", "title": "There is no Artificial General Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of creating Artificial General Intelligence (AGI) -- or in other\nwords of creating Turing machines (modern computers) that can behave in a way\nthat mimics human intelligence -- has occupied AI researchers ever since the\nidea of AI was first proposed. One common theme in these discussions is the\nthesis that the ability of a machine to conduct convincing dialogues with human\nbeings can serve as at least a sufficient criterion of AGI. We argue that this\nvery ability should be accepted also as a necessary condition of AGI, and we\nprovide a description of the nature of human dialogue in particular and of\nhuman language in general against this background. We then argue that it is for\nmathematical reasons impossible to program a machine in such a way that it\ncould master human dialogue behaviour in its full generality. This is (1)\nbecause there are no traditional explicitly designed mathematical models that\ncould be used as a starting point for creating such programs; and (2) because\neven the sorts of automated models generated by using machine learning, which\nhave been used successfully in areas such as machine translation, cannot be\nextended to cope with human dialogue. If this is so, then we can conclude that\na Turing machine also cannot possess AGI, because it fails to fulfil a\nnecessary condition thereof. At the same time, however, we acknowledge the\npotential of Turing machines to master dialogue behaviour in highly restricted\ncontexts, where what is called ``narrow'' AI can still be of considerable\nutility.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 12:42:23 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 20:26:52 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Landgrebe", "J.", ""], ["Smith", "B.", ""]]}, {"id": "1906.05887", "submitter": "Jeremy Barnes", "authors": "Jeremy Barnes, Lilja {\\O}vrelid, Erik Velldal", "title": "Sentiment analysis is not solved! Assessing and probing sentiment\n  classification", "comments": "Accepted to BlackBoxNLP Workshop at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural methods for SA have led to quantitative improvements over previous\napproaches, but these advances are not always accompanied with a thorough\nanalysis of the qualitative differences. Therefore, it is not clear what\noutstanding conceptual challenges for sentiment analysis remain. In this work,\nwe attempt to discover what challenges still prove a problem for sentiment\nclassifiers for English and to provide a challenging dataset. We collect the\nsubset of sentences that an (oracle) ensemble of state-of-the-art sentiment\nclassifiers misclassify and then annotate them for 18 linguistic and\nparalinguistic phenomena, such as negation, sarcasm, modality, etc. The dataset\nis available at https://github.com/ltgoslo/assessing_and_probing_sentiment.\nFinally, we provide a case study that demonstrates the usefulness of the\ndataset to probe the performance of a given sentiment classifier with respect\nto linguistic phenomena.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 18:35:00 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Barnes", "Jeremy", ""], ["\u00d8vrelid", "Lilja", ""], ["Velldal", "Erik", ""]]}, {"id": "1906.05889", "submitter": "Jeremy Barnes", "authors": "\\`Alex R. Atrio, Toni Badia, Jeremy Barnes", "title": "On the Effect of Word Order on Cross-lingual Sentiment Analysis", "comments": "Accepted to SEPLN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Current state-of-the-art models for sentiment analysis make use of word order\neither explicitly by pre-training on a language modeling objective or\nimplicitly by using recurrent neural networks (RNNs) or convolutional networks\n(CNNs). This is a problem for cross-lingual models that use bilingual\nembeddings as features, as the difference in word order between source and\ntarget languages is not resolved. In this work, we explore reordering as a\npre-processing step for sentence-level cross-lingual sentiment classification\nwith two language combinations (English-Spanish, English-Catalan). We find that\nwhile reordering helps both models, CNNS are more sensitive to local\nreorderings, while global reordering benefits RNNs.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 18:50:17 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Atrio", "\u00c0lex R.", ""], ["Badia", "Toni", ""], ["Barnes", "Jeremy", ""]]}, {"id": "1906.05906", "submitter": "Arya D. McCarthy", "authors": "Tiago Pimentel, Arya D. McCarthy, Dami\\'an E. Blasi, Brian Roark, Ryan\n  Cotterell", "title": "Meaning to Form: Measuring Systematicity as Information", "comments": "Accepted for publication at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A longstanding debate in semiotics centers on the relationship between\nlinguistic signs and their corresponding semantics: is there an arbitrary\nrelationship between a word form and its meaning, or does some systematic\nphenomenon pervade? For instance, does the character bigram \\textit{gl} have\nany systematic relationship to the meaning of words like \\textit{glisten},\n\\textit{gleam} and \\textit{glow}? In this work, we offer a holistic\nquantification of the systematicity of the sign using mutual information and\nrecurrent neural networks. We employ these in a data-driven and massively\nmultilingual approach to the question, examining 106 languages. We find a\nstatistically significant reduction in entropy when modeling a word form\nconditioned on its semantic representation. Encouragingly, we also recover\nwell-attested English examples of systematic affixes. We conclude with the\nmeta-point: Our approximate effect size (measured in bits) is quite\nsmall---despite some amount of systematicity between form and meaning, an\narbitrary relationship and its resulting benefits dominate human language.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 19:30:12 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2019 18:14:45 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Pimentel", "Tiago", ""], ["McCarthy", "Arya D.", ""], ["Blasi", "Dami\u00e1n E.", ""], ["Roark", "Brian", ""], ["Cotterell", "Ryan", ""]]}, {"id": "1906.05939", "submitter": "Sotiris Kotitsas", "authors": "Sotiris Kotitsas, Dimitris Pappas, Ion Androutsopoulos, Ryan McDonald\n  and Marianna Apidianaki", "title": "Embedding Biomedical Ontologies by Jointly Encoding Network Structure\n  and Textual Node Descriptors", "comments": "Proceedings of the 18th Workshop on Biomedical Natural Language\n  Processing (BioNLP 2019) of the 57th Annual Meeting of the Association for\n  Computational Linguistics (ACL 2019), Florence, Italy, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network Embedding (NE) methods, which map network nodes to low-dimensional\nfeature vectors, have wide applications in network analysis and bioinformatics.\nMany existing NE methods rely only on network structure, overlooking other\ninformation associated with the nodes, e.g., text describing the nodes. Recent\nattempts to combine the two sources of information only consider local network\nstructure. We extend NODE2VEC, a well-known NE method that considers broader\nnetwork structure, to also consider textual node descriptors using recurrent\nneural encoders. Our method is evaluated on link prediction in two networks\nderived from UMLS. Experimental results demonstrate the effectiveness of the\nproposed approach compared to previous work.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 21:40:15 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 08:15:57 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Kotitsas", "Sotiris", ""], ["Pappas", "Dimitris", ""], ["Androutsopoulos", "Ion", ""], ["McDonald", "Ryan", ""], ["Apidianaki", "Marianna", ""]]}, {"id": "1906.05962", "submitter": "Guan-Lin Chao", "authors": "Guan-Lin Chao, William Chan, Ian Lane", "title": "Speaker-Targeted Audio-Visual Models for Speech Recognition in\n  Cocktail-Party Environments", "comments": "Published in INTERSPEECH 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.CV cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech recognition in cocktail-party environments remains a significant\nchallenge for state-of-the-art speech recognition systems, as it is extremely\ndifficult to extract an acoustic signal of an individual speaker from a\nbackground of overlapping speech with similar frequency and temporal\ncharacteristics. We propose the use of speaker-targeted acoustic and\naudio-visual models for this task. We complement the acoustic features in a\nhybrid DNN-HMM model with information of the target speaker's identity as well\nas visual features from the mouth region of the target speaker. Experimentation\nwas performed using simulated cocktail-party data generated from the GRID\naudio-visual corpus by overlapping two speakers's speech on a single acoustic\nchannel. Our audio-only baseline achieved a WER of 26.3%. The audio-visual\nmodel improved the WER to 4.4%. Introducing speaker identity information had an\neven more pronounced effect, improving the WER to 3.6%. Combining both\napproaches, however, did not significantly improve performance further. Our\nwork demonstrates that speaker-targeted models can significantly improve the\nspeech recognition in cocktail party environments.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 23:52:16 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Chao", "Guan-Lin", ""], ["Chan", "William", ""], ["Lane", "Ian", ""]]}, {"id": "1906.05963", "submitter": "Armin Kappeler", "authors": "Simao Herdade, Armin Kappeler, Kofi Boakye, Joao Soares", "title": "Image Captioning: Transforming Objects into Words", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image captioning models typically follow an encoder-decoder architecture\nwhich uses abstract image feature vectors as input to the encoder. One of the\nmost successful algorithms uses feature vectors extracted from the region\nproposals obtained from an object detector. In this work we introduce the\nObject Relation Transformer, that builds upon this approach by explicitly\nincorporating information about the spatial relationship between input detected\nobjects through geometric attention. Quantitative and qualitative results\ndemonstrate the importance of such geometric attention for image captioning,\nleading to improvements on all common captioning metrics on the MS-COCO\ndataset.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 00:00:29 GMT"}, {"version": "v2", "created": "Sat, 11 Jan 2020 11:03:05 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Herdade", "Simao", ""], ["Kappeler", "Armin", ""], ["Boakye", "Kofi", ""], ["Soares", "Joao", ""]]}, {"id": "1906.05993", "submitter": "Jo\\~ao Sedoc", "authors": "Saket Karve, Lyle Ungar, Jo\\~ao Sedoc", "title": "Conceptor Debiasing of Word Representations Evaluated on WEAT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bias in word embeddings such as Word2Vec has been widely investigated, and\nmany efforts made to remove such bias. We show how to use conceptors debiasing\nto post-process both traditional and contextualized word embeddings. Our\nconceptor debiasing can simultaneously remove racial and gender biases and,\nunlike standard debiasing methods, can make effect use of heterogeneous lists\nof biased words. We show that conceptor debiasing diminishes racial and gender\nbias of word representations as measured using the Word Embedding Association\nTest (WEAT) of Caliskan et al. (2017).\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 02:53:26 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Karve", "Saket", ""], ["Ungar", "Lyle", ""], ["Sedoc", "Jo\u00e3o", ""]]}, {"id": "1906.06003", "submitter": "Hongyu Lin", "authors": "Hongyu Lin, Yaojie Lu, Xianpei Han, Le Sun", "title": "Cost-sensitive Regularization for Label Confusion-aware Event Detection", "comments": "Accepted to ACL2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In supervised event detection, most of the mislabeling occurs between a small\nnumber of confusing type pairs, including trigger-NIL pairs and sibling\nsub-types of the same coarse type. To address this label confusion problem,\nthis paper proposes cost-sensitive regularization, which can force the training\nprocedure to concentrate more on optimizing confusing type pairs. Specifically,\nwe introduce a cost-weighted term into the training loss, which penalizes more\non mislabeling between confusing label pairs. Furthermore, we also propose two\nestimators which can effectively measure such label confusion based on\ninstance-level or population-level statistics. Experiments on TAC-KBP 2017\ndatasets demonstrate that the proposed method can significantly improve the\nperformances of different models in both English and Chinese event detection.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 03:27:11 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Lin", "Hongyu", ""], ["Lu", "Yaojie", ""], ["Han", "Xianpei", ""], ["Sun", "Le", ""]]}, {"id": "1906.06045", "submitter": "Haichao Zhu", "authors": "Haichao Zhu, Li Dong, Furu Wei, Wenhui Wang, Bing Qin, Ting Liu", "title": "Learning to Ask Unanswerable Questions for Machine Reading Comprehension", "comments": "ACL 2019 (long paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine reading comprehension with unanswerable questions is a challenging\ntask. In this work, we propose a data augmentation technique by automatically\ngenerating relevant unanswerable questions according to an answerable question\npaired with its corresponding paragraph that contains the answer. We introduce\na pair-to-sequence model for unanswerable question generation, which\neffectively captures the interactions between the question and the paragraph.\nWe also present a way to construct training data for our question generation\nmodels by leveraging the existing reading comprehension dataset. Experimental\nresults show that the pair-to-sequence model performs consistently better\ncompared with the sequence-to-sequence baseline. We further use the\nautomatically generated unanswerable questions as a means of data augmentation\non the SQuAD 2.0 dataset, yielding 1.9 absolute F1 improvement with BERT-base\nmodel and 1.7 absolute F1 improvement with BERT-large model.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 06:35:10 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Zhu", "Haichao", ""], ["Dong", "Li", ""], ["Wei", "Furu", ""], ["Wang", "Wenhui", ""], ["Qin", "Bing", ""], ["Liu", "Ting", ""]]}, {"id": "1906.06050", "submitter": "Can Xu", "authors": "Can Xu, Wei Wu, Chongyang Tao, Huang Hu, Matt Schuerman, and Ying Wang", "title": "Neural Response Generation with Meta-Words", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present open domain response generation with meta-words. A meta-word is a\nstructured record that describes various attributes of a response, and thus\nallows us to explicitly model the one-to-many relationship within open domain\ndialogues and perform response generation in an explainable and controllable\nmanner. To incorporate meta-words into generation, we enhance the\nsequence-to-sequence architecture with a goal tracking memory network that\nformalizes meta-word expression as a goal and manages the generation process to\nachieve the goal with a state memory panel and a state controller. Experimental\nresults on two large-scale datasets indicate that our model can significantly\noutperform several state-of-the-art generation models in terms of response\nrelevance, response diversity, accuracy of one-to-many modeling, accuracy of\nmeta-word expression, and human evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 06:53:57 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Xu", "Can", ""], ["Wu", "Wei", ""], ["Tao", "Chongyang", ""], ["Hu", "Huang", ""], ["Schuerman", "Matt", ""], ["Wang", "Ying", ""]]}, {"id": "1906.06056", "submitter": "Chaitanya Alaparthi", "authors": "Chaitanya Sai Alaparthi", "title": "Microsoft AI Challenge India 2018: Learning to Rank Passages for Web\n  Question Answering with Deep Attention Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This paper describes our system for The Microsoft AI Challenge India 2018:\nRanking Passages for Web Question Answering. The system uses the biLSTM network\nwith co-attention mechanism between query and passage representations.\nAdditionally, we use self attention on embeddings to increase the lexical\ncoverage by allowing the system to take union over different embeddings. We\nalso incorporate hand-crafted features to improve the system performance. Our\nsystem achieved a Mean Reciprocal Rank (MRR) of 0.67 on eval-1 dataset.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 07:29:29 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Alaparthi", "Chaitanya Sai", ""]]}, {"id": "1906.06127", "submitter": "Yuan Yao", "authors": "Yuan Yao, Deming Ye, Peng Li, Xu Han, Yankai Lin, Zhenghao Liu,\n  Zhiyuan Liu, Lixin Huang, Jie Zhou and Maosong Sun", "title": "DocRED: A Large-Scale Document-Level Relation Extraction Dataset", "comments": "Accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple entities in a document generally exhibit complex inter-sentence\nrelations, and cannot be well handled by existing relation extraction (RE)\nmethods that typically focus on extracting intra-sentence relations for single\nentity pairs. In order to accelerate the research on document-level RE, we\nintroduce DocRED, a new dataset constructed from Wikipedia and Wikidata with\nthree features: (1) DocRED annotates both named entities and relations, and is\nthe largest human-annotated dataset for document-level RE from plain text; (2)\nDocRED requires reading multiple sentences in a document to extract entities\nand infer their relations by synthesizing all information of the document; (3)\nalong with the human-annotated data, we also offer large-scale distantly\nsupervised data, which enables DocRED to be adopted for both supervised and\nweakly supervised scenarios. In order to verify the challenges of\ndocument-level RE, we implement recent state-of-the-art methods for RE and\nconduct a thorough evaluation of these methods on DocRED. Empirical results\nshow that DocRED is challenging for existing RE methods, which indicates that\ndocument-level RE remains an open problem and requires further efforts. Based\non the detailed analysis on the experiments, we discuss multiple promising\ndirections for future research.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 11:12:20 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 08:40:35 GMT"}, {"version": "v3", "created": "Fri, 9 Aug 2019 07:42:54 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Yao", "Yuan", ""], ["Ye", "Deming", ""], ["Li", "Peng", ""], ["Han", "Xu", ""], ["Lin", "Yankai", ""], ["Liu", "Zhenghao", ""], ["Liu", "Zhiyuan", ""], ["Huang", "Lixin", ""], ["Zhou", "Jie", ""], ["Sun", "Maosong", ""]]}, {"id": "1906.06187", "submitter": "Leon Weber", "authors": "Leon Weber, Pasquale Minervini, Jannes M\\\"unchmeyer, Ulf Leser, Tim\n  Rockt\\\"aschel", "title": "NLProlog: Reasoning with Weak Unification for Question Answering in\n  Natural Language", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rule-based models are attractive for various tasks because they inherently\nlead to interpretable and explainable decisions and can easily incorporate\nprior knowledge. However, such systems are difficult to apply to problems\ninvolving natural language, due to its linguistic variability. In contrast,\nneural models can cope very well with ambiguity by learning distributed\nrepresentations of words and their composition from data, but lead to models\nthat are difficult to interpret. In this paper, we describe a model combining\nneural networks with logic programming in a novel manner for solving multi-hop\nreasoning tasks over natural language. Specifically, we propose to use a Prolog\nprover which we extend to utilize a similarity function over pretrained\nsentence encoders. We fine-tune the representations for the similarity function\nvia backpropagation. This leads to a system that can apply rule-based reasoning\nto natural language, and induce domain-specific rules from training data. We\nevaluate the proposed system on two different question answering tasks, showing\nthat it outperforms two baselines -- BIDAF (Seo et al., 2016a) and FAST QA\n(Weissenborn et al., 2017b) on a subset of the WikiHop corpus and achieves\ncompetitive results on the MedHop data set (Welbl et al., 2017).\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 13:05:08 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Weber", "Leon", ""], ["Minervini", "Pasquale", ""], ["M\u00fcnchmeyer", "Jannes", ""], ["Leser", "Ulf", ""], ["Rockt\u00e4schel", "Tim", ""]]}, {"id": "1906.06207", "submitter": "Markus Kitza", "authors": "Markus Kitza, Pavel Golik, Ralf Schl\\\"uter, Hermann Ney", "title": "Cumulative Adaptation for BLSTM Acoustic Models", "comments": "Submitted to Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the robust speech recognition problem as an adaptation\ntask. Specifically, we investigate the cumulative application of adaptation\nmethods. A bidirectional Long Short-Term Memory (BLSTM) based neural network,\ncapable of learning temporal relationships and translation invariant\nrepresentations, is used for robust acoustic modelling. Further, i-vectors were\nused as an input to the neural network to perform instantaneous speaker and\nenvironment adaptation, providing 8\\% relative improvement in word error rate\non the NIST Hub5 2000 evaluation test set. By enhancing the first-pass i-vector\nbased adaptation with a second-pass adaptation using speaker and environment\ndependent transformations within the network, a further relative improvement of\n5\\% in word error rate was achieved. We have reevaluated the features used to\nestimate i-vectors and their normalization to achieve the best performance in a\nmodern large scale automatic speech recognition system.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 13:55:12 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Kitza", "Markus", ""], ["Golik", "Pavel", ""], ["Schl\u00fcter", "Ralf", ""], ["Ney", "Hermann", ""]]}, {"id": "1906.06216", "submitter": "Hyounghun Kim", "authors": "Hyounghun Kim, Mohit Bansal", "title": "Improving Visual Question Answering by Referring to Generated Paragraph\n  Captions", "comments": "ACL 2019 (7 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Paragraph-style image captions describe diverse aspects of an image as\nopposed to the more common single-sentence captions that only provide an\nabstract description of the image. These paragraph captions can hence contain\nsubstantial information of the image for tasks such as visual question\nanswering. Moreover, this textual information is complementary with visual\ninformation present in the image because it can discuss both more abstract\nconcepts and more explicit, intermediate symbolic information about objects,\nevents, and scenes that can directly be matched with the textual question and\ncopied into the textual answer (i.e., via easier modality match). Hence, we\npropose a combined Visual and Textual Question Answering (VTQA) model which\ntakes as input a paragraph caption as well as the corresponding image, and\nanswers the given question based on both inputs. In our model, the inputs are\nfused to extract related information by cross-attention (early fusion), then\nfused again in the form of consensus (late fusion), and finally expected\nanswers are given an extra score to enhance the chance of selection (later\nfusion). Empirical results show that paragraph captions, even when\nautomatically generated (via an RL-based encoder-decoder model), help correctly\nanswer more visual questions. Overall, our joint model, when trained on the\nVisual Genome dataset, significantly improves the VQA performance over a strong\nbaseline model.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 14:14:42 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Kim", "Hyounghun", ""], ["Bansal", "Mohit", ""]]}, {"id": "1906.06253", "submitter": "Gon\\c{c}alo M. Correia", "authors": "Gon\\c{c}alo M. Correia and Andr\\'e F. T. Martins", "title": "A Simple and Effective Approach to Automatic Post-Editing with Transfer\n  Learning", "comments": "In proceedings of ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic post-editing (APE) seeks to automatically refine the output of a\nblack-box machine translation (MT) system through human post-edits. APE systems\nare usually trained by complementing human post-edited data with large,\nartificial data generated through back-translations, a time-consuming process\noften no easier than training an MT system from scratch. In this paper, we\npropose an alternative where we fine-tune pre-trained BERT models on both the\nencoder and decoder of an APE system, exploring several parameter sharing\nstrategies. By only training on a dataset of 23K sentences for 3 hours on a\nsingle GPU, we obtain results that are competitive with systems that were\ntrained on 5M artificial sentences. When we add this artificial data, our\nmethod obtains state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 15:36:22 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Correia", "Gon\u00e7alo M.", ""], ["Martins", "Andr\u00e9 F. T.", ""]]}, {"id": "1906.06298", "submitter": "Tao Li", "authors": "Tao Li, Vivek Srikumar", "title": "Augmenting Neural Networks with First-order Logic", "comments": "Accepted in ACL 2019. Minor fixes in Fig 4; extra citation in related\n  works; Typo fix in constraint N3 and its description", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, the dominant paradigm for training neural networks involves minimizing\ntask loss on a large dataset. Using world knowledge to inform a model, and yet\nretain the ability to perform end-to-end training remains an open question. In\nthis paper, we present a novel framework for introducing declarative knowledge\nto neural network architectures in order to guide training and prediction. Our\nframework systematically compiles logical statements into computation graphs\nthat augment a neural network without extra learnable parameters or manual\nredesign. We evaluate our modeling strategy on three tasks: machine\ncomprehension, natural language inference, and text chunking. Our experiments\nshow that knowledge-augmented networks can strongly improve over baselines,\nespecially in low-data regimes.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 17:10:42 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 16:14:28 GMT"}, {"version": "v3", "created": "Wed, 19 Aug 2020 19:08:51 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Li", "Tao", ""], ["Srikumar", "Vivek", ""]]}, {"id": "1906.06332", "submitter": "Tanik Saikh Mr", "authors": "Dibyanayan Bandyopadhyay, Baban Gain, Tanik Saikh, Asif Ekbal", "title": "IITP at MEDIQA 2019: Systems Report for Natural Language Inference,\n  Question Entailment and Question Answering", "comments": null, "journal-ref": null, "doi": "10.18653/v1/W19-5056", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the experiments accomplished as a part of our\nparticipation in the MEDIQA challenge, an (Abacha et al., 2019) shared task. We\nparticipated in all the three tasks defined in this particular shared task. The\ntasks are viz. i. Natural Language Inference (NLI) ii. Recognizing Question\nEntailment(RQE) and their application in medical Question Answering (QA). We\nsubmitted runs using multiple deep learning based systems (runs) for each of\nthese three tasks. We submitted five system results in each of the NLI and RQE\ntasks, and four system results for the QA task. The systems yield encouraging\nresults in all three tasks. The highest performance obtained in NLI, RQE and QA\ntasks are 81.8%, 53.2%, and 71.7%, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 06:38:33 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Bandyopadhyay", "Dibyanayan", ""], ["Gain", "Baban", ""], ["Saikh", "Tanik", ""], ["Ekbal", "Asif", ""]]}, {"id": "1906.06349", "submitter": "Samuel Korsky", "authors": "Samuel A. Korsky, Robert C. Berwick", "title": "On the Computational Power of RNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent neural network architectures such as the basic recurrent neural\nnetwork (RNN) and Gated Recurrent Unit (GRU) have gained prominence as\nend-to-end learning architectures for natural language processing tasks. But\nwhat is the computational power of such systems? We prove that finite precision\nRNNs with one hidden layer and ReLU activation and finite precision GRUs are\nexactly as computationally powerful as deterministic finite automata. Allowing\narbitrary precision, we prove that RNNs with one hidden layer and ReLU\nactivation are at least as computationally powerful as pushdown automata. If we\nalso allow infinite precision, infinite edge weights, and nonlinear output\nactivation functions, we prove that GRUs are at least as computationally\npowerful as pushdown automata. All results are shown constructively.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 18:04:39 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 02:04:08 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Korsky", "Samuel A.", ""], ["Berwick", "Robert C.", ""]]}, {"id": "1906.06362", "submitter": "Reno Kriz", "authors": "Daphne Ippolito, Reno Kriz, Maria Kustikova, Jo\\~ao Sedoc, Chris\n  Callison-Burch", "title": "Comparison of Diverse Decoding Methods from Conditional Language Models", "comments": "11 pages, Association of Computational Linguistics (ACL 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While conditional language models have greatly improved in their ability to\noutput high-quality natural language, many NLP applications benefit from being\nable to generate a diverse set of candidate sequences. Diverse decoding\nstrategies aim to, within a given-sized candidate list, cover as much of the\nspace of high-quality outputs as possible, leading to improvements for tasks\nthat re-rank and combine candidate outputs. Standard decoding methods, such as\nbeam search, optimize for generating high likelihood sequences rather than\ndiverse ones, though recent work has focused on increasing diversity in these\nmethods. In this work, we perform an extensive survey of decoding-time\nstrategies for generating diverse outputs from conditional language models. We\nalso show how diversity can be improved without sacrificing quality by\nover-sampling additional candidates, then filtering to the desired number.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 18:39:34 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Ippolito", "Daphne", ""], ["Kriz", "Reno", ""], ["Kustikova", "Maria", ""], ["Sedoc", "Jo\u00e3o", ""], ["Callison-Burch", "Chris", ""]]}, {"id": "1906.06401", "submitter": "Shrimai Prabhumoye", "authors": "Shrimai Prabhumoye, Khyathi Raghavi Chandu, Ruslan Salakhutdinov, and\n  Alan W Black", "title": "\"My Way of Telling a Story\": Persona based Grounded Story Generation", "comments": null, "journal-ref": "Storytelling Workshop at ACL 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual storytelling is the task of generating stories based on a sequence of\nimages. Inspired by the recent works in neural generation focusing on\ncontrolling the form of text, this paper explores the idea of generating these\nstories in different personas. However, one of the main challenges of\nperforming this task is the lack of a dataset of visual stories in different\npersonas. Having said that, there are independent datasets for both visual\nstorytelling and annotated sentences for various persona. In this paper we\ndescribe an approach to overcome this by getting labelled persona data from a\ndifferent task and leveraging those annotations to perform persona based story\ngeneration. We inspect various ways of incorporating personality in both the\nencoder and the decoder representations to steer the generation in the target\ndirection. To this end, we propose five models which are incremental extensions\nto the baseline model to perform the task at hand. In our experiments we use\nfive different personas to guide the generation process. We find that the\nmodels based on our hypotheses perform better at capturing words while\ngenerating stories in the target persona.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 21:00:20 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Prabhumoye", "Shrimai", ""], ["Chandu", "Khyathi Raghavi", ""], ["Salakhutdinov", "Ruslan", ""], ["Black", "Alan W", ""]]}, {"id": "1906.06425", "submitter": "Shrimai Prabhumoye", "authors": "Shrimai Prabhumoye, Elijah Mayfield, Alan W Black", "title": "Principled Frameworks for Evaluating Ethics in NLP Systems", "comments": null, "journal-ref": "Widening NLP Workshop at ACL 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We critique recent work on ethics in natural language processing. Those\ndiscussions have focused on data collection, experimental design, and\ninterventions in modeling. But we argue that we ought to first understand the\nframeworks of ethics that are being used to evaluate the fairness and justice\nof algorithmic systems. Here, we begin that discussion by outlining\ndeontological ethics, and envision a research agenda prioritized by it.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 22:52:21 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Prabhumoye", "Shrimai", ""], ["Mayfield", "Elijah", ""], ["Black", "Alan W", ""]]}, {"id": "1906.06438", "submitter": "Adhiguna Kuncoro", "authors": "Adhiguna Kuncoro, Chris Dyer, Laura Rimell, Stephen Clark, Phil\n  Blunsom", "title": "Scalable Syntax-Aware Language Models Using Knowledge Distillation", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior work has shown that, on small amounts of training data, syntactic\nneural language models learn structurally sensitive generalisations more\nsuccessfully than sequential language models. However, their computational\ncomplexity renders scaling difficult, and it remains an open question whether\nstructural biases are still necessary when sequential models have access to\never larger amounts of training data. To answer this question, we introduce an\nefficient knowledge distillation (KD) technique that transfers knowledge from a\nsyntactic language model trained on a small corpus to an LSTM language model,\nhence enabling the LSTM to develop a more structurally sensitive representation\nof the larger training data it learns from. On targeted syntactic evaluations,\nwe find that, while sequential LSTMs perform much better than previously\nreported, our proposed technique substantially improves on this baseline,\nyielding a new state of the art. Our findings and analysis affirm the\nimportance of structural biases, even in models that learn from large amounts\nof data.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 23:42:08 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Kuncoro", "Adhiguna", ""], ["Dyer", "Chris", ""], ["Rimell", "Laura", ""], ["Clark", "Stephen", ""], ["Blunsom", "Phil", ""]]}, {"id": "1906.06442", "submitter": "Isaac Caswell", "authors": "Isaac Caswell, Ciprian Chelba, David Grangier", "title": "Tagged Back-Translation", "comments": "Accepted as oral presentation in WMT 2019; 9 pages; 9 tables; 1\n  figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent work in Neural Machine Translation (NMT) has shown significant quality\ngains from noised-beam decoding during back-translation, a method to generate\nsynthetic parallel data. We show that the main role of such synthetic noise is\nnot to diversify the source side, as previously suggested, but simply to\nindicate to the model that the given source is synthetic. We propose a simpler\nalternative to noising techniques, consisting of tagging back-translated source\nsentences with an extra token. Our results on WMT outperform noised\nback-translation in English-Romanian and match performance on English-German,\nre-defining state-of-the-art in the former.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 00:36:41 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Caswell", "Isaac", ""], ["Chelba", "Ciprian", ""], ["Grangier", "David", ""]]}, {"id": "1906.06448", "submitter": "Hitomi Yanaka", "authors": "Hitomi Yanaka, Koji Mineshima, Daisuke Bekki, Kentaro Inui, Satoshi\n  Sekine, Lasha Abzianidze and Johan Bos", "title": "Can neural networks understand monotonicity reasoning?", "comments": "accepted by ACL2019 BlackboxNLP (long paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monotonicity reasoning is one of the important reasoning skills for any\nintelligent natural language inference (NLI) model in that it requires the\nability to capture the interaction between lexical and syntactic structures.\nSince no test set has been developed for monotonicity reasoning with wide\ncoverage, it is still unclear whether neural models can perform monotonicity\nreasoning in a proper way. To investigate this issue, we introduce the\nMonotonicity Entailment Dataset (MED). Performance by state-of-the-art NLI\nmodels on the new test set is substantially worse, under 55%, especially on\ndownward reasoning. In addition, analysis using a monotonicity-driven data\naugmentation method showed that these models might be limited in their\ngeneralization ability in upward and downward reasoning.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 01:18:41 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 10:52:46 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Yanaka", "Hitomi", ""], ["Mineshima", "Koji", ""], ["Bekki", "Daisuke", ""], ["Inui", "Kentaro", ""], ["Sekine", "Satoshi", ""], ["Abzianidze", "Lasha", ""], ["Bos", "Johan", ""]]}, {"id": "1906.06464", "submitter": "Yiding Hao", "authors": "Yiding Hao and Dustin Bowers", "title": "Action-Sensitive Phonological Dependencies", "comments": "To appear in the Proceedings of the 16th SIGMORPHON Workshop on\n  Computational Research in Phonetics, Phonology, and Morphology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper defines a subregular class of functions called the tier-based\nsynchronized strictly local (TSSL) functions. These functions are similar to\nthe the tier-based input-output strictly local (TIOSL) functions, except that\nthe locality condition is enforced not on the input and output streams, but on\nthe computation history of the minimal subsequential finite-state transducer.\nWe show that TSSL functions naturally describe rhythmic syncope while TIOSL\nfunctions cannot, and we argue that TSSL functions provide a more restricted\ncharacterization of rhythmic syncope than existing treatments within Optimality\nTheory.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 00:03:33 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Hao", "Yiding", ""], ["Bowers", "Dustin", ""]]}, {"id": "1906.06465", "submitter": "Martin Jaggi", "authors": "Arno Schneuwly and Ralf Grubenmann and S\\'everine Rion Logean and Mark\n  Cieliebak and Martin Jaggi", "title": "Correlating Twitter Language with Community-Level Health Outcomes", "comments": "ACL SMM4H Workshop (Social Media Mining for Health Applications)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study how language on social media is linked to diseases such as\natherosclerotic heart disease (AHD), diabetes and various types of cancer. Our\nproposed model leverages state-of-the-art sentence embeddings, followed by a\nregression model and clustering, without the need of additional labelled data.\nIt allows to predict community-level medical outcomes from language, and\nthereby potentially translate these to the individual level. The method is\napplicable to a wide range of target variables and allows us to discover known\nand potentially novel correlations of medical outcomes with life-style aspects\nand other socioeconomic risk factors.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 01:42:23 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 16:57:24 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Schneuwly", "Arno", ""], ["Grubenmann", "Ralf", ""], ["Logean", "S\u00e9verine Rion", ""], ["Cieliebak", "Mark", ""], ["Jaggi", "Martin", ""]]}, {"id": "1906.06481", "submitter": "Jie Wang", "authors": "Haoshen Fan, Jie Wang, Bojin Zhuang, Shaojun Wang and Jing Xiao", "title": "A Hierarchical Attention Based Seq2seq Model for Chinese Lyrics\n  Generation", "comments": "accepted by The 16th Pacific Rim International Conference on AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we comprehensively study on context-aware generation of\nChinese song lyrics. Conventional text generative models generate a sequence or\nsentence word by word, failing to consider the contextual relationship between\nsentences. Taking account into the characteristics of lyrics, a hierarchical\nattention based Seq2Seq (Sequence-to-Sequence) model is proposed for Chinese\nlyrics generation. With encoding of word-level and sentence-level contextual\ninformation, this model promotes the topic relevance and consistency of\ngeneration. A large Chinese lyrics corpus is also leveraged for model training.\nEventually, results of automatic and human evaluations demonstrate that our\nmodel is able to compose complete Chinese lyrics with one united topic\nconstraint.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 06:58:42 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Fan", "Haoshen", ""], ["Wang", "Jie", ""], ["Zhuang", "Bojin", ""], ["Wang", "Shaojun", ""], ["Xiao", "Jing", ""]]}, {"id": "1906.06493", "submitter": "Guy De Pauw", "authors": "Janneke van de Loo, Guy De Pauw, Walter Daelemans", "title": "A weakly supervised sequence tagging and grammar induction approach to\n  semantic frame slot filling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes continuing work on semantic frame slot filling for a\ncommand and control task using a weakly-supervised approach. We investigate the\nadvantages of using retraining techniques that take the output of a\nhierarchical hidden markov model as input to two inductive approaches: (1)\ndiscriminative sequence labelers based on conditional random fields and\nmemory-based learning and (2) probabilistic context-free grammar induction.\nExperimental results show that this setup can significantly improve F-scores\nwithout the need for additional information sources. Furthermore, qualitative\nanalysis shows that the weakly supervised technique is able to automatically\ninduce an easily interpretable and syntactically appropriate grammar for the\ndomain and task at hand.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 08:13:32 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["van de Loo", "Janneke", ""], ["De Pauw", "Guy", ""], ["Daelemans", "Walter", ""]]}, {"id": "1906.06550", "submitter": "Ahmad Aghaebrahimian Ph.D.", "authors": "Ahmad Aghaebrahimian and Mark Cieliebak", "title": "Towards Integration of Statistical Hypothesis Tests into Deep Neural\n  Networks", "comments": "Accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report our ongoing work about a new deep architecture working in tandem\nwith a statistical test procedure for jointly training texts and their label\ndescriptions for multi-label and multi-class classification tasks. A\nstatistical hypothesis testing method is used to extract the most informative\nwords for each given class. These words are used as a class description for\nmore label-aware text classification. Intuition is to help the model to\nconcentrate on more informative words rather than more frequent ones. The model\nleverages the use of label descriptions in addition to the input text to\nenhance text classification performance. Our method is entirely data-driven,\nhas no dependency on other sources of information than the training data, and\nis adaptable to different classification problems by providing appropriate\ntraining data without major hyper-parameter tuning. We trained and tested our\nsystem on several publicly available datasets, where we managed to improve the\nstate-of-the-art on one set with a high margin, and to obtain competitive\nresults on all other ones.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 12:47:18 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Aghaebrahimian", "Ahmad", ""], ["Cieliebak", "Mark", ""]]}, {"id": "1906.06581", "submitter": "Rajhans Samdani", "authors": "Rajhans Samdani, Pierre Rappolt, Ankit Goyal, Pratyus Patnaik", "title": "Practical User Feedback-driven Internal Search Using Online Learning to\n  Rank", "comments": "Proceedings of the 2019 IJCAI Workshop SCAI: The 4th International\n  Workshop on Search-Oriented Conversational AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a system, Spoke, for creating and searching internal knowledge\nbase (KB) articles for organizations. Spoke is available as a SaaS\n(Software-as-a-Service) product deployed across hundreds of organizations with\na diverse set of domains. Spoke continually improves search quality using\nconversational user feedback which allows it to provide better search\nexperience than standard information retrieval systems without encoding any\nexplicit domain knowledge. We achieve this by using a real-time online\nlearning-to-rank (L2R) algorithm that automatically customizes relevance\nscoring for each organization deploying Spoke by using a query similarity\nkernel.\n  The focus of this paper is on incorporating practical considerations into our\nrelevance scoring function and algorithm that make Spoke easy to deploy and\nsuitable for handling events that naturally happen over the life-cycle of any\nKB deployment. We show that Spoke outperforms competitive baselines by up to\n41% in offline F1 comparisons.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 15:55:43 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 20:12:41 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Samdani", "Rajhans", ""], ["Rappolt", "Pierre", ""], ["Goyal", "Ankit", ""], ["Patnaik", "Pratyus", ""]]}, {"id": "1906.06582", "submitter": "Christoph Benzm\\\"uller", "authors": "David Fuenmayor and Christoph Benzm\\\"uller", "title": "A Computational-Hermeneutic Approach for Conceptual Explicitation", "comments": "29 pages, 9 figures, to appear in A. Nepomuceno, L. Magnani, F.\n  Salguero, C. Bar\\'es, M. Fontaine (eds.), Model-Based Reasoning in Science\n  and Technology. Inferential Models for Logic, Language, Cognition and\n  Computation, Series \"Sapere\", Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a computer-supported approach for the logical analysis and\nconceptual explicitation of argumentative discourse. Computational hermeneutics\nharnesses recent progresses in automated reasoning for higher-order logics and\naims at formalizing natural-language argumentative discourse using flexible\ncombinations of expressive non-classical logics. In doing so, it allows us to\nrender explicit the tacit conceptualizations implicit in argumentative\ndiscursive practices. Our approach operates on networks of structured arguments\nand is iterative and two-layered. At one layer we search for logically correct\nformalizations for each of the individual arguments. At the next layer we\nselect among those correct formalizations the ones which honor the argument's\ndialectic role, i.e. attacking or supporting other arguments as intended. We\noperate at these two layers in parallel and continuously rate sentences'\nformalizations by using, primarily, inferential adequacy criteria. An\ninterpretive, logical theory will thus gradually evolve. This theory is\ncomposed of meaning postulates serving as explications for concepts playing a\nrole in the analyzed arguments. Such a recursive, iterative approach to\ninterpretation does justice to the inherent circularity of understanding: the\nwhole is understood compositionally on the basis of its parts, while each part\nis understood only in the context of the whole (hermeneutic circle). We\nsummarily discuss previous work on exemplary applications of human-in-the-loop\ncomputational hermeneutics in metaphysical discourse. We also discuss some of\nthe main challenges involved in fully-automating our approach. By sketching\nsome design ideas and reviewing relevant technologies, we argue for the\ntechnological feasibility of a highly-automated computational hermeneutics.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 15:57:57 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2019 09:49:19 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Fuenmayor", "David", ""], ["Benzm\u00fcller", "Christoph", ""]]}, {"id": "1906.06593", "submitter": "Samuel Bell", "authors": "Samuel Bell, Helen Yannakoudakis and Marek Rei", "title": "Context is Key: Grammatical Error Detection with Contextual Word\n  Representations", "comments": null, "journal-ref": "Proceedings of the Fourteenth Workshop on Innovative Use of NLP\n  for Building Educational Applications (BEA 2019), pp. 103-115", "doi": "10.18653/v1/W19-4410", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grammatical error detection (GED) in non-native writing requires systems to\nidentify a wide range of errors in text written by language learners. Error\ndetection as a purely supervised task can be challenging, as GED datasets are\nlimited in size and the label distributions are highly imbalanced.\nContextualized word representations offer a possible solution, as they can\nefficiently capture compositional information in language and can be optimized\non large amounts of unsupervised data. In this paper, we perform a systematic\ncomparison of ELMo, BERT and Flair embeddings (Peters et al., 2017; Devlin et\nal., 2018; Akbik et al., 2018) on a range of public GED datasets, and propose\nan approach to effectively integrate such representations in current methods,\nachieving a new state of the art on GED. We further analyze the strengths and\nweaknesses of different contextual embeddings for the task at hand, and present\ndetailed analyses of their impact on different types of errors.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 17:29:06 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 17:06:15 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Bell", "Samuel", ""], ["Yannakoudakis", "Helen", ""], ["Rei", "Marek", ""]]}, {"id": "1906.06606", "submitter": "Yair Feldman", "authors": "Yair Feldman, Ran El-Yaniv", "title": "Multi-Hop Paragraph Retrieval for Open-Domain Question Answering", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the task of multi-hop open-domain Question\nAnswering (QA). This task is particularly challenging since it requires the\nsimultaneous performance of textual reasoning and efficient searching. We\npresent a method for retrieving multiple supporting paragraphs, nested amidst a\nlarge knowledge base, which contain the necessary evidence to answer a given\nquestion. Our method iteratively retrieves supporting paragraphs by forming a\njoint vector representation of both a question and a paragraph. The retrieval\nis performed by considering contextualized sentence-level representations of\nthe paragraphs in the knowledge source. Our method achieves state-of-the-art\nperformance over two well-known datasets, SQuAD-Open and HotpotQA, which serve\nas our single- and multi-hop open-domain QA benchmarks, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 19:17:10 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Feldman", "Yair", ""], ["El-Yaniv", "Ran", ""]]}, {"id": "1906.06678", "submitter": "Zhi-Xiu Ye", "authors": "Zhi-Xiu Ye and Zhen-Hua Ling", "title": "Multi-Level Matching and Aggregation Network for Few-Shot Relation\n  Classification", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a multi-level matching and aggregation network (MLMAN)\nfor few-shot relation classification. Previous studies on this topic adopt\nprototypical networks, which calculate the embedding vector of a query instance\nand the prototype vector of each support set independently. In contrast, our\nproposed MLMAN model encodes the query instance and each support set in an\ninteractive way by considering their matching information at both local and\ninstance levels. The final class prototype for each support set is obtained by\nattentive aggregation over the representations of its support instances, where\nthe weights are calculated using the query instance. Experimental results\ndemonstrate the effectiveness of our proposed methods, which achieve a new\nstate-of-the-art performance on the FewRel dataset.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 13:10:33 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Ye", "Zhi-Xiu", ""], ["Ling", "Zhen-Hua", ""]]}, {"id": "1906.06685", "submitter": "Yangjun Zhang", "authors": "Yangjun Zhang, Pengjie Ren, Maarten de Rijke", "title": "Improving Background Based Conversation with Context-aware Knowledge\n  Pre-selection", "comments": "SCAI 2019 workshop paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background Based Conversations (BBCs) have been developed to make dialogue\nsystems generate more informative and natural responses by leveraging\nbackground knowledge. Existing methods for BBCs can be grouped into two\ncategories: extraction-based methods and generation-based methods. The former\nextract spans frombackground material as responses that are not necessarily\nnatural. The latter generate responses thatare natural but not necessarily\neffective in leveraging background knowledge. In this paper, we focus on\ngeneration-based methods and propose a model, namely Context-aware Knowledge\nPre-selection (CaKe), which introduces a pre-selection process that uses\ndynamic bi-directional attention to improve knowledge selection by using the\nutterance history context as prior information to select the most relevant\nbackground material. Experimental results show that our model is superior to\ncurrent state-of-the-art baselines, indicating that it benefits from the\npre-selection process, thus improving in-formativeness and fluency.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 13:33:55 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Zhang", "Yangjun", ""], ["Ren", "Pengjie", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1906.06703", "submitter": "Nafise Sadat Moosavi", "authors": "Nafise Sadat Moosavi, Leo Born, Massimo Poesio, Michael Strube", "title": "Using Automatically Extracted Minimum Spans to Disentangle Coreference\n  Evaluation from Boundary Detection", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The common practice in coreference resolution is to identify and evaluate the\nmaximum span of mentions. The use of maximum spans tangles coreference\nevaluation with the challenges of mention boundary detection like prepositional\nphrase attachment. To address this problem, minimum spans are manually\nannotated in smaller corpora. However, this additional annotation is costly and\ntherefore, this solution does not scale to large corpora. In this paper, we\npropose the MINA algorithm for automatically extracting minimum spans to\nbenefit from minimum span evaluation in all corpora. We show that the extracted\nminimum spans by MINA are consistent with those that are manually annotated by\nexperts. Our experiments show that using minimum spans is in particular\nimportant in cross-dataset coreference evaluation, in which detected mention\nboundaries are noisier due to domain shift. We will integrate MINA into\nhttps://github.com/ns-moosavi/coval for reporting standard coreference scores\nbased on both maximum and automatically detected minimum spans.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 14:33:45 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Moosavi", "Nafise Sadat", ""], ["Born", "Leo", ""], ["Poesio", "Massimo", ""], ["Strube", "Michael", ""]]}, {"id": "1906.06718", "submitter": "Jiaming Luo", "authors": "Jiaming Luo, Yuan Cao, Regina Barzilay", "title": "Neural Decipherment via Minimum-Cost Flow: from Ugaritic to Linear B", "comments": "Accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a novel neural approach for automatic decipherment\nof lost languages. To compensate for the lack of strong supervision signal, our\nmodel design is informed by patterns in language change documented in\nhistorical linguistics. The model utilizes an expressive sequence-to-sequence\nmodel to capture character-level correspondences between cognates. To\neffectively train the model in an unsupervised manner, we innovate the training\nprocedure by formalizing it as a minimum-cost flow problem. When applied to the\ndecipherment of Ugaritic, we achieve a 5.5% absolute improvement over\nstate-of-the-art results. We also report the first automatic results in\ndeciphering Linear B, a syllabic language related to ancient Greek, where our\nmodel correctly translates 67.3% of cognates.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 15:37:54 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Luo", "Jiaming", ""], ["Cao", "Yuan", ""], ["Barzilay", "Regina", ""]]}, {"id": "1906.06719", "submitter": "Wenxian Shi", "authors": "Wenxian Shi, Hao Zhou, Ning Miao, Lei Li", "title": "Dispersed Exponential Family Mixture VAEs for Interpretable Text\n  Generation", "comments": "Camera ready version for ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models are commonly used for generating images and text.\nInterpretability of these models is one important pursuit, other than the\ngeneration quality. Variational auto-encoder (VAE) with Gaussian distribution\nas prior has been successfully applied in text generation, but it is hard to\ninterpret the meaning of the latent variable. To enhance the controllability\nand interpretability, one can replace the Gaussian prior with a mixture of\nGaussian distributions (GM-VAE), whose mixture components could be related to\nhidden semantic aspects of data. In this paper, we generalize the practice and\nintroduce DEM-VAE, a class of models for text generation using VAEs with a\nmixture distribution of exponential family. Unfortunately, a standard\nvariational training algorithm fails due to the mode-collapse problem. We\ntheoretically identify the root cause of the problem and propose an effective\nalgorithm to train DEM-VAE. Our method penalizes the training with an extra\ndispersion term to induce a well-structured latent space. Experimental results\nshow that our approach does obtain a meaningful space, and it outperforms\nstrong baselines in text generation benchmarks. The code is available at\nhttps://github.com/wenxianxian/demvae.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 15:41:07 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 09:50:41 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2020 09:53:34 GMT"}, {"version": "v4", "created": "Fri, 21 Aug 2020 09:52:58 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Shi", "Wenxian", ""], ["Zhou", "Hao", ""], ["Miao", "Ning", ""], ["Li", "Lei", ""]]}, {"id": "1906.06725", "submitter": "Weiyan Shi", "authors": "Xuewei Wang, Weiyan Shi, Richard Kim, Yoojung Oh, Sijia Yang, Jingwen\n  Zhang and Zhou Yu", "title": "Persuasion for Good: Towards a Personalized Persuasive Dialogue System\n  for Social Good", "comments": "Accepted by ACL 2019 as a long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing intelligent persuasive conversational agents to change people's\nopinions and actions for social good is the frontier in advancing the ethical\ndevelopment of automated dialogue systems. To do so, the first step is to\nunderstand the intricate organization of strategic disclosures and appeals\nemployed in human persuasion conversations. We designed an online persuasion\ntask where one participant was asked to persuade the other to donate to a\nspecific charity. We collected a large dataset with 1,017 dialogues and\nannotated emerging persuasion strategies from a subset. Based on the\nannotation, we built a baseline classifier with context information and\nsentence-level features to predict the 10 persuasion strategies used in the\ncorpus. Furthermore, to develop an understanding of personalized persuasion\nprocesses, we analyzed the relationships between individuals' demographic and\npsychological backgrounds including personality, morality, value systems, and\ntheir willingness for donation. Then, we analyzed which types of persuasion\nstrategies led to a greater amount of donation depending on the individuals'\npersonal backgrounds. This work lays the ground for developing a personalized\npersuasive dialogue system.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 16:43:02 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 04:17:44 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Wang", "Xuewei", ""], ["Shi", "Weiyan", ""], ["Kim", "Richard", ""], ["Oh", "Yoojung", ""], ["Yang", "Sijia", ""], ["Zhang", "Jingwen", ""], ["Yu", "Zhou", ""]]}, {"id": "1906.06755", "submitter": "Michael Hahn", "authors": "Michael Hahn", "title": "Theoretical Limitations of Self-Attention in Neural Sequence Models", "comments": "Accepted by: Transactions of the Association for Computational\n  Linguistics", "journal-ref": null, "doi": "10.1162/tacl_a_00306", "report-no": null, "categories": "cs.CL cs.FL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformers are emerging as the new workhorse of NLP, showing great success\nacross tasks. Unlike LSTMs, transformers process input sequences entirely\nthrough self-attention. Previous work has suggested that the computational\ncapabilities of self-attention to process hierarchical structures are limited.\nIn this work, we mathematically investigate the computational power of\nself-attention to model formal languages. Across both soft and hard attention,\nwe show strong theoretical limitations of the computational abilities of\nself-attention, finding that it cannot model periodic finite-state languages,\nnor hierarchical structure, unless the number of layers or heads increases with\ninput length. These limitations seem surprising given the practical success of\nself-attention and the prominent role assigned to hierarchical structure in\nlinguistics, suggesting that natural language can be approximated well with\nmodels that are too weak for the formal languages typically assumed in\ntheoretical linguistics.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 19:19:49 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 22:35:16 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Hahn", "Michael", ""]]}, {"id": "1906.06788", "submitter": "Jiahuan Pei", "authors": "Jiahuan Pei, Arent Stienstra, Julia Kiseleva, Maarten de Rijke", "title": "SEntNet: Source-aware Recurrent Entity Network for Dialogue Response\n  Selection", "comments": "Proceedings of the 2019 IJCAI Workshop SCAI: The 4th International\n  Workshop on Search-Oriented Conversational AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue response selection is an important part of Task-oriented Dialogue\nSystems (TDSs); it aims to predict an appropriate response given a dialogue\ncontext. Obtaining key information from a complex, long dialogue context is\nchallenging, especially when different sources of information are available,\ne.g., the user's utterances, the system's responses, and results retrieved from\na knowledge base (KB). Previous work ignores the type of information source and\nmerges sources for response selection. However, accounting for the source type\nmay lead to remarkable differences in the quality of response selection. We\npropose the Source-aware Recurrent Entity Network (SEntNet), which is aware of\ndifferent information sources for the response selection process. SEntNet\nachieves this by employing source-specific memories to exploit differences in\nthe usage of words and syntactic structure from different information sources\n(user, system, and KB). Experimental results show that SEntNet obtains 91.0%\naccuracy on the Dialog bAbI dataset, outperforming prior work by 4.7%. On the\nDSTC2 dataset, SEntNet obtains an accuracy of 41.2%, beating source unaware\nrecurrent entity networks by 2.4%.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 22:36:33 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 17:24:59 GMT"}, {"version": "v3", "created": "Thu, 20 Jun 2019 00:38:00 GMT"}, {"version": "v4", "created": "Mon, 16 Sep 2019 09:29:48 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Pei", "Jiahuan", ""], ["Stienstra", "Arent", ""], ["Kiseleva", "Julia", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1906.06849", "submitter": "Sheikh Muhammad Sarwar", "authors": "Sheikh Muhammad Sarwar, Hamed Bonab, James Allan", "title": "A Multi-Task Architecture on Relevance-based Neural Query Translation", "comments": "Accepted for publication at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a multi-task learning approach to train a Neural Machine\nTranslation (NMT) model with a Relevance-based Auxiliary Task (RAT) for search\nquery translation. The translation process for Cross-lingual Information\nRetrieval (CLIR) task is usually treated as a black box and it is performed as\nan independent step. However, an NMT model trained on sentence-level parallel\ndata is not aware of the vocabulary distribution of the retrieval corpus. We\naddress this problem with our multi-task learning architecture that achieves\n16% improvement over a strong NMT baseline on Italian-English query-document\ndataset. We show using both quantitative and qualitative analysis that our\nmodel generates balanced and precise translations with the regularization\neffect it achieves from multi-task learning paradigm.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 05:37:27 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Sarwar", "Sheikh Muhammad", ""], ["Bonab", "Hamed", ""], ["Allan", "James", ""]]}, {"id": "1906.06870", "submitter": "Raghav Gupta", "authors": "Darsh J Shah, Raghav Gupta, Amir A Fayazi, Dilek Hakkani-Tur", "title": "Robust Zero-Shot Cross-Domain Slot Filling with Example Values", "comments": "To appear in ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Task-oriented dialog systems increasingly rely on deep learning-based slot\nfilling models, usually needing extensive labeled training data for target\ndomains. Often, however, little to no target domain training data may be\navailable, or the training and target domain schemas may be misaligned, as is\ncommon for web forms on similar websites. Prior zero-shot slot filling models\nuse slot descriptions to learn concepts, but are not robust to misaligned\nschemas. We propose utilizing both the slot description and a small number of\nexamples of slot values, which may be easily available, to learn semantic\nrepresentations of slots which are transferable across domains and robust to\nmisaligned schemas. Our approach outperforms state-of-the-art models on two\nmulti-domain datasets, especially in the low-data setting.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 07:07:01 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Shah", "Darsh J", ""], ["Gupta", "Raghav", ""], ["Fayazi", "Amir A", ""], ["Hakkani-Tur", "Dilek", ""]]}, {"id": "1906.06892", "submitter": "Yaxian Xia", "authors": "Yaxian Xia and Lun Huang and Wenmin Wang and Xiaoyong Wei and Wenmin\n  Wang", "title": "ParNet: Position-aware Aggregated Relation Network for Image-Text\n  matching", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploring fine-grained relationship between entities(e.g. objects in image or\nwords in sentence) has great contribution to understand multimedia content\nprecisely. Previous attention mechanism employed in image-text matching either\ntakes multiple self attention steps to gather correspondences or uses image\nobjects (or words) as context to infer image-text similarity. However, they\nonly take advantage of semantic information without considering that objects'\nrelative position also contributes to image understanding. To this end, we\nintroduce a novel position-aware relation module to model both the semantic and\nspatial relationship simultaneously for image-text matching in this paper.\nGiven an image, our method utilizes the location of different objects to\ncapture spatial relationship innovatively. With the combination of semantic and\nspatial relationship, it's easier to understand the content of different\nmodalities (images and sentences) and capture fine-grained latent\ncorrespondences of image-text pairs. Besides, we employ a two-step aggregated\nrelation module to capture interpretable alignment of image-text pairs. The\nfirst step, we call it intra-modal relation mechanism, in which we computes\nresponses between different objects in an image or different words in a\nsentence separately; The second step, we call it inter-modal relation\nmechanism, in which the query plays a role of textual context to refine the\nrelationship among object proposals in an image. In this way, our\nposition-aware aggregated relation network (ParNet) not only knows which\nentities are relevant by attending on different objects (words) adaptively, but\nalso adjust the inter-modal correspondence according to the latent alignments\naccording to query's content. Our approach achieves the state-of-the-art\nresults on MS-COCO dataset.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 08:26:43 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Xia", "Yaxian", ""], ["Huang", "Lun", ""], ["Wang", "Wenmin", ""], ["Wei", "Xiaoyong", ""], ["Wang", "Wenmin", ""]]}, {"id": "1906.06893", "submitter": "Yifan Gao", "authors": "Yifan Gao, Piji Li, Irwin King, Michael R. Lyu", "title": "Interconnected Question Generation with Coreference Alignment and\n  Conversation Flow Modeling", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We study the problem of generating interconnected questions in\nquestion-answering style conversations. Compared with previous works which\ngenerate questions based on a single sentence (or paragraph), this setting is\ndifferent in two major aspects: (1) Questions are highly conversational. Almost\nhalf of them refer back to conversation history using coreferences. (2) In a\ncoherent conversation, questions have smooth transitions between turns. We\npropose an end-to-end neural model with coreference alignment and conversation\nflow modeling. The coreference alignment modeling explicitly aligns coreferent\nmentions in conversation history with corresponding pronominal references in\ngenerated questions, which makes generated questions interconnected to\nconversation history. The conversation flow modeling builds a coherent\nconversation by starting questioning on the first few sentences in a text\npassage and smoothly shifting the focus to later parts. Extensive experiments\nshow that our system outperforms several baselines and can generate highly\nconversational questions. The code implementation is released at\nhttps://github.com/Evan-Gao/conversational-QG.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 08:30:55 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Gao", "Yifan", ""], ["Li", "Piji", ""], ["King", "Irwin", ""], ["Lyu", "Michael R.", ""]]}, {"id": "1906.06905", "submitter": "Ji-Ung Lee", "authors": "Ji-Ung Lee, Erik Schwan and Christian M. Meyer", "title": "Manipulating the Difficulty of C-Tests", "comments": "To appear as a long paper in Proceedings of the 57th Annual Meeting\n  of the Association for Computational Linguistics (ACL 2019). Download our\n  code and data from the user study at github:\n  https://github.com/UKPLab/acl2019-ctest-difficulty-manipulation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose two novel manipulation strategies for increasing and decreasing\nthe difficulty of C-tests automatically. This is a crucial step towards\ngenerating learner-adaptive exercises for self-directed language learning and\npreparing language assessment tests. To reach the desired difficulty level, we\nmanipulate the size and the distribution of gaps based on absolute and relative\ngap difficulty predictions. We evaluate our approach in corpus-based\nexperiments and in a user study with 60 participants. We find that both\nstrategies are able to generate C-tests with the desired difficulty level.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 08:57:38 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2019 08:07:32 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Lee", "Ji-Ung", ""], ["Schwan", "Erik", ""], ["Meyer", "Christian M.", ""]]}, {"id": "1906.06906", "submitter": "Ruidan He", "authors": "Ruidan He, Wee Sun Lee, Hwee Tou Ng, Daniel Dahlmeier", "title": "An Interactive Multi-Task Learning Network for End-to-End Aspect-Based\n  Sentiment Analysis", "comments": "Accepted to ACL2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect-based sentiment analysis produces a list of aspect terms and their\ncorresponding sentiments for a natural language sentence. This task is usually\ndone in a pipeline manner, with aspect term extraction performed first,\nfollowed by sentiment predictions toward the extracted aspect terms. While\neasier to develop, such an approach does not fully exploit joint information\nfrom the two subtasks and does not use all available sources of training\ninformation that might be helpful, such as document-level labeled sentiment\ncorpus. In this paper, we propose an interactive multi-task learning network\n(IMN) which is able to jointly learn multiple related tasks simultaneously at\nboth the token level as well as the document level. Unlike conventional\nmulti-task learning methods that rely on learning common features for the\ndifferent tasks, IMN introduces a message passing architecture where\ninformation is iteratively passed to different tasks through a shared set of\nlatent variables. Experimental results demonstrate superior performance of the\nproposed method against multiple baselines on three benchmark datasets.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 09:00:01 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["He", "Ruidan", ""], ["Lee", "Wee Sun", ""], ["Ng", "Hwee Tou", ""], ["Dahlmeier", "Daniel", ""]]}, {"id": "1906.06916", "submitter": "Lixiang Hong", "authors": "Lixiang Hong, JinJian Lin, Jiang Tao and Jianyang Zeng", "title": "BERE: An accurate distantly supervised biomedical entity relation\n  extraction network", "comments": "My tutor told me to withdraw this paper at once", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated entity relation extraction (RE) from literature provides an\nimportant source for constructing biomedical database, which is more efficient\nand extensible than manual curation. However, existing RE models usually ignore\nthe information contained in sentence structures and target entities. In this\npaper, we propose BERE, a deep learning based model which uses Gumbel Tree-GRU\nto learn sentence structures and joint embedding to incorporate entity\ninformation. It also employs word-level attention for improved relation\nextraction and sentence-level attention to suit the distantly supervised\ndataset. Because the existing dataset are relatively small, we further\nconstruct a much larger drug-target interaction extraction (DTIE) dataset by\ndistant supervision. Experiments conducted on both DDIExtraction 2013 task and\nDTIE dataset show our model's effectiveness over state-of-the-art baselines in\nterms of F1 measures and PR curves.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 09:33:27 GMT"}, {"version": "v2", "created": "Sat, 22 Jun 2019 15:58:54 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Hong", "Lixiang", ""], ["Lin", "JinJian", ""], ["Tao", "Jiang", ""], ["Zeng", "Jianyang", ""]]}, {"id": "1906.06917", "submitter": "Momchil Hardalov", "authors": "Daniel Kopev, Dimitrina Zlatkova, Kristiyan Mitov, Atanas Atanasov,\n  Momchil Hardalov, Ivan Koychev, Preslav Nakov", "title": "Recursive Style Breach Detection with Multifaceted Ensemble Learning", "comments": "Accepted as regular paper at AIMSA 2018", "journal-ref": null, "doi": "10.1007/978-3-319-99344-7_12", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a supervised approach for style change detection, which aims at\npredicting whether there are changes in the style in a given text document, as\nwell as at finding the exact positions where such changes occur. In particular,\nwe combine a TF.IDF representation of the document with features specifically\nengineered for the task, and we make predictions via an ensemble of diverse\nclassifiers including SVM, Random Forest, AdaBoost, MLP, and LightGBM. Whenever\nthe model detects that style change is present, we apply it recursively,\nlooking to find the specific positions of the change. Our approach powered the\nwinning system for the PAN@CLEF 2018 task on Style Change Detection.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 09:33:30 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Kopev", "Daniel", ""], ["Zlatkova", "Dimitrina", ""], ["Mitov", "Kristiyan", ""], ["Atanasov", "Atanas", ""], ["Hardalov", "Momchil", ""], ["Koychev", "Ivan", ""], ["Nakov", "Preslav", ""]]}, {"id": "1906.06945", "submitter": "Bin Liang", "authors": "Bin Liang, Jiachen Du, Ruifeng Xu, Binyang Li, Hejiao Huang", "title": "Context-aware Embedding for Targeted Aspect-based Sentiment Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based neural models were employed to detect the different aspects\nand sentiment polarities of the same target in targeted aspect-based sentiment\nanalysis (TABSA). However, existing methods do not specifically pre-train\nreasonable embeddings for targets and aspects in TABSA. This may result in\ntargets or aspects having the same vector representations in different contexts\nand losing the context-dependent information. To address this problem, we\npropose a novel method to refine the embeddings of targets and aspects. Such\npivotal embedding refinement utilizes a sparse coefficient vector to adjust the\nembeddings of target and aspect from the context. Hence the embeddings of\ntargets and aspects can be refined from the highly correlative words instead of\nusing context-independent or randomly initialized vectors. Experiment results\non two benchmark datasets show that our approach yields the state-of-the-art\nperformance in TABSA task.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 10:59:50 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Liang", "Bin", ""], ["Du", "Jiachen", ""], ["Xu", "Ruifeng", ""], ["Li", "Binyang", ""], ["Huang", "Hejiao", ""]]}, {"id": "1906.06947", "submitter": "Xiao Liu", "authors": "Xiao Liu, Heyan Huang, Yue Zhang", "title": "Open Domain Event Extraction Using Neural Latent Variable Models", "comments": "accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider open domain event extraction, the task of extracting unconstraint\ntypes of events from news clusters. A novel latent variable neural model is\nconstructed, which is scalable to very large corpus. A dataset is collected and\nmanually annotated, with task-specific evaluation metrics being designed.\nResults show that the proposed unsupervised model gives better performance\ncompared to the state-of-the-art method for event schema induction.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 11:01:20 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Liu", "Xiao", ""], ["Huang", "Heyan", ""], ["Zhang", "Yue", ""]]}, {"id": "1906.07004", "submitter": "Hui Su", "authors": "Hui Su, Xiaoyu Shen, Rongzhi Zhang, Fei Sun, Pengwei Hu, Cheng Niu,\n  Jie Zhou", "title": "Improving Multi-turn Dialogue Modelling with Utterance ReWriter", "comments": "Accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has made impressive progress in single-turn dialogue\nmodelling. In the multi-turn setting, however, current models are still far\nfrom satisfactory. One major challenge is the frequently occurred coreference\nand information omission in our daily conversation, making it hard for machines\nto understand the real intention. In this paper, we propose rewriting the human\nutterance as a pre-process to help multi-turn dialgoue modelling. Each\nutterance is first rewritten to recover all coreferred and omitted information.\nThe next processing steps are then performed based on the rewritten utterance.\nTo properly train the utterance rewriter, we collect a new dataset with human\nannotations and introduce a Transformer-based utterance rewriting architecture\nusing the pointer network. We show the proposed architecture achieves\nremarkably good performance on the utterance rewriting task. The trained\nutterance rewriter can be easily integrated into online chatbots and brings\ngeneral improvement over different domains.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 06:45:08 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Su", "Hui", ""], ["Shen", "Xiaoyu", ""], ["Zhang", "Rongzhi", ""], ["Sun", "Fei", ""], ["Hu", "Pengwei", ""], ["Niu", "Cheng", ""], ["Zhou", "Jie", ""]]}, {"id": "1906.07020", "submitter": "Waleed Ragheb", "authors": "Waleed Ragheb, J\\'er\\^ome Az\\'e, Sandra Bringay and Maximilien\n  Servajean", "title": "Attention-based Modeling for Emotion Detection and Classification in\n  Textual Conversations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of modeling textual conversations and\ndetecting emotions. Our proposed model makes use of 1) deep transfer learning\nrather than the classical shallow methods of word embedding; 2) self-attention\nmechanisms to focus on the most important parts of the texts and 3) turn-based\nconversational modeling for classifying the emotions. The approach does not\nrely on any hand-crafted features or lexicons. Our model was evaluated on the\ndata provided by the SemEval-2019 shared task on contextual emotion detection\nin text. The model shows very competitive results.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 14:56:55 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Ragheb", "Waleed", ""], ["Az\u00e9", "J\u00e9r\u00f4me", ""], ["Bringay", "Sandra", ""], ["Servajean", "Maximilien", ""]]}, {"id": "1906.07040", "submitter": "Alexander Panchenko", "authors": "Andrey Kutuzov, Mohammad Dorgham, Oleksiy Oliynyk, Chris Biemann,\n  Alexander Panchenko", "title": "Making Fast Graph-based Algorithms with Graph Metric Embeddings", "comments": "In Proceedings of the 57th Annual Meeting of the Association for\n  Computational Linguistics (ACL'2019). Florence, Italy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computation of distance measures between nodes in graphs is inefficient\nand does not scale to large graphs. We explore dense vector representations as\nan effective way to approximate the same information: we introduce a simple yet\nefficient and effective approach for learning graph embeddings. Instead of\ndirectly operating on the graph structure, our method takes structural measures\nof pairwise node similarities into account and learns dense node\nrepresentations reflecting user-defined graph distance measures, such as\ne.g.the shortest path distance or distance measures that take information\nbeyond the graph structure into account. We demonstrate a speed-up of several\norders of magnitude when predicting word similarity by vector operations on our\nembeddings as opposed to directly computing the respective path-based measures,\nwhile outperforming various other graph embeddings on semantic similarity and\nword sense disambiguation tasks and show evaluations on the WordNet graph and\ntwo knowledge base graphs.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 14:01:33 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Kutuzov", "Andrey", ""], ["Dorgham", "Mohammad", ""], ["Oliynyk", "Oleksiy", ""], ["Biemann", "Chris", ""], ["Panchenko", "Alexander", ""]]}, {"id": "1906.07093", "submitter": "Ke Hu", "authors": "Ke Hu, Hasim Sak, Hank Liao", "title": "Adversarial Training for Multilingual Acoustic Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual training has been shown to improve acoustic modeling performance\nby sharing and transferring knowledge in modeling different languages.\nKnowledge sharing is usually achieved by using common lower-level layers for\ndifferent languages in a deep neural network. Recently, the domain adversarial\nnetwork was proposed to reduce domain mismatch of training data and learn\ndomain-invariant features. It is thus worth exploring whether adversarial\ntraining can further promote knowledge sharing in multilingual models. In this\nwork, we apply the domain adversarial network to encourage the shared layers of\na multilingual model to learn language-invariant features. Bidirectional Long\nShort-Term Memory (LSTM) recurrent neural networks (RNN) are used as building\nblocks. We show that shared layers learned this way contain less language\nidentification information and lead to better performance. In an automatic\nspeech recognition task for seven languages, the resultant acoustic model\nimproves the word error rate (WER) of the multilingual model by 4% relative on\naverage, and the monolingual models by 10%.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 15:42:26 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Hu", "Ke", ""], ["Sak", "Hasim", ""], ["Liao", "Hank", ""]]}, {"id": "1906.07108", "submitter": "Daya Guo", "authors": "Daya Guo, Duyu Tang, Nan Duan, Ming Zhou, Jian Yin", "title": "Coupling Retrieval and Meta-Learning for Context-Dependent Semantic\n  Parsing", "comments": "Accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an approach to incorporate retrieved datapoints as\nsupporting evidence for context-dependent semantic parsing, such as generating\nsource code conditioned on the class environment. Our approach naturally\ncombines a retrieval model and a meta-learner, where the former learns to find\nsimilar datapoints from the training data, and the latter considers retrieved\ndatapoints as a pseudo task for fast adaptation. Specifically, our retriever is\na context-aware encoder-decoder model with a latent variable which takes\ncontext environment into consideration, and our meta-learner learns to utilize\nretrieved datapoints in a model-agnostic meta-learning paradigm for fast\nadaptation. We conduct experiments on CONCODE and CSQA datasets, where the\ncontext refers to class environment in JAVA codes and conversational history,\nrespectively. We use sequence-to-action model as the base semantic parser,\nwhich performs the state-of-the-art accuracy on both datasets. Results show\nthat both the context-aware retriever and the meta-learning strategy improve\naccuracy, and our approach performs better than retrieve-and-edit baselines.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 16:18:28 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Guo", "Daya", ""], ["Tang", "Duyu", ""], ["Duan", "Nan", ""], ["Zhou", "Ming", ""], ["Yin", "Jian", ""]]}, {"id": "1906.07132", "submitter": "Yichen Jiang", "authors": "Yichen Jiang, Mohit Bansal", "title": "Avoiding Reasoning Shortcuts: Adversarial Evaluation, Training, and\n  Model Development for Multi-Hop QA", "comments": "ACL 2019 (11 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-hop question answering requires a model to connect multiple pieces of\nevidence scattered in a long context to answer the question. In this paper, we\nshow that in the multi-hop HotpotQA (Yang et al., 2018) dataset, the examples\noften contain reasoning shortcuts through which models can directly locate the\nanswer by word-matching the question with a sentence in the context. We\ndemonstrate this issue by constructing adversarial documents that create\ncontradicting answers to the shortcut but do not affect the validity of the\noriginal answer. The performance of strong baseline models drops significantly\non our adversarial evaluation, indicating that they are indeed exploiting the\nshortcuts rather than performing multi-hop reasoning. After adversarial\ntraining, the baseline's performance improves but is still limited on the\nadversarial evaluation. Hence, we use a control unit that dynamically attends\nto the question at different reasoning hops to guide the model's multi-hop\nreasoning. We show that this 2-hop model trained on the regular data is more\nrobust to the adversaries than the baseline model. After adversarial training,\nthis 2-hop model not only achieves improvements over its counterpart trained on\nregular data, but also outperforms the adversarially-trained 1-hop baseline. We\nhope that these insights and initial improvements will motivate the development\nof new models that combine explicit compositional reasoning with adversarial\ntraining.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 17:03:57 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Jiang", "Yichen", ""], ["Bansal", "Mohit", ""]]}, {"id": "1906.07194", "submitter": "Cristian Danescu-Niculescu-Mizil", "authors": "Justine Zhang, Robert Filbin, Christine Morrison, Jaclyn Weiser,\n  Cristian Danescu-Niculescu-Mizil", "title": "Finding Your Voice: The Linguistic Development of Mental Health\n  Counselors", "comments": "To appear at ACL 2019, 12 pages, 2 figures; code available through\n  the Cornell Conversational Analysis Toolkit (https://convokit.cornell.edu)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mental health counseling is an enterprise with profound societal importance\nwhere conversations play a primary role. In order to acquire the conversational\nskills needed to face a challenging range of situations, mental health\ncounselors must rely on training and on continued experience with actual\nclients. However, in the absence of large scale longitudinal studies, the\nnature and significance of this developmental process remain unclear. For\nexample, prior literature suggests that experience might not translate into\nconsequential changes in counselor behavior. This has led some to even argue\nthat counseling is a profession without expertise.\n  In this work, we develop a computational framework to quantify the extent to\nwhich individuals change their linguistic behavior with experience and to study\nthe nature of this evolution. We use our framework to conduct a large\nlongitudinal study of mental health counseling conversations, tracking over\n3,400 counselors across their tenure. We reveal that overall, counselors do\nindeed change their conversational behavior to become more diverse across\ninteractions, developing an individual voice that distinguishes them from other\ncounselors. Furthermore, a finer-grained investigation shows that the rate and\nnature of this diversification vary across functionally different\nconversational components.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 18:00:04 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Zhang", "Justine", ""], ["Filbin", "Robert", ""], ["Morrison", "Christine", ""], ["Weiser", "Jaclyn", ""], ["Danescu-Niculescu-Mizil", "Cristian", ""]]}, {"id": "1906.07220", "submitter": "Anusha Balakrishnan", "authors": "Anusha Balakrishnan, Jinfeng Rao, Kartikeya Upasani, Michael White,\n  Rajen Subba", "title": "Constrained Decoding for Neural NLG from Compositional Representations\n  in Task-Oriented Dialogue", "comments": "To appear in the Proceedings of the 57th Annual Meeting of the\n  Association for Computational Linguistics (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating fluent natural language responses from structured semantic\nrepresentations is a critical step in task-oriented conversational systems.\nAvenues like the E2E NLG Challenge have encouraged the development of neural\napproaches, particularly sequence-to-sequence (Seq2Seq) models for this\nproblem. The semantic representations used, however, are often underspecified,\nwhich places a higher burden on the generation model for sentence planning, and\nalso limits the extent to which generated responses can be controlled in a live\nsystem. In this paper, we (1) propose using tree-structured semantic\nrepresentations, like those used in traditional rule-based NLG systems, for\nbetter discourse-level structuring and sentence-level planning; (2) introduce a\nchallenging dataset using this representation for the weather domain; (3)\nintroduce a constrained decoding approach for Seq2Seq models that leverages\nthis representation to improve semantic correctness; and (4) demonstrate\npromising results on our dataset and the E2E dataset.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 18:54:51 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Balakrishnan", "Anusha", ""], ["Rao", "Jinfeng", ""], ["Upasani", "Kartikeya", ""], ["White", "Michael", ""], ["Subba", "Rajen", ""]]}, {"id": "1906.07234", "submitter": "Siyuan Feng", "authors": "Siyuan Feng, Tan Lee, Zhiyuan Peng", "title": "Combining Adversarial Training and Disentangled Speech Representation\n  for Robust Zero-Resource Subword Modeling", "comments": "5 pages, 3 figures, accepted for publication in INTERSPEECH 2019,\n  Graz, Austria", "journal-ref": null, "doi": "10.21437/Interspeech.2019-1337", "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study addresses the problem of unsupervised subword unit discovery from\nuntranscribed speech. It forms the basis of the ultimate goal of ZeroSpeech\n2019, building text-to-speech systems without text labels. In this work, unit\ndiscovery is formulated as a pipeline of phonetically discriminative feature\nlearning and unit inference. One major difficulty in robust unsupervised\nfeature learning is dealing with speaker variation. Here the robustness towards\nspeaker variation is achieved by applying adversarial training and FHVAE based\ndisentangled speech representation learning. A comparison of the two approaches\nas well as their combination is studied in a DNN-bottleneck feature (DNN-BNF)\narchitecture. Experiments are conducted on ZeroSpeech 2019 and 2017.\nExperimental results on ZeroSpeech 2017 show that both approaches are effective\nwhile the latter is more prominent, and that their combination brings further\nmarginal improvement in across-speaker condition. Results on ZeroSpeech 2019\nshow that in the ABX discriminability task, our approaches significantly\noutperform the official baseline, and are competitive to or even outperform the\nofficial topline. The proposed unit sequence smoothing algorithm improves\nsynthesis quality, at a cost of slight decrease in ABX discriminability.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 19:40:46 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 12:22:28 GMT"}, {"version": "v3", "created": "Fri, 9 Aug 2019 15:55:00 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Feng", "Siyuan", ""], ["Lee", "Tan", ""], ["Peng", "Zhiyuan", ""]]}, {"id": "1906.07241", "submitter": "Robert Logan", "authors": "Robert L. Logan IV, Nelson F. Liu, Matthew E. Peters, Matt Gardner and\n  Sameer Singh", "title": "Barack's Wife Hillary: Using Knowledge-Graphs for Fact-Aware Language\n  Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling human language requires the ability to not only generate fluent text\nbut also encode factual knowledge. However, traditional language models are\nonly capable of remembering facts seen at training time, and often have\ndifficulty recalling them. To address this, we introduce the knowledge graph\nlanguage model (KGLM), a neural language model with mechanisms for selecting\nand copying facts from a knowledge graph that are relevant to the context.\nThese mechanisms enable the model to render information it has never seen\nbefore, as well as generate out-of-vocabulary tokens. We also introduce the\nLinked WikiText-2 dataset, a corpus of annotated text aligned to the Wikidata\nknowledge graph whose contents (roughly) match the popular WikiText-2\nbenchmark. In experiments, we demonstrate that the KGLM achieves significantly\nbetter performance than a strong baseline language model. We additionally\ncompare different language model's ability to complete sentences requiring\nfactual knowledge, showing that the KGLM outperforms even very large language\nmodels in generating facts.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 19:48:41 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 18:37:00 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Logan", "Robert L.", "IV"], ["Liu", "Nelson F.", ""], ["Peters", "Matthew E.", ""], ["Gardner", "Matt", ""], ["Singh", "Sameer", ""]]}, {"id": "1906.07280", "submitter": "Enrico Santus", "authors": "Emmanuele Chersoni, Enrico Santus, Ludovica Pannitto, Alessandro\n  Lenci, Philippe Blache, Chu-Ren Huang", "title": "A Structured Distributional Model of Sentence Meaning and Processing", "comments": "accepted at JLNE; Journal of Natural Language Engineering; 26 pages,\n  thematic fit, selectional preference, natural language processing, nlp, ai", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most compositional distributional semantic models represent sentence meaning\nwith a single vector. In this paper, we propose a Structured Distributional\nModel (SDM) that combines word embeddings with formal semantics and is based on\nthe assumption that sentences represent events and situations. The semantic\nrepresentation of a sentence is a formal structure derived from Discourse\nRepresentation Theory and containing distributional vectors. This structure is\ndynamically and incrementally built by integrating knowledge about events and\ntheir typical participants, as they are activated by lexical items. Event\nknowledge is modeled as a graph extracted from parsed corpora and encoding\nroles and relationships between participants that are represented as\ndistributional vectors. SDM is grounded on extensive psycholinguistic research\nshowing that generalized knowledge about events stored in semantic memory plays\na key role in sentence comprehension. We evaluate SDM on two recently\nintroduced compositionality datasets, and our results show that combining a\nsimple compositional model with event knowledge constantly improves\nperformances, even with different types of word embeddings.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 21:31:40 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Chersoni", "Emmanuele", ""], ["Santus", "Enrico", ""], ["Pannitto", "Ludovica", ""], ["Lenci", "Alessandro", ""], ["Blache", "Philippe", ""], ["Huang", "Chu-Ren", ""]]}, {"id": "1906.07285", "submitter": "Michael Hahn", "authors": "Michael Hahn and Marco Baroni", "title": "Tabula nearly rasa: Probing the Linguistic Knowledge of Character-Level\n  Neural Language Models Trained on Unsegmented Text", "comments": "Accepted by Transactions of the Association for Computational\n  Linguistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) have reached striking performance in many\nnatural language processing tasks. This has renewed interest in whether these\ngeneric sequence processing devices are inducing genuine linguistic knowledge.\nNearly all current analytical studies, however, initialize the RNNs with a\nvocabulary of known words, and feed them tokenized input during training. We\npresent a multi-lingual study of the linguistic knowledge encoded in RNNs\ntrained as character-level language models, on input data with word boundaries\nremoved. These networks face a tougher and more cognitively realistic task,\nhaving to discover any useful linguistic unit from scratch based on input\nstatistics. The results show that our \"near tabula rasa\" RNNs are mostly able\nto solve morphological, syntactic and semantic tasks that intuitively\npresuppose word-level knowledge, and indeed they learned, to some extent, to\ntrack word boundaries. Our study opens the door to speculations about the\nnecessity of an explicit, rigid word lexicon in language learning and usage.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 21:53:10 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Hahn", "Michael", ""], ["Baroni", "Marco", ""]]}, {"id": "1906.07286", "submitter": "Miguel Gra\\c{c}a", "authors": "Miguel Gra\\c{c}a, Yunsu Kim, Julian Schamper, Shahram Khadivi and\n  Hermann Ney", "title": "Generalizing Back-Translation in Neural Machine Translation", "comments": "4th Conference on Machine Translation (WMT 2019) camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Back-translation - data augmentation by translating target monolingual data -\nis a crucial component in modern neural machine translation (NMT). In this\nwork, we reformulate back-translation in the scope of cross-entropy\noptimization of an NMT model, clarifying its underlying mathematical\nassumptions and approximations beyond its heuristic usage. Our formulation\ncovers broader synthetic data generation schemes, including sampling from a\ntarget-to-source NMT model. With this formulation, we point out fundamental\nproblems of the sampling-based approaches and propose to remedy them by (i)\ndisabling label smoothing for the target-to-source model and (ii) sampling from\na restricted search space. Our statements are investigated on the WMT 2018\nGerman - English news translation task.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 22:13:24 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Gra\u00e7a", "Miguel", ""], ["Kim", "Yunsu", ""], ["Schamper", "Julian", ""], ["Khadivi", "Shahram", ""], ["Ney", "Hermann", ""]]}, {"id": "1906.07307", "submitter": "Wei Fang", "authors": "Wei Fang, Yu-An Chung, James Glass", "title": "Towards Transfer Learning for End-to-End Speech Synthesis from Deep\n  Pre-Trained Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern text-to-speech (TTS) systems are able to generate audio that sounds\nalmost as natural as human speech. However, the bar of developing high-quality\nTTS systems remains high since a sizable set of studio-quality <text, audio>\npairs is usually required. Compared to commercial data used to develop\nstate-of-the-art systems, publicly available data are usually worse in terms of\nboth quality and size. Audio generated by TTS systems trained on publicly\navailable data tends to not only sound less natural, but also exhibits more\nbackground noise. In this work, we aim to lower TTS systems' reliance on\nhigh-quality data by providing them the textual knowledge extracted by deep\npre-trained language models during training. In particular, we investigate the\nuse of BERT to assist the training of Tacotron-2, a state of the art TTS\nconsisting of an encoder and an attention-based decoder. BERT representations\nlearned from large amounts of unlabeled text data are shown to contain very\nrich semantic and syntactic information about the input text, and have\npotential to be leveraged by a TTS system to compensate the lack of\nhigh-quality data. We incorporate BERT as a parallel branch to the Tacotron-2\nencoder with its own attention head. For an input text, it is simultaneously\npassed into BERT and the Tacotron-2 encoder. The representations extracted by\nthe two branches are concatenated and then fed to the decoder. As a preliminary\nstudy, although we have not found incorporating BERT into Tacotron-2 generates\nmore natural or cleaner speech at a human-perceivable level, we observe\nimprovements in other aspects such as the model is being significantly better\nat knowing when to stop decoding such that there is much less babbling at the\nend of the synthesized audio and faster convergence during training.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 23:48:05 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Fang", "Wei", ""], ["Chung", "Yu-An", ""], ["Glass", "James", ""]]}, {"id": "1906.07317", "submitter": "Xu Xiang", "authors": "Xu Xiang, Shuai Wang, Houjun Huang, Yanmin Qian, Kai Yu", "title": "Margin Matters: Towards More Discriminative Deep Neural Network\n  Embeddings for Speaker Recognition", "comments": "not accepted by INTERSPEECH 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, speaker embeddings extracted from a speaker discriminative deep\nneural network (DNN) yield better performance than the conventional methods\nsuch as i-vector. In most cases, the DNN speaker classifier is trained using\ncross entropy loss with softmax. However, this kind of loss function does not\nexplicitly encourage inter-class separability and intra-class compactness. As a\nresult, the embeddings are not optimal for speaker recognition tasks. In this\npaper, to address this issue, three different margin based losses which not\nonly separate classes but also demand a fixed margin between classes are\nintroduced to deep speaker embedding learning. It could be demonstrated that\nthe margin is the key to obtain more discriminative speaker embeddings.\nExperiments are conducted on two public text independent tasks: VoxCeleb1 and\nSpeaker in The Wild (SITW). The proposed approach can achieve the\nstate-of-the-art performance, with 25% ~ 30% equal error rate (EER) reduction\non both tasks when compared to strong baselines using cross entropy loss with\nsoftmax, obtaining 2.238% EER on VoxCeleb1 test set and 2.761% EER on SITW\ncore-core test set, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 00:31:04 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Xiang", "Xu", ""], ["Wang", "Shuai", ""], ["Huang", "Houjun", ""], ["Qian", "Yanmin", ""], ["Yu", "Kai", ""]]}, {"id": "1906.07337", "submitter": "Nidhi Kaushik Vyas", "authors": "Keita Kurita, Nidhi Vyas, Ayush Pareek, Alan W Black, Yulia Tsvetkov", "title": "Measuring Bias in Contextualized Word Representations", "comments": "1st ACL Workshop on Gender Bias for Natural Language Processing 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual word embeddings such as BERT have achieved state of the art\nperformance in numerous NLP tasks. Since they are optimized to capture the\nstatistical properties of training data, they tend to pick up on and amplify\nsocial stereotypes present in the data as well. In this study, we (1)~propose a\ntemplate-based method to quantify bias in BERT; (2)~show that this method\nobtains more consistent results in capturing social biases than the traditional\ncosine based method; and (3)~conduct a case study, evaluating gender bias in a\ndownstream task of Gender Pronoun Resolution. Although our case study focuses\non gender bias, the proposed technique is generalizable to unveiling other\nbiases, including in multiclass settings, such as racial and religious biases.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 01:58:56 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Kurita", "Keita", ""], ["Vyas", "Nidhi", ""], ["Pareek", "Ayush", ""], ["Black", "Alan W", ""], ["Tsvetkov", "Yulia", ""]]}, {"id": "1906.07343", "submitter": "YiDing Jiang", "authors": "Yiding Jiang, Shixiang Gu, Kevin Murphy, Chelsea Finn", "title": "Language as an Abstraction for Hierarchical Deep Reinforcement Learning", "comments": "Published in Neural Information Processing Systems (NeurIPS) 2019;\n  Supplementary materials: https://sites.google.com/view/hal-demo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving complex, temporally-extended tasks is a long-standing problem in\nreinforcement learning (RL). We hypothesize that one critical element of\nsolving such problems is the notion of compositionality. With the ability to\nlearn concepts and sub-skills that can be composed to solve longer tasks, i.e.\nhierarchical RL, we can acquire temporally-extended behaviors. However,\nacquiring effective yet general abstractions for hierarchical RL is remarkably\nchallenging. In this paper, we propose to use language as the abstraction, as\nit provides unique compositional structure, enabling fast learning and\ncombinatorial generalization, while retaining tremendous flexibility, making it\nsuitable for a variety of problems. Our approach learns an\ninstruction-following low-level policy and a high-level policy that can reuse\nabstractions across tasks, in essence, permitting agents to reason using\nstructured language. To study compositional task learning, we introduce an\nopen-source object interaction environment built using the MuJoCo physics\nengine and the CLEVR engine. We find that, using our approach, agents can learn\nto solve to diverse, temporally-extended tasks such as object sorting and\nmulti-object rearrangement, including from raw pixel observations. Our analysis\nreveals that the compositional nature of language is critical for learning\ndiverse sub-skills and systematically generalizing to new sub-skills in\ncomparison to non-compositional abstractions that use the same supervision.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 02:27:45 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 21:51:49 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Jiang", "Yiding", ""], ["Gu", "Shixiang", ""], ["Murphy", "Kevin", ""], ["Finn", "Chelsea", ""]]}, {"id": "1906.07348", "submitter": "Lajanugen Logeswaran", "authors": "Lajanugen Logeswaran, Ming-Wei Chang, Kenton Lee, Kristina Toutanova,\n  Jacob Devlin, Honglak Lee", "title": "Zero-Shot Entity Linking by Reading Entity Descriptions", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the zero-shot entity linking task, where mentions must be linked\nto unseen entities without in-domain labeled data. The goal is to enable robust\ntransfer to highly specialized domains, and so no metadata or alias tables are\nassumed. In this setting, entities are only identified by text descriptions,\nand models must rely strictly on language understanding to resolve the new\nentities. First, we show that strong reading comprehension models pre-trained\non large unlabeled data can be used to generalize to unseen entities. Second,\nwe propose a simple and effective adaptive pre-training strategy, which we term\ndomain-adaptive pre-training (DAP), to address the domain shift problem\nassociated with linking unseen entities in a new domain. We present experiments\non a new dataset that we construct for this task and show that DAP improves\nover strong pre-training baselines, including BERT. The data and code are\navailable at https://github.com/lajanugen/zeshel.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 02:36:39 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Logeswaran", "Lajanugen", ""], ["Chang", "Ming-Wei", ""], ["Lee", "Kenton", ""], ["Toutanova", "Kristina", ""], ["Devlin", "Jacob", ""], ["Lee", "Honglak", ""]]}, {"id": "1906.07382", "submitter": "Anirudh Dahiya", "authors": "Anirudh Dahiya, Neeraj Battan, Manish Shrivastava, Dipti Mishra Sharma", "title": "Curriculum Learning Strategies for Hindi-English Codemixed Sentiment\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment Analysis and other semantic tasks are commonly used for social\nmedia textual analysis to gauge public opinion and make sense from the noise on\nsocial media. The language used on social media not only commonly diverges from\nthe formal language, but is compounded by codemixing between languages,\nespecially in large multilingual societies like India.\n  Traditional methods for learning semantic NLP tasks have long relied on end\nto end task specific training, requiring expensive data creation process, even\nmore so for deep learning methods. This challenge is even more severe for\nresource scarce texts like codemixed language pairs, with lack of well learnt\nrepresentations as model priors, and task specific datasets can be few and\nsmall in quantities to efficiently exploit recent deep learning approaches. To\naddress above challenges, we introduce curriculum learning strategies for\nsemantic tasks in code-mixed Hindi-English (Hi-En) texts, and investigate\nvarious training strategies for enhancing model performance. Our method\noutperforms the state of the art methods for Hi-En codemixed sentiment analysis\nby 3.31% accuracy, and also shows better model robustness in terms of\nconvergence, and variance in test performance.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 05:14:17 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Dahiya", "Anirudh", ""], ["Battan", "Neeraj", ""], ["Shrivastava", "Manish", ""], ["Sharma", "Dipti Mishra", ""]]}, {"id": "1906.07389", "submitter": "Isabelle Augenstein", "authors": "Johannes Bjerva, Yova Kementchedjhieva, Ryan Cotterell, Isabelle\n  Augenstein", "title": "Uncovering Probabilistic Implications in Typological Knowledge Bases", "comments": "To appear in Proceedings of ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of linguistic typology is rooted in the implications we find\nbetween linguistic features, such as the fact that languages with object-verb\nword ordering tend to have post-positions. Uncovering such implications\ntypically amounts to time-consuming manual processing by trained and\nexperienced linguists, which potentially leaves key linguistic universals\nunexplored. In this paper, we present a computational model which successfully\nidentifies known universals, including Greenberg universals, but also uncovers\nnew ones, worthy of further linguistic investigation. Our approach outperforms\nbaselines previously used for this problem, as well as a strong baseline from\nknowledge base population.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 05:51:13 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Bjerva", "Johannes", ""], ["Kementchedjhieva", "Yova", ""], ["Cotterell", "Ryan", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "1906.07414", "submitter": "Hieu-Thi Luong", "authors": "Hieu-Thi Luong and Junichi Yamagishi", "title": "A Unified Speaker Adaptation Method for Speech Synthesis using\n  Transcribed and Untranscribed Speech with Backpropagation", "comments": "14 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By representing speaker characteristic as a single fixed-length vector\nextracted solely from speech, we can train a neural multi-speaker speech\nsynthesis model by conditioning the model on those vectors. This model can also\nbe adapted to unseen speakers regardless of whether the transcript of\nadaptation data is available or not. However, this setup restricts the speaker\ncomponent to just a single bias vector, which in turn limits the performance of\nadaptation process. In this study, we propose a novel speech synthesis model,\nwhich can be adapted to unseen speakers by fine-tuning part of or all of the\nnetwork using either transcribed or untranscribed speech. Our methodology\nessentially consists of two steps: first, we split the conventional acoustic\nmodel into a speaker-independent (SI) linguistic encoder and a speaker-adaptive\n(SA) acoustic decoder; second, we train an auxiliary acoustic encoder that can\nbe used as a substitute for the linguistic encoder whenever linguistic features\nare unobtainable. The results of objective and subjective evaluations show that\nadaptation using either transcribed or untranscribed speech with our\nmethodology achieved a reasonable level of performance with an extremely\nlimited amount of data and greatly improved performance with more data.\nSurprisingly, adaptation with untranscribed speech surpassed the transcribed\ncounterpart in the subjective test, which reveals the limitations of the\nconventional acoustic model and hints at potential directions for improvements.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 07:24:45 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 02:36:55 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Luong", "Hieu-Thi", ""], ["Yamagishi", "Junichi", ""]]}, {"id": "1906.07429", "submitter": "Lei Shen", "authors": "Lei Shen, Yang Feng, Haolan Zhan", "title": "Modeling Semantic Relationship in Multi-turn Conversations with\n  Hierarchical Latent Variables", "comments": "6 pages, accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-turn conversations consist of complex semantic structures, and it is\nstill a challenge to generate coherent and diverse responses given previous\nutterances. It's practical that a conversation takes place under a background,\nmeanwhile, the query and response are usually most related and they are\nconsistent in topic but also different in content. However, little work focuses\non such hierarchical relationship among utterances. To address this problem, we\npropose a Conversational Semantic Relationship RNN (CSRR) model to construct\nthe dependency explicitly. The model contains latent variables in three\nhierarchies. The discourse-level one captures the global background, the\npair-level one stands for the common topic information between query and\nresponse, and the utterance-level ones try to represent differences in content.\nExperimental results show that our model significantly improves the quality of\nresponses in terms of fluency, coherence and diversity compared to baseline\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 07:57:22 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Shen", "Lei", ""], ["Feng", "Yang", ""], ["Zhan", "Haolan", ""]]}, {"id": "1906.07510", "submitter": "Zhijiang Guo", "authors": "Zhijiang Guo and Yan Zhang and Wei Lu", "title": "Attention Guided Graph Convolutional Networks for Relation Extraction", "comments": "Accepted to ACL 2019, 11 pages, 4 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dependency trees convey rich structural information that is proven useful for\nextracting relations among entities in text. However, how to effectively make\nuse of relevant information while ignoring irrelevant information from the\ndependency trees remains a challenging research question. Existing approaches\nemploying rule based hard-pruning strategies for selecting relevant partial\ndependency structures may not always yield optimal results. In this work, we\npropose Attention Guided Graph Convolutional Networks (AGGCNs), a novel model\nwhich directly takes full dependency trees as inputs. Our model can be\nunderstood as a soft-pruning approach that automatically learns how to\nselectively attend to the relevant sub-structures useful for the relation\nextraction task. Extensive results on various tasks including cross-sentence\nn-ary relation extraction and large-scale sentence-level relation extraction\nshow that our model is able to better leverage the structural information of\nthe full dependency trees, giving significantly better results than previous\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 11:55:16 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 13:52:25 GMT"}, {"version": "v3", "created": "Fri, 9 Aug 2019 05:26:24 GMT"}, {"version": "v4", "created": "Thu, 10 Oct 2019 10:25:45 GMT"}, {"version": "v5", "created": "Fri, 11 Oct 2019 02:51:17 GMT"}, {"version": "v6", "created": "Sat, 14 Mar 2020 13:21:39 GMT"}, {"version": "v7", "created": "Tue, 25 Aug 2020 14:53:16 GMT"}, {"version": "v8", "created": "Sun, 6 Sep 2020 15:17:00 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Guo", "Zhijiang", ""], ["Zhang", "Yan", ""], ["Lu", "Wei", ""]]}, {"id": "1906.07523", "submitter": "Emre Yilmaz", "authors": "Emre Y{\\i}lmaz, Samuel Cohen, Xianghu Yue, David van Leeuwen, Haizhou\n  Li", "title": "Multi-Graph Decoding for Code-Switching ASR", "comments": "Accepted for publication at Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the FAME! Project, a code-switching (CS) automatic speech recognition\n(ASR) system for Frisian-Dutch speech is developed that can accurately\ntranscribe the local broadcaster's bilingual archives with CS speech. This\narchive contains recordings with monolingual Frisian and Dutch speech segments\nas well as Frisian-Dutch CS speech, hence the recognition performance on\nmonolingual segments is also vital for accurate transcriptions. In this work,\nwe propose a multi-graph decoding and rescoring strategy using bilingual and\nmonolingual graphs together with a unified acoustic model for CS ASR. The\nproposed decoding scheme gives the freedom to design and employ alternative\nsearch spaces for each (monolingual or bilingual) recognition task and enables\nthe effective use of monolingual resources of the high-resourced mixed language\nin low-resourced CS scenarios. In our scenario, Dutch is the high-resourced and\nFrisian is the low-resourced language. We therefore use additional monolingual\nDutch text resources to improve the Dutch language model (LM) and compare the\nperformance of single- and multi-graph CS ASR systems on Dutch segments using\nlarger Dutch LMs. The ASR results show that the proposed approach outperforms\nbaseline single-graph CS ASR systems, providing better performance on the\nmonolingual Dutch segments without any accuracy loss on monolingual Frisian and\ncode-mixed segments.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 12:24:32 GMT"}, {"version": "v2", "created": "Fri, 28 Jun 2019 07:07:08 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Y\u0131lmaz", "Emre", ""], ["Cohen", "Samuel", ""], ["Yue", "Xianghu", ""], ["van Leeuwen", "David", ""], ["Li", "Haizhou", ""]]}, {"id": "1906.07525", "submitter": "Xiaoye Tan", "authors": "Xiaoye Tan and Rui Yan and Chongyang Tao and Mingrui Wu", "title": "Mimicking Human Process: Text Representation via Latent Semantic\n  Clustering for Classification", "comments": "6 pages, 5 figures, 2nd Workshop on Humanizing AI (HAI) at IJCAI'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Considering that words with different characteristic in the text have\ndifferent importance for classification, grouping them together separately can\nstrengthen the semantic expression of each part. Thus we propose a new text\nrepresentation scheme by clustering words according to their latent semantics\nand composing them together to get a set of cluster vectors, which are then\nconcatenated as the final text representation. Evaluation on five\nclassification benchmarks proves the effectiveness of our method. We further\nconduct visualization analysis showing statistical clustering results and\nverifying the validity of our motivation.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 12:27:25 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Tan", "Xiaoye", ""], ["Yan", "Rui", ""], ["Tao", "Chongyang", ""], ["Wu", "Mingrui", ""]]}, {"id": "1906.07544", "submitter": "Manolis Kyriakakis", "authors": "Manolis Kyriakakis, Ion Androutsopoulos, Joan Gin\\'es i Ametll\\'e,\n  Artur Saudabayev", "title": "Transfer Learning for Causal Sentence Detection", "comments": "5 pages, short paper at BioNLP 2019 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of detecting sentences that express causality, as a step\ntowards mining causal relations from texts. To bypass the scarcity of causal\ninstances in relation extraction datasets, we exploit transfer learning, namely\nELMO and BERT, using a bidirectional GRU with self-attention (BIGRUATT) as a\nbaseline. We experiment with both generic public relation extraction datasets\nand a new biomedical causal sentence detection dataset, a subset of which we\nmake publicly available. We find that transfer learning helps only in very\nsmall datasets. With larger datasets, BIGRUATT reaches a performance plateau,\nthen larger datasets and transfer learning do not help.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 13:17:13 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 08:59:14 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Kyriakakis", "Manolis", ""], ["Androutsopoulos", "Ion", ""], ["Ametll\u00e9", "Joan Gin\u00e9s i", ""], ["Saudabayev", "Artur", ""]]}, {"id": "1906.07555", "submitter": "Menglin Xia", "authors": "Menglin Xia, Ekaterina Kochmar, Ted Briscoe", "title": "Automatic learner summary assessment for reading comprehension", "comments": "NAACL2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Automating the assessment of learner summaries provides a useful tool for\nassessing learner reading comprehension. We present a summarization task for\nevaluating non-native reading comprehension and propose three novel approaches\nto automatically assess the learner summaries. We evaluate our models on two\ndatasets we created and show that our models outperform traditional approaches\nthat rely on exact word match on this task. Our best model produces quality\nassessments close to professional examiners.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 13:29:04 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Xia", "Menglin", ""], ["Kochmar", "Ekaterina", ""], ["Briscoe", "Ted", ""]]}, {"id": "1906.07562", "submitter": "Ales Horak", "authors": "Marie Du\\v{z}\\'i and Ale\\v{s} Hor\\'ak", "title": "Hyperintensional Reasoning based on Natural Language Knowledge Base", "comments": "Preprint of an article accepted for publication in the International\n  Journal of Uncertainty, Fuzziness and Knowledge-Based Systems \\c{opyright}\n  2019 copyright World Scientific Publishing Company\n  https://www.worldscientific.com/worldscinet/ijufks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of automated reasoning techniques over large natural-language\ntexts heavily relies on a fine-grained analysis of natural language\nassumptions. While there is a common agreement that the analysis should be\nhyperintensional, most of the automatic reasoning systems are still based on an\nintensional logic, at the best. In this paper, we introduce the system of\nreasoning based on a fine-grained, hyperintensional analysis. To this end we\napply Tichy's Transparent Intensional Logic (TIL) with its procedural\nsemantics. TIL is a higher-order, hyperintensional logic of partial functions,\nin particular apt for a fine-grained natural-language analysis. Within TIL we\nrecognise three kinds of context, namely extensional, intensional and\nhyperintensional, in which a particular natural-language term, or rather its\nmeaning, can occur. Having defined the three kinds of context and implemented\nan algorithm of context recognition, we are in a position to develop and\nimplement an extensional logic of hyperintensions with the inference machine\nthat should neither over-infer nor under-infer.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 13:32:20 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Du\u017e\u00ed", "Marie", ""], ["Hor\u00e1k", "Ale\u0161", ""]]}, {"id": "1906.07580", "submitter": "Menglin Xia", "authors": "Menglin Xia, Ekaterina Kochmar, Ted Briscoe", "title": "Text Readability Assessment for Second Language Learners", "comments": "Proceedings of the 11th Workshop on Innovative Use of NLP for\n  Building Educational Applications", "journal-ref": null, "doi": "10.18653/v1/W16-0502", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper addresses the task of readability assessment for the texts aimed\nat second language (L2) learners. One of the major challenges in this task is\nthe lack of significantly sized level-annotated data. For the present work, we\ncollected a dataset of CEFR-graded texts tailored for learners of English as an\nL2 and investigated text readability assessment for both native and L2\nlearners. We applied a generalization method to adapt models trained on larger\nnative corpora to estimate text readability for learners, and explored domain\nadaptation and self-learning techniques to make use of the native data to\nimprove system performance on the limited L2 data. In our experiments, the best\nperforming model for readability on learner texts achieves an accuracy of 0.797\nand PCC of $0.938$.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 13:46:21 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Xia", "Menglin", ""], ["Kochmar", "Ekaterina", ""], ["Briscoe", "Ted", ""]]}, {"id": "1906.07591", "submitter": "Julien Rossi", "authors": "Julien Rossi, Matthias Wirth, Evangelos Kanoulas", "title": "Query Generation for Patent Retrieval with Keyword Extraction based on\n  Syntactic Features", "comments": "Presented as short paper at JURIX 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes a new method to extract relevant keywords from patent\nclaims, as part of the task of retrieving other patents with similar claims\n(search for prior art). The method combines a qualitative analysis of the\nwriting style of the claims with NLP methods to parse text, in order to\nrepresent a legal text as a specialization arborescence of terms. In this\nsetting, the set of extracted keywords are yielding better search results than\nkeywords extracted with traditional methods such as tf-idf. The performance is\nmeasured on the search results of a query consisting of the extracted keywords.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 14:03:14 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Rossi", "Julien", ""], ["Wirth", "Matthias", ""], ["Kanoulas", "Evangelos", ""]]}, {"id": "1906.07592", "submitter": "Stefan Schweter", "authors": "Stefan Schweter and Johannes Baiter", "title": "Towards Robust Named Entity Recognition for Historic German", "comments": "8 pages, 5 figures, accepted at the 4th Workshop on Representation\n  Learning for NLP (RepL4NLP), held in conjunction with ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in language modeling using deep neural networks have shown\nthat these models learn representations, that vary with the network depth from\nmorphology to semantic relationships like co-reference. We apply pre-trained\nlanguage models to low-resource named entity recognition for Historic German.\nWe show on a series of experiments that character-based pre-trained language\nmodels do not run into trouble when faced with low-resource datasets. Our\npre-trained character-based language models improve upon classical CRF-based\nmethods and previous work on Bi-LSTMs by boosting F1 score performance by up to\n6%. Our pre-trained language and NER models are publicly available under\nhttps://github.com/stefan-it/historic-ner .\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 14:06:40 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Schweter", "Stefan", ""], ["Baiter", "Johannes", ""]]}, {"id": "1906.07599", "submitter": "Jeremy Barnes", "authors": "Jeremy Barnes", "title": "LTG-Oslo Hierarchical Multi-task Network: The importance of negation for\n  document-level sentiment in Spanish", "comments": "Accepted in NEGES (Negation in Spanish) workshop at SEPLN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper details LTG-Oslo team's participation in the sentiment track of\nthe NEGES 2019 evaluation campaign. We participated in the task with a\nhierarchical multi-task network, which used shared lower-layers in a deep\nBiLSTM to predict negation, while the higher layers were dedicated to\npredicting document-level sentiment. The multi-task component shows promise as\na way to incorporate information on negation into deep neural sentiment\nclassifiers, despite the fact that the absolute results on the test set were\nrelatively low for a binary classification task.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 14:18:31 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Barnes", "Jeremy", ""]]}, {"id": "1906.07601", "submitter": "Yannick Est\\`eve", "authors": "Antoine Caubri\\`ere, Natalia Tomashenko, Antoine Laurent, Emmanuel\n  Morin, Nathalie Camelin, Yannick Est\\`eve", "title": "Curriculum-based transfer learning for an effective end-to-end spoken\n  language understanding and domain portability", "comments": "Accepted to the INTERSPEECH 2019 conference. Submitted on March 29,\n  2019 (Paper submission deadline)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an end-to-end approach to extract semantic concepts directly from\nthe speech audio signal. To overcome the lack of data available for this spoken\nlanguage understanding approach, we investigate the use of a transfer learning\nstrategy based on the principles of curriculum learning. This approach allows\nus to exploit out-of-domain data that can help to prepare a fully neural\narchitecture. Experiments are carried out on the French MEDIA and PORTMEDIA\ncorpora and show that this end-to-end SLU approach reaches the best results\never published on this task. We compare our approach to a classical pipeline\napproach that uses ASR, POS tagging, lemmatizer, chunker... and other NLP tools\nthat aim to enrich ASR outputs that feed an SLU text to concepts system. Last,\nwe explore the promising capacity of our end-to-end SLU approach to address the\nproblem of domain portability.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 14:19:52 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Caubri\u00e8re", "Antoine", ""], ["Tomashenko", "Natalia", ""], ["Laurent", "Antoine", ""], ["Morin", "Emmanuel", ""], ["Camelin", "Nathalie", ""], ["Est\u00e8ve", "Yannick", ""]]}, {"id": "1906.07610", "submitter": "Jeremy Barnes", "authors": "Jeremy Barnes, Erik Velldal, Lilja {\\O}vrelid", "title": "Improving Sentiment Analysis with Multi-task Learning of Negation", "comments": "Under submission for Journal of Natural Language Engineering special\n  issue on Negation. 30 pages with references", "journal-ref": "Nat. Lang. Eng. 27 (2021) 249-269", "doi": "10.1017/S1351324920000510", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Sentiment analysis is directly affected by compositional phenomena in\nlanguage that act on the prior polarity of the words and phrases found in the\ntext. Negation is the most prevalent of these phenomena and in order to\ncorrectly predict sentiment, a classifier must be able to identify negation and\ndisentangle the effect that its scope has on the final polarity of a text. This\npaper proposes a multi-task approach to explicitly incorporate information\nabout negation in sentiment analysis, which we show outperforms learning\nnegation implicitly in a data-driven manner. We describe our approach, a\ncascading neural architecture with selective sharing of LSTM layers, and show\nthat explicitly training the model with negation as an auxiliary task helps\nimprove the main task of sentiment analysis. The effect is demonstrated across\nseveral different standard English-language data sets for both tasks and we\nanalyze several aspects of our system related to its performance, varying types\nand amounts of input data and different multi-task setups.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 14:31:58 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 09:17:24 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Barnes", "Jeremy", ""], ["Velldal", "Erik", ""], ["\u00d8vrelid", "Lilja", ""]]}, {"id": "1906.07651", "submitter": "Tsvetomila Mihaylova", "authors": "Tsvetomila Mihaylova and Andr\\'e F. T. Martins", "title": "Scheduled Sampling for Transformers", "comments": null, "journal-ref": "ACL 2019 Student Research Workshop", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scheduled sampling is a technique for avoiding one of the known problems in\nsequence-to-sequence generation: exposure bias. It consists of feeding the\nmodel a mix of the teacher forced embeddings and the model predictions from the\nprevious step in training time. The technique has been used for improving the\nmodel performance with recurrent neural networks (RNN). In the Transformer\nmodel, unlike the RNN, the generation of a new word attends to the full\nsentence generated so far, not only to the last word, and it is not\nstraightforward to apply the scheduled sampling technique. We propose some\nstructural changes to allow scheduled sampling to be applied to Transformer\narchitecture, via a two-pass decoding strategy. Experiments on two language\npairs achieve performance close to a teacher-forcing baseline and show that\nthis technique is promising for further exploration.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 15:46:08 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Mihaylova", "Tsvetomila", ""], ["Martins", "Andr\u00e9 F. T.", ""]]}, {"id": "1906.07662", "submitter": "Hung Ngo", "authors": "Song Nguyen Duc Cong, Quoc Hung Ngo, Rachsuda Jiamthapthaksin", "title": "State-of-the-Art Vietnamese Word Segmentation", "comments": "2016 2nd International Conference on Science in Information\n  Technology (ICSITech)", "journal-ref": null, "doi": "10.1109/ICSITech.2016.7852619", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Word segmentation is the first step of any tasks in Vietnamese language\nprocessing. This paper reviews stateof-the-art approaches and systems for word\nsegmentation in Vietnamese. To have an overview of all stages from building\ncorpora to developing toolkits, we discuss building the corpus stage,\napproaches applied to solve the word segmentation and existing toolkits to\nsegment words in Vietnamese sentences. In addition, this study shows clearly\nthe motivations on building corpus and implementing machine learning techniques\nto improve the accuracy for Vietnamese word segmentation. According to our\nobservation, this study also reports a few of achivements and limitations in\nexisting Vietnamese word segmentation systems.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 16:00:56 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Cong", "Song Nguyen Duc", ""], ["Ngo", "Quoc Hung", ""], ["Jiamthapthaksin", "Rachsuda", ""]]}, {"id": "1906.07668", "submitter": "Tunazzina Islam", "authors": "Tunazzina Islam", "title": "Yoga-Veganism: Correlation Mining of Twitter Health Data", "comments": "In Proceedings of 8th KDD Workshop on Issues of Sentiment Discovery\n  and Opinion Mining (WISDOM) @KDD 2019. arXiv admin note: substantial text\n  overlap with arXiv:1906.02132", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays social media is a huge platform of data. People usually share their\ninterest, thoughts via discussions, tweets, status. It is not possible to go\nthrough all the data manually. We need to mine the data to explore hidden\npatterns or unknown correlations, find out the dominant topic in data and\nunderstand people's interest through the discussions. In this work, we explore\nTwitter data related to health. We extract the popular topics under different\ncategories (e.g. diet, exercise) discussed in Twitter via topic modeling,\nobserve model behavior on new tweets, discover interesting correlation (i.e.\nYoga-Veganism). We evaluate accuracy by comparing with ground truth using\nmanual annotation both for train and test data.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 20:56:48 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Islam", "Tunazzina", ""]]}, {"id": "1906.07689", "submitter": "Hao Tan", "authors": "Hao Tan, Franck Dernoncourt, Zhe Lin, Trung Bui, Mohit Bansal", "title": "Expressing Visual Relationships via Language", "comments": "ACL 2019 (11 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Describing images with text is a fundamental problem in vision-language\nresearch. Current studies in this domain mostly focus on single image\ncaptioning. However, in various real applications (e.g., image editing,\ndifference interpretation, and retrieval), generating relational captions for\ntwo images, can also be very useful. This important problem has not been\nexplored mostly due to lack of datasets and effective models. To push forward\nthe research in this direction, we first introduce a new language-guided image\nediting dataset that contains a large number of real image pairs with\ncorresponding editing instructions. We then propose a new relational speaker\nmodel based on an encoder-decoder architecture with static relational attention\nand sequential multi-head attention. We also extend the model with dynamic\nrelational attention, which calculates visual alignment while decoding. Our\nmodels are evaluated on our newly collected and two public datasets consisting\nof image pairs annotated with relationship sentences. Experimental results,\nbased on both automatic and human evaluation, demonstrate that our model\noutperforms all baselines and existing methods on all the datasets.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 17:01:21 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 02:49:11 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Tan", "Hao", ""], ["Dernoncourt", "Franck", ""], ["Lin", "Zhe", ""], ["Bui", "Trung", ""], ["Bansal", "Mohit", ""]]}, {"id": "1906.07701", "submitter": "Julia Ive", "authors": "Julia Ive and Pranava Madhyastha and Lucia Specia", "title": "Distilling Translations with Visual Awareness", "comments": "accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work on multimodal machine translation has shown that visual\ninformation is only needed in very specific cases, for example in the presence\nof ambiguous words where the textual context is not sufficient. As a\nconsequence, models tend to learn to ignore this information. We propose a\ntranslate-and-refine approach to this problem where images are only used by a\nsecond stage decoder. This approach is trained jointly to generate a good first\ndraft translation and to improve over this draft by (i) making better use of\nthe target language textual context (both left and right-side contexts) and\n(ii) making use of visual context. This approach leads to the state of the art\nresults. Additionally, we show that it has the ability to recover from\nerroneous or missing words in the source language.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 17:30:30 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Ive", "Julia", ""], ["Madhyastha", "Pranava", ""], ["Specia", "Lucia", ""]]}, {"id": "1906.07808", "submitter": "Alberto Poncelas", "authors": "Alberto Poncelas, Gideon Maillette de Buy Wenniger, Andy Way", "title": "Adaptation of Machine Translation Models with Back-translated Data using\n  Transductive Data Selection Methods", "comments": "Accepted in CICLing 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data selection has proven its merit for improving Neural Machine Translation\n(NMT), when applied to authentic data. But the benefit of using synthetic data\nin NMT training, produced by the popular back-translation technique, raises the\nquestion if data selection could also be useful for synthetic data?\n  In this work we use Infrequent N-gram Recovery (INR) and Feature Decay\nAlgorithms (FDA), two transductive data selection methods to obtain subsets of\nsentences from synthetic data. These methods ensure that selected sentences\nshare n-grams with the test set so the NMT model can be adapted to translate\nit.\n  Performing data selection on back-translated data creates new challenges as\nthe source-side may contain noise originated by the model used in the\nback-translation. Hence, finding n-grams present in the test set become more\ndifficult. Despite that, in our work we show that adapting a model with a\nselection of synthetic data is an useful approach.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 20:56:11 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Poncelas", "Alberto", ""], ["Wenniger", "Gideon Maillette de Buy", ""], ["Way", "Andy", ""]]}, {"id": "1906.07839", "submitter": "Neville Ryant", "authors": "Neville Ryant, Kenneth Church, Christopher Cieri, Alejandrina Cristia,\n  Jun Du, Sriram Ganapathy, Mark Liberman", "title": "The Second DIHARD Diarization Challenge: Dataset, task, and baselines", "comments": "Accepted by Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the second DIHARD challenge, the second in a series of\nspeaker diarization challenges intended to improve the robustness of\ndiarization systems to variation in recording equipment, noise conditions, and\nconversational domain. The challenge comprises four tracks evaluating\ndiarization performance under two input conditions (single channel vs.\nmulti-channel) and two segmentation conditions (diarization from a reference\nspeech segmentation vs. diarization from scratch). In order to prevent\nparticipants from overtuning to a particular combination of recording\nconditions and conversational domain, recordings are drawn from a variety of\nsources ranging from read audiobooks to meeting speech, to child language\nacquisition recordings, to dinner parties, to web video. We describe the task\nand metrics, challenge design, datasets, and baseline systems for speech\nenhancement, speech activity detection, and diarization.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 23:04:09 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Ryant", "Neville", ""], ["Church", "Kenneth", ""], ["Cieri", "Christopher", ""], ["Cristia", "Alejandrina", ""], ["Du", "Jun", ""], ["Ganapathy", "Sriram", ""], ["Liberman", "Mark", ""]]}, {"id": "1906.07854", "submitter": "Seunghyun Yoon", "authors": "Jiin Nam, Seunghyun Yoon, Kyomin Jung", "title": "Surf at MEDIQA 2019: Improving Performance of Natural Language Inference\n  in the Clinical Domain by Adopting Pre-trained Language Model", "comments": "9 pages, Accepted to ACL 2019 workshop on BioNLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning techniques have shown promising results in many natural\nlanguage processing (NLP) tasks, it has not been widely applied to the clinical\ndomain. The lack of large datasets and the pervasive use of domain-specific\nlanguage (i.e. abbreviations and acronyms) in the clinical domain causes slower\nprogress in NLP tasks than that of the general NLP tasks. To fill this gap, we\nemploy word/subword-level based models that adopt large-scale data-driven\nmethods such as pre-trained language models and transfer learning in analyzing\ntext for the clinical domain. Empirical results demonstrate the superiority of\nthe proposed methods by achieving 90.6% accuracy in medical domain natural\nlanguage inference task. Furthermore, we inspect the independent strengths of\nthe proposed approaches in quantitative and qualitative manners. This analysis\nwill help researchers to select necessary components in building models for the\nmedical domain.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 00:13:04 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Nam", "Jiin", ""], ["Yoon", "Seunghyun", ""], ["Jung", "Kyomin", ""]]}, {"id": "1906.07880", "submitter": "Xinyu Wang", "authors": "Xinyu Wang, Jingxian Huang, Kewei Tu", "title": "Second-Order Semantic Dependency Parsing with End-to-End Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Semantic dependency parsing aims to identify semantic relationships between\nwords in a sentence that form a graph. In this paper, we propose a second-order\nsemantic dependency parser, which takes into consideration not only individual\ndependency edges but also interactions between pairs of edges. We show that\nsecond-order parsing can be approximated using mean field (MF) variational\ninference or loopy belief propagation (LBP). We can unfold both algorithms as\nrecurrent layers of a neural network and therefore can train the parser in an\nend-to-end manner. Our experiments show that our approach achieves\nstate-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 02:05:39 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 12:06:48 GMT"}, {"version": "v3", "created": "Wed, 24 Feb 2021 07:56:57 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Wang", "Xinyu", ""], ["Huang", "Jingxian", ""], ["Tu", "Kewei", ""]]}, {"id": "1906.07886", "submitter": "Jonathan Rawski", "authors": "Jane Chandlee, Remi Eyraud, Jeffrey Heinz, Adam Jardine, Jonathan\n  Rawski", "title": "Learning with Partially Ordered Representations", "comments": "to appear in Proceedings of Mathematics of Language (ACL SIGMOL 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CL cs.LG cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper examines the characterization and learning of grammars defined\nwith enriched representational models. Model-theoretic approaches to formal\nlanguage theory traditionally assume that each position in a string belongs to\nexactly one unary relation. We consider unconventional string models where\npositions can have multiple, shared properties, which are arguably useful in\nmany applications. We show the structures given by these models are partially\nordered, and present a learning algorithm that exploits this ordering relation\nto effectively prune the hypothesis space. We prove this learning algorithm,\nwhich takes positive examples as input, finds the most general grammar which\ncovers the data.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 02:43:50 GMT"}, {"version": "v2", "created": "Sun, 23 Jun 2019 16:42:24 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Chandlee", "Jane", ""], ["Eyraud", "Remi", ""], ["Heinz", "Jeffrey", ""], ["Jardine", "Adam", ""], ["Rawski", "Jonathan", ""]]}, {"id": "1906.07901", "submitter": "Shruti Palaskar", "authors": "Shruti Palaskar, Jindrich Libovick\\'y, Spandana Gella and Florian\n  Metze", "title": "Multimodal Abstractive Summarization for How2 Videos", "comments": "To appear in ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study abstractive summarization for open-domain videos.\nUnlike the traditional text news summarization, the goal is less to \"compress\"\ntext information but rather to provide a fluent textual summary of information\nthat has been collected and fused from different source modalities, in our case\nvideo and audio transcripts (or text). We show how a multi-source\nsequence-to-sequence model with hierarchical attention can integrate\ninformation from different modalities into a coherent output, compare various\nmodels trained with different modalities and present pilot experiments on the\nHow2 corpus of instructional videos. We also propose a new evaluation metric\n(Content F1) for abstractive summarization task that measures semantic adequacy\nrather than fluency of the summaries, which is covered by metrics like ROUGE\nand BLEU.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 03:52:42 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Palaskar", "Shruti", ""], ["Libovick\u00fd", "Jindrich", ""], ["Gella", "Spandana", ""], ["Metze", "Florian", ""]]}, {"id": "1906.07955", "submitter": "Emre Yilmaz", "authors": "Emre Y{\\i}lmaz, Adem Derinel, Zhou Kun, Henk van den Heuvel, Niko\n  Brummer, Haizhou Li, David A. van Leeuwen", "title": "Large-Scale Speaker Diarization of Radio Broadcast Archives", "comments": "Accepted for publication at Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes our initial efforts to build a large-scale speaker\ndiarization (SD) and identification system on a recently digitized radio\nbroadcast archive from the Netherlands which has more than 6500 audio tapes\nwith 3000 hours of Frisian-Dutch speech recorded between 1950-2016. The\nemployed large-scale diarization scheme involves two stages: (1) tape-level\nspeaker diarization providing pseudo-speaker identities and (2) speaker linking\nto relate pseudo-speakers appearing in multiple tapes. Having access to the\nspeaker models of several frequently appearing speakers from the previously\ncollected FAME! speech corpus, we further perform speaker identification by\nlinking these known speakers to the pseudo-speakers identified at the first\nstage. In this work, we present a recently created longitudinal and\nmultilingual SD corpus designed for large-scale SD research and evaluate the\nperformance of a new speaker linking system using x-vectors with PLDA to\nquantify cross-tape speaker similarity on this corpus. The performance of this\nspeaker linking system is evaluated on a small subset of the archive which is\nmanually annotated with speaker information. The speaker linking performance\nreported on this subset (53 hours) and the whole archive (3000 hours) is\ncompared to quantify the impact of scaling up in the amount of speech data.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 07:58:42 GMT"}, {"version": "v2", "created": "Fri, 28 Jun 2019 07:22:04 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Y\u0131lmaz", "Emre", ""], ["Derinel", "Adem", ""], ["Kun", "Zhou", ""], ["Heuvel", "Henk van den", ""], ["Brummer", "Niko", ""], ["Li", "Haizhou", ""], ["van Leeuwen", "David A.", ""]]}, {"id": "1906.07978", "submitter": "Chenhui Chu", "authors": "Chenhui Chu and Raj Dabre", "title": "Multilingual Multi-Domain Adaptation Approaches for Neural Machine\n  Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose two novel methods for domain adaptation for the\nattention-only neural machine translation (NMT) model, i.e., the Transformer.\nOur methods focus on training a single translation model for multiple domains\nby either learning domain specialized hidden state representations or predictor\nbiases for each domain. We combine our methods with a previously proposed\nblack-box method called mixed fine tuning, which is known to be highly\neffective for domain adaptation. In addition, we incorporate multilingualism\ninto the domain adaptation framework. Experiments show that multilingual\nmulti-domain adaptation can significantly improve both resource-poor in-domain\nand resource-rich out-of-domain translations, and the combination of our\nmethods with mixed fine tuning achieves the best performance.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 08:56:02 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 08:01:12 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Chu", "Chenhui", ""], ["Dabre", "Raj", ""]]}, {"id": "1906.08003", "submitter": "Emre Yilmaz", "authors": "Qinyi Wang, Emre Y{\\i}lmaz, Adem Derinel and Haizhou Li", "title": "Code-Switching Detection Using ASR-Generated Language Posteriors", "comments": "Accepted for publication at Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code-switching (CS) detection refers to the automatic detection of language\nswitches in code-mixed utterances. This task can be achieved by using a CS\nautomatic speech recognition (ASR) system that can handle such language\nswitches. In our previous work, we have investigated the code-switching\ndetection performance of the Frisian-Dutch CS ASR system by using the time\nalignment of the most likely hypothesis and found that this technique suffers\nfrom over-switching due to numerous very short spurious language switches. In\nthis paper, we propose a novel method for CS detection aiming to remedy this\nshortcoming by using the language posteriors which are the sum of the\nframe-level posteriors of phones belonging to the same language. The CS\nASR-generated language posteriors contain more complete language-specific\ninformation on frame level compared to the time alignment of the ASR output.\nHence, it is expected to yield more accurate and robust CS detection. The CS\ndetection experiments demonstrate that the proposed language posterior-based\napproach provides higher detection accuracy than the baseline system in terms\nof equal error rate. Moreover, a detailed CS detection error analysis reveals\nthat using language posteriors reduces the false alarms and results in more\nrobust CS detection.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 09:56:34 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Wang", "Qinyi", ""], ["Y\u0131lmaz", "Emre", ""], ["Derinel", "Adem", ""], ["Li", "Haizhou", ""]]}, {"id": "1906.08041", "submitter": "Ruizhi Li", "authors": "Ruizhi Li, Xiaofei Wang, Sri Harish Mallidi, Shinji Watanabe, Takaaki\n  Hori and Hynek Hermansky", "title": "Multi-Stream End-to-End Speech Recognition", "comments": "submitted to IEEE TASLP (In review). arXiv admin note: substantial\n  text overlap with arXiv:1811.04897, arXiv:1811.04903", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based methods and Connectionist Temporal Classification (CTC)\nnetwork have been promising research directions for end-to-end (E2E) Automatic\nSpeech Recognition (ASR). The joint CTC/Attention model has achieved great\nsuccess by utilizing both architectures during multi-task training and joint\ndecoding. In this work, we present a multi-stream framework based on joint\nCTC/Attention E2E ASR with parallel streams represented by separate encoders\naiming to capture diverse information. On top of the regular attention\nnetworks, the Hierarchical Attention Network (HAN) is introduced to steer the\ndecoder toward the most informative encoders. A separate CTC network is\nassigned to each stream to force monotonic alignments. Two representative\nframework have been proposed and discussed, which are Multi-Encoder\nMulti-Resolution (MEM-Res) framework and Multi-Encoder Multi-Array (MEM-Array)\nframework, respectively. In MEM-Res framework, two heterogeneous encoders with\ndifferent architectures, temporal resolutions and separate CTC networks work in\nparallel to extract complimentary information from same acoustics. Experiments\nare conducted on Wall Street Journal (WSJ) and CHiME-4, resulting in relative\nWord Error Rate (WER) reduction of 18.0-32.1% and the best WER of 3.6% in the\nWSJ eval92 test set. The MEM-Array framework aims at improving the far-field\nASR robustness using multiple microphone arrays which are activated by separate\nencoders. Compared with the best single-array results, the proposed framework\nhas achieved relative WER reduction of 3.7% and 9.7% in AMI and DIRHA\nmulti-array corpora, respectively, which also outperforms conventional fusion\nstrategies.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 23:00:15 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 18:47:43 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Li", "Ruizhi", ""], ["Wang", "Xiaofei", ""], ["Mallidi", "Sri Harish", ""], ["Watanabe", "Shinji", ""], ["Hori", "Takaaki", ""], ["Hermansky", "Hynek", ""]]}, {"id": "1906.08042", "submitter": "Kun Qian", "authors": "Jungo Kasai, Kun Qian, Sairam Gurajada, Yunyao Li, Lucian Popa", "title": "Low-resource Deep Entity Resolution with Transfer and Active Learning", "comments": "This paper is accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity resolution (ER) is the task of identifying different representations\nof the same real-world entities across databases. It is a key step for\nknowledge base creation and text mining. Recent adaptation of deep learning\nmethods for ER mitigates the need for dataset-specific feature engineering by\nconstructing distributed representations of entity records. While these methods\nachieve state-of-the-art performance over benchmark data, they require large\namounts of labeled data, which are typically unavailable in realistic ER\napplications. In this paper, we develop a deep learning-based method that\ntargets low-resource settings for ER through a novel combination of transfer\nlearning and active learning. We design an architecture that allows us to learn\na transferable model from a high-resource setting to a low-resource one. To\nfurther adapt to the target dataset, we incorporate active learning that\ncarefully selects a few informative examples to fine-tune the transferred\nmodel. Empirical evaluation demonstrates that our method achieves comparable,\nif not better, performance compared to state-of-the-art learning-based methods\nwhile using an order of magnitude fewer labels.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 20:33:24 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Kasai", "Jungo", ""], ["Qian", "Kun", ""], ["Gurajada", "Sairam", ""], ["Li", "Yunyao", ""], ["Popa", "Lucian", ""]]}, {"id": "1906.08043", "submitter": "Titouan Parcollet", "authors": "Titouan Parcollet, Mohamed Morchid, Georges Linar\\`es, Renato De Mori", "title": "Real to H-space Encoder for Speech Recognition", "comments": "Accepted at INTERSPEECH 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) and more precisely recurrent neural networks\n(RNNs) are at the core of modern automatic speech recognition systems, due to\ntheir efficiency to process input sequences. Recently, it has been shown that\ndifferent input representations, based on multidimensional algebras, such as\ncomplex and quaternion numbers, are able to bring to neural networks a more\nnatural, compressive and powerful representation of the input signal by\noutperforming common real-valued NNs. Indeed, quaternion-valued neural networks\n(QNNs) better learn both internal dependencies, such as the relation between\nthe Mel-filter-bank value of a specific time frame and its time derivatives,\nand global dependencies, describing the relations that exist between time\nframes. Nonetheless, QNNs are limited to quaternion-valued input signals, and\nit is difficult to benefit from this powerful representation with real-valued\ninput data. This paper proposes to tackle this weakness by introducing a\nreal-to-quaternion encoder that allows QNNs to process any one dimensional\ninput features, such as traditional Mel-filter-banks for automatic speech\nrecognition.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 20:07:45 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Parcollet", "Titouan", ""], ["Morchid", "Mohamed", ""], ["Linar\u00e8s", "Georges", ""], ["De Mori", "Renato", ""]]}, {"id": "1906.08069", "submitter": "Mike Zhang", "authors": "Mike Zhang and Antonio Toral", "title": "The Effect of Translationese in Machine Translation Test Sets", "comments": "9 pages, 10 pages appendix, 3 figures, 20 tables, accepted in WMT19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effect of translationese has been studied in the field of machine\ntranslation (MT), mostly with respect to training data. We study in depth the\neffect of translationese on test data, using the test sets from the last three\neditions of WMT's news shared task, containing 17 translation directions. We\nshow evidence that (i) the use of translationese in test sets results in\ninflated human evaluation scores for MT systems; (ii) in some cases system\nrankings do change and (iii) the impact translationese has on a translation\ndirection is inversely correlated to the translation quality attainable by\nstate-of-the-art MT systems for that direction.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 12:39:09 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Zhang", "Mike", ""], ["Toral", "Antonio", ""]]}, {"id": "1906.08101", "submitter": "Yiming Cui", "authors": "Yiming Cui, Wanxiang Che, Ting Liu, Bing Qin, Ziqing Yang, Shijin\n  Wang, Guoping Hu", "title": "Pre-Training with Whole Word Masking for Chinese BERT", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bidirectional Encoder Representations from Transformers (BERT) has shown\nmarvelous improvements across various NLP tasks. Recently, an upgraded version\nof BERT has been released with Whole Word Masking (WWM), which mitigate the\ndrawbacks of masking partial WordPiece tokens in pre-training BERT. In this\ntechnical report, we adapt whole word masking in Chinese text, that masking the\nwhole word instead of masking Chinese characters, which could bring another\nchallenge in Masked Language Model (MLM) pre-training task. The proposed models\nare verified on various NLP tasks, across sentence-level to document-level,\nincluding machine reading comprehension (CMRC 2018, DRCD, CJRC), natural\nlanguage inference (XNLI), sentiment classification (ChnSentiCorp), sentence\npair matching (LCQMC, BQ Corpus), and document classification (THUCNews).\nExperimental results on these datasets show that the whole word masking could\nbring another significant gain. Moreover, we also examine the effectiveness of\nthe Chinese pre-trained models: BERT, ERNIE, BERT-wwm, BERT-wwm-ext,\nRoBERTa-wwm-ext, and RoBERTa-wwm-ext-large. We release all the pre-trained\nmodels: \\url{https://github.com/ymcui/Chinese-BERT-wwm\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 13:54:25 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 03:44:25 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Cui", "Yiming", ""], ["Che", "Wanxiang", ""], ["Liu", "Ting", ""], ["Qin", "Bing", ""], ["Yang", "Ziqing", ""], ["Wang", "Shijin", ""], ["Hu", "Guoping", ""]]}, {"id": "1906.08104", "submitter": "Yue Dong", "authors": "Yue Dong, Zichao Li, Mehdi Rezagholizadeh and Jackie Chi Kit Cheung", "title": "EditNTS: An Neural Programmer-Interpreter Model for Sentence\n  Simplification through Explicit Editing", "comments": "9 pages, 1 figure, accepted at ACL2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first sentence simplification model that learns explicit edit\noperations (ADD, DELETE, and KEEP) via a neural programmer-interpreter\napproach. Most current neural sentence simplification systems are variants of\nsequence-to-sequence models adopted from machine translation. These methods\nlearn to simplify sentences as a byproduct of the fact that they are trained on\ncomplex-simple sentence pairs. By contrast, our neural programmer-interpreter\nis directly trained to predict explicit edit operations on targeted parts of\nthe input sentence, resembling the way that humans might perform simplification\nand revision. Our model outperforms previous state-of-the-art neural sentence\nsimplification models (without external knowledge) by large margins on three\nbenchmark text simplification corpora in terms of SARI (+0.95 WikiLarge, +1.89\nWikiSmall, +1.41 Newsela), and is judged by humans to produce overall better\nand simpler output sentences.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 14:00:15 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Dong", "Yue", ""], ["Li", "Zichao", ""], ["Rezagholizadeh", "Mehdi", ""], ["Cheung", "Jackie Chi Kit", ""]]}, {"id": "1906.08237", "submitter": "Zhilin Yang", "authors": "Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan\n  Salakhutdinov, Quoc V. Le", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding", "comments": "Pretrained models and code are available at\n  https://github.com/zihangdai/xlnet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the capability of modeling bidirectional contexts, denoising\nautoencoding based pretraining like BERT achieves better performance than\npretraining approaches based on autoregressive language modeling. However,\nrelying on corrupting the input with masks, BERT neglects dependency between\nthe masked positions and suffers from a pretrain-finetune discrepancy. In light\nof these pros and cons, we propose XLNet, a generalized autoregressive\npretraining method that (1) enables learning bidirectional contexts by\nmaximizing the expected likelihood over all permutations of the factorization\norder and (2) overcomes the limitations of BERT thanks to its autoregressive\nformulation. Furthermore, XLNet integrates ideas from Transformer-XL, the\nstate-of-the-art autoregressive model, into pretraining. Empirically, under\ncomparable experiment settings, XLNet outperforms BERT on 20 tasks, often by a\nlarge margin, including question answering, natural language inference,\nsentiment analysis, and document ranking.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 17:35:48 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 12:48:08 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Yang", "Zhilin", ""], ["Dai", "Zihang", ""], ["Yang", "Yiming", ""], ["Carbonell", "Jaime", ""], ["Salakhutdinov", "Ruslan", ""], ["Le", "Quoc V.", ""]]}, {"id": "1906.08286", "submitter": "Frederick Liu", "authors": "Frederick Liu, Besim Avci", "title": "Incorporating Priors with Feature Attribution on Text Classification", "comments": "Accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature attribution methods, proposed recently, help users interpret the\npredictions of complex models. Our approach integrates feature attributions\ninto the objective function to allow machine learning practitioners to\nincorporate priors in model building. To demonstrate the effectiveness our\ntechnique, we apply it to two tasks: (1) mitigating unintended bias in text\nclassifiers by neutralizing identity terms; (2) improving classifier\nperformance in a scarce data setting by forcing the model to focus on toxic\nterms. Our approach adds an L2 distance loss between feature attributions and\ntask-specific prior values to the objective. Our experiments show that i) a\nclassifier trained with our technique reduces undesired model biases without a\ntrade off on the original task; ii) incorporating priors helps model\nperformance in scarce data settings.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 18:08:06 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Liu", "Frederick", ""], ["Avci", "Besim", ""]]}, {"id": "1906.08287", "submitter": "Tanya Goyal", "authors": "Tanya Goyal and Greg Durrett", "title": "Embedding time expressions for deep temporal ordering models", "comments": "Acl 2019 (short paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven models have demonstrated state-of-the-art performance in\ninferring the temporal ordering of events in text. However, these models often\noverlook explicit temporal signals, such as dates and time windows. Rule-based\nmethods can be used to identify the temporal links between these time\nexpressions (timexes), but they fail to capture timexes' interactions with\nevents and are hard to integrate with the distributed representations of neural\nnet models. In this paper, we introduce a framework to infuse temporal\nawareness into such models by learning a pre-trained model to embed timexes. We\ngenerate synthetic data consisting of pairs of timexes, then train a character\nLSTM to learn embeddings and classify the timexes' temporal relation. We\nevaluate the utility of these embeddings in the context of a strong neural\nmodel for event temporal ordering, and show a small increase in performance on\nthe MATRES dataset and more substantial gains on an automatically collected\ndataset with more frequent event-timex interactions.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 18:08:33 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Goyal", "Tanya", ""], ["Durrett", "Greg", ""]]}, {"id": "1906.08318", "submitter": "Geeticka Chauhan", "authors": "Geeticka Chauhan, Matthew B. A. McDermott and Peter Szolovits", "title": "REflex: Flexible Framework for Relation Extraction in Multiple Domains", "comments": "accepted by BioNLP 2019 at the Association of Computation Linguistics\n  2019", "journal-ref": null, "doi": "10.18653/v1/W19-5004", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systematic comparison of methods for relation extraction (RE) is difficult\nbecause many experiments in the field are not described precisely enough to be\ncompletely reproducible and many papers fail to report ablation studies that\nwould highlight the relative contributions of their various combined\ntechniques. In this work, we build a unifying framework for RE, applying this\non three highly used datasets (from the general, biomedical and clinical\ndomains) with the ability to be extendable to new datasets. By performing a\nsystematic exploration of modeling, pre-processing and training methodologies,\nwe find that choices of pre-processing are a large contributor performance and\nthat omission of such information can further hinder fair comparison. Other\ninsights from our exploration allow us to provide recommendations for future\nresearch in this area.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 19:21:16 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 14:10:20 GMT"}, {"version": "v3", "created": "Thu, 27 Jun 2019 19:40:37 GMT"}, {"version": "v4", "created": "Sat, 20 Jul 2019 17:59:54 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Chauhan", "Geeticka", ""], ["McDermott", "Matthew B. A.", ""], ["Szolovits", "Peter", ""]]}, {"id": "1906.08333", "submitter": "Youngmoon Jung", "authors": "Youngmoon Jung, Younggwan Kim, Hyungjun Lim, Yeunju Choi, Hoirin Kim", "title": "Spatial Pyramid Encoding with Convex Length Normalization for\n  Text-Independent Speaker Verification", "comments": "5 pages, 2 figures, Interspeech 2019", "journal-ref": "Proc. of Interspeech 2019, 2019, pp. 4030-4034", "doi": "10.21437/Interspeech.2019-2177", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new pooling method called spatial pyramid\nencoding (SPE) to generate speaker embeddings for text-independent speaker\nverification. We first partition the output feature maps from a deep residual\nnetwork (ResNet) into increasingly fine sub-regions and extract speaker\nembeddings from each sub-region through a learnable dictionary encoding layer.\nThese embeddings are concatenated to obtain the final speaker representation.\nThe SPE layer not only generates a fixed-dimensional speaker embedding for a\nvariable-length speech segment, but also aggregates the information of feature\ndistribution from multi-level temporal bins. Furthermore, we apply deep length\nnormalization by augmenting the loss function with ring loss. By applying ring\nloss, the network gradually learns to normalize the speaker embeddings using\nmodel weights themselves while preserving convexity, leading to more robust\nspeaker embeddings. Experiments on the VoxCeleb1 dataset show that the proposed\nsystem using the SPE layer and ring loss-based deep length normalization\noutperforms both i-vector and d-vector baselines.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 20:13:27 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Jung", "Youngmoon", ""], ["Kim", "Younggwan", ""], ["Lim", "Hyungjun", ""], ["Choi", "Yeunju", ""], ["Kim", "Hoirin", ""]]}, {"id": "1906.08340", "submitter": "Dinghan Shen", "authors": "Dinghan Shen, Pengyu Cheng, Dhanasekar Sundararaman, Xinyuan Zhang,\n  Qian Yang, Meng Tang, Asli Celikyilmaz, Lawrence Carin", "title": "Learning Compressed Sentence Representations for On-Device Text\n  Processing", "comments": "To appear at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vector representations of sentences, trained on massive text corpora, are\nwidely used as generic sentence embeddings across a variety of NLP problems.\nThe learned representations are generally assumed to be continuous and\nreal-valued, giving rise to a large memory footprint and slow retrieval speed,\nwhich hinders their applicability to low-resource (memory and computation)\nplatforms, such as mobile devices. In this paper, we propose four different\nstrategies to transform continuous and generic sentence embeddings into a\nbinarized form, while preserving their rich semantic information. The\nintroduced methods are evaluated across a wide range of downstream tasks, where\nthe binarized sentence embeddings are demonstrated to degrade performance by\nonly about 2% relative to their continuous counterparts, while reducing the\nstorage requirement by over 98%. Moreover, with the learned binary\nrepresentations, the semantic relatedness of two sentences can be evaluated by\nsimply calculating their Hamming distance, which is more computational\nefficient compared with the inner product operation between continuous\nembeddings. Detailed analysis and case study further validate the effectiveness\nof proposed methods.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 20:29:31 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Shen", "Dinghan", ""], ["Cheng", "Pengyu", ""], ["Sundararaman", "Dhanasekar", ""], ["Zhang", "Xinyuan", ""], ["Yang", "Qian", ""], ["Tang", "Meng", ""], ["Celikyilmaz", "Asli", ""], ["Carin", "Lawrence", ""]]}, {"id": "1906.08379", "submitter": "Tony Schulte", "authors": "Inom Mirzaev, Anthony Schulte, Michael Conover, Sam Shah", "title": "Considerations for the Interpretation of Bias Measures of Word\n  Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embedding spaces are powerful tools for capturing latent semantic\nrelationships between terms in corpora, and have become widely popular for\nbuilding state-of-the-art natural language processing algorithms. However,\nstudies have shown that societal biases present in text corpora may be\nincorporated into the word embedding spaces learned from them. Thus, there is\nan ethical concern that human-like biases contained in the corpora and their\nderived embedding spaces might be propagated, or even amplified with the usage\nof the biased embedding spaces in downstream applications. In an attempt to\nquantify these biases so that they may be better understood and studied,\nseveral bias metrics have been proposed. We explore the statistical properties\nof these proposed measures in the context of their cited applications as well\nas their supposed utilities. We find that there are caveats to the simple\ninterpretation of these metrics as proposed. We find that the bias metric\nproposed by Bolukbasi et al. 2016 is highly sensitive to embedding\nhyper-parameter selection, and that in many cases, the variance due to the\nselection of some hyper-parameters is greater than the variance in the metric\ndue to corpus selection, while in fewer cases the bias rankings of corpora vary\nwith hyper-parameter selection. In light of these observations, it may be the\ncase that bias estimates should not be thought to directly measure the\nproperties of the underlying corpus, but rather the properties of the specific\nembedding spaces in question, particularly in the context of hyper-parameter\nselections used to generate them. Hence, bias metrics of spaces generated with\ndiffering hyper-parameters should be compared only with explicit consideration\nof the embedding-learning algorithms particular configurations.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 21:56:25 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Mirzaev", "Inom", ""], ["Schulte", "Anthony", ""], ["Conover", "Michael", ""], ["Shah", "Sam", ""]]}, {"id": "1906.08382", "submitter": "Haseeb Shah", "authors": "Haseeb Shah, Johannes Villmow, Adrian Ulges, Ulrich Schwanecke and\n  Faisal Shafait", "title": "An Open-World Extension to Knowledge Graph Completion Models", "comments": "8 pages, accepted to AAAI-2019", "journal-ref": "AAAI-19 Vol 33 (2019) 3044-3051", "doi": "10.1609/aaai.v33i01.33013044", "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel extension to embedding-based knowledge graph completion\nmodels which enables them to perform open-world link prediction, i.e. to\npredict facts for entities unseen in training based on their textual\ndescription. Our model combines a regular link prediction model learned from a\nknowledge graph with word embeddings learned from a textual corpus. After\ntraining both independently, we learn a transformation to map the embeddings of\nan entity's name and description to the graph-based embedding space. In\nexperiments on several datasets including FB20k, DBPedia50k and our new dataset\nFB15k-237-OWE, we demonstrate competitive results. Particularly, our approach\nexploits the full knowledge graph structure even when textual descriptions are\nscarce, does not require a joint training on graph and text, and can be applied\nto any embedding-based link prediction model, such as TransE, ComplEx and\nDistMult.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 22:23:20 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Shah", "Haseeb", ""], ["Villmow", "Johannes", ""], ["Ulges", "Adrian", ""], ["Schwanecke", "Ulrich", ""], ["Shafait", "Faisal", ""]]}, {"id": "1906.08393", "submitter": "Renjie Zheng", "authors": "Renjie Zheng, Hairong Liu, Mingbo Ma, Baigong Zheng, Liang Huang", "title": "Robust Machine Translation with Domain Sensitive Pseudo-Sources:\n  Baidu-OSU WMT19 MT Robustness Shared Task System Report", "comments": "accepted by WMT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the machine translation system developed jointly by\nBaidu Research and Oregon State University for WMT 2019 Machine Translation\nRobustness Shared Task. Translation of social media is a very challenging\nproblem, since its style is very different from normal parallel corpora (e.g.\nNews) and also include various types of noises. To make it worse, the amount of\nsocial media parallel corpora is extremely limited. In this paper, we use a\ndomain sensitive training method which leverages a large amount of parallel\ndata from popular domains together with a little amount of parallel data from\nsocial media. Furthermore, we generate a parallel dataset with pseudo noisy\nsource sentences which are back-translated from monolingual data using a model\ntrained by a similar domain sensitive way. We achieve more than 10 BLEU\nimprovement in both En-Fr and Fr-En translation compared with the baseline\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 23:20:57 GMT"}, {"version": "v2", "created": "Sat, 22 Jun 2019 16:07:24 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Zheng", "Renjie", ""], ["Liu", "Hairong", ""], ["Ma", "Mingbo", ""], ["Zheng", "Baigong", ""], ["Huang", "Liang", ""]]}, {"id": "1906.08401", "submitter": "Mandy Guo", "authors": "Mandy Guo, Yinfei Yang, Keith Stevens, Daniel Cer, Heming Ge,\n  Yun-Hsuan Sung, Brian Strope and Ray Kurzweil", "title": "Hierarchical Document Encoder for Parallel Corpus Mining", "comments": "accepted by WMT2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore using multilingual document embeddings for nearest neighbor mining\nof parallel data. Three document-level representations are investigated: (i)\ndocument embeddings generated by simply averaging multilingual sentence\nembeddings; (ii) a neural bag-of-words (BoW) document encoding model; (iii) a\nhierarchical multilingual document encoder (HiDE) that builds on our\nsentence-level model. The results show document embeddings derived from\nsentence-level averaging are surprisingly effective for clean datasets, but\nsuggest models trained hierarchically at the document-level are more effective\non noisy data. Analysis experiments demonstrate our hierarchical models are\nvery robust to variations in the underlying sentence embedding quality. Using\ndocument embeddings trained with HiDE achieves state-of-the-art performance on\nUnited Nations (UN) parallel document mining, 94.9% P@1 for en-fr and 97.3% P@1\nfor en-es.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 00:59:22 GMT"}, {"version": "v2", "created": "Sun, 30 Jun 2019 06:09:51 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Guo", "Mandy", ""], ["Yang", "Yinfei", ""], ["Stevens", "Keith", ""], ["Cer", "Daniel", ""], ["Ge", "Heming", ""], ["Sung", "Yun-Hsuan", ""], ["Strope", "Brian", ""], ["Kurzweil", "Ray", ""]]}, {"id": "1906.08430", "submitter": "Gabriel Grand", "authors": "Gabriel Grand and Yonatan Belinkov", "title": "Adversarial Regularization for Visual Question Answering: Strengths,\n  Shortcomings, and Side Effects", "comments": "In Proceedings of the 2nd Workshop on Shortcomings in Vision and\n  Language (SiVL) at NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual question answering (VQA) models have been shown to over-rely on\nlinguistic biases in VQA datasets, answering questions \"blindly\" without\nconsidering visual context. Adversarial regularization (AdvReg) aims to address\nthis issue via an adversary sub-network that encourages the main model to learn\na bias-free representation of the question. In this work, we investigate the\nstrengths and shortcomings of AdvReg with the goal of better understanding how\nit affects inference in VQA models. Despite achieving a new state-of-the-art on\nVQA-CP, we find that AdvReg yields several undesirable side-effects, including\nunstable gradients and sharply reduced performance on in-domain examples. We\ndemonstrate that gradual introduction of regularization during training helps\nto alleviate, but not completely solve, these issues. Through error analyses,\nwe observe that AdvReg improves generalization to binary questions, but impairs\nperformance on questions with heterogeneous answer distributions.\nQualitatively, we also find that regularized models tend to over-rely on visual\nfeatures, while ignoring important linguistic cues in the question. Our results\nsuggest that AdvReg requires further refinement before it can be considered a\nviable bias mitigation technique for VQA.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 03:28:09 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Grand", "Gabriel", ""], ["Belinkov", "Yonatan", ""]]}, {"id": "1906.08449", "submitter": "Congying Xia", "authors": "Congying Xia, Chenwei Zhang, Tao Yang, Yaliang Li, Nan Du, Xian Wu,\n  Wei Fan, Fenglong Ma, Philip Yu", "title": "Multi-Grained Named Entity Recognition", "comments": "In ACL 2019 as a long paper", "journal-ref": null, "doi": "10.18653/v1/P19-1138", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel framework, MGNER, for Multi-Grained Named Entity\nRecognition where multiple entities or entity mentions in a sentence could be\nnon-overlapping or totally nested. Different from traditional approaches\nregarding NER as a sequential labeling task and annotate entities\nconsecutively, MGNER detects and recognizes entities on multiple granularities:\nit is able to recognize named entities without explicitly assuming\nnon-overlapping or totally nested structures. MGNER consists of a Detector that\nexamines all possible word segments and a Classifier that categorizes entities.\nIn addition, contextual information and a self-attention mechanism are utilized\nthroughout the framework to improve the NER performance. Experimental results\nshow that MGNER outperforms current state-of-the-art baselines up to 4.4% in\nterms of the F1 score among nested/non-overlapping NER tasks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 05:33:30 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Xia", "Congying", ""], ["Zhang", "Chenwei", ""], ["Yang", "Tao", ""], ["Li", "Yaliang", ""], ["Du", "Nan", ""], ["Wu", "Xian", ""], ["Fan", "Wei", ""], ["Ma", "Fenglong", ""], ["Yu", "Philip", ""]]}, {"id": "1906.08487", "submitter": "Jamin Shin", "authors": "Jamin Shin, Peng Xu, Andrea Madotto, Pascale Fung", "title": "HappyBot: Generating Empathetic Dialogue Responses by Improving User\n  Experience Look-ahead", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent neural conversation models that attempted to incorporate emotion and\ngenerate empathetic responses either focused on conditioning the output to a\ngiven emotion, or incorporating the current user emotional state. While these\napproaches have been successful to some extent in generating more diverse and\nseemingly engaging utterances, they do not factor in how the user would feel\ntowards the generated dialogue response. Hence, in this paper, we advocate such\nlook-ahead of user emotion as the key to modeling and generating empathetic\ndialogue responses. We thus train a Sentiment Predictor to estimate the user\nsentiment look-ahead towards the generated system responses, which is then used\nas the reward function for generating more empathetic responses. Human\nevaluation results show that our model outperforms other baselines in empathy,\nrelevance, and fluency.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 08:03:58 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Shin", "Jamin", ""], ["Xu", "Peng", ""], ["Madotto", "Andrea", ""], ["Fung", "Pascale", ""]]}, {"id": "1906.08570", "submitter": "Kaveri Anuranjana", "authors": "Kaveri Anuranjana, Vijjini Anvesh Rao, Radhika Mamidi", "title": "Hindi Question Generation Using Dependency Structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hindi question answering systems suffer from a lack of data. To address the\nsame, this paper presents an approach towards automatic question generation. We\npresent a rule-based system for question generation in Hindi by formalizing\nquestion transformation methods based on karaka-dependency theory. We use a\nHindi dependency parser to mark the karaka roles and use IndoWordNet a Hindi\nontology to detect the semantic category of the karaka role heads to generate\nthe interrogatives. We analyze how one sentence can have multiple generations\nfrom the same karaka role's rule. The generations are manually annotated by\nmultiple annotators on a semantic and syntactic scale for evaluation. Further,\nwe constrain our generation with the help of various semantic and syntactic\nfilters so as to improve the generation quality. Using these methods, we are\nable to generate diverse questions, significantly more than number of sentences\nfed to the system.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 12:05:13 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Anuranjana", "Kaveri", ""], ["Rao", "Vijjini Anvesh", ""], ["Mamidi", "Radhika", ""]]}, {"id": "1906.08584", "submitter": "Ngoc Quan Pham", "authors": "Ngoc-Quan Pham, Jan Niehues, Thanh-Le Ha, Alex Waibel", "title": "Improving Zero-shot Translation with Language-Independent Constraints", "comments": "10 pages version accepted in WMT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important concern in training multilingual neural machine translation\n(NMT) is to translate between language pairs unseen during training, i.e\nzero-shot translation. Improving this ability kills two birds with one stone by\nproviding an alternative to pivot translation which also allows us to better\nunderstand how the model captures information between languages.\n  In this work, we carried out an investigation on this capability of the\nmultilingual NMT models. First, we intentionally create an encoder architecture\nwhich is independent with respect to the source language. Such experiments shed\nlight on the ability of NMT encoders to learn multilingual representations, in\ngeneral. Based on such proof of concept, we were able to design regularization\nmethods into the standard Transformer model, so that the whole architecture\nbecomes more robust in zero-shot conditions. We investigated the behaviour of\nsuch models on the standard IWSLT 2017 multilingual dataset. We achieved an\naverage improvement of 2.23 BLEU points across 12 language pairs compared to\nthe zero-shot performance of a state-of-the-art multilingual system.\nAdditionally, we carry out further experiments in which the effect is confirmed\neven for language pairs with multiple intermediate pivots.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 12:49:17 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Pham", "Ngoc-Quan", ""], ["Niehues", "Jan", ""], ["Ha", "Thanh-Le", ""], ["Waibel", "Alex", ""]]}, {"id": "1906.08593", "submitter": "Rajarshee Mitra", "authors": "Rajarshee Mitra", "title": "Conflict as an Inverse of Attention in Sequence Relationship", "comments": "Accepted at HAI workshop for IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention is a very efficient way to model the relationship between two\nsequences by comparing how similar two intermediate representations are.\nInitially demonstrated in NMT, it is a standard in all NLU tasks today when\nefficient interaction between sequences is considered. However, we show that\nattention, by virtue of its composition, works best only when it is given that\nthere is a match somewhere between two sequences. It does not very well adapt\nto cases when there is no similarity between two sequences or if the\nrelationship is contrastive. We propose an Conflict model which is very similar\nto how attention works but which emphasizes mostly on how well two sequences\nrepel each other and finally empirically show how this method in conjunction\nwith attention can boost the overall performance.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 13:16:37 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 08:35:03 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Mitra", "Rajarshee", ""]]}, {"id": "1906.08646", "submitter": "Christoph Alt", "authors": "Christoph Alt, Marc H\\\"ubner, Leonhard Hennig", "title": "Fine-tuning Pre-Trained Transformer Language Models to Distantly\n  Supervised Relation Extraction", "comments": "To appear in Proceedings of ACL 2019 (11 pages). arXiv admin note:\n  text overlap with arXiv:1906.03088", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distantly supervised relation extraction is widely used to extract relational\nfacts from text, but suffers from noisy labels. Current relation extraction\nmethods try to alleviate the noise by multi-instance learning and by providing\nsupporting linguistic and contextual information to more efficiently guide the\nrelation classification. While achieving state-of-the-art results, we observed\nthese models to be biased towards recognizing a limited set of relations with\nhigh precision, while ignoring those in the long tail. To address this gap, we\nutilize a pre-trained language model, the OpenAI Generative Pre-trained\nTransformer (GPT) [Radford et al., 2018]. The GPT and similar models have been\nshown to capture semantic and syntactic features, and also a notable amount of\n\"common-sense\" knowledge, which we hypothesize are important features for\nrecognizing a more diverse set of relations. By extending the GPT to the\ndistantly supervised setting, and fine-tuning it on the NYT10 dataset, we show\nthat it predicts a larger set of distinct relation types with high confidence.\nManual and automated evaluation of our model shows that it achieves a\nstate-of-the-art AUC score of 0.422 on the NYT10 dataset, and performs\nespecially well at higher recall levels.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 11:04:51 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Alt", "Christoph", ""], ["H\u00fcbner", "Marc", ""], ["Hennig", "Leonhard", ""]]}, {"id": "1906.08647", "submitter": "Emre Yilmaz", "authors": "Astik Biswas, Emre Y{\\i}lmaz, Febe de Wet, Ewald van der Westhuizen,\n  Thomas Niesler", "title": "Semi-supervised acoustic model training for five-lingual code-switched\n  ASR", "comments": "Accepted for publication at Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents recent progress in the acoustic modelling of\nunder-resourced code-switched (CS) speech in multiple South African languages.\nWe consider two approaches. The first constructs separate bilingual acoustic\nmodels corresponding to language pairs (English-isiZulu, English-isiXhosa,\nEnglish-Setswana and English-Sesotho). The second constructs a single unified\nfive-lingual acoustic model representing all the languages (English, isiZulu,\nisiXhosa, Setswana and Sesotho). For these two approaches we consider the\neffectiveness of semi-supervised training to increase the size of the very\nsparse acoustic training sets. Using approximately 11 hours of untranscribed\nspeech, we show that both approaches benefit from semi-supervised training. The\nbilingual TDNN-F acoustic models also benefit from the addition of CNN layers\n(CNN-TDNN-F), while the five-lingual system does not show any significant\nimprovement. Furthermore, because English is common to all language pairs in\nour data, it dominates when training a unified language model, leading to\nimproved English ASR performance at the expense of the other languages.\nNevertheless, the five-lingual model offers flexibility because it can process\nmore than two languages simultaneously, and is therefore an attractive option\nas an automatic transcription system in a semi-supervised training pipeline.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 14:11:55 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 13:45:15 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Biswas", "Astik", ""], ["Y\u0131lmaz", "Emre", ""], ["de Wet", "Febe", ""], ["van der Westhuizen", "Ewald", ""], ["Niesler", "Thomas", ""]]}, {"id": "1906.08711", "submitter": "Yutai Hou", "authors": "Yutai Hou, Zhihan Zhou, Yijia Liu, Ning Wang, Wanxiang Che, Han Liu,\n  Ting Liu", "title": "Few-Shot Sequence Labeling with Label Dependency Transfer and Pair-wise\n  Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While few-shot classification has been widely explored with similarity based\nmethods, few-shot sequence labeling poses a unique challenge as it also calls\nfor modeling the label dependencies. To consider both the item similarity and\nlabel dependency, we propose to leverage the conditional random fields (CRFs)\nin few-shot sequence labeling. It calculates emission score with similarity\nbased methods and obtains transition score with a specially designed transfer\nmechanism. When applying CRF in the few-shot scenarios, the discrepancy of\nlabel sets among different domains makes it hard to use the label dependency\nlearned in prior domains. To tackle this, we introduce the dependency transfer\nmechanism that transfers abstract label transition patterns. In addition, the\nsimilarity methods rely on the high quality sample representation, which is\nchallenging for sequence labeling, because sense of a word is different when\nmeasuring its similarity to words in different sentences. To remedy this, we\ntake advantage of recent contextual embedding technique, and further propose a\npair-wise embedder. It provides additional certainty for word sense by\nembedding query and support sentence pairwisely. Experimental results on slot\ntagging and named entity recognition show that our model significantly\noutperforms the strongest few-shot learning baseline by 11.76 (21.2%) and 12.18\n(97.7%) F1 scores respectively in the one-shot setting.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 15:57:26 GMT"}, {"version": "v2", "created": "Thu, 15 Aug 2019 01:34:15 GMT"}, {"version": "v3", "created": "Mon, 9 Sep 2019 14:50:14 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Hou", "Yutai", ""], ["Zhou", "Zhihan", ""], ["Liu", "Yijia", ""], ["Wang", "Ning", ""], ["Che", "Wanxiang", ""], ["Liu", "Han", ""], ["Liu", "Ting", ""]]}, {"id": "1906.08717", "submitter": "Kuruvilla Abraham", "authors": "Mateus Machado, Evandro Ruiz, Kuruvilla Joseph Abraham", "title": "A New Statistical Approach for Comparing Algorithms for Lexicon Based\n  Sentiment Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lexicon based sentiment analysis usually relies on the identification of\nvarious words to which a numerical value corresponding to sentiment can be\nassigned. In principle, classifiers can be obtained from these algorithms by\ncomparison with human annotation, which is considered the gold standard. In\npractise this is difficult in languages such as Portuguese where there is a\npaucity of human annotated texts. Thus in order to compare algorithms, a next\nbest step is to directly compare different algorithms with each other without\nreferring to human annotation. In this paper we develop methods for a\nstatistical comparison of algorithms which does not rely on human annotation or\non known class labels. We will motivate the use of marginal homogeneity tests,\nas well as log linear models within the framework of maximum likelihood\nestimation We will also show how some uncertainties present in lexicon based\nsentiment analysis may be similar to those which occur in human annotated\ntweets. We will also show how the variability in the output of different\nalgorithms is lexicon dependent, and quantify this variability in the output\nwithin the framework of log linear models.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 16:04:38 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Machado", "Mateus", ""], ["Ruiz", "Evandro", ""], ["Abraham", "Kuruvilla Joseph", ""]]}, {"id": "1906.08733", "submitter": "Rui Aguiar", "authors": "Rui Aguiar, Kevin Liao", "title": "Autonomous Haiku Generation", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence is an excellent tool to improve efficiency and lower\ncost in many quantitative real world applications, but what if the task is not\neasily defined? What if the task is generating creativity? Poetry is a creative\nendeavor that is highly difficult to both grasp and achieve with any level of\ncompetence. As Rita Dove, a famous American poet and author states, \"Poetry is\nlanguage at its most distilled and most powerful.\" Taking Doves quote as an\ninspiration, our task was to generate high quality haikus using artificial\nintelligence and deep learning.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 16:25:47 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Aguiar", "Rui", ""], ["Liao", "Kevin", ""]]}, {"id": "1906.08871", "submitter": "Gautam Krishna", "authors": "Gautam Krishna, Co Tran, Mason Carnahan, Ahmed H Tewfik", "title": "Advancing Speech Recognition With No Speech Or With Noisy Speech", "comments": "Extended version of our accepted IEEE EUSIPCO 2019 paper with\n  additional results for CTC model based recognition. arXiv admin note:\n  substantial text overlap with arXiv:1906.08045, arXiv:1906.08044", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we demonstrate end-to-end continuous speech recognition (CSR)\nusing electroencephalography (EEG) signals with no speech signal as input. An\nattention model based automatic speech recognition (ASR) and connectionist\ntemporal classification (CTC) based ASR systems were implemented for performing\nrecognition. We further demonstrate CSR for noisy speech by fusing with EEG\nfeatures.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 23:06:51 GMT"}, {"version": "v2", "created": "Wed, 17 Jul 2019 03:13:24 GMT"}, {"version": "v3", "created": "Sat, 27 Jul 2019 03:46:44 GMT"}, {"version": "v4", "created": "Sat, 17 Aug 2019 02:44:48 GMT"}, {"version": "v5", "created": "Wed, 21 Aug 2019 19:00:45 GMT"}, {"version": "v6", "created": "Sun, 10 Nov 2019 02:47:45 GMT"}, {"version": "v7", "created": "Wed, 13 Nov 2019 03:53:06 GMT"}, {"version": "v8", "created": "Wed, 4 Mar 2020 22:28:26 GMT"}, {"version": "v9", "created": "Sun, 15 Mar 2020 02:51:46 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Krishna", "Gautam", ""], ["Tran", "Co", ""], ["Carnahan", "Mason", ""], ["Tewfik", "Ahmed H", ""]]}, {"id": "1906.08876", "submitter": "Sanqiang Zhao", "authors": "Sanqiang Zhao, Piyush Sharma, Tomer Levinboim, Radu Soricut", "title": "Informative Image Captioning with External Sources of Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An image caption should fluently present the essential information in a given\nimage, including informative, fine-grained entity mentions and the manner in\nwhich these entities interact. However, current captioning models are usually\ntrained to generate captions that only contain common object names, thus\nfalling short on an important \"informativeness\" dimension. We present a\nmechanism for integrating image information together with fine-grained labels\n(assumed to be generated by some upstream models) into a caption that describes\nthe image in a fluent and informative manner. We introduce a multimodal,\nmulti-encoder model based on Transformer that ingests both image features and\nmultiple sources of entity labels. We demonstrate that we can learn to control\nthe appearance of these entity labels in the output, resulting in captions that\nare both fluent and informative.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 21:51:48 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Zhao", "Sanqiang", ""], ["Sharma", "Piyush", ""], ["Levinboim", "Tomer", ""], ["Soricut", "Radu", ""]]}, {"id": "1906.08885", "submitter": "Philipp Koehn", "authors": "Vishrav Chaudhary and Yuqing Tang and Francisco Guzm\\'an and Holger\n  Schwenk and Philipp Koehn", "title": "Low-Resource Corpus Filtering using Multilingual Sentence Embeddings", "comments": "6 pages, WMT 2019", "journal-ref": "Conference on Machine Translation (WMT) 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we describe our submission to the WMT19 low-resource parallel\ncorpus filtering shared task. Our main approach is based on the LASER toolkit\n(Language-Agnostic SEntence Representations), which uses an encoder-decoder\narchitecture trained on a parallel corpus to obtain multilingual sentence\nrepresentations. We then use the representations directly to score and filter\nthe noisy parallel sentences without additionally training a scoring function.\nWe contrast our approach to other promising methods and show that LASER yields\nstrong results. Finally, we produce an ensemble of different scoring methods\nand obtain additional gains. Our submission achieved the best overall\nperformance for both the Nepali-English and Sinhala-English 1M tasks by a\nmargin of 1.3 and 1.4 BLEU respectively, as compared to the second best\nsystems. Moreover, our experiments show that this technique is promising for\nlow and even no-resource scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 22:39:44 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Chaudhary", "Vishrav", ""], ["Tang", "Yuqing", ""], ["Guzm\u00e1n", "Francisco", ""], ["Schwenk", "Holger", ""], ["Koehn", "Philipp", ""]]}, {"id": "1906.08911", "submitter": "Vivek Kale PhD", "authors": "Vivek Kale, Christian Iwainsky, Michael Klemm, Jonas H. Muller\n  Korndorfer and Florina M. Ciorba", "title": "Toward a Standard Interface for User-Defined Scheduling in OpenMP", "comments": "16 pages with references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CL cs.PF cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parallel loops are an important part of OpenMP programs. Efficient scheduling\nof parallel loops can improve performance of the programs. The current OpenMP\nspecification only offers three options for loop scheduling, which are\ninsufficient in certain instances. Given the large number of other possible\nscheduling strategies, it is infeasible to standardize each one. A more viable\napproach is to extend the OpenMP standard to allow for users to define loop\nscheduling strategies. The approach will enable standard-compliant\napplication-specific scheduling. This work analyzes the principal components\nrequired by user-defined scheduling and proposes two competing interfaces as\ncandidates for the OpenMP standard. We conceptually compare the two proposed\ninterfaces with respect to the three host languages of OpenMP, i.e., C, C++,\nand Fortran. These interfaces serve the OpenMP community as a basis for\ndiscussion and prototype implementation for user-defined scheduling.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 01:47:32 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2019 20:29:35 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Kale", "Vivek", ""], ["Iwainsky", "Christian", ""], ["Klemm", "Michael", ""], ["Korndorfer", "Jonas H. Muller", ""], ["Ciorba", "Florina M.", ""]]}, {"id": "1906.08931", "submitter": "Wei Ye", "authors": "Wei Ye, Bo Li, Rui Xie, Zhonghao Sheng, Long Chen, Shikun Zhang", "title": "Exploiting Entity BIO Tag Embeddings and Multi-task Learning for\n  Relation Extraction with Imbalanced Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In practical scenario, relation extraction needs to first identify entity\npairs that have relation and then assign a correct relation class. However, the\nnumber of non-relation entity pairs in context (negative instances) usually far\nexceeds the others (positive instances), which negatively affects a model's\nperformance. To mitigate this problem, we propose a multi-task architecture\nwhich jointly trains a model to perform relation identification with\ncross-entropy loss and relation classification with ranking loss. Meanwhile, we\nobserve that a sentence may have multiple entities and relation mentions, and\nthe patterns in which the entities appear in a sentence may contain useful\nsemantic information that can be utilized to distinguish between positive and\nnegative instances. Thus we further incorporate the embeddings of\ncharacter-wise/word-wise BIO tag from the named entity recognition task into\ncharacter/word embeddings to enrich the input representation. Experiment\nresults show that our proposed approach can significantly improve the\nperformance of a baseline model with more than 10% absolute increase in\nF1-score, and outperform the state-of-the-art models on ACE 2005 Chinese and\nEnglish corpus. Moreover, BIO tag embeddings are particularly effective and can\nbe used to improve other models as well.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 03:25:30 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Ye", "Wei", ""], ["Li", "Bo", ""], ["Xie", "Rui", ""], ["Sheng", "Zhonghao", ""], ["Chen", "Long", ""], ["Zhang", "Shikun", ""]]}, {"id": "1906.08934", "submitter": "Jorge Gustavo Madrid Perez", "authors": "Jorge Madrid, Hugo Jair Escalante, Eduardo Morales", "title": "Meta-learning of textual representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in AutoML has lead to state-of-the-art methods (e.g.,\nAutoSKLearn) that can be readily used by non-experts to approach any supervised\nlearning problem. Whereas these methods are quite effective, they are still\nlimited in the sense that they work for tabular (matrix formatted) data only.\nThis paper describes one step forward in trying to automate the design of\nsupervised learning methods in the context of text mining. We introduce a meta\nlearning methodology for automatically obtaining a representation for text\nmining tasks starting from raw text. We report experiments considering 60\ndifferent textual representations and more than 80 text mining datasets\nassociated to a wide variety of tasks. Experimental results show the proposed\nmethodology is a promising solution to obtain highly effective off the shell\ntext classification pipelines.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 03:39:46 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2019 21:19:49 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Madrid", "Jorge", ""], ["Escalante", "Hugo Jair", ""], ["Morales", "Eduardo", ""]]}, {"id": "1906.08939", "submitter": "Muhao Chen", "authors": "Weijia Shi, Muhao Chen, Yingtao Tian, Kai-Wei Chang", "title": "Learning Bilingual Word Embeddings Using Lexical Definitions", "comments": "ACL 2019 RepL4NLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bilingual word embeddings, which representlexicons of different languages in\na shared em-bedding space, are essential for supporting se-mantic and knowledge\ntransfers in a variety ofcross-lingual NLP tasks. Existing approachesto\ntraining bilingual word embeddings requireoften require pre-defined seed\nlexicons that areexpensive to obtain, or parallel sentences thatcomprise coarse\nand noisy alignment. In con-trast, we propose BilLex that leverages pub-licly\navailable lexical definitions for bilingualword embedding learning. Without the\nneedof predefined seed lexicons, BilLex comprisesa novel word pairing strategy\nto automati-cally identify and propagate the precise fine-grained word\nalignment from lexical defini-tions. We evaluate BilLex in word-level\nandsentence-level translation tasks, which seek tofind the cross-lingual\ncounterparts of wordsand sentences respectively.BilLex signifi-cantly\noutperforms previous embedding meth-ods on both tasks.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 04:14:07 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Shi", "Weijia", ""], ["Chen", "Muhao", ""], ["Tian", "Yingtao", ""], ["Chang", "Kai-Wei", ""]]}, {"id": "1906.08942", "submitter": "Bhavana Dalvi Mishra", "authors": "Xinya Du, Bhavana Dalvi Mishra, Niket Tandon, Antoine Bosselut,\n  Wen-tau Yih, Peter Clark, Claire Cardie", "title": "Be Consistent! Improving Procedural Text Comprehension using Label\n  Consistency", "comments": "NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our goal is procedural text comprehension, namely tracking how the properties\nof entities (e.g., their location) change with time given a procedural text\n(e.g., a paragraph about photosynthesis, a recipe). This task is challenging as\nthe world is changing throughout the text, and despite recent advances, current\nsystems still struggle with this task. Our approach is to leverage the fact\nthat, for many procedural texts, multiple independent descriptions are readily\navailable, and that predictions from them should be consistent (label\nconsistency). We present a new learning framework that leverages label\nconsistency during training, allowing consistency bias to be built into the\nmodel. Evaluation on a standard benchmark dataset for procedural text, ProPara\n(Dalvi et al., 2018), shows that our approach significantly improves prediction\nperformance (F1) over prior state-of-the-art systems.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 04:29:22 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Du", "Xinya", ""], ["Mishra", "Bhavana Dalvi", ""], ["Tandon", "Niket", ""], ["Bosselut", "Antoine", ""], ["Yih", "Wen-tau", ""], ["Clark", "Peter", ""], ["Cardie", "Claire", ""]]}, {"id": "1906.08972", "submitter": "Bidisha Samanta", "authors": "Bidisha Samanta, Sharmila Reddy, Hussain Jagirdar, Niloy Ganguly,\n  Soumen Chakrabarti", "title": "A Deep Generative Model for Code-Switched Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code-switching, the interleaving of two or more languages within a sentence\nor discourse is pervasive in multilingual societies. Accurate language models\nfor code-switched text are critical for NLP tasks. State-of-the-art\ndata-intensive neural language models are difficult to train well from scarce\nlanguage-labeled code-switched text. A potential solution is to use deep\ngenerative models to synthesize large volumes of realistic code-switched text.\nAlthough generative adversarial networks and variational autoencoders can\nsynthesize plausible monolingual text from continuous latent space, they cannot\nadequately address code-switched text, owing to their informal style and\ncomplex interplay between the constituent languages. We introduce VACS, a novel\nvariational autoencoder architecture specifically tailored to code-switching\nphenomena. VACS encodes to and decodes from a two-level hierarchical\nrepresentation, which models syntactic contextual signals in the lower level,\nand language switching signals in the upper layer. Sampling representations\nfrom the prior and decoding them produced well-formed, diverse code-switched\nsentences. Extensive experiments show that using synthetic code-switched text\nwith natural monolingual data results in significant (33.06%) drop in\nperplexity.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 06:27:17 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Samanta", "Bidisha", ""], ["Reddy", "Sharmila", ""], ["Jagirdar", "Hussain", ""], ["Ganguly", "Niloy", ""], ["Chakrabarti", "Soumen", ""]]}, {"id": "1906.08976", "submitter": "Tony Sun", "authors": "Tony Sun, Andrew Gaut, Shirlyn Tang, Yuxin Huang, Mai ElSherief, Jieyu\n  Zhao, Diba Mirza, Elizabeth Belding, Kai-Wei Chang, William Yang Wang", "title": "Mitigating Gender Bias in Natural Language Processing: Literature Review", "comments": "Accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As Natural Language Processing (NLP) and Machine Learning (ML) tools rise in\npopularity, it becomes increasingly vital to recognize the role they play in\nshaping societal biases and stereotypes. Although NLP models have shown success\nin modeling various applications, they propagate and may even amplify gender\nbias found in text corpora. While the study of bias in artificial intelligence\nis not new, methods to mitigate gender bias in NLP are relatively nascent. In\nthis paper, we review contemporary studies on recognizing and mitigating gender\nbias in NLP. We discuss gender bias based on four forms of representation bias\nand analyze methods recognizing gender bias. Furthermore, we discuss the\nadvantages and drawbacks of existing gender debiasing methods. Finally, we\ndiscuss future studies for recognizing and mitigating gender bias in NLP.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 06:39:11 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Sun", "Tony", ""], ["Gaut", "Andrew", ""], ["Tang", "Shirlyn", ""], ["Huang", "Yuxin", ""], ["ElSherief", "Mai", ""], ["Zhao", "Jieyu", ""], ["Mirza", "Diba", ""], ["Belding", "Elizabeth", ""], ["Chang", "Kai-Wei", ""], ["Wang", "William Yang", ""]]}, {"id": "1906.08990", "submitter": "Kurt Stockinger", "authors": "Katrin Affolter, Kurt Stockinger, Abraham Bernstein", "title": "A Comparative Survey of Recent Natural Language Interfaces for Databases", "comments": null, "journal-ref": "VLDB Journal 2019", "doi": "10.1007/s00778-019-00567-8", "report-no": null, "categories": "cs.DB cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Over the last few years natural language interfaces (NLI) for databases have\ngained significant traction both in academia and industry. These systems use\nvery different approaches as described in recent survey papers. However, these\nsystems have not been systematically compared against a set of benchmark\nquestions in order to rigorously evaluate their functionalities and expressive\npower.\n  In this paper, we give an overview over 24 recently developed NLIs for\ndatabases. Each of the systems is evaluated using a curated list of ten sample\nquestions to show their strengths and weaknesses. We categorize the NLIs into\nfour groups based on the methodology they are using: keyword-, pattern-,\nparsing-, and grammar-based NLI. Overall, we learned that keyword-based systems\nare enough to answer simple questions. To solve more complex questions\ninvolving subqueries, the system needs to apply some sort of parsing to\nidentify structural dependencies. Grammar-based systems are overall the most\npowerful ones, but are highly dependent on their manually designed rules. In\naddition to providing a systematic analysis of the major systems, we derive\nlessons learned that are vital for designing NLIs that can answer a wide range\nof user questions.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 07:49:36 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Affolter", "Katrin", ""], ["Stockinger", "Kurt", ""], ["Bernstein", "Abraham", ""]]}, {"id": "1906.08996", "submitter": "Miguel Domingo", "authors": "Miguel Domingo and Mercedes Garc\\'ia-Mart\\'inez and \\'Alvaro Peris and\n  Alexandre Helle and Amando Estela and Laurent Bi\\'e and Francisco Casacuberta\n  and Manuel Herranz", "title": "Incremental Adaptation of NMT for Professional Post-editors: A User\n  Study", "comments": "Accepted for publication in MT Summit 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common use of machine translation in the industry is providing initial\ntranslation hypotheses, which are later supervised and post-edited by a human\nexpert. During this revision process, new bilingual data are continuously\ngenerated. Machine translation systems can benefit from these new data,\nincrementally updating the underlying models under an online learning paradigm.\nWe conducted a user study on this scenario, for a neural machine translation\nsystem. The experimentation was carried out by professional translators, with a\nvast experience in machine translation post-editing. The results showed a\nreduction in the required amount of human effort needed when post-editing the\noutputs of the system, improvements in the translation quality and a positive\nperception of the adaptive system by the users.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 08:10:05 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Domingo", "Miguel", ""], ["Garc\u00eda-Mart\u00ednez", "Mercedes", ""], ["Peris", "\u00c1lvaro", ""], ["Helle", "Alexandre", ""], ["Estela", "Amando", ""], ["Bi\u00e9", "Laurent", ""], ["Casacuberta", "Francisco", ""], ["Herranz", "Manuel", ""]]}, {"id": "1906.09000", "submitter": "Miguel Domingo", "authors": "Miguel Domingo and Mercedes Garc\\'ia-Mart\\'inez and Amando Estela and\n  Laurent Bi\\'e and Alexandre Helle and \\'Alvaro Peris and Francisco\n  Casacuberta and Manuerl Herranz", "title": "Demonstration of a Neural Machine Translation System with Online\n  Learning for Translators", "comments": "Accepted for publication in ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a demonstration of our system, which implements online learning\nfor neural machine translation in a production environment. These techniques\nallow the system to continuously learn from the corrections provided by the\ntranslators. We implemented an end-to-end platform integrating our machine\ntranslation servers to one of the most common user interfaces for professional\ntranslators: SDL Trados Studio. Our objective was to save post-editing effort\nas the machine is continuously learning from human choices and adapting the\nmodels to a specific domain or user style.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 08:19:49 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Domingo", "Miguel", ""], ["Garc\u00eda-Mart\u00ednez", "Mercedes", ""], ["Estela", "Amando", ""], ["Bi\u00e9", "Laurent", ""], ["Helle", "Alexandre", ""], ["Peris", "\u00c1lvaro", ""], ["Casacuberta", "Francisco", ""], ["Herranz", "Manuerl", ""]]}, {"id": "1906.09246", "submitter": "Jind\\v{r}ich Helcl", "authors": "Jind\\v{r}ich Helcl, Jind\\v{r}ich Libovick\\'y, Martin Popel", "title": "CUNI System for the WMT19 Robustness Task", "comments": "WMT19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present our submission to the WMT19 Robustness Task. Our baseline system\nis the Charles University (CUNI) Transformer system trained for the WMT18\nshared task on News Translation. Quantitative results show that the CUNI\nTransformer system is already far more robust to noisy input than the\nLSTM-based baseline provided by the task organizers. We further improved the\nperformance of our model by fine-tuning on the in-domain noisy data without\ninfluencing the translation quality on the news domain.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 17:11:46 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Helcl", "Jind\u0159ich", ""], ["Libovick\u00fd", "Jind\u0159ich", ""], ["Popel", "Martin", ""]]}, {"id": "1906.09266", "submitter": "Keegan Hines E", "authors": "Mohammad Reza Sarshogh, Keegan E. Hines", "title": "A Multitask Network for Localization and Recognition of Text in Images", "comments": "ICDAR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an end-to-end trainable multi-task network that addresses the\nproblem of lexicon-free text extraction from complex documents. This network\nsimultaneously solves the problems of text localization and text recognition\nand text segments are identified with no post-processing, cropping, or word\ngrouping. A convolutional backbone and Feature Pyramid Network are combined to\nprovide a shared representation that benefits each of three model heads: text\nlocalization, classification, and text recognition. To improve recognition\naccuracy, we describe a dynamic pooling mechanism that retains high-resolution\ninformation across all RoIs. For text recognition, we propose a convolutional\nmechanism with attention which out-performs more common recurrent\narchitectures. Our model is evaluated against benchmark datasets and comparable\nmethods and achieves high performance in challenging regimes of non-traditional\nOCR.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 17:25:45 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Sarshogh", "Mohammad Reza", ""], ["Hines", "Keegan E.", ""]]}, {"id": "1906.09285", "submitter": "Zhen Wang", "authors": "Zhen Wang, Xiang Yue, Soheil Moosavinasab, Yungui Huang, Simon Lin,\n  Huan Sun", "title": "SurfCon: Synonym Discovery on Privacy-Aware Clinical Data", "comments": "KDD 2019 (Accepted for Oral Presentation at the Research track)", "journal-ref": null, "doi": "10.1145/3292500.3330894", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unstructured clinical texts contain rich health-related information. To\nbetter utilize the knowledge buried in clinical texts, discovering synonyms for\na medical query term has become an important task. Recent automatic synonym\ndiscovery methods leveraging raw text information have been developed. However,\nto preserve patient privacy and security, it is usually quite difficult to get\naccess to large-scale raw clinical texts. In this paper, we study a new setting\nnamed synonym discovery on privacy-aware clinical data (i.e., medical terms\nextracted from the clinical texts and their aggregated co-occurrence counts,\nwithout raw clinical texts). To solve the problem, we propose a new framework\nSurfCon that leverages two important types of information in the privacy-aware\nclinical data, i.e., the surface form information, and the global context\ninformation for synonym discovery. In particular, the surface form module\nenables us to detect synonyms that look similar while the global context module\nplays a complementary role to discover synonyms that are semantically similar\nbut in different surface forms, and both allow us to deal with the OOV query\nissue (i.e., when the query is not found in the given data). We conduct\nextensive experiments and case studies on publicly available privacy-aware\nclinical data, and show that SurfCon can outperform strong baseline methods by\nlarge margins under various settings.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 18:23:17 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Wang", "Zhen", ""], ["Yue", "Xiang", ""], ["Moosavinasab", "Soheil", ""], ["Huang", "Yungui", ""], ["Lin", "Simon", ""], ["Sun", "Huan", ""]]}, {"id": "1906.09292", "submitter": "Ke Hu", "authors": "Ke Hu, Antoine Bruguier, Tara N. Sainath, Rohit Prabhavalkar, Golan\n  Pundak", "title": "Phoneme-Based Contextualization for Cross-Lingual Speech Recognition in\n  End-to-End Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual automatic speech recognition, i.e., biasing recognition towards a\ngiven context (e.g. user's playlists, or contacts), is challenging in\nend-to-end (E2E) models. Such models maintain a limited number of candidates\nduring beam-search decoding, and have been found to recognize rare named\nentities poorly. The problem is exacerbated when biasing towards proper nouns\nin foreign languages, e.g., geographic location names, which are virtually\nunseen in training and are thus out-of-vocabulary (OOV). While grapheme or\nwordpiece E2E models might have a difficult time spelling OOV words, phonemes\nare more acoustically salient and past work has shown that E2E phoneme models\ncan better predict such words. In this work, we propose an E2E model containing\nboth English wordpieces and phonemes in the modeling space, and perform\ncontextual biasing of foreign words at the phoneme level by mapping\npronunciations of foreign words into similar English phonemes. In experimental\nevaluations, we find that the proposed approach performs 16% better than a\ngrapheme-only biasing model, and 8% better than a wordpiece-only biasing model\non a foreign place name recognition task, with only slight degradation on\nregular English tasks.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 19:04:39 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 16:10:57 GMT"}, {"version": "v3", "created": "Mon, 22 Jul 2019 13:36:27 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Hu", "Ke", ""], ["Bruguier", "Antoine", ""], ["Sainath", "Tara N.", ""], ["Prabhavalkar", "Rohit", ""], ["Pundak", "Golan", ""]]}, {"id": "1906.09302", "submitter": "Dagmar Gromann", "authors": "Xiaoyu Yin, Dagmar Gromann, and Sebastian Rudolph", "title": "Neural Machine Translating from Natural Language to SPARQL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SPARQL is a highly powerful query language for an ever-growing number of\nLinked Data resources and Knowledge Graphs. Using it requires a certain\nfamiliarity with the entities in the domain to be queried as well as expertise\nin the language's syntax and semantics, none of which average human web users\ncan be assumed to possess. To overcome this limitation, automatically\ntranslating natural language questions to SPARQL queries has been a vibrant\nfield of research. However, to this date, the vast success of deep learning\nmethods has not yet been fully propagated to this research problem. This paper\ncontributes to filling this gap by evaluating the utilization of eight\ndifferent Neural Machine Translation (NMT) models for the task of translating\nfrom natural language to the structured query language SPARQL. While\nhighlighting the importance of high-quantity and high-quality datasets, the\nresults show a dominance of a CNN-based architecture with a BLEU score of up to\n98 and accuracy of up to 94%.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 19:34:19 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Yin", "Xiaoyu", ""], ["Gromann", "Dagmar", ""], ["Rudolph", "Sebastian", ""]]}, {"id": "1906.09308", "submitter": "Asma Ghandeharioun", "authors": "Asma Ghandeharioun, Judy Hanwen Shen, Natasha Jaques, Craig Ferguson,\n  Noah Jones, Agata Lapedriza, Rosalind Picard", "title": "Approximating Interactive Human Evaluation with Self-Play for\n  Open-Domain Dialog Systems", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building an open-domain conversational agent is a challenging problem.\nCurrent evaluation methods, mostly post-hoc judgments of static conversation,\ndo not capture conversation quality in a realistic interactive context. In this\npaper, we investigate interactive human evaluation and provide evidence for its\nnecessity; we then introduce a novel, model-agnostic, and dataset-agnostic\nmethod to approximate it. In particular, we propose a self-play scenario where\nthe dialog system talks to itself and we calculate a combination of proxies\nsuch as sentiment and semantic coherence on the conversation trajectory. We\nshow that this metric is capable of capturing the human-rated quality of a\ndialog model better than any automated metric known to-date, achieving a\nsignificant Pearson correlation (r>.7, p<.05). To investigate the strengths of\nthis novel metric and interactive evaluation in comparison to state-of-the-art\nmetrics and human evaluation of static conversations, we perform extended\nexperiments with a set of models, including several that make novel\nimprovements to recent hierarchical dialog generation architectures through\nsentiment and semantic knowledge distillation on the utterance level. Finally,\nwe open-source the interactive evaluation platform we built and the dataset we\ncollected to allow researchers to efficiently deploy and evaluate dialog\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 20:08:18 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 01:47:34 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Ghandeharioun", "Asma", ""], ["Shen", "Judy Hanwen", ""], ["Jaques", "Natasha", ""], ["Ferguson", "Craig", ""], ["Jones", "Noah", ""], ["Lapedriza", "Agata", ""], ["Picard", "Rosalind", ""]]}, {"id": "1906.09310", "submitter": "Layla El Asri", "authors": "Layla El Asri and Adam Trischler", "title": "A Study of State Aliasing in Structured Prediction with RNNs", "comments": "Deep Reinforcement Learning Meets Structured Prediction workshop at\n  ICLR 2019 and Representation Learning for NLP workshop at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end reinforcement learning agents learn a state representation and a\npolicy at the same time. Recurrent neural networks (RNNs) have been trained\nsuccessfully as reinforcement learning agents in settings like dialogue that\nrequire structured prediction. In this paper, we investigate the\nrepresentations learned by RNN-based agents when trained with both policy\ngradient and value-based methods. We show through extensive experiments and\nanalysis that, when trained with policy gradient, recurrent neural networks\noften fail to learn a state representation that leads to an optimal policy in\nsettings where the same action should be taken at different states. To explain\nthis failure, we highlight the problem of state aliasing, which entails\nconflating two or more distinct states in the representation space. We\ndemonstrate that state aliasing occurs when several states share the same\noptimal action and the agent is trained via policy gradient. We characterize\nthis phenomenon through experiments on a simple maze setting and a more complex\ntext-based game, and make recommendations for training RNNs with reinforcement\nlearning.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 20:16:52 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Asri", "Layla El", ""], ["Trischler", "Adam", ""]]}, {"id": "1906.09317", "submitter": "Yufang Hou", "authors": "Yufang Hou, Charles Jochim, Martin Gleize, Francesca Bonin and Debasis\n  Ganguly", "title": "Identification of Tasks, Datasets, Evaluation Metrics, and Numeric\n  Scores for Scientific Leaderboards Construction", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the fast-paced inception of novel tasks and new datasets helps foster\nactive research in a community towards interesting directions, keeping track of\nthe abundance of research activity in different areas on different datasets is\nlikely to become increasingly difficult. The community could greatly benefit\nfrom an automatic system able to summarize scientific results, e.g., in the\nform of a leaderboard. In this paper we build two datasets and develop a\nframework (TDMS-IE) aimed at automatically extracting task, dataset, metric and\nscore from NLP papers, towards the automatic construction of leaderboards.\nExperiments show that our model outperforms several baselines by a large\nmargin. Our model is a first step towards automatic leaderboard construction,\ne.g., in the NLP domain.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 20:55:57 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Hou", "Yufang", ""], ["Jochim", "Charles", ""], ["Gleize", "Martin", ""], ["Bonin", "Francesca", ""], ["Ganguly", "Debasis", ""]]}, {"id": "1906.09320", "submitter": "Xue Mengge", "authors": "Mengge Xue, Weiming Cai, Jinsong Su, Linfeng Song, Yubin Ge, Yubao Liu\n  and Bin Wang", "title": "Neural Collective Entity Linking Based on Recurrent Random Walk Network\n  Learning", "comments": null, "journal-ref": "IJCAI 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Benefiting from the excellent ability of neural networks on learning semantic\nrepresentations, existing studies for entity linking (EL) have resorted to\nneural networks to exploit both the local mention-to-entity compatibility and\nthe global interdependence between different EL decisions for target entity\ndisambiguation. However, most neural collective EL methods depend entirely upon\nneural networks to automatically model the semantic dependencies between\ndifferent EL decisions, which lack of the guidance from external knowledge. In\nthis paper, we propose a novel end-to-end neural network with recurrent\nrandom-walk layers for collective EL, which introduces external knowledge to\nmodel the semantic interdependence between different EL decisions.\nSpecifically, we first establish a model based on local context features, and\nthen stack random-walk layers to reinforce the evidence for related EL\ndecisions into high-probability decisions, where the semantic interdependence\nbetween candidate entities is mainly induced from an external knowledge base.\nFinally, a semantic regularizer that preserves the collective EL decisions\nconsistency is incorporated into the conventional objective function, so that\nthe external knowledge base can be fully exploited in collective EL decisions.\nExperimental results and in-depth analysis on various datasets show that our\nmodel achieves better performance than other state-of-the-art models. Our code\nand data are released at \\url{https://github.com/DeepLearnXMU/RRWEL}.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 11:09:12 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Xue", "Mengge", ""], ["Cai", "Weiming", ""], ["Su", "Jinsong", ""], ["Song", "Linfeng", ""], ["Ge", "Yubin", ""], ["Liu", "Yubao", ""], ["Wang", "Bin", ""]]}, {"id": "1906.09321", "submitter": "Jie Wang", "authors": "Haoshen Fan, Jie Wang, Bojin Zhuang, Shaojun Wang and Jing Xiao", "title": "Automatic Acrostic Couplet Generation with Three-Stage Neural Network\n  Pipelines", "comments": "accepted by The 16th Pacific Rim International Conference on AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As one of the quintessence of Chinese traditional culture, couplet\ncompromises two syntactically symmetric clauses equal in length, namely, an\nantecedent and subsequent clause. Moreover, corresponding characters and\nphrases at the same position of the two clauses are paired with each other\nunder certain constraints of semantic and/or syntactic relatedness. Automatic\ncouplet generation is recognized as a challenging problem even in the\nArtificial Intelligence field. In this paper, we comprehensively study on\nautomatic generation of acrostic couplet with the first characters defined by\nusers. The complete couplet generation is mainly divided into three stages,\nthat is, antecedent clause generation pipeline, subsequent clause generation\npipeline and clause re-ranker. To realize semantic and/or syntactic relatedness\nbetween two clauses, attention-based Sequence-to-Sequence (S2S) neural network\nis employed. Moreover, to provide diverse couplet candidates for re-ranking, a\ncluster-based beam search approach is incorporated into the S2S network. Both\nBLEU metrics and human judgments have demonstrated the effectiveness of our\nproposed method. Eventually, a mini-program based on this generation system is\ndeveloped and deployed on Wechat for real users.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 06:47:16 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Fan", "Haoshen", ""], ["Wang", "Jie", ""], ["Zhuang", "Bojin", ""], ["Wang", "Shaojun", ""], ["Xiao", "Jing", ""]]}, {"id": "1906.09322", "submitter": "Jie Wang", "authors": "Xu Lu, Jie Wang, Bojin Zhuang, Shaojun Wang and Jing Xiao", "title": "A Syllable-Structured, Contextually-Based Conditionally Generation of\n  Chinese Lyrics", "comments": "accepted by The 16th Pacific Rim International Conference on AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel, syllable-structured Chinese lyrics generation\nmodel given a piece of original melody. Most previously reported lyrics\ngeneration models fail to include the relationship between lyrics and melody.\nIn this work, we propose to interpret lyrics-melody alignments as syllable\nstructural information and use a multi-channel sequence-to-sequence model with\nconsidering both phrasal structures and semantics. Two different RNN encoders\nare applied, one of which is for encoding syllable structures while the other\nfor semantic encoding with contextual sentences or input keywords. Moreover, a\nlarge Chinese lyrics corpus for model training is leveraged. With automatic and\nhuman evaluations, results demonstrate the effectiveness of our proposed lyrics\ngeneration model. To the best of our knowledge, there is few previous reports\non lyrics generation considering both music and linguistic perspectives.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 09:09:12 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Lu", "Xu", ""], ["Wang", "Jie", ""], ["Zhuang", "Bojin", ""], ["Wang", "Shaojun", ""], ["Xiao", "Jing", ""]]}, {"id": "1906.09324", "submitter": "Jie Wang", "authors": "Ziwen Wang, Jie Wang, Haiqian Gu, Fei Su and Bojin Zhuang", "title": "Automatic Conditional Generation of Personalized Social Media Short\n  Texts", "comments": "published in PRICAI 2018", "journal-ref": "In: Geng X., Kang BH. (eds) PRICAI 2018: Trends in Artificial\n  Intelligence", "doi": "10.1007/978-3-319-97310-4_7", "report-no": null, "categories": "cs.CL cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic text generation has received much attention owing to rapid\ndevelopment of deep neural networks. In general, text generation systems based\non statistical language model will not consider anthropomorphic\ncharacteristics, which results in machine-like generated texts. To fill the\ngap, we propose a conditional language generation model with Big Five\nPersonality (BFP) feature vectors as input context, which writes human-like\nshort texts. The short text generator consists of a layer of long short memory\nnetwork (LSTM), where a BFP feature vector is concatenated as one part of input\nfor each cell. To enable supervised training generation model, a text\nclassification model based convolution neural network (CNN) has been used to\nprepare BFP-tagged Chinese micro-blog corpora. Validated by a BFP linguistic\ncomputational model, our generated Chinese short texts exhibit discriminative\npersonality styles, which are also syntactically correct and semantically\nsmooth with appropriate emoticons. With combination of natural language\ngeneration with psychological linguistics, our proposed BFP-dependent text\ngeneration model can be widely used for individualization in machine\ntranslation, image caption, dialogue generation and so on.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 09:20:41 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Wang", "Ziwen", ""], ["Wang", "Jie", ""], ["Gu", "Haiqian", ""], ["Su", "Fei", ""], ["Zhuang", "Bojin", ""]]}, {"id": "1906.09325", "submitter": "Tomek Korbak", "authors": "Renard Korzeniowski and Rafa{\\l} Rolczy\\'nski and Przemys{\\l}aw\n  Sadownik and Tomasz Korbak and Marcin Mo\\.zejko", "title": "Exploiting Unsupervised Pre-training and Automated Feature Engineering\n  for Low-resource Hate Speech Detection in Polish", "comments": "http://poleval.pl/publication", "journal-ref": "Proceedings of the PolEval 2019 Workshop", "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents our contribution to PolEval 2019 Task 6: Hate speech and\nbullying detection. We describe three parallel approaches that we followed:\nfine-tuning a pre-trained ULMFiT model to our classification task, fine-tuning\na pre-trained BERT model to our classification task, and using the TPOT library\nto find the optimal pipeline. We present results achieved by these three tools\nand review their advantages and disadvantages in terms of user experience. Our\nteam placed second in subtask 2 with a shallow model found by TPOT: a~logistic\nregression classifier with non-trivial feature engineering.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 13:11:26 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Korzeniowski", "Renard", ""], ["Rolczy\u0144ski", "Rafa\u0142", ""], ["Sadownik", "Przemys\u0142aw", ""], ["Korbak", "Tomasz", ""], ["Mo\u017cejko", "Marcin", ""]]}, {"id": "1906.09379", "submitter": "Kumiko Tanaka-Ishii", "authors": "Shuntaro Takahashi and Kumiko Tanaka-Ishii", "title": "Evaluating Computational Language Models with Scaling Properties of\n  Natural Language", "comments": "32 pages, accepted by Computational Linguistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this article, we evaluate computational models of natural language with\nrespect to the universal statistical behaviors of natural language. Statistical\nmechanical analyses have revealed that natural language text is characterized\nby scaling properties, which quantify the global structure in the vocabulary\npopulation and the long memory of a text. We study whether five scaling\nproperties (given by Zipf's law, Heaps' law, Ebeling's method, Taylor's law,\nand long-range correlation analysis) can serve for evaluation of computational\nmodels. Specifically, we test $n$-gram language models, a probabilistic\ncontext-free grammar (PCFG), language models based on Simon/Pitman-Yor\nprocesses, neural language models, and generative adversarial networks (GANs)\nfor text generation. Our analysis reveals that language models based on\nrecurrent neural networks (RNNs) with a gating mechanism (i.e., long short-term\nmemory, LSTM; a gated recurrent unit, GRU; and quasi-recurrent neural networks,\nQRNNs) are the only computational models that can reproduce the long memory\nbehavior of natural language. Furthermore, through comparison with recently\nproposed model-based evaluation methods, we find that the exponent of Taylor's\nlaw is a good indicator of model quality.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 03:24:32 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Takahashi", "Shuntaro", ""], ["Tanaka-Ishii", "Kumiko", ""]]}, {"id": "1906.09384", "submitter": "Mayank Agarwal", "authors": "Sohini Upadhyay, Mayank Agarwal, Djallel Bounneffouf, Yasaman Khazaeni", "title": "A Bandit Approach to Posterior Dialog Orchestration Under a Budget", "comments": "2nd Conversational AI Workshop, NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building multi-domain AI agents is a challenging task and an open problem in\nthe area of AI. Within the domain of dialog, the ability to orchestrate\nmultiple independently trained dialog agents, or skills, to create a unified\nsystem is of particular significance. In this work, we study the task of online\nposterior dialog orchestration, where we define posterior orchestration as the\ntask of selecting a subset of skills which most appropriately answer a user\ninput using features extracted from both the user input and the individual\nskills. To account for the various costs associated with extracting skill\nfeatures, we consider online posterior orchestration under a skill execution\nbudget. We formalize this setting as Context Attentive Bandit with Observations\n(CABO), a variant of context attentive bandits, and evaluate it on simulated\nnon-conversational and proprietary conversational datasets.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 04:02:26 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Upadhyay", "Sohini", ""], ["Agarwal", "Mayank", ""], ["Bounneffouf", "Djallel", ""], ["Khazaeni", "Yasaman", ""]]}, {"id": "1906.09404", "submitter": "Yu Sun", "authors": "Chen Zheng, Yu Sun, Shengxian Wan, Dianhai Yu", "title": "RLTM: An Efficient Neural IR Framework for Long Documents", "comments": "Accepted by IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have achieved significant improvements in information\nretrieval (IR). However, most existing models are computational costly and can\nnot efficiently scale to long documents. This paper proposes a novel End-to-End\nneural ranking framework called Reinforced Long Text Matching (RLTM) which\nmatches a query with long documents efficiently and effectively. The core idea\nbehind the framework can be analogous to the human judgment process which\nfirstly locates the relevance parts quickly from the whole document and then\nmatches these parts with the query carefully to obtain the final label.\nFirstly, we select relevant sentences from the long documents by a coarse and\nefficient matching model. Secondly, we generate a relevance score by a more\nsophisticated matching model based on the sentence selected. The whole model is\ntrained jointly with reinforcement learning in a pairwise manner by maximizing\nthe expected score gaps between positive and negative examples. Experimental\nresults demonstrate that RLTM has greatly improved the efficiency and\neffectiveness of the state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 07:32:15 GMT"}, {"version": "v2", "created": "Sun, 11 Aug 2019 01:33:15 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Zheng", "Chen", ""], ["Sun", "Yu", ""], ["Wan", "Shengxian", ""], ["Yu", "Dianhai", ""]]}, {"id": "1906.09426", "submitter": "Brij Mohan Lal Srivastava", "authors": "Brij Mohan Lal Srivastava, Basil Abraham, Sunayana Sitaram, Rupesh\n  Mehta, Preethi Jyothi", "title": "End-to-End ASR for Code-switched Hindi-English Speech", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end (E2E) models have been explored for large speech corpora and have\nbeen found to match or outperform traditional pipeline-based systems in some\nlanguages. However, most prior work on end-to-end models use speech corpora\nexceeding hundreds or thousands of hours. In this study, we explore end-to-end\nmodels for code-switched Hindi-English language with less than 50 hours of\ndata. We utilize two specific measures to improve network performance in the\nlow-resource setting, namely multi-task learning (MTL) and balancing the corpus\nto deal with the inherent class imbalance problem i.e. the skewed frequency\ndistribution over graphemes. We compare the results of the proposed approaches\nwith traditional, cascaded ASR systems. While the lack of data adversely\naffects the performance of end-to-end models, we see promising improvements\nwith MTL and balancing the corpus.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 10:23:42 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Srivastava", "Brij Mohan Lal", ""], ["Abraham", "Basil", ""], ["Sitaram", "Sunayana", ""], ["Mehta", "Rupesh", ""], ["Jyothi", "Preethi", ""]]}, {"id": "1906.09444", "submitter": "Chenze Shao", "authors": "Chenze Shao, Yang Feng, Jinchao Zhang, Fandong Meng, Xilin Chen and\n  Jie Zhou", "title": "Retrieving Sequential Information for Non-Autoregressive Neural Machine\n  Translation", "comments": "12 pages, 4 figures, ACL 2019 long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-Autoregressive Transformer (NAT) aims to accelerate the Transformer model\nthrough discarding the autoregressive mechanism and generating target words\nindependently, which fails to exploit the target sequential information.\nOver-translation and under-translation errors often occur for the above reason,\nespecially in the long sentence translation scenario. In this paper, we propose\ntwo approaches to retrieve the target sequential information for NAT to enhance\nits translation ability while preserving the fast-decoding property. Firstly,\nwe propose a sequence-level training method based on a novel reinforcement\nalgorithm for NAT (Reinforce-NAT) to reduce the variance and stabilize the\ntraining procedure. Secondly, we propose an innovative Transformer decoder\nnamed FS-decoder to fuse the target sequential information into the top layer\nof the decoder. Experimental results on three translation tasks show that the\nReinforce-NAT surpasses the baseline NAT system by a significant margin on BLEU\nwithout decelerating the decoding speed and the FS-decoder achieves comparable\ntranslation performance to the autoregressive Transformer with considerable\nspeedup.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 13:20:57 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Shao", "Chenze", ""], ["Feng", "Yang", ""], ["Zhang", "Jinchao", ""], ["Meng", "Fandong", ""], ["Chen", "Xilin", ""], ["Zhou", "Jie", ""]]}, {"id": "1906.09445", "submitter": "Hadrien Van Lierde", "authors": "Hadrien Van Lierde and Tommy W. S. Chow", "title": "Learning with fuzzy hypergraphs: a topical approach to query-oriented\n  text summarization", "comments": "8 figures", "journal-ref": "Information Sciences, 496 (2019), 212-224", "doi": "10.1016/j.ins.2019.05.020", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing graph-based methods for extractive document summarization represent\nsentences of a corpus as the nodes of a graph or a hypergraph in which edges\ndepict relationships of lexical similarity between sentences. Such approaches\nfail to capture semantic similarities between sentences when they express a\nsimilar information but have few words in common and are thus lexically\ndissimilar. To overcome this issue, we propose to extract semantic similarities\nbased on topical representations of sentences. Inspired by the Hierarchical\nDirichlet Process, we propose a probabilistic topic model in order to infer\ntopic distributions of sentences. As each topic defines a semantic connection\namong a group of sentences with a certain degree of membership for each\nsentence, we propose a fuzzy hypergraph model in which nodes are sentences and\nfuzzy hyperedges are topics. To produce an informative summary, we extract a\nset of sentences from the corpus by simultaneously maximizing their relevance\nto a user-defined query, their centrality in the fuzzy hypergraph and their\ncoverage of topics present in the corpus. We formulate a polynomial time\nalgorithm building on the theory of submodular functions to solve the\nassociated optimization problem. A thorough comparative analysis with other\ngraph-based summarization systems is included in the paper. Our obtained\nresults show the superiority of our method in terms of content coverage of the\nsummaries.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 13:28:32 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Van Lierde", "Hadrien", ""], ["Chow", "Tommy W. S.", ""]]}, {"id": "1906.09450", "submitter": "Mohamed Yahya", "authors": "Konstantine Arkoudas and Mohamed Yahya", "title": "Semantically Driven Auto-completion", "comments": "12 pages, under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Bloomberg Terminal has been a leading source of financial data and\nanalytics for over 30 years. Through its thousands of functions, the Terminal\nallows its users to query and run analytics over a large array of data sources,\nincluding structured, semi-structured, and unstructured data; as well as plot\ncharts, set up event-driven alerts and triggers, create interactive maps,\nexchange information via instant and email-style messages, and so on. To\nimprove user experience, we have been building question answering systems that\ncan understand a wide range of natural language constructions for various\ndomains that are of fundamental interest to our users. Such natural language\ninterfaces, while exceedingly helpful to users, introduce a number of usability\nchallenges of their own. We tackle some of these challenges through\nauto-completion for query formulation. A distinguishing mark of our\nauto-complete systems is that they are based on and guided by corresponding\nsemantic parsing systems. We describe the auto-complete problem as it arises in\nthis setting, the novel algorithms that we use to solve it, and report on the\nquality of the results and the efficiency of our approach.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 14:02:14 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Arkoudas", "Konstantine", ""], ["Yahya", "Mohamed", ""]]}, {"id": "1906.09532", "submitter": "Mingda Chen", "authors": "Mingda Chen, Kevin Gimpel", "title": "Smaller Text Classifiers with Discriminative Cluster Embeddings", "comments": "Appeared in NAACL 2018 short", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embedding parameters often dominate overall model sizes in neural\nmethods for natural language processing. We reduce deployed model sizes of text\nclassifiers by learning a hard word clustering in an end-to-end manner. We use\nthe Gumbel-Softmax distribution to maximize over the latent clustering while\nminimizing the task loss. We propose variations that selectively assign\nadditional parameters to words, which further improves accuracy while still\nremaining parameter-efficient.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 02:00:40 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Chen", "Mingda", ""], ["Gimpel", "Kevin", ""]]}, {"id": "1906.09535", "submitter": "Mingda Chen", "authors": "Mingda Chen, Qingming Tang, Karen Livescu, Kevin Gimpel", "title": "Variational Sequential Labelers for Semi-Supervised Learning", "comments": "Appeared in EMNLP 2018 Long", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a family of multitask variational methods for semi-supervised\nsequence labeling. Our model family consists of a latent-variable generative\nmodel and a discriminative labeler. The generative models use latent variables\nto define the conditional probability of a word given its context, drawing\ninspiration from word prediction objectives commonly used in learning word\nembeddings. The labeler helps inject discriminative information into the latent\nspace. We explore several latent variable configurations, including ones with\nhierarchical structure, which enables the model to account for both\nlabel-specific and word-specific information. Our models consistently\noutperform standard sequential baselines on 8 sequence labeling datasets, and\nimprove further with unlabeled data.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 02:17:46 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Chen", "Mingda", ""], ["Tang", "Qingming", ""], ["Livescu", "Karen", ""], ["Gimpel", "Kevin", ""]]}, {"id": "1906.09543", "submitter": "Jun Jiang", "authors": "Jun Jiang, Shumao Pang, Xia Zhao, Liwei Wang, Andrew Wen, Hongfang\n  Liu, Qianjin Feng", "title": "Cross-lingual Data Transformation and Combination for Text\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Text classification is a fundamental task for text data mining. In order to\ntrain a generalizable model, a large volume of text must be collected. To\naddress data insufficiency, cross-lingual data may occasionally be necessary.\nCross-lingual data sources may however suffer from data incompatibility, as\ntext written in different languages can hold distinct word sequences and\nsemantic patterns. Machine translation and word embedding alignment provide an\neffective way to transform and combine data for cross-lingual data training. To\nthe best of our knowledge, there has been little work done on evaluating how\nthe methodology used to conduct semantic space transformation and data\ncombination affects the performance of classification models trained from\ncross-lingual resources. In this paper, we systematically evaluated the\nperformance of two commonly used CNN (Convolutional Neural Network) and RNN\n(Recurrent Neural Network) text classifiers with differing data transformation\nand combination strategies. Monolingual models were trained from English and\nFrench alongside their translated and aligned embeddings. Our results suggested\nthat semantic space transformation may conditionally promote the performance of\nmonolingual models. Bilingual models were trained from a combination of both\nEnglish and French. Our results indicate that a cross-lingual classification\nmodel can significantly benefit from cross-lingual data by learning from\ntranslated or aligned embedding spaces.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 02:56:02 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Jiang", "Jun", ""], ["Pang", "Shumao", ""], ["Zhao", "Xia", ""], ["Wang", "Liwei", ""], ["Wen", "Andrew", ""], ["Liu", "Hongfang", ""], ["Feng", "Qianjin", ""]]}, {"id": "1906.09556", "submitter": "Shaobo Cui", "authors": "Shaobo Cui, Rongzhong Lian, Di Jiang, Yuanfeng Song, Siqi Bao, Yong\n  Jiang", "title": "DAL: Dual Adversarial Learning for Dialogue Generation", "comments": "10 pages, published on NeuralGen workshop at NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In open-domain dialogue systems, generative approaches have attracted much\nattention for response generation. However, existing methods are heavily\nplagued by generating safe responses and unnatural responses. To alleviate\nthese two problems, we propose a novel framework named Dual Adversarial\nLearning (DAL) for high-quality response generation. DAL is the first work to\ninnovatively utilizes the duality between query generation and response\ngeneration to avoid safe responses and increase the diversity of the generated\nresponses. Additionally, DAL uses adversarial learning to mimic human judges\nand guides the system to generate natural responses. Experimental results\ndemonstrate that DAL effectively improves both diversity and overall quality of\nthe generated responses. DAL outperforms the state-of-the-art methods regarding\nautomatic metrics and human evaluations.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 05:28:03 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Cui", "Shaobo", ""], ["Lian", "Rongzhong", ""], ["Jiang", "Di", ""], ["Song", "Yuanfeng", ""], ["Bao", "Siqi", ""], ["Jiang", "Yong", ""]]}, {"id": "1906.09569", "submitter": "Nim Dvir Mr.", "authors": "Nim Dvir, Ruti Gafni", "title": "Systematic improvement of user engagement with academic titles using\n  computational linguistics", "comments": "Dvir, N., & Gafni, R. (2019). Systematic improvement of user\n  engagement with academic titles using computational linguistics. Proceedings\n  of the Informing Science and Information Technology Education Conference,\n  Jerusalem, Israel, pp. 501-512 Santa Rosa, CA: Informing Science Institute.\n  https://doi.org/10.28945/4338", "journal-ref": null, "doi": "10.28945/4338", "report-no": null, "categories": "cs.CL cs.DL cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes a novel approach to systematically improve information\ninteractions based solely on its wording. Following an interdisciplinary\nliterature review, we recognized three key attributes of words that drive user\nengagement: (1) Novelty (2) Familiarity (3) Emotionality. Based on these\nattributes, we developed a model to systematically improve a given content\nusing computational linguistics, natural language processing (NLP) and text\nanalysis (word frequency, sentiment analysis and lexical substitution). We\nconducted a pilot study (n=216) in which the model was used to formalize\nevaluation and optimization of academic titles. A between-group design (A/B\ntesting) was used to compare responses to the original and modified (treatment)\ntitles. Data was collected for selection and evaluation (User Engagement\nScale). The pilot results suggest that user engagement with digital information\nis fostered by, and perhaps dependent upon, the wording being used. They also\nprovide empirical support that engaging content can be systematically evaluated\nand produced. The preliminary results show that the modified (treatment) titles\nhad significantly higher scores for information use and user engagement\n(selection and evaluation). We propose that computational linguistics is a\nuseful approach for optimizing information interactions. The empirically based\ninsights can inform the development of digital content strategies, thereby\nimproving the success of information interactions.elop more sophisticated\ninteraction measures.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 09:23:08 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Dvir", "Nim", ""], ["Gafni", "Ruti", ""]]}, {"id": "1906.09601", "submitter": "Long Zhou", "authors": "Long Zhou, Jiajun Zhang, Chengqing Zong, Heng Yu", "title": "Sequence Generation: From Both Sides to the Middle", "comments": "Accepted by IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The encoder-decoder framework has achieved promising process for many\nsequence generation tasks, such as neural machine translation and text\nsummarization. Such a framework usually generates a sequence token by token\nfrom left to right, hence (1) this autoregressive decoding procedure is\ntime-consuming when the output sentence becomes longer, and (2) it lacks the\nguidance of future context which is crucial to avoid under translation. To\nalleviate these issues, we propose a synchronous bidirectional sequence\ngeneration (SBSG) model which predicts its outputs from both sides to the\nmiddle simultaneously. In the SBSG model, we enable the left-to-right (L2R) and\nright-to-left (R2L) generation to help and interact with each other by\nleveraging interactive bidirectional attention network. Experiments on neural\nmachine translation (En-De, Ch-En, and En-Ro) and text summarization tasks show\nthat the proposed model significantly speeds up decoding while improving the\ngeneration quality compared to the autoregressive Transformer.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 16:13:45 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Zhou", "Long", ""], ["Zhang", "Jiajun", ""], ["Zong", "Chengqing", ""], ["Yu", "Heng", ""]]}, {"id": "1906.09635", "submitter": "Shawn Tan", "authors": "Shawn Tan and Yikang Shen and Chin-wei Huang and Aaron Courville", "title": "Investigating Biases in Textual Entailment Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to understand logical relationships between sentences is an\nimportant task in language understanding. To aid in progress for this task,\nresearchers have collected datasets for machine learning and evaluation of\ncurrent systems. However, like in the crowdsourced Visual Question Answering\n(VQA) task, some biases in the data inevitably occur. In our experiments, we\nfind that performing classification on just the hypotheses on the SNLI dataset\nyields an accuracy of 64%. We analyze the bias extent in the SNLI and the\nMultiNLI dataset, discuss its implication, and propose a simple method to\nreduce the biases in the datasets.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 19:38:53 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Tan", "Shawn", ""], ["Shen", "Yikang", ""], ["Huang", "Chin-wei", ""], ["Courville", "Aaron", ""]]}, {"id": "1906.09675", "submitter": "Chris Hokamp", "authors": "Chris Hokamp and John Glover and Demian Gholipour", "title": "Evaluating the Supervised and Zero-shot Performance of Multi-lingual\n  Translation Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study several methods for full or partial sharing of the decoder\nparameters of multilingual NMT models. We evaluate both fully supervised and\nzero-shot translation performance in 110 unique translation directions using\nonly the WMT 2019 shared task parallel datasets for training. We use additional\ntest sets and re-purpose evaluation methods recently used for unsupervised MT\nin order to evaluate zero-shot translation performance for language pairs where\nno gold-standard parallel data is available. To our knowledge, this is the\nlargest evaluation of multi-lingual translation yet conducted in terms of the\ntotal size of the training data we use, and in terms of the diversity of\nzero-shot translation pairs we evaluate. We conduct an in-depth evaluation of\nthe translation performance of different models, highlighting the trade-offs\nbetween methods of sharing decoder parameters. We find that models which have\ntask-specific decoder parameters outperform models where decoder parameters are\nfully shared across all tasks.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 00:25:18 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Hokamp", "Chris", ""], ["Glover", "John", ""], ["Gholipour", "Demian", ""]]}, {"id": "1906.09676", "submitter": "Arnold Wiliem", "authors": "Sam Maksoud, Arnold Wiliem, Kun Zhao, Teng Zhang, Lin Wu and Brian C.\n  Lovell", "title": "CORAL8: Concurrent Object Regression for Area Localization in Medical\n  Image Panels", "comments": "Accepted for MICCAI 2019", "journal-ref": null, "doi": "10.1007/978-3-030-32239-7_48", "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work tackles the problem of generating a medical report for multi-image\npanels. We apply our solution to the Renal Direct Immunofluorescence (RDIF)\nassay which requires a pathologist to generate a report based on observations\nacross the eight different WSI in concert with existing clinical features. To\nthis end, we propose a novel attention-based multi-modal generative recurrent\nneural network (RNN) architecture capable of dynamically sampling image data\nconcurrently across the RDIF panel. The proposed methodology incorporates text\nfrom the clinical notes of the requesting physician to regulate the output of\nthe network to align with the overall clinical context. In addition, we found\nthe importance of regularizing the attention weights for word generation\nprocesses. This is because the system can ignore the attention mechanism by\nassigning equal weights for all members. Thus, we propose two regularizations\nwhich force the system to utilize the attention mechanism. Experiments on our\nnovel collection of RDIF WSIs provided by a large clinical laboratory\ndemonstrate that our framework offers significant improvements over existing\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 00:30:32 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Maksoud", "Sam", ""], ["Wiliem", "Arnold", ""], ["Zhao", "Kun", ""], ["Zhang", "Teng", ""], ["Wu", "Lin", ""], ["Lovell", "Brian C.", ""]]}, {"id": "1906.09694", "submitter": "Frank Z. Xing", "authors": "Haodong Bai and Frank Z. Xing and Erik Cambria and Win-Bin Huang", "title": "Business Taxonomy Construction Using Concept-Level Hierarchical\n  Clustering", "comments": "Accepted to The First Workshop on Financial Technology and Natural\n  Language Processing (FinNLP@IJCAI-19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Business taxonomies are indispensable tools for investors to do equity\nresearch and make professional decisions. However, to identify the structure of\nindustry sectors in an emerging market is challenging for two reasons. First,\nexisting taxonomies are designed for mature markets, which may not be the\nappropriate classification for small companies with innovative business models.\nSecond, emerging markets are fast-developing, thus the static business\ntaxonomies cannot promptly reflect the new features. In this article, we\npropose a new method to construct business taxonomies automatically from the\ncontent of corporate annual reports. Extracted concepts are hierarchically\nclustered using greedy affinity propagation. Our method requires less\nsupervision and is able to discover new terms. Experiments and evaluation on\nthe Chinese National Equities Exchange and Quotations (NEEQ) market show\nseveral advantages of the business taxonomy we build. Our results provide an\neffective tool for understanding and investing in the new growth companies.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 02:59:22 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Bai", "Haodong", ""], ["Xing", "Frank Z.", ""], ["Cambria", "Erik", ""], ["Huang", "Win-Bin", ""]]}, {"id": "1906.09719", "submitter": "Yugo Murawaki", "authors": "Yugo Murawaki", "title": "On the Definition of Japanese Word", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The annotation guidelines for Universal Dependencies (UD) stipulate that the\nbasic units of dependency annotation are syntactic words, but it is not clear\nwhat are syntactic words in Japanese. Departing from the long tradition of\nusing phrasal units called bunsetsu for dependency parsing, the current UD\nJapanese treebanks adopt the Short Unit Words. However, we argue that they are\nnot syntactic word as specified by the annotation guidelines. Although we find\nnon-mainstream attempts to linguistically define Japanese words, such\ndefinitions have never been applied to corpus annotation. We discuss the costs\nand benefits of adopting the rather unfamiliar criteria.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 04:46:10 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Murawaki", "Yugo", ""]]}, {"id": "1906.09741", "submitter": "Zichao Li", "authors": "Zichao Li and Xin Jiang and Lifeng Shang and Qun Liu", "title": "Decomposable Neural Paraphrase Generation", "comments": "To appear in ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Paraphrasing exists at different granularity levels, such as lexical level,\nphrasal level and sentential level. This paper presents Decomposable Neural\nParaphrase Generator (DNPG), a Transformer-based model that can learn and\ngenerate paraphrases of a sentence at different levels of granularity in a\ndisentangled way. Specifically, the model is composed of multiple encoders and\ndecoders with different structures, each of which corresponds to a specific\ngranularity. The empirical study shows that the decomposition mechanism of DNPG\nmakes paraphrase generation more interpretable and controllable. Based on DNPG,\nwe further develop an unsupervised domain adaptation method for paraphrase\ngeneration. Experimental results show that the proposed model achieves\ncompetitive in-domain performance compared to the state-of-the-art neural\nmodels, and significantly better performance when adapting to a new domain.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 06:35:36 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Li", "Zichao", ""], ["Jiang", "Xin", ""], ["Shang", "Lifeng", ""], ["Liu", "Qun", ""]]}, {"id": "1906.09774", "submitter": "Endang Wahyu Pamungkas", "authors": "Endang Wahyu Pamungkas", "title": "Emotionally-Aware Chatbots: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Textual conversational agent or chatbots' development gather tremendous\ntraction from both academia and industries in recent years. Nowadays, chatbots\nare widely used as an agent to communicate with a human in some services such\nas booking assistant, customer service, and also a personal partner. The\nbiggest challenge in building chatbot is to build a humanizing machine to\nimprove user engagement. Some studies show that emotion is an important aspect\nto humanize machine, including chatbot. In this paper, we will provide a\nsystematic review of approaches in building an emotionally-aware chatbot (EAC).\nAs far as our knowledge, there is still no work focusing on this area. We\npropose three research question regarding EAC studies. We start with the\nhistory and evolution of EAC, then several approaches to build EAC by previous\nstudies, and some available resources in building EAC. Based on our\ninvestigation, we found that in the early development, EAC exploits a simple\nrule-based approach while now most of EAC use neural-based approach. We also\nnotice that most of EAC contain emotion classifier in their architecture, which\nutilize several available affective resources. We also predict that the\ndevelopment of EAC will continue to gain more and more attention from scholars,\nnoted by some recent studies propose new datasets for building EAC in various\nlanguages.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 08:20:10 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Pamungkas", "Endang Wahyu", ""]]}, {"id": "1906.09777", "submitter": "Xindian Ma", "authors": "Xindian Ma, Peng Zhang, Shuai Zhang, Nan Duan, Yuexian Hou, Dawei\n  Song, Ming Zhou", "title": "A Tensorized Transformer for Language Modeling", "comments": "Accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latest development of neural models has connected the encoder and decoder\nthrough a self-attention mechanism. In particular, Transformer, which is solely\nbased on self-attention, has led to breakthroughs in Natural Language\nProcessing (NLP) tasks. However, the multi-head attention mechanism, as a key\ncomponent of Transformer, limits the effective deployment of the model to a\nresource-limited setting. In this paper, based on the ideas of tensor\ndecomposition and parameters sharing, we propose a novel self-attention model\n(namely Multi-linear attention) with Block-Term Tensor Decomposition (BTD). We\ntest and verify the proposed attention method on three language modeling tasks\n(i.e., PTB, WikiText-103 and One-billion) and a neural machine translation task\n(i.e., WMT-2016 English-German). Multi-linear attention can not only largely\ncompress the model parameters but also obtain performance improvements,\ncompared with a number of language modeling approaches, such as Transformer,\nTransformer-XL, and Transformer with tensor train decomposition.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 08:28:37 GMT"}, {"version": "v2", "created": "Fri, 9 Aug 2019 09:27:41 GMT"}, {"version": "v3", "created": "Wed, 6 Nov 2019 13:53:14 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Ma", "Xindian", ""], ["Zhang", "Peng", ""], ["Zhang", "Shuai", ""], ["Duan", "Nan", ""], ["Hou", "Yuexian", ""], ["Song", "Dawei", ""], ["Zhou", "Ming", ""]]}, {"id": "1906.09795", "submitter": "Shohei Tanaka", "authors": "Shohei Tanaka, Koichiro Yoshino, Katsuhito Sudoh, and Satoshi Nakamura", "title": "Conversational Response Re-ranking Based on Event Causality and Role\n  Factored Tensor Event Embedding", "comments": "Accepted by 1st Workshop NLP for Conversational AI, ACL 2019 Workshop\n  (ConvAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method for selecting coherent and diverse responses for a\ngiven dialogue context. The proposed method re-ranks response candidates\ngenerated from conversational models by using event causality relations between\nevents in a dialogue history and response candidates (e.g., ``be stressed out''\nprecedes ``relieve stress''). We use distributed event representation based on\nthe Role Factored Tensor Model for a robust matching of event causality\nrelations due to limited event causality knowledge of the system. Experimental\nresults showed that the proposed method improved coherency and dialogue\ncontinuity of system responses.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 09:08:29 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Tanaka", "Shohei", ""], ["Yoshino", "Koichiro", ""], ["Sudoh", "Katsuhito", ""], ["Nakamura", "Satoshi", ""]]}, {"id": "1906.09821", "submitter": "Nils Reimers", "authors": "Nils Reimers, Benjamin Schiller, Tilman Beck, Johannes Daxenberger,\n  Christian Stab, Iryna Gurevych", "title": "Classification and Clustering of Arguments with Contextualized Word\n  Embeddings", "comments": "Conference paper at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We experiment with two recent contextualized word embedding methods (ELMo and\nBERT) in the context of open-domain argument search. For the first time, we\nshow how to leverage the power of contextualized word embeddings to classify\nand cluster topic-dependent arguments, achieving impressive results on both\ntasks and across multiple datasets. For argument classification, we improve the\nstate-of-the-art for the UKP Sentential Argument Mining Corpus by 20.8\npercentage points and for the IBM Debater - Evidence Sentences dataset by 7.4\npercentage points. For the understudied task of argument clustering, we propose\na pre-training step which improves by 7.8 percentage points over strong\nbaselines on a novel dataset, and by 12.3 percentage points for the Argument\nFacet Similarity (AFS) Corpus.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 09:55:21 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Reimers", "Nils", ""], ["Schiller", "Benjamin", ""], ["Beck", "Tilman", ""], ["Daxenberger", "Johannes", ""], ["Stab", "Christian", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1906.09825", "submitter": "Okko R\\\"as\\\"anen", "authors": "Shreyas Seshadri, Okko R\\\"as\\\"anen", "title": "SylNet: An Adaptable End-to-End Syllable Count Estimator for Speech", "comments": null, "journal-ref": null, "doi": "10.1109/LSP.2019.2929415", "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic syllable count estimation (SCE) is used in a variety of\napplications ranging from speaking rate estimation to detecting social activity\nfrom wearable microphones or developmental research concerned with quantifying\nspeech heard by language-learning children in different environments. The\nmajority of previously utilized SCE methods have relied on heuristic DSP\nmethods, and only a small number of bi-directional long short-term memory\n(BLSTM) approaches have made use of modern machine learning approaches in the\nSCE task. This paper presents a novel end-to-end method called SylNet for\nautomatic syllable counting from speech, built on the basis of a recent\ndevelopments in neural network architectures. We describe how the entire model\ncan be optimized directly to minimize SCE error on the training data without\nannotations aligned at the syllable level, and how it can be adapted to new\nlanguages using limited speech data with known syllable counts. Experiments on\nseveral different languages reveal that SylNet generalizes to languages beyond\nits training data and further improves with adaptation. It also outperforms\nseveral previously proposed methods for syllabification, including end-to-end\nBLSTMs.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 10:05:23 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Seshadri", "Shreyas", ""], ["R\u00e4s\u00e4nen", "Okko", ""]]}, {"id": "1906.09832", "submitter": "Okko R\\\"as\\\"anen", "authors": "Okko R\\\"as\\\"anen, Khazar Khorrami", "title": "A computational model of early language acquisition from audiovisual\n  experiences of young infants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Earlier research has suggested that human infants might use statistical\ndependencies between speech and non-linguistic multimodal input to bootstrap\ntheir language learning before they know how to segment words from running\nspeech. However, feasibility of this hypothesis in terms of real-world infant\nexperiences has remained unclear. This paper presents a step towards a more\nrealistic test of the multimodal bootstrapping hypothesis by describing a\nneural network model that can learn word segments and their meanings from\nreferentially ambiguous acoustic input. The model is tested on recordings of\nreal infant-caregiver interactions using utterance-level labels for concrete\nvisual objects that were attended by the infant when caregiver spoke an\nutterance containing the name of the object, and using random visual labels for\nutterances during absence of attention. The results show that beginnings of\nlexical knowledge may indeed emerge from individually ambiguous learning\nscenarios. In addition, the hidden layers of the network show gradually\nincreasing selectivity to phonetic categories as a function of layer depth,\nresembling models trained for phone recognition in a supervised manner.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 10:14:24 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["R\u00e4s\u00e4nen", "Okko", ""], ["Khorrami", "Khazar", ""]]}, {"id": "1906.09833", "submitter": "Yvette Graham", "authors": "Yvette Graham and Barry Haddow and Philipp Koehn", "title": "Translationese in Machine Translation Evaluation", "comments": "17 pages, 8 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The term translationese has been used to describe the presence of unusual\nfeatures of translated text. In this paper, we provide a detailed analysis of\nthe adverse effects of translationese on machine translation evaluation\nresults. Our analysis shows evidence to support differences in text originally\nwritten in a given language relative to translated text and this can\npotentially negatively impact the accuracy of machine translation evaluations.\nFor this reason we recommend that reverse-created test data be omitted from\nfuture machine translation test sets. In addition, we provide a re-evaluation\nof a past high-profile machine translation evaluation claiming human-parity of\nMT, as well as analysis of the since re-evaluations of it. We find potential\nways of improving the reliability of all three past evaluations. One important\nissue not previously considered is the statistical power of significance tests\napplied in past evaluations that aim to investigate human-parity of MT. Since\nthe very aim of such evaluations is to reveal legitimate ties between human and\nMT systems, power analysis is of particular importance, where low power could\nresult in claims of human parity that in fact simply correspond to Type II\nerror. We therefore provide a detailed power analysis of tests used in such\nevaluations to provide an indication of a suitable minimum sample size of\ntranslations for such studies. Subsequently, since no past evaluation that\naimed to investigate claims of human parity ticks all boxes in terms of\naccuracy and reliability, we rerun the evaluation of the systems claiming human\nparity. Finally, we provide a comprehensive check-list for future machine\ntranslation evaluation.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 10:14:42 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Graham", "Yvette", ""], ["Haddow", "Barry", ""], ["Koehn", "Philipp", ""]]}, {"id": "1906.09912", "submitter": "Kemal Kurniawan", "authors": "Kemal Kurniawan", "title": "KaWAT: A Word Analogy Task Dataset for Indonesian", "comments": "Extended abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduced KaWAT (Kata Word Analogy Task), a new word analogy task dataset\nfor Indonesian. We evaluated on it several existing pretrained Indonesian word\nembeddings and embeddings trained on Indonesian online news corpus. We also\ntested them on two downstream tasks and found that pretrained word embeddings\nhelped either by reducing the training epochs or yielding significant\nperformance gains.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 06:32:24 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Kurniawan", "Kemal", ""]]}, {"id": "1906.09978", "submitter": "Ekaterina Artemova", "authors": "Anton A. Emelyanov and Ekaterina Artemova", "title": "Multilingual Named Entity Recognition Using Pretrained Embeddings,\n  Attention Mechanism and NCRF", "comments": "BSNLP Shared Task 2019 paper. arXiv admin note: text overlap with\n  arXiv:1806.05626 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we tackle multilingual named entity recognition task. We use\nthe BERT Language Model as embeddings with bidirectional recurrent network,\nattention, and NCRF on the top. We apply multilingual BERT only as embedder\nwithout any fine-tuning. We test out model on the dataset of the BSNLP shared\ntask, which consists of texts in Bulgarian, Czech, Polish and Russian\nlanguages.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 13:03:47 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Emelyanov", "Anton A.", ""], ["Artemova", "Ekaterina", ""]]}, {"id": "1906.09992", "submitter": "Caio Corro", "authors": "Caio Corro and Ivan Titov", "title": "Learning Latent Trees with Stochastic Perturbations and Differentiable\n  Dynamic Programming", "comments": "Accepted at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We treat projective dependency trees as latent variables in our probabilistic\nmodel and induce them in such a way as to be beneficial for a downstream task,\nwithout relying on any direct tree supervision. Our approach relies on Gumbel\nperturbations and differentiable dynamic programming. Unlike previous\napproaches to latent tree learning, we stochastically sample global structures\nand our parser is fully differentiable. We illustrate its effectiveness on\nsentiment analysis and natural language inference tasks. We also study its\nproperties on a synthetic structure induction task. Ablation studies emphasize\nthe importance of both stochasticity and constraining latent structures to be\nprojective trees.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 14:29:12 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Corro", "Caio", ""], ["Titov", "Ivan", ""]]}, {"id": "1906.10002", "submitter": "Daniel Loureiro", "authors": "Daniel Loureiro and Alipio Jorge", "title": "LIAAD at SemDeep-5 Challenge: Word-in-Context (WiC)", "comments": "Accepted at the SemDeep-5 Workshop in IJCAI 2019. Code and data:\n  https://github.com/danlou/LMMS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the LIAAD system that was ranked second place in the\nWord-in-Context challenge (WiC) featured in SemDeep-5. Our solution is based on\na novel system for Word Sense Disambiguation (WSD) using contextual embeddings\nand full-inventory sense embeddings. We adapt this WSD system, in a\nstraightforward manner, for the present task of detecting whether the same\nsense occurs in a pair of sentences. Additionally, we show that our solution is\nable to achieve competitive performance even without using the provided\ntraining or development sets, mitigating potential concerns related to task\noverfitting\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 14:49:05 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Loureiro", "Daniel", ""], ["Jorge", "Alipio", ""]]}, {"id": "1906.10007", "submitter": "Daniel Loureiro", "authors": "Daniel Loureiro and Alipio Jorge", "title": "Language Modelling Makes Sense: Propagating Representations through\n  WordNet for Full-Coverage Word Sense Disambiguation", "comments": "Accepted to ACL 2019. Code and data: https://github.com/danlou/lmms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual embeddings represent a new generation of semantic representations\nlearned from Neural Language Modelling (NLM) that addresses the issue of\nmeaning conflation hampering traditional word embeddings. In this work, we show\nthat contextual embeddings can be used to achieve unprecedented gains in Word\nSense Disambiguation (WSD) tasks. Our approach focuses on creating sense-level\nembeddings with full-coverage of WordNet, and without recourse to explicit\nknowledge of sense distributions or task-specific modelling. As a result, a\nsimple Nearest Neighbors (k-NN) method using our representations is able to\nconsistently surpass the performance of previous systems using powerful neural\nsequencing models. We also analyse the robustness of our approach when ignoring\npart-of-speech and lemma features, requiring disambiguation against the full\nsense inventory, and revealing shortcomings to be improved. Finally, we explore\napplications of our sense embeddings for concept-level analyses of contextual\nembeddings and their respective NLMs.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 14:59:12 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Loureiro", "Daniel", ""], ["Jorge", "Alipio", ""]]}, {"id": "1906.10068", "submitter": "Maximilian Splieth\\\"over", "authors": "Maximilian Splieth\\\"over, Jonas Klaff, Hendrik Heuer", "title": "Is It Worth the Attention? A Comparative Evaluation of Attention Layers\n  for Argument Unit Segmentation", "comments": "Accepted to the 6th Workshop on Argument Mining 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention mechanisms have seen some success for natural language processing\ndownstream tasks in recent years and generated new State-of-the-Art results. A\nthorough evaluation of the attention mechanism for the task of Argumentation\nMining is missing, though. With this paper, we report a comparative evaluation\nof attention layers in combination with a bidirectional long short-term memory\nnetwork, which is the current state-of-the-art approach to the unit\nsegmentation task. We also compare sentence-level contextualized word\nembeddings to pre-generated ones. Our findings suggest that for this task the\nadditional attention layer does not improve upon a less complex approach. In\nmost cases, the contextualized embeddings do also not show an improvement on\nthe baseline score.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 16:40:47 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Splieth\u00f6ver", "Maximilian", ""], ["Klaff", "Jonas", ""], ["Heuer", "Hendrik", ""]]}, {"id": "1906.10169", "submitter": "Corentin Dancette", "authors": "Remi Cadene and Corentin Dancette and Hedi Ben-younes and Matthieu\n  Cord and Devi Parikh", "title": "RUBi: Reducing Unimodal Biases in Visual Question Answering", "comments": "NeurIPS 2019\n  http://papers.nips.cc/paper/8371-rubi-reducing-unimodal-biases-for-visual-question-answering", "journal-ref": "Advances in Neural Information Processing Systems 2019 (pp.\n  839-850)", "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual Question Answering (VQA) is the task of answering questions about an\nimage. Some VQA models often exploit unimodal biases to provide the correct\nanswer without using the image information. As a result, they suffer from a\nhuge drop in performance when evaluated on data outside their training set\ndistribution. This critical issue makes them unsuitable for real-world\nsettings.\n  We propose RUBi, a new learning strategy to reduce biases in any VQA model.\nIt reduces the importance of the most biased examples, i.e. examples that can\nbe correctly classified without looking at the image. It implicitly forces the\nVQA model to use the two input modalities instead of relying on statistical\nregularities between the question and the answer. We leverage a question-only\nmodel that captures the language biases by identifying when these unwanted\nregularities are used. It prevents the base VQA model from learning them by\ninfluencing its predictions. This leads to dynamically adjusting the loss in\norder to compensate for biases. We validate our contributions by surpassing the\ncurrent state-of-the-art results on VQA-CP v2. This dataset is specifically\ndesigned to assess the robustness of VQA models when exposed to different\nquestion biases at test time than what was seen during training.\n  Our code is available: github.com/cdancette/rubi.bootstrap.pytorch\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 18:55:24 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 11:25:27 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Cadene", "Remi", ""], ["Dancette", "Corentin", ""], ["Ben-younes", "Hedi", ""], ["Cord", "Matthieu", ""], ["Parikh", "Devi", ""]]}, {"id": "1906.10197", "submitter": "Kanishk Gandhi", "authors": "Kanishk Gandhi and Brenden M. Lake", "title": "Mutual exclusivity as a challenge for deep neural networks", "comments": "Published in Advances in Neural Information Processing Systems\n  (NeurIPS) 33", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strong inductive biases allow children to learn in fast and adaptable ways.\nChildren use the mutual exclusivity (ME) bias to help disambiguate how words\nmap to referents, assuming that if an object has one label then it does not\nneed another. In this paper, we investigate whether or not standard neural\narchitectures have an ME bias, demonstrating that they lack this learning\nassumption. Moreover, we show that their inductive biases are poorly matched to\nlifelong learning formulations of classification and translation. We\ndemonstrate that there is a compelling case for designing neural networks that\nreason by mutual exclusivity, which remains an open challenge.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 19:47:05 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 18:51:28 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 21:50:33 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Gandhi", "Kanishk", ""], ["Lake", "Brenden M.", ""]]}, {"id": "1906.10198", "submitter": "Gustavo Aguilar", "authors": "Gustavo Aguilar, Viktor Rozgi\\'c, Weiran Wang, and Chao Wang", "title": "Multimodal and Multi-view Models for Emotion Recognition", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studies on emotion recognition (ER) show that combining lexical and acoustic\ninformation results in more robust and accurate models. The majority of the\nstudies focus on settings where both modalities are available in training and\nevaluation. However, in practice, this is not always the case; getting ASR\noutput may represent a bottleneck in a deployment pipeline due to computational\ncomplexity or privacy-related constraints. To address this challenge, we study\nthe problem of efficiently combining acoustic and lexical modalities during\ntraining while still providing a deployable acoustic model that does not\nrequire lexical inputs. We first experiment with multimodal models and two\nattention mechanisms to assess the extent of the benefits that lexical\ninformation can provide. Then, we frame the task as a multi-view learning\nproblem to induce semantic information from a multimodal model into our\nacoustic-only network using a contrastive loss function. Our multimodal model\noutperforms the previous state of the art on the USC-IEMOCAP dataset reported\non lexical and acoustic information. Additionally, our multi-view-trained\nacoustic network significantly surpasses models that have been exclusively\ntrained with acoustic features.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 19:47:23 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Aguilar", "Gustavo", ""], ["Rozgi\u0107", "Viktor", ""], ["Wang", "Weiran", ""], ["Wang", "Chao", ""]]}, {"id": "1906.10225", "submitter": "Yoon Kim", "authors": "Yoon Kim, Chris Dyer, Alexander M. Rush", "title": "Compound Probabilistic Context-Free Grammars for Grammar Induction", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a formalization of the grammar induction problem that models\nsentences as being generated by a compound probabilistic context-free grammar.\nIn contrast to traditional formulations which learn a single stochastic\ngrammar, our grammar's rule probabilities are modulated by a per-sentence\ncontinuous latent variable, which induces marginal dependencies beyond the\ntraditional context-free assumptions. Inference in this grammar is performed by\ncollapsed variational inference, in which an amortized variational posterior is\nplaced on the continuous variable, and the latent trees are marginalized out\nwith dynamic programming. Experiments on English and Chinese show the\neffectiveness of our approach compared to recent state-of-the-art methods when\nevaluated on unsupervised parsing.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 20:45:50 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2019 01:53:59 GMT"}, {"version": "v3", "created": "Sat, 13 Jul 2019 00:47:50 GMT"}, {"version": "v4", "created": "Wed, 24 Jul 2019 03:04:52 GMT"}, {"version": "v5", "created": "Wed, 14 Aug 2019 15:02:33 GMT"}, {"version": "v6", "created": "Sun, 18 Aug 2019 05:04:18 GMT"}, {"version": "v7", "created": "Sun, 1 Sep 2019 02:06:46 GMT"}, {"version": "v8", "created": "Tue, 17 Mar 2020 23:53:34 GMT"}, {"version": "v9", "created": "Sun, 29 Mar 2020 16:27:33 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Kim", "Yoon", ""], ["Dyer", "Chris", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1906.10256", "submitter": "Jayadev Bhaskaran", "authors": "Jayadev Bhaskaran and Isha Bhallamudi", "title": "Good Secretaries, Bad Truck Drivers? Occupational Gender Stereotypes in\n  Sentiment Analysis", "comments": "Accepted at GeBNLP (ACL Workshop on Gender Bias for NLP) at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we investigate the presence of occupational gender stereotypes\nin sentiment analysis models. Such a task has implications for reducing\nimplicit biases in these models, which are being applied to an increasingly\nwide variety of downstream tasks. We release a new gender-balanced dataset of\n800 sentences pertaining to specific professions and propose a methodology for\nusing it as a test bench to evaluate sentiment analysis models. We evaluate the\npresence of occupational gender stereotypes in 3 different models using our\napproach, and explore their relationship with societal perceptions of\noccupations.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 22:31:33 GMT"}, {"version": "v2", "created": "Sat, 13 Jul 2019 05:38:28 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Bhaskaran", "Jayadev", ""], ["Bhallamudi", "Isha", ""]]}, {"id": "1906.10282", "submitter": "Shuoyang Ding", "authors": "Shuoyang Ding, Hainan Xu, Philipp Koehn", "title": "Saliency-driven Word Alignment Interpretation for Neural Machine\n  Translation", "comments": "Accepted to WMT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their original goal to jointly learn to align and translate, Neural\nMachine Translation (NMT) models, especially Transformer, are often perceived\nas not learning interpretable word alignments. In this paper, we show that NMT\nmodels do learn interpretable word alignments, which could only be revealed\nwith proper interpretation methods. We propose a series of such methods that\nare model-agnostic, are able to be applied either offline or online, and do not\nrequire parameter update or architectural change. We show that under the force\ndecoding setup, the alignments induced by our interpretation method are of\nbetter quality than fast-align for some systems, and when performing free\ndecoding, they agree well with the alignments induced by automatic alignment\ntools.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 00:43:32 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 19:04:07 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Ding", "Shuoyang", ""], ["Xu", "Hainan", ""], ["Koehn", "Philipp", ""]]}, {"id": "1906.10369", "submitter": "Emre Yilmaz", "authors": "Chitralekha Gupta, Emre Y{\\i}lmaz, Haizhou Li", "title": "Acoustic Modeling for Automatic Lyrics-to-Audio Alignment", "comments": "Accepted for publication at Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic lyrics to polyphonic audio alignment is a challenging task not only\nbecause the vocals are corrupted by background music, but also there is a lack\nof annotated polyphonic corpus for effective acoustic modeling. In this work,\nwe propose (1) using additional speech and music-informed features and (2)\nadapting the acoustic models trained on a large amount of solo singing vocals\ntowards polyphonic music using a small amount of in-domain data. Incorporating\nadditional information such as voicing and auditory features together with\nconventional acoustic features aims to bring robustness against the increased\nspectro-temporal variations in singing vocals. By adapting the acoustic model\nusing a small amount of polyphonic audio data, we reduce the domain mismatch\nbetween training and testing data. We perform several alignment experiments and\npresent an in-depth alignment error analysis on acoustic features, and model\nadaptation techniques. The results demonstrate that the proposed strategy\nprovides a significant error reduction of word boundary alignment over\ncomparable existing systems, especially on more challenging polyphonic data\nwith long-duration musical interludes.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 08:11:20 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Gupta", "Chitralekha", ""], ["Y\u0131lmaz", "Emre", ""], ["Li", "Haizhou", ""]]}, {"id": "1906.10511", "submitter": "Laura Martinus", "authors": "Laura Martinus and Jade Z. Abbott", "title": "Benchmarking Neural Machine Translation for Southern African Languages", "comments": "arXiv admin note: text overlap with arXiv:1906.05685", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unlike major Western languages, most African languages are very\nlow-resourced. Furthermore, the resources that do exist are often scattered and\ndifficult to obtain and discover. As a result, the data and code for existing\nresearch has rarely been shared. This has lead a struggle to reproduce reported\nresults, and few publicly available benchmarks for African machine translation\nmodels exist. To start to address these problems, we trained neural machine\ntranslation models for 5 Southern African languages on publicly-available\ndatasets. Code is provided for training the models and evaluate the models on a\nnewly released evaluation set, with the aim of spur future research in the\nfield for Southern African languages.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 18:47:28 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Martinus", "Laura", ""], ["Abbott", "Jade Z.", ""]]}, {"id": "1906.10519", "submitter": "Jeremy Barnes", "authors": "Jeremy Barnes, Roman Klinger", "title": "Embedding Projection for Targeted Cross-Lingual Sentiment: Model\n  Comparisons and a Real-World Study", "comments": "Submitted to Journal of Artificial Intelligence Research (41 pages,\n  51 with references). arXiv admin note: text overlap with arXiv:1805.09016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sentiment analysis benefits from large, hand-annotated resources in order to\ntrain and test machine learning models, which are often data hungry. While some\nlanguages, e.g., English, have a vast array of these resources, most\nunder-resourced languages do not, especially for fine-grained sentiment tasks,\nsuch as aspect-level or targeted sentiment analysis. To improve this situation,\nwe propose a cross-lingual approach to sentiment analysis that is applicable to\nunder-resourced languages and takes into account target-level information. This\nmodel incorporates sentiment information into bilingual distributional\nrepresentations, by jointly optimizing them for semantics and sentiment,\nshowing state-of-the-art performance at sentence-level when combined with\nmachine translation. The adaptation to targeted sentiment analysis on multiple\ndomains shows that our model outperforms other projection-based bilingual\nembedding methods on binary targeted sentiment tasks. Our analysis on ten\nlanguages demonstrates that the amount of unlabeled monolingual data has\nsurprisingly little effect on the sentiment results. As expected, the choice of\nannotated source language for projection to a target leads to better results\nfor source-target language pairs which are similar. Therefore, our results\nsuggest that more efforts should be spent on the creation of resources for less\nsimilar languages to those which are resource-rich already. Finally, a domain\nmismatch leads to a decreased performance. This suggests resources in any\nlanguage should ideally cover varieties of domains.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 08:18:12 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Barnes", "Jeremy", ""], ["Klinger", "Roman", ""]]}, {"id": "1906.10551", "submitter": "Oren Halvani", "authors": "Oren Halvani, Christian Winter, Lukas Graner", "title": "Assessing the Applicability of Authorship Verification Methods", "comments": "Paper has been accepted for publication in: The 14th International\n  Conference on Availability, Reliability and Security (ARES 2019). arXiv admin\n  note: text overlap with arXiv:1901.00399", "journal-ref": null, "doi": "10.1145/3339252.3340508", "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Authorship verification (AV) is a research subject in the field of digital\ntext forensics that concerns itself with the question, whether two documents\nhave been written by the same person. During the past two decades, an\nincreasing number of proposed AV approaches can be observed. However, a closer\nlook at the respective studies reveals that the underlying characteristics of\nthese methods are rarely addressed, which raises doubts regarding their\napplicability in real forensic settings. The objective of this paper is to fill\nthis gap by proposing clear criteria and properties that aim to improve the\ncharacterization of existing and future AV approaches. Based on these\nproperties, we conduct three experiments using 12 existing AV approaches,\nincluding the current state of the art. The examined methods were trained,\noptimized and evaluated on three self-compiled corpora, where each corpus\nfocuses on a different aspect of applicability. Our results indicate that part\nof the methods are able to cope with very challenging verification cases such\nas 250 characters long informal chat conversations (72.7% accuracy) or cases in\nwhich two scientific documents were written at different times with an average\ndifference of 15.6 years (> 75% accuracy). However, we also identified that all\ninvolved methods are prone to cross-topic verification cases.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 09:44:46 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Halvani", "Oren", ""], ["Winter", "Christian", ""], ["Graner", "Lukas", ""]]}, {"id": "1906.10607", "submitter": "Daniel Lee", "authors": "Rakesh Verma, Samaneh Karimi, Daniel Lee, Omprakash Gnawali, Azadeh\n  Shakery", "title": "Newswire versus Social Media for Disaster Response and Recovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a disaster situation, first responders need to quickly acquire situational\nawareness and prioritize response based on the need, resources available and\nimpact. Can they do this based on digital media such as Twitter alone, or\nnewswire alone, or some combination of the two? We examine this question in the\ncontext of the 2015 Nepal Earthquakes. Because newswire articles are longer,\neffective summaries can be helpful in saving time yet giving key content. We\nevaluate the effectiveness of several unsupervised summarization techniques in\ncapturing key content. We propose a method to link tweets written by the public\nand newswire articles, so that we can compare their key characteristics:\ntimeliness, whether tweets appear earlier than their corresponding news\narticles, and content. A novel idea is to view relevant tweets as a summary of\nthe matching news article and evaluate these summaries. Whenever possible, we\npresent both quantitative and qualitative evaluations. One of our main findings\nis that tweets and newswire articles provide complementary perspectives that\nform a holistic view of the disaster situation.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 15:31:14 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Verma", "Rakesh", ""], ["Karimi", "Samaneh", ""], ["Lee", "Daniel", ""], ["Gnawali", "Omprakash", ""], ["Shakery", "Azadeh", ""]]}, {"id": "1906.10724", "submitter": "Rahul Aralikatte", "authors": "Rahul Aralikatte and Anders S{\\o}gaard", "title": "Model-based annotation of coreference", "comments": "To appear in LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans do not make inferences over texts, but over models of what texts are\nabout. When annotators are asked to annotate coreferent spans of text, it is\ntherefore a somewhat unnatural task. This paper presents an alternative in\nwhich we preprocess documents, linking entities to a knowledge base, and turn\nthe coreference annotation task -- in our case limited to pronouns -- into an\nannotation task where annotators are asked to assign pronouns to entities.\nModel-based annotation is shown to lead to faster annotation and higher\ninter-annotator agreement, and we argue that it also opens up for an\nalternative approach to coreference resolution. We present two new coreference\nbenchmark datasets, for English Wikipedia and English teacher-student\ndialogues, and evaluate state-of-the-art coreference resolvers on them.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 18:56:36 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 08:25:13 GMT"}, {"version": "v3", "created": "Sun, 1 Mar 2020 23:17:56 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Aralikatte", "Rahul", ""], ["S\u00f8gaard", "Anders", ""]]}, {"id": "1906.10793", "submitter": "Yehia Abd Alrahman", "authors": "Yehia Abd Alrahman, Giuseppe Perelli, Nir Piterman", "title": "Reconfigurable Interaction for MAS Modelling", "comments": "This is a final and revised version. This research is funded by the\n  ERC consolidator grant D-SynMA under the European Union's Horizon 2020\n  research and innovation programme (grant agreement No 772459)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a formalism to model and reason about multi-agent systems. We\nallow agents to interact and communicate in different modes so that they can\npursue joint tasks; agents may dynamically synchronize, exchange data, adapt\ntheir behaviour, and reconfigure their communication interfaces. The formalism\ndefines a local behaviour based on shared variables and a global one based on\nmessage passing. We extend LTL to be able to reason explicitly about the\nintentions of the different agents and their interaction protocols. We also\nstudy the complexity of satisfiability and model-checking of this extension.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 00:31:46 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 11:51:59 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Alrahman", "Yehia Abd", ""], ["Perelli", "Giuseppe", ""], ["Piterman", "Nir", ""]]}, {"id": "1906.10816", "submitter": "Oleksandr Polozov", "authors": "Richard Shin, Miltiadis Allamanis, Marc Brockschmidt, Oleksandr\n  Polozov", "title": "Program Synthesis and Semantic Parsing with Learned Code Idioms", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS)\n  2019. 13 pages total, 9 pages of main text", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Program synthesis of general-purpose source code from natural language\nspecifications is challenging due to the need to reason about high-level\npatterns in the target program and low-level implementation details at the same\ntime. In this work, we present PATOIS, a system that allows a neural program\nsynthesizer to explicitly interleave high-level and low-level reasoning at\nevery generation step. It accomplishes this by automatically mining common code\nidioms from a given corpus, incorporating them into the underlying language for\nneural synthesis, and training a tree-based neural synthesizer to use these\nidioms during code generation. We evaluate PATOIS on two complex semantic\nparsing datasets and show that using learned code idioms improves the\nsynthesizer's accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 02:28:10 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 21:58:59 GMT"}, {"version": "v3", "created": "Thu, 5 Sep 2019 01:28:05 GMT"}, {"version": "v4", "created": "Tue, 5 Nov 2019 02:44:38 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Shin", "Richard", ""], ["Allamanis", "Miltiadis", ""], ["Brockschmidt", "Marc", ""], ["Polozov", "Oleksandr", ""]]}, {"id": "1906.10827", "submitter": "Mikhail Yurochkin", "authors": "Mikhail Yurochkin, Sebastian Claici, Edward Chien, Farzaneh Mirzazadeh\n  and Justin Solomon", "title": "Hierarchical Optimal Transport for Document Representation", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to measure similarity between documents enables intelligent\nsummarization and analysis of large corpora. Past distances between documents\nsuffer from either an inability to incorporate semantic similarities between\nwords or from scalability issues. As an alternative, we introduce hierarchical\noptimal transport as a meta-distance between documents, where documents are\nmodeled as distributions over topics, which themselves are modeled as\ndistributions over words. We then solve an optimal transport problem on the\nsmaller topic space to compute a similarity score. We give conditions on the\ntopics under which this construction defines a distance, and we relate it to\nthe word mover's distance. We evaluate our technique for k-NN classification\nand show better interpretability and scalability with comparable performance to\ncurrent methods at a fraction of the cost.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 03:26:23 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 22:07:08 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Yurochkin", "Mikhail", ""], ["Claici", "Sebastian", ""], ["Chien", "Edward", ""], ["Mirzazadeh", "Farzaneh", ""], ["Solomon", "Justin", ""]]}, {"id": "1906.10834", "submitter": "Zhenchuan Yang", "authors": "Zhenchuan Yang, Chun Zhang, Weibin Zhang, Jianxiu Jin, Dongpeng Chen", "title": "Essence Knowledge Distillation for Speech Recognition", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that a speech recognition system that combines multiple\nacoustic models trained on the same data significantly outperforms a\nsingle-model system. Unfortunately, real time speech recognition using a whole\nensemble of models is too computationally expensive. In this paper, we propose\nto distill the knowledge of essence in an ensemble of models (i.e. the teacher\nmodel) to a single model (i.e. the student model) that needs much less\ncomputation to deploy. Previously, all the soften outputs of the teacher model\nare used to optimize the student model. We argue that not all the outputs of\nthe ensemble are necessary to be distilled. Some of the outputs may even\ncontain noisy information that is useless or even harmful to the training of\nthe student model. In addition, we propose to train the student model with a\nmultitask learning approach by utilizing both the soften outputs of the teacher\nmodel and the correct hard labels. The proposed method achieves some surprising\nresults on the Switchboard data set. When the student model is trained together\nwith the correct labels and the essence knowledge from the teacher model, it\nnot only significantly outperforms another single model with the same\narchitecture that is trained only with the correct labels, but also\nconsistently outperforms the teacher model that is used to generate the soft\nlabels.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 03:58:29 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Yang", "Zhenchuan", ""], ["Zhang", "Chun", ""], ["Zhang", "Weibin", ""], ["Jin", "Jianxiu", ""], ["Chen", "Dongpeng", ""]]}, {"id": "1906.10876", "submitter": "Naoyuki Kanda", "authors": "Naoyuki Kanda, Shota Horiguchi, Ryoichi Takashima, Yusuke Fujita,\n  Kenji Nagamatsu, Shinji Watanabe", "title": "Auxiliary Interference Speaker Loss for Target-Speaker Speech\n  Recognition", "comments": "Accepted to INTERSPEECH 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel auxiliary loss function for target-speaker\nautomatic speech recognition (ASR). Our method automatically extracts and\ntranscribes target speaker's utterances from a monaural mixture of multiple\nspeakers speech given a short sample of the target speaker. The proposed\nauxiliary loss function attempts to additionally maximize interference speaker\nASR accuracy during training. This will regularize the network to achieve a\nbetter representation for speaker separation, thus achieving better accuracy on\nthe target-speaker ASR. We evaluated our proposed method using\ntwo-speaker-mixed speech in various signal-to-interference-ratio conditions. We\nfirst built a strong target-speaker ASR baseline based on the state-of-the-art\nlattice-free maximum mutual information. This baseline achieved a word error\nrate (WER) of 18.06% on the test set while a normal ASR trained with clean data\nproduced a completely corrupted result (WER of 84.71%). Then, our proposed loss\nfurther reduced the WER by 6.6% relative to this strong baseline, achieving a\nWER of 16.87%. In addition to the accuracy improvement, we also showed that the\nauxiliary output branch for the proposed loss can even be used for a secondary\nASR for interference speakers' speech.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 07:09:57 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Kanda", "Naoyuki", ""], ["Horiguchi", "Shota", ""], ["Takashima", "Ryoichi", ""], ["Fujita", "Yusuke", ""], ["Nagamatsu", "Kenji", ""], ["Watanabe", "Shinji", ""]]}, {"id": "1906.10907", "submitter": "Kai Hakala", "authors": "Kai Hakala, Aleksi Vesanto, Niko Miekka, Tapio Salakoski, Filip Ginter", "title": "Leveraging Text Repetitions and Denoising Autoencoders in OCR\n  Post-correction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A common approach for improving OCR quality is a post-processing step based\non models correcting misdetected characters and tokens. These models are\ntypically trained on aligned pairs of OCR read text and their manually\ncorrected counterparts. In this paper we show that the requirement of manually\ncorrected training data can be alleviated by estimating the OCR errors from\nrepeating text spans found in large OCR read text corpora and generating\nsynthetic training examples following this error distribution. We use the\ngenerated data for training a character-level neural seq2seq model and evaluate\nthe performance of the suggested model on a manually corrected corpus of\nFinnish newspapers mostly from the 19th century. The results show that a clear\nimprovement over the underlying OCR system as well as previously suggested\nmodels utilizing uniformly generated noise can be achieved.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 08:28:51 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Hakala", "Kai", ""], ["Vesanto", "Aleksi", ""], ["Miekka", "Niko", ""], ["Salakoski", "Tapio", ""], ["Ginter", "Filip", ""]]}, {"id": "1906.10910", "submitter": "Youngnam Lee", "authors": "Youngnam Lee, Youngduck Choi, Junghyun Cho, Alexander R. Fabbri,\n  Hyunbin Loh, Chanyou Hwang, Yongku Lee, Sang-Wook Kim, Dragomir Radev", "title": "Creating A Neural Pedagogical Agent by Jointly Learning to Review and\n  Assess", "comments": "9 pages, 9 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning plays an increasing role in intelligent tutoring systems as\nboth the amount of data available and specialization among students grow.\nNowadays, these systems are frequently deployed on mobile applications. Users\non such mobile education platforms are dynamic, frequently being added,\naccessing the application with varying levels of focus, and changing while\nusing the service. The education material itself, on the other hand, is often\nstatic and is an exhaustible resource whose use in tasks such as problem\nrecommendation must be optimized. The ability to update user models with\nrespect to educational material in real-time is thus essential; however,\nexisting approaches require time-consuming re-training of user features\nwhenever new data is added. In this paper, we introduce a neural pedagogical\nagent for real-time user modeling in the task of predicting user response\ncorrectness, a central task for mobile education applications. Our model,\ninspired by work in natural language processing on sequence modeling and\nmachine translation, updates user features in real-time via bidirectional\nrecurrent neural networks with an attention mechanism over embedded\nquestion-response pairs. We experiment on the mobile education application\nSantaTOEIC, which has 559k users, 66M response data points as well as a set of\n10k study problems each expert-annotated with topic tags and gathered since\n2016. Our model outperforms existing approaches over several metrics in\npredicting user response correctness, notably out-performing other methods on\nnew users without large question-response histories. Additionally, our\nattention mechanism and annotated tag set allow us to create an interpretable\neducation platform, with a smart review system that addresses the\naforementioned issue of varied user attention and problem exhaustion.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 08:37:44 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 09:03:34 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Lee", "Youngnam", ""], ["Choi", "Youngduck", ""], ["Cho", "Junghyun", ""], ["Fabbri", "Alexander R.", ""], ["Loh", "Hyunbin", ""], ["Hwang", "Chanyou", ""], ["Lee", "Yongku", ""], ["Kim", "Sang-Wook", ""], ["Radev", "Dragomir", ""]]}, {"id": "1906.10924", "submitter": "Benjamin Roth", "authors": "Alona Sydorova, Nina Poerner, Benjamin Roth", "title": "Interpretable Question Answering on Knowledge Bases and Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability of machine learning (ML) models becomes more relevant with\ntheir increasing adoption. In this work, we address the interpretability of ML\nbased question answering (QA) models on a combination of knowledge bases (KB)\nand text documents. We adapt post hoc explanation methods such as LIME and\ninput perturbation (IP) and compare them with the self-explanatory attention\nmechanism of the model. For this purpose, we propose an automatic evaluation\nparadigm for explanation methods in the context of QA. We also conduct a study\nwith human annotators to evaluate whether explanations help them identify\nbetter QA models. Our results suggest that IP provides better explanations than\nLIME or attention, according to both automatic and human evaluation. We obtain\nthe same ranking of methods in both experiments, which supports the validity of\nour automatic evaluation paradigm.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 09:10:33 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Sydorova", "Alona", ""], ["Poerner", "Nina", ""], ["Roth", "Benjamin", ""]]}, {"id": "1906.11024", "submitter": "Yinqiao Li", "authors": "Tong Xiao and Yinqiao Li and Jingbo Zhu and Zhengtao Yu and Tongran\n  Liu", "title": "Sharing Attention Weights for Fast Transformer", "comments": "IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the Transformer machine translation system has shown strong results\nby stacking attention layers on both the source and target-language sides. But\nthe inference of this model is slow due to the heavy use of dot-product\nattention in auto-regressive decoding. In this paper we speed up Transformer\nvia a fast and lightweight attention model. More specifically, we share\nattention weights in adjacent layers and enable the efficient re-use of hidden\nstates in a vertical manner. Moreover, the sharing policy can be jointly\nlearned with the MT model. We test our approach on ten WMT and NIST OpenMT\ntasks. Experimental results show that it yields an average of 1.3X speed-up\n(with almost no decrease in BLEU) on top of a state-of-the-art implementation\nthat has already adopted a cache for fast inference. Also, our approach obtains\na 1.8X speed-up when it works with the \\textsc{Aan} model. This is even 16\ntimes faster than the baseline with no use of the attention cache.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 12:27:05 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Xiao", "Tong", ""], ["Li", "Yinqiao", ""], ["Zhu", "Jingbo", ""], ["Yu", "Zhengtao", ""], ["Liu", "Tongran", ""]]}, {"id": "1906.11085", "submitter": "Hichem Mezaoui", "authors": "Hichem Mezaoui, Aleksandr Gontcharov, Isuru Gunasekara", "title": "Enhancing PIO Element Detection in Medical Text Using Contextualized\n  Embedding", "comments": "BioNLP 2019: 18th ACL Workshop on Biomedical Natural Language\n  Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we investigate a new approach to Population, Intervention and\nOutcome (PIO) element detection, a common task in Evidence Based Medicine\n(EBM). The purpose of this study is two-fold: to build a training dataset for\nPIO element detection with minimum redundancy and ambiguity and to investigate\npossible options in utilizing state of the art embedding methods for the task\nof PIO element detection. For the former purpose, we build a new and improved\ndataset by investigating the shortcomings of previously released datasets. For\nthe latter purpose, we leverage the state of the art text embedding,\nBidirectional Encoder Representations from Transformers (BERT), and build a\nmulti-label classifier. We show that choosing a domain specific pre-trained\nembedding further optimizes the performance of the classifier. Furthermore, we\nshow that the model could be enhanced by using ensemble methods and boosting\ntechniques provided that features are adequately chosen.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 13:27:39 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Mezaoui", "Hichem", ""], ["Gontcharov", "Aleksandr", ""], ["Gunasekara", "Isuru", ""]]}, {"id": "1906.11126", "submitter": "Deepak P", "authors": "Iknoor Singh, Deepak P, Anoop K", "title": "On the Coherence of Fake News Articles", "comments": "8th International Workshop on News Recommendation and Analytics (INRA\n  2020) held in conjunction with ECML PKDD 2020 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generation and spread of fake news within new and online media sources is\nemerging as a phenomenon of high societal significance. Combating them using\ndata-driven analytics has been attracting much recent scholarly interest. In\nthis study, we analyze the textual coherence of fake news articles vis-a-vis\nlegitimate ones. We develop three computational formulations of textual\ncoherence drawing upon the state-of-the-art methods in natural language\nprocessing and data science. Two real-world datasets from widely different\ndomains which have fake/legitimate article labellings are then analyzed with\nrespect to textual coherence. We observe apparent differences in textual\ncoherence across fake and legitimate news articles, with fake news articles\nconsistently scoring lower on coherence as compared to legitimate news ones.\nWhile the relative coherence shortfall of fake news articles as compared to\nlegitimate ones form the main observation from our study, we analyze several\naspects of the differences and outline potential avenues of further inquiry.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 14:33:18 GMT"}, {"version": "v2", "created": "Sat, 15 Aug 2020 08:45:35 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Singh", "Iknoor", ""], ["P", "Deepak", ""], ["K", "Anoop", ""]]}, {"id": "1906.11180", "submitter": "Jiaoyan Chen", "authors": "Jiaoyan Chen and Ernesto Jimenez-Ruiz and Ian Horrocks", "title": "Canonicalizing Knowledge Base Literals", "comments": null, "journal-ref": "International Semantic Web Conference (ISWC) 2019", "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontology-based knowledge bases (KBs) like DBpedia are very valuable\nresources, but their usefulness and usability is limited by various quality\nissues. One such issue is the use of string literals instead of semantically\ntyped entities. In this paper we study the automated canonicalization of such\nliterals, i.e., replacing the literal with an existing entity from the KB or\nwith a new entity that is typed using classes from the KB. We propose a\nframework that combines both reasoning and machine learning in order to predict\nthe relevant entities and types, and we evaluate this framework against\nstate-of-the-art baselines for both semantic typing and entity matching.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 15:53:59 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Chen", "Jiaoyan", ""], ["Jimenez-Ruiz", "Ernesto", ""], ["Horrocks", "Ian", ""]]}, {"id": "1906.11298", "submitter": "Xiang Lisa Li", "authors": "Xiang Lisa Li and Dingquan Wang and Jason Eisner", "title": "A Generative Model for Punctuation in Dependency Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Treebanks traditionally treat punctuation marks as ordinary words, but\nlinguists have suggested that a tree's \"true\" punctuation marks are not\nobserved (Nunberg, 1990). These latent \"underlying\" marks serve to delimit or\nseparate constituents in the syntax tree. When the tree's yield is rendered as\na written sentence, a string rewriting mechanism transduces the underlying\nmarks into \"surface\" marks, which are part of the observed (surface) string but\nshould not be regarded as part of the tree. We formalize this idea in a\ngenerative model of punctuation that admits efficient dynamic programming. We\ntrain it without observing the underlying marks, by locally maximizing the\nincomplete data likelihood (similarly to EM). When we use the trained model to\nreconstruct the tree's underlying punctuation, the results appear plausible\nacross 5 languages, and in particular, are consistent with Nunberg's analysis\nof English. We show that our generative model can be used to beat baselines on\npunctuation restoration. Also, our reconstruction of a sentence's underlying\npunctuation lets us appropriately render the surface punctuation (via our\ntrained underlying-to-surface mechanism) when we syntactically transform the\nsentence.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 19:03:17 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Li", "Xiang Lisa", ""], ["Wang", "Dingquan", ""], ["Eisner", "Jason", ""]]}, {"id": "1906.11301", "submitter": "Esin Durmus", "authors": "Esin Durmus and Claire Cardie", "title": "Exploring the Role of Prior Beliefs for Argument Persuasion", "comments": "11 pages", "journal-ref": null, "doi": "10.18653/v1/N18-1094", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Public debate forums provide a common platform for exchanging opinions on a\ntopic of interest. While recent studies in natural language processing (NLP)\nhave provided empirical evidence that the language of the debaters and their\npatterns of interaction play a key role in changing the mind of a reader,\nresearch in psychology has shown that prior beliefs can affect our\ninterpretation of an argument and could therefore constitute a competing\nalternative explanation for resistance to changing one's stance. To study the\nactual effect of language use vs. prior beliefs on persuasion, we provide a new\ndataset and propose a controlled setting that takes into consideration two\nreader level factors: political and religious ideology. We find that prior\nbeliefs affected by these reader level factors play a more important role than\nlanguage use effects and argue that it is important to account for them in NLP\nstudies of persuasion.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 19:15:41 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Durmus", "Esin", ""], ["Cardie", "Claire", ""]]}, {"id": "1906.11310", "submitter": "Esin Durmus", "authors": "Esin Durmus and Claire Cardie", "title": "A Corpus for Modeling User and Language Effects in Argumentation on\n  Online Debating", "comments": null, "journal-ref": null, "doi": "10.18653/v1/P19-1057", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Existing argumentation datasets have succeeded in allowing researchers to\ndevelop computational methods for analyzing the content, structure and\nlinguistic features of argumentative text. They have been much less successful\nin fostering studies of the effect of \"user\" traits -- characteristics and\nbeliefs of the participants -- on the debate/argument outcome as this type of\nuser information is generally not available. This paper presents a dataset of\n78, 376 debates generated over a 10-year period along with surprisingly\ncomprehensive participant profiles. We also complete an example study using the\ndataset to analyze the effect of selected user traits on the debate outcome in\ncomparison to the linguistic features typically employed in studies of this\nkind.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 19:38:02 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Durmus", "Esin", ""], ["Cardie", "Claire", ""]]}, {"id": "1906.11313", "submitter": "Esin Durmus", "authors": "Esin Durmus, Faisal Ladhak and Claire Cardie", "title": "Determining Relative Argument Specificity and Stance for Complex\n  Argumentative Structures", "comments": null, "journal-ref": null, "doi": "10.18653/v1/P19-1456", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Systems for automatic argument generation and debate require the ability to\n(1) determine the stance of any claims employed in the argument and (2) assess\nthe specificity of each claim relative to the argument context. Existing work\non understanding claim specificity and stance, however, has been limited to the\nstudy of argumentative structures that are relatively shallow, most often\nconsisting of a single claim that directly supports or opposes the argument\nthesis. In this paper, we tackle these tasks in the context of complex\narguments on a diverse set of topics. In particular, our dataset consists of\nmanually curated argument trees for 741 controversial topics covering 95,312\nunique claims; lines of argument are generally of depth 2 to 6. We find that as\nthe distance between a pair of claims increases along the argument path,\ndetermining the relative specificity of a pair of claims becomes easier and\ndetermining their relative stance becomes harder.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 19:45:42 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Durmus", "Esin", ""], ["Ladhak", "Faisal", ""], ["Cardie", "Claire", ""]]}, {"id": "1906.11315", "submitter": "Varun Kumar Vijay", "authors": "Varun Kumar Vijay, Abhinav Ganesh, Hanlin Tang, Arjun Bansal", "title": "Generalization to Novel Objects using Prior Relational Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To solve tasks in new environments involving objects unseen during training,\nagents must reason over prior information about those objects and their\nrelations. We introduce the Prior Knowledge Graph network, an architecture for\ncombining prior information, structured as a knowledge graph, with a symbolic\nparsing of the visual scene, and demonstrate that this approach is able to\napply learned relations to novel objects whereas the baseline algorithms fail.\nAblation experiments show that the agents ground the knowledge graph relations\nto semantically-relevant behaviors. In both a Sokoban game and the more complex\nPacman environment, our network is also more sample efficient than the\nbaselines, reaching the same performance in 5-10x fewer episodes. Once the\nagents are trained with our approach, we can manipulate agent behavior by\nmodifying the knowledge graph in semantically meaningful ways. These results\nsuggest that our network provides a framework for agents to reason over\nstructured knowledge graphs while still leveraging gradient based learning\napproaches.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 19:48:25 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2019 13:44:38 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Vijay", "Varun Kumar", ""], ["Ganesh", "Abhinav", ""], ["Tang", "Hanlin", ""], ["Bansal", "Arjun", ""]]}, {"id": "1906.11384", "submitter": "Junyi Du", "authors": "Junyi Du, He Jiang, Jiaming Shen and Xiang Ren", "title": "Eliciting Knowledge from Experts:Automatic Transcript Parsing for\n  Cognitive Task Analysis", "comments": "In proceedings of ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cognitive task analysis (CTA) is a type of analysis in applied psychology\naimed at eliciting and representing the knowledge and thought processes of\ndomain experts. In CTA, often heavy human labor is involved to parse the\ninterview transcript into structured knowledge (e.g., flowchart for different\nactions). To reduce human efforts and scale the process, automated CTA\ntranscript parsing is desirable. However, this task has unique challenges as\n(1) it requires the understanding of long-range context information in\nconversational text; and (2) the amount of labeled data is limited and\nindirect---i.e., context-aware, noisy, and low-resource. In this paper, we\npropose a weakly-supervised information extraction framework for automated CTA\ntranscript parsing. We partition the parsing process into a sequence labeling\ntask and a text span-pair relation extraction task, with distant supervision\nfrom human-curated protocol files. To model long-range context information for\nextracting sentence relations, neighbor sentences are involved as a part of\ninput. Different types of models for capturing context dependency are then\napplied. We manually annotate real-world CTA transcripts to facilitate the\nevaluation of the parsing tasks\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 23:34:22 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Du", "Junyi", ""], ["Jiang", "He", ""], ["Shen", "Jiaming", ""], ["Ren", "Xiang", ""]]}, {"id": "1906.11455", "submitter": "Jingjing Xu", "authors": "Ruixuan Luo, Jingjing Xu, Yi Zhang, Xuancheng Ren, Xu Sun", "title": "PKUSEG: A Toolkit for Multi-Domain Chinese Word Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chinese word segmentation (CWS) is a fundamental step of Chinese natural\nlanguage processing. In this paper, we build a new toolkit, named PKUSEG, for\nmulti-domain word segmentation. Unlike existing single-model toolkits, PKUSEG\ntargets at multi-domain word segmentation and provides separate models for\ndifferent domains, such as web, medicine, and tourism. The new toolkit also\nsupports POS tagging and model training to adapt to various application\nscenarios. Experiments show that PKUSEG achieves high performance on multiple\ndomains. The toolkit is now freely and publicly available for the usage of\nresearch and industry.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 06:40:42 GMT"}, {"version": "v2", "created": "Fri, 28 Jun 2019 02:34:00 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Luo", "Ruixuan", ""], ["Xu", "Jingjing", ""], ["Zhang", "Yi", ""], ["Ren", "Xuancheng", ""], ["Sun", "Xu", ""]]}, {"id": "1906.11483", "submitter": "Shijie Wu", "authors": "Shijie Wu, Ryan Cotterell, Timothy J. O'Donnell", "title": "Morphological Irregularity Correlates with Frequency", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a study of morphological irregularity. Following recent work, we\ndefine an information-theoretic measure of irregularity based on the\npredictability of forms in a language. Using a neural transduction model, we\nestimate this quantity for the forms in 28 languages. We first present several\nvalidatory and exploratory analyses of irregularity. We then show that our\nanalyses provide evidence for a correlation between irregularity and frequency:\nhigher frequency items are more likely to be irregular and irregular items are\nmore likely be highly frequent. To our knowledge, this result is the first of\nits breadth and confirms longstanding proposals from the linguistics\nliterature. The correlation is more robust when aggregated at the level of\nwhole paradigms--providing support for models of linguistic structure in which\ninflected forms are unified by abstract underlying stems or lexemes. Code is\navailable at https://github.com/shijie-wu/neural-transducer.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 08:03:02 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Wu", "Shijie", ""], ["Cotterell", "Ryan", ""], ["O'Donnell", "Timothy J.", ""]]}, {"id": "1906.11511", "submitter": "David Mare\\v{c}ek", "authors": "Rudolf Rosa and David Mare\\v{c}ek", "title": "Inducing Syntactic Trees from BERT Representations", "comments": "Accepted abstract for the BlackboxNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We use the English model of BERT and explore how a deletion of one word in a\nsentence changes representations of other words. Our hypothesis is that\nremoving a reducible word (e.g. an adjective) does not affect the\nrepresentation of other words so much as removing e.g. the main verb, which\nmakes the sentence ungrammatical and of \"high surprise\" for the language model.\nWe estimate reducibilities of individual words and also of longer continuous\nphrases (word n-grams), study their syntax-related properties, and then also\nuse them to induce full dependency trees.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 09:05:32 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Rosa", "Rudolf", ""], ["Mare\u010dek", "David", ""]]}, {"id": "1906.11521", "submitter": "Ondrej Klejch", "authors": "Ondrej Klejch, Joachim Fainberg, Peter Bell, Steve Renals", "title": "Lattice-Based Unsupervised Test-Time Adaptation of Neural Network\n  Acoustic Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustic model adaptation to unseen test recordings aims to reduce the\nmismatch between training and testing conditions. Most adaptation schemes for\nneural network models require the use of an initial one-best transcription for\nthe test data, generated by an unadapted model, in order to estimate the\nadaptation transform. It has been found that adaptation methods using\ndiscriminative objective functions - such as cross-entropy loss - often require\ncareful regularisation to avoid over-fitting to errors in the one-best\ntranscriptions. In this paper we solve this problem by performing\ndiscriminative adaptation using lattices obtained from a first pass decoding,\nan approach that can be readily integrated into the lattice-free maximum mutual\ninformation (LF-MMI) framework. We investigate this approach on three\ntranscription tasks of varying difficulty: TED talks, multi-genre broadcast\n(MGB) and a low-resource language (Somali). We find that our proposed approach\nenables many more parameters to be adapted without over-fitting being observed,\nand is successful even when the initial transcription has a WER in excess of\n50%.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 09:47:47 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Klejch", "Ondrej", ""], ["Fainberg", "Joachim", ""], ["Bell", "Peter", ""], ["Renals", "Steve", ""]]}, {"id": "1906.11565", "submitter": "Kisu Yang", "authors": "Kisu Yang, Dongyub Lee, Taesun Whang, Seolhwa Lee, Heuiseok Lim", "title": "EmotionX-KU: BERT-Max based Contextual Emotion Classifier", "comments": "The 7th International Workshop on Natural Language Processing for\n  Social Media (in conjunction with IJCAI 2019); figure modified", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a contextual emotion classifier based on a transferable language\nmodel and dynamic max pooling, which predicts the emotion of each utterance in\na dialogue. A representative emotion analysis task, EmotionX, requires to\nconsider contextual information from colloquial dialogues and to deal with a\nclass imbalance problem. To alleviate these problems, our model leverages the\nself-attention based transferable language model and the weighted cross entropy\nloss. Furthermore, we apply post-training and fine-tuning mechanisms to enhance\nthe domain adaptability of our model and utilize several machine learning\ntechniques to improve its performance. We conduct experiments on two\nemotion-labeled datasets named Friends and EmotionPush. As a result, our model\noutperforms the previous state-of-the-art model and also shows competitive\nperformance in the EmotionX 2019 challenge. The code will be available in the\nGithub page.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 11:46:48 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 09:30:45 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Yang", "Kisu", ""], ["Lee", "Dongyub", ""], ["Whang", "Taesun", ""], ["Lee", "Seolhwa", ""], ["Lim", "Heuiseok", ""]]}, {"id": "1906.11604", "submitter": "Suyoun Kim", "authors": "Suyoun Kim, Siddharth Dalmia, Florian Metze", "title": "Gated Embeddings in End-to-End Speech Recognition for\n  Conversational-Context Fusion", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel conversational-context aware end-to-end speech recognizer\nbased on a gated neural network that incorporates\nconversational-context/word/speech embeddings. Unlike conventional speech\nrecognition models, our model learns longer conversational-context information\nthat spans across sentences and is consequently better at recognizing long\nconversations. Specifically, we propose to use the text-based external word\nand/or sentence embeddings (i.e., fastText, BERT) within an end-to-end\nframework, yielding a significant improvement in word error rate with better\nconversational-context representation. We evaluated the models on the\nSwitchboard conversational speech corpus and show that our model outperforms\nstandard end-to-end speech recognition models.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 13:10:37 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Kim", "Suyoun", ""], ["Dalmia", "Siddharth", ""], ["Metze", "Florian", ""]]}, {"id": "1906.11608", "submitter": "Leon Derczynski", "authors": "Leon Derczynski", "title": "Simple Natural Language Processing Tools for Danish", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This technical note describes a set of baseline tools for automatic\nprocessing of Danish text. The tools are machine-learning based, using natural\nlanguage processing models trained over previously annotated documents. They\nare maintained at ITU Copenhagen and will always be freely available.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 13:15:12 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2019 08:16:08 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Derczynski", "Leon", ""]]}, {"id": "1906.11746", "submitter": "Matthias Lindemann", "authors": "Matthias Lindemann and Jonas Groschwitz and Alexander Koller", "title": "Compositional Semantic Parsing Across Graphbanks", "comments": "Accepted at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most semantic parsers that map sentences to graph-based meaning\nrepresentations are hand-designed for specific graphbanks. We present a\ncompositional neural semantic parser which achieves, for the first time,\ncompetitive accuracies across a diverse range of graphbanks. Incorporating BERT\nembeddings and multi-task learning improves the accuracy further, setting new\nstates of the art on DM, PAS, PSD, AMR 2015 and EDS.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 15:50:59 GMT"}, {"version": "v2", "created": "Sat, 13 Jul 2019 10:12:10 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Lindemann", "Matthias", ""], ["Groschwitz", "Jonas", ""], ["Koller", "Alexander", ""]]}, {"id": "1906.11751", "submitter": "Amjad Almahairi", "authors": "Mai Oudah, Amjad Almahairi, Nizar Habash", "title": "The Impact of Preprocessing on Arabic-English Statistical and Neural\n  Machine Translation", "comments": "Accepted to MT Summit 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural networks have become the state-of-the-art approach for machine\ntranslation (MT) in many languages. While linguistically-motivated tokenization\ntechniques were shown to have significant effects on the performance of\nstatistical MT, it remains unclear if those techniques are well suited for\nneural MT. In this paper, we systematically compare neural and statistical MT\nmodels for Arabic-English translation on data preprecossed by various prominent\ntokenization schemes. Furthermore, we consider a range of data and vocabulary\nsizes and compare their effect on both approaches. Our empirical results show\nthat the best choice of tokenization scheme is largely based on the type of\nmodel and the size of data. We also show that we can gain significant\nimprovements using a system selection that combines the output from neural and\nstatistical MT.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 15:53:58 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Oudah", "Mai", ""], ["Almahairi", "Amjad", ""], ["Habash", "Nizar", ""]]}, {"id": "1906.11752", "submitter": "Alexander Koller", "authors": "Antoine Venant and Alexander Koller", "title": "Semantic expressive capacity with bounded memory", "comments": "Accepted at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the capacity of mechanisms for compositional semantic parsing\nto describe relations between sentences and semantic representations.\n  We prove that in order to represent certain relations, mechanisms which are\nsyntactically projective must be able to remember an unbounded number of\nlocations in the semantic representations, where nonprojective mechanisms need\nnot.\n  This is the first result of this kind, and has consequences both for\ngrammar-based and for neural systems.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 15:54:57 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Venant", "Antoine", ""], ["Koller", "Alexander", ""]]}, {"id": "1906.11790", "submitter": "Richard Shin", "authors": "Richard Shin", "title": "Encoding Database Schemas with Relation-Aware Self-Attention for\n  Text-to-SQL Parsers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When translating natural language questions into SQL queries to answer\nquestions from a database, we would like our methods to generalize to domains\nand database schemas outside of the training set. To handle complex questions\nand database schemas with a neural encoder-decoder paradigm, it is critical to\nproperly encode the schema as part of the input with the question. In this\npaper, we use relation-aware self-attention within the encoder so that it can\nreason about how the tables and columns in the provided schema relate to each\nother and use this information in interpreting the question. We achieve\nsignificant gains on the recently-released Spider dataset with 42.94% exact\nmatch accuracy, compared to the 18.96% reported in published work.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 16:52:29 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Shin", "Richard", ""]]}, {"id": "1906.11861", "submitter": "Jat Sharmistha", "authors": "Sharmistha Jat, Hao Tang, Partha Talukdar and Tom Mitchell", "title": "Relating Simple Sentence Representations in Deep Neural Networks and the\n  Brain", "comments": "Association for Computational Linguistics (ACL) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What is the relationship between sentence representations learned by deep\nrecurrent models against those encoded by the brain? Is there any\ncorrespondence between hidden layers of these recurrent models and brain\nregions when processing sentences? Can these deep models be used to synthesize\nbrain data which can then be utilized in other extrinsic tasks? We investigate\nthese questions using sentences with simple syntax and semantics (e.g., The\nbone was eaten by the dog.). We consider multiple neural network architectures,\nincluding recently proposed ELMo and BERT. We use magnetoencephalography (MEG)\nbrain recording data collected from human subjects when they were reading these\nsimple sentences.\n  Overall, we find that BERT's activations correlate the best with MEG brain\ndata. We also find that the deep network representation can be used to generate\nbrain data from new sentences to augment existing brain data.\n  To the best of our knowledge, this is the first work showing that the MEG\nbrain recording when reading a word in a sentence can be used to distinguish\nearlier words in the sentence. Our exploration is also the first to use deep\nneural network representations to generate synthetic brain data and to show\nthat it helps in improving subsequent stimuli decoding task accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 18:23:27 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Jat", "Sharmistha", ""], ["Tang", "Hao", ""], ["Talukdar", "Partha", ""], ["Mitchell", "Tom", ""]]}, {"id": "1906.11889", "submitter": "Lena A. J\\\"ager", "authors": "Lena A. J\\\"ager, Silvia Makowski, Paul Prasse, Sascha Liehr,\n  Maximilian Seidler and Tobias Scheffer", "title": "Deep Eyedentification: Biometric Identification using Micro-Movements of\n  the Eye", "comments": null, "journal-ref": "In: U. Brefeld et al. (Eds.): Machine Learning and Knowledge\n  Discovery in Databases, ECML PKDD 2019, LNCS 11907, pp. 299-314, Springer\n  Nature, Switzerland, 2020", "doi": "10.1007/978-3-030-46147-8_18", "report-no": null, "categories": "cs.CV cs.CL cs.HC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We study involuntary micro-movements of the eye for biometric identification.\nWhile prior studies extract lower-frequency macro-movements from the output of\nvideo-based eye-tracking systems and engineer explicit features of these\nmacro-movements, we develop a deep convolutional architecture that processes\nthe raw eye-tracking signal. Compared to prior work, the network attains a\nlower error rate by one order of magnitude and is faster by two orders of\nmagnitude: it identifies users accurately within seconds.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 10:36:40 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 08:27:02 GMT"}, {"version": "v3", "created": "Thu, 4 Jul 2019 05:14:56 GMT"}, {"version": "v4", "created": "Wed, 15 Apr 2020 10:06:31 GMT"}, {"version": "v5", "created": "Tue, 5 May 2020 08:30:44 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["J\u00e4ger", "Lena A.", ""], ["Makowski", "Silvia", ""], ["Prasse", "Paul", ""], ["Liehr", "Sascha", ""], ["Seidler", "Maximilian", ""], ["Scheffer", "Tobias", ""]]}, {"id": "1906.11894", "submitter": "Michele Alberti", "authors": "Michele Alberti, Lars V\\\"ogtlin, Vinaychandran Pondenkandath, Mathias\n  Seuret, Rolf Ingold, and Marcus Liwicki", "title": "Labeling, Cutting, Grouping: an Efficient Text Line Segmentation Method\n  for Medieval Manuscripts", "comments": null, "journal-ref": "2019 15th IAPR International Conference on Document Analysis and\n  Recognition (ICDAR), Sydney, Australia", "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new way for text-line extraction by integrating\ndeep-learning based pre-classification and state-of-the-art segmentation\nmethods. Text-line extraction in complex handwritten documents poses a\nsignificant challenge, even to the most modern computer vision algorithms.\nHistorical manuscripts are a particularly hard class of documents as they\npresent several forms of noise, such as degradation, bleed-through, interlinear\nglosses, and elaborated scripts. In this work, we propose a novel method which\nuses semantic segmentation at pixel level as intermediate task, followed by a\ntext-line extraction step. We measured the performance of our method on a\nrecent dataset of challenging medieval manuscripts and surpassed\nstate-of-the-art results by reducing the error by 80.7%. Furthermore, we\ndemonstrate the effectiveness of our approach on various other datasets written\nin different scripts. Hence, our contribution is two-fold. First, we\ndemonstrate that semantic pixel segmentation can be used as strong denoising\npre-processing step before performing text line extraction. Second, we\nintroduce a novel, simple and robust algorithm that leverages the high-quality\nsemantic segmentation to achieve a text-line extraction performance of 99.42%\nline IU on a challenging dataset.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 11:06:43 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 11:28:34 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Alberti", "Michele", ""], ["V\u00f6gtlin", "Lars", ""], ["Pondenkandath", "Vinaychandran", ""], ["Seuret", "Mathias", ""], ["Ingold", "Rolf", ""], ["Liwicki", "Marcus", ""]]}, {"id": "1906.11906", "submitter": "Xiaoyi Liu", "authors": "Xiaoyi Liu, Diego Klabjan, Patrick NBless", "title": "Data Extraction from Charts via Single Deep Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic data extraction from charts is challenging for two reasons: there\nexist many relations among objects in a chart, which is not a common\nconsideration in general computer vision problems; and different types of\ncharts may not be processed by the same model. To address these problems, we\npropose a framework of a single deep neural network, which consists of object\ndetection, text recognition and object matching modules. The framework handles\nboth bar and pie charts, and it may also be extended to other types of charts\nby slight revisions and by augmenting the training data. Our model performs\nsuccessfully on 79.4% of test simulated bar charts and 88.0% of test simulated\npie charts, while for charts outside of the training domain it degrades for\n57.5% and 62.3%, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 21:54:50 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Liu", "Xiaoyi", ""], ["Klabjan", "Diego", ""], ["NBless", "Patrick", ""]]}, {"id": "1906.11930", "submitter": "Murthy Devarakonda", "authors": "Ananya Poddar, Bharath Dandala, Murthy Devarakonda", "title": "Training Models to Extract Treatment Plans from Clinical Notes Using\n  Contents of Sections with Headings", "comments": "15 pages, 4 Figures, and 4 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: Using natural language processing (NLP) to find sentences that\nstate treatment plans in a clinical note, would automate plan extraction and\nwould further enable their use in tools that help providers and care managers.\nHowever, as in the most NLP tasks on clinical text, creating gold standard to\ntrain and test NLP models is tedious and expensive. Fortuitously, sometimes but\nnot always clinical notes contain sections with a heading that identifies the\nsection as a plan. Leveraging contents of such labeled sections as a noisy\ntraining data, we assessed accuracy of NLP models trained with the data.\n  Methods: We used common variations of plan headings and rule-based heuristics\nto find plan sections with headings in clinical notes, and we extracted\nsentences from them and formed a noisy training data of plan sentences. We\ntrained Support Vector Machine (SVM) and Convolutional Neural Network (CNN)\nmodels with the data. We measured accuracy of the trained models on the noisy\ndataset using ten-fold cross validation and separately on a set-aside manually\nannotated dataset.\n  Results: About 13% of 117,730 clinical notes contained treatment plans\nsections with recognizable headings in the 1001 longitudinal patient records\nthat were obtained from Cleveland Clinic under an IRB approval. We were able to\nextract and create a noisy training data of 13,492 plan sentences from the\nclinical notes. CNN achieved best F measures, 0.91 and 0.97 in the\ncross-validation and set-aside evaluation experiments respectively. SVM\nslightly underperformed with F measures of 0.89 and 0.96 in the same\nexperiments.\n  Conclusion: Our study showed that the training supervised learning models\nusing noisy plan sentences was effective in identifying them in all clinical\nnotes. More broadly, sections with informal headings in clinical notes can be a\ngood source for generating effective training data.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 19:40:09 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Poddar", "Ananya", ""], ["Dandala", "Bharath", ""], ["Devarakonda", "Murthy", ""]]}, {"id": "1906.11943", "submitter": "Xian Li", "authors": "Xian Li, Paul Michel, Antonios Anastasopoulos, Yonatan Belinkov, Nadir\n  Durrani, Orhan Firat, Philipp Koehn, Graham Neubig, Juan Pino, Hassan Sajjad", "title": "Findings of the First Shared Task on Machine Translation Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We share the findings of the first shared task on improving robustness of\nMachine Translation (MT). The task provides a testbed representing challenges\nfacing MT models deployed in the real world, and facilitates new approaches to\nimprove models; robustness to noisy input and domain mismatch. We focus on two\nlanguage pairs (English-French and English-Japanese), and the submitted systems\nare evaluated on a blind test set consisting of noisy comments on Reddit and\nprofessionally sourced translations. As a new task, we received 23 submissions\nby 11 participating teams from universities, companies, national labs, etc. All\nsubmitted systems achieved large improvements over baselines, with the best\nimprovement having +22.33 BLEU. We evaluated submissions by both human judgment\nand automatic evaluation (BLEU), which shows high correlations (Pearson's r =\n0.94 and 0.95). Furthermore, we conducted a qualitative analysis of the\nsubmitted systems using compare-mt, which revealed their salient differences in\nhandling challenges in this task. Such analysis provides additional insights\nwhen there is occasional disagreement between human judgment and BLEU, e.g.\nsystems better at producing colloquial expressions received higher score from\nhuman judgment.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 20:24:55 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 19:51:52 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Li", "Xian", ""], ["Michel", "Paul", ""], ["Anastasopoulos", "Antonios", ""], ["Belinkov", "Yonatan", ""], ["Durrani", "Nadir", ""], ["Firat", "Orhan", ""], ["Koehn", "Philipp", ""], ["Neubig", "Graham", ""], ["Pino", "Juan", ""], ["Sajjad", "Hassan", ""]]}, {"id": "1906.12035", "submitter": "Xipeng Qiu", "authors": "Xipeng Qiu, Hengzhi Pei, Hang Yan, Xuanjing Huang", "title": "A Concise Model for Multi-Criteria Chinese Word Segmentation with\n  Transformer Encoder", "comments": "Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-criteria Chinese word segmentation (MCCWS) aims to exploit the\nrelations among the multiple heterogeneous segmentation criteria and further\nimprove the performance of each single criterion. Previous work usually regards\nMCCWS as different tasks, which are learned together under the multi-task\nlearning framework. In this paper, we propose a concise but effective unified\nmodel for MCCWS, which is fully-shared for all the criteria. By leveraging the\npowerful ability of the Transformer encoder, the proposed unified model can\nsegment Chinese text according to a unique criterion-token indicating the\noutput criterion. Besides, the proposed unified model can segment both\nsimplified and traditional Chinese and has an excellent transfer capability.\nExperiments on eight datasets with different criteria show that our model\noutperforms our single-criterion baseline model and other multi-criteria\nmodels. Source codes of this paper are available on Github\nhttps://github.com/acphile/MCCWS.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 04:08:15 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 11:02:37 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Qiu", "Xipeng", ""], ["Pei", "Hengzhi", ""], ["Yan", "Hang", ""], ["Huang", "Xuanjing", ""]]}, {"id": "1906.12039", "submitter": "Aditya Siddhant", "authors": "Mihir Kale, Aditya Siddhant, Sreyashi Nag, Radhika Parik, Matthias\n  Grabmair, Anthony Tomasic", "title": "Supervised Contextual Embeddings for Transfer Learning in Natural\n  Language Processing Tasks", "comments": "Appeared in 2nd Learning from Limited Labeled Data (LLD) Workshop at\n  ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained word embeddings are the primary method for transfer learning in\nseveral Natural Language Processing (NLP) tasks. Recent works have focused on\nusing unsupervised techniques such as language modeling to obtain these\nembeddings. In contrast, this work focuses on extracting representations from\nmultiple pre-trained supervised models, which enriches word embeddings with\ntask and domain specific knowledge. Experiments performed in cross-task,\ncross-domain and cross-lingual settings indicate that such supervised\nembeddings are helpful, especially in the low-resource setting, but the extent\nof gains is dependent on the nature of the task and domain. We make our code\npublicly available.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 04:41:06 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Kale", "Mihir", ""], ["Siddhant", "Aditya", ""], ["Nag", "Sreyashi", ""], ["Parik", "Radhika", ""], ["Grabmair", "Matthias", ""], ["Tomasic", "Anthony", ""]]}, {"id": "1906.12068", "submitter": "Dimitar Shterionov", "authors": "Eva Vanmassenhove, Dimitar Shterionov, Andy Way", "title": "Lost in Translation: Loss and Decay of Linguistic Richness in Machine\n  Translation", "comments": "Accepted for publication at the 17th Machine Translation Summit\n  (MTSummit2019), Dublin, Ireland, August 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work presents an empirical approach to quantifying the loss of lexical\nrichness in Machine Translation (MT) systems compared to Human Translation\n(HT). Our experiments show how current MT systems indeed fail to render the\nlexical diversity of human generated or translated text. The inability of MT\nsystems to generate diverse outputs and its tendency to exacerbate already\nfrequent patterns while ignoring less frequent ones, might be the underlying\ncause for, among others, the currently heavily debated issues related to gender\nbiased output. Can we indeed, aside from biased data, talk about an algorithm\nthat exacerbates seen biases?\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 07:31:33 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Vanmassenhove", "Eva", ""], ["Shterionov", "Dimitar", ""], ["Way", "Andy", ""]]}, {"id": "1906.12188", "submitter": "Ahmad Asadi", "authors": "Ahmad Asadi and Reza Safabakhsh", "title": "A Deep Decoder Structure Based on WordEmbedding Regression for An\n  Encoder-Decoder Based Model for Image Captioning", "comments": "19 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating textual descriptions for images has been an attractive problem for\nthe computer vision and natural language processing researchers in recent\nyears. Dozens of models based on deep learning have been proposed to solve this\nproblem. The existing approaches are based on neural encoder-decoder structures\nequipped with the attention mechanism. These methods strive to train decoders\nto minimize the log likelihood of the next word in a sentence given the\nprevious ones, which results in the sparsity of the output space. In this work,\nwe propose a new approach to train decoders to regress the word embedding of\nthe next word with respect to the previous ones instead of minimizing the log\nlikelihood. The proposed method is able to learn and extract long-term\ninformation and can generate longer fine-grained captions without introducing\nany external memory cell. Furthermore, decoders trained by the proposed\ntechnique can take the importance of the generated words into consideration\nwhile generating captions. In addition, a novel semantic attention mechanism is\nproposed that guides attention points through the image, taking the meaning of\nthe previously generated word into account. We evaluate the proposed approach\nwith the MS-COCO dataset. The proposed model outperformed the state of the art\nmodels especially in generating longer captions. It achieved a CIDEr score\nequal to 125.0 and a BLEU-4 score equal to 50.5, while the best scores of the\nstate of the art models are 117.1 and 48.0, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 13:51:59 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Asadi", "Ahmad", ""], ["Safabakhsh", "Reza", ""]]}, {"id": "1906.12230", "submitter": "Andrew Moore", "authors": "Henry B. Moss, Andrew Moore, David S. Leslie, Paul Rayson", "title": "FIESTA: Fast IdEntification of State-of-The-Art models using adaptive\n  bandit algorithms", "comments": "ACL 2019. Code available at: https://github.com/apmoore1/fiesta", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present FIESTA, a model selection approach that significantly reduces the\ncomputational resources required to reliably identify state-of-the-art\nperformance from large collections of candidate models. Despite being known to\nproduce unreliable comparisons, it is still common practice to compare model\nevaluations based on single choices of random seeds. We show that reliable\nmodel selection also requires evaluations based on multiple train-test splits\n(contrary to common practice in many shared tasks). Using bandit theory from\nthe statistics literature, we are able to adaptively determine appropriate\nnumbers of data splits and random seeds used to evaluate each model, focusing\ncomputational resources on the evaluation of promising models whilst avoiding\nwasting evaluations on models with lower performance. Furthermore, our\nuser-friendly Python implementation produces confidence guarantees of correctly\nselecting the optimal model. We evaluate our algorithms by selecting between 8\ntarget-dependent sentiment analysis methods using dramatically fewer model\nevaluations than current model selection approaches.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 14:11:13 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Moss", "Henry B.", ""], ["Moore", "Andrew", ""], ["Leslie", "David S.", ""], ["Rayson", "Paul", ""]]}, {"id": "1906.12284", "submitter": "Denis Emelin", "authors": "Denis Emelin, Ivan Titov, Rico Sennrich", "title": "Widening the Representation Bottleneck in Neural Machine Translation\n  with Lexical Shortcuts", "comments": "Accepted submission to WMT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The transformer is a state-of-the-art neural translation model that uses\nattention to iteratively refine lexical representations with information drawn\nfrom the surrounding context. Lexical features are fed into the first layer and\npropagated through a deep network of hidden layers. We argue that the need to\nrepresent and propagate lexical features in each layer limits the model's\ncapacity for learning and representing other information relevant to the task.\nTo alleviate this bottleneck, we introduce gated shortcut connections between\nthe embedding layer and each subsequent layer within the encoder and decoder.\nThis enables the model to access relevant lexical content dynamically, without\nexpending limited resources on storing it within intermediate states. We show\nthat the proposed modification yields consistent improvements over a baseline\ntransformer on standard WMT translation tasks in 5 translation directions (0.9\nBLEU on average) and reduces the amount of lexical information passed along the\nhidden layers. We furthermore evaluate different ways to integrate lexical\nconnections into the transformer architecture and present ablation experiments\nexploring the effect of proposed shortcuts on model behavior.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 16:14:06 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Emelin", "Denis", ""], ["Titov", "Ivan", ""], ["Sennrich", "Rico", ""]]}, {"id": "1906.12330", "submitter": "Seth Huang", "authors": "Lu Haonan, Seth H. Huang, Tian Ye, Guo Xiuyan", "title": "Graph Star Net for Generalized Multi-Task Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present graph star net (GraphStar), a novel and unified\ngraph neural net architecture which utilizes message-passing relay and\nattention mechanism for multiple prediction tasks - node classification, graph\nclassification and link prediction. GraphStar addresses many earlier challenges\nfacing graph neural nets and achieves non-local representation without\nincreasing the model depth or bearing heavy computational costs. We also\npropose a new method to tackle topic-specific sentiment analysis based on node\nclassification and text classification as graph classification. Our work shows\nthat 'star nodes' can learn effective graph-data representation and improve on\ncurrent methods for the three tasks. Specifically, for graph classification and\nlink prediction, GraphStar outperforms the current state-of-the-art models by\n2-5% on several key benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 03:05:17 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Haonan", "Lu", ""], ["Huang", "Seth H.", ""], ["Ye", "Tian", ""], ["Xiuyan", "Guo", ""]]}]