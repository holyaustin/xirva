[{"id": "1710.00164", "submitter": "Yun-Nung Chen", "authors": "Ta-Chung Chi, Po-Chun Chen, Shang-Yu Su, Yun-Nung Chen", "title": "Speaker Role Contextual Modeling for Language Understanding and Dialogue\n  Policy Learning", "comments": "Accepted by IJCNLP 2017, The 8th International Joint Conference on\n  Natural Language Processing (IJCNLP 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language understanding (LU) and dialogue policy learning are two essential\ncomponents in conversational systems. Human-human dialogues are not\nwell-controlled and often random and unpredictable due to their own goals and\nspeaking habits. This paper proposes a role-based contextual model to consider\ndifferent speaker roles independently based on the various speaking patterns in\nthe multi-turn dialogues. The experiments on the benchmark dataset show that\nthe proposed role-based model successfully learns role-specific behavioral\npatterns for contextual encoding and then significantly improves language\nunderstanding and dialogue policy learning tasks.\n", "versions": [{"version": "v1", "created": "Sat, 30 Sep 2017 08:46:03 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Chi", "Ta-Chung", ""], ["Chen", "Po-Chun", ""], ["Su", "Shang-Yu", ""], ["Chen", "Yun-Nung", ""]]}, {"id": "1710.00165", "submitter": "Shang-Yu Su", "authors": "Po-Chun Chen, Ta-Chung Chi, Shang-Yu Su, Yun-Nung Chen", "title": "Dynamic Time-Aware Attention to Speaker Roles and Contexts for Spoken\n  Language Understanding", "comments": "Accepted by ASRU 2017. arXiv admin note: text overlap with\n  arXiv:1710.00164", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spoken language understanding (SLU) is an essential component in\nconversational systems. Most SLU component treats each utterance independently,\nand then the following components aggregate the multi-turn information in the\nseparate phases. In order to avoid error propagation and effectively utilize\ncontexts, prior work leveraged history for contextual SLU. However, the\nprevious model only paid attention to the content in history utterances without\nconsidering their temporal information and speaker roles. In the dialogues, the\nmost recent utterances should be more important than the least recent ones.\nFurthermore, users usually pay attention to 1) self history for reasoning and\n2) others' utterances for listening, the speaker of the utterances may provides\ninformative cues to help understanding. Therefore, this paper proposes an\nattention-based network that additionally leverages temporal information and\nspeaker role for better SLU, where the attention to contexts and speaker roles\ncan be automatically learned in an end-to-end manner. The experiments on the\nbenchmark Dialogue State Tracking Challenge 4 (DSTC4) dataset show that the\ntime-aware dynamic role attention networks significantly improve the\nunderstanding performance.\n", "versions": [{"version": "v1", "created": "Sat, 30 Sep 2017 08:50:16 GMT"}, {"version": "v2", "created": "Fri, 8 Dec 2017 10:47:58 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Chen", "Po-Chun", ""], ["Chi", "Ta-Chung", ""], ["Su", "Shang-Yu", ""], ["Chen", "Yun-Nung", ""]]}, {"id": "1710.00205", "submitter": "James Henderson", "authors": "Diana Nicoleta Popa, James Henderson", "title": "Bag-of-Vector Embeddings of Dependency Graphs for Semantic Induction", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vector-space models, from word embeddings to neural network parsers, have\nmany advantages for NLP. But how to generalise from fixed-length word vectors\nto a vector space for arbitrary linguistic structures is still unclear. In this\npaper we propose bag-of-vector embeddings of arbitrary linguistic graphs. A\nbag-of-vector space is the minimal nonparametric extension of a vector space,\nallowing the representation to grow with the size of the graph, but not tying\nthe representation to any specific tree or graph structure. We propose\nefficient training and inference algorithms based on tensor factorisation for\nembedding arbitrary graphs in a bag-of-vector space. We demonstrate the\nusefulness of this representation by training bag-of-vector embeddings of\ndependency graphs and evaluating them on unsupervised semantic induction for\nthe Semantic Textual Similarity and Natural Language Inference tasks.\n", "versions": [{"version": "v1", "created": "Sat, 30 Sep 2017 14:21:12 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Popa", "Diana Nicoleta", ""], ["Henderson", "James", ""]]}, {"id": "1710.00273", "submitter": "Jason Dou", "authors": "Jason Dou, Michelle Liu, Haaris Muneer, Adam Schlussel", "title": "What Words Do We Use to Lie?: Word Choice in Deceptive Messages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text messaging is the most widely used form of computer- mediated\ncommunication (CMC). Previous findings have shown that linguistic factors can\nreliably indicate messages as deceptive. For example, users take longer and use\nmore words to craft deceptive messages than they do truthful messages. Existing\nresearch has also examined how factors, such as student status and gender,\naffect rates of deception and word choice in deceptive messages. However, this\nresearch has been limited by small sample sizes and has returned contradicting\nfindings. This paper aims to address these issues by using a dataset of text\nmessages collected from a large and varied set of participants using an Android\nmessaging application. The results of this paper show significant differences\nin word choice and frequency of deceptive messages between male and female\nparticipants, as well as between students and non-students.\n", "versions": [{"version": "v1", "created": "Sun, 1 Oct 2017 00:04:10 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Dou", "Jason", ""], ["Liu", "Michelle", ""], ["Muneer", "Haaris", ""], ["Schlussel", "Adam", ""]]}, {"id": "1710.00284", "submitter": "Liqun Shao", "authors": "Liqun Shao, Hao Zhang, Ming Jia, Jie Wang", "title": "Efficient and Effective Single-Document Summarizations and A\n  Word-Embedding Measurement of Quality", "comments": "10 pages, conference; accepted by KDIR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our task is to generate an effective summary for a given document with\nspecific realtime requirements. We use the softplus function to enhance keyword\nrankings to favor important sentences, based on which we present a number of\nsummarization algorithms using various keyword extraction and topic clustering\nmethods. We show that our algorithms meet the realtime requirements and yield\nthe best ROUGE recall scores on DUC-02 over all previously-known algorithms. We\nshow that our algorithms meet the realtime requirements and yield the best\nROUGE recall scores on DUC-02 over all previously-known algorithms. To evaluate\nthe quality of summaries without human-generated benchmarks, we define a\nmeasure called WESM based on word-embedding using Word Mover's Distance. We\nshow that the orderings of the ROUGE and WESM scores of our algorithms are\nhighly comparable, suggesting that WESM may serve as a viable alternative for\nmeasuring the quality of a summary.\n", "versions": [{"version": "v1", "created": "Sun, 1 Oct 2017 03:36:45 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Shao", "Liqun", ""], ["Zhang", "Hao", ""], ["Jia", "Ming", ""], ["Wang", "Jie", ""]]}, {"id": "1710.00286", "submitter": "Liqun Shao", "authors": "Liqun Shao, Jie Wang", "title": "DTATG: An Automatic Title Generator based on Dependency Trees", "comments": "8 pages, conference: accepted by KDIR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study automatic title generation for a given block of text and present a\nmethod called DTATG to generate titles. DTATG first extracts a small number of\ncentral sentences that convey the main meanings of the text and are in a\nsuitable structure for conversion into a title. DTATG then constructs a\ndependency tree for each of these sentences and removes certain branches using\na Dependency Tree Compression Model we devise. We also devise a title test to\ndetermine if a sentence can be used as a title. If a trimmed sentence passes\nthe title test, then it becomes a title candidate. DTATG selects the title\ncandidate with the highest ranking score as the final title. Our experiments\nshowed that DTATG can generate adequate titles. We also showed that\nDTATG-generated titles have higher F1 scores than those generated by the\nprevious methods.\n", "versions": [{"version": "v1", "created": "Sun, 1 Oct 2017 03:52:37 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Shao", "Liqun", ""], ["Wang", "Jie", ""]]}, {"id": "1710.00341", "submitter": "Preslav Nakov", "authors": "Georgi Karadzhov, Preslav Nakov, Lluis Marquez, Alberto Barron-Cedeno,\n  Ivan Koychev", "title": "Fully Automated Fact Checking Using External Sources", "comments": "RANLP-2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the constantly growing proliferation of false claims online in recent\nyears, there has been also a growing research interest in automatically\ndistinguishing false rumors from factually true claims. Here, we propose a\ngeneral-purpose framework for fully-automatic fact checking using external\nsources, tapping the potential of the entire Web as a knowledge source to\nconfirm or reject a claim. Our framework uses a deep neural network with LSTM\ntext encoding to combine semantic kernels with task-specific embeddings that\nencode a claim together with pieces of potentially-relevant text fragments from\nthe Web, taking the source reliability into account. The evaluation results\nshow good performance on two different tasks and datasets: (i) rumor detection\nand (ii) fact checking of the answers to a question in community question\nanswering forums.\n", "versions": [{"version": "v1", "created": "Sun, 1 Oct 2017 12:54:50 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Karadzhov", "Georgi", ""], ["Nakov", "Preslav", ""], ["Marquez", "Lluis", ""], ["Barron-Cedeno", "Alberto", ""], ["Koychev", "Ivan", ""]]}, {"id": "1710.00346", "submitter": "Preslav Nakov", "authors": "Preslav Nakov and Stephan Vogel", "title": "Robust Tuning Datasets for Statistical Machine Translation", "comments": "RANLP-2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the idea of automatically crafting a tuning dataset for\nStatistical Machine Translation (SMT) that makes the hyper-parameters of the\nSMT system more robust with respect to some specific deficiencies of the\nparameter tuning algorithms. This is an under-explored research direction,\nwhich can allow better parameter tuning. In this paper, we achieve this goal by\nselecting a subset of the available sentence pairs, which are more suitable for\nspecific combinations of optimizers, objective functions, and evaluation\nmeasures. We demonstrate the potential of the idea with the pairwise ranking\noptimization (PRO) optimizer, which is known to yield too short translations.\nWe show that the learning problem can be alleviated by tuning on a subset of\nthe development set, selected based on sentence length. In particular, using\nthe longest 50% of the tuning sentences, we achieve two-fold tuning speedup,\nand improvements in BLEU score that rival those of alternatives, which fix\nBLEU+1's smoothing instead.\n", "versions": [{"version": "v1", "created": "Sun, 1 Oct 2017 13:18:48 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Nakov", "Preslav", ""], ["Vogel", "Stephan", ""]]}, {"id": "1710.00372", "submitter": "Roman Orus", "authors": "Roman Orus, Roger Martin, Juan Uriagereka", "title": "Mathematical foundations of matrix syntax", "comments": "48 pages, 7 figures, 6 tables. Revised version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix syntax is a formal model of syntactic relations in language. The\npurpose of this paper is to explain its mathematical foundations, for an\naudience with some formal background. We make an axiomatic presentation,\nmotivating each axiom on linguistic and practical grounds. The resulting\nmathematical structure resembles some aspects of quantum mechanics. Matrix\nsyntax allows us to describe a number of language phenomena that are otherwise\nvery difficult to explain, such as linguistic chains, and is arguably a more\neconomical theory of language than most of the theories proposed in the context\nof the minimalist program in linguistics. In particular, sentences are\nnaturally modelled as vectors in a Hilbert space with a tensor product\nstructure, built from 2x2 matrices belonging to some specific group.\n", "versions": [{"version": "v1", "created": "Sun, 1 Oct 2017 15:55:17 GMT"}, {"version": "v2", "created": "Mon, 11 Mar 2019 16:57:08 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Orus", "Roman", ""], ["Martin", "Roger", ""], ["Uriagereka", "Juan", ""]]}, {"id": "1710.00453", "submitter": "Alane Suhr", "authors": "Stephanie Zhou, Alane Suhr, Yoav Artzi", "title": "Visual Reasoning with Natural Language", "comments": "AAAI NCHRC 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language provides a widely accessible and expressive interface for\nrobotic agents. To understand language in complex environments, agents must\nreason about the full range of language inputs and their correspondence to the\nworld. Such reasoning over language and vision is an open problem that is\nreceiving increasing attention. While existing data sets focus on visual\ndiversity, they do not display the full range of natural language expressions,\nsuch as counting, set reasoning, and comparisons.\n  We propose a simple task for natural language visual reasoning, where images\nare paired with descriptive statements. The task is to predict if a statement\nis true for the given scene. This abstract describes our existing synthetic\nimages corpus and our current work on collecting real vision data.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 01:52:05 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Zhou", "Stephanie", ""], ["Suhr", "Alane", ""], ["Artzi", "Yoav", ""]]}, {"id": "1710.00477", "submitter": "Santiago Castro", "authors": "Santiago Castro, Luis Chiruzzo, Aiala Ros\\'a, Diego Garat and\n  Guillermo Moncecchi", "title": "A Crowd-Annotated Spanish Corpus for Humor Analysis", "comments": "Camera-ready version of the paper submitted to SocialNLP 2018, with a\n  fixed typo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational Humor involves several tasks, such as humor recognition, humor\ngeneration, and humor scoring, for which it is useful to have human-curated\ndata. In this work we present a corpus of 27,000 tweets written in Spanish and\ncrowd-annotated by their humor value and funniness score, with about four\nannotations per tweet, tagged by 1,300 people over the Internet. It is equally\ndivided between tweets coming from humorous and non-humorous accounts. The\ninter-annotator agreement Krippendorff's alpha value is 0.5710. The dataset is\navailable for general use and can serve as a basis for humor detection and as a\nfirst step to tackle subjectivity.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 04:16:36 GMT"}, {"version": "v2", "created": "Thu, 12 Oct 2017 23:17:52 GMT"}, {"version": "v3", "created": "Mon, 28 May 2018 18:26:21 GMT"}, {"version": "v4", "created": "Thu, 19 Jul 2018 04:52:36 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Castro", "Santiago", ""], ["Chiruzzo", "Luis", ""], ["Ros\u00e1", "Aiala", ""], ["Garat", "Diego", ""], ["Moncecchi", "Guillermo", ""]]}, {"id": "1710.00519", "submitter": "Wenpeng Yin", "authors": "Wenpeng Yin, Hinrich Sch\\\"utze", "title": "Attentive Convolution: Equipping CNNs with RNN-style Attention\n  Mechanisms", "comments": "Camera-ready for TACL. 16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In NLP, convolutional neural networks (CNNs) have benefited less than\nrecurrent neural networks (RNNs) from attention mechanisms. We hypothesize that\nthis is because the attention in CNNs has been mainly implemented as attentive\npooling (i.e., it is applied to pooling) rather than as attentive convolution\n(i.e., it is integrated into convolution). Convolution is the differentiator of\nCNNs in that it can powerfully model the higher-level representation of a word\nby taking into account its local fixed-size context in the input text t^x. In\nthis work, we propose an attentive convolution network, ATTCONV. It extends the\ncontext scope of the convolution operation, deriving higher-level features for\na word not only from local context, but also information extracted from\nnonlocal context by the attention mechanism commonly used in RNNs. This\nnonlocal context can come (i) from parts of the input text t^x that are distant\nor (ii) from extra (i.e., external) contexts t^y. Experiments on sentence\nmodeling with zero-context (sentiment analysis), single-context (textual\nentailment) and multiple-context (claim verification) demonstrate the\neffectiveness of ATTCONV in sentence representation learning with the\nincorporation of context. In particular, attentive convolution outperforms\nattentive pooling and is a strong competitor to popular attentive RNNs.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 07:58:19 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 16:12:16 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Yin", "Wenpeng", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1710.00641", "submitter": "Mirco Ravanelli", "authors": "Mirco Ravanelli, Philemon Brakel, Maurizio Omologo, Yoshua Bengio", "title": "Improving speech recognition by revising gated recurrent units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech recognition is largely taking advantage of deep learning, showing that\nsubstantial benefits can be obtained by modern Recurrent Neural Networks\n(RNNs). The most popular RNNs are Long Short-Term Memory (LSTMs), which\ntypically reach state-of-the-art performance in many tasks thanks to their\nability to learn long-term dependencies and robustness to vanishing gradients.\nNevertheless, LSTMs have a rather complex design with three multiplicative\ngates, that might impair their efficient implementation. An attempt to simplify\nLSTMs has recently led to Gated Recurrent Units (GRUs), which are based on just\ntwo multiplicative gates.\n  This paper builds on these efforts by further revising GRUs and proposing a\nsimplified architecture potentially more suitable for speech recognition. The\ncontribution of this work is two-fold. First, we suggest to remove the reset\ngate in the GRU design, resulting in a more efficient single-gate architecture.\nSecond, we propose to replace tanh with ReLU activations in the state update\nequations. Results show that, in our implementation, the revised architecture\nreduces the per-epoch training time with more than 30% and consistently\nimproves recognition performance across different tasks, input features, and\nnoisy conditions when compared to a standard GRU.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 12:40:50 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Ravanelli", "Mirco", ""], ["Brakel", "Philemon", ""], ["Omologo", "Maurizio", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1710.00683", "submitter": "Xiao-Yong Yan", "authors": "Xiaoyong Yan, Petter Minnhagen", "title": "The Dependence of Frequency Distributions on Multiple Meanings of Words,\n  Codes and Signs", "comments": "10 pages, 12 figures", "journal-ref": "Physica A 490, 554-564 (2018)", "doi": "10.1016/j.physa.2017.08.133", "report-no": null, "categories": "cs.CL eess.AS physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dependence of the frequency distributions due to multiple meanings of\nwords in a text is investigated by deleting letters. By coding the words with\nfewer letters the number of meanings per coded word increases. This increase is\nmeasured and used as an input in a predictive theory. For a text written in\nEnglish, the word-frequency distribution is broad and fat-tailed, whereas if\nthe words are only represented by their first letter the distribution becomes\nexponential. Both distribution are well predicted by the theory, as is the\nwhole sequence obtained by consecutively representing the words by the first\nL=6,5,4,3,2,1 letters. Comparisons of texts written by Chinese characters and\nthe same texts written by letter-codes are made and the similarity of the\ncorresponding frequency-distributions are interpreted as a consequence of the\nmultiple meanings of Chinese characters. This further implies that the\ndifference of the shape for word-frequencies for an English text written by\nletters and a Chinese text written by Chinese characters is due to the coding\nand not to the language per se.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 00:39:25 GMT"}], "update_date": "2017-10-04", "authors_parsed": [["Yan", "Xiaoyong", ""], ["Minnhagen", "Petter", ""]]}, {"id": "1710.00689", "submitter": "Preslav Nakov", "authors": "Martin Boyanov, Ivan Koychev, Preslav Nakov, Alessandro Moschitti,\n  Giovanni Da San Martino", "title": "Building Chatbots from Forum Data: Model Selection Using Question\n  Answering Metrics", "comments": "RANLP-2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to use question answering (QA) data from Web forums to train\nchatbots from scratch, i.e., without dialog training data. First, we extract\npairs of question and answer sentences from the typically much longer texts of\nquestions and answers in a forum. We then use these shorter texts to train\nseq2seq models in a more efficient way. We further improve the parameter\noptimization using a new model selection strategy based on QA measures.\nFinally, we propose to use extrinsic evaluation with respect to a QA task as an\nautomatic evaluation method for chatbots. The evaluation shows that the model\nachieves a MAP of 63.5% on the extrinsic task. Moreover, it can answer\ncorrectly 49.5% of the questions when they are similar to questions asked in\nthe forum, and 47.3% of the questions when they are more conversational in\nstyle.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 14:34:25 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Boyanov", "Martin", ""], ["Koychev", "Ivan", ""], ["Nakov", "Preslav", ""], ["Moschitti", "Alessandro", ""], ["Martino", "Giovanni Da San", ""]]}, {"id": "1710.00803", "submitter": "Marcos Zampieri", "authors": "Marcos Zampieri", "title": "Compiling and Processing Historical and Contemporary Portuguese Corpora", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This technical report describes the framework used for processing three large\nPortuguese corpora. Two corpora contain texts from newspapers, one published in\nBrazil and the other published in Portugal. The third corpus is Colonia, a\nhistorical Portuguese collection containing texts written between the 16th and\nthe early 20th century. The report presents pre-processing methods,\nsegmentation, and annotation of the corpora as well as indexing and querying\nmethods. Finally, it presents published research papers using the corpora.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 17:18:37 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Zampieri", "Marcos", ""]]}, {"id": "1710.00880", "submitter": "Haw-Shiuan Chang", "authors": "Haw-Shiuan Chang, ZiYun Wang, Luke Vilnis, Andrew McCallum", "title": "Distributional Inclusion Vector Embedding for Unsupervised Hypernymy\n  Detection", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling hypernymy, such as poodle is-a dog, is an important generalization\naid to many NLP tasks, such as entailment, coreference, relation extraction,\nand question answering. Supervised learning from labeled hypernym sources, such\nas WordNet, limits the coverage of these models, which can be addressed by\nlearning hypernyms from unlabeled text. Existing unsupervised methods either do\nnot scale to large vocabularies or yield unacceptably poor accuracy. This paper\nintroduces distributional inclusion vector embedding (DIVE), a\nsimple-to-implement unsupervised method of hypernym discovery via per-word\nnon-negative vector embeddings which preserve the inclusion property of word\ncontexts in a low-dimensional and interpretable space. In experimental\nevaluations more comprehensive than any previous literature of which we are\naware-evaluating on 11 datasets using multiple existing as well as newly\nproposed scoring functions-we find that our method provides up to double the\nprecision of previous unsupervised embeddings, and the highest average\nperformance, using a much more compact word representation, and yielding many\nnew state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 19:33:46 GMT"}, {"version": "v2", "created": "Mon, 19 Feb 2018 07:16:39 GMT"}, {"version": "v3", "created": "Tue, 29 May 2018 19:33:43 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Chang", "Haw-Shiuan", ""], ["Wang", "ZiYun", ""], ["Vilnis", "Luke", ""], ["McCallum", "Andrew", ""]]}, {"id": "1710.00888", "submitter": "Jose Berengueres Ph.D", "authors": "Jose Berengueres and Dani Castro", "title": "Sentiment Perception of Readers and Writers in Emoji use", "comments": "8 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous research has traditionally analyzed emoji sentiment from the point\nof view of the reader of the content not the author. Here, we analyze emoji\nsentiment from the point of view of the author and present a emoji sentiment\nbenchmark that was built from an employee happiness dataset where emoji happen\nto be annotated with daily happiness of the author of the comment. The data\nspans over 3 years, and 4k employees of 56 companies based in Barcelona. We\ncompare sentiment of writers to readers. Results indicate that, there is an 82%\nagreement in how emoji sentiment is perceived by readers and writers. Finally,\nwe report that when authors use emoji they report higher levels of happiness.\nEmoji use was not found to be correlated with differences in author moodiness.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 20:07:18 GMT"}, {"version": "v2", "created": "Tue, 9 Jan 2018 23:26:06 GMT"}], "update_date": "2018-01-11", "authors_parsed": [["Berengueres", "Jose", ""], ["Castro", "Dani", ""]]}, {"id": "1710.00923", "submitter": "Michael Gasser", "authors": "Michael Gasser", "title": "Minimal Dependency Translation: a Framework for Computer-Assisted\n  Translation for Under-Resourced Languages", "comments": "EAI International Conference on ICT for Development for Africa\n  September 25-27, 2017, Bahir Dar, Ethiopia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper introduces Minimal Dependency Translation (MDT), an ongoing\nproject to develop a rule-based framework for the creation of rudimentary\nbilingual lexicon-grammars for machine translation and computer-assisted\ntranslation into and out of under-resourced languages as well as initial steps\ntowards an implementation of MDT for English-to-Amharic translation. The basic\nunits in MDT, called groups, are headed multi-item sequences. In addition to\nwordforms, groups may contain lexemes, syntactic-semantic categories, and\ngrammatical features. Each group is associated with one or more translations,\neach of which is a group in a target language. During translation, constraint\nsatisfaction is used to select a set of source-language groups for the input\nsentence and to sequence the words in the associated target-language groups.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 21:56:16 GMT"}], "update_date": "2017-10-04", "authors_parsed": [["Gasser", "Michael", ""]]}, {"id": "1710.00936", "submitter": "Ramnik Arora", "authors": "M. Stone and R. Arora", "title": "Identifying Nominals with No Head Match Co-references Using Deep\n  Learning", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying nominals with no head match is a long-standing challenge in\ncoreference resolution with current systems performing significantly worse than\nhumans. In this paper we present a new neural network architecture which\noutperforms the current state-of-the-art system on the English portion of the\nCoNLL 2012 Shared Task. This is done by using a logistic regression on features\nproduced by two submodels, one of which is has the architecture proposed in\n[CM16a] while the other combines domain specific embeddings of the antecedent\nand the mention. We also propose some simple additional features which seem to\nimprove performance for all models substantially, increasing F1 by almost 4% on\nbasic logistic regression and other complex models.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 23:02:17 GMT"}], "update_date": "2017-10-04", "authors_parsed": [["Stone", "M.", ""], ["Arora", "R.", ""]]}, {"id": "1710.00969", "submitter": "Daqi Zheng", "authors": "Yukun Yan, Daqi Zheng, Zhengdong Lu, Sen Song", "title": "Event Identification as a Decision Process with Non-linear\n  Representation of Text", "comments": "8 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose scale-free Identifier Network(sfIN), a novel model for event\nidentification in documents. In general, sfIN first encodes a document into\nmulti-scale memory stacks, then extracts special events via conducting\nmulti-scale actions, which can be considered as a special type of sequence\nlabelling. The design of large scale actions makes it more efficient processing\na long document. The whole model is trained with both supervised learning and\nreinforcement learning.\n", "versions": [{"version": "v1", "created": "Tue, 3 Oct 2017 03:24:28 GMT"}], "update_date": "2017-10-04", "authors_parsed": [["Yan", "Yukun", ""], ["Zheng", "Daqi", ""], ["Lu", "Zhengdong", ""], ["Song", "Sen", ""]]}, {"id": "1710.00987", "submitter": "Jialiang Zhao", "authors": "Jialiang Zhao and Qi Gao", "title": "Annotation and Detection of Emotion in Text-based Dialogue Systems with\n  CNN", "comments": "7 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge of users' emotion states helps improve human-computer interaction.\nIn this work, we presented EmoNet, an emotion detector of Chinese daily\ndialogues based on deep convolutional neural networks. In order to maintain the\noriginal linguistic features, such as the order, commonly used methods like\nsegmentation and keywords extraction were not adopted, instead we increased the\ndepth of CNN and tried to let CNN learn inner linguistic relationships. Our\nmain contribution is that we presented a new model and a new pipeline which can\nbe used in multi-language environment to solve sentimental problems.\nExperimental results shows EmoNet has a great capacity in learning the emotion\nof dialogues and achieves a better result than other state of art detectors do.\n", "versions": [{"version": "v1", "created": "Tue, 3 Oct 2017 05:19:12 GMT"}], "update_date": "2017-10-04", "authors_parsed": [["Zhao", "Jialiang", ""], ["Gao", "Qi", ""]]}, {"id": "1710.00998", "submitter": "Enrico Santus", "authors": "Emmanuele Chersoni, Enrico Santus, Philippe Blache, Alessandro Lenci", "title": "Is Structure Necessary for Modeling Argument Expectations in\n  Distributional Semantics?", "comments": "conference paper, IWCS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the number of NLP studies dedicated to thematic fit estimation,\nlittle attention has been paid to the related task of composing and updating\nverb argument expectations. The few exceptions have mostly modeled this\nphenomenon with structured distributional models, implicitly assuming a\nsimilarly structured representation of events. Recent experimental evidence,\nhowever, suggests that human processing system could also exploit an\nunstructured \"bag-of-arguments\" type of event representation to predict\nupcoming input. In this paper, we re-implement a traditional structured model\nand adapt it to compare the different hypotheses concerning the degree of\nstructure in our event knowledge, evaluating their relative performance in the\ntask of the argument expectations update.\n", "versions": [{"version": "v1", "created": "Tue, 3 Oct 2017 06:14:31 GMT"}], "update_date": "2017-10-04", "authors_parsed": [["Chersoni", "Emmanuele", ""], ["Santus", "Enrico", ""], ["Blache", "Philippe", ""], ["Lenci", "Alessandro", ""]]}, {"id": "1710.01025", "submitter": "Prasanna Raj Noel Dabre", "authors": "Raj Dabre and Sadao Kurohashi", "title": "MMCR4NLP: Multilingual Multiway Corpora Repository for Natural Language\n  Processing", "comments": "V2: Fixed broken urls V1: 4 pages, Language Resources Paper,\n  Submitted to LREC 2018, parallel corpora, multilingual multiway corpora,\n  machine translation, resource", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilinguality is gradually becoming ubiquitous in the sense that more and\nmore researchers have successfully shown that using additional languages help\nimprove the results in many Natural Language Processing tasks. Multilingual\nMultiway Corpora (MMC) contain the same sentence in multiple languages. Such\ncorpora have been primarily used for Multi-Source and Pivot Language Machine\nTranslation but are also useful for developing multilingual sequence taggers by\ntransfer learning. While these corpora are available, they are not organized\nfor multilingual experiments and researchers need to write boilerplate code\nevery time they want to use said corpora. Moreover, because there is no\nofficial MMC collection it becomes difficult to compare against existing\napproaches. As such we present our work on creating a unified and\nsystematically organized repository of MMC spanning a large number of\nlanguages. We also provide training, development and test splits for corpora\nwhere official splits are unavailable. We hope that this will help speed up the\npace of multilingual NLP research and ensure that NLP researchers obtain\nresults that are more trustable since they can be compared easily. We indicate\ncorpora sources, extraction procedures if any and relevant statistics. We also\nmake our collection public for research purposes.\n", "versions": [{"version": "v1", "created": "Tue, 3 Oct 2017 08:19:24 GMT"}, {"version": "v2", "created": "Wed, 4 Oct 2017 07:46:21 GMT"}, {"version": "v3", "created": "Thu, 14 Feb 2019 07:09:57 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Dabre", "Raj", ""], ["Kurohashi", "Sadao", ""]]}, {"id": "1710.01093", "submitter": "Helen L Bear", "authors": "Helen L. Bear, Richard W. Harvey, Barry-John Theobald, and Yuxuan Lan", "title": "Which phoneme-to-viseme maps best improve visual-only computer\n  lip-reading?", "comments": null, "journal-ref": "Helen L. Bear, Richard W. Harvey, Barry-John Theobald, and Yuxuan\n  Lan. Which phoneme-to-viseme maps best improve visual-only computer\n  lip-reading? Advances in Visual Computing 2014. p230-239", "doi": null, "report-no": null, "categories": "cs.CV cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A critical assumption of all current visual speech recognition systems is\nthat there are visual speech units called visemes which can be mapped to units\nof acoustic speech, the phonemes. Despite there being a number of published\nmaps it is infrequent to see the effectiveness of these tested, particularly on\nvisual-only lip-reading (many works use audio-visual speech). Here we examine\n120 mappings and consider if any are stable across talkers. We show a method\nfor devising maps based on phoneme confusions from an automated lip-reading\nsystem, and we present new mappings that show improvements for individual\ntalkers.\n", "versions": [{"version": "v1", "created": "Tue, 3 Oct 2017 11:44:40 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Bear", "Helen L.", ""], ["Harvey", "Richard W.", ""], ["Theobald", "Barry-John", ""], ["Lan", "Yuxuan", ""]]}, {"id": "1710.01095", "submitter": "Ingrid Falk", "authors": "Ingrid Falk, Fabienne Martin", "title": "Towards an Inferential Lexicon of Event Selecting Predicates for French", "comments": null, "journal-ref": "International Conference on Computational Semantics, Sep 2017,\n  Montpellier, France. 2017", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a manually constructed seed lexicon encoding the inferential\nprofiles of French event selecting predicates across different uses. The\ninferential profile (Karttunen, 1971a) of a verb is designed to capture the\ninferences triggered by the use of this verb in context. It reflects the\ninfluence of the clause-embedding verb on the factuality of the event described\nby the embedded clause. The resource developed provides evidence for the\nfollowing three hypotheses: (i) French implicative verbs have an aspect\ndependent profile (their inferential profile varies with outer aspect), while\nfactive verbs have an aspect independent profile (they keep the same\ninferential profile with both imperfective and perfective aspect); (ii)\nimplicativity decreases with imperfective aspect: the inferences triggered by\nFrench implicative verbs combined with perfective aspect are often weakened\nwhen the same verbs are combined with imperfective aspect; (iii) implicativity\ndecreases with an animate (deep) subject: the inferences triggered by a verb\nwhich is implicative with an inanimate subject are weakened when the same verb\nis used with an animate subject. The resource additionally shows that verbs\nwith different inferential profiles display clearly distinct sub-categorisation\npatterns. In particular, verbs that have both factive and implicative readings\nare shown to prefer infinitival clauses in their implicative reading, and\ntensed clauses in their factive reading.\n", "versions": [{"version": "v1", "created": "Tue, 3 Oct 2017 11:48:37 GMT"}], "update_date": "2017-10-04", "authors_parsed": [["Falk", "Ingrid", ""], ["Martin", "Fabienne", ""]]}, {"id": "1710.01142", "submitter": "Helen L Bear", "authors": "Helen L. Bear, Richard W. Harvey, Yuxuan Lan", "title": "Finding phonemes: improving machine lip-reading", "comments": null, "journal-ref": "Helen L. Bear, Richard W. Harvey, Yuxuan Lan. Finding phonemes:\n  improving machine lip-reading. Audio-Visual Speech Processing (AVSP), 2015\n  p115-120", "doi": null, "report-no": null, "categories": "cs.CV cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine lip-reading there is continued debate and research around the\ncorrect classes to be used for recognition. In this paper we use a structured\napproach for devising speaker-dependent viseme classes, which enables the\ncreation of a set of phoneme-to-viseme maps where each has a different quantity\nof visemes ranging from two to 45. Viseme classes are based upon the mapping of\narticulated phonemes, which have been confused during phoneme recognition, into\nviseme groups. Using these maps, with the LiLIR dataset, we show the effect of\nchanging the viseme map size in speaker-dependent machine lip-reading, measured\nby word recognition correctness and so demonstrate that word recognition with\nphoneme classifiers is not just possible, but often better than word\nrecognition with viseme classifiers. Furthermore, there are intermediate units\nbetween visemes and phonemes which are better still.\n", "versions": [{"version": "v1", "created": "Tue, 3 Oct 2017 13:32:40 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Bear", "Helen L.", ""], ["Harvey", "Richard W.", ""], ["Lan", "Yuxuan", ""]]}, {"id": "1710.01329", "submitter": "Toan Nguyen", "authors": "Toan Q. Nguyen, David Chiang", "title": "Improving Lexical Choice in Neural Machine Translation", "comments": "Accepted at NAACL HLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore two solutions to the problem of mistranslating rare words in\nneural machine translation. First, we argue that the standard output layer,\nwhich computes the inner product of a vector representing the context with all\npossible output word embeddings, rewards frequent words disproportionately, and\nwe propose to fix the norms of both vectors to a constant value. Second, we\nintegrate a simple lexical module which is jointly trained with the rest of the\nmodel. We evaluate our approaches on eight language pairs with data sizes\nranging from 100k to 8M words, and achieve improvements of up to +4.3 BLEU,\nsurpassing phrase-based translation in nearly all settings.\n", "versions": [{"version": "v1", "created": "Tue, 3 Oct 2017 18:15:10 GMT"}, {"version": "v2", "created": "Fri, 6 Oct 2017 20:48:00 GMT"}, {"version": "v3", "created": "Tue, 17 Apr 2018 18:18:22 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Nguyen", "Toan Q.", ""], ["Chiang", "David", ""]]}, {"id": "1710.01411", "submitter": "Mohammad Sadegh Rasooli", "authors": "Maryam Aminian, Mohammad Sadegh Rasooli, Mona Diab", "title": "Transferring Semantic Roles Using Translation and Syntactic Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our paper addresses the problem of annotation projection for semantic role\nlabeling for resource-poor languages using supervised annotations from a\nresource-rich language through parallel data. We propose a transfer method that\nemploys information from source and target syntactic dependencies as well as\nword alignment density to improve the quality of an iterative bootstrapping\nmethod. Our experiments yield a $3.5$ absolute labeled F-score improvement over\na standard annotation projection method.\n", "versions": [{"version": "v1", "created": "Tue, 3 Oct 2017 22:40:05 GMT"}], "update_date": "2017-10-05", "authors_parsed": [["Aminian", "Maryam", ""], ["Rasooli", "Mohammad Sadegh", ""], ["Diab", "Mona", ""]]}, {"id": "1710.01487", "submitter": "Preslav Nakov", "authors": "Giovanni Da San Martino, Salvatore Romeo, Alberto Barron-Cedeno,\n  Shafiq Joty, Lluis Marquez, Alessandro Moschitti, Preslav Nakov", "title": "Cross-Language Question Re-Ranking", "comments": "SIGIR-2017; Community Question Answering; Cross-language Approaches;\n  Question Retrieval; Kernel-based Methods; Neural Networks; Distributed\n  Representations", "journal-ref": "SIGIR 2017: 1145-1148", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study how to find relevant questions in community forums when the language\nof the new questions is different from that of the existing questions in the\nforum. In particular, we explore the Arabic-English language pair. We compare a\nkernel-based system with a feed-forward neural network in a scenario where a\nlarge parallel corpus is available for training a machine translation system,\nbilingual dictionaries, and cross-language word embeddings. We observe that\nboth approaches degrade the performance of the system when working on the\ntranslated text, especially the kernel-based system, which depends heavily on a\nsyntactic kernel. We address this issue using a cross-language tree kernel,\nwhich compares the original Arabic tree to the English trees of the related\nquestions. We show that this kernel almost closes the performance gap with\nrespect to the monolingual system. On the neural network side, we use the\nparallel corpus to train cross-language embeddings, which we then use to\nrepresent the Arabic input and the English related questions in the same space.\nThe results also improve to close to those of the monolingual neural network.\nOverall, the kernel system shows a better performance compared to the neural\nnetwork in all cases.\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 07:23:23 GMT"}], "update_date": "2017-10-05", "authors_parsed": [["Martino", "Giovanni Da San", ""], ["Romeo", "Salvatore", ""], ["Barron-Cedeno", "Alberto", ""], ["Joty", "Shafiq", ""], ["Marquez", "Lluis", ""], ["Moschitti", "Alessandro", ""], ["Nakov", "Preslav", ""]]}, {"id": "1710.01492", "submitter": "Preslav Nakov", "authors": "Preslav Nakov", "title": "Semantic Sentiment Analysis of Twitter Data", "comments": "Microblog sentiment analysis; Twitter opinion mining; In the\n  Encyclopedia on Social Network Analysis and Mining (ESNAM), Second edition.\n  2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet and the proliferation of smart mobile devices have changed the way\ninformation is created, shared, and spreads, e.g., microblogs such as Twitter,\nweblogs such as LiveJournal, social networks such as Facebook, and instant\nmessengers such as Skype and WhatsApp are now commonly used to share thoughts\nand opinions about anything in the surrounding world. This has resulted in the\nproliferation of social media content, thus creating new opportunities to study\npublic opinion at a scale that was never possible before. Naturally, this\nabundance of data has quickly attracted business and research interest from\nvarious fields including marketing, political science, and social studies,\namong many others, which are interested in questions like these: Do people like\nthe new Apple Watch? Do Americans support ObamaCare? How do Scottish feel about\nthe Brexit? Answering these questions requires studying the sentiment of\nopinions people express in social media, which has given rise to the fast\ngrowth of the field of sentiment analysis in social media, with Twitter being\nespecially popular for research due to its scale, representativeness, variety\nof topics discussed, as well as ease of public access to its messages. Here we\npresent an overview of work on sentiment analysis on Twitter.\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 07:57:59 GMT"}], "update_date": "2017-10-05", "authors_parsed": [["Nakov", "Preslav", ""]]}, {"id": "1710.01504", "submitter": "Preslav Nakov", "authors": "Shafiq Joty, Francisco Guzm\\'an, Llu\\'is M\\`arquez, Preslav Nakov", "title": "Discourse Structure in Machine Translation Evaluation", "comments": "machine translation, machine translation evaluation, discourse\n  analysis. Computational Linguistics, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we explore the potential of using sentence-level discourse\nstructure for machine translation evaluation. We first design discourse-aware\nsimilarity measures, which use all-subtree kernels to compare discourse parse\ntrees in accordance with the Rhetorical Structure Theory (RST). Then, we show\nthat a simple linear combination with these measures can help improve various\nexisting machine translation evaluation metrics regarding correlation with\nhuman judgments both at the segment- and at the system-level. This suggests\nthat discourse information is complementary to the information used by many of\nthe existing evaluation metrics, and thus it could be taken into account when\ndeveloping richer evaluation metrics, such as the WMT-14 winning combined\nmetric DiscoTKparty. We also provide a detailed analysis of the relevance of\nvarious discourse elements and relations from the RST parse trees for machine\ntranslation evaluation. In particular we show that: (i) all aspects of the RST\ntree are relevant, (ii) nuclearity is more useful than relation type, and (iii)\nthe similarity of the translation RST tree to the reference tree is positively\ncorrelated with translation quality.\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 08:28:24 GMT"}], "update_date": "2017-10-05", "authors_parsed": [["Joty", "Shafiq", ""], ["Guzm\u00e1n", "Francisco", ""], ["M\u00e0rquez", "Llu\u00eds", ""], ["Nakov", "Preslav", ""]]}, {"id": "1710.01507", "submitter": "Yash Kumar Lal", "authors": "Vaibhav Kumar, Dhruv Khattar, Siddhartha Gairola, Yash Kumar Lal,\n  Vasudeva Varma", "title": "Identifying Clickbait: A Multi-Strategy Approach Using Neural Networks", "comments": "Accepted at SIGIR 2018 as Short Paper", "journal-ref": "\"Identifying Clickbait: A Multi-Strategy Approach Using Neural\n  Networks\". In Proceedings of the 41st International ACM SIGIR Conference on\n  Research and Development in Information Retrieval 2018. Pages: 1225-1228", "doi": "10.1145/3209978.3210144", "report-no": null, "categories": "cs.IR cs.CL cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online media outlets, in a bid to expand their reach and subsequently\nincrease revenue through ad monetisation, have begun adopting clickbait\ntechniques to lure readers to click on articles. The article fails to fulfill\nthe promise made by the headline. Traditional methods for clickbait detection\nhave relied heavily on feature engineering which, in turn, is dependent on the\ndataset it is built for. The application of neural networks for this task has\nonly been explored partially. We propose a novel approach considering all\ninformation found in a social media post. We train a bidirectional LSTM with an\nattention mechanism to learn the extent to which a word contributes to the\npost's clickbait score in a differential manner. We also employ a Siamese net\nto capture the similarity between source and target information. Information\ngleaned from images has not been considered in previous approaches. We learn\nimage embeddings from large amounts of data using Convolutional Neural Networks\nto add another layer of complexity to our model. Finally, we concatenate the\noutputs from the three separate components, serving it as input to a fully\nconnected layer. We conduct experiments over a test corpus of 19538 social\nmedia posts, attaining an F1 score of 65.37% on the dataset bettering the\nprevious state-of-the-art, as well as other proposed approaches, feature\nengineering or otherwise.\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 08:53:12 GMT"}, {"version": "v2", "created": "Wed, 22 Nov 2017 22:41:19 GMT"}, {"version": "v3", "created": "Fri, 9 Feb 2018 13:49:13 GMT"}, {"version": "v4", "created": "Wed, 1 Aug 2018 17:17:16 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Kumar", "Vaibhav", ""], ["Khattar", "Dhruv", ""], ["Gairola", "Siddhartha", ""], ["Lal", "Yash Kumar", ""], ["Varma", "Vasudeva", ""]]}, {"id": "1710.01779", "submitter": "Alexander Panchenko", "authors": "Alexander Panchenko, Eugen Ruppert, Stefano Faralli, Simone Paolo\n  Ponzetto, Chris Biemann", "title": "Building a Web-Scale Dependency-Parsed Corpus from CommonCrawl", "comments": "In Proceedings of the 11th Conference on Language Resources and\n  Evaluation (LREC'2018). Miyazaki, Japan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present DepCC, the largest-to-date linguistically analyzed corpus in\nEnglish including 365 million documents, composed of 252 billion tokens and 7.5\nbillion of named entity occurrences in 14.3 billion sentences from a web-scale\ncrawl of the \\textsc{Common Crawl} project. The sentences are processed with a\ndependency parser and with a named entity tagger and contain provenance\ninformation, enabling various applications ranging from training syntax-based\nword embeddings to open information extraction and question answering. We built\nan index of all sentences and their linguistic meta-data enabling quick search\nacross the corpus. We demonstrate the utility of this corpus on the verb\nsimilarity task by showing that a distributional model trained on our corpus\nyields better results than models trained on smaller corpora, like Wikipedia.\nThis distributional model outperforms the state of art models of verb\nsimilarity trained on smaller corpora on the SimVerb3500 dataset.\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 19:42:37 GMT"}, {"version": "v2", "created": "Wed, 28 Feb 2018 18:14:30 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Panchenko", "Alexander", ""], ["Ruppert", "Eugen", ""], ["Faralli", "Stefano", ""], ["Ponzetto", "Simone Paolo", ""], ["Biemann", "Chris", ""]]}, {"id": "1710.01789", "submitter": "Aodong Li", "authors": "Aodong Li, Shiyue Zhang, Dong Wang and Thomas Fang Zheng", "title": "Enhanced Neural Machine Translation by Learning from Draft", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT) has recently achieved impressive results. A\npotential problem of the existing NMT algorithm, however, is that the decoding\nis conducted from left to right, without considering the right context. This\npaper proposes an two-stage approach to solve the problem. In the first stage,\na conventional attention-based NMT system is used to produce a draft\ntranslation, and in the second stage, a novel double-attention NMT system is\nused to refine the translation, by looking at the original input as well as the\ndraft translation. This drafting-and-refinement can obtain the right-context\ninformation from the draft, hence producing more consistent translations. We\nevaluated this approach using two Chinese-English translation tasks, one with\n44k pairs and 1M pairs respectively. The experiments showed that our approach\nachieved positive improvements over the conventional NMT system: the\nimprovements are 2.4 and 0.9 BLEU points on the small-scale and large-scale\ntasks, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 20:13:43 GMT"}], "update_date": "2017-10-06", "authors_parsed": [["Li", "Aodong", ""], ["Zhang", "Shiyue", ""], ["Wang", "Dong", ""], ["Zheng", "Thomas Fang", ""]]}, {"id": "1710.01799", "submitter": "Kenneth Arnold", "authors": "Kenneth C. Arnold, Kai-Wei Chang, Adam T. Kalai", "title": "Counterfactual Language Model Adaptation for Suggesting Phrases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Mobile devices use language models to suggest words and phrases for use in\ntext entry. Traditional language models are based on contextual word frequency\nin a static corpus of text. However, certain types of phrases, when offered to\nwriters as suggestions, may be systematically chosen more often than their\nfrequency would predict. In this paper, we propose the task of generating\nsuggestions that writers accept, a related but distinct task to making accurate\npredictions. Although this task is fundamentally interactive, we propose a\ncounterfactual setting that permits offline training and evaluation. We find\nthat even a simple language model can capture text characteristics that improve\nacceptability.\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 20:49:52 GMT"}], "update_date": "2017-10-06", "authors_parsed": [["Arnold", "Kenneth C.", ""], ["Chang", "Kai-Wei", ""], ["Kalai", "Adam T.", ""]]}, {"id": "1710.01809", "submitter": "Heike Adel", "authors": "Heike Adel, Ngoc Thang Vu, Katrin Kirchhoff, Dominic Telaar, Tanja\n  Schultz", "title": "Syntactic and Semantic Features For Code-Switching Factored Language\n  Models", "comments": "IEEE/ACM Transactions on Audio, Speech, and Language Processing\n  (Volume: 23, Issue: 3, March 2015)", "journal-ref": null, "doi": "10.1109/TASLP.2015.2389622", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents our latest investigations on different features for\nfactored language models for Code-Switching speech and their effect on\nautomatic speech recognition (ASR) performance. We focus on syntactic and\nsemantic features which can be extracted from Code-Switching text data and\nintegrate them into factored language models. Different possible factors, such\nas words, part-of-speech tags, Brown word clusters, open class words and\nclusters of open class word embeddings are explored. The experimental results\nreveal that Brown word clusters, part-of-speech tags and open-class words are\nthe most effective at reducing the perplexity of factored language models on\nthe Mandarin-English Code-Switching corpus SEAME. In ASR experiments, the model\ncontaining Brown word clusters and part-of-speech tags and the model also\nincluding clusters of open class word embeddings yield the best mixed error\nrate results. In summary, the best language model can significantly reduce the\nperplexity on the SEAME evaluation set by up to 10.8% relative and the mixed\nerror rate by up to 3.4% relative.\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 21:21:30 GMT"}], "update_date": "2017-10-06", "authors_parsed": [["Adel", "Heike", ""], ["Vu", "Ngoc Thang", ""], ["Kirchhoff", "Katrin", ""], ["Telaar", "Dominic", ""], ["Schultz", "Tanja", ""]]}, {"id": "1710.01949", "submitter": "Herman Kamper", "authors": "Herman Kamper, Gregory Shakhnarovich, Karen Livescu", "title": "Semantic speech retrieval with a visually grounded model of\n  untranscribed speech", "comments": "10 pages, 3 figures, 5 tables; accepted to the IEEE/ACM Transactions\n  on Audio, Speech and Language Processing", "journal-ref": "IEEE/ACM Transactions on Audio, Speech and Language Processing 27\n  (2019) 89-98", "doi": "10.1109/TASLP.2018.2872106", "report-no": null, "categories": "cs.CL cs.CV eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is growing interest in models that can learn from unlabelled speech\npaired with visual context. This setting is relevant for low-resource speech\nprocessing, robotics, and human language acquisition research. Here we study\nhow a visually grounded speech model, trained on images of scenes paired with\nspoken captions, captures aspects of semantics. We use an external image tagger\nto generate soft text labels from images, which serve as targets for a neural\nmodel that maps untranscribed speech to (semantic) keyword labels. We introduce\na newly collected data set of human semantic relevance judgements and an\nassociated task, semantic speech retrieval, where the goal is to search for\nspoken utterances that are semantically relevant to a given text query. Without\nseeing any text, the model trained on parallel speech and images achieves a\nprecision of almost 60% on its top ten semantic retrievals. Compared to a\nsupervised model trained on transcriptions, our model matches human judgements\nbetter by some measures, especially in retrieving non-verbatim semantic\nmatches. We perform an extensive analysis of the model and its resulting\nrepresentations.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 10:24:46 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 13:58:31 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Kamper", "Herman", ""], ["Shakhnarovich", "Gregory", ""], ["Livescu", "Karen", ""]]}, {"id": "1710.01977", "submitter": "Thai Le", "authors": "Xinyue Cao, Thai Le, Jason (Jiasheng) Zhang", "title": "Machine Learning Based Detection of Clickbait Posts in Social Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clickbait (headlines) make use of misleading titles that hide critical\ninformation from or exaggerate the content on the landing target pages to\nentice clicks. As clickbaits often use eye-catching wording to attract viewers,\ntarget contents are often of low quality. Clickbaits are especially widespread\non social media such as Twitter, adversely impacting user experience by causing\nimmense dissatisfaction. Hence, it has become increasingly important to put\nforward a widely applicable approach to identify and detect clickbaits. In this\npaper, we make use of a dataset from the clickbait challenge 2017\n(clickbait-challenge.com) comprising of over 21,000 headlines/titles, each of\nwhich is annotated by at least five judgments from crowdsourcing on how\nclickbait it is. We attempt to build an effective computational clickbait\ndetection model on this dataset. We first considered a total of 331 features,\nfiltered out many features to avoid overfitting and improve the running time of\nlearning, and eventually selected the 60 most important features for our final\nmodel. Using these features, Random Forest Regression achieved the following\nresults: MSE=0.035 MSE, Accuracy=0.82, and F1-sore=0.61 on the clickbait class.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 11:54:34 GMT"}], "update_date": "2017-10-06", "authors_parsed": [["Cao", "Xinyue", "", "Jiasheng"], ["Le", "Thai", "", "Jiasheng"], ["Jason", "", "", "Jiasheng"], ["Zhang", "", ""]]}, {"id": "1710.02076", "submitter": "Ignacio Cases", "authors": "Ignacio Cases, Minh-Thang Luong, Christopher Potts", "title": "On the Effective Use of Pretraining for Natural Language Inference", "comments": "This manuscript dates from late Winter 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have excelled at many NLP tasks, but there remain open\nquestions about the performance of pretrained distributed word representations\nand their interaction with weight initialization and other hyperparameters. We\naddress these questions empirically using attention-based sequence-to-sequence\nmodels for natural language inference (NLI). Specifically, we compare three\ntypes of embeddings: random, pretrained (GloVe, word2vec), and retrofitted\n(pretrained plus WordNet information). We show that pretrained embeddings\noutperform both random and retrofitted ones in a large NLI corpus. Further\nexperiments on more controlled data sets shed light on the contexts for which\nretrofitted embeddings can be useful. We also explore two principled approaches\nto initializing the rest of the model parameters, Gaussian and orthogonal,\nshowing that the latter yields gains of up to 2.9% in the NLI task.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 15:29:33 GMT"}], "update_date": "2017-10-06", "authors_parsed": [["Cases", "Ignacio", ""], ["Luong", "Minh-Thang", ""], ["Potts", "Christopher", ""]]}, {"id": "1710.02086", "submitter": "Sreelekha S", "authors": "Sreelekha S, Pushpak Bhattacharyya", "title": "Indowordnets help in Indian Language Machine Translation", "comments": "4 pages with 3 tables submitted to LREC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Being less resource languages, Indian-Indian and English-Indian language MT\nsystem developments faces the difficulty to translate various lexical\nphenomena. In this paper, we present our work on a comparative study of 440\nphrase-based statistical trained models for 110 language pairs across 11 Indian\nlanguages. We have developed 110 baseline Statistical Machine Translation\nsystems. Then we have augmented the training corpus with Indowordnet synset\nword entries of lexical database and further trained 110 models on top of the\nbaseline system. We have done a detailed performance comparison using various\nevaluation metrics such as BLEU score, METEOR and TER. We observed significant\nimprovement in evaluations of translation quality across all the 440 models\nafter using the Indowordnet. These experiments give a detailed insight in two\nways : (1) usage of lexical database with synset mapping for resource poor\nlanguages (2) efficient usage of Indowordnet sysnset mapping. More over, synset\nmapped lexical entries helped the SMT system to handle the ambiguity to a great\nextent during the translation.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 16:03:42 GMT"}, {"version": "v2", "created": "Fri, 6 Oct 2017 04:15:38 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["S", "Sreelekha", ""], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "1710.02093", "submitter": "Sreelekha S", "authors": "Sreelekha S, Pushpak Bhattacharyya", "title": "Morphology Generation for Statistical Machine Translation", "comments": "4 pages 4 tables and 3 figures submitted to LREC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When translating into morphologically rich languages, Statistical MT\napproaches face the problem of data sparsity. The severity of the sparseness\nproblem will be high when the corpus size of morphologically richer language is\nless. Even though we can use factored models to correctly generate\nmorphological forms of words, the problem of data sparseness limits their\nperformance. In this paper, we describe a simple and effective solution which\nis based on enriching the input corpora with various morphological forms of\nwords. We use this method with the phrase-based and factor-based experiments on\ntwo morphologically rich languages: Hindi and Marathi when translating from\nEnglish. We evaluate the performance of our experiments both in terms automatic\nevaluation and subjective evaluation such as adequacy and fluency. We observe\nthat the morphology injection method helps in improving the quality of\ntranslation. We further analyze that the morph injection method helps in\nhandling the data sparseness problem to a great level.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 16:15:23 GMT"}, {"version": "v2", "created": "Thu, 2 Nov 2017 11:03:27 GMT"}, {"version": "v3", "created": "Fri, 10 Nov 2017 05:00:16 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["S", "Sreelekha", ""], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "1710.02095", "submitter": "Preslav Nakov", "authors": "Francisco Guzm\\'an, Shafiq R. Joty, Llu\\'is M\\`arquez, Preslav Nakov", "title": "Machine Translation Evaluation with Neural Networks", "comments": "Machine Translation, Reference-based MT Evaluation, Deep Neural\n  Networks, Distributed Representation of Texts, Textual Similarity", "journal-ref": "Computer Speech & Language 45: 180-200 (2017)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for machine translation evaluation using neural\nnetworks in a pairwise setting, where the goal is to select the better\ntranslation from a pair of hypotheses, given the reference translation. In this\nframework, lexical, syntactic and semantic information from the reference and\nthe two hypotheses is embedded into compact distributed vector representations,\nand fed into a multi-layer neural network that models nonlinear interactions\nbetween each of the hypotheses and the reference, as well as between the two\nhypotheses. We experiment with the benchmark datasets from the WMT Metrics\nshared task, on which we obtain the best results published so far, with the\nbasic network configuration. We also perform a series of experiments to analyze\nand understand the contribution of the different components of the network. We\nevaluate variants and extensions, including fine-tuning of the semantic\nembeddings, and sentence-based representations modeled with convolutional and\nrecurrent neural networks. In summary, the proposed framework is flexible and\ngeneralizable, allows for efficient learning and scoring, and provides an MT\nevaluation metric that correlates with human judgments, and is on par with the\nstate of the art.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 16:18:08 GMT"}], "update_date": "2017-10-06", "authors_parsed": [["Guzm\u00e1n", "Francisco", ""], ["Joty", "Shafiq R.", ""], ["M\u00e0rquez", "Llu\u00eds", ""], ["Nakov", "Preslav", ""]]}, {"id": "1710.02100", "submitter": "Sreelekha S", "authors": "Sreelekha S, Pushpak Bhattacharyya", "title": "Phrase Pair Mappings for Hindi-English Statistical Machine Translation", "comments": "4 pages with 5 tables submitted to LREC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present our work on the creation of lexical resources for\nthe Machine Translation between English and Hindi. We describes the development\nof phrase pair mappings for our experiments and the comparative performance\nevaluation between different trained models on top of the baseline Statistical\nMachine Translation system. We focused on augmenting the parallel corpus with\nmore vocabulary as well as with various inflected forms by exploring different\nways. We have augmented the training corpus with various lexical resources such\nas lexical words, synset words, function words and verb phrases. We have\ndescribed the case studies, automatic and subjective evaluations, detailed\nerror analysis for both the English to Hindi and Hindi to English machine\ntranslation systems. We further analyzed that, there is an incremental growth\nin the quality of machine translation with the usage of various lexical\nresources. Thus lexical resources do help uplift the translation quality of\nresource poor langugaes.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 16:21:55 GMT"}, {"version": "v2", "created": "Thu, 2 Nov 2017 11:00:18 GMT"}, {"version": "v3", "created": "Fri, 10 Nov 2017 05:05:18 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["S", "Sreelekha", ""], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "1710.02187", "submitter": "Benjamin Heinzerling", "authors": "Benjamin Heinzerling and Michael Strube", "title": "BPEmb: Tokenization-free Pre-trained Subword Embeddings in 275 Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present BPEmb, a collection of pre-trained subword unit embeddings in 275\nlanguages, based on Byte-Pair Encoding (BPE). In an evaluation using\nfine-grained entity typing as testbed, BPEmb performs competitively, and for\nsome languages bet- ter than alternative subword approaches, while requiring\nvastly fewer resources and no tokenization. BPEmb is available at\nhttps://github.com/bheinzerling/bpemb\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 19:24:07 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Heinzerling", "Benjamin", ""], ["Strube", "Michael", ""]]}, {"id": "1710.02318", "submitter": "Shuming Ma", "authors": "Shuming Ma, Xu Sun", "title": "A Semantic Relevance Based Neural Network for Text Summarization and\n  Text Simplification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text summarization and text simplification are two major ways to simplify the\ntext for poor readers, including children, non-native speakers, and the\nfunctionally illiterate. Text summarization is to produce a brief summary of\nthe main ideas of the text, while text simplification aims to reduce the\nlinguistic complexity of the text and retain the original meaning. Recently,\nmost approaches for text summarization and text simplification are based on the\nsequence-to-sequence model, which achieves much success in many text generation\ntasks. However, although the generated simplified texts are similar to source\ntexts literally, they have low semantic relevance. In this work, our goal is to\nimprove semantic relevance between source texts and simplified texts for text\nsummarization and text simplification. We introduce a Semantic Relevance Based\nneural model to encourage high semantic similarity between texts and summaries.\nIn our model, the source text is represented by a gated attention encoder,\nwhile the summary representation is produced by a decoder. Besides, the\nsimilarity score between the representations is maximized during training. Our\nexperiments show that the proposed model outperforms the state-of-the-art\nsystems on two benchmark corpus.\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 09:06:33 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Ma", "Shuming", ""], ["Sun", "Xu", ""]]}, {"id": "1710.02365", "submitter": "Pavel Kral", "authors": "Pavel Kr\\'al, Ladislav Lenc", "title": "Czech Text Document Corpus v 2.0", "comments": "Accepted for LREC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces \"Czech Text Document Corpus v 2.0\", a collection of\ntext documents for automatic document classification in Czech language. It is\ncomposed of the text documents provided by the Czech News Agency and is freely\navailable for research purposes at http://ctdc.kiv.zcu.cz/. This corpus was\ncreated in order to facilitate a straightforward comparison of the document\nclassification approaches on Czech data. It is particularly dedicated to\nevaluation of multi-label document classification approaches, because one\ndocument is usually labelled with more than one label. Besides the information\nabout the document classes, the corpus is also annotated at the morphological\nlayer. This paper further shows the results of selected state-of-the-art\nmethods on this corpus to offer the possibility of an easy comparison with\nthese approaches.\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 12:22:44 GMT"}, {"version": "v2", "created": "Tue, 30 Jan 2018 21:29:21 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["Kr\u00e1l", "Pavel", ""], ["Lenc", "Ladislav", ""]]}, {"id": "1710.02398", "submitter": "Sreelekha S", "authors": "Sreelekha S, Pushpak Bhattacharyya", "title": "Bilingual Words and Phrase Mappings for Marathi and Hindi SMT", "comments": "5 pages with 5 tables and 2 figures submitted to LREC 2018. arXiv\n  admin note: substantial text overlap with arXiv:1703.01485, arXiv:1710.02100", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lack of proper linguistic resources is the major challenges faced by the\nMachine Translation system developments when dealing with the resource poor\nlanguages. In this paper, we describe effective ways to utilize the lexical\nresources to improve the quality of statistical machine translation. Our\nresearch on the usage of lexical resources mainly focused on two ways, such as;\naugmenting the parallel corpus with more vocabulary and to provide various word\nforms. We have augmented the training corpus with various lexical resources\nsuch as lexical words, function words, kridanta pairs and verb phrases. We have\ndescribed the case studies, evaluations and detailed error analysis for both\nMarathi to Hindi and Hindi to Marathi machine translation systems. From the\nevaluations we observed that, there is an incremental growth in the quality of\nmachine translation as the usage of various lexical resources increases.\nMoreover, usage of various lexical resources helps to improve the coverage and\nquality of machine translation where limited parallel corpus is available.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 16:26:43 GMT"}, {"version": "v2", "created": "Thu, 2 Nov 2017 11:03:21 GMT"}, {"version": "v3", "created": "Fri, 10 Nov 2017 05:02:54 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["S", "Sreelekha", ""], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "1710.02437", "submitter": "James Henderson", "authors": "James Henderson", "title": "Learning Word Embeddings for Hyponymy with Entailment-Based\n  Distributional Semantics", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lexical entailment, such as hyponymy, is a fundamental issue in the semantics\nof natural language. This paper proposes distributional semantic models which\nefficiently learn word embeddings for entailment, using a recently-proposed\nframework for modelling entailment in a vector-space. These models postulate a\nlatent vector for a pseudo-phrase containing two neighbouring word vectors. We\ninvestigate both modelling words as the evidence they contribute about this\nphrase vector, or as the posterior distribution of a one-word phrase vector,\nand find that the posterior vectors perform better. The resulting word\nembeddings outperform the best previous results on predicting hyponymy between\nwords, in unsupervised and semi-supervised experiments.\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 14:54:04 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Henderson", "James", ""]]}, {"id": "1710.02514", "submitter": "Amir Yazdavar", "authors": "Monireh Ebrahimi, Amir Hossein Yazdavar, Amit Sheth", "title": "On the Challenges of Sentiment Analysis for Dynamic Events", "comments": "9 pages, 2 figures ,IEEE Intelligent Systems 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the proliferation of social media over the last decade, determining\npeople's attitude with respect to a specific topic, document, interaction or\nevents has fueled research interest in natural language processing and\nintroduced a new channel called sentiment and emotion analysis. For instance,\nbusinesses routinely look to develop systems to automatically understand their\ncustomer conversations by identifying the relevant content to enhance marketing\ntheir products and managing their reputations. Previous efforts to assess\npeople's sentiment on Twitter have suggested that Twitter may be a valuable\nresource for studying political sentiment and that it reflects the offline\npolitical landscape. According to a Pew Research Center report, in January 2016\n44 percent of US adults stated having learned about the presidential election\nthrough social media. Furthermore, 24 percent reported use of social media\nposts of the two candidates as a source of news and information, which is more\nthan the 15 percent who have used both candidates' websites or emails combined.\nThe first presidential debate between Trump and Hillary was the most tweeted\ndebate ever with 17.1 million tweets.\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 17:46:53 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Ebrahimi", "Monireh", ""], ["Yazdavar", "Amir Hossein", ""], ["Sheth", "Amit", ""]]}, {"id": "1710.02560", "submitter": "Mirco Ravanelli", "authors": "Mirco Ravanelli and Maurizio Omologo", "title": "The DIRHA-English corpus and related tasks for distant-speech\n  recognition in domestic environments", "comments": "ASRU 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the contents and the possible usage of the\nDIRHA-ENGLISH multi-microphone corpus, recently realized under the EC DIRHA\nproject. The reference scenario is a domestic environment equipped with a large\nnumber of microphones and microphone arrays distributed in space.\n  The corpus is composed of both real and simulated material, and it includes\n12 US and 12 UK English native speakers. Each speaker uttered different sets of\nphonetically-rich sentences, newspaper articles, conversational speech,\nkeywords, and commands. From this material, a large set of 1-minute sequences\nwas generated, which also includes typical domestic background noise as well as\ninter/intra-room reverberation effects. Dev and test sets were derived, which\nrepresent a very precious material for different studies on multi-microphone\nspeech processing and distant-speech recognition. Various tasks and\ncorresponding Kaldi recipes have already been developed.\n  The paper reports a first set of baseline results obtained using different\ntechniques, including Deep Neural Networks (DNN), aligned with the\nstate-of-the-art at international level.\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 19:20:38 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Ravanelli", "Mirco", ""], ["Omologo", "Maurizio", ""]]}, {"id": "1710.02569", "submitter": "Ximena Gutierrez-Vasques", "authors": "Ximena Gutierrez-Vasques, Victor Mijangos", "title": "Low-resource bilingual lexicon extraction using graph based word\n  embeddings", "comments": "Draft accepted in MICAI-IJCLA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we focus on the task of automatically extracting bilingual\nlexicon for the language pair Spanish-Nahuatl. This is a low-resource setting\nwhere only a small amount of parallel corpus is available. Most of the\ndownstream methods do not work well under low-resources conditions. This is\nspecially true for the approaches that use vectorial representations like\nWord2Vec. Our proposal is to construct bilingual word vectors from a graph.\nThis graph is generated using translation pairs obtained from an unsupervised\nword alignment method.\n  We show that, in a low-resource setting, these type of vectors are successful\nin representing words in a bilingual semantic space. Moreover, when a linear\ntransformation is applied to translate words from one language to another, our\ngraph based representations considerably outperform the popular setting that\nuses Word2Vec.\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 19:57:59 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Gutierrez-Vasques", "Ximena", ""], ["Mijangos", "Victor", ""]]}, {"id": "1710.02603", "submitter": "Aaron Jaech", "authors": "Aaron Jaech and Mari Ostendorf", "title": "Low-Rank RNN Adaptation for Context-Aware Language Modeling", "comments": "Accepted to TACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A context-aware language model uses location, user and/or domain metadata\n(context) to adapt its predictions. In neural language models, context\ninformation is typically represented as an embedding and it is given to the RNN\nas an additional input, which has been shown to be useful in many applications.\nWe introduce a more powerful mechanism for using context to adapt an RNN by\nletting the context vector control a low-rank transformation of the recurrent\nlayer weight matrix. Experiments show that allowing a greater fraction of the\nmodel parameters to be adjusted has benefits in terms of perplexity and\nclassification for several different types of context.\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 22:40:36 GMT"}, {"version": "v2", "created": "Fri, 4 May 2018 19:56:42 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Jaech", "Aaron", ""], ["Ostendorf", "Mari", ""]]}, {"id": "1710.02650", "submitter": "Johannes Schneider", "authors": "Johannes Schneider", "title": "Topic Modeling based on Keywords and Context", "comments": "SIAM International Conference on Data Mining (SDM), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current topic models often suffer from discovering topics not matching human\nintuition, unnatural switching of topics within documents and high\ncomputational demands. We address these concerns by proposing a topic model and\nan inference algorithm based on automatically identifying characteristic\nkeywords for topics. Keywords influence topic-assignments of nearby words. Our\nalgorithm learns (key)word-topic scores and it self-regulates the number of\ntopics. Inference is simple and easily parallelizable. Qualitative analysis\nyields comparable results to state-of-the-art models (eg. LDA), but with\ndifferent strengths and weaknesses. Quantitative analysis using 9 datasets\nshows gains in terms of classification accuracy, PMI score, computational\nperformance and consistency of topic assignments within documents, while most\noften using less topics.\n", "versions": [{"version": "v1", "created": "Sat, 7 Oct 2017 08:18:12 GMT"}, {"version": "v2", "created": "Sat, 3 Feb 2018 23:36:54 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Schneider", "Johannes", ""]]}, {"id": "1710.02717", "submitter": "Mingbo Ma", "authors": "Mingbo Ma, Liang Huang, Bing Xiang and Bowen Zhou", "title": "Group Sparse CNNs for Question Classification with Answer Sets", "comments": "6, ACL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question classification is an important task with wide applications. However,\ntraditional techniques treat questions as general sentences, ignoring the\ncorresponding answer data. In order to consider answer information into\nquestion modeling, we first introduce novel group sparse autoencoders which\nrefine question representation by utilizing group information in the answer\nset. We then propose novel group sparse CNNs which naturally learn question\nrepresentation with respect to their answers by implanting group sparse\nautoencoders into traditional CNNs. The proposed model significantly outperform\nstrong baselines on four datasets.\n", "versions": [{"version": "v1", "created": "Sat, 7 Oct 2017 18:30:38 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Ma", "Mingbo", ""], ["Huang", "Liang", ""], ["Xiang", "Bing", ""], ["Zhou", "Bowen", ""]]}, {"id": "1710.02718", "submitter": "Mingbo Ma", "authors": "Mingbo Ma, Dapeng Li, Kai Zhao and Liang Huang", "title": "OSU Multimodal Machine Translation System Report", "comments": "5, WMT 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes Oregon State University's submissions to the shared\nWMT'17 task \"multimodal translation task I\". In this task, all the sentence\npairs are image captions in different languages. The key difference between\nthis task and conventional machine translation is that we have corresponding\nimages as additional information for each sentence pair. In this paper, we\nintroduce a simple but effective system which takes an image shared between\ndifferent languages, feeding it into the both encoding and decoding side. We\nreport our system's performance for English-French and English-German with\nFlickr30K (in-domain) and MSCOCO (out-of-domain) datasets. Our system achieves\nthe best performance in TER for English-German for MSCOCO dataset.\n", "versions": [{"version": "v1", "created": "Sat, 7 Oct 2017 18:37:08 GMT"}, {"version": "v2", "created": "Thu, 14 Dec 2017 02:07:11 GMT"}], "update_date": "2017-12-15", "authors_parsed": [["Ma", "Mingbo", ""], ["Li", "Dapeng", ""], ["Zhao", "Kai", ""], ["Huang", "Liang", ""]]}, {"id": "1710.02745", "submitter": "Ishan Verma", "authors": "Kaustubh Mani, Ishan Verma, Hardik Meisheri, Lipika Dey", "title": "Multi-Document Summarization using Distributed Bag-of-Words Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the number of documents on the web is growing exponentially,\nmulti-document summarization is becoming more and more important since it can\nprovide the main ideas in a document set in short time. In this paper, we\npresent an unsupervised centroid-based document-level reconstruction framework\nusing distributed bag of words model. Specifically, our approach selects\nsummary sentences in order to minimize the reconstruction error between the\nsummary and the documents. We apply sentence selection and beam search, to\nfurther improve the performance of our model. Experimental results on two\ndifferent datasets show significant performance gains compared with the\nstate-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Sat, 7 Oct 2017 20:43:27 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 07:27:24 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Mani", "Kaustubh", ""], ["Verma", "Ishan", ""], ["Meisheri", "Hardik", ""], ["Dey", "Lipika", ""]]}, {"id": "1710.02772", "submitter": "Zheqian Chen", "authors": "Zheqian Chen, Rongqin Yang, Bin Cao, Zhou Zhao, Deng Cai, Xiaofei He", "title": "Smarnet: Teaching Machines to Read and Comprehend Like Human", "comments": "8 pages, paper for SQuAD machine comprehension", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Comprehension (MC) is a challenging task in Natural Language\nProcessing field, which aims to guide the machine to comprehend a passage and\nanswer the given question. Many existing approaches on MC task are suffering\nthe inefficiency in some bottlenecks, such as insufficient lexical\nunderstanding, complex question-passage interaction, incorrect answer\nextraction and so on. In this paper, we address these problems from the\nviewpoint of how humans deal with reading tests in a scientific way.\nSpecifically, we first propose a novel lexical gating mechanism to dynamically\ncombine the words and characters representations. We then guide the machines to\nread in an interactive way with attention mechanism and memory network. Finally\nwe add a checking layer to refine the answer for insurance. The extensive\nexperiments on two popular datasets SQuAD and TriviaQA show that our method\nexceeds considerable performance than most state-of-the-art solutions at the\ntime of submission.\n", "versions": [{"version": "v1", "created": "Sun, 8 Oct 2017 02:51:26 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Chen", "Zheqian", ""], ["Yang", "Rongqin", ""], ["Cao", "Bin", ""], ["Zhao", "Zhou", ""], ["Cai", "Deng", ""], ["He", "Xiaofei", ""]]}, {"id": "1710.02855", "submitter": "Anoop Kunchukuttan", "authors": "Anoop Kunchukuttan, Pratik Mehta, Pushpak Bhattacharyya", "title": "The IIT Bombay English-Hindi Parallel Corpus", "comments": "accepted for LREC 2018, 4 pages, parallel corpus for English-Hindi\n  machine translation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the IIT Bombay English-Hindi Parallel Corpus. The corpus is a\ncompilation of parallel corpora previously available in the public domain as\nwell as new parallel corpora we collected. The corpus contains 1.49 million\nparallel segments, of which 694k segments were not previously available in the\npublic domain. The corpus has been pre-processed for machine translation, and\nwe report baseline phrase-based SMT and NMT translation results on this corpus.\nThis corpus has been used in two editions of shared tasks at the Workshop on\nAsian Language Translation (2016 and 2017). The corpus is freely available for\nnon-commercial research. To the best of our knowledge, this is the largest\npublicly available English-Hindi parallel corpus.\n", "versions": [{"version": "v1", "created": "Sun, 8 Oct 2017 16:56:05 GMT"}, {"version": "v2", "created": "Sat, 19 May 2018 20:00:21 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Kunchukuttan", "Anoop", ""], ["Mehta", "Pratik", ""], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "1710.02861", "submitter": "Vijayasaradhi Indurthi", "authors": "Vijayasaradhi Indurthi, Subba Reddy Oota", "title": "Clickbait detection using word embeddings", "comments": "Clickbait Challenge 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clickbait is a pejorative term describing web content that is aimed at\ngenerating online advertising revenue, especially at the expense of quality or\naccuracy, relying on sensationalist headlines or eye-catching thumbnail\npictures to attract click-throughs and to encourage forwarding of the material\nover online social networks. We use distributed word representations of the\nwords in the title as features to identify clickbaits in online news media. We\ntrain a machine learning model using linear regression to predict the cickbait\nscore of a given tweet. Our methods achieve an F1-score of 64.98\\% and an MSE\nof 0.0791. Compared to other methods, our method is simple, fast to train, does\nnot require extensive feature engineering and yet moderately effective.\n", "versions": [{"version": "v1", "created": "Sun, 8 Oct 2017 17:34:03 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Indurthi", "Vijayasaradhi", ""], ["Oota", "Subba Reddy", ""]]}, {"id": "1710.02925", "submitter": "Alice Lai", "authors": "Alice Lai, Yonatan Bisk, Julia Hockenmaier", "title": "Natural Language Inference from Multiple Premises", "comments": "Accepted at IJCNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a novel textual entailment task that requires inference over\nmultiple premise sentences. We present a new dataset for this task that\nminimizes trivial lexical inferences, emphasizes knowledge of everyday events,\nand presents a more challenging setting for textual entailment. We evaluate\nseveral strong neural baselines and analyze how the multiple premise task\ndiffers from standard textual entailment.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 03:07:54 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Lai", "Alice", ""], ["Bisk", "Yonatan", ""], ["Hockenmaier", "Julia", ""]]}, {"id": "1710.02973", "submitter": "Panagiotis Papadakos", "authors": "Alexandros Papangelis, Panagiotis Papadakos, Margarita Kotti, Yannis\n  Stylianou, Yannis Tzitzikas, Dimitris Plexousakis", "title": "LD-SDS: Towards an Expressive Spoken Dialogue System based on\n  Linked-Data", "comments": "Presented in Search Oriented Conversational AI SCAI 17 Workshop,\n  Co-located with ICTIR 17, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we discuss the related challenges and describe an approach\ntowards the fusion of state-of-the-art technologies from the Spoken Dialogue\nSystems (SDS) and the Semantic Web and Information Retrieval domains. We\nenvision a dialogue system named LD-SDS that will support advanced, expressive,\nand engaging user requests, over multiple, complex, rich, and open-domain data\nsources that will leverage the wealth of the available Linked Data.\nSpecifically, we focus on: a) improving the identification, disambiguation and\nlinking of entities occurring in data sources and user input; b) offering\nadvanced query services for exploiting the semantics of the data, with\nreasoning and exploratory capabilities; and c) expanding the typical\ninformation seeking dialogue model (slot filling) to better reflect real-world\nconversational search scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 07:36:18 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Papangelis", "Alexandros", ""], ["Papadakos", "Panagiotis", ""], ["Kotti", "Margarita", ""], ["Stylianou", "Yannis", ""], ["Tzitzikas", "Yannis", ""], ["Plexousakis", "Dimitris", ""]]}, {"id": "1710.03006", "submitter": "Gregor Wiedemann", "authors": "Gregor Wiedemann and Gerhard Heyer", "title": "Page Stream Segmentation with Convolutional Neural Nets Combining\n  Textual and Visual Features", "comments": "Full paper version: 6 pages, 3 figures, 2 tables", "journal-ref": "Proceedings of the 11th International Conference on Language\n  Resources and Evaluation (LREC 2018)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, (retro-)digitizing paper-based files became a major\nundertaking for private and public archives as well as an important task in\nelectronic mailroom applications. As a first step, the workflow involves\nscanning and Optical Character Recognition (OCR) of documents. Preservation of\ndocument contexts of single page scans is a major requirement in this context.\nTo facilitate workflows involving very large amounts of paper scans, page\nstream segmentation (PSS) is the task to automatically separate a stream of\nscanned images into multi-page documents. In a digitization project together\nwith a German federal archive, we developed a novel approach based on\nconvolutional neural networks (CNN) combining image and text features to\nachieve optimal document separation results. Evaluation shows that our PSS\narchitecture achieves an accuracy up to 93 % which can be regarded as a new\nstate-of-the-art for this task.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 09:29:55 GMT"}, {"version": "v2", "created": "Thu, 8 Feb 2018 16:58:00 GMT"}, {"version": "v3", "created": "Mon, 25 Mar 2019 13:57:32 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Wiedemann", "Gregor", ""], ["Heyer", "Gerhard", ""]]}, {"id": "1710.03203", "submitter": "Yujie Lu", "authors": "Yujie Lu and Tatsunori Mori", "title": "Deep Learning Paradigm with Transformed Monolingual Word Embeddings for\n  Multilingual Sentiment Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The surge of social media use brings huge demand of multilingual sentiment\nanalysis (MSA) for unveiling cultural difference. So far, traditional methods\nresorted to machine translation---translating texts in other languages to\nEnglish, and then adopt the methods once worked in English. However, this\nparadigm is conditioned by the quality of machine translation. In this paper,\nwe propose a new deep learning paradigm to assimilate the differences between\nlanguages for MSA. We first pre-train monolingual word embeddings separately,\nthen map word embeddings in different spaces into a shared embedding space, and\nthen finally train a parameter-sharing deep neural network for MSA. The\nexperimental results show that our paradigm is effective. Especially, our CNN\nmodel outperforms a state-of-the-art baseline by around 2.1% in terms of\nclassification accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 17:30:12 GMT"}, {"version": "v2", "created": "Tue, 10 Oct 2017 00:51:23 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Lu", "Yujie", ""], ["Mori", "Tatsunori", ""]]}, {"id": "1710.03255", "submitter": "Bowen Shi", "authors": "Bowen Shi and Karen Livescu", "title": "Multitask training with unlabeled data for end-to-end sign language\n  fingerspelling recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of automatic American Sign Language fingerspelling\nrecognition from video. Prior work has largely relied on frame-level labels,\nhand-crafted features, or other constraints, and has been hampered by the\nscarcity of data for this task. We introduce a model for fingerspelling\nrecognition that addresses these issues. The model consists of an\nauto-encoder-based feature extractor and an attention-based neural\nencoder-decoder, which are trained jointly. The model receives a sequence of\nimage frames and outputs the fingerspelled word, without relying on any\nframe-level training labels or hand-crafted features. In addition, the\nauto-encoder subcomponent makes it possible to leverage unlabeled data to\nimprove the feature learning. The model achieves 11.6% and 4.4% absolute letter\naccuracy improvement respectively in signer-independent and signer-adapted\nfingerspelling recognition over previous approaches that required frame-level\ntraining labels.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 18:21:57 GMT"}, {"version": "v2", "created": "Sun, 17 Feb 2019 22:52:59 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Shi", "Bowen", ""], ["Livescu", "Karen", ""]]}, {"id": "1710.03348", "submitter": "Hamidreza Ghader", "authors": "Hamidreza Ghader, Christof Monz", "title": "What does Attention in Neural Machine Translation Pay Attention to?", "comments": "To appear in IJCNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention in neural machine translation provides the possibility to encode\nrelevant parts of the source sentence at each translation step. As a result,\nattention is considered to be an alignment model as well. However, there is no\nwork that specifically studies attention and provides analysis of what is being\nlearned by attention models. Thus, the question still remains that how\nattention is similar or different from the traditional alignment. In this\npaper, we provide detailed analysis of attention and compare it to traditional\nalignment. We answer the question of whether attention is only capable of\nmodelling translational equivalent or it captures more information. We show\nthat attention is different from alignment in some cases and is capturing\nuseful information other than alignments.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 23:21:34 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Ghader", "Hamidreza", ""], ["Monz", "Christof", ""]]}, {"id": "1710.03430", "submitter": "Seunghyun Yoon", "authors": "Seunghyun Yoon, Joongbo Shin, Kyomin Jung", "title": "Learning to Rank Question-Answer Pairs using Hierarchical Recurrent\n  Encoder with Latent Topic Clustering", "comments": "10 pages, Accepted as a conference paper at NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel end-to-end neural architecture for ranking\ncandidate answers, that adapts a hierarchical recurrent neural network and a\nlatent topic clustering module. With our proposed model, a text is encoded to a\nvector representation from an word-level to a chunk-level to effectively\ncapture the entire meaning. In particular, by adapting the hierarchical\nstructure, our model shows very small performance degradations in longer text\ncomprehension while other state-of-the-art recurrent neural network models\nsuffer from it. Additionally, the latent topic clustering module extracts\nsemantic information from target samples. This clustering module is useful for\nany text related tasks by allowing each data sample to find its nearest topic\ncluster, thus helping the neural network model analyze the entire data. We\nevaluate our models on the Ubuntu Dialogue Corpus and consumer electronic\ndomain question answering dataset, which is related to Samsung products. The\nproposed model shows state-of-the-art results for ranking question-answer\npairs.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 07:26:50 GMT"}, {"version": "v2", "created": "Wed, 21 Feb 2018 04:33:41 GMT"}, {"version": "v3", "created": "Mon, 9 Apr 2018 10:04:00 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Yoon", "Seunghyun", ""], ["Shin", "Joongbo", ""], ["Jung", "Kyomin", ""]]}, {"id": "1710.03476", "submitter": "Rob Van Der Goot", "authors": "Rob van der Goot and Gertjan van Noord", "title": "MoNoise: Modeling Noise Using a Modular Normalization System", "comments": "Source code: https://bitbucket.org/robvanderg/monoise", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose MoNoise: a normalization model focused on generalizability and\nefficiency, it aims at being easily reusable and adaptable. Normalization is\nthe task of translating texts from a non- canonical domain to a more canonical\ndomain, in our case: from social media data to standard language. Our proposed\nmodel is based on a modular candidate generation in which each module is\nresponsible for a different type of normalization action. The most important\ngeneration modules are a spelling correction system and a word embeddings\nmodule. Depending on the definition of the normalization task, a static lookup\nlist can be crucial for performance. We train a random forest classifier to\nrank the candidates, which generalizes well to all different types of\nnormaliza- tion actions. Most features for the ranking originate from the\ngeneration modules; besides these features, N-gram features prove to be an\nimportant source of information. We show that MoNoise beats the\nstate-of-the-art on different normalization benchmarks for English and Dutch,\nwhich all define the task of normalization slightly different.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 09:41:46 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["van der Goot", "Rob", ""], ["van Noord", "Gertjan", ""]]}, {"id": "1710.03501", "submitter": "Laurent Besacier", "authors": "P. Godard, G. Adda, M. Adda-Decker, J. Benjumea, L. Besacier, J.\n  Cooper-Leavitt, G-N. Kouarata, L. Lamel, H. Maynard, M. Mueller, A. Rialland,\n  S. Stueker, F. Yvon, M. Zanon-Boito", "title": "A Very Low Resource Language Speech Corpus for Computational Language\n  Documentation Experiments", "comments": "accepted to LREC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Most speech and language technologies are trained with massive amounts of\nspeech and text information. However, most of the world languages do not have\nsuch resources or stable orthography. Systems constructed under these almost\nzero resource conditions are not only promising for speech technology but also\nfor computational language documentation. The goal of computational language\ndocumentation is to help field linguists to (semi-)automatically analyze and\nannotate audio recordings of endangered and unwritten languages. Example tasks\nare automatic phoneme discovery or lexicon discovery from the speech signal.\nThis paper presents a speech corpus collected during a realistic language\ndocumentation process. It is made up of 5k speech utterances in Mboshi (Bantu\nC25) aligned to French text translations. Speech transcriptions are also made\navailable: they correspond to a non-standard graphemic form close to the\nlanguage phonology. We present how the data was collected, cleaned and\nprocessed and we illustrate its use through a zero-resource task: spoken term\ndiscovery. The dataset is made available to the community for reproducible\ncomputational language documentation experiments and their evaluation.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 10:39:20 GMT"}, {"version": "v2", "created": "Wed, 11 Oct 2017 08:27:29 GMT"}, {"version": "v3", "created": "Thu, 15 Feb 2018 06:32:01 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Godard", "P.", ""], ["Adda", "G.", ""], ["Adda-Decker", "M.", ""], ["Benjumea", "J.", ""], ["Besacier", "L.", ""], ["Cooper-Leavitt", "J.", ""], ["Kouarata", "G-N.", ""], ["Lamel", "L.", ""], ["Maynard", "H.", ""], ["Mueller", "M.", ""], ["Rialland", "A.", ""], ["Stueker", "S.", ""], ["Yvon", "F.", ""], ["Zanon-Boito", "M.", ""]]}, {"id": "1710.03538", "submitter": "Mirco Ravanelli", "authors": "Mirco Ravanelli, Maurizio Omologo", "title": "Contaminated speech training methods for robust DNN-HMM distant speech\n  recognition", "comments": null, "journal-ref": "INTERSPEECH 2015", "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the significant progress made in the last years, state-of-the-art\nspeech recognition technologies provide a satisfactory performance only in the\nclose-talking condition. Robustness of distant speech recognition in adverse\nacoustic conditions, on the other hand, remains a crucial open issue for future\napplications of human-machine interaction. To this end, several advances in\nspeech enhancement, acoustic scene analysis as well as acoustic modeling, have\nrecently contributed to improve the state-of-the-art in the field. One of the\nmost effective approaches to derive a robust acoustic modeling is based on\nusing contaminated speech, which proved helpful in reducing the acoustic\nmismatch between training and testing conditions.\n  In this paper, we revise this classical approach in the context of modern\nDNN-HMM systems, and propose the adoption of three methods, namely, asymmetric\ncontext windowing, close-talk based supervision, and close-talk based\npre-training. The experimental results, obtained using both real and simulated\ndata, show a significant advantage in using these three methods, overall\nproviding a 15% error rate reduction compared to the baseline systems. The same\ntrend in performance is confirmed either using a high-quality training set of\nsmall size, and a large one.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 12:36:45 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Ravanelli", "Mirco", ""], ["Omologo", "Maurizio", ""]]}, {"id": "1710.03743", "submitter": "Mat\\=iss Rikters", "authors": "Mat\\=iss Rikters, Mark Fishel", "title": "Confidence through Attention", "comments": null, "journal-ref": "Machine Translation Summit XVI, Nagoya, Japan, September 2017", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention distributions of the generated translations are a useful bi-product\nof attention-based recurrent neural network translation models and can be\ntreated as soft alignments between the input and output tokens. In this work,\nwe use attention distributions as a confidence metric for output translations.\nWe present two strategies of using the attention distributions: filtering out\nbad translations from a large back-translated corpus, and selecting the best\ntranslation in a hybrid setup of two different translation systems. While\nmanual evaluation indicated only a weak correlation between our confidence\nscore and human judgments, the use-cases showed improvements of up to 2.22 BLEU\npoints for filtering and 0.99 points for hybrid translation, tested on\nEnglish<->German and English<->Latvian translation.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 17:47:41 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Rikters", "Mat\u012bss", ""], ["Fishel", "Mark", ""]]}, {"id": "1710.03838", "submitter": "Dingquan Wang", "authors": "Dingquan Wang, Jason Eisner", "title": "The Galactic Dependencies Treebanks: Getting More Data by Synthesizing\n  New Languages", "comments": "16 pages, 5 figures", "journal-ref": "Transactions of the Association of Computational Linguistics\n  (TACL), 4:491--505, 2016", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We release Galactic Dependencies 1.0---a large set of synthetic languages not\nfound on Earth, but annotated in Universal Dependencies format. This new\nresource aims to provide training and development data for NLP methods that aim\nto adapt to unfamiliar languages. Each synthetic treebank is produced from a\nreal treebank by stochastically permuting the dependents of nouns and/or verbs\nto match the word order of other real languages. We discuss the usefulness,\nrealism, parsability, perplexity, and diversity of the synthetic languages. As\na simple demonstration of the use of Galactic Dependencies, we consider\nsingle-source transfer, which attempts to parse a real target language using a\nparser trained on a \"nearby\" source language. We find that including synthetic\nsource languages somewhat increases the diversity of the source pool, which\nsignificantly improves results for most target languages.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 22:12:46 GMT"}], "update_date": "2017-10-12", "authors_parsed": [["Wang", "Dingquan", ""], ["Eisner", "Jason", ""]]}, {"id": "1710.03877", "submitter": "Dingquan Wang", "authors": "Dingquan Wang, Jason Eisner", "title": "Fine-Grained Prediction of Syntactic Typology: Discovering Latent\n  Structure with Supervised Learning", "comments": "16 pages, 5 figures", "journal-ref": "Transactions of the Association of Computational Linguistics\n  (TACL), 5:147--161, 2017", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to predict the basic word-order facts of a novel language given\nonly a corpus of part-of-speech (POS) sequences. We predict how often direct\nobjects follow their verbs, how often adjectives follow their nouns, and in\ngeneral the directionalities of all dependency relations. Such typological\nproperties could be helpful in grammar induction. While such a problem is\nusually regarded as unsupervised learning, our innovation is to treat it as\nsupervised learning, using a large collection of realistic synthetic languages\nas training data. The supervised learner must identify surface features of a\nlanguage's POS sequence (hand-engineered or neural features) that correlate\nwith the language's deeper structure (latent trees). In the experiment, we\nshow: 1) Given a small set of real languages, it helps to add many synthetic\nlanguages to the training data. 2) Our system is robust even when the POS\nsequences include noise. 3) Our system on this task outperforms a grammar\ninduction baseline by a large margin.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 01:47:21 GMT"}], "update_date": "2017-10-12", "authors_parsed": [["Wang", "Dingquan", ""], ["Eisner", "Jason", ""]]}, {"id": "1710.03954", "submitter": "Mathias Kraus", "authors": "Mathias Kraus, Stefan Feuerriegel", "title": "Decision support from financial disclosures with deep neural networks\n  and transfer learning", "comments": null, "journal-ref": null, "doi": "10.1016/j.dss.2017.10.001", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Company disclosures greatly aid in the process of financial decision-making;\ntherefore, they are consulted by financial investors and automated traders\nbefore exercising ownership in stocks. While humans are usually able to\ncorrectly interpret the content, the same is rarely true of computerized\ndecision support systems, which struggle with the complexity and ambiguity of\nnatural language. A possible remedy is represented by deep learning, which\novercomes several shortcomings of traditional methods of text mining. For\ninstance, recurrent neural networks, such as long short-term memories, employ\nhierarchical structures, together with a large number of hidden layers, to\nautomatically extract features from ordered sequences of words and capture\nhighly non-linear relationships such as context-dependent meanings. However,\ndeep learning has only recently started to receive traction, possibly because\nits performance is largely untested. Hence, this paper studies the use of deep\nneural networks for financial decision support. We additionally experiment with\ntransfer learning, in which we pre-train the network on a different corpus with\na length of 139.1 million words. Our results reveal a higher directional\naccuracy as compared to traditional machine learning when predicting stock\nprice movements in response to financial disclosures. Our work thereby helps to\nhighlight the business value of deep learning and provides recommendations to\npractitioners and executives.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 08:22:10 GMT"}], "update_date": "2017-10-12", "authors_parsed": [["Kraus", "Mathias", ""], ["Feuerriegel", "Stefan", ""]]}, {"id": "1710.03957", "submitter": "Yanran Li", "authors": "Yanran Li, Hui Su, Xiaoyu Shen, Wenjie Li, Ziqiang Cao, Shuzi Niu", "title": "DailyDialog: A Manually Labelled Multi-turn Dialogue Dataset", "comments": "accepted by IJCNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a high-quality multi-turn dialog dataset, DailyDialog, which is\nintriguing in several aspects. The language is human-written and less noisy.\nThe dialogues in the dataset reflect our daily communication way and cover\nvarious topics about our daily life. We also manually label the developed\ndataset with communication intention and emotion information. Then, we evaluate\nexisting approaches on DailyDialog dataset and hope it benefit the research\nfield of dialog systems.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 08:30:30 GMT"}], "update_date": "2017-10-12", "authors_parsed": [["Li", "Yanran", ""], ["Su", "Hui", ""], ["Shen", "Xiaoyu", ""], ["Li", "Wenjie", ""], ["Cao", "Ziqiang", ""], ["Niu", "Shuzi", ""]]}, {"id": "1710.04087", "submitter": "Alexis Conneau", "authors": "Alexis Conneau, Guillaume Lample, Marc'Aurelio Ranzato, Ludovic\n  Denoyer, Herv\\'e J\\'egou", "title": "Word Translation Without Parallel Data", "comments": "ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art methods for learning cross-lingual word embeddings have\nrelied on bilingual dictionaries or parallel corpora. Recent studies showed\nthat the need for parallel data supervision can be alleviated with\ncharacter-level information. While these methods showed encouraging results,\nthey are not on par with their supervised counterparts and are limited to pairs\nof languages sharing a common alphabet. In this work, we show that we can build\na bilingual dictionary between two languages without using any parallel\ncorpora, by aligning monolingual word embedding spaces in an unsupervised way.\nWithout using any character information, our model even outperforms existing\nsupervised methods on cross-lingual tasks for some language pairs. Our\nexperiments demonstrate that our method works very well also for distant\nlanguage pairs, like English-Russian or English-Chinese. We finally describe\nexperiments on the English-Esperanto low-resource language pair, on which there\nonly exists a limited amount of parallel data, to show the potential impact of\nour method in fully unsupervised machine translation. Our code, embeddings and\ndictionaries are publicly available.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 14:24:28 GMT"}, {"version": "v2", "created": "Fri, 10 Nov 2017 14:01:51 GMT"}, {"version": "v3", "created": "Tue, 30 Jan 2018 14:41:51 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Conneau", "Alexis", ""], ["Lample", "Guillaume", ""], ["Ranzato", "Marc'Aurelio", ""], ["Denoyer", "Ludovic", ""], ["J\u00e9gou", "Herv\u00e9", ""]]}, {"id": "1710.04099", "submitter": "Finn {\\AA}rup Nielsen", "authors": "Finn {\\AA}rup Nielsen", "title": "Wembedder: Wikidata entity embedding web service", "comments": "3 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  I present a web service for querying an embedding of entities in the Wikidata\nknowledge graph. The embedding is trained on the Wikidata dump using Gensim's\nWord2Vec implementation and a simple graph walk. A REST API is implemented.\nTogether with the Wikidata API the web service exposes a multilingual resource\nfor over 600'000 Wikidata items and properties.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 14:56:27 GMT"}], "update_date": "2017-10-12", "authors_parsed": [["Nielsen", "Finn \u00c5rup", ""]]}, {"id": "1710.04142", "submitter": "Nishtha Madaan", "authors": "Nishtha Madaan, Sameep Mehta, Mayank Saxena, Aditi Aggarwal, Taneea S\n  Agrawaal, Vrinda Malhotra", "title": "Bollywood Movie Corpus for Text, Images and Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In past few years, several data-sets have been released for text and images.\nWe present an approach to create the data-set for use in detecting and removing\ngender bias from text. We also include a set of challenges we have faced while\ncreating this corpora. In this work, we have worked with movie data from\nWikipedia plots and movie trailers from YouTube. Our Bollywood Movie corpus\ncontains 4000 movies extracted from Wikipedia and 880 trailers extracted from\nYouTube which were released from 1970-2017. The corpus contains csv files with\nthe following data about each movie - Wikipedia title of movie, cast, plot\ntext, co-referenced plot text, soundtrack information, link to movie poster,\ncaption of movie poster, number of males in poster, number of females in\nposter. In addition to that, corresponding to each cast member the following\ndata is available - cast name, cast gender, cast verbs, cast adjectives, cast\nrelations, cast centrality, cast mentions. We present some preliminary results\non the task of bias removal which suggest that the data-set is quite useful for\nperforming such tasks.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 15:51:13 GMT"}], "update_date": "2017-10-12", "authors_parsed": [["Madaan", "Nishtha", ""], ["Mehta", "Sameep", ""], ["Saxena", "Mayank", ""], ["Aggarwal", "Aditi", ""], ["Agrawaal", "Taneea S", ""], ["Malhotra", "Vrinda", ""]]}, {"id": "1710.04203", "submitter": "Giannis Haralabopoulos", "authors": "Giannis Haralabopoulos and Elena Simperl", "title": "Crowdsourcing for Beyond Polarity Sentiment Analysis A Pure Emotion\n  Lexicon", "comments": "Keywords: Beyond Polarity, Pure Sentiment, Crowdsourcing, Sentiment\n  Analysis, Lexicon Acquisition, Reddit, Twitter, Brexit [19 pages, 6 figures,\n  4 tables]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment analysis aims to uncover emotions conveyed through information. In\nits simplest form, it is performed on a polarity basis, where the goal is to\nclassify information with positive or negative emotion. Recent research has\nexplored more nuanced ways to capture emotions that go beyond polarity. For\nthese methods to work, they require a critical resource: a lexicon that is\nappropriate for the task at hand, in terms of the range of emotions it captures\ndiversity. In the past, sentiment analysis lexicons have been created by\nexperts, such as linguists and behavioural scientists, with strict rules.\nLexicon evaluation was also performed by experts or gold standards. In our\npaper, we propose a crowdsourcing method for lexicon acquisition, which is\nscalable, cost-effective, and doesn't require experts or gold standards. We\nalso compare crowd and expert evaluations of the lexicon, to assess the overall\nlexicon quality, and the evaluation capabilities of the crowd.\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 21:38:48 GMT"}], "update_date": "2017-10-12", "authors_parsed": [["Haralabopoulos", "Giannis", ""], ["Simperl", "Elena", ""]]}, {"id": "1710.04312", "submitter": "Kyle Hundman", "authors": "Kyle Hundman, Chris A. Mattmann", "title": "Measurement Context Extraction from Text: Discovering Opportunities and\n  Gaps in Earth Science", "comments": null, "journal-ref": "23rd ACM SIGKDD International Conference on Knowledge Discovery\n  and Data Mining, Data-Driven Discovery Workshop, Halifax, Canada, August 2017", "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Marve, a system for extracting measurement values, units, and\nrelated words from natural language text. Marve uses conditional random fields\n(CRF) to identify measurement values and units, followed by a rule-based system\nto find related entities, descriptors and modifiers within a sentence. Sentence\ntokens are represented by an undirected graphical model, and rules are based on\npart-of-speech and word dependency patterns connecting values and units to\ncontextual words. Marve is unique in its focus on measurement context and early\nexperimentation demonstrates Marve's ability to generate high-precision\nextractions with strong recall. We also discuss Marve's role in refining\nmeasurement requirements for NASA's proposed HyspIRI mission, a hyperspectral\ninfrared imaging satellite that will study the world's ecosystems. In general,\nour work with HyspIRI demonstrates the value of semantic measurement\nextractions in characterizing quantitative discussion contained in large\ncorpuses of natural language text. These extractions accelerate broad,\ncross-cutting research and expose scientists new algorithmic approaches and\nexperimental nuances. They also facilitate identification of scientific\nopportunities enabled by HyspIRI leading to more efficient scientific\ninvestment and research.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 21:37:07 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Hundman", "Kyle", ""], ["Mattmann", "Chris A.", ""]]}, {"id": "1710.04334", "submitter": "Allen Nie", "authors": "Allen Nie, Erin D. Bennett, Noah D. Goodman", "title": "DisSent: Sentence Representation Learning from Explicit Discourse\n  Relations", "comments": "13 pages, 4 figures. ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning effective representations of sentences is one of the core missions\nof natural language understanding. Existing models either train on a vast\namount of text, or require costly, manually curated sentence relation datasets.\nWe show that with dependency parsing and rule-based rubrics, we can curate a\nhigh quality sentence relation task by leveraging explicit discourse relations.\nWe show that our curated dataset provides an excellent signal for learning\nvector representations of sentence meaning, representing relations that can\nonly be determined when the meanings of two sentences are combined. We\ndemonstrate that the automatically curated corpus allows a bidirectional LSTM\nsentence encoder to yield high quality sentence embeddings and can serve as a\nsupervised fine-tuning dataset for larger models such as BERT. Our fixed\nsentence embeddings achieve high performance on a variety of transfer tasks,\nincluding SentEval, and we achieve state-of-the-art results on Penn Discourse\nTreebank's implicit relation prediction task.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 00:56:13 GMT"}, {"version": "v2", "created": "Thu, 3 May 2018 03:52:37 GMT"}, {"version": "v3", "created": "Tue, 14 May 2019 17:21:48 GMT"}, {"version": "v4", "created": "Tue, 4 Jun 2019 07:22:22 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Nie", "Allen", ""], ["Bennett", "Erin D.", ""], ["Goodman", "Noah D.", ""]]}, {"id": "1710.04344", "submitter": "Zeyu Dai", "authors": "Zeyu Dai, Wenlin Yao, Ruihong Huang", "title": "Using Context Events in Neural Network Models for Event Temporal Status\n  Identification", "comments": "Accepted by IJCNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Focusing on the task of identifying event temporal status, we find that\nevents directly or indirectly governing the target event in a dependency tree\nare most important contexts. Therefore, we extract dependency chains containing\ncontext events and use them as input in neural network models, which\nconsistently outperform previous models using local context words as input.\nVisualization verifies that the dependency chain representation can effectively\ncapture the context events which are closely related to the target event and\nplay key roles in predicting event temporal status.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 02:39:45 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Dai", "Zeyu", ""], ["Yao", "Wenlin", ""], ["Huang", "Ruihong", ""]]}, {"id": "1710.04437", "submitter": "Yuichiroh Matsubayashi", "authors": "Yuichiroh Matsubayashi and Kentaro Inui", "title": "Revisiting the Design Issues of Local Models for Japanese\n  Predicate-Argument Structure Analysis", "comments": "6 pages, 2 figures, in IJCNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The research trend in Japanese predicate-argument structure (PAS) analysis is\nshifting from pointwise prediction models with local features to global models\ndesigned to search for globally optimal solutions. However, the existing global\nmodels tend to employ only relatively simple local features; therefore, the\noverall performance gains are rather limited. The importance of designing a\nlocal model is demonstrated in this study by showing that the performance of a\nsophisticated local model can be considerably improved with recent feature\nembedding methods and a feature combination learning based on a neural network,\noutperforming the state-of-the-art global models in $F_1$ on a common benchmark\ndataset.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 10:36:41 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Matsubayashi", "Yuichiroh", ""], ["Inui", "Kentaro", ""]]}, {"id": "1710.04515", "submitter": "Dan Lim", "authors": "Dan Lim", "title": "Convolutional Attention-based Seq2Seq Neural Network for End-to-End ASR", "comments": "Masters thesis, Korea Univ", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis introduces the sequence to sequence model with Luong's attention\nmechanism for end-to-end ASR. It also describes various neural network\nalgorithms including Batch normalization, Dropout and Residual network which\nconstitute the convolutional attention-based seq2seq neural network. Finally\nthe proposed model proved its effectiveness for speech recognition achieving\n15.8% phoneme error rate on TIMIT dataset.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 13:40:43 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Lim", "Dan", ""]]}, {"id": "1710.04600", "submitter": "Deepak Gupta", "authors": "Deepak Gupta, Pabitra Lenka, Harsimran Bedi, Asif Ekbal, Pushpak\n  Bhattacharyya", "title": "Auto Analysis of Customer Feedback using CNN and GRU Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Analyzing customer feedback is the best way to channelize the data into new\nmarketing strategies that benefit entrepreneurs as well as customers. Therefore\nan automated system which can analyze the customer behavior is in great demand.\nUsers may write feedbacks in any language, and hence mining appropriate\ninformation often becomes intractable. Especially in a traditional\nfeature-based supervised model, it is difficult to build a generic system as\none has to understand the concerned language for finding the relevant features.\nIn order to overcome this, we propose deep Convolutional Neural Network (CNN)\nand Recurrent Neural Network (RNN) based approaches that do not require\nhandcrafting of features. We evaluate these techniques for analyzing customer\nfeedback sentences in four languages, namely English, French, Japanese and\nSpanish. Our empirical analysis shows that our models perform well in all the\nfour languages on the setups of IJCNLP Shared Task on Customer Feedback\nAnalysis. Our model achieved the second rank in French, with an accuracy of\n71.75% and third ranks for all the other languages.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 16:33:01 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Gupta", "Deepak", ""], ["Lenka", "Pabitra", ""], ["Bedi", "Harsimran", ""], ["Ekbal", "Asif", ""], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "1710.04802", "submitter": "Jey Han Lau", "authors": "Jey Han Lau, Lianhua Chi, Khoi-Nguyen Tran, Trevor Cohn", "title": "End-to-end Network for Twitter Geolocation Prediction and Hashing", "comments": "10 pages, in Proceedings of the 8th International Joint Conference on\n  Natural Language Processing (IJCNLP 2017) (to appear)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an end-to-end neural network to predict the geolocation of a\ntweet. The network takes as input a number of raw Twitter metadata such as the\ntweet message and associated user account information. Our model is language\nindependent, and despite minimal feature engineering, it is interpretable and\ncapable of learning location indicative words and timing patterns. Compared to\nstate-of-the-art systems, our model outperforms them by 2%-6%. Additionally, we\npropose extensions to the model to compress representation learnt by the\nnetwork into binary codes. Experiments show that it produces compact codes\ncompared to benchmark hashing algorithms. An implementation of the model is\nreleased publicly.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 04:51:18 GMT"}], "update_date": "2017-10-16", "authors_parsed": [["Lau", "Jey Han", ""], ["Chi", "Lianhua", ""], ["Tran", "Khoi-Nguyen", ""], ["Cohn", "Trevor", ""]]}, {"id": "1710.04989", "submitter": "Marcos Zampieri", "authors": "Marcos Zampieri, Shervin Malmasi, Gustavo Paetzold, Lucia Specia", "title": "Complex Word Identification: Challenges in Data Annotation and System\n  Performance", "comments": "Proceedings of the 4th Workshop on NLP Techniques for Educational\n  Applications (NLPTEA 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper revisits the problem of complex word identification (CWI)\nfollowing up the SemEval CWI shared task. We use ensemble classifiers to\ninvestigate how well computational methods can discriminate between complex and\nnon-complex words. Furthermore, we analyze the classification performance to\nunderstand what makes lexical complexity challenging. Our findings show that\nmost systems performed poorly on the SemEval CWI dataset, and one of the\nreasons for that is the way in which human annotation was performed.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 16:24:23 GMT"}], "update_date": "2017-10-16", "authors_parsed": [["Zampieri", "Marcos", ""], ["Malmasi", "Shervin", ""], ["Paetzold", "Gustavo", ""], ["Specia", "Lucia", ""]]}, {"id": "1710.05094", "submitter": "Lifu Huang", "authors": "Zhihao Zhou, Lifu Huang, Heng Ji", "title": "Learning Phrase Embeddings from Paraphrases with GRUs", "comments": "IJCNLP'2017 Workshop on Curation and Applications of Parallel and\n  Comparable Corpora", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Learning phrase representations has been widely explored in many Natural\nLanguage Processing (NLP) tasks (e.g., Sentiment Analysis, Machine Translation)\nand has shown promising improvements. Previous studies either learn\nnon-compositional phrase representations with general word embedding learning\ntechniques or learn compositional phrase representations based on syntactic\nstructures, which either require huge amounts of human annotations or cannot be\neasily generalized to all phrases. In this work, we propose to take advantage\nof large-scaled paraphrase database and present a pair-wise gated recurrent\nunits (pairwise-GRU) framework to generate compositional phrase\nrepresentations. Our framework can be re-used to generate representations for\nany phrases. Experimental results show that our framework achieves\nstate-of-the-art results on several phrase similarity tasks.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 22:55:43 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Zhou", "Zhihao", ""], ["Huang", "Lifu", ""], ["Ji", "Heng", ""]]}, {"id": "1710.05298", "submitter": "Hyemin Ahn", "authors": "Hyemin Ahn, Timothy Ha, Yunho Choi, Hwiyeon Yoo, and Songhwai Oh", "title": "Text2Action: Generative Adversarial Synthesis from Language to Action", "comments": "8 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a generative model which learns the relationship\nbetween language and human action in order to generate a human action sequence\ngiven a sentence describing human behavior. The proposed generative model is a\ngenerative adversarial network (GAN), which is based on the sequence to\nsequence (SEQ2SEQ) model. Using the proposed generative network, we can\nsynthesize various actions for a robot or a virtual agent using a text encoder\nrecurrent neural network (RNN) and an action decoder RNN. The proposed\ngenerative network is trained from 29,770 pairs of actions and sentence\nannotations extracted from MSR-Video-to-Text (MSR-VTT), a large-scale video\ndataset. We demonstrate that the network can generate human-like actions which\ncan be transferred to a Baxter robot, such that the robot performs an action\nbased on a provided sentence. Results show that the proposed generative network\ncorrectly models the relationship between language and action and can generate\na diverse set of actions from the same sentence.\n", "versions": [{"version": "v1", "created": "Sun, 15 Oct 2017 07:51:01 GMT"}, {"version": "v2", "created": "Tue, 24 Oct 2017 06:32:52 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Ahn", "Hyemin", ""], ["Ha", "Timothy", ""], ["Choi", "Yunho", ""], ["Yoo", "Hwiyeon", ""], ["Oh", "Songhwai", ""]]}, {"id": "1710.05364", "submitter": "Yiwei Zhou", "authors": "Yiwei Zhou", "title": "Clickbait Detection in Tweets Using Self-attentive Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clickbait detection in tweets remains an elusive challenge. In this paper, we\ndescribe the solution for the Zingel Clickbait Detector at the Clickbait\nChallenge 2017, which is capable of evaluating each tweet's level of click\nbaiting. We first reformat the regression problem as a multi-classification\nproblem, based on the annotation scheme. To perform multi-classification, we\napply a token-level, self-attentive mechanism on the hidden states of\nbi-directional Gated Recurrent Units (biGRU), which enables the model to\ngenerate tweets' task-specific vector representations by attending to important\ntokens. The self-attentive neural network can be trained end-to-end, without\ninvolving any manual feature engineering. Our detector ranked first in the\nfinal evaluation of Clickbait Challenge 2017.\n", "versions": [{"version": "v1", "created": "Sun, 15 Oct 2017 17:32:59 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Zhou", "Yiwei", ""]]}, {"id": "1710.05370", "submitter": "Erik Velldal", "authors": "Erik Velldal and Lilja {\\O}vrelid and Eivind Alexander Bergem and\n  Cathrine Stadsnes and Samia Touileb and Fredrik J{\\o}rgensen", "title": "NoReC: The Norwegian Review Corpus", "comments": "Pending (non-anonymous) review for LREC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the Norwegian Review Corpus (NoReC), created for training\nand evaluating models for document-level sentiment analysis. The full-text\nreviews have been collected from major Norwegian news sources and cover a range\nof different domains, including literature, movies, video games, restaurants,\nmusic and theater, in addition to product reviews across a range of categories.\nEach review is labeled with a manually assigned score of 1-6, as provided by\nthe rating of the original author. This first release of the corpus comprises\nmore than 35,000 reviews. It is distributed using the CoNLL-U format,\npre-processed using UDPipe, along with a rich set of metadata. The work\nreported in this paper forms part of the SANT initiative (Sentiment Analysis\nfor Norwegian Text), a project seeking to provide resources and tools for\nsentiment analysis and opinion mining for Norwegian. As resources for sentiment\nanalysis have so far been unavailable for Norwegian, NoReC represents a highly\nvaluable and sought-after addition to Norwegian language technology.\n", "versions": [{"version": "v1", "created": "Sun, 15 Oct 2017 18:15:35 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Velldal", "Erik", ""], ["\u00d8vrelid", "Lilja", ""], ["Bergem", "Eivind Alexander", ""], ["Stadsnes", "Cathrine", ""], ["Touileb", "Samia", ""], ["J\u00f8rgensen", "Fredrik", ""]]}, {"id": "1710.05429", "submitter": "Amir Yazdavar", "authors": "Amir Hossein Yazdavar, Hussein S. Al-Olimat, Monireh Ebrahimi,\n  Goonmeet Bajaj, Tanvi Banerjee, Krishnaprasad Thirunarayan, Jyotishman\n  Pathak, Amit Sheth", "title": "Semi-Supervised Approach to Monitoring Clinical Depressive Symptoms in\n  Social Media", "comments": "8 pages, Advances in Social Networks Analysis and Mining (ASONAM),\n  2017 IEEE/ACM International Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rise of social media, millions of people are routinely expressing\ntheir moods, feelings, and daily struggles with mental health issues on social\nmedia platforms like Twitter. Unlike traditional observational cohort studies\nconducted through questionnaires and self-reported surveys, we explore the\nreliable detection of clinical depression from tweets obtained unobtrusively.\nBased on the analysis of tweets crawled from users with self-reported\ndepressive symptoms in their Twitter profiles, we demonstrate the potential for\ndetecting clinical depression symptoms which emulate the PHQ-9 questionnaire\nclinicians use today. Our study uses a semi-supervised statistical model to\nevaluate how the duration of these symptoms and their expression on Twitter (in\nterms of word usage patterns and topical preferences) align with the medical\nfindings reported via the PHQ-9. Our proactive and automatic screening tool is\nable to identify clinical depressive symptoms with an accuracy of 68% and\nprecision of 72%.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 00:52:32 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Yazdavar", "Amir Hossein", ""], ["Al-Olimat", "Hussein S.", ""], ["Ebrahimi", "Monireh", ""], ["Bajaj", "Goonmeet", ""], ["Banerjee", "Tanvi", ""], ["Thirunarayan", "Krishnaprasad", ""], ["Pathak", "Jyotishman", ""], ["Sheth", "Amit", ""]]}, {"id": "1710.05519", "submitter": "Kiem-Hieu Nguyen", "authors": "Kiem-Hieu Nguyen", "title": "BKTreebank: Building a Vietnamese Dependency Treebank", "comments": "Accepted for LREC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dependency treebank is an important resource in any language. In this paper,\nwe present our work on building BKTreebank, a dependency treebank for\nVietnamese. Important points on designing POS tagset, dependency relations, and\nannotation guidelines are discussed. We describe experiments on POS tagging and\ndependency parsing on the treebank. Experimental results show that the treebank\nis a useful resource for Vietnamese language processing.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 05:49:29 GMT"}, {"version": "v2", "created": "Wed, 21 Feb 2018 10:45:32 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Nguyen", "Kiem-Hieu", ""]]}, {"id": "1710.05709", "submitter": "Simon Ostermann", "authors": "Simon Ostermann and Michael Roth and Stefan Thater and Manfred Pinkal", "title": "Aligning Script Events with Narrative Texts", "comments": "6 pages, accepted for *SEM 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Script knowledge plays a central role in text understanding and is relevant\nfor a variety of downstream tasks. In this paper, we consider two recent\ndatasets which provide a rich and general representation of script events in\nterms of paraphrase sets. We introduce the task of mapping event mentions in\nnarrative texts to such script event types, and present a model for this task\nthat exploits rich linguistic representations as well as information on\ntemporal ordering. The results of our experiments demonstrate that this complex\ntask is indeed feasible.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 14:11:38 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 17:08:59 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Ostermann", "Simon", ""], ["Roth", "Michael", ""], ["Thater", "Stefan", ""], ["Pinkal", "Manfred", ""]]}, {"id": "1710.05780", "submitter": "Gerasimos Spanakis", "authors": "Alexander Bartl, Gerasimos Spanakis", "title": "A retrieval-based dialogue system utilizing utterance and context\n  embeddings", "comments": "A shorter version is accepted at ICMLA2017 conference;\n  acknowledgement added; typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding semantically rich and computer-understandable representations for\ntextual dialogues, utterances and words is crucial for dialogue systems (or\nconversational agents), as their performance mostly depends on understanding\nthe context of conversations. Recent research aims at finding distributed\nvector representations (embeddings) for words, such that semantically similar\nwords are relatively close within the vector-space. Encoding the \"meaning\" of\ntext into vectors is a current trend, and text can range from words, phrases\nand documents to actual human-to-human conversations. In recent research\napproaches, responses have been generated utilizing a decoder architecture,\ngiven the vector representation of the current conversation. In this paper, the\nutilization of embeddings for answer retrieval is explored by using\nLocality-Sensitive Hashing Forest (LSH Forest), an Approximate Nearest Neighbor\n(ANN) model, to find similar conversations in a corpus and rank possible\ncandidates. Experimental results on the well-known Ubuntu Corpus (in English)\nand a customer service chat dataset (in Dutch) show that, in combination with a\ncandidate selection method, retrieval-based approaches outperform generative\nones and reveal promising future research directions towards the usability of\nsuch a system.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 15:23:56 GMT"}, {"version": "v2", "created": "Tue, 17 Oct 2017 07:32:32 GMT"}, {"version": "v3", "created": "Fri, 20 Oct 2017 10:16:43 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Bartl", "Alexander", ""], ["Spanakis", "Gerasimos", ""]]}, {"id": "1710.05978", "submitter": "Andreea Salinca", "authors": "Andreea Salinca", "title": "Convolutional Neural Networks for Sentiment Classification on Business\n  Reviews", "comments": "Published in Proceedings of IJCAI Workshop on Semantic Machine\n  Learning, 5 pages", "journal-ref": "Proceedings of IJCAI Workshop on Semantic Machine Learning (SML\n  2017): 35-39", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently Convolutional Neural Networks (CNNs) models have proven remarkable\nresults for text classification and sentiment analysis. In this paper, we\npresent our approach on the task of classifying business reviews using word\nembeddings on a large-scale dataset provided by Yelp: Yelp 2017 challenge\ndataset. We compare word-based CNN using several pre-trained word embeddings\nand end-to-end vector representations for text reviews classification. We\nconduct several experiments to capture the semantic relationship between\nbusiness reviews and we use deep learning techniques that prove that the\nobtained results are competitive with traditional methods.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 20:03:08 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Salinca", "Andreea", ""]]}, {"id": "1710.06071", "submitter": "Franck Dernoncourt", "authors": "Franck Dernoncourt, Ji Young Lee", "title": "PubMed 200k RCT: a Dataset for Sequential Sentence Classification in\n  Medical Abstracts", "comments": "Accepted as a conference paper at IJCNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present PubMed 200k RCT, a new dataset based on PubMed for sequential\nsentence classification. The dataset consists of approximately 200,000\nabstracts of randomized controlled trials, totaling 2.3 million sentences. Each\nsentence of each abstract is labeled with their role in the abstract using one\nof the following classes: background, objective, method, result, or conclusion.\nThe purpose of releasing this dataset is twofold. First, the majority of\ndatasets for sequential short-text classification (i.e., classification of\nshort texts that appear in sequences) are small: we hope that releasing a new\nlarge dataset will help develop more accurate algorithms for this task. Second,\nfrom an application perspective, researchers need better tools to efficiently\nskim through the literature. Automatically classifying each sentence in an\nabstract would help researchers read abstracts more efficiently, especially in\nfields where abstracts may be long, such as the medical field.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 03:22:00 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Dernoncourt", "Franck", ""], ["Lee", "Ji Young", ""]]}, {"id": "1710.06112", "submitter": "Jiawei Hu", "authors": "Jiawei Hu and Qun Liu", "title": "CASICT Tibetan Word Segmentation System for MLWS2017", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We participated in the MLWS 2017 on Tibetan word segmentation task, our\nsystem is trained in a unrestricted way, by introducing a baseline system and\n76w tibetan segmented sentences of ours. In the system character sequence is\nprocessed by the baseline system into word sequence, then a subword unit (BPE\nalgorithm) split rare words into subwords with its corresponding features,\nafter that a neural network classifier is adopted to token each subword into\n\"B,M,E,S\" label, in decoding step a simple rule is used to recover a final word\nsequence. The candidate system for submition is selected by evaluating the\nF-score in dev set pre-extracted from the 76w sentences. Experiment shows that\nthis method can fix segmentation errors of baseline system and result in a\nsignificant performance gain.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 06:05:50 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Hu", "Jiawei", ""], ["Liu", "Qun", ""]]}, {"id": "1710.06280", "submitter": "Sosuke Kobayashi", "authors": "Jun Hatori, Yuta Kikuchi, Sosuke Kobayashi, Kuniyuki Takahashi, Yuta\n  Tsuboi, Yuya Unno, Wilson Ko, Jethro Tan", "title": "Interactively Picking Real-World Objects with Unconstrained Spoken\n  Language Instructions", "comments": "9 pages. International Conference on Robotics and Automation (ICRA)\n  2018. Accompanying videos are available at the following links:\n  https://youtu.be/_Uyv1XIUqhk (the system submitted to ICRA-2018) and\n  http://youtu.be/DGJazkyw0Ws (with improvements after ICRA-2018 submission)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comprehension of spoken natural language is an essential component for robots\nto communicate with human effectively. However, handling unconstrained spoken\ninstructions is challenging due to (1) complex structures including a wide\nvariety of expressions used in spoken language and (2) inherent ambiguity in\ninterpretation of human instructions. In this paper, we propose the first\ncomprehensive system that can handle unconstrained spoken language and is able\nto effectively resolve ambiguity in spoken instructions. Specifically, we\nintegrate deep-learning-based object detection together with natural language\nprocessing technologies to handle unconstrained spoken instructions, and\npropose a method for robots to resolve instruction ambiguity through dialogue.\nThrough our experiments on both a simulated environment as well as a physical\nindustrial robot arm, we demonstrate the ability of our system to understand\nnatural instructions from human operators effectively, and how higher success\nrates of the object picking task can be achieved through an interactive\nclarification process.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 13:46:59 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 03:11:49 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Hatori", "Jun", ""], ["Kikuchi", "Yuta", ""], ["Kobayashi", "Sosuke", ""], ["Takahashi", "Kuniyuki", ""], ["Tsuboi", "Yuta", ""], ["Unno", "Yuya", ""], ["Ko", "Wilson", ""], ["Tan", "Jethro", ""]]}, {"id": "1710.06303", "submitter": "Aditya Mogadala", "authors": "Aditya Mogadala, Umanga Bista, Lexing Xie and Achim Rettinger", "title": "Describing Natural Images Containing Novel Objects with Knowledge Guided\n  Assitance", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Images in the wild encapsulate rich knowledge about varied abstract concepts\nand cannot be sufficiently described with models built only using image-caption\npairs containing selected objects. We propose to handle such a task with the\nguidance of a knowledge base that incorporate many abstract concepts. Our\nmethod is a two-step process where we first build a multi-entity-label image\nrecognition model to predict abstract concepts as image labels and then\nleverage them in the second step as an external semantic attention and\nconstrained inference in the caption generation model for describing images\nthat depict unseen/novel objects. Evaluations show that our models outperform\nmost of the prior work for out-of-domain captioning on MSCOCO and are useful\nfor integration of knowledge and vision in general.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 14:11:37 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Mogadala", "Aditya", ""], ["Bista", "Umanga", ""], ["Xie", "Lexing", ""], ["Rettinger", "Achim", ""]]}, {"id": "1710.06313", "submitter": "Mat\\=iss Rikters", "authors": "Mat\\=iss Rikters and Ond\\v{r}ej Bojar", "title": "Paying Attention to Multi-Word Expressions in Neural Machine Translation", "comments": null, "journal-ref": "Published in Machine Translation Summit XVI, Nagoya, Japan,\n  September 2017", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Processing of multi-word expressions (MWEs) is a known problem for any\nnatural language processing task. Even neural machine translation (NMT)\nstruggles to overcome it. This paper presents results of experiments on\ninvestigating NMT attention allocation to the MWEs and improving automated\ntranslation of sentences that contain MWEs in English->Latvian and\nEnglish->Czech NMT systems. Two improvement strategies were explored -(1)\nbilingual pairs of automatically extracted MWE candidates were added to the\nparallel corpus used to train the NMT system, and (2) full sentences containing\nthe automatically extracted MWE candidates were added to the parallel corpus.\nBoth approaches allowed to increase automated evaluation results. The best\nresult - 0.99 BLEU point increase - has been reached with the first approach,\nwhile with the second approach minimal improvements achieved. We also provide\nopen-source software and tools used for MWE extraction and alignment\ninspection.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 14:27:36 GMT"}, {"version": "v2", "created": "Sat, 4 May 2019 20:50:29 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Rikters", "Mat\u012bss", ""], ["Bojar", "Ond\u0159ej", ""]]}, {"id": "1710.06371", "submitter": "Ivan Vuli\\'c", "authors": "Ivan Vuli\\'c and Nikola Mrk\\v{s}i\\'c", "title": "Specialising Word Vectors for Lexical Entailment", "comments": "NAACL-HLT 2018 (long paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present LEAR (Lexical Entailment Attract-Repel), a novel post-processing\nmethod that transforms any input word vector space to emphasise the asymmetric\nrelation of lexical entailment (LE), also known as the IS-A or\nhyponymy-hypernymy relation. By injecting external linguistic constraints\n(e.g., WordNet links) into the initial vector space, the LE specialisation\nprocedure brings true hyponymy-hypernymy pairs closer together in the\ntransformed Euclidean space. The proposed asymmetric distance measure adjusts\nthe norms of word vectors to reflect the actual WordNet-style hierarchy of\nconcepts. Simultaneously, a joint objective enforces semantic similarity using\nthe symmetric cosine distance, yielding a vector space specialised for both\nlexical relations at once. LEAR specialisation achieves state-of-the-art\nperformance in the tasks of hypernymy directionality, hypernymy detection, and\ngraded lexical entailment, demonstrating the effectiveness and robustness of\nthe proposed asymmetric specialisation model.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 16:39:09 GMT"}, {"version": "v2", "created": "Thu, 19 Apr 2018 13:02:39 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Vuli\u0107", "Ivan", ""], ["Mrk\u0161i\u0107", "Nikola", ""]]}, {"id": "1710.06390", "submitter": "Maria Glenski", "authors": "Maria Glenski, Ellyn Ayton, Dustin Arendt, and Svitlana Volkova", "title": "Fishing for Clickbaits in Social Images and Texts with\n  Linguistically-Infused Neural Network Models", "comments": "Pineapplefish Clickbait Detector, Clickbait Challenge 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the results and conclusions of our participation in the\nClickbait Challenge 2017 on automatic clickbait detection in social media. We\nfirst describe linguistically-infused neural network models and identify\ninformative representations to predict the level of clickbaiting present in\nTwitter posts. Our models allow to answer the question not only whether a post\nis a clickbait or not, but to what extent it is a clickbait post e.g., not at\nall, slightly, considerably, or heavily clickbaity using a score ranging from 0\nto 1. We evaluate the predictive power of models trained on varied text and\nimage representations extracted from tweets. Our best performing model that\nrelies on the tweet text and linguistic markers of biased language extracted\nfrom the tweet and the corresponding page yields mean squared error (MSE) of\n0.04, mean absolute error (MAE) of 0.16 and R2 of 0.43 on the held-out test\ndata. For the binary classification setup (clickbait vs. non-clickbait), our\nmodel achieved F1 score of 0.69. We have not found that image representations\ncombined with text yield significant performance improvement yet. Nevertheless,\nthis work is the first to present preliminary analysis of objects extracted\nusing Google Tensorflow object detection API from images in clickbait vs.\nnon-clickbait Twitter posts. Finally, we outline several steps to improve model\nperformance as a part of the future work.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 17:00:59 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Glenski", "Maria", ""], ["Ayton", "Ellyn", ""], ["Arendt", "Dustin", ""], ["Volkova", "Svitlana", ""]]}, {"id": "1710.06393", "submitter": "Santiago Castro", "authors": "Aiala Ros\\'a and Luis Chiruzzo and Mathias Etcheverry and Santiago\n  Castro", "title": "RETUYT in TASS 2017: Sentiment Analysis for Spanish Tweets using SVM and\n  CNN", "comments": "in Spanish. Published in\n  http://ceur-ws.org/Vol-1896/p9_retuyt_tass2017.pdf", "journal-ref": "ISSN 1613-0073, TASS 2017: Workshop on Semantic Analysis at SEPLN,\n  Sep 2017, pages 77-83", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents classifiers based on SVM and Convolutional Neural\nNetworks (CNN) for the TASS 2017 challenge on tweets sentiment analysis. The\nclassifier with the best performance in general uses a combination of SVM and\nCNN. The use of word embeddings was particularly useful for improving the\nclassifiers performance.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 17:02:54 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Ros\u00e1", "Aiala", ""], ["Chiruzzo", "Luis", ""], ["Etcheverry", "Mathias", ""], ["Castro", "Santiago", ""]]}, {"id": "1710.06406", "submitter": "Claire Bonial", "authors": "Claire Bonial, Matthew Marge, Ron artstein, Ashley Foots, Felix\n  Gervits, Cory J. Hayes, Cassidy Henry, Susan G. Hill, Anton Leuski, Stephanie\n  M. Lukin, Pooja Moolchandani, Kimberly A. Pollard, David Traum, Clare R. Voss", "title": "Laying Down the Yellow Brick Road: Development of a Wizard-of-Oz\n  Interface for Collecting Human-Robot Dialogue", "comments": "7 pages, 2 figures, accepted for oral presentation at the Symposium\n  on Natural Communication for Human-Robot Collaboration, AAAI Fall Symposium\n  Series, November 9-11, 2017, https://www.aaai.org/ocs/index.php/FSS/FSS17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the adaptation and refinement of a graphical user interface\ndesigned to facilitate a Wizard-of-Oz (WoZ) approach to collecting human-robot\ndialogue data. The data collected will be used to develop a dialogue system for\nrobot navigation. Building on an interface previously used in the development\nof dialogue systems for virtual agents and video playback, we add templates\nwith open parameters which allow the wizard to quickly produce a wide variety\nof utterances. Our research demonstrates that this approach to data collection\nis viable as an intermediate step in developing a dialogue system for physical\nrobots in remote locations from their users - a domain in which the human and\nrobot need to regularly verify and update a shared understanding of the\nphysical environment. We show that our WoZ interface and the fixed set of\nutterances and templates therein provide for a natural pace of dialogue with\ngood coverage of the navigation domain.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 17:34:31 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Bonial", "Claire", ""], ["Marge", "Matthew", ""], ["artstein", "Ron", ""], ["Foots", "Ashley", ""], ["Gervits", "Felix", ""], ["Hayes", "Cory J.", ""], ["Henry", "Cassidy", ""], ["Hill", "Susan G.", ""], ["Leuski", "Anton", ""], ["Lukin", "Stephanie M.", ""], ["Moolchandani", "Pooja", ""], ["Pollard", "Kimberly A.", ""], ["Traum", "David", ""], ["Voss", "Clare R.", ""]]}, {"id": "1710.06481", "submitter": "Johannes Welbl", "authors": "Johannes Welbl, Pontus Stenetorp, Sebastian Riedel", "title": "Constructing Datasets for Multi-hop Reading Comprehension Across\n  Documents", "comments": "This paper directly corresponds to the TACL version\n  (https://transacl.org/ojs/index.php/tacl/article/view/1325) apart from minor\n  changes in wording, additional footnotes, and appendices", "journal-ref": "Transactions of the Association for Computational Linguistics\n  (TACL), Vol 6 (2018), pages 287-302", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most Reading Comprehension methods limit themselves to queries which can be\nanswered using a single sentence, paragraph, or document. Enabling models to\ncombine disjoint pieces of textual evidence would extend the scope of machine\ncomprehension methods, but currently there exist no resources to train and test\nthis capability. We propose a novel task to encourage the development of models\nfor text understanding across multiple documents and to investigate the limits\nof existing methods. In our task, a model learns to seek and combine evidence -\neffectively performing multi-hop (alias multi-step) inference. We devise a\nmethodology to produce datasets for this task, given a collection of\nquery-answer pairs and thematically linked documents. Two datasets from\ndifferent domains are induced, and we identify potential pitfalls and devise\ncircumvention strategies. We evaluate two previously proposed competitive\nmodels and find that one can integrate information across documents. However,\nboth models struggle to select relevant information, as providing documents\nguaranteed to be relevant greatly improves their performance. While the models\noutperform several strong baselines, their best accuracy reaches 42.9% compared\nto human performance at 74.0% - leaving ample room for improvement.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 19:35:07 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 17:08:20 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Welbl", "Johannes", ""], ["Stenetorp", "Pontus", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1710.06524", "submitter": "Ignacio Arroyo-Fernandez", "authors": "Ignacio Arroyo-Fern\\'andez, Carlos-Francisco M\\'endez-Cruz, Gerardo\n  Sierra, Juan-Manuel Torres-Moreno and Grigori Sidorov", "title": "Unsupervised Sentence Representations as Word Information Series:\n  Revisiting TF--IDF", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Sentence representation at the semantic level is a challenging task for\nNatural Language Processing and Artificial Intelligence. Despite the advances\nin word embeddings (i.e. word vector representations), capturing sentence\nmeaning is an open question due to complexities of semantic interactions among\nwords. In this paper, we present an embedding method, which is aimed at\nlearning unsupervised sentence representations from unlabeled text. We propose\nan unsupervised method that models a sentence as a weighted series of word\nembeddings. The weights of the word embeddings are fitted by using Shannon's\nword entropies provided by the Term Frequency--Inverse Document Frequency\n(TF--IDF) transform. The hyperparameters of the model can be selected according\nto the properties of data (e.g. sentence length and textual gender).\nHyperparameter selection involves word embedding methods and dimensionalities,\nas well as weighting schemata. Our method offers advantages over existing\nmethods: identifiable modules, short-term training, online inference of\n(unseen) sentence representations, as well as independence from domain,\nexternal knowledge and language resources. Results showed that our model\noutperformed the state of the art in well-known Semantic Textual Similarity\n(STS) benchmarks. Moreover, our model reached state-of-the-art performance when\ncompared to supervised and knowledge-based STS systems.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 23:13:32 GMT"}, {"version": "v2", "created": "Fri, 20 Oct 2017 02:11:59 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Arroyo-Fern\u00e1ndez", "Ignacio", ""], ["M\u00e9ndez-Cruz", "Carlos-Francisco", ""], ["Sierra", "Gerardo", ""], ["Torres-Moreno", "Juan-Manuel", ""], ["Sidorov", "Grigori", ""]]}, {"id": "1710.06536", "submitter": "Soujanya Poria", "authors": "Iti Chaturvedi, Soujanya Poria, Erik Cambria", "title": "Basic tasks of sentiment analysis", "comments": null, "journal-ref": "Encyclopedia of Social Network Analysis and Mining, 2017", "doi": "10.1007/978-1-4614-7163-9_110159-1", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subjectivity detection is the task of identifying objective and subjective\nsentences. Objective sentences are those which do not exhibit any sentiment.\nSo, it is desired for a sentiment analysis engine to find and separate the\nobjective sentences for further analysis, e.g., polarity detection. In\nsubjective sentences, opinions can often be expressed on one or multiple\ntopics. Aspect extraction is a subtask of sentiment analysis that consists in\nidentifying opinion targets in opinionated text, i.e., in detecting the\nspecific aspects of a product or service the opinion holder is either praising\nor complaining about.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 00:26:24 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["Chaturvedi", "Iti", ""], ["Poria", "Soujanya", ""], ["Cambria", "Erik", ""]]}, {"id": "1710.06554", "submitter": "Raphael Tang", "authors": "Raphael Tang, Jimmy Lin", "title": "Honk: A PyTorch Reimplementation of Convolutional Neural Networks for\n  Keyword Spotting", "comments": "3 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe Honk, an open-source PyTorch reimplementation of convolutional\nneural networks for keyword spotting that are included as examples in\nTensorFlow. These models are useful for recognizing \"command triggers\" in\nspeech-based interfaces (e.g., \"Hey Siri\"), which serve as explicit cues for\naudio recordings of utterances that are sent to the cloud for full speech\nrecognition. Evaluation on Google's recently released Speech Commands Dataset\nshows that our reimplementation is comparable in accuracy and provides a\nstarting point for future work on the keyword spotting task.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 01:47:29 GMT"}, {"version": "v2", "created": "Tue, 28 Nov 2017 17:05:44 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Tang", "Raphael", ""], ["Lin", "Jimmy", ""]]}, {"id": "1710.06632", "submitter": "Jose Camacho-Collados", "authors": "Mohammad Taher Pilehvar, Jose Camacho-Collados, Roberto Navigli, Nigel\n  Collier", "title": "Towards a Seamless Integration of Word Senses into Downstream NLP\n  Applications", "comments": "ACL 2017", "journal-ref": "Proceedings of the 55th Annual Meeting of the Association for\n  Computational Linguistics (Volume 1: Long Papers), Vancouver, Canada (2017),\n  pages 1857-1869", "doi": "10.18653/v1/P17-1170", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lexical ambiguity can impede NLP systems from accurate understanding of\nsemantics. Despite its potential benefits, the integration of sense-level\ninformation into NLP systems has remained understudied. By incorporating a\nnovel disambiguation algorithm into a state-of-the-art classification model, we\ncreate a pipeline to integrate sense-level information into downstream NLP\napplications. We show that a simple disambiguation of the input text can lead\nto consistent performance improvement on multiple topic categorization and\npolarity detection datasets, particularly when the fine granularity of the\nunderlying sense inventory is reduced and the document is sufficiently large.\nOur results also point to the need for sense representation research to focus\nmore on in vivo evaluations which target the performance in downstream NLP\napplications rather than artificial benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 09:13:06 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["Pilehvar", "Mohammad Taher", ""], ["Camacho-Collados", "Jose", ""], ["Navigli", "Roberto", ""], ["Collier", "Nigel", ""]]}, {"id": "1710.06700", "submitter": "Hamdy Mubarak", "authors": "Hamdy Mubarak", "title": "Build Fast and Accurate Lemmatization for Arabic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe the complexity of building a lemmatizer for Arabic\nwhich has a rich and complex derivational morphology, and we discuss the need\nfor a fast and accurate lammatization to enhance Arabic Information Retrieval\n(IR) results. We also introduce a new data set that can be used to test\nlemmatization accuracy, and an efficient lemmatization algorithm that\noutperforms state-of-the-art Arabic lemmatization in terms of accuracy and\nspeed. We share the data set and the code for public.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 12:36:06 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["Mubarak", "Hamdy", ""]]}, {"id": "1710.06917", "submitter": "Boyang Li", "authors": "Boyang Li, Beth Cardier, Tong Wang, Florian Metze", "title": "Annotating High-Level Structures of Short Stories and Personal Anecdotes", "comments": "7 pages, 2 figures and 3 tables. Accepted at the LREC 2018 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stories are a vital form of communication in human culture; they are employed\ndaily to persuade, to elicit sympathy, or to convey a message. Computational\nunderstanding of human narratives, especially high-level narrative structures,\nremain limited to date. Multiple literary theories for narrative structures\nexist, but operationalization of the theories has remained a challenge. We\ndeveloped an annotation scheme by consolidating and extending existing\nnarratological theories, including Labov and Waletsky's (1967) functional\ncategorization scheme and Freytag's (1863) pyramid of dramatic tension, and\npresent 360 annotated short stories collected from online sources. In the\nfuture, this research will support an approach that enables systems to\nintelligently sustain complex communications with humans.\n", "versions": [{"version": "v1", "created": "Sun, 8 Oct 2017 21:12:27 GMT"}, {"version": "v2", "created": "Tue, 27 Feb 2018 00:51:06 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Li", "Boyang", ""], ["Cardier", "Beth", ""], ["Wang", "Tong", ""], ["Metze", "Florian", ""]]}, {"id": "1710.06922", "submitter": "Jason Lee", "authors": "Jason Lee, Kyunghyun Cho, Jason Weston and Douwe Kiela", "title": "Emergent Translation in Multi-Agent Communication", "comments": "Accepted to ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While most machine translation systems to date are trained on large parallel\ncorpora, humans learn language in a different way: by being grounded in an\nenvironment and interacting with other humans. In this work, we propose a\ncommunication game where two agents, native speakers of their own respective\nlanguages, jointly learn to solve a visual referential task. We find that the\nability to understand and translate a foreign language emerges as a means to\nachieve shared goals. The emergent translation is interactive and multimodal,\nand crucially does not require parallel corpora, but only monolingual,\nindependent text and corresponding images. Our proposed translation model\nachieves this by grounding the source and target languages into a shared visual\nmodality, and outperforms several baselines on both word-level and\nsentence-level translation tasks. Furthermore, we show that agents in a\nmultilingual community learn to translate better and faster than in a bilingual\ncommunication setting.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 00:37:27 GMT"}, {"version": "v2", "created": "Wed, 11 Apr 2018 03:22:49 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Lee", "Jason", ""], ["Cho", "Kyunghyun", ""], ["Weston", "Jason", ""], ["Kiela", "Douwe", ""]]}, {"id": "1710.06923", "submitter": "Sunil Kumar Kopparapu Dr", "authors": "C. Anantaram and Sunil Kumar Kopparapu", "title": "Adapting general-purpose speech recognition engine output for\n  domain-specific natural language question answering", "comments": "20 opages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech-based natural language question-answering interfaces to enterprise\nsystems are gaining a lot of attention. General-purpose speech engines can be\nintegrated with NLP systems to provide such interfaces. Usually,\ngeneral-purpose speech engines are trained on large `general' corpus. However,\nwhen such engines are used for specific domains, they may not recognize\ndomain-specific words well, and may produce erroneous output. Further, the\naccent and the environmental conditions in which the speaker speaks a sentence\nmay induce the speech engine to inaccurately recognize certain words. The\nsubsequent natural language question-answering does not produce the requisite\nresults as the question does not accurately represent what the speaker\nintended. Thus, the speech engine's output may need to be adapted for a domain\nbefore further natural language processing is carried out. We present two\nmechanisms for such an adaptation, one based on evolutionary development and\nthe other based on machine learning, and show how we can repair the\nspeech-output to make the subsequent natural language question-answering\nbetter.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 12:18:16 GMT"}], "update_date": "2017-10-20", "authors_parsed": [["Anantaram", "C.", ""], ["Kopparapu", "Sunil Kumar", ""]]}, {"id": "1710.06931", "submitter": "Dushyanta Dhyani", "authors": "Dushyanta Dhyani", "title": "OhioState at IJCNLP-2017 Task 4: Exploring Neural Architectures for\n  Multilingual Customer Feedback Analysis", "comments": "To appear in IJCNLP (Shared Task) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes our systems for IJCNLP 2017 Shared Task on Customer\nFeedback Analysis. We experimented with simple neural architectures that gave\ncompetitive performance on certain tasks. This includes shallow CNN and\nBi-Directional LSTM architectures with Facebook's Fasttext as a baseline model.\nOur best performing model was in the Top 5 systems using the Exact-Accuracy and\nMicro-Average-F1 metrics for the Spanish (85.28% for both) and French (70% and\n73.17% respectively) task, and outperformed all the other models on comment\n(87.28%) and meaningless (51.85%) tags using Micro Average F1 by Tags metric\nfor the French task.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 20:48:18 GMT"}, {"version": "v2", "created": "Tue, 31 Oct 2017 20:30:02 GMT"}], "update_date": "2017-11-02", "authors_parsed": [["Dhyani", "Dushyanta", ""]]}, {"id": "1710.06937", "submitter": "Xiaodong Cui", "authors": "Xiaodong Cui, Vaibhava Goel, George Saon", "title": "Embedding-Based Speaker Adaptive Training of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An embedding-based speaker adaptive training (SAT) approach is proposed and\ninvestigated in this paper for deep neural network acoustic modeling. In this\napproach, speaker embedding vectors, which are a constant given a particular\nspeaker, are mapped through a control network to layer-dependent element-wise\naffine transformations to canonicalize the internal feature representations at\nthe output of hidden layers of a main network. The control network for\ngenerating the speaker-dependent mappings is jointly estimated with the main\nnetwork for the overall speaker adaptive acoustic modeling. Experiments on\nlarge vocabulary continuous speech recognition (LVCSR) tasks show that the\nproposed SAT scheme can yield superior performance over the widely-used\nspeaker-aware training using i-vectors with speaker-adapted input features.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 17:10:11 GMT"}], "update_date": "2017-10-20", "authors_parsed": [["Cui", "Xiaodong", ""], ["Goel", "Vaibhava", ""], ["Saon", "George", ""]]}, {"id": "1710.07032", "submitter": "Michael Ringgaard", "authors": "Michael Ringgaard, Rahul Gupta, Fernando C. N. Pereira", "title": "SLING: A framework for frame semantic parsing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe SLING, a framework for parsing natural language into semantic\nframes. SLING supports general transition-based, neural-network parsing with\nbidirectional LSTM input encoding and a Transition Based Recurrent Unit (TBRU)\nfor output decoding. The parsing model is trained end-to-end using only the\ntext tokens as input. The transition system has been designed to output frame\ngraphs directly without any intervening symbolic representation. The SLING\nframework includes an efficient and scalable frame store implementation as well\nas a neural network JIT compiler for fast inference during parsing. SLING is\nimplemented in C++ and it is available for download on GitHub.\n", "versions": [{"version": "v1", "created": "Thu, 19 Oct 2017 08:13:19 GMT"}], "update_date": "2017-10-20", "authors_parsed": [["Ringgaard", "Michael", ""], ["Gupta", "Rahul", ""], ["Pereira", "Fernando C. N.", ""]]}, {"id": "1710.07045", "submitter": "Pieter Fivez", "authors": "Pieter Fivez, Simon \\v{S}uster, Walter Daelemans", "title": "Unsupervised Context-Sensitive Spelling Correction of English and Dutch\n  Clinical Free-Text with Word and Character N-Gram Embeddings", "comments": "Appears in volume 7 of the CLIN Journal,\n  http://www.clinjournal.org/biblio/volume", "journal-ref": "CLIN Journal, Volume 7, 2017", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an unsupervised context-sensitive spelling correction method for\nclinical free-text that uses word and character n-gram embeddings. Our method\ngenerates misspelling replacement candidates and ranks them according to their\nsemantic fit, by calculating a weighted cosine similarity between the\nvectorized representation of a candidate and the misspelling context. To tune\nthe parameters of this model, we generate self-induced spelling error corpora.\nWe perform our experiments for two languages. For English, we greatly\noutperform off-the-shelf spelling correction tools on a manually annotated\nMIMIC-III test set, and counter the frequency bias of a noisy channel model,\nshowing that neural embeddings can be successfully exploited to improve upon\nthe state-of-the-art. For Dutch, we also outperform an off-the-shelf spelling\ncorrection tool on manually annotated clinical records from the Antwerp\nUniversity Hospital, but can offer no empirical evidence that our method\ncounters the frequency bias of a noisy channel model in this case as well.\nHowever, both our context-sensitive model and our implementation of the noisy\nchannel model obtain high scores on the test set, establishing a\nstate-of-the-art for Dutch clinical spelling correction with the noisy channel\nmodel.\n", "versions": [{"version": "v1", "created": "Thu, 19 Oct 2017 09:15:37 GMT"}], "update_date": "2017-10-20", "authors_parsed": [["Fivez", "Pieter", ""], ["\u0160uster", "Simon", ""], ["Daelemans", "Walter", ""]]}, {"id": "1710.07177", "submitter": "Desmond Elliott", "authors": "Desmond Elliott, Stella Frank, Lo\\\"ic Barrault, Fethi Bougares, Lucia\n  Specia", "title": "Findings of the Second Shared Task on Multimodal Machine Translation and\n  Multilingual Image Description", "comments": null, "journal-ref": "Proceedings of the Second Conference on Machine Translation, 2017,\n  pp. 215--233", "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the results from the second shared task on multimodal machine\ntranslation and multilingual image description. Nine teams submitted 19 systems\nto two tasks. The multimodal translation task, in which the source sentence is\nsupplemented by an image, was extended with a new language (French) and two new\ntest sets. The multilingual image description task was changed such that at\ntest time, only the image is given. Compared to last year, multimodal systems\nimproved, but text-only systems remain competitive.\n", "versions": [{"version": "v1", "created": "Thu, 19 Oct 2017 15:20:14 GMT"}], "update_date": "2017-10-20", "authors_parsed": [["Elliott", "Desmond", ""], ["Frank", "Stella", ""], ["Barrault", "Lo\u00efc", ""], ["Bougares", "Fethi", ""], ["Specia", "Lucia", ""]]}, {"id": "1710.07210", "submitter": "Honglun Zhang", "authors": "Honglun Zhang, Liqiang Xiao, Wenqing Chen, Yongkun Wang, Yaohui Jin", "title": "Multi-Task Label Embedding for Text Classification", "comments": "arXiv admin note: text overlap with arXiv:1707.02892", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning in text classification leverages implicit correlations\namong related tasks to extract common features and yield performance gains.\nHowever, most previous works treat labels of each task as independent and\nmeaningless one-hot vectors, which cause a loss of potential information and\nmakes it difficult for these models to jointly learn three or more tasks. In\nthis paper, we propose Multi-Task Label Embedding to convert labels in text\nclassification into semantic vectors, thereby turning the original tasks into\nvector matching tasks. We implement unsupervised, supervised and\nsemi-supervised models of Multi-Task Label Embedding, all utilizing semantic\ncorrelations among tasks and making it particularly convenient to scale and\ntransfer as more tasks are involved. Extensive experiments on five benchmark\ndatasets for text classification show that our models can effectively improve\nperformances of related tasks with semantic representations of labels and\nadditional information from each other.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 23:35:58 GMT"}], "update_date": "2017-10-20", "authors_parsed": [["Zhang", "Honglun", ""], ["Xiao", "Liqiang", ""], ["Chen", "Wenqing", ""], ["Wang", "Yongkun", ""], ["Jin", "Yaohui", ""]]}, {"id": "1710.07388", "submitter": "Yi Luan", "authors": "Yi Luan, Chris Brockett, Bill Dolan, Jianfeng Gao, Michel Galley", "title": "Multi-Task Learning for Speaker-Role Adaptation in Neural Conversation\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building a persona-based conversation agent is challenging owing to the lack\nof large amounts of speaker-specific conversation data for model training. This\npaper addresses the problem by proposing a multi-task learning approach to\ntraining neural conversation models that leverages both conversation data\nacross speakers and other types of data pertaining to the speaker and speaker\nroles to be modeled. Experiments show that our approach leads to significant\nimprovements over baseline model quality, generating responses that capture\nmore precisely speakers' traits and speaking styles. The model offers the\nbenefits of being algorithmically simple and easy to implement, and not relying\non large quantities of data representing specific individual speakers.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 01:31:31 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Luan", "Yi", ""], ["Brockett", "Chris", ""], ["Dolan", "Bill", ""], ["Gao", "Jianfeng", ""], ["Galley", "Michel", ""]]}, {"id": "1710.07394", "submitter": "Lei Gao", "authors": "Lei Gao, Alexis Kuppersmith, Ruihong Huang", "title": "Recognizing Explicit and Implicit Hate Speech Using a Weakly Supervised\n  Two-path Bootstrapping Approach", "comments": "Published in IJCNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the wake of a polarizing election, social media is laden with hateful\ncontent. To address various limitations of supervised hate speech\nclassification methods including corpus bias and huge cost of annotation, we\npropose a weakly supervised two-path bootstrapping approach for an online hate\nspeech detection model leveraging large-scale unlabeled data. This system\nsignificantly outperforms hate speech detection systems that are trained in a\nsupervised manner using manually annotated data. Applying this model on a large\nquantity of tweets collected before, after, and on election day reveals\nmotivations and patterns of inflammatory language.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 02:11:06 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 02:33:19 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Gao", "Lei", ""], ["Kuppersmith", "Alexis", ""], ["Huang", "Ruihong", ""]]}, {"id": "1710.07395", "submitter": "Lei Gao", "authors": "Lei Gao, Ruihong Huang", "title": "Detecting Online Hate Speech Using Context Aware Models", "comments": "Published in RANLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the wake of a polarizing election, the cyber world is laden with hate\nspeech. Context accompanying a hate speech text is useful for identifying hate\nspeech, which however has been largely overlooked in existing datasets and hate\nspeech detection models. In this paper, we provide an annotated corpus of hate\nspeech with context information well kept. Then we propose two types of hate\nspeech detection models that incorporate context information, a logistic\nregression model with context features and a neural network model with learning\ncomponents for context. Our evaluation shows that both models outperform a\nstrong baseline by around 3% to 4% in F1 score and combining these two models\nfurther improve the performance by another 7% in F1 score.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 02:11:21 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 02:36:52 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Gao", "Lei", ""], ["Huang", "Ruihong", ""]]}, {"id": "1710.07441", "submitter": "Elaheh ShafieiBavani", "authors": "Elaheh ShafieiBavani, Mohammad Ebrahimi, Raymond Wong, Fang Chen", "title": "A Semantically Motivated Approach to Compute ROUGE Scores", "comments": "16 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": "UNSW-CSE-TR-201706", "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ROUGE is one of the first and most widely used evaluation metrics for text\nsummarization. However, its assessment merely relies on surface similarities\nbetween peer and model summaries. Consequently, ROUGE is unable to fairly\nevaluate abstractive summaries including lexical variations and paraphrasing.\nExploring the effectiveness of lexical resource-based models to address this\nissue, we adopt a graph-based algorithm into ROUGE to capture the semantic\nsimilarities between peer and model summaries. Our semantically motivated\napproach computes ROUGE scores based on both lexical and semantic similarities.\nExperiment results over TAC AESOP datasets indicate that exploiting the\nlexico-semantic similarity of the words used in summaries would significantly\nhelp ROUGE correlate better with human judgments.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 07:38:54 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["ShafieiBavani", "Elaheh", ""], ["Ebrahimi", "Mohammad", ""], ["Wong", "Raymond", ""], ["Chen", "Fang", ""]]}, {"id": "1710.07503", "submitter": "Eirini Papagiannopoulou", "authors": "Eirini Papagiannopoulou and Grigorios Tsoumakas", "title": "Local Word Vectors Guiding Keyphrase Extraction", "comments": "author pre-print version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated keyphrase extraction is a fundamental textual information\nprocessing task concerned with the selection of representative phrases from a\ndocument that summarize its content. This work presents a novel unsupervised\nmethod for keyphrase extraction, whose main innovation is the use of local word\nembeddings (in particular GloVe vectors), i.e., embeddings trained from the\nsingle document under consideration. We argue that such local representation of\nwords and keyphrases are able to accurately capture their semantics in the\ncontext of the document they are part of, and therefore can help in improving\nkeyphrase extraction quality. Empirical results offer evidence that indeed\nlocal representations lead to better keyphrase extraction results compared to\nboth embeddings trained on very large third corpora or larger corpora\nconsisting of several documents of the same scientific field and to other\nstate-of-the-art unsupervised keyphrase extraction methods.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 12:22:15 GMT"}, {"version": "v2", "created": "Fri, 17 Nov 2017 10:30:33 GMT"}, {"version": "v3", "created": "Fri, 15 Dec 2017 13:06:42 GMT"}, {"version": "v4", "created": "Fri, 13 Apr 2018 10:30:44 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Papagiannopoulou", "Eirini", ""], ["Tsoumakas", "Grigorios", ""]]}, {"id": "1710.07551", "submitter": "Tuka Alhanai", "authors": "Tuka Alhanai, Rhoda Au, and James Glass", "title": "Spoken Language Biomarkers for Detecting Cognitive Impairment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study we developed an automated system that evaluates speech and\nlanguage features from audio recordings of neuropsychological examinations of\n92 subjects in the Framingham Heart Study. A total of 265 features were used in\nan elastic-net regularized binomial logistic regression model to classify the\npresence of cognitive impairment, and to select the most predictive features.\nWe compared performance with a demographic model from 6,258 subjects in the\ngreater study cohort (0.79 AUC), and found that a system that incorporated both\naudio and text features performed the best (0.92 AUC), with a True Positive\nRate of 29% (at 0% False Positive Rate) and a good model fit (Hosmer-Lemeshow\ntest > 0.05). We also found that decreasing pitch and jitter, shorter segments\nof speech, and responses phrased as questions were positively associated with\ncognitive impairment.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 14:41:43 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Alhanai", "Tuka", ""], ["Au", "Rhoda", ""], ["Glass", "James", ""]]}, {"id": "1710.07654", "submitter": "Wei Ping", "authors": "Wei Ping, Kainan Peng, Andrew Gibiansky, Sercan O. Arik, Ajay Kannan,\n  Sharan Narang, Jonathan Raiman, John Miller", "title": "Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence\n  Learning", "comments": "Published as a conference paper at ICLR 2018. (v3 changed paper\n  title)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Deep Voice 3, a fully-convolutional attention-based neural\ntext-to-speech (TTS) system. Deep Voice 3 matches state-of-the-art neural\nspeech synthesis systems in naturalness while training ten times faster. We\nscale Deep Voice 3 to data set sizes unprecedented for TTS, training on more\nthan eight hundred hours of audio from over two thousand speakers. In addition,\nwe identify common error modes of attention-based speech synthesis networks,\ndemonstrate how to mitigate them, and compare several different waveform\nsynthesis methods. We also describe how to scale inference to ten million\nqueries per day on one single-GPU server.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 18:17:23 GMT"}, {"version": "v2", "created": "Thu, 30 Nov 2017 02:50:28 GMT"}, {"version": "v3", "created": "Thu, 22 Feb 2018 06:23:45 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Ping", "Wei", ""], ["Peng", "Kainan", ""], ["Gibiansky", "Andrew", ""], ["Arik", "Sercan O.", ""], ["Kannan", "Ajay", ""], ["Narang", "Sharan", ""], ["Raiman", "Jonathan", ""], ["Miller", "John", ""]]}, {"id": "1710.07695", "submitter": "Xiyou Zhou", "authors": "Wanyun Cui, Xiyou Zhou, Hangyu Lin, Yanghua Xiao, Haixun Wang,\n  Seung-won Hwang and Wei Wang", "title": "Verb Pattern: A Probabilistic Semantic Representation on Verbs", "comments": "7 pages, 3 figures, camera-ready version published on AAAI 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Verbs are important in semantic understanding of natural language.\nTraditional verb representations, such as FrameNet, PropBank, VerbNet, focus on\nverbs' roles. These roles are too coarse to represent verbs' semantics. In this\npaper, we introduce verb patterns to represent verbs' semantics, such that each\npattern corresponds to a single semantic of the verb. First we analyze the\nprinciples for verb patterns: generality and specificity. Then we propose a\nnonparametric model based on description length. Experimental results prove the\nhigh effectiveness of verb patterns. We further apply verb patterns to\ncontext-aware conceptualization, to show that verb patterns are helpful in\nsemantic-related tasks.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 20:23:45 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Cui", "Wanyun", ""], ["Zhou", "Xiyou", ""], ["Lin", "Hangyu", ""], ["Xiao", "Yanghua", ""], ["Wang", "Haixun", ""], ["Hwang", "Seung-won", ""], ["Wang", "Wei", ""]]}, {"id": "1710.07728", "submitter": "Jason Anastasopoulos", "authors": "Jason Anastasopoulos and Jake Ryland Williams", "title": "A Computational Framework for Multi-Modal Social Action Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We create a computational framework for understanding social action and\ndemonstrate how this framework can be used to build an open-source event\ndetection tool with scalable statistical machine learning algorithms and a\nsubsampled database of over 600 million geo-tagged Tweets from around the\nworld. These Tweets were collected between April 1st, 2014 and April 30th,\n2015, most notably when the Black Lives Matter movement began. We demonstrate\nhow these methods can be used diagnostically-by researchers, government\nofficials and the public-to understand peaceful and violent collective action\nat very fine-grained levels of time and geography.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 23:42:22 GMT"}, {"version": "v2", "created": "Tue, 24 Oct 2017 16:05:45 GMT"}], "update_date": "2017-10-30", "authors_parsed": [["Anastasopoulos", "Jason", ""], ["Williams", "Jake Ryland", ""]]}, {"id": "1710.07729", "submitter": "Jake Williams", "authors": "Jake Ryland Williams and Giovanni C. Santia", "title": "Is space a word, too?", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cond-mat.stat-mech", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For words, rank-frequency distributions have long been heralded for adherence\nto a potentially-universal phenomenon known as Zipf's law. The hypothetical\nform of this empirical phenomenon was refined by Ben\\^{i}ot Mandelbrot to that\nwhich is presently referred to as the Zipf-Mandelbrot law. Parallel to this,\nHerbet Simon proposed a selection model potentially explaining Zipf's law.\nHowever, a significant dispute between Simon and Mandelbrot, notable empirical\nexceptions, and the lack of a strong empirical connection between Simon's model\nand the Zipf-Mandelbrot law have left the questions of universality and\nmechanistic generation open. We offer a resolution to these issues by\nexhibiting how the dark matter of word segmentation, i.e., space, punctuation,\netc., connect the Zipf-Mandelbrot law to Simon's mechanistic process. This\nexplains Mandelbrot's refinement as no more than a fudge factor, accommodating\nthe effects of the exclusion of the rank-frequency dark matter. Thus,\nintegrating these non-word objects resolves a more-generalized rank-frequency\nlaw. Since this relies upon the integration of space, etc., we find support for\nthe hypothesis that $all$ are generated by common processes, indicating from a\nphysical perspective that space is a word, too.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 23:43:26 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Williams", "Jake Ryland", ""], ["Santia", "Giovanni C.", ""]]}, {"id": "1710.07770", "submitter": "Yingming Li", "authors": "Baiyun Cui, Yingming Li, Yaqing Zhang and Zhongfei Zhang", "title": "Text Coherence Analysis Based on Deep Neural Network", "comments": "4 pages, 2 figures, CIKM 2017", "journal-ref": null, "doi": "10.1145/3132847.3133047", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel deep coherence model (DCM) using a\nconvolutional neural network architecture to capture the text coherence. The\ntext coherence problem is investigated with a new perspective of learning\nsentence distributional representation and text coherence modeling\nsimultaneously. In particular, the model captures the interactions between\nsentences by computing the similarities of their distributional\nrepresentations. Further, it can be easily trained in an end-to-end fashion.\nThe proposed model is evaluated on a standard Sentence Ordering task. The\nexperimental results demonstrate its effectiveness and promise in coherence\nassessment showing a significant improvement over the state-of-the-art by a\nwide margin.\n", "versions": [{"version": "v1", "created": "Sat, 21 Oct 2017 08:06:48 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Cui", "Baiyun", ""], ["Li", "Yingming", ""], ["Zhang", "Yaqing", ""], ["Zhang", "Zhongfei", ""]]}, {"id": "1710.07868", "submitter": "Mohit Yadav", "authors": "Mohit Yadav and Vivek Tyagi", "title": "Deep Triphone Embedding Improves Phoneme Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel Deep Triphone Embedding (DTE)\nrepresentation derived from Deep Neural Network (DNN) to encapsulate the\ndiscriminative information present in the adjoining speech frames. DTEs are\ngenerated using a four hidden layer DNN with 3000 nodes in each hidden layer at\nthe first-stage. This DNN is trained with the tied-triphone classification\naccuracy as an optimization criterion. Thereafter, we retain the activation\nvectors (3000) of the last hidden layer, for each speech MFCC frame, and\nperform dimension reduction to further obtain a 300 dimensional representation,\nwhich we termed as DTE. DTEs along with MFCC features are fed into a\nsecond-stage four hidden layer DNN, which is subsequently trained for the task\nof tied-triphone classification. Both DNNs are trained using tri-phone labels\ngenerated from a tied-state triphone HMM-GMM system, by performing a\nforced-alignment between the transcriptions and MFCC feature frames. We conduct\nthe experiments on publicly available TED-LIUM speech corpus. The results show\nthat the proposed DTE method provides an improvement of absolute 2.11% in\nphoneme recognition, when compared with a competitive hybrid tied-state\ntriphone HMM-DNN system.\n", "versions": [{"version": "v1", "created": "Sun, 22 Oct 2017 01:06:23 GMT"}, {"version": "v2", "created": "Tue, 24 Oct 2017 14:59:30 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Yadav", "Mohit", ""], ["Tyagi", "Vivek", ""]]}, {"id": "1710.07960", "submitter": "Piotr Przyby{\\l}a", "authors": "Piotr Przyby{\\l}a", "title": "How big is big enough? Unsupervised word sense disambiguation using a\n  very large corpus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the problem of disambiguating a target word for Polish is\napproached by searching for related words with known meaning. These relatives\nare used to build a training corpus from unannotated text. This technique is\nimproved by proposing new rich sources of replacements that substitute the\ntraditional requirement of monosemy with heuristics based on wordnet relations.\nThe na\\\"ive Bayesian classifier has been modified to account for an unknown\ndistribution of senses. A corpus of 600 million web documents (594 billion\ntokens), gathered by the NEKST search engine allows us to assess the\nrelationship between training set size and disambiguation accuracy. The\nclassifier is evaluated using both a wordnet baseline and a corpus with 17,314\nmanually annotated occurrences of 54 ambiguous words.\n", "versions": [{"version": "v1", "created": "Sun, 22 Oct 2017 15:12:43 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Przyby\u0142a", "Piotr", ""]]}, {"id": "1710.08015", "submitter": "Chenwei Zhang", "authors": "Chenwei Zhang, Nan Du, Wei Fan, Yaliang Li, Chun-Ta Lu, Philip S. Yu", "title": "Bringing Semantic Structures to User Intent Detection in Online Medical\n  Queries", "comments": "10 pages, 2017 IEEE International Conference on Big Data (Big Data\n  2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet has revolutionized healthcare by offering medical information\nubiquitously to patients via web search. The healthcare status, complex medical\ninformation needs of patients are expressed diversely and implicitly in their\nmedical text queries. Aiming to better capture a focused picture of user's\nmedical-related information search and shed insights on their healthcare\ninformation access strategies, it is challenging yet rewarding to detect\nstructured user intentions from their diversely expressed medical text queries.\nWe introduce a graph-based formulation to explore structured concept\ntransitions for effective user intent detection in medical queries, where each\nnode represents a medical concept mention and each directed edge indicates a\nmedical concept transition. A deep model based on multi-task learning is\nintroduced to extract structured semantic transitions from user queries, where\nthe model extracts word-level medical concept mentions as well as\nsentence-level concept transitions collectively. A customized graph-based\nmutual transfer loss function is designed to impose explicit constraints and\nfurther exploit the contribution of mentioning a medical concept word to the\nimplication of a semantic transition. We observe an 8% relative improvement in\nAUC and 23% relative reduction in coverage error by comparing the proposed\nmodel with the best baseline model for the concept transition inference task on\nreal-world medical text queries.\n", "versions": [{"version": "v1", "created": "Sun, 22 Oct 2017 21:03:28 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Zhang", "Chenwei", ""], ["Du", "Nan", ""], ["Fan", "Wei", ""], ["Li", "Yaliang", ""], ["Lu", "Chun-Ta", ""], ["Yu", "Philip S.", ""]]}, {"id": "1710.08048", "submitter": "Andres Campero", "authors": "Andres Campero and Bjarke Felbo and Joshua B. Tenenbaum and Rebecca\n  Saxe", "title": "A First Step in Combining Cognitive Event Features and Natural Language\n  Representations to Predict Emotions", "comments": "Conference on Cognitive Computational Neuroscience (2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the representational space of emotions by combining methods from\ndifferent academic fields. Cognitive science has proposed appraisal theory as a\nview on human emotion with previous research showing how human-rated abstract\nevent features can predict fine-grained emotions and capture the similarity\nspace of neural patterns in mentalizing brain regions. At the same time,\nnatural language processing (NLP) has demonstrated how transfer and multitask\nlearning can be used to cope with scarcity of annotated data for text modeling.\n  The contribution of this work is to show that appraisal theory can be\ncombined with NLP for mutual benefit. First, fine-grained emotion prediction\ncan be improved to human-level performance by using NLP representations in\naddition to appraisal features. Second, using the appraisal features as\nauxiliary targets during training can improve predictions even when only text\nis available as input. Third, we obtain a representation with a similarity\nmatrix that better correlates with the neural activity across regions. Best\nresults are achieved when the model is trained to simultaneously predict\nappraisals, emotions and emojis using a shared representation.\n  While these results are preliminary, the integration of cognitive\nneuroscience and NLP techniques opens up an interesting direction for future\nresearch.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 00:26:50 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Campero", "Andres", ""], ["Felbo", "Bjarke", ""], ["Tenenbaum", "Joshua B.", ""], ["Saxe", "Rebecca", ""]]}, {"id": "1710.08246", "submitter": "Muktabh Mayank Srivastava", "authors": "Richa Sharma, Muktabh Mayank Srivastava", "title": "Testing the limits of unsupervised learning for semantic similarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Semantic Similarity between two sentences can be defined as a way to\ndetermine how related or unrelated two sentences are. The task of Semantic\nSimilarity in terms of distributed representations can be thought to be\ngenerating sentence embeddings (dense vectors) which take both context and\nmeaning of sentence in account. Such embeddings can be produced by multiple\nmethods, in this paper we try to evaluate LSTM auto encoders for generating\nthese embeddings. Unsupervised algorithms (auto encoders to be specific) just\ntry to recreate their inputs, but they can be forced to learn order (and some\ninherent meaning to some extent) by creating proper bottlenecks. We try to\nevaluate how properly can algorithms trained just on plain English Sentences\nlearn to figure out Semantic Similarity, without giving them any sense of what\nmeaning of a sentence is.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 12:58:12 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Sharma", "Richa", ""], ["Srivastava", "Muktabh Mayank", ""]]}, {"id": "1710.08312", "submitter": "Patrick Verga", "authors": "Patrick Verga, Emma Strubell, Ofer Shai, Andrew McCallum", "title": "Attending to All Mention Pairs for Full Abstract Biological Relation\n  Extraction", "comments": "6th Workshop on Automated Knowledge Base Construction (AKBC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most work in relation extraction forms a prediction by looking at a short\nspan of text within a single sentence containing a single entity pair mention.\nHowever, many relation types, particularly in biomedical text, are expressed\nacross sentences or require a large context to disambiguate. We propose a model\nto consider all mention and entity pairs simultaneously in order to make a\nprediction. We encode full paper abstracts using an efficient self-attention\nencoder and form pairwise predictions between all mentions with a bi-affine\noperation. An entity-pair wise pooling aggregates mention pair scores to make a\nfinal prediction while alleviating training noise by performing within document\nmulti-instance learning. We improve our model's performance by jointly training\nthe model to predict named entities and adding an additional corpus of weakly\nlabeled data. We demonstrate our model's effectiveness by achieving the state\nof the art on the Biocreative V Chemical Disease Relation dataset for models\nwithout KB resources, outperforming ensembles of models which use hand-crafted\nfeatures and additional linguistic resources.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 14:46:58 GMT"}, {"version": "v2", "created": "Wed, 15 Nov 2017 19:22:10 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Verga", "Patrick", ""], ["Strubell", "Emma", ""], ["Shai", "Ofer", ""], ["McCallum", "Andrew", ""]]}, {"id": "1710.08321", "submitter": "Muktabh Mayank Srivastava", "authors": "Nishant Nikhil, Muktabh Mayank Srivastava", "title": "Content Based Document Recommender using Deep Learning", "comments": "Accepted in ICICI 2017, Coimbatore, India", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the recent advancements in information technology there has been a huge\nsurge in amount of data available. But information retrieval technology has not\nbeen able to keep up with this pace of information generation resulting in over\nspending of time for retrieving relevant information. Even though systems exist\nfor assisting users to search a database along with filtering and recommending\nrelevant information, but recommendation system which uses content of documents\nfor recommendation still have a long way to mature. Here we present a Deep\nLearning based supervised approach to recommend similar documents based on the\nsimilarity of content. We combine the C-DSSM model with Word2Vec distributed\nrepresentations of words to create a novel model to classify a document pair as\nrelevant/irrelavant by assigning a score to it. Using our model retrieval of\ndocuments can be done in O(1) time and the memory complexity is O(n), where n\nis number of documents.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 15:08:38 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Nikhil", "Nishant", ""], ["Srivastava", "Muktabh Mayank", ""]]}, {"id": "1710.08396", "submitter": "Barathi Ganesh H B", "authors": "Vinayakumar R, Barathi Ganesh HB, Anand Kumar M, Soman KP", "title": "Deep Health Care Text Classification", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Health related social media mining is a valuable apparatus for the early\nrecognition of the diverse antagonistic medicinal conditions. Mostly, the\nexisting methods are based on machine learning with knowledge-based learning.\nThis working note presents the Recurrent neural network (RNN) and Long\nshort-term memory (LSTM) based embedding for automatic health text\nclassification in the social media mining. For each task, two systems are built\nand that classify the tweet at the tweet level. RNN and LSTM are used for\nextracting features and non-linear activation function at the last layer\nfacilitates to distinguish the tweets of different categories. The experiments\nare conducted on 2nd Social Media Mining for Health Applications Shared Task at\nAMIA 2017. The experiment results are considerable; however the proposed method\nis appropriate for the health text classification. This is primarily due to the\nreason that, it doesn't rely on any feature engineering mechanisms.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 17:24:12 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["R", "Vinayakumar", ""], ["HB", "Barathi Ganesh", ""], ["M", "Anand Kumar", ""], ["KP", "Soman", ""]]}, {"id": "1710.08451", "submitter": "Samhaa El-Beltagy", "authors": "Samhaa R. El-Beltagy, Talaat Khalil, Amal Halaby, and Muhammad Hammad", "title": "Combining Lexical Features and a Supervised Learning Approach for Arabic\n  Sentiment Analysis", "comments": "arXiv admin note: This version has been removed because it is in\n  violation of arXiv's copyright policy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of building sentiment analysis tools for Arabic social media\nhas been recognized during the past couple of years, especially with the rapid\nincrease in the number of Arabic social media users. One of the main\ndifficulties in tackling this problem is that text within social media is\nmostly colloquial, with many dialects being used within social media platforms.\nIn this paper, we present a set of features that were integrated with a machine\nlearning based sentiment analysis model and applied on Egyptian, Saudi,\nLevantine, and MSA Arabic social media datasets. Many of the proposed features\nwere derived through the use of an Arabic Sentiment Lexicon. The model also\npresents emoticon based features, as well as input text related features such\nas the number of segments within the text, the length of the text, whether the\ntext ends with a question mark or not, etc. We show that the presented features\nhave resulted in an increased accuracy across six of the seven datasets we've\nexperimented with and which are all benchmarked. Since the developed model\nout-performs all existing Arabic sentiment analysis systems that have publicly\navailable datasets, we can state that this model presents state-of-the-art in\nArabic sentiment analysis.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 18:34:37 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["El-Beltagy", "Samhaa R.", ""], ["Khalil", "Talaat", ""], ["Halaby", "Amal", ""], ["Hammad", "Muhammad", ""]]}, {"id": "1710.08458", "submitter": "Samhaa R El-Beltagy", "authors": "Samhaa R. El-Beltagy, Mona El Kalamawy, Abu Bakr Soliman", "title": "NileTMRG at SemEval-2017 Task 4: Arabic Sentiment Analysis", "comments": null, "journal-ref": "Proceedings of the 11th International Workshop on Semantic\n  Evaluations (SemEval-2017), pages 790-795, Vancouver, Canada, 2017", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes two systems that were used by the authors for addressing\nArabic Sentiment Analysis as part of SemEval-2017, task 4. The authors\nparticipated in three Arabic related subtasks which are: Subtask A (Message\nPolarity Classification), Sub-task B (Topic-Based Message Polarity\nclassification) and Subtask D (Tweet quantification) using the team name of\nNileTMRG. For subtask A, we made use of our previously developed sentiment\nanalyzer which we augmented with a scored lexicon. For subtasks B and D, we\nused an ensemble of three different classifiers. The first classifier was a\nconvolutional neural network for which we trained (word2vec) word embeddings.\nThe second classifier consisted of a MultiLayer Perceptron, while the third\nclassifier was a Logistic regression model that takes the same input as the\nsecond classifier. Voting between the three classifiers was used to determine\nthe final outcome. The output from task B, was quantified to produce the\nresults for task D. In all three Arabic related tasks in which NileTMRG\nparticipated, the team ranked at number one.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 18:55:19 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["El-Beltagy", "Samhaa R.", ""], ["Kalamawy", "Mona El", ""], ["Soliman", "Abu Bakr", ""]]}, {"id": "1710.08528", "submitter": "Olga Papadopoulou", "authors": "Olga Papadopoulou, Markos Zampoglou, Symeon Papadopoulos, Ioannis\n  Kompatsiaris", "title": "A Two-Level Classification Approach for Detecting Clickbait Posts using\n  Text-Based Features", "comments": "Clickbait Challenge 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of social media as news sources has led to the rise of\nclickbait posts attempting to attract users to click on article links without\ninforming them on the actual article content. This paper presents our efforts\nto create a clickbait detector inspired by fake news detection algorithms, and\nour submission to the Clickbait Challenge 2017. The detector is based almost\nexclusively on text-based features taken from previous work on clickbait\ndetection, our own work on fake post detection, and features we designed\nspecifically for the challenge. We use a two-level classification approach,\ncombining the outputs of 65 first-level classifiers in a second-level feature\nvector. We present our exploratory results with individual features and their\ncombinations, taken from the post text and the target article title, as well as\nfeature selection. While our own blind tests with the dataset led to an F-score\nof 0.63, our final evaluation in the Challenge only achieved an F-score of\n0.43. We explore the possible causes of this, and lay out potential future\nsteps to achieve more successful results.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 22:12:51 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Papadopoulou", "Olga", ""], ["Zampoglou", "Markos", ""], ["Papadopoulos", "Symeon", ""], ["Kompatsiaris", "Ioannis", ""]]}, {"id": "1710.08634", "submitter": "Ricardo Usbeck", "authors": "Ricardo Usbeck and Michael Hoffmann and Michael R\\\"oder and Jens\n  Lehmann and Axel-Cyrille Ngonga Ngomo", "title": "Using Multi-Label Classification for Improved Question Answering", "comments": "15 pages, 4 Tables, 3 Figues", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A plethora of diverse approaches for question answering over RDF data have\nbeen developed in recent years. While the accuracy of these systems has\nincreased significantly over time, most systems still focus on particular types\nof questions or particular challenges in question answering. What is a curse\nfor single systems is a blessing for the combination of these systems. We show\nin this paper how machine learning techniques can be applied to create a more\naccurate question answering metasystem by reusing existing systems. In\nparticular, we develop a multi-label classification-based metasystem for\nquestion answering over 6 existing systems using an innovative set of 14\nquestion features. The metasystem outperforms the best single system by 14%\nF-measure on the recent QALD-6 benchmark. Furthermore, we analyzed the\ninfluence and correlation of the underlying features on the metasystem quality.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 07:40:16 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Usbeck", "Ricardo", ""], ["Hoffmann", "Michael", ""], ["R\u00f6der", "Michael", ""], ["Lehmann", "Jens", ""], ["Ngomo", "Axel-Cyrille Ngonga", ""]]}, {"id": "1710.08691", "submitter": "Diego Moussallem", "authors": "Axel-Cyrille Ngonga Ngomo, Michael R\\\"oder, Diego Moussallem, Ricardo\n  Usbeck, Ren\\'e Speck", "title": "BENGAL: An Automatic Benchmark Generator for Entity Recognition and\n  Linking", "comments": "Accepted at INLG 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The manual creation of gold standards for named entity recognition and entity\nlinking is time- and resource-intensive. Moreover, recent works show that such\ngold standards contain a large proportion of mistakes in addition to being\ndifficult to maintain. We hence present BENGAL, a novel automatic generation of\nsuch gold standards as a complement to manually created benchmarks. The main\nadvantage of our benchmarks is that they can be readily generated at any time.\nThey are also cost-effective while being guaranteed to be free of annotation\nerrors. We compare the performance of 11 tools on benchmarks in English\ngenerated by BENGAL and on 16benchmarks created manually. We show that our\napproach can be ported easily across languages by presenting results achieved\nby 4 tools on both Brazilian Portuguese and Spanish. Overall, our results\nsuggest that our automatic benchmark generation approach can create varied\nbenchmarks that have characteristics similar to those of existing benchmarks.\nOur approach is open-source. Our experimental results are available at\nhttp://faturl.com/bengalexpinlg and the code at\nhttps://github.com/dice-group/BENGAL.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 10:15:58 GMT"}, {"version": "v2", "created": "Wed, 21 Feb 2018 15:30:52 GMT"}, {"version": "v3", "created": "Thu, 1 Nov 2018 13:40:55 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Ngomo", "Axel-Cyrille Ngonga", ""], ["R\u00f6der", "Michael", ""], ["Moussallem", "Diego", ""], ["Usbeck", "Ricardo", ""], ["Speck", "Ren\u00e9", ""]]}, {"id": "1710.08721", "submitter": "Philippe Thomas", "authors": "Philippe Thomas", "title": "Clickbait Identification using Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the results of our participation in the Clickbait\nDetection Challenge 2017. The system relies on a fusion of neural networks,\nincorporating different types of available informations. It does not require\nany linguistic preprocessing, and hence generalizes more easily to new domains\nand languages. The final combined model achieves a mean squared error of\n0.0428, an accuracy of 0.826, and a F1 score of 0.564. According to the\nofficial evaluation metric the system ranked 6th of the 13 participating teams.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 12:11:07 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Thomas", "Philippe", ""]]}, {"id": "1710.08963", "submitter": "Patrick Perry", "authors": "Patrick O. Perry and Kenneth Benoit", "title": "Scaling Text with the Class Affinity Model", "comments": "30 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic methods for classifying text form a rich tradition in machine\nlearning and natural language processing. For many important problems, however,\nclass prediction is uninteresting because the class is known, and instead the\nfocus shifts to estimating latent quantities related to the text, such as\naffect or ideology. We focus on one such problem of interest, estimating the\nideological positions of 55 Irish legislators in the 1991 D\\'ail confidence\nvote. To solve the D\\'ail scaling problem and others like it, we develop a text\nmodeling framework that allows actors to take latent positions on a \"gray\"\nspectrum between \"black\" and \"white\" polar opposites. We are able to validate\nresults from this model by measuring the influences exhibited by individual\nwords, and we are able to quantify the uncertainty in the scaling estimates by\nusing a sentence-level block bootstrap. Applying our method to the D\\'ail\ndebate, we are able to scale the legislators between extreme pro-government and\npro-opposition in a way that reveals nuances in their speeches not captured by\ntheir votes or party affiliations.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 19:38:20 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Perry", "Patrick O.", ""], ["Benoit", "Kenneth", ""]]}, {"id": "1710.09026", "submitter": "Markus Kliegl", "authors": "Markus Kliegl, Siddharth Goyal, Kexin Zhao, Kavya Srinet, Mohammad\n  Shoeybi", "title": "Trace norm regularization and faster inference for embedded speech\n  recognition RNNs", "comments": "Our optimized inference kernels are available at:\n  https://github.com/PaddlePaddle/farm (Note: This paper was submitted to, but\n  rejected from, ICLR 2018. We believe it may still be of value to others.\n  Please see the discussion here: https://openreview.net/forum?id=B1tC-LT6W)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and evaluate new techniques for compressing and speeding up dense\nmatrix multiplications as found in the fully connected and recurrent layers of\nneural networks for embedded large vocabulary continuous speech recognition\n(LVCSR). For compression, we introduce and study a trace norm regularization\ntechnique for training low rank factored versions of matrix multiplications.\nCompared to standard low rank training, we show that our method leads to good\naccuracy versus number of parameter trade-offs and can be used to speed up\ntraining of large models. For speedup, we enable faster inference on ARM\nprocessors through new open sourced kernels optimized for small batch sizes,\nresulting in 3x to 7x speed ups over the widely used gemmlowp library. Beyond\nLVCSR, we expect our techniques and kernels to be more generally applicable to\nembedded neural networks with large fully connected or recurrent layers.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 00:20:55 GMT"}, {"version": "v2", "created": "Tue, 6 Feb 2018 10:00:10 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Kliegl", "Markus", ""], ["Goyal", "Siddharth", ""], ["Zhao", "Kexin", ""], ["Srinet", "Kavya", ""], ["Shoeybi", "Mohammad", ""]]}, {"id": "1710.09085", "submitter": "Prasenjit Majumder", "authors": "Sounak Banerjee, Prasenjit Majumder, Mandar Mitra", "title": "Re-evaluating the need for Modelling Term-Dependence in Text\n  Classification Problems", "comments": "23 Pages, 16 Figures, 3 Tables, Some Figures at the end of the\n  document because of limiting factors in the Latex format", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A substantial amount of research has been carried out in developing machine\nlearning algorithms that account for term dependence in text classification.\nThese algorithms offer acceptable performance in most cases but they are\nassociated with a substantial cost. They require significantly greater\nresources to operate. This paper argues against the justification of the higher\ncosts of these algorithms, based on their performance in text classification\nproblems. In order to prove the conjecture, the performance of one of the best\ndependence models is compared to several well established algorithms in text\nclassification. A very specific collection of datasets have been designed,\nwhich would best reflect the disparity in the nature of text data, that are\npresent in real world applications. The results show that even one of the best\nterm dependence models, performs decent at best when compared to other\nindependence models. Coupled with their substantially greater requirement for\nhardware resources for operation, this makes them an impractical choice for\nbeing used in real world scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 06:26:28 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Banerjee", "Sounak", ""], ["Majumder", "Prasenjit", ""], ["Mitra", "Mandar", ""]]}, {"id": "1710.09137", "submitter": "Aditya Mogadala", "authors": "Aditya Mogadala, Dominik Jung, Achim Rettinger", "title": "Linking Tweets with Monolingual and Cross-Lingual News using Transformed\n  Word Embeddings", "comments": "Presented at CICLing 2017 (18th International Conference on\n  Intelligent Text Processing and Computational Linguistics). To appear in\n  International Journal of Computational Linguistics and Applications (IJLCA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media platforms have grown into an important medium to spread\ninformation about an event published by the traditional media, such as news\narticles. Grouping such diverse sources of information that discuss the same\ntopic in varied perspectives provide new insights. But the gap in word usage\nbetween informal social media content such as tweets and diligently written\ncontent (e.g. news articles) make such assembling difficult. In this paper, we\npropose a transformation framework to bridge the word usage gap between tweets\nand online news articles across languages by leveraging their word embeddings.\nUsing our framework, word embeddings extracted from tweets and news articles\nare aligned closer to each other across languages, thus facilitating the\nidentification of similarity between news articles and tweets. Experimental\nresults show a notable improvement over baselines for monolingual tweets and\nnews articles comparison, while new findings are reported for cross-lingual\ncomparison.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 09:45:58 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Mogadala", "Aditya", ""], ["Jung", "Dominik", ""], ["Rettinger", "Achim", ""]]}, {"id": "1710.09233", "submitter": "Renato Fabbri", "authors": "Renato Fabbri and Luis Henrique Garcia", "title": "A Simple Text Analytics Model To Assist Literary Criticism: comparative\n  approach and example on James Joyce against Shakespeare and the Bible", "comments": "Scripts and corpus in https://github.com/ttm/joyce", "journal-ref": "Anais do XX ENMC - Encontro Nacional de Modelagem Computacional e\n  VIII ECTM - Encontro de Ci\\^encias e Tecnologia de Materiais, Nova Friburgo,\n  RJ - 16 a 19 Outubro 2017", "doi": null, "report-no": "ISSN 2527-2357, ISBN 978-85-5676-019-7", "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Literary analysis, criticism or studies is a largely valued field with\ndedicated journals and researchers which remains mostly within the humanities\nscope. Text analytics is the computer-aided process of deriving information\nfrom texts. In this article we describe a simple and generic model for\nperforming literary analysis using text analytics. The method relies on\nstatistical measures of: 1) token and sentence sizes and 2) Wordnet synset\nfeatures. These measures are then used in Principal Component Analysis where\nthe texts to be analyzed are observed against Shakespeare and the Bible,\nregarded as reference literature. The model is validated by analyzing selected\nworks from James Joyce (1882-1941), one of the most important writers of the\n20th century. We discuss the consistency of this approach, the reasons why we\ndid not use other techniques (e.g. part-of-speech tagging) and the ways by\nwhich the analysis model might be adapted and enhanced.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 16:08:58 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Fabbri", "Renato", ""], ["Garcia", "Luis Henrique", ""]]}, {"id": "1710.09306", "submitter": "Marcos Zampieri", "authors": "Octavia-Maria Sulea, Marcos Zampieri, Shervin Malmasi, Mihaela Vela,\n  Liviu P. Dinu, Josef van Genabith", "title": "Exploring the Use of Text Classification in the Legal Domain", "comments": "Proceedings of the 2nd Workshop on Automated Semantic Analysis of\n  Information in Legal Texts (ASAIL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the application of text classification methods\nto support law professionals. We present several experiments applying machine\nlearning techniques to predict with high accuracy the ruling of the French\nSupreme Court and the law area to which a case belongs to. We also investigate\nthe influence of the time period in which a ruling was made on the form of the\ncase description and the extent to which we need to mask information in a full\ncase ruling to automatically obtain training and test data that resembles case\ndescriptions. We developed a mean probability ensemble system combining the\noutput of multiple SVM classifiers. We report results of 98% average F1 score\nin predicting a case ruling, 96% F1 score for predicting the law area of a\ncase, and 87.07% F1 score on estimating the date of a ruling.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 15:34:52 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Sulea", "Octavia-Maria", ""], ["Zampieri", "Marcos", ""], ["Malmasi", "Shervin", ""], ["Vela", "Mihaela", ""], ["Dinu", "Liviu P.", ""], ["van Genabith", "Josef", ""]]}, {"id": "1710.09340", "submitter": "Daniel Fern\\'andez-Gonz\\'alez", "authors": "Daniel Fern\\'andez-Gonz\\'alez and Carlos G\\'omez-Rodr\\'iguez", "title": "Non-Projective Dependency Parsing with Non-Local Transitions", "comments": "Proceedings of NAACL-HLT 2018. 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel transition system, based on the Covington non-projective\nparser, introducing non-local transitions that can directly create arcs\ninvolving nodes to the left of the current focus positions. This avoids the\nneed for long sequences of No-Arc transitions to create long-distance arcs,\nthus alleviating error propagation. The resulting parser outperforms the\noriginal version and achieves the best accuracy on the Stanford Dependencies\nconversion of the Penn Treebank among greedy transition-based algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 16:57:51 GMT"}, {"version": "v2", "created": "Mon, 14 May 2018 15:03:35 GMT"}, {"version": "v3", "created": "Tue, 15 May 2018 18:44:23 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Fern\u00e1ndez-Gonz\u00e1lez", "Daniel", ""], ["G\u00f3mez-Rodr\u00edguez", "Carlos", ""]]}, {"id": "1710.09589", "submitter": "Barbara Plank", "authors": "Barbara Plank", "title": "ALL-IN-1: Short Text Classification with One Model for All Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ALL-IN-1, a simple model for multilingual text classification that\ndoes not require any parallel data. It is based on a traditional Support Vector\nMachine classifier exploiting multilingual word embeddings and character\nn-grams. Our model is simple, easily extendable yet very effective, overall\nranking 1st (out of 12 teams) in the IJCNLP 2017 shared task on customer\nfeedback analysis in four languages: English, French, Japanese and Spanish.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 08:41:50 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Plank", "Barbara", ""]]}, {"id": "1710.09617", "submitter": "Yanzhang He", "authors": "Yanzhang He, Rohit Prabhavalkar, Kanishka Rao, Wei Li, Anton Bakhtin,\n  Ian McGraw", "title": "Streaming Small-Footprint Keyword Spotting using Sequence-to-Sequence\n  Models", "comments": "To appear in Proceedings of IEEE ASRU 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop streaming keyword spotting systems using a recurrent neural\nnetwork transducer (RNN-T) model: an all-neural, end-to-end trained,\nsequence-to-sequence model which jointly learns acoustic and language model\ncomponents. Our models are trained to predict either phonemes or graphemes as\nsubword units, thus allowing us to detect arbitrary keyword phrases, without\nany out-of-vocabulary words. In order to adapt the models to the requirements\nof keyword spotting, we propose a novel technique which biases the RNN-T system\ntowards a specific keyword of interest.\n  Our systems are compared against a strong sequence-trained, connectionist\ntemporal classification (CTC) based \"keyword-filler\" baseline, which is\naugmented with a separate phoneme language model. Overall, our RNN-T system\nwith the proposed biasing technique significantly improves performance over the\nbaseline system.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 09:50:16 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["He", "Yanzhang", ""], ["Prabhavalkar", "Rohit", ""], ["Rao", "Kanishka", ""], ["Li", "Wei", ""], ["Bakhtin", "Anton", ""], ["McGraw", "Ian", ""]]}, {"id": "1710.09753", "submitter": "Heike Adel", "authors": "Heike Adel and Hinrich Sch\\\"utze", "title": "Impact of Coreference Resolution on Slot Filling", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we demonstrate the importance of coreference resolution for\nnatural language processing on the example of the TAC Slot Filling shared task.\nWe illustrate the strengths and weaknesses of automatic coreference resolution\nsystems and provide experimental results to show that they improve performance\nin the slot filling end-to-end setting. Finally, we publish KBPchains, a\nresource containing automatically extracted coreference chains from the TAC\nsource corpus in order to support other researchers working on this topic.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 15:25:37 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Adel", "Heike", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1710.09805", "submitter": "Weinan Zhang", "authors": "Long Chen, Fajie Yuan, Joemon M. Jose, Weinan Zhang", "title": "Improving Negative Sampling for Word Representation using Self-embedded\n  Features", "comments": "Accepted in WSDM 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although the word-popularity based negative sampler has shown superb\nperformance in the skip-gram model, the theoretical motivation behind\noversampling popular (non-observed) words as negative samples is still not well\nunderstood. In this paper, we start from an investigation of the gradient\nvanishing issue in the skipgram model without a proper negative sampler. By\nperforming an insightful analysis from the stochastic gradient descent (SGD)\nlearning perspective, we demonstrate that, both theoretically and intuitively,\nnegative samples with larger inner product scores are more informative than\nthose with lower scores for the SGD learner in terms of both convergence rate\nand accuracy. Understanding this, we propose an alternative sampling algorithm\nthat dynamically selects informative negative samples during each SGD update.\nMore importantly, the proposed sampler accounts for multi-dimensional\nself-embedded features during the sampling process, which essentially makes it\nmore effective than the original popularity-based (one-dimensional) sampler.\nEmpirical experiments further verify our observations, and show that our\nfine-grained samplers gain significant improvement over the existing ones\nwithout increasing computational complexity.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 16:54:13 GMT"}, {"version": "v2", "created": "Fri, 8 Dec 2017 18:40:22 GMT"}, {"version": "v3", "created": "Tue, 26 Jun 2018 07:32:18 GMT"}], "update_date": "2018-06-27", "authors_parsed": [["Chen", "Long", ""], ["Yuan", "Fajie", ""], ["Jose", "Joemon M.", ""], ["Zhang", "Weinan", ""]]}, {"id": "1710.09867", "submitter": "Felix Hill Mr", "authors": "Felix Hill, Stephen Clark, Karl Moritz Hermann, Phil Blunsom", "title": "Understanding Early Word Learning in Situated Artificial Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network-based systems can now learn to locate the referents of words\nand phrases in images, answer questions about visual scenes, and execute\nsymbolic instructions as first-person actors in partially-observable worlds. To\nachieve this so-called grounded language learning, models must overcome\nchallenges that infants face when learning their first words. While it is\nnotable that models with no meaningful prior knowledge overcome these\nobstacles, researchers currently lack a clear understanding of how they do so,\na problem that we attempt to address in this paper. For maximum control and\ngenerality, we focus on a simple neural network-based language learning agent,\ntrained via policy-gradient methods, which can interpret single-word\ninstructions in a simulated 3D world. Whilst the goal is not to explicitly\nmodel infant word learning, we take inspiration from experimental paradigms in\ndevelopmental psychology and apply some of these to the artificial agent,\nexploring the conditions under which established human biases and learning\neffects emerge. We further propose a novel method for visualising semantic\nrepresentations in the agent.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 18:48:20 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 17:43:34 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Hill", "Felix", ""], ["Clark", "Stephen", ""], ["Hermann", "Karl Moritz", ""], ["Blunsom", "Phil", ""]]}, {"id": "1710.09942", "submitter": "Sharmistha", "authors": "Tushar Nagarajan, Sharmistha and Partha Talukdar", "title": "CANDiS: Coupled & Attention-Driven Neural Distant Supervision", "comments": "WiNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distant Supervision for Relation Extraction uses heuristically aligned text\ndata with an existing knowledge base as training data. The unsupervised nature\nof this technique allows it to scale to web-scale relation extraction tasks, at\nthe expense of noise in the training data. Previous work has explored\nrelationships among instances of the same entity-pair to reduce this noise, but\nrelationships among instances across entity-pairs have not been fully\nexploited. We explore the use of inter-instance couplings based on verb-phrase\nand entity type similarities. We propose a novel technique, CANDiS, which casts\ndistant supervision using inter-instance coupling into an end-to-end neural\nnetwork model. CANDiS incorporates an attention module at the instance-level to\nmodel the multi-instance nature of this problem. CANDiS outperforms existing\nstate-of-the-art techniques on a standard benchmark dataset.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 23:16:31 GMT"}], "update_date": "2017-10-30", "authors_parsed": [["Nagarajan", "Tushar", ""], ["Sharmistha", "", ""], ["Talukdar", "Partha", ""]]}, {"id": "1710.10224", "submitter": "Jaeyoung Kim", "authors": "Jaeyoung Kim, Mostafa El-Khamy, Jungwon Lee", "title": "BridgeNets: Student-Teacher Transfer Learning Based on Recursive Neural\n  Networks and its Application to Distant Speech Recognition", "comments": "Accepted to 2018 IEEE International Conference on Acoustics, Speech\n  and Signal Processing (ICASSP 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the remarkable progress achieved on automatic speech recognition,\nrecognizing far-field speeches mixed with various noise sources is still a\nchallenging task. In this paper, we introduce novel student-teacher transfer\nlearning, BridgeNet which can provide a solution to improve distant speech\nrecognition. There are two key features in BridgeNet. First, BridgeNet extends\ntraditional student-teacher frameworks by providing multiple hints from a\nteacher network. Hints are not limited to the soft labels from a teacher\nnetwork. Teacher's intermediate feature representations can better guide a\nstudent network to learn how to denoise or dereverberate noisy input. Second,\nthe proposed recursive architecture in the BridgeNet can iteratively improve\ndenoising and recognition performance. The experimental results of BridgeNet\nshowed significant improvements in tackling the distant speech recognition\nproblem, where it achieved up to 13.24% relative WER reductions on AMI corpus\ncompared to a baseline neural network without teacher's hints.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 16:16:05 GMT"}, {"version": "v2", "created": "Fri, 16 Feb 2018 18:42:15 GMT"}, {"version": "v3", "created": "Wed, 21 Feb 2018 21:52:36 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Kim", "Jaeyoung", ""], ["El-Khamy", "Mostafa", ""], ["Lee", "Jungwon", ""]]}, {"id": "1710.10248", "submitter": "Vasily Pestun", "authors": "Vasily Pestun, Yiannis Vlassopoulos", "title": "Tensor network language model", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cond-mat.dis-nn cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new statistical model suitable for machine learning of systems\nwith long distance correlations such as natural languages. The model is based\non directed acyclic graph decorated by multi-linear tensor maps in the vertices\nand vector spaces in the edges, called tensor network. Such tensor networks\nhave been previously employed for effective numerical computation of the\nrenormalization group flow on the space of effective quantum field theories and\nlattice models of statistical mechanics. We provide explicit algebro-geometric\nanalysis of the parameter moduli space for tree graphs, discuss model\nproperties and applications such as statistical translation.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 17:26:57 GMT"}, {"version": "v2", "created": "Mon, 30 Oct 2017 16:03:48 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Pestun", "Vasily", ""], ["Vlassopoulos", "Yiannis", ""]]}, {"id": "1710.10280", "submitter": "Andrew Lampinen", "authors": "Andrew K. Lampinen, James L. McClelland", "title": "One-shot and few-shot learning of word embeddings", "comments": "15 pages, 7 figures, under review as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard deep learning systems require thousands or millions of examples to\nlearn a concept, and cannot integrate new concepts easily. By contrast, humans\nhave an incredible ability to do one-shot or few-shot learning. For instance,\nfrom just hearing a word used in a sentence, humans can infer a great deal\nabout it, by leveraging what the syntax and semantics of the surrounding words\ntells us. Here, we draw inspiration from this to highlight a simple technique\nby which deep recurrent networks can similarly exploit their prior knowledge to\nlearn a useful representation for a new word from little data. This could make\nnatural language processing systems much more flexible, by allowing them to\nlearn continually from the new words they encounter.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 18:05:22 GMT"}, {"version": "v2", "created": "Tue, 2 Jan 2018 16:53:05 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Lampinen", "Andrew K.", ""], ["McClelland", "James L.", ""]]}, {"id": "1710.10361", "submitter": "Jimmy Lin", "authors": "Raphael Tang, Jimmy Lin", "title": "Deep Residual Learning for Small-Footprint Keyword Spotting", "comments": "Published in ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the application of deep residual learning and dilated convolutions\nto the keyword spotting task, using the recently-released Google Speech\nCommands Dataset as our benchmark. Our best residual network (ResNet)\nimplementation significantly outperforms Google's previous convolutional neural\nnetworks in terms of accuracy. By varying model depth and width, we can achieve\ncompact models that also outperform previous small-footprint variants. To our\nknowledge, we are the first to examine these approaches for keyword spotting,\nand our results establish an open-source state-of-the-art reference to support\nthe development of future speech-based interfaces.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 00:43:01 GMT"}, {"version": "v2", "created": "Fri, 21 Sep 2018 10:57:04 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Tang", "Raphael", ""], ["Lin", "Jimmy", ""]]}, {"id": "1710.10380", "submitter": "Shuai Tang", "authors": "Shuai Tang, Hailin Jin, Chen Fang, Zhaowen Wang, Virginia R. de Sa", "title": "Speeding up Context-based Sentence Representation Learning with\n  Non-autoregressive Convolutional Decoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context plays an important role in human language understanding, thus it may\nalso be useful for machines learning vector representations of language. In\nthis paper, we explore an asymmetric encoder-decoder structure for unsupervised\ncontext-based sentence representation learning. We carefully designed\nexperiments to show that neither an autoregressive decoder nor an RNN decoder\nis required. After that, we designed a model which still keeps an RNN as the\nencoder, while using a non-autoregressive convolutional decoder. We further\ncombine a suite of effective designs to significantly improve model efficiency\nwhile also achieving better performance. Our model is trained on two different\nlarge unlabelled corpora, and in both cases the transferability is evaluated on\na set of downstream NLP tasks. We empirically show that our model is simple and\nfast while producing rich sentence representations that excel in downstream\ntasks.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 03:18:12 GMT"}, {"version": "v2", "created": "Sat, 6 Jan 2018 00:12:18 GMT"}, {"version": "v3", "created": "Fri, 1 Jun 2018 01:05:28 GMT"}], "update_date": "2018-06-04", "authors_parsed": [["Tang", "Shuai", ""], ["Jin", "Hailin", ""], ["Fang", "Chen", ""], ["Wang", "Zhaowen", ""], ["de Sa", "Virginia R.", ""]]}, {"id": "1710.10393", "submitter": "Xu Sun", "authors": "Xu Sun, Bingzhen Wei, Xuancheng Ren, Shuming Ma", "title": "Label Embedding Network: Learning Label Representation for Soft Training\n  of Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method, called Label Embedding Network, which can learn label\nrepresentation (label embedding) during the training process of deep networks.\nWith the proposed method, the label embedding is adaptively and automatically\nlearned through back propagation. The original one-hot represented loss\nfunction is converted into a new loss function with soft distributions, such\nthat the originally unrelated labels have continuous interactions with each\nother during the training process. As a result, the trained model can achieve\nsubstantially higher accuracy and with faster convergence speed. Experimental\nresults based on competitive tasks demonstrate the effectiveness of the\nproposed method, and the learned label embedding is reasonable and\ninterpretable. The proposed method achieves comparable or even better results\nthan the state-of-the-art systems. The source code is available at\n\\url{https://github.com/lancopku/LabelEmb}.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 05:42:19 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Sun", "Xu", ""], ["Wei", "Bingzhen", ""], ["Ren", "Xuancheng", ""], ["Ma", "Shuming", ""]]}, {"id": "1710.10398", "submitter": "Kalpesh Krishna", "authors": "Kalpesh Krishna, Liang Lu, Kevin Gimpel, Karen Livescu", "title": "A Study of All-Convolutional Encoders for Connectionist Temporal\n  Classification", "comments": "Accepted to ICASSP-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connectionist temporal classification (CTC) is a popular sequence prediction\napproach for automatic speech recognition that is typically used with models\nbased on recurrent neural networks (RNNs). We explore whether deep\nconvolutional neural networks (CNNs) can be used effectively instead of RNNs as\nthe \"encoder\" in CTC. CNNs lack an explicit representation of the entire\nsequence, but have the advantage that they are much faster to train. We present\nan exploration of CNNs as encoders for CTC models, in the context of\ncharacter-based (lexicon-free) automatic speech recognition. In particular, we\nexplore a range of one-dimensional convolutional layers, which are particularly\nefficient. We compare the performance of our CNN-based models against typical\nRNNbased models in terms of training time, decoding time, model size and word\nerror rate (WER) on the Switchboard Eval2000 corpus. We find that our CNN-based\nmodels are close in performance to LSTMs, while not matching them, and are much\nfaster to train and decode.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 06:24:36 GMT"}, {"version": "v2", "created": "Thu, 15 Feb 2018 18:55:30 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Krishna", "Kalpesh", ""], ["Lu", "Liang", ""], ["Gimpel", "Kevin", ""], ["Livescu", "Karen", ""]]}, {"id": "1710.10453", "submitter": "Avi Caciularu", "authors": "Mor Cohen, Avi Caciularu, Idan Rejwan, Jonathan Berant", "title": "Inducing Regular Grammars Using Recurrent Neural Networks", "comments": "Accepted to L&R 2018 workshop, ICML & IJCAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grammar induction is the task of learning a grammar from a set of examples.\nRecently, neural networks have been shown to be powerful learning machines that\ncan identify patterns in streams of data. In this work we investigate their\neffectiveness in inducing a regular grammar from data, without any assumptions\nabout the grammar. We train a recurrent neural network to distinguish between\nstrings that are in or outside a regular language, and utilize an algorithm for\nextracting the learned finite-state automaton. We apply this method to several\nregular languages and find unexpected results regarding the connections between\nthe network's states that may be regarded as evidence for generalization.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 12:00:09 GMT"}, {"version": "v2", "created": "Tue, 26 Jun 2018 14:27:47 GMT"}], "update_date": "2018-06-27", "authors_parsed": [["Cohen", "Mor", ""], ["Caciularu", "Avi", ""], ["Rejwan", "Idan", ""], ["Berant", "Jonathan", ""]]}, {"id": "1710.10467", "submitter": "Quan Wang", "authors": "Li Wan, Quan Wang, Alan Papir, Ignacio Lopez Moreno", "title": "Generalized End-to-End Loss for Speaker Verification", "comments": "Published at ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new loss function called generalized end-to-end\n(GE2E) loss, which makes the training of speaker verification models more\nefficient than our previous tuple-based end-to-end (TE2E) loss function. Unlike\nTE2E, the GE2E loss function updates the network in a way that emphasizes\nexamples that are difficult to verify at each step of the training process.\nAdditionally, the GE2E loss does not require an initial stage of example\nselection. With these properties, our model with the new loss function\ndecreases speaker verification EER by more than 10%, while reducing the\ntraining time by 60% at the same time. We also introduce the MultiReader\ntechnique, which allows us to do domain adaptation - training a more accurate\nmodel that supports multiple keywords (i.e. \"OK Google\" and \"Hey Google\") as\nwell as multiple dialects.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 13:51:51 GMT"}, {"version": "v2", "created": "Wed, 31 Jan 2018 22:11:24 GMT"}, {"version": "v3", "created": "Fri, 14 Dec 2018 21:29:09 GMT"}, {"version": "v4", "created": "Thu, 24 Jan 2019 19:13:25 GMT"}, {"version": "v5", "created": "Mon, 9 Nov 2020 17:02:39 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Wan", "Li", ""], ["Wang", "Quan", ""], ["Papir", "Alan", ""], ["Moreno", "Ignacio Lopez", ""]]}, {"id": "1710.10498", "submitter": "Shubhangi Tandon", "authors": "Sharath T. S. and Shubhangi Tandon", "title": "Topic Based Sentiment Analysis Using Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper , we tackle Sentiment Analysis conditioned on a Topic in\nTwitter data using Deep Learning . We propose a 2-tier approach : In the first\nphase we create our own Word Embeddings and see that they do perform better\nthan state-of-the-art embeddings when used with standard classifiers. We then\nperform inference on these embeddings to learn more about a word with respect\nto all the topics being considered, and also the top n-influencing words for\neach topic. In the second phase we use these embeddings to predict the\nsentiment of the tweet with respect to a given topic, and all other topics\nunder discussion.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 17:13:49 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["S.", "Sharath T.", ""], ["Tandon", "Shubhangi", ""]]}, {"id": "1710.10504", "submitter": "Rui Liu", "authors": "Rui Liu, Wei Wei, Weiguang Mao, Maria Chikina", "title": "Phase Conductor on Multi-layered Attentions for Machine Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention models have been intensively studied to improve NLP tasks such as\nmachine comprehension via both question-aware passage attention model and\nself-matching attention model. Our research proposes phase conductor\n(PhaseCond) for attention models in two meaningful ways. First, PhaseCond, an\narchitecture of multi-layered attention models, consists of multiple phases\neach implementing a stack of attention layers producing passage representations\nand a stack of inner or outer fusion layers regulating the information flow.\nSecond, we extend and improve the dot-product attention function for PhaseCond\nby simultaneously encoding multiple question and passage embedding layers from\ndifferent perspectives. We demonstrate the effectiveness of our proposed model\nPhaseCond on the SQuAD dataset, showing that our model significantly\noutperforms both state-of-the-art single-layered and multiple-layered attention\nmodels. We deepen our results with new findings via both detailed qualitative\nanalysis and visualized examples showing the dynamic changes through\nmulti-layered attention models.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 17:28:04 GMT"}, {"version": "v2", "created": "Wed, 1 Nov 2017 00:15:22 GMT"}], "update_date": "2017-11-02", "authors_parsed": [["Liu", "Rui", ""], ["Wei", "Wei", ""], ["Mao", "Weiguang", ""], ["Chikina", "Maria", ""]]}, {"id": "1710.10520", "submitter": "Shubhangi Tandon", "authors": "Sharath T.S., Shubhangi Tandon, Ryan Bauer", "title": "A Dual Encoder Sequence to Sequence Model for Open-Domain Dialogue\n  Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ever since the successful application of sequence to sequence learning for\nneural machine translation systems, interest has surged in its applicability\ntowards language generation in other problem domains. Recent work has\ninvestigated the use of these neural architectures towards modeling open-domain\nconversational dialogue, where it has been found that although these models are\ncapable of learning a good distributional language model, dialogue coherence is\nstill of concern. Unlike translation, conversation is much more a one-to-many\nmapping from utterance to a response, and it is even more pressing that the\nmodel be aware of the preceding flow of conversation. In this paper we propose\nto tackle this problem by introducing previous conversational context in terms\nof latent representations of dialogue acts over time. We inject the latent\ncontext representations into a sequence to sequence neural network in the form\nof dialog acts using a second encoder to enhance the quality and the coherence\nof the conversations generated. The main task of this research work is to show\nthat adding latent variables that capture discourse relations does indeed\nresult in more coherent responses when compared to conventional sequence to\nsequence models.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 19:40:47 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["S.", "Sharath T.", ""], ["Tandon", "Shubhangi", ""], ["Bauer", "Ryan", ""]]}, {"id": "1710.10574", "submitter": "Zih-Wei Lin", "authors": "Zih-Wei Lin, Tzu-Wei Sung, Hung-Yi Lee, Lin-Shan Lee", "title": "Personalized word representations Carrying Personalized Semantics\n  Learned from Social Network Posts", "comments": "Accepted by the 12th biannual IEEE workshop on Automatic Speech\n  Recognition and Understanding (ASRU'17)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed word representations have been shown to be very useful in various\nnatural language processing (NLP) application tasks. These word vectors learned\nfrom huge corpora very often carry both semantic and syntactic information of\nwords. However, it is well known that each individual user has his own language\npatterns because of different factors such as interested topics, friend groups,\nsocial activities, wording habits, etc., which may imply some kind of\npersonalized semantics. With such personalized semantics, the same word may\nimply slightly differently for different users. For example, the word\n\"Cappuccino\" may imply \"Leisure\", \"Joy\", \"Excellent\" for a user enjoying\ncoffee, by only a kind of drink for someone else. Such personalized semantics\nof course cannot be carried by the standard universal word vectors trained with\nhuge corpora produced by many people. In this paper, we propose a framework to\ntrain different personalized word vectors for different users based on the very\nsuccessful continuous skip-gram model using the social network data posted by\nmany individual users. In this framework, universal background word vectors are\nfirst learned from the background corpora, and then adapted by the personalized\ncorpus for each individual user to learn the personalized word vectors. We use\ntwo application tasks to evaluate the quality of the personalized word vectors\nobtained in this way, the user prediction task and the sentence completion\ntask. These personalized word vectors were shown to carry some personalized\nsemantics and offer improved performance on these two evaluation tasks.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 08:04:24 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Lin", "Zih-Wei", ""], ["Sung", "Tzu-Wei", ""], ["Lee", "Hung-Yi", ""], ["Lee", "Lin-Shan", ""]]}, {"id": "1710.10585", "submitter": "Yantao Jia", "authors": "Denghui Zhang, Pengshan Cai, Yantao Jia, Manling Li, Yuanzhuo Wang,\n  Xueqi Cheng", "title": "Path-Based Attention Neural Model for Fine-Grained Entity Typing", "comments": "AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Fine-grained entity typing aims to assign entity mentions in the free text\nwith types arranged in a hierarchical structure. Traditional distant\nsupervision based methods employ a structured data source as a weak supervision\nand do not need hand-labeled data, but they neglect the label noise in the\nautomatically labeled training corpus. Although recent studies use many\nfeatures to prune wrong data ahead of training, they suffer from error\npropagation and bring much complexity. In this paper, we propose an end-to-end\ntyping model, called the path-based attention neural model (PAN), to learn a\nnoise- robust performance by leveraging the hierarchical structure of types.\nExperiments demonstrate its effectiveness.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 09:24:56 GMT"}, {"version": "v2", "created": "Tue, 9 Jan 2018 02:56:13 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["Zhang", "Denghui", ""], ["Cai", "Pengshan", ""], ["Jia", "Yantao", ""], ["Li", "Manling", ""], ["Wang", "Yuanzhuo", ""], ["Cheng", "Xueqi", ""]]}, {"id": "1710.10586", "submitter": "Yvette Graham", "authors": "Yvette Graham, George Awad, Alan Smeaton", "title": "Evaluation of Automatic Video Captioning Using Direct Assessment", "comments": "26 pages, 8 figures", "journal-ref": null, "doi": "10.1371/journal.pone.0202789", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Direct Assessment, a method for manually assessing the quality of\nautomatically-generated captions for video. Evaluating the accuracy of video\ncaptions is particularly difficult because for any given video clip there is no\ndefinitive ground truth or correct answer against which to measure. Automatic\nmetrics for comparing automatic video captions against a manual caption such as\nBLEU and METEOR, drawn from techniques used in evaluating machine translation,\nwere used in the TRECVid video captioning task in 2016 but these are shown to\nhave weaknesses. The work presented here brings human assessment into the\nevaluation by crowdsourcing how well a caption describes a video. We\nautomatically degrade the quality of some sample captions which are assessed\nmanually and from this we are able to rate the quality of the human assessors,\na factor we take into account in the evaluation. Using data from the TRECVid\nvideo-to-text task in 2016, we show how our direct assessment method is\nreplicable and robust and should scale to where there many caption-generation\ntechniques to be evaluated.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 09:37:02 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Graham", "Yvette", ""], ["Awad", "George", ""], ["Smeaton", "Alan", ""]]}, {"id": "1710.10609", "submitter": "Dhiraj Madan", "authors": "Dhiraj Madan and Sachindra Joshi", "title": "Finding Dominant User Utterances And System Responses in Conversations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are several dialog frameworks which allow manual specification of\nintents and rule based dialog flow. The rule based framework provides good\ncontrol to dialog designers at the expense of being more time consuming and\nlaborious. The job of a dialog designer can be reduced if we could identify\npairs of user intents and corresponding responses automatically from prior\nconversations between users and agents. In this paper we propose an approach to\nfind these frequent user utterances (which serve as examples for intents) and\ncorresponding agent responses. We propose a novel SimCluster algorithm that\nextends standard K-means algorithm to simultaneously cluster user utterances\nand agent utterances by taking their adjacency information into account. The\nmethod also aligns these clusters to provide pairs of intents and response\ngroups. We compare our results with those produced by using simple Kmeans\nclustering on a real dataset and observe upto 10% absolute improvement in\nF1-scores. Through our experiments on synthetic dataset, we show that our\nalgorithm gains more advantage over K-means algorithm when the data has large\nvariance.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 13:21:18 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Madan", "Dhiraj", ""], ["Joshi", "Sachindra", ""]]}, {"id": "1710.10639", "submitter": "Reid Pryzant", "authors": "Reid Pryzant, Yongjoo Chung, Dan Jurafsky, and Denny Britz", "title": "JESC: Japanese-English Subtitle Corpus", "comments": "To appear at LREC 2018. Project website updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe the Japanese-English Subtitle Corpus (JESC). JESC\nis a large Japanese-English parallel corpus covering the underrepresented\ndomain of conversational dialogue. It consists of more than 3.2 million\nexamples, making it the largest freely available dataset of its kind. The\ncorpus was assembled by crawling and aligning subtitles found on the web. The\nassembly process incorporates a number of novel preprocessing elements to\nensure high monolingual fluency and accurate bilingual alignments. We summarize\nits contents and evaluate its quality using human experts and baseline machine\ntranslation (MT) systems.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 16:15:30 GMT"}, {"version": "v2", "created": "Tue, 31 Oct 2017 01:04:43 GMT"}, {"version": "v3", "created": "Thu, 14 Dec 2017 15:50:39 GMT"}, {"version": "v4", "created": "Wed, 21 Feb 2018 16:23:56 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Pryzant", "Reid", ""], ["Chung", "Yongjoo", ""], ["Jurafsky", "Dan", ""], ["Britz", "Denny", ""]]}, {"id": "1710.10723", "submitter": "Christopher Clark", "authors": "Christopher Clark and Matt Gardner", "title": "Simple and Effective Multi-Paragraph Reading Comprehension", "comments": "11 pages, updated a reference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of adapting neural paragraph-level question answering\nmodels to the case where entire documents are given as input. Our proposed\nsolution trains models to produce well calibrated confidence scores for their\nresults on individual paragraphs. We sample multiple paragraphs from the\ndocuments during training, and use a shared-normalization training objective\nthat encourages the model to produce globally correct output. We combine this\nmethod with a state-of-the-art pipeline for training models on document QA\ndata. Experiments demonstrate strong performance on several document QA\ndatasets. Overall, we are able to achieve a score of 71.3 F1 on the web portion\nof TriviaQA, a large improvement from the 56.7 F1 of the previous best system.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 23:47:49 GMT"}, {"version": "v2", "created": "Tue, 7 Nov 2017 18:55:35 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Clark", "Christopher", ""], ["Gardner", "Matt", ""]]}, {"id": "1710.10739", "submitter": "Bin Wang", "authors": "Bin Wang and Zhijian Ou", "title": "Learning neural trans-dimensional random field language models with\n  noise-contrastive estimation", "comments": "5 pages and 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trans-dimensional random field language models (TRF LMs) where sentences are\nmodeled as a collection of random fields, have shown close performance with\nLSTM LMs in speech recognition and are computationally more efficient in\ninference. However, the training efficiency of neural TRF LMs is not\nsatisfactory, which limits the scalability of TRF LMs on large training corpus.\nIn this paper, several techniques on both model formulation and parameter\nestimation are proposed to improve the training efficiency and the performance\nof neural TRF LMs. First, TRFs are reformulated in the form of exponential\ntilting of a reference distribution. Second, noise-contrastive estimation (NCE)\nis introduced to jointly estimate the model parameters and normalization\nconstants. Third, we extend the neural TRF LMs by marrying the deep\nconvolutional neural network (CNN) and the bidirectional LSTM into the\npotential function to extract the deep hierarchical features and\nbidirectionally sequential features. Utilizing all the above techniques enables\nthe successful and efficient training of neural TRF LMs on a 40x larger\ntraining set with only 1/3 training time and further reduces the WER with\nrelative reduction of 4.7% on top of a strong LSTM LM baseline.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 01:55:10 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Wang", "Bin", ""], ["Ou", "Zhijian", ""]]}, {"id": "1710.10774", "submitter": "Andros Tjandra", "authors": "Andros Tjandra, Sakriani Sakti, Satoshi Nakamura", "title": "Sequence-to-Sequence ASR Optimization via Reinforcement Learning", "comments": "Accepted at ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the success of sequence-to-sequence approaches in automatic speech\nrecognition (ASR) systems, the models still suffer from several problems,\nmainly due to the mismatch between the training and inference conditions. In\nthe sequence-to-sequence architecture, the model is trained to predict the\ngrapheme of the current time-step given the input of speech signal and the\nground-truth grapheme history of the previous time-steps. However, it remains\nunclear how well the model approximates real-world speech during inference.\nThus, generating the whole transcription from scratch based on previous\npredictions is complicated and errors can propagate over time. Furthermore, the\nmodel is optimized to maximize the likelihood of training data instead of error\nrate evaluation metrics that actually quantify recognition quality. This paper\npresents an alternative strategy for training sequence-to-sequence ASR models\nby adopting the idea of reinforcement learning (RL). Unlike the standard\ntraining scheme with maximum likelihood estimation, our proposed approach\nutilizes the policy gradient algorithm. We can (1) sample the whole\ntranscription based on the model's prediction in the training process and (2)\ndirectly optimize the model with negative Levenshtein distance as the reward.\nExperimental results demonstrate that we significantly improved the performance\ncompared to a model trained only with maximum likelihood estimation.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 05:09:36 GMT"}, {"version": "v2", "created": "Wed, 28 Feb 2018 13:44:38 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Tjandra", "Andros", ""], ["Sakti", "Sakriani", ""], ["Nakamura", "Satoshi", ""]]}, {"id": "1710.10777", "submitter": "Yao Ming", "authors": "Yao Ming and Shaozu Cao and Ruixiang Zhang and Zhen Li and Yuanzhe\n  Chen and Yangqiu Song and Huamin Qu", "title": "Understanding Hidden Memories of Recurrent Neural Networks", "comments": "Published at IEEE Conference on Visual Analytics Science and\n  Technology (IEEE VAST 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) have been successfully applied to various\nnatural language processing (NLP) tasks and achieved better results than\nconventional methods. However, the lack of understanding of the mechanisms\nbehind their effectiveness limits further improvements on their architectures.\nIn this paper, we present a visual analytics method for understanding and\ncomparing RNN models for NLP tasks. We propose a technique to explain the\nfunction of individual hidden state units based on their expected response to\ninput texts. We then co-cluster hidden state units and words based on the\nexpected response and visualize co-clustering results as memory chips and word\nclouds to provide more structured knowledge on RNNs' hidden states. We also\npropose a glyph-based sequence visualization based on aggregate information to\nanalyze the behavior of an RNN's hidden state at the sentence-level. The\nusability and effectiveness of our method are demonstrated through case studies\nand reviews from domain experts.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 05:37:25 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Ming", "Yao", ""], ["Cao", "Shaozu", ""], ["Zhang", "Ruixiang", ""], ["Li", "Zhen", ""], ["Chen", "Yuanzhe", ""], ["Song", "Yangqiu", ""], ["Qu", "Huamin", ""]]}, {"id": "1710.10994", "submitter": "Mohammad Ebrahim Khademi", "authors": "Mohammad Ebrahim Khademi, Mohammad Fakhredanesh and Seyed Mojtaba\n  Hoseini", "title": "Conceptual Text Summarizer: A new model in continuous vector space", "comments": "The experimental results completed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional methods of summarization are not cost-effective and possible\ntoday. Extractive summarization is a process that helps to extract the most\nimportant sentences from a text automatically and generates a short informative\nsummary. In this work, we propose an unsupervised method to summarize Persian\ntexts. This method is a novel hybrid approach that clusters the concepts of the\ntext using deep learning and traditional statistical methods. First we produce\na word embedding based on Hamshahri2 corpus and a dictionary of word\nfrequencies. Then the proposed algorithm extracts the keywords of the document,\nclusters its concepts, and finally ranks the sentences to produce the summary.\nWe evaluated the proposed method on Pasokh single-document corpus using the\nROUGE evaluation measure. Without using any hand-crafted features, our proposed\nmethod achieves state-of-the-art results. We compared our unsupervised method\nwith the best supervised Persian methods and we achieved an overall improvement\nof ROUGE-2 recall score of 7.5%.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 14:55:25 GMT"}, {"version": "v2", "created": "Mon, 5 Feb 2018 13:34:02 GMT"}, {"version": "v3", "created": "Sat, 1 Sep 2018 11:40:10 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Khademi", "Mohammad Ebrahim", ""], ["Fakhredanesh", "Mohammad", ""], ["Hoseini", "Seyed Mojtaba", ""]]}, {"id": "1710.11027", "submitter": "Diego Esteves", "authors": "Diego Esteves and Rafael Peres and Jens Lehmann and Giulio Napolitano", "title": "Named Entity Recognition in Twitter using Images and Text", "comments": "The 3rd International Workshop on Natural Language Processing for\n  Informal Text (NLPIT 2017), 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named Entity Recognition (NER) is an important subtask of information\nextraction that seeks to locate and recognise named entities. Despite recent\nachievements, we still face limitations with correctly detecting and\nclassifying entities, prominently in short and noisy text, such as Twitter. An\nimportant negative aspect in most of NER approaches is the high dependency on\nhand-crafted features and domain-specific knowledge, necessary to achieve\nstate-of-the-art results. Thus, devising models to deal with such\nlinguistically complex contexts is still challenging. In this paper, we propose\na novel multi-level architecture that does not rely on any specific linguistic\nresource or encoded rule. Unlike traditional approaches, we use features\nextracted from images and text to classify named entities. Experimental tests\nagainst state-of-the-art NER for Twitter on the Ritter dataset present\ncompetitive results (0.59 F-measure), indicating that this approach may lead\ntowards better NER models.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 15:56:03 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Esteves", "Diego", ""], ["Peres", "Rafael", ""], ["Lehmann", "Jens", ""], ["Napolitano", "Giulio", ""]]}, {"id": "1710.11035", "submitter": "Andrei Popescu-Belis", "authors": "Pierre-Edouard Honnet, Andrei Popescu-Belis, Claudiu Musat, Michael\n  Baeriswyl", "title": "Machine Translation of Low-Resource Spoken Dialects: Strategies for\n  Normalizing Swiss German", "comments": "11th Language Resources and Evaluation Conference (LREC), 7-12 May\n  2018, Miyazaki (Japan)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this work is to design a machine translation (MT) system for a\nlow-resource family of dialects, collectively known as Swiss German, which are\nwidely spoken in Switzerland but seldom written. We collected a significant\nnumber of parallel written resources to start with, up to a total of about 60k\nwords. Moreover, we identified several other promising data sources for Swiss\nGerman. Then, we designed and compared three strategies for normalizing Swiss\nGerman input in order to address the regional diversity. We found that\ncharacter-based neural MT was the best solution for text normalization. In\ncombination with phrase-based statistical MT, our solution reached 36% BLEU\nscore when translating from the Bernese dialect. This value, however, decreases\nas the testing data becomes more remote from the training one, geographically\nand topically. These resources and normalization techniques are a first step\ntowards full MT of Swiss German dialects.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 16:04:04 GMT"}, {"version": "v2", "created": "Tue, 6 Feb 2018 15:23:52 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Honnet", "Pierre-Edouard", ""], ["Popescu-Belis", "Andrei", ""], ["Musat", "Claudiu", ""], ["Baeriswyl", "Michael", ""]]}, {"id": "1710.11041", "submitter": "Mikel Artetxe", "authors": "Mikel Artetxe, Gorka Labaka, Eneko Agirre, Kyunghyun Cho", "title": "Unsupervised Neural Machine Translation", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of the recent success of neural machine translation (NMT) in\nstandard benchmarks, the lack of large parallel corpora poses a major practical\nproblem for many language pairs. There have been several proposals to alleviate\nthis issue with, for instance, triangulation and semi-supervised learning\ntechniques, but they still require a strong cross-lingual signal. In this work,\nwe completely remove the need of parallel data and propose a novel method to\ntrain an NMT system in a completely unsupervised manner, relying on nothing but\nmonolingual corpora. Our model builds upon the recent work on unsupervised\nembedding mappings, and consists of a slightly modified attentional\nencoder-decoder model that can be trained on monolingual corpora alone using a\ncombination of denoising and backtranslation. Despite the simplicity of the\napproach, our system obtains 15.56 and 10.21 BLEU points in WMT 2014\nFrench-to-English and German-to-English translation. The model can also profit\nfrom small parallel corpora, and attains 21.81 and 15.24 points when combined\nwith 100,000 parallel sentences, respectively. Our implementation is released\nas an open source project.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 16:17:34 GMT"}, {"version": "v2", "created": "Mon, 26 Feb 2018 16:54:14 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Artetxe", "Mikel", ""], ["Labaka", "Gorka", ""], ["Agirre", "Eneko", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1710.11154", "submitter": "Viviana Cotik", "authors": "Viviana Cotik and Dar\\'io Filippo and Roland Roller and Hans Uszkoreit\n  and Feiyu Xu", "title": "Creation of an Annotated Corpus of Spanish Radiology Reports", "comments": "WiNLP Workshop ACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new annotated corpus of 513 anonymized radiology\nreports written in Spanish. Reports were manually annotated with entities,\nnegation and uncertainty terms and relations. The corpus was conceived as an\nevaluation resource for named entity recognition and relation extraction\nalgorithms, and as input for the use of supervised methods. Biomedical\nannotated resources are scarce due to confidentiality issues and associated\ncosts. This work provides some guidelines that could help other researchers to\nundertake similar tasks.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 18:05:57 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Cotik", "Viviana", ""], ["Filippo", "Dar\u00edo", ""], ["Roller", "Roland", ""], ["Uszkoreit", "Hans", ""], ["Xu", "Feiyu", ""]]}, {"id": "1710.11169", "submitter": "Xiang Ren", "authors": "Zeqiu Wu, Xiang Ren, Frank F. Xu, Ji Li, Jiawei Han", "title": "Indirect Supervision for Relation Extraction using Question-Answer Pairs", "comments": "9 pages + 1 page reference. Accepted to WSDM 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic relation extraction (RE) for types of interest is of great\nimportance for interpreting massive text corpora in an efficient manner.\nTraditional RE models have heavily relied on human-annotated corpus for\ntraining, which can be costly in generating labeled data and become obstacles\nwhen dealing with more relation types. Thus, more RE extraction systems have\nshifted to be built upon training data automatically acquired by linking to\nknowledge bases (distant supervision). However, due to the incompleteness of\nknowledge bases and the context-agnostic labeling, the training data collected\nvia distant supervision (DS) can be very noisy. In recent years, as increasing\nattention has been brought to tackling question-answering (QA) tasks, user\nfeedback or datasets of such tasks become more accessible. In this paper, we\npropose a novel framework, ReQuest, to leverage question-answer pairs as an\nindirect source of supervision for relation extraction, and study how to use\nsuch supervision to reduce noise induced from DS. Our model jointly embeds\nrelation mentions, types, QA entity mention pairs and text features in two\nlow-dimensional spaces (RE and QA), where objects with same relation types or\nsemantically similar question-answer pairs have similar representations. Shared\nfeatures connect these two spaces, carrying clearer semantic knowledge from\nboth sources. ReQuest, then use these learned embeddings to estimate the types\nof test relation mentions. We formulate a global objective function and adopt a\nnovel margin-based QA loss to reduce noise in DS by exploiting semantic\nevidence from the QA dataset. Our experimental results achieve an average of\n11% improvement in F1 score on two public RE datasets combined with TREC QA\ndataset.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 18:27:19 GMT"}, {"version": "v2", "created": "Thu, 23 Nov 2017 07:43:31 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Wu", "Zeqiu", ""], ["Ren", "Xiang", ""], ["Xu", "Frank F.", ""], ["Li", "Ji", ""], ["Han", "Jiawei", ""]]}, {"id": "1710.11277", "submitter": "Xiujun Li", "authors": "Baolin Peng and Xiujun Li and Jianfeng Gao and Jingjing Liu and\n  Yun-Nung Chen and Kam-Fai Wong", "title": "Adversarial Advantage Actor-Critic Model for Task-Completion Dialogue\n  Policy Learning", "comments": "5 pages, 3 figures, ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new method --- adversarial advantage actor-critic\n(Adversarial A2C), which significantly improves the efficiency of dialogue\npolicy learning in task-completion dialogue systems. Inspired by generative\nadversarial networks (GAN), we train a discriminator to differentiate\nresponses/actions generated by dialogue agents from responses/actions by\nexperts. Then, we incorporate the discriminator as another critic into the\nadvantage actor-critic (A2C) framework, to encourage the dialogue agent to\nexplore state-action within the regions where the agent takes actions similar\nto those of the experts. Experimental results in a movie-ticket booking domain\nshow that the proposed Adversarial A2C can accelerate policy exploration\nefficiently.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 00:25:03 GMT"}, {"version": "v2", "created": "Thu, 8 Feb 2018 18:41:05 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Peng", "Baolin", ""], ["Li", "Xiujun", ""], ["Gao", "Jianfeng", ""], ["Liu", "Jingjing", ""], ["Chen", "Yun-Nung", ""], ["Wong", "Kam-Fai", ""]]}, {"id": "1710.11301", "submitter": "Chris Bruno", "authors": "Daniel Harasim, Chris Bruno, Eva Portelance, Martin Rohrmeier, Timothy\n  J. O'Donnell", "title": "A generalized parsing framework for Abstract Grammars", "comments": "Technical Report [v2: added Martin Rohrmeier as author.] [v3: fixed\n  error stating that AGs are equivalent to GCFGS. this is in fact not known\n  yet. other minor typos fixed.]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This technical report presents a general framework for parsing a variety of\ngrammar formalisms. We develop a grammar formalism, called an Abstract Grammar,\nwhich is general enough to represent grammars at many levels of the hierarchy,\nincluding Context Free Grammars, Minimalist Grammars, and Generalized\nContext-free Grammars. We then develop a single parsing framework which is\ncapable of parsing grammars which are at least up to GCFGs on the hierarchy.\nOur parsing framework exposes a grammar interface, so that it can parse any\nparticular grammar formalism that can be reduced to an Abstract Grammar.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 02:23:15 GMT"}, {"version": "v2", "created": "Thu, 30 Nov 2017 15:04:09 GMT"}, {"version": "v3", "created": "Fri, 19 Jan 2018 17:49:05 GMT"}], "update_date": "2018-01-22", "authors_parsed": [["Harasim", "Daniel", ""], ["Bruno", "Chris", ""], ["Portelance", "Eva", ""], ["Rohrmeier", "Martin", ""], ["O'Donnell", "Timothy J.", ""]]}, {"id": "1710.11332", "submitter": "Jingjing Xu", "authors": "Jingjing Xu", "title": "Improving Social Media Text Summarization by Learning Sentence Weight\n  Distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, encoder-decoder models are widely used in social media text\nsummarization. However, these models sometimes select noise words in irrelevant\nsentences as part of a summary by error, thus declining the performance. In\norder to inhibit irrelevant sentences and focus on key information, we propose\nan effective approach by learning sentence weight distribution. In our model,\nwe build a multi-layer perceptron to predict sentence weights. During training,\nwe use the ROUGE score as an alternative to the estimated sentence weight, and\ntry to minimize the gap between estimated weights and predicted weights. In\nthis way, we encourage our model to focus on the key sentences, which have high\nrelevance with the summary. Experimental results show that our approach\noutperforms baselines on a large-scale social media corpus.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 05:43:52 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Xu", "Jingjing", ""]]}, {"id": "1710.11334", "submitter": "Jingjing Xu", "authors": "Jingjing Xu", "title": "Shallow Discourse Parsing with Maximum Entropy Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, more research has been devoted to studying the subtask of\nthe complete shallow discourse parsing, such as indentifying discourse\nconnective and arguments of connective. There is a need to design a full\ndiscourse parser to pull these subtasks together. So we develop a discourse\nparser turning the free text into discourse relations. The parser includes\nconnective identifier, arguments identifier, sense classifier and non-explicit\nidentifier, which connects with each other in pipeline. Each component applies\nthe maximum entropy model with abundant lexical and syntax features extracted\nfrom the Penn Discourse Tree-bank. The head-based representation of the PDTB is\nadopted in the arguments identifier, which turns the problem of indentifying\nthe arguments of discourse connective into finding the head and end of the\narguments. In the non-explicit identifier, the contextual type features like\nwords which have high frequency and can reflect the discourse relation are\nintroduced to improve the performance of non-explicit identifier. Compared with\nother methods, experimental results achieve the considerable performance.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 05:47:38 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Xu", "Jingjing", ""]]}, {"id": "1710.11342", "submitter": "Zhengli Zhao", "authors": "Zhengli Zhao, Dheeru Dua, Sameer Singh", "title": "Generating Natural Adversarial Examples", "comments": "Published as a conference paper at the International Conference on\n  Learning Representations (ICLR) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to their complex nature, it is hard to characterize the ways in which\nmachine learning models can misbehave or be exploited when deployed. Recent\nwork on adversarial examples, i.e. inputs with minor perturbations that result\nin substantially different model predictions, is helpful in evaluating the\nrobustness of these models by exposing the adversarial scenarios where they\nfail. However, these malicious perturbations are often unnatural, not\nsemantically meaningful, and not applicable to complicated domains such as\nlanguage. In this paper, we propose a framework to generate natural and legible\nadversarial examples that lie on the data manifold, by searching in semantic\nspace of dense and continuous data representation, utilizing the recent\nadvances in generative adversarial networks. We present generated adversaries\nto demonstrate the potential of the proposed approach for black-box classifiers\nfor a wide range of applications such as image classification, textual\nentailment, and machine translation. We include experiments to show that the\ngenerated adversaries are natural, legible to humans, and useful in evaluating\nand analyzing black-box classifiers.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 06:22:26 GMT"}, {"version": "v2", "created": "Fri, 23 Feb 2018 23:28:31 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Zhao", "Zhengli", ""], ["Dua", "Dheeru", ""], ["Singh", "Sameer", ""]]}, {"id": "1710.11344", "submitter": "Yu Wu", "authors": "Yu Wu, Wei Wu, Chen Xing, Can Xu, Zhoujun Li, Ming Zhou", "title": "A Sequential Matching Framework for Multi-turn Response Selection in\n  Retrieval-based Chatbots", "comments": "Submitted to Computational Linguistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of response selection for multi-turn conversation in\nretrieval-based chatbots. The task requires matching a response candidate with\na conversation context, whose challenges include how to recognize important\nparts of the context, and how to model the relationships among utterances in\nthe context. Existing matching methods may lose important information in\ncontexts as we can interpret them with a unified framework in which contexts\nare transformed to fixed-length vectors without any interaction with responses\nbefore matching. The analysis motivates us to propose a new matching framework\nthat can sufficiently carry the important information in contexts to matching\nand model the relationships among utterances at the same time. The new\nframework, which we call a sequential matching framework (SMF), lets each\nutterance in a context interacts with a response candidate at the first step\nand transforms the pair to a matching vector. The matching vectors are then\naccumulated following the order of the utterances in the context with a\nrecurrent neural network (RNN) which models the relationships among the\nutterances. The context-response matching is finally calculated with the hidden\nstates of the RNN. Under SMF, we propose a sequential convolutional network and\nsequential attention network and conduct experiments on two public data sets to\ntest their performance. Experimental results show that both models can\nsignificantly outperform the state-of-the-art matching methods. We also show\nthat the models are interpretable with visualizations that provide us insights\non how they capture and leverage the important information in contexts for\nmatching.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 06:29:11 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Wu", "Yu", ""], ["Wu", "Wei", ""], ["Xing", "Chen", ""], ["Xu", "Can", ""], ["Li", "Zhoujun", ""], ["Zhou", "Ming", ""]]}, {"id": "1710.11350", "submitter": "Eva Portelance", "authors": "Eva Portelance, Amelia Bruno, Daniel Harasim, Leon Bergen and Timothy\n  J. O'Donnell", "title": "Grammar Induction for Minimalist Grammars using Variational Bayesian\n  Inference : A Technical Report", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The following technical report presents a formal approach to probabilistic\nminimalist grammar parameter estimation. We describe a formalization of a\nminimalist grammar. We then present an algorithm for the application of\nvariational Bayesian inference to this formalization.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 07:09:14 GMT"}, {"version": "v2", "created": "Thu, 18 Jan 2018 22:00:50 GMT"}, {"version": "v3", "created": "Thu, 29 Aug 2019 00:04:48 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Portelance", "Eva", ""], ["Bruno", "Amelia", ""], ["Harasim", "Daniel", ""], ["Bergen", "Leon", ""], ["O'Donnell", "Timothy J.", ""]]}, {"id": "1710.11475", "submitter": "Qiuyuan Huang", "authors": "Qiuyuan Huang, Paul Smolensky, Xiaodong He, Li Deng, Dapeng Wu", "title": "A Neural-Symbolic Approach to Design of CAPTCHA", "comments": "arXiv admin note: substantial text overlap with arXiv:1709.09118", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CAPTCHAs based on reading text are susceptible to machine-learning-based\nattacks due to recent significant advances in deep learning (DL). To address\nthis, this paper promotes image/visual captioning based CAPTCHAs, which is\nrobust against machine-learning-based attacks. To develop\nimage/visual-captioning-based CAPTCHAs, this paper proposes a new image\ncaptioning architecture by exploiting tensor product representations (TPR), a\nstructured neural-symbolic framework developed in cognitive science over the\npast 20 years, with the aim of integrating DL with explicit language structures\nand rules. We call it the Tensor Product Generation Network (TPGN). The key\nideas of TPGN are: 1) unsupervised learning of role-unbinding vectors of words\nvia a TPR-based deep neural network, and 2) integration of TPR with typical DL\narchitectures including Long Short-Term Memory (LSTM) models. The novelty of\nour approach lies in its ability to generate a sentence and extract partial\ngrammatical structure of the sentence by using role-unbinding vectors, which\nare obtained in an unsupervised manner. Experimental results demonstrate the\neffectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 09:18:51 GMT"}, {"version": "v2", "created": "Tue, 25 Sep 2018 21:01:26 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Huang", "Qiuyuan", ""], ["Smolensky", "Paul", ""], ["He", "Xiaodong", ""], ["Deng", "Li", ""], ["Wu", "Dapeng", ""]]}, {"id": "1710.11601", "submitter": "Lea Frermann", "authors": "Lea Frermann and Shay B. Cohen and Mirella Lapata", "title": "Whodunnit? Crime Drama as a Case for Natural Language Understanding", "comments": "To appear in Transactions of the Association for Computational\n  Linguistics (TACL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we argue that crime drama exemplified in television programs\nsuch as CSI:Crime Scene Investigation is an ideal testbed for approximating\nreal-world natural language understanding and the complex inferences associated\nwith it. We propose to treat crime drama as a new inference task, capitalizing\non the fact that each episode poses the same basic question (i.e., who\ncommitted the crime) and naturally provides the answer when the perpetrator is\nrevealed. We develop a new dataset based on CSI episodes, formalize perpetrator\nidentification as a sequence labeling problem, and develop an LSTM-based model\nwhich learns from multi-modal data. Experimental results show that an\nincremental inference strategy is key to making accurate guesses as well as\nlearning from representations fusing textual, visual, and acoustic input.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 17:27:44 GMT"}], "update_date": "2017-11-03", "authors_parsed": [["Frermann", "Lea", ""], ["Cohen", "Shay B.", ""], ["Lapata", "Mirella", ""]]}]