[{"id": "1909.00015", "submitter": "Gon\\c{c}alo M. Correia", "authors": "Gon\\c{c}alo M. Correia, Vlad Niculae, Andr\\'e F.T. Martins", "title": "Adaptively Sparse Transformers", "comments": "Conference on Empirical Methods in Natural Language Processing\n  (EMNLP), 2019, Hong Kong, China", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention mechanisms have become ubiquitous in NLP. Recent architectures,\nnotably the Transformer, learn powerful context-aware word representations\nthrough layered, multi-headed attention. The multiple heads learn diverse types\nof word relationships. However, with standard softmax attention, all attention\nheads are dense, assigning a non-zero weight to all context words. In this\nwork, we introduce the adaptively sparse Transformer, wherein attention heads\nhave flexible, context-dependent sparsity patterns. This sparsity is\naccomplished by replacing softmax with $\\alpha$-entmax: a differentiable\ngeneralization of softmax that allows low-scoring words to receive precisely\nzero weight. Moreover, we derive a method to automatically learn the $\\alpha$\nparameter -- which controls the shape and sparsity of $\\alpha$-entmax --\nallowing attention heads to choose between focused or spread-out behavior. Our\nadaptively sparse Transformer improves interpretability and head diversity when\ncompared to softmax Transformers on machine translation datasets. Findings of\nthe quantitative and qualitative analysis of our approach include that heads in\ndifferent layers learn different sparsity preferences and tend to be more\ndiverse in their attention distributions than softmax Transformers.\nFurthermore, at no cost in accuracy, sparsity in attention heads helps to\nuncover different head specializations.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 18:06:14 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 16:55:20 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Correia", "Gon\u00e7alo M.", ""], ["Niculae", "Vlad", ""], ["Martins", "Andr\u00e9 F. T.", ""]]}, {"id": "1909.00021", "submitter": "Javier Turek", "authors": "Javier S. Turek, Shailee Jain, Vy Vo, Mihai Capota, Alexander G. Huth,\n  Theodore L. Willke", "title": "Approximating Stacked and Bidirectional Recurrent Architectures with the\n  Delayed Recurrent Neural Network", "comments": "to be published in Proceedings of International Conference on Machine\n  Learning 2020 (ICML)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that topological enhancements to recurrent neural\nnetworks (RNNs) can increase their expressiveness and representational\ncapacity. Two popular enhancements are stacked RNNs, which increases the\ncapacity for learning non-linear functions, and bidirectional processing, which\nexploits acausal information in a sequence. In this work, we explore the\ndelayed-RNN, which is a single-layer RNN that has a delay between the input and\noutput. We prove that a weight-constrained version of the delayed-RNN is\nequivalent to a stacked-RNN. We also show that the delay gives rise to partial\nacausality, much like bidirectional networks. Synthetic experiments confirm\nthat the delayed-RNN can mimic bidirectional networks, solving some acausal\ntasks similarly, and outperforming them in others. Moreover, we show similar\nperformance to bidirectional networks in a real-world natural language\nprocessing task. These results suggest that delayed-RNNs can approximate\ntopologies including stacked RNNs, bidirectional RNNs, and stacked\nbidirectional RNNs - but with equivalent or faster runtimes for the\ndelayed-RNNs.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 18:18:04 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 05:45:08 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Turek", "Javier S.", ""], ["Jain", "Shailee", ""], ["Vo", "Vy", ""], ["Capota", "Mihai", ""], ["Huth", "Alexander G.", ""], ["Willke", "Theodore L.", ""]]}, {"id": "1909.00040", "submitter": "Chunting Zhou", "authors": "Chunting Zhou, Xuezhe Ma, Junjie Hu, Graham Neubig", "title": "Handling Syntactic Divergence in Low-resource Machine Translation", "comments": "Accepted by EMNLP 2019 (short paper)", "journal-ref": "EMNLP 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite impressive empirical successes of neural machine translation (NMT) on\nstandard benchmarks, limited parallel data impedes the application of NMT\nmodels to many language pairs. Data augmentation methods such as\nback-translation make it possible to use monolingual data to help alleviate\nthese issues, but back-translation itself fails in extreme low-resource\nscenarios, especially for syntactically divergent languages. In this paper, we\npropose a simple yet effective solution, whereby target-language sentences are\nre-ordered to match the order of the source and used as an additional source of\ntraining-time supervision. Experiments with simulated low-resource\nJapanese-to-English, and real low-resource Uyghur-to-English scenarios find\nsignificant improvements over other semi-supervised alternatives.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 19:07:56 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Zhou", "Chunting", ""], ["Ma", "Xuezhe", ""], ["Hu", "Junjie", ""], ["Neubig", "Graham", ""]]}, {"id": "1909.00080", "submitter": "Avinash Madasu", "authors": "Avinash Madasu and Vijjini Anvesh Rao", "title": "Sequential Learning of Convolutional Features for Effective Text\n  Classification", "comments": "Accepted Long Paper at EMNLP-IJCNLP 2019, Hong Kong, China", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text classification has been one of the major problems in natural language\nprocessing. With the advent of deep learning, convolutional neural network\n(CNN) has been a popular solution to this task. However, CNNs which were first\nproposed for images, face many crucial challenges in the context of text\nprocessing, namely in their elementary blocks: convolution filters and max\npooling. These challenges have largely been overlooked by the most existing CNN\nmodels proposed for text classification. In this paper, we present an\nexperimental study on the fundamental blocks of CNNs in text categorization.\nBased on this critique, we propose Sequential Convolutional Attentive Recurrent\nNetwork (SCARN). The proposed SCARN model utilizes both the advantages of\nrecurrent and convolutional structures efficiently in comparison to previously\nproposed recurrent convolutional models. We test our model on different text\nclassification datasets across tasks like sentiment analysis and question\nclassification. Extensive experiments establish that SCARN outperforms other\nrecurrent convolutional architectures with significantly less parameters.\nFurthermore, SCARN achieves better performance compared to equally large\nvarious deep CNN and LSTM architectures.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 22:10:52 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 20:25:01 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Madasu", "Avinash", ""], ["Rao", "Vijjini Anvesh", ""]]}, {"id": "1909.00088", "submitter": "Steven Y. Feng", "authors": "Steven Y. Feng, Aaron W. Li and Jesse Hoey", "title": "Keep Calm and Switch On! Preserving Sentiment and Fluency in Semantic\n  Text Exchange", "comments": "EMNLP-IJCNLP 2019; Code available at\n  https://github.com/styfeng/SMERTI", "journal-ref": null, "doi": "10.18653/v1/D19-1272", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel method for measurably adjusting the\nsemantics of text while preserving its sentiment and fluency, a task we call\nsemantic text exchange. This is useful for text data augmentation and the\nsemantic correction of text generated by chatbots and virtual assistants. We\nintroduce a pipeline called SMERTI that combines entity replacement, similarity\nmasking, and text infilling. We measure our pipeline's success by its Semantic\nText Exchange Score (STES): the ability to preserve the original text's\nsentiment and fluency while adjusting semantic content. We propose to use\nmasking (replacement) rate threshold as an adjustable parameter to control the\namount of semantic change in the text. Our experiments demonstrate that SMERTI\ncan outperform baseline models on Yelp reviews, Amazon reviews, and news\nheadlines.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 23:10:28 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 07:59:38 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Feng", "Steven Y.", ""], ["Li", "Aaron W.", ""], ["Hoey", "Jesse", ""]]}, {"id": "1909.00091", "submitter": "Serina Chang", "authors": "Serina Chang and Kathleen McKeown", "title": "Automatically Inferring Gender Associations from Language", "comments": null, "journal-ref": "EMNLP 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we pose the question: do people talk about women and men in\ndifferent ways? We introduce two datasets and a novel integration of approaches\nfor automatically inferring gender associations from language, discovering\ncoherent word clusters, and labeling the clusters for the semantic concepts\nthey represent. The datasets allow us to compare how people write about women\nand men in two different settings - one set draws from celebrity news and the\nother from student reviews of computer science professors. We demonstrate that\nthere are large-scale differences in the ways that people talk about women and\nmen and that these differences vary across domains. Human evaluations show that\nour methods significantly outperform strong baselines.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 23:27:06 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Chang", "Serina", ""], ["McKeown", "Kathleen", ""]]}, {"id": "1909.00098", "submitter": "Dongyeop Kang", "authors": "Dongyeop Kang, Varun Gangal, Eduard Hovy", "title": "(Male, Bachelor) and (Female, Ph.D) have different connotations:\n  Parallelly Annotated Stylistic Language Dataset with Multiple Personas", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stylistic variation in text needs to be studied with different aspects\nincluding the writer's personal traits, interpersonal relations, rhetoric, and\nmore. Despite recent attempts on computational modeling of the variation, the\nlack of parallel corpora of style language makes it difficult to systematically\ncontrol the stylistic change as well as evaluate such models. We release\nPASTEL, the parallel and annotated stylistic language dataset, that contains\n~41K parallel sentences (8.3K parallel stories) annotated across different\npersonas. Each persona has different styles in conjunction: gender, age,\ncountry, political view, education, ethnic, and time-of-writing. The dataset is\ncollected from human annotators with solid control of input denotation: not\nonly preserving original meaning between text, but promoting stylistic\ndiversity to annotators. We test the dataset on two interesting applications of\nstyle language, where PASTEL helps design appropriate experiment and\nevaluation. First, in predicting a target style (e.g., male or female in\ngender) given a text, multiple styles of PASTEL make other external style\nvariables controlled (or fixed), which is a more accurate experimental design.\nSecond, a simple supervised model with our parallel text outperforms the\nunsupervised models using nonparallel text in style transfer. Our dataset is\npublicly available.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 00:33:32 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Kang", "Dongyeop", ""], ["Gangal", "Varun", ""], ["Hovy", "Eduard", ""]]}, {"id": "1909.00100", "submitter": "Henry Tsai", "authors": "Henry Tsai, Jason Riesa, Melvin Johnson, Naveen Arivazhagan, Xin Li\n  and Amelia Archer", "title": "Small and Practical BERT Models for Sequence Labeling", "comments": "11 pages including appendices; accepted to appear at EMNLP-IJCNLP\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a practical scheme to train a single multilingual sequence\nlabeling model that yields state of the art results and is small and fast\nenough to run on a single CPU. Starting from a public multilingual BERT\ncheckpoint, our final model is 6x smaller and 27x faster, and has higher\naccuracy than a state-of-the-art multilingual baseline. We show that our model\nespecially outperforms on low-resource languages, and works on codemixed input\ntext without being explicitly trained on codemixed examples. We showcase the\neffectiveness of our method by reporting on part-of-speech tagging and\nmorphological prediction on 70 treebanks and 48 languages.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 00:39:12 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Tsai", "Henry", ""], ["Riesa", "Jason", ""], ["Johnson", "Melvin", ""], ["Arivazhagan", "Naveen", ""], ["Li", "Xin", ""], ["Archer", "Amelia", ""]]}, {"id": "1909.00102", "submitter": "Alexander Hanbo Li", "authors": "Alexander Hanbo Li, Abhinav Sethy", "title": "Knowledge Enhanced Attention for Robust Natural Language Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network models have been very successful at achieving high accuracy on\nnatural language inference (NLI) tasks. However, as demonstrated in recent\nliterature, when tested on some simple adversarial examples, most of the models\nsuffer a significant drop in performance. This raises the concern about the\nrobustness of NLI models. In this paper, we propose to make NLI models robust\nby incorporating external knowledge to the attention mechanism using a simple\ntransformation. We apply the new attention to two popular types of NLI models:\none is Transformer encoder, and the other is a decomposable model, and show\nthat our method can significantly improve their robustness. Moreover, when\ncombined with BERT pretraining, our method achieves the human-level performance\non the adversarial SNLI data set.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 01:04:58 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Li", "Alexander Hanbo", ""], ["Sethy", "Abhinav", ""]]}, {"id": "1909.00105", "submitter": "Bodhisattwa Prasad Majumder", "authors": "Bodhisattwa Prasad Majumder, Shuyang Li, Jianmo Ni, Julian McAuley", "title": "Generating Personalized Recipes from Historical User Preferences", "comments": "Accepted in EMNLP 2019. Data and codes are available at\n  https://github.com/majumderb/recipe-personalization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing approaches to recipe generation are unable to create recipes for\nusers with culinary preferences but incomplete knowledge of ingredients in\nspecific dishes. We propose a new task of personalized recipe generation to\nhelp these users: expanding a name and incomplete ingredient details into\ncomplete natural-text instructions aligned with the user's historical\npreferences. We attend on technique- and recipe-level representations of a\nuser's previously consumed recipes, fusing these 'user-aware' representations\nin an attention fusion layer to control recipe text generation. Experiments on\na new dataset of 180K recipes and 700K interactions show our model's ability to\ngenerate plausible and personalized recipes compared to non-personalized\nbaselines.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 01:50:42 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Majumder", "Bodhisattwa Prasad", ""], ["Li", "Shuyang", ""], ["Ni", "Jianmo", ""], ["McAuley", "Julian", ""]]}, {"id": "1909.00107", "submitter": "Panayiotis Georgiou", "authors": "Prashanth Gurunath Shivakumar, Shao-Yen Tseng, Panayiotis Georgiou,\n  Shrikanth Narayanan", "title": "Behavior Gated Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most current language modeling techniques only exploit co-occurrence,\nsemantic and syntactic information from the sequence of words. However, a range\nof information such as the state of the speaker and dynamics of the interaction\nmight be useful. In this work we derive motivation from psycholinguistics and\npropose the addition of behavioral information into the context of language\nmodeling. We propose the augmentation of language models with an additional\nmodule which analyzes the behavioral state of the current context. This\nbehavioral information is used to gate the outputs of the language model before\nthe final word prediction output. We show that the addition of behavioral\ncontext in language models achieves lower perplexities on behavior-rich\ndatasets. We also confirm the validity of the proposed models on a variety of\nmodel architectures and improve on previous state-of-the-art models with\ngeneric domain Penn Treebank Corpus.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 02:10:32 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Shivakumar", "Prashanth Gurunath", ""], ["Tseng", "Shao-Yen", ""], ["Georgiou", "Panayiotis", ""], ["Narayanan", "Shrikanth", ""]]}, {"id": "1909.00109", "submitter": "Daniel Andor", "authors": "Daniel Andor, Luheng He, Kenton Lee, Emily Pitler", "title": "Giving BERT a Calculator: Finding Operations and Arguments with Reading\n  Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reading comprehension models have been successfully applied to extractive\ntext answers, but it is unclear how best to generalize these models to\nabstractive numerical answers. We enable a BERT-based reading comprehension\nmodel to perform lightweight numerical reasoning. We augment the model with a\npredefined set of executable 'programs' which encompass simple arithmetic as\nwell as extraction. Rather than having to learn to manipulate numbers directly,\nthe model can pick a program and execute it. On the recent Discrete Reasoning\nOver Passages (DROP) dataset, designed to challenge reading comprehension\nmodels, we show a 33% absolute improvement by adding shallow programs. The\nmodel can learn to predict new operations when appropriate in a math word\nproblem setting (Roy and Roth, 2015) with very few training examples.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 02:30:24 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 21:55:23 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Andor", "Daniel", ""], ["He", "Luheng", ""], ["Lee", "Kenton", ""], ["Pitler", "Emily", ""]]}, {"id": "1909.00111", "submitter": "Marten van Schijndel", "authors": "Marten van Schijndel, Aaron Mueller, and Tal Linzen", "title": "Quantity doesn't buy quality syntax with neural language models", "comments": "Accepted for presentation at EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks can learn to predict upcoming words remarkably well\non average; in syntactically complex contexts, however, they often assign\nunexpectedly high probabilities to ungrammatical words. We investigate to what\nextent these shortcomings can be mitigated by increasing the size of the\nnetwork and the corpus on which it is trained. We find that gains from\nincreasing network size are minimal beyond a certain point. Likewise, expanding\nthe training corpus yields diminishing returns; we estimate that the training\ncorpus would need to be unrealistically large for the models to match human\nperformance. A comparison to GPT and BERT, Transformer-based models trained on\nbillions of words, reveals that these models perform even more poorly than our\nLSTMs in some constructions. Our results make the case for more data efficient\narchitectures.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 02:41:49 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["van Schijndel", "Marten", ""], ["Mueller", "Aaron", ""], ["Linzen", "Tal", ""]]}, {"id": "1909.00121", "submitter": "Haoran Chen", "authors": "Haoran Chen, Ke Lin, Alexander Maye, Jianming Li and Xiaolin Hu", "title": "A Semantics-Assisted Video Captioning Model Trained with Scheduled\n  Sampling", "comments": "11 pages", "journal-ref": "Front. Robot. AI 7:475767 (2020)", "doi": "10.3389/frobt.2020.475767", "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the features of a video, recurrent neural networks can be used to\nautomatically generate a caption for the video. Existing methods for video\ncaptioning have at least three limitations. First, semantic information has\nbeen widely applied to boost the performance of video captioning models, but\nexisting networks often fail to provide meaningful semantic features. Second,\nthe Teacher Forcing algorithm is often utilized to optimize video captioning\nmodels, but during training and inference, different strategies are applied to\nguide word generation, leading to poor performance. Third, current video\ncaptioning models are prone to generate relatively short captions that express\nvideo contents inappropriately. Toward resolving these three problems, we\nsuggest three corresponding improvements. First of all, we propose a metric to\ncompare the quality of semantic features, and utilize appropriate features as\ninput for a semantic detection network (SDN) with adequate complexity in order\nto generate meaningful semantic features for videos. Then, we apply a scheduled\nsampling strategy that gradually transfers the training phase from a\nteacher-guided manner toward a more self-teaching manner. Finally, the ordinary\nlogarithm probability loss function is leveraged by sentence length so that the\ninclination of generating short sentences is alleviated. Our model achieves\nbetter results than previous models on the YouTube2Text dataset and is\ncompetitive with the previous best model on the MSR-VTT dataset.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 04:01:38 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2019 16:01:47 GMT"}, {"version": "v3", "created": "Fri, 24 Jul 2020 08:01:29 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Chen", "Haoran", ""], ["Lin", "Ke", ""], ["Maye", "Alexander", ""], ["Li", "Jianming", ""], ["Hu", "Xiaolin", ""]]}, {"id": "1909.00124", "submitter": "Hao Wang", "authors": "Hao Wang, Bing Liu, Chaozhuo Li, Yan Yang, and Tianrui Li", "title": "Learning with Noisy Labels for Sentence-level Sentiment Classification", "comments": "to appear in EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) can fit (or even over-fit) the training data very\nwell. If a DNN model is trained using data with noisy labels and tested on data\nwith clean labels, the model may perform poorly. This paper studies the problem\nof learning with noisy labels for sentence-level sentiment classification. We\npropose a novel DNN model called NetAb (as shorthand for convolutional neural\nNetworks with Ab-networks) to handle noisy labels during training. NetAb\nconsists of two convolutional neural networks, one with a noise transition\nlayer for dealing with the input noisy labels and the other for predicting\n'clean' labels. We train the two networks using their respective loss functions\nin a mutual reinforcement manner. Experimental results demonstrate the\neffectiveness of the proposed model.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 04:18:50 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Wang", "Hao", ""], ["Liu", "Bing", ""], ["Li", "Chaozhuo", ""], ["Yang", "Yan", ""], ["Li", "Tianrui", ""]]}, {"id": "1909.00126", "submitter": "Tao Li", "authors": "Tao Li, Vivek Gupta, Maitrey Mehta, Vivek Srikumar", "title": "A Logic-Driven Framework for Consistency of Neural Models", "comments": "Accepted in EMNLP 2019; Extra footnote after camera ready; Addressing\n  R-fuzzy and S-fuzzy logic + extra acknowledgement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural models show remarkable accuracy on individual predictions, their\ninternal beliefs can be inconsistent across examples. In this paper, we\nformalize such inconsistency as a generalization of prediction error. We\npropose a learning framework for constraining models using logic rules to\nregularize them away from inconsistency. Our framework can leverage both\nlabeled and unlabeled examples and is directly compatible with off-the-shelf\nlearning schemes without model redesign. We instantiate our framework on\nnatural language inference, where experiments show that enforcing invariants\nstated in logic can help make the predictions of neural models both accurate\nand consistent.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 04:38:06 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 01:17:57 GMT"}, {"version": "v3", "created": "Thu, 5 Sep 2019 00:20:14 GMT"}, {"version": "v4", "created": "Fri, 13 Sep 2019 03:52:50 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Li", "Tao", ""], ["Gupta", "Vivek", ""], ["Mehta", "Maitrey", ""], ["Srikumar", "Vivek", ""]]}, {"id": "1909.00131", "submitter": "Prathyusha Jwalapuram", "authors": "Prathyusha Jwalapuram, Shafiq Joty, Irina Temnikova and Preslav Nakov", "title": "Evaluating Pronominal Anaphora in Machine Translation: An Evaluation\n  Measure and a Test Suite", "comments": "Accepted at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ongoing neural revolution in machine translation has made it easier to\nmodel larger contexts beyond the sentence-level, which can potentially help\nresolve some discourse-level ambiguities such as pronominal anaphora, thus\nenabling better translations. Unfortunately, even when the resulting\nimprovements are seen as substantial by humans, they remain virtually unnoticed\nby traditional automatic evaluation measures like BLEU, as only a few words end\nup being affected. Thus, specialized evaluation measures are needed. With this\naim in mind, we contribute an extensive, targeted dataset that can be used as a\ntest suite for pronoun translation, covering multiple source languages and\ndifferent pronoun errors drawn from real system translations, for English. We\nfurther propose an evaluation measure to differentiate good and bad pronoun\ntranslations. We also conduct a user study to report correlations with human\njudgments.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 05:28:51 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Jwalapuram", "Prathyusha", ""], ["Joty", "Shafiq", ""], ["Temnikova", "Irina", ""], ["Nakov", "Preslav", ""]]}, {"id": "1909.00136", "submitter": "Junhui Li", "authors": "Jie Zhu, Junhui Li, Muhua Zhu, Longhua Qian, Min Zhang, Guodong Zhou", "title": "Modeling Graph Structure in Transformer for Better AMR-to-Text\n  Generation", "comments": "Accepted by EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies on AMR-to-text generation often formalize the task as a\nsequence-to-sequence (seq2seq) learning problem by converting an Abstract\nMeaning Representation (AMR) graph into a word sequence. Graph structures are\nfurther modeled into the seq2seq framework in order to utilize the structural\ninformation in the AMR graphs. However, previous approaches only consider the\nrelations between directly connected concepts while ignoring the rich structure\nin AMR graphs. In this paper we eliminate such a strong limitation and propose\na novel structure-aware self-attention approach to better modeling the\nrelations between indirectly connected concepts in the state-of-the-art seq2seq\nmodel, i.e., the Transformer. In particular, a few different methods are\nexplored to learn structural representations between two concepts. Experimental\nresults on English AMR benchmark datasets show that our approach significantly\noutperforms the state of the art with 29.66 and 31.82 BLEU scores on LDC2015E86\nand LDC2017T10, respectively. To the best of our knowledge, these are the best\nresults achieved so far by supervised models on the benchmarks.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 05:45:20 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Zhu", "Jie", ""], ["Li", "Junhui", ""], ["Zhu", "Muhua", ""], ["Qian", "Longhua", ""], ["Zhang", "Min", ""], ["Zhou", "Guodong", ""]]}, {"id": "1909.00137", "submitter": "Mingda Chen", "authors": "Mingda Chen, Zewei Chu, Yang Chen, Karl Stratos, Kevin Gimpel", "title": "EntEval: A Holistic Evaluation Benchmark for Entity Representations", "comments": "EMNLP 2019. Fixed typo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rich entity representations are useful for a wide class of problems involving\nentities. Despite their importance, there is no standardized benchmark that\nevaluates the overall quality of entity representations. In this work, we\npropose EntEval: a test suite of diverse tasks that require nontrivial\nunderstanding of entities including entity typing, entity similarity, entity\nrelation prediction, and entity disambiguation. In addition, we develop\ntraining techniques for learning better entity representations by using natural\nhyperlink annotations in Wikipedia. We identify effective objectives for\nincorporating the contextual information in hyperlinks into state-of-the-art\npretrained language models and show that they improve strong baselines on\nmultiple EntEval tasks.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 06:02:11 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 13:20:16 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Chen", "Mingda", ""], ["Chu", "Zewei", ""], ["Chen", "Yang", ""], ["Stratos", "Karl", ""], ["Gimpel", "Kevin", ""]]}, {"id": "1909.00140", "submitter": "Wenjie Zhou", "authors": "Wenjie Zhou, Minghua Zhang, Yunfang Wu", "title": "Question-type Driven Question Generation", "comments": "Accepted by EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question generation is a challenging task which aims to ask a question based\non an answer and relevant context. The existing works suffer from the\nmismatching between question type and answer, i.e. generating a question with\ntype $how$ while the answer is a personal name. We propose to automatically\npredict the question type based on the input answer and context. Then, the\nquestion type is fused into a seq2seq model to guide the question generation,\nso as to deal with the mismatching problem. We achieve significant improvement\non the accuracy of question type prediction and finally obtain state-of-the-art\nresults for question generation on both SQuAD and MARCO datasets.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 06:11:31 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Zhou", "Wenjie", ""], ["Zhang", "Minghua", ""], ["Wu", "Yunfang", ""]]}, {"id": "1909.00141", "submitter": "Deren Lei", "authors": "Siyao Li, Deren Lei, Pengda Qin, William Yang Wang", "title": "Deep Reinforcement Learning with Distributional Semantic Rewards for\n  Abstractive Summarization", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (RL) has been a commonly-used strategy for the\nabstractive summarization task to address both the exposure bias and\nnon-differentiable task issues. However, the conventional reward Rouge-L simply\nlooks for exact n-grams matches between candidates and annotated references,\nwhich inevitably makes the generated sentences repetitive and incoherent. In\nthis paper, instead of Rouge-L, we explore the practicability of utilizing the\ndistributional semantics to measure the matching degrees. With distributional\nsemantics, sentence-level evaluation can be obtained, and semantically-correct\nphrases can also be generated without being limited to the surface form of the\nreference sentences. Human judgments on Gigaword and CNN/Daily Mail datasets\nshow that our proposed distributional semantics reward (DSR) has distinct\nsuperiority in capturing the lexical and compositional diversity of natural\nlanguage.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 06:13:33 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 23:30:26 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Li", "Siyao", ""], ["Lei", "Deren", ""], ["Qin", "Pengda", ""], ["Wang", "William Yang", ""]]}, {"id": "1909.00142", "submitter": "Mingda Chen", "authors": "Mingda Chen, Zewei Chu, Kevin Gimpel", "title": "Evaluation Benchmarks and Learning Criteria for Discourse-Aware Sentence\n  Representations", "comments": "EMNLP 2019. Updated results and fixed typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior work on pretrained sentence embeddings and benchmarks focus on the\ncapabilities of stand-alone sentences. We propose DiscoEval, a test suite of\ntasks to evaluate whether sentence representations include broader context\ninformation. We also propose a variety of training objectives that makes use of\nnatural annotations from Wikipedia to build sentence encoders capable of\nmodeling discourse. We benchmark sentence encoders pretrained with our proposed\ntraining objectives, as well as other popular pretrained sentence encoders on\nDiscoEval and other sentence evaluation tasks. Empirically, we show that these\ntraining objectives help to encode different aspects of information in document\nstructures. Moreover, BERT and ELMo demonstrate strong performances over\nDiscoEval with individual hidden layers showing different characteristics.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 06:19:42 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 14:16:52 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Chen", "Mingda", ""], ["Chu", "Zewei", ""], ["Gimpel", "Kevin", ""]]}, {"id": "1909.00153", "submitter": "Phillip Keung", "authors": "Phillip Keung, Yichao Lu, Vikas Bhardwaj", "title": "Adversarial Learning with Contextual Embeddings for Zero-resource\n  Cross-lingual Classification and NER", "comments": "In EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual word embeddings (e.g. GPT, BERT, ELMo, etc.) have demonstrated\nstate-of-the-art performance on various NLP tasks. Recent work with the\nmultilingual version of BERT has shown that the model performs very well in\nzero-shot and zero-resource cross-lingual settings, where only labeled English\ndata is used to finetune the model. We improve upon multilingual BERT's\nzero-resource cross-lingual performance via adversarial learning. We report the\nmagnitude of the improvement on the multilingual MLDoc text classification and\nCoNLL 2002/2003 named entity recognition tasks. Furthermore, we show that\nlanguage-adversarial training encourages BERT to align the embeddings of\nEnglish documents and their translations, which may be the cause of the\nobserved performance gains.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 06:59:46 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 06:02:01 GMT"}, {"version": "v3", "created": "Thu, 19 Mar 2020 20:09:25 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Keung", "Phillip", ""], ["Lu", "Yichao", ""], ["Bhardwaj", "Vikas", ""]]}, {"id": "1909.00154", "submitter": "Francisco Pereira", "authors": "Francisco C. Pereira", "title": "Rethinking travel behavior modeling representations through embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the concept of travel behavior embeddings, a method for\nre-representing discrete variables that are typically used in travel demand\nmodeling, such as mode, trip purpose, education level, family type or\noccupation. This re-representation process essentially maps those variables\ninto a latent space called the \\emph{embedding space}. The benefit of this is\nthat such spaces allow for richer nuances than the typical transformations used\nin categorical variables (e.g. dummy encoding, contrasted encoding, principal\ncomponents analysis). While the usage of latent variable representations is not\nnew per se in travel demand modeling, the idea presented here brings several\ninnovations: it is an entirely data driven algorithm; it is informative and\nconsistent, since the latent space can be visualized and interpreted based on\ndistances between different categories; it preserves interpretability of\ncoefficients, despite being based on Neural Network principles; and it is\ntransferrable, in that embeddings learned from one dataset can be reused for\nother ones, as long as travel behavior keeps consistent between the datasets.\n  The idea is strongly inspired on natural language processing techniques,\nnamely the word2vec algorithm. Such algorithm is behind recent developments\nsuch as in automatic translation or next word prediction. Our method is\ndemonstrated using a model choice model, and shows improvements of up to 60\\%\nwith respect to initial likelihood, and up to 20% with respect to likelihood of\nthe corresponding traditional model (i.e. using dummy variables) in\nout-of-sample evaluation. We provide a new Python package, called PyTre (PYthon\nTRavel Embeddings), that others can straightforwardly use to replicate our\nresults or improve their own models. Our experiments are themselves based on an\nopen dataset (swissmetro).\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 07:05:43 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Pereira", "Francisco C.", ""]]}, {"id": "1909.00156", "submitter": "Junnan Zhu", "authors": "Junnan Zhu, Qian Wang, Yining Wang, Yu Zhou, Jiajun Zhang, Shaonan\n  Wang, Chengqing Zong", "title": "NCLS: Neural Cross-Lingual Summarization", "comments": "Accepted to EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual summarization (CLS) is the task to produce a summary in one\nparticular language for a source document in a different language. Existing\nmethods simply divide this task into two steps: summarization and translation,\nleading to the problem of error propagation. To handle that, we present an\nend-to-end CLS framework, which we refer to as Neural Cross-Lingual\nSummarization (NCLS), for the first time. Moreover, we propose to further\nimprove NCLS by incorporating two related tasks, monolingual summarization and\nmachine translation, into the training process of CLS under multi-task\nlearning. Due to the lack of supervised CLS data, we propose a round-trip\ntranslation strategy to acquire two high-quality large-scale CLS datasets based\non existing monolingual summarization datasets. Experimental results have shown\nthat our NCLS achieves remarkable improvement over traditional pipeline methods\non both English-to-Chinese and Chinese-to-English CLS human-corrected test\nsets. In addition, NCLS with multi-task learning can further significantly\nimprove the quality of generated summaries. We make our dataset and code\npublicly available here: http://www.nlpr.ia.ac.cn/cip/dataset.htm.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 07:24:48 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Zhu", "Junnan", ""], ["Wang", "Qian", ""], ["Wang", "Yining", ""], ["Zhou", "Yu", ""], ["Zhang", "Jiajun", ""], ["Wang", "Shaonan", ""], ["Zong", "Chengqing", ""]]}, {"id": "1909.00157", "submitter": "Shuo Wang", "authors": "Shuo Wang, Yang Liu, Chao Wang, Huanbo Luan and Maosong Sun", "title": "Improving Back-Translation with Uncertainty-based Confidence Estimation", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While back-translation is simple and effective in exploiting abundant\nmonolingual corpora to improve low-resource neural machine translation (NMT),\nthe synthetic bilingual corpora generated by NMT models trained on limited\nauthentic bilingual data are inevitably noisy. In this work, we propose to\nquantify the confidence of NMT model predictions based on model uncertainty.\nWith word- and sentence-level confidence measures based on uncertainty, it is\npossible for back-translation to better cope with noise in synthetic bilingual\ncorpora. Experiments on Chinese-English and English-German translation tasks\nshow that uncertainty-based confidence estimation significantly improves the\nperformance of back-translation.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 07:35:36 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Wang", "Shuo", ""], ["Liu", "Yang", ""], ["Wang", "Chao", ""], ["Luan", "Huanbo", ""], ["Sun", "Maosong", ""]]}, {"id": "1909.00160", "submitter": "Soumya Sharma", "authors": "Soumya Sharma, Bishal Santra, Abhik Jana, T.Y.S.S. Santosh, Niloy\n  Ganguly and Pawan Goyal", "title": "Incorporating Domain Knowledge into Medical NLI using Knowledge Graphs", "comments": "EMNLP 2019 accepted short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, biomedical version of embeddings obtained from language models such\nas BioELMo have shown state-of-the-art results for the textual inference task\nin the medical domain. In this paper, we explore how to incorporate structured\ndomain knowledge, available in the form of a knowledge graph (UMLS), for the\nMedical NLI task. Specifically, we experiment with fusing embeddings obtained\nfrom knowledge graph with the state-of-the-art approaches for NLI task (ESIM\nmodel). We also experiment with fusing the domain-specific sentiment\ninformation for the task. Experiments conducted on MedNLI dataset clearly show\nthat this strategy improves the baseline BioELMo architecture for the Medical\nNLI task.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 07:41:42 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Sharma", "Soumya", ""], ["Santra", "Bishal", ""], ["Jana", "Abhik", ""], ["Santosh", "T. Y. S. S.", ""], ["Ganguly", "Niloy", ""], ["Goyal", "Pawan", ""]]}, {"id": "1909.00161", "submitter": "Wenpeng Yin", "authors": "Wenpeng Yin, Jamaal Hay, Dan Roth", "title": "Benchmarking Zero-shot Text Classification: Datasets, Evaluation and\n  Entailment Approach", "comments": "EMNLP2019 camera-ready, 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-shot text classification (0Shot-TC) is a challenging NLU problem to\nwhich little attention has been paid by the research community. 0Shot-TC aims\nto associate an appropriate label with a piece of text, irrespective of the\ntext domain and the aspect (e.g., topic, emotion, event, etc.) described by the\nlabel. And there are only a few articles studying 0Shot-TC, all focusing only\non topical categorization which, we argue, is just the tip of the iceberg in\n0Shot-TC. In addition, the chaotic experiments in literature make no uniform\ncomparison, which blurs the progress.\n  This work benchmarks the 0Shot-TC problem by providing unified datasets,\nstandardized evaluations, and state-of-the-art baselines. Our contributions\ninclude: i) The datasets we provide facilitate studying 0Shot-TC relative to\nconceptually different and diverse aspects: the ``topic'' aspect includes\n``sports'' and ``politics'' as labels; the ``emotion'' aspect includes ``joy''\nand ``anger''; the ``situation'' aspect includes ``medical assistance'' and\n``water shortage''. ii) We extend the existing evaluation setup\n(label-partially-unseen) -- given a dataset, train on some labels, test on all\nlabels -- to include a more challenging yet realistic evaluation\nlabel-fully-unseen 0Shot-TC (Chang et al., 2008), aiming at classifying text\nsnippets without seeing task specific training data at all. iii) We unify the\n0Shot-TC of diverse aspects within a textual entailment formulation and study\nit this way.\n  Code & Data: https://github.com/yinwenpeng/BenchmarkingZeroShot\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 07:42:11 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Yin", "Wenpeng", ""], ["Hay", "Jamaal", ""], ["Roth", "Dan", ""]]}, {"id": "1909.00164", "submitter": "Ying Luo", "authors": "Ying Luo, Hai Zhao, Junlang Zhan", "title": "Named Entity Recognition Only from Word Embeddings", "comments": "Accepted by EMNLP2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network models have helped named entity (NE) recognition achieve\namazing performance without handcrafting features. However, existing systems\nrequire large amounts of human annotated training data. Efforts have been made\nto replace human annotations with external knowledge (e.g., NE dictionary,\npart-of-speech tags), while it is another challenge to obtain such effective\nresources. In this work, we propose a fully unsupervised NE recognition model\nwhich only needs to take informative clues from pre-trained word embeddings. We\nfirst apply Gaussian Hidden Markov Model and Deep Autoencoding Gaussian Mixture\nModel on word embeddings for entity span detection and type prediction, and\nthen further design an instance selector based on reinforcement learning to\ndistinguish positive sentences from noisy sentences and refine these\ncoarse-grained annotations through neural networks. Extensive experiments on\nCoNLL benchmark datasets demonstrate that our proposed light NE recognition\nmodel achieves remarkable performance without using any annotated lexicon or\ncorpus.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 08:22:13 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 15:22:32 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Luo", "Ying", ""], ["Zhao", "Hai", ""], ["Zhan", "Junlang", ""]]}, {"id": "1909.00170", "submitter": "Zhuosheng Zhang", "authors": "Ying Luo, Hai Zhao, Zhuosheng Zhang, Bingjie Tang", "title": "Open Named Entity Modeling from Embedding Distribution", "comments": "The early version accepted by IEEE Transactions on Knowledge and Data\n  Engineering (TKDE)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we report our discovery on named entity distribution in a\ngeneral word embedding space, which helps an open definition on multilingual\nnamed entity definition rather than previous closed and constraint definition\non named entities through a named entity dictionary, which is usually derived\nfrom human labor and replies on schedule update. Our initial visualization of\nmonolingual word embeddings indicates named entities tend to gather together\ndespite of named entity types and language difference, which enable us to model\nall named entities using a specific geometric structure inside embedding space,\nnamely, the named entity hypersphere. For monolingual cases, the proposed named\nentity model gives an open description of diverse named entity types and\ndifferent languages. For cross-lingual cases, mapping the proposed named entity\nmodel provides a novel way to build a named entity dataset for resource-poor\nlanguages. At last, the proposed named entity model may be shown as a handy\nclue to enhance state-of-the-art named entity recognition systems generally.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 08:56:46 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 15:01:25 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Luo", "Ying", ""], ["Zhao", "Hai", ""], ["Zhang", "Zhuosheng", ""], ["Tang", "Bingjie", ""]]}, {"id": "1909.00175", "submitter": "Yanyan Zou", "authors": "Yanyan Zou, Wei Lu", "title": "Joint Detection and Location of English Puns", "comments": "Accepted by NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A pun is a form of wordplay for an intended humorous or rhetorical effect,\nwhere a word suggests two or more meanings by exploiting polysemy (homographic\npun) or phonological similarity to another word (heterographic pun). This paper\npresents an approach that addresses pun detection and pun location jointly from\na sequence labeling perspective. We employ a new tagging scheme such that the\nmodel is capable of performing such a joint task, where useful structural\ninformation can be properly captured. We show that our proposed model is\neffective in handling both homographic and heterographic puns. Empirical\nresults on the benchmark datasets demonstrate that our approach can achieve new\nstate-of-the-art results.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 09:31:36 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Zou", "Yanyan", ""], ["Lu", "Wei", ""]]}, {"id": "1909.00176", "submitter": "Yanyan Zou", "authors": "Yanyan Zou, Wei Lu", "title": "Quantity Tagger: A Latent-Variable Sequence Labeling Approach to Solving\n  Addition-Subtraction Word Problems", "comments": "Accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  An arithmetic word problem typically includes a textual description\ncontaining several constant quantities. The key to solving the problem is to\nreveal the underlying mathematical relations (such as addition and subtraction)\namong quantities, and then generate equations to find solutions. This work\npresents a novel approach, Quantity Tagger, that automatically discovers such\nhidden relations by tagging each quantity with a sign corresponding to one type\nof mathematical operation. For each quantity, we assume there exists a latent,\nvariable-sized quantity span surrounding the quantity token in the text, which\nconveys information useful for determining its sign. Empirical results show\nthat our method achieves 5 and 8 points of accuracy gains on two datasets\nrespectively, compared to prior approaches.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 09:33:04 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Zou", "Yanyan", ""], ["Lu", "Wei", ""]]}, {"id": "1909.00180", "submitter": "Shuo Ren", "authors": "Shuo Ren, Yu Wu, Shujie Liu, Ming Zhou, Shuai Ma", "title": "Explicit Cross-lingual Pre-training for Unsupervised Machine Translation", "comments": "Accepted to EMNLP2019; 10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-training has proven to be effective in unsupervised machine translation\ndue to its ability to model deep context information in cross-lingual\nscenarios. However, the cross-lingual information obtained from shared BPE\nspaces is inexplicit and limited. In this paper, we propose a novel\ncross-lingual pre-training method for unsupervised machine translation by\nincorporating explicit cross-lingual training signals. Specifically, we first\ncalculate cross-lingual n-gram embeddings and infer an n-gram translation table\nfrom them. With those n-gram translation pairs, we propose a new pre-training\nmodel called Cross-lingual Masked Language Model (CMLM), which randomly chooses\nsource n-grams in the input text stream and predicts their translation\ncandidates at each time step. Experiments show that our method can incorporate\nbeneficial cross-lingual information into pre-trained models. Taking\npre-trained CMLM models as the encoder and decoder, we significantly improve\nthe performance of unsupervised machine translation.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 09:58:57 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Ren", "Shuo", ""], ["Wu", "Yu", ""], ["Liu", "Shujie", ""], ["Zhou", "Ming", ""], ["Ma", "Shuai", ""]]}, {"id": "1909.00183", "submitter": "Muhammed Tarik Altuncu", "authors": "M. Tarik Altuncu, Eloise Sorin, Joshua D. Symons, Erik Mayer, Sophia\n  N. Yaliraki, Francesca Toni, Mauricio Barahona", "title": "Extracting information from free text through unsupervised graph-based\n  clustering: an application to patient incident records", "comments": "To appear as a book chapter", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR math.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The large volume of text in electronic healthcare records often remains\nunderused due to a lack of methodologies to extract interpretable content. Here\nwe present an unsupervised framework for the analysis of free text that\ncombines text-embedding with paragraph vectors and graph-theoretical multiscale\ncommunity detection. We analyse text from a corpus of patient incident reports\nfrom the National Health Service in England to find content-based clusters of\nreports in an unsupervised manner and at different levels of resolution. Our\nunsupervised method extracts groups with high intrinsic textual consistency and\ncompares well against categories hand-coded by healthcare personnel. We also\nshow how to use our content-driven clusters to improve the supervised\nprediction of the degree of harm of the incident based on the text of the\nreport. Finally, we discuss future directions to monitor reports over time, and\nto detect emerging trends outside pre-existing categories.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 10:03:11 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Altuncu", "M. Tarik", ""], ["Sorin", "Eloise", ""], ["Symons", "Joshua D.", ""], ["Mayer", "Erik", ""], ["Yaliraki", "Sophia N.", ""], ["Toni", "Francesca", ""], ["Barahona", "Mauricio", ""]]}, {"id": "1909.00187", "submitter": "Shivashankar Subramanian", "authors": "Shivashankar Subramanian and Trevor Cohn and Timothy Baldwin", "title": "Deep Ordinal Regression for Pledge Specificity Prediction", "comments": "Camera ready --- EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many pledges are made in the course of an election campaign, forming\nimportant corpora for political analysis of campaign strategy and governmental\naccountability. At present, there are no publicly available annotated datasets\nof pledges, and most political analyses rely on manual analysis. In this paper\nwe collate a novel dataset of manifestos from eleven Australian federal\nelection cycles, with over 12,000 sentences annotated with specificity (e.g.,\nrhetorical vs.\\ detailed pledge) on a fine-grained scale. We propose deep\nordinal regression approaches for specificity prediction, under both supervised\nand semi-supervised settings, and provide empirical results demonstrating the\neffectiveness of the proposed techniques over several baseline approaches. We\nanalyze the utility of pledge specificity modeling across a spectrum of policy\nissues in performing ideology prediction, and further provide qualitative\nanalysis in terms of capturing party-specific issue salience across election\ncycles.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 10:38:56 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Subramanian", "Shivashankar", ""], ["Cohn", "Trevor", ""], ["Baldwin", "Timothy", ""]]}, {"id": "1909.00188", "submitter": "Shuhao Gu", "authors": "Shuhao Gu and Yang Feng", "title": "Improving Multi-Head Attention with Capsule Networks", "comments": "accepted by NLPCC2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-head attention advances neural machine translation by working out\nmultiple versions of attention in different subspaces, but the neglect of\nsemantic overlapping between subspaces increases the difficulty of translation\nand consequently hinders the further improvement of translation performance. In\nthis paper, we employ capsule networks to comb the information from the\nmultiple heads of the attention so that similar information can be clustered\nand unique information can be reserved. To this end, we adopt two routing\nmechanisms of Dynamic Routing and EM Routing, to fulfill the clustering and\nseparating. We conducted experiments on Chinese-to-English and\nEnglish-to-German translation tasks and got consistent improvements over the\nstrong Transformer baseline.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 10:43:06 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Gu", "Shuhao", ""], ["Feng", "Yang", ""]]}, {"id": "1909.00204", "submitter": "Junqiu Wei", "authors": "Junqiu Wei, Xiaozhe Ren, Xiaoguang Li, Wenyong Huang, Yi Liao, Yasheng\n  Wang, Jiashu Lin, Xin Jiang, Xiao Chen, Qun Liu", "title": "NEZHA: Neural Contextualized Representation for Chinese Language\n  Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pre-trained language models have achieved great successes in various\nnatural language understanding (NLU) tasks due to its capacity to capture the\ndeep contextualized information in text by pre-training on large-scale corpora.\nIn this technical report, we present our practice of pre-training language\nmodels named NEZHA (NEural contextualiZed representation for CHinese lAnguage\nunderstanding) on Chinese corpora and finetuning for the Chinese NLU tasks. The\ncurrent version of NEZHA is based on BERT with a collection of proven\nimprovements, which include Functional Relative Positional Encoding as an\neffective positional encoding scheme, Whole Word Masking strategy, Mixed\nPrecision Training and the LAMB Optimizer in training the models. The\nexperimental results show that NEZHA achieves the state-of-the-art performances\nwhen finetuned on several representative Chinese tasks, including named entity\nrecognition (People's Daily NER), sentence matching (LCQMC), Chinese sentiment\nclassification (ChnSenti) and natural language inference (XNLI).\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 12:08:53 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 08:52:55 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Wei", "Junqiu", ""], ["Ren", "Xiaozhe", ""], ["Li", "Xiaoguang", ""], ["Huang", "Wenyong", ""], ["Liao", "Yi", ""], ["Wang", "Yasheng", ""], ["Lin", "Jiashu", ""], ["Jiang", "Xin", ""], ["Chen", "Xiao", ""], ["Liu", "Qun", ""]]}, {"id": "1909.00215", "submitter": "Yi-Ting Yeh", "authors": "Yi-Ting Yeh, Yun-Nung Chen", "title": "QAInfomax: Learning Robust Question Answering System by Mutual\n  Information Maximization", "comments": "EMNLP 2019 short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard accuracy metrics indicate that modern reading comprehension systems\nhave achieved strong performance in many question answering datasets. However,\nthe extent these systems truly understand language remains unknown, and\nexisting systems are not good at distinguishing distractor sentences, which\nlook related but do not actually answer the question. To address this problem,\nwe propose QAInfomax as a regularizer in reading comprehension systems by\nmaximizing mutual information among passages, a question, and its answer.\nQAInfomax helps regularize the model to not simply learn the superficial\ncorrelation for answering questions. The experiments show that our proposed\nQAInfomax achieves the state-of-the-art performance on the benchmark\nAdversarial-SQuAD dataset.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 13:50:28 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Yeh", "Yi-Ting", ""], ["Chen", "Yun-Nung", ""]]}, {"id": "1909.00228", "submitter": "Fenia Christopoulou", "authors": "Fenia Christopoulou, Makoto Miwa, Sophia Ananiadou", "title": "Connecting the Dots: Document-level Neural Relation Extraction with\n  Edge-oriented Graphs", "comments": "12 pages, 5 figures, 6 tables. Accepted in EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document-level relation extraction is a complex human process that requires\nlogical inference to extract relationships between named entities in text.\nExisting approaches use graph-based neural models with words as nodes and edges\nas relations between them, to encode relations across sentences. These models\nare node-based, i.e., they form pair representations based solely on the two\ntarget node representations. However, entity relations can be better expressed\nthrough unique edge representations formed as paths between nodes. We thus\npropose an edge-oriented graph neural model for document-level relation\nextraction. The model utilises different types of nodes and edges to create a\ndocument-level graph. An inference mechanism on the graph edges enables to\nlearn intra- and inter-sentence relations using multi-instance learning\ninternally. Experiments on two document-level biomedical datasets for\nchemical-disease and gene-disease associations show the usefulness of the\nproposed edge-oriented approach.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 15:14:01 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Christopoulou", "Fenia", ""], ["Miwa", "Makoto", ""], ["Ananiadou", "Sophia", ""]]}, {"id": "1909.00230", "submitter": "Cong Fu", "authors": "Cong Fu, Tong Chen, Meng Qu, Woojeong Jin, Xiang Ren", "title": "Collaborative Policy Learning for Open Knowledge Graph Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there has been a surge of interests in interpretable graph\nreasoning methods. However, these models often suffer from limited performance\nwhen working on sparse and incomplete graphs, due to the lack of evidential\npaths that can reach target entities. Here we study open knowledge graph\nreasoning---a task that aims to reason for missing facts over a graph augmented\nby a background text corpus. A key challenge of the task is to filter out\n\"irrelevant\" facts extracted from corpus, in order to maintain an effective\nsearch space during path inference. We propose a novel reinforcement learning\nframework to train two collaborative agents jointly, i.e., a multi-hop graph\nreasoner and a fact extractor. The fact extraction agent generates fact triples\nfrom corpora to enrich the graph on the fly; while the reasoning agent provides\nfeedback to the fact extractor and guides it towards promoting facts that are\nhelpful for the interpretable reasoning. Experiments on two public datasets\ndemonstrate the effectiveness of the proposed approach. Source code and\ndatasets used in this paper can be downloaded at\nhttps://github.com/shanzhenren/CPL\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 15:46:05 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Fu", "Cong", ""], ["Chen", "Tong", ""], ["Qu", "Meng", ""], ["Jin", "Woojeong", ""], ["Ren", "Xiang", ""]]}, {"id": "1909.00252", "submitter": "Orion Weller", "authors": "Orion Weller and Kevin Seppi", "title": "Humor Detection: A Transformer Gets the Last Laugh", "comments": "Accepted to EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much previous work has been done in attempting to identify humor in text. In\nthis paper we extend that capability by proposing a new task: assessing whether\nor not a joke is humorous. We present a novel way of approaching this problem\nby building a model that learns to identify humorous jokes based on ratings\ngleaned from Reddit pages, consisting of almost 16,000 labeled instances. Using\nthese ratings to determine the level of humor, we then employ a Transformer\narchitecture for its advantages in learning from sentence context. We\ndemonstrate the effectiveness of this approach and show results that are\ncomparable to human performance. We further demonstrate our model's increased\ncapabilities on humor identification problems, such as the previously created\ndatasets for short jokes and puns. These experiments show that this method\noutperforms all previous work done on these tasks, with an F-measure of 93.1%\nfor the Puns dataset and 98.6% on the Short Jokes dataset.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 18:01:29 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Weller", "Orion", ""], ["Seppi", "Kevin", ""]]}, {"id": "1909.00277", "submitter": "Lifu Huang", "authors": "Lifu Huang, Ronan Le Bras, Chandra Bhagavatula, Yejin Choi", "title": "Cosmos QA: Machine Reading Comprehension with Contextual Commonsense\n  Reasoning", "comments": "EMNLP'2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding narratives requires reading between the lines, which in turn,\nrequires interpreting the likely causes and effects of events, even when they\nare not mentioned explicitly. In this paper, we introduce Cosmos QA, a\nlarge-scale dataset of 35,600 problems that require commonsense-based reading\ncomprehension, formulated as multiple-choice questions. In stark contrast to\nmost existing reading comprehension datasets where the questions focus on\nfactual and literal understanding of the context paragraph, our dataset focuses\non reading between the lines over a diverse collection of people's everyday\nnarratives, asking such questions as \"what might be the possible reason of\n...?\", or \"what would have happened if ...\" that require reasoning beyond the\nexact text spans in the context. To establish baseline performances on Cosmos\nQA, we experiment with several state-of-the-art neural architectures for\nreading comprehension, and also propose a new architecture that improves over\nthe competitive baselines. Experimental results demonstrate a significant gap\nbetween machine (68.4%) and human performance (94%), pointing to avenues for\nfuture research on commonsense machine comprehension. Dataset, code and\nleaderboard is publicly available at https://wilburone.github.io/cosmos.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 19:55:44 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 21:16:16 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Huang", "Lifu", ""], ["Bras", "Ronan Le", ""], ["Bhagavatula", "Chandra", ""], ["Choi", "Yejin", ""]]}, {"id": "1909.00279", "submitter": "Zhichao Yang", "authors": "Zhichao Yang, Pengshan Cai, Yansong Feng, Fei Li, Weijiang Feng, Elena\n  Suet-Ying Chiu, Hong Yu", "title": "Generating Classical Chinese Poems from Vernacular Chinese", "comments": "Published in EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Classical Chinese poetry is a jewel in the treasure house of Chinese culture.\nPrevious poem generation models only allow users to employ keywords to\ninterfere the meaning of generated poems, leaving the dominion of generation to\nthe model. In this paper, we propose a novel task of generating classical\nChinese poems from vernacular, which allows users to have more control over the\nsemantic of generated poems. We adapt the approach of unsupervised machine\ntranslation (UMT) to our task. We use segmentation-based padding and\nreinforcement learning to address under-translation and over-translation\nrespectively. According to experiments, our approach significantly improve the\nperplexity and BLEU compared with typical UMT models. Furthermore, we explored\nguidelines on how to write the input vernacular to generate better poems. Human\nevaluation showed our approach can generate high-quality poems which are\ncomparable to amateur poems.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 20:07:25 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Yang", "Zhichao", ""], ["Cai", "Pengshan", ""], ["Feng", "Yansong", ""], ["Li", "Fei", ""], ["Feng", "Weijiang", ""], ["Chiu", "Elena Suet-Ying", ""], ["Yu", "Hong", ""]]}, {"id": "1909.00301", "submitter": "Jiacheng Liu", "authors": "Jiacheng Liu, Julia Hockenmaier", "title": "Phrase Grounding by Soft-Label Chain Conditional Random Field", "comments": "11 pages, 5 figures, accepted by EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The phrase grounding task aims to ground each entity mention in a given\ncaption of an image to a corresponding region in that image. Although there are\nclear dependencies between how different mentions of the same caption should be\ngrounded, previous structured prediction methods that aim to capture such\ndependencies need to resort to approximate inference or non-differentiable\nlosses. In this paper, we formulate phrase grounding as a sequence labeling\ntask where we treat candidate regions as potential labels, and use neural chain\nConditional Random Fields (CRFs) to model dependencies among regions for\nadjacent mentions. In contrast to standard sequence labeling tasks, the phrase\ngrounding task is defined such that there may be multiple correct candidate\nregions. To address this multiplicity of gold labels, we define so-called\nSoft-Label Chain CRFs, and present an algorithm that enables convenient\nend-to-end training. Our method establishes a new state-of-the-art on phrase\ngrounding on the Flickr30k Entities dataset. Analysis shows that our model\nbenefits both from the entity dependencies captured by the CRF and from the\nsoft-label training regime. Our code is available at\n\\url{github.com/liujch1998/SoftLabelCCRF}\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 01:57:45 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Liu", "Jiacheng", ""], ["Hockenmaier", "Julia", ""]]}, {"id": "1909.00303", "submitter": "Mostafa Abdou", "authors": "Mostafa Abdou, Artur Kulmizev, Felix Hill, Daniel M. Low, Anders\n  S{\\o}gaard", "title": "Higher-order Comparisons of Sentence Encoder Representations", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representational Similarity Analysis (RSA) is a technique developed by\nneuroscientists for comparing activity patterns of different measurement\nmodalities (e.g., fMRI, electrophysiology, behavior). As a framework, RSA has\nseveral advantages over existing approaches to interpretation of language\nencoders based on probing or diagnostic classification: namely, it does not\nrequire large training samples, is not prone to overfitting, and it enables a\nmore transparent comparison between the representational geometries of\ndifferent models and modalities. We demonstrate the utility of RSA by\nestablishing a previously unknown correspondence between widely-employed\npretrained language encoders and human processing difficulty via eye-tracking\ndata, showcasing its potential in the interpretability toolbox for neural\nmodels\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 02:13:12 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 11:12:56 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Abdou", "Mostafa", ""], ["Kulmizev", "Artur", ""], ["Hill", "Felix", ""], ["Low", "Daniel M.", ""], ["S\u00f8gaard", "Anders", ""]]}, {"id": "1909.00310", "submitter": "Zuchao Li", "authors": "Shexia He, Zuchao Li, Hai Zhao", "title": "Syntax-aware Multilingual Semantic Role Labeling", "comments": "Shexia He and Zuchao Li made equal contribution to this paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, semantic role labeling (SRL) has earned a series of success with\neven higher performance improvements, which can be mainly attributed to\nsyntactic integration and enhanced word representation. However, most of these\nefforts focus on English, while SRL on multiple languages more than English has\nreceived relatively little attention so that is kept underdevelopment. Thus\nthis paper intends to fill the gap on multilingual SRL with special focus on\nthe impact of syntax and contextualized word representation. Unlike existing\nwork, we propose a novel method guided by syntactic rule to prune arguments,\nwhich enables us to integrate syntax into multilingual SRL model simply and\neffectively. We present a unified SRL model designed for multiple languages\ntogether with the proposed uniform syntax enhancement. Our model achieves new\nstate-of-the-art results on the CoNLL-2009 benchmarks of all seven languages.\nBesides, we pose a discussion on the syntactic role among different languages\nand verify the effectiveness of deep enhanced representation for multilingual\nSRL.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 02:48:43 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 04:12:58 GMT"}, {"version": "v3", "created": "Tue, 10 Sep 2019 00:29:37 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["He", "Shexia", ""], ["Li", "Zuchao", ""], ["Zhao", "Hai", ""]]}, {"id": "1909.00324", "submitter": "Yunlong Liang", "authors": "Yunlong Liang, Fandong Meng, Jinchao Zhang, Jinan Xu, Yufeng Chen and\n  Jie Zhou", "title": "A Novel Aspect-Guided Deep Transition Model for Aspect Based Sentiment\n  Analysis", "comments": "Accepted at EMNLP 2019 as a long paper. Code is available at\n  https://github.com/XL2248/AGDT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect based sentiment analysis (ABSA) aims to identify the sentiment\npolarity towards the given aspect in a sentence, while previous models\ntypically exploit an aspect-independent (weakly associative) encoder for\nsentence representation generation. In this paper, we propose a novel\nAspect-Guided Deep Transition model, named AGDT, which utilizes the given\naspect to guide the sentence encoding from scratch with the specially-designed\ndeep transition architecture. Furthermore, an aspect-oriented objective is\ndesigned to enforce AGDT to reconstruct the given aspect with the generated\nsentence representation. In doing so, our AGDT can accurately generate\naspect-specific sentence representation, and thus conduct more accurate\nsentiment predictions. Experimental results on multiple SemEval datasets\ndemonstrate the effectiveness of our proposed approach, which significantly\noutperforms the best reported results with the same setting.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 05:22:30 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Liang", "Yunlong", ""], ["Meng", "Fandong", ""], ["Zhang", "Jinchao", ""], ["Xu", "Jinan", ""], ["Chen", "Yufeng", ""], ["Zhou", "Jie", ""]]}, {"id": "1909.00325", "submitter": "Luke De Oliveira", "authors": "Luke de Oliveira, Alfredo L\\'ainez Rodrigo", "title": "Repurposing Decoder-Transformer Language Models for Abstractive\n  Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network models have shown excellent fluency and performance when\napplied to abstractive summarization. Many approaches to neural abstractive\nsummarization involve the introduction of significant inductive bias,\nexemplified through the use of components such as pointer-generator\narchitectures, coverage, and partially extractive procedures, designed to mimic\nthe process by which humans summarize documents. We show that it is possible to\nattain competitive performance by instead directly viewing summarization as a\nlanguage modeling problem and effectively leveraging transfer learning. We\nintroduce a simple procedure built upon decoder-transformers to obtain highly\ncompetitive ROUGE scores for summarization performance using a language\nmodeling loss alone, with no beam-search or other decoding-time optimization,\nand instead relying on efficient nucleus sampling and greedy decoding.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 05:26:30 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["de Oliveira", "Luke", ""], ["Rodrigo", "Alfredo L\u00e1inez", ""]]}, {"id": "1909.00326", "submitter": "Shilin He", "authors": "Shilin He, Zhaopeng Tu, Xing Wang, Longyue Wang, Michael R. Lyu,\n  Shuming Shi", "title": "Towards Understanding Neural Machine Translation with Word Importance", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although neural machine translation (NMT) has advanced the state-of-the-art\non various language pairs, the interpretability of NMT remains unsatisfactory.\nIn this work, we propose to address this gap by focusing on understanding the\ninput-output behavior of NMT models. Specifically, we measure the word\nimportance by attributing the NMT output to every input word through a\ngradient-based method. We validate the approach on a couple of perturbation\noperations, language pairs, and model architectures, demonstrating its\nsuperiority on identifying input words with higher influence on translation\nperformance. Encouragingly, the calculated importance can serve as indicators\nof input words that are under-translated by NMT models. Furthermore, our\nanalysis reveals that words of certain syntactic categories have higher\nimportance while the categories vary across language pairs, which can inspire\nbetter design principles of NMT architectures for multi-lingual translation.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 06:04:48 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 11:57:20 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["He", "Shilin", ""], ["Tu", "Zhaopeng", ""], ["Wang", "Xing", ""], ["Wang", "Longyue", ""], ["Lyu", "Michael R.", ""], ["Shi", "Shuming", ""]]}, {"id": "1909.00333", "submitter": "Hangfeng He", "authors": "Hangfeng He, Qiang Ning, Dan Roth", "title": "QuASE: Question-Answer Driven Sentence Encoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question-answering (QA) data often encodes essential information in many\nfacets. This paper studies a natural question: Can we get supervision from QA\ndata for other tasks (typically, non-QA ones)? For example, {\\em can we use\nQAMR (Michael et al., 2017) to improve named entity recognition?} We suggest\nthat simply further pre-training BERT is often not the best option, and propose\nthe {\\em question-answer driven sentence encoding (QuASE)} framework. QuASE\nlearns representations from QA data, using BERT or other state-of-the-art\ncontextual language models. In particular, we observe the need to distinguish\nbetween two types of sentence encodings, depending on whether the target task\nis a single- or multi-sentence input; in both cases, the resulting encoding is\nshown to be an easy-to-use plugin for many downstream tasks. This work may\npoint out an alternative way to supervise NLP tasks.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 06:30:57 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 15:40:12 GMT"}, {"version": "v3", "created": "Thu, 3 Dec 2020 21:12:24 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["He", "Hangfeng", ""], ["Ning", "Qiang", ""], ["Roth", "Dan", ""]]}, {"id": "1909.00338", "submitter": "Florian Kunneman", "authors": "Florian Kunneman, Mattijs Lambooij, Albert Wong, Antal van den Bosch,\n  Liesbeth Mollema", "title": "Monitoring stance towards vaccination in Twitter messages", "comments": "16 pages, 2 figures, accepted for BMC Medical Informatics and\n  Decision Making journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We developed a system to automatically classify stance towards vaccination in\nTwitter messages, with a focus on messages with a negative stance. Such a\nsystem makes it possible to monitor the ongoing stream of messages on social\nmedia, offering actionable insights into public hesitance with respect to\nvaccination. For Dutch Twitter messages that mention vaccination-related key\nterms, we annotated their stance and feeling in relation to vaccination\n(provided that they referred to this topic). Subsequently, we used these coded\ndata to train and test different machine learning set-ups. With the aim to best\nidentify messages with a negative stance towards vaccination, we compared\nset-ups at an increasing dataset size and decreasing reliability, at an\nincreasing number of categories to distinguish, and with different\nclassification algorithms. We found that Support Vector Machines trained on a\ncombination of strictly and laxly labeled data with a more fine-grained\nlabeling yielded the best result, at an F1-score of 0.36 and an Area under the\nROC curve of 0.66, outperforming a rule-based sentiment analysis baseline that\nyielded an F1-score of 0.25 and an Area under the ROC curve of 0.57. The\noutcomes of our study indicate that stance prediction by a computerized system\nonly is a challenging task. Our analysis of the data and behavior of our system\nsuggests that an approach is needed in which the use of a larger training\ndataset is combined with a setting in which a human-in-the-loop provides the\nsystem with feedback on its predictions.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 07:00:26 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Kunneman", "Florian", ""], ["Lambooij", "Mattijs", ""], ["Wong", "Albert", ""], ["Bosch", "Antal van den", ""], ["Mollema", "Liesbeth", ""]]}, {"id": "1909.00349", "submitter": "Tasnim Mohiuddin", "authors": "Han Cheol Moon, Tasnim Mohiuddin, Shafiq Joty, and Xu Chi", "title": "A Unified Neural Coherence Model", "comments": "To appear at EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, neural approaches to coherence modeling have achieved\nstate-of-the-art results in several evaluation tasks. However, we show that\nmost of these models often fail on harder tasks with more realistic application\nscenarios. In particular, the existing models underperform on tasks that\nrequire the model to be sensitive to local contexts such as candidate ranking\nin conversational dialogue and in machine translation. In this paper, we\npropose a unified coherence model that incorporates sentence grammar,\ninter-sentence coherence relations, and global coherence patterns into a common\nneural framework. With extensive experiments on local and global discrimination\ntasks, we demonstrate that our proposed model outperforms existing models by a\ngood margin, and establish a new state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 08:16:53 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Moon", "Han Cheol", ""], ["Mohiuddin", "Tasnim", ""], ["Joty", "Shafiq", ""], ["Chi", "Xu", ""]]}, {"id": "1909.00352", "submitter": "Leonardo F. R. Ribeiro", "authors": "Leonardo F. R. Ribeiro, Claire Gardent, Iryna Gurevych", "title": "Enhancing AMR-to-Text Generation with Dual Graph Representations", "comments": "Accepted as a long conference paper to EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating text from graph-based data, such as Abstract Meaning\nRepresentation (AMR), is a challenging task due to the inherent difficulty in\nhow to properly encode the structure of a graph with labeled edges. To address\nthis difficulty, we propose a novel graph-to-sequence model that encodes\ndifferent but complementary perspectives of the structural information\ncontained in the AMR graph. The model learns parallel top-down and bottom-up\nrepresentations of nodes capturing contrasting views of the graph. We also\ninvestigate the use of different node message passing strategies, employing\ndifferent state-of-the-art graph encoders to compute node representations based\non incoming and outgoing perspectives. In our experiments, we demonstrate that\nthe dual graph representation leads to improvements in AMR-to-text generation,\nachieving state-of-the-art results on two AMR datasets.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 08:22:38 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Ribeiro", "Leonardo F. R.", ""], ["Gardent", "Claire", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1909.00361", "submitter": "Yiming Cui", "authors": "Yiming Cui, Wanxiang Che, Ting Liu, Bing Qin, Shijin Wang, Guoping Hu", "title": "Cross-Lingual Machine Reading Comprehension", "comments": "10 pages, accepted as a conference paper at EMNLP-IJCNLP 2019 (long\n  paper)", "journal-ref": "EMNLP 2019 1586-1595", "doi": "10.18653/v1/D19-1169", "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though the community has made great progress on Machine Reading Comprehension\n(MRC) task, most of the previous works are solving English-based MRC problems,\nand there are few efforts on other languages mainly due to the lack of\nlarge-scale training data. In this paper, we propose Cross-Lingual Machine\nReading Comprehension (CLMRC) task for the languages other than English.\nFirstly, we present several back-translation approaches for CLMRC task, which\nis straightforward to adopt. However, to accurately align the answer into\nanother language is difficult and could introduce additional noise. In this\ncontext, we propose a novel model called Dual BERT, which takes advantage of\nthe large-scale training data provided by rich-resource language (such as\nEnglish) and learn the semantic relations between the passage and question in a\nbilingual context, and then utilize the learned knowledge to improve reading\ncomprehension performance of low-resource language. We conduct experiments on\ntwo Chinese machine reading comprehension datasets CMRC 2018 and DRCD. The\nresults show consistent and significant improvements over various\nstate-of-the-art systems by a large margin, which demonstrate the potentials in\nCLMRC task. Resources available: https://github.com/ymcui/Cross-Lingual-MRC\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 09:14:52 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Cui", "Yiming", ""], ["Che", "Wanxiang", ""], ["Liu", "Ting", ""], ["Qin", "Bing", ""], ["Wang", "Shijin", ""], ["Hu", "Guoping", ""]]}, {"id": "1909.00369", "submitter": "Longyue Wang", "authors": "Longyue Wang, Zhaopeng Tu, Xing Wang, Shuming Shi", "title": "One Model to Learn Both: Zero Pronoun Prediction and Translation", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero pronouns (ZPs) are frequently omitted in pro-drop languages, but should\nbe recalled in non-pro-drop languages. This discourse phenomenon poses a\nsignificant challenge for machine translation (MT) when translating texts from\npro-drop to non-pro-drop languages. In this paper, we propose a unified and\ndiscourse-aware ZP translation approach for neural MT models. Specifically, we\njointly learn to predict and translate ZPs in an end-to-end manner, allowing\nboth components to interact with each other. In addition, we employ\nhierarchical neural networks to exploit discourse-level context, which is\nbeneficial for ZP prediction and thus translation. Experimental results on both\nChinese-English and Japanese-English data show that our approach significantly\nand accumulatively improves both translation performance and ZP prediction\naccuracy over not only baseline but also previous works using external ZP\nprediction models. Extensive analyses confirm that the performance improvement\ncomes from the alleviation of different kinds of errors especially caused by\nsubjective ZPs.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 10:07:20 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Wang", "Longyue", ""], ["Tu", "Zhaopeng", ""], ["Wang", "Xing", ""], ["Shi", "Shuming", ""]]}, {"id": "1909.00383", "submitter": "Xing Wang", "authors": "Xing Wang, Zhaopeng Tu, Longyue Wang, Shuming Shi", "title": "Self-Attention with Structural Position Representations", "comments": "Accepted by EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although self-attention networks (SANs) have advanced the state-of-the-art on\nvarious NLP tasks, one criticism of SANs is their ability of encoding positions\nof input words (Shaw et al., 2018). In this work, we propose to augment SANs\nwith structural position representations to model the latent structure of the\ninput sentence, which is complementary to the standard sequential positional\nrepresentations. Specifically, we use dependency tree to represent the\ngrammatical structure of a sentence, and propose two strategies to encode the\npositional relationships among words in the dependency tree. Experimental\nresults on NIST Chinese-to-English and WMT14 English-to-German translation\ntasks show that the proposed approach consistently boosts performance over both\nthe absolute and relative sequential position representations.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 11:34:32 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Wang", "Xing", ""], ["Tu", "Zhaopeng", ""], ["Wang", "Longyue", ""], ["Shi", "Shuming", ""]]}, {"id": "1909.00393", "submitter": "Matan Orbach", "authors": "Matan Orbach, Yonatan Bilu, Ariel Gera, Yoav Kantor, Lena Dankin,\n  Tamar Lavee, Lili Kotlerman, Shachar Mirkin, Michal Jacovi, Ranit Aharonov\n  and Noam Slonim", "title": "A Dataset of General-Purpose Rebuttal", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Natural Language Understanding, the task of response generation is usually\nfocused on responses to short texts, such as tweets or a turn in a dialog. Here\nwe present a novel task of producing a critical response to a long\nargumentative text, and suggest a method based on general rebuttal arguments to\naddress it. We do this in the context of the recently-suggested task of\nlistening comprehension over argumentative content: given a speech on some\nspecified topic, and a list of relevant arguments, the goal is to determine\nwhich of the arguments appear in the speech. The general rebuttals we describe\nhere (written in English) overcome the need for topic-specific arguments to be\nprovided, by proving to be applicable for a large set of topics. This allows\ncreating responses beyond the scope of topics for which specific arguments are\navailable. All data collected during this work is freely available for\nresearch.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 13:24:35 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Orbach", "Matan", ""], ["Bilu", "Yonatan", ""], ["Gera", "Ariel", ""], ["Kantor", "Yoav", ""], ["Dankin", "Lena", ""], ["Lavee", "Tamar", ""], ["Kotlerman", "Lili", ""], ["Mirkin", "Shachar", ""], ["Jacovi", "Michal", ""], ["Aharonov", "Ranit", ""], ["Slonim", "Noam", ""]]}, {"id": "1909.00412", "submitter": "Marco Del Tredici", "authors": "Marco Del Tredici, Diego Marcheggiani, Sabine Schulte im Walde and\n  Raquel Fern\\'andez", "title": "You Shall Know a User by the Company It Keeps: Dynamic Representations\n  for Social Media Users in NLP", "comments": "To appear in Proceeding of EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Information about individuals can help to better understand what they say,\nparticularly in social media where texts are short. Current approaches to\nmodelling social media users pay attention to their social connections, but\nexploit this information in a static way, treating all connections uniformly.\nThis ignores the fact, well known in sociolinguistics, that an individual may\nbe part of several communities which are not equally relevant in all\ncommunicative situations. We present a model based on Graph Attention Networks\nthat captures this observation. It dynamically explores the social graph of a\nuser, computes a user representation given the most relevant connections for a\ntarget task, and combines it with linguistic information to make a prediction.\nWe apply our model to three different tasks, evaluate it against alternative\nmodels, and analyse the results extensively, showing that it significantly\noutperforms other current methods.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 14:48:04 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Del Tredici", "Marco", ""], ["Marcheggiani", "Diego", ""], ["Walde", "Sabine Schulte im", ""], ["Fern\u00e1ndez", "Raquel", ""]]}, {"id": "1909.00415", "submitter": "Giannis Karamanolakis", "authors": "Giannis Karamanolakis, Daniel Hsu, Luis Gravano", "title": "Leveraging Just a Few Keywords for Fine-Grained Aspect Detection Through\n  Weakly Supervised Co-Training", "comments": "Accepted to EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User-generated reviews can be decomposed into fine-grained segments (e.g.,\nsentences, clauses), each evaluating a different aspect of the principal entity\n(e.g., price, quality, appearance). Automatically detecting these aspects can\nbe useful for both users and downstream opinion mining applications. Current\nsupervised approaches for learning aspect classifiers require many fine-grained\naspect labels, which are labor-intensive to obtain. And, unfortunately,\nunsupervised topic models often fail to capture the aspects of interest. In\nthis work, we consider weakly supervised approaches for training aspect\nclassifiers that only require the user to provide a small set of seed words\n(i.e., weakly positive indicators) for the aspects of interest. First, we show\nthat current weakly supervised approaches do not effectively leverage the\npredictive power of seed words for aspect detection. Next, we propose a\nstudent-teacher approach that effectively leverages seed words in a\nbag-of-words classifier (teacher); in turn, we use the teacher to train a\nsecond model (student) that is potentially more powerful (e.g., a neural\nnetwork that uses pre-trained word embeddings). Finally, we show that iterative\nco-training can be used to cope with noisy seed words, leading to both improved\nteacher and student models. Our proposed approach consistently outperforms\nprevious weakly supervised approaches (by 14.1 absolute F1 points on average)\nin six different domains of product reviews and six multilingual datasets of\nrestaurant reviews.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 15:12:23 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Karamanolakis", "Giannis", ""], ["Hsu", "Daniel", ""], ["Gravano", "Luis", ""]]}, {"id": "1909.00421", "submitter": "Xintong Yu", "authors": "Xintong Yu, Hongming Zhang, Yangqiu Song, Yan Song, and Changshui\n  Zhang", "title": "What You See is What You Get: Visual Pronoun Coreference Resolution in\n  Dialogues", "comments": "10 pages, 7 figures. Accepted by EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grounding a pronoun to a visual object it refers to requires complex\nreasoning from various information sources, especially in conversational\nscenarios. For example, when people in a conversation talk about something all\nspeakers can see, they often directly use pronouns (e.g., it) to refer to it\nwithout previous introduction. This fact brings a huge challenge for modern\nnatural language understanding systems, particularly conventional context-based\npronoun coreference models. To tackle this challenge, in this paper, we\nformally define the task of visual-aware pronoun coreference resolution (PCR)\nand introduce VisPro, a large-scale dialogue PCR dataset, to investigate\nwhether and how the visual information can help resolve pronouns in dialogues.\nWe then propose a novel visual-aware PCR model, VisCoref, for this task and\nconduct comprehensive experiments and case studies on our dataset. Results\ndemonstrate the importance of the visual information in this PCR case and show\nthe effectiveness of the proposed model.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 15:47:03 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Yu", "Xintong", ""], ["Zhang", "Hongming", ""], ["Song", "Yangqiu", ""], ["Song", "Yan", ""], ["Zhang", "Changshui", ""]]}, {"id": "1909.00426", "submitter": "Ikuya Yamada", "authors": "Ikuya Yamada, Koki Washio, Hiroyuki Shindo, Yuji Matsumoto", "title": "Global Entity Disambiguation with Pretrained Contextualized Embeddings\n  of Words and Entities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new global entity disambiguation (ED) model based on\ncontextualized embeddings of words and entities. Our model is based on a\nbidirectional transformer encoder (i.e., BERT) and produces contextualized\nembeddings for words and entities in the input text. The model is trained using\na new masked entity prediction task that aims to train the model by predicting\nrandomly masked entities in entity-annotated texts obtained from Wikipedia. We\nfurther extend the model by solving ED as a sequential decision task to capture\nglobal contextual information. We evaluate our model using six standard ED\ndatasets and achieve new state-of-the-art results on all but one dataset.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 16:29:53 GMT"}, {"version": "v2", "created": "Sat, 4 Apr 2020 07:39:31 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Yamada", "Ikuya", ""], ["Washio", "Koki", ""], ["Shindo", "Hiroyuki", ""], ["Matsumoto", "Yuji", ""]]}, {"id": "1909.00429", "submitter": "Qiang Ning", "authors": "Qiang Ning, Sanjay Subramanian, Dan Roth", "title": "An Improved Neural Baseline for Temporal Relation Extraction", "comments": "This short paper is accepted to EMNLP 2019; appendix included", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining temporal relations (e.g., before or after) between events has\nbeen a challenging natural language understanding task, partly due to the\ndifficulty to generate large amounts of high-quality training data.\nConsequently, neural approaches have not been widely used on it, or showed only\nmoderate improvements. This paper proposes a new neural system that achieves\nabout 10% absolute improvement in accuracy over the previous best system (25%\nerror reduction) on two benchmark datasets. The proposed system is trained on\nthe state-of-the-art MATRES dataset and applies contextualized word embeddings,\na Siamese encoder of a temporal common sense knowledge base, and global\ninference via integer linear programming (ILP). We suggest that the new\napproach could serve as a strong baseline for future research in this area.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 16:47:57 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Ning", "Qiang", ""], ["Subramanian", "Sanjay", ""], ["Roth", "Dan", ""]]}, {"id": "1909.00430", "submitter": "Matan Ben Noach", "authors": "Matan Ben Noach and Yoav Goldberg", "title": "Transfer Learning Between Related Tasks Using Expected Label Proportions", "comments": "EMNLP 2019", "journal-ref": "2019 Conference on Empirical Methods in Natural Language\n  Processing and 9th International Joint Conference on Natural Language\n  Processing", "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning systems thrive on abundance of labeled training data but such\ndata is not always available, calling for alternative methods of supervision.\nOne such method is expectation regularization (XR) (Mann and McCallum, 2007),\nwhere models are trained based on expected label proportions. We propose a\nnovel application of the XR framework for transfer learning between related\ntasks, where knowing the labels of task A provides an estimation of the label\nproportion of task B. We then use a model trained for A to label a large\ncorpus, and use this corpus with an XR loss to train a model for task B. To\nmake the XR framework applicable to large-scale deep-learning setups, we\npropose a stochastic batched approximation procedure. We demonstrate the\napproach on the task of Aspect-based Sentiment classification, where we\neffectively use a sentence-level sentiment predictor to train accurate\naspect-based predictor. The method improves upon fully supervised neural system\ntrained on aspect-level data, and is also cumulative with LM-based pretraining,\nas we demonstrate by improving a BERT-based Aspect-based Sentiment model.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 17:11:35 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Noach", "Matan Ben", ""], ["Goldberg", "Yoav", ""]]}, {"id": "1909.00437", "submitter": "Aditya Siddhant", "authors": "Aditya Siddhant, Melvin Johnson, Henry Tsai, Naveen Arivazhagan, Jason\n  Riesa, Ankur Bapna, Orhan Firat, Karthik Raman", "title": "Evaluating the Cross-Lingual Effectiveness of Massively Multilingual\n  Neural Machine Translation", "comments": null, "journal-ref": "AAAI 2020", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently proposed massively multilingual neural machine translation (NMT)\nsystem has been shown to be capable of translating over 100 languages to and\nfrom English within a single model. Its improved translation performance on low\nresource languages hints at potential cross-lingual transfer capability for\ndownstream tasks. In this paper, we evaluate the cross-lingual effectiveness of\nrepresentations from the encoder of a massively multilingual NMT model on 5\ndownstream classification and sequence labeling tasks covering a diverse set of\nover 50 languages. We compare against a strong baseline, multilingual BERT\n(mBERT), in different cross-lingual transfer learning scenarios and show gains\nin zero-shot transfer in 4 out of these 5 tasks.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 17:32:21 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Siddhant", "Aditya", ""], ["Johnson", "Melvin", ""], ["Tsai", "Henry", ""], ["Arivazhagan", "Naveen", ""], ["Riesa", "Jason", ""], ["Bapna", "Ankur", ""], ["Firat", "Orhan", ""], ["Raman", "Karthik", ""]]}, {"id": "1909.00444", "submitter": "Elias Stengel-Eskin", "authors": "Elias Stengel-Eskin, Tzu-Ray Su, Matt Post, Benjamin Van Durme", "title": "A Discriminative Neural Model for Cross-Lingual Word Alignment", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel discriminative word alignment model, which we integrate\ninto a Transformer-based machine translation model. In experiments based on a\nsmall number of labeled examples (~1.7K-5K sentences) we evaluate its\nperformance intrinsically on both English-Chinese and English-Arabic alignment,\nwhere we achieve major improvements over unsupervised baselines (11-27 F1). We\nevaluate the model extrinsically on data projection for Chinese NER, showing\nthat our alignments lead to higher performance when used to project NER tags\nfrom English to Chinese. Finally, we perform an ablation analysis and an\nannotation experiment that jointly support the utility and feasibility of\nfuture manual alignment elicitation.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 18:37:32 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Stengel-Eskin", "Elias", ""], ["Su", "Tzu-Ray", ""], ["Post", "Matt", ""], ["Van Durme", "Benjamin", ""]]}, {"id": "1909.00453", "submitter": "Sachin Kumar", "authors": "Sachin Kumar, Shuly Wintner, Noah A. Smith, Yulia Tsvetkov", "title": "Topics to Avoid: Demoting Latent Confounds in Text Classification", "comments": "2019 Conference on Empirical Methods in Natural Language Processing\n  (EMNLP 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite impressive performance on many text classification tasks, deep neural\nnetworks tend to learn frequent superficial patterns that are specific to the\ntraining data and do not always generalize well. In this work, we observe this\nlimitation with respect to the task of native language identification. We find\nthat standard text classifiers which perform well on the test set end up\nlearning topical features which are confounds of the prediction task (e.g., if\nthe input text mentions Sweden, the classifier predicts that the author's\nnative language is Swedish). We propose a method that represents the latent\ntopical confounds and a model which \"unlearns\" confounding features by\npredicting both the label of the input text and the confound; but we train the\ntwo predictors adversarially in an alternating fashion to learn a text\nrepresentation that predicts the correct label but is less prone to using\ninformation about the confound. We show that this model generalizes better and\nlearns features that are indicative of the writing style rather than the\ncontent.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 19:18:44 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 20:18:55 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Kumar", "Sachin", ""], ["Wintner", "Shuly", ""], ["Smith", "Noah A.", ""], ["Tsvetkov", "Yulia", ""]]}, {"id": "1909.00502", "submitter": "Shun Kiyono", "authors": "Shun Kiyono, Jun Suzuki, Masato Mita, Tomoya Mizumoto, Kentaro Inui", "title": "An Empirical Study of Incorporating Pseudo Data into Grammatical Error\n  Correction", "comments": "Proceedings of the 2019 Conference on Empirical Methods in Natural\n  Language Processing (EMNLP 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The incorporation of pseudo data in the training of grammatical error\ncorrection models has been one of the main factors in improving the performance\nof such models. However, consensus is lacking on experimental configurations,\nnamely, choosing how the pseudo data should be generated or used. In this\nstudy, these choices are investigated through extensive experiments, and\nstate-of-the-art performance is achieved on the CoNLL-2014 test set\n($F_{0.5}=65.0$) and the official test set of the BEA-2019 shared task\n($F_{0.5}=70.2$) without making any modifications to the model architecture.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 01:33:08 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Kiyono", "Shun", ""], ["Suzuki", "Jun", ""], ["Mita", "Masato", ""], ["Mizumoto", "Tomoya", ""], ["Inui", "Kentaro", ""]]}, {"id": "1909.00504", "submitter": "Kawin Ethayarajh", "authors": "Kawin Ethayarajh", "title": "Rotate King to get Queen: Word Relationships as Orthogonal\n  Transformations in Embedding Space", "comments": "Accepted to EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A notable property of word embeddings is that word relationships can exist as\nlinear substructures in the embedding space. For example, $\\textit{gender}$\ncorresponds to $\\vec{\\textit{woman}} - \\vec{\\textit{man}}$ and\n$\\vec{\\textit{queen}} - \\vec{\\textit{king}}$. This, in turn, allows word\nanalogies to be solved arithmetically: $\\vec{\\textit{king}} -\n\\vec{\\textit{man}} + \\vec{\\textit{woman}} \\approx \\vec{\\textit{queen}}$. This\nproperty is notable because it suggests that models trained on word embeddings\ncan easily learn such relationships as geometric translations. However, there\nis no evidence that models $\\textit{exclusively}$ represent relationships in\nthis manner. We document an alternative way in which downstream models might\nlearn these relationships: orthogonal and linear transformations. For example,\ngiven a translation vector for $\\textit{gender}$, we can find an orthogonal\nmatrix $R$, representing a rotation and reflection, such that\n$R(\\vec{\\textit{king}}) \\approx \\vec{\\textit{queen}}$ and\n$R(\\vec{\\textit{man}}) \\approx \\vec{\\textit{woman}}$. Analogical reasoning\nusing orthogonal transformations is almost as accurate as using vector\narithmetic; using linear transformations is more accurate than both. Our\nfindings suggest that these transformations can be as good a representation of\nword relationships as translation vectors.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 01:36:33 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 17:09:30 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Ethayarajh", "Kawin", ""]]}, {"id": "1909.00505", "submitter": "Joseph Davison", "authors": "Joshua Feldman, Joe Davison, Alexander M. Rush", "title": "Commonsense Knowledge Mining from Pretrained Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring commonsense knowledge is a key challenge in natural language\nprocessing, but due to the sparsity of training data, previous work has shown\nthat supervised methods for commonsense knowledge mining underperform when\nevaluated on novel data. In this work, we develop a method for generating\ncommonsense knowledge using a large, pre-trained bidirectional language model.\nBy transforming relational triples into masked sentences, we can use this model\nto rank a triple's validity by the estimated pointwise mutual information\nbetween the two entities. Since we do not update the weights of the\nbidirectional model, our approach is not biased by the coverage of any one\ncommonsense knowledge base. Though this method performs worse on a test set\nthan models explicitly trained on a corresponding training set, it outperforms\nthese methods when mining commonsense knowledge from new sources, suggesting\nthat unsupervised techniques may generalize better than current supervised\napproaches.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 01:41:00 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Feldman", "Joshua", ""], ["Davison", "Joe", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1909.00512", "submitter": "Kawin Ethayarajh", "authors": "Kawin Ethayarajh", "title": "How Contextual are Contextualized Word Representations? Comparing the\n  Geometry of BERT, ELMo, and GPT-2 Embeddings", "comments": "Accepted to EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Replacing static word embeddings with contextualized word representations has\nyielded significant improvements on many NLP tasks. However, just how\ncontextual are the contextualized representations produced by models such as\nELMo and BERT? Are there infinitely many context-specific representations for\neach word, or are words essentially assigned one of a finite number of\nword-sense representations? For one, we find that the contextualized\nrepresentations of all words are not isotropic in any layer of the\ncontextualizing model. While representations of the same word in different\ncontexts still have a greater cosine similarity than those of two different\nwords, this self-similarity is much lower in upper layers. This suggests that\nupper layers of contextualizing models produce more context-specific\nrepresentations, much like how upper layers of LSTMs produce more task-specific\nrepresentations. In all layers of ELMo, BERT, and GPT-2, on average, less than\n5% of the variance in a word's contextualized representations can be explained\nby a static embedding for that word, providing some justification for the\nsuccess of contextualized representations.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 01:51:46 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Ethayarajh", "Kawin", ""]]}, {"id": "1909.00516", "submitter": "Yang Liu", "authors": "Yang Liu", "title": "Beyond The Wall Street Journal: Anchoring and Comparing Discourse\n  Signals across Genres", "comments": "10 pages. In Proceedings of 7th Workshop on Discourse Relation\n  Parsing and Treebanking (DISRPT) at NAACL-HLT 2019, Minneapolis, MN", "journal-ref": null, "doi": "10.18653/v1/W19-2710", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent research on discourse relations has found that they are cued not only\nby discourse markers (DMs) but also by other textual signals and that signaling\ninformation is indicative of genres. While several corpora exist with discourse\nrelation signaling information such as the Penn Discourse Treebank (PDTB,\nPrasad et al. 2008) and the Rhetorical Structure Theory Signalling Corpus\n(RST-SC, Das and Taboada 2018), they both annotate the Wall Street Journal\n(WSJ) section of the Penn Treebank (PTB, Marcus et al. 1993), which is limited\nto the news domain. Thus, this paper adapts the signal identification and\nanchoring scheme (Liu and Zeldes, 2019) to three more genres, examines the\ndistribution of signaling devices across relations and genres, and provides a\ntaxonomy of indicative signals found in this dataset.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 02:27:19 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Liu", "Yang", ""]]}, {"id": "1909.00519", "submitter": "Mojtaba Nayyeri", "authors": "Mojtaba Nayyeri, Chengjin Xu, Yadollah Yaghoobzadeh, Hamed Shariat\n  Yazdi, Jens Lehmann", "title": "Toward Understanding The Effect Of Loss function On Then Performance Of\n  Knowledge Graph Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs (KGs) represent world's facts in structured forms. KG\ncompletion exploits the existing facts in a KG to discover new ones.\nTranslation-based embedding model (TransE) is a prominent formulation to do KG\ncompletion. Despite the efficiency of TransE in memory and time, it suffers\nfrom several limitations in encoding relation patterns such as symmetric,\nreflexive etc. To resolve this problem, most of the attempts have circled\naround the revision of the score function of TransE i.e., proposing a more\ncomplicated score function such as Trans(A, D, G, H, R, etc) to mitigate the\nlimitations. In this paper, we tackle this problem from a different\nperspective. We show that existing theories corresponding to the limitations of\nTransE are inaccurate because they ignore the effect of loss function.\nAccordingly, we pose theoretical investigations of the main limitations of\nTransE in the light of loss function. To the best of our knowledge, this has\nnot been investigated so far comprehensively. We show that by a proper\nselection of the loss function for training the TransE model, the main\nlimitations of the model are mitigated. This is explained by setting\nupper-bound for the scores of positive samples, showing the region of truth\n(i.e., the region that a triple is considered positive by the model). Our\ntheoretical proofs with experimental results fill the gap between the\ncapability of translation-based class of embedding models and the loss\nfunction. The theories emphasise the importance of the selection of the loss\nfunctions for training the models. Our experimental evaluations on different\nloss functions used for training the models justify our theoretical proofs and\nconfirm the importance of the loss functions on the performance.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 03:10:14 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 08:58:05 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Nayyeri", "Mojtaba", ""], ["Xu", "Chengjin", ""], ["Yaghoobzadeh", "Yadollah", ""], ["Yazdi", "Hamed Shariat", ""], ["Lehmann", "Jens", ""]]}, {"id": "1909.00521", "submitter": "Yue Yu", "authors": "Yue Yu and Siyao Peng and Grace Hui Yang", "title": "Modeling Long-Range Context for Concurrent Dialogue Acts Recognition", "comments": "Accepted to CIKM '19", "journal-ref": null, "doi": "10.1145/3357384.3358145", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In dialogues, an utterance is a chain of consecutive sentences produced by\none speaker which ranges from a short sentence to a thousand-word post. When\nstudying dialogues at the utterance level, it is not uncommon that an utterance\nwould serve multiple functions. For instance, \"Thank you. It works great.\"\nexpresses both gratitude and positive feedback in the same utterance. Multiple\ndialogue acts (DA) for one utterance breeds complex dependencies across\ndialogue turns. Therefore, DA recognition challenges a model's predictive power\nover long utterances and complex DA context. We term this problem Concurrent\nDialogue Acts (CDA) recognition. Previous work on DA recognition either assumes\none DA per utterance or fails to realize the sequential nature of dialogues. In\nthis paper, we present an adapted Convolutional Recurrent Neural Network (CRNN)\nwhich models the interactions between utterances of long-range context. Our\nmodel significantly outperforms existing work on CDA recognition on a tech\nforum dataset.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 03:12:19 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 13:28:58 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Yu", "Yue", ""], ["Peng", "Siyao", ""], ["Yang", "Grace Hui", ""]]}, {"id": "1909.00522", "submitter": "Siyao Peng", "authors": "Siyao Peng, Amir Zeldes", "title": "All Roads Lead to UD: Converting Stanford and Penn Parses to English\n  Universal Dependencies with Multilayer Annotations", "comments": "accepted in LAW-MWE-CxG-2018 at COLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe and evaluate different approaches to the conversion of gold\nstandard corpus data from Stanford Typed Dependencies (SD) and Penn-style\nconstituent trees to the latest English Universal Dependencies representation\n(UD 2.2). Our results indicate that pure SD to UD conversion is highly accurate\nacross multiple genres, resulting in around 1.5% errors, but can be improved\nfurther to fewer than 0.5% errors given access to annotations beyond the pure\nsyntax tree, such as entity types and coreference resolution, which are\nnecessary for correct generation of several UD relations. We show that\nconstituent-based conversion using CoreNLP (with automatic NER) performs\nsubstantially worse in all genres, including when using gold constituent trees,\nprimarily due to underspecification of phrasal grammatical functions.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 03:14:17 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Peng", "Siyao", ""], ["Zeldes", "Amir", ""]]}, {"id": "1909.00531", "submitter": "Mamoru Komachi", "authors": "Hayahide Yamagishi and Mamoru Komachi", "title": "Improving Context-aware Neural Machine Translation with Target-side\n  Context", "comments": "12 pages; PACLING 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, several studies on neural machine translation (NMT) have\nattempted to use document-level context by using a multi-encoder and two\nattention mechanisms to read the current and previous sentences to incorporate\nthe context of the previous sentences. These studies concluded that the\ntarget-side context is less useful than the source-side context. However, we\nconsidered that the reason why the target-side context is less useful lies in\nthe architecture used to model these contexts.\n  Therefore, in this study, we investigate how the target-side context can\nimprove context-aware neural machine translation. We propose a weight sharing\nmethod wherein NMT saves decoder states and calculates an attention vector\nusing the saved states when translating a current sentence. Our experiments\nshow that the target-side context is also useful if we plug it into NMT as the\ndecoder state when translating a previous sentence.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 04:04:18 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Yamagishi", "Hayahide", ""], ["Komachi", "Mamoru", ""]]}, {"id": "1909.00542", "submitter": "Diego Molla-Aliod", "authors": "Diego Molla and Christopher Jones", "title": "Classification Betters Regression in Query-based Multi-document\n  Summarisation Techniques for Question Answering: Macquarie University at\n  BioASQ7b", "comments": "12 pages, 3 figures, 7 tables. As accepted at BioASQ workshop,\n  ECML-PKDD 2019", "journal-ref": null, "doi": "10.1007/978-3-030-43887-6_56", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task B Phase B of the 2019 BioASQ challenge focuses on biomedical question\nanswering. Macquarie University's participation applies query-based\nmulti-document extractive summarisation techniques to generate a multi-sentence\nanswer given the question and the set of relevant snippets. In past\nparticipation we explored the use of regression approaches using deep learning\narchitectures and a simple policy gradient architecture. For the 2019 challenge\nwe experiment with the use of classification approaches with and without\nreinforcement learning. In addition, we conduct a correlation analysis between\nvarious ROUGE metrics and the BioASQ human evaluation scores.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 04:39:26 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Molla", "Diego", ""], ["Jones", "Christopher", ""]]}, {"id": "1909.00556", "submitter": "Yiheng Huang", "authors": "Yiheng Huang and Liqiang He and Lei Han and Guangsen Wang and Dan Su", "title": "Phrase-Level Class based Language Model for Mandarin Smart Speaker Query\n  Recognition", "comments": "5 pages, 3 figures and 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of speech assistants requires precise recognition of a number of\nentities on particular contexts. A common solution is to train a class-based\nn-gram language model and then expand the classes into specific words or\nphrases. However, when the class has a huge list, e.g., more than 20 million\nsongs, a fully expansion will cause memory explosion. Worse still, the list\nitems in the class need to be updated frequently, which requires a dynamic\nmodel updating technique. In this work, we propose to train pruned language\nmodels for the word classes to replace the slots in the root n-gram. We further\npropose to use a novel technique, named Difference Language Model (DLM), to\ncorrect the bias from the pruned language models. Once the decoding graph is\nbuilt, we only need to recalculate the DLM when the entities in word classes\nare updated. Results show that the proposed method consistently and\nsignificantly outperforms the conventional approaches on all datasets, esp. for\nlarge lists, which the conventional approaches cannot handle.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 05:55:36 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Huang", "Yiheng", ""], ["He", "Liqiang", ""], ["Han", "Lei", ""], ["Wang", "Guangsen", ""], ["Su", "Dan", ""]]}, {"id": "1909.00562", "submitter": "Junya Ono", "authors": "Junya Ono, Masao Utiyama, Eiichiro Sumita", "title": "Hybrid Data-Model Parallel Training for Sequence-to-Sequence Recurrent\n  Neural Network Machine Translation", "comments": "9 pages, 4 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reduction of training time is an important issue in many tasks like patent\ntranslation involving neural networks. Data parallelism and model parallelism\nare two common approaches for reducing training time using multiple graphics\nprocessing units (GPUs) on one machine. In this paper, we propose a hybrid\ndata-model parallel approach for sequence-to-sequence (Seq2Seq) recurrent\nneural network (RNN) machine translation. We apply a model parallel approach to\nthe RNN encoder-decoder part of the Seq2Seq model and a data parallel approach\nto the attention-softmax part of the model. We achieved a speed-up of 4.13 to\n4.20 times when using 4 GPUs compared with the training speed when using 1 GPU\nwithout affecting machine translation accuracy as measured in terms of BLEU\nscores.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 06:41:34 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 06:12:02 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Ono", "Junya", ""], ["Utiyama", "Masao", ""], ["Sumita", "Eiichiro", ""]]}, {"id": "1909.00564", "submitter": "Zhenxin Yang", "authors": "Zhengxin Yang, Jinchao Zhang, Fandong Meng, Shuhao Gu, Yang Feng, Jie\n  Zhou", "title": "Enhancing Context Modeling with a Query-Guided Capsule Network for\n  Document-level Translation", "comments": "11 pages, 7 figures, 2019 Conference on Empirical Methods in Natural\n  Language Processing", "journal-ref": null, "doi": "10.18653/v1/D19-1164", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context modeling is essential to generate coherent and consistent translation\nfor Document-level Neural Machine Translations. The widely used method for\ndocument-level translation usually compresses the context information into a\nrepresentation via hierarchical attention networks. However, this method\nneither considers the relationship between context words nor distinguishes the\nroles of context words. To address this problem, we propose a query-guided\ncapsule networks to cluster context information into different perspectives\nfrom which the target translation may concern. Experiment results show that our\nmethod can significantly outperform strong baselines on multiple data sets of\ndifferent domains.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 06:55:16 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 07:40:07 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Yang", "Zhengxin", ""], ["Zhang", "Jinchao", ""], ["Meng", "Fandong", ""], ["Gu", "Shuhao", ""], ["Feng", "Yang", ""], ["Zhou", "Jie", ""]]}, {"id": "1909.00574", "submitter": "Zechang Li", "authors": "Zechang Li, Yuxuan Lai, Yuxi Xie, Yansong Feng, Dongyan Zhao", "title": "A Sketch-Based System for Semantic Parsing", "comments": "Accepted by NLPCC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents our semantic parsing system for the evaluation task of\nopen domain semantic parsing in NLPCC 2019. Many previous works formulate\nsemantic parsing as a sequence-to-sequence(seq2seq) problem. Instead, we treat\nthe task as a sketch-based problem in a coarse-to-fine(coarse2fine) fashion.\nThe sketch is a high-level structure of the logical form exclusive of low-level\ndetails such as entities and predicates. In this way, we are able to optimize\neach part individually. Specifically, we decompose the process into three\nstages: the sketch classification determines the high-level structure while the\nentity labeling and the matching network fill in missing details. Moreover, we\nadopt the seq2seq method to evaluate logical form candidates from an overall\nperspective. The co-occurrence relationship between predicates and entities\ncontribute to the reranking as well. Our submitted system achieves the exactly\nmatching accuracy of 82.53% on full test set and 47.83% on hard test subset,\nwhich is the 3rd place in NLPCC 2019 Shared Task 2. After optimizations for\nparameters, network structure and sampling, the accuracy reaches 84.47% on full\ntest set and 63.08% on hard test subset(Our code and data are available at\nhttps://github.com/zechagl/NLPCC2019-Semantic-Parsing).\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 07:16:57 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 08:04:48 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Li", "Zechang", ""], ["Lai", "Yuxuan", ""], ["Xie", "Yuxi", ""], ["Feng", "Yansong", ""], ["Zhao", "Dongyan", ""]]}, {"id": "1909.00578", "submitter": "Prodromos Malakasiotis", "authors": "Stratos Xenouleas, Prodromos Malakasiotis, Marianna Apidianaki and Ion\n  Androutsopoulos", "title": "SumQE: a BERT-based Summary Quality Estimation Model", "comments": "In Proceedings of the Conference on Empirical Methods in Natural\n  Language Processing and the 9th International Joint Conference on Natural\n  Language Processing (EMNLP-IJCNLP 2019), Hong Kong, China, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose SumQE, a novel Quality Estimation model for summarization based on\nBERT. The model addresses linguistic quality aspects that are only indirectly\ncaptured by content-based approaches to summary evaluation, without involving\ncomparison with human references. SumQE achieves very high correlations with\nhuman ratings, outperforming simpler models addressing these linguistic\naspects. Predictions of the SumQE model can be used for system development, and\nto inform users of the quality of automatically produced summaries and other\ntypes of generated text.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 07:30:53 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Xenouleas", "Stratos", ""], ["Malakasiotis", "Prodromos", ""], ["Apidianaki", "Marianna", ""], ["Androutsopoulos", "Ion", ""]]}, {"id": "1909.00596", "submitter": "Traian Rebedea", "authors": "George-Sebastian P\\^irtoac\\u{a}, Traian Rebedea, Stefan Ruseti", "title": "Answering questions by learning to rank -- Learning to rank by answering\n  questions", "comments": "Presented at EMNLP 2019; 10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Answering multiple-choice questions in a setting in which no supporting\ndocuments are explicitly provided continues to stand as a core problem in\nnatural language processing. The contribution of this article is two-fold.\nFirst, it describes a method which can be used to semantically rank documents\nextracted from Wikipedia or similar natural language corpora. Second, we\npropose a model employing the semantic ranking that holds the first place in\ntwo of the most popular leaderboards for answering multiple-choice questions:\nARC Easy and Challenge. To achieve this, we introduce a self-attention based\nneural network that latently learns to rank documents by their importance\nrelated to a given question, whilst optimizing the objective of predicting the\ncorrect answer. These documents are considered relevant contexts for the\nunderlying question. We have published the ranked documents so that they can be\nused off-the-shelf to improve downstream decision models.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 08:36:32 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 10:09:56 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["P\u00eertoac\u0103", "George-Sebastian", ""], ["Rebedea", "Traian", ""], ["Ruseti", "Stefan", ""]]}, {"id": "1909.00599", "submitter": "Gyuwan Kim", "authors": "Gyuwan Kim", "title": "Subword Language Model for Query Auto-Completion", "comments": "EMNLP-IJCNLP 2019; Code is available at\n  https://github.com/clovaai/subword-qac ; 11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current neural query auto-completion (QAC) systems rely on character-level\nlanguage models, but they slow down when queries are long. We present how to\nutilize subword language models for the fast and accurate generation of query\ncompletion candidates. Representing queries with subwords shorten a decoding\nlength significantly. To deal with issues coming from introducing subword\nlanguage model, we develop a retrace algorithm and a reranking method by\napproximate marginalization. As a result, our model achieves up to 2.5 times\nfaster while maintaining a similar quality of generated results compared to the\ncharacter-level baseline. Also, we propose a new evaluation metric, mean\nrecoverable length (MRL), measuring how many upcoming characters the model\ncould complete correctly. It provides more explicit meaning and eliminates the\nneed for prefix length sampling for existing rank-based metrics. Moreover, we\nperformed a comprehensive analysis with ablation study to figure out the\nimportance of each component.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 08:40:41 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Kim", "Gyuwan", ""]]}, {"id": "1909.00615", "submitter": "Zhiyuan Ma", "authors": "Jiaying Zhang, Zhixing Zhang, Huanhuan Zhang, Zhiyuan Ma, Yangming\n  Zhou, Ping He", "title": "Enriching Medcial Terminology Knowledge Bases via Pre-trained Language\n  Model and Graph Convolutional Network", "comments": "8 pages, submitted to BIBM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enriching existing medical terminology knowledge bases (KBs) is an important\nand never-ending work for clinical research because new terminology alias may\nbe continually added and standard terminologies may be newly renamed. In this\npaper, we propose a novel automatic terminology enriching approach to\nsupplement a set of terminologies to KBs. Specifically, terminology and entity\ncharacters are first fed into pre-trained language model to obtain semantic\nembedding. The pre-trained model is used again to initialize the terminology\nand entity representations, then they are further embedded through graph\nconvolutional network to gain structure embedding. Afterwards, both semantic\nand structure embeddings are combined to measure the relevancy between the\nterminology and the entity. Finally, the optimal alignment is achieved based on\nthe order of relevancy between the terminology and all the entities in the KB.\nExperimental results on clinical indicator terminology KB, collected from 38\ntop-class hospitals of Shanghai Hospital Development Center, show that our\nproposed approach outperforms baseline methods and can effectively enrich the\nKB.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 09:16:06 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Zhang", "Jiaying", ""], ["Zhang", "Zhixing", ""], ["Zhang", "Huanhuan", ""], ["Ma", "Zhiyuan", ""], ["Zhou", "Yangming", ""], ["He", "Ping", ""]]}, {"id": "1909.00672", "submitter": "Linfeng Li", "authors": "Linfeng Li, Peng Wang, Yao Wang, Jinpeng Jiang, Buzhou Tang, Jun Yan,\n  Shenghui Wang, Yuting Liu", "title": "A Method to Learn Embedding of a Probabilistic Medical Knowledge Graph:\n  Algorithm Development", "comments": null, "journal-ref": "JMIR Med Inform 2020;8(5):e17645", "doi": "10.2196/17645", "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an algorithm named as PrTransH to learn embedding vectors\nfrom real world EMR data based medical knowledge. The unique challenge in\nembedding medical knowledge graph from real world EMR data is that the\nuncertainty of knowledge triplets blurs the border between \"correct triplet\"\nand \"wrong triplet\", changing the fundamental assumption of many existing\nalgorithms. To address the challenge, some enhancements are made to existing\nTransH algorithm, including: 1) involve probability of medical knowledge\ntriplet into training objective; 2) replace the margin-based ranking loss with\nunified loss calculation considering both valid and corrupted triplets; 3)\naugment training data set with medical background knowledge. Verifications on\nreal world EMR data based medical knowledge graph prove that PrTransH\noutperforms TransH in link prediction task. To the best of our survey, this\npaper is the first one to learn and verify knowledge embedding on probabilistic\nknowledge graphs.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 11:28:35 GMT"}, {"version": "v2", "created": "Sun, 8 Nov 2020 18:06:34 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Li", "Linfeng", ""], ["Wang", "Peng", ""], ["Wang", "Yao", ""], ["Jiang", "Jinpeng", ""], ["Tang", "Buzhou", ""], ["Yan", "Jun", ""], ["Wang", "Shenghui", ""], ["Liu", "Yuting", ""]]}, {"id": "1909.00692", "submitter": "Sreyasi Nag Chowdhury", "authors": "Sreyasi Nag Chowdhury, Simon Razniewski, Gerhard Weikum", "title": "Story-oriented Image Selection and Placement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal contents have become commonplace on the Internet today, manifested\nas news articles, social media posts, and personal or business blog posts.\nAmong the various kinds of media (images, videos, graphics, icons, audio) used\nin such multimodal stories, images are the most popular. The selection of\nimages from a collection - either author's personal photo album, or web\nrepositories - and their meticulous placement within a text, builds a succinct\nmultimodal commentary for digital consumption. In this paper we present a\nsystem that automates the process of selecting relevant images for a story and\nplacing them at contextual paragraphs within the story for a multimodal\nnarration. We leverage automatic object recognition, user-provided tags, and\ncommonsense knowledge, and use an unsupervised combinatorial optimization to\nsolve the selection and placement problems seamlessly as a single unit.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 12:41:45 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Chowdhury", "Sreyasi Nag", ""], ["Razniewski", "Simon", ""], ["Weikum", "Gerhard", ""]]}, {"id": "1909.00694", "submitter": "Jun Saito", "authors": "Jun Saito, Yugo Murawaki, Sadao Kurohashi", "title": "Minimally Supervised Learning of Affective Events Using Discourse\n  Relations", "comments": "8 pages, 1 figure. EMNLP2019 (short paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing affective events that trigger positive or negative sentiment has\na wide range of natural language processing applications but remains a\nchallenging problem mainly because the polarity of an event is not necessarily\npredictable from its constituent words. In this paper, we propose to propagate\naffective polarity using discourse relations. Our method is simple and only\nrequires a very small seed lexicon and a large raw corpus. Our experiments\nusing Japanese data show that our method learns affective events effectively\nwithout manually labeled data. It also improves supervised learning results\nwhen labeled data are small.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 12:46:26 GMT"}, {"version": "v2", "created": "Sat, 28 Dec 2019 13:32:04 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Saito", "Jun", ""], ["Murawaki", "Yugo", ""], ["Kurohashi", "Sadao", ""]]}, {"id": "1909.00734", "submitter": "Xinyu Hua", "authors": "Xinyu Hua and Lu Wang", "title": "Sentence-Level Content Planning and Style Specification for Neural Text\n  Generation", "comments": "Accepted as a long paper to EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building effective text generation systems requires three critical\ncomponents: content selection, text planning, and surface realization, and\ntraditionally they are tackled as separate problems. Recent all-in-one style\nneural generation models have made impressive progress, yet they often produce\noutputs that are incoherent and unfaithful to the input. To address these\nissues, we present an end-to-end trained two-step generation model, where a\nsentence-level content planner first decides on the keyphrases to cover as well\nas a desired language style, followed by a surface realization decoder that\ngenerates relevant and coherent text. For experiments, we consider three tasks\nfrom domains with diverse topics and varying language styles: persuasive\nargument construction from Reddit, paragraph generation for normal and simple\nversions of Wikipedia, and abstract generation for scientific articles.\nAutomatic evaluation shows that our system can significantly outperform\ncompetitive comparisons. Human judges further rate our system generated text as\nmore fluent and correct, compared to the generations by its variants that do\nnot consider language style.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 14:29:36 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Hua", "Xinyu", ""], ["Wang", "Lu", ""]]}, {"id": "1909.00754", "submitter": "Liliang Ren", "authors": "Liliang Ren, Jianmo Ni and Julian McAuley", "title": "Scalable and Accurate Dialogue State Tracking via Hierarchical Sequence\n  Generation", "comments": "The 2019 Conference on Empirical Methods in Natural Language\n  Processing (EMNLP 2019); Updated empirical results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing approaches to dialogue state tracking rely on pre-defined ontologies\nconsisting of a set of all possible slot types and values. Though such\napproaches exhibit promising performance on single-domain benchmarks, they\nsuffer from computational complexity that increases proportionally to the\nnumber of pre-defined slots that need tracking. This issue becomes more severe\nwhen it comes to multi-domain dialogues which include larger numbers of slots.\nIn this paper, we investigate how to approach DST using a generation framework\nwithout the pre-defined ontology list. Given each turn of user utterance and\nsystem response, we directly generate a sequence of belief states by applying a\nhierarchical encoder-decoder structure. In this way, the computational\ncomplexity of our model will be a constant regardless of the number of\npre-defined slots. Experiments on both the multi-domain and the single domain\ndialogue state tracking dataset show that our model not only scales easily with\nthe increasing number of pre-defined domains and slots but also reaches the\nstate-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 15:00:08 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 04:25:31 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Ren", "Liliang", ""], ["Ni", "Jianmo", ""], ["McAuley", "Julian", ""]]}, {"id": "1909.00764", "submitter": "Michihiro Yasunaga", "authors": "Kokil Jaidka, Michihiro Yasunaga, Muthu Kumar Chandrasekaran, Dragomir\n  Radev, and Min-Yen Kan", "title": "The CL-SciSumm Shared Task 2018: Results and Key Insights", "comments": "BIRNDL @ SIGIR 2018. arXiv admin note: substantial text overlap with\n  arXiv:1907.09854", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This overview describes the official results of the CL-SciSumm Shared Task\n2018 -- the first medium-scale shared task on scientific document summarization\nin the computational linguistics (CL) domain. This year, the dataset comprised\n60 annotated sets of citing and reference papers from the open access research\npapers in the CL domain. The Shared Task was organized as a part of the 41st\nAnnual Conference of the Special Interest Group in Information Retrieval\n(SIGIR), held in Ann Arbor, USA in July 2018. We compare the participating\nsystems in terms of two evaluation metrics. The annotated dataset and\nevaluation scripts can be accessed and used by the community from:\n\\url{https://github.com/WING-NUS/scisumm-corpus}.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 15:23:55 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Jaidka", "Kokil", ""], ["Yasunaga", "Michihiro", ""], ["Chandrasekaran", "Muthu Kumar", ""], ["Radev", "Dragomir", ""], ["Kan", "Min-Yen", ""]]}, {"id": "1909.00786", "submitter": "Rui Zhang", "authors": "Rui Zhang, Tao Yu, He Yang Er, Sungrok Shim, Eric Xue, Xi Victoria\n  Lin, Tianze Shi, Caiming Xiong, Richard Socher, Dragomir Radev", "title": "Editing-Based SQL Query Generation for Cross-Domain Context-Dependent\n  Questions", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the cross-domain context-dependent text-to-SQL generation task.\nBased on the observation that adjacent natural language questions are often\nlinguistically dependent and their corresponding SQL queries tend to overlap,\nwe utilize the interaction history by editing the previous predicted query to\nimprove the generation quality. Our editing mechanism views SQL as sequences\nand reuses generation results at the token level in a simple manner. It is\nflexible to change individual tokens and robust to error propagation.\nFurthermore, to deal with complex table structures in different domains, we\nemploy an utterance-table encoder and a table-aware decoder to incorporate the\ncontext of the user utterance and the table schema. We evaluate our approach on\nthe SParC dataset and demonstrate the benefit of editing compared with the\nstate-of-the-art baselines which generate SQL from scratch. Our code is\navailable at https://github.com/ryanzhumich/sparc_atis_pytorch.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 16:24:57 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 00:40:29 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Zhang", "Rui", ""], ["Yu", "Tao", ""], ["Er", "He Yang", ""], ["Shim", "Sungrok", ""], ["Xue", "Eric", ""], ["Lin", "Xi Victoria", ""], ["Shi", "Tianze", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""], ["Radev", "Dragomir", ""]]}, {"id": "1909.00867", "submitter": "Mingzhi Yu", "authors": "Mingzhi Yu, Diane Litman and Susannah Paletz", "title": "Investigating the Relationship between Multi-Party Linguistic\n  Entrainment, Team Characteristics, and the Perception of Team Social Outcomes", "comments": "Proceedings 32nd International FLAIRS Conference, Sarasota, Florida,\n  May", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-party linguistic entrainment refers to the phenomenon that speakers\ntend to speak more similarly during conversation. We first developed new\nmeasures of multi-party entrainment on features describing linguistic style,\nand then examined the relationship between entrainment and team characteristics\nin terms of gender composition, team size, and diversity. Next, we predicted\nthe perception of team social outcomes using multi-party linguistic entrainment\nand team characteristics with a hierarchical regression model. We found that\nteams with greater gender diversity had higher minimum convergence than teams\nwith less gender diversity. Entrainment contributed significantly to predicting\nperceived team social outcomes both alone and controlling for team\ncharacteristics.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 21:04:39 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Yu", "Mingzhi", ""], ["Litman", "Diane", ""], ["Paletz", "Susannah", ""]]}, {"id": "1909.00868", "submitter": "Bohan Li", "authors": "Bohan Li, Junxian He, Graham Neubig, Taylor Berg-Kirkpatrick, Yiming\n  Yang", "title": "A Surprisingly Effective Fix for Deep Latent Variable Modeling of Text", "comments": "EMNLP 2019 short paper. The first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When trained effectively, the Variational Autoencoder (VAE) is both a\npowerful language model and an effective representation learning framework. In\npractice, however, VAEs are trained with the evidence lower bound (ELBO) as a\nsurrogate objective to the intractable marginal data likelihood. This approach\nto training yields unstable results, frequently leading to a disastrous local\noptimum known as posterior collapse. In this paper, we investigate a simple fix\nfor posterior collapse which yields surprisingly effective results. The\ncombination of two known heuristics, previously considered only in isolation,\nsubstantially improves held-out likelihood, reconstruction, and latent\nrepresentation learning when compared with previous state-of-the-art methods.\nMore interestingly, while our experiments demonstrate superiority on these\nprinciple evaluations, our method obtains a worse ELBO. We use these results to\nargue that the typical surrogate objective for VAEs may not be sufficient or\nnecessarily appropriate for balancing the goals of representation learning and\ndata distribution modeling.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 21:08:00 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Li", "Bohan", ""], ["He", "Junxian", ""], ["Neubig", "Graham", ""], ["Berg-Kirkpatrick", "Taylor", ""], ["Yang", "Yiming", ""]]}, {"id": "1909.00871", "submitter": "Rowan Hall Maudslay", "authors": "Rowan Hall Maudslay, Hila Gonen, Ryan Cotterell, Simone Teufel", "title": "It's All in the Name: Mitigating Gender Bias with Name-Based\n  Counterfactual Data Substitution", "comments": "Correction to proof in appendix and minor changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper treats gender bias latent in word embeddings. Previous mitigation\nattempts rely on the operationalisation of gender bias as a projection over a\nlinear subspace. An alternative approach is Counterfactual Data Augmentation\n(CDA), in which a corpus is duplicated and augmented to remove bias, e.g. by\nswapping all inherently-gendered words in the copy. We perform an empirical\ncomparison of these approaches on the English Gigaword and Wikipedia, and find\nthat whilst both successfully reduce direct bias and perform well in tasks\nwhich quantify embedding quality, CDA variants outperform projection-based\nmethods at the task of drawing non-biased gender analogies by an average of 19%\nacross both corpora. We propose two improvements to CDA: Counterfactual Data\nSubstitution (CDS), a variant of CDA in which potentially biased text is\nrandomly substituted to avoid duplication, and the Names Intervention, a novel\nname-pairing technique that vastly increases the number of words being treated.\nCDA/S with the Names Intervention is the only approach which is able to\nmitigate indirect gender bias: following debiasing, previously biased words are\nsignificantly less clustered according to gender (cluster purity is reduced by\n49%), thus improving on the state-of-the-art for bias mitigation.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 21:33:03 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 19:37:55 GMT"}, {"version": "v3", "created": "Wed, 5 Feb 2020 12:11:16 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Maudslay", "Rowan Hall", ""], ["Gonen", "Hila", ""], ["Cotterell", "Ryan", ""], ["Teufel", "Simone", ""]]}, {"id": "1909.00876", "submitter": "Mingzhi Yu", "authors": "Mingzhi Yu, Emer Gilmartin and Diane Litman", "title": "Identifying Personality Traits Using Overlap Dynamics in Multiparty\n  Dialogue", "comments": "Proceedings Interspeech 2019, Graz, Austria, September", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on human spoken language has shown that speech plays an important\nrole in identifying speaker personality traits. In this work, we propose an\napproach for identifying speaker personality traits using overlap dynamics in\nmultiparty spoken dialogues. We first define a set of novel features\nrepresenting the overlap dynamics of each speaker. We then investigate the\nimpact of speaker personality traits on these features using ANOVA tests. We\nfind that features of overlap dynamics significantly vary for speakers with\ndifferent levels of both Extraversion and Conscientiousness. Finally, we find\nthat classifiers using only overlap dynamics features outperform random\nguessing in identifying Extraversion and Agreeableness, and that the\nimprovements are statistically significant.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 21:50:52 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Yu", "Mingzhi", ""], ["Gilmartin", "Emer", ""], ["Litman", "Diane", ""]]}, {"id": "1909.00923", "submitter": "Shengluan Hou", "authors": "Ruqian Lu and Shengluan Hou and Chuanqing Wang and Yu Huang and\n  Chaoqun Fei and Songmao Zhang", "title": "Attributed Rhetorical Structure Grammar for Domain Text Summarization", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new approach of automatic text summarization which\ncombines domain oriented text analysis (DoTA) and rhetorical structure theory\n(RST) in a grammar form: the attributed rhetorical structure grammar (ARSG),\nwhere the non-terminal symbols are domain keywords, called domain relations,\nwhile the rhetorical relations serve as attributes. We developed machine\nlearning algorithms for learning such a grammar from a corpus of sample domain\ntexts, as well as parsing algorithms for the learned grammar, together with\nadjustable text summarization algorithms for generating domain specific\nsummaries. Our practical experiments have shown that with support of domain\nknowledge the drawback of missing very large training data set can be\neffectively compensated. We have also shown that the knowledge based approach\nmay be made more powerful by introducing grammar parsing and RST as inference\nengine. For checking the feasibility of model transfer, we introduced a\ntechnique for mapping a grammar from one domain to others with acceptable cost.\nWe have also made a comprehensive comparison of our approach with some others.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 02:31:47 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Lu", "Ruqian", ""], ["Hou", "Shengluan", ""], ["Wang", "Chuanqing", ""], ["Huang", "Yu", ""], ["Fei", "Chaoqun", ""], ["Zhang", "Songmao", ""]]}, {"id": "1909.00925", "submitter": "Oluwatobi Olabiyi", "authors": "Oluwatobi Olabiyi, Erik T. Mueller, Christopher Larson, Tarek Lahlou", "title": "Adversarial Bootstrapping for Dialogue Model Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Open domain neural dialogue models, despite their successes, are known to\nproduce responses that lack relevance, diversity, and in many cases coherence.\nThese shortcomings stem from the limited ability of common training objectives\nto directly express these properties as well as their interplay with training\ndatasets and model architectures. Toward addressing these problems, this paper\nproposes bootstrapping a dialogue response generator with an adversarially\ntrained discriminator. The method involves training a neural generator in both\nautoregressive and traditional teacher-forcing modes, with the maximum\nlikelihood loss of the auto-regressive outputs weighted by the score from a\nmetric-based discriminator model. The discriminator input is a mixture of\nground truth labels, the teacher-forcing outputs of the generator, and\ndistractors sampled from the dataset, thereby allowing for richer feedback on\nthe autoregressive outputs of the generator. To improve the calibration of the\ndiscriminator output, we also bootstrap the discriminator with the matching of\nthe intermediate features of the ground truth and the generator's\nautoregressive output. We explore different sampling and adversarial policy\noptimization strategies during training in order to understand how to encourage\nresponse diversity without sacrificing relevance. Our experiments shows that\nadversarial bootstrapping is effective at addressing exposure bias, leading to\nimprovement in response relevance and coherence. The improvement is\ndemonstrated with the state-of-the-art results on the Movie and Ubuntu dialogue\ndatasets with respect to human evaluations and BLUE, ROGUE, and distinct n-gram\nscores.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 02:45:28 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 18:23:54 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Olabiyi", "Oluwatobi", ""], ["Mueller", "Erik T.", ""], ["Larson", "Christopher", ""], ["Lahlou", "Tarek", ""]]}, {"id": "1909.00930", "submitter": "Bailin Wang", "authors": "Bailin Wang, Wei Lu", "title": "Combining Spans into Entities: A Neural Two-Stage Approach for\n  Recognizing Discontiguous Entities", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In medical documents, it is possible that an entity of interest not only\ncontains a discontiguous sequence of words but also overlaps with another\nentity. Entities of such structures are intrinsically hard to recognize due to\nthe large space of possible entity combinations. In this work, we propose a\nneural two-stage approach to recognize discontiguous and overlapping entities\nby decomposing this problem into two subtasks: 1) it first detects all the\noverlapping spans that either form entities on their own or present as segments\nof discontiguous entities, based on the representation of segmental hypergraph,\n2) next it learns to combine these segments into discontiguous entities with a\nclassifier, which filters out other incorrect combinations of segments. Two\nneural components are designed for these subtasks respectively and they are\nlearned jointly using a shared encoder for text. Our model achieves the\nstate-of-the-art performance in a standard dataset, even in the absence of\nexternal features that previous methods used.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 02:59:21 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Wang", "Bailin", ""], ["Lu", "Wei", ""]]}, {"id": "1909.00931", "submitter": "Yuki Arase", "authors": "Yuki Arase and Junichi Tsujii", "title": "Transfer Fine-Tuning: A BERT Case Study", "comments": "Accepted at the Conference on Empirical Methods in Natural Language\n  Processing (EMNLP 2019) *Retitled from \"Injecting Phrasal Paraphrase Relation\n  into Sentence Representation for Semantic Equivalence Assessment\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A semantic equivalence assessment is defined as a task that assesses semantic\nequivalence in a sentence pair by binary judgment (i.e., paraphrase\nidentification) or grading (i.e., semantic textual similarity measurement). It\nconstitutes a set of tasks crucial for research on natural language\nunderstanding. Recently, BERT realized a breakthrough in sentence\nrepresentation learning (Devlin et al., 2019), which is broadly transferable to\nvarious NLP tasks. While BERT's performance improves by increasing its model\nsize, the required computational power is an obstacle preventing practical\napplications from adopting the technology. Herein, we propose to inject phrasal\nparaphrase relations into BERT in order to generate suitable representations\nfor semantic equivalence assessment instead of increasing the model size.\nExperiments on standard natural language understanding tasks confirm that our\nmethod effectively improves a smaller BERT model while maintaining the model\nsize. The generated model exhibits superior performance compared to a larger\nBERT model on semantic equivalence assessment tasks. Furthermore, it achieves\nlarger performance gains on tasks with limited training datasets for\nfine-tuning, which is a property desirable for transfer learning.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 03:06:46 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Arase", "Yuki", ""], ["Tsujii", "Junichi", ""]]}, {"id": "1909.00945", "submitter": "Ramesh Manuvinakurike", "authors": "Maike Paetzel, Ramesh Manuvinakurike", "title": "\"Can you say more about the location?\" The Development of a Pedagogical\n  Reference Resolution Agent", "comments": "Accepted at 1st workshop on dialogue for social good", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In an increasingly globalized world, geographic literacy is crucial. In this\npaper, we present a collaborative two-player game to improve people's ability\nto locate countries on the world map. We discuss two implementations of the\ngame: First, we created a web-based version which can be played with the\nremote-controlled agent Nellie. With the knowledge we gained from a large\nonline data collection, we re-implemented the game so it can be played\nface-to-face with the Furhat robot Neil. Our analysis shows that participants\nfound the game not just engaging to play, they also believe they gained lasting\nknowledge about the world map.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 04:16:28 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Paetzel", "Maike", ""], ["Manuvinakurike", "Ramesh", ""]]}, {"id": "1909.00964", "submitter": "Haoyang Huang", "authors": "Haoyang Huang, Yaobo Liang, Nan Duan, Ming Gong, Linjun Shou, Daxin\n  Jiang, Ming Zhou", "title": "Unicoder: A Universal Language Encoder by Pre-training with Multiple\n  Cross-lingual Tasks", "comments": "Accepted to EMNLP2019; 10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Unicoder, a universal language encoder that is insensitive to\ndifferent languages. Given an arbitrary NLP task, a model can be trained with\nUnicoder using training data in one language and directly applied to inputs of\nthe same task in other languages. Comparing to similar efforts such as\nMultilingual BERT and XLM, three new cross-lingual pre-training tasks are\nproposed, including cross-lingual word recovery, cross-lingual paraphrase\nclassification and cross-lingual masked language model. These tasks help\nUnicoder learn the mappings among different languages from more perspectives.\nWe also find that doing fine-tuning on multiple languages together can bring\nfurther improvement. Experiments are performed on two tasks: cross-lingual\nnatural language inference (XNLI) and cross-lingual question answering (XQA),\nwhere XLM is our baseline. On XNLI, 1.8% averaged accuracy improvement (on 15\nlanguages) is obtained. On XQA, which is a new cross-lingual dataset built by\nus, 5.5% averaged accuracy improvement (on French and German) is obtained.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 06:11:44 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 08:33:34 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Huang", "Haoyang", ""], ["Liang", "Yaobo", ""], ["Duan", "Nan", ""], ["Gong", "Ming", ""], ["Shou", "Linjun", ""], ["Jiang", "Daxin", ""], ["Zhou", "Ming", ""]]}, {"id": "1909.00986", "submitter": "Robin Jia", "authors": "Robin Jia and Aditi Raghunathan and Kerem G\\\"oksel and Percy Liang", "title": "Certified Robustness to Adversarial Word Substitutions", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art NLP models can often be fooled by adversaries that apply\nseemingly innocuous label-preserving transformations (e.g., paraphrasing) to\ninput text. The number of possible transformations scales exponentially with\ntext length, so data augmentation cannot cover all transformations of an input.\nThis paper considers one exponentially large family of label-preserving\ntransformations, in which every word in the input can be replaced with a\nsimilar word. We train the first models that are provably robust to all word\nsubstitutions in this family. Our training procedure uses Interval Bound\nPropagation (IBP) to minimize an upper bound on the worst-case loss that any\ncombination of word substitutions can induce. To evaluate models' robustness to\nthese transformations, we measure accuracy on adversarially chosen word\nsubstitutions applied to test examples. Our IBP-trained models attain $75\\%$\nadversarial accuracy on both sentiment analysis on IMDB and natural language\ninference on SNLI. In comparison, on IMDB, models trained normally and ones\ntrained with data augmentation achieve adversarial accuracy of only $8\\%$ and\n$35\\%$, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 07:29:48 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Jia", "Robin", ""], ["Raghunathan", "Aditi", ""], ["G\u00f6ksel", "Kerem", ""], ["Liang", "Percy", ""]]}, {"id": "1909.00997", "submitter": "Pritha Ganguly", "authors": "Nitesh Methani, Pritha Ganguly, Mitesh M. Khapra and Pratyush Kumar", "title": "PlotQA: Reasoning over Scientific Plots", "comments": "This is an extension of our previous arxiv paper \"Data Interpretation\n  over Plots\" and it is to be presented at WACV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing synthetic datasets (FigureQA, DVQA) for reasoning over plots do not\ncontain variability in data labels, real-valued data, or complex reasoning\nquestions. Consequently, proposed models for these datasets do not fully\naddress the challenge of reasoning over plots. In particular, they assume that\nthe answer comes either from a small fixed size vocabulary or from a bounding\nbox within the image. However, in practice, this is an unrealistic assumption\nbecause many questions require reasoning and thus have real-valued answers\nwhich appear neither in a small fixed size vocabulary nor in the image. In this\nwork, we aim to bridge this gap between existing datasets and real-world plots.\nSpecifically, we propose PlotQA with 28.9 million question-answer pairs over\n224,377 plots on data from real-world sources and questions based on\ncrowd-sourced question templates. Further, 80.76% of the out-of-vocabulary\n(OOV) questions in PlotQA have answers that are not in a fixed vocabulary.\nAnalysis of existing models on PlotQA reveals that they cannot deal with OOV\nquestions: their overall accuracy on our dataset is in single digits. This is\nnot surprising given that these models were not designed for such questions. As\na step towards a more holistic model which can address fixed vocabulary as well\nas OOV questions, we propose a hybrid approach: Specific questions are answered\nby choosing the answer from a fixed vocabulary or by extracting it from a\npredicted bounding box in the plot, while other questions are answered with a\ntable question-answering engine which is fed with a structured table generated\nby detecting visual elements from the image. On the existing DVQA dataset, our\nmodel has an accuracy of 58%, significantly improving on the highest reported\naccuracy of 46%. On PlotQA, our model has an accuracy of 22.52%, which is\nsignificantly better than state of the art models.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 08:23:51 GMT"}, {"version": "v2", "created": "Sat, 11 Jan 2020 08:45:36 GMT"}, {"version": "v3", "created": "Sat, 1 Feb 2020 06:56:30 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Methani", "Nitesh", ""], ["Ganguly", "Pritha", ""], ["Khapra", "Mitesh M.", ""], ["Kumar", "Pratyush", ""]]}, {"id": "1909.01007", "submitter": "Avishai Gretz", "authors": "Assaf Toledo, Shai Gretz, Edo Cohen-Karlik, Roni Friedman, Elad\n  Venezian, Dan Lahav, Michal Jacovi, Ranit Aharonov and Noam Slonim", "title": "Automatic Argument Quality Assessment -- New Datasets and Methods", "comments": "Published at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the task of automatic assessment of argument quality. To that end,\nwe actively collected 6.3k arguments, more than a factor of five compared to\npreviously examined data. Each argument was explicitly and carefully annotated\nfor its quality. In addition, 14k pairs of arguments were annotated\nindependently, identifying the higher quality argument in each pair. In spite\nof the inherent subjective nature of the task, both annotation schemes led to\nsurprisingly consistent results. We release the labeled datasets to the\ncommunity. Furthermore, we suggest neural methods based on a recently released\nlanguage model, for argument ranking as well as for argument-pair\nclassification. In the former task, our results are comparable to\nstate-of-the-art; in the latter task our results significantly outperform\nearlier methods.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 09:00:44 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Toledo", "Assaf", ""], ["Gretz", "Shai", ""], ["Cohen-Karlik", "Edo", ""], ["Friedman", "Roni", ""], ["Venezian", "Elad", ""], ["Lahav", "Dan", ""], ["Jacovi", "Michal", ""], ["Aharonov", "Ranit", ""], ["Slonim", "Noam", ""]]}, {"id": "1909.01013", "submitter": "Xuefeng Bai", "authors": "Xuefeng Bai and Yue Zhang and Hailong Cao and Tiejun Zhao", "title": "Duality Regularization for Unsupervised Bilingual Lexicon Induction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised bilingual lexicon induction naturally exhibits duality, which\nresults from symmetry in back-translation. For example, EN-IT and IT-EN\ninduction can be mutually primal and dual problems. Current state-of-the-art\nmethods, however, consider the two tasks independently. In this paper, we\npropose to train primal and dual models jointly, using regularizers to\nencourage consistency in back translation cycles. Experiments across 6 language\npairs show that the proposed method significantly outperforms competitive\nbaselines, obtaining the best-published results on a standard benchmark.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 09:22:11 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Bai", "Xuefeng", ""], ["Zhang", "Yue", ""], ["Cao", "Hailong", ""], ["Zhao", "Tiejun", ""]]}, {"id": "1909.01053", "submitter": "Michalina Strzyz", "authors": "Michalina Strzyz, David Vilares, Carlos G\\'omez-Rodr\\'iguez", "title": "Towards Making a Dependency Parser See", "comments": "Camera-ready version to appear at EMNLP 2019 (final peer-reviewed\n  manuscript). 8 pages (incl. appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore whether it is possible to leverage eye-tracking data in an RNN\ndependency parser (for English) when such information is only available during\ntraining, i.e., no aggregated or token-level gaze features are used at\ninference time. To do so, we train a multitask learning model that parses\nsentences as sequence labeling and leverages gaze features as auxiliary tasks.\nOur method also learns to train from disjoint datasets, i.e. it can be used to\ntest whether already collected gaze features are useful to improve the\nperformance on new non-gazed annotated treebanks. Accuracy gains are modest but\npositive, showing the feasibility of the approach. It can serve as a first step\ntowards architectures that can better leverage eye-tracking data or other\ncomplementary information available only for training sentences, possibly\nleading to improvements in syntactic parsing.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 10:42:35 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Strzyz", "Michalina", ""], ["Vilares", "David", ""], ["G\u00f3mez-Rodr\u00edguez", "Carlos", ""]]}, {"id": "1909.01059", "submitter": "Jamshid Mozafari", "authors": "Jamshid Mozafari, Mohammad Ali Nematbakhsh, Afsaneh Fatemi", "title": "Attention-based Pairwise Multi-Perspective Convolutional Neural Network\n  for Answer Selection in Question Answering", "comments": "13 pages, 11 figures, journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past few years, question answering and information retrieval systems\nhave become widely used. These systems attempt to find the answer of the asked\nquestions from raw text sources. A component of these systems is Answer\nSelection which selects the most relevant from candidate answers. Syntactic\nsimilarities were mostly used to compute the similarity, but in recent works,\ndeep neural networks have been used, making a significant improvement in this\nfield. In this research, a model is proposed to select the most relevant\nanswers to the factoid question from the candidate answers. The proposed model\nranks the candidate answers in terms of semantic and syntactic similarity to\nthe question, using convolutional neural networks. In this research, Attention\nmechanism and Sparse feature vector use the context-sensitive interactions\nbetween questions and answer sentence. Wide convolution increases the\nimportance of the interrogative word. Pairwise ranking is used to learn\ndifferentiable representations to distinguish positive and negative answers.\nOur model indicates strong performance on the TrecQA Raw beating previous\nstate-of-the-art systems by 1.4% in MAP and 1.1% in MRR while using the\nbenefits of no additional syntactic parsers and external tools. The results\nshow that using context-sensitive interactions between question and answer\nsentences can help to find the correct answer more accurately.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 10:58:01 GMT"}, {"version": "v2", "created": "Sat, 14 Sep 2019 13:50:06 GMT"}, {"version": "v3", "created": "Mon, 11 Nov 2019 19:33:34 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Mozafari", "Jamshid", ""], ["Nematbakhsh", "Mohammad Ali", ""], ["Fatemi", "Afsaneh", ""]]}, {"id": "1909.01063", "submitter": "Zhuosheng Zhang", "authors": "Zhuosheng Zhang, Zhen Meng, Hai Zhao", "title": "A Smart Sliding Chinese Pinyin Input Method Editor on Touchscreen", "comments": "There are some insufficient explanations that may confuse readers. We\n  will continue the research, but it will take a lot of time. After discussing\n  with co-authors, we decide to withdraw this version from ArXiv, instead of\n  replacement. We may re-upload a new version of this work in the future", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a smart sliding Chinese pinyin Input Method Editor (IME)\nfor touchscreen devices which allows user finger sliding from one key to\nanother on the touchscreen instead of tapping keys one by one, while the target\nChinese character sequence will be predicted during the sliding process to help\nuser input Chinese characters efficiently. Moreover, the layout of the virtual\nkeyboard of our IME adapts to user sliding for more efficient inputting. The\nlayout adaption process is utilized with Recurrent Neural Networks (RNN) and\ndeep reinforcement learning. The pinyin-to-character converter is implemented\nwith a sequence-to-sequence (Seq2Seq) model to predict the target Chinese\nsequence. A sliding simulator is built to automatically produce sliding samples\nfor model training and virtual keyboard test. The key advantage of our proposed\nIME is that nearly all its built-in tactics can be optimized automatically with\ndeep learning algorithms only following user behavior. Empirical studies verify\nthe effectiveness of the proposed model and show a better user input\nefficiency.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 11:04:19 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 02:10:38 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Zhang", "Zhuosheng", ""], ["Meng", "Zhen", ""], ["Zhao", "Hai", ""]]}, {"id": "1909.01065", "submitter": "Zhuosheng Zhang", "authors": "Zhuosheng Zhang, Bingjie Tang, Zuchao Li, Hai Zhao", "title": "Modeling Named Entity Embedding Distribution into Hypersphere", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work models named entity distribution from a way of visualizing\ntopological structure of embedding space, so that we make an assumption that\nmost, if not all, named entities (NEs) for a language tend to aggregate\ntogether to be accommodated by a specific hypersphere in embedding space. Thus\nwe present a novel open definition for NE which alleviates the obvious drawback\nin previous closed NE definition with a limited NE dictionary. Then, we show\ntwo applications with introducing the proposed named entity hypersphere model.\nFirst, using a generative adversarial neural network to learn a transformation\nmatrix of two embedding spaces, which results in a convenient determination of\nnamed entity distribution in the target language, indicating the potential of\nfast named entity discovery only using isomorphic relation between embedding\nspaces. Second, the named entity hypersphere model is directly integrated with\nvarious named entity recognition models over sentences to achieve\nstate-of-the-art results. Only assuming that embeddings are available, we show\na prior knowledge free approach on effective named entity distribution\ndepiction.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 11:09:12 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Zhang", "Zhuosheng", ""], ["Tang", "Bingjie", ""], ["Li", "Zuchao", ""], ["Zhao", "Hai", ""]]}, {"id": "1909.01066", "submitter": "Fabio Petroni", "authors": "Fabio Petroni, Tim Rockt\\\"aschel, Patrick Lewis, Anton Bakhtin,\n  Yuxiang Wu, Alexander H. Miller, Sebastian Riedel", "title": "Language Models as Knowledge Bases?", "comments": "accepted at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in pretraining language models on large textual corpora led\nto a surge of improvements for downstream NLP tasks. Whilst learning linguistic\nknowledge, these models may also be storing relational knowledge present in the\ntraining data, and may be able to answer queries structured as\n\"fill-in-the-blank\" cloze statements. Language models have many advantages over\nstructured knowledge bases: they require no schema engineering, allow\npractitioners to query about an open class of relations, are easy to extend to\nmore data, and require no human supervision to train. We present an in-depth\nanalysis of the relational knowledge already present (without fine-tuning) in a\nwide range of state-of-the-art pretrained language models. We find that (i)\nwithout fine-tuning, BERT contains relational knowledge competitive with\ntraditional NLP methods that have some access to oracle knowledge, (ii) BERT\nalso does remarkably well on open-domain question answering against a\nsupervised baseline, and (iii) certain types of factual knowledge are learned\nmuch more readily than others by standard language model pretraining\napproaches. The surprisingly strong ability of these models to recall factual\nknowledge without any fine-tuning demonstrates their potential as unsupervised\nopen-domain QA systems. The code to reproduce our analysis is available at\nhttps://github.com/facebookresearch/LAMA.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 11:11:08 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 09:33:20 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Petroni", "Fabio", ""], ["Rockt\u00e4schel", "Tim", ""], ["Lewis", "Patrick", ""], ["Bakhtin", "Anton", ""], ["Wu", "Yuxiang", ""], ["Miller", "Alexander H.", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1909.01093", "submitter": "Zhiqiang Ma", "authors": "Azadeh Nematzadeh, Grace Bang, Xiaomo Liu, Zhiqiang Ma", "title": "Empirical Study on Detecting Controversy in Social Media", "comments": "The work is accepted by the 2nd KDD Workshop on Anomaly Detection in\n  Finance, 2019. The authors contributed equally to this work, listed in the\n  alphabetical order", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Companies and financial investors are paying increasing attention to social\nconsciousness in developing their corporate strategies and making investment\ndecisions to support a sustainable economy for the future. Public discussion on\nincidents and events -- controversies -- of companies can provide valuable\ninsights on how well the company operates with regards to social consciousness\nand indicate the company's overall operational capability. However, there are\nchallenges in evaluating the degree of a company's social consciousness and\nenvironmental sustainability due to the lack of systematic data. We introduce a\nsystem that utilizes Twitter data to detect and monitor controversial events\nand show their impact on market volatility. In our study, controversial events\nare identified from clustered tweets that share the same 5W terms and sentiment\npolarities of these clusters. Credible news links inside the event tweets are\nused to validate the truth of the event. A case study on the Starbucks\nPhiladelphia arrests shows that this method can provide the desired\nfunctionality.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 18:36:55 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Nematzadeh", "Azadeh", ""], ["Bang", "Grace", ""], ["Liu", "Xiaomo", ""], ["Ma", "Zhiqiang", ""]]}, {"id": "1909.01101", "submitter": "Hao Xiong", "authors": "Tianchi Bi, Hao Xiong, Zhongjun He, Hua Wu and Haifeng Wang", "title": "Multi-agent Learning for Neural Machine Translation", "comments": "Accepted by EMNLP2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional Neural Machine Translation (NMT) models benefit from the\ntraining with an additional agent, e.g., dual learning, and bidirectional\ndecoding with one agent decoding from left to right and the other decoding in\nthe opposite direction. In this paper, we extend the training framework to the\nmulti-agent scenario by introducing diverse agents in an interactive updating\nprocess. At training time, each agent learns advanced knowledge from others,\nand they work together to improve translation quality. Experimental results on\nNIST Chinese-English, IWSLT 2014 German-English, WMT 2014 English-German and\nlarge-scale Chinese-English translation tasks indicate that our approach\nachieves absolute improvements over the strong baseline systems and shows\ncompetitive performance on all tasks.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 11:55:59 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Bi", "Tianchi", ""], ["Xiong", "Hao", ""], ["He", "Zhongjun", ""], ["Wu", "Hua", ""], ["Wang", "Haifeng", ""]]}, {"id": "1909.01120", "submitter": "Saravanan Thirumuruganathan", "authors": "Riccardo Cappuzzo, Paolo Papotti, Saravanan Thirumuruganathan", "title": "Local Embeddings for Relational Data Integration", "comments": "Accepted to SIGMOD 2020 as Creating Embeddings of Heterogeneous\n  Relational Datasets for Data Integration Tasks. Code can be found at\n  https://gitlab.eurecom.fr/cappuzzo/embdi", "journal-ref": null, "doi": "10.1145/3318464.3389742", "report-no": null, "categories": "cs.DB cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning based techniques have been recently used with promising results\nfor data integration problems. Some methods directly use pre-trained embeddings\nthat were trained on a large corpus such as Wikipedia. However, they may not\nalways be an appropriate choice for enterprise datasets with custom vocabulary.\nOther methods adapt techniques from natural language processing to obtain\nembeddings for the enterprise's relational data. However, this approach blindly\ntreats a tuple as a sentence, thus losing a large amount of contextual\ninformation present in the tuple.\n  We propose algorithms for obtaining local embeddings that are effective for\ndata integration tasks on relational databases. We make four major\ncontributions. First, we describe a compact graph-based representation that\nallows the specification of a rich set of relationships inherent in the\nrelational world. Second, we propose how to derive sentences from such a graph\nthat effectively \"describe\" the similarity across elements (tokens, attributes,\nrows) in the two datasets. The embeddings are learned based on such sentences.\nThird, we propose effective optimization to improve the quality of the learned\nembeddings and the performance of integration tasks. Finally, we propose a\ndiverse collection of criteria to evaluate relational embeddings and perform an\nextensive set of experiments validating them against multiple baseline methods.\nOur experiments show that our framework, EmbDI, produces meaningful results for\ndata integration tasks such as schema matching and entity resolution both in\nsupervised and unsupervised settings.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 12:45:02 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 08:56:00 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Cappuzzo", "Riccardo", ""], ["Papotti", "Paolo", ""], ["Thirumuruganathan", "Saravanan", ""]]}, {"id": "1909.01135", "submitter": "Chidimma Opara", "authors": "Chidimma Opara, Bo Wei, and Yingke Chen", "title": "HTMLPhish: Enabling Phishing Web Page Detection by Applying Deep\n  Learning Techniques on HTML Analysis", "comments": null, "journal-ref": "International Joint Conference on Neural Networks (IJCNN) 2020", "doi": "10.1109/IJCNN48605.2020.9207707", "report-no": null, "categories": "cs.CR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the development and implementation of phishing attacks require\nlittle technical skills and costs. This uprising has led to an ever-growing\nnumber of phishing attacks on the World Wide Web. Consequently, proactive\ntechniques to fight phishing attacks have become extremely necessary. In this\npaper, we propose HTMLPhish, a deep learning based data-driven end-to-end\nautomatic phishing web page classification approach. Specifically, HTMLPhish\nreceives the content of the HTML document of a web page and employs\nConvolutional Neural Networks (CNNs) to learn the semantic dependencies in the\ntextual contents of the HTML. The CNNs learn appropriate feature\nrepresentations from the HTML document embeddings without extensive manual\nfeature engineering. Furthermore, our proposed approach of the concatenation of\nthe word and character embeddings allows our model to manage new features and\nensure easy extrapolation to test data. We conduct comprehensive experiments on\na dataset of more than 50,000 HTML documents that provides a distribution of\nphishing to benign web pages obtainable in the real-world that yields over 93\npercent Accuracy and True Positive Rate. Also, HTMLPhish is a completely\nlanguage-independent and client-side strategy which can, therefore, conduct web\npage phishing detection regardless of the textual language.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 23:58:50 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 17:10:56 GMT"}, {"version": "v3", "created": "Fri, 15 May 2020 10:30:32 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Opara", "Chidimma", ""], ["Wei", "Bo", ""], ["Chen", "Yingke", ""]]}, {"id": "1909.01136", "submitter": "Binbin Xu", "authors": "Binbin Xu and C\\'edric Gil-Jardin\\'e and Frantz Thiessard and Eric\n  Tellier and Marta Avalos and Emmanuel Lagarde", "title": "Pre-training A Neural Language Model Improves The Sample Efficiency of\n  an Emergency Room Classification Model", "comments": "Version of the published manuscript", "journal-ref": "The 33rd Florida Artificial Intelligence Research Society\n  Conference, 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To build a French national electronic injury surveillance system based on\nemergency room visits, we aim to develop a coding system to classify their\ncauses from clinical notes in free-text. Supervised learning techniques have\nshown good results in this area but require a large amount of expert annotated\ndataset which is time consuming and costly to obtain. We hypothesize that the\nNatural Language Processing Transformer model incorporating a generative\nself-supervised pre-training step can significantly reduce the required number\nof annotated samples for supervised fine-tuning. In this preliminary study, we\ntest our hypothesis in the simplified problem of predicting whether a visit is\nthe consequence of a traumatic event or not from free-text clinical notes.\nUsing fully re-trained GPT-2 models (without OpenAI pre-trained weights), we\nassess the gain of applying a self-supervised pre-training phase with unlabeled\nnotes prior to the supervised learning task. Results show that the number of\ndata required to achieve a ginve level of performance (AUC>0.95) was reduced by\na factor of 10 when applying pre-training. Namely, for 16 times more data, the\nfully-supervised model achieved an improvement <1% in AUC. To conclude, it is\npossible to adapt a multi-purpose neural language model such as the GPT-2 to\ncreate a powerful tool for classification of free-text notes with only a small\nnumber of labeled samples.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 17:25:06 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 16:16:29 GMT"}, {"version": "v3", "created": "Fri, 13 Sep 2019 14:47:26 GMT"}, {"version": "v4", "created": "Thu, 24 Oct 2019 12:19:14 GMT"}, {"version": "v5", "created": "Wed, 7 Apr 2021 09:33:10 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Xu", "Binbin", ""], ["Gil-Jardin\u00e9", "C\u00e9dric", ""], ["Thiessard", "Frantz", ""], ["Tellier", "Eric", ""], ["Avalos", "Marta", ""], ["Lagarde", "Emmanuel", ""]]}, {"id": "1909.01145", "submitter": "Peng Liu", "authors": "Peng Liu, Xixin Wu, Shiyin Kang, Guangzhi Li, Dan Su, Dong Yu", "title": "Maximizing Mutual Information for Tacotron", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end speech synthesis methods already achieve close-to-human quality\nperformance. However compared to HMM-based and NN-based frame-to-frame\nregression methods, they are prone to some synthesis errors, such as missing or\nrepeating words and incomplete synthesis. We attribute the comparatively high\nutterance error rate to the local information preference of conditional\nautoregressive models, and the ill-posed training objective of the model, which\ndescribes mostly the training status of the autoregressive module, but rarely\nthat of the condition module. Inspired by InfoGAN, we propose to maximize the\nmutual information between the text condition and the predicted acoustic\nfeatures to strengthen the dependency between them for CAR speech synthesis\nmodel, which would alleviate the local information preference issue and reduce\nthe utterance error rate. The training objective of maximizing mutual\ninformation can be considered as a metric of the dependency between the\nautoregressive module and the condition module. Experiment results show that\nour method can reduce the utterance error rate.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 04:03:14 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 07:24:35 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Liu", "Peng", ""], ["Wu", "Xixin", ""], ["Kang", "Shiyin", ""], ["Li", "Guangzhi", ""], ["Su", "Dan", ""], ["Yu", "Dong", ""]]}, {"id": "1909.01146", "submitter": "Jeffrey Cheng", "authors": "Jeffrey Cheng and Chris Callison-Burch", "title": "Bilingual is At Least Monolingual (BALM): A Novel Translation Algorithm\n  that Encodes Monolingual Priors", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art machine translation (MT) models do not use knowledge of any\nsingle language's structure; this is the equivalent of asking someone to\ntranslate from English to German while knowing neither language. BALM is a\nframework incorporates monolingual priors into an MT pipeline; by casting input\nand output languages into embedded space using BERT, we can solve machine\ntranslation with much simpler models. We find that English-to-German\ntranslation on the Multi30k dataset can be solved with a simple feedforward\nnetwork under the BALM framework with near-SOTA BLEU scores.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 03:16:10 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Cheng", "Jeffrey", ""], ["Callison-Burch", "Chris", ""]]}, {"id": "1909.01187", "submitter": "Eric Malmi", "authors": "Eric Malmi, Sebastian Krause, Sascha Rothe, Daniil Mirylenka, Aliaksei\n  Severyn", "title": "Encode, Tag, Realize: High-Precision Text Editing", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose LaserTagger - a sequence tagging approach that casts text\ngeneration as a text editing task. Target texts are reconstructed from the\ninputs using three main edit operations: keeping a token, deleting it, and\nadding a phrase before the token. To predict the edit operations, we propose a\nnovel model, which combines a BERT encoder with an autoregressive Transformer\ndecoder. This approach is evaluated on English text on four tasks: sentence\nfusion, sentence splitting, abstractive summarization, and grammar correction.\nLaserTagger achieves new state-of-the-art results on three of these tasks,\nperforms comparably to a set of strong seq2seq baselines with a large number of\ntraining examples, and outperforms them when the number of examples is limited.\nFurthermore, we show that at inference time tagging can be more than two orders\nof magnitude faster than comparable seq2seq models, making it more attractive\nfor running in a live environment.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 13:54:52 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Malmi", "Eric", ""], ["Krause", "Sebastian", ""], ["Rothe", "Sascha", ""], ["Mirylenka", "Daniil", ""], ["Severyn", "Aliaksei", ""]]}, {"id": "1909.01214", "submitter": "Yang Gao", "authors": "Florian B\\\"ohm and Yang Gao and Christian M. Meyer and Ori Shapira and\n  Ido Dagan and Iryna Gurevych", "title": "Better Rewards Yield Better Summaries: Learning to Summarise Without\n  References", "comments": "Accepted to EMNLP2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) based document summarisation systems yield\nstate-of-the-art performance in terms of ROUGE scores, because they directly\nuse ROUGE as the rewards during training. However, summaries with high ROUGE\nscores often receive low human judgement. To find a better reward function that\ncan guide RL to generate human-appealing summaries, we learn a reward function\nfrom human ratings on 2,500 summaries. Our reward function only takes the\ndocument and system summary as input. Hence, once trained, it can be used to\ntrain RL-based summarisation systems without using any reference summaries. We\nshow that our learned rewards have significantly higher correlation with human\nratings than previous approaches. Human evaluation experiments show that,\ncompared to the state-of-the-art supervised-learning systems and\nROUGE-as-rewards RL summarisation systems, the RL systems using our learned\nrewards during training generate summarieswith higher human ratings. The\nlearned reward function and our source code are available at\nhttps://github.com/yg211/summary-reward-no-reference.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 14:30:13 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["B\u00f6hm", "Florian", ""], ["Gao", "Yang", ""], ["Meyer", "Christian M.", ""], ["Shapira", "Ori", ""], ["Dagan", "Ido", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1909.01247", "submitter": "Stefan Daniel Dumitrescu", "authors": "Stefan Daniel Dumitrescu and Andrei-Marius Avram", "title": "Introducing RONEC -- the Romanian Named Entity Corpus", "comments": "8 pages + annex, accepted to LREC2020 in the main conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present RONEC - the Named Entity Corpus for the Romanian language. The\ncorpus contains over 26000 entities in ~5000 annotated sentences, belonging to\n16 distinct classes. The sentences have been extracted from a copy-right free\nnewspaper, covering several styles. This corpus represents the first initiative\nin the Romanian language space specifically targeted for named entity\nrecognition. It is available in BRAT and CoNLL-U Plus formats, and it is free\nto use and extend at github.com/dumitrescustefan/ronec .\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 15:20:44 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 16:34:28 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Dumitrescu", "Stefan Daniel", ""], ["Avram", "Andrei-Marius", ""]]}, {"id": "1909.01259", "submitter": "Ikuya Yamada", "authors": "Ikuya Yamada, Hiroyuki Shindo", "title": "Neural Attentive Bag-of-Entities Model for Text Classification", "comments": "Accepted to CoNLL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study proposes a Neural Attentive Bag-of-Entities model, which is a\nneural network model that performs text classification using entities in a\nknowledge base. Entities provide unambiguous and relevant semantic signals that\nare beneficial for capturing semantics in texts. We combine simple high-recall\nentity detection based on a dictionary, to detect entities in a document, with\na novel neural attention mechanism that enables the model to focus on a small\nnumber of unambiguous and relevant entities. We tested the effectiveness of our\nmodel using two standard text classification datasets (i.e., the 20 Newsgroups\nand R8 datasets) and a popular factoid question answering dataset based on a\ntrivia quiz game. As a result, our model achieved state-of-the-art results on\nall datasets. The source code of the proposed model is available online at\nhttps://github.com/wikipedia2vec/wikipedia2vec.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 15:50:34 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 10:23:49 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Yamada", "Ikuya", ""], ["Shindo", "Hiroyuki", ""]]}, {"id": "1909.01276", "submitter": "Lukasz Augustyniak", "authors": "{\\L}ukasz Augustyniak, Tomasz Kajdanowicz, Przemys{\\l}aw Kazienko", "title": "Aspect Detection using Word and Char Embeddings with (Bi)LSTM and CRF", "comments": "IEEE AIKE", "journal-ref": "2019 IEEE Second International Conference on Artificial\n  Intelligence and Knowledge Engineering (AIKE), Sardinia, Italy, 2019, pp.\n  43-50", "doi": "10.1109/AIKE.2019.00016", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We proposed a~new accurate aspect extraction method that makes use of both\nword and character-based embeddings. We have conducted experiments of various\nmodels of aspect extraction using LSTM and BiLSTM including CRF enhancement on\nfive different pre-trained word embeddings extended with character embeddings.\nThe results revealed that BiLSTM outperforms regular LSTM, but also word\nembedding coverage in train and test sets profoundly impacted aspect detection\nperformance. Moreover, the additional CRF layer consistently improves the\nresults across different models and text embeddings. Summing up, we obtained\nstate-of-the-art F-score results for SemEval Restaurants (85%) and Laptops\n(80%).\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 16:16:00 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Augustyniak", "\u0141ukasz", ""], ["Kajdanowicz", "Tomasz", ""], ["Kazienko", "Przemys\u0142aw", ""]]}, {"id": "1909.01296", "submitter": "Ivan Vuli\\'c", "authors": "Matthew Henderson, Ivan Vuli\\'c, I\\~nigo Casanueva, Pawe{\\l}\n  Budzianowski, Daniela Gerz, Sam Coope, Georgios Spithourakis, Tsung-Hsien\n  Wen, Nikola Mrk\\v{s}i\\'c, Pei-Hao Su", "title": "PolyResponse: A Rank-based Approach to Task-Oriented Dialogue with\n  Application in Restaurant Search and Booking", "comments": "EMNLP 2019 (Demo paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present PolyResponse, a conversational search engine that supports\ntask-oriented dialogue. It is a retrieval-based approach that bypasses the\ncomplex multi-component design of traditional task-oriented dialogue systems\nand the use of explicit semantics in the form of task-specific ontologies. The\nPolyResponse engine is trained on hundreds of millions of examples extracted\nfrom real conversations: it learns what responses are appropriate in different\nconversational contexts. It then ranks a large index of text and visual\nresponses according to their similarity to the given context, and narrows down\nthe list of relevant entities during the multi-turn conversation. We introduce\na restaurant search and booking system powered by the PolyResponse engine,\ncurrently available in 8 different languages.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 16:40:24 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Henderson", "Matthew", ""], ["Vuli\u0107", "Ivan", ""], ["Casanueva", "I\u00f1igo", ""], ["Budzianowski", "Pawe\u0142", ""], ["Gerz", "Daniela", ""], ["Coope", "Sam", ""], ["Spithourakis", "Georgios", ""], ["Wen", "Tsung-Hsien", ""], ["Mrk\u0161i\u0107", "Nikola", ""], ["Su", "Pei-Hao", ""]]}, {"id": "1909.01322", "submitter": "Shikib Mehri", "authors": "Shikib Mehri, Alan W Black and Maxine Eskenazi", "title": "CMU GetGoing: An Understandable and Memorable Dialog System for Seniors", "comments": "Accepted to the Dialog for Good (DiGo) workshop\n  (http://dialogforgood.org) at SIGDial 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice-based technologies are typically developed for the average user, and\nthus generally not tailored to the specific needs of any subgroup of the\npopulation, like seniors. This paper presents CMU GetGoing, an accessible trip\nplanning dialog system designed for senior users. The GetGoing system design is\ndescribed in detail, with particular attention to the senior-tailored features.\nA user study is presented, demonstrating that the senior-tailored features\nsignificantly improve comprehension and retention of information.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 17:35:27 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Mehri", "Shikib", ""], ["Black", "Alan W", ""], ["Eskenazi", "Maxine", ""]]}, {"id": "1909.01326", "submitter": "Emily Sheng", "authors": "Emily Sheng, Kai-Wei Chang, Premkumar Natarajan, Nanyun Peng", "title": "The Woman Worked as a Babysitter: On Biases in Language Generation", "comments": "EMNLP 2019 short paper (5 pages); Updated references and examples,\n  changed figure 2 & 3 order, fixed grammar, results unmodified", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a systematic study of biases in natural language generation (NLG)\nby analyzing text generated from prompts that contain mentions of different\ndemographic groups. In this work, we introduce the notion of the regard towards\na demographic, use the varying levels of regard towards different demographics\nas a defining metric for bias in NLG, and analyze the extent to which sentiment\nscores are a relevant proxy metric for regard. To this end, we collect\nstrategically-generated text from language models and manually annotate the\ntext with both sentiment and regard scores. Additionally, we build an automatic\nregard classifier through transfer learning, so that we can analyze biases in\nunseen text. Together, these methods reveal the extent of the biased nature of\nlanguage model generations. Our analysis provides a study of biases in NLG,\nbias metrics and correlated human judgments, and empirical evidence on the\nusefulness of our annotated dataset.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 17:50:44 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 18:55:16 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Sheng", "Emily", ""], ["Chang", "Kai-Wei", ""], ["Natarajan", "Premkumar", ""], ["Peng", "Nanyun", ""]]}, {"id": "1909.01362", "submitter": "Jonathan Chang", "authors": "Jonathan P. Chang and Cristian Danescu-Niculescu-Mizil", "title": "Trouble on the Horizon: Forecasting the Derailment of Online\n  Conversations as they Develop", "comments": "To appear in Proceedings of EMNLP 2019. Data and code to be released\n  as part of the Cornell Conversational Analysis Toolkit (convokit.cornell.edu)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.HC physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online discussions often derail into toxic exchanges between participants.\nRecent efforts mostly focused on detecting antisocial behavior after the fact,\nby analyzing single comments in isolation. To provide more timely notice to\nhuman moderators, a system needs to preemptively detect that a conversation is\nheading towards derailment before it actually turns toxic. This means modeling\nderailment as an emerging property of a conversation rather than as an isolated\nutterance-level event.\n  Forecasting emerging conversational properties, however, poses several\ninherent modeling challenges. First, since conversations are dynamic, a\nforecasting model needs to capture the flow of the discussion, rather than\nproperties of individual comments. Second, real conversations have an unknown\nhorizon: they can end or derail at any time; thus a practical forecasting model\nneeds to assess the risk in an online fashion, as the conversation develops. In\nthis work we introduce a conversational forecasting model that learns an\nunsupervised representation of conversational dynamics and exploits it to\npredict future derailment as the conversation develops. By applying this model\nto two new diverse datasets of online conversations with labels for antisocial\nevents, we show that it outperforms state-of-the-art systems at forecasting\nderailment.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 18:00:05 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Chang", "Jonathan P.", ""], ["Danescu-Niculescu-Mizil", "Cristian", ""]]}, {"id": "1909.01380", "submitter": "Elena Voita", "authors": "Elena Voita, Rico Sennrich, Ivan Titov", "title": "The Bottom-up Evolution of Representations in the Transformer: A Study\n  with Machine Translation and Language Modeling Objectives", "comments": "EMNLP 2019 (camera-ready)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We seek to understand how the representations of individual tokens and the\nstructure of the learned feature space evolve between layers in deep neural\nnetworks under different learning objectives. We focus on the Transformers for\nour analysis as they have been shown effective on various tasks, including\nmachine translation (MT), standard left-to-right language models (LM) and\nmasked language modeling (MLM). Previous work used black-box probing tasks to\nshow that the representations learned by the Transformer differ significantly\ndepending on the objective. In this work, we use canonical correlation analysis\nand mutual information estimators to study how information flows across\nTransformer layers and how this process depends on the choice of learning\nobjective. For example, as you go from bottom to top layers, information about\nthe past in left-to-right language models gets vanished and predictions about\nthe future get formed. In contrast, for MLM, representations initially acquire\ninformation about the context around the token, partially forgetting the token\nidentity and producing a more generalized token representation. The token\nidentity then gets recreated at the top MLM layers.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 18:06:03 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Voita", "Elena", ""], ["Sennrich", "Rico", ""], ["Titov", "Ivan", ""]]}, {"id": "1909.01383", "submitter": "Elena Voita", "authors": "Elena Voita, Rico Sennrich, Ivan Titov", "title": "Context-Aware Monolingual Repair for Neural Machine Translation", "comments": "EMNLP 2019 (camera-ready)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern sentence-level NMT systems often produce plausible translations of\nisolated sentences. However, when put in context, these translations may end up\nbeing inconsistent with each other. We propose a monolingual DocRepair model to\ncorrect inconsistencies between sentence-level translations. DocRepair performs\nautomatic post-editing on a sequence of sentence-level translations, refining\ntranslations of sentences in context of each other. For training, the DocRepair\nmodel requires only monolingual document-level data in the target language. It\nis trained as a monolingual sequence-to-sequence model that maps inconsistent\ngroups of sentences into consistent ones. The consistent groups come from the\noriginal training data; the inconsistent groups are obtained by sampling\nround-trip translations for each isolated sentence. We show that this approach\nsuccessfully imitates inconsistencies we aim to fix: using contrastive\nevaluation, we show large improvements in the translation of several contextual\nphenomena in an English-Russian translation task, as well as improvements in\nthe BLEU score. We also conduct a human evaluation and show a strong preference\nof the annotators to corrected translations over the baseline ones. Moreover,\nwe analyze which discourse phenomena are hard to capture using monolingual data\nonly.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 18:12:36 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 11:13:52 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Voita", "Elena", ""], ["Sennrich", "Rico", ""], ["Titov", "Ivan", ""]]}, {"id": "1909.01388", "submitter": "Weiyan Shi", "authors": "Weiyan Shi, Kun Qian, Xuewei Wang and Zhou Yu", "title": "How to Build User Simulators to Train RL-based Dialog Systems", "comments": "Long Paper Accepted by EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User simulators are essential for training reinforcement learning (RL) based\ndialog models. The performance of the simulator directly impacts the RL policy.\nHowever, building a good user simulator that models real user behaviors is\nchallenging. We propose a method of standardizing user simulator building that\ncan be used by the community to compare dialog system quality using the same\nset of user simulators fairly. We present implementations of six user\nsimulators trained with different dialog planning and generation methods. We\nthen calculate a set of automatic metrics to evaluate the quality of these\nsimulators both directly and indirectly. We also ask human users to assess the\nsimulators directly and indirectly by rating the simulated dialogs and\ninteracting with the trained systems. This paper presents a comprehensive\nevaluation framework for user simulator study and provides a better\nunderstanding of the pros and cons of different user simulators, as well as\ntheir impacts on the trained systems.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 18:22:24 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Shi", "Weiyan", ""], ["Qian", "Kun", ""], ["Wang", "Xuewei", ""], ["Yu", "Zhou", ""]]}, {"id": "1909.01401", "submitter": "Pengfei Sun", "authors": "Pengfei Sun and Gopala K. Anumanchipalli and Edward F. Chang", "title": "Brain2Char: A Deep Architecture for Decoding Text from Brain Recordings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decoding language representations directly from the brain can enable new\nBrain-Computer Interfaces (BCI) for high bandwidth human-human and\nhuman-machine communication. Clinically, such technologies can restore\ncommunication in people with neurological conditions affecting their ability to\nspeak. In this study, we propose a novel deep network architecture Brain2Char,\nfor directly decoding text (specifically character sequences) from direct brain\nrecordings (called Electrocorticography, ECoG). Brain2Char framework combines\nstate-of-the-art deep learning modules --- 3D Inception layers for multiband\nspatiotemporal feature extraction from neural data and bidirectional recurrent\nlayers, dilated convolution layers followed by language model weighted beam\nsearch to decode character sequences, optimizing a connectionist temporal\nclassification (CTC) loss. Additionally, given the highly non-linear\ntransformations that underlie the conversion of cortical function to character\nsequences, we perform regularizations on the network's latent representations\nmotivated by insights into cortical encoding of speech production and\nartifactual aspects specific to ECoG data acquisition. To do this, we impose\nauxiliary losses on latent representations for articulatory movements, speech\nacoustics and session specific non-linearities. In 3 participants tested here,\nBrain2Char achieves 10.6\\%, 8.5\\% and 7.0\\% Word Error Rates (WER) respectively\non vocabulary sizes ranging from 1200 to 1900 words. Brain2Char also performs\nwell when 2 participants silently mimed sentences. These results set a new\nstate-of-the-art on decoding text from brain and demonstrate the potential of\nBrain2Char as a high-performance communication BCI.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 18:54:43 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Sun", "Pengfei", ""], ["Anumanchipalli", "Gopala K.", ""], ["Chang", "Edward F.", ""]]}, {"id": "1909.01441", "submitter": "Zihan Wang", "authors": "Zihan Wang, Jingbo Shang, Liyuan Liu, Lihao Lu, Jiacheng Liu, Jiawei\n  Han", "title": "CrossWeigh: Training Named Entity Tagger from Imperfect Annotations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Everyone makes mistakes. So do human annotators when curating labels for\nnamed entity recognition (NER). Such label mistakes might hurt model training\nand interfere model comparison. In this study, we dive deep into one of the\nwidely-adopted NER benchmark datasets, CoNLL03 NER. We are able to identify\nlabel mistakes in about 5.38% test sentences, which is a significant ratio\nconsidering that the state-of-the-art test F1 score is already around 93%.\nTherefore, we manually correct these label mistakes and form a cleaner test\nset. Our re-evaluation of popular models on this corrected test set leads to\nmore accurate assessments, compared to those on the original test set. More\nimportantly, we propose a simple yet effective framework, CrossWeigh, to handle\nlabel mistakes during NER model training. Specifically, it partitions the\ntraining data into several folds and train independent NER models to identify\npotential mistakes in each fold. Then it adjusts the weights of training data\naccordingly to train the final NER model. Extensive experiments demonstrate\nsignificant improvements of plugging various NER models into our proposed\nframework on three datasets. All implementations and corrected test set are\navailable at our Github repo: https://github.com/ZihanWangKi/CrossWeigh.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 20:34:34 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Wang", "Zihan", ""], ["Shang", "Jingbo", ""], ["Liu", "Liyuan", ""], ["Lu", "Lihao", ""], ["Liu", "Jiacheng", ""], ["Han", "Jiawei", ""]]}, {"id": "1909.01459", "submitter": "Miriam Hurtado Bodell", "authors": "Miriam Hurtado Bodell, Martin Arvidsson and M{\\aa}ns Magnusson", "title": "Interpretable Word Embeddings via Informative Priors", "comments": "10 pages, 2 figures, EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings have demonstrated strong performance on NLP tasks. However,\nlack of interpretability and the unsupervised nature of word embeddings have\nlimited their use within computational social science and digital humanities.\nWe propose the use of informative priors to create interpretable and\ndomain-informed dimensions for probabilistic word embeddings. Experimental\nresults show that sensible priors can capture latent semantic concepts better\nthan or on-par with the current state of the art, while retaining the\nsimplicity and generalizability of using priors.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 21:20:28 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Bodell", "Miriam Hurtado", ""], ["Arvidsson", "Martin", ""], ["Magnusson", "M\u00e5ns", ""]]}, {"id": "1909.01462", "submitter": "Luca Lugini", "authors": "Luca Lugini, Diane Litman", "title": "Predicting Specificity in Classroom Discussion", "comments": null, "journal-ref": "Proceedings of the 12th Workshop on Innovative Use of NLP for\n  Building Educational Applications, September 2017, Copenhagen, Denmark", "doi": "10.18653/v1/W17-5006", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High quality classroom discussion is important to student development,\nenhancing abilities to express claims, reason about other students' claims, and\nretain information for longer periods of time. Previous small-scale studies\nhave shown that one indicator of classroom discussion quality is specificity.\nIn this paper we tackle the problem of predicting specificity for classroom\ndiscussions. We propose several methods and feature sets capable of\noutperforming the state of the art in specificity prediction. Additionally, we\nprovide a set of meaningful, interpretable features that can be used to analyze\nclassroom discussions at a pedagogical level.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 21:24:18 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Lugini", "Luca", ""], ["Litman", "Diane", ""]]}, {"id": "1909.01474", "submitter": "Solomia Fedushko", "authors": "Solomiia Fedushko, Sofia Kolos", "title": "Effective Strategies for Using Hashtags in Online Communication", "comments": "9 pages, 8 figures", "journal-ref": "International Journal of Computing and Related Technologies,\n  Volume 2, Issue 2, 2019", "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The features of use of hashtags among students of Lviv were investigated. The\nlist of optimal strategies for using these communicative tools for personal\nbranding is determined. The effective strategy for using hashtags in online\ncommunication for the personal and company branding is considered. The results\nof calculation of effectiveness of hashtags related to #education is\ncalculated. The reports of using hashtag #education in social networks is\npresented.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 22:20:24 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Fedushko", "Solomiia", ""], ["Kolos", "Sofia", ""]]}, {"id": "1909.01482", "submitter": "Tao Meng", "authors": "Tao Meng and Nanyun Peng and Kai-Wei Chang", "title": "Target Language-Aware Constrained Inference for Cross-lingual Dependency\n  Parsing", "comments": "15 pages, 3 figures, published in EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior work on cross-lingual dependency parsing often focuses on capturing the\ncommonalities between source and target languages and overlooks the potential\nof leveraging linguistic properties of the languages to facilitate the\ntransfer. In this paper, we show that weak supervisions of linguistic knowledge\nfor the target languages can improve a cross-lingual graph-based dependency\nparser substantially. Specifically, we explore several types of corpus\nlinguistic statistics and compile them into corpus-wise constraints to guide\nthe inference process during the test time. We adapt two techniques, Lagrangian\nrelaxation and posterior regularization, to conduct inference with\ncorpus-statistics constraints. Experiments show that the Lagrangian relaxation\nand posterior regularization inference improve the performances on 15 and 17\nout of 19 target languages, respectively. The improvements are especially\nsignificant for target languages that have different word order features from\nthe source language.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 22:34:42 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Meng", "Tao", ""], ["Peng", "Nanyun", ""], ["Chang", "Kai-Wei", ""]]}, {"id": "1909.01492", "submitter": "Po-Sen Huang", "authors": "Po-Sen Huang, Robert Stanforth, Johannes Welbl, Chris Dyer, Dani\n  Yogatama, Sven Gowal, Krishnamurthy Dvijotham, Pushmeet Kohli", "title": "Achieving Verified Robustness to Symbol Substitutions via Interval Bound\n  Propagation", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are part of many contemporary NLP systems, yet their\nempirical successes come at the price of vulnerability to adversarial attacks.\nPrevious work has used adversarial training and data augmentation to partially\nmitigate such brittleness, but these are unlikely to find worst-case\nadversaries due to the complexity of the search space arising from discrete\ntext perturbations. In this work, we approach the problem from the opposite\ndirection: to formally verify a system's robustness against a predefined class\nof adversarial attacks. We study text classification under synonym replacements\nor character flip perturbations. We propose modeling these input perturbations\nas a simplex and then using Interval Bound Propagation -- a formal model\nverification method. We modify the conventional log-likelihood training\nobjective to train models that can be efficiently verified, which would\notherwise come with exponential search complexity. The resulting models show\nonly little difference in terms of nominal accuracy, but have much improved\nverified accuracy under perturbations and come with an efficiently computable\nformal guarantee on worst case adversaries.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 23:03:10 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 18:21:49 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Huang", "Po-Sen", ""], ["Stanforth", "Robert", ""], ["Welbl", "Johannes", ""], ["Dyer", "Chris", ""], ["Yogatama", "Dani", ""], ["Gowal", "Sven", ""], ["Dvijotham", "Krishnamurthy", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1909.01496", "submitter": "Zachary Ziegler", "authors": "Zachary M. Ziegler, Yuntian Deng, Alexander M. Rush", "title": "Neural Linguistic Steganography", "comments": "EMNLP 2019 Accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whereas traditional cryptography encrypts a secret message into an\nunintelligible form, steganography conceals that communication is taking place\nby encoding a secret message into a cover signal. Language is a particularly\npragmatic cover signal due to its benign occurrence and independence from any\none medium. Traditionally, linguistic steganography systems encode secret\nmessages in existing text via synonym substitution or word order\nrearrangements. Advances in neural language models enable previously\nimpractical generation-based techniques. We propose a steganography technique\nbased on arithmetic coding with large-scale neural language models. We find\nthat our approach can generate realistic looking cover sentences as evaluated\nby humans, while at the same time preserving security by matching the cover\nmessage distribution with the language model distribution.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 23:15:19 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Ziegler", "Zachary M.", ""], ["Deng", "Yuntian", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1909.01515", "submitter": "Mingyang Chen", "authors": "Mingyang Chen, Wen Zhang, Wei Zhang, Qiang Chen, Huajun Chen", "title": "Meta Relational Learning for Few-Shot Link Prediction in Knowledge\n  Graphs", "comments": "Accepted by EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Link prediction is an important way to complete knowledge graphs (KGs), while\nembedding-based methods, effective for link prediction in KGs, perform poorly\non relations that only have a few associative triples. In this work, we propose\na Meta Relational Learning (MetaR) framework to do the common but challenging\nfew-shot link prediction in KGs, namely predicting new triples about a relation\nby only observing a few associative triples. We solve few-shot link prediction\nby focusing on transferring relation-specific meta information to make model\nlearn the most important knowledge and learn faster, corresponding to relation\nmeta and gradient meta respectively in MetaR. Empirically, our model achieves\nstate-of-the-art results on few-shot link prediction KG benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 01:35:47 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Chen", "Mingyang", ""], ["Zhang", "Wen", ""], ["Zhang", "Wei", ""], ["Chen", "Qiang", ""], ["Chen", "Huajun", ""]]}, {"id": "1909.01522", "submitter": "Katharina Kann", "authors": "Katharina Kann, Kyunghyun Cho, Samuel R. Bowman", "title": "Towards Realistic Practices In Low-Resource Natural Language Processing:\n  The Development Set", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Development sets are impractical to obtain for real low-resource languages,\nsince using all available data for training is often more effective. However,\ndevelopment sets are widely used in research papers that purport to deal with\nlow-resource natural language processing (NLP). Here, we aim to answer the\nfollowing questions: Does using a development set for early stopping in the\nlow-resource setting influence results as compared to a more realistic\nalternative, where the number of training epochs is tuned on development\nlanguages? And does it lead to overestimation or underestimation of\nperformance? We repeat multiple experiments from recent work on neural models\nfor low-resource NLP and compare results for models obtained by training with\nand without development sets. On average over languages, absolute accuracy\ndiffers by up to 1.4%. However, for some languages and tasks, differences are\nas big as 18.0% accuracy. Our results highlight the importance of realistic\nexperimental setups in the publication of low-resource NLP research results.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 02:20:54 GMT"}, {"version": "v2", "created": "Sun, 15 Sep 2019 00:38:42 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Kann", "Katharina", ""], ["Cho", "Kyunghyun", ""], ["Bowman", "Samuel R.", ""]]}, {"id": "1909.01528", "submitter": "Meng Cao", "authors": "Meng Cao, Jackie Chi Kit Cheung", "title": "Referring Expression Generation Using Entity Profiles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Referring Expression Generation (REG) is the task of generating contextually\nappropriate references to entities. A limitation of existing REG systems is\nthat they rely on entity-specific supervised training, which means that they\ncannot handle entities not seen during training. In this study, we address this\nin two ways. First, we propose task setups in which we specifically test a REG\nsystem's ability to generalize to entities not seen during training. Second, we\npropose a profile-based deep neural network model, ProfileREG, which encodes\nboth the local context and an external profile of the entity to generate\nreference realizations. Our model generates tokens by learning to choose\nbetween generating pronouns, generating from a fixed vocabulary, or copying a\nword from the profile. We evaluate our model on three different splits of the\nWebNLG dataset, and show that it outperforms competitive baselines in all\nsettings according to automatic and human evaluations.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 02:42:07 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Cao", "Meng", ""], ["Cheung", "Jackie Chi Kit", ""]]}, {"id": "1909.01559", "submitter": "Baigong Zheng", "authors": "Baigong Zheng, Renjie Zheng, Mingbo Ma, Liang Huang", "title": "Simpler and Faster Learning of Adaptive Policies for Simultaneous\n  Translation", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simultaneous translation is widely useful but remains challenging. Previous\nwork falls into two main categories: (a) fixed-latency policies such as Ma et\nal. (2019) and (b) adaptive policies such as Gu et al. (2017). The former are\nsimple and effective, but have to aggressively predict future content due to\ndiverging source-target word order; the latter do not anticipate, but suffer\nfrom unstable and inefficient training. To combine the merits of both\napproaches, we propose a simple supervised-learning framework to learn an\nadaptive policy from oracle READ/WRITE sequences generated from parallel text.\nAt each step, such an oracle sequence chooses to WRITE the next target word if\nthe available source sentence context provides enough information to do so,\notherwise READ the next source word. Experiments on German<->English show that\nour method, without retraining the underlying NMT model, can learn flexible\npolicies with better BLEU scores and similar latencies compared to previous\nwork.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 05:37:36 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 01:19:12 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Zheng", "Baigong", ""], ["Zheng", "Renjie", ""], ["Ma", "Mingbo", ""], ["Huang", "Liang", ""]]}, {"id": "1909.01562", "submitter": "Zhaopeng Tu", "authors": "Jie Hao, Xing Wang, Shuming Shi, Jinfeng Zhang, Zhaopeng Tu", "title": "Towards Better Modeling Hierarchical Structure for Self-Attention with\n  Ordered Neurons", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that a hybrid of self-attention networks (SANs) and\nrecurrent neural networks (RNNs) outperforms both individual architectures,\nwhile not much is known about why the hybrid models work. With the belief that\nmodeling hierarchical structure is an essential complementary between SANs and\nRNNs, we propose to further enhance the strength of hybrid models with an\nadvanced variant of RNNs - Ordered Neurons LSTM (ON-LSTM), which introduces a\nsyntax-oriented inductive bias to perform tree-like composition. Experimental\nresults on the benchmark machine translation task show that the proposed\napproach outperforms both individual architectures and a standard hybrid model.\nFurther analyses on targeted linguistic evaluation and logical inference tasks\ndemonstrate that the proposed approach indeed benefits from a better modeling\nof hierarchical structure.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 05:59:03 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 01:53:45 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Hao", "Jie", ""], ["Wang", "Xing", ""], ["Shi", "Shuming", ""], ["Zhang", "Jinfeng", ""], ["Tu", "Zhaopeng", ""]]}, {"id": "1909.01567", "submitter": "Masashi Shimbo", "authors": "Katsuhiko Hayashi and Masashi Shimbo", "title": "A Non-commutative Bilinear Model for Answering Path Queries in Knowledge\n  Graphs", "comments": "Accepted for EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bilinear diagonal models for knowledge graph embedding (KGE), such as\nDistMult and ComplEx, balance expressiveness and computational efficiency by\nrepresenting relations as diagonal matrices. Although they perform well in\npredicting atomic relations, composite relations (relation paths) cannot be\nmodeled naturally by the product of relation matrices, as the product of\ndiagonal matrices is commutative and hence invariant with the order of\nrelations. In this paper, we propose a new bilinear KGE model, called\nBlockHolE, based on block circulant matrices. In BlockHolE, relation matrices\ncan be non-commutative, allowing composite relations to be modeled by matrix\nproduct. The model is parameterized in a way that covers a spectrum ranging\nfrom diagonal to full relation matrices. A fast computation technique is\ndeveloped on the basis of the duality of the Fourier transform of circulant\nmatrices.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 06:26:05 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Hayashi", "Katsuhiko", ""], ["Shimbo", "Masashi", ""]]}, {"id": "1909.01568", "submitter": "Michael Wayne Goodman", "authors": "Michael Wayne Goodman", "title": "AMR Normalization for Fairer Evaluation", "comments": "Updates: fixed errors in Figs 5--7; adjusted Fig 6 for clarity; added\n  software version numbers; added acknowledgments; fix typo in bibliography", "journal-ref": "33rd Pacific Asia Conference on Language, Information and\n  Computation (PACLIC 33), pages 47-56, Hakodate, Japan, September 13-15, 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meaning Representation (AMR; Banarescu et al., 2013) encodes the meaning of\nsentences as a directed graph and Smatch (Cai and Knight, 2013) is the primary\nmetric for evaluating AMR graphs. Smatch, however, is unaware of some\nmeaning-equivalent variations in graph structure allowed by the AMR\nSpecification and gives different scores for AMRs exhibiting these variations.\nIn this paper I propose four normalization methods for helping to ensure that\nconceptually equivalent AMRs are evaluated as equivalent. Equivalent AMRs with\nand without normalization can look quite different---comparing a gold corpus to\nitself with relation reification alone yields a difference of 25 Smatch points,\nsuggesting that the outputs of two systems may not be directly comparable\nwithout normalization. The algorithms described in this paper are implemented\non top of an existing open-source Python toolkit for AMR and will be released\nunder the same license.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 06:29:35 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 09:14:55 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Goodman", "Michael Wayne", ""]]}, {"id": "1909.01584", "submitter": "Jiaming Shen", "authors": "Yu Shi, Jiaming Shen, Yuchen Li, Naijing Zhang, Xinwei He, Zhengzhi\n  Lou, Qi Zhu, Matthew Walker, Myunghwan Kim, Jiawei Han", "title": "Discovering Hypernymy in Text-Rich Heterogeneous Information Network by\n  Exploiting Context Granularity", "comments": "CIKM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text-rich heterogeneous information networks (text-rich HINs) are ubiquitous\nin real-world applications. Hypernymy, also known as is-a relation or\nsubclass-of relation, lays in the core of many knowledge graphs and benefits\nmany downstream applications. Existing methods of hypernymy discovery either\nleverage textual patterns to extract explicitly mentioned hypernym-hyponym\npairs, or learn a distributional representation for each term of interest based\nits context. These approaches rely on statistical signals from the textual\ncorpus, and their effectiveness would therefore be hindered when the signals\nfrom the corpus are not sufficient for all terms of interest. In this work, we\npropose to discover hypernymy in text-rich HINs, which can introduce additional\nhigh-quality signals. We develop a new framework, named HyperMine, that\nexploits multi-granular contexts and combines signals from both text and\nnetwork without human labeled data. HyperMine extends the definition of context\nto the scenario of text-rich HIN. For example, we can define typed nodes and\ncommunities as contexts. These contexts encode signals of different\ngranularities and we feed them into a hypernymy inference model. HyperMine\nlearns this model using weak supervision acquired based on high-precision\ntextual patterns. Extensive experiments on two large real-world datasets\ndemonstrate the effectiveness of HyperMine and the utility of modeling context\ngranularity. We further show a case study that a high-quality taxonomy can be\ngenerated solely based on the hypernymy discovered by HyperMine.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 07:23:06 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Shi", "Yu", ""], ["Shen", "Jiaming", ""], ["Li", "Yuchen", ""], ["Zhang", "Naijing", ""], ["He", "Xinwei", ""], ["Lou", "Zhengzhi", ""], ["Zhu", "Qi", ""], ["Walker", "Matthew", ""], ["Kim", "Myunghwan", ""], ["Han", "Jiawei", ""]]}, {"id": "1909.01610", "submitter": "Jacopo Staiano", "authors": "Thomas Scialom, Sylvain Lamprier, Benjamin Piwowarski, Jacopo Staiano", "title": "Answers Unite! Unsupervised Metrics for Reinforced Summarization Models", "comments": "Accepted at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstractive summarization approaches based on Reinforcement Learning (RL)\nhave recently been proposed to overcome classical likelihood maximization. RL\nenables to consider complex, possibly non-differentiable, metrics that globally\nassess the quality and relevance of the generated outputs. ROUGE, the most used\nsummarization metric, is known to suffer from bias towards lexical similarity\nas well as from suboptimal accounting for fluency and readability of the\ngenerated abstracts. We thus explore and propose alternative evaluation\nmeasures: the reported human-evaluation analysis shows that the proposed\nmetrics, based on Question Answering, favorably compares to ROUGE -- with the\nadditional property of not requiring reference summaries. Training a RL-based\nmodel on these metrics leads to improvements (both in terms of human or\nautomated metrics) over current approaches that use ROUGE as a reward.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 08:20:31 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Scialom", "Thomas", ""], ["Lamprier", "Sylvain", ""], ["Piwowarski", "Benjamin", ""], ["Staiano", "Jacopo", ""]]}, {"id": "1909.01627", "submitter": "Cinzia Di Giusto", "authors": "Cinzia Di Giusto (C&A), Cinzia Giusto (SARDES), Laetitia Laversa\n  (C&A), Etienne Lozes", "title": "On the k-synchronizability of systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CL cs.SC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we work on the notion of k-synchronizability: a system is\nk-synchronizable if any of its executions, up to reordering causally\nindependent actions, can be divided into a succession of k-bounded interaction\nphases. We show two results (both for mailbox and peer-to-peer automata):\nfirst, the reachability problem is decidable for k-synchronizable systems;\nsecond, the membership problem (whether a given system is k-synchronizable) is\ndecidable as well. Our proofs fix several important issues in previous attempts\nto prove these two results for mailbox automata.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 08:58:53 GMT"}, {"version": "v2", "created": "Tue, 21 Jan 2020 14:24:45 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Di Giusto", "Cinzia", "", "C&A"], ["Giusto", "Cinzia", "", "SARDES"], ["Laversa", "Laetitia", "", "C&A"], ["Lozes", "Etienne", ""]]}, {"id": "1909.01638", "submitter": "Ivan Vuli\\'c", "authors": "Ivan Vuli\\'c, Goran Glava\\v{s}, Roi Reichart, Anna Korhonen", "title": "Do We Really Need Fully Unsupervised Cross-Lingual Embeddings?", "comments": "EMNLP 2019 (Long paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent efforts in cross-lingual word embedding (CLWE) learning have\npredominantly focused on fully unsupervised approaches that project monolingual\nembeddings into a shared cross-lingual space without any cross-lingual signal.\nThe lack of any supervision makes such approaches conceptually attractive. Yet,\ntheir only core difference from (weakly) supervised projection-based CLWE\nmethods is in the way they obtain a seed dictionary used to initialize an\niterative self-learning procedure. The fully unsupervised methods have arguably\nbecome more robust, and their primary use case is CLWE induction for pairs of\nresource-poor and distant languages. In this paper, we question the ability of\neven the most robust unsupervised CLWE approaches to induce meaningful CLWEs in\nthese more challenging settings. A series of bilingual lexicon induction (BLI)\nexperiments with 15 diverse languages (210 language pairs) show that fully\nunsupervised CLWE methods still fail for a large number of language pairs\n(e.g., they yield zero BLI performance for 87/210 pairs). Even when they\nsucceed, they never surpass the performance of weakly supervised methods\n(seeded with 500-1,000 translation pairs) using the same self-learning\nprocedure in any BLI setup, and the gaps are often substantial. These findings\ncall for revisiting the main motivations behind fully unsupervised CLWE\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 09:17:21 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Vuli\u0107", "Ivan", ""], ["Glava\u0161", "Goran", ""], ["Reichart", "Roi", ""], ["Korhonen", "Anna", ""]]}, {"id": "1909.01642", "submitter": "Vishwajeet Kumar", "authors": "Vishwajeet Kumar, Sivaanandh Muneeswaran, Ganesh Ramakrishnan, and\n  Yuan-Fang Li", "title": "ParaQG: A System for Generating Questions and Answers from Paragraphs", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating syntactically and semantically valid and relevant questions from\nparagraphs is useful with many applications. Manual generation is a\nlabour-intensive task, as it requires the reading, parsing and understanding of\nlong passages of text. A number of question generation models based on\nsequence-to-sequence techniques have recently been proposed. Most of them\ngenerate questions from sentences only, and none of them is publicly available\nas an easy-to-use service. In this paper, we demonstrate ParaQG, a Web-based\nsystem for generating questions from sentences and paragraphs. ParaQG\nincorporates a number of novel functionalities to make the question generation\nprocess user-friendly. It provides an interactive interface for a user to\nselect answers with visual insights on generation of questions. It also employs\nvarious faceted views to group similar questions as well as filtering\ntechniques to eliminate unanswerable questions\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 09:23:50 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Kumar", "Vishwajeet", ""], ["Muneeswaran", "Sivaanandh", ""], ["Ramakrishnan", "Ganesh", ""], ["Li", "Yuan-Fang", ""]]}, {"id": "1909.01700", "submitter": "Chengzhu Yu", "authors": "Chengzhu Yu, Heng Lu, Na Hu, Meng Yu, Chao Weng, Kun Xu, Peng Liu,\n  Deyi Tuo, Shiyin Kang, Guangzhi Lei, Dan Su, Dong Yu", "title": "DurIAN: Duration Informed Attention Network For Multimodal Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a generic and robust multimodal synthesis system\nthat produces highly natural speech and facial expression simultaneously. The\nkey component of this system is the Duration Informed Attention Network\n(DurIAN), an autoregressive model in which the alignments between the input\ntext and the output acoustic features are inferred from a duration model. This\nis different from the end-to-end attention mechanism used, and accounts for\nvarious unavoidable artifacts, in existing end-to-end speech synthesis systems\nsuch as Tacotron. Furthermore, DurIAN can be used to generate high quality\nfacial expression which can be synchronized with generated speech with/without\nparallel speech and face data. To improve the efficiency of speech generation,\nwe also propose a multi-band parallel generation strategy on top of the WaveRNN\nmodel. The proposed Multi-band WaveRNN effectively reduces the total\ncomputational complexity from 9.8 to 5.5 GFLOPS, and is able to generate audio\nthat is 6 times faster than real time on a single CPU core. We show that DurIAN\ncould generate highly natural speech that is on par with current state of the\nart end-to-end systems, while at the same time avoid word skipping/repeating\nerrors in those systems. Finally, a simple yet effective approach for\nfine-grained control of expressiveness of speech and facial expression is\nintroduced.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 11:35:48 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 22:35:53 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Yu", "Chengzhu", ""], ["Lu", "Heng", ""], ["Hu", "Na", ""], ["Yu", "Meng", ""], ["Weng", "Chao", ""], ["Xu", "Kun", ""], ["Liu", "Peng", ""], ["Tuo", "Deyi", ""], ["Kang", "Shiyin", ""], ["Lei", "Guangzhi", ""], ["Su", "Dan", ""], ["Yu", "Dong", ""]]}, {"id": "1909.01701", "submitter": "Ond\\v{r}ej Bojar", "authors": "Tereza Vojt\\v{e}chov\\'a and Michal Nov\\'ak and Milo\\v{s} Klou\\v{c}ek\n  and Ond\\v{r}ej Bojar", "title": "SAO WMT19 Test Suite: Machine Translation of Audit Reports", "comments": "WMT19 (http://www.statmt.org/wmt19/)", "journal-ref": "Vojt\\v{e}chov\\'a et al. (2019): SAO WMT19 Test Suite: Machine\n  Translation of Audit Reports. In: Fourth Conference on Machine Translation -\n  Proceedings of the Conference, pp. 680-692, ACL, ISBN 978-1-950737-27-7", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a machine translation test set of documents from the\nauditing domain and its use as one of the \"test suites\" in the WMT19 News\nTranslation Task for translation directions involving Czech, English and\nGerman.\n  Our evaluation suggests that current MT systems optimized for the general\nnews domain can perform quite well even in the particular domain of audit\nreports. The detailed manual evaluation however indicates that deep factual\nknowledge of the domain is necessary. For the naked eye of a non-expert,\ntranslations by many systems seem almost perfect and automatic MT evaluation\nwith one reference is practically useless for considering these details.\n  Furthermore, we show on a sample document from the domain of agreements that\neven the best systems completely fail in preserving the semantics of the\nagreement, namely the identity of the parties.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 11:37:26 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Vojt\u011bchov\u00e1", "Tereza", ""], ["Nov\u00e1k", "Michal", ""], ["Klou\u010dek", "Milo\u0161", ""], ["Bojar", "Ond\u0159ej", ""]]}, {"id": "1909.01716", "submitter": "Michihiro Yasunaga", "authors": "Michihiro Yasunaga, Jungo Kasai, Rui Zhang, Alexander R. Fabbri, Irene\n  Li, Dan Friedman, Dragomir R. Radev", "title": "ScisummNet: A Large Annotated Corpus and Content-Impact Models for\n  Scientific Paper Summarization with Citation Networks", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific article summarization is challenging: large, annotated corpora are\nnot available, and the summary should ideally include the article's impacts on\nresearch community. This paper provides novel solutions to these two\nchallenges. We 1) develop and release the first large-scale manually-annotated\ncorpus for scientific papers (on computational linguistics) by enabling faster\nannotation, and 2) propose summarization methods that integrate the authors'\noriginal highlights (abstract) and the article's actual impacts on the\ncommunity (citations), to create comprehensive, hybrid summaries. We conduct\nexperiments to demonstrate the efficacy of our corpus in training data-driven\nmodels for scientific paper summarization and the advantage of our hybrid\nsummaries over abstracts and traditional citation-based summaries. Our large\nannotated corpus and hybrid methods provide a new framework for scientific\npaper summarization research.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 12:04:48 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 02:51:44 GMT"}, {"version": "v3", "created": "Mon, 16 Sep 2019 01:32:22 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Yasunaga", "Michihiro", ""], ["Kasai", "Jungo", ""], ["Zhang", "Rui", ""], ["Fabbri", "Alexander R.", ""], ["Li", "Irene", ""], ["Friedman", "Dan", ""], ["Radev", "Dragomir R.", ""]]}, {"id": "1909.01720", "submitter": "Lianwei Wu", "authors": "Lianwei Wu, Yuan Rao, Haolin Jin, Ambreen Nazir, Ling Sun", "title": "Different Absorption from the Same Sharing: Sifted Multi-task Learning\n  for Fake News Detection", "comments": "10 pages, 5 figures, EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, neural networks based on multi-task learning have achieved\npromising performance on fake news detection, which focus on learning shared\nfeatures among tasks as complementary features to serve different tasks.\nHowever, in most of the existing approaches, the shared features are completely\nassigned to different tasks without selection, which may lead to some useless\nand even adverse features integrated into specific tasks. In this paper, we\ndesign a sifted multi-task learning method with a selected sharing layer for\nfake news detection. The selected sharing layer adopts gate mechanism and\nattention mechanism to filter and select shared feature flows between tasks.\nExperiments on two public and widely used competition datasets, i.e. RumourEval\nand PHEME, demonstrate that our proposed method achieves the state-of-the-art\nperformance and boosts the F1-score by more than 0.87%, 1.31%, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 12:15:02 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Wu", "Lianwei", ""], ["Rao", "Yuan", ""], ["Jin", "Haolin", ""], ["Nazir", "Ambreen", ""], ["Sun", "Ling", ""]]}, {"id": "1909.01761", "submitter": "Yu Wang", "authors": "Yu Wang", "title": "Single Training Dimension Selection for Word Embedding with PCA", "comments": "6 pages, 5 figures, 2 tables, EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a fast and reliable method based on PCA to select\nthe number of dimensions for word embeddings. First, we train one embedding\nwith a generous upper bound (e.g. 1,000) of dimensions. Then we transform the\nembeddings using PCA and incrementally remove the lesser dimensions one at a\ntime while recording the embeddings' performance on language tasks. Lastly, we\nselect the number of dimensions while balancing model size and accuracy.\nExperiments using various datasets and language tasks demonstrate that we are\nable to train 10 times fewer sets of embeddings while retaining optimal\nperformance. Researchers interested in training the best-performing embeddings\nfor downstream tasks, such as sentiment analysis, question answering and\nhypernym extraction, as well as those interested in embedding compression\nshould find the method helpful.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 23:19:41 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Wang", "Yu", ""]]}, {"id": "1909.01772", "submitter": "Tommaso Teofili", "authors": "Tommaso Teofili, Niyati Chhaya", "title": "Affect Enriched Word Embeddings for News Information Retrieval", "comments": null, "journal-ref": "NewsIR@SIGIR 2019: 63-68", "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed representations of words have shown to be useful to improve the\neffectiveness of IR systems in many sub-tasks like query expansion, retrieval\nand ranking. Algorithms like word2vec, GloVe and others are also key factors in\nmany improvements in different NLP tasks. One common issue with such embedding\nmodels is that words like happy and sad appear in similar contexts and hence\nare wrongly clustered close in the embedding space. In this paper we leverage\nAff2Vec, a set of word embeddings models which include affect information, in\norder to better capture the affect aspect in news text to achieve better\nresults in information retrieval tasks, also such embeddings are less hit by\nthe synonym/antonym issue. We evaluate their effectiveness on two IR related\ntasks (query expansion and ranking) over the New York Times dataset (TREC-core\n'17) comparing them against other word embeddings based models and classic\nranking models.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 13:12:30 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Teofili", "Tommaso", ""], ["Chhaya", "Niyati", ""]]}, {"id": "1909.01792", "submitter": "G\\'abor Melis", "authors": "G\\'abor Melis, Tom\\'a\\v{s} Ko\\v{c}isk\\'y, Phil Blunsom", "title": "Mogrifier LSTM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many advances in Natural Language Processing have been based upon more\nexpressive models for how inputs interact with the context in which they occur.\nRecurrent networks, which have enjoyed a modicum of success, still lack the\ngeneralization and systematicity ultimately required for modelling language. In\nthis work, we propose an extension to the venerable Long Short-Term Memory in\nthe form of mutual gating of the current input and the previous output. This\nmechanism affords the modelling of a richer space of interactions between\ninputs and their context. Equivalently, our model can be viewed as making the\ntransition function given by the LSTM context-dependent. Experiments\ndemonstrate markedly improved generalization on language modelling in the range\nof 3-4 perplexity points on Penn Treebank and Wikitext-2, and 0.01-0.05 bpc on\nfour character-based datasets. We establish a new state of the art on all\ndatasets with the exception of Enwik8, where we close a large gap between the\nLSTM and Transformer models.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 13:32:23 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 14:12:52 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Melis", "G\u00e1bor", ""], ["Ko\u010disk\u00fd", "Tom\u00e1\u0161", ""], ["Blunsom", "Phil", ""]]}, {"id": "1909.01800", "submitter": "Lukasz Augustyniak", "authors": "{\\L}ukasz Augustyniak, Tomasz Kajdanowicz, Przemys{\\l}aw Kazienko", "title": "Extracting Aspects Hierarchies using Rhetorical Structure Theory", "comments": "ACAI 2018 MLNLP", "journal-ref": "ACAI 2018 MLNLP", "doi": "10.1145/3302425.3302479", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach to generate aspect hierarchies that proved to be\nconsistently correct compared with human-generated hierarchies. We present an\nunsupervised technique using Rhetorical Structure Theory and graph analysis. We\nevaluated our approach based on 100,000 reviews from Amazon and achieved an\nastonishing 80% coverage compared with human-generated hierarchies coded in\nConceptNet. The method could be easily extended with a sentiment analysis model\nand used to describe sentiment on different levels of aspect granularity.\nHence, besides the flat aspect structure, we can differentiate between aspects\nand describe if the charging aspect is related to battery or price.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 13:48:27 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Augustyniak", "\u0141ukasz", ""], ["Kajdanowicz", "Tomasz", ""], ["Kazienko", "Przemys\u0142aw", ""]]}, {"id": "1909.01807", "submitter": "Michael Stewart", "authors": "Michael Stewart, Majigsuren Enkhsaikhan and Wei Liu", "title": "ICDM 2019 Knowledge Graph Contest: Team UWA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present an overview of our triple extraction system for the ICDM 2019\nKnowledge Graph Contest. Our system uses a pipeline-based approach to extract a\nset of triples from a given document. It offers a simple and effective solution\nto the challenge of knowledge graph construction from domain-specific text. It\nalso provides the facility to visualise useful information about each triple\nsuch as the degree, betweenness, structured relation type(s), and named entity\ntypes.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 13:56:52 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Stewart", "Michael", ""], ["Enkhsaikhan", "Majigsuren", ""], ["Liu", "Wei", ""]]}, {"id": "1909.01860", "submitter": "Shiv Ram Dubey", "authors": "Yash Srivastava, Vaishnav Murali, Shiv Ram Dubey, Snehasis Mukherjee", "title": "Visual Question Answering using Deep Learning: A Survey and Performance\n  Analysis", "comments": "Accepted in Fifth IAPR International Conference on Computer Vision\n  and Image Processing (CVIP), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Visual Question Answering (VQA) task combines challenges for processing\ndata with both Visual and Linguistic processing, to answer basic `common sense'\nquestions about given images. Given an image and a question in natural\nlanguage, the VQA system tries to find the correct answer to it using visual\nelements of the image and inference gathered from textual questions. In this\nsurvey, we cover and discuss the recent datasets released in the VQA domain\ndealing with various types of question-formats and robustness of the\nmachine-learning models. Next, we discuss about new deep learning models that\nhave shown promising results over the VQA datasets. At the end, we present and\ndiscuss some of the results computed by us over the vanilla VQA model, Stacked\nAttention Network and the VQA Challenge 2017 winner model. We also provide the\ndetailed analysis along with the challenges and future research directions.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 07:03:03 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 01:11:29 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Srivastava", "Yash", ""], ["Murali", "Vaishnav", ""], ["Dubey", "Shiv Ram", ""], ["Mukherjee", "Snehasis", ""]]}, {"id": "1909.01863", "submitter": "Syrielle Montariol", "authors": "Syrielle Montariol and Alexandre Allauzen", "title": "Empirical Study of Diachronic Word Embeddings for Scarce Data", "comments": "7 pages", "journal-ref": "RANLP 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word meaning change can be inferred from drifts of time-varying word\nembeddings. However, temporal data may be too sparse to build robust word\nembeddings and to discriminate significant drifts from noise. In this paper, we\ncompare three models to learn diachronic word embeddings on scarce data:\nincremental updating of a Skip-Gram from Kim et al. (2014), dynamic filtering\nfrom Bamler and Mandt (2017), and dynamic Bernoulli embeddings from Rudolph and\nBlei (2018). In particular, we study the performance of different\ninitialisation schemes and emphasise what characteristics of each model are\nmore suitable to data scarcity, relying on the distribution of detected drifts.\nFinally, we regularise the loss of these models to better adapt to scarce data.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 15:11:32 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Montariol", "Syrielle", ""], ["Allauzen", "Alexandre", ""]]}, {"id": "1909.01871", "submitter": "Khanh Nguyen", "authors": "Khanh Nguyen and Hal Daum\\'e III", "title": "Help, Anna! Visual Navigation with Natural Multimodal Assistance via\n  Retrospective Curiosity-Encouraging Imitation Learning", "comments": "In EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile agents that can leverage help from humans can potentially accomplish\nmore complex tasks than they could entirely on their own. We develop \"Help,\nAnna!\" (HANNA), an interactive photo-realistic simulator in which an agent\nfulfills object-finding tasks by requesting and interpreting natural\nlanguage-and-vision assistance. An agent solving tasks in a HANNA environment\ncan leverage simulated human assistants, called ANNA (Automatic Natural\nNavigation Assistants), which, upon request, provide natural language and\nvisual instructions to direct the agent towards the goals. To address the HANNA\nproblem, we develop a memory-augmented neural agent that hierarchically models\nmultiple levels of decision-making, and an imitation learning algorithm that\nteaches the agent to avoid repeating past mistakes while simultaneously\npredicting its own chances of making future progress. Empirically, our approach\nis able to ask for help more effectively than competitive baselines and, thus,\nattains higher task success rate on both previously seen and previously unseen\nenvironments. We publicly release code and data at\nhttps://github.com/khanhptnk/hanna . A video demo is available at\nhttps://youtu.be/18P94aaaLKg .\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 15:20:01 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 16:16:31 GMT"}, {"version": "v3", "created": "Sun, 15 Sep 2019 03:30:13 GMT"}, {"version": "v4", "created": "Tue, 8 Oct 2019 16:08:40 GMT"}, {"version": "v5", "created": "Mon, 21 Oct 2019 07:12:17 GMT"}, {"version": "v6", "created": "Fri, 22 Nov 2019 16:11:17 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Nguyen", "Khanh", ""], ["Daum\u00e9", "Hal", "III"]]}, {"id": "1909.01953", "submitter": "Jaemin Cho", "authors": "Jaemin Cho, Minjoon Seo, Hannaneh Hajishirzi", "title": "Mixture Content Selection for Diverse Sequence Generation", "comments": "EMNLP-IJCNLP 2019; Code is available at\n  https://github.com/clovaai/FocusSeq2Seq", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating diverse sequences is important in many NLP applications such as\nquestion generation or summarization that exhibit semantically one-to-many\nrelationships between source and the target sequences. We present a method to\nexplicitly separate diversification from generation using a general\nplug-and-play module (called SELECTOR) that wraps around and guides an existing\nencoder-decoder model. The diversification stage uses a mixture of experts to\nsample different binary masks on the source sequence for diverse content\nselection. The generation stage uses a standard encoder-decoder model given\neach selected content from the source sequence. Due to the non-differentiable\nnature of discrete sampling and the lack of ground truth labels for binary\nmask, we leverage a proxy for ground truth mask and adopt stochastic hard-EM\nfor training. In question generation (SQuAD) and abstractive summarization\n(CNN-DM), our method demonstrates significant improvements in accuracy,\ndiversity and training efficiency, including state-of-the-art top-1 accuracy in\nboth datasets, 6% gain in top-5 accuracy, and 3.7 times faster training over a\nstate of the art model. Our code is publicly available at\nhttps://github.com/clovaai/FocusSeq2Seq.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 17:23:54 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Cho", "Jaemin", ""], ["Seo", "Minjoon", ""], ["Hajishirzi", "Hannaneh", ""]]}, {"id": "1909.01958", "submitter": "Peter Clark", "authors": "Peter Clark, Oren Etzioni, Daniel Khashabi, Tushar Khot, Bhavana Dalvi\n  Mishra, Kyle Richardson, Ashish Sabharwal, Carissa Schoenick, Oyvind Tafjord,\n  Niket Tandon, Sumithra Bhakthavatsalam, Dirk Groeneveld, Michal Guerquin,\n  Michael Schmitz", "title": "From 'F' to 'A' on the N.Y. Regents Science Exams: An Overview of the\n  Aristo Project", "comments": "AI Magazine 41 (4) Winter 2020. New analysis sections added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  AI has achieved remarkable mastery over games such as Chess, Go, and Poker,\nand even Jeopardy, but the rich variety of standardized exams has remained a\nlandmark challenge. Even in 2016, the best AI system achieved merely 59.3% on\nan 8th Grade science exam challenge. This paper reports unprecedented success\non the Grade 8 New York Regents Science Exam, where for the first time a system\nscores more than 90% on the exam's non-diagram, multiple choice (NDMC)\nquestions. In addition, our Aristo system, building upon the success of recent\nlanguage models, exceeded 83% on the corresponding Grade 12 Science Exam NDMC\nquestions. The results, on unseen test questions, are robust across different\ntest years and different variations of this kind of test. They demonstrate that\nmodern NLP methods can result in mastery on this task. While not a full\nsolution to general question-answering (the questions are multiple choice, and\nthe domain is restricted to 8th Grade science), it represents a significant\nmilestone for the field.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 17:33:42 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 20:51:37 GMT"}, {"version": "v3", "created": "Tue, 2 Feb 2021 00:42:53 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Clark", "Peter", ""], ["Etzioni", "Oren", ""], ["Khashabi", "Daniel", ""], ["Khot", "Tushar", ""], ["Mishra", "Bhavana Dalvi", ""], ["Richardson", "Kyle", ""], ["Sabharwal", "Ashish", ""], ["Schoenick", "Carissa", ""], ["Tafjord", "Oyvind", ""], ["Tandon", "Niket", ""], ["Bhakthavatsalam", "Sumithra", ""], ["Groeneveld", "Dirk", ""], ["Guerquin", "Michal", ""], ["Schmitz", "Michael", ""]]}, {"id": "1909.02027", "submitter": "Stefan Larson", "authors": "Stefan Larson, Anish Mahendran, Joseph J. Peper, Christopher Clarke,\n  Andrew Lee, Parker Hill, Jonathan K. Kummerfeld, Kevin Leach, Michael A.\n  Laurenzano, Lingjia Tang, Jason Mars", "title": "An Evaluation Dataset for Intent Classification and Out-of-Scope\n  Prediction", "comments": "Accepted to EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task-oriented dialog systems need to know when a query falls outside their\nrange of supported intents, but current text classification corpora only define\nlabel sets that cover every example. We introduce a new dataset that includes\nqueries that are out-of-scope---i.e., queries that do not fall into any of the\nsystem's supported intents. This poses a new challenge because models cannot\nassume that every query at inference time belongs to a system-supported intent\nclass. Our dataset also covers 150 intent classes over 10 domains, capturing\nthe breadth that a production task-oriented agent must handle. We evaluate a\nrange of benchmark classifiers on our dataset along with several different\nout-of-scope identification schemes. We find that while the classifiers perform\nwell on in-scope intent classification, they struggle to identify out-of-scope\nqueries. Our dataset and evaluation fill an important gap in the field,\noffering a way of more rigorously and realistically benchmarking text\nclassification in task-driven dialog systems.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 18:04:56 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Larson", "Stefan", ""], ["Mahendran", "Anish", ""], ["Peper", "Joseph J.", ""], ["Clarke", "Christopher", ""], ["Lee", "Andrew", ""], ["Hill", "Parker", ""], ["Kummerfeld", "Jonathan K.", ""], ["Leach", "Kevin", ""], ["Laurenzano", "Michael A.", ""], ["Tang", "Lingjia", ""], ["Mars", "Jason", ""]]}, {"id": "1909.02050", "submitter": "Ming Jiang", "authors": "Ming Jiang, Qiuyuan Huang, Lei Zhang, Xin Wang, Pengchuan Zhang, Zhe\n  Gan, Jana Diesner, Jianfeng Gao", "title": "TIGEr: Text-to-Image Grounding for Image Caption Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new metric called TIGEr for the automatic evaluation of\nimage captioning systems. Popular metrics, such as BLEU and CIDEr, are based\nsolely on text matching between reference captions and machine-generated\ncaptions, potentially leading to biased evaluations because references may not\nfully cover the image content and natural language is inherently ambiguous.\nBuilding upon a machine-learned text-image grounding model, TIGEr allows to\nevaluate caption quality not only based on how well a caption represents image\ncontent, but also on how well machine-generated captions match human-generated\ncaptions. Our empirical tests show that TIGEr has a higher consistency with\nhuman judgments than alternative existing metrics. We also comprehensively\nassess the metric's effectiveness in caption evaluation by measuring the\ncorrelation between human judgments and metric scores.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 18:43:04 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Jiang", "Ming", ""], ["Huang", "Qiuyuan", ""], ["Zhang", "Lei", ""], ["Wang", "Xin", ""], ["Zhang", "Pengchuan", ""], ["Gan", "Zhe", ""], ["Diesner", "Jana", ""], ["Gao", "Jianfeng", ""]]}, {"id": "1909.02059", "submitter": "Eva Sharma", "authors": "Eva Sharma, Luyang Huang, Zhe Hu and Lu Wang", "title": "An Entity-Driven Framework for Abstractive Summarization", "comments": "Proceedings of the 2019 Empirical Methods in Natural Language\n  Processing Conference and 9th International Joint Conference on Natural\n  Language Processing (EMNLP-IJCNLP-2019) (19 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstractive summarization systems aim to produce more coherent and concise\nsummaries than their extractive counterparts. Popular neural models have\nachieved impressive results for single-document summarization, yet their\noutputs are often incoherent and unfaithful to the input. In this paper, we\nintroduce SENECA, a novel System for ENtity-drivEn Coherent Abstractive\nsummarization framework that leverages entity information to generate\ninformative and coherent abstracts. Our framework takes a two-step approach:\n(1) an entity-aware content selection module first identifies salient sentences\nfrom the input, then (2) an abstract generation module conducts cross-sentence\ninformation compression and abstraction to generate the final summary, which is\ntrained with rewards to promote coherence, conciseness, and clarity. The two\ncomponents are further connected using reinforcement learning. Automatic\nevaluation shows that our model significantly outperforms previous\nstate-of-the-art on ROUGE and our proposed coherence measures on New York Times\nand CNN/Daily Mail datasets. Human judges further rate our system summaries as\nmore informative and coherent than those by popular summarization models.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 19:07:29 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Sharma", "Eva", ""], ["Huang", "Luyang", ""], ["Hu", "Zhe", ""], ["Wang", "Lu", ""]]}, {"id": "1909.02060", "submitter": "Tatsunori Hashimoto", "authors": "Yonatan Oren, Shiori Sagawa, Tatsunori B. Hashimoto, Percy Liang", "title": "Distributionally Robust Language Modeling", "comments": "Camera ready version for EMNLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language models are generally trained on data spanning a wide range of topics\n(e.g., news, reviews, fiction), but they might be applied to an a priori\nunknown target distribution (e.g., restaurant reviews). In this paper, we first\nshow that training on text outside the test distribution can degrade test\nperformance when using standard maximum likelihood (MLE) training. To remedy\nthis without the knowledge of the test distribution, we propose an approach\nwhich trains a model that performs well over a wide range of potential test\ndistributions. In particular, we derive a new distributionally robust\noptimization (DRO) procedure which minimizes the loss of the model over the\nworst-case mixture of topics with sufficient overlap with the training\ndistribution. Our approach, called topic conditional value at risk (topic\nCVaR), obtains a 5.5 point perplexity reduction over MLE when the language\nmodels are trained on a mixture of Yelp reviews and news and tested only on\nreviews.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 19:07:33 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Oren", "Yonatan", ""], ["Sagawa", "Shiori", ""], ["Hashimoto", "Tatsunori B.", ""], ["Liang", "Percy", ""]]}, {"id": "1909.02063", "submitter": "Bas Hofstra", "authors": "Bas Hofstra, Vivek V. Kulkarni, Sebastian Munoz-Najar Galvez, Bryan\n  He, Dan Jurafsky, Daniel A. McFarland", "title": "The Diversity-Innovation Paradox in Science", "comments": "Updated paper; tightened up terminology, added better theoretical\n  explanation, tested for a mechanism in the updated paper, added robustness\n  analyses, updated and improved metrics across the board", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Prior work finds a diversity paradox: diversity breeds innovation, and yet,\nunderrepresented groups that diversify organizations have less successful\ncareers within them. Does the diversity paradox hold for scientists as well? We\nstudy this by utilizing a near-population of ~1.2 million US doctoral\nrecipients from 1977-2015 and following their careers into publishing and\nfaculty positions. We use text analysis and machine learning to answer a series\nof questions: How do we detect scientific innovations? Are underrepresented\ngroups more likely to generate scientific innovations? And are the innovations\nof underrepresented groups adopted and rewarded? Our analyses show that\nunderrepresented groups produce higher rates of scientific novelty. However,\ntheir novel contributions are devalued and discounted: e.g., novel\ncontributions by gender and racial minorities are taken up by other scholars at\nlower rates than novel contributions by gender and racial majorities, and\nequally impactful contributions of gender and racial minorities are less likely\nto result in successful scientific careers than for majority groups. These\nresults suggest there may be unwarranted reproduction of stratification in\nacademic careers that discounts diversity's role in innovation and partly\nexplains the underrepresentation of some groups in academia.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 19:10:20 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2020 02:31:51 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Hofstra", "Bas", ""], ["Kulkarni", "Vivek V.", ""], ["Galvez", "Sebastian Munoz-Najar", ""], ["He", "Bryan", ""], ["Jurafsky", "Dan", ""], ["McFarland", "Daniel A.", ""]]}, {"id": "1909.02074", "submitter": "Sarthak Garg", "authors": "Sarthak Garg, Stephan Peitz, Udhyakumar Nallasamy, Matthias Paulik", "title": "Jointly Learning to Align and Translate with Transformer Models", "comments": "10 pages, 2 figures. To appear at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state of the art in machine translation (MT) is governed by neural\napproaches, which typically provide superior translation accuracy over\nstatistical approaches. However, on the closely related task of word alignment,\ntraditional statistical word alignment models often remain the go-to solution.\nIn this paper, we present an approach to train a Transformer model to produce\nboth accurate translations and alignments. We extract discrete alignments from\nthe attention probabilities learnt during regular neural machine translation\nmodel training and leverage them in a multi-task framework to optimize towards\ntranslation and alignment objectives. We demonstrate that our approach produces\ncompetitive results compared to GIZA++ trained IBM alignment models without\nsacrificing translation accuracy and outperforms previous attempts on\nTransformer model based word alignment. Finally, by incorporating IBM model\nalignments into our multi-task training, we report significantly better\nalignment accuracies compared to GIZA++ on three publicly available data sets.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 19:54:06 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Garg", "Sarthak", ""], ["Peitz", "Stephan", ""], ["Nallasamy", "Udhyakumar", ""], ["Paulik", "Matthias", ""]]}, {"id": "1909.02097", "submitter": "Soravit Changpinyo", "authors": "Soravit Changpinyo, Bo Pang, Piyush Sharma, Radu Soricut", "title": "Decoupled Box Proposal and Featurization with Ultrafine-Grained Semantic\n  Labels Improve Image Captioning and Visual Question Answering", "comments": "The 2019 Conference on Empirical Methods in Natural Language\n  Processing (EMNLP 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object detection plays an important role in current solutions to vision and\nlanguage tasks like image captioning and visual question answering. However,\npopular models like Faster R-CNN rely on a costly process of annotating\nground-truths for both the bounding boxes and their corresponding semantic\nlabels, making it less amenable as a primitive task for transfer learning. In\nthis paper, we examine the effect of decoupling box proposal and featurization\nfor down-stream tasks. The key insight is that this allows us to leverage a\nlarge amount of labeled annotations that were previously unavailable for\nstandard object detection benchmarks. Empirically, we demonstrate that this\nleads to effective transfer learning and improved image captioning and visual\nquestion answering models, as measured on publicly available benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 20:37:30 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Changpinyo", "Soravit", ""], ["Pang", "Bo", ""], ["Sharma", "Piyush", ""], ["Soricut", "Radu", ""]]}, {"id": "1909.02117", "submitter": "Xiaotao Gu", "authors": "Xiyuan Yang, Xiaotao Gu, Sheng Lin, Siliang Tang, Yueting Zhuang, Fei\n  Wu, Zhigang Chen, Guoping Hu, Xiang Ren", "title": "Learning Dynamic Context Augmentation for Global Entity Linking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite of the recent success of collective entity linking (EL) methods,\nthese \"global\" inference methods may yield sub-optimal results when the\n\"all-mention coherence\" assumption breaks, and often suffer from high\ncomputational cost at the inference stage, due to the complex search space. In\nthis paper, we propose a simple yet effective solution, called Dynamic Context\nAugmentation (DCA), for collective EL, which requires only one pass through the\nmentions in a document. DCA sequentially accumulates context information to\nmake efficient, collective inference, and can cope with different local EL\nmodels as a plug-and-enhance module. We explore both supervised and\nreinforcement learning strategies for learning the DCA model. Extensive\nexperiments show the effectiveness of our model with different learning\nsettings, base models, decision orders and attention mechanisms.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 21:13:23 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Yang", "Xiyuan", ""], ["Gu", "Xiaotao", ""], ["Lin", "Sheng", ""], ["Tang", "Siliang", ""], ["Zhuang", "Yueting", ""], ["Wu", "Fei", ""], ["Chen", "Zhigang", ""], ["Hu", "Guoping", ""], ["Ren", "Xiang", ""]]}, {"id": "1909.02126", "submitter": "Aida Mostafazadeh Davani", "authors": "Aida Mostafazadeh Davani, Leigh Yeh, Mohammad Atari, Brendan Kennedy,\n  Gwenyth Portillo-Wightman, Elaine Gonzalez, Natalie Delong, Rhea Bhatia,\n  Arineh Mirinjian, Xiang Ren, Morteza Dehghani", "title": "Reporting the Unreported: Event Extraction for Analyzing the Local\n  Representation of Hate Crimes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Official reports of hate crimes in the US are under-reported relative to the\nactual number of such incidents. Further, despite statistical approximations,\nthere are no official reports from a large number of US cities regarding\nincidents of hate. Here, we first demonstrate that event extraction and\nmulti-instance learning, applied to a corpus of local news articles, can be\nused to predict instances of hate crime. We then use the trained model to\ndetect incidents of hate in cities for which the FBI lacks statistics. Lastly,\nwe train models on predicting homicide and kidnapping, compare the predictions\nto FBI reports, and establish that incidents of hate are indeed under-reported,\ncompared to other types of crimes, in local press.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 21:45:51 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Davani", "Aida Mostafazadeh", ""], ["Yeh", "Leigh", ""], ["Atari", "Mohammad", ""], ["Kennedy", "Brendan", ""], ["Portillo-Wightman", "Gwenyth", ""], ["Gonzalez", "Elaine", ""], ["Delong", "Natalie", ""], ["Bhatia", "Rhea", ""], ["Mirinjian", "Arineh", ""], ["Ren", "Xiang", ""], ["Dehghani", "Morteza", ""]]}, {"id": "1909.02134", "submitter": "Hao Peng", "authors": "Hao Peng, Roy Schwartz, Noah A. Smith", "title": "PaLM: A Hybrid Parser and Language Model", "comments": "EMNLP 2019 short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present PaLM, a hybrid parser and neural language model. Building on an\nRNN language model, PaLM adds an attention layer over text spans in the left\ncontext. An unsupervised constituency parser can be derived from its attention\nweights, using a greedy decoding algorithm. We evaluate PaLM on language\nmodeling, and empirically show that it outperforms strong baselines. If\nsyntactic annotations are available, the attention component can be trained in\na supervised manner, providing syntactically-informed representations of the\ncontext, and further improving language modeling performance.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 22:10:41 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Peng", "Hao", ""], ["Schwartz", "Roy", ""], ["Smith", "Noah A.", ""]]}, {"id": "1909.02151", "submitter": "Bill Yuchen Lin", "authors": "Bill Yuchen Lin, Xinyue Chen, Jamin Chen, Xiang Ren", "title": "KagNet: Knowledge-Aware Graph Networks for Commonsense Reasoning", "comments": "11 pages, 4 figures, in Proc. of EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commonsense reasoning aims to empower machines with the human ability to make\npresumptions about ordinary situations in our daily life. In this paper, we\npropose a textual inference framework for answering commonsense questions,\nwhich effectively utilizes external, structured commonsense knowledge graphs to\nperform explainable inferences. The framework first grounds a question-answer\npair from the semantic space to the knowledge-based symbolic space as a schema\ngraph, a related sub-graph of external knowledge graphs. It represents schema\ngraphs with a novel knowledge-aware graph network module named KagNet, and\nfinally scores answers with graph representations. Our model is based on graph\nconvolutional networks and LSTMs, with a hierarchical path-based attention\nmechanism. The intermediate attention scores make it transparent and\ninterpretable, which thus produce trustworthy inferences. Using ConceptNet as\nthe only external resource for Bert-based models, we achieved state-of-the-art\nperformance on the CommonsenseQA, a large-scale dataset for commonsense\nreasoning.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 23:37:25 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Lin", "Bill Yuchen", ""], ["Chen", "Xinyue", ""], ["Chen", "Jamin", ""], ["Ren", "Xiang", ""]]}, {"id": "1909.02164", "submitter": "Wenhu Chen", "authors": "Wenhu Chen, Hongmin Wang, Jianshu Chen, Yunkai Zhang, Hong Wang,\n  Shiyang Li, Xiyou Zhou and William Yang Wang", "title": "TabFact: A Large-scale Dataset for Table-based Fact Verification", "comments": "Accepted to ICLR 2020, 17 pages, 15 figures. Main paper has 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of verifying whether a textual hypothesis holds based on the\ngiven evidence, also known as fact verification, plays an important role in the\nstudy of natural language understanding and semantic representation. However,\nexisting studies are mainly restricted to dealing with unstructured evidence\n(e.g., natural language sentences and documents, news, etc), while verification\nunder structured evidence, such as tables, graphs, and databases, remains\nunder-explored. This paper specifically aims to study the fact verification\ngiven semi-structured data as evidence. To this end, we construct a large-scale\ndataset called TabFact with 16k Wikipedia tables as the evidence for 118k\nhuman-annotated natural language statements, which are labeled as either\nENTAILED or REFUTED. TabFact is challenging since it involves both soft\nlinguistic reasoning and hard symbolic reasoning. To address these reasoning\nchallenges, we design two different models: Table-BERT and Latent Program\nAlgorithm (LPA). Table-BERT leverages the state-of-the-art pre-trained language\nmodel to encode the linearized tables and statements into continuous vectors\nfor verification. LPA parses statements into programs and executes them against\nthe tables to obtain the returned binary value for verification. Both methods\nachieve similar accuracy but still lag far behind human performance. We also\nperform a comprehensive analysis to demonstrate great future opportunities. The\ndata and code of the dataset are provided in\n\\url{https://github.com/wenhuchen/Table-Fact-Checking}.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 00:25:17 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 01:59:41 GMT"}, {"version": "v3", "created": "Tue, 8 Oct 2019 05:58:51 GMT"}, {"version": "v4", "created": "Tue, 31 Dec 2019 17:16:32 GMT"}, {"version": "v5", "created": "Sun, 14 Jun 2020 19:14:22 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Chen", "Wenhu", ""], ["Wang", "Hongmin", ""], ["Chen", "Jianshu", ""], ["Zhang", "Yunkai", ""], ["Wang", "Hong", ""], ["Li", "Shiyang", ""], ["Zhou", "Xiyou", ""], ["Wang", "William Yang", ""]]}, {"id": "1909.02177", "submitter": "Wenxuan Zhou", "authors": "Wenxuan Zhou, Hongtao Lin, Bill Yuchen Lin, Ziqi Wang, Junyi Du,\n  Leonardo Neves, Xiang Ren", "title": "NERO: A Neural Rule Grounding Framework for Label-Efficient Relation\n  Extraction", "comments": "Accepted by WWW2020. Code available at\n  https://github.com/INK-USC/NERO", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural models for relation extraction tend to be less reliable when\nperfectly labeled data is limited, despite their success in label-sufficient\nscenarios. Instead of seeking more instance-level labels from human annotators,\nhere we propose to annotate frequent surface patterns to form labeling rules.\nThese rules can be automatically mined from large text corpora and generalized\nvia a soft rule matching mechanism. Prior works use labeling rules in an exact\nmatching fashion, which inherently limits the coverage of sentence matching and\nresults in the low-recall issue. In this paper, we present a neural approach to\nground rules for RE, named NERO, which jointly learns a relation extraction\nmodule and a soft matching module. One can employ any neural relation\nextraction models as the instantiation for the RE module. The soft matching\nmodule learns to match rules with semantically similar sentences such that raw\ncorpora can be automatically labeled and leveraged by the RE module (in a much\nbetter coverage) as augmented supervision, in addition to the exactly matched\nsentences. Extensive experiments and analysis on two public and widely-used\ndatasets demonstrate the effectiveness of the proposed NERO framework,\ncomparing with both rule-based and semi-supervised methods. Through user\nstudies, we find that the time efficiency for a human to annotate rules and\nsentences are similar (0.30 vs. 0.35 min per label). In particular, NERO's\nperformance using 270 rules is comparable to the models trained using 3,000\nlabeled sentences, yielding a 9.5x speedup. Moreover, NERO can predict for\nunseen relations at test time and provide interpretable predictions. We release\nour code to the community for future research.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 01:50:14 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2019 19:48:43 GMT"}, {"version": "v3", "created": "Fri, 1 Nov 2019 15:51:40 GMT"}, {"version": "v4", "created": "Wed, 15 Jan 2020 23:02:14 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Zhou", "Wenxuan", ""], ["Lin", "Hongtao", ""], ["Lin", "Bill Yuchen", ""], ["Wang", "Ziqi", ""], ["Du", "Junyi", ""], ["Neves", "Leonardo", ""], ["Ren", "Xiang", ""]]}, {"id": "1909.02188", "submitter": "Libo Qin", "authors": "Libo Qin, Wanxiang Che, Yangming Li, Haoyang Wen, Ting Liu", "title": "A Stack-Propagation Framework with Token-Level Intent Detection for\n  Spoken Language Understanding", "comments": "Accepted at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intent detection and slot filling are two main tasks for building a spoken\nlanguage understanding (SLU) system. The two tasks are closely tied and the\nslots often highly depend on the intent. In this paper, we propose a novel\nframework for SLU to better incorporate the intent information, which further\nguides the slot filling. In our framework, we adopt a joint model with\nStack-Propagation which can directly use the intent information as input for\nslot filling, thus to capture the intent semantic knowledge. In addition, to\nfurther alleviate the error propagation, we perform the token-level intent\ndetection for the Stack-Propagation framework. Experiments on two publicly\ndatasets show that our model achieves the state-of-the-art performance and\noutperforms other previous methods by a large margin. Finally, we use the\nBidirectional Encoder Representation from Transformer (BERT) model in our\nframework, which further boost our performance in SLU task.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 02:41:56 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Qin", "Libo", ""], ["Che", "Wanxiang", ""], ["Li", "Yangming", ""], ["Wen", "Haoyang", ""], ["Liu", "Ting", ""]]}, {"id": "1909.02195", "submitter": "Matthew Guzdial", "authors": "Shukan Shah, Matthew Guzdial, Mark O. Riedl", "title": "Automated Let's Play Commentary", "comments": "5 pages, 2 figures", "journal-ref": "Proceedings of the 2019 Experimental AI in Games Workshop", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let's Plays of video games represent a relatively unexplored area for\nexperimental AI in games. In this short paper, we discuss an approach to\ngenerate automated commentary for Let's Play videos, drawing on convolutional\ndeep neural networks. We focus on Let's Plays of the popular game Minecraft. We\ncompare our approach and a prior approach and demonstrate the generation of\nautomated, artificial commentary.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 03:30:26 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 20:40:28 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Shah", "Shukan", ""], ["Guzdial", "Matthew", ""], ["Riedl", "Mark O.", ""]]}, {"id": "1909.02197", "submitter": "Sneha Kudugunta", "authors": "Sneha Reddy Kudugunta, Ankur Bapna, Isaac Caswell, Naveen Arivazhagan,\n  Orhan Firat", "title": "Investigating Multilingual NMT Representations at Scale", "comments": "Paper at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual Neural Machine Translation (NMT) models have yielded large\nempirical success in transfer learning settings. However, these black-box\nrepresentations are poorly understood, and their mode of transfer remains\nelusive. In this work, we attempt to understand massively multilingual NMT\nrepresentations (with 103 languages) using Singular Value Canonical Correlation\nAnalysis (SVCCA), a representation similarity framework that allows us to\ncompare representations across different languages, layers and models. Our\nanalysis validates several empirical results and long-standing intuitions, and\nunveils new observations regarding how representations evolve in a multilingual\ntranslation model. We draw three major conclusions from our analysis, with\nimplications on cross-lingual transfer learning: (i) Encoder representations of\ndifferent languages cluster based on linguistic similarity, (ii)\nRepresentations of a source language learned by the encoder are dependent on\nthe target language, and vice-versa, and (iii) Representations of high resource\nand/or linguistically similar languages are more robust when fine-tuning on an\narbitrary language pair, which is critical to determining how much\ncross-lingual transfer can be expected in a zero or few-shot setting. We\nfurther connect our findings with existing empirical observations in\nmultilingual NMT and transfer learning.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 03:32:48 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 23:43:09 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Kudugunta", "Sneha Reddy", ""], ["Bapna", "Ankur", ""], ["Caswell", "Isaac", ""], ["Arivazhagan", "Naveen", ""], ["Firat", "Orhan", ""]]}, {"id": "1909.02201", "submitter": "Dong-Jin Kim", "authors": "Dong-Jin Kim, Jinsoo Choi, Tae-Hyun Oh, In So Kweon", "title": "Image Captioning with Very Scarce Supervised Data: Adversarial\n  Semi-Supervised Learning Approach", "comments": "EMNLP 2019. Project page :\n  https://sites.google.com/view/emnlp19scarcecaption", "journal-ref": null, "doi": "10.18653/v1/D19-1208", "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constructing an organized dataset comprised of a large number of images and\nseveral captions for each image is a laborious task, which requires vast human\neffort. On the other hand, collecting a large number of images and sentences\nseparately may be immensely easier. In this paper, we develop a novel\ndata-efficient semi-supervised framework for training an image captioning\nmodel. We leverage massive unpaired image and caption data by learning to\nassociate them. To this end, our proposed semi-supervised learning method\nassigns pseudo-labels to unpaired samples via Generative Adversarial Networks\nto learn the joint distribution of image and caption. To evaluate, we construct\nscarcely-paired COCO dataset, a modified version of MS COCO caption dataset.\nThe empirical results show the effectiveness of our method compared to several\nstrong baselines, especially when the amount of the paired samples are scarce.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 04:16:48 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 07:01:02 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Kim", "Dong-Jin", ""], ["Choi", "Jinsoo", ""], ["Oh", "Tae-Hyun", ""], ["Kweon", "In So", ""]]}, {"id": "1909.02209", "submitter": "Zhuosheng Zhang", "authors": "Zhuosheng Zhang, Yuwei Wu, Hai Zhao, Zuchao Li, Shuailiang Zhang, Xi\n  Zhou, Xiang Zhou", "title": "Semantics-aware BERT for Language Understanding", "comments": "Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The latest work on language representations carefully integrates\ncontextualized features into language model training, which enables a series of\nsuccess especially in various machine reading comprehension and natural\nlanguage inference tasks. However, the existing language representation models\nincluding ELMo, GPT and BERT only exploit plain context-sensitive features such\nas character or word embeddings. They rarely consider incorporating structured\nsemantic information which can provide rich semantics for language\nrepresentation. To promote natural language understanding, we propose to\nincorporate explicit contextual semantics from pre-trained semantic role\nlabeling, and introduce an improved language representation model,\nSemantics-aware BERT (SemBERT), which is capable of explicitly absorbing\ncontextual semantics over a BERT backbone. SemBERT keeps the convenient\nusability of its BERT precursor in a light fine-tuning way without substantial\ntask-specific modifications. Compared with BERT, semantics-aware BERT is as\nsimple in concept but more powerful. It obtains new state-of-the-art or\nsubstantially improves results on ten reading comprehension and language\ninference tasks.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 04:47:10 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 03:38:35 GMT"}, {"version": "v3", "created": "Tue, 4 Feb 2020 09:43:22 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Zhang", "Zhuosheng", ""], ["Wu", "Yuwei", ""], ["Zhao", "Hai", ""], ["Li", "Zuchao", ""], ["Zhang", "Shuailiang", ""], ["Zhou", "Xi", ""], ["Zhou", "Xiang", ""]]}, {"id": "1909.02217", "submitter": "Ming Jiang", "authors": "Ming Jiang, Junjie Hu, Qiuyuan Huang, Lei Zhang, Jana Diesner,\n  Jianfeng Gao", "title": "REO-Relevance, Extraness, Omission: A Fine-grained Evaluation for Image\n  Captioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Popular metrics used for evaluating image captioning systems, such as BLEU\nand CIDEr, provide a single score to gauge the system's overall effectiveness.\nThis score is often not informative enough to indicate what specific errors are\nmade by a given system. In this study, we present a fine-grained evaluation\nmethod REO for automatically measuring the performance of image captioning\nsystems. REO assesses the quality of captions from three perspectives: 1)\nRelevance to the ground truth, 2) Extraness of the content that is irrelevant\nto the ground truth, and 3) Omission of the elements in the images and human\nreferences. Experiments on three benchmark datasets demonstrate that our method\nachieves a higher consistency with human judgments and provides more intuitive\nevaluation results than alternative metrics.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 05:44:46 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Jiang", "Ming", ""], ["Hu", "Junjie", ""], ["Huang", "Qiuyuan", ""], ["Zhang", "Lei", ""], ["Diesner", "Jana", ""], ["Gao", "Jianfeng", ""]]}, {"id": "1909.02218", "submitter": "Hongyang Xue", "authors": "Hongyang Xue, Wenqing Chu, Zhou Zhao, Deng Cai", "title": "A Better Way to Attend: Attention with Trees for Video Question\n  Answering", "comments": "12 pages", "journal-ref": "IEEE Transactions on Image Processing ( Volume: 27 , Issue: 11 ,\n  Nov. 2018 )", "doi": "10.1109/TIP.2018.2859820", "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new attention model for video question answering. The main idea\nof the attention models is to locate on the most informative parts of the\nvisual data. The attention mechanisms are quite popular these days. However,\nmost existing visual attention mechanisms regard the question as a whole. They\nignore the word-level semantics where each word can have different attentions\nand some words need no attention. Neither do they consider the semantic\nstructure of the sentences. Although the Extended Soft Attention (E-SA) model\nfor video question answering leverages the word-level attention, it performs\npoorly on long question sentences. In this paper, we propose the heterogeneous\ntree-structured memory network (HTreeMN) for video question answering. Our\nproposed approach is based upon the syntax parse trees of the question\nsentences. The HTreeMN treats the words differently where the \\textit{visual}\nwords are processed with an attention module and the \\textit{verbal} ones not.\nIt also utilizes the semantic structure of the sentences by combining the\nneighbors based on the recursive structure of the parse trees. The\nunderstandings of the words and the videos are propagated and merged from\nleaves to the root. Furthermore, we build a hierarchical attention mechanism to\ndistill the attended features. We evaluate our approach on two datasets. The\nexperimental results show the superiority of our HTreeMN model over the other\nattention models especially on complex questions. Our code is available on\ngithub.\n  Our code is available at https://github.com/ZJULearning/TreeAttention\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 05:48:51 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Xue", "Hongyang", ""], ["Chu", "Wenqing", ""], ["Zhao", "Zhou", ""], ["Cai", "Deng", ""]]}, {"id": "1909.02222", "submitter": "Jie Hao", "authors": "Jie Hao, Xing Wang, Shuming Shi, Jinfeng Zhang, Zhaopeng Tu", "title": "Multi-Granularity Self-Attention for Neural Machine Translation", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current state-of-the-art neural machine translation (NMT) uses a deep\nmulti-head self-attention network with no explicit phrase information. However,\nprior work on statistical machine translation has shown that extending the\nbasic translation unit from words to phrases has produced substantial\nimprovements, suggesting the possibility of improving NMT performance from\nexplicit modeling of phrases. In this work, we present multi-granularity\nself-attention (Mg-Sa): a neural network that combines multi-head\nself-attention and phrase modeling. Specifically, we train several attention\nheads to attend to phrases in either n-gram or syntactic formalism. Moreover,\nwe exploit interactions among phrases to enhance the strength of structure\nmodeling - a commonly-cited weakness of self-attention. Experimental results on\nWMT14 English-to-German and NIST Chinese-to-English translation tasks show the\nproposed approach consistently improves performance. Targeted linguistic\nanalysis reveals that Mg-Sa indeed captures useful phrase information at\nvarious levels of granularities.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 06:16:23 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Hao", "Jie", ""], ["Wang", "Xing", ""], ["Shi", "Shuming", ""], ["Zhang", "Jinfeng", ""], ["Tu", "Zhaopeng", ""]]}, {"id": "1909.02224", "submitter": "Pei Zhou", "authors": "Pei Zhou, Weijia Shi, Jieyu Zhao, Kuan-Hao Huang, Muhao Chen, Ryan\n  Cotterell and Kai-Wei Chang", "title": "Examining Gender Bias in Languages with Grammatical Gender", "comments": "9 pages, 4 figures. Accepted at EMNLP-IJCNLP 2019 as a long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that word embeddings exhibit gender bias inherited\nfrom the training corpora. However, most studies to date have focused on\nquantifying and mitigating such bias only in English. These analyses cannot be\ndirectly extended to languages that exhibit morphological agreement on gender,\nsuch as Spanish and French. In this paper, we propose new metrics for\nevaluating gender bias in word embeddings of these languages and further\ndemonstrate evidence of gender bias in bilingual embeddings which align these\nlanguages with English. Finally, we extend an existing approach to mitigate\ngender bias in word embeddings under both monolingual and bilingual settings.\nExperiments on modified Word Embedding Association Test, word similarity, word\ntranslation, and word pair translation tasks show that the proposed approaches\neffectively reduce the gender bias while preserving the utility of the\nembeddings.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 06:20:43 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 19:22:25 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Zhou", "Pei", ""], ["Shi", "Weijia", ""], ["Zhao", "Jieyu", ""], ["Huang", "Kuan-Hao", ""], ["Chen", "Muhao", ""], ["Cotterell", "Ryan", ""], ["Chang", "Kai-Wei", ""]]}, {"id": "1909.02235", "submitter": "Meishan Zhang", "authors": "Zhang Meishan and Zhang Yue and Fu Guohong", "title": "Cross-Lingual Dependency Parsing Using Code-Mixed TreeBank", "comments": "10 pages", "journal-ref": "EMNLP 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Treebank translation is a promising method for cross-lingual transfer of\nsyntactic dependency knowledge. The basic idea is to map dependency arcs from a\nsource treebank to its target translation according to word alignments. This\nmethod, however, can suffer from imperfect alignment between source and target\nwords. To address this problem, we investigate syntactic transfer by code\nmixing, translating only confident words in a source treebank. Cross-lingual\nword embeddings are leveraged for transferring syntactic knowledge to the\ntarget from the resulting code-mixed treebank. Experiments on University\nDependency Treebanks show that code-mixed treebanks are more effective than\ntranslated treebanks, giving highly competitive performances among\ncross-lingual parsing methods.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 07:10:44 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Meishan", "Zhang", ""], ["Yue", "Zhang", ""], ["Guohong", "Fu", ""]]}, {"id": "1909.02244", "submitter": "Xiujun Li", "authors": "Xiujun Li and Chunyuan Li and Qiaolin Xia and Yonatan Bisk and Asli\n  Celikyilmaz and Jianfeng Gao and Noah Smith and Yejin Choi", "title": "Robust Navigation with Language Pretraining and Stochastic Sampling", "comments": "8 pages, 4 figures, EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Core to the vision-and-language navigation (VLN) challenge is building robust\ninstruction representations and action decoding schemes, which can generalize\nwell to previously unseen instructions and environments. In this paper, we\nreport two simple but highly effective methods to address these challenges and\nlead to a new state-of-the-art performance. First, we adapt large-scale\npretrained language models to learn text representations that generalize better\nto previously unseen instructions. Second, we propose a stochastic sampling\nscheme to reduce the considerable gap between the expert actions in training\nand sampled actions in test, so that the agent can learn to correct its own\nmistakes during long sequential action decoding. Combining the two techniques,\nwe achieve a new state of the art on the Room-to-Room benchmark with 6%\nabsolute gain over the previous best result (47% -> 53%) on the Success Rate\nweighted by Path Length metric.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 07:31:58 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Li", "Xiujun", ""], ["Li", "Chunyuan", ""], ["Xia", "Qiaolin", ""], ["Bisk", "Yonatan", ""], ["Celikyilmaz", "Asli", ""], ["Gao", "Jianfeng", ""], ["Smith", "Noah", ""], ["Choi", "Yejin", ""]]}, {"id": "1909.02250", "submitter": "Takashi Shibuya", "authors": "Takashi Shibuya, Eduard Hovy", "title": "Nested Named Entity Recognition via Second-best Sequence Learning and\n  Decoding", "comments": "Accepted to TACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When an entity name contains other names within it, the identification of all\ncombinations of names can become difficult and expensive. We propose a new\nmethod to recognize not only outermost named entities but also inner nested\nones. We design an objective function for training a neural model that treats\nthe tag sequence for nested entities as the second best path within the span of\ntheir parent entity. In addition, we provide the decoding method for inference\nthat extracts entities iteratively from outermost ones to inner ones in an\noutside-to-inside way. Our method has no additional hyperparameters to the\nconditional random field based model widely used for flat named entity\nrecognition tasks. Experiments demonstrate that our method performs better than\nor at least as well as existing methods capable of handling nested entities,\nachieving the F1-scores of 85.82%, 84.34%, and 77.36% on ACE-2004, ACE-2005,\nand GENIA datasets, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 07:56:45 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 06:43:48 GMT"}, {"version": "v3", "created": "Fri, 10 Jul 2020 06:04:22 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Shibuya", "Takashi", ""], ["Hovy", "Eduard", ""]]}, {"id": "1909.02265", "submitter": "Phuong Le-Hong", "authors": "Tho Luong Chi and Phuong Le-Hong", "title": "Towards Task-Oriented Dialogue in Mixed Domains", "comments": "Accepted for conference PACLING 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates the task-oriented dialogue problem in mixed-domain\nsettings. We study the effect of alternating between different domains in\nsequences of dialogue turns using two related state-of-the-art dialogue\nsystems. We first show that a specialized state tracking component in multiple\ndomains plays an important role and gives better results than an end-to-end\ntask-oriented dialogue system. We then propose a hybrid system which is able to\nimprove the belief tracking accuracy of about 28% of average absolute point on\na standard multi-domain dialogue dataset. These experimental results give some\nuseful insights for improving our commercial chatbot platform FPT.AI, which is\ncurrently deployed for many practical chatbot applications.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 08:47:49 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Chi", "Tho Luong", ""], ["Le-Hong", "Phuong", ""]]}, {"id": "1909.02273", "submitter": "Chengyi Wang", "authors": "Chengyi Wang, Shuangzhi Wu, Shujie Liu", "title": "Source Dependency-Aware Transformer with Supervised Self-Attention", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Transformer has achieved the state-of-the-art performance on many\nmachine translation tasks. However, without syntax knowledge explicitly\nconsidered in the encoder, incorrect context information that violates the\nsyntax structure may be integrated into source hidden states, leading to\nerroneous translations. In this paper, we propose a novel method to incorporate\nsource dependencies into the Transformer. Specifically, we adopt the source\ndependency tree and define two matrices to represent the dependency relations.\nBased on the matrices, two heads in the multi-head self-attention module are\ntrained in a supervised manner and two extra cross entropy losses are\nintroduced into the training objective function. Under this training objective,\nthe model is trained to learn the source dependency relations directly. Without\nrequiring pre-parsed input during inference, our model can generate better\ntranslations with the dependency-aware context information. Experiments on\nbi-directional Chinese-to-English, English-to-Japanese and English-to-German\ntranslation tasks show that our proposed method can significantly improve the\nTransformer baseline.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 09:17:37 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Wang", "Chengyi", ""], ["Wu", "Shuangzhi", ""], ["Liu", "Shujie", ""]]}, {"id": "1909.02279", "submitter": "Chengyi Wang", "authors": "Chengyi Wang, Shuangzhi Wu, Shujie Liu", "title": "Accelerating Transformer Decoding via a Hybrid of Self-attention and\n  Recurrent Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the highly parallelizable architecture, Transformer is faster to train\nthan RNN-based models and popularly used in machine translation tasks. However,\nat inference time, each output word requires all the hidden states of the\npreviously generated words, which limits the parallelization capability, and\nmakes it much slower than RNN-based ones. In this paper, we systematically\nanalyze the time cost of different components of both the Transformer and\nRNN-based model. Based on it, we propose a hybrid network of self-attention and\nRNN structures, in which, the highly parallelizable self-attention is utilized\nas the encoder, and the simpler RNN structure is used as the decoder. Our\nhybrid network can decode 4-times faster than the Transformer. In addition,\nwith the help of knowledge distillation, our hybrid network achieves comparable\ntranslation quality to the original Transformer.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 09:22:25 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Wang", "Chengyi", ""], ["Wu", "Shuangzhi", ""], ["Liu", "Shujie", ""]]}, {"id": "1909.02304", "submitter": "Heng Gong", "authors": "Heng Gong, Xiaocheng Feng, Bing Qin, Ting Liu", "title": "Table-to-Text Generation with Effective Hierarchical Encoder on Three\n  Dimensions (Row, Column and Time)", "comments": "EMNLP 2019 (Long paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although Seq2Seq models for table-to-text generation have achieved remarkable\nprogress, modeling table representation in one dimension is inadequate. This is\nbecause (1) the table consists of multiple rows and columns, which means that\nencoding a table should not depend only on one dimensional sequence or set of\nrecords and (2) most of the tables are time series data (e.g. NBA game data,\nstock market data), which means that the description of the current table may\nbe affected by its historical data. To address aforementioned problems, not\nonly do we model each table cell considering other records in the same row, we\nalso enrich table's representation by modeling each table cell in context of\nother cells in the same column or with historical (time dimension) data\nrespectively. In addition, we develop a table cell fusion gate to combine\nrepresentations from row, column and time dimension into one dense vector\naccording to the saliency of each dimension's representation. We evaluated our\nmethods on ROTOWIRE, a benchmark dataset of NBA basketball games. Both\nautomatic and human evaluation results demonstrate the effectiveness of our\nmodel with improvement of 2.66 in BLEU over the strong baseline and\noutperformance of state-of-the-art model.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 10:25:34 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Gong", "Heng", ""], ["Feng", "Xiaocheng", ""], ["Qin", "Bing", ""], ["Liu", "Ting", ""]]}, {"id": "1909.02307", "submitter": "Laura Rettig", "authors": "Laura Rettig, Julien Audiffren, Philippe Cudr\\'e-Mauroux", "title": "Fusing Vector Space Models for Domain-Specific Applications", "comments": "ICTAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of tuning word embeddings for specific use cases and\ndomains. We propose a new method that automatically combines multiple\ndomain-specific embeddings, selected from a wide range of pre-trained\ndomain-specific embeddings, to improve their combined expressive power. Our\napproach relies on two key components: 1) a ranking function, based on a new\nembedding similarity measure, that selects the most relevant embeddings to use\ngiven a domain and 2) a dimensionality reduction method that combines the\nselected embeddings to produce a more compact and efficient encoding that\npreserves the expressiveness. We empirically show that our method produces\neffective domain-specific embeddings that consistently improve the performance\nof state-of-the-art machine learning algorithms on multiple tasks, compared to\ngeneric embeddings trained on large text corpora.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 10:34:07 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Rettig", "Laura", ""], ["Audiffren", "Julien", ""], ["Cudr\u00e9-Mauroux", "Philippe", ""]]}, {"id": "1909.02314", "submitter": "Javier \\'Alvez", "authors": "Javier \\'Alvez and Itziar Gonzalez-Dios and German Rigau", "title": "Commonsense Reasoning Using WordNet and SUMO: a Detailed Analysis", "comments": "9 pages, 2 figures, 2 tables; 10th Global WordNet Conference - GWC\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a detailed analysis of a sample of large benchmark of commonsense\nreasoning problems that has been automatically obtained from WordNet, SUMO and\ntheir mapping. The objective is to provide a better assessment of the quality\nof both the benchmark and the involved knowledge resources for advanced\ncommonsense reasoning tasks. By means of this analysis, we are able to detect\nsome knowledge misalignments, mapping errors and lack of knowledge and\nresources. Our final objective is the extraction of some guidelines towards a\nbetter exploitation of this commonsense knowledge framework by the improvement\nof the included resources.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 10:54:03 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 16:46:34 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["\u00c1lvez", "Javier", ""], ["Gonzalez-Dios", "Itziar", ""], ["Rigau", "German", ""]]}, {"id": "1909.02322", "submitter": "Reinald Kim Amplayo", "authors": "Reinald Kim Amplayo and Mirella Lapata", "title": "Informative and Controllable Opinion Summarization", "comments": "EACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Opinion summarization is the task of automatically generating summaries for a\nset of reviews about a specific target (e.g., a movie or a product). Since the\nnumber of reviews for each target can be prohibitively large, neural\nnetwork-based methods follow a two-stage approach where an extractive step\nfirst pre-selects a subset of salient opinions and an abstractive step creates\nthe summary while conditioning on the extracted subset. However, the extractive\nmodel leads to loss of information which may be useful depending on user needs.\nIn this paper we propose a summarization framework that eliminates the need to\nrely only on pre-selected content and waste possibly useful information,\nespecially when customizing summaries. The framework enables the use of all\ninput reviews by first condensing them into multiple dense vectors which serve\nas input to an abstractive model. We showcase an effective instantiation of our\nframework which produces more informative summaries and also allows to take\nuser preferences into account using our zero-shot customization technique.\nExperimental results demonstrate that our model improves the state of the art\non the Rotten Tomatoes dataset and generates customized summaries effectively.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 11:11:41 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2021 16:06:35 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Amplayo", "Reinald Kim", ""], ["Lapata", "Mirella", ""]]}, {"id": "1909.02339", "submitter": "Anne Lauscher", "authors": "Anne Lauscher, Ivan Vuli\\'c, Edoardo Maria Ponti, Anna Korhonen, and\n  Goran Glava\\v{s}", "title": "Specializing Unsupervised Pretraining Models for Word-Level Semantic\n  Similarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised pretraining models have been shown to facilitate a wide range of\ndownstream NLP applications. These models, however, retain some of the\nlimitations of traditional static word embeddings. In particular, they encode\nonly the distributional knowledge available in raw text corpora, incorporated\nthrough language modeling objectives. In this work, we complement such\ndistributional knowledge with external lexical knowledge, that is, we integrate\nthe discrete knowledge on word-level semantic similarity into pretraining. To\nthis end, we generalize the standard BERT model to a multi-task learning\nsetting where we couple BERT's masked language modeling and next sentence\nprediction objectives with an auxiliary task of binary word relation\nclassification. Our experiments suggest that our \"Lexically Informed\" BERT\n(LIBERT), specialized for the word-level semantic similarity, yields better\nperformance than the lexically blind \"vanilla\" BERT on several language\nunderstanding tasks. Concretely, LIBERT outperforms BERT in 9 out of 10 tasks\nof the GLUE benchmark and is on a par with BERT in the remaining one. Moreover,\nwe show consistent gains on 3 benchmarks for lexical simplification, a task\nwhere knowledge about word-level semantic similarity is paramount.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 11:49:40 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 15:31:20 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Lauscher", "Anne", ""], ["Vuli\u0107", "Ivan", ""], ["Ponti", "Edoardo Maria", ""], ["Korhonen", "Anna", ""], ["Glava\u0161", "Goran", ""]]}, {"id": "1909.02392", "submitter": "Rahul Aralikatte", "authors": "Rahul Aralikatte, Heather Lent, Ana Valeria Gonzalez, Daniel\n  Hershcovich, Chen Qiu, Anders Sandholm, Michael Ringaard, Anders S{\\o}gaard", "title": "Rewarding Coreference Resolvers for Being Consistent with World\n  Knowledge", "comments": "To appear in EMNLP 2019 (with corrected Fig. 2)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unresolved coreference is a bottleneck for relation extraction, and\nhigh-quality coreference resolvers may produce an output that makes it a lot\neasier to extract knowledge triples. We show how to improve coreference\nresolvers by forwarding their input to a relation extraction system and reward\nthe resolvers for producing triples that are found in knowledge bases. Since\nrelation extraction systems can rely on different forms of supervision and be\nbiased in different ways, we obtain the best performance, improving over the\nstate of the art, using multi-task reinforcement learning.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 13:29:26 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 21:56:27 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Aralikatte", "Rahul", ""], ["Lent", "Heather", ""], ["Gonzalez", "Ana Valeria", ""], ["Hershcovich", "Daniel", ""], ["Qiu", "Chen", ""], ["Sandholm", "Anders", ""], ["Ringaard", "Michael", ""], ["S\u00f8gaard", "Anders", ""]]}, {"id": "1909.02399", "submitter": "Yidan Hu", "authors": "Yuan Miao, Gongqi Lin, Yidan Hu, Chunyan Miao", "title": "Reading Comprehension Ability Test-A Turing Test for Reading\n  Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reading comprehension is an important ability of human intelligence. Literacy\nand numeracy are two most essential foundation for people to succeed at study,\nat work and in life. Reading comprehension ability is a core component of\nliteracy. In most of the education systems, developing reading comprehension\nability is compulsory in the curriculum from year one to year 12. It is an\nindispensable ability in the dissemination of knowledge. With the emerging\nartificial intelligence, computers start to be able to read and understand like\npeople in some context. They can even read better than human beings for some\ntasks, but have little clue in other tasks. It will be very beneficial if we\ncan identify the levels of machine comprehension ability, which will direct us\non the further improvement. Turing test is a well-known test of the difference\nbetween computer intelligence and human intelligence. In order to be able to\ncompare the difference between people reading and machines reading, we proposed\na test called (reading) Comprehension Ability Test (CAT).CAT is similar to\nTuring test, passing of which means we cannot differentiate people from\nalgorithms in term of their comprehension ability. CAT has multiple levels\nshowing the different abilities in reading comprehension, from identifying\nbasic facts, performing inference, to understanding the intent and sentiment.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 13:33:11 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Miao", "Yuan", ""], ["Lin", "Gongqi", ""], ["Hu", "Yidan", ""], ["Miao", "Chunyan", ""]]}, {"id": "1909.02476", "submitter": "Aneek Barman Roy", "authors": "Aneek Barman Roy, Baolei Chen, Siddharth Tiwari and Zihan Huang", "title": "A Discussion on Influence of Newspaper Headlines on Social Media", "comments": "13 pages, 11 Figures, 3 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Newspaper headlines contribute severely and have an influence on the social\nmedia. This work studies the durability of impact of verbs and adjectives on\nheadlines and determine the factors which are responsible for its nature of\ninfluence on the social media. Each headline has been categorized into\npositive, negative or neutral based on its sentiment score. Initial results\nshow that intensity of a sentiment nature is positively correlated with the\nsocial media impression. Additionally, verbs and adjectives show a relation\nwith the sentiment scores\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 15:22:44 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Roy", "Aneek Barman", ""], ["Chen", "Baolei", ""], ["Tiwari", "Siddharth", ""], ["Huang", "Zihan", ""]]}, {"id": "1909.02480", "submitter": "Chunting Zhou", "authors": "Xuezhe Ma, Chunting Zhou, Xian Li, Graham Neubig, Eduard Hovy", "title": "FlowSeq: Non-Autoregressive Conditional Sequence Generation with\n  Generative Flow", "comments": "Accepted by EMNLP 2019 (Long Paper)", "journal-ref": "EMNLP 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most sequence-to-sequence (seq2seq) models are autoregressive; they generate\neach token by conditioning on previously generated tokens. In contrast,\nnon-autoregressive seq2seq models generate all tokens in one pass, which leads\nto increased efficiency through parallel processing on hardware such as GPUs.\nHowever, directly modeling the joint distribution of all tokens simultaneously\nis challenging, and even with increasingly complex model structures accuracy\nlags significantly behind autoregressive models. In this paper, we propose a\nsimple, efficient, and effective model for non-autoregressive sequence\ngeneration using latent variable models. Specifically, we turn to generative\nflow, an elegant technique to model complex distributions using neural\nnetworks, and design several layers of flow tailored for modeling the\nconditional density of sequential latent variables. We evaluate this model on\nthree neural machine translation (NMT) benchmark datasets, achieving comparable\nperformance with state-of-the-art non-autoregressive NMT models and almost\nconstant decoding time w.r.t the sequence length.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 15:32:34 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 21:57:15 GMT"}, {"version": "v3", "created": "Wed, 9 Oct 2019 05:37:40 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Ma", "Xuezhe", ""], ["Zhou", "Chunting", ""], ["Li", "Xian", ""], ["Neubig", "Graham", ""], ["Hovy", "Eduard", ""]]}, {"id": "1909.02489", "submitter": "Wei Wei", "authors": "Wei Wei, Ling Cheng, Xianling Mao, Guangyou Zhou, and Feida Zhu", "title": "Stack-VS: Stacked Visual-Semantic Attention for Image Caption Generation", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, automatic image caption generation has been an important focus of\nthe work on multimodal translation task. Existing approaches can be roughly\ncategorized into two classes, i.e., top-down and bottom-up, the former\ntransfers the image information (called as visual-level feature) directly into\na caption, and the later uses the extracted words (called as semanticlevel\nattribute) to generate a description. However, previous methods either are\ntypically based one-stage decoder or partially utilize part of visual-level or\nsemantic-level information for image caption generation. In this paper, we\naddress the problem and propose an innovative multi-stage architecture (called\nas Stack-VS) for rich fine-gained image caption generation, via combining\nbottom-up and top-down attention models to effectively handle both visual-level\nand semantic-level information of an input image. Specifically, we also propose\na novel well-designed stack decoder model, which is constituted by a sequence\nof decoder cells, each of which contains two LSTM-layers work interactively to\nre-optimize attention weights on both visual-level feature vectors and\nsemantic-level attribute embeddings for generating a fine-gained image caption.\nExtensive experiments on the popular benchmark dataset MSCOCO show the\nsignificant improvements on different evaluation metrics, i.e., the\nimprovements on BLEU-4/CIDEr/SPICE scores are 0.372, 1.226 and 0.216,\nrespectively, as compared to the state-of-the-arts.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 15:41:53 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Wei", "Wei", ""], ["Cheng", "Ling", ""], ["Mao", "Xianling", ""], ["Zhou", "Guangyou", ""], ["Zhu", "Feida", ""]]}, {"id": "1909.02560", "submitter": "Zhouxing Shi", "authors": "Zhouxing Shi, Minlie Huang", "title": "Robustness to Modification with Shared Words in Paraphrase\n  Identification", "comments": "Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Revealing the robustness issues of natural language processing models and\nimproving their robustness is important to their performance under difficult\nsituations. In this paper, we study the robustness of paraphrase identification\nmodels from a new perspective -- via modification with shared words, and we\nshow that the models have significant robustness issues when facing such\nmodifications. To modify an example consisting of a sentence pair, we either\nreplace some words shared by both sentences or introduce new shared words. We\naim to construct a valid new example such that a target model makes a wrong\nprediction. To find a modification solution, we use beam search constrained by\nheuristic rules, and we leverage a BERT masked language model for generating\nsubstitution words compatible with the context. Experiments show that the\nperformance of the target models has a dramatic drop on the modified examples,\nthereby revealing the robustness issue. We also show that adversarial training\ncan mitigate this issue.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 17:59:15 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 17:46:33 GMT"}, {"version": "v3", "created": "Sun, 10 Nov 2019 11:52:40 GMT"}, {"version": "v4", "created": "Sat, 2 May 2020 04:38:11 GMT"}, {"version": "v5", "created": "Mon, 5 Oct 2020 06:20:50 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Shi", "Zhouxing", ""], ["Huang", "Minlie", ""]]}, {"id": "1909.02597", "submitter": "Jason Phang", "authors": "Alex Warstadt, Yu Cao, Ioana Grosu, Wei Peng, Hagen Blix, Yining Nie,\n  Anna Alsop, Shikha Bordia, Haokun Liu, Alicia Parrish, Sheng-Fu Wang, Jason\n  Phang, Anhad Mohananey, Phu Mon Htut, Paloma Jereti\\v{c} and Samuel R. Bowman", "title": "Investigating BERT's Knowledge of Language: Five Analysis Methods with\n  NPIs", "comments": "Accepted to EMNLP 2019; Added link to code+dataset", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though state-of-the-art sentence representation models can perform tasks\nrequiring significant knowledge of grammar, it is an open question how best to\nevaluate their grammatical knowledge. We explore five experimental methods\ninspired by prior work evaluating pretrained sentence representation models. We\nuse a single linguistic phenomenon, negative polarity item (NPI) licensing in\nEnglish, as a case study for our experiments. NPIs like \"any\" are grammatical\nonly if they appear in a licensing environment like negation (\"Sue doesn't have\nany cats\" vs. \"Sue has any cats\"). This phenomenon is challenging because of\nthe variety of NPI licensing environments that exist. We introduce an\nartificially generated dataset that manipulates key features of NPI licensing\nfor the experiments. We find that BERT has significant knowledge of these\nfeatures, but its success varies widely across different experimental methods.\nWe conclude that a variety of methods is necessary to reveal all relevant\naspects of a model's grammatical knowledge in a given domain.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 18:58:51 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 18:13:06 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Warstadt", "Alex", ""], ["Cao", "Yu", ""], ["Grosu", "Ioana", ""], ["Peng", "Wei", ""], ["Blix", "Hagen", ""], ["Nie", "Yining", ""], ["Alsop", "Anna", ""], ["Bordia", "Shikha", ""], ["Liu", "Haokun", ""], ["Parrish", "Alicia", ""], ["Wang", "Sheng-Fu", ""], ["Phang", "Jason", ""], ["Mohananey", "Anhad", ""], ["Htut", "Phu Mon", ""], ["Jereti\u010d", "Paloma", ""], ["Bowman", "Samuel R.", ""]]}, {"id": "1909.02606", "submitter": "Binxuan Huang", "authors": "Binxuan Huang, Kathleen M. Carley", "title": "Syntax-Aware Aspect Level Sentiment Classification with Graph Attention\n  Networks", "comments": "Accepted by EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect level sentiment classification aims to identify the sentiment\nexpressed towards an aspect given a context sentence. Previous neural network\nbased methods largely ignore the syntax structure in one sentence. In this\npaper, we propose a novel target-dependent graph attention network (TD-GAT) for\naspect level sentiment classification, which explicitly utilizes the dependency\nrelationship among words. Using the dependency graph, it propagates sentiment\nfeatures directly from the syntactic context of an aspect target. In our\nexperiments, we show our method outperforms multiple baselines with GloVe\nembeddings. We also demonstrate that using BERT representations further\nsubstantially boosts the performance.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 19:20:27 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Huang", "Binxuan", ""], ["Carley", "Kathleen M.", ""]]}, {"id": "1909.02607", "submitter": "Sheng Zhang", "authors": "Sheng Zhang and Xutai Ma and Kevin Duh and Benjamin Van Durme", "title": "Broad-Coverage Semantic Parsing as Transduction", "comments": "Accepted at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We unify different broad-coverage semantic parsing tasks under a transduction\nparadigm, and propose an attention-based neural framework that incrementally\nbuilds a meaning representation via a sequence of semantic relations. By\nleveraging multiple attention mechanisms, the transducer can be effectively\ntrained without relying on a pre-trained aligner. Experiments conducted on\nthree separate broad-coverage semantic parsing tasks -- AMR, SDP and UCCA --\ndemonstrate that our attention-based neural transducer improves the state of\nthe art on both AMR and UCCA, and is competitive with the state of the art on\nSDP.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 19:21:27 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 19:58:41 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Zhang", "Sheng", ""], ["Ma", "Xutai", ""], ["Duh", "Kevin", ""], ["Van Durme", "Benjamin", ""]]}, {"id": "1909.02621", "submitter": "Masato Hagiwara", "authors": "Masato Hagiwara, Takumi Ito, Tatsuki Kuribayashi, Jun Suzuki, Kentaro\n  Inui", "title": "TEASPN: Framework and Protocol for Integrated Writing Assistance\n  Environments", "comments": "Accepted at EMNLP 2019 (system demonstrations)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language technologies play a key role in assisting people with their writing.\nAlthough there has been steady progress in e.g., grammatical error correction\n(GEC), human writers are yet to benefit from this progress due to the high\ndevelopment cost of integrating with writing software. We propose TEASPN, a\nprotocol and an open-source framework for achieving integrated writing\nassistance environments. The protocol standardizes the way writing software\ncommunicates with servers that implement such technologies, allowing developers\nand researchers to integrate the latest developments in natural language\nprocessing (NLP) with low cost. As a result, users can enjoy the integrated\nexperience in their favorite writing software. The results from experiments\nwith human participants show that users use a wide range of technologies and\nrate their writing experience favorably, allowing them to write more fluent\ntext.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 20:26:10 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Hagiwara", "Masato", ""], ["Ito", "Takumi", ""], ["Kuribayashi", "Tatsuki", ""], ["Suzuki", "Jun", ""], ["Inui", "Kentaro", ""]]}, {"id": "1909.02622", "submitter": "Wei Zhao", "authors": "Wei Zhao, Maxime Peyrard, Fei Liu, Yang Gao, Christian M. Meyer,\n  Steffen Eger", "title": "MoverScore: Text Generation Evaluating with Contextualized Embeddings\n  and Earth Mover Distance", "comments": "EMNLP19 Camera-Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A robust evaluation metric has a profound impact on the development of text\ngeneration systems. A desirable metric compares system output against\nreferences based on their semantics rather than surface forms. In this paper we\ninvestigate strategies to encode system and reference texts to devise a metric\nthat shows a high correlation with human judgment of text quality. We validate\nour new metric, namely MoverScore, on a number of text generation tasks\nincluding summarization, machine translation, image captioning, and\ndata-to-text generation, where the outputs are produced by a variety of neural\nand non-neural systems. Our findings suggest that metrics combining\ncontextualized representations with a distance measure perform the best. Such\nmetrics also demonstrate strong generalization capability across tasks. For\nease-of-use we make our metrics available as web service.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 20:26:44 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 09:56:23 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Zhao", "Wei", ""], ["Peyrard", "Maxime", ""], ["Liu", "Fei", ""], ["Gao", "Yang", ""], ["Meyer", "Christian M.", ""], ["Eger", "Steffen", ""]]}, {"id": "1909.02635", "submitter": "Aditya Gupta", "authors": "Aditya Gupta and Greg Durrett", "title": "Effective Use of Transformer Networks for Entity Tracking", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tracking entities in procedural language requires understanding the\ntransformations arising from actions on entities as well as those entities'\ninteractions. While self-attention-based pre-trained language encoders like GPT\nand BERT have been successfully applied across a range of natural language\nunderstanding tasks, their ability to handle the nuances of procedural texts is\nstill untested. In this paper, we explore the use of pre-trained transformer\nnetworks for entity tracking tasks in procedural text. First, we test standard\nlightweight approaches for prediction with pre-trained transformers, and find\nthat these approaches underperform even simple baselines. We show that much\nstronger results can be attained by restructuring the input to guide the\ntransformer model to focus on a particular entity. Second, we assess the degree\nto which transformer networks capture the process dynamics, investigating such\nfactors as merged entities and oblique entity references. On two different\ntasks, ingredient detection in recipes and QA over scientific processes, we\nachieve state-of-the-art results, but our models still largely attend to\nshallow context clues and do not form complex representations of intermediate\nentity or process state.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 21:13:37 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Gupta", "Aditya", ""], ["Durrett", "Greg", ""]]}, {"id": "1909.02667", "submitter": "Gautam Mantena", "authors": "Gautam Mantena, Ozlem Kalinli, Ossama Abdel-Hamid, Don McAllaster", "title": "Bandwidth Embeddings for Mixed-bandwidth Speech Recognition", "comments": "A part of this work is accepted in Interspeech 2019\n  https://interspeech2019.org", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we tackle the problem of handling narrowband and wideband\nspeech by building a single acoustic model (AM), also called mixed bandwidth\nAM. In the proposed approach, an auxiliary input feature is used to provide the\nbandwidth information to the model, and bandwidth embeddings are jointly\nlearned as part of acoustic model training. Experimental evaluations show that\nusing bandwidth embeddings helps the model to handle the variability of the\nnarrow and wideband speech, and makes it possible to train a mixed-bandwidth\nAM. Furthermore, we propose to use parallel convolutional layers to handle the\nmismatch between the narrow and wideband speech better, where separate\nconvolution layers are used for each type of input speech signal. Our best\nsystem achieves 13% relative improvement on narrowband speech, while not\ndegrading on wideband speech.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 23:07:26 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Mantena", "Gautam", ""], ["Kalinli", "Ozlem", ""], ["Abdel-Hamid", "Ossama", ""], ["McAllaster", "Don", ""]]}, {"id": "1909.02670", "submitter": "Lisa Fan", "authors": "Lisa Fan, Marshall White, Eva Sharma, Ruisi Su, Prafulla Kumar\n  Choubey, Ruihong Huang, Lu Wang", "title": "In Plain Sight: Media Bias Through the Lens of Factual Reporting", "comments": "To appear as a short paper in EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing prevalence of political bias in news media calls for greater\npublic awareness of it, as well as robust methods for its detection. While\nprior work in NLP has primarily focused on the lexical bias captured by\nlinguistic attributes such as word choice and syntax, other types of bias stem\nfrom the actual content selected for inclusion in the text. In this work, we\ninvestigate the effects of informational bias: factual content that can\nnevertheless be deployed to sway reader opinion. We first produce a new\ndataset, BASIL, of 300 news articles annotated with 1,727 bias spans and find\nevidence that informational bias appears in news articles more frequently than\nlexical bias. We further study our annotations to observe how informational\nbias surfaces in news articles by different media outlets. Lastly, a baseline\nmodel for informational bias prediction is presented by fine-tuning BERT on our\nlabeled data, indicating the challenges of the task and future directions.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 23:20:29 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Fan", "Lisa", ""], ["White", "Marshall", ""], ["Sharma", "Eva", ""], ["Su", "Ruisi", ""], ["Choubey", "Prafulla Kumar", ""], ["Huang", "Ruihong", ""], ["Wang", "Lu", ""]]}, {"id": "1909.02745", "submitter": "Bin Bi", "authors": "Bin Bi, Chen Wu, Ming Yan, Wei Wang, Jiangnan Xia, Chenliang Li", "title": "Incorporating External Knowledge into Machine Reading for Generative\n  Question Answering", "comments": "Accepted at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commonsense and background knowledge is required for a QA model to answer\nmany nontrivial questions. Different from existing work on knowledge-aware QA,\nwe focus on a more challenging task of leveraging external knowledge to\ngenerate answers in natural language for a given question with context.\n  In this paper, we propose a new neural model, Knowledge-Enriched Answer\nGenerator (KEAG), which is able to compose a natural answer by exploiting and\naggregating evidence from all four information sources available: question,\npassage, vocabulary and knowledge. During the process of answer generation,\nKEAG adaptively determines when to utilize symbolic knowledge and which fact\nfrom the knowledge is useful. This allows the model to exploit external\nknowledge that is not explicitly stated in the given text, but that is relevant\nfor generating an answer. The empirical study on public benchmark of answer\ngeneration demonstrates that KEAG improves answer quality over models without\nknowledge and existing knowledge-aware models, confirming its effectiveness in\nleveraging knowledge.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 07:20:17 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Bi", "Bin", ""], ["Wu", "Chen", ""], ["Yan", "Ming", ""], ["Wang", "Wei", ""], ["Xia", "Jiangnan", ""], ["Li", "Chenliang", ""]]}, {"id": "1909.02762", "submitter": "Tao Shen", "authors": "Tao Shen, Xiubo Geng, Tao Qin, Guodong Long, Jing Jiang, Daxin Jiang", "title": "Effective Search of Logical Forms for Weakly Supervised Knowledge-Based\n  Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many algorithms for Knowledge-Based Question Answering (KBQA) depend on\nsemantic parsing, which translates a question to its logical form. When only\nweak supervision is provided, it is usually necessary to search valid logical\nforms for model training. However, a complex question typically involves a huge\nsearch space, which creates two main problems: 1) the solutions limited by\ncomputation time and memory usually reduce the success rate of the search, and\n2) spurious logical forms in the search results degrade the quality of training\ndata. These two problems lead to a poorly-trained semantic parsing model. In\nthis work, we propose an effective search method for weakly supervised KBQA\nbased on operator prediction for questions. With search space constrained by\npredicted operators, sufficient search paths can be explored, more valid\nlogical forms can be derived, and operators possibly causing spurious logical\nforms can be avoided. As a result, a larger proportion of questions in a weakly\nsupervised training set are equipped with logical forms, and fewer spurious\nlogical forms are generated. Such high-quality training data directly\ncontributes to a better semantic parsing model. Experimental results on one of\nthe largest KBQA datasets (i.e., CSQA) verify the effectiveness of our\napproach: improving the precision from 67% to 72% and the recall from 67% to\n72% in terms of the overall score.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 08:22:28 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Shen", "Tao", ""], ["Geng", "Xiubo", ""], ["Qin", "Tao", ""], ["Long", "Guodong", ""], ["Jiang", "Jing", ""], ["Jiang", "Daxin", ""]]}, {"id": "1909.02764", "submitter": "Roman Klinger", "authors": "Deniz Cevher and Sebastian Zepf and Roman Klinger", "title": "Towards Multimodal Emotion Recognition in German Speech Events in Cars\n  using Transfer Learning", "comments": "12 pages, 2 figures, accepted at KONVENS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recognition of emotions by humans is a complex process which considers\nmultiple interacting signals such as facial expressions and both prosody and\nsemantic content of utterances. Commonly, research on automatic recognition of\nemotions is, with few exceptions, limited to one modality. We describe an\nin-car experiment for emotion recognition from speech interactions for three\nmodalities: the audio signal of a spoken interaction, the visual signal of the\ndriver's face, and the manually transcribed content of utterances of the\ndriver. We use off-the-shelf tools for emotion detection in audio and face and\ncompare that to a neural transfer learning approach for emotion recognition\nfrom text which utilizes existing resources from other domains. We see that\ntransfer learning enables models based on out-of-domain corpora to perform\nwell. This method contributes up to 10 percentage points in F1, with up to 76\nmicro-average F1 across the emotions joy, annoyance and insecurity. Our\nfindings also indicate that off-the-shelf-tools analyzing face and audio are\nnot ready yet for emotion detection in in-car speech interactions without\nfurther adjustments.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 08:33:00 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 11:03:10 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Cevher", "Deniz", ""], ["Zepf", "Sebastian", ""], ["Klinger", "Roman", ""]]}, {"id": "1909.02766", "submitter": "Felix Hamborg", "authors": "Felix Hamborg and Corinna Breitinger and Bela Gipp", "title": "Giveme5W1H: A Universal System for Extracting Main Events from News\n  Articles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Event extraction from news articles is a commonly required prerequisite for\nvarious tasks, such as article summarization, article clustering, and news\naggregation. Due to the lack of universally applicable and publicly available\nmethods tailored to news datasets, many researchers redundantly implement event\nextraction methods for their own projects. The journalistic 5W1H questions are\ncapable of describing the main event of an article, i.e., by answering who did\nwhat, when, where, why, and how. We provide an in-depth description of an\nimproved version of Giveme5W1H, a system that uses syntactic and\ndomain-specific rules to automatically extract the relevant phrases from\nEnglish news articles to provide answers to these 5W1H questions. Given the\nanswers to these questions, the system determines an article's main event. In\nan expert evaluation with three assessors and 120 articles, we determined an\noverall precision of p=0.73, and p=0.82 for answering the first four W\nquestions, which alone can sufficiently summarize the main event reported on in\na news article. We recently made our system publicly available, and it remains\nthe only universal open-source 5W1H extractor capable of being applied to a\nwide range of use cases in news analysis.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 08:37:42 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Hamborg", "Felix", ""], ["Breitinger", "Corinna", ""], ["Gipp", "Bela", ""]]}, {"id": "1909.02776", "submitter": "Hosein Rezaei", "authors": "Hosein Rezaei, Seyed Amid Moeinzadeh, Azar Shahgholian and Mohamad\n  Saraee", "title": "Features in Extractive Supervised Single-document Summarization: Case of\n  Persian News", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text summarization has been one of the most challenging areas of research in\nNLP. Much effort has been made to overcome this challenge by using either the\nabstractive or extractive methods. Extractive methods are more popular, due to\ntheir simplicity compared with the more elaborate abstractive methods. In\nextractive approaches, the system will not generate sentences. Instead, it\nlearns how to score sentences within the text by using some textual features\nand subsequently selecting those with the highest-rank. Therefore, the core\nobjective is ranking and it highly depends on the document. This dependency has\nbeen unnoticed by many state-of-the-art solutions. In this work, the features\nof the document are integrated into vectors of every sentence. In this way, the\nsystem becomes informed about the context, increases the precision of the\nlearned model and consequently produces comprehensive and brief summaries.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 09:04:14 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 03:10:27 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Rezaei", "Hosein", ""], ["Moeinzadeh", "Seyed Amid", ""], ["Shahgholian", "Azar", ""], ["Saraee", "Mohamad", ""]]}, {"id": "1909.02809", "submitter": "Gerasimos Spanakis", "authors": "Tobias Bauer and Emre Devrim and Misha Glazunov and William Lopez\n  Jaramillo and Balaganesh Mohan and Gerasimos Spanakis", "title": "#MeTooMaastricht: Building a chatbot to assist survivors of sexual\n  harassment", "comments": "19 pages, accepted at SoGood2019 workshop (ECMLPKDD2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the recent social movement of #MeToo, we are building a chatbot\nto assist survivors of sexual harassment cases (designed for the city of\nMaastricht but can easily be extended). The motivation behind this work is\ntwofold: properly assist survivors of such events by directing them to\nappropriate institutions that can offer them help and increase the incident\ndocumentation so as to gather more data about harassment cases which are\ncurrently under reported. We break down the problem into three data\nscience/machine learning components: harassment type identification (treated as\na classification problem), spatio-temporal information extraction (treated as\nNamed Entity Recognition problem) and dialogue with the users (treated as a\nslot-filling based chatbot). We are able to achieve a success rate of more than\n98% for the identification of a harassment-or-not case and around 80% for the\nspecific type harassment identification. Locations and dates are identified\nwith more than 90% accuracy and time occurrences prove more challenging with\nalmost 80%. Finally, initial validation of the chatbot shows great potential\nfor the further development and deployment of such a beneficial for the whole\nsociety tool.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 10:36:33 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Bauer", "Tobias", ""], ["Devrim", "Emre", ""], ["Glazunov", "Misha", ""], ["Jaramillo", "William Lopez", ""], ["Mohan", "Balaganesh", ""], ["Spanakis", "Gerasimos", ""]]}, {"id": "1909.02851", "submitter": "Piotr Szyma\\'nski", "authors": "Jan Mizgajski, Adrian Szymczak, Robert G{\\l}owski, Piotr Szyma\\'nski,\n  Piotr \\.Zelasko, {\\L}ukasz Augustyniak, Miko{\\l}aj Morzy, Yishay Carmiel,\n  Jeff Hodson, {\\L}ukasz W\\'ojciak, Daniel Smoczyk, Adam Wr\\'obel, Bartosz\n  Borowik, Adam Artajew, Marcin Baran, Cezary Kwiatkowski, Marzena\n  \\.Zy{\\l}a-Hoppe", "title": "Avaya Conversational Intelligence: A Real-Time System for Spoken\n  Language Understanding in Human-Human Call Center Conversations", "comments": "Accepted for Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Avaya Conversational Intelligence(ACI) is an end-to-end, cloud-based solution\nfor real-time Spoken Language Understanding for call centers. It combines large\nvocabulary, real-time speech recognition, transcript refinement, and entity and\nintent recognition in order to convert live audio into a rich, actionable\nstream of structured events. These events can be further leveraged with a\nbusiness rules engine, thus serving as a foundation for real-time supervision\nand assistance applications. After the ingestion, calls are enriched with\nunsupervised keyword extraction, abstractive summarization, and\nbusiness-defined attributes, enabling offline use cases, such as business\nintelligence, topic mining, full-text search, quality assurance, and agent\ntraining. ACI comes with a pretrained, configurable library of hundreds of\nintents and a robust intent training environment that allows for efficient,\ncost-effective creation and customization of customer-specific intents.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 22:57:10 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Mizgajski", "Jan", ""], ["Szymczak", "Adrian", ""], ["G\u0142owski", "Robert", ""], ["Szyma\u0144ski", "Piotr", ""], ["\u017belasko", "Piotr", ""], ["Augustyniak", "\u0141ukasz", ""], ["Morzy", "Miko\u0142aj", ""], ["Carmiel", "Yishay", ""], ["Hodson", "Jeff", ""], ["W\u00f3jciak", "\u0141ukasz", ""], ["Smoczyk", "Daniel", ""], ["Wr\u00f3bel", "Adam", ""], ["Borowik", "Bartosz", ""], ["Artajew", "Adam", ""], ["Baran", "Marcin", ""], ["Kwiatkowski", "Cezary", ""], ["\u017by\u0142a-Hoppe", "Marzena", ""]]}, {"id": "1909.02855", "submitter": "Paula Czarnowska", "authors": "Paula Czarnowska, Sebastian Ruder, Edouard Grave, Ryan Cotterell and\n  Ann Copestake", "title": "Don't Forget the Long Tail! A Comprehensive Analysis of Morphological\n  Generalization in Bilingual Lexicon Induction", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human translators routinely have to translate rare inflections of words - due\nto the Zipfian distribution of words in a language. When translating from\nSpanish, a good translator would have no problem identifying the proper\ntranslation of a statistically rare inflection such as habl\\'aramos. Note the\nlexeme itself, hablar, is relatively common. In this work, we investigate\nwhether state-of-the-art bilingual lexicon inducers are capable of learning\nthis kind of generalization. We introduce 40 morphologically complete\ndictionaries in 10 languages and evaluate three of the state-of-the-art models\non the task of translation of less frequent morphological forms. We demonstrate\nthat the performance of state-of-the-art models drops considerably when\nevaluated on infrequent morphological inflections and then show that adding a\nsimple morphological constraint at training time improves the performance,\nproving that the bilingual lexicon inducers can benefit from better encoding of\nmorphology.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 12:27:43 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 10:51:07 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Czarnowska", "Paula", ""], ["Ruder", "Sebastian", ""], ["Grave", "Edouard", ""], ["Cotterell", "Ryan", ""], ["Copestake", "Ann", ""]]}, {"id": "1909.02857", "submitter": "Clara Vania", "authors": "Clara Vania, Yova Kementchedjhieva, Anders S{\\o}gaard, and Adam Lopez", "title": "A systematic comparison of methods for low-resource dependency parsing\n  on genuinely low-resource languages", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parsers are available for only a handful of the world's languages, since they\nrequire lots of training data. How far can we get with just a small amount of\ntraining data? We systematically compare a set of simple strategies for\nimproving low-resource parsers: data augmentation, which has not been tested\nbefore; cross-lingual training; and transliteration. Experimenting on three\ntypologically diverse low-resource languages---North S\\'ami, Galician, and\nKazah---We find that (1) when only the low-resource treebank is available, data\naugmentation is very helpful; (2) when a related high-resource treebank is\navailable, cross-lingual training is helpful and complements data augmentation;\nand (3) when the high-resource treebank uses a different writing system,\ntransliteration into a shared orthographic spaces is also very helpful.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 12:32:52 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Vania", "Clara", ""], ["Kementchedjhieva", "Yova", ""], ["S\u00f8gaard", "Anders", ""], ["Lopez", "Adam", ""]]}, {"id": "1909.02930", "submitter": "Michael Cochez", "authors": "Ruijie Wang, Meng Wang, Jun Liu, Michael Cochez, Stefan Decker", "title": "Structured Query Construction via Knowledge Graph Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to facilitate the accesses of general users to knowledge graphs, an\nincreasing effort is being exerted to construct graph-structured queries of\ngiven natural language questions. At the core of the construction is to deduce\nthe structure of the target query and determine the vertices/edges which\nconstitute the query. Existing query construction methods rely on question\nunderstanding and conventional graph-based algorithms which lead to inefficient\nand degraded performances facing complex natural language questions over\nknowledge graphs with large scales. In this paper, we focus on this problem and\npropose a novel framework standing on recent knowledge graph embedding\ntechniques. Our framework first encodes the underlying knowledge graph into a\nlow-dimensional embedding space by leveraging generalized local knowledge\ngraphs. Given a natural language question, the learned embedding\nrepresentations of the knowledge graph are utilized to compute the query\nstructure and assemble vertices/edges into the target query. Extensive\nexperiments were conducted on the benchmark dataset, and the results\ndemonstrate that our framework outperforms state-of-the-art baseline models\nregarding effectiveness and efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 14:29:00 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Wang", "Ruijie", ""], ["Wang", "Meng", ""], ["Liu", "Jun", ""], ["Cochez", "Michael", ""], ["Decker", "Stefan", ""]]}, {"id": "1909.02950", "submitter": "Douwe Kiela", "authors": "Douwe Kiela, Suvrat Bhooshan, Hamed Firooz, Ethan Perez, Davide\n  Testuggine", "title": "Supervised Multimodal Bitransformers for Classifying Images and Text", "comments": "Rejected from EMNLP, twice", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised bidirectional transformer models such as BERT have led to\ndramatic improvements in a wide variety of textual classification tasks. The\nmodern digital world is increasingly multimodal, however, and textual\ninformation is often accompanied by other modalities such as images. We\nintroduce a supervised multimodal bitransformer model that fuses information\nfrom text and image encoders, and obtain state-of-the-art performance on\nvarious multimodal classification benchmark tasks, outperforming strong\nbaselines, including on hard test sets specifically designed to measure\nmultimodal performance.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 14:59:18 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 03:08:28 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Kiela", "Douwe", ""], ["Bhooshan", "Suvrat", ""], ["Firooz", "Hamed", ""], ["Perez", "Ethan", ""], ["Testuggine", "Davide", ""]]}, {"id": "1909.02955", "submitter": "Konstantinos Kogkalidis", "authors": "Konstantinos Kogkalidis", "title": "Extracting and Learning a Dependency-Enhanced Type Lexicon for Dutch", "comments": "MSc Thesis, 94 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis is concerned with type-logical grammars and their practical\napplicability as tools of reasoning about sentence syntax and semantics. The\nfocal point is narrowed to Dutch, a language exhibiting a large degree of word\norder variability. In order to overcome difficulties arising as a result of\nthat variability, the thesis explores and expands upon a type grammar based on\nMultiplicative Intuitionistic Linear Logic, agnostic to word order but enriched\nwith decorations that aim to reduce its proof-theoretic complexity. An\nalgorithm for the conversion of dependency-annotated sentences into type\nsequences is then implemented, populating the type logic with concrete,\ndata-driven lexical types. Two experiments are ran on the resulting grammar\ninstantiation. The first pertains to the learnability of the type-assignment\nprocess by a neural architecture. A novel application of a self-attentive\nsequence transduction model is proposed; contrary to established practices, it\nconstructs types inductively by internalizing the type-formation syntax, thus\nexhibiting generalizability beyond a pre-specified type vocabulary. The second\nrevolves around a deductive parsing system that can resolve structural\nambiguities by consulting both word and type information; preliminary results\nsuggest both excellent computational efficiency and performance.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 15:03:29 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 12:54:57 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Kogkalidis", "Konstantinos", ""]]}, {"id": "1909.02965", "submitter": "Simon Keizer", "authors": "Simon Keizer, Ond\\v{r}ej Du\\v{s}ek, Xingkun Liu, Verena Rieser", "title": "User Evaluation of a Multi-dimensional Statistical Dialogue System", "comments": "SIGdial 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first complete spoken dialogue system driven by a\nmulti-dimensional statistical dialogue manager. This framework has been shown\nto substantially reduce data needs by leveraging domain-independent dimensions,\nsuch as social obligations or feedback, which (as we show) can be transferred\nbetween domains. In this paper, we conduct a user study and show that the\nperformance of a multi-dimensional system, which can be adapted from a source\ndomain, is equivalent to that of a one-dimensional baseline, which can only be\ntrained from scratch.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 15:10:37 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Keizer", "Simon", ""], ["Du\u0161ek", "Ond\u0159ej", ""], ["Liu", "Xingkun", ""], ["Rieser", "Verena", ""]]}, {"id": "1909.03004", "submitter": "Jesse Dodge", "authors": "Jesse Dodge, Suchin Gururangan, Dallas Card, Roy Schwartz, Noah A.\n  Smith", "title": "Show Your Work: Improved Reporting of Experimental Results", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in natural language processing proceeds, in part, by demonstrating\nthat new models achieve superior performance (e.g., accuracy) on held-out test\ndata, compared to previous results. In this paper, we demonstrate that test-set\nperformance scores alone are insufficient for drawing accurate conclusions\nabout which model performs best. We argue for reporting additional details,\nespecially performance on validation data obtained during model development. We\npresent a novel technique for doing so: expected validation performance of the\nbest-found model as a function of computation budget (i.e., the number of\nhyperparameter search trials or the overall training time). Using our approach,\nwe find multiple recent model comparisons where authors would have reached a\ndifferent conclusion if they had used more (or less) computation. Our approach\nalso allows us to estimate the amount of computation required to obtain a given\naccuracy; applying it to several recently published results yields massive\nvariation across papers, from hours to weeks. We conclude with a set of best\npractices for reporting experimental results which allow for robust future\ncomparisons, and provide code to allow researchers to use our technique.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 16:40:42 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Dodge", "Jesse", ""], ["Gururangan", "Suchin", ""], ["Card", "Dallas", ""], ["Schwartz", "Roy", ""], ["Smith", "Noah A.", ""]]}, {"id": "1909.03011", "submitter": "Jesse Dodge", "authors": "Jesse Dodge, Roy Schwartz, Hao Peng, Noah A. Smith", "title": "RNN Architecture Learning with Sparse Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural models for NLP typically use large numbers of parameters to reach\nstate-of-the-art performance, which can lead to excessive memory usage and\nincreased runtime. We present a structure learning method for learning sparse,\nparameter-efficient NLP models. Our method applies group lasso to rational RNNs\n(Peng et al., 2018), a family of models that is closely connected to weighted\nfinite-state automata (WFSAs). We take advantage of rational RNNs' natural\ngrouping of the weights, so the group lasso penalty directly removes WFSA\nstates, substantially reducing the number of parameters in the model. Our\nexperiments on a number of sentiment analysis datasets, using both GloVe and\nBERT embeddings, show that our approach learns neural structures which have\nfewer parameters without sacrificing performance relative to parameter-rich\nbaselines. Our method also highlights the interpretable properties of rational\nRNNs. We show that sparsifying such models makes them easier to visualize, and\nwe present models that rely exclusively on as few as three WFSAs after pruning\nmore than 90% of the weights. We publicly release our code.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 16:51:21 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Dodge", "Jesse", ""], ["Schwartz", "Roy", ""], ["Peng", "Hao", ""], ["Smith", "Noah A.", ""]]}, {"id": "1909.03022", "submitter": "Luca Lugini", "authors": "Luca Lugini, Diane Litman", "title": "Argument Component Classification for Classroom Discussions", "comments": null, "journal-ref": "Proceedings of the 5th Workshop on Argument Mining, November 2018,\n  Brussels, Belgium", "doi": "10.18653/v1/W18-5208", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on argument component classification for transcribed\nspoken classroom discussions, with the goal of automatically classifying\nstudent utterances into claims, evidence, and warrants. We show that an\nexisting method for argument component classification developed for another\neducationally-oriented domain performs poorly on our dataset. We then show that\nfeature sets from prior work on argument mining for student essays and online\ndialogues can be used to improve performance considerably. We also provide a\ncomparison between convolutional neural networks and recurrent neural networks\nwhen trained under different conditions to classify argument components in\nclassroom discussions. While neural network models are not always able to\noutperform a logistic regression model, we were able to gain some useful\ninsights: convolutional networks are more robust than recurrent networks both\nat the character and at the word level, and specificity information can help\nboost performance in multi-task training.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 17:17:06 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Lugini", "Luca", ""], ["Litman", "Diane", ""]]}, {"id": "1909.03023", "submitter": "Luca Lugini", "authors": "Luca Lugini, Diane Litman, Amanda Godley, Christopher Olshefski", "title": "Annotating Student Talk in Text-based Classroom Discussions", "comments": null, "journal-ref": "Proceedings of the Thirteenth Workshop on Innovative Use of NLP\n  for Building Educational Applications, June 2018, New Orleans, USA", "doi": "10.18653/v1/W18-0511", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classroom discussions in English Language Arts have a positive effect on\nstudents' reading, writing and reasoning skills. Although prior work has\nlargely focused on teacher talk and student-teacher interactions, we focus on\nthree theoretically-motivated aspects of high-quality student talk:\nargumentation, specificity, and knowledge domain. We introduce an annotation\nscheme, then show that the scheme can be used to produce reliable annotations\nand that the annotations are predictive of discussion quality. We also\nhighlight opportunities provided by our scheme for education and natural\nlanguage processing research.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 17:18:49 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Lugini", "Luca", ""], ["Litman", "Diane", ""], ["Godley", "Amanda", ""], ["Olshefski", "Christopher", ""]]}, {"id": "1909.03039", "submitter": "Jonas Kemp", "authors": "Jonas Kemp, Alvin Rajkomar, Andrew M. Dai", "title": "Improved Hierarchical Patient Classification with Language Model\n  Pretraining over Clinical Notes", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - extended\n  abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical notes in electronic health records contain highly heterogeneous\nwriting styles, including non-standard terminology or abbreviations. Using\nthese notes in predictive modeling has traditionally required preprocessing\n(e.g. taking frequent terms or topic modeling) that removes much of the\nrichness of the source data. We propose a pretrained hierarchical recurrent\nneural network model that parses minimally processed clinical notes in an\nintuitive fashion, and show that it improves performance for discharge\ndiagnosis classification tasks on the Medical Information Mart for Intensive\nCare III (MIMIC-III) dataset, compared to models that treat the notes as an\nunordered collection of terms or that conduct no pretraining. We also apply an\nattribution technique to examples to identify the words that the model uses to\nmake its prediction, and show the importance of the words' nearby context.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 17:49:56 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 20:04:00 GMT"}, {"version": "v3", "created": "Fri, 15 Nov 2019 02:17:14 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Kemp", "Jonas", ""], ["Rajkomar", "Alvin", ""], ["Dai", "Andrew M.", ""]]}, {"id": "1909.03042", "submitter": "Tongfei Chen", "authors": "Tongfei Chen, Zhengping Jiang, Adam Poliak, Keisuke Sakaguchi,\n  Benjamin Van Durme", "title": "Uncertain Natural Language Inference", "comments": "Accepted to ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Uncertain Natural Language Inference (UNLI), a refinement of\nNatural Language Inference (NLI) that shifts away from categorical labels,\ntargeting instead the direct prediction of subjective probability assessments.\nWe demonstrate the feasibility of collecting annotations for UNLI by relabeling\na portion of the SNLI dataset under a probabilistic scale, where items even\nwith the same categorical label differ in how likely people judge them to be\ntrue given a premise. We describe a direct scalar regression modeling approach,\nand find that existing categorically labeled NLI data can be used in\npre-training. Our best models approach human performance, demonstrating models\nmay be capable of more subtle inferences than the categorical bin assignment\nemployed in current NLI tasks.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 17:52:55 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 01:50:37 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Chen", "Tongfei", ""], ["Jiang", "Zhengping", ""], ["Poliak", "Adam", ""], ["Sakaguchi", "Keisuke", ""], ["Van Durme", "Benjamin", ""]]}, {"id": "1909.03044", "submitter": "Qingyu Chen", "authors": "Qingyu Chen, Jingcheng Du, Sun Kim, W. John Wilbur and Zhiyong Lu", "title": "Deep learning with sentence embeddings pre-trained on biomedical corpora\n  improves the performance of finding similar sentences in electronic medical\n  records", "comments": "15 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capturing sentence semantics plays a vital role in a range of text mining\napplications. Despite continuous efforts on the development of related datasets\nand models in the general domain, both datasets and models are limited in\nbiomedical and clinical domains. The BioCreative/OHNLP organizers have made the\nfirst attempt to annotate 1,068 sentence pairs from clinical notes and have\ncalled for a community effort to tackle the Semantic Textual Similarity\n(BioCreative/OHNLP STS) challenge. We developed models using traditional\nmachine learning and deep learning approaches. For the post challenge, we focus\non two models: the Random Forest and the Encoder Network. We applied sentence\nembeddings pre-trained on PubMed abstracts and MIMIC-III clinical notes and\nupdated the Random Forest and the Encoder Network accordingly. The official\nresults demonstrated our best submission was the ensemble of eight models. It\nachieved a Person correlation coefficient of 0.8328, the highest performance\namong 13 submissions from 4 teams. For the post challenge, the performance of\nboth Random Forest and the Encoder Network was improved; in particular, the\ncorrelation of the Encoder Network was improved by ~13%. During the challenge\ntask, no end-to-end deep learning models had better performance than machine\nlearning models that take manually-crafted features. In contrast, with the\nsentence embeddings pre-trained on biomedical corpora, the Encoder Network now\nachieves a correlation of ~0.84, which is higher than the original best model.\nThe ensembled model taking the improved versions of the Random Forest and\nEncoder Network as inputs further increased performance to 0.8528. Deep\nlearning models with sentence embeddings pre-trained on biomedical corpora\nachieve the highest performance on the test set.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 17:56:01 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Chen", "Qingyu", ""], ["Du", "Jingcheng", ""], ["Kim", "Sun", ""], ["Wilbur", "W. John", ""], ["Lu", "Zhiyong", ""]]}, {"id": "1909.03065", "submitter": "Ben Zhou", "authors": "Ben Zhou, Daniel Khashabi, Qiang Ning and Dan Roth", "title": "\"Going on a vacation\" takes longer than \"Going for a walk\": A Study of\n  Temporal Commonsense Understanding", "comments": "EMNLP 2019 (short paper). arXiv admin note: text overlap with\n  arXiv:1908.04926", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding time is crucial for understanding events expressed in natural\nlanguage. Because people rarely say the obvious, it is often necessary to have\ncommonsense knowledge about various temporal aspects of events, such as\nduration, frequency, and temporal order. However, this important problem has so\nfar received limited attention. This paper systematically studies this temporal\ncommonsense problem. Specifically, we define five classes of temporal\ncommonsense, and use crowdsourcing to develop a new dataset, MCTACO, that\nserves as a test set for this task. We find that the best current methods used\non MCTACO are still far behind human performance, by about 20%, and discuss\nseveral directions for improvement. We hope that the new dataset and our study\nhere can foster more future research on this topic.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 14:12:15 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Zhou", "Ben", ""], ["Khashabi", "Daniel", ""], ["Ning", "Qiang", ""], ["Roth", "Dan", ""]]}, {"id": "1909.03084", "submitter": "Yichao Zhou", "authors": "Yichao Zhou, Jyun-Yu Jiang, Kai-Wei Chang and Wei Wang", "title": "Learning to Discriminate Perturbations for Blocking Adversarial Attacks\n  in Text Classification", "comments": "10 pages, 8 tables, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks against machine learning models have threatened various\nreal-world applications such as spam filtering and sentiment analysis. In this\npaper, we propose a novel framework, learning to DIScriminate Perturbations\n(DISP), to identify and adjust malicious perturbations, thereby blocking\nadversarial attacks for text classification models. To identify adversarial\nattacks, a perturbation discriminator validates how likely a token in the text\nis perturbed and provides a set of potential perturbations. For each potential\nperturbation, an embedding estimator learns to restore the embedding of the\noriginal word based on the context and a replacement token is chosen based on\napproximate kNN search. DISP can block adversarial attacks for any NLP model\nwithout modifying the model structure or training procedure. Extensive\nexperiments on two benchmark datasets demonstrate that DISP significantly\noutperforms baseline methods in blocking adversarial attacks for text\nclassification. In addition, in-depth analysis shows the robustness of DISP\nacross different situations.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 18:13:48 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Zhou", "Yichao", ""], ["Jiang", "Jyun-Yu", ""], ["Chang", "Kai-Wei", ""], ["Wang", "Wei", ""]]}, {"id": "1909.03087", "submitter": "Stephen Roller", "authors": "Margaret Li, Jason Weston, Stephen Roller", "title": "ACUTE-EVAL: Improved Dialogue Evaluation with Optimized Questions and\n  Multi-turn Comparisons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While dialogue remains an important end-goal of natural language research,\nthe difficulty of evaluation is an oft-quoted reason why it remains troublesome\nto make real progress towards its solution. Evaluation difficulties are\nactually two-fold: not only do automatic metrics not correlate well with human\njudgments, but also human judgments themselves are in fact difficult to\nmeasure. The two most used human judgment tests, single-turn pairwise\nevaluation and multi-turn Likert scores, both have serious flaws as we discuss\nin this work.\n  We instead provide a novel procedure involving comparing two full dialogues,\nwhere a human judge is asked to pay attention to only one speaker within each,\nand make a pairwise judgment. The questions themselves are optimized to\nmaximize the robustness of judgments across different annotators, resulting in\nbetter tests. We also show how these tests work in self-play model chat setups,\nresulting in faster, cheaper tests. We hope these tests become the de facto\nstandard, and will release open-source code to that end.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 18:44:49 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Li", "Margaret", ""], ["Weston", "Jason", ""], ["Roller", "Stephen", ""]]}, {"id": "1909.03099", "submitter": "Sathyanarayanan Aakur", "authors": "Sathyanarayanan N. Aakur and Sudeep Sarkar", "title": "Abductive Reasoning as Self-Supervision for Common Sense Question\n  Answering", "comments": "8 Pages, 4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question answering has seen significant advances in recent times, especially\nwith the introduction of increasingly bigger transformer-based models\npre-trained on massive amounts of data. While achieving impressive results on\nmany benchmarks, their performances appear to be proportional to the amount of\ntraining data available in the target domain. In this work, we explore the\nability of current question-answering models to generalize - to both other\ndomains as well as with restricted training data. We find that large amounts of\ntraining data are necessary, both for pre-training as well as fine-tuning to a\ntask, for the models to perform well on the designated task. We introduce a\nnovel abductive reasoning approach based on Grenander's Pattern Theory\nframework to provide self-supervised domain adaptation cues or \"pseudo-labels,\"\nwhich can be used instead of expensive human annotations. The proposed\nself-supervised training regimen allows for effective domain adaptation without\nlosing performance compared to fully supervised baselines. Extensive\nexperiments on two publicly available benchmarks show the efficacy of the\nproposed approach. We show that neural networks models trained using\nself-labeled data can retain up to $75\\%$ of the performance of models trained\non large amounts of human-annotated training data.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 19:39:37 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 02:50:17 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Aakur", "Sathyanarayanan N.", ""], ["Sarkar", "Sudeep", ""]]}, {"id": "1909.03100", "submitter": "Niloofar Safi Samghabadi", "authors": "Niloofar Safi Samghabadi, Afsheen Hatami, Mahsa Shafaei, Sudipta Kar,\n  Thamar Solorio", "title": "Attending the Emotions to Detect Online Abusive Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, abusive behavior has become a serious issue in online social\nnetworks. In this paper, we present a new corpus from a semi-anonymous social\nmedia platform, which contains the instances of offensive and neutral classes.\nWe introduce a single deep neural architecture that considers both local and\nsequential information from the text in order to detect abusive language. Along\nwith this model, we introduce a new attention mechanism called emotion-aware\nattention. This mechanism utilizes the emotions behind the text to find the\nmost important words within that text. We experiment with this model on our\ndataset and later present the analysis. Additionally, we evaluate our proposed\nmethod on different corpora and show new state-of-the-art results with respect\nto offensive language detection.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 19:40:06 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Samghabadi", "Niloofar Safi", ""], ["Hatami", "Afsheen", ""], ["Shafaei", "Mahsa", ""], ["Kar", "Sudipta", ""], ["Solorio", "Thamar", ""]]}, {"id": "1909.03104", "submitter": "Nada Almarwani", "authors": "Nada Almarwani, Hanan Aldarmaki, Mona Diab", "title": "Efficient Sentence Embedding using Discrete Cosine Transform", "comments": "To appear in EMNLP 2019", "journal-ref": "EMNLP 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vector averaging remains one of the most popular sentence embedding methods\nin spite of its obvious disregard for syntactic structure. While more complex\nsequential or convolutional networks potentially yield superior classification\nperformance, the improvements in classification accuracy are typically mediocre\ncompared to the simple vector averaging. As an efficient alternative, we\npropose the use of discrete cosine transform (DCT) to compress word sequences\nin an order-preserving manner. The lower order DCT coefficients represent the\noverall feature patterns in sentences, which results in suitable embeddings for\ntasks that could benefit from syntactic features. Our results in semantic\nprobing tasks demonstrate that DCT embeddings indeed preserve more syntactic\ninformation compared with vector averaging. With practically equivalent\ncomplexity, the model yields better overall performance in downstream\nclassification tasks that correlate with syntactic features, which illustrates\nthe capacity of DCT to preserve word order information.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 19:44:48 GMT"}, {"version": "v2", "created": "Wed, 8 Jan 2020 22:32:19 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Almarwani", "Nada", ""], ["Aldarmaki", "Hanan", ""], ["Diab", "Mona", ""]]}, {"id": "1909.03135", "submitter": "Andrey Kutuzov", "authors": "Andrey Kutuzov, Elizaveta Kuzmenko", "title": "To lemmatize or not to lemmatize: how word normalisation affects ELMo\n  performance in word sense disambiguation", "comments": "Accepted to NODALIDA2019 Deep Learning for Natural Language\n  Processing workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We critically evaluate the widespread assumption that deep learning NLP\nmodels do not require lemmatized input. To test this, we trained versions of\ncontextualised word embedding ELMo models on raw tokenized corpora and on the\ncorpora with word tokens replaced by their lemmas. Then, these models were\nevaluated on the word sense disambiguation task. This was done for the English\nand Russian languages.\n  The experiments showed that while lemmatization is indeed not necessary for\nEnglish, the situation is different for Russian. It seems that for\nrich-morphology languages, using lemmatized training and testing data yields\nsmall but consistent improvements: at least for word sense disambiguation. This\nmeans that the decisions about text pre-processing before training ELMo should\nconsider the linguistic nature of the language in question.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 21:49:47 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Kutuzov", "Andrey", ""], ["Kuzmenko", "Elizaveta", ""]]}, {"id": "1909.03149", "submitter": "Emanuele Bugliarello", "authors": "Emanuele Bugliarello, Naoaki Okazaki", "title": "Enhancing Machine Translation with Dependency-Aware Self-Attention", "comments": "Accepted at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most neural machine translation models only rely on pairs of parallel\nsentences, assuming syntactic information is automatically learned by an\nattention mechanism. In this work, we investigate different approaches to\nincorporate syntactic knowledge in the Transformer model and also propose a\nnovel, parameter-free, dependency-aware self-attention mechanism that improves\nits translation quality, especially for long sentences and in low-resource\nscenarios. We show the efficacy of each approach on WMT English-German and\nEnglish-Turkish, and WAT English-Japanese translation tasks.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 23:29:57 GMT"}, {"version": "v2", "created": "Sun, 5 Apr 2020 21:36:48 GMT"}, {"version": "v3", "created": "Tue, 21 Apr 2020 09:20:31 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Bugliarello", "Emanuele", ""], ["Okazaki", "Naoaki", ""]]}, {"id": "1909.03186", "submitter": "Sandeep Subramanian", "authors": "Sandeep Subramanian, Raymond Li, Jonathan Pilault, Christopher Pal", "title": "On Extractive and Abstractive Neural Document Summarization with\n  Transformer Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method to produce abstractive summaries of long documents that\nexceed several thousand words via neural abstractive summarization. We perform\na simple extractive step before generating a summary, which is then used to\ncondition the transformer language model on relevant information before being\ntasked with generating a summary. We show that this extractive step\nsignificantly improves summarization results. We also show that this approach\nproduces more abstractive summaries compared to prior work that employs a copy\nmechanism while still achieving higher rouge scores. Note: The abstract above\nwas not written by the authors, it was generated by one of the models presented\nin this paper.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 04:33:26 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 16:46:42 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Subramanian", "Sandeep", ""], ["Li", "Raymond", ""], ["Pilault", "Jonathan", ""], ["Pal", "Christopher", ""]]}, {"id": "1909.03193", "submitter": "Liang Yao", "authors": "Liang Yao, Chengsheng Mao, Yuan Luo", "title": "KG-BERT: BERT for Knowledge Graph Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs are important resources for many artificial intelligence\ntasks but often suffer from incompleteness. In this work, we propose to use\npre-trained language models for knowledge graph completion. We treat triples in\nknowledge graphs as textual sequences and propose a novel framework named\nKnowledge Graph Bidirectional Encoder Representations from Transformer\n(KG-BERT) to model these triples. Our method takes entity and relation\ndescriptions of a triple as input and computes scoring function of the triple\nwith the KG-BERT language model. Experimental results on multiple benchmark\nknowledge graphs show that our method can achieve state-of-the-art performance\nin triple classification, link prediction and relation prediction tasks.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 06:09:25 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 06:03:30 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Yao", "Liang", ""], ["Mao", "Chengsheng", ""], ["Luo", "Yuan", ""]]}, {"id": "1909.03223", "submitter": "Tong Niu", "authors": "Tong Niu, Caiming Xiong, Richard Socher", "title": "Deleter: Leveraging BERT to Perform Unsupervised Successive Text\n  Compression", "comments": "5 pages, 1 figure (presented @ WeCNLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text compression has diverse applications such as Summarization, Reading\nComprehension and Text Editing. However, almost all existing approaches require\neither hand-crafted features, syntactic labels or parallel data. Even for one\nthat achieves this task in an unsupervised setting, its architecture\nnecessitates a task-specific autoencoder. Moreover, these models only generate\none compressed sentence for each source input, so that adapting to different\nstyle requirements (e.g. length) for the final output usually implies\nretraining the model from scratch. In this work, we propose a fully\nunsupervised model, Deleter, that is able to discover an \"optimal deletion\npath\" for an arbitrary sentence, where each intermediate sequence along the\npath is a coherent subsequence of the previous one. This approach relies\nexclusively on a pretrained bidirectional language model (BERT) to score each\ncandidate deletion based on the average Perplexity of the resulting sentence\nand performs progressive greedy lookahead search to select the best deletion\nfor each step. We apply Deleter to the task of extractive Sentence Compression,\nand found that our model is competitive with state-of-the-art supervised models\ntrained on 1.02 million in-domain examples with similar compression ratio.\nQualitative analysis, as well as automatic and human evaluations both verify\nthat our model produces high-quality compression.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 09:14:18 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Niu", "Tong", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "1909.03227", "submitter": "Zhepei Wei", "authors": "Zhepei Wei, Jianlin Su, Yue Wang, Yuan Tian, Yi Chang", "title": "A Novel Cascade Binary Tagging Framework for Relational Triple\n  Extraction", "comments": "Accepted by ACL 2020. Code and data are available at:\n  https://github.com/weizhepei/CasRel", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting relational triples from unstructured text is crucial for\nlarge-scale knowledge graph construction. However, few existing works excel in\nsolving the overlapping triple problem where multiple relational triples in the\nsame sentence share the same entities. In this work, we introduce a fresh\nperspective to revisit the relational triple extraction task and propose a\nnovel cascade binary tagging framework (CasRel) derived from a principled\nproblem formulation. Instead of treating relations as discrete labels as in\nprevious works, our new framework models relations as functions that map\nsubjects to objects in a sentence, which naturally handles the overlapping\nproblem. Experiments show that the CasRel framework already outperforms\nstate-of-the-art methods even when its encoder module uses a randomly\ninitialized BERT encoder, showing the power of the new tagging framework. It\nenjoys further performance boost when employing a pre-trained BERT encoder,\noutperforming the strongest baseline by 17.5 and 30.2 absolute gain in F1-score\non two public datasets NYT and WebNLG, respectively. In-depth analysis on\ndifferent scenarios of overlapping triples shows that the method delivers\nconsistent performance gain across all these scenarios. The source code and\ndata are released online.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 09:40:20 GMT"}, {"version": "v2", "created": "Sun, 5 Apr 2020 11:06:54 GMT"}, {"version": "v3", "created": "Tue, 28 Apr 2020 13:41:27 GMT"}, {"version": "v4", "created": "Mon, 22 Jun 2020 10:00:21 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Wei", "Zhepei", ""], ["Su", "Jianlin", ""], ["Wang", "Yue", ""], ["Tian", "Yuan", ""], ["Chang", "Yi", ""]]}, {"id": "1909.03242", "submitter": "Isabelle Augenstein", "authors": "Isabelle Augenstein and Christina Lioma and Dongsheng Wang and Lucas\n  Chaves Lima and Casper Hansen and Christian Hansen and Jakob Grue Simonsen", "title": "MultiFC: A Real-World Multi-Domain Dataset for Evidence-Based Fact\n  Checking of Claims", "comments": "Proceedings of EMNLP 2019, to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We contribute the largest publicly available dataset of naturally occurring\nfactual claims for the purpose of automatic claim verification. It is collected\nfrom 26 fact checking websites in English, paired with textual sources and rich\nmetadata, and labelled for veracity by human expert journalists. We present an\nin-depth analysis of the dataset, highlighting characteristics and challenges.\nFurther, we present results for automatic veracity prediction, both with\nestablished baselines and with a novel method for joint ranking of evidence\npages and predicting veracity that outperforms all baselines. Significant\nperformance increases are achieved by encoding evidence, and by modelling\nmetadata. Our best-performing model achieves a Macro F1 of 49.2%, showing that\nthis is a challenging testbed for claim veracity prediction.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 10:57:29 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 15:51:53 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Augenstein", "Isabelle", ""], ["Lioma", "Christina", ""], ["Wang", "Dongsheng", ""], ["Lima", "Lucas Chaves", ""], ["Hansen", "Casper", ""], ["Hansen", "Christian", ""], ["Simonsen", "Jakob Grue", ""]]}, {"id": "1909.03285", "submitter": "Chunchuan Lyu Mr.", "authors": "Chunchuan Lyu, Shay B. Cohen, Ivan Titov", "title": "Semantic Role Labeling with Iterative Structure Refinement", "comments": null, "journal-ref": "EMNLP 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern state-of-the-art Semantic Role Labeling (SRL) methods rely on\nexpressive sentence encoders (e.g., multi-layer LSTMs) but tend to model only\nlocal (if any) interactions between individual argument labeling decisions.\nThis contrasts with earlier work and also with the intuition that the labels of\nindividual arguments are strongly interdependent. We model interactions between\nargument labeling decisions through {\\it iterative refinement}. Starting with\nan output produced by a factorized model, we iteratively refine it using a\nrefinement network. Instead of modeling arbitrary interactions among roles and\nwords, we encode prior knowledge about the SRL problem by designing a\nrestricted network architecture capturing non-local interactions. This modeling\nchoice prevents overfitting and results in an effective model, outperforming\nstrong factorized baseline models on all 7 CoNLL-2009 languages, and achieving\nstate-of-the-art results on 5 of them, including English.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 15:23:37 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Lyu", "Chunchuan", ""], ["Cohen", "Shay B.", ""], ["Titov", "Ivan", ""]]}, {"id": "1909.03315", "submitter": "Martin Andrews", "authors": "Martin Andrews, Sam Witteveen", "title": "Relationships from Entity Stream", "comments": "Accepted paper for the ViGIL workshop at NIPS 2017. (4 pages +\n  references)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relational reasoning is a central component of intelligent behavior, but has\nproven difficult for neural networks to learn. The Relation Network (RN) module\nwas recently proposed by DeepMind to solve such problems, and demonstrated\nstate-of-the-art results on a number of datasets. However, the RN module scales\nquadratically in the size of the input, since it calculates relationship\nfactors between every patch in the visual field, including those that do not\ncorrespond to entities. In this paper, we describe an architecture that enables\nrelationships to be determined from a stream of entities obtained by an\nattention mechanism over the input field. The model is trained end-to-end, and\ndemonstrates equivalent performance with greater interpretability while\nrequiring only a fraction of the model parameters of the original RN module.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 18:24:57 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Andrews", "Martin", ""], ["Witteveen", "Sam", ""]]}, {"id": "1909.03317", "submitter": "Sam Davidson", "authors": "Sam Davidson, Dian Yu, Zhou Yu", "title": "Dependency Parsing for Spoken Dialog Systems", "comments": "To be presented at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dependency parsing of conversational input can play an important role in\nlanguage understanding for dialog systems by identifying the relationships\nbetween entities extracted from user utterances. Additionally, effective\ndependency parsing can elucidate differences in language structure and usage\nfor discourse analysis of human-human versus human-machine dialogs. However,\nmodels trained on datasets based on news articles and web data do not perform\nwell on spoken human-machine dialog, and currently available annotation schemes\ndo not adapt well to dialog data. Therefore, we propose the Spoken Conversation\nUniversal Dependencies (SCUD) annotation scheme that extends the Universal\nDependencies (UD) (Nivre et al., 2016) guidelines to spoken human-machine\ndialogs. We also provide ConvBank, a conversation dataset between humans and an\nopen-domain conversational dialog system with SCUD annotation. Finally, to\ndemonstrate the utility of the dataset, we train a dependency parser on the\nConvBank dataset. We demonstrate that by pre-training a dependency parser on a\nset of larger public datasets and fine-tuning on ConvBank data, we achieved the\nbest result, 85.05% unlabeled and 77.82% labeled attachment accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 18:32:28 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Davidson", "Sam", ""], ["Yu", "Dian", ""], ["Yu", "Zhou", ""]]}, {"id": "1909.03329", "submitter": "Fan-Keng Sun", "authors": "Fan-Keng Sun, Cheng-Hao Ho, and Hung-Yi Lee", "title": "LAMOL: LAnguage MOdeling for Lifelong Language Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most research on lifelong learning applies to images or games, but not\nlanguage. We present LAMOL, a simple yet effective method for lifelong language\nlearning (LLL) based on language modeling. LAMOL replays pseudo-samples of\nprevious tasks while requiring no extra memory or model capacity. Specifically,\nLAMOL is a language model that simultaneously learns to solve the tasks and\ngenerate training samples. When the model is trained for a new task, it\ngenerates pseudo-samples of previous tasks for training alongside data for the\nnew task. The results show that LAMOL prevents catastrophic forgetting without\nany sign of intransigence and can perform five very different language tasks\nsequentially with only one model. Overall, LAMOL outperforms previous methods\nby a considerable margin and is only 2-3% worse than multitasking, which is\nusually considered the LLL upper bound. The source code is available at\nhttps://github.com/jojotenya/LAMOL.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 20:17:34 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 04:36:52 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Sun", "Fan-Keng", ""], ["Ho", "Cheng-Hao", ""], ["Lee", "Hung-Yi", ""]]}, {"id": "1909.03341", "submitter": "Changhan Wang", "authors": "Changhan Wang, Kyunghyun Cho, Jiatao Gu", "title": "Neural Machine Translation with Byte-Level Subwords", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Almost all existing machine translation models are built on top of\ncharacter-based vocabularies: characters, subwords or words. Rare characters\nfrom noisy text or character-rich languages such as Japanese and Chinese\nhowever can unnecessarily take up vocabulary slots and limit its compactness.\nRepresenting text at the level of bytes and using the 256 byte set as\nvocabulary is a potential solution to this issue. High computational cost has\nhowever prevented it from being widely deployed or used in practice. In this\npaper, we investigate byte-level subwords, specifically byte-level BPE (BBPE),\nwhich is compacter than character vocabulary and has no out-of-vocabulary\ntokens, but is more efficient than using pure bytes only is. We claim that\ncontextualizing BBPE embeddings is necessary, which can be implemented by a\nconvolutional or recurrent layer. Our experiments show that BBPE has comparable\nperformance to BPE while its size is only 1/8 of that for BPE. In the\nmultilingual setting, BBPE maximizes vocabulary sharing across many languages\nand achieves better translation quality. Moreover, we show that BBPE enables\ntransferring models between languages with non-overlapping character sets.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 21:29:46 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 19:29:29 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Wang", "Changhan", ""], ["Cho", "Kyunghyun", ""], ["Gu", "Jiatao", ""]]}, {"id": "1909.03343", "submitter": "Jack Merullo", "authors": "Jack Merullo, Luke Yeh, Abram Handler, Alvin Grissom II, Brendan\n  O'Connor, Mohit Iyyer", "title": "Investigating Sports Commentator Bias within a Large Corpus of American\n  Football Broadcasts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sports broadcasters inject drama into play-by-play commentary by building\nteam and player narratives through subjective analyses and anecdotes. Prior\nstudies based on small datasets and manual coding show that such theatrics\nevince commentator bias in sports broadcasts. To examine this phenomenon, we\nassemble FOOTBALL, which contains 1,455 broadcast transcripts from American\nfootball games across six decades that are automatically annotated with 250K\nplayer mentions and linked with racial metadata. We identify major confounding\nfactors for researchers examining racial bias in FOOTBALL, and perform a\ncomputational analysis that supports conclusions from prior social science\nstudies.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 21:40:04 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 19:21:31 GMT"}, {"version": "v3", "created": "Wed, 18 Sep 2019 21:50:37 GMT"}, {"version": "v4", "created": "Sat, 19 Oct 2019 01:42:03 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Merullo", "Jack", ""], ["Yeh", "Luke", ""], ["Handler", "Abram", ""], ["Grissom", "Alvin", "II"], ["O'Connor", "Brendan", ""], ["Iyyer", "Mohit", ""]]}, {"id": "1909.03359", "submitter": "Gurbinder Gill", "authors": "Gurbinder Gill (1), Roshan Dathathri (1), Saeed Maleki (2), Madan\n  Musuvathi (2), Todd Mytkowicz (2), Olli Saarikivi (2) ((1) The University of\n  Texas at Austin, (2) Microsoft Research)", "title": "Distributed Training of Embeddings using Graph Analytics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications today, such as NLP, network analysis, and code analysis,\nrely on semantically embedding objects into low-dimensional fixed-length\nvectors. Such embeddings naturally provide a way to perform useful downstream\ntasks, such as identifying relations among objects or predicting objects for a\ngiven context, etc. Unfortunately, the training necessary for accurate\nembeddings is usually computationally intensive and requires processing large\namounts of data. Furthermore, distributing this training is challenging. Most\nembedding training uses stochastic gradient descent (SGD), an \"inherently\"\nsequential algorithm. Prior approaches to parallelizing SGD do not honor these\ndependencies and thus potentially suffer poor convergence.\n  This paper presents a distributed training framework for a class of\napplications that use Skip-gram-like models to generate embeddings. We call\nthis class Any2Vec and it includes Word2Vec, DeepWalk, and Node2Vec among\nothers. We first formulate Any2Vec training algorithm as a graph application\nand leverage the state-of-the-art distributed graph analytics framework,\nD-Galois. We adapt D-Galois to support dynamic graph generation and\nrepartitioning, and incorporate novel communication optimizations. Finally, we\nintroduce a novel way to combine gradients during distributed training to\nprevent accuracy loss. We show that our framework, called GraphAny2Vec, matches\non a cluster of 32 hosts the accuracy of the state-of-the-art shared-memory\nimplementations of Word2Vec and Vertex2Vec on 1 host, and gives a geo-mean\nspeedup of 12x and 5x respectively. Furthermore, GraphAny2Vec is on average 2x\nfaster than the state-of-the-art distributed Word2Vec implementation, DMTK, on\n32 hosts. We also show the superiority of our Gradient Combiner independent of\nGraphAny2Vec by incorporating it in DMTK, which raises its accuracy by > 30%.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 01:06:03 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 00:34:44 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Gill", "Gurbinder", ""], ["Dathathri", "Roshan", ""], ["Maleki", "Saeed", ""], ["Musuvathi", "Madan", ""], ["Mytkowicz", "Todd", ""], ["Saarikivi", "Olli", ""]]}, {"id": "1909.03368", "submitter": "John Hewitt", "authors": "John Hewitt, Percy Liang", "title": "Designing and Interpreting Probes with Control Tasks", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probes, supervised models trained to predict properties (like\nparts-of-speech) from representations (like ELMo), have achieved high accuracy\non a range of linguistic tasks. But does this mean that the representations\nencode linguistic structure or just that the probe has learned the linguistic\ntask? In this paper, we propose control tasks, which associate word types with\nrandom outputs, to complement linguistic tasks. By construction, these tasks\ncan only be learned by the probe itself. So a good probe, (one that reflects\nthe representation), should be selective, achieving high linguistic task\naccuracy and low control task accuracy. The selectivity of a probe puts\nlinguistic task accuracy in context with the probe's capacity to memorize from\nword types. We construct control tasks for English part-of-speech tagging and\ndependency edge prediction, and show that popular probes on ELMo\nrepresentations are not selective. We also find that dropout, commonly used to\ncontrol probe complexity, is ineffective for improving selectivity of MLPs, but\nthat other forms of regularization are effective. Finally, we find that while\nprobes on the first layer of ELMo yield slightly better part-of-speech tagging\naccuracy than the second, probes on the second layer are substantially more\nselective, which raises the question of which layer better represents\nparts-of-speech.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 02:04:32 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Hewitt", "John", ""], ["Liang", "Percy", ""]]}, {"id": "1909.03396", "submitter": "Tomer Levinboim", "authors": "Tomer Levinboim, Ashish V. Thapliyal, Piyush Sharma, Radu Soricut", "title": "Quality Estimation for Image Captions Based on Large-scale Human\n  Evaluations", "comments": "10 pages, 6 figures, 3 tables. Accepted to NAACL2021.\n  https://www.aclweb.org/anthology/2021.naacl-main.253/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic image captioning has improved significantly over the last few\nyears, but the problem is far from being solved, with state of the art models\nstill often producing low quality captions when used in the wild. In this\npaper, we focus on the task of Quality Estimation (QE) for image captions,\nwhich attempts to model the caption quality from a human perspective and\nwithout access to ground-truth references, so that it can be applied at\nprediction time to detect low-quality captions produced on previously unseen\nimages. For this task, we develop a human evaluation process that collects\ncoarse-grained caption annotations from crowdsourced users, which is then used\nto collect a large scale dataset spanning more than 600k caption quality\nratings. We then carefully validate the quality of the collected ratings and\nestablish baseline models for this new QE task. Finally, we further collect\nfine-grained caption quality annotations from trained raters, and use them to\ndemonstrate that QE models trained over the coarse ratings can effectively\ndetect and filter out low-quality image captions, thereby improving the user\nexperience from captioning systems.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 06:55:53 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 19:03:27 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Levinboim", "Tomer", ""], ["Thapliyal", "Ashish V.", ""], ["Sharma", "Piyush", ""], ["Soricut", "Radu", ""]]}, {"id": "1909.03405", "submitter": "Weidi Xu", "authors": "Weidi Xu, Xingyi Cheng, Kunlong Chen, Wei Wang, Bin Bi, Ming Yan, Chen\n  Wu, Luo Si, Wei Chu and Taifeng Wang", "title": "Symmetric Regularization based BERT for Pair-wise Semantic Reasoning", "comments": "8 pages, 3 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability of semantic reasoning over the sentence pair is essential for\nmany natural language understanding tasks, e.g., natural language inference and\nmachine reading comprehension. A recent significant improvement in these tasks\ncomes from BERT. As reported, the next sentence prediction (NSP) in BERT, which\nlearns the contextual relationship between two sentences, is of great\nsignificance for downstream problems with sentence-pair input. Despite the\neffectiveness of NSP, we suggest that NSP still lacks the essential signal to\ndistinguish between entailment and shallow correlation. To remedy this, we\npropose to augment the NSP task to a 3-class categorization task, which\nincludes a category for previous sentence prediction (PSP). The involvement of\nPSP encourages the model to focus on the informative semantics to determine the\nsentence order, thereby improves the ability of semantic understanding. This\nsimple modification yields remarkable improvement against vanilla BERT. To\nfurther incorporate the document-level information, the scope of NSP and PSP is\nexpanded into a broader range, i.e., NSP and PSP also include close but\nnonsuccessive sentences, the noise of which is mitigated by the label-smoothing\ntechnique. Both qualitative and quantitative experimental results demonstrate\nthe effectiveness of the proposed method. Our method consistently improves the\nperformance on the NLI and MRC benchmarks, including the challenging HANS\ndataset \\cite{hans}, suggesting that the document-level task is still promising\nfor the pre-training.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 08:55:09 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 09:03:51 GMT"}, {"version": "v3", "created": "Thu, 17 Jun 2021 10:09:38 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Xu", "Weidi", ""], ["Cheng", "Xingyi", ""], ["Chen", "Kunlong", ""], ["Wang", "Wei", ""], ["Bi", "Bin", ""], ["Yan", "Ming", ""], ["Wu", "Chen", ""], ["Si", "Luo", ""], ["Chu", "Wei", ""], ["Wang", "Taifeng", ""]]}, {"id": "1909.03409", "submitter": "Bin Guo", "authors": "Bin Guo, Hao Wang, Yasan Ding, Wei Wu, Shaoyang Hao, Yueqi Sun, Zhiwen\n  Yu", "title": "Conditional Text Generation for Harmonious Human-Machine Interaction", "comments": "Accepted by the ACM Transactions on Intelligent Systems and\n  Technology (TIST)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, with the development of deep learning, text generation\ntechnology has undergone great changes and provided many kinds of services for\nhuman beings, such as restaurant reservation and daily communication. The\nautomatically generated text is becoming more and more fluent so researchers\nbegin to consider more anthropomorphic text generation technology, that is the\nconditional text generation, including emotional text generation, personalized\ntext generation, and so on. Conditional Text Generation (CTG) has thus become a\nresearch hotspot. As a promising research field, we find that many efforts have\nbeen paid to exploring it. Therefore, we aim to give a comprehensive review of\nthe new research trends of CTG. We first summary several key techniques and\nillustrate the technical evolution route in the field of neural text\ngeneration, based on the concept model of CTG. We further make an investigation\nof existing CTG fields and propose several general learning models for CTG.\nFinally, we discuss the open issues and promising research directions of CTG.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 09:31:20 GMT"}, {"version": "v2", "created": "Thu, 24 Dec 2020 15:38:26 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Guo", "Bin", ""], ["Wang", "Hao", ""], ["Ding", "Yasan", ""], ["Wu", "Wei", ""], ["Hao", "Shaoyang", ""], ["Sun", "Yueqi", ""], ["Yu", "Zhiwen", ""]]}, {"id": "1909.03415", "submitter": "Yidan Hu", "authors": "Yidan Hu, Gongqi Lin, Yuan Miao, Chunyan Miao", "title": "Commonsense Knowledge + BERT for Level 2 Reading Comprehension Ability\n  Test", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commonsense knowledge plays an important role when we read. The performance\nof BERT on SQuAD dataset shows that the accuracy of BERT can be better than\nhuman users. However, it does not mean that computers can surpass the human\nbeing in reading comprehension. CommonsenseQA is a large-scale dataset which is\ndesigned based on commonsense knowledge. BERT only achieved an accuracy of\n55.9% on it. The result shows that computers cannot apply commonsense knowledge\nlike human beings to answer questions. Comprehension Ability Test (CAT) divided\nthe reading comprehension ability at four levels. We can achieve human like\ncomprehension ability level by level. BERT has performed well at level 1 which\ndoes not require common knowledge. In this research, we propose a system which\naims to allow computers to read articles and answer related questions with\ncommonsense knowledge like a human being for CAT level 2. This system consists\nof three parts. Firstly, we built a commonsense knowledge graph; and then\nautomatically constructed the commonsense knowledge question dataset according\nto it. Finally, BERT is combined with the commonsense knowledge to achieve the\nreading comprehension ability at CAT level 2. Experiments show that it can pass\nthe CAT as long as the required common knowledge is included in the knowledge\nbase.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 09:47:56 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Hu", "Yidan", ""], ["Lin", "Gongqi", ""], ["Miao", "Yuan", ""], ["Miao", "Chunyan", ""]]}, {"id": "1909.03434", "submitter": "Che-Ping Tsai", "authors": "Che-Ping Tsai and Hung-Yi Lee", "title": "Order-free Learning Alleviating Exposure Bias in Multi-label\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label classification (MLC) assigns multiple labels to each sample.\nPrior studies show that MLC can be transformed to a sequence prediction problem\nwith a recurrent neural network (RNN) decoder to model the label dependency.\nHowever, training a RNN decoder requires a predefined order of labels, which is\nnot directly available in the MLC specification. Besides, RNN thus trained\ntends to overfit the label combinations in the training set and have difficulty\ngenerating unseen label sequences. In this paper, we propose a new framework\nfor MLC which does not rely on a predefined label order and thus alleviates\nexposure bias. The experimental results on three multi-label classification\nbenchmark datasets show that our method outperforms competitive baselines by a\nlarge margin. We also find the proposed approach has a higher probability of\ngenerating label combinations not seen during training than the baseline\nmodels. The result shows that the proposed approach has better generalization\ncapability.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 11:53:24 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Tsai", "Che-Ping", ""], ["Lee", "Hung-Yi", ""]]}, {"id": "1909.03453", "submitter": "Valentin Barriere", "authors": "Valentin Barriere and Amaury Fouret", "title": "May I Check Again? -- A simple but efficient way to generate and use\n  contextual dictionaries for Named Entity Recognition. Application to French\n  Legal Texts", "comments": "accepted at NoDaLiDa'19, Turku, Finland", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a new method to learn a model robust to typos for a\nNamed Entity Recognition task. Our improvement over existing methods helps the\nmodel to take into account the context of the sentence inside a court decision\nin order to recognize an entity with a typo. We used state-of-the-art models\nand enriched the last layer of the neural network with high-level information\nlinked with the potential of the word to be a certain type of entity. More\nprecisely, we utilized the similarities between the word and the potential\nentity candidates in the tagged sentence context. The experiments on a dataset\nof French court decisions show a reduction of the relative F1-score error of\n32%, upgrading the score obtained with the most competitive fine-tuned\nstate-of-the-art system from 94.85% to 96.52%.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 12:52:46 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Barriere", "Valentin", ""], ["Fouret", "Amaury", ""]]}, {"id": "1909.03464", "submitter": "Johannes Bjerva", "authors": "Johannes Bjerva, Wouter Kouw, Isabelle Augenstein", "title": "Back to the Future -- Sequential Alignment of Text Representations", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language evolves over time in many ways relevant to natural language\nprocessing tasks. For example, recent occurrences of tokens 'BERT' and 'ELMO'\nin publications refer to neural network architectures rather than persons. This\ntype of temporal signal is typically overlooked, but is important if one aims\nto deploy a machine learning model over an extended period of time. In\nparticular, language evolution causes data drift between time-steps in\nsequential decision-making tasks. Examples of such tasks include prediction of\npaper acceptance for yearly conferences (regular intervals) or author stance\nprediction for rumours on Twitter (irregular intervals). Inspired by successes\nin computer vision, we tackle data drift by sequentially aligning learned\nrepresentations. We evaluate on three challenging tasks varying in terms of\ntime-scales, linguistic units, and domains. These tasks show our method\noutperforming several strong baselines, including using all available data. We\nargue that, due to its low computational expense, sequential alignment is a\npractical solution to dealing with language evolution.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 13:35:12 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 06:00:30 GMT"}, {"version": "v3", "created": "Fri, 22 Nov 2019 11:55:47 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Bjerva", "Johannes", ""], ["Kouw", "Wouter", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "1909.03477", "submitter": "Chen Zhang", "authors": "Chen Zhang, Qiuchi Li, Dawei Song", "title": "Aspect-based Sentiment Classification with Aspect-specific Graph\n  Convolutional Networks", "comments": "11 pages, 4 figures, accepted to EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to their inherent capability in semantic alignment of aspects and their\ncontext words, attention mechanism and Convolutional Neural Networks (CNNs) are\nwidely applied for aspect-based sentiment classification. However, these models\nlack a mechanism to account for relevant syntactical constraints and long-range\nword dependencies, and hence may mistakenly recognize syntactically irrelevant\ncontextual words as clues for judging aspect sentiment. To tackle this problem,\nwe propose to build a Graph Convolutional Network (GCN) over the dependency\ntree of a sentence to exploit syntactical information and word dependencies.\nBased on it, a novel aspect-specific sentiment classification framework is\nraised. Experiments on three benchmarking collections illustrate that our\nproposed model has comparable effectiveness to a range of state-of-the-art\nmodels, and further demonstrate that both syntactical information and\nlong-range word dependencies are properly captured by the graph convolution\nstructure.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 14:21:54 GMT"}, {"version": "v2", "created": "Sun, 13 Oct 2019 06:20:58 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Zhang", "Chen", ""], ["Li", "Qiuchi", ""], ["Song", "Dawei", ""]]}, {"id": "1909.03480", "submitter": "Prithviraj Ammanabrolu", "authors": "Prithviraj Ammanabrolu, Ethan Tien, Wesley Cheung, Zhaochen Luo,\n  William Ma, Lara J. Martin, Mark O. Riedl", "title": "Story Realization: Expanding Plot Events into Sentences", "comments": "In proceedings of AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network based approaches to automated story plot generation attempt to\nlearn how to generate novel plots from a corpus of natural language plot\nsummaries. Prior work has shown that a semantic abstraction of sentences called\nevents improves neural plot generation and and allows one to decompose the\nproblem into: (1) the generation of a sequence of events (event-to-event) and\n(2) the transformation of these events into natural language sentences\n(event-to-sentence). However, typical neural language generation approaches to\nevent-to-sentence can ignore the event details and produce\ngrammatically-correct but semantically-unrelated sentences. We present an\nensemble-based model that generates natural language guided by events.We\nprovide results---including a human subjects study---for a full end-to-end\nautomated story generation system showing that our method generates more\ncoherent and plausible stories than baseline approaches.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 15:09:32 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 18:32:23 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Ammanabrolu", "Prithviraj", ""], ["Tien", "Ethan", ""], ["Cheung", "Wesley", ""], ["Luo", "Zhaochen", ""], ["Ma", "William", ""], ["Martin", "Lara J.", ""], ["Riedl", "Mark O.", ""]]}, {"id": "1909.03493", "submitter": "Donghyun Kim", "authors": "Donghyun Kim, Kuniaki Saito, Kate Saenko, Stan Sclaroff, Bryan A.\n  Plummer", "title": "MULE: Multimodal Universal Language Embedding", "comments": "Accepted as an oral at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing vision-language methods typically support two languages at a time at\nmost. In this paper, we present a modular approach which can easily be\nincorporated into existing vision-language methods in order to support many\nlanguages. We accomplish this by learning a single shared Multimodal Universal\nLanguage Embedding (MULE) which has been visually-semantically aligned across\nall languages. Then we learn to relate MULE to visual data as if it were a\nsingle language. Our method is not architecture specific, unlike prior work\nwhich typically learned separate branches for each language, enabling our\napproach to easily be adapted to many vision-language methods and tasks. Since\nMULE learns a single language branch in the multimodal model, we can also scale\nto support many languages, and languages with fewer annotations can take\nadvantage of the good representation learned from other (more abundant)\nlanguage data. We demonstrate the effectiveness of MULE on the bidirectional\nimage-sentence retrieval task, supporting up to four languages in a single\nmodel. In addition, we show that Machine Translation can be used for data\naugmentation in multilingual learning, which, combined with MULE, improves mean\nrecall by up to 21.9% on a single-language compared to prior work, with the\nmost significant gains seen on languages with relatively few annotations. Our\ncode is publicly available.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 16:08:04 GMT"}, {"version": "v2", "created": "Sat, 28 Dec 2019 21:57:10 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Kim", "Donghyun", ""], ["Saito", "Kuniaki", ""], ["Saenko", "Kate", ""], ["Sclaroff", "Stan", ""], ["Plummer", "Bryan A.", ""]]}, {"id": "1909.03508", "submitter": "Martin Andrews", "authors": "Yew Ken Chia, Sam Witteveen, Martin Andrews", "title": "Transformer to CNN: Label-scarce distillation for efficient text\n  classification", "comments": "Accepted paper for CDNNRIA workshop at NeurIPS 2018. (3 pages +\n  references)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Significant advances have been made in Natural Language Processing (NLP)\nmodelling since the beginning of 2018. The new approaches allow for accurate\nresults, even when there is little labelled data, because these NLP models can\nbenefit from training on both task-agnostic and task-specific unlabelled data.\nHowever, these advantages come with significant size and computational costs.\nThis workshop paper outlines how our proposed convolutional student\narchitecture, having been trained by a distillation process from a large-scale\nmodel, can achieve 300x inference speedup and 39x reduction in parameter count.\nIn some cases, the student model performance surpasses its teacher on the\nstudied tasks.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 16:57:26 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Chia", "Yew Ken", ""], ["Witteveen", "Sam", ""], ["Andrews", "Martin", ""]]}, {"id": "1909.03524", "submitter": "Linzi Xing", "authors": "Linzi Xing, Michael J. Paul, Giuseppe Carenini", "title": "Evaluating Topic Quality with Posterior Variability", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic topic models such as latent Dirichlet allocation (LDA) are\npopularly used with Bayesian inference methods such as Gibbs sampling to learn\nposterior distributions over topic model parameters. We derive a novel measure\nof LDA topic quality using the variability of the posterior distributions.\nCompared to several existing baselines for automatic topic evaluation, the\nproposed metric achieves state-of-the-art correlations with human judgments of\ntopic quality in experiments on three corpora. We additionally demonstrate that\ntopic quality estimation can be further improved using a supervised estimator\nthat combines multiple metrics.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 18:25:48 GMT"}, {"version": "v2", "created": "Sun, 15 Sep 2019 04:55:06 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Xing", "Linzi", ""], ["Paul", "Michael J.", ""], ["Carenini", "Giuseppe", ""]]}, {"id": "1909.03526", "submitter": "Chiyu Zhang", "authors": "Chiyu Zhang and Muhammad Abdul-Mageed", "title": "Multi-Task Bidirectional Transformer Representations for Irony Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Supervised deep learning requires large amounts of training data. In the\ncontext of the FIRE2019 Arabic irony detection shared task (IDAT@FIRE2019), we\nshow how we mitigate this need by fine-tuning the pre-trained bidirectional\nencoders from transformers (BERT) on gold data in a multi-task setting. We\nfurther improve our models by by further pre-training BERT on `in-domain' data,\nthus alleviating an issue of dialect mismatch in the Google-released BERT\nmodel. Our best model acquires 82.4 macro F1 score, and has the unique\nadvantage of being feature-engineering free (i.e., based exclusively on deep\nlearning).\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 18:31:42 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 04:37:02 GMT"}, {"version": "v3", "created": "Thu, 31 Oct 2019 06:57:28 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Zhang", "Chiyu", ""], ["Abdul-Mageed", "Muhammad", ""]]}, {"id": "1909.03527", "submitter": "Danish Contractor", "authors": "Danish Contractor and Krunal Shah and Aditi Partap and Mausam and\n  Parag Singla", "title": "Large Scale Question Answering using Tourism Data", "comments": "20 pages with supplementary notes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the novel task of answering entity-seeking recommendation\nquestions using a collection of reviews that describe candidate answer\nentities. We harvest a QA dataset that contains 47,124 paragraph-sized real\nuser questions from travelers seeking recommendations for hotels, attractions\nand restaurants. Each question can have thousands of candidate answers to\nchoose from and each candidate is associated with a collection of unstructured\nreviews. This dataset is especially challenging because commonly used neural\narchitectures for reasoning and QA are prohibitively expensive for a task of\nthis scale. As a solution, we design a scalable cluster-select-rerank approach.\nIt first clusters text for each entity to identify exemplar sentences\ndescribing an entity. It then uses a scalable neural information retrieval (IR)\nmodule to select a set of potential entities from the large candidate set. A\nreranker uses a deeper attention-based architecture to pick the best answers\nfrom the selected entities. This strategy performs better than a pure IR or a\npure attention-based reasoning approach yielding nearly 25% relative\nimprovement in Accuracy@3 over both approaches.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 18:35:03 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 17:17:28 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Contractor", "Danish", ""], ["Shah", "Krunal", ""], ["Partap", "Aditi", ""], ["Mausam", "", ""], ["Singla", "Parag", ""]]}, {"id": "1909.03544", "submitter": "Milan Straka", "authors": "Milan Straka, Jana Strakov\\'a, Jan Haji\\v{c}", "title": "Czech Text Processing with Contextual Embeddings: POS Tagging,\n  Lemmatization, Parsing and NER", "comments": "Fixed the incorrectly evaluated CNEC 2.0 results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextualized embeddings, which capture appropriate word meaning depending\non context, have recently been proposed. We evaluate two meth ods for\nprecomputing such embeddings, BERT and Flair, on four Czech text processing\ntasks: part-of-speech (POS) tagging, lemmatization, dependency pars ing and\nnamed entity recognition (NER). The first three tasks, POS tagging,\nlemmatization and dependency parsing, are evaluated on two corpora: the Prague\nDependency Treebank 3.5 and the Universal Dependencies 2.3. The named entity\nrecognition (NER) is evaluated on the Czech Named Entity Corpus 1.1 and 2.0. We\nreport state-of-the-art results for the above mentioned tasks and corpora.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 21:00:05 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 16:30:01 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Straka", "Milan", ""], ["Strakov\u00e1", "Jana", ""], ["Haji\u010d", "Jan", ""]]}, {"id": "1909.03546", "submitter": "David Wadden", "authors": "David Wadden, Ulme Wennberg, Yi Luan, Hannaneh Hajishirzi", "title": "Entity, Relation, and Event Extraction with Contextualized Span\n  Representations", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the capabilities of a unified, multi-task framework for three\ninformation extraction tasks: named entity recognition, relation extraction,\nand event extraction. Our framework (called DyGIE++) accomplishes all tasks by\nenumerating, refining, and scoring text spans designed to capture local\n(within-sentence) and global (cross-sentence) context. Our framework achieves\nstate-of-the-art results across all tasks, on four datasets from a variety of\ndomains. We perform experiments comparing different techniques to construct\nspan representations. Contextualized embeddings like BERT perform well at\ncapturing relationships among entities in the same or adjacent sentences, while\ndynamic span graph updates model long-range cross-sentence relationships. For\ninstance, propagating span representations via predicted coreference links can\nenable the model to disambiguate challenging entity mentions. Our code is\npublicly available at https://github.com/dwadden/dygiepp and can be easily\nadapted for new tasks or datasets.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 21:19:09 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 01:26:15 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Wadden", "David", ""], ["Wennberg", "Ulme", ""], ["Luan", "Yi", ""], ["Hajishirzi", "Hannaneh", ""]]}, {"id": "1909.03553", "submitter": "Peter Clark", "authors": "Oyvind Tafjord, Matt Gardner, Kevin Lin, Peter Clark", "title": "QuaRTz: An Open-Domain Dataset of Qualitative Relationship Questions", "comments": "EMNLP'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the first open-domain dataset, called QuaRTz, for reasoning\nabout textual qualitative relationships. QuaRTz contains general qualitative\nstatements, e.g., \"A sunscreen with a higher SPF protects the skin longer.\",\ntwinned with 3864 crowdsourced situated questions, e.g., \"Billy is wearing\nsunscreen with a lower SPF than Lucy. Who will be best protected from the\nsun?\", plus annotations of the properties being compared. Unlike previous\ndatasets, the general knowledge is textual and not tied to a fixed set of\nrelationships, and tests a system's ability to comprehend and apply textual\nqualitative knowledge in a novel setting. We find state-of-the-art results are\nsubstantially (20%) below human performance, presenting an open challenge to\nthe NLP community.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 22:05:19 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Tafjord", "Oyvind", ""], ["Gardner", "Matt", ""], ["Lin", "Kevin", ""], ["Clark", "Peter", ""]]}, {"id": "1909.03564", "submitter": "Artit Wangperawong", "authors": "Xinyi Liu and Artit Wangperawong", "title": "Transfer Learning Robustness in Multi-Class Categorization by\n  Fine-Tuning Pre-Trained Contextualized Language Models", "comments": "Pre-trained models and code available at\n  https://github.com/artitw/text2class", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study compares the effectiveness and robustness of multi-class\ncategorization of Amazon product data using transfer learning on pre-trained\ncontextualized language models. Specifically, we fine-tuned BERT and XLNet, two\nbidirectional models that have achieved state-of-the-art performance on many\nnatural language tasks and benchmarks, including text classification. While\nexisting classification studies and benchmarks focus on binary targets, with\nthe exception of ordinal ranking tasks, here we examine the robustness of such\nmodels as the number of classes grows from 1 to 20. Our experiments demonstrate\nan approximately linear decrease in performance metrics (i.e., precision,\nrecall, $F_1$ score, and accuracy) with the number of class labels. BERT\nconsistently outperforms XLNet using identical hyperparameters on the entire\nrange of class label quantities for categorizing products based on their\ntextual descriptions. BERT is also more affordable than XLNet in terms of the\ncomputational cost (i.e., time and memory) required for training. In all cases\nstudied, the performance degradation rates were estimated to be 1% per\nadditional class label.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 23:35:00 GMT"}, {"version": "v2", "created": "Sat, 21 Sep 2019 17:54:14 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Liu", "Xinyi", ""], ["Wangperawong", "Artit", ""]]}, {"id": "1909.03569", "submitter": "Prince Zizhuang Wang", "authors": "Prince Zizhuang Wang and William Yang Wang", "title": "Neural Gaussian Copula for Variational Autoencoder", "comments": "11 pages", "journal-ref": "EMNLP 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational language models seek to estimate the posterior of latent\nvariables with an approximated variational posterior. The model often assumes\nthe variational posterior to be factorized even when the true posterior is not.\nThe learned variational posterior under this assumption does not capture the\ndependency relationships over latent variables. We argue that this would cause\na typical training problem called posterior collapse observed in all other\nvariational language models. We propose Gaussian Copula Variational Autoencoder\n(VAE) to avert this problem. Copula is widely used to model correlation and\ndependencies of high-dimensional random variables, and therefore it is helpful\nto maintain the dependency relationships that are lost in VAE. The empirical\nresults show that by modeling the correlation of latent variables explicitly\nusing a neural parametric copula, we can avert this training difficulty while\ngetting competitive results among all other VAE approaches.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 00:10:58 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Wang", "Prince Zizhuang", ""], ["Wang", "William Yang", ""]]}, {"id": "1909.03582", "submitter": "Peng Xu", "authors": "Peng Xu, Chien-Sheng Wu, Andrea Madotto and Pascale Fung", "title": "Clickbait? Sensational Headline Generation with Auto-tuned Reinforcement\n  Learning", "comments": "Accepted by EMNLP2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensational headlines are headlines that capture people's attention and\ngenerate reader interest. Conventional abstractive headline generation methods,\nunlike human writers, do not optimize for maximal reader attention. In this\npaper, we propose a model that generates sensational headlines without labeled\ndata. We first train a sensationalism scorer by classifying online headlines\nwith many comments (\"clickbait\") against a baseline of headlines generated from\na summarization model. The score from the sensationalism scorer is used as the\nreward for a reinforcement learner. However, maximizing the noisy\nsensationalism reward will generate unnatural phrases instead of sensational\nheadlines. To effectively leverage this noisy reward, we propose a novel loss\nfunction, Auto-tuned Reinforcement Learning (ARL), to dynamically balance\nreinforcement learning (RL) with maximum likelihood estimation (MLE). Human\nevaluation shows that 60.8% of samples generated by our model are sensational,\nwhich is significantly better than the Pointer-Gen baseline and other RL\nmodels.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 01:33:01 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Xu", "Peng", ""], ["Wu", "Chien-Sheng", ""], ["Madotto", "Andrea", ""], ["Fung", "Pascale", ""]]}, {"id": "1909.03588", "submitter": "Xianggen Liu", "authors": "Xianggen Liu, Lili Mou, Fandong Meng, Hao Zhou, Jie Zhou, Sen Song", "title": "Unsupervised Paraphrasing by Simulated Annealing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised paraphrase generation is a promising and important research\ntopic in natural language processing. We propose UPSA, a novel approach that\naccomplishes Unsupervised Paraphrasing by Simulated Annealing. We model\nparaphrase generation as an optimization problem and propose a sophisticated\nobjective function, involving semantic similarity, expression diversity, and\nlanguage fluency of paraphrases. Then, UPSA searches the sentence space towards\nthis objective by performing a sequence of local editing. Our method is\nunsupervised and does not require parallel corpora for training, so it could be\neasily applied to different domains. We evaluate our approach on a variety of\nbenchmark datasets, namely, Quora, Wikianswers, MSCOCO, and Twitter. Extensive\nresults show that UPSA achieves the state-of-the-art performance compared with\nprevious unsupervised methods in terms of both automatic and human evaluations.\nFurther, our approach outperforms most existing domain-adapted supervised\nmodels, showing the generalizability of UPSA.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 01:59:31 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 01:55:22 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Liu", "Xianggen", ""], ["Mou", "Lili", ""], ["Meng", "Fandong", ""], ["Zhou", "Hao", ""], ["Zhou", "Jie", ""], ["Song", "Sen", ""]]}, {"id": "1909.03590", "submitter": "Eric Yuan", "authors": "Rui Meng, Xingdi Yuan, Tong Wang, Peter Brusilovsky, Adam Trischler,\n  Daqing He", "title": "Does Order Matter? An Empirical Study on Generating Multiple Keyphrases\n  as a Sequence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, concatenating multiple keyphrases as a target sequence has been\nproposed as a new learning paradigm for keyphrase generation. Existing studies\nconcatenate target keyphrases in different orders but no study has examined the\neffects of ordering on models' behavior. In this paper, we propose several\norderings for concatenation and inspect the important factors for training a\nsuccessful keyphrase generation model. By running comprehensive comparisons, we\nobserve one preferable ordering and summarize a number of empirical findings\nand challenges, which can shed light on future research on this line of work.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 02:04:53 GMT"}, {"version": "v2", "created": "Sun, 6 Oct 2019 23:10:28 GMT"}, {"version": "v3", "created": "Sun, 20 Oct 2019 19:03:01 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Meng", "Rui", ""], ["Yuan", "Xingdi", ""], ["Wang", "Tong", ""], ["Brusilovsky", "Peter", ""], ["Trischler", "Adam", ""], ["He", "Daqing", ""]]}, {"id": "1909.03598", "submitter": "Xiaolei Huang", "authors": "Xiaolei Huang, Jonathan May, Nanyun Peng", "title": "What Matters for Neural Cross-Lingual Named Entity Recognition: An\n  Empirical Analysis", "comments": "7 pages", "journal-ref": "published at EMNLP 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building named entity recognition (NER) models for languages that do not have\nmuch training data is a challenging task. While recent work has shown promising\nresults on cross-lingual transfer from high-resource languages to low-resource\nlanguages, it is unclear what knowledge is transferred. In this paper, we first\npropose a simple and efficient neural architecture for cross-lingual NER.\nExperiments show that our model achieves competitive performance with the\nstate-of-the-art. We further analyze how transfer learning works for\ncross-lingual NER on two transferable factors: sequential order and\nmultilingual embeddings, and investigate how model performance varies across\nentity lengths. Finally, we conduct a case-study on a non-Latin language,\nBengali, which suggests that leveraging knowledge from Wikipedia will be a\npromising direction to further improve the model performances. Our results can\nshed light on future research for improving cross-lingual NER.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 02:45:38 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Huang", "Xiaolei", ""], ["May", "Jonathan", ""], ["Peng", "Nanyun", ""]]}, {"id": "1909.03622", "submitter": "James O' Neill", "authors": "James O' Neill and Danushka Bollegala", "title": "Transfer Reward Learning for Policy Gradient-Based Text Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task-specific scores are often used to optimize for and evaluate the\nperformance of conditional text generation systems. However, such scores are\nnon-differentiable and cannot be used in the standard supervised learning\nparadigm. Hence, policy gradient methods are used since the gradient can be\ncomputed without requiring a differentiable objective.\n  However, we argue that current n-gram overlap based measures that are used as\nrewards can be improved by using model-based rewards transferred from tasks\nthat directly compare the similarity of sentence pairs. These reward models\neither output a score of sentence-level syntactic and semantic similarity\nbetween entire predicted and target sentences as the expected return, or for\nintermediate phrases as segmented accumulative rewards.\n  We demonstrate that using a \\textit{Transferable Reward Learner} leads to\nimproved results on semantical evaluation measures in policy-gradient models\nfor image captioning tasks. Our InferSent actor-critic model improves over a\nBLEU trained actor-critic model on MSCOCO when evaluated on a Word Mover's\nDistance similarity measure by 6.97 points, also improving on a Sliding Window\nCosine Similarity measure by 10.48 points. Similar performance improvements are\nalso obtained on the smaller Flickr-30k dataset, demonstrating the general\napplicability of the proposed transfer learning method.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 03:36:42 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Neill", "James O'", ""], ["Bollegala", "Danushka", ""]]}, {"id": "1909.03683", "submitter": "Christopher Clark", "authors": "Christopher Clark, Mark Yatskar, Luke Zettlemoyer", "title": "Don't Take the Easy Way Out: Ensemble Based Methods for Avoiding Known\n  Dataset Biases", "comments": "In EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art models often make use of superficial patterns in the data\nthat do not generalize well to out-of-domain or adversarial settings. For\nexample, textual entailment models often learn that particular key words imply\nentailment, irrespective of context, and visual question answering models learn\nto predict prototypical answers, without considering evidence in the image. In\nthis paper, we show that if we have prior knowledge of such biases, we can\ntrain a model to be more robust to domain shift. Our method has two stages: we\n(1) train a naive model that makes predictions exclusively based on dataset\nbiases, and (2) train a robust model as part of an ensemble with the naive one\nin order to encourage it to focus on other patterns in the data that are more\nlikely to generalize. Experiments on five datasets with out-of-domain test sets\nshow significantly improved robustness in all settings, including a 12 point\ngain on a changing priors visual question answering dataset and a 9 point gain\non an adversarial question answering test set.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 07:44:24 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Clark", "Christopher", ""], ["Yatskar", "Mark", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1909.03716", "submitter": "Deepak Gupta", "authors": "Deepak Gupta, Kaheer Suleman, Mahmoud Adada, Andrew McNamara and\n  Justin Harris", "title": "Improving Neural Question Generation using World Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we propose a method for incorporating world knowledge (linked\nentities and fine-grained entity types) into a neural question generation\nmodel. This world knowledge helps to encode additional information related to\nthe entities present in the passage required to generate human-like questions.\nWe evaluate our models on both SQuAD and MS MARCO to demonstrate the usefulness\nof the world knowledge features. The proposed world knowledge enriched question\ngeneration model is able to outperform the vanilla neural question generation\nmodel by 1.37 and 1.59 absolute BLEU 4 score on SQuAD and MS MARCO test dataset\nrespectively.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 09:26:42 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 08:02:09 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Gupta", "Deepak", ""], ["Suleman", "Kaheer", ""], ["Adada", "Mahmoud", ""], ["McNamara", "Andrew", ""], ["Harris", "Justin", ""]]}, {"id": "1909.03745", "submitter": "Wanjun Zhong", "authors": "Wanjun Zhong, Jingjing Xu, Duyu Tang, Zenan Xu, Nan Duan, Ming Zhou,\n  Jiahai Wang, Jian Yin", "title": "Reasoning Over Semantic-Level Graph for Fact Checking", "comments": "9pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fact checking is a challenging task because verifying the truthfulness of a\nclaim requires reasoning about multiple retrievable evidence. In this work, we\npresent a method suitable for reasoning about the semantic-level structure of\nevidence. Unlike most previous works, which typically represent evidence\nsentences with either string concatenation or fusing the features of isolated\nevidence sentences, our approach operates on rich semantic structures of\nevidence obtained by semantic role labeling. We propose two mechanisms to\nexploit the structure of evidence while leveraging the advances of pre-trained\nmodels like BERT, GPT or XLNet. Specifically, using XLNet as the backbone, we\nfirst utilize the graph structure to re-define the relative distances of words,\nwith the intuition that semantically related words should have short distances.\nThen, we adopt graph convolutional network and graph attention network to\npropagate and aggregate information from neighboring nodes on the graph. We\nevaluate our system on FEVER, a benchmark dataset for fact checking, and find\nthat rich structural information is helpful and both our graph-based mechanisms\nimprove the accuracy. Our model is the state-of-the-art system in terms of both\nofficial evaluation metrics, namely claim verification accuracy and FEVER\nscore.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 10:34:09 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 07:33:15 GMT"}, {"version": "v3", "created": "Sat, 25 Apr 2020 06:48:06 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Zhong", "Wanjun", ""], ["Xu", "Jingjing", ""], ["Tang", "Duyu", ""], ["Xu", "Zenan", ""], ["Duan", "Nan", ""], ["Zhou", "Ming", ""], ["Wang", "Jiahai", ""], ["Yin", "Jian", ""]]}, {"id": "1909.03750", "submitter": "Alberto Poncelas", "authors": "Alberto Poncelas, Maja Popovic, Dimitar Shterionov, Gideon Maillette\n  de Buy Wenniger and Andy Way", "title": "Combining SMT and NMT Back-Translated Data for Efficient NMT", "comments": null, "journal-ref": "Proceedings of Recent Advances in Natural Language Processing\n  (RANLP 2019). pages 922--931", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) models achieve their best performance when\nlarge sets of parallel data are used for training. Consequently, techniques for\naugmenting the training set have become popular recently. One of these methods\nis back-translation (Sennrich et al., 2016), which consists on generating\nsynthetic sentences by translating a set of monolingual, target-language\nsentences using a Machine Translation (MT) model.\n  Generally, NMT models are used for back-translation. In this work, we analyze\nthe performance of models when the training data is extended with synthetic\ndata using different MT approaches. In particular we investigate\nback-translated data generated not only by NMT but also by Statistical Machine\nTranslation (SMT) models and combinations of both. The results reveal that the\nmodels achieve the best performances when the training set is augmented with\nback-translated data created by merging different MT approaches.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 10:45:05 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Poncelas", "Alberto", ""], ["Popovic", "Maja", ""], ["Shterionov", "Dimitar", ""], ["Wenniger", "Gideon Maillette de Buy", ""], ["Way", "Andy", ""]]}, {"id": "1909.03759", "submitter": "Danish Contractor", "authors": "Nikhil Verma and Abhishek Sharma and Dhiraj Madan and Danish\n  Contractor and Harshit Kumar and Sachindra Joshi", "title": "Neural Conversational QA: Learning to Reason v.s. Exploiting Patterns", "comments": "Accepted at EMNLP 2020. NOTE: An older version of this paper\n  presented a model called 'UrcaNet'. Please view the v1 version of this paper\n  on arxiv for details on that model. This version does not contain UrcaNet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Conversational QA tasks like ShARC require systems to answer questions\nbased on the contents of a given passage. On studying recent state-of-the-art\nmodels on the ShARCQA task, we found indications that the models learn spurious\nclues/patterns in the dataset. Furthermore, we show that a heuristic-based\nprogram designed to exploit these patterns can have performance comparable to\nthat of the neural models. In this paper we share our findings about four types\nof patterns found in the ShARC corpus and describe how neural models exploit\nthem. Motivated by the aforementioned findings, we create and share a modified\ndataset that has fewer spurious patterns, consequently allowing models to learn\nbetter.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 11:05:15 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 07:43:53 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Verma", "Nikhil", ""], ["Sharma", "Abhishek", ""], ["Madan", "Dhiraj", ""], ["Contractor", "Danish", ""], ["Kumar", "Harshit", ""], ["Joshi", "Sachindra", ""]]}, {"id": "1909.03792", "submitter": "Arezoo Hatefi Ghahfarrokhi", "authors": "Arezoo Hatefi Ghahfarrokhi, Mehrnoush Shamsfard", "title": "Tehran Stock Exchange Prediction Using Sentiment Analysis of Online\n  Textual Opinions", "comments": "Intelligent Systems in Accounting, Finance and Management (2019)", "journal-ref": null, "doi": "10.1002/isaf.1465", "report-no": null, "categories": "q-fin.ST cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the impact of the social media data in\npredicting the Tehran Stock Exchange (TSE) variables for the first time. We\nconsider the closing price and daily return of three different stocks for this\ninvestigation. We collected our social media data from Sahamyab.com/stocktwits\nfor about three months. To extract information from online comments, we propose\na hybrid sentiment analysis approach that combines lexicon-based and\nlearning-based methods. Since lexicons that are available for the Persian\nlanguage are not practical for sentiment analysis in the stock market domain,\nwe built a particular sentiment lexicon for this domain. After designing and\ncalculating daily sentiment indices using the sentiment of the comments, we\nexamine their impact on the baseline models that only use historical market\ndata and propose new predictor models using multi regression analysis. In\naddition to the sentiments, we also examine the comments volume and the users'\nreliabilities. We conclude that the predictability of various stocks in TSE is\ndifferent depending on their attributes. Moreover, we indicate that for\npredicting the closing price only comments volume and for predicting the daily\nreturn both the volume and the sentiment of the comments could be useful. We\ndemonstrate that Users' Trust coefficients have different behaviors toward the\nthree stocks.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 13:36:21 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 08:10:56 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Ghahfarrokhi", "Arezoo Hatefi", ""], ["Shamsfard", "Mehrnoush", ""]]}, {"id": "1909.03794", "submitter": "Zhiwei Lin", "authors": "Lianbo Ma, Peng Sun, Zhiwei Lin, Hui Wang", "title": "Composing Knowledge Graph Embeddings via Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning knowledge graph embedding from an existing knowledge graph is very\nimportant to knowledge graph completion. For a fact $(h,r,t)$ with the head\nentity $h$ having a relation $r$ with the tail entity $t$, the current\napproaches aim to learn low dimensional representations\n$(\\mathbf{h},\\mathbf{r},\\mathbf{t})$, each of which corresponds to the elements\nin $(h, r, t)$, respectively. As $(\\mathbf{h},\\mathbf{r},\\mathbf{t})$ is\nlearned from the existing facts within a knowledge graph, these representations\ncan not be used to detect unknown facts (if the entities or relations never\noccur in the knowledge graph).\n  This paper proposes a new approach called TransW, aiming to go beyond the\ncurrent work by composing knowledge graph embeddings using word embeddings.\nGiven the fact that an entity or a relation contains one or more words (quite\noften), it is sensible to learn a mapping function from word embedding spaces\nto knowledge embedding spaces, which shows how entities are constructed using\nhuman words. More importantly, composing knowledge embeddings using word\nembeddings makes it possible to deal with the emerging new facts (either new\nentities or relations). Experimental results using three public datasets show\nthe consistency and outperformance of the proposed TransW.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 12:22:28 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Ma", "Lianbo", ""], ["Sun", "Peng", ""], ["Lin", "Zhiwei", ""], ["Wang", "Hui", ""]]}, {"id": "1909.03795", "submitter": "Danny Merkx", "authors": "Danny Merkx, Stefan L. Frank, Mirjam Ernestus", "title": "Language learning using Speech to Image retrieval", "comments": "Submitted to InterSpeech 2019", "journal-ref": "Proc. Interspeech 2019", "doi": "10.21437/Interspeech.2019-3067", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans learn language by interaction with their environment and listening to\nother humans. It should also be possible for computational models to learn\nlanguage directly from speech but so far most approaches require text. We\nimprove on existing neural network approaches to create visually grounded\nembeddings for spoken utterances. Using a combination of a multi-layer GRU,\nimportance sampling, cyclic learning rates, ensembling and vectorial\nself-attention our results show a remarkable increase in image-caption\nretrieval performance over previous work. Furthermore, we investigate which\nlayers in the model learn to recognise words in the input. We find that deeper\nnetwork layers are better at encoding word presence, although the final layer\nhas slightly lower performance. This shows that our visually grounded sentence\nencoder learns to recognise words from the input even though it is not\nexplicitly trained for word recognition.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 12:24:06 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Merkx", "Danny", ""], ["Frank", "Stefan L.", ""], ["Ernestus", "Mirjam", ""]]}, {"id": "1909.03821", "submitter": "Takuma Ebisu", "authors": "Takuma Ebisu, Ryutaro Ichise", "title": "Combination of Unified Embedding Model and Observed Features for\n  Knowledge Graph Completion", "comments": "under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs are useful for many artificial intelligence tasks but often\nhave missing data. Hence, a method for completing knowledge graphs is required.\nExisting approaches include embedding models, the Path Ranking Algorithm, and\nrule evaluation models. However, these approaches have limitations. For\nexample, all the information is mixed and difficult to interpret in embedding\nmodels, and traditional rule evaluation models are basically slow. In this\npaper, we provide an integrated view of various approaches and combine them to\ncompensate for their limitations. We first unify state-of-the-art embedding\nmodels, such as ComplEx and TorusE, reinterpreting them as a variant of\ntranslation-based models. Then, we show that these models utilize paths for\nlink prediction and propose a method for evaluating rules based on this idea.\nFinally, we combine an embedding model and observed feature models to predict\nmissing triples. This is possible because all of these models utilize paths. We\nalso conduct experiments, including link prediction tasks, with standard\ndatasets to evaluate our method and framework. The experiments show that our\nmethod can evaluate rules faster than traditional methods and that our\nframework outperforms state-of-the-art models in terms of link prediction.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 12:58:16 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 10:00:41 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Ebisu", "Takuma", ""], ["Ichise", "Ryutaro", ""]]}, {"id": "1909.03862", "submitter": "Yinhe Zheng Dr.", "authors": "Yinhe Zheng, Guanyi Chen, Minlie Huang", "title": "Out-of-domain Detection for Natural Language Understanding in Dialog\n  Systems", "comments": "Accepted by TALSP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural Language Understanding (NLU) is a vital component of dialogue\nsystems, and its ability to detect Out-of-Domain (OOD) inputs is critical in\npractical applications, since the acceptance of the OOD input that is\nunsupported by the current system may lead to catastrophic failure. However,\nmost existing OOD detection methods rely heavily on manually labeled OOD\nsamples and cannot take full advantage of unlabeled data. This limits the\nfeasibility of these models in practical applications.\n  In this paper, we propose a novel model to generate high-quality pseudo OOD\nsamples that are akin to IN-Domain (IND) input utterances, and thereby improves\nthe performance of OOD detection. To this end, an autoencoder is trained to map\nan input utterance into a latent code. and the codes of IND and OOD samples are\ntrained to be indistinguishable by utilizing a generative adversarial network.\nTo provide more supervision signals, an auxiliary classifier is introduced to\nregularize the generated OOD samples to have indistinguishable intent labels.\nExperiments show that these pseudo OOD samples generated by our model can be\nused to effectively improve OOD detection in NLU. Besides, we also demonstrate\nthat the effectiveness of these pseudo OOD data can be further improved by\nefficiently utilizing unlabeled data.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 13:49:10 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 02:50:03 GMT"}, {"version": "v3", "created": "Sun, 22 Mar 2020 01:58:50 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Zheng", "Yinhe", ""], ["Chen", "Guanyi", ""], ["Huang", "Minlie", ""]]}, {"id": "1909.03881", "submitter": "Sahil Garg", "authors": "Sahil Garg, Aram Galstyan, Greg Ver Steeg, Guillermo Cecchi", "title": "Nearly-Unsupervised Hashcode Representations for Relation Extraction", "comments": "Proceedings of EMNLP-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, kernelized locality sensitive hashcodes have been successfully\nemployed as representations of natural language text, especially showing high\nrelevance to biomedical relation extraction tasks. In this paper, we propose to\noptimize the hashcode representations in a nearly unsupervised manner, in which\nwe only use data points, but not their class labels, for learning. The\noptimized hashcode representations are then fed to a supervised classifier\nfollowing the prior work. This nearly unsupervised approach allows fine-grained\noptimization of each hash function, which is particularly suitable for building\nhashcode representations generalizing from a training set to a test set. We\nempirically evaluate the proposed approach for biomedical relation extraction\ntasks, obtaining significant accuracy improvements w.r.t. state-of-the-art\nsupervised and semi-supervised approaches.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 14:20:05 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Garg", "Sahil", ""], ["Galstyan", "Aram", ""], ["Steeg", "Greg Ver", ""], ["Cecchi", "Guillermo", ""]]}, {"id": "1909.03918", "submitter": "Ting Yao", "authors": "Ting Yao and Yingwei Pan and Yehao Li and Tao Mei", "title": "Hierarchy Parsing for Image Captioning", "comments": "ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is always well believed that parsing an image into constituent visual\npatterns would be helpful for understanding and representing an image.\nNevertheless, there has not been evidence in support of the idea on describing\nan image with a natural-language utterance. In this paper, we introduce a new\ndesign to model a hierarchy from instance level (segmentation), region level\n(detection) to the whole image to delve into a thorough image understanding for\ncaptioning. Specifically, we present a HIerarchy Parsing (HIP) architecture\nthat novelly integrates hierarchical structure into image encoder. Technically,\nan image decomposes into a set of regions and some of the regions are resolved\ninto finer ones. Each region then regresses to an instance, i.e., foreground of\nthe region. Such process naturally builds a hierarchal tree. A tree-structured\nLong Short-Term Memory (Tree-LSTM) network is then employed to interpret the\nhierarchal structure and enhance all the instance-level, region-level and\nimage-level features. Our HIP is appealing in view that it is pluggable to any\nneural captioning models. Extensive experiments on COCO image captioning\ndataset demonstrate the superiority of HIP. More remarkably, HIP plus a\ntop-down attention-based LSTM decoder increases CIDEr-D performance from 120.1%\nto 127.2% on COCO Karpathy test split. When further endowing instance-level and\nregion-level features from HIP with semantic relation learnt through Graph\nConvolutional Networks (GCN), CIDEr-D is boosted up to 130.6%.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 15:18:21 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 13:39:52 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Yao", "Ting", ""], ["Pan", "Yingwei", ""], ["Li", "Yehao", ""], ["Mei", "Tao", ""]]}, {"id": "1909.03922", "submitter": "Dongyeop Kang", "authors": "Dongyeop Kang, Anusha Balakrishnan, Pararth Shah, Paul Crook, Y-Lan\n  Boureau, Jason Weston", "title": "Recommendation as a Communication Game: Self-Supervised Bot-Play for\n  Goal-oriented Dialogue", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional recommendation systems produce static rather than interactive\nrecommendations invariant to a user's specific requests, clarifications, or\ncurrent mood, and can suffer from the cold-start problem if their tastes are\nunknown. These issues can be alleviated by treating recommendation as an\ninteractive dialogue task instead, where an expert recommender can sequentially\nask about someone's preferences, react to their requests, and recommend more\nappropriate items. In this work, we collect a goal-driven recommendation\ndialogue dataset (GoRecDial), which consists of 9,125 dialogue games and 81,260\nconversation turns between pairs of human workers recommending movies to each\nother. The task is specifically designed as a cooperative game between two\nplayers working towards a quantifiable common goal. We leverage the dataset to\ndevelop an end-to-end dialogue system that can simultaneously converse and\nrecommend. Models are first trained to imitate the behavior of human players\nwithout considering the task goal itself (supervised training). We then\nfinetune our models on simulated bot-bot conversations between two paired\npre-trained models (bot-play), in order to achieve the dialogue goal. Our\nexperiments show that models finetuned with bot-play learn improved dialogue\nstrategies, reach the dialogue goal more often when paired with a human, and\nare rated as more consistent by humans compared to models trained without\nbot-play. The dataset and code are publicly available through the ParlAI\nframework.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 15:19:56 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Kang", "Dongyeop", ""], ["Balakrishnan", "Anusha", ""], ["Shah", "Pararth", ""], ["Crook", "Paul", ""], ["Boureau", "Y-Lan", ""], ["Weston", "Jason", ""]]}, {"id": "1909.03965", "submitter": "Hanna Silen", "authors": "Rob Clark, Hanna Silen, Tom Kenter, Ralph Leith", "title": "Evaluating Long-form Text-to-Speech: Comparing the Ratings of Sentences\n  and Paragraphs", "comments": "Accepted for The 10th ISCA Speech Synthesis Workshop (SSW10), 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text-to-speech systems are typically evaluated on single sentences. When\nlong-form content, such as data consisting of full paragraphs or dialogues is\nconsidered, evaluating sentences in isolation is not always appropriate as the\ncontext in which the sentences are synthesized is missing. In this paper, we\ninvestigate three different ways of evaluating the naturalness of long-form\ntext-to-speech synthesis. We compare the results obtained from evaluating\nsentences in isolation, evaluating whole paragraphs of speech, and presenting a\nselection of speech or text as context and evaluating the subsequent speech. We\nfind that, even though these three evaluations are based upon the same\nmaterial, the outcomes differ per setting, and moreover that these outcomes do\nnot necessarily correlate with each other. We show that our findings are\nconsistent between a single speaker setting of read paragraphs and a\ntwo-speaker dialogue scenario. We conclude that to evaluate the quality of\nlong-form speech, the traditional way of evaluating sentences in isolation does\nnot suffice, and that multiple evaluations are required.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 16:13:20 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Clark", "Rob", ""], ["Silen", "Hanna", ""], ["Kenter", "Tom", ""], ["Leith", "Ralph", ""]]}, {"id": "1909.04002", "submitter": "Charuta Pethe", "authors": "Charuta Pethe, Steven Skiena", "title": "The Trumpiest Trump? Identifying a Subject's Most Characteristic Tweets", "comments": "11 pages, 4 figures. Accepted at EMNLP-IJCNLP 2019 as a long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sequence of documents produced by any given author varies in style and\ncontent, but some documents are more typical or representative of the source\nthan others. We quantify the extent to which a given short text is\ncharacteristic of a specific person, using a dataset of tweets from fifteen\ncelebrities. Such analysis is useful for generating excerpts of high-volume\nTwitter profiles, and understanding how representativeness relates to tweet\npopularity. We first consider the related task of binary author detection (is x\nthe author of text T?), and report a test accuracy of 90.37% for the best of\nfive approaches to this problem. We then use these models to compute\ncharacterization scores among all of an author's texts. A user study shows\nhuman evaluators agree with our characterization model for all 15 celebrities\nin our dataset, each with p-value < 0.05. We use these classifiers to show\nsurprisingly strong correlations between characterization scores and the\npopularity of the associated texts. Indeed, we demonstrate a statistically\nsignificant correlation between this score and tweet popularity\n(likes/replies/retweets) for 13 of the 15 celebrities in our study.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 17:28:40 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Pethe", "Charuta", ""], ["Skiena", "Steven", ""]]}, {"id": "1909.04028", "submitter": "Matr Grenander", "authors": "Matt Grenander, Yue Dong, Jackie Chi Kit Cheung, Annie Louis", "title": "Countering the Effects of Lead Bias in News Summarization via\n  Multi-Stage Training and Auxiliary Losses", "comments": "5 pages, accepted at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence position is a strong feature for news summarization, since the lead\noften (but not always) summarizes the key points of the article. In this paper,\nwe show that recent neural systems excessively exploit this trend, which\nalthough powerful for many inputs, is also detrimental when summarizing\ndocuments where important content should be extracted from later parts of the\narticle. We propose two techniques to make systems sensitive to the importance\nof content in different parts of the article. The first technique employs\n'unbiased' data; i.e., randomly shuffled sentences of the source document, to\npretrain the model. The second technique uses an auxiliary ROUGE-based loss\nthat encourages the model to distribute importance scores throughout a document\nby mimicking sentence-level ROUGE scores on the training data. We show that\nthese techniques significantly improve the performance of a competitive\nreinforcement learning based extractive system, with the auxiliary loss being\nmore powerful than pretraining.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 05:50:18 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Grenander", "Matt", ""], ["Dong", "Yue", ""], ["Cheung", "Jackie Chi Kit", ""], ["Louis", "Annie", ""]]}, {"id": "1909.04054", "submitter": "Arman Cohan", "authors": "Arman Cohan, Iz Beltagy, Daniel King, Bhavana Dalvi, Daniel S. Weld", "title": "Pretrained Language Models for Sequential Sentence Classification", "comments": "EMNLP 2019", "journal-ref": "Proceedings of the 2019 Conference on Empirical Methods in Natural\n  Language Processing and the 9th International Joint Conference on Natural\n  Language Processing (EMNLP-IJCNLP) (2019) 3693-3699", "doi": "10.18653/v1/D19-1383", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a step toward better document-level understanding, we explore\nclassification of a sequence of sentences into their corresponding categories,\na task that requires understanding sentences in context of the document. Recent\nsuccessful models for this task have used hierarchical models to contextualize\nsentence representations, and Conditional Random Fields (CRFs) to incorporate\ndependencies between subsequent labels. In this work, we show that pretrained\nlanguage models, BERT (Devlin et al., 2018) in particular, can be used for this\ntask to capture contextual dependencies without the need for hierarchical\nencoding nor a CRF. Specifically, we construct a joint sentence representation\nthat allows BERT Transformer layers to directly utilize contextual information\nfrom all words in all sentences. Our approach achieves state-of-the-art results\non four datasets, including a new dataset of structured scientific abstracts.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 18:00:05 GMT"}, {"version": "v2", "created": "Sun, 22 Sep 2019 22:36:23 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Cohan", "Arman", ""], ["Beltagy", "Iz", ""], ["King", "Daniel", ""], ["Dalvi", "Bhavana", ""], ["Weld", "Daniel S.", ""]]}, {"id": "1909.04076", "submitter": "Lianhui Qin", "authors": "Lianhui Qin, Antoine Bosselut, Ari Holtzman, Chandra Bhagavatula,\n  Elizabeth Clark and Yejin Choi", "title": "Counterfactual Story Reasoning and Generation", "comments": "Accepted to EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual reasoning requires predicting how alternative events, contrary\nto what actually happened, might have resulted in different outcomes. Despite\nbeing considered a necessary component of AI-complete systems, few resources\nhave been developed for evaluating counterfactual reasoning in narratives.\n  In this paper, we propose Counterfactual Story Rewriting: given an original\nstory and an intervening counterfactual event, the task is to minimally revise\nthe story to make it compatible with the given counterfactual event. Solving\nthis task will require deep understanding of causal narrative chains and\ncounterfactual invariance, and integration of such story reasoning capabilities\ninto conditional language generation models.\n  We present TimeTravel, a new dataset of 29,849 counterfactual rewritings,\neach with the original story, a counterfactual event, and human-generated\nrevision of the original story compatible with the counterfactual event.\nAdditionally, we include 80,115 counterfactual \"branches\" without a rewritten\nstoryline to support future work on semi- or un-supervised approaches to\ncounterfactual story rewriting.\n  Finally, we evaluate the counterfactual rewriting capacities of several\ncompetitive baselines based on pretrained language models, and assess whether\ncommon overlap and model-based automatic metrics for text generation correlate\nwell with human scores for counterfactual rewriting.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 18:08:35 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 06:19:50 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Qin", "Lianhui", ""], ["Bosselut", "Antoine", ""], ["Holtzman", "Ari", ""], ["Bhagavatula", "Chandra", ""], ["Clark", "Elizabeth", ""], ["Choi", "Yejin", ""]]}, {"id": "1909.04101", "submitter": "Maxwell Forbes", "authors": "Maxwell Forbes, Christine Kaeser-Chen, Piyush Sharma, Serge Belongie", "title": "Neural Naturalist: Generating Fine-Grained Image Comparisons", "comments": "Published at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the new Birds-to-Words dataset of 41k sentences describing\nfine-grained differences between photographs of birds. The language collected\nis highly detailed, while remaining understandable to the everyday observer\n(e.g., \"heart-shaped face,\" \"squat body\"). Paragraph-length descriptions\nnaturally adapt to varying levels of taxonomic and visual distance---drawn from\na novel stratified sampling approach---with the appropriate level of detail. We\npropose a new model called Neural Naturalist that uses a joint image encoding\nand comparative module to generate comparative language, and evaluate the\nresults with humans who must use the descriptions to distinguish real images.\n  Our results indicate promising potential for neural models to explain\ndifferences in visual embedding space using natural language, as well as a\nconcrete path for machine learning to aid citizen scientists in their effort to\npreserve biodiversity.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 18:54:40 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2019 23:03:30 GMT"}, {"version": "v3", "created": "Thu, 14 Nov 2019 01:19:36 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Forbes", "Maxwell", ""], ["Kaeser-Chen", "Christine", ""], ["Sharma", "Piyush", ""], ["Belongie", "Serge", ""]]}, {"id": "1909.04120", "submitter": "Michael Glass", "authors": "Michael Glass, Alfio Gliozzo, Rishav Chakravarti, Anthony Ferritto,\n  Lin Pan, G P Shrivatsa Bhargav, Dinesh Garg, Avirup Sil", "title": "Span Selection Pre-training for Question Answering", "comments": "Accepted at ACL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BERT (Bidirectional Encoder Representations from Transformers) and related\npre-trained Transformers have provided large gains across many language\nunderstanding tasks, achieving a new state-of-the-art (SOTA). BERT is\npre-trained on two auxiliary tasks: Masked Language Model and Next Sentence\nPrediction. In this paper we introduce a new pre-training task inspired by\nreading comprehension to better align the pre-training from memorization to\nunderstanding. Span Selection Pre-Training (SSPT) poses cloze-like training\ninstances, but rather than draw the answer from the model's parameters, it is\nselected from a relevant passage. We find significant and consistent\nimprovements over both BERT-BASE and BERT-LARGE on multiple reading\ncomprehension (MRC) datasets. Specifically, our proposed model has strong\nempirical evidence as it obtains SOTA results on Natural Questions, a new\nbenchmark MRC dataset, outperforming BERT-LARGE by 3 F1 points on short answer\nprediction. We also show significant impact in HotpotQA, improving answer\nprediction F1 by 4 points and supporting fact prediction F1 by 1 point and\noutperforming the previous best system. Moreover, we show that our pre-training\napproach is particularly effective when training data is limited, improving the\nlearning curve by a large amount.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 19:32:31 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 18:18:04 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Glass", "Michael", ""], ["Gliozzo", "Alfio", ""], ["Chakravarti", "Rishav", ""], ["Ferritto", "Anthony", ""], ["Pan", "Lin", ""], ["Bhargav", "G P Shrivatsa", ""], ["Garg", "Dinesh", ""], ["Sil", "Avirup", ""]]}, {"id": "1909.04130", "submitter": "Lyan Verwimp", "authors": "Lyan Verwimp and Jerome R. Bellegarda", "title": "Reverse Transfer Learning: Can Word Embeddings Trained for Different NLP\n  Tasks Improve Neural Language Models?", "comments": "Accepted for publication at Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language processing (NLP) tasks tend to suffer from a paucity of\nsuitably annotated training data, hence the recent success of transfer learning\nacross a wide variety of them. The typical recipe involves: (i) training a\ndeep, possibly bidirectional, neural network with an objective related to\nlanguage modeling, for which training data is plentiful; and (ii) using the\ntrained network to derive contextual representations that are far richer than\nstandard linear word embeddings such as word2vec, and thus result in important\ngains. In this work, we wonder whether the opposite perspective is also true:\ncan contextual representations trained for different NLP tasks improve language\nmodeling itself? Since language models (LMs) are predominantly locally\noptimized, other NLP tasks may help them make better predictions based on the\nentire semantic fabric of a document. We test the performance of several types\nof pre-trained embeddings in neural LMs, and we investigate whether it is\npossible to make the LM more aware of global semantic information through\nembeddings pre-trained with a domain classification model. Initial experiments\nsuggest that as long as the proper objective criterion is used during training,\npre-trained embeddings are likely to be beneficial for neural language\nmodeling.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 20:01:51 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Verwimp", "Lyan", ""], ["Bellegarda", "Jerome R.", ""]]}, {"id": "1909.04157", "submitter": "Liang Lu", "authors": "Liang Lu, Eric Sun and Yifan Gong", "title": "Self-Teaching Networks", "comments": "5 pages, Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose self-teaching networks to improve the generalization capacity of\ndeep neural networks. The idea is to generate soft supervision labels using the\noutput layer for training the lower layers of the network. During the network\ntraining, we seek an auxiliary loss that drives the lower layer to mimic the\nbehavior of the output layer. The connection between the two network layers\nthrough the auxiliary loss can help the gradient flow, which works similar to\nthe residual networks. Furthermore, the auxiliary loss also works as a\nregularizer, which improves the generalization capacity of the network. We\nevaluated the self-teaching network with deep recurrent neural networks on\nspeech recognition tasks, where we trained the acoustic model using 30 thousand\nhours of data. We tested the acoustic model using data collected from 4\nscenarios. We show that the self-teaching network can achieve consistent\nimprovements and outperform existing methods such as label smoothing and\nconfidence penalization.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 21:11:35 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Lu", "Liang", ""], ["Sun", "Eric", ""], ["Gong", "Yifan", ""]]}, {"id": "1909.04164", "submitter": "Matthew Peters", "authors": "Matthew E. Peters, Mark Neumann, Robert L. Logan IV, Roy Schwartz,\n  Vidur Joshi, Sameer Singh, Noah A. Smith", "title": "Knowledge Enhanced Contextual Word Representations", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual word representations, typically trained on unstructured, unlabeled\ntext, do not contain any explicit grounding to real world entities and are\noften unable to remember facts about those entities. We propose a general\nmethod to embed multiple knowledge bases (KBs) into large scale models, and\nthereby enhance their representations with structured, human-curated knowledge.\nFor each KB, we first use an integrated entity linker to retrieve relevant\nentity embeddings, then update contextual word representations via a form of\nword-to-entity attention. In contrast to previous approaches, the entity\nlinkers and self-supervised language modeling objective are jointly trained\nend-to-end in a multitask setting that combines a small amount of entity\nlinking supervision with a large amount of raw text. After integrating WordNet\nand a subset of Wikipedia into BERT, the knowledge enhanced BERT (KnowBert)\ndemonstrates improved perplexity, ability to recall facts as measured in a\nprobing task and downstream performance on relationship extraction, entity\ntyping, and word sense disambiguation. KnowBert's runtime is comparable to\nBERT's and it scales to large KBs.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 21:18:50 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 00:14:48 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Peters", "Matthew E.", ""], ["Neumann", "Mark", ""], ["Logan", "Robert L.", "IV"], ["Schwartz", "Roy", ""], ["Joshi", "Vidur", ""], ["Singh", "Sameer", ""], ["Smith", "Noah A.", ""]]}, {"id": "1909.04165", "submitter": "Bailin Wang", "authors": "Bailin Wang, Ivan Titov and Mirella Lapata", "title": "Learning Semantic Parsers from Denotations with Latent Structured\n  Alignments and Abstract Programs", "comments": "EMNLP2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Semantic parsing aims to map natural language utterances onto machine\ninterpretable meaning representations, aka programs whose execution against a\nreal-world environment produces a denotation. Weakly-supervised semantic\nparsers are trained on utterance-denotation pairs treating programs as latent.\nThe task is challenging due to the large search space and spuriousness of\nprograms which may execute to the correct answer but do not generalize to\nunseen examples. Our goal is to instill an inductive bias in the parser to help\nit distinguish between spurious and correct programs. We capitalize on the\nintuition that correct programs would likely respect certain structural\nconstraints were they to be aligned to the question (e.g., program fragments\nare unlikely to align to overlapping text spans) and propose to model\nalignments as structured latent variables. In order to make the\nlatent-alignment framework tractable, we decompose the parsing task into (1)\npredicting a partial \"abstract program\" and (2) refining it while modeling\nstructured alignments with differential dynamic programming. We obtain\nstate-of-the-art performance on the WIKITABLEQUESTIONS and WIKISQL datasets.\nWhen compared to a standard attention baseline, we observe that the proposed\nstructured-alignment mechanism is highly beneficial.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 21:20:36 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Wang", "Bailin", ""], ["Titov", "Ivan", ""], ["Lapata", "Mirella", ""]]}, {"id": "1909.04176", "submitter": "Jiawei Wu", "authors": "Jiawei Wu, Wenhan Xiong, William Yang Wang", "title": "Learning to Learn and Predict: A Meta-Learning Approach for Multi-Label\n  Classification", "comments": "11pages, 5 figures, accepted to EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many tasks in natural language processing can be viewed as multi-label\nclassification problems. However, most of the existing models are trained with\nthe standard cross-entropy loss function and use a fixed prediction policy\n(e.g., a threshold of 0.5) for all the labels, which completely ignores the\ncomplexity and dependencies among different labels. In this paper, we propose a\nmeta-learning method to capture these complex label dependencies. More\nspecifically, our method utilizes a meta-learner to jointly learn the training\npolicies and prediction policies for different labels. The training policies\nare then used to train the classifier with the cross-entropy loss function, and\nthe prediction policies are further implemented for prediction. Experimental\nresults on fine-grained entity typing and text classification demonstrate that\nour proposed method can obtain more accurate multi-label classification\nresults.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 22:00:39 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Wu", "Jiawei", ""], ["Xiong", "Wenhan", ""], ["Wang", "William Yang", ""]]}, {"id": "1909.04181", "submitter": "Chiyu Zhang", "authors": "Chiyu Zhang and Muhammad Abdul-Mageed", "title": "BERT-Based Arabic Social Media Author Profiling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We report our models for detecting age, language variety, and gender from\nsocial media data in the context of the Arabic author profiling and deception\ndetection shared task (APDA). We build simple models based on pre-trained\nbidirectional encoders from transformers (BERT). We first fine-tune the\npre-trained BERT model on each of the three datasets with shared task released\ndata. Then we augment shared task data with in-house data for gender and\ndialect, showing the utility of augmenting training data. Our best models on\nthe shared task test data are acquired with a majority voting of various BERT\nmodels trained under different data conditions. We acquire 54.72% accuracy for\nage, 93.75% for dialect, 81.67% for gender, and 40.97% joint accuracy across\nthe three tasks.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 22:08:12 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 04:33:59 GMT"}, {"version": "v3", "created": "Thu, 31 Oct 2019 06:54:50 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Zhang", "Chiyu", ""], ["Abdul-Mageed", "Muhammad", ""]]}, {"id": "1909.04189", "submitter": "Sandeep Soni", "authors": "Sandeep Soni, Kristina Lerman, Jacob Eisenstein", "title": "Follow the Leader: Documents on the Leading Edge of Semantic Change Get\n  More Citations", "comments": "25 pages, 3 figures, To appear in the Journal of the Association of\n  Information Sciences and Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diachronic word embeddings -- vector representations of words over time --\noffer remarkable insights into the evolution of language and provide a tool for\nquantifying sociocultural change from text documents. Prior work has used such\nembeddings to identify shifts in the meaning of individual words. However,\nsimply knowing that a word has changed in meaning is insufficient to identify\nthe instances of word usage that convey the historical or the newer meaning. In\nthis paper, we link diachronic word embeddings to documents, by situating those\ndocuments as leaders or laggards with respect to ongoing semantic changes.\nSpecifically, we propose a novel method to quantify the degree of semantic\nprogressiveness in each word usage, and then show how these usages can be\naggregated to obtain scores for each document. We analyze two large collections\nof documents, representing legal opinions and scientific articles. Documents\nthat are scored as semantically progressive receive a larger number of\ncitations, indicating that they are especially influential. Our work thus\nprovides a new technique for identifying lexical semantic leaders and\ndemonstrates a new link between progressive use of language and influence in a\ncitation network.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 22:43:02 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 19:41:11 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Soni", "Sandeep", ""], ["Lerman", "Kristina", ""], ["Eisenstein", "Jacob", ""]]}, {"id": "1909.04225", "submitter": "Hanjie Chen", "authors": "Hanjie Chen, Yangfeng Ji", "title": "Improving the Explainability of Neural Sentiment Classifiers via Data\n  Augmentation", "comments": "11 pages, NeurIPS 2019 Workshop on Robust AI in Financial Services", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment analysis has been widely used by businesses for social media\nopinion mining, especially in the financial services industry, where customers'\nfeedbacks are critical for companies. Recent progress of neural network models\nhas achieved remarkable performance on sentiment classification, while the lack\nof classification interpretation may raise the trustworthy and many other\nissues in practice. In this work, we study the problem of improving the\nexplainability of existing sentiment classifiers. We propose two data\naugmentation methods that create additional training examples to help improve\nmodel explainability: one method with a predefined sentiment word list as\nexternal knowledge and the other with adversarial examples. We test the\nproposed methods on both CNN and RNN classifiers with three benchmark sentiment\ndatasets. The model explainability is assessed by both human evaluators and a\nsimple automatic evaluation measurement. Experiments show the proposed data\naugmentation methods significantly improve the explainability of both neural\nclassifiers.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 01:30:23 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 02:30:50 GMT"}, {"version": "v3", "created": "Sat, 30 Nov 2019 20:44:15 GMT"}, {"version": "v4", "created": "Mon, 25 May 2020 01:27:27 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Chen", "Hanjie", ""], ["Ji", "Yangfeng", ""]]}, {"id": "1909.04242", "submitter": "Guanhua Zhang", "authors": "Guanhua Zhang, Bing Bai, Junqi Zhang, Kun Bai, Conghui Zhu, Tiejun\n  Zhao", "title": "Mitigating Annotation Artifacts in Natural Language Inference Datasets\n  to Improve Cross-dataset Generalization Ability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language inference (NLI) aims at predicting the relationship between\na given pair of premise and hypothesis. However, several works have found that\nthere widely exists a bias pattern called annotation artifacts in NLI datasets,\nmaking it possible to identify the label only by looking at the hypothesis.\nThis irregularity makes the evaluation results over-estimated and affects\nmodels' generalization ability. In this paper, we consider a more trust-worthy\nsetting, i.e., cross-dataset evaluation. We explore the impacts of annotation\nartifacts in cross-dataset testing. Furthermore, we propose a training\nframework to mitigate the impacts of the bias pattern. Experimental results\ndemonstrate that our methods can alleviate the negative effect of the artifacts\nand improve the generalization ability of models.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 02:35:34 GMT"}, {"version": "v2", "created": "Sat, 5 Oct 2019 14:40:31 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Zhang", "Guanhua", ""], ["Bai", "Bing", ""], ["Zhang", "Junqi", ""], ["Bai", "Kun", ""], ["Zhu", "Conghui", ""], ["Zhao", "Tiejun", ""]]}, {"id": "1909.04251", "submitter": "Jing Qian", "authors": "Jing Qian, Anna Bethke, Yinyin Liu, Elizabeth Belding, William Yang\n  Wang", "title": "A Benchmark Dataset for Learning to Intervene in Online Hate Speech", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Countering online hate speech is a critical yet challenging task, but one\nwhich can be aided by the use of Natural Language Processing (NLP) techniques.\nPrevious research has primarily focused on the development of NLP methods to\nautomatically and effectively detect online hate speech while disregarding\nfurther action needed to calm and discourage individuals from using hate speech\nin the future. In addition, most existing hate speech datasets treat each post\nas an isolated instance, ignoring the conversational context. In this paper, we\npropose a novel task of generative hate speech intervention, where the goal is\nto automatically generate responses to intervene during online conversations\nthat contain hate speech. As a part of this work, we introduce two\nfully-labeled large-scale hate speech intervention datasets collected from Gab\nand Reddit. These datasets provide conversation segments, hate speech labels,\nas well as intervention responses written by Mechanical Turk Workers. In this\npaper, we also analyze the datasets to understand the common intervention\nstrategies and explore the performance of common automatic response generation\nmethods on these new datasets to provide a benchmark for future research.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 03:00:58 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Qian", "Jing", ""], ["Bethke", "Anna", ""], ["Liu", "Yinyin", ""], ["Belding", "Elizabeth", ""], ["Wang", "William Yang", ""]]}, {"id": "1909.04273", "submitter": "Bowen Yu", "authors": "Bowen Yu, Zhenyu Zhang, Xiaobo Shu, Yubin Wang, Tingwen Liu, Bin Wang,\n  Sujian Li", "title": "Joint Extraction of Entities and Relations Based on a Novel\n  Decomposition Strategy", "comments": "Accepted by ECAI 2020. Code and data are available at\n  https://github.com/yubowen-ph/JointER", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Joint extraction of entities and relations aims to detect entity pairs along\nwith their relations using a single model. Prior work typically solves this\ntask in the extract-then-classify or unified labeling manner. However, these\nmethods either suffer from the redundant entity pairs, or ignore the important\ninner structure in the process of extracting entities and relations. To address\nthese limitations, in this paper, we first decompose the joint extraction task\ninto two interrelated subtasks, namely HE extraction and TER extraction. The\nformer subtask is to distinguish all head-entities that may be involved with\ntarget relations, and the latter is to identify corresponding tail-entities and\nrelations for each extracted head-entity. Next, these two subtasks are further\ndeconstructed into several sequence labeling problems based on our proposed\nspan-based tagging scheme, which are conveniently solved by a hierarchical\nboundary tagger and a multi-span decoding algorithm. Owing to the reasonable\ndecomposition strategy, our model can fully capture the semantic\ninterdependency between different steps, as well as reduce noise from\nirrelevant entity pairs. Experimental results show that our method outperforms\nprevious work by 5.2%, 5.9% and 21.5% (F1 score), achieving a new\nstate-of-the-art on three public datasets\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 04:08:10 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 02:03:02 GMT"}, {"version": "v3", "created": "Wed, 19 Feb 2020 03:42:32 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Yu", "Bowen", ""], ["Zhang", "Zhenyu", ""], ["Shu", "Xiaobo", ""], ["Wang", "Yubin", ""], ["Liu", "Tingwen", ""], ["Wang", "Bin", ""], ["Li", "Sujian", ""]]}, {"id": "1909.04302", "submitter": "Shao-Yen Tseng", "authors": "Shao-Yen Tseng, Panayiotis Georgiou, Shrikanth Narayanan", "title": "Multimodal Embeddings from Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Word embeddings such as ELMo have recently been shown to model word semantics\nwith greater efficacy through contextualized learning on large-scale language\ncorpora, resulting in significant improvement in state of the art across many\nnatural language tasks. In this work we integrate acoustic information into\ncontextualized lexical embeddings through the addition of multimodal inputs to\na pretrained bidirectional language model. The language model is trained on\nspoken language that includes text and audio modalities. The resulting\nrepresentations from this model are multimodal and contain paralinguistic\ninformation which can modify word meanings and provide affective information.\nWe show that these multimodal embeddings can be used to improve over previous\nstate of the art multimodal models in emotion recognition on the CMU-MOSEI\ndataset.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 05:46:39 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Tseng", "Shao-Yen", ""], ["Georgiou", "Panayiotis", ""], ["Narayanan", "Shrikanth", ""]]}, {"id": "1909.04303", "submitter": "Deng Cai", "authors": "Deng Cai and Wai Lam", "title": "Core Semantic First: A Top-down Approach for AMR Parsing", "comments": "EMNLP2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel scheme for parsing a piece of text into its Abstract\nMeaning Representation (AMR): Graph Spanning based Parsing (GSP). One novel\ncharacteristic of GSP is that it constructs a parse graph incrementally in a\ntop-down fashion. Starting from the root, at each step, a new node and its\nconnections to existing nodes will be jointly predicted. The output graph spans\nthe nodes by the distance to the root, following the intuition of first\ngrasping the main ideas then digging into more details. The \\textit{core\nsemantic first} principle emphasizes capturing the main ideas of a sentence,\nwhich is of great interest. We evaluate our model on the latest AMR sembank and\nachieve the state-of-the-art performance in the sense that no heuristic graph\nre-categorization is adopted. More importantly, the experiments show that our\nparser is especially good at obtaining the core semantics.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 05:51:12 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 07:02:03 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Cai", "Deng", ""], ["Lam", "Wai", ""]]}, {"id": "1909.04315", "submitter": "Huiyun Yang", "authors": "Huiyun Yang, Shujian Huang, Xinyu Dai, Jiajun Chen", "title": "Fine-grained Knowledge Fusion for Sequence Labeling Domain Adaptation", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In sequence labeling, previous domain adaptation methods focus on the\nadaptation from the source domain to the entire target domain without\nconsidering the diversity of individual target domain samples, which may lead\nto negative transfer results for certain samples. Besides, an important\ncharacteristic of sequence labeling tasks is that different elements within a\ngiven sample may also have diverse domain relevance, which requires further\nconsideration. To take the multi-level domain relevance discrepancy into\naccount, in this paper, we propose a fine-grained knowledge fusion model with\nthe domain relevance modeling scheme to control the balance between learning\nfrom the target domain data and learning from the source domain model.\nExperiments on three sequence labeling tasks show that our fine-grained\nknowledge fusion model outperforms strong baselines and other state-of-the-art\nsequence labeling domain adaptation methods.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 06:31:09 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Yang", "Huiyun", ""], ["Huang", "Shujian", ""], ["Dai", "Xinyu", ""], ["Chen", "Jiajun", ""]]}, {"id": "1909.04367", "submitter": "Binny Mathew", "authors": "Binny Mathew, Suman Kalyan Maity, Pawan Goyal, and Animesh Mukherjee", "title": "Competing Topic Naming Conventions in Quora: Predicting Appropriate\n  Topic Merges and Winning Topics from Millions of Topic Pairs", "comments": "15 pages, 8 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quora is a popular Q&A site which provides users with the ability to tag\nquestions with multiple relevant topics which helps to attract quality answers.\nThese topics are not predefined but user-defined conventions and it is not so\nrare to have multiple such conventions present in the Quora ecosystem\ndescribing exactly the same concept. In almost all such cases, users (or Quora\nmoderators) manually merge the topic pair into one of the either topics, thus\nselecting one of the competing conventions. An important application for the\nsite therefore is to identify such competing conventions early enough that\nshould merge in future. In this paper, we propose a two-step approach that\nuniquely combines the anomaly detection and the supervised classification\nframeworks to predict whether two topics from among millions of topic pairs are\nindeed competing conventions, and should merge, achieving an F-score of 0.711.\nWe also develop a model to predict the direction of the topic merge, i.e., the\nwinning convention, achieving an F-score of 0.898. Our system is also able to\npredict ~ 25% of the correct case of merges within the first month of the merge\nand ~ 40% of the cases within a year. This is an encouraging result since Quora\nusers on average take 936 days to identify such a correct merge. Human judgment\nexperiments show that our system is able to predict almost all the correct\ncases that humans can predict plus 37.24% correct cases which the humans are\nnot able to identify at all.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 09:35:23 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Mathew", "Binny", ""], ["Maity", "Suman Kalyan", ""], ["Goyal", "Pawan", ""], ["Mukherjee", "Animesh", ""]]}, {"id": "1909.04386", "submitter": "Xavier Ferrer Aran", "authors": "Xavier Ferrer Aran, Jose M. Such, Natalia Criado", "title": "Attesting Biases and Discrimination using Language Semantics", "comments": "Author's copy of the manuscript accepted in the Responsible\n  Artificial Intelligence Agents workshop of the International Conference on\n  Autonomous Agents and Multiagent Systems (AAMAS'19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI agents are increasingly deployed and used to make automated decisions that\naffect our lives on a daily basis. It is imperative to ensure that these\nsystems embed ethical principles and respect human values. We focus on how we\ncan attest to whether AI agents treat users fairly without discriminating\nagainst particular individuals or groups through biases in language. In\nparticular, we discuss human unconscious biases, how they are embedded in\nlanguage, and how AI systems inherit those biases by learning from and\nprocessing human language. Then, we outline a roadmap for future research to\nbetter understand and attest problematic AI biases derived from language.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 10:12:01 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Aran", "Xavier Ferrer", ""], ["Such", "Jose M.", ""], ["Criado", "Natalia", ""]]}, {"id": "1909.04387", "submitter": "Amanda Cercas Curry", "authors": "Amanda Cercas Curry, Verena Rieser", "title": "A Crowd-based Evaluation of Abuse Response Strategies in Conversational\n  Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How should conversational agents respond to verbal abuse through the user? To\nanswer this question, we conduct a large-scale crowd-sourced evaluation of\nabuse response strategies employed by current state-of-the-art systems. Our\nresults show that some strategies, such as \"polite refusal\" score highly across\nthe board, while for other strategies demographic factors, such as age, as well\nas the severity of the preceding abuse influence the user's perception of which\nresponse is appropriate. In addition, we find that most data-driven models lag\nbehind rule-based or commercial systems in terms of their perceived\nappropriateness.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 10:12:59 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Curry", "Amanda Cercas", ""], ["Rieser", "Verena", ""]]}, {"id": "1909.04393", "submitter": "Paul Diac", "authors": "Paul Diac, Liana Tucar, Radu Mereuta", "title": "Extending the Service Composition Formalism with Relational Parameters", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Web Service Composition deals with the (re)use of Web Services to provide\ncomplex functionality, inexistent in any single service. Over the\nstate-of-the-art, we introduce a new type of modeling, based on ontologies and\nrelations between objects, which allows us to extend the expressiveness of\nproblems that can be solved automatically.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 10:32:49 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Diac", "Paul", ""], ["Tucar", "Liana", ""], ["Mereuta", "Radu", ""]]}, {"id": "1909.04402", "submitter": "Mitja Nikolaus", "authors": "Mitja Nikolaus, Mostafa Abdou, Matthew Lamm, Rahul Aralikatte and\n  Desmond Elliott", "title": "Compositional Generalization in Image Captioning", "comments": "To appear at CoNLL 2019, EMNLP", "journal-ref": "Proceedings of the 23rd Conference on Computational Natural\n  Language Learning (CoNLL), pp. 87--98, ACL, 2019", "doi": "10.18653/v1/K19-1009", "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image captioning models are usually evaluated on their ability to describe a\nheld-out set of images, not on their ability to generalize to unseen concepts.\nWe study the problem of compositional generalization, which measures how well a\nmodel composes unseen combinations of concepts when describing images.\nState-of-the-art image captioning models show poor generalization performance\non this task. We propose a multi-task model to address the poor performance,\nthat combines caption generation and image--sentence ranking, and uses a\ndecoding mechanism that re-ranks the captions according their similarity to the\nimage. This model is substantially better at generalizing to unseen\ncombinations of concepts compared to state-of-the-art captioning models.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 10:55:56 GMT"}, {"version": "v2", "created": "Mon, 16 Sep 2019 15:53:45 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Nikolaus", "Mitja", ""], ["Abdou", "Mostafa", ""], ["Lamm", "Matthew", ""], ["Aralikatte", "Rahul", ""], ["Elliott", "Desmond", ""]]}, {"id": "1909.04448", "submitter": "Yutai Hou", "authors": "Yutai Hou, Meng Fang, Wanxiang Che, Ting Liu", "title": "A Corpus-free State2Seq User Simulator for Task-oriented Dialogue", "comments": "Accepted by CCL2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent reinforcement learning algorithms for task-oriented dialogue system\nabsorbs a lot of interest. However, an unavoidable obstacle for training such\nalgorithms is that annotated dialogue corpora are often unavailable. One of the\npopular approaches addressing this is to train a dialogue agent with a user\nsimulator. Traditional user simulators are built upon a set of dialogue rules\nand therefore lack response diversity. This severely limits the simulated cases\nfor agent training. Later data-driven user models work better in diversity but\nsuffer from data scarcity problem. To remedy this, we design a new corpus-free\nframework that taking advantage of their benefits. The framework builds a user\nsimulator by first generating diverse dialogue data from templates and then\nbuild a new State2Seq user simulator on the data. To enhance the performance,\nwe propose the State2Seq user simulator model to efficiently leverage dialogue\nstate and history. Experiment results on an open dataset show that our user\nsimulator helps agents achieve an improvement of 6.36% on success rate.\nState2Seq model outperforms the seq2seq baseline for 1.9 F-score.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 12:50:06 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Hou", "Yutai", ""], ["Fang", "Meng", ""], ["Che", "Wanxiang", ""], ["Liu", "Ting", ""]]}, {"id": "1909.04453", "submitter": "Xiaoyu Shen", "authors": "Xiaoyu Shen, Jun Suzuki, Kentaro Inui, Hui Su, Dietrich Klakow and\n  Satoshi Sekine", "title": "Select and Attend: Towards Controllable Content Selection in Text\n  Generation", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many text generation tasks naturally contain two steps: content selection and\nsurface realization. Current neural encoder-decoder models conflate both steps\ninto a black-box architecture. As a result, the content to be described in the\ntext cannot be explicitly controlled. This paper tackles this problem by\ndecoupling content selection from the decoder. The decoupled content selection\nis human interpretable, whose value can be manually manipulated to control the\ncontent of generated text. The model can be trained end-to-end without human\nannotations by maximizing a lower bound of the marginal likelihood. We further\npropose an effective way to trade-off between performance and controllability\nwith a single adjustable hyperparameter. In both data-to-text and headline\ngeneration tasks, our model achieves promising results, paving the way for\ncontrollable content selection in text generation.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 12:59:10 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Shen", "Xiaoyu", ""], ["Suzuki", "Jun", ""], ["Inui", "Kentaro", ""], ["Su", "Hui", ""], ["Klakow", "Dietrich", ""], ["Sekine", "Satoshi", ""]]}, {"id": "1909.04455", "submitter": "Chun Yuan Yuan", "authors": "Chunyuan Yuan, Wei Zhou, Qianwen Ma, Shangwen Lv, Jizhong Han, Songlin\n  Hu", "title": "Learning review representations from user and product level information\n  for spam detection", "comments": "6 pages. Accepted as IEEE ICDM 2019, Short Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Opinion spam has become a widespread problem in social media, where hired\nspammers write deceptive reviews to promote or demote products to mislead the\nconsumers for profit or fame. Existing works mainly focus on manually designing\ndiscrete textual or behavior features, which cannot capture complex semantics\nof reviews. Although recent works apply deep learning methods to learn\nreview-level semantic features, their models ignore the impact of the\nuser-level and product-level information on learning review semantics and the\ninherent user-review-product relationship information. In this paper, we\npropose a Hierarchical Fusion Attention Network (HFAN) to automatically learn\nthe semantics of reviews from the user and product level. Specifically, we\ndesign a multi-attention unit to extract user(product)-related review\ninformation. Then, we use orthogonal decomposition and fusion attention to\nlearn a user, review, and product representation from the review information.\nFinally, we take the review as a relation between user and product entity and\napply TransH to jointly encode this relationship into review representation.\nExperimental results obtained more than 10\\% absolute precision improvement\nover the state-of-the-art performances on four real-world datasets, which show\nthe effectiveness and versatility of the model.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 13:01:27 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Yuan", "Chunyuan", ""], ["Zhou", "Wei", ""], ["Ma", "Qianwen", ""], ["Lv", "Shangwen", ""], ["Han", "Jizhong", ""], ["Hu", "Songlin", ""]]}, {"id": "1909.04465", "submitter": "Chun Yuan Yuan", "authors": "Chunyuan Yuan, Qianwen Ma, Wei Zhou, Jizhong Han, Songlin Hu", "title": "Jointly embedding the local and global relations of heterogeneous graph\n  for rumor detection", "comments": "10 pages, Accepted to the IEEE International Conference on Data\n  Mining 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of social media has revolutionized the way people\ncommunicate, share information and make decisions, but it also provides an\nideal platform for publishing and spreading rumors. Existing rumor detection\nmethods focus on finding clues from text content, user profiles, and\npropagation patterns. However, the local semantic relation and global\nstructural information in the message propagation graph have not been well\nutilized by previous works.\n  In this paper, we present a novel global-local attention network (GLAN) for\nrumor detection, which jointly encodes the local semantic and global structural\ninformation. We first generate a better integrated representation for each\nsource tweet by fusing the semantic information of related retweets with the\nattention mechanism. Then, we model the global relationships among all source\ntweets, retweets, and users as a heterogeneous graph to capture the rich\nstructural information for rumor detection. We conduct experiments on three\nreal-world datasets, and the results demonstrate that GLAN significantly\noutperforms the state-of-the-art models in both rumor detection and early\ndetection scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 13:18:59 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 12:42:08 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Yuan", "Chunyuan", ""], ["Ma", "Qianwen", ""], ["Zhou", "Wei", ""], ["Han", "Jizhong", ""], ["Hu", "Songlin", ""]]}, {"id": "1909.04493", "submitter": "Ningyu Zhang", "authors": "Qianghuai Jia, Ningyu Zhang, Nengwei Hua", "title": "Context-aware Deep Model for Entity Recommendation in Search Engine at\n  Alibaba", "comments": "CIKM2019 International Workshop on Entity Retrieval. arXiv admin\n  note: text overlap with arXiv:1511.08996 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity recommendation, providing search users with an improved experience via\nassisting them in finding related entities for a given query, has become an\nindispensable feature of today's search engines. Existing studies typically\nonly consider the queries with explicit entities. They usually fail to handle\ncomplex queries that without entities, such as \"what food is good for cold\nweather\", because their models could not infer the underlying meaning of the\ninput text. In this work, we believe that contexts convey valuable evidence\nthat could facilitate the semantic modeling of queries, and take them into\nconsideration for entity recommendation. In order to better model the semantics\nof queries and entities, we learn the representation of queries and entities\njointly with attentive deep neural networks. We evaluate our approach using\nlarge-scale, real-world search logs from a widely used commercial Chinese\nsearch engine. Our system has been deployed in ShenMa Search Engine and you can\nfetch it in UC Browser of Alibaba. Results from online A/B test suggest that\nthe impression efficiency of click-through rate increased by 5.1% and page view\nincreased by 5.5%.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 07:47:20 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Jia", "Qianghuai", ""], ["Zhang", "Ningyu", ""], ["Hua", "Nengwei", ""]]}, {"id": "1909.04495", "submitter": "Yulun Hsieh", "authors": "Yu-Lun Hsieh and Minhao Cheng and Da-Cheng Juan and Wei Wei and\n  Wen-Lian Hsu and Cho-Jui Hsieh", "title": "Natural Adversarial Sentence Generation with Gradient-based Perturbation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This work proposes a novel algorithm to generate natural language adversarial\ninput for text classification models, in order to investigate the robustness of\nthese models. It involves applying gradient-based perturbation on the sentence\nembeddings that are used as the features for the classifier, and learning a\ndecoder for generation. We employ this method to a sentiment analysis model and\nverify its effectiveness in inducing incorrect predictions by the model. We\nalso conduct quantitative and qualitative analysis on these examples and\ndemonstrate that our approach can generate more natural adversaries. In\naddition, it can be used to successfully perform black-box attacks, which\ninvolves attacking other existing models whose parameters are not known. On a\npublic sentiment analysis API, the proposed method introduces a 20% relative\ndecrease in average accuracy and 74% relative increase in absolute error.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 07:22:01 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Hsieh", "Yu-Lun", ""], ["Cheng", "Minhao", ""], ["Juan", "Da-Cheng", ""], ["Wei", "Wei", ""], ["Hsu", "Wen-Lian", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1909.04499", "submitter": "Jason Lee", "authors": "Jason Lee, Kyunghyun Cho, Douwe Kiela", "title": "Countering Language Drift via Visual Grounding", "comments": "Accepted to EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emergent multi-agent communication protocols are very different from natural\nlanguage and not easily interpretable by humans. We find that agents that were\ninitially pretrained to produce natural language can also experience\ndetrimental language drift: when a non-linguistic reward is used in a\ngoal-based task, e.g. some scalar success metric, the communication protocol\nmay easily and radically diverge from natural language. We recast translation\nas a multi-agent communication game and examine auxiliary training constraints\nfor their effectiveness in mitigating language drift. We show that a\ncombination of syntactic (language model likelihood) and semantic (visual\ngrounding) constraints gives the best communication performance, allowing\npre-trained agents to retain English syntax while learning to accurately convey\nthe intended meaning.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 14:05:28 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Lee", "Jason", ""], ["Cho", "Kyunghyun", ""], ["Kiela", "Douwe", ""]]}, {"id": "1909.04547", "submitter": "Jonas Pfeiffer", "authors": "Jonas Pfeiffer, Aishwarya Kamath, Iryna Gurevych, Sebastian Ruder", "title": "What do Deep Networks Like to Read?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research towards understanding neural networks probes models in a\ntop-down manner, but is only able to identify model tendencies that are known a\npriori. We propose Susceptibility Identification through Fine-Tuning (SIFT), a\nnovel abstractive method that uncovers a model's preferences without imposing\nany prior. By fine-tuning an autoencoder with the gradients from a fixed\nclassifier, we are able to extract propensities that characterize different\nkinds of classifiers in a bottom-up manner. We further leverage the SIFT\narchitecture to rephrase sentences in order to predict the opposing class of\nthe ground truth label, uncovering potential artifacts encoded in the fixed\nclassification model. We evaluate our method on three diverse tasks with four\ndifferent models. We contrast the propensities of the models as well as\nreproduce artifacts reported in the literature.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 15:00:23 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Pfeiffer", "Jonas", ""], ["Kamath", "Aishwarya", ""], ["Gurevych", "Iryna", ""], ["Ruder", "Sebastian", ""]]}, {"id": "1909.04556", "submitter": "Chris Piech", "authors": "Chris Piech, Sami Abu-El-Haija", "title": "Human Languages in Source Code: Auto-Translation for Localized\n  Instruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Computer science education has promised open access around the world, but\naccess is largely determined by what human language you speak. As younger\nstudents learn computer science it is less appropriate to assume that they\nshould learn English beforehand. To that end we present CodeInternational, the\nfirst tool to translate code between human languages. To develop a theory of\nnon-English code, and inform our translation decisions, we conduct a study of\npublic code repositories on GitHub. The study is to the best of our knowledge\nthe first on human-language in code and covers 2.9 million Java repositories.\nTo demonstrate CodeInternational's educational utility, we build an interactive\nversion of the popular English-language Karel reader and translate it into 100\nspoken languages. Our translations have already been used in classrooms around\nthe world, and represent a first step in an important open CS-education\nproblem.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 15:06:58 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Piech", "Chris", ""], ["Abu-El-Haija", "Sami", ""]]}, {"id": "1909.04625", "submitter": "Ethan Wilcox", "authors": "Aixiu An, Peng Qian, Ethan Wilcox, and Roger Levy", "title": "Representation of Constituents in Neural Language Models: Coordination\n  Phrase as a Case Study", "comments": "To appear at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural language models have achieved state-of-the-art performances on many\nNLP tasks, and recently have been shown to learn a number of\nhierarchically-sensitive syntactic dependencies between individual words.\nHowever, equally important for language processing is the ability to combine\nwords into phrasal constituents, and use constituent-level features to drive\ndownstream expectations. Here we investigate neural models' ability to\nrepresent constituent-level features, using coordinated noun phrases as a case\nstudy. We assess whether different neural language models trained on English\nand French represent phrase-level number and gender features, and use those\nfeatures to drive downstream expectations. Our results suggest that models use\na linear combination of NP constituent number to drive CoordNP/verb number\nagreement. This behavior is highly regular and even sensitive to local\nsyntactic context, however it differs crucially from observed human behavior.\nModels have less success with gender agreement. Models trained on large corpora\nperform best, and there is no obvious advantage for models trained using\nexplicit syntactic supervision.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 17:02:15 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["An", "Aixiu", ""], ["Qian", "Peng", ""], ["Wilcox", "Ethan", ""], ["Levy", "Roger", ""]]}, {"id": "1909.04702", "submitter": "James Foulds", "authors": "Kamrun Naher Keya, Yannis Papanikolaou, James R. Foulds", "title": "Neural Embedding Allocation: Distributed Representations of Topic Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embedding models such as the skip-gram learn vector representations of\nwords' semantic relationships, and document embedding models learn similar\nrepresentations for documents. On the other hand, topic models provide latent\nrepresentations of the documents' topical themes. To get the benefits of these\nrepresentations simultaneously, we propose a unifying algorithm, called neural\nembedding allocation (NEA), which deconstructs topic models into interpretable\nvector-space embeddings of words, topics, documents, authors, and so on, by\nlearning neural embeddings to mimic the topic models. We showcase NEA's\neffectiveness and generality on LDA, author-topic models and the recently\nproposed mixed membership skip gram topic model and achieve better performance\nwith the embeddings compared to several state-of-the-art models. Furthermore,\nwe demonstrate that using NEA to smooth out the topics improves coherence\nscores over the original topic models when the number of topics is large.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 18:39:26 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Keya", "Kamrun Naher", ""], ["Papanikolaou", "Yannis", ""], ["Foulds", "James R.", ""]]}, {"id": "1909.04739", "submitter": "Niket Tandon", "authors": "Niket Tandon and Bhavana Dalvi Mishra and Keisuke Sakaguchi and\n  Antoine Bosselut and Peter Clark", "title": "WIQA: A dataset for \"What if...\" reasoning over procedural text", "comments": "Accepted at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce WIQA, the first large-scale dataset of \"What if...\" questions\nover procedural text. WIQA contains three parts: a collection of paragraphs\neach describing a process, e.g., beach erosion; a set of crowdsourced influence\ngraphs for each paragraph, describing how one change affects another; and a\nlarge (40k) collection of \"What if...?\" multiple-choice questions derived from\nthe graphs. For example, given a paragraph about beach erosion, would stormy\nweather result in more or less erosion (or have no effect)? The task is to\nanswer the questions, given their associated paragraph. WIQA contains three\nkinds of questions: perturbations to steps mentioned in the paragraph; external\n(out-of-paragraph) perturbations requiring commonsense knowledge; and\nirrelevant (no effect) perturbations. We find that state-of-the-art models\nachieve 73.8% accuracy, well below the human performance of 96.3%. We analyze\nthe challenges, in particular tracking chains of influences, and present the\ndataset as an open challenge to the community.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 20:37:39 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Tandon", "Niket", ""], ["Mishra", "Bhavana Dalvi", ""], ["Sakaguchi", "Keisuke", ""], ["Bosselut", "Antoine", ""], ["Clark", "Peter", ""]]}, {"id": "1909.04745", "submitter": "Niket Tandon", "authors": "Bhavana Dalvi Mishra and Niket Tandon and Antoine Bosselut and Wen-tau\n  Yih and Peter Clark", "title": "Everything Happens for a Reason: Discovering the Purpose of Actions in\n  Procedural Text", "comments": "Accepted to EMNLP 2019 as a long paper. This revision fixed a typo in\n  an author name in references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our goal is to better comprehend procedural text, e.g., a paragraph about\nphotosynthesis, by not only predicting what happens, but why some actions need\nto happen before others. Our approach builds on a prior process comprehension\nframework for predicting actions' effects, to also identify subsequent steps\nthat those effects enable. We present our new model (XPAD) that biases effect\npredictions towards those that (1) explain more of the actions in the paragraph\nand (2) are more plausible with respect to background knowledge. We also extend\nan existing benchmark dataset for procedural text comprehension, ProPara, by\nadding the new task of explaining actions by predicting their dependencies. We\nfind that XPAD significantly outperforms prior systems on this task, while\nmaintaining the performance on the original task in ProPara. The dataset is\navailable at http://data.allenai.org/propara\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 20:46:56 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 23:55:04 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Mishra", "Bhavana Dalvi", ""], ["Tandon", "Niket", ""], ["Bosselut", "Antoine", ""], ["Yih", "Wen-tau", ""], ["Clark", "Peter", ""]]}, {"id": "1909.04758", "submitter": "Xiangci Li", "authors": "Xiangci Li, Gully Burns, Nanyun Peng", "title": "Scientific Discourse Tagging for Evidence Extraction", "comments": "Accepted by The 16th Conference of the European Chapter of the\n  Association for Computational Linguistics (EACL 2021). 9 pages of main texts,\n  3 pages of references and 1 page of supportive information. 6 figures and 6\n  tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Evidence plays a crucial role in any biomedical research narrative, providing\njustification for some claims and refutation for others. We seek to build\nmodels of scientific argument using information extraction methods from\nfull-text papers. We present the capability of automatically extracting text\nfragments from primary research papers that describe the evidence presented in\nthat paper's figures, which arguably provides the raw material of any\nscientific argument made within the paper. We apply richly contextualized deep\nrepresentation learning pre-trained on biomedical domain corpus to the analysis\nof scientific discourse structures and the extraction of \"evidence fragments\"\n(i.e., the text in the results section describing data presented in a specified\nsubfigure) from a set of biomedical experimental research articles. We first\ndemonstrate our state-of-the-art scientific discourse tagger on two scientific\ndiscourse tagging datasets and its transferability to new datasets. We then\nshow the benefit of leveraging scientific discourse tags for downstream tasks\nsuch as claim-extraction and evidence fragment detection. Our work demonstrates\nthe potential of using evidence fragments derived from figure spans for\nimproving the quality of scientific claims by cataloging, indexing and reusing\nevidence fragments as independent documents.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 21:17:20 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 02:28:43 GMT"}, {"version": "v3", "created": "Mon, 25 Jan 2021 02:37:09 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Li", "Xiangci", ""], ["Burns", "Gully", ""], ["Peng", "Nanyun", ""]]}, {"id": "1909.04761", "submitter": "Julian Eisenschlos", "authors": "Julian Martin Eisenschlos, Sebastian Ruder, Piotr Czapla, Marcin\n  Kardas, Sylvain Gugger, Jeremy Howard", "title": "MultiFiT: Efficient Multi-lingual Language Model Fine-tuning", "comments": "Proceedings of EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pretrained language models are promising particularly for low-resource\nlanguages as they only require unlabelled data. However, training existing\nmodels requires huge amounts of compute, while pretrained cross-lingual models\noften underperform on low-resource languages. We propose Multi-lingual language\nmodel Fine-Tuning (MultiFiT) to enable practitioners to train and fine-tune\nlanguage models efficiently in their own language. In addition, we propose a\nzero-shot method using an existing pretrained cross-lingual model. We evaluate\nour methods on two widely used cross-lingual classification datasets where they\noutperform models pretrained on orders of magnitude more data and compute. We\nrelease all models and code.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 21:30:54 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 19:05:15 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Eisenschlos", "Julian Martin", ""], ["Ruder", "Sebastian", ""], ["Czapla", "Piotr", ""], ["Kardas", "Marcin", ""], ["Gugger", "Sylvain", ""], ["Howard", "Jeremy", ""]]}, {"id": "1909.04793", "submitter": "Evangelia Spiliopoulou", "authors": "Evangelia Spiliopoulou and Artidoro Pagnoni and Eduard Hovy", "title": "Definition Frames: Using Definitions for Hybrid Concept Representations", "comments": "To appear in COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in word representations have shown tremendous improvements in\ndownstream NLP tasks, but lack semantic interpretability. In this paper, we\nintroduce Definition Frames (DF), a matrix distributed representation extracted\nfrom definitions, where each dimension is semantically interpretable. DF\ndimensions correspond to the Qualia structure relations: a set of relations\nthat uniquely define a term. Our results show that DFs have competitive\nperformance with other distributional semantic approaches on word similarity\ntasks.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 23:43:05 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 01:43:40 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Spiliopoulou", "Evangelia", ""], ["Pagnoni", "Artidoro", ""], ["Hovy", "Eduard", ""]]}, {"id": "1909.04800", "submitter": "Badri Narayana Patro", "authors": "Badri N. Patro, Anupriy, Vinay P. Namboodiri", "title": "Probabilistic framework for solving Visual Dialog", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG cs.MM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we propose a probabilistic framework for solving the task of\n`Visual Dialog'. Solving this task requires reasoning and understanding of\nvisual modality, language modality, and common sense knowledge to answer.\nVarious architectures have been proposed to solve this task by variants of\nmulti-modal deep learning techniques that combine visual and language\nrepresentations. However, we believe that it is crucial to understand and\nanalyze the sources of uncertainty for solving this task. Our approach allows\nfor estimating uncertainty and also aids a diverse generation of answers. The\nproposed approach is obtained through a probabilistic representation module\nthat provides us with representations for image, question and conversation\nhistory, a module that ensures that diverse latent representations for\ncandidate answers are obtained given the probabilistic representations and an\nuncertainty representation module that chooses the appropriate answer that\nminimizes uncertainty. We thoroughly evaluate the model with a detailed\nablation analysis, comparison with state of the art and visualization of the\nuncertainty that aids in the understanding of the method. Using the proposed\nprobabilistic framework, we thus obtain an improved visual dialog system that\nis also more explainable.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 00:25:12 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 07:30:39 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Patro", "Badri N.", ""], ["Anupriy", "", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "1909.04822", "submitter": "Elaheh ShafieiBavani", "authors": "Elaheh ShafieiBavani, Antonio Jimeno Yepes, Xu Zhong, David Martinez\n  Iraola", "title": "Global Locality in Biomedical Relation and Event Extraction", "comments": "10 pages. arXiv admin note: text overlap with arXiv:1802.10569,\n  arXiv:1710.08312 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the exponential growth of biomedical literature, event and relation\nextraction are important tasks in biomedical text mining. Most work only focus\non relation extraction, and detect a single entity pair mention on a short span\nof text, which is not ideal due to long sentences that appear in biomedical\ncontexts. We propose an approach to both relation and event extraction, for\nsimultaneously predicting relationships between all mention pairs in a text. We\nalso perform an empirical study to discuss different network setups for this\npurpose. The best performing model includes a set of multi-head attentions and\nconvolutions, an adaptation of the transformer architecture, which offers\nself-attention the ability to strengthen dependencies among related elements,\nand models the interaction between features extracted by multiple attention\nheads. Experiment results demonstrate that our approach outperforms the state\nof the art on a set of benchmark biomedical corpora including BioNLP 2009,\n2011, 2013 and BioCreative 2017 shared tasks.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 02:20:57 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 07:03:07 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["ShafieiBavani", "Elaheh", ""], ["Yepes", "Antonio Jimeno", ""], ["Zhong", "Xu", ""], ["Iraola", "David Martinez", ""]]}, {"id": "1909.04849", "submitter": "Sewon Min", "authors": "Sewon Min, Danqi Chen, Hannaneh Hajishirzi, Luke Zettlemoyer", "title": "A Discrete Hard EM Approach for Weakly Supervised Question Answering", "comments": "Published as a conference paper at EMNLP 2019 (long). Code available\n  at https://github.com/shmsw25/qa-hard-em", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many question answering (QA) tasks only provide weak supervision for how the\nanswer should be computed. For example, TriviaQA answers are entities that can\nbe mentioned multiple times in supporting documents, while DROP answers can be\ncomputed by deriving many different equations from numbers in the reference\ntext. In this paper, we show it is possible to convert such tasks into discrete\nlatent variable learning problems with a precomputed, task-specific set of\npossible \"solutions\" (e.g. different mentions or equations) that contains one\ncorrect option. We then develop a hard EM learning scheme that computes\ngradients relative to the most likely solution at each update. Despite its\nsimplicity, we show that this approach significantly outperforms previous\nmethods on six QA tasks, including absolute gains of 2--10%, and achieves the\nstate-of-the-art on five of them. Using hard updates instead of maximizing\nmarginal likelihood is key to these results as it encourages the model to find\nthe one correct answer, which we show through detailed qualitative analysis.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 04:47:36 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Min", "Sewon", ""], ["Chen", "Danqi", ""], ["Hajishirzi", "Hannaneh", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1909.04879", "submitter": "Mamoru Komachi", "authors": "Michiki Kurosawa and Mamoru Komachi", "title": "Dynamic Fusion: Attentional Language Model for Neural Machine\n  Translation", "comments": "13 pages; PACLING 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural Machine Translation (NMT) can be used to generate fluent output. As\nsuch, language models have been investigated for incorporation with NMT. In\nprior investigations, two models have been used: a translation model and a\nlanguage model. The translation model's predictions are weighted by the\nlanguage model with a hand-crafted ratio in advance. However, these approaches\nfail to adopt the language model weighting with regard to the translation\nhistory. In another line of approach, language model prediction is incorporated\ninto the translation model by jointly considering source and target\ninformation. However, this line of approach is limited because it largely\nignores the adequacy of the translation output.\n  Accordingly, this work employs two mechanisms, the translation model and the\nlanguage model, with an attentive architecture to the language model as an\nauxiliary element of the translation model. Compared with previous work in\nEnglish--Japanese machine translation using a language model, the experimental\nresults obtained with the proposed Dynamic Fusion mechanism improve BLEU and\nRank-based Intuitive Bilingual Evaluation Scores (RIBES) scores. Additionally,\nin the analyses of the attention and predictivity of the language model, the\nDynamic Fusion mechanism allows predictive language modeling that conforms to\nthe appropriate grammatical structure.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 07:14:58 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Kurosawa", "Michiki", ""], ["Komachi", "Mamoru", ""]]}, {"id": "1909.04917", "submitter": "Lukasz Augustyniak", "authors": "{\\L}ukasz Augustyniak, Tomasz Kajdanowicz, Przemys{\\l}aw Kazienko", "title": "Comprehensive Analysis of Aspect Term Extraction Methods using Various\n  Text Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a variety of model designs and methods have blossomed in the\ncontext of the sentiment analysis domain. However, there is still a lack of\nwide and comprehensive studies of aspect-based sentiment analysis (ABSA). We\nwant to fill this gap and propose a comparison with ablation analysis of aspect\nterm extraction using various text embedding methods. We particularly focused\non architectures based on long short-term memory (LSTM) with optional\nconditional random field (CRF) enhancement using different pre-trained word\nembeddings. Moreover, we analyzed the influence on the performance of extending\nthe word vectorization step with character embedding. The experimental results\non SemEval datasets revealed that not only does bi-directional long short-term\nmemory (BiLSTM) outperform regular LSTM, but also word embedding coverage and\nits source highly affect aspect detection performance. An additional CRF layer\nconsistently improves the results as well.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 08:40:16 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 13:40:58 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Augustyniak", "\u0141ukasz", ""], ["Kajdanowicz", "Tomasz", ""], ["Kazienko", "Przemys\u0142aw", ""]]}, {"id": "1909.04925", "submitter": "Betty van Aken", "authors": "Betty van Aken, Benjamin Winter, Alexander L\\\"oser, Felix A. Gers", "title": "How Does BERT Answer Questions? A Layer-Wise Analysis of Transformer\n  Representations", "comments": "Accepted at CIKM 2019", "journal-ref": null, "doi": "10.1145/3357384.3358028", "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bidirectional Encoder Representations from Transformers (BERT) reach\nstate-of-the-art results in a variety of Natural Language Processing tasks.\nHowever, understanding of their internal functioning is still insufficient and\nunsatisfactory. In order to better understand BERT and other Transformer-based\nmodels, we present a layer-wise analysis of BERT's hidden states. Unlike\nprevious research, which mainly focuses on explaining Transformer models by\ntheir attention weights, we argue that hidden states contain equally valuable\ninformation. Specifically, our analysis focuses on models fine-tuned on the\ntask of Question Answering (QA) as an example of a complex downstream task. We\ninspect how QA models transform token vectors in order to find the correct\nanswer. To this end, we apply a set of general and QA-specific probing tasks\nthat reveal the information stored in each representation layer. Our\nqualitative analysis of hidden state visualizations provides additional\ninsights into BERT's reasoning process. Our results show that the\ntransformations within BERT go through phases that are related to traditional\npipeline tasks. The system can therefore implicitly incorporate task-specific\ninformation into its token representations. Furthermore, our analysis reveals\nthat fine-tuning has little impact on the models' semantic abilities and that\nprediction errors can be recognized in the vector representations of even early\nlayers.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 08:55:09 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["van Aken", "Betty", ""], ["Winter", "Benjamin", ""], ["L\u00f6ser", "Alexander", ""], ["Gers", "Felix A.", ""]]}, {"id": "1909.04948", "submitter": "Timo Denk", "authors": "Timo I. Denk, Christian Reisswig", "title": "BERTgrid: Contextualized Embedding for 2D Document Representation and\n  Understanding", "comments": "4 pages, accepted at the \"Document Intelligence\" workshop of 33rd\n  Conference on Neural Information Processing Systems (NeurIPS 2019),\n  Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For understanding generic documents, information like font sizes, column\nlayout, and generally the positioning of words may carry semantic information\nthat is crucial for solving a downstream document intelligence task. Our novel\nBERTgrid, which is based on Chargrid by Katti et al. (2018), represents a\ndocument as a grid of contextualized word piece embedding vectors, thereby\nmaking its spatial structure and semantics accessible to the processing neural\nnetwork. The contextualized embedding vectors are retrieved from a BERT\nlanguage model. We use BERTgrid in combination with a fully convolutional\nnetwork on a semantic instance segmentation task for extracting fields from\ninvoices. We demonstrate its performance on tabulated line item and document\nheader field extraction.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 09:51:02 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 09:55:39 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Denk", "Timo I.", ""], ["Reisswig", "Christian", ""]]}, {"id": "1909.04985", "submitter": "Edouard Delasalles", "authors": "Edouard Delasalles, Sylvain Lamprier, Ludovic Denoyer", "title": "Learning Dynamic Author Representations with Temporal Language Models", "comments": "International Conference on Data Mining, ICDM 2019", "journal-ref": null, "doi": "10.1109/ICDM.2019.00022", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language models are at the heart of numerous works, notably in the text\nmining and information retrieval communities. These statistical models aim at\nextracting word distributions, from simple unigram models to recurrent\napproaches with latent variables that capture subtle dependencies in texts.\nHowever, those models are learned from word sequences only, and authors'\nidentities, as well as publication dates, are seldom considered. We propose a\nneural model, based on recurrent language modeling, which aims at capturing\nlanguage diffusion tendencies in author communities through time. By\nconditioning language models with author and temporal vector states, we are\nable to leverage the latent dependencies between the text contexts. This allows\nus to beat several temporal and non-temporal language baselines on two\nreal-world corpora, and to learn meaningful author representations that vary\nthrough time.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 11:51:43 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Delasalles", "Edouard", ""], ["Lamprier", "Sylvain", ""], ["Denoyer", "Ludovic", ""]]}, {"id": "1909.05016", "submitter": "Richard Csaky", "authors": "Richard Csaky", "title": "Proposal Towards a Personalized Knowledge-powered Self-play Based\n  Ensemble Dialog System", "comments": "14 pages. Originally written for the 2019 Amazon Alexa application", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the application document for the 2019 Amazon Alexa competition. We\ngive an overall vision of our conversational experience, as well as a sample\nconversation that we would like our dialog system to achieve by the end of the\ncompetition. We believe personalization, knowledge, and self-play are important\ncomponents towards better chatbots. These are further highlighted by our\ndetailed system architecture proposal and novelty section. Finally, we describe\nhow we would ensure an engaging experience, how this research would impact the\nfield, and related work.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 12:53:01 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Csaky", "Richard", ""]]}, {"id": "1909.05017", "submitter": "Artit Wangperawong", "authors": "Kettip Kriangchaivech and Artit Wangperawong", "title": "Question Generation by Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A machine learning model was developed to automatically generate questions\nfrom Wikipedia passages using transformers, an attention-based model eschewing\nthe paradigm of existing recurrent neural networks (RNNs). The model was\ntrained on the inverted Stanford Question Answering Dataset (SQuAD), which is a\nreading comprehension dataset consisting of 100,000+ questions posed by\ncrowdworkers on a set of Wikipedia articles. After training, the question\ngeneration model is able to generate simple questions relevant to unseen\npassages and answers containing an average of 8 words per question. The word\nerror rate (WER) was used as a metric to compare the similarity between SQuAD\nquestions and the model-generated questions. Although the high average WER\nsuggests that the questions generated differ from the original SQuAD questions,\nthe questions generated are mostly grammatically correct and plausible in their\nown right.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 19:48:53 GMT"}, {"version": "v2", "created": "Sat, 14 Sep 2019 20:02:20 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Kriangchaivech", "Kettip", ""], ["Wangperawong", "Artit", ""]]}, {"id": "1909.05023", "submitter": "Johannes Bausch", "authors": "Johannes Bausch, Sathyawageeswar Subramanian, Stephen Piddock", "title": "A Quantum Search Decoder for Natural Language Processing", "comments": "39 pages, 16 figures, 2 algorithms", "journal-ref": "Quantum Mach. Intell. 3, 16 (2021)", "doi": "10.1007/s42484-021-00041-1", "report-no": null, "categories": "quant-ph cs.CL cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic language models, e.g. those based on an LSTM, often face the\nproblem of finding a high probability prediction from a sequence of random\nvariables over a set of tokens. This is commonly addressed using a form of\ngreedy decoding such as beam search, where a limited number of\nhighest-likelihood paths (the beam width) of the decoder are kept, and at the\nend the maximum-likelihood path is chosen. In this work, we construct a quantum\nalgorithm to find the globally optimal parse (i.e. for infinite beam width)\nwith high constant success probability. When the input to the decoder is\ndistributed as a power-law with exponent $k>0$, our algorithm has runtime $R^{n\nf(R,k)}$, where $R$ is the alphabet size, $n$ the input length; here $f<1/2$,\nand $f\\rightarrow 0$ exponentially fast with increasing $k$, hence making our\nalgorithm always more than quadratically faster than its classical counterpart.\nWe further modify our procedure to recover a finite beam width variant, which\nenables an even stronger empirical speedup while still retaining higher\naccuracy than possible classically. Finally, we apply this quantum beam search\ndecoder to Mozilla's implementation of Baidu's DeepSpeech neural net, which we\nshow to exhibit such a power law word rank frequency.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 17:59:23 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 16:51:11 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Bausch", "Johannes", ""], ["Subramanian", "Sathyawageeswar", ""], ["Piddock", "Stephen", ""]]}, {"id": "1909.05088", "submitter": "Eva Vanmassenhove", "authors": "Eva Vanmassenhove, Christian Hardmeier, Andy Way", "title": "Getting Gender Right in Neural Machine Translation", "comments": "Proceedings of the 2018 Conference on Empirical Methods in Natural\n  Language Processing (EMNLP), October-November, 2018. Brussels, Belgium, pages\n  3003-3008, URL: https://www.aclweb.org/anthology/D18-1334, DOI:\n  10.18653/v1/D18-1334", "journal-ref": "Proceedings of the 2018 Conference on Empirical Methods in Natural\n  Language Processing", "doi": "10.18653/v1/D18-1334", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Speakers of different languages must attend to and encode strikingly\ndifferent aspects of the world in order to use their language correctly (Sapir,\n1921; Slobin, 1996). One such difference is related to the way gender is\nexpressed in a language. Saying \"I am happy\" in English, does not encode any\nadditional knowledge of the speaker that uttered the sentence. However, many\nother languages do have grammatical gender systems and so such knowledge would\nbe encoded. In order to correctly translate such a sentence into, say, French,\nthe inherent gender information needs to be retained/recovered. The same\nsentence would become either \"Je suis heureux\", for a male speaker or \"Je suis\nheureuse\" for a female one. Apart from morphological agreement, demographic\nfactors (gender, age, etc.) also influence our use of language in terms of word\nchoices or even on the level of syntactic constructions (Tannen, 1991;\nPennebaker et al., 2003). We integrate gender information into NMT systems. Our\ncontribution is two-fold: (1) the compilation of large datasets with speaker\ninformation for 20 language pairs, and (2) a simple set of experiments that\nincorporate gender information into NMT for multiple language pairs. Our\nexperiments show that adding a gender feature to an NMT system significantly\nimproves the translation quality for some language pairs.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 14:44:27 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Vanmassenhove", "Eva", ""], ["Hardmeier", "Christian", ""], ["Way", "Andy", ""]]}, {"id": "1909.05158", "submitter": "Gustavo Aguilar", "authors": "Gustavo Aguilar and Thamar Solorio", "title": "From English to Code-Switching: Transfer Learning with Strong\n  Morphological Clues", "comments": "Accepted to ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linguistic Code-switching (CS) is still an understudied phenomenon in natural\nlanguage processing. The NLP community has mostly focused on monolingual and\nmulti-lingual scenarios, but little attention has been given to CS in\nparticular. This is partly because of the lack of resources and annotated data,\ndespite its increasing occurrence in social media platforms. In this paper, we\naim at adapting monolingual models to code-switched text in various tasks.\nSpecifically, we transfer English knowledge from a pre-trained ELMo model to\ndifferent code-switched language pairs (i.e., Nepali-English, Spanish-English,\nand Hindi-English) using the task of language identification. Our method,\nCS-ELMo, is an extension of ELMo with a simple yet effective position-aware\nattention mechanism inside its character convolutions. We show the\neffectiveness of this transfer learning step by outperforming multilingual BERT\nand homologous CS-unaware ELMo models and establishing a new state of the art\nin CS tasks, such as NER and POS tagging. Our technique can be expanded to more\nEnglish-paired code-switched languages, providing more resources to the CS\ncommunity.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 15:53:21 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 18:54:22 GMT"}, {"version": "v3", "created": "Fri, 1 May 2020 20:56:37 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Aguilar", "Gustavo", ""], ["Solorio", "Thamar", ""]]}, {"id": "1909.05166", "submitter": "Gustavo Aguilar", "authors": "Gustavo Aguilar and Thamar Solorio", "title": "Dependency-Aware Named Entity Recognition with Relative and Global\n  Attentions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named entity recognition is one of the core tasks in NLP. Although many\nimprovements have been made on this task during the last years, the\nstate-of-the-art systems do not explicitly take into account the recursive\nnature of language. Instead of only treating the text as a plain sequence of\nwords, we incorporate a linguistically-inspired way to recognize entities based\non syntax and tree structures. Our model exploits syntactic relationships among\nwords using a Tree-LSTM guided by dependency trees. Then, we enhance these\nfeatures by applying relative and global attention mechanisms. On the one hand,\nthe relative attention detects the most informative words in the sentence with\nrespect to the word being evaluated. On the other hand, the global attention\nspots the most relevant words in the sequence. Lastly, we linearly project the\nweighted vectors into the tagging space so that a conditional random field\nclassifier predicts the entity labels. Our findings show that the model detects\nwords that disclose the entity types based on their syntactic roles in a\nsentence (e.g., verbs such as speak and write are attended when the entity type\nis PERSON, whereas meet and travel strongly relate to LOCATION). We confirm our\nfindings and establish a new state of the art on two datasets.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 16:10:26 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Aguilar", "Gustavo", ""], ["Solorio", "Thamar", ""]]}, {"id": "1909.05190", "submitter": "Kuo Liao", "authors": "Xiao Ding, Kuo Liao, Ting Liu, Zhongyang Li, Junwen Duan", "title": "Event Representation Learning Enhanced with External Commonsense\n  Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior work has proposed effective methods to learn event representations that\ncan capture syntactic and semantic information over text corpus, demonstrating\ntheir effectiveness for downstream tasks such as script event prediction. On\nthe other hand, events extracted from raw texts lacks of commonsense knowledge,\nsuch as the intents and emotions of the event participants, which are useful\nfor distinguishing event pairs when there are only subtle differences in their\nsurface realizations. To address this issue, this paper proposes to leverage\nexternal commonsense knowledge about the intent and sentiment of the event.\nExperiments on three event-related tasks, i.e., event similarity, script event\nprediction and stock market prediction, show that our model obtains much better\nevent embeddings for the tasks, achieving 78% improvements on hard similarity\ntask, yielding more precise inferences on subsequent events under given\ncontexts, and better accuracies in predicting the volatilities of the stock\nmarket.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 03:00:39 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 08:51:02 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Ding", "Xiao", ""], ["Liao", "Kuo", ""], ["Liu", "Ting", ""], ["Li", "Zhongyang", ""], ["Duan", "Junwen", ""]]}, {"id": "1909.05192", "submitter": "Bernhard Lutz", "authors": "Bernhard Lutz, Nicolas Pr\\\"ollochs, Dirk Neumann", "title": "The Longer the Better? The Interplay Between Review Length and Line of\n  Argumentation in Online Consumer Reviews", "comments": "arXiv admin note: text overlap with arXiv:1810.10942", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Review helpfulness serves as focal point in understanding customers' purchase\ndecision-making process on online retailer platforms. An overwhelming majority\nof previous works find longer reviews to be more helpful than short reviews. In\nthis paper, we propose that longer reviews should not be assumed to be\nuniformly more helpful; instead, we argue that the effect depends on the line\nof argumentation in the review text. To test this idea, we use a large dataset\nof customer reviews from Amazon in combination with a state-of-the-art approach\nfrom natural language processing that allows us to study argumentation lines at\nsentence level. Our empirical analysis suggests that the frequency of\nargumentation changes moderates the effect of review length on helpfulness.\nAltogether, we disprove the prevailing narrative that longer reviews are\nuniformly perceived as more helpful. Our findings allow retailer platforms to\nimprove their customer feedback systems and to feature more useful product\nreviews.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 15:19:51 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 18:51:18 GMT"}, {"version": "v3", "created": "Thu, 26 Sep 2019 09:25:44 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Lutz", "Bernhard", ""], ["Pr\u00f6llochs", "Nicolas", ""], ["Neumann", "Dirk", ""]]}, {"id": "1909.05233", "submitter": "Ankur Mali", "authors": "Ankur Mali, Alexander Ororbia, C. Lee Giles", "title": "The Neural State Pushdown Automata", "comments": "10 pages, 7 Table, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In order to learn complex grammars, recurrent neural networks (RNNs) require\nsufficient computational resources to ensure correct grammar recognition. A\nwidely-used approach to expand model capacity would be to couple an RNN to an\nexternal memory stack. Here, we introduce a \"neural state\" pushdown automaton\n(NSPDA), which consists of a digital stack, instead of an analog one, that is\ncoupled to a neural network state machine. We empirically show its\neffectiveness in recognizing various context-free grammars (CFGs). First, we\ndevelop the underlying mechanics of the proposed higher order recurrent network\nand its manipulation of a stack as well as how to stably program its underlying\npushdown automaton (PDA) to achieve desired finite-state network dynamics.\nNext, we introduce a noise regularization scheme for higher-order (tensor)\nnetworks, to our knowledge the first of its kind, and design an algorithm for\nimproved incremental learning. Finally, we design a method for inserting\ngrammar rules into a NSPDA and empirically show that this prior knowledge\nimproves its training convergence time by an order of magnitude and, in some\ncases, leads to better generalization. The NSPDA is also compared to a\nclassical analog stack neural network pushdown automaton (NNPDA) as well as a\nwide array of first and second-order RNNs with and without external memory,\ntrained using different learning algorithms. Our results show that, for Dyck(2)\nlanguages, prior rule-based knowledge is critical for optimization convergence\nand for ensuring generalization to longer sequences at test time. We observe\nthat many RNNs with and without memory, but no prior knowledge, fail to\nconverge and generalize poorly on CFGs.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 00:32:11 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 20:12:33 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Mali", "Ankur", ""], ["Ororbia", "Alexander", ""], ["Giles", "C. Lee", ""]]}, {"id": "1909.05246", "submitter": "Mansour Saffar Mehrjardi", "authors": "Mansour Saffar Mehrjardi, Amine Trabelsi, Osmar R. Zaiane", "title": "Self-Attentional Models Application in Task-Oriented Dialogue Generation\n  Systems", "comments": "Appeared in proceedings of Recent Advances in Natural Language\n  Processing (RANLP) Conference, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Self-attentional models are a new paradigm for sequence modelling tasks which\ndiffer from common sequence modelling methods, such as recurrence-based and\nconvolution-based sequence learning, in the way that their architecture is only\nbased on the attention mechanism. Self-attentional models have been used in the\ncreation of the state-of-the-art models in many NLP tasks such as neural\nmachine translation, but their usage has not been explored for the task of\ntraining end-to-end task-oriented dialogue generation systems yet. In this\nstudy, we apply these models on the three different datasets for training\ntask-oriented chatbots. Our finding shows that self-attentional models can be\nexploited to create end-to-end task-oriented chatbots which not only achieve\nhigher evaluation scores compared to recurrence-based models, but also do so\nmore efficiently.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 03:40:26 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Mehrjardi", "Mansour Saffar", ""], ["Trabelsi", "Amine", ""], ["Zaiane", "Osmar R.", ""]]}, {"id": "1909.05286", "submitter": "Avirup Sil", "authors": "Lin Pan, Rishav Chakravarti, Anthony Ferritto, Michael Glass, Alfio\n  Gliozzo, Salim Roukos, Radu Florian, Avirup Sil", "title": "Frustratingly Easy Natural Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing literature on Question Answering (QA) mostly focuses on algorithmic\nnovelty, data augmentation, or increasingly large pre-trained language models\nlike XLNet and RoBERTa. Additionally, a lot of systems on the QA leaderboards\ndo not have associated research documentation in order to successfully\nreplicate their experiments. In this paper, we outline these algorithmic\ncomponents such as Attention-over-Attention, coupled with data augmentation and\nensembling strategies that have shown to yield state-of-the-art results on\nbenchmark datasets like SQuAD, even achieving super-human performance. Contrary\nto these prior results, when we evaluate on the recently proposed Natural\nQuestions benchmark dataset, we find that an incredibly simple approach of\ntransfer learning from BERT outperforms the previous state-of-the-art system\ntrained on 4 million more examples than ours by 1.9 F1 points. Adding\nensembling strategies further improves that number by 2.3 F1 points.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 18:28:48 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Pan", "Lin", ""], ["Chakravarti", "Rishav", ""], ["Ferritto", "Anthony", ""], ["Glass", "Michael", ""], ["Gliozzo", "Alfio", ""], ["Roukos", "Salim", ""], ["Florian", "Radu", ""], ["Sil", "Avirup", ""]]}, {"id": "1909.05308", "submitter": "Tazin Afrin", "authors": "Tazin Afrin and Diane Litman", "title": "Identifying Editor Roles in Argumentative Writing from Student Revision\n  Histories", "comments": null, "journal-ref": "In: Artificial Intelligence in Education. AIED 2019. Lecture Notes\n  in Computer Science, vol 11626. Springer, Cham", "doi": "10.1007/978-3-030-23207-8_2", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for identifying editor roles from students' revision\nbehaviors during argumentative writing. We first develop a method for applying\na topic modeling algorithm to identify a set of editor roles from a vocabulary\ncapturing three aspects of student revision behaviors: operation, purpose, and\nposition. We validate the identified roles by showing that modeling the editor\nroles that students take when revising a paper not only accounts for the\nvariance in revision purposes in our data, but also relates to writing\nimprovement.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 20:47:32 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Afrin", "Tazin", ""], ["Litman", "Diane", ""]]}, {"id": "1909.05309", "submitter": "Tazin Afrin", "authors": "Tazin Afrin and Diane Litman", "title": "Annotation and Classification of Sentence-level Revision Improvement", "comments": null, "journal-ref": "In Proceedings of the Thirteenth Workshop on Innovative Use of NLP\n  for Building Educational Applications (pp. 240-246) 2018", "doi": "10.18653/v1/W18-0528", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studies of writing revisions rarely focus on revision quality. To address\nthis issue, we introduce a corpus of between-draft revisions of student\nargumentative essays, annotated as to whether each revision improves essay\nquality. We demonstrate a potential usage of our annotations by developing a\nmachine learning model to predict revision improvement. With the goal of\nexpanding training data, we also extract revisions from a dataset edited by\nexpert proofreaders. Our results indicate that blending expert and non-expert\nrevisions increases model performance, with expert data particularly important\nfor predicting low-quality revisions.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 21:02:16 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Afrin", "Tazin", ""], ["Litman", "Diane", ""]]}, {"id": "1909.05311", "submitter": "Shangwen  Lv", "authors": "Shangwen Lv, Daya Guo, Jingjing Xu, Duyu Tang, Nan Duan, Ming Gong,\n  Linjun Shou, Daxin Jiang, Guihong Cao, Songlin Hu", "title": "Graph-Based Reasoning over Heterogeneous External Knowledge for\n  Commonsense Question Answering", "comments": "8 pages, 7 figure, AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commonsense question answering aims to answer questions which require\nbackground knowledge that is not explicitly expressed in the question. The key\nchallenge is how to obtain evidence from external knowledge and make\npredictions based on the evidence. Recent works either learn to generate\nevidence from human-annotated evidence which is expensive to collect, or\nextract evidence from either structured or unstructured knowledge bases which\nfails to take advantages of both sources. In this work, we propose to\nautomatically extract evidence from heterogeneous knowledge sources, and answer\nquestions based on the extracted evidence. Specifically, we extract evidence\nfrom both structured knowledge base (i.e. ConceptNet) and Wikipedia plain\ntexts. We construct graphs for both sources to obtain the relational structures\nof evidence. Based on these graphs, we propose a graph-based approach\nconsisting of a graph-based contextual word representation learning module and\na graph-based inference module. The first module utilizes graph structural\ninformation to re-define the distance between words for learning better\ncontextual word representations. The second module adopts graph convolutional\nnetwork to encode neighbor information into the representations of nodes, and\naggregates evidence with graph attention mechanism for predicting the final\nanswer. Experimental results on CommonsenseQA dataset illustrate that our\ngraph-based approach over both knowledge sources brings improvement over strong\nbaselines. Our approach achieves the state-of-the-art accuracy (75.3%) on the\nCommonsenseQA leaderboard.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 12:43:12 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 02:19:16 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Lv", "Shangwen", ""], ["Guo", "Daya", ""], ["Xu", "Jingjing", ""], ["Tang", "Duyu", ""], ["Duan", "Nan", ""], ["Gong", "Ming", ""], ["Shou", "Linjun", ""], ["Jiang", "Daxin", ""], ["Cao", "Guihong", ""], ["Hu", "Songlin", ""]]}, {"id": "1909.05316", "submitter": "Junjie Hu", "authors": "Junjie Hu, Yu Cheng, Zhe Gan, Jingjing Liu, Jianfeng Gao, Graham\n  Neubig", "title": "What Makes A Good Story? Designing Composite Rewards for Visual\n  Storytelling", "comments": "Accepted paper in Thirty-Fourth AAAI Conference on Artificial\n  Intelligence (AAAI) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous storytelling approaches mostly focused on optimizing traditional\nmetrics such as BLEU, ROUGE and CIDEr. In this paper, we re-examine this\nproblem from a different angle, by looking deep into what defines a\nrealistically-natural and topically-coherent story. To this end, we propose\nthree assessment criteria: relevance, coherence and expressiveness, which we\nobserve through empirical analysis could constitute a \"high-quality\" story to\nthe human eye. Following this quality guideline, we propose a reinforcement\nlearning framework, ReCo-RL, with reward functions designed to capture the\nessence of these quality criteria. Experiments on the Visual Storytelling\nDataset (VIST) with both automatic and human evaluations demonstrate that our\nReCo-RL model achieves better performance than state-of-the-art baselines on\nboth traditional metrics and the proposed new criteria.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 19:17:03 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 19:49:21 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Hu", "Junjie", ""], ["Cheng", "Yu", ""], ["Gan", "Zhe", ""], ["Liu", "Jingjing", ""], ["Gao", "Jianfeng", ""], ["Neubig", "Graham", ""]]}, {"id": "1909.05355", "submitter": "Preksha Nema I", "authors": "Preksha Nema, Akash Kumar Mohankumar, Mitesh M. Khapra, Balaji Vasan\n  Srinivasan, Balaraman Ravindran", "title": "Let's Ask Again: Refine Network for Automatic Question Generation", "comments": "accepted in EMNLP 2019 in Main Conference, (10 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we focus on the task of Automatic Question Generation (AQG)\nwhere given a passage and an answer the task is to generate the corresponding\nquestion. It is desired that the generated question should be (i) grammatically\ncorrect (ii) answerable from the passage and (iii) specific to the given\nanswer. An analysis of existing AQG models shows that they produce questions\nwhich do not adhere to one or more of {the above-mentioned qualities}. In\nparticular, the generated questions look like an incomplete draft of the\ndesired question with a clear scope for refinement. {To alleviate this\nshortcoming}, we propose a method which tries to mimic the human process of\ngenerating questions by first creating an initial draft and then refining it.\nMore specifically, we propose Refine Network (RefNet) which contains two\ndecoders. The second decoder uses a dual attention network which pays attention\nto both (i) the original passage and (ii) the question (initial draft)\ngenerated by the first decoder. In effect, it refines the question generated by\nthe first decoder, thereby making it more correct and complete. We evaluate\nRefNet on three datasets, \\textit{viz.}, SQuAD, HOTPOT-QA, and DROP, and show\nthat it outperforms existing state-of-the-art methods by 7-16\\% on all of these\ndatasets. Lastly, we show that we can improve the quality of the second decoder\non specific metrics, such as, fluency and answerability by explicitly rewarding\nrevisions that improve on the corresponding metric during training. The code\nhas been made publicly available\n\\footnote{https://github.com/PrekshaNema25/RefNet-QG}\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 04:03:26 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Nema", "Preksha", ""], ["Mohankumar", "Akash Kumar", ""], ["Khapra", "Mitesh M.", ""], ["Srinivasan", "Balaji Vasan", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "1909.05356", "submitter": "Alankar Jain", "authors": "Alankar Jain, Bhargavi Paranjape, Zachary C. Lipton", "title": "Entity Projection via Machine Translation for Cross-Lingual NER", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although over 100 languages are supported by strong off-the-shelf machine\ntranslation systems, only a subset of them possess large annotated corpora for\nnamed entity recognition. Motivated by this fact, we leverage machine\ntranslation to improve annotation-projection approaches to cross-lingual named\nentity recognition. We propose a system that improves over prior\nentity-projection methods by: (a) leveraging machine translation systems twice:\nfirst for translating sentences and subsequently for translating entities; (b)\nmatching entities based on orthographic and phonetic similarity; and (c)\nidentifying matches based on distributional statistics derived from the\ndataset. Our approach improves upon current state-of-the-art methods for\ncross-lingual named entity recognition on 5 diverse languages by an average of\n4.1 points. Further, our method achieves state-of-the-art F_1 scores for\nArmenian, outperforming even a monolingual model trained on Armenian source\ndata.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 17:40:21 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 06:44:24 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Jain", "Alankar", ""], ["Paranjape", "Bhargavi", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "1909.05357", "submitter": "Ming Tan", "authors": "Ming Tan, Yang Yu, Haoyu Wang, Dakuo Wang, Saloni Potdar, Shiyu Chang,\n  Mo Yu", "title": "Out-of-Domain Detection for Low-Resource Text Classification Tasks", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Out-of-domain (OOD) detection for low-resource text classification is a\nrealistic but understudied task. The goal is to detect the OOD cases with\nlimited in-domain (ID) training data, since we observe that training data is\noften insufficient in machine learning applications. In this work, we propose\nan OOD-resistant Prototypical Network to tackle this zero-shot OOD detection\nand few-shot ID classification task. Evaluation on real-world datasets show\nthat the proposed solution outperforms state-of-the-art methods in zero-shot\nOOD detection task, while maintaining a competitive performance on ID\nclassification task.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 20:23:26 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Tan", "Ming", ""], ["Yu", "Yang", ""], ["Wang", "Haoyu", ""], ["Wang", "Dakuo", ""], ["Potdar", "Saloni", ""], ["Chang", "Shiyu", ""], ["Yu", "Mo", ""]]}, {"id": "1909.05358", "submitter": "Chinnadhurai Sankar", "authors": "Bill Byrne, Karthik Krishnamoorthi, Chinnadhurai Sankar, Arvind\n  Neelakantan, Daniel Duckworth, Semih Yavuz, Ben Goodrich, Amit Dubey, Andy\n  Cedilnik, Kyu-Young Kim", "title": "Taskmaster-1: Toward a Realistic and Diverse Dialog Dataset", "comments": "To appear at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A significant barrier to progress in data-driven approaches to building\ndialog systems is the lack of high quality, goal-oriented conversational data.\nTo help satisfy this elementary requirement, we introduce the initial release\nof the Taskmaster-1 dataset which includes 13,215 task-based dialogs comprising\nsix domains. Two procedures were used to create this collection, each with\nunique advantages. The first involves a two-person, spoken \"Wizard of Oz\" (WOz)\napproach in which trained agents and crowdsourced workers interact to complete\nthe task while the second is \"self-dialog\" in which crowdsourced workers write\nthe entire dialog themselves. We do not restrict the workers to detailed\nscripts or to a small knowledge base and hence we observe that our dataset\ncontains more realistic and diverse conversations in comparison to existing\ndatasets. We offer several baseline models including state of the art neural\nseq2seq architectures with benchmark performance as well as qualitative human\nevaluations. Dialogs are labeled with API calls and arguments, a simple and\ncost effective approach which avoids the requirement of complex annotation\nschema. The layer of abstraction between the dialog model and the service\nprovider API allows for a given model to interact with multiple services that\nprovide similar functionally. Finally, the dataset will evoke interest in\nwritten vs. spoken language, discourse patterns, error handling and other\nlinguistic phenomena related to dialog system research, development and design.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 22:18:39 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Byrne", "Bill", ""], ["Krishnamoorthi", "Karthik", ""], ["Sankar", "Chinnadhurai", ""], ["Neelakantan", "Arvind", ""], ["Duckworth", "Daniel", ""], ["Yavuz", "Semih", ""], ["Goodrich", "Ben", ""], ["Dubey", "Amit", ""], ["Cedilnik", "Andy", ""], ["Kim", "Kyu-Young", ""]]}, {"id": "1909.05359", "submitter": "Vitor Beires Nogueira", "authors": "Paulo Quaresma, Vitor Beires Nogueira, Kashyap Raiyani, Roy Bayot, and\n  Teresa Gon\\c{c}alves", "title": "From Textual Information Sources to Linked Data in the Agatha Project", "comments": "Part of DECLARE 19 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic reasoning about textual information is a challenging task in modern\nNatural Language Processing (NLP) systems. In this work we describe our\nproposal for representing and reasoning about Portuguese documents by means of\nLinked Data like ontologies and thesauri. Our approach resorts to a specialized\npipeline of natural language processing (part-of-speech tagger, named entity\nrecognition, semantic role labeling) to populate an ontology for the domain of\ncriminal investigations. The provided architecture and ontology are language\nindependent. Although some of the NLP modules are language dependent, they can\nbe built using adequate AI methodologies.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 08:27:37 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Quaresma", "Paulo", ""], ["Nogueira", "Vitor Beires", ""], ["Raiyani", "Kashyap", ""], ["Bayot", "Roy", ""], ["Gon\u00e7alves", "Teresa", ""]]}, {"id": "1909.05360", "submitter": "Rujun Han", "authors": "Rujun Han, Qiang Ning, Nanyun Peng", "title": "Joint Event and Temporal Relation Extraction with Shared Representations\n  and Structured Prediction", "comments": "Published at EMNLP'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a joint event and temporal relation extraction model with shared\nrepresentation learning and structured prediction. The proposed method has two\nadvantages over existing work. First, it improves event representation by\nallowing the event and relation modules to share the same contextualized\nembeddings and neural representation learner. Second, it avoids error\npropagation in the conventional pipeline systems by leveraging structured\ninference and learning methods to assign both the event labels and the temporal\nrelation labels jointly. Experiments show that the proposed method can improve\nboth event extraction and temporal relation extraction over state-of-the-art\nsystems, with the end-to-end F1 improved by 10% and 6.8% on two benchmark\ndatasets respectively.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 18:00:43 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 22:23:33 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Han", "Rujun", ""], ["Ning", "Qiang", ""], ["Peng", "Nanyun", ""]]}, {"id": "1909.05361", "submitter": "Xiang Gao", "authors": "Xiang Gao, Yizhe Zhang, Sungjin Lee, Michel Galley, Chris Brockett,\n  Jianfeng Gao, Bill Dolan", "title": "Structuring Latent Spaces for Stylized Response Generation", "comments": "accepted to appear at EMNLP 2019 (long)", "journal-ref": "EMNLP 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating responses in a targeted style is a useful yet challenging task,\nespecially in the absence of parallel data. With limited data, existing methods\ntend to generate responses that are either less stylized or less\ncontext-relevant. We propose StyleFusion, which bridges conversation modeling\nand non-parallel style transfer by sharing a structured latent space. This\nstructure allows the system to generate stylized relevant responses by sampling\nin the neighborhood of the conversation model prediction, and continuously\ncontrol the style level. We demonstrate this method using dialogues from Reddit\ndata and two sets of sentences with distinct styles (arXiv and Sherlock Holmes\nnovels). Automatic and human evaluation show that, without sacrificing\nappropriateness, the system generates responses of the targeted style and\noutperforms competitive baselines.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 18:11:58 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Gao", "Xiang", ""], ["Zhang", "Yizhe", ""], ["Lee", "Sungjin", ""], ["Galley", "Michel", ""], ["Brockett", "Chris", ""], ["Gao", "Jianfeng", ""], ["Dolan", "Bill", ""]]}, {"id": "1909.05362", "submitter": "Mayank Sharma", "authors": "Prabhakar Gupta, Mayank Sharma, Kartik Pitale, Keshav Kumar", "title": "Problems with automating translation of movie/TV show subtitles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present 27 problems encountered in automating the translation of movie/TV\nshow subtitles. We categorize each problem in one of the three categories viz.\nproblems directly related to textual translation, problems related to subtitle\ncreation guidelines, and problems due to adaptability of machine translation\n(MT) engines. We also present the findings of a translation quality evaluation\nexperiment where we share the frequency of 16 key problems. We show that the\nsystems working at the frontiers of Natural Language Processing do not perform\nwell for subtitles and require some post-processing solutions for redressal of\nthese problems\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 06:45:51 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Gupta", "Prabhakar", ""], ["Sharma", "Mayank", ""], ["Pitale", "Kartik", ""], ["Kumar", "Keshav", ""]]}, {"id": "1909.05363", "submitter": "Armins Stepanjans", "authors": "Armins Stepanjans and Andr\\'e Freitas", "title": "Identifying and Explaining Discriminative Attributes", "comments": "EMNLP-IJCNLP 2019, source code available at\n  https://github.com/ab-10/hawk", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying what is at the center of the meaning of a word and what\ndiscriminates it from other words is a fundamental natural language inference\ntask. This paper describes an explicit word vector representation model (WVM)\nto support the identification of discriminative attributes. A core contribution\nof the paper is a quantitative and qualitative comparative analysis of\ndifferent types of data sources and Knowledge Bases in the construction of\nexplainable and explicit WVMs: (i) knowledge graphs built from dictionary\ndefinitions, (ii) entity-attribute-relationships graphs derived from images and\n(iii) commonsense knowledge graphs. Using a detailed quantitative and\nqualitative analysis, we demonstrate that these data sources have complementary\nsemantic aspects, supporting the creation of explicit semantic vector spaces.\nThe explicit vector spaces are evaluated using the task of discriminative\nattribute identification, showing comparable performance to the\nstate-of-the-art systems in the task (F1-score = 0.69), while delivering full\nmodel transparency and explainability.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 01:13:41 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Stepanjans", "Armins", ""], ["Freitas", "Andr\u00e9", ""]]}, {"id": "1909.05364", "submitter": "Wu Xing", "authors": "Xing Wu, Dongjun Wei, Liangjun Zang, Jizhong Han and Songlin Hu", "title": "TransSent: Towards Generation of Structured Sentences with Discourse\n  Marker", "comments": "5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured sentences are important expressions in human writings and\ndialogues. Previous works on neural text generation fused semantic and\nstructural information by encoding the entire sentence into a mixed hidden\nrepresentation. However, when a generated sentence becomes complicated, the\nstructure is difficult to be properly maintained. To alleviate this problem, we\nexplicitly separate the modeling process of semantic and structural\ninformation. Intuitively, humans generate structured sentences by directly\nconnecting discourses with discourse markers (such as and, but, etc.).\nTherefore, we propose a task that mimics this process, called discourse\ntransfer. This task represents a structured sentence as (head discourse,\ndiscourse marker, tail discourse), and aims at tail discourse generation based\non head discourse and discourse marker. We also propose a corresponding model\ncalled TransSent, which interprets the relationship between two discourses as a\ntranslation1 from the head discourse to the tail discourse in the embedding\nspace. We experiment TransSent not only in discourse transfer task but also in\nfree text generation and dialogue generation tasks. Automatic and human\nevaluation results show that TransSent can generate structured sentences with\nhigh quality, and has certain scalability in different tasks.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 14:03:35 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 17:05:52 GMT"}, {"version": "v3", "created": "Fri, 8 May 2020 10:44:23 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Wu", "Xing", ""], ["Wei", "Dongjun", ""], ["Zang", "Liangjun", ""], ["Han", "Jizhong", ""], ["Hu", "Songlin", ""]]}, {"id": "1909.05365", "submitter": "Mingyang Zhou", "authors": "Mingyang Zhou, Josh Arnold, Zhou Yu", "title": "Building Task-Oriented Visual Dialog Systems Through Alternative\n  Optimization Between Dialog Policy and Language Generation", "comments": "updated with acknowledgement and minor typo fixes on tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) is an effective approach to learn an optimal\ndialog policy for task-oriented visual dialog systems. A common practice is to\napply RL on a neural sequence-to-sequence (seq2seq) framework with the action\nspace being the output vocabulary in the decoder. However, it is difficult to\ndesign a reward function that can achieve a balance between learning an\neffective policy and generating a natural dialog response. This paper proposes\na novel framework that alternatively trains a RL policy for image guessing and\na supervised seq2seq model to improve dialog generation quality. We evaluate\nour framework on the GuessWhich task and the framework achieves the\nstate-of-the-art performance in both task completion and dialog quality.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 01:28:34 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 19:45:17 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Zhou", "Mingyang", ""], ["Arnold", "Josh", ""], ["Yu", "Zhou", ""]]}, {"id": "1909.05367", "submitter": "Giuseppe Marra", "authors": "Marco Maggini, Giuseppe Marra, Stefano Melacci, Andrea Zugarini", "title": "Learning in Text Streams: Discovery and Disambiguation of Entity and\n  Relation Instances", "comments": null, "journal-ref": null, "doi": "10.1109/TNNLS.2019.2955597", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a scenario where an artificial agent is reading a stream of text\ncomposed of a set of narrations, and it is informed about the identity of some\nof the individuals that are mentioned in the text portion that is currently\nbeing read. The agent is expected to learn to follow the narrations, thus\ndisambiguating mentions and discovering new individuals. We focus on the case\nin which individuals are entities and relations, and we propose an end-to-end\ntrainable memory network that learns to discover and disambiguate them in an\nonline manner, performing one-shot learning, and dealing with a small number of\nsparse supervisions. Our system builds a not-given-in-advance knowledge base,\nand it improves its skills while reading unsupervised text. The model deals\nwith abrupt changes in the narration, taking into account their effects when\nresolving co-references. We showcase the strong disambiguation and discovery\nskills of our model on a corpus of Wikipedia documents and on a newly\nintroduced dataset, that we make publicly available.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 15:01:07 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 09:55:41 GMT"}, {"version": "v3", "created": "Mon, 27 Apr 2020 18:07:20 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Maggini", "Marco", ""], ["Marra", "Giuseppe", ""], ["Melacci", "Stefano", ""], ["Zugarini", "Andrea", ""]]}, {"id": "1909.05370", "submitter": "Yun Zhao", "authors": "Yun Zhao", "title": "An Auxiliary Classifier Generative Adversarial Framework for Relation\n  Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relation extraction models suffer from limited qualified training data. Using\nhuman annotators to label sentences is too expensive and does not scale well\nespecially when dealing with large datasets. In this paper, we use Auxiliary\nClassifier Generative Adversarial Networks (AC-GANs) to generate high-quality\nrelational sentences and to improve the performance of relation classifier in\nend-to-end models. In AC-GAN, the discriminator gives not only a probability\ndistribution over the real source, but also a probability distribution over the\nrelation labels. This helps to generate meaningful relational sentences.\nExperimental results show that our proposed data augmentation method\nsignificantly improves the performance of relation extraction compared to\nstate-of-the-art methods\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 19:24:51 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Zhao", "Yun", ""]]}, {"id": "1909.05372", "submitter": "Christopher R\\'e", "authors": "Christopher R\\'e, Feng Niu, Pallavi Gudipati, Charles Srisuwananukorn", "title": "Overton: A Data System for Monitoring and Improving Machine-Learned\n  Products", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a system called Overton, whose main design goal is to support\nengineers in building, monitoring, and improving production machine learning\nsystems. Key challenges engineers face are monitoring fine-grained quality,\ndiagnosing errors in sophisticated applications, and handling contradictory or\nincomplete supervision data. Overton automates the life cycle of model\nconstruction, deployment, and monitoring by providing a set of novel\nhigh-level, declarative abstractions. Overton's vision is to shift developers\nto these higher-level tasks instead of lower-level machine learning tasks. In\nfact, using Overton, engineers can build deep-learning-based applications\nwithout writing any code in frameworks like TensorFlow. For over a year,\nOverton has been used in production to support multiple applications in both\nnear-real-time applications and back-of-house processing. In that time,\nOverton-based applications have answered billions of queries in multiple\nlanguages and processed trillions of records reducing errors 1.7-2.9 times\nversus production systems.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 03:51:13 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["R\u00e9", "Christopher", ""], ["Niu", "Feng", ""], ["Gudipati", "Pallavi", ""], ["Srisuwananukorn", "Charles", ""]]}, {"id": "1909.05378", "submitter": "Tao Yu", "authors": "Tao Yu, Rui Zhang, He Yang Er, Suyi Li, Eric Xue, Bo Pang, Xi Victoria\n  Lin, Yi Chern Tan, Tianze Shi, Zihan Li, Youxuan Jiang, Michihiro Yasunaga,\n  Sungrok Shim, Tao Chen, Alexander Fabbri, Zifan Li, Luyao Chen, Yuwen Zhang,\n  Shreya Dixit, Vincent Zhang, Caiming Xiong, Richard Socher, Walter S Lasecki,\n  Dragomir Radev", "title": "CoSQL: A Conversational Text-to-SQL Challenge Towards Cross-Domain\n  Natural Language Interfaces to Databases", "comments": "Accepted to EMNLP 2019, long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present CoSQL, a corpus for building cross-domain, general-purpose\ndatabase (DB) querying dialogue systems. It consists of 30k+ turns plus 10k+\nannotated SQL queries, obtained from a Wizard-of-Oz (WOZ) collection of 3k\ndialogues querying 200 complex DBs spanning 138 domains. Each dialogue\nsimulates a real-world DB query scenario with a crowd worker as a user\nexploring the DB and a SQL expert retrieving answers with SQL, clarifying\nambiguous questions, or otherwise informing of unanswerable questions. When\nuser questions are answerable by SQL, the expert describes the SQL and\nexecution results to the user, hence maintaining a natural interaction flow.\nCoSQL introduces new challenges compared to existing task-oriented dialogue\ndatasets:(1) the dialogue states are grounded in SQL, a domain-independent\nexecutable representation, instead of domain-specific slot-value pairs, and (2)\nbecause testing is done on unseen databases, success requires generalizing to\nnew domains. CoSQL includes three tasks: SQL-grounded dialogue state tracking,\nresponse generation from query results, and user dialogue act prediction. We\nevaluate a set of strong baselines for each task and show that CoSQL presents\nsignificant challenges for future research. The dataset, baselines, and\nleaderboard will be released at https://yale-lily.github.io/cosql.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 21:15:47 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Yu", "Tao", ""], ["Zhang", "Rui", ""], ["Er", "He Yang", ""], ["Li", "Suyi", ""], ["Xue", "Eric", ""], ["Pang", "Bo", ""], ["Lin", "Xi Victoria", ""], ["Tan", "Yi Chern", ""], ["Shi", "Tianze", ""], ["Li", "Zihan", ""], ["Jiang", "Youxuan", ""], ["Yasunaga", "Michihiro", ""], ["Shim", "Sungrok", ""], ["Chen", "Tao", ""], ["Fabbri", "Alexander", ""], ["Li", "Zifan", ""], ["Chen", "Luyao", ""], ["Zhang", "Yuwen", ""], ["Dixit", "Shreya", ""], ["Zhang", "Vincent", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""], ["Lasecki", "Walter S", ""], ["Radev", "Dragomir", ""]]}, {"id": "1909.05398", "submitter": "Matthew Hausknecht", "authors": "Matthew Hausknecht, Prithviraj Ammanabrolu, Marc-Alexandre C\\^ot\\'e,\n  Xingdi Yuan", "title": "Interactive Fiction Games: A Colossal Adventure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A hallmark of human intelligence is the ability to understand and communicate\nwith language. Interactive Fiction games are fully text-based simulation\nenvironments where a player issues text commands to effect change in the\nenvironment and progress through the story. We argue that IF games are an\nexcellent testbed for studying language-based autonomous agents. In particular,\nIF games combine challenges of combinatorial action spaces, language\nunderstanding, and commonsense reasoning. To facilitate rapid development of\nlanguage-based agents, we introduce Jericho, a learning environment for\nman-made IF games and conduct a comprehensive study of text-agents across a\nrich set of games, highlighting directions in which agents can improve.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 22:41:00 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 18:59:52 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2020 19:36:33 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Hausknecht", "Matthew", ""], ["Ammanabrolu", "Prithviraj", ""], ["C\u00f4t\u00e9", "Marc-Alexandre", ""], ["Yuan", "Xingdi", ""]]}, {"id": "1909.05421", "submitter": "Renjie Zheng", "authors": "Renjie Zheng, Mingbo Ma, Baigong Zheng, Liang Huang", "title": "Speculative Beam Search for Simultaneous Translation", "comments": "accepted by EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Beam search is universally used in full-sentence translation but its\napplication to simultaneous translation remains non-trivial, where output words\nare committed on the fly. In particular, the recently proposed wait-k policy\n(Ma et al., 2019a) is a simple and effective method that (after an initial\nwait) commits one output word on receiving each input word, making beam search\nseemingly impossible. To address this challenge, we propose a speculative beam\nsearch algorithm that hallucinates several steps into the future in order to\nreach a more accurate decision, implicitly benefiting from a target language\nmodel. This makes beam search applicable for the first time to the generation\nof a single word in each step. Experiments over diverse language pairs show\nlarge improvements over previous work.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 01:00:59 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Zheng", "Renjie", ""], ["Ma", "Mingbo", ""], ["Zheng", "Baigong", ""], ["Huang", "Liang", ""]]}, {"id": "1909.05424", "submitter": "Changhan Wang", "authors": "Changhan Wang, Anirudh Jain, Danlu Chen, Jiatao Gu", "title": "VizSeq: A Visual Analysis Toolkit for Text Generation Tasks", "comments": null, "journal-ref": null, "doi": "10.18653/v1/D19-3043", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic evaluation of text generation tasks (e.g. machine translation, text\nsummarization, image captioning and video description) usually relies heavily\non task-specific metrics, such as BLEU and ROUGE. They, however, are abstract\nnumbers and are not perfectly aligned with human assessment. This suggests\ninspecting detailed examples as a complement to identify system error patterns.\nIn this paper, we present VizSeq, a visual analysis toolkit for instance-level\nand corpus-level system evaluation on a wide variety of text generation tasks.\nIt supports multimodal sources and multiple text references, providing\nvisualization in Jupyter notebook or a web app interface. It can be used\nlocally or deployed onto public servers for centralized data hosting and\nbenchmarking. It covers most common n-gram based metrics accelerated with\nmultiprocessing, and also provides latest embedding-based metrics such as\nBERTScore.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 01:16:27 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Wang", "Changhan", ""], ["Jain", "Anirudh", ""], ["Chen", "Danlu", ""], ["Gu", "Jiatao", ""]]}, {"id": "1909.05438", "submitter": "Yibo Sun", "authors": "Yibo Sun, Duyu Tang, Nan Duan, Yeyun Gong, Xiaocheng Feng, Bing Qin,\n  Daxin Jiang", "title": "Neural Semantic Parsing in Low-Resource Settings with Back-Translation\n  and Meta-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural semantic parsing has achieved impressive results in recent years, yet\nits success relies on the availability of large amounts of supervised data. Our\ngoal is to learn a neural semantic parser when only prior knowledge about a\nlimited number of simple rules is available, without access to either annotated\nprograms or execution results. Our approach is initialized by rules, and\nimproved in a back-translation paradigm using generated question-program pairs\nfrom the semantic parser and the question generator. A phrase table with\nfrequent mapping patterns is automatically derived, also updated as training\nprogresses, to measure the quality of generated instances. We train the model\nwith model-agnostic meta-learning to guarantee the accuracy and stability on\nexamples covered by rules, and meanwhile acquire the versatility to generalize\nwell on examples uncovered by rules. Results on three benchmark datasets with\ndifferent domains and programs show that our approach incrementally improves\nthe accuracy. On WikiSQL, our best model is comparable to the SOTA system\nlearned from denotations.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 02:47:47 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Sun", "Yibo", ""], ["Tang", "Duyu", ""], ["Duan", "Nan", ""], ["Gong", "Yeyun", ""], ["Feng", "Xiaocheng", ""], ["Qin", "Bing", ""], ["Jiang", "Daxin", ""]]}, {"id": "1909.05448", "submitter": "Junfan Chen", "authors": "Junfan Chen, Richong Zhang, Yongyi Mao, Hongyu Guo, Jie Xu", "title": "Uncover the Ground-Truth Relations in Distant Supervision: A Neural\n  Expectation-Maximization Framework", "comments": "To appear in 2019 Conference on Empirical Methods in Natural Language\n  Processing and 9th International Joint Conference on Natural Language\n  Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distant supervision for relation extraction enables one to effectively\nacquire structured relations out of very large text corpora with less human\nefforts. Nevertheless, most of the prior-art models for such tasks assume that\nthe given text can be noisy, but their corresponding labels are clean. Such\nunrealistic assumption is contradictory with the fact that the given labels are\noften noisy as well, thus leading to significant performance degradation of\nthose models on real-world data. To cope with this challenge, we propose a\nnovel label-denoising framework that combines neural network with probabilistic\nmodelling, which naturally takes into account the noisy labels during learning.\nWe empirically demonstrate that our approach significantly improves the current\nart in uncovering the ground-truth relation labels.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 04:20:51 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Chen", "Junfan", ""], ["Zhang", "Richong", ""], ["Mao", "Yongyi", ""], ["Guo", "Hongyu", ""], ["Xu", "Jie", ""]]}, {"id": "1909.05449", "submitter": "Chen Xia", "authors": "Chen Xia, Haoxiang Zhang, Jacob Moghtader, Allen Wu, Kai-Wei Chang", "title": "Visualizing Trends of Key Roles in News Articles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are tons of news articles generated every day reflecting the activities\nof key roles such as people, organizations and political parties. Analyzing\nthese key roles allows us to understand the trends in news. In this paper, we\npresent a demonstration system that visualizes the trend of key roles in news\narticles based on natural language processing techniques. Specifically, we\napply a semantic role labeler and the dynamic word embedding technique to\nunderstand relationships between key roles in the news across different time\nperiods and visualize the trends of key role and news topics change over time.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 04:21:41 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Xia", "Chen", ""], ["Zhang", "Haoxiang", ""], ["Moghtader", "Jacob", ""], ["Wu", "Allen", ""], ["Chang", "Kai-Wei", ""]]}, {"id": "1909.05478", "submitter": "Muhammad Nabeel Asim", "authors": "Muhammad Nabeel Asim, Muhammad Usman Ghani Khan, Muhammad Imran Malik,\n  Andreas Dengel, Sheraz Ahmed", "title": "A Robust Hybrid Approach for Textual Document Classification", "comments": "ICDAR Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text document classification is an important task for diverse natural\nlanguage processing based applications. Traditional machine learning approaches\nmainly focused on reducing dimensionality of textual data to perform\nclassification. This although improved the overall classification accuracy, the\nclassifiers still faced sparsity problem due to lack of better data\nrepresentation techniques. Deep learning based text document classification, on\nthe other hand, benefitted greatly from the invention of word embeddings that\nhave solved the sparsity problem and researchers focus mainly remained on the\ndevelopment of deep architectures. Deeper architectures, however, learn some\nredundant features that limit the performance of deep learning based solutions.\nIn this paper, we propose a two stage text document classification methodology\nwhich combines traditional feature engineering with automatic feature\nengineering (using deep learning). The proposed methodology comprises a filter\nbased feature selection (FSE) algorithm followed by a deep convolutional neural\nnetwork. This methodology is evaluated on the two most commonly used public\ndatasets, i.e., 20 Newsgroups data and BBC news data. Evaluation results reveal\nthat the proposed methodology outperforms the state-of-the-art of both the\n(traditional) machine learning and deep learning based text document\nclassification methodologies with a significant margin of 7.7% on 20 Newsgroups\nand 6.6% on BBC news datasets.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 06:39:07 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Asim", "Muhammad Nabeel", ""], ["Khan", "Muhammad Usman Ghani", ""], ["Malik", "Muhammad Imran", ""], ["Dengel", "Andreas", ""], ["Ahmed", "Sheraz", ""]]}, {"id": "1909.05504", "submitter": "Christoph Stanik", "authors": "Christoph Stanik, Marlo Haering and Walid Maalej", "title": "Classifying Multilingual User Feedback using Traditional Machine\n  Learning and Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rise of social media like Twitter and of software distribution\nplatforms like app stores, users got various ways to express their opinion\nabout software products. Popular software vendors get user feedback\nthousandfold per day. Research has shown that such feedback contains valuable\ninformation for software development teams such as problem reports or feature\nand support inquires. Since the manual analysis of user feedback is cumbersome\nand hard to manage many researchers and tool vendors suggested to use automated\nanalyses based on traditional supervised machine learning approaches. In this\nwork, we compare the results of traditional machine learning and deep learning\nin classifying user feedback in English and Italian into problem reports,\ninquiries, and irrelevant. Our results show that using traditional machine\nlearning, we can still achieve comparable results to deep learning, although we\ncollected thousands of labels.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 08:35:54 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Stanik", "Christoph", ""], ["Haering", "Marlo", ""], ["Maalej", "Walid", ""]]}, {"id": "1909.05528", "submitter": "Youzhi Tian", "authors": "Weixin Liang, Youzhi Tian, Chengcai Chen, Zhou Yu", "title": "MOSS: End-to-End Dialog System Framework with Modular Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major bottleneck in training end-to-end task-oriented dialog system is the\nlack of data. To utilize limited training data more efficiently, we propose\nModular Supervision Network (MOSS), an encoder-decoder training framework that\ncould incorporate supervision from various intermediate dialog system modules\nincluding natural language understanding, dialog state tracking, dialog policy\nlearning, and natural language generation. With only 60% of the training data,\nMOSS-all (i.e., MOSS with supervision from all four dialog modules) outperforms\nstate-of-the-art models on CamRest676. Moreover, introducing modular\nsupervision has even bigger benefits when the dialog task has a more complex\ndialog state and action space. With only 40% of the training data, MOSS-all\noutperforms the state-of-the-art model on a complex laptop network\ntroubleshooting dataset, LaptopNetwork, that we introduced. LaptopNetwork\nconsists of conversations between real customers and customer service agents in\nChinese. Moreover, MOSS framework can accommodate dialogs that have supervision\nfrom different dialog modules at both the framework level and model level.\nTherefore, MOSS is extremely flexible to update in a real-world deployment.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 09:27:37 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Liang", "Weixin", ""], ["Tian", "Youzhi", ""], ["Chen", "Chengcai", ""], ["Yu", "Zhou", ""]]}, {"id": "1909.05553", "submitter": "Milan Straka", "authors": "Jakub N\\'aplava, Milan Straka", "title": "CUNI System for the Building Educational Applications 2019 Shared Task:\n  Grammatical Error Correction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe our systems submitted to the Building Educational\nApplications (BEA) 2019 Shared Task (Bryant et al., 2019). We participated in\nall three tracks. Our models are NMT systems based on the Transformer model,\nwhich we improve by incorporating several enhancements: applying dropout to\nwhole source and target words, weighting target subwords, averaging model\ncheckpoints, and using the trained model iteratively for correcting the\nintermediate translations. The system in the Restricted Track is trained on the\nprovided corpora with oversampled \"cleaner\" sentences and reaches 59.39 F0.5\nscore on the test set. The system in the Low-Resource Track is trained from\nWikipedia revision histories and reaches 44.13 F0.5 score. Finally, we finetune\nthe system from the Low-Resource Track on restricted data and achieve 64.55\nF0.5 score, placing third in the Unrestricted Track.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 10:31:25 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["N\u00e1plava", "Jakub", ""], ["Straka", "Milan", ""]]}, {"id": "1909.05608", "submitter": "Daniel Korat", "authors": "Oren Pereg, Daniel Korat, Moshe Wasserblat, Jonathan Mamou, Ido Dagan", "title": "ABSApp: A Portable Weakly-Supervised Aspect-Based Sentiment Extraction\n  System", "comments": "6 pages, demo paper at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ABSApp, a portable system for weakly-supervised aspect-based\nsentiment extraction. The system is interpretable and user friendly and does\nnot require labeled training data, hence can be rapidly and cost-effectively\nused across different domains in applied setups. The system flow includes three\nstages: First, it generates domain-specific aspect and opinion lexicons based\non an unlabeled dataset; second, it enables the user to view and edit those\nlexicons (weak supervision); and finally, it enables the user to select an\nunlabeled target dataset from the same domain, classify it, and generate an\naspect-based sentiment report. ABSApp has been successfully used in a number of\nreal-life use cases, among them movie review analysis and convention impact\nanalysis.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 12:50:34 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Pereg", "Oren", ""], ["Korat", "Daniel", ""], ["Wasserblat", "Moshe", ""], ["Mamou", "Jonathan", ""], ["Dagan", "Ido", ""]]}, {"id": "1909.05639", "submitter": "Dafydd Gibbon", "authors": "Dafydd Gibbon, Peng Li", "title": "Quantifying and Correlating Rhythm Formants in Speech", "comments": "6 pagers, 7 figures, 2 tables, accepted: LPSS (Linguistic Properties\n  of Spontaneous Speech, Taipei 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of the present study is exploratory: to introduce and apply a\nnew theory of speech rhythm zones or rhythm formants (R-formants). R-formants\nare zones of high magnitude frequencies in the low frequency (LF) long-term\nspectrum (LTS), rather like formants in the short-term spectra of vowels and\nconsonants. After an illustration of the method, an R-formant analysis is made\nof non-elicited extracts from public speeches. The LF-LTS of three domains, the\namplitude modulated (AM) absolute (rectified) signal, the amplitude envelope\nmodulation (AEM) and frequency modulation (FM, F0, 'pitch') of the signal are\ncompared. The first two correlate well, but the third does not correlate\nconsistently with the other two, presumably due to variability of tone, pitch\naccent and intonation. Consequently, only the LF LTS of the absolute speech\nsignal is used in the empirical analysis. An informal discussion of the\nrelation between R-formant patterns and utterance structure and a selection of\npragmatic variables over the same utterances showed some trends for R-formant\nfunctionality and thus useful directions for future research.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 16:18:34 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Gibbon", "Dafydd", ""], ["Li", "Peng", ""]]}, {"id": "1909.05645", "submitter": "Haiyang Xu", "authors": "Haiyang Xu, Hui Zhang, Kun Han, Yun Wang, Yiping Peng, Xiangang Li", "title": "Learning Alignment for Multimodal Emotion Recognition from Speech", "comments": "InterSpeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech emotion recognition is a challenging problem because human convey\nemotions in subtle and complex ways. For emotion recognition on human speech,\none can either extract emotion related features from audio signals or employ\nspeech recognition techniques to generate text from speech and then apply\nnatural language processing to analyze the sentiment. Further, emotion\nrecognition will be beneficial from using audio-textual multimodal information,\nit is not trivial to build a system to learn from multimodality. One can build\nmodels for two input sources separately and combine them in a decision level,\nbut this method ignores the interaction between speech and text in the temporal\ndomain. In this paper, we propose to use an attention mechanism to learn the\nalignment between speech frames and text words, aiming to produce more accurate\nmultimodal feature representations. The aligned multimodal features are fed\ninto a sequential model for emotion recognition. We evaluate the approach on\nthe IEMOCAP dataset and the experimental results show the proposed approach\nachieves the state-of-the-art performance on the dataset.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 03:06:38 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 03:08:30 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Xu", "Haiyang", ""], ["Zhang", "Hui", ""], ["Han", "Kun", ""], ["Wang", "Yun", ""], ["Peng", "Yiping", ""], ["Li", "Xiangang", ""]]}, {"id": "1909.05658", "submitter": "Zhe Zhao", "authors": "Zhe Zhao and Hui Chen and Jinbin Zhang and Xin Zhao and Tao Liu and\n  Wei Lu and Xi Chen and Haotang Deng and Qi Ju and Xiaoyong Du", "title": "UER: An Open-Source Toolkit for Pre-training Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing works, including ELMO and BERT, have revealed the importance of\npre-training for NLP tasks. While there does not exist a single pre-training\nmodel that works best in all cases, it is of necessity to develop a framework\nthat is able to deploy various pre-training models efficiently. For this\npurpose, we propose an assemble-on-demand pre-training toolkit, namely\nUniversal Encoder Representations (UER). UER is loosely coupled, and\nencapsulated with rich modules. By assembling modules on demand, users can\neither reproduce a state-of-the-art pre-training model or develop a\npre-training model that remains unexplored. With UER, we have built a model\nzoo, which contains pre-trained models based on different corpora, encoders,\nand targets (objectives). With proper pre-trained models, we could achieve new\nstate-of-the-art results on a range of downstream datasets.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 13:46:58 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Zhao", "Zhe", ""], ["Chen", "Hui", ""], ["Zhang", "Jinbin", ""], ["Zhao", "Xin", ""], ["Liu", "Tao", ""], ["Lu", "Wei", ""], ["Chen", "Xi", ""], ["Deng", "Haotang", ""], ["Ju", "Qi", ""], ["Du", "Xiaoyong", ""]]}, {"id": "1909.05708", "submitter": "Yova Kementchedjhieva", "authors": "Yova Kementchedjhieva, Mareike Hartmann and Anders S{\\o}gaard", "title": "Lost in Evaluation: Misleading Benchmarks for Bilingual Dictionary\n  Induction", "comments": "Accepted at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of bilingual dictionary induction (BDI) is commonly used for\nintrinsic evaluation of cross-lingual word embeddings. The largest dataset for\nBDI was generated automatically, so its quality is dubious. We study the\ncomposition and quality of the test sets for five diverse languages from this\ndataset, with concerning findings: (1) a quarter of the data consists of proper\nnouns, which can be hardly indicative of BDI performance, and (2) there are\npervasive gaps in the gold-standard targets. These issues appear to affect the\nranking between cross-lingual embedding systems on individual languages, and\nthe overall degree to which the systems differ in performance. With proper\nnouns removed from the data, the margin between the top two systems included in\nthe study grows from 3.4% to 17.2%. Manual verification of the predictions, on\nthe other hand, reveals that gaps in the gold standard targets artificially\ninflate the margin between the two systems on English to Bulgarian BDI from\n0.1% to 6.7%. We thus suggest that future research either avoids drawing\nconclusions from quantitative results on this BDI dataset, or accompanies such\nevaluation with rigorous error analysis.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 14:21:54 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 11:11:00 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Kementchedjhieva", "Yova", ""], ["Hartmann", "Mareike", ""], ["S\u00f8gaard", "Anders", ""]]}, {"id": "1909.05725", "submitter": "Ting-Hao Huang", "authors": "Ting-Hao 'Kenneth' Huang, Amos Azaria, Oscar J. Romero, Jeffrey P.\n  Bigham", "title": "InstructableCrowd: Creating IF-THEN Rules for Smartphones via\n  Conversations with the Crowd", "comments": "Published at Human Computation (2019) 6:1:113-146", "journal-ref": "Human Computation (2019) 6:1:113-146", "doi": "10.15346/hc.v6i1.7", "report-no": null, "categories": "cs.HC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language interfaces have become a common part of modern digital life.\nChatbots utilize text-based conversations to communicate with users; personal\nassistants on smartphones such as Google Assistant take direct speech commands\nfrom their users; and speech-controlled devices such as Amazon Echo use voice\nas their only input mode. In this paper, we introduce InstructableCrowd, a\ncrowd-powered system that allows users to program their devices via\nconversation. The user verbally expresses a problem to the system, in which a\ngroup of crowd workers collectively respond and program relevant multi-part\nIF-THEN rules to help the user. The IF-THEN rules generated by\nInstructableCrowd connect relevant sensor combinations (e.g., location,\nweather, device acceleration, etc.) to useful effectors (e.g., text messages,\ndevice alarms, etc.). Our study showed that non-programmers can use the\nconversational interface of InstructableCrowd to create IF-THEN rules that have\nsimilar quality compared with the rules created manually. InstructableCrowd\ngenerally illustrates how users may converse with their devices, not only to\ntrigger simple voice commands, but also to personalize their increasingly\npowerful and complicated devices.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 14:43:38 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Huang", "Ting-Hao 'Kenneth'", ""], ["Azaria", "Amos", ""], ["Romero", "Oscar J.", ""], ["Bigham", "Jeffrey P.", ""]]}, {"id": "1909.05780", "submitter": "Yasumasa Onoe", "authors": "Yasumasa Onoe, Greg Durrett", "title": "Fine-Grained Entity Typing for Domain Independent Entity Linking", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural entity linking models are very powerful, but run the risk of\noverfitting to the domain they are trained in. For this problem, a domain is\ncharacterized not just by genre of text but even by factors as specific as the\nparticular distribution of entities, as neural models tend to overfit by\nmemorizing properties of frequent entities in a dataset. We tackle the problem\nof building robust entity linking models that generalize effectively and do not\nrely on labeled entity linking data with a specific entity distribution. Rather\nthan predicting entities directly, our approach models fine-grained entity\nproperties, which can help disambiguate between even closely related entities.\nWe derive a large inventory of types (tens of thousands) from Wikipedia\ncategories, and use hyperlinked mentions in Wikipedia to distantly label data\nand train an entity typing model. At test time, we classify a mention with this\ntyping model and use soft type predictions to link the mention to the most\nsimilar candidate entity. We evaluate our entity linking system on the\nCoNLL-YAGO dataset (Hoffart et al., 2011) and show that our approach\noutperforms prior domain-independent entity linking systems. We also test our\napproach in a harder setting derived from the WikilinksNED dataset (Eshel et\nal., 2017) where all the mention-entity pairs are unseen during test time.\nResults indicate that our approach generalizes better than a state-of-the-art\nneural model on the dataset.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 16:29:24 GMT"}, {"version": "v2", "created": "Wed, 8 Jan 2020 17:50:10 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Onoe", "Yasumasa", ""], ["Durrett", "Greg", ""]]}, {"id": "1909.05803", "submitter": "Yichen Jiang", "authors": "Yichen Jiang, Mohit Bansal", "title": "Self-Assembling Modular Networks for Interpretable Multi-Hop Reasoning", "comments": "11 pages (EMNLP 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-hop QA requires a model to connect multiple pieces of evidence\nscattered in a long context to answer the question. The recently proposed\nHotpotQA (Yang et al., 2018) dataset is comprised of questions embodying four\ndifferent multi-hop reasoning paradigms (two bridge entity setups, checking\nmultiple properties, and comparing two entities), making it challenging for a\nsingle neural network to handle all four. In this work, we present an\ninterpretable, controller-based Self-Assembling Neural Modular Network (Hu et\nal., 2017, 2018) for multi-hop reasoning, where we design four novel modules\n(Find, Relocate, Compare, NoOp) to perform unique types of language reasoning.\nBased on a question, our layout controller RNN dynamically infers a series of\nreasoning modules to construct the entire network. Empirically, we show that\nour dynamic, multi-hop modular network achieves significant improvements over\nthe static, single-hop baseline (on both regular and adversarial evaluation).\nWe further demonstrate the interpretability of our model via three analyses.\nFirst, the controller can softly decompose the multi-hop question into multiple\nsingle-hop sub-questions to promote compositional reasoning behavior of the\nmain network. Second, the controller can predict layouts that conform to the\nlayouts designed by human experts. Finally, the intermediate module can infer\nthe entity that connects two distantly-located supporting facts by addressing\nthe sub-question from the controller.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 17:00:45 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 21:11:19 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Jiang", "Yichen", ""], ["Bansal", "Mohit", ""]]}, {"id": "1909.05819", "submitter": "Danushka Bollegala", "authors": "Danushka Bollegala, Tomoya Machide, Ken-ichi Kawarabayashi", "title": "Anonymising Queries by Semantic Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Protecting the privacy of search engine users is an important requirement in\nmany information retrieval scenarios. A user might not want a search engine to\nguess his or her information need despite requesting relevant results. We\npropose a method to protect the privacy of search engine users by decomposing\nthe queries using semantically \\emph{related} and unrelated \\emph{distractor}\nterms. Instead of a single query, the search engine receives multiple\ndecomposed query terms. Next, we reconstruct the search results relevant to the\noriginal query term by aggregating the search results retrieved for the\ndecomposed query terms. We show that the word embeddings learnt using a\ndistributed representation learning method can be used to find semantically\nrelated and distractor query terms. We derive the relationship between the\n\\emph{anonymity} achieved through the proposed query anonymisation method and\nthe \\emph{reconstructability} of the original search results using the\ndecomposed queries. We analytically study the risk of discovering the search\nengine users' information intents under the proposed query anonymisation\nmethod, and empirically evaluate its robustness against clustering-based\nattacks. Our experimental results show that the proposed method can accurately\nreconstruct the search results for user queries, without compromising the\nprivacy of the search engine users.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 17:27:46 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Bollegala", "Danushka", ""], ["Machide", "Tomoya", ""], ["Kawarabayashi", "Ken-ichi", ""]]}, {"id": "1909.05840", "submitter": "Amir Gholami", "authors": "Sheng Shen and Zhen Dong and Jiayu Ye and Linjian Ma and Zhewei Yao\n  and Amir Gholami and Michael W. Mahoney and Kurt Keutzer", "title": "Q-BERT: Hessian Based Ultra Low Precision Quantization of BERT", "comments": null, "journal-ref": "AAAI 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer based architectures have become de-facto models used for a range\nof Natural Language Processing tasks. In particular, the BERT based models\nachieved significant accuracy gain for GLUE tasks, CoNLL-03 and SQuAD. However,\nBERT based models have a prohibitive memory footprint and latency. As a result,\ndeploying BERT based models in resource constrained environments has become a\nchallenging task. In this work, we perform an extensive analysis of fine-tuned\nBERT models using second order Hessian information, and we use our results to\npropose a novel method for quantizing BERT models to ultra low precision. In\nparticular, we propose a new group-wise quantization scheme, and we use a\nHessian based mix-precision method to compress the model further. We\nextensively test our proposed method on BERT downstream tasks of SST-2, MNLI,\nCoNLL-03, and SQuAD. We can achieve comparable performance to baseline with at\nmost $2.3\\%$ performance degradation, even with ultra-low precision\nquantization down to 2 bits, corresponding up to $13\\times$ compression of the\nmodel parameters, and up to $4\\times$ compression of the embedding table as\nwell as activations. Among all tasks, we observed the highest performance loss\nfor BERT fine-tuned on SQuAD. By probing into the Hessian based analysis as\nwell as visualization, we show that this is related to the fact that current\ntraining/fine-tuning strategy of BERT does not converge for SQuAD.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 17:45:59 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 00:13:30 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Shen", "Sheng", ""], ["Dong", "Zhen", ""], ["Ye", "Jiayu", ""], ["Ma", "Linjian", ""], ["Yao", "Zhewei", ""], ["Gholami", "Amir", ""], ["Mahoney", "Michael W.", ""], ["Keutzer", "Kurt", ""]]}, {"id": "1909.05855", "submitter": "Srinivas Sunkara", "authors": "Abhinav Rastogi, Xiaoxue Zang, Srinivas Sunkara, Raghav Gupta, Pranav\n  Khaitan", "title": "Towards Scalable Multi-domain Conversational Agents: The Schema-Guided\n  Dialogue Dataset", "comments": "To appear at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Virtual assistants such as Google Assistant, Alexa and Siri provide a\nconversational interface to a large number of services and APIs spanning\nmultiple domains. Such systems need to support an ever-increasing number of\nservices with possibly overlapping functionality. Furthermore, some of these\nservices have little to no training data available. Existing public datasets\nfor task-oriented dialogue do not sufficiently capture these challenges since\nthey cover few domains and assume a single static ontology per domain. In this\nwork, we introduce the the Schema-Guided Dialogue (SGD) dataset, containing\nover 16k multi-domain conversations spanning 16 domains. Our dataset exceeds\nthe existing task-oriented dialogue corpora in scale, while also highlighting\nthe challenges associated with building large-scale virtual assistants. It\nprovides a challenging testbed for a number of tasks including language\nunderstanding, slot filling, dialogue state tracking and response generation.\nAlong the same lines, we present a schema-guided paradigm for task-oriented\ndialogue, in which predictions are made over a dynamic set of intents and\nslots, provided as input, using their natural language descriptions. This\nallows a single dialogue system to easily support a large number of services\nand facilitates simple integration of new services without requiring additional\ntraining data. Building upon the proposed paradigm, we release a model for\ndialogue state tracking capable of zero-shot generalization to new APIs, while\nremaining competitive in the regular setting.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 17:57:57 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 18:57:49 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Rastogi", "Abhinav", ""], ["Zang", "Xiaoxue", ""], ["Sunkara", "Srinivas", ""], ["Gupta", "Raghav", ""], ["Khaitan", "Pranav", ""]]}, {"id": "1909.05858", "submitter": "Bryan McCann", "authors": "Nitish Shirish Keskar, Bryan McCann, Lav R. Varshney, Caiming Xiong,\n  Richard Socher", "title": "CTRL: A Conditional Transformer Language Model for Controllable\n  Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale language models show promising text generation capabilities, but\nusers cannot easily control particular aspects of the generated text. We\nrelease CTRL, a 1.63 billion-parameter conditional transformer language model,\ntrained to condition on control codes that govern style, content, and\ntask-specific behavior. Control codes were derived from structure that\nnaturally co-occurs with raw text, preserving the advantages of unsupervised\nlearning while providing more explicit control over text generation. These\ncodes also allow CTRL to predict which parts of the training data are most\nlikely given a sequence. This provides a potential method for analyzing large\namounts of data via model-based source attribution. We have released multiple\nfull-sized, pretrained versions of CTRL at https://github.com/salesforce/ctrl.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 17:57:18 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2019 20:08:56 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Keskar", "Nitish Shirish", ""], ["McCann", "Bryan", ""], ["Varshney", "Lav R.", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "1909.05863", "submitter": "Ethan Perez", "authors": "Ethan Perez, Siddharth Karamcheti, Rob Fergus, Jason Weston, Douwe\n  Kiela, Kyunghyun Cho", "title": "Finding Generalizable Evidence by Learning to Convince Q&A Models", "comments": "EMNLP 2019. Code available at https://github.com/ethanjperez/convince", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a system that finds the strongest supporting evidence for a given\nanswer to a question, using passage-based question-answering (QA) as a testbed.\nWe train evidence agents to select the passage sentences that most convince a\npretrained QA model of a given answer, if the QA model received those sentences\ninstead of the full passage. Rather than finding evidence that convinces one\nmodel alone, we find that agents select evidence that generalizes; agent-chosen\nevidence increases the plausibility of the supported answer, as judged by other\nQA models and humans. Given its general nature, this approach improves QA in a\nrobust manner: using agent-selected evidence (i) humans can correctly answer\nquestions with only ~20% of the full passage and (ii) QA models can generalize\nto longer passages and harder questions.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 18:00:00 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Perez", "Ethan", ""], ["Karamcheti", "Siddharth", ""], ["Fergus", "Rob", ""], ["Weston", "Jason", ""], ["Kiela", "Douwe", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1909.05882", "submitter": "Juan Sebasti\\'an G\\'omez Ca\\~n\\'on", "authors": "Juan Sebasti\\'an G\\'omez Ca\\~n\\'on and Perfecto Herrera and Emilia\n  G\\'omez and Estefan\\'ia Cano", "title": "The emotions that we perceive in music: the influence of language and\n  lyrics comprehension on agreement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the present study, we address the relationship between the emotions\nperceived in pop and rock music (mainly in Euro-American styles with English\nlyrics) and the language spoken by the listener. Our goal is to understand the\ninfluence of lyrics comprehension on the perception of emotions and use this\ninformation to improve Music Emotion Recognition (MER) models. Two main\nresearch questions are addressed: 1. Are there differences and similarities\nbetween the emotions perceived in pop/rock music by listeners raised with\ndifferent mother tongues? 2. Do personal characteristics have an influence on\nthe perceived emotions for listeners of a given language? Personal\ncharacteristics include the listeners' general demographics, familiarity and\npreference for the fragments, and music sophistication. Our hypothesis is that\ninter-rater agreement (as defined by Krippendorff's alpha coefficient) from\nsubjects is directly influenced by the comprehension of lyrics.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 18:02:03 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 08:31:02 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Ca\u00f1\u00f3n", "Juan Sebasti\u00e1n G\u00f3mez", ""], ["Herrera", "Perfecto", ""], ["G\u00f3mez", "Emilia", ""], ["Cano", "Estefan\u00eda", ""]]}, {"id": "1909.05885", "submitter": "Ishita Dasgupta", "authors": "Ishita Dasgupta, Demi Guo, Samuel J. Gershman and Noah D. Goodman", "title": "Analyzing machine-learned representations: A natural language case study", "comments": "This article supersedes a previous article arXiv:1802.04302", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  As modern deep networks become more complex, and get closer to human-like\ncapabilities in certain domains, the question arises of how the representations\nand decision rules they learn compare to the ones in humans. In this work, we\nstudy representations of sentences in one such artificial system for natural\nlanguage processing. We first present a diagnostic test dataset to examine the\ndegree of abstract composable structure represented. Analyzing performance on\nthese diagnostic tests indicates a lack of systematicity in the representations\nand decision rules, and reveals a set of heuristic strategies. We then\ninvestigate the effect of the training distribution on learning these heuristic\nstrategies, and study changes in these representations with various\naugmentations to the training set. Our results reveal parallels to the\nanalogous representations in people. We find that these systems can learn\nabstract rules and generalize them to new contexts under certain circumstances\n-- similar to human zero-shot reasoning. However, we also note some\nshortcomings in this generalization behavior -- similar to human judgment\nerrors like belief bias. Studying these parallels suggests new ways to\nunderstand psychological phenomena in humans as well as informs best strategies\nfor building artificial intelligence with human-like language understanding.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 18:03:17 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Dasgupta", "Ishita", ""], ["Guo", "Demi", ""], ["Gershman", "Samuel J.", ""], ["Goodman", "Noah D.", ""]]}, {"id": "1909.05890", "submitter": "Chi Zhang", "authors": "Chi Zhang, Bryan Wilkinson, Ashwinkumar Ganesan, Tim Oates", "title": "Determining the Scale of Impact from Denial-of-Service Attacks in Real\n  Time Using Twitter", "comments": "DYnamic and Novel Advances in Machine Learning and Intelligent Cyber\n  Security Workshop, December 3--4, 2018, San Juan, PR, USA", "journal-ref": null, "doi": "10.1145/3306195.3306199", "report-no": null, "categories": "cs.SI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Denial of Service (DoS) attacks are common in on-line and mobile services\nsuch as Twitter, Facebook and banking. As the scale and frequency of\nDistributed Denial of Service (DDoS) attacks increase, there is an urgent need\nfor determining the impact of the attack. Two central challenges of the task\nare to get feedback from a large number of users and to get it in a timely\nmanner. In this paper, we present a weakly-supervised model that does not need\nannotated data to measure the impact of DoS issues by applying Latent Dirichlet\nAllocation and symmetric Kullback-Leibler divergence on tweets. There is a\nlimitation to the weakly-supervised module. It assumes that the event detected\nin a time window is a DoS attack event. This will become less of a problem,\nwhen more non-attack events twitter got collected and become less likely to be\nidentified as a new event. Another way to remove that limitation, an optional\nclassification layer, trained on manually annotated DoS attack tweets, to\nfilter out non-attack tweets can be used to increase precision at the expense\nof recall. Experimental results show that we can learn weakly-supervised models\nthat can achieve comparable precision to supervised ones and can be generalized\nacross entities in the same industry.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 18:11:56 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Zhang", "Chi", ""], ["Wilkinson", "Bryan", ""], ["Ganesan", "Ashwinkumar", ""], ["Oates", "Tim", ""]]}, {"id": "1909.05952", "submitter": "Yusuke Fujita", "authors": "Yusuke Fujita, Naoyuki Kanda, Shota Horiguchi, Kenji Nagamatsu, Shinji\n  Watanabe", "title": "End-to-End Neural Speaker Diarization with Permutation-Free Objectives", "comments": "Accepted to INTERSPEECH 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel end-to-end neural-network-based speaker\ndiarization method. Unlike most existing methods, our proposed method does not\nhave separate modules for extraction and clustering of speaker representations.\nInstead, our model has a single neural network that directly outputs speaker\ndiarization results. To realize such a model, we formulate the speaker\ndiarization problem as a multi-label classification problem, and introduces a\npermutation-free objective function to directly minimize diarization errors\nwithout being suffered from the speaker-label permutation problem. Besides its\nend-to-end simplicity, the proposed method also benefits from being able to\nexplicitly handle overlapping speech during training and inference. Because of\nthe benefit, our model can be easily trained/adapted with real-recorded\nmulti-speaker conversations just by feeding the corresponding multi-speaker\nsegment labels. We evaluated the proposed method on simulated speech mixtures.\nThe proposed method achieved diarization error rate of 12.28%, while a\nconventional clustering-based system produced diarization error rate of 28.77%.\nFurthermore, the domain adaptation with real-recorded speech provided 25.6%\nrelative improvement on the CALLHOME dataset. Our source code is available\nonline at https://github.com/hitachi-speech/EEND.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 21:12:10 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Fujita", "Yusuke", ""], ["Kanda", "Naoyuki", ""], ["Horiguchi", "Shota", ""], ["Nagamatsu", "Kenji", ""], ["Watanabe", "Shinji", ""]]}, {"id": "1909.06002", "submitter": "Yi Zhang", "authors": "Yi Zhang, Tao Ge, Furu Wei, Ming Zhou, Xu Sun", "title": "Sequence-to-sequence Pre-training with Data Augmentation for Sentence\n  Rewriting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study sequence-to-sequence (seq2seq) pre-training with data augmentation\nfor sentence rewriting. Instead of training a seq2seq model with gold training\ndata and augmented data simultaneously, we separate them to train in different\nphases: pre-training with the augmented data and fine-tuning with the gold\ndata. We also introduce multiple data augmentation methods to help model\npre-training for sentence rewriting. We evaluate our approach in two typical\nwell-defined sentence rewriting tasks: Grammatical Error Correction (GEC) and\nFormality Style Transfer (FST). Experiments demonstrate our approach can better\nutilize augmented data without hurting the model's trust in gold data and\nfurther improve the model's performance with our proposed data augmentation\nmethods.\n  Our approach substantially advances the state-of-the-art results in\nwell-recognized sentence rewriting benchmarks over both GEC and FST.\nSpecifically, it pushes the CoNLL-2014 benchmark's $F_{0.5}$ score and JFLEG\nTest GLEU score to 62.61 and 63.54 in the restricted training setting, 66.77\nand 65.22 respectively in the unrestricted setting, and advances GYAFC\nbenchmark's BLEU to 74.24 (2.23 absolute improvement) in E&M domain and 77.97\n(2.64 absolute improvement) in F&R domain.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 02:20:25 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2019 11:02:51 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Zhang", "Yi", ""], ["Ge", "Tao", ""], ["Wei", "Furu", ""], ["Zhou", "Ming", ""], ["Sun", "Xu", ""]]}, {"id": "1909.06007", "submitter": "Xiang Deng", "authors": "Xiang Deng, Huan Sun", "title": "Leveraging 2-hop Distant Supervision from Table Entity Pairs for\n  Relation Extraction", "comments": null, "journal-ref": null, "doi": "10.18653/v1/D19-1039", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distant supervision (DS) has been widely used to automatically construct\n(noisy) labeled data for relation extraction (RE). Given two entities, distant\nsupervision exploits sentences that directly mention them for predicting their\nsemantic relation. We refer to this strategy as 1-hop DS, which unfortunately\nmay not work well for long-tail entities with few supporting sentences. In this\npaper, we introduce a new strategy named 2-hop DS to enhance distantly\nsupervised RE, based on the observation that there exist a large number of\nrelational tables on the Web which contain entity pairs that share common\nrelations. We refer to such entity pairs as anchors for each other, and collect\nall sentences that mention the anchor entity pairs of a given target entity\npair to help relation prediction. We develop a new neural RE method REDS2 in\nthe multi-instance learning paradigm, which adopts a hierarchical model\nstructure to fuse information respectively from 1-hop DS and 2-hop DS.\nExtensive experimental results on a benchmark dataset show that REDS2 can\nconsistently outperform various baselines across different settings by a\nsubstantial margin.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 02:43:36 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Deng", "Xiang", ""], ["Sun", "Huan", ""]]}, {"id": "1909.06044", "submitter": "Haochen Liu", "authors": "Haochen Liu, Tyler Derr, Zitao Liu and Jiliang Tang", "title": "Say What I Want: Towards the Dark Side of Neural Dialogue Models", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural dialogue models have been widely adopted in various chatbot\napplications because of their good performance in simulating and generalizing\nhuman conversations. However, there exists a dark side of these models -- due\nto the vulnerability of neural networks, a neural dialogue model can be\nmanipulated by users to say what they want, which brings in concerns about the\nsecurity of practical chatbot services. In this work, we investigate whether we\ncan craft inputs that lead a well-trained black-box neural dialogue model to\ngenerate targeted outputs. We formulate this as a reinforcement learning (RL)\nproblem and train a Reverse Dialogue Generator which efficiently finds such\ninputs for targeted outputs. Experiments conducted on a representative neural\ndialogue model show that our proposed model is able to discover such desired\ninputs in a considerable portion of cases. Overall, our work reveals this\nweakness of neural dialogue models and may prompt further researches of\ndeveloping corresponding solutions to avoid it.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 05:50:50 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 16:12:10 GMT"}, {"version": "v3", "created": "Fri, 27 Sep 2019 00:43:28 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Liu", "Haochen", ""], ["Derr", "Tyler", ""], ["Liu", "Zitao", ""], ["Tang", "Jiliang", ""]]}, {"id": "1909.06058", "submitter": "Mengdi Zhu", "authors": "Mengdi Zhu, Zheye Deng, Wenhan Xiong, Mo Yu, Ming Zhang, William Yang\n  Wang", "title": "Neural Correction Model for Open-Domain Named Entity Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named Entity Recognition (NER) plays an important role in a wide range of\nnatural language processing tasks, such as relation extraction, question\nanswering, etc. However, previous studies on NER are limited to particular\ngenres, using small manually-annotated or large but low-quality datasets.\nMeanwhile, previous datasets for open-domain NER, built using distant\nsupervision, suffer from low precision, recall and ratio of annotated tokens\n(RAT). In this work, to address the low precision and recall problems, we first\nutilize DBpedia as the source of distant supervision to annotate abstracts from\nWikipedia and design a neural correction model trained with a human-annotated\nNER dataset, DocRED, to correct the false entity labels. In this way, we build\na large and high-quality dataset called AnchorNER and then train various models\nwith it. To address the low RAT problem of previous datasets, we introduce a\nmulti-task learning method to exploit the context information. We evaluate our\nmethods on five NER datasets and our experimental results show that models\ntrained with AnchorNER and our multi-task learning method obtain\nstate-of-the-art performances in the open-domain setting.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 06:44:30 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2020 10:14:01 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Zhu", "Mengdi", ""], ["Deng", "Zheye", ""], ["Xiong", "Wenhan", ""], ["Yu", "Mo", ""], ["Zhang", "Ming", ""], ["Wang", "William Yang", ""]]}, {"id": "1909.06091", "submitter": "Alham Fikri Aji", "authors": "Alham Fikri Aji, Kenneth Heafield", "title": "Neural Machine Translation with 4-Bit Precision and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) is resource intensive. We design a\nquantization procedure to compress NMT models better for devices with limited\nhardware capability. Because most neural network parameters are near zero, we\nemploy logarithmic quantization in lieu of fixed-point quantization. However,\nwe find bias terms are less amenable to log quantization but note they comprise\na tiny fraction of the model, so we leave them uncompressed. We also propose to\nuse an error-feedback mechanism during retraining, to preserve the compressed\nmodel as a stale gradient. We empirically show that NMT models based on\nTransformer or RNN architecture can be compressed up to 4-bit precision without\nany noticeable quality degradation. Models can be compressed up to binary\nprecision, albeit with lower quality. The RNN architecture seems to be more\nrobust to quantization, compared to the Transformer.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 08:55:08 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2019 17:26:10 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Aji", "Alham Fikri", ""], ["Heafield", "Kenneth", ""]]}, {"id": "1909.06092", "submitter": "Goran Glava\\v{s}", "authors": "Anne Lauscher, Goran Glava\\v{s}, Simone Paolo Ponzetto, Ivan Vuli\\'c", "title": "A General Framework for Implicit and Explicit Debiasing of\n  Distributional Word Vector Spaces", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Distributional word vectors have recently been shown to encode many of the\nhuman biases, most notably gender and racial biases, and models for attenuating\nsuch biases have consequently been proposed. However, existing models and\nstudies (1) operate on under-specified and mutually differing bias definitions,\n(2) are tailored for a particular bias (e.g., gender bias) and (3) have been\nevaluated inconsistently and non-rigorously. In this work, we introduce a\ngeneral framework for debiasing word embeddings. We operationalize the\ndefinition of a bias by discerning two types of bias specification: explicit\nand implicit. We then propose three debiasing models that operate on explicit\nor implicit bias specifications and that can be composed towards more robust\ndebiasing. Finally, we devise a full-fledged evaluation framework in which we\ncouple existing bias metrics with newly proposed ones. Experimental findings\nacross three embedding methods suggest that the proposed debiasing models are\nrobust and widely applicable: they often completely remove the bias both\nimplicitly and explicitly without degradation of semantic information encoded\nin any of the input distributional spaces. Moreover, we successfully transfer\ndebiasing models, by means of cross-lingual embedding spaces, and remove or\nattenuate biases in distributional word vector spaces of languages that lack\nreadily available bias specifications.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 08:57:14 GMT"}, {"version": "v2", "created": "Fri, 3 Jan 2020 17:22:06 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Lauscher", "Anne", ""], ["Glava\u0161", "Goran", ""], ["Ponzetto", "Simone Paolo", ""], ["Vuli\u0107", "Ivan", ""]]}, {"id": "1909.06146", "submitter": "Qiao Jin", "authors": "Qiao Jin, Bhuwan Dhingra, Zhengping Liu, William W. Cohen, Xinghua Lu", "title": "PubMedQA: A Dataset for Biomedical Research Question Answering", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce PubMedQA, a novel biomedical question answering (QA) dataset\ncollected from PubMed abstracts. The task of PubMedQA is to answer research\nquestions with yes/no/maybe (e.g.: Do preoperative statins reduce atrial\nfibrillation after coronary artery bypass grafting?) using the corresponding\nabstracts. PubMedQA has 1k expert-annotated, 61.2k unlabeled and 211.3k\nartificially generated QA instances. Each PubMedQA instance is composed of (1)\na question which is either an existing research article title or derived from\none, (2) a context which is the corresponding abstract without its conclusion,\n(3) a long answer, which is the conclusion of the abstract and, presumably,\nanswers the research question, and (4) a yes/no/maybe answer which summarizes\nthe conclusion. PubMedQA is the first QA dataset where reasoning over\nbiomedical research texts, especially their quantitative contents, is required\nto answer the questions. Our best performing model, multi-phase fine-tuning of\nBioBERT with long answer bag-of-word statistics as additional supervision,\nachieves 68.1% accuracy, compared to single human performance of 78.0% accuracy\nand majority-baseline of 55.2% accuracy, leaving much room for improvement.\nPubMedQA is publicly available at https://pubmedqa.github.io.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 11:18:20 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Jin", "Qiao", ""], ["Dhingra", "Bhuwan", ""], ["Liu", "Zhengping", ""], ["Cohen", "William W.", ""], ["Lu", "Xinghua", ""]]}, {"id": "1909.06162", "submitter": "Pankaj Gupta", "authors": "Pankaj Gupta, Khushbu Saxena, Usama Yaseen, Thomas Runkler, Hinrich\n  Sch\\\"utze", "title": "Neural Architectures for Fine-Grained Propaganda Detection in News", "comments": "EMNLP2019: Fine-grained propaganda detection shared task at NLP4IF\n  workshop (EMNLP2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes our system (MIC-CIS) details and results of\nparticipation in the fine-grained propaganda detection shared task 2019. To\naddress the tasks of sentence (SLC) and fragment level (FLC) propaganda\ndetection, we explore different neural architectures (e.g., CNN, LSTM-CRF and\nBERT) and extract linguistic (e.g., part-of-speech, named entity, readability,\nsentiment, emotion, etc.), layout and topical features. Specifically, we have\ndesigned multi-granularity and multi-tasking neural architectures to jointly\nperform both the sentence and fragment level propaganda detection.\nAdditionally, we investigate different ensemble schemes such as\nmajority-voting, relax-voting, etc. to boost overall system performance.\nCompared to the other participating systems, our submissions are ranked 3rd and\n4th in FLC and SLC tasks, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 12:11:47 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Gupta", "Pankaj", ""], ["Saxena", "Khushbu", ""], ["Yaseen", "Usama", ""], ["Runkler", "Thomas", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1909.06194", "submitter": "Fereshteh Jafariakinabad", "authors": "Fereshteh Jafariakinabad, Kien A. Hua", "title": "Style-aware Neural Model with Application in Authorship Attribution", "comments": "arXiv admin note: text overlap with arXiv:1902.09723", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Writing style is a combination of consistent decisions associated with a\nspecific author at different levels of language production, including lexical,\nsyntactic, and structural. In this paper, we introduce a style-aware neural\nmodel to encode document information from three stylistic levels and evaluate\nit in the domain of authorship attribution. First, we propose a simple way to\njointly encode syntactic and lexical representations of sentences.\nSubsequently, we employ an attention-based hierarchical neural network to\nencode the syntactic and semantic structure of sentences in documents while\nrewarding the sentences which contribute more to capturing the writing style.\nOur experimental results, based on four benchmark datasets, reveal the benefits\nof encoding document information from all three stylistic levels when compared\nto the baseline methods in the literature.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 16:25:05 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Jafariakinabad", "Fereshteh", ""], ["Hua", "Kien A.", ""]]}, {"id": "1909.06200", "submitter": "Mengdi Zhu", "authors": "Mengdi Zhu, Zhiwei Yu, Xiaojun Wan", "title": "A Neural Approach to Irony Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ironies can not only express stronger emotions but also show a sense of\nhumor. With the development of social media, ironies are widely used in public.\nAlthough many prior research studies have been conducted in irony detection,\nfew studies focus on irony generation. The main challenges for irony generation\nare the lack of large-scale irony dataset and difficulties in modeling the\nironic pattern. In this work, we first systematically define irony generation\nbased on style transfer task. To address the lack of data, we make use of\ntwitter and build a large-scale dataset. We also design a combination of\nrewards for reinforcement learning to control the generation of ironic\nsentences. Experimental results demonstrate the effectiveness of our model in\nterms of irony accuracy, sentiment preservation, and content preservation.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 13:05:27 GMT"}, {"version": "v2", "created": "Mon, 16 Sep 2019 03:56:02 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Zhu", "Mengdi", ""], ["Yu", "Zhiwei", ""], ["Wan", "Xiaojun", ""]]}, {"id": "1909.06247", "submitter": "Yusuke Fujita", "authors": "Yusuke Fujita, Naoyuki Kanda, Shota Horiguchi, Yawen Xue, Kenji\n  Nagamatsu, Shinji Watanabe", "title": "End-to-End Neural Speaker Diarization with Self-attention", "comments": "Accepted for ASRU 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker diarization has been mainly developed based on the clustering of\nspeaker embeddings. However, the clustering-based approach has two major\nproblems; i.e., (i) it is not optimized to minimize diarization errors\ndirectly, and (ii) it cannot handle speaker overlaps correctly. To solve these\nproblems, the End-to-End Neural Diarization (EEND), in which a bidirectional\nlong short-term memory (BLSTM) network directly outputs speaker diarization\nresults given a multi-talker recording, was recently proposed. In this study,\nwe enhance EEND by introducing self-attention blocks instead of BLSTM blocks.\nIn contrast to BLSTM, which is conditioned only on its previous and next hidden\nstates, self-attention is directly conditioned on all the other frames, making\nit much suitable for dealing with the speaker diarization problem. We evaluated\nour proposed method on simulated mixtures, real telephone calls, and real\ndialogue recordings. The experimental results revealed that the self-attention\nwas the key to achieving good performance and that our proposed method\nperformed significantly better than the conventional BLSTM-based method. Our\nmethod was even better than that of the state-of-the-art x-vector\nclustering-based method. Finally, by visualizing the latent representation, we\nshow that the self-attention can capture global speaker characteristics in\naddition to local speech activity dynamics. Our source code is available online\nat https://github.com/hitachi-speech/EEND.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 14:18:18 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Fujita", "Yusuke", ""], ["Kanda", "Naoyuki", ""], ["Horiguchi", "Shota", ""], ["Xue", "Yawen", ""], ["Nagamatsu", "Kenji", ""], ["Watanabe", "Shinji", ""]]}, {"id": "1909.06249", "submitter": "Akshay Parekh", "authors": "Akshay Parekh, Ashish Anand, and Amit Awekar", "title": "Taxonomical hierarchy of canonicalized relations from multiple Knowledge\n  Bases", "comments": "Accepted at CoDS-COMAD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work addresses two important questions pertinent to Relation Extraction\n(RE). First, what are all possible relations that could exist between any two\ngiven entity types? Second, how do we define an unambiguous taxonomical (is-a)\nhierarchy among the identified relations? To address the first question, we use\nthree resources Wikipedia Infobox, Wikidata, and DBpedia. This study focuses on\nrelations between person, organization and location entity types. We exploit\nWikidata and DBpedia in a data-driven manner, and Wikipedia Infobox templates\nmanually to generate lists of relations. Further, to address the second\nquestion, we canonicalize, filter, and combine the identified relations from\nthe three resources to construct a taxonomical hierarchy. This hierarchy\ncontains 623 canonical relations with highest contribution from Wikipedia\nInfobox followed by DBpedia and Wikidata. The generated relation list subsumes\nan average of 85% of relations from RE datasets when entity types are\nrestricted.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 14:20:30 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 09:21:25 GMT"}, {"version": "v3", "created": "Fri, 1 Nov 2019 05:15:57 GMT"}, {"version": "v4", "created": "Tue, 12 Nov 2019 07:37:38 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Parekh", "Akshay", ""], ["Anand", "Ashish", ""], ["Awekar", "Amit", ""]]}, {"id": "1909.06273", "submitter": "Martin Andrews", "authors": "Martin Andrews, Yew Ken Chia, Sam Witteveen", "title": "Scene Graph Parsing by Attention Graph", "comments": "Accepted paper for the ViGIL workshop at NeurIPS 2018. (4 pages +\n  references)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scene graph representations, which form a graph of visual object nodes\ntogether with their attributes and relations, have proved useful across a\nvariety of vision and language applications. Recent work in the area has used\nNatural Language Processing dependency tree methods to automatically build\nscene graphs.\n  In this work, we present an 'Attention Graph' mechanism that can be trained\nend-to-end, and produces a scene graph structure that can be lifted directly\nfrom the top layer of a standard Transformer model.\n  The scene graphs generated by our model achieve an F-score similarity of\n52.21% to ground-truth graphs on the evaluation set using the SPICE metric,\nsurpassing the best previous approaches by 2.5%.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 14:54:37 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Andrews", "Martin", ""], ["Chia", "Yew Ken", ""], ["Witteveen", "Sam", ""]]}, {"id": "1909.06276", "submitter": "Binxuan Huang", "authors": "Binxuan Huang and Kathleen M. Carley", "title": "Parameterized Convolutional Neural Networks for Aspect Level Sentiment\n  Classification", "comments": "Accepted by EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel parameterized convolutional neural network for aspect\nlevel sentiment classification. Using parameterized filters and parameterized\ngates, we incorporate aspect information into convolutional neural networks\n(CNN). Experiments demonstrate that our parameterized filters and parameterized\ngates effectively capture the aspect-specific features, and our CNN-based\nmodels achieve excellent results on SemEval 2014 datasets.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 14:59:51 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Huang", "Binxuan", ""], ["Carley", "Kathleen M.", ""]]}, {"id": "1909.06283", "submitter": "Prithviraj Ammanabrolu", "authors": "Prithviraj Ammanabrolu, William Broniec, Alex Mueller, Jeremy Paul,\n  Mark O. Riedl", "title": "Toward Automated Quest Generation in Text-Adventure Games", "comments": "In Proceedings of the International Conference on Computational\n  Creativity (ICCC-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive fictions, or text-adventures, are games in which a player\ninteracts with a world entirely through textual descriptions and text actions.\nText-adventure games are typically structured as puzzles or quests wherein the\nplayer must execute certain actions in a certain order to succeed. In this\npaper, we consider the problem of procedurally generating a quest, defined as a\nseries of actions required to progress towards a goal, in a text-adventure\ngame. Quest generation in text environments is challenging because they must be\nsemantically coherent. We present and evaluate two quest generation techniques:\n(1) a Markov model, and (2) a neural generative model. We specifically look at\ngenerating quests about cooking and train our models on recipe data. We\nevaluate our techniques with human participant studies looking at perceived\ncreativity and coherence.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 15:10:06 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 23:16:40 GMT"}, {"version": "v3", "created": "Sun, 17 Nov 2019 00:36:59 GMT"}, {"version": "v4", "created": "Wed, 19 Aug 2020 17:37:02 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Ammanabrolu", "Prithviraj", ""], ["Broniec", "William", ""], ["Mueller", "Alex", ""], ["Paul", "Jeremy", ""], ["Riedl", "Mark O.", ""]]}, {"id": "1909.06317", "submitter": "Shigeki Karita", "authors": "Shigeki Karita, Nanxin Chen, Tomoki Hayashi, Takaaki Hori, Hirofumi\n  Inaguma, Ziyan Jiang, Masao Someki, Nelson Enrique Yalta Soplin, Ryuichi\n  Yamamoto, Xiaofei Wang, Shinji Watanabe, Takenori Yoshimura, Wangyou Zhang", "title": "A Comparative Study on Transformer vs RNN in Speech Applications", "comments": "Accepted at ASRU 2019", "journal-ref": "IEEE Automatic Speech Recognition and Understanding Workshop 2019", "doi": "10.1109/ASRU46091.2019.9003750", "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-to-sequence models have been widely used in end-to-end speech\nprocessing, for example, automatic speech recognition (ASR), speech translation\n(ST), and text-to-speech (TTS). This paper focuses on an emergent\nsequence-to-sequence model called Transformer, which achieves state-of-the-art\nperformance in neural machine translation and other natural language processing\napplications. We undertook intensive studies in which we experimentally\ncompared and analyzed Transformer and conventional recurrent neural networks\n(RNN) in a total of 15 ASR, one multilingual ASR, one ST, and two TTS\nbenchmarks. Our experiments revealed various training tips and significant\nperformance benefits obtained with Transformer for each task including the\nsurprising superiority of Transformer in 13/15 ASR benchmarks in comparison\nwith RNN. We are preparing to release Kaldi-style reproducible recipes using\nopen source and publicly available datasets for all the ASR, ST, and TTS tasks\nfor the community to succeed our exciting outcomes.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 16:27:08 GMT"}, {"version": "v2", "created": "Sat, 28 Sep 2019 11:11:38 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Karita", "Shigeki", ""], ["Chen", "Nanxin", ""], ["Hayashi", "Tomoki", ""], ["Hori", "Takaaki", ""], ["Inaguma", "Hirofumi", ""], ["Jiang", "Ziyan", ""], ["Someki", "Masao", ""], ["Soplin", "Nelson Enrique Yalta", ""], ["Yamamoto", "Ryuichi", ""], ["Wang", "Xiaofei", ""], ["Watanabe", "Shinji", ""], ["Yoshimura", "Takenori", ""], ["Zhang", "Wangyou", ""]]}, {"id": "1909.06321", "submitter": "Rabeeh Karimi Mahabadi", "authors": "Rabeeh Karimi Mahabadi, Yonatan Belinkov and James Henderson", "title": "End-to-End Bias Mitigation by Modelling Biases in Corpora", "comments": "Accepted in ACL 2020 as a long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several recent studies have shown that strong natural language understanding\n(NLU) models are prone to relying on unwanted dataset biases without learning\nthe underlying task, resulting in models that fail to generalize to\nout-of-domain datasets and are likely to perform poorly in real-world\nscenarios. We propose two learning strategies to train neural models, which are\nmore robust to such biases and transfer better to out-of-domain datasets. The\nbiases are specified in terms of one or more bias-only models, which learn to\nleverage the dataset biases. During training, the bias-only models' predictions\nare used to adjust the loss of the base model to reduce its reliance on biases\nby down-weighting the biased examples and focusing the training on the hard\nexamples. We experiment on large-scale natural language inference and fact\nverification benchmarks, evaluating on out-of-domain datasets that are\nspecifically designed to assess the robustness of models against known biases\nin the training data. Results show that our debiasing methods greatly improve\nrobustness in all settings and better transfer to other textual entailment\ndatasets. Our code and data are publicly available in\n\\url{https://github.com/rabeehk/robust-nli}.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 16:41:13 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 16:12:16 GMT"}, {"version": "v3", "created": "Thu, 23 Apr 2020 19:44:20 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Mahabadi", "Rabeeh Karimi", ""], ["Belinkov", "Yonatan", ""], ["Henderson", "James", ""]]}, {"id": "1909.06351", "submitter": "Desh Raj", "authors": "Desh Raj, David Snyder, Daniel Povey, Sanjeev Khudanpur", "title": "Probing the Information Encoded in X-vectors", "comments": "Accepted at IEEE Workshop on Automatic Speech Recognition and\n  Understanding (ASRU) 2019", "journal-ref": "IEEE Automatic Speech Recognition and Understanding Workshop\n  (ASRU) (2019): 726-733", "doi": "10.1109/ASRU46091.2019.9003979", "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural network based speaker embeddings, such as x-vectors, have been\nshown to perform well in text-independent speaker recognition/verification\ntasks. In this paper, we use simple classifiers to investigate the contents\nencoded by x-vector embeddings. We probe these embeddings for information\nrelated to the speaker, channel, transcription (sentence, words, phones), and\nmeta information about the utterance (duration and augmentation type), and\ncompare these with the information encoded by i-vectors across a varying number\nof dimensions. We also study the effect of data augmentation during extractor\ntraining on the information captured by x-vectors. Experiments on the RedDots\ndata set show that x-vectors capture spoken content and channel-related\ninformation, while performing well on speaker verification tasks.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 17:56:13 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 22:55:18 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Raj", "Desh", ""], ["Snyder", "David", ""], ["Povey", "Daniel", ""], ["Khudanpur", "Sanjeev", ""]]}, {"id": "1909.06356", "submitter": "Shiyue Zhang", "authors": "Shiyue Zhang, Mohit Bansal", "title": "Addressing Semantic Drift in Question Generation for Semi-Supervised\n  Question Answering", "comments": "15 pages (EMNLP 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text-based Question Generation (QG) aims at generating natural and relevant\nquestions that can be answered by a given answer in some context. Existing QG\nmodels suffer from a \"semantic drift\" problem, i.e., the semantics of the\nmodel-generated question drifts away from the given context and answer. In this\npaper, we first propose two semantics-enhanced rewards obtained from downstream\nquestion paraphrasing and question answering tasks to regularize the QG model\nto generate semantically valid questions. Second, since the traditional\nevaluation metrics (e.g., BLEU) often fall short in evaluating the quality of\ngenerated questions, we propose a QA-based evaluation method which measures the\nQG model's ability to mimic human annotators in generating QA training data.\nExperiments show that our method achieves the new state-of-the-art performance\nw.r.t. traditional metrics, and also performs best on our QA-based evaluation\nmetrics. Further, we investigate how to use our QG model to augment QA datasets\nand enable semi-supervised QA. We propose two ways to generate synthetic QA\npairs: generate new questions from existing articles or collect QA pairs from\nnew articles. We also propose two empirically effective strategies, a data\nfilter and mixing mini-batch training, to properly use the QG-generated data\nfor QA. Experiments show that our method improves over both BiDAF and BERT QA\nbaselines, even without introducing new articles.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 17:59:03 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Zhang", "Shiyue", ""], ["Bansal", "Mohit", ""]]}, {"id": "1909.06414", "submitter": "Yilun Zhou", "authors": "Yilun Zhou, Julie A. Shah, Steven Schockaert", "title": "Learning Household Task Knowledge from WikiHow Descriptions", "comments": "IJCAI 2019 Workshop on Semantic Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commonsense procedural knowledge is important for AI agents and robots that\noperate in a human environment. While previous attempts at constructing\nprocedural knowledge are mostly rule- and template-based, recent advances in\ndeep learning provide the possibility of acquiring such knowledge directly from\nnatural language sources. As a first step in this direction, we propose a model\nto learn embeddings for tasks, as well as the individual steps that need to be\ntaken to solve them, based on WikiHow articles. We learn these embeddings such\nthat they are predictive of both step relevance and step ordering. We also\nexperiment with the use of integer programming for inferring consistent global\nstep orderings from noisy pairwise predictions.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 19:16:53 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Zhou", "Yilun", ""], ["Shah", "Julie A.", ""], ["Schockaert", "Steven", ""]]}, {"id": "1909.06434", "submitter": "Sebastien Jean", "authors": "S\\'ebastien Jean, Orhan Firat, Melvin Johnson", "title": "Adaptive Scheduling for Multi-Task Learning", "comments": "Continual Learning Workshop at NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To train neural machine translation models simultaneously on multiple tasks\n(languages), it is common to sample each task uniformly or in proportion to\ndataset sizes. As these methods offer little control over performance\ntrade-offs, we explore different task scheduling approaches. We first consider\nexisting non-adaptive techniques, then move on to adaptive schedules that\nover-sample tasks with poorer results compared to their respective baseline. As\nexplicit schedules can be inefficient, especially if one task is highly\nover-sampled, we also consider implicit schedules, learning to scale learning\nrates or gradients of individual tasks instead. These techniques allow training\nmultilingual models that perform better for low-resource language pairs (tasks\nwith small amount of data), while minimizing negative effects on high-resource\ntasks.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 20:23:40 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Jean", "S\u00e9bastien", ""], ["Firat", "Orhan", ""], ["Johnson", "Melvin", ""]]}, {"id": "1909.06502", "submitter": "Hassan S. Shavarani", "authors": "Hassan S. Shavarani and Satoshi Sekine", "title": "Multi-class Multilingual Classification of Wikipedia Articles Using\n  Extended Named Entity Tag Set", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wikipedia is a great source of general world knowledge which can guide NLP\nmodels better understand their motivation to make predictions. Structuring\nWikipedia is the initial step towards this goal which can facilitate fine-grain\nclassification of articles. In this work, we introduce the Shinra 5-Language\nCategorization Dataset (SHINRA-5LDS), a large multi-lingual and multi-labeled\nset of annotated Wikipedia articles in Japanese, English, French, German, and\nFarsi using Extended Named Entity (ENE) tag set. We evaluate the dataset using\nthe best models provided for ENE label set classification and show that the\ncurrently available classification models struggle with large datasets using\nfine-grained tag sets.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 01:47:09 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 20:57:22 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Shavarani", "Hassan S.", ""], ["Sekine", "Satoshi", ""]]}, {"id": "1909.06515", "submitter": "Juan Pino", "authors": "Juan Pino, Liezl Puzon, Jiatao Gu, Xutai Ma, Arya D. McCarthy, Deepak\n  Gopinath", "title": "Harnessing Indirect Training Data for End-to-End Automatic Speech\n  Translation: Tricks of the Trade", "comments": "IWSLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For automatic speech translation (AST), end-to-end approaches are\noutperformed by cascaded models that transcribe with automatic speech\nrecognition (ASR), then translate with machine translation (MT). A major cause\nof the performance gap is that, while existing AST corpora are small, massive\ndatasets exist for both the ASR and MT subsystems. In this work, we evaluate\nseveral data augmentation and pretraining approaches for AST, by comparing all\non the same datasets. Simple data augmentation by translating ASR transcripts\nproves most effective on the English--French augmented LibriSpeech dataset,\nclosing the performance gap from 8.2 to 1.4 BLEU, compared to a very strong\ncascade that could directly utilize copious ASR and MT data. The same\nend-to-end approach plus fine-tuning closes the gap on the English--Romanian\nMuST-C dataset from 6.7 to 3.7 BLEU. In addition to these results, we present\npractical recommendations for augmentation and pretraining approaches. Finally,\nwe decrease the performance gap to 0.01 BLEU using a Transformer-based\narchitecture.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 03:05:30 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 17:54:44 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Pino", "Juan", ""], ["Puzon", "Liezl", ""], ["Gu", "Jiatao", ""], ["Ma", "Xutai", ""], ["McCarthy", "Arya D.", ""], ["Gopinath", "Deepak", ""]]}, {"id": "1909.06516", "submitter": "Mozhdeh Gheini", "authors": "Mozhdeh Gheini, Jonathan May", "title": "A Universal Parent Model for Low-Resource Neural Machine Translation\n  Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning from a high-resource language pair `parent' has been proven\nto be an effective way to improve neural machine translation quality for\nlow-resource language pairs `children.' However, previous approaches build a\ncustom parent model or at least update an existing parent model's vocabulary\nfor each child language pair they wish to train, in an effort to align parent\nand child vocabularies. This is not a practical solution. It is wasteful to\ndevote the majority of training time for new language pairs to optimizing\nparameters on an unrelated data set. Further, this overhead reduces the utility\nof neural machine translation for deployment in humanitarian assistance\nscenarios, where extra time to deploy a new language pair can mean the\ndifference between life and death. In this work, we present a `universal'\npre-trained neural parent model with constant vocabulary that can be used as a\nstarting point for training practically any new low-resource language to a\nfixed target language. We demonstrate that our approach, which leverages\northography unification and a broad-coverage approach to subword\nidentification, generalizes well to several languages from a variety of\nfamilies, and that translation systems built with our approach can be built\nmore quickly than competing methods and with better quality as well.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 03:11:52 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2019 00:32:28 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Gheini", "Mozhdeh", ""], ["May", "Jonathan", ""]]}, {"id": "1909.06522", "submitter": "Chunxi Liu", "authors": "Chunxi Liu, Qiaochu Zhang, Xiaohui Zhang, Kritika Singh, Yatharth\n  Saraf, Geoffrey Zweig", "title": "Multilingual Graphemic Hybrid ASR with Massive Data Augmentation", "comments": "Accepted for publication at the 1st Joint Workshop of SLTU (Spoken\n  Language Technologies for Under-resourced languages) and CCURL (Collaboration\n  and Computing for Under-Resourced Languages) (SLTU-CCURL 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Towards developing high-performing ASR for low-resource languages, approaches\nto address the lack of resources are to make use of data from multiple\nlanguages, and to augment the training data by creating acoustic variations. In\nthis work we present a single grapheme-based ASR model learned on 7\ngeographically proximal languages, using standard hybrid BLSTM-HMM acoustic\nmodels with lattice-free MMI objective. We build the single ASR grapheme set\nvia taking the union over each language-specific grapheme set, and we find such\nmultilingual graphemic hybrid ASR model can perform language-independent\nrecognition on all 7 languages, and substantially outperform each monolingual\nASR model. Secondly, we evaluate the efficacy of multiple data augmentation\nalternatives within language, as well as their complementarity with\nmultilingual modeling. Overall, we show that the proposed multilingual\ngraphemic hybrid ASR with various data augmentation can not only recognize any\nwithin training set languages, but also provide large ASR performance\nimprovements.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 03:46:49 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 20:39:07 GMT"}, {"version": "v3", "created": "Wed, 8 Apr 2020 22:09:51 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Liu", "Chunxi", ""], ["Zhang", "Qiaochu", ""], ["Zhang", "Xiaohui", ""], ["Singh", "Kritika", ""], ["Saraf", "Yatharth", ""], ["Zweig", "Geoffrey", ""]]}, {"id": "1909.06532", "submitter": "Hieu-Thi Luong", "authors": "Hieu-Thi Luong, Junichi Yamagishi", "title": "Bootstrapping non-parallel voice conversion from speaker-adaptive\n  text-to-speech", "comments": "Accepted for IEEE ASRU 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice conversion (VC) and text-to-speech (TTS) are two tasks that share a\nsimilar objective, generating speech with a target voice. However, they are\nusually developed independently under vastly different frameworks. In this\npaper, we propose a methodology to bootstrap a VC system from a pretrained\nspeaker-adaptive TTS model and unify the techniques as well as the\ninterpretations of these two tasks. Moreover by offloading the heavy data\ndemand to the training stage of the TTS model, our VC system can be built using\na small amount of target speaker speech data. It also opens up the possibility\nof using speech in a foreign unseen language to build the system. Our\nsubjective evaluations show that the proposed framework is able to not only\nachieve competitive performance in the standard intra-language scenario but\nalso adapt and convert using speech utterances in an unseen language.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 04:43:32 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Luong", "Hieu-Thi", ""], ["Yamagishi", "Junichi", ""]]}, {"id": "1909.06563", "submitter": "Pankaj Gupta", "authors": "Pankaj Gupta, Yatin Chaudhary, Hinrich Sch\\\"utze", "title": "Multi-view and Multi-source Transfers in Neural Topic Modeling with\n  Pretrained Topic and Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though word embeddings and topics are complementary representations, several\npast works have only used pre-trained word embeddings in (neural) topic\nmodeling to address data sparsity problem in short text or small collection of\ndocuments. However, no prior work has employed (pre-trained latent) topics in\ntransfer learning paradigm. In this paper, we propose an approach to (1)\nperform knowledge transfer using latent topics obtained from a large source\ncorpus, and (2) jointly transfer knowledge via the two representations (or\nviews) in neural topic modeling to improve topic quality, better deal with\npolysemy and data sparsity issues in a target corpus. In doing so, we first\naccumulate topics and word representations from one or many source corpora to\nbuild a pool of topics and word vectors. Then, we identify one or multiple\nrelevant source domain(s) and take advantage of corresponding topics and word\nfeatures via the respective pools to guide meaningful learning in the sparse\ntarget domain. We quantify the quality of topic and document representations\nvia generalization (perplexity), interpretability (topic coherence) and\ninformation retrieval (IR) using short-text, long-text, small and large\ndocument collections from news and medical domains. We have demonstrated the\nstate-of-the-art results on topic modeling with the proposed framework.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 09:16:05 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 13:05:34 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Gupta", "Pankaj", ""], ["Chaudhary", "Yatin", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1909.06564", "submitter": "Qiongkai Xu", "authors": "Qiongkai Xu, Chenchen Xu and Lizhen Qu", "title": "ALTER: Auxiliary Text Rewriting Tool for Natural Language Generation", "comments": "EMNLP 2019 (Demo)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe ALTER, an auxiliary text rewriting tool that\nfacilitates the rewriting process for natural language generation tasks, such\nas paraphrasing, text simplification, fairness-aware text rewriting, and text\nstyle transfer. Our tool is characterized by two features, i) recording of\nword-level revision histories and ii) flexible auxiliary edit support and\nfeedback to annotators. The text rewriting assist and traceable rewriting\nhistory are potentially beneficial to the future research of natural language\ngeneration.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 09:18:44 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Xu", "Qiongkai", ""], ["Xu", "Chenchen", ""], ["Qu", "Lizhen", ""]]}, {"id": "1909.06614", "submitter": "Qiujia Li", "authors": "Qiujia Li, Chao Zhang, Philip C. Woodland", "title": "Integrating Source-channel and Attention-based Sequence-to-sequence\n  Models for Speech Recognition", "comments": "To appear in Proc. ASRU2019, December 14-18, 2019, Sentosa, Singapore", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel automatic speech recognition (ASR) framework\ncalled Integrated Source-Channel and Attention (ISCA) that combines the\nadvantages of traditional systems based on the noisy source-channel model (SC)\nand end-to-end style systems using attention-based sequence-to-sequence models.\nThe traditional SC system framework includes hidden Markov models and\nconnectionist temporal classification (CTC) based acoustic models, language\nmodels (LMs), and a decoding procedure based on a lexicon, whereas the\nend-to-end style attention-based system jointly models the whole process with a\nsingle model. By rescoring the hypotheses produced by traditional systems using\nend-to-end style systems based on an extended noisy source-channel model, ISCA\nallows structured knowledge to be easily incorporated via the SC-based model\nwhile exploiting the complementarity of the attention-based model. Experiments\non the AMI meeting corpus show that ISCA is able to give a relative word error\nrate reduction up to 21% over an individual system, and by 13% over an\nalternative method which also involves combining CTC and attention-based\nmodels.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 15:40:27 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 11:09:08 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Li", "Qiujia", ""], ["Zhang", "Chao", ""], ["Woodland", "Philip C.", ""]]}, {"id": "1909.06618", "submitter": "Erion \\c{C}ano", "authors": "Erion \\c{C}ano and Ond\\v{r}ej Bojar", "title": "Efficiency Metrics for Data-Driven Models: A Text Summarization Case\n  Study", "comments": "11 pages, 4 tables, 2 figures, 6 equations. Published in proceedings\n  of INLG 2019, the 12th International Conference on Natural Language\n  Generation, Tokyo, Japan", "journal-ref": null, "doi": "10.18653/v1/W19-8630", "report-no": null, "categories": "cs.CL cs.LG cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Using data-driven models for solving text summarization or similar tasks has\nbecome very common in the last years. Yet most of the studies report basic\naccuracy scores only, and nothing is known about the ability of the proposed\nmodels to improve when trained on more data. In this paper, we define and\npropose three data efficiency metrics: data score efficiency, data time\ndeficiency and overall data efficiency. We also propose a simple scheme that\nuses those metrics and apply it for a more comprehensive evaluation of popular\nmethods on text summarization and title generation tasks. For the latter task,\nwe process and release a huge collection of 35 million abstract-title pairs\nfrom scientific articles. Our results reveal that among the tested models, the\nTransformer is the most efficient on both tasks.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 16:03:49 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["\u00c7ano", "Erion", ""], ["Bojar", "Ond\u0159ej", ""]]}, {"id": "1909.06635", "submitter": "Shweta Mahajan", "authors": "Shweta Mahajan, Teresa Botschen, Iryna Gurevych, Stefan Roth", "title": "Joint Wasserstein Autoencoders for Aligning Multimodal Embeddings", "comments": "Accepted at ICCV 2019 Workshop on Cross-Modal Learning in Real World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key challenges in learning joint embeddings of multiple\nmodalities, e.g. of images and text, is to ensure coherent cross-modal\nsemantics that generalize across datasets. We propose to address this through\njoint Gaussian regularization of the latent representations. Building on\nWasserstein autoencoders (WAEs) to encode the input in each domain, we enforce\nthe latent embeddings to be similar to a Gaussian prior that is shared across\nthe two domains, ensuring compatible continuity of the encoded semantic\nrepresentations of images and texts. Semantic alignment is achieved through\nsupervision from matching image-text pairs. To show the benefits of our\nsemi-supervised representation, we apply it to cross-modal retrieval and phrase\nlocalization. We not only achieve state-of-the-art accuracy, but significantly\nbetter generalization across datasets, owing to the semantic continuity of the\nlatent space.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 17:25:03 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Mahajan", "Shweta", ""], ["Botschen", "Teresa", ""], ["Gurevych", "Iryna", ""], ["Roth", "Stefan", ""]]}, {"id": "1909.06639", "submitter": "Yaushian Wang", "authors": "Yau-Shian Wang and Hung-Yi Lee and Yun-Nung Chen", "title": "Tree Transformer: Integrating Tree Structures into Self-Attention", "comments": "accepted by EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-training Transformer from large-scale raw texts and fine-tuning on the\ndesired task have achieved state-of-the-art results on diverse NLP tasks.\nHowever, it is unclear what the learned attention captures. The attention\ncomputed by attention heads seems not to match human intuitions about\nhierarchical structures. This paper proposes Tree Transformer, which adds an\nextra constraint to attention heads of the bidirectional Transformer encoder in\norder to encourage the attention heads to follow tree structures. The tree\nstructures can be automatically induced from raw texts by our proposed\n\"Constituent Attention\" module, which is simply implemented by self-attention\nbetween two adjacent words. With the same training procedure identical to BERT,\nthe experiments demonstrate the effectiveness of Tree Transformer in terms of\ninducing tree structures, better language modeling, and further learning more\nexplainable attention scores.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 17:49:37 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 20:38:07 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Wang", "Yau-Shian", ""], ["Lee", "Hung-Yi", ""], ["Chen", "Yun-Nung", ""]]}, {"id": "1909.06644", "submitter": "Angus Addlesee", "authors": "Angus Addlesee, Arash Eshghi and Ioannis Konstas", "title": "Current Challenges in Spoken Dialogue Systems and Why They Are Critical\n  for Those Living with Dementia", "comments": "Published at Dialog for Good 2019 - Workshop on Speech and Language\n  Technology Serving Society", "journal-ref": "Dialog for Good (2019)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue technologies such as Amazon's Alexa have the potential to transform\nthe healthcare industry. However, current systems are not yet naturally\ninteractive: they are often turn-based, have naive end-of-turn detection and\ncompletely ignore many types of verbal and visual feedback - such as\nbackchannels, hesitation markers, filled pauses, gaze, brow furrows and\ndisfluencies - that are crucial in guiding and managing the conversational\nprocess. This is especially important in the healthcare industry as target\nusers of Spoken Dialogue Systems (SDSs) are likely to be frail, older,\ndistracted or suffer from cognitive decline which impacts their ability to make\neffective use of current systems. In this paper, we outline some of the\nchallenges that are in urgent need of further research, including Incremental\nSpeech Recognition and a systematic study of the interactional patterns in\nconversation that are potentially diagnostic of dementia, and how these might\ninform research on and the design of the next generation of SDSs.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 18:03:57 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Addlesee", "Angus", ""], ["Eshghi", "Arash", ""], ["Konstas", "Ioannis", ""]]}, {"id": "1909.06654", "submitter": "Jordi Pons M.Sc.", "authors": "Jordi Pons, Xavier Serra", "title": "musicnn: Pre-trained convolutional neural networks for music audio\n  tagging", "comments": "Accepted to be presented at the Late-Breaking/Demo session of ISMIR\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pronounced as \"musician\", the musicnn library contains a set of pre-trained\nmusically motivated convolutional neural networks for music audio tagging:\nhttps://github.com/jordipons/musicnn. This repository also includes some\npre-trained vgg-like baselines. These models can be used as out-of-the-box\nmusic audio taggers, as music feature extractors, or as pre-trained models for\ntransfer learning.\n  We also provide the code to train the aforementioned models:\nhttps://github.com/jordipons/musicnn-training. This framework also allows\nimplementing novel models. For example, a musically motivated convolutional\nneural network with an attention-based output layer (instead of the temporal\npooling layer) can achieve state-of-the-art results for music audio tagging:\n90.77 ROC-AUC / 38.61 PR-AUC on the MagnaTagATune dataset --- and 88.81 ROC-AUC\n/ 31.51 PR-AUC on the Million Song Dataset.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 18:52:47 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Pons", "Jordi", ""], ["Serra", "Xavier", ""]]}, {"id": "1909.06670", "submitter": "Rohola Zandie", "authors": "Francesca Dino, Rohola Zandie, Hojjat Abdollahi, Sarah Schoeder and\n  Mohammad H. Mahoor", "title": "Delivering Cognitive Behavioral Therapy Using A Conversational\n  SocialRobot", "comments": "Accepted in IROS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social robots are becoming an integrated part of our daily life due to their\nability to provide companionship and entertainment. A subfield of robotics,\nSocially Assistive Robotics (SAR), is particularly suitable for expanding these\nbenefits into the healthcare setting because of its unique ability to provide\ncognitive, social, and emotional support. This paper presents our recent\nresearch on developing SAR by evaluating the ability of a life-like\nconversational social robot, called Ryan, to administer internet-delivered\ncognitive behavioral therapy (iCBT) to older adults with depression. For Ryan\nto administer the therapy, we developed a dialogue-management system, called\nProgram-R. Using an accredited CBT manual for the treatment of depression, we\ncreated seven hour-long iCBT dialogues and integrated them into Program-R using\nArtificial Intelligence Markup Language (AIML). To assess the effectiveness of\nRobot-based iCBT and users' likability of our approach, we conducted an HRI\nstudy with a cohort of elderly people with mild-to-moderate depression over a\nperiod of four weeks. Quantitative analyses of participant's spoken responses\n(e.g. word count and sentiment analysis), face-scale mood scores, and exit\nsurveys, strongly support the notion robot-based iCBT is a viable alternative\nto traditional human-delivered therapy.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 20:31:34 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Dino", "Francesca", ""], ["Zandie", "Rohola", ""], ["Abdollahi", "Hojjat", ""], ["Schoeder", "Sarah", ""], ["Mahoor", "Mohammad H.", ""]]}, {"id": "1909.06694", "submitter": "John Wieting", "authors": "John Wieting, Taylor Berg-Kirkpatrick, Kevin Gimpel, Graham Neubig", "title": "Beyond BLEU: Training Neural Machine Translation with Semantic\n  Similarity", "comments": "Published as a long paper at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While most neural machine translation (NMT) systems are still trained using\nmaximum likelihood estimation, recent work has demonstrated that optimizing\nsystems to directly improve evaluation metrics such as BLEU can substantially\nimprove final translation accuracy. However, training with BLEU has some\nlimitations: it doesn't assign partial credit, it has a limited range of output\nvalues, and it can penalize semantically correct hypotheses if they differ\nlexically from the reference. In this paper, we introduce an alternative reward\nfunction for optimizing NMT systems that is based on recent work in semantic\nsimilarity. We evaluate on four disparate languages translated to English, and\nfind that training with our proposed metric results in better translations as\nevaluated by BLEU, semantic similarity, and human evaluation, and also that the\noptimization procedure converges faster. Analysis suggests that this is because\nthe proposed metric is more conducive to optimization, assigning partial credit\nand providing more diversity in scores than BLEU.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 23:15:20 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Wieting", "John", ""], ["Berg-Kirkpatrick", "Taylor", ""], ["Gimpel", "Kevin", ""], ["Neubig", "Graham", ""]]}, {"id": "1909.06695", "submitter": "Qian Yang", "authors": "Qian Yang, Zhouyuan Huo, Wenlin Wang, Heng Huang, Lawrence Carin", "title": "Ouroboros: On Accelerating Training of Transformer-Based Language Models", "comments": "To appear in the proceedings of Neural Information Processing Systems\n  Conference (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language models are essential for natural language processing (NLP) tasks,\nsuch as machine translation and text summarization. Remarkable performance has\nbeen demonstrated recently across many NLP domains via a Transformer-based\nlanguage model with over a billion parameters, verifying the benefits of model\nsize. Model parallelism is required if a model is too large to fit in a single\ncomputing device. Current methods for model parallelism either suffer from\nbackward locking in backpropagation or are not applicable to language models.\nWe propose the first model-parallel algorithm that speeds the training of\nTransformer-based language models. We also prove that our proposed algorithm is\nguaranteed to converge to critical points for non-convex problems. Extensive\nexperiments on Transformer and Transformer-XL language models demonstrate that\nthe proposed algorithm obtains a much faster speedup beyond data parallelism,\nwith comparable or better accuracy. Code to reproduce experiments is to be\nfound at \\url{https://github.com/LaraQianYang/Ouroboros}.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 23:21:56 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Yang", "Qian", ""], ["Huo", "Zhouyuan", ""], ["Wang", "Wenlin", ""], ["Huang", "Heng", ""], ["Carin", "Lawrence", ""]]}, {"id": "1909.06708", "submitter": "Zhuohan Li", "authors": "Zhuohan Li, Zi Lin, Di He, Fei Tian, Tao Qin, Liwei Wang, Tie-Yan Liu", "title": "Hint-Based Training for Non-Autoregressive Machine Translation", "comments": "EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the unparallelizable nature of the autoregressive factorization,\nAutoRegressive Translation (ART) models have to generate tokens sequentially\nduring decoding and thus suffer from high inference latency. Non-AutoRegressive\nTranslation (NART) models were proposed to reduce the inference time, but could\nonly achieve inferior translation accuracy. In this paper, we proposed a novel\napproach to leveraging the hints from hidden states and word alignments to help\nthe training of NART models. The results achieve significant improvement over\nprevious NART models for the WMT14 En-De and De-En datasets and are even\ncomparable to a strong LSTM-based ART baseline but one order of magnitude\nfaster in inference.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 01:39:59 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Li", "Zhuohan", ""], ["Lin", "Zi", ""], ["He", "Di", ""], ["Tian", "Fei", ""], ["Qin", "Tao", ""], ["Wang", "Liwei", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1909.06723", "submitter": "Xiaosen Wang", "authors": "Xiaosen Wang, Hao Jin, Yichen Yang, Kun He", "title": "Natural Language Adversarial Defense through Synonym Encoding", "comments": "Accepted by UAI 2021, code is avaliable at\n  https://github.com/JHL-HUST/SEM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the area of natural language processing, deep learning models are recently\nknown to be vulnerable to various types of adversarial perturbations, but\nrelatively few works are done on the defense side. Especially, there exists few\neffective defense method against the successful synonym substitution based\nattacks that preserve the syntactic structure and semantic information of the\noriginal text while fooling the deep learning models. We contribute in this\ndirection and propose a novel adversarial defense method called Synonym\nEncoding Method (SEM). Specifically, SEM inserts an encoder before the input\nlayer of the target model to map each cluster of synonyms to a unique encoding\nand trains the model to eliminate possible adversarial perturbations without\nmodifying the network architecture or adding extra data. Extensive experiments\ndemonstrate that SEM can effectively defend the current synonym substitution\nbased attacks and block the transferability of adversarial examples. SEM is\nalso easy and efficient to scale to large models and big datasets.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 03:35:18 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 06:11:54 GMT"}, {"version": "v3", "created": "Wed, 8 Apr 2020 01:23:25 GMT"}, {"version": "v4", "created": "Tue, 15 Jun 2021 02:08:45 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Wang", "Xiaosen", ""], ["Jin", "Hao", ""], ["Yang", "Yichen", ""], ["He", "Kun", ""]]}, {"id": "1909.06731", "submitter": "Yoshihiko Suhara", "authors": "Wataru Hirota, Yoshihiko Suhara, Behzad Golshan, Wang-Chiew Tan", "title": "Emu: Enhancing Multilingual Sentence Embeddings with Semantic\n  Specialization", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Emu, a system that semantically enhances multilingual sentence\nembeddings. Our framework fine-tunes pre-trained multilingual sentence\nembeddings using two main components: a semantic classifier and a language\ndiscriminator. The semantic classifier improves the semantic similarity of\nrelated sentences, whereas the language discriminator enhances the\nmultilinguality of the embeddings via multilingual adversarial training. Our\nexperimental results based on several language pairs show that our specialized\nembeddings outperform the state-of-the-art multilingual sentence embedding\nmodel on the task of cross-lingual intent classification using only monolingual\nlabeled data.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 04:31:21 GMT"}, {"version": "v2", "created": "Sun, 24 Nov 2019 17:21:37 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Hirota", "Wataru", ""], ["Suhara", "Yoshihiko", ""], ["Golshan", "Behzad", ""], ["Tan", "Wang-Chiew", ""]]}, {"id": "1909.06743", "submitter": "Harsh Jhamtani", "authors": "Harsh Jhamtani, Sanket Vaibhav Mehta, Jaime Carbonell, Taylor\n  Berg-Kirkpatrick", "title": "Learning Rhyming Constraints using Structured Adversaries", "comments": "EMNLP-IJCNLP 2019 Short Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing recurrent neural language models often fail to capture higher-level\nstructure present in text: for example, rhyming patterns present in poetry.\nMuch prior work on poetry generation uses manually defined constraints which\nare satisfied during decoding using either specialized decoding procedures or\nrejection sampling. The rhyming constraints themselves are typically not\nlearned by the generator. We propose an alternate approach that uses a\nstructured discriminator to learn a poetry generator that directly captures\nrhyming constraints in a generative adversarial setup. By causing the\ndiscriminator to compare poems based only on a learned similarity matrix of\npairs of line ending words, the proposed approach is able to successfully learn\nrhyming patterns in two different English poetry datasets (Sonnet and Limerick)\nwithout explicitly being provided with any phonetic information.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 05:58:09 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Jhamtani", "Harsh", ""], ["Mehta", "Sanket Vaibhav", ""], ["Carbonell", "Jaime", ""], ["Berg-Kirkpatrick", "Taylor", ""]]}, {"id": "1909.06762", "submitter": "Libo Qin", "authors": "Libo Qin, Yijia Liu, Wanxiang Che, Haoyang Wen, Yangming Li, Ting Liu", "title": "Entity-Consistent End-to-end Task-Oriented Dialogue System with KB\n  Retriever", "comments": "Accepted at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Querying the knowledge base (KB) has long been a challenge in the end-to-end\ntask-oriented dialogue system. Previous sequence-to-sequence (Seq2Seq) dialogue\ngeneration work treats the KB query as an attention over the entire KB, without\nthe guarantee that the generated entities are consistent with each other. In\nthis paper, we propose a novel framework which queries the KB in two steps to\nimprove the consistency of generated entities. In the first step, inspired by\nthe observation that a response can usually be supported by a single KB row, we\nintroduce a KB retrieval component which explicitly returns the most relevant\nKB row given a dialogue history. The retrieval result is further used to filter\nthe irrelevant entities in a Seq2Seq response generation model to improve the\nconsistency among the output entities. In the second step, we further perform\nthe attention mechanism to address the most correlated KB column. Two methods\nare proposed to make the training feasible without labeled retrieval data,\nwhich include distant supervision and Gumbel-Softmax technique. Experiments on\ntwo publicly available task oriented dialog datasets show the effectiveness of\nour model by outperforming the baseline systems and producing entity-consistent\nresponses.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 08:50:59 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 02:12:27 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Qin", "Libo", ""], ["Liu", "Yijia", ""], ["Che", "Wanxiang", ""], ["Wen", "Haoyang", ""], ["Li", "Yangming", ""], ["Liu", "Ting", ""]]}, {"id": "1909.06775", "submitter": "Yuxuan Wang", "authors": "Yuxuan Wang, Wanxiang Che, Jiang Guo, Yijia Liu, Ting Liu", "title": "Cross-Lingual BERT Transformation for Zero-Shot Dependency Parsing", "comments": "to appear at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the problem of learning cross-lingual representations\nin a contextual space. We propose Cross-Lingual BERT Transformation (CLBT), a\nsimple and efficient approach to generate cross-lingual contextualized word\nembeddings based on publicly available pre-trained BERT models (Devlin et al.,\n2018). In this approach, a linear transformation is learned from contextual\nword alignments to align the contextualized embeddings independently trained in\ndifferent languages. We demonstrate the effectiveness of this approach on\nzero-shot cross-lingual transfer parsing. Experiments show that our embeddings\nsubstantially outperform the previous state-of-the-art that uses static\nembeddings. We further compare our approach with XLM (Lample and Conneau,\n2019), a recently proposed cross-lingual language model trained with massive\nparallel data, and achieve highly competitive results.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 10:33:17 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Wang", "Yuxuan", ""], ["Che", "Wanxiang", ""], ["Guo", "Jiang", ""], ["Liu", "Yijia", ""], ["Liu", "Ting", ""]]}, {"id": "1909.06805", "submitter": "Keonnyeong Lee", "authors": "Keonnyeong Lee, In-Chul Yoo, and Dongsuk Yook", "title": "Many-to-Many Voice Conversion using Cycle-Consistent Variational\n  Autoencoder with Multiple Decoders", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the obstacles in many-to-many voice conversion is the requirement of\nthe parallel training data, which contain pairs of utterances with the same\nlinguistic content spoken by different speakers. Since collecting such parallel\ndata is a highly expensive task, many works attempted to use non-parallel\ntraining data for many-to-many voice conversion. One of such approaches is\nusing the variational autoencoder (VAE). Though it can handle many-to-many\nvoice conversion without the parallel training, the VAE based voice conversion\nmethods suffer from low sound qualities of the converted speech. One of the\nmajor reasons is because the VAE learns only the self-reconstruction path. The\nconversion path is not trained at all. In this paper, we propose a cycle\nconsistency loss for VAE to explicitly learn the conversion path. In addition,\nwe propose to use multiple decoders to further improve the sound qualities of\nthe conventional VAE based voice conversion methods. The effectiveness of the\nproposed method is validated using objective and the subjective evaluations.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 14:03:40 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 07:05:43 GMT"}, {"version": "v3", "created": "Tue, 5 Nov 2019 23:38:33 GMT"}, {"version": "v4", "created": "Sun, 2 Feb 2020 05:24:56 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Lee", "Keonnyeong", ""], ["Yoo", "In-Chul", ""], ["Yook", "Dongsuk", ""]]}, {"id": "1909.06814", "submitter": "Leshem Choshen", "authors": "Leshem Choshen and Omri Abend", "title": "Automatically Extracting Challenge Sets for Non local Phenomena in\n  Neural Machine Translation", "comments": "Accepted for CoNLL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the state of the art Transformer Machine Translation (MT) model\nis not biased towards monotonic reordering (unlike previous recurrent neural\nnetwork models), but that nevertheless, long-distance dependencies remain a\nchallenge for the model. Since most dependencies are short-distance, common\nevaluation metrics will be little influenced by how well systems perform on\nthem. We, therefore, propose an automatic approach for extracting challenge\nsets replete with long-distance dependencies and argue that evaluation using\nthis methodology provides a complementary perspective on system performance. To\nsupport our claim, we compile challenge sets for English-German and\nGerman-English, which are much larger than any previously released challenge\nset for MT. The extracted sets are large enough to allow reliable automatic\nevaluation, which makes the proposed approach a scalable and practical solution\nfor evaluating MT performance on the long-tail of syntactic phenomena.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 15:21:20 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 08:26:01 GMT"}, {"version": "v3", "created": "Thu, 19 Sep 2019 06:29:07 GMT"}, {"version": "v4", "created": "Wed, 25 Sep 2019 08:18:21 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Choshen", "Leshem", ""], ["Abend", "Omri", ""]]}, {"id": "1909.06845", "submitter": "Diederik Aerts", "authors": "Diederik Aerts and Lester Beltran", "title": "Quantum Structure in Cognition: Human Language as a Boson Gas of\n  Entangled Words", "comments": "45 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CL quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We model a piece of text of human language telling a story by means of the\nquantum structure describing a Bose gas in a state close to a Bose-Einstein\ncondensate near absolute zero temperature. For this we introduce energy levels\nfor the words (concepts) used in the story and we also introduce the new notion\nof 'cogniton' as the quantum of human thought. Words (concepts) are then\ncognitons in different energy states as it is the case for photons in different\nenergy states, or states of different radiative frequency, when the considered\nboson gas is that of the quanta of the electromagnetic field. We show that\nBose-Einstein statistics delivers a very good model for these pieces of texts\ntelling stories, both for short stories and for long stories of the size of\nnovels. We analyze an unexpected connection with Zipf's law in human language,\nthe Zipf ranking relating to the energy levels of the words, and the\nBose-Einstein graph coinciding with the Zipf graph. We investigate the issue of\n'identity and indistinguishability' from this new perspective and conjecture\nthat the way one can easily understand how two of 'the same concepts' are\n'absolutely identical and indistinguishable' in human language is also the way\nin which quantum particles are absolutely identical and indistinguishable in\nphysical reality, providing in this way new evidence for our conceptuality\ninterpretation of quantum theory.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 17:40:57 GMT"}, {"version": "v2", "created": "Sat, 5 Oct 2019 17:15:59 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Aerts", "Diederik", ""], ["Beltran", "Lester", ""]]}, {"id": "1909.06877", "submitter": "Su Wang", "authors": "Su Wang, Greg Durrett, Katrin Erk", "title": "Query-Focused Scenario Construction", "comments": "Accepted at EMNLP-IJCNLP 2019", "journal-ref": "EMNLP-IJCNLP 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The news coverage of events often contains not one but multiple incompatible\naccounts of what happened. We develop a query-based system that extracts\ncompatible sets of events (scenarios) from such data, formulated as one-class\nclustering. Our system incrementally evaluates each event's compatibility with\nalready selected events, taking order into account. We use synthetic data\nconsisting of article mixtures for scalable training and evaluate our model on\na new human-curated dataset of scenarios about real-world news topics. Stronger\nneural network models and harder synthetic training settings are both important\nto achieve high performance, and our final scenario construction system\nsubstantially outperforms baselines based on prior work.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 20:25:22 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Wang", "Su", ""], ["Durrett", "Greg", ""], ["Erk", "Katrin", ""]]}, {"id": "1909.06886", "submitter": "Xueping Peng", "authors": "Xueping Peng, Guodong Long, Tao Shen, Sen Wang, Jing Jiang, Michael\n  Blumenstein", "title": "Temporal Self-Attention Network for Medical Concept Embedding", "comments": "10 pages, 7 figures, accepted at IEEE ICDM 2019", "journal-ref": null, "doi": "10.1109/ICDM.2019.00060", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In longitudinal electronic health records (EHRs), the event records of a\npatient are distributed over a long period of time and the temporal relations\nbetween the events reflect sufficient domain knowledge to benefit prediction\ntasks such as the rate of inpatient mortality. Medical concept embedding as a\nfeature extraction method that transforms a set of medical concepts with a\nspecific time stamp into a vector, which will be fed into a supervised learning\nalgorithm. The quality of the embedding significantly determines the learning\nperformance over the medical data. In this paper, we propose a medical concept\nembedding method based on applying a self-attention mechanism to represent each\nmedical concept. We propose a novel attention mechanism which captures the\ncontextual information and temporal relationships between medical concepts. A\nlight-weight neural net, \"Temporal Self-Attention Network (TeSAN)\", is then\nproposed to learn medical concept embedding based solely on the proposed\nattention mechanism. To test the effectiveness of our proposed methods, we have\nconducted clustering and prediction tasks on two public EHRs datasets comparing\nTeSAN against five state-of-the-art embedding methods. The experimental results\ndemonstrate that the proposed TeSAN model is superior to all the compared\nmethods. To the best of our knowledge, this work is the first to exploit\ntemporal self-attentive relations between medical events.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 21:20:09 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Peng", "Xueping", ""], ["Long", "Guodong", ""], ["Shen", "Tao", ""], ["Wang", "Sen", ""], ["Jiang", "Jing", ""], ["Blumenstein", "Michael", ""]]}, {"id": "1909.06937", "submitter": "Yijin Liu", "authors": "Yijin Liu, Fandong Meng, Jinchao Zhang, Jie Zhou, Yufeng Chen and\n  Jinan Xu", "title": "CM-Net: A Novel Collaborative Memory Network for Spoken Language\n  Understanding", "comments": "Accepted as a long paper at EMNLP 2019. Code and data is available\n  at: https://github.com/Adaxry/CM-Net", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spoken Language Understanding (SLU) mainly involves two tasks, intent\ndetection and slot filling, which are generally modeled jointly in existing\nworks. However, most existing models fail to fully utilize co-occurrence\nrelations between slots and intents, which restricts their potential\nperformance. To address this issue, in this paper we propose a novel\nCollaborative Memory Network (CM-Net) based on the well-designed block, named\nCM-block. The CM-block firstly captures slot-specific and intent-specific\nfeatures from memories in a collaborative manner, and then uses these enriched\nfeatures to enhance local context representations, based on which the\nsequential information flow leads to more specific (slot and intent) global\nutterance representations. Through stacking multiple CM-blocks, our CM-Net is\nable to alternately perform information exchange among specific memories, local\ncontexts and the global utterance, and thus incrementally enriches each other.\nWe evaluate the CM-Net on two standard benchmarks (ATIS and SNIPS) and a\nself-collected corpus (CAIS). Experimental results show that the CM-Net\nachieves the state-of-the-art results on the ATIS and SNIPS in most of\ncriteria, and significantly outperforms the baseline models on the CAIS.\nAdditionally, we make the CAIS dataset publicly available for the research\ncommunity.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 02:10:58 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Liu", "Yijin", ""], ["Meng", "Fandong", ""], ["Zhang", "Jinchao", ""], ["Zhou", "Jie", ""], ["Chen", "Yufeng", ""], ["Xu", "Jinan", ""]]}, {"id": "1909.07005", "submitter": "Seungyoung Lim", "authors": "Seungyoung Lim, Myungji Kim, Jooyoul Lee", "title": "KorQuAD1.0: Korean QA Dataset for Machine Reading Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Reading Comprehension (MRC) is a task that requires machine to\nunderstand natural language and answer questions by reading a document. It is\nthe core of automatic response technology such as chatbots and automatized\ncustomer supporting systems. We present Korean Question Answering\nDataset(KorQuAD), a large-scale Korean dataset for extractive machine reading\ncomprehension task. It consists of 70,000+ human generated question-answer\npairs on Korean Wikipedia articles. We release KorQuAD1.0 and launch a\nchallenge at https://KorQuAD.github.io to encourage the development of\nmultilingual natural language processing research.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 06:15:27 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 04:09:21 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Lim", "Seungyoung", ""], ["Kim", "Myungji", ""], ["Lee", "Jooyoul", ""]]}, {"id": "1909.07009", "submitter": "Guokun Lai", "authors": "Guokun Lai, Barlas Oguz, Yiming Yang, Veselin Stoyanov", "title": "Bridging the domain gap in cross-lingual document classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scarcity of labeled training data often prohibits the\ninternationalization of NLP models to multiple languages. Recent developments\nin cross-lingual understanding (XLU) has made progress in this area, trying to\nbridge the language barrier using language universal representations. However,\neven if the language problem was resolved, models trained in one language would\nnot transfer to another language perfectly due to the natural domain drift\nacross languages and cultures. We consider the setting of semi-supervised\ncross-lingual understanding, where labeled data is available in a source\nlanguage (English), but only unlabeled data is available in the target\nlanguage. We combine state-of-the-art cross-lingual methods with recently\nproposed methods for weakly supervised learning such as unsupervised\npre-training and unsupervised data augmentation to simultaneously close both\nthe language gap and the domain gap in XLU. We show that addressing the domain\ngap is crucial. We improve over strong baselines and achieve a new\nstate-of-the-art for cross-lingual document classification.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 06:20:23 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2019 15:30:29 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Lai", "Guokun", ""], ["Oguz", "Barlas", ""], ["Yang", "Yiming", ""], ["Stoyanov", "Veselin", ""]]}, {"id": "1909.07054", "submitter": "Sebastien Cossin", "authors": "Marine Qu\\'erou\\'e, Agn\\`es Lash\\'eras-Bauduin, Vianney Jouhet, Frantz\n  Thiessard, Jean-Marc Vital, Anne-Marie Rogues, S\\'ebastien Cossin (UB)", "title": "Automatic detection of surgical site infections from a clinical data\n  warehouse", "comments": "in French", "journal-ref": "TALMED 2019, Aug 2019, Lyon, France", "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reducing the incidence of surgical site infections (SSIs) is one of the\nobjectives of the French nosocomial infection control program. Manual\nmonitoring of SSIs is carried out each year by the hospital hygiene team and\nsurgeons at the University Hospital of Bordeaux. Our goal was to develop an\nautomatic detection algorithm based on hospital information system data. Three\nyears (2015, 2016 and 2017) of manual spine surgery monitoring have been used\nas a gold standard to extract features and train machine learning algorithms.\nThe dataset contained 22 SSIs out of 2133 spine surgeries. Two different\napproaches were compared. The first used several data sources and achieved the\nbest performance but is difficult to generalize to other institutions. The\nsecond was based on free text only with semiautomatic extraction of\ndiscriminant terms. The algorithms managed to identify all the SSIs with 20 and\n26 false positives respectively on the dataset. Another evaluation is underway.\nThese results are encouraging for the development of semi-automated\nsurveillance methods.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 08:31:20 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Qu\u00e9rou\u00e9", "Marine", "", "UB"], ["Lash\u00e9ras-Bauduin", "Agn\u00e8s", "", "UB"], ["Jouhet", "Vianney", "", "UB"], ["Thiessard", "Frantz", "", "UB"], ["Vital", "Jean-Marc", "", "UB"], ["Rogues", "Anne-Marie", "", "UB"], ["Cossin", "S\u00e9bastien", "", "UB"]]}, {"id": "1909.07063", "submitter": "Marc Dymetman", "authors": "Tetiana Parshakova and Jean-Marc Andreoli and Marc Dymetman", "title": "Global Autoregressive Models for Data-Efficient Sequence Learning", "comments": "To appear in CONLL (The SIGNLL Conference on Computational Natural\n  Language Learning) Hong Kong, Nov. 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard autoregressive seq2seq models are easily trained by max-likelihood,\nbut tend to show poor results under small-data conditions. We introduce a class\nof seq2seq models, GAMs (Global Autoregressive Models), which combine an\nautoregressive component with a log-linear component, allowing the use of\nglobal \\textit{a priori} features to compensate for lack of data. We train\nthese models in two steps. In the first step, we obtain an \\emph{unnormalized}\nGAM that maximizes the likelihood of the data, but is improper for fast\ninference or evaluation. In the second step, we use this GAM to train (by\ndistillation) a second autoregressive model that approximates the\n\\emph{normalized} distribution associated with the GAM, and can be used for\nfast inference and evaluation. Our experiments focus on language modelling\nunder synthetic conditions and show a strong perplexity reduction of using the\nsecond autoregressive model over the standard one.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 08:46:30 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 19:40:01 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Parshakova", "Tetiana", ""], ["Andreoli", "Jean-Marc", ""], ["Dymetman", "Marc", ""]]}, {"id": "1909.07083", "submitter": "Bowen Li", "authors": "Bowen Li, Xiaojuan Qi, Thomas Lukasiewicz, Philip H. S. Torr", "title": "Controllable Text-to-Image Generation", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel controllable text-to-image generative\nadversarial network (ControlGAN), which can effectively synthesise high-quality\nimages and also control parts of the image generation according to natural\nlanguage descriptions. To achieve this, we introduce a word-level spatial and\nchannel-wise attention-driven generator that can disentangle different visual\nattributes, and allow the model to focus on generating and manipulating\nsubregions corresponding to the most relevant words. Also, a word-level\ndiscriminator is proposed to provide fine-grained supervisory feedback by\ncorrelating words with image regions, facilitating training an effective\ngenerator which is able to manipulate specific visual attributes without\naffecting the generation of other content. Furthermore, perceptual loss is\nadopted to reduce the randomness involved in the image generation, and to\nencourage the generator to manipulate specific attributes required in the\nmodified text. Extensive experiments on benchmark datasets demonstrate that our\nmethod outperforms existing state of the art, and is able to effectively\nmanipulate synthetic images using natural language descriptions. Code is\navailable at https://github.com/mrlibw/ControlGAN.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 09:29:52 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 18:30:18 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Li", "Bowen", ""], ["Qi", "Xiaojuan", ""], ["Lukasiewicz", "Thomas", ""], ["Torr", "Philip H. S.", ""]]}, {"id": "1909.07101", "submitter": "Joachim Bingel", "authors": "Joachim Bingel, Victor Petr\\'en Bach Hansen, Ana Valeria Gonzalez,\n  Pawe{\\l} Budzianowski, Isabelle Augenstein, Anders S{\\o}gaard", "title": "Domain Transfer in Dialogue Systems without Turn-Level Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Task oriented dialogue systems rely heavily on specialized dialogue state\ntracking (DST) modules for dynamically predicting user intent throughout the\nconversation. State-of-the-art DST models are typically trained in a supervised\nmanner from manual annotations at the turn level. However, these annotations\nare costly to obtain, which makes it difficult to create accurate dialogue\nsystems for new domains. To address these limitations, we propose a method,\nbased on reinforcement learning, for transferring DST models to new domains\nwithout turn-level supervision. Across several domains, our experiments show\nthat this method quickly adapts off-the-shelf models to new domains and\nperforms on par with models trained with turn-level supervision. We also show\nour method can improve models trained using turn-level supervision by\nsubsequent fine-tuning optimization toward dialog-level rewards.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 10:19:02 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Bingel", "Joachim", ""], ["Hansen", "Victor Petr\u00e9n Bach", ""], ["Gonzalez", "Ana Valeria", ""], ["Budzianowski", "Pawe\u0142", ""], ["Augenstein", "Isabelle", ""], ["S\u00f8gaard", "Anders", ""]]}, {"id": "1909.07158", "submitter": "Kristian Miok", "authors": "Kristian Miok, Dong Nguyen-Doan, Bla\\v{z} \\v{S}krlj, Daniela Zaharie\n  and Marko Robnik-\\v{S}ikonja", "title": "Prediction Uncertainty Estimation for Hate Speech Classification", "comments": "The final authenticated publication is available online at\n  https://doi.org/10.1007/978-3-030-31372-2_24", "journal-ref": "Statistical Language and Speech Processing 2019 Proceedings", "doi": "10.1007/978-3-030-31372-2_24", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a result of social network popularity, in recent years, hate speech\nphenomenon has significantly increased. Due to its harmful effect on minority\ngroups as well as on large communities, there is a pressing need for hate\nspeech detection and filtering. However, automatic approaches shall not\njeopardize free speech, so they shall accompany their decisions with\nexplanations and assessment of uncertainty. Thus, there is a need for\npredictive machine learning models that not only detect hate speech but also\nhelp users understand when texts cross the line and become unacceptable. The\nreliability of predictions is usually not addressed in text classification. We\nfill this gap by proposing the adaptation of deep neural networks that can\nefficiently estimate prediction uncertainty. To reliably detect hate speech, we\nuse Monte Carlo dropout regularization, which mimics Bayesian inference within\nneural networks. We evaluate our approach using different text embedding\nmethods. We visualize the reliability of results with a novel technique that\naids in understanding the classification reliability and errors.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 12:43:17 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 14:29:59 GMT"}, {"version": "v3", "created": "Thu, 12 Dec 2019 11:59:54 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Miok", "Kristian", ""], ["Nguyen-Doan", "Dong", ""], ["\u0160krlj", "Bla\u017e", ""], ["Zaharie", "Daniela", ""], ["Robnik-\u0160ikonja", "Marko", ""]]}, {"id": "1909.07285", "submitter": "Camille Goudeseune", "authors": "Mark Hasegawa-Johnson, Camille Goudeseune, Gina-Anne Levow", "title": "Fast transcription of speech in low-resource languages", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present software that, in only a few hours, transcribes forty hours of\nrecorded speech in a surprise language, using only a few tens of megabytes of\nnoisy text in that language, and a zero-resource grapheme to phoneme (G2P)\ntable. A pretrained acoustic model maps acoustic features to phonemes; a\nreversed G2P maps these to graphemes; then a language model maps these to a\nmost-likely grapheme sequence, i.e., a transcription. This software has worked\nsuccessfully with corpora in Arabic, Assam, Kinyarwanda, Russian, Sinhalese,\nSwahili, Tagalog, and Tamil.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 15:38:36 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Hasegawa-Johnson", "Mark", ""], ["Goudeseune", "Camille", ""], ["Levow", "Gina-Anne", ""]]}, {"id": "1909.07290", "submitter": "Benjamin Newman", "authors": "Benjamin Newman, Reuben Cohn-Gordon, Christopher Potts", "title": "Communication-based Evaluation for Natural Language Generation", "comments": "11 pages, 2 figures, SCiL, camera-ready - clarified certain points,\n  updated acknowledgements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language generation (NLG) systems are commonly evaluated using n-gram\noverlap measures (e.g. BLEU, ROUGE). These measures do not directly capture\nsemantics or speaker intentions, and so they often turn out to be misaligned\nwith our true goals for NLG. In this work, we argue instead for\ncommunication-based evaluations: assuming the purpose of an NLG system is to\nconvey information to a reader/listener, we can directly evaluate its\neffectiveness at this task using the Rational Speech Acts model of pragmatic\nlanguage use. We illustrate with a color reference dataset that contains\ndescriptions in pre-defined quality categories, showing that our method better\naligns with these quality categories than do any of the prominent n-gram\noverlap methods.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 15:42:36 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 05:24:46 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Newman", "Benjamin", ""], ["Cohn-Gordon", "Reuben", ""], ["Potts", "Christopher", ""]]}, {"id": "1909.07342", "submitter": "Surafel Melaku Lakew Mr.", "authors": "Surafel M. Lakew, Marcello Federico, Matteo Negri, Marco Turchi", "title": "Multilingual Neural Machine Translation for Zero-Resource Languages", "comments": "15 pages, Published on Italian Journal of Computational Linguistics\n  (IJCoL) -- Multilingual Neural Machine Translation for Low-Resource\n  Languages, June 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In recent years, Neural Machine Translation (NMT) has been shown to be more\neffective than phrase-based statistical methods, thus quickly becoming the\nstate of the art in machine translation (MT). However, NMT systems are limited\nin translating low-resourced languages, due to the significant amount of\nparallel data that is required to learn useful mappings between languages. In\nthis work, we show how the so-called multilingual NMT can help to tackle the\nchallenges associated with low-resourced language translation. The underlying\nprinciple of multilingual NMT is to force the creation of hidden\nrepresentations of words in a shared semantic space across multiple languages,\nthus enabling a positive parameter transfer across languages. Along this\ndirection, we present multilingual translation experiments with three languages\n(English, Italian, Romanian) covering six translation directions, utilizing\nboth recurrent neural networks and transformer (or self-attentive) neural\nnetworks. We then focus on the zero-shot translation problem, that is how to\nleverage multi-lingual data in order to learn translation directions that are\nnot covered by the available training material. To this aim, we introduce our\nrecently proposed iterative self-training method, which incrementally improves\na multilingual NMT on a zero-shot direction by just relying on monolingual\ndata. Our results on TED talks data show that multilingual NMT outperforms\nconventional bilingual NMT, that the transformer NMT outperforms recurrent NMT,\nand that zero-shot NMT outperforms conventional pivoting methods and even\nmatches the performance of a fully-trained bilingual system.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 17:22:25 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Lakew", "Surafel M.", ""], ["Federico", "Marcello", ""], ["Negri", "Matteo", ""], ["Turchi", "Marco", ""]]}, {"id": "1909.07405", "submitter": "Peter West", "authors": "Peter West, Ari Holtzman, Jan Buys, Yejin Choi", "title": "BottleSum: Unsupervised and Self-supervised Sentence Summarization using\n  the Information Bottleneck Principle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The principle of the Information Bottleneck (Tishby et al. 1999) is to\nproduce a summary of information X optimized to predict some other relevant\ninformation Y. In this paper, we propose a novel approach to unsupervised\nsentence summarization by mapping the Information Bottleneck principle to a\nconditional language modelling objective: given a sentence, our approach seeks\na compressed sentence that can best predict the next sentence. Our iterative\nalgorithm under the Information Bottleneck objective searches gradually shorter\nsubsequences of the given sentence while maximizing the probability of the next\nsentence conditioned on the summary. Using only pretrained language models with\nno direct supervision, our approach can efficiently perform extractive sentence\nsummarization over a large corpus.\n  Building on our unsupervised extractive summarization (BottleSumEx), we then\npresent a new approach to self-supervised abstractive summarization\n(BottleSumSelf), where a transformer-based language model is trained on the\noutput summaries of our unsupervised method. Empirical results demonstrate that\nour extractive method outperforms other unsupervised models on multiple\nautomatic metrics. In addition, we find that our self-supervised abstractive\nmodel outperforms unsupervised baselines (including our own) by human\nevaluation along multiple attributes.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 18:00:24 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2019 16:39:51 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["West", "Peter", ""], ["Holtzman", "Ari", ""], ["Buys", "Jan", ""], ["Choi", "Yejin", ""]]}, {"id": "1909.07502", "submitter": "Benjamin Shickel", "authors": "Benjamin Shickel, Scott Siegel, Martin Heesacker, Sherry Benton, and\n  Parisa Rashidi", "title": "Automatic Detection and Classification of Cognitive Distortions in\n  Mental Health Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cognitive psychology, automatic and self-reinforcing irrational thought\npatterns are known as cognitive distortions. Left unchecked, patients\nexhibiting these types of thoughts can become stuck in negative feedback loops\nof unhealthy thinking, leading to inaccurate perceptions of reality commonly\nassociated with anxiety and depression. In this paper, we present a machine\nlearning framework for the automatic detection and classification of 15 common\ncognitive distortions in two novel mental health free text datasets collected\nfrom both crowdsourcing and a real-world online therapy program. When\ndifferentiating between distorted and non-distorted passages, our model\nachieved a weighted F1 score of 0.88. For classifying distorted passages into\none of 15 distortion categories, our model yielded weighted F1 scores of 0.68\nin the larger crowdsourced dataset and 0.45 in the smaller online counseling\ndataset, both of which outperformed random baseline metrics by a large margin.\nFor both tasks, we also identified the most discriminative words and phrases\nbetween classes to highlight common thematic elements for improving targeted\nand therapist-guided mental health treatment. Furthermore, we performed an\nexploratory analysis using unsupervised content-based clustering and topic\nmodeling algorithms as first efforts towards a data-driven perspective on the\nthematic relationship between similar cognitive distortions traditionally\ndeemed unique. Finally, we highlight the difficulties in applying mental\nhealth-based machine learning in a real-world setting and comment on the\nimplications and benefits of our framework for improving automated delivery of\ntherapeutic treatment in conjunction with traditional cognitive-behavioral\ntherapy.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 22:21:27 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 00:50:07 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Shickel", "Benjamin", ""], ["Siegel", "Scott", ""], ["Heesacker", "Martin", ""], ["Benton", "Sherry", ""], ["Rashidi", "Parisa", ""]]}, {"id": "1909.07512", "submitter": "Duncan Cameron-Steinke", "authors": "Duncan Cameron-Steinke", "title": "Short-Text Classification Using Unsupervised Keyword Expansion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Short-text classification, like all data science, struggles to achieve high\nperformance using limited data. As a solution, a short sentence may be expanded\nwith new and relevant feature words to form an artificially enlarged dataset,\nand add new features to testing data. This paper applies a novel approach to\ntext expansion by generating new words directly for each input sentence, thus\nrequiring no additional datasets or previous training. In this unsupervised\napproach, new keywords are formed within the hidden states of a pre-trained\nlanguage model and then used to create extended pseudo documents. The word\ngeneration process was assessed by examining how well the predicted words\nmatched to topics of the input sentence. It was found that this method could\nproduce 3-10 relevant new words for each target topic, while generating just 1\nword related to each non-target topic. Generated words were then added to short\nnews headlines to create extended pseudo headlines. Experimental results have\nshown that models trained using the pseudo headlines can improve classification\naccuracy when limiting the number of training examples.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 22:51:29 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Cameron-Steinke", "Duncan", ""]]}, {"id": "1909.07521", "submitter": "Kyle Richardson", "authors": "Kyle Richardson and Hai Hu and Lawrence S. Moss and Ashish Sabharwal", "title": "Probing Natural Language Inference Models through Semantic Fragments", "comments": "AAAI camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Do state-of-the-art models for language understanding already have, or can\nthey easily learn, abilities such as boolean coordination, quantification,\nconditionals, comparatives, and monotonicity reasoning (i.e., reasoning about\nword substitutions in sentential contexts)? While such phenomena are involved\nin natural language inference (NLI) and go beyond basic linguistic\nunderstanding, it is unclear the extent to which they are captured in existing\nNLI benchmarks and effectively learned by models. To investigate this, we\npropose the use of semantic fragments---systematically generated datasets that\neach target a different semantic phenomenon---for probing, and efficiently\nimproving, such capabilities of linguistic models. This approach to creating\nchallenge datasets allows direct control over the semantic diversity and\ncomplexity of the targeted linguistic phenomena, and results in a more precise\ncharacterization of a model's linguistic behavior. Our experiments, using a\nlibrary of 8 such semantic fragments, reveal two remarkable findings: (a)\nState-of-the-art models, including BERT, that are pre-trained on existing NLI\nbenchmark datasets perform poorly on these new fragments, even though the\nphenomena probed here are central to the NLI task. (b) On the other hand, with\nonly a few minutes of additional fine-tuning---with a carefully selected\nlearning rate and a novel variation of \"inoculation\"---a BERT-based model can\nmaster all of these logic and monotonicity fragments while retaining its\nperformance on established NLI benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 23:44:49 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 01:18:37 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Richardson", "Kyle", ""], ["Hu", "Hai", ""], ["Moss", "Lawrence S.", ""], ["Sabharwal", "Ashish", ""]]}, {"id": "1909.07523", "submitter": "Lianwei Wu", "authors": "Lianwei Wu, Yuan Rao, Ambreen Nazir, Haolin Jin", "title": "Discovering Differential Features: Adversarial Learning for Information\n  Credibility Evaluation", "comments": "Information Sciences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A series of deep learning approaches extract a large number of credibility\nfeatures to detect fake news on the Internet. However, these extracted features\nstill suffer from many irrelevant and noisy features that restrict severely the\nperformance of the approaches. In this paper, we propose a novel model based on\nAdversarial Networks and inspirited by the Shared-Private model (ANSP), which\naims at reducing common, irrelevant features from the extracted features for\ninformation credibility evaluation. Specifically, ANSP involves two tasks: one\nis to prevent the binary classification of true and false information for\ncapturing common features relying on adversarial networks guided by\nreinforcement learning. Another extracts credibility features (henceforth,\nprivate features) from multiple types of credibility information and compares\nwith the common features through two strategies, i.e., orthogonality\nconstraints and KL-divergence for making the private features more\ndifferential. Experiments first on two six-label LIAR and Weibo datasets\ndemonstrate that ANSP achieves the state-of-the-art performance, boosting the\naccuracy by 2.1%, 3.1%, respectively and then on four-label Twitter16 validate\nthe robustness of the model with 1.8% performance improvements.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 23:53:59 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Wu", "Lianwei", ""], ["Rao", "Yuan", ""], ["Nazir", "Ambreen", ""], ["Jin", "Haolin", ""]]}, {"id": "1909.07575", "submitter": "Chengyi Wang", "authors": "Chengyi Wang, Yu Wu, Shujie Liu, Zhenglu Yang and Ming Zhou", "title": "Bridging the Gap between Pre-Training and Fine-Tuning for End-to-End\n  Speech Translation", "comments": "AAAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end speech translation, a hot topic in recent years, aims to translate\na segment of audio into a specific language with an end-to-end model.\nConventional approaches employ multi-task learning and pre-training methods for\nthis task, but they suffer from the huge gap between pre-training and\nfine-tuning. To address these issues, we propose a Tandem Connectionist\nEncoding Network (TCEN) which bridges the gap by reusing all subnets in\nfine-tuning, keeping the roles of subnets consistent, and pre-training the\nattention module. Furthermore, we propose two simple but effective methods to\nguarantee the speech encoder outputs and the MT encoder inputs are consistent\nin terms of semantic representation and sequence length. Experimental results\nshow that our model outperforms baselines 2.2 BLEU on a large benchmark\ndataset.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 03:47:25 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 01:41:08 GMT"}, {"version": "v3", "created": "Mon, 18 Nov 2019 07:52:43 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Wang", "Chengyi", ""], ["Wu", "Yu", ""], ["Liu", "Shujie", ""], ["Yang", "Zhenglu", ""], ["Zhou", "Ming", ""]]}, {"id": "1909.07583", "submitter": "Yuhong Guo", "authors": "Yaser Alwattar and Yuhong Guo", "title": "Inverse Visual Question Answering with Multi-Level Attentions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel deep multi-level attention model to address\ninverse visual question answering. The proposed model generates regional visual\nand semantic features at the object level and then enhances them with the\nanswer cue by using attention mechanisms. Two levels of multiple attentions are\nemployed in the model, including the dual attention at the partial question\nencoding step and the dynamic attention at the next question word generation\nstep. We evaluate the proposed model on the VQA V1 dataset. It demonstrates\nstate-of-the-art performance in terms of multiple commonly used metrics.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 04:41:12 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 00:13:21 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Alwattar", "Yaser", ""], ["Guo", "Yuhong", ""]]}, {"id": "1909.07586", "submitter": "Xudong Han", "authors": "Xudong Han, Philip Schulz, and Trevor Cohn", "title": "Grounding learning of modifier dynamics: An application to color naming", "comments": "EMNLP 2019 (5 pages + 1 references)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grounding is crucial for natural language understanding. An important subtask\nis to understand modified color expressions, such as 'dirty blue'. We present a\nmodel of color modifiers that, compared with previous additive models in RGB\nspace, learns more complex transformations. In addition, we present a model\nthat operates in the HSV color space. We show that certain adjectives are\nbetter modeled in that space. To account for all modifiers, we train a hard\nensemble model that selects a color space depending on the modifier color pair.\nExperimental results show significant and consistent improvements compared to\nthe state-of-the-art baseline model.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 04:49:25 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Han", "Xudong", ""], ["Schulz", "Philip", ""], ["Cohn", "Trevor", ""]]}, {"id": "1909.07593", "submitter": "Hao Li", "authors": "Hao Li, Wei Lu", "title": "Learning Explicit and Implicit Structures for Targeted Sentiment\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Targeted sentiment analysis is the task of jointly predicting target entities\nand their associated sentiment information. Existing research efforts mostly\nregard this joint task as a sequence labeling problem, building models that can\ncapture explicit structures in the output space. However, the importance of\ncapturing implicit global structural information that resides in the input\nspace is largely unexplored. In this work, we argue that both types of\ninformation (implicit and explicit structural information) are crucial for\nbuilding a successful targeted sentiment analysis model. Our experimental\nresults show that properly capturing both information is able to lead to better\nperformance than competitive existing approaches. We also conduct extensive\nexperiments to investigate our model's effectiveness and robustness.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 05:03:43 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Li", "Hao", ""], ["Lu", "Wei", ""]]}, {"id": "1909.07597", "submitter": "Wenhan Xiong", "authors": "Wenhan Xiong, Mo Yu, Xiaoxiao Guo, Hong Wang, Shiyu Chang, Murray\n  Campbell and William Yang Wang", "title": "Simple yet Effective Bridge Reasoning for Open-Domain Multi-Hop Question\n  Answering", "comments": "MRQA'19 at EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key challenge of multi-hop question answering (QA) in the open-domain\nsetting is to accurately retrieve the supporting passages from a large corpus.\nExisting work on open-domain QA typically relies on off-the-shelf information\nretrieval (IR) techniques to retrieve \\textbf{answer passages}, i.e., the\npassages containing the groundtruth answers. However, IR-based approaches are\ninsufficient for multi-hop questions, as the topic of the second or further\nhops is not explicitly covered by the question. To resolve this issue, we\nintroduce a new sub-problem of open-domain multi-hop QA, which aims to\nrecognize the bridge (\\emph{i.e.}, the anchor that links to the answer passage)\nfrom the context of a set of start passages with a reading comprehension model.\nThis model, the \\textbf{bridge reasoner}, is trained with a weakly supervised\nsignal and produces the candidate answer passages for the \\textbf{passage\nreader} to extract the answer. On the full-wiki HotpotQA benchmark, we\nsignificantly improve the baseline method by 14 point F1. Without using any\nmemory-inefficient contextual embeddings, our result is also competitive with\nthe state-of-the-art that applies BERT in multiple modules.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 05:15:05 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 20:22:29 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Xiong", "Wenhan", ""], ["Yu", "Mo", ""], ["Guo", "Xiaoxiao", ""], ["Wang", "Hong", ""], ["Chang", "Shiyu", ""], ["Campbell", "Murray", ""], ["Wang", "William Yang", ""]]}, {"id": "1909.07598", "submitter": "Rajarshi Das", "authors": "Ameya Godbole, Dilip Kavarthapu, Rajarshi Das, Zhiyu Gong, Abhishek\n  Singhal, Hamed Zamani, Mo Yu, Tian Gao, Xiaoxiao Guo, Manzil Zaheer and\n  Andrew McCallum", "title": "Multi-step Entity-centric Information Retrieval for Multi-Hop Question\n  Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-hop question answering (QA) requires an information retrieval (IR)\nsystem that can find \\emph{multiple} supporting evidence needed to answer the\nquestion, making the retrieval process very challenging. This paper introduces\nan IR technique that uses information of entities present in the initially\nretrieved evidence to learn to `\\emph{hop}' to other relevant evidence. In a\nsetting, with more than \\textbf{5 million} Wikipedia paragraphs, our approach\nleads to significant boost in retrieval performance. The retrieved evidence\nalso increased the performance of an existing QA model (without any training)\non the \\hotpot benchmark by \\textbf{10.59} F1.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 05:23:50 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Godbole", "Ameya", ""], ["Kavarthapu", "Dilip", ""], ["Das", "Rajarshi", ""], ["Gong", "Zhiyu", ""], ["Singhal", "Abhishek", ""], ["Zamani", "Hamed", ""], ["Yu", "Mo", ""], ["Gao", "Tian", ""], ["Guo", "Xiaoxiao", ""], ["Zaheer", "Manzil", ""], ["McCallum", "Andrew", ""]]}, {"id": "1909.07606", "submitter": "Weijie Liu", "authors": "Weijie Liu, Peng Zhou, Zhe Zhao, Zhiruo Wang, Qi Ju, Haotang Deng and\n  Ping Wang", "title": "K-BERT: Enabling Language Representation with Knowledge Graph", "comments": "8 pages, 20190917", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained language representation models, such as BERT, capture a general\nlanguage representation from large-scale corpora, but lack domain-specific\nknowledge. When reading a domain text, experts make inferences with relevant\nknowledge. For machines to achieve this capability, we propose a\nknowledge-enabled language representation model (K-BERT) with knowledge graphs\n(KGs), in which triples are injected into the sentences as domain knowledge.\nHowever, too much knowledge incorporation may divert the sentence from its\ncorrect meaning, which is called knowledge noise (KN) issue. To overcome KN,\nK-BERT introduces soft-position and visible matrix to limit the impact of\nknowledge. K-BERT can easily inject domain knowledge into the models by\nequipped with a KG without pre-training by-self because it is capable of\nloading model parameters from the pre-trained BERT. Our investigation reveals\npromising results in twelve NLP tasks. Especially in domain-specific tasks\n(including finance, law, and medicine), K-BERT significantly outperforms BERT,\nwhich demonstrates that K-BERT is an excellent choice for solving the\nknowledge-driven problems that require experts.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 06:16:04 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Liu", "Weijie", ""], ["Zhou", "Peng", ""], ["Zhao", "Zhe", ""], ["Wang", "Zhiruo", ""], ["Ju", "Qi", ""], ["Deng", "Haotang", ""], ["Wang", "Ping", ""]]}, {"id": "1909.07734", "submitter": "Boaz Shmueli", "authors": "Boaz Shmueli, Lun-Wei Ku", "title": "SocialNLP EmotionX 2019 Challenge Overview: Predicting Emotions in\n  Spoken Dialogues and Chats", "comments": "The 7th International Workshop on Natural Language Processing for\n  Social Media co-located with IJCAI-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an overview of the EmotionX 2019 Challenge, held at the 7th\nInternational Workshop on Natural Language Processing for Social Media\n(SocialNLP), in conjunction with IJCAI 2019. The challenge entailed predicting\nemotions in spoken and chat-based dialogues using augmented EmotionLines\ndatasets. EmotionLines contains two distinct datasets: the first includes\nexcerpts from a US-based TV sitcom episode scripts (Friends) and the second\ncontains online chats (EmotionPush). A total of thirty-six teams registered to\nparticipate in the challenge. Eleven of the teams successfully submitted their\npredictions performance evaluation. The top-scoring team achieved a micro-F1\nscore of 81.5% for the spoken-based dialogues (Friends) and 79.5% for the\nchat-based dialogues (EmotionPush).\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 11:55:32 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 12:50:10 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Shmueli", "Boaz", ""], ["Ku", "Lun-Wei", ""]]}, {"id": "1909.07739", "submitter": "Jifan Yu", "authors": "Jifan Yu, Chenyu Wang, Gan Luo, Lei Hou, Juanzi Li, Jie Tang, Zhiyuan\n  Liu", "title": "Course Concept Expansion in MOOCs with External Knowledge and\n  Interactive Game", "comments": null, "journal-ref": null, "doi": "10.18653/v1/P19-1421", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As Massive Open Online Courses (MOOCs) become increasingly popular, it is\npromising to automatically provide extracurricular knowledge for MOOC users.\nSuffering from semantic drifts and lack of knowledge guidance, existing methods\ncan not effectively expand course concepts in complex MOOC environments. In\nthis paper, we first build a novel boundary during searching for new concepts\nvia external knowledge base and then utilize heterogeneous features to verify\nthe high-quality results. In addition, to involve human efforts in our model,\nwe design an interactive optimization mechanism based on a game. Our\nexperiments on the four datasets from Coursera and XuetangX show that the\nproposed method achieves significant improvements(+0.19 by MAP) over existing\nmethods. The source code and datasets have been published.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 12:07:22 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Yu", "Jifan", ""], ["Wang", "Chenyu", ""], ["Luo", "Gan", ""], ["Hou", "Lei", ""], ["Li", "Juanzi", ""], ["Tang", "Jie", ""], ["Liu", "Zhiyuan", ""]]}, {"id": "1909.07746", "submitter": "Shobhit Jain", "authors": "Shobhit Jain, Sravan Babu Bodapati, Ramesh Nallapati, Anima Anandkumar", "title": "Multi Sense Embeddings from Topic Models", "comments": "Accepted at ACL supported conference for Natural Language & Speech\n  Processing. https://www.aclweb.org/anthology/W19-74, Year: 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Distributed word embeddings have yielded state-of-the-art performance in many\nNLP tasks, mainly due to their success in capturing useful semantic\ninformation. These representations assign only a single vector to each word\nwhereas a large number of words are polysemous (i.e., have multiple meanings).\nIn this work, we approach this critical problem in lexical semantics, namely\nthat of representing various senses of polysemous words in vector spaces. We\npropose a topic modeling based skip-gram approach for learning multi-prototype\nword embeddings. We also introduce a method to prune the embeddings determined\nby the probabilistic representation of the word in each topic. We use our\nembeddings to show that they can capture the context and word similarity\nstrongly and outperform various state-of-the-art implementations.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 12:23:33 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 17:14:17 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Jain", "Shobhit", ""], ["Bodapati", "Sravan Babu", ""], ["Nallapati", "Ramesh", ""], ["Anandkumar", "Anima", ""]]}, {"id": "1909.07755", "submitter": "Markus Eberts", "authors": "Markus Eberts, Adrian Ulges", "title": "Span-based Joint Entity and Relation Extraction with Transformer\n  Pre-training", "comments": "Published at ECAI 2020; marginally revised version; because of new\n  insights into evaluation metrics used in related work, we updated Table 1 and\n  report both micro/macro averaged entity values for the ADE dataset", "journal-ref": null, "doi": "10.3233/FAIA200321", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce SpERT, an attention model for span-based joint entity and\nrelation extraction. Our key contribution is a light-weight reasoning on BERT\nembeddings, which features entity recognition and filtering, as well as\nrelation classification with a localized, marker-free context representation.\nThe model is trained using strong within-sentence negative samples, which are\nefficiently extracted in a single BERT pass. These aspects facilitate a search\nover all spans in the sentence.\n  In ablation studies, we demonstrate the benefits of pre-training, strong\nnegative sampling and localized context. Our model outperforms prior work by up\nto 2.6% F1 score on several datasets for joint entity and relation extraction.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 13:01:12 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 09:58:10 GMT"}, {"version": "v3", "created": "Tue, 19 Nov 2019 16:21:59 GMT"}, {"version": "v4", "created": "Mon, 28 Jun 2021 19:39:43 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Eberts", "Markus", ""], ["Ulges", "Adrian", ""]]}, {"id": "1909.07863", "submitter": "Aditya Kaushik Surikuchi", "authors": "Aditya Surikuchi, Jorma Laaksonen", "title": "Character-Centric Storytelling", "comments": "ACL Storytelling (StoryNLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential vision-to-language or visual storytelling has recently been one of\nthe areas of focus in computer vision and language modeling domains. Though\nexisting models generate narratives that read subjectively well, there could be\ncases when these models miss out on generating stories that account and address\nall prospective human and animal characters in the image sequences. Considering\nthis scenario, we propose a model that implicitly learns relationships between\nprovided characters and thereby generates stories with respective characters in\nscope. We use the VIST dataset for this purpose and report numerous statistics\non the dataset. Eventually, we describe the model, explain the experiment and\ndiscuss our current status and future work.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 14:51:59 GMT"}, {"version": "v2", "created": "Sat, 7 Dec 2019 13:12:52 GMT"}, {"version": "v3", "created": "Mon, 6 Jan 2020 10:11:42 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Surikuchi", "Aditya", ""], ["Laaksonen", "Jorma", ""]]}, {"id": "1909.07873", "submitter": "Prashanth Vijayaraghavan", "authors": "Prashanth Vijayaraghavan, Deb Roy", "title": "Generating Black-Box Adversarial Examples for Text Classifiers Using a\n  Deep Reinforced Model", "comments": "16 pages, 3 figures, ECML PKDD 2019", "journal-ref": "Joint European Conference on Machine Learning and Knowledge\n  Discovery in Databases. Springer, Cham, 2019", "doi": "10.1007/978-3-030-46147-8_43", "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, generating adversarial examples has become an important means of\nmeasuring robustness of a deep learning model. Adversarial examples help us\nidentify the susceptibilities of the model and further counter those\nvulnerabilities by applying adversarial training techniques. In natural\nlanguage domain, small perturbations in the form of misspellings or paraphrases\ncan drastically change the semantics of the text. We propose a reinforcement\nlearning based approach towards generating adversarial examples in black-box\nsettings. We demonstrate that our method is able to fool well-trained models\nfor (a) IMDB sentiment classification task and (b) AG's news corpus news\ncategorization task with significantly high success rates. We find that the\nadversarial examples generated are semantics-preserving perturbations to the\noriginal text.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 15:05:31 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Vijayaraghavan", "Prashanth", ""], ["Roy", "Deb", ""]]}, {"id": "1909.07881", "submitter": "Palakorn Achananuparp", "authors": "Helena Lee, Palakorn Achananuparp, Yue Liu, Ee-Peng Lim, Lav R.\n  Varshney", "title": "Estimating Glycemic Impact of Cooking Recipes via Online Crowdsourcing\n  and Machine Learning", "comments": "To appear in the Proceedings of Digital Public Health 2019 as short\n  paper", "journal-ref": null, "doi": "10.1145/3357729.3357748", "report-no": null, "categories": "cs.CY cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consumption of diets with low glycemic impact is highly recommended for\ndiabetics and pre-diabetics as it helps maintain their blood glucose levels.\nHowever, laboratory analysis of dietary glycemic potency is time-consuming and\nexpensive. In this paper, we explore a data-driven approach utilizing online\ncrowdsourcing and machine learning to estimate the glycemic impact of cooking\nrecipes. We show that a commonly used healthiness metric may not always be\neffective in determining recipes suitable for diabetics, thus emphasizing the\nimportance of the glycemic-impact estimation task. Our best classification\nmodel, trained on nutritional and crowdsourced data obtained from Amazon\nMechanical Turk (AMT), can accurately identify recipes which are unhealthful\nfor diabetics.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 15:14:51 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Lee", "Helena", ""], ["Achananuparp", "Palakorn", ""], ["Liu", "Yue", ""], ["Lim", "Ee-Peng", ""], ["Varshney", "Lav R.", ""]]}, {"id": "1909.07907", "submitter": "Jetic G \\=u", "authors": "Jetic G\\=u, Hassan S. Shavarani, Anoop Sarkar", "title": "Pointer-based Fusion of Bilingual Lexicons into Neural Machine\n  Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT) systems require large amounts of high\nquality in-domain parallel corpora for training. State-of-the-art NMT systems\nstill face challenges related to out-of-vocabulary words and dealing with\nlow-resource language pairs. In this paper, we propose and compare several\nmodels for fusion of bilingual lexicons with an end-to-end trained\nsequence-to-sequence model for machine translation. The result is a fusion\nmodel with two information sources for the decoder: a neural conditional\nlanguage model and a bilingual lexicon. This fusion model learns how to combine\nboth sources of information in order to produce higher quality translation\noutput. Our experiments show that our proposed models work well in relatively\nlow-resource scenarios, and also effectively reduce the parameter size and\ntraining cost for NMT without sacrificing performance.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 15:52:18 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["G\u016b", "Jetic", ""], ["Shavarani", "Hassan S.", ""], ["Sarkar", "Anoop", ""]]}, {"id": "1909.07913", "submitter": "Danish Pruthi", "authors": "Danish Pruthi, Mansi Gupta, Bhuwan Dhingra, Graham Neubig, Zachary C.\n  Lipton", "title": "Learning to Deceive with Attention-Based Explanations", "comments": "Accepted to ACL 2020 as a long paper. Updated version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention mechanisms are ubiquitous components in neural architectures\napplied to natural language processing. In addition to yielding gains in\npredictive accuracy, attention weights are often claimed to confer\ninterpretability, purportedly useful both for providing insights to\npractitioners and for explaining why a model makes its decisions to\nstakeholders. We call the latter use of attention mechanisms into question by\ndemonstrating a simple method for training models to produce deceptive\nattention masks. Our method diminishes the total weight assigned to designated\nimpermissible tokens, even when the models can be shown to nevertheless rely on\nthese features to drive predictions. Across multiple models and tasks, our\napproach manipulates attention weights while paying surprisingly little cost in\naccuracy. Through a human study, we show that our manipulated attention-based\nexplanations deceive people into thinking that predictions from a model biased\nagainst gender minorities do not rely on the gender. Consequently, our results\ncast doubt on attention's reliability as a tool for auditing algorithms in the\ncontext of fairness and accountability.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 16:10:30 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 20:13:40 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Pruthi", "Danish", ""], ["Gupta", "Mansi", ""], ["Dhingra", "Bhuwan", ""], ["Neubig", "Graham", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "1909.07928", "submitter": "Ella Rabinovich", "authors": "Ella Rabinovich, Julia Watson, Barend Beekhuizen, Suzanne Stevenson", "title": "Say Anything: Automatic Semantic Infelicity Detection in L2 English\n  Indefinite Pronouns", "comments": "10 pages, CoNLL2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational research on error detection in second language speakers has\nmainly addressed clear grammatical anomalies typical to learners at the\nbeginner-to-intermediate level. We focus instead on acquisition of subtle\nsemantic nuances of English indefinite pronouns by non-native speakers at\nvarying levels of proficiency. We first lay out theoretical, linguistically\nmotivated hypotheses, and supporting empirical evidence on the nature of the\nchallenges posed by indefinite pronouns to English learners. We then suggest\nand evaluate an automatic approach for detection of atypical usage patterns,\ndemonstrating that deep learning architectures are promising for this task\ninvolving nuanced semantic anomalies.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 16:46:58 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Rabinovich", "Ella", ""], ["Watson", "Julia", ""], ["Beekhuizen", "Barend", ""], ["Stevenson", "Suzanne", ""]]}, {"id": "1909.07930", "submitter": "Piero Molino", "authors": "Piero Molino, Yaroslav Dudin, Sai Sumanth Miryala", "title": "Ludwig: a type-based declarative deep learning toolbox", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present Ludwig, a flexible, extensible and easy to use\ntoolbox which allows users to train deep learning models and use them for\nobtaining predictions without writing code. Ludwig implements a novel approach\nto deep learning model building based on two main abstractions: data types and\ndeclarative configuration files. The data type abstraction allows for easier\ncode and sub-model reuse, and the standardized interfaces imposed by this\nabstraction allow for encapsulation and make the code easy to extend.\nDeclarative model definition configuration files enable inexperienced users to\nobtain effective models and increase the productivity of expert users.\nAlongside these two innovations, Ludwig introduces a general modularized deep\nlearning architecture called Encoder-Combiner-Decoder that can be instantiated\nto perform a vast amount of machine learning tasks. These innovations make it\npossible for engineers, scientists from other fields and, in general, a much\nbroader audience to adopt deep learning models for their tasks, concretely\nhelping in its democratization.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 16:54:29 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Molino", "Piero", ""], ["Dudin", "Yaroslav", ""], ["Miryala", "Sai Sumanth", ""]]}, {"id": "1909.07940", "submitter": "Eric Wallace", "authors": "Eric Wallace, Yizhong Wang, Sujian Li, Sameer Singh, Matt Gardner", "title": "Do NLP Models Know Numbers? Probing Numeracy in Embeddings", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to understand and work with numbers (numeracy) is critical for\nmany complex reasoning tasks. Currently, most NLP models treat numbers in text\nin the same way as other tokens---they embed them as distributed vectors. Is\nthis enough to capture numeracy? We begin by investigating the numerical\nreasoning capabilities of a state-of-the-art question answering model on the\nDROP dataset. We find this model excels on questions that require numerical\nreasoning, i.e., it already captures numeracy. To understand how this\ncapability emerges, we probe token embedding methods (e.g., BERT, GloVe) on\nsynthetic list maximum, number decoding, and addition tasks. A surprising\ndegree of numeracy is naturally present in standard embeddings. For example,\nGloVe and word2vec accurately encode magnitude for numbers up to 1,000.\nFurthermore, character-level embeddings are even more precise---ELMo captures\nnumeracy the best for all pre-trained methods---but BERT, which uses sub-word\nunits, is less exact.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 17:24:37 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 04:08:27 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Wallace", "Eric", ""], ["Wang", "Yizhong", ""], ["Li", "Sujian", ""], ["Singh", "Sameer", ""], ["Gardner", "Matt", ""]]}, {"id": "1909.07950", "submitter": "Ahmed Sabir", "authors": "Ahmed Sabir, Francesc Moreno-Noguer and Llu\\'is Padr\\'o", "title": "Semantic Relatedness Based Re-ranker for Text Spotting", "comments": "Accepted by EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications such as textual entailment, plagiarism detection or document\nclustering rely on the notion of semantic similarity, and are usually\napproached with dimension reduction techniques like LDA or with embedding-based\nneural approaches. We present a scenario where semantic similarity is not\nenough, and we devise a neural approach to learn semantic relatedness. The\nscenario is text spotting in the wild, where a text in an image (e.g. street\nsign, advertisement or bus destination) must be identified and recognized. Our\ngoal is to improve the performance of vision systems by leveraging semantic\ninformation. Our rationale is that the text to be spotted is often related to\nthe image context in which it appears (word pairs such as Delta-airplane, or\nquarters-parking are not similar, but are clearly related). We show how\nlearning a word-to-word or word-to-sentence relatedness score can improve the\nperformance of text spotting systems up to 2.9 points, outperforming other\nmeasures in a benchmark dataset.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 17:31:37 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 15:29:27 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Sabir", "Ahmed", ""], ["Moreno-Noguer", "Francesc", ""], ["Padr\u00f3", "Llu\u00eds", ""]]}, {"id": "1909.08041", "submitter": "Yixin Nie", "authors": "Yixin Nie, Songhe Wang, Mohit Bansal", "title": "Revealing the Importance of Semantic Retrieval for Machine Reading at\n  Scale", "comments": "14 pages (EMNLP 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Reading at Scale (MRS) is a challenging task in which a system is\ngiven an input query and is asked to produce a precise output by \"reading\"\ninformation from a large knowledge base. The task has gained popularity with\nits natural combination of information retrieval (IR) and machine comprehension\n(MC). Advancements in representation learning have led to separated progress in\nboth IR and MC; however, very few studies have examined the relationship and\ncombined design of retrieval and comprehension at different levels of\ngranularity, for development of MRS systems. In this work, we give general\nguidelines on system design for MRS by proposing a simple yet effective\npipeline system with special consideration on hierarchical semantic retrieval\nat both paragraph and sentence level, and their potential effects on the\ndownstream task. The system is evaluated on both fact verification and\nopen-domain multihop QA, achieving state-of-the-art results on the leaderboard\ntest sets of both FEVER and HOTPOTQA. To further demonstrate the importance of\nsemantic retrieval, we present ablation and analysis studies to quantify the\ncontribution of neural retrieval modules at both paragraph-level and\nsentence-level, and illustrate that intermediate semantic retrieval modules are\nvital for not only effectively filtering upstream information and thus saving\ndownstream computation, but also for shaping upstream data distribution and\nproviding better data for downstream modeling. Code/data made publicly\navailable at: https://github.com/easonnie/semanticRetrievalMRS\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 19:21:11 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Nie", "Yixin", ""], ["Wang", "Songhe", ""], ["Bansal", "Mohit", ""]]}, {"id": "1909.08053", "submitter": "Mohammad Shoeybi", "authors": "Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared\n  Casper, and Bryan Catanzaro", "title": "Megatron-LM: Training Multi-Billion Parameter Language Models Using\n  Model Parallelism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work in language modeling demonstrates that training large transformer\nmodels advances the state of the art in Natural Language Processing\napplications. However, very large models can be quite difficult to train due to\nmemory constraints. In this work, we present our techniques for training very\nlarge transformer models and implement a simple, efficient intra-layer model\nparallel approach that enables training transformer models with billions of\nparameters. Our approach does not require a new compiler or library changes, is\northogonal and complimentary to pipeline model parallelism, and can be fully\nimplemented with the insertion of a few communication operations in native\nPyTorch. We illustrate this approach by converging transformer based models up\nto 8.3 billion parameters using 512 GPUs. We sustain 15.1 PetaFLOPs across the\nentire application with 76% scaling efficiency when compared to a strong single\nGPU baseline that sustains 39 TeraFLOPs, which is 30% of peak FLOPs. To\ndemonstrate that large language models can further advance the state of the art\n(SOTA), we train an 8.3 billion parameter transformer language model similar to\nGPT-2 and a 3.9 billion parameter model similar to BERT. We show that careful\nattention to the placement of layer normalization in BERT-like models is\ncritical to achieving increased performance as the model size grows. Using the\nGPT-2 model we achieve SOTA results on the WikiText103 (10.8 compared to SOTA\nperplexity of 15.8) and LAMBADA (66.5% compared to SOTA accuracy of 63.2%)\ndatasets. Our BERT model achieves SOTA results on the RACE dataset (90.9%\ncompared to SOTA accuracy of 89.4%).\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 19:42:54 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 00:30:15 GMT"}, {"version": "v3", "created": "Sat, 5 Oct 2019 03:27:58 GMT"}, {"version": "v4", "created": "Fri, 13 Mar 2020 23:45:18 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Shoeybi", "Mohammad", ""], ["Patwary", "Mostofa", ""], ["Puri", "Raul", ""], ["LeGresley", "Patrick", ""], ["Casper", "Jared", ""], ["Catanzaro", "Bryan", ""]]}, {"id": "1909.08079", "submitter": "Ugo Tanielian", "authors": "Ugo Tanielian, Flavian Vasile", "title": "Relaxed Softmax for learning from Positive and Unlabeled data", "comments": "9 pages, 5 figures, 2 tables, published at RecSys 2019", "journal-ref": "RecSys 2019 Proceedings of the 13th ACM Conference on Recommender\n  Systems", "doi": "10.1145/3298689.3347034", "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the softmax model and its fast approximations have become\nthe de-facto loss functions for deep neural networks when dealing with\nmulti-class prediction. This loss has been extended to language modeling and\nrecommendation, two fields that fall into the framework of learning from\nPositive and Unlabeled data. In this paper, we stress the different drawbacks\nof the current family of softmax losses and sampling schemes when applied in a\nPositive and Unlabeled learning setup. We propose both a Relaxed Softmax loss\n(RS) and a new negative sampling scheme based on Boltzmann formulation. We show\nthat the new training objective is better suited for the tasks of density\nestimation, item similarity and next-event prediction by driving uplifts in\nperformance on textual and recommendation datasets against classical softmax.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 20:29:57 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Tanielian", "Ugo", ""], ["Vasile", "Flavian", ""]]}, {"id": "1909.08089", "submitter": "Wen Xiao", "authors": "Wen Xiao and Giuseppe Carenini", "title": "Extractive Summarization of Long Documents by Combining Global and Local\n  Context", "comments": "12 pages (with appendix), accepted at EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel neural single document extractive\nsummarization model for long documents, incorporating both the global context\nof the whole document and the local context within the current topic. We\nevaluate the model on two datasets of scientific papers, Pubmed and arXiv,\nwhere it outperforms previous work, both extractive and abstractive models, on\nROUGE-1, ROUGE-2 and METEOR scores. We also show that, consistently with our\ngoal, the benefits of our method become stronger as we apply it to longer\ndocuments. Rather surprisingly, an ablation study indicates that the benefits\nof our model seem to come exclusively from modeling the local context, even for\nthe longest documents.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 20:52:19 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Xiao", "Wen", ""], ["Carenini", "Giuseppe", ""]]}, {"id": "1909.08090", "submitter": "Andreas Stolcke", "authors": "Andreas Stolcke and Takuya Yoshioka", "title": "DOVER: A Method for Combining Diarization Outputs", "comments": "Minor corrections to results in Table 2, row 1. Code made available\n  at http://github.com/stolcke/dover", "journal-ref": "Proc. IEEE Automatic Speech Recognition and Understanding Workshop\n  2019, pp. 757-763", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech recognition and other natural language tasks have long benefited from\nvoting-based algorithms as a method to aggregate outputs from several systems\nto achieve a higher accuracy than any of the individual systems. Diarization,\nthe task of segmenting an audio stream into speaker-homogeneous and co-indexed\nregions, has so far not seen the benefit of this strategy because the structure\nof the task does not lend itself to a simple voting approach. This paper\npresents DOVER (diarization output voting error reduction), an algorithm for\nweighted voting among diarization hypotheses, in the spirit of the ROVER\nalgorithm for combining speech recognition hypotheses. We evaluate the\nalgorithm for diarization of meeting recordings with multiple microphones, and\nfind that it consistently reduces diarization error rate over the average of\nresults from individual channels, and often improves on the single best channel\nchosen by an oracle.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 20:56:50 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 01:25:13 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Stolcke", "Andreas", ""], ["Yoshioka", "Takuya", ""]]}, {"id": "1909.08103", "submitter": "Shota Horiguchi", "authors": "Naoyuki Kanda, Shota Horiguchi, Yusuke Fujita, Yawen Xue, Kenji\n  Nagamatsu, Shinji Watanabe", "title": "Simultaneous Speech Recognition and Speaker Diarization for Monaural\n  Dialogue Recordings with Target-Speaker Acoustic Models", "comments": "Accepted to ASRU 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the use of target-speaker automatic speech\nrecognition (TS-ASR) for simultaneous speech recognition and speaker\ndiarization of single-channel dialogue recordings. TS-ASR is a technique to\nautomatically extract and recognize only the speech of a target speaker given a\nshort sample utterance of that speaker. One obvious drawback of TS-ASR is that\nit cannot be used when the speakers in the recordings are unknown because it\nrequires a sample of the target speakers in advance of decoding. To remove this\nlimitation, we propose an iterative method, in which (i) the estimation of\nspeaker embeddings and (ii) TS-ASR based on the estimated speaker embeddings\nare alternately executed. We evaluated the proposed method by using very\nchallenging dialogue recordings in which the speaker overlap ratio was over\n20%. We confirmed that the proposed method significantly reduced both the word\nerror rate (WER) and diarization error rate (DER). Our proposed method combined\nwith i-vector speaker embeddings ultimately achieved a WER that differed by\nonly 2.1 % from that of TS-ASR given oracle speaker embeddings. Furthermore,\nour method can solve speaker diarization simultaneously as a by-product and\nachieved better DER than that of the conventional clustering-based speaker\ndiarization method based on i-vector.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 21:12:11 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Kanda", "Naoyuki", ""], ["Horiguchi", "Shota", ""], ["Fujita", "Yusuke", ""], ["Xue", "Yawen", ""], ["Nagamatsu", "Kenji", ""], ["Watanabe", "Shinji", ""]]}, {"id": "1909.08135", "submitter": "Lucy Lu Wang", "authors": "Lucy Lu Wang, Oyvind Tafjord, Arman Cohan, Sarthak Jain, Sam\n  Skjonsberg, Carissa Schoenick, Nick Botner, Waleed Ammar", "title": "SUPP.AI: Finding Evidence for Supplement-Drug Interactions", "comments": "ACL Demo 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dietary supplements are used by a large portion of the population, but\ninformation on their pharmacologic interactions is incomplete. To address this\nchallenge, we present SUPP.AI, an application for browsing evidence of\nsupplement-drug interactions (SDIs) extracted from the biomedical literature.\nWe train a model to automatically extract supplement information and identify\nsuch interactions from the scientific literature. To address the lack of\nlabeled data for SDI identification, we use labels of the closely related task\nof identifying drug-drug interactions (DDIs) for supervision. We fine-tune the\ncontextualized word representations of the RoBERTa language model using labeled\nDDI data, and apply the fine-tuned model to identify supplement interactions.\nWe extract 195k evidence sentences from 22M articles (P=0.82, R=0.58, F1=0.68)\nfor 60k interactions. We create the SUPP.AI application for users to search\nevidence sentences extracted by our model. SUPP.AI is an attempt to close the\ninformation gap on dietary supplements by making up-to-date evidence on SDIs\nmore discoverable for researchers, clinicians, and consumers.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 22:54:10 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 01:30:08 GMT"}, {"version": "v3", "created": "Tue, 7 Jul 2020 00:02:46 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Wang", "Lucy Lu", ""], ["Tafjord", "Oyvind", ""], ["Cohan", "Arman", ""], ["Jain", "Sarthak", ""], ["Skjonsberg", "Sam", ""], ["Schoenick", "Carissa", ""], ["Botner", "Nick", ""], ["Ammar", "Waleed", ""]]}, {"id": "1909.08166", "submitter": "Wei Li", "authors": "Wei Li, Shuheng Li, Shuming Ma, Yancheng He, Deli Chen, Xu Sun", "title": "Recursive Graphical Neural Networks for Text Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complicated syntax structure of natural language is hard to be explicitly\nmodeled by sequence-based models. Graph is a natural structure to describe the\ncomplicated relation between tokens. The recent advance in Graph Neural\nNetworks (GNN) provides a powerful tool to model graph structure data, but\nsimple graph models such as Graph Convolutional Networks (GCN) suffer from\nover-smoothing problem, that is, when stacking multiple layers, all nodes will\nconverge to the same value. In this paper, we propose a novel Recursive\nGraphical Neural Networks model (ReGNN) to represent text organized in the form\nof graph. In our proposed model, LSTM is used to dynamically decide which part\nof the aggregated neighbor information should be transmitted to upper layers\nthus alleviating the over-smoothing problem. Furthermore, to encourage the\nexchange between the local and global information, a global graph-level node is\ndesigned. We conduct experiments on both single and multiple label text\nclassification tasks. Experiment results show that our ReGNN model surpasses\nthe strong baselines significantly in most of the datasets and greatly\nalleviates the over-smoothing problem.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 01:54:53 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Li", "Wei", ""], ["Li", "Shuheng", ""], ["Ma", "Shuming", ""], ["He", "Yancheng", ""], ["Chen", "Deli", ""], ["Sun", "Xu", ""]]}, {"id": "1909.08167", "submitter": "Minlong Peng", "authors": "Minlong Peng, Qi Zhang, Xuanjing Huang", "title": "Weighed Domain-Invariant Representation Learning for Cross-domain\n  Sentiment Analysis", "comments": "Address the problem of the domain-invariant representation learning\n  framework under target shift", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-domain sentiment analysis is currently a hot topic in the research and\nengineering areas. One of the most popular frameworks in this field is the\ndomain-invariant representation learning (DIRL) paradigm, which aims to learn a\ndistribution-invariant feature representation across domains. However, in this\nwork, we find out that applying DIRL may harm domain adaptation when the label\ndistribution $\\rm{P}(\\rm{Y})$ changes across domains. To address this problem,\nwe propose a modification to DIRL, obtaining a novel weighted domain-invariant\nrepresentation learning (WDIRL) framework. We show that it is easy to transfer\nexisting SOTA DIRL models to WDIRL. Empirical studies on extensive cross-domain\nsentiment analysis tasks verified our statements and showed the effectiveness\nof our proposed solution.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 02:03:03 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Peng", "Minlong", ""], ["Zhang", "Qi", ""], ["Huang", "Xuanjing", ""]]}, {"id": "1909.08187", "submitter": "Yuhong Guo", "authors": "Xinyuan Lu and Yuhong Guo", "title": "Learning to Generate Questions with Adaptive Copying Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic question generation is an important problem in natural language\nprocessing. In this paper we propose a novel adaptive copying recurrent neural\nnetwork model to tackle the problem of question generation from sentences and\nparagraphs. The proposed model adds a copying mechanism component onto a\nbidirectional LSTM architecture to generate more suitable questions adaptively\nfrom the input data. Our experimental results show the proposed model can\noutperform the state-of-the-art question generation methods in terms of BLEU\nand ROUGE evaluation scores.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 05:27:45 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Lu", "Xinyuan", ""], ["Guo", "Yuhong", ""]]}, {"id": "1909.08191", "submitter": "Hung Nghiep Tran", "authors": "Hung Nghiep Tran and Atsuhiro Takasu", "title": "Exploring Scholarly Data by Semantic Query on Knowledge Graph Embedding\n  Space", "comments": "TPDL 2019", "journal-ref": "International Conference on Theory and Practice of Digital\n  Libraries (TPDL 2019)", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The trends of open science have enabled several open scholarly datasets which\ninclude millions of papers and authors. Managing, exploring, and utilizing such\nlarge and complicated datasets effectively are challenging. In recent years,\nthe knowledge graph has emerged as a universal data format for representing\nknowledge about heterogeneous entities and their relationships. The knowledge\ngraph can be modeled by knowledge graph embedding methods, which represent\nentities and relations as embedding vectors in semantic space, then model the\ninteractions between these embedding vectors. However, the semantic structures\nin the knowledge graph embedding space are not well-studied, thus knowledge\ngraph embedding methods are usually only used for knowledge graph completion\nbut not data representation and analysis. In this paper, we propose to analyze\nthese semantic structures based on the well-studied word embedding space and\nuse them to support data exploration. We also define the semantic queries,\nwhich are algebraic operations between the embedding vectors in the knowledge\ngraph embedding space, to solve queries such as similarity and analogy between\nthe entities on the original datasets. We then design a general framework for\ndata exploration by semantic queries and discuss the solution to some\ntraditional scholarly data exploration tasks. We also propose some new\ninteresting tasks that can be solved based on the uncanny semantic structures\nof the embedding space.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 04:32:00 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Tran", "Hung Nghiep", ""], ["Takasu", "Atsuhiro", ""]]}, {"id": "1909.08211", "submitter": "Penghui Wei", "authors": "Penghui Wei, Nan Xu, Wenji Mao", "title": "Modeling Conversation Structure and Temporal Dynamics for Jointly\n  Predicting Rumor Stance and Veracity", "comments": "EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatically verifying rumorous information has become an important and\nchallenging task in natural language processing and social media analytics.\nPrevious studies reveal that people's stances towards rumorous messages can\nprovide indicative clues for identifying the veracity of rumors, and thus\ndetermining the stances of public reactions is a crucial preceding step for\nrumor veracity prediction. In this paper, we propose a hierarchical multi-task\nlearning framework for jointly predicting rumor stance and veracity on Twitter,\nwhich consists of two components. The bottom component of our framework\nclassifies the stances of tweets in a conversation discussing a rumor via\nmodeling the structural property based on a novel graph convolutional network.\nThe top component predicts the rumor veracity by exploiting the temporal\ndynamics of stance evolution. Experimental results on two benchmark datasets\nshow that our method outperforms previous methods in both rumor stance\nclassification and veracity prediction.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 05:02:56 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Wei", "Penghui", ""], ["Xu", "Nan", ""], ["Mao", "Wenji", ""]]}, {"id": "1909.08217", "submitter": "Deric Pang", "authors": "Deric Pang, Lucy H. Lin, Noah A. Smith", "title": "Improving Natural Language Inference with a Pretrained Parser", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel approach to incorporate syntax into natural language\ninference (NLI) models. Our method uses contextual token-level vector\nrepresentations from a pretrained dependency parser. Like other contextual\nembedders, our method is broadly applicable to any neural model. We experiment\nwith four strong NLI models (decomposable attention model, ESIM, BERT, and\nMT-DNN), and show consistent benefit to accuracy across three NLI benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 05:54:32 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Pang", "Deric", ""], ["Lin", "Lucy H.", ""], ["Smith", "Noah A.", ""]]}, {"id": "1909.08229", "submitter": "Wonjin Yoon", "authors": "Wonjin Yoon, Jinhyuk Lee, Donghyeon Kim, Minbyul Jeong, Jaewoo Kang", "title": "Pre-trained Language Model for Biomedical Question Answering", "comments": "This paper is accepted for an oral presentation in BioASQ Workshop @\n  ECML PKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent success of question answering systems is largely attributed to\npre-trained language models. However, as language models are mostly pre-trained\non general domain corpora such as Wikipedia, they often have difficulty in\nunderstanding biomedical questions. In this paper, we investigate the\nperformance of BioBERT, a pre-trained biomedical language model, in answering\nbiomedical questions including factoid, list, and yes/no type questions.\nBioBERT uses almost the same structure across various question types and\nachieved the best performance in the 7th BioASQ Challenge (Task 7b, Phase B).\nBioBERT pre-trained on SQuAD or SQuAD 2.0 easily outperformed previous\nstate-of-the-art models. BioBERT obtains the best performance when it uses the\nappropriate pre-/post-processing strategies for questions, passages, and\nanswers.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 06:53:30 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Yoon", "Wonjin", ""], ["Lee", "Jinhyuk", ""], ["Kim", "Donghyeon", ""], ["Jeong", "Minbyul", ""], ["Kang", "Jaewoo", ""]]}, {"id": "1909.08250", "submitter": "EPTCS", "authors": "Van Duc Nguyen (New Mexico State University), Tran Cao Son (New Mexico\n  State University), Enrico Pontelli (New Mexico State University)", "title": "Natural Language Generation for Non-Expert Users", "comments": "In Proceedings ICLP 2019, arXiv:1909.07646", "journal-ref": "EPTCS 306, 2019, pp. 280-294", "doi": "10.4204/EPTCS.306.33", "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the difficulty in presenting computational results, especially\nwhen the results are a collection of atoms in a logical language, to users, who\nare not proficient in computer programming and/or the logical representation of\nthe results, we propose a system for automatic generation of natural language\ndescriptions for applications targeting mainstream users. Differently from many\nearlier systems with the same aim, the proposed system does not employ\ntemplates for the generation task. It assumes that there exist some natural\nlanguage sentences in the application domain and uses this repository for the\nnatural language description. It does not require, however, a large corpus as\nit is often required in machine learning approaches. The systems consist of two\nmain components. The first one aims at analyzing the sentences and constructs a\nGrammatical Framework (GF) for given sentences and is implemented using the\nStanford parser and an answer set program. The second component is for sentence\nconstruction and relies on GF Library. The paper includes two use cases to\ndemostrate the capability of the system. As the sentence construction is done\nvia GF, the paper includes a use case evaluation showing that the proposed\nsystem could also be utilized in addressing a challenge to create an abstract\nWikipedia, which is recently discussed in the BlueSky session of the 2018\nInternational Semantic Web Conference.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 07:09:07 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Nguyen", "Van Duc", "", "New Mexico State University"], ["Son", "Tran Cao", "", "New Mexico\n  State University"], ["Pontelli", "Enrico", "", "New Mexico State University"]]}, {"id": "1909.08306", "submitter": "Reinald Kim Amplayo", "authors": "Reinald Kim Amplayo, Seonjae Lim, Seung-won Hwang", "title": "Text Length Adaptation in Sentiment Classification", "comments": "ACML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can a text classifier generalize well for datasets where the text length is\ndifferent? For example, when short reviews are sentiment-labeled, can these\ntransfer to predict the sentiment of long reviews (i.e., short to long\ntransfer), or vice versa? While unsupervised transfer learning has been\nwell-studied for cross domain/lingual transfer tasks, Cross Length Transfer\n(CLT) has not yet been explored. One reason is the assumption that length\ndifference is trivially transferable in classification. We show that it is not,\nbecause short/long texts differ in context richness and word intensity. We\ndevise new benchmark datasets from diverse domains and languages, and show that\nexisting models from similar tasks cannot deal with the unique challenge of\ntransferring across text lengths. We introduce a strong baseline model called\nBaggedCNN that treats long texts as bags containing short texts. We propose a\nstate-of-the-art CLT model called Length Transfer Networks (LeTraNets) that\nintroduces a two-way encoding scheme for short and long texts using multiple\ntraining mechanisms. We test our models and find that existing models perform\nworse than the BaggedCNN baseline, while LeTraNets outperforms all models.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 09:21:28 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Amplayo", "Reinald Kim", ""], ["Lim", "Seonjae", ""], ["Hwang", "Seung-won", ""]]}, {"id": "1909.08314", "submitter": "Mark Collier", "authors": "Mark Collier and Joeran Beel", "title": "Memory-Augmented Neural Networks for Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory-augmented neural networks (MANNs) have been shown to outperform other\nrecurrent neural network architectures on a series of artificial sequence\nlearning tasks, yet they have had limited application to real-world tasks. We\nevaluate direct application of Neural Turing Machines (NTM) and Differentiable\nNeural Computers (DNC) to machine translation. We further propose and evaluate\ntwo models which extend the attentional encoder-decoder with capabilities\ninspired by memory augmented neural networks. We evaluate our proposed models\non IWSLT Vietnamese to English and ACL Romanian to English datasets. Our\nproposed models and the memory augmented neural networks perform similarly to\nthe attentional encoder-decoder on the Vietnamese to English translation task\nwhile have a 0.3-1.9 lower BLEU score for the Romanian to English task.\nInterestingly, our analysis shows that despite being equipped with additional\nflexibility and being randomly initialized memory augmented neural networks\nlearn an algorithm for machine translation almost identical to the attentional\nencoder-decoder.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 09:39:14 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Collier", "Mark", ""], ["Beel", "Joeran", ""]]}, {"id": "1909.08349", "submitter": "Gaurav Verma", "authors": "Gaurav Verma, Balaji Vasan Srinivasan", "title": "A Lexical, Syntactic, and Semantic Perspective for Understanding Style\n  in Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With a growing interest in modeling inherent subjectivity in natural\nlanguage, we present a linguistically-motivated process to understand and\nanalyze the writing style of individuals from three perspectives: lexical,\nsyntactic, and semantic. We discuss the stylistically expressive elements\nwithin each of these levels and use existing methods to quantify the linguistic\nintuitions related to some of these elements. We show that such a multi-level\nanalysis is useful for developing a well-knit understanding of style - which is\nindependent of the natural language task at hand, and also demonstrate its\nvalue in solving three downstream tasks: authors' style analysis, authorship\nattribution, and emotion prediction. We conduct experiments on a variety of\ndatasets, comprising texts from social networking sites, user reviews, legal\ndocuments, literary books, and newswire. The results on the aforementioned\ntasks and datasets illustrate that such a multi-level understanding of style,\nwhich has been largely ignored in recent works, models style-related\nsubjectivity in text and can be leveraged to improve performance on multiple\ndownstream tasks both qualitatively and quantitatively.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 10:55:46 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Verma", "Gaurav", ""], ["Srinivasan", "Balaji Vasan", ""]]}, {"id": "1909.08357", "submitter": "Jiangtong Li", "authors": "Jiangtong Li, Hai Zhao, Zuchao Li, Wei Bi, Xiaojiang Liu", "title": "Subword ELMo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding from Language Models (ELMo) has shown to be effective for improving\nmany natural language processing (NLP) tasks, and ELMo takes character\ninformation to compose word representation to train language models.However,\nthe character is an insufficient and unnatural linguistic unit for word\nrepresentation.Thus we introduce Embedding from Subword-aware Language Models\n(ESuLMo) which learns word representation from subwords using unsupervised\nsegmentation over words.We show that ESuLMo can enhance four benchmark NLP\ntasks more effectively than ELMo, including syntactic dependency parsing,\nsemantic role labeling, implicit discourse relation recognition and textual\nentailment, which brings a meaningful improvement over ELMo.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 11:14:53 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Li", "Jiangtong", ""], ["Zhao", "Hai", ""], ["Li", "Zuchao", ""], ["Bi", "Wei", ""], ["Liu", "Xiaojiang", ""]]}, {"id": "1909.08358", "submitter": "Jiaju Du", "authors": "Jiaju Du, Fanchao Qi, Maosong Sun", "title": "Using BERT for Word Sense Disambiguation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word Sense Disambiguation (WSD), which aims to identify the correct sense of\na given polyseme, is a long-standing problem in NLP. In this paper, we propose\nto use BERT to extract better polyseme representations for WSD and explore\nseveral ways of combining BERT and the classifier. We also utilize sense\ndefinitions to train a unified classifier for all words, which enables the\nmodel to disambiguate unseen polysemes. Experiments show that our model\nachieves the state-of-the-art results on the standard English All-word WSD\nevaluation.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 11:15:22 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Du", "Jiaju", ""], ["Qi", "Fanchao", ""], ["Sun", "Maosong", ""]]}, {"id": "1909.08402", "submitter": "Malte Ostendorff", "authors": "Malte Ostendorff, Peter Bourgonje, Maria Berger, Julian\n  Moreno-Schneider, Georg Rehm, Bela Gipp", "title": "Enriching BERT with Knowledge Graph Embeddings for Document\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we focus on the classification of books using short\ndescriptive texts (cover blurbs) and additional metadata. Building upon BERT, a\ndeep neural language model, we demonstrate how to combine text representations\nwith metadata and knowledge graph embeddings, which encode author information.\nCompared to the standard BERT approach we achieve considerably better results\nfor the classification task. For a more coarse-grained classification using\neight labels we achieve an F1- score of 87.20, while a detailed classification\nusing 343 labels yields an F1-score of 64.70. We make the source code and\ntrained models of our experiments publicly available\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 12:40:39 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Ostendorff", "Malte", ""], ["Bourgonje", "Peter", ""], ["Berger", "Maria", ""], ["Moreno-Schneider", "Julian", ""], ["Rehm", "Georg", ""], ["Gipp", "Bela", ""]]}, {"id": "1909.08478", "submitter": "Ankur Bapna", "authors": "Ankur Bapna, Naveen Arivazhagan, Orhan Firat", "title": "Simple, Scalable Adaptation for Neural Machine Translation", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-tuning pre-trained Neural Machine Translation (NMT) models is the\ndominant approach for adapting to new languages and domains. However,\nfine-tuning requires adapting and maintaining a separate model for each target\ntask. We propose a simple yet efficient approach for adaptation in NMT. Our\nproposed approach consists of injecting tiny task specific adapter layers into\na pre-trained model. These lightweight adapters, with just a small fraction of\nthe original model size, adapt the model to multiple individual tasks\nsimultaneously. We evaluate our approach on two tasks: (i) Domain Adaptation\nand (ii) Massively Multilingual NMT. Experiments on domain adaptation\ndemonstrate that our proposed approach is on par with full fine-tuning on\nvarious domains, dataset sizes and model capacities. On a massively\nmultilingual dataset of 103 languages, our adaptation approach bridges the gap\nbetween individual bilingual models and one massively multilingual model for\nmost language pairs, paving the way towards universal machine translation.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 14:38:34 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Bapna", "Ankur", ""], ["Arivazhagan", "Naveen", ""], ["Firat", "Orhan", ""]]}, {"id": "1909.08491", "submitter": "William Havard", "authors": "William N. Havard, Jean-Pierre Chevrot, Laurent Besacier", "title": "Word Recognition, Competition, and Activation in a Model of Visually\n  Grounded Speech", "comments": "Accepted at CoNLL2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study how word-like units are represented and activated in\na recurrent neural model of visually grounded speech. The model used in our\nexperiments is trained to project an image and its spoken description in a\ncommon representation space. We show that a recurrent model trained on spoken\nsentences implicitly segments its input into word-like units and reliably maps\nthem to their correct visual referents. We introduce a methodology originating\nfrom linguistics to analyse the representation learned by neural networks --\nthe gating paradigm -- and show that the correct representation of a word is\nonly activated if the network has access to first phoneme of the target word,\nsuggesting that the network does not rely on a global acoustic pattern.\nFurthermore, we find out that not all speech frames (MFCC vectors in our case)\nplay an equal role in the final encoded representation of a given word, but\nthat some frames have a crucial effect on it. Finally, we suggest that word\nrepresentation could be activated through a process of lexical competition.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 15:00:56 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Havard", "William N.", ""], ["Chevrot", "Jean-Pierre", ""], ["Besacier", "Laurent", ""]]}, {"id": "1909.08504", "submitter": "Genta Indra Winata", "authors": "Genta Indra Winata, Zhaojiang Lin, Jamin Shin, Zihan Liu, Pascale Fung", "title": "Hierarchical Meta-Embeddings for Code-Switching Named Entity Recognition", "comments": "Accepted by EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In countries that speak multiple main languages, mixing up different\nlanguages within a conversation is commonly called code-switching. Previous\nworks addressing this challenge mainly focused on word-level aspects such as\nword embeddings. However, in many cases, languages share common subwords,\nespecially for closely related languages, but also for languages that are\nseemingly irrelevant. Therefore, we propose Hierarchical Meta-Embeddings (HME)\nthat learn to combine multiple monolingual word-level and subword-level\nembeddings to create language-agnostic lexical representations. On the task of\nNamed Entity Recognition for English-Spanish code-switching data, our model\nachieves the state-of-the-art performance in the multilingual settings. We also\nshow that, in cross-lingual settings, our model not only leverages closely\nrelated languages, but also learns from languages with different roots.\nFinally, we show that combining different subunits are crucial for capturing\ncode-switching entities.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 15:34:12 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Winata", "Genta Indra", ""], ["Lin", "Zhaojiang", ""], ["Shin", "Jamin", ""], ["Liu", "Zihan", ""], ["Fung", "Pascale", ""]]}, {"id": "1909.08582", "submitter": "Genta Indra Winata", "authors": "Genta Indra Winata, Andrea Madotto, Chien-Sheng Wu, Pascale Fung", "title": "Code-Switched Language Models Using Neural Based Synthetic Data from\n  Parallel Sentences", "comments": "Accepted in CoNLL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training code-switched language models is difficult due to lack of data and\ncomplexity in the grammatical structure. Linguistic constraint theories have\nbeen used for decades to generate artificial code-switching sentences to cope\nwith this issue. However, this require external word alignments or constituency\nparsers that create erroneous results on distant languages. We propose a\nsequence-to-sequence model using a copy mechanism to generate code-switching\ndata by leveraging parallel monolingual translations from a limited source of\ncode-switching data. The model learns how to combine words from parallel\nsentences and identifies when to switch one language to the other. Moreover, it\ncaptures code-switching constraints by attending and aligning the words in\ninputs, without requiring any external knowledge. Based on experimental\nresults, the language model trained with the generated sentences achieves\nstate-of-the-art performance and improves end-to-end automatic speech\nrecognition.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 17:11:41 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Winata", "Genta Indra", ""], ["Madotto", "Andrea", ""], ["Wu", "Chien-Sheng", ""], ["Fung", "Pascale", ""]]}, {"id": "1909.08593", "submitter": "Daniel M. Ziegler", "authors": "Daniel M. Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B. Brown, Alec\n  Radford, Dario Amodei, Paul Christiano, Geoffrey Irving", "title": "Fine-Tuning Language Models from Human Preferences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reward learning enables the application of reinforcement learning (RL) to\ntasks where reward is defined by human judgment, building a model of reward by\nasking humans questions. Most work on reward learning has used simulated\nenvironments, but complex information about values is often expressed in\nnatural language, and we believe reward learning for language is a key to\nmaking RL practical and safe for real-world tasks. In this paper, we build on\nadvances in generative pretraining of language models to apply reward learning\nto four natural language tasks: continuing text with positive sentiment or\nphysically descriptive language, and summarization tasks on the TL;DR and\nCNN/Daily Mail datasets. For stylistic continuation we achieve good results\nwith only 5,000 comparisons evaluated by humans. For summarization, models\ntrained with 60,000 comparisons copy whole sentences from the input but skip\nirrelevant preamble; this leads to reasonable ROUGE scores and very good\nperformance according to our human labelers, but may be exploiting the fact\nthat labelers rely on simple heuristics.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 17:33:39 GMT"}, {"version": "v2", "created": "Wed, 8 Jan 2020 23:02:36 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Ziegler", "Daniel M.", ""], ["Stiennon", "Nisan", ""], ["Wu", "Jeffrey", ""], ["Brown", "Tom B.", ""], ["Radford", "Alec", ""], ["Amodei", "Dario", ""], ["Christiano", "Paul", ""], ["Irving", "Geoffrey", ""]]}, {"id": "1909.08663", "submitter": "Matthew A. Kelly", "authors": "Wang Jing (Beijing Normal University), M. A. Kelly (The Pennsylvania\n  State University), David Reitter (Google Research)", "title": "Do We Need Neural Models to Explain Human Judgments of Acceptability?", "comments": "10 pages (8 pages + 2 pages of references), 1 figure, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Native speakers can judge whether a sentence is an acceptable instance of\ntheir language. Acceptability provides a means of evaluating whether\ncomputational language models are processing language in a human-like manner.\nWe test the ability of computational language models, simple language features,\nand word embeddings to predict native English speakers judgments of\nacceptability on English-language essays written by non-native speakers. We\nfind that much of the sentence acceptability variance can be captured by a\ncombination of features including misspellings, word order, and word similarity\n(Pearson's r = 0.494). While predictive neural models fit acceptability\njudgments well (r = 0.527), we find that a 4-gram model with statistical\nsmoothing is just as good (r = 0.528). Thanks to incorporating a count of\nmisspellings, our 4-gram model surpasses both the previous unsupervised\nstate-of-the art (Lau et al., 2015; r = 0.472), and the average non-expert\nnative speaker (r = 0.46). Our results demonstrate that acceptability is well\ncaptured by n-gram statistics and simple language features.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 19:02:53 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 19:30:15 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Jing", "Wang", "", "Beijing Normal University"], ["Kelly", "M. A.", "", "The Pennsylvania\n  State University"], ["Reitter", "David", "", "Google Research"]]}, {"id": "1909.08681", "submitter": "Zheng Zhang", "authors": "Zheng Zhang, Ruiqing Yin, Jun Zhu, Pierre Zweigenbaum", "title": "Cross-Lingual Contextual Word Embeddings Mapping With Multi-Sense Words\n  In Mind", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work in cross-lingual contextual word embedding learning cannot handle\nmulti-sense words well. In this work, we explore the characteristics of\ncontextual word embeddings and show the link between contextual word embeddings\nand word senses. We propose two improving solutions by considering contextual\nmulti-sense word embeddings as noise (removal) and by generating cluster level\naverage anchor embeddings for contextual multi-sense word embeddings\n(replacement). Experiments show that our solutions can improve the supervised\ncontextual word embeddings alignment for multi-sense words in a microscopic\nperspective without hurting the macroscopic performance on the bilingual\nlexicon induction task. For unsupervised alignment, our methods significantly\nimprove the performance on the bilingual lexicon induction task for more than\n10 points.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 20:10:32 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Zhang", "Zheng", ""], ["Yin", "Ruiqing", ""], ["Zhu", "Jun", ""], ["Zweigenbaum", "Pierre", ""]]}, {"id": "1909.08686", "submitter": "Mukuntha Narayanan Sundararaman", "authors": "Alan Aipe, Mukuntha Narayanan Sundararaman, Asif Ekbal", "title": "Sentiment-Aware Recommendation System for Healthcare using Social Media", "comments": "Accepted at the 20th International Conference on Computational\n  Linguistics and Intelligent Text Processing (CICLing 2019), April 7-13, 2019,\n  La Rochelle, France; Springer LNCS Proceedings for CICLing 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last decade, health communities (known as forums) have evolved into\nplatforms where more and more users share their medical experiences, thereby\nseeking guidance and interacting with people of the community. The shared\ncontent, though informal and unstructured in nature, contains valuable medical\nand/or health-related information and can be leveraged to produce structured\nsuggestions to the common people. In this paper, at first we propose a stacked\ndeep learning model for sentiment analysis from the medical forum data. The\nstacked model comprises of Convolutional Neural Network (CNN) followed by a\nLong Short Term Memory (LSTM) and then by another CNN. For a blog classified\nwith positive sentiment, we retrieve the top-n similar posts. Thereafter, we\ndevelop a probabilistic model for suggesting the suitable treatments or\nprocedures for a particular disease or health condition. We believe that\nintegration of medical sentiment and suggestion would be beneficial to the\nusers for finding the relevant contents regarding medications and medical\nconditions, without having to manually stroll through a large amount of\nunstructured contents.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 20:20:25 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Aipe", "Alan", ""], ["Sundararaman", "Mukuntha Narayanan", ""], ["Ekbal", "Asif", ""]]}, {"id": "1909.08700", "submitter": "No\\'emien Kocher", "authors": "No\\'emien Kocher, Christian Scuito, Lorenzo Tarantino, Alexandros\n  Lazaridis, Andreas Fischer and Claudiu Musat", "title": "Alleviating Sequence Information Loss with Data Overlapping and Prime\n  Batch Sizes", "comments": null, "journal-ref": "Proceedings of the 23rd Conference on Computational Natural\n  Language Learning (CoNLL), Hong Kong, China, 2019, p. 890-899", "doi": "10.18653/v1/K19-1083", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In sequence modeling tasks the token order matters, but this information can\nbe partially lost due to the discretization of the sequence into data points.\nIn this paper, we study the imbalance between the way certain token pairs are\nincluded in data points and others are not. We denote this a token order\nimbalance (TOI) and we link the partial sequence information loss to a\ndiminished performance of the system as a whole, both in text and speech\nprocessing tasks. We then provide a mechanism to leverage the full token order\ninformation -Alleviated TOI- by iteratively overlapping the token composition\nof data points. For recurrent networks, we use prime numbers for the batch size\nto avoid redundancies when building batches from overlapped data points. The\nproposed method achieved state of the art performance in both text and speech\nrelated tasks.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 20:50:51 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Kocher", "No\u00e9mien", ""], ["Scuito", "Christian", ""], ["Tarantino", "Lorenzo", ""], ["Lazaridis", "Alexandros", ""], ["Fischer", "Andreas", ""], ["Musat", "Claudiu", ""]]}, {"id": "1909.08705", "submitter": "Arshit Gupta", "authors": "Arshit Gupta, Peng Zhang, Garima Lalwani and Mona Diab", "title": "CASA-NLU: Context-Aware Self-Attentive Natural Language Understanding\n  for Task-Oriented Chatbots", "comments": "To appear at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural Language Understanding (NLU) is a core component of dialog systems.\nIt typically involves two tasks - intent classification (IC) and slot labeling\n(SL), which are then followed by a dialogue management (DM) component. Such NLU\nsystems cater to utterances in isolation, thus pushing the problem of context\nmanagement to DM. However, contextual information is critical to the correct\nprediction of intents and slots in a conversation. Prior work on contextual NLU\nhas been limited in terms of the types of contextual signals used and the\nunderstanding of their impact on the model. In this work, we propose a\ncontext-aware self-attentive NLU (CASA-NLU) model that uses multiple signals,\nsuch as previous intents, slots, dialog acts and utterances over a variable\ncontext window, in addition to the current user utterance. CASA-NLU outperforms\na recurrent contextual NLU baseline on two conversational datasets, yielding a\ngain of up to 7% on the IC task for one of the datasets. Moreover, a\nnon-contextual variant of CASA-NLU achieves state-of-the-art performance for IC\ntask on standard public datasets - Snips and ATIS.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 21:00:04 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Gupta", "Arshit", ""], ["Zhang", "Peng", ""], ["Lalwani", "Garima", ""], ["Diab", "Mona", ""]]}, {"id": "1909.08723", "submitter": "Yiming Wang", "authors": "Yiming Wang and Tongfei Chen and Hainan Xu and Shuoyang Ding and Hang\n  Lv and Yiwen Shao and Nanyun Peng and Lei Xie and Shinji Watanabe and Sanjeev\n  Khudanpur", "title": "Espresso: A Fast End-to-end Neural Speech Recognition Toolkit", "comments": "Accepted to ASRU 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Espresso, an open-source, modular, extensible end-to-end neural\nautomatic speech recognition (ASR) toolkit based on the deep learning library\nPyTorch and the popular neural machine translation toolkit fairseq. Espresso\nsupports distributed training across GPUs and computing nodes, and features\nvarious decoding approaches commonly employed in ASR, including look-ahead\nword-based language model fusion, for which a fast, parallelized decoder is\nimplemented. Espresso achieves state-of-the-art ASR performance on the WSJ,\nLibriSpeech, and Switchboard data sets among other end-to-end systems without\ndata augmentation, and is 4--11x faster for decoding than similar systems (e.g.\nESPnet).\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 22:05:05 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 17:23:56 GMT"}, {"version": "v3", "created": "Tue, 15 Oct 2019 03:35:16 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Wang", "Yiming", ""], ["Chen", "Tongfei", ""], ["Xu", "Hainan", ""], ["Ding", "Shuoyang", ""], ["Lv", "Hang", ""], ["Shao", "Yiwen", ""], ["Peng", "Nanyun", ""], ["Xie", "Lei", ""], ["Watanabe", "Shinji", ""], ["Khudanpur", "Sanjeev", ""]]}, {"id": "1909.08744", "submitter": "Phoebe Mulcaire", "authors": "Phoebe Mulcaire, Jungo Kasai, Noah A. Smith", "title": "Low-Resource Parsing with Crosslingual Contextualized Representations", "comments": "CoNLL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite advances in dependency parsing, languages with small treebanks still\npresent challenges. We assess recent approaches to multilingual contextual word\nrepresentations (CWRs), and compare them for crosslingual transfer from a\nlanguage with a large treebank to a language with a small or nonexistent\ntreebank, by sharing parameters between languages in the parser itself. We\nexperiment with a diverse selection of languages in both simulated and truly\nlow-resource scenarios, and show that multilingual CWRs greatly facilitate\nlow-resource dependency parsing even without crosslingual supervision such as\ndictionaries or parallel text. Furthermore, we examine the non-contextual part\nof the learned language models (which we call a \"decontextual probe\") to\ndemonstrate that polyglot language models better encode crosslingual lexical\ncorrespondence compared to aligned monolingual language models. This analysis\nprovides further evidence that polyglot training is an effective approach to\ncrosslingual transfer.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 00:23:09 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Mulcaire", "Phoebe", ""], ["Kasai", "Jungo", ""], ["Smith", "Noah A.", ""]]}, {"id": "1909.08752", "submitter": "Sanghwan Bae", "authors": "Sanghwan Bae, Taeuk Kim, Jihoon Kim, Sang-goo Lee", "title": "Summary Level Training of Sentence Rewriting for Abstractive\n  Summarization", "comments": "EMNLP 2019 Workshop on New Frontiers in Summarization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an attempt to combine extractive and abstractive summarization, Sentence\nRewriting models adopt the strategy of extracting salient sentences from a\ndocument first and then paraphrasing the selected ones to generate a summary.\nHowever, the existing models in this framework mostly rely on sentence-level\nrewards or suboptimal labels, causing a mismatch between a training objective\nand evaluation metric. In this paper, we present a novel training signal that\ndirectly maximizes summary-level ROUGE scores through reinforcement learning.\nIn addition, we incorporate BERT into our model, making good use of its ability\non natural language understanding. In extensive experiments, we show that a\ncombination of our proposed model and training procedure obtains new\nstate-of-the-art performance on both CNN/Daily Mail and New York Times\ndatasets. We also demonstrate that it generalizes better on DUC-2002 test set.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 00:47:13 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 09:20:10 GMT"}, {"version": "v3", "created": "Thu, 26 Sep 2019 07:07:03 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Bae", "Sanghwan", ""], ["Kim", "Taeuk", ""], ["Kim", "Jihoon", ""], ["Lee", "Sang-goo", ""]]}, {"id": "1909.08782", "submitter": "Gabriel Ilharco", "authors": "Gabriel Ilharco, Yuan Zhang, Jason Baldridge", "title": "Large-scale representation learning from visually grounded untranscribed\n  speech", "comments": null, "journal-ref": "The SIGNLL Conference on Computational Natural Language Learning\n  (CoNLL), 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systems that can associate images with their spoken audio captions are an\nimportant step towards visually grounded language learning. We describe a\nscalable method to automatically generate diverse audio for image captioning\ndatasets. This supports pretraining deep networks for encoding both audio and\nimages, which we do via a dual encoder that learns to align latent\nrepresentations from both modalities. We show that a masked margin softmax loss\nfor such models is superior to the standard triplet loss. We fine-tune these\nmodels on the Flickr8k Audio Captions Corpus and obtain state-of-the-art\nresults---improving recall in the top 10 from 29.6% to 49.5%. We also obtain\nhuman ratings on retrieval outputs to better assess the impact of incidentally\nmatching image-caption pairs that were not associated in the data, finding that\nautomatic evaluation substantially underestimates the quality of the retrieved\nresults.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 02:50:23 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Ilharco", "Gabriel", ""], ["Zhang", "Yuan", ""], ["Baldridge", "Jason", ""]]}, {"id": "1909.08784", "submitter": "Ian Stewart", "authors": "Ian Stewart, Diyi Yang, Jacob Eisenstein", "title": "Characterizing Collective Attention via Descriptor Context: A Case Study\n  of Public Discussions of Crisis Events", "comments": "ICWSM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media datasets make it possible to rapidly quantify collective\nattention to emerging topics and breaking news, such as crisis events.\nCollective attention is typically measured by aggregate counts, such as the\nnumber of posts that mention a name or hashtag. But according to rationalist\nmodels of natural language communication, the collective salience of each\nentity will be expressed not only in how often it is mentioned, but in the form\nthat those mentions take. This is because natural language communication is\npremised on (and customized to) the expectations that speakers and writers have\nabout how their messages will be interpreted by the intended audience. We test\nthis idea by conducting a large-scale analysis of public online discussions of\nbreaking news events on Facebook and Twitter, focusing on five recent crisis\nevents. We examine how people refer to locations, focusing specifically on\ncontextual descriptors, such as \"San Juan\" versus \"San Juan, Puerto Rico.\"\nRationalist accounts of natural language communication predict that such\ndescriptors will be unnecessary (and therefore omitted) when the named entity\nis expected to have high prior salience to the reader. We find that the use of\ncontextual descriptors is indeed associated with proxies for social and\ninformational expectations, including macro-level factors like the location's\nglobal salience and micro-level factors like audience engagement. We also find\na consistent decrease in descriptor context use over the lifespan of each\ncrisis event. These findings provide evidence about how social media users\ncommunicate with their audiences, and point towards more fine-grained models of\ncollective attention that may help researchers and crisis response\norganizations to better understand public perception of unfolding crisis\nevents.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 02:56:51 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2020 20:31:55 GMT"}, {"version": "v3", "created": "Tue, 31 Mar 2020 21:42:54 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Stewart", "Ian", ""], ["Yang", "Diyi", ""], ["Eisenstein", "Jacob", ""]]}, {"id": "1909.08796", "submitter": "Jakob Prange", "authors": "Jakob Prange, Nathan Schneider, Omri Abend", "title": "Made for Each Other: Broad-coverage Semantic Structures Meet Preposition\n  Supersenses", "comments": "to appear at CoNLL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Universal Conceptual Cognitive Annotation (UCCA; Abend and Rappoport, 2013)\nis a typologically-informed, broad-coverage semantic annotation scheme that\ndescribes coarse-grained predicate-argument structure but currently lacks\nsemantic roles. We argue that lexicon-free annotation of the semantic roles\nmarked by prepositions, as formulated by Schneider et al. (2018b), is\ncomplementary and suitable for integration within UCCA. We show empirically for\nEnglish that the schemes, though annotated independently, are compatible and\ncan be combined in a single semantic graph. A comparison of several approaches\nto parsing the integrated representation lays the groundwork for future\nresearch on this task.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 04:15:02 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Prange", "Jakob", ""], ["Schneider", "Nathan", ""], ["Abend", "Omri", ""]]}, {"id": "1909.08824", "submitter": "Li Du", "authors": "Li Du, Xiao Ding, Ting Liu and Zhongyang Li", "title": "Modeling Event Background for If-Then Commonsense Reasoning Using\n  Context-aware Variational Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Understanding event and event-centered commonsense reasoning are crucial for\nnatural language processing (NLP). Given an observed event, it is trivial for\nhuman to infer its intents and effects, while this type of If-Then reasoning\nstill remains challenging for NLP systems. To facilitate this, a If-Then\ncommonsense reasoning dataset Atomic is proposed, together with an RNN-based\nSeq2Seq model to conduct such reasoning. However, two fundamental problems\nstill need to be addressed: first, the intents of an event may be multiple,\nwhile the generations of RNN-based Seq2Seq models are always semantically\nclose; second, external knowledge of the event background may be necessary for\nunderstanding events and conducting the If-Then reasoning. To address these\nissues, we propose a novel context-aware variational autoencoder effectively\nlearning event background information to guide the If-Then reasoning.\nExperimental results show that our approach improves the accuracy and diversity\nof inferences compared with state-of-the-art baseline methods.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 06:46:02 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 08:22:45 GMT"}, {"version": "v3", "created": "Sun, 1 Dec 2019 07:31:56 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Du", "Li", ""], ["Ding", "Xiao", ""], ["Liu", "Ting", ""], ["Li", "Zhongyang", ""]]}, {"id": "1909.08837", "submitter": "Shen Gao", "authors": "Shen Gao, Xiuying Chen, Piji Li, Zhangming Chan, Dongyan Zhao, Rui Yan", "title": "How to Write Summaries with Patterns? Learning towards Abstractive\n  Summarization through Prototype Editing", "comments": "EMNLP 2019. Dataset available at\n  https://github.com/gsh199449/proto-summ", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Under special circumstances, summaries should conform to a particular style\nwith patterns, such as court judgments and abstracts in academic papers. To\nthis end, the prototype document-summary pairs can be utilized to generate\nbetter summaries. There are two main challenges in this task: (1) the model\nneeds to incorporate learned patterns from the prototype, but (2) should avoid\ncopying contents other than the patternized words---such as irrelevant\nfacts---into the generated summaries. To tackle these challenges, we design a\nmodel named Prototype Editing based Summary Generator (PESG). PESG first learns\nsummary patterns and prototype facts by analyzing the correlation between a\nprototype document and its summary. Prototype facts are then utilized to help\nextract facts from the input document. Next, an editing generator generates new\nsummary based on the summary pattern or extracted facts. Finally, to address\nthe second challenge, a fact checker is used to estimate mutual information\nbetween the input document and generated summary, providing an additional\nsignal for the generator. Extensive experiments conducted on a large-scale\nreal-world text summarization dataset show that PESG achieves the\nstate-of-the-art performance in terms of both automatic metrics and human\nevaluations.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 07:36:54 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Gao", "Shen", ""], ["Chen", "Xiuying", ""], ["Li", "Piji", ""], ["Chan", "Zhangming", ""], ["Zhao", "Dongyan", ""], ["Yan", "Rui", ""]]}, {"id": "1909.08855", "submitter": "Pratyay Banerjee", "authors": "Arindam Mitra, Pratyay Banerjee, Kuntal Kumar Pal, Swaroop Mishra and\n  Chitta Baral", "title": "How Additional Knowledge can Improve Natural Language Commonsense\n  Question Answering?", "comments": "14 pages, 14 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently several datasets have been proposed to encourage research in\nQuestion Answering domains where commonsense knowledge is expected to play an\nimportant role. Recent language models such as ROBERTA, BERT and GPT that have\nbeen pre-trained on Wikipedia articles and books have shown reasonable\nperformance with little fine-tuning on several such Multiple Choice\nQuestion-Answering (MCQ) datasets. Our goal in this work is to develop methods\nto incorporate additional (commonsense) knowledge into language model-based\napproaches for better question-answering in such domains. In this work, we\nfirst categorize external knowledge sources, and show performance does improve\non using such sources. We then explore three different strategies for knowledge\nincorporation and four different models for question-answering using external\ncommonsense knowledge. We analyze our predictions to explore the scope of\nfurther improvements.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 08:25:47 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 03:14:58 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2020 07:26:45 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Mitra", "Arindam", ""], ["Banerjee", "Pratyay", ""], ["Pal", "Kuntal Kumar", ""], ["Mishra", "Swaroop", ""], ["Baral", "Chitta", ""]]}, {"id": "1909.08859", "submitter": "Aykut Erdem", "authors": "Mustafa Sercan Amac, Semih Yagcioglu, Aykut Erdem, Erkut Erdem", "title": "Procedural Reasoning Networks for Understanding Multimodal Procedures", "comments": "Accepted to CoNLL 2019. The project website with code and demo is\n  available at https://hucvl.github.io/prn/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of comprehending procedural commonsense\nknowledge. This is a challenging task as it requires identifying key entities,\nkeeping track of their state changes, and understanding temporal and causal\nrelations. Contrary to most of the previous work, in this study, we do not rely\non strong inductive bias and explore the question of how multimodality can be\nexploited to provide a complementary semantic signal. Towards this end, we\nintroduce a new entity-aware neural comprehension model augmented with external\nrelational memory units. Our model learns to dynamically update entity states\nin relation to each other while reading the text instructions. Our experimental\nanalysis on the visual reasoning tasks in the recently proposed RecipeQA\ndataset reveals that our approach improves the accuracy of the previously\nreported models by a large margin. Moreover, we find that our model learns\neffective dynamic representations of entities even though we do not use any\nsupervision at the level of entity states.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 08:39:00 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Amac", "Mustafa Sercan", ""], ["Yagcioglu", "Semih", ""], ["Erdem", "Aykut", ""], ["Erdem", "Erkut", ""]]}, {"id": "1909.08863", "submitter": "Pratyay Banerjee", "authors": "Pratyay Banerjee", "title": "ASU at TextGraphs 2019 Shared Task: Explanation ReGeneration using\n  Language Models and Iterative Re-Ranking", "comments": "6+1 pages, 1 figures, Shared Task on Proceedings of the Thirteenth\n  Workshop on Graph-Based Methods for Natural Language Processing\n  (TextGraphs-13)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we describe the system from Natural Language Processing group at\nArizona State University for the TextGraphs 2019 Shared Task. The task focuses\non Explanation Regeneration, an intermediate step towards general multi-hop\ninference on large graphs. Our approach consists of modeling the explanation\nregeneration task as a \\textit{learning to rank} problem, for which we use\nstate-of-the-art language models and explore dataset preparation techniques. We\nutilize an iterative re-ranking based approach to further improve the rankings.\nOur system secured 2nd rank in the task with a mean average precision (MAP) of\n41.3\\% on the test set.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 08:47:16 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Banerjee", "Pratyay", ""]]}, {"id": "1909.08880", "submitter": "Edison Marrese-Taylor", "authors": "Edison Marrese-Taylor, Pablo Loyola, Yutaka Matsuo", "title": "An Edit-centric Approach for Wikipedia Article Quality Assessment", "comments": "Accepted at the W-NUT Workshop, EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an edit-centric approach to assess Wikipedia article quality as a\ncomplementary alternative to current full document-based techniques. Our model\nconsists of a main classifier equipped with an auxiliary generative module\nwhich, for a given edit, jointly provides an estimation of its quality and\ngenerates a description in natural language. We performed an empirical study to\nassess the feasibility of the proposed model and its cost-effectiveness in\nterms of data and quality requirements.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 09:20:32 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Marrese-Taylor", "Edison", ""], ["Loyola", "Pablo", ""], ["Matsuo", "Yutaka", ""]]}, {"id": "1909.08905", "submitter": "Qian Liu", "authors": "Qian Liu, Bei Chen, Haoyan Liu, Lei Fang, Jian-Guang Lou, Bin Zhou,\n  Dongmei Zhang", "title": "A Split-and-Recombine Approach for Follow-up Query Analysis", "comments": "Accepted by EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context-dependent semantic parsing has proven to be an important yet\nchallenging task. To leverage the advances in context-independent semantic\nparsing, we propose to perform follow-up query analysis, aiming to restate\ncontext-dependent natural language queries with contextual information. To\naccomplish the task, we propose STAR, a novel approach with a well-designed\ntwo-phase process. It is parser-independent and able to handle multifarious\nfollow-up scenarios in different domains. Experiments on the FollowUp dataset\nshow that STAR outperforms the state-of-the-art baseline by a large margin of\nnearly 8%. The superiority on parsing results verifies the feasibility of\nfollow-up query analysis. We also explore the extensibility of STAR on the SQA\ndataset, which is very promising.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 10:16:21 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Liu", "Qian", ""], ["Chen", "Bei", ""], ["Liu", "Haoyan", ""], ["Fang", "Lei", ""], ["Lou", "Jian-Guang", ""], ["Zhou", "Bin", ""], ["Zhang", "Dongmei", ""]]}, {"id": "1909.08927", "submitter": "Shipra Sharma Ms.", "authors": "Shipra Sharma and Balwinder Sodhi", "title": "Extracting Conceptual Knowledge from Natural Language Text Using Maximum\n  Likelihood Principle", "comments": "12 pages, Under review in IEEE TKDE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain-specific knowledge graphs constructed from natural language text are\nubiquitous in today's world. In many such scenarios the base text, from which\nthe knowledge graph is constructed, concerns itself with practical, on-hand,\nactual or ground-reality information about the domain. Product documentation in\nsoftware engineering domain are one example of such base texts. Other examples\ninclude blogs and texts related to digital artifacts, reports on emerging\nmarkets and business models, patient medical records, etc. Though the above\nsources contain a wealth of knowledge about their respective domains, the\nconceptual knowledge on which they are based is often missing or unclear.\nAccess to this conceptual knowledge can enormously increase the utility of\navailable data and assist in several tasks such as knowledge graph completion,\ngrounding, querying, etc.\n  Our contributions in this paper are twofold. First, we propose a novel\nMarkovian stochastic model for document generation from conceptual knowledge.\nThe uniqueness of our approach lies in the fact that the conceptual knowledge\nin the writer's mind forms a component of the parameter set of our stochastic\nmodel. Secondly, we solve the inverse problem of learning the best conceptual\nknowledge from a given document, by finding model parameters which maximize the\nlikelihood of generating the specific document over all possible parameter\nvalues. This likelihood maximization is done using an application of Baum-Welch\nalgorithm, which is a known special case of Expectation-Maximization (EM)\nalgorithm. We run our conceptualization algorithm on several well-known natural\nlanguage sources and obtain very encouraging results. The results of our\nextensive experiments concur with the hypothesis that the information contained\nin these sources has a well-defined and rigorous underlying conceptual\nstructure, which can be discovered using our method.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 11:54:55 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Sharma", "Shipra", ""], ["Sodhi", "Balwinder", ""]]}, {"id": "1909.08940", "submitter": "Nafise Sadat Moosavi", "authors": "Nafise Sadat Moosavi, Prasetya Ajie Utama, Andreas R\\\"uckl\\'e, and\n  Iryna Gurevych", "title": "Improving Generalization by Incorporating Coverage in Natural Language\n  Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of natural language inference (NLI) is to identify the relation\nbetween the given premise and hypothesis. While recent NLI models achieve very\nhigh performance on individual datasets, they fail to generalize across similar\ndatasets. This indicates that they are solving NLI datasets instead of the task\nitself. In order to improve generalization, we propose to extend the input\nrepresentations with an abstract view of the relation between the hypothesis\nand the premise, i.e., how well the individual words, or word n-grams, of the\nhypothesis are covered by the premise. Our experiments show that the use of\nthis information considerably improves generalization across different NLI\ndatasets without requiring any external knowledge or additional data. Finally,\nwe show that using the coverage information is not only beneficial for\nimproving the performance across different datasets of the same task. The\nresulting generalization improves the performance across datasets that belong\nto similar but not the same tasks.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 12:38:22 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Moosavi", "Nafise Sadat", ""], ["Utama", "Prasetya Ajie", ""], ["R\u00fcckl\u00e9", "Andreas", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1909.08970", "submitter": "Tzuf Paz-Argaman", "authors": "Tzuf Paz-Argaman and Reut Tsarfaty", "title": "RUN through the Streets: A New Dataset and Baseline Models for Realistic\n  Urban Navigation", "comments": "accepted to appear at the EMNLP 2019 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following navigation instructions in natural language requires a composition\nof language, action, and knowledge of the environment. Knowledge of the\nenvironment may be provided via visual sensors or as a symbolic world\nrepresentation referred to as a map. Here we introduce the Realistic Urban\nNavigation (RUN) task, aimed at interpreting navigation instructions based on a\nreal, dense, urban map. Using Amazon Mechanical Turk, we collected a dataset of\n2515 instructions aligned with actual routes over three regions of Manhattan.\nWe propose a strong baseline for the task and empirically investigate which\naspects of the neural architecture are important for the RUN success. Our\nresults empirically show that entity abstraction, attention over words and\nworlds, and a constantly updating world-state, significantly contribute to task\naccuracy.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 13:21:05 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Paz-Argaman", "Tzuf", ""], ["Tsarfaty", "Reut", ""]]}, {"id": "1909.08975", "submitter": "Dieuwke Hupkes", "authors": "Jaap Jumelet, Willem Zuidema and Dieuwke Hupkes", "title": "Analysing Neural Language Models: Contextual Decomposition Reveals\n  Default Reasoning in Number and Gender Assignment", "comments": "To appear at CoNLL2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extensive research has recently shown that recurrent neural language models\nare able to process a wide range of grammatical phenomena. How these models are\nable to perform these remarkable feats so well, however, is still an open\nquestion. To gain more insight into what information LSTMs base their decisions\non, we propose a generalisation of Contextual Decomposition (GCD). In\nparticular, this setup enables us to accurately distil which part of a\nprediction stems from semantic heuristics, which part truly emanates from\nsyntactic cues and which part arise from the model biases themselves instead.\nWe investigate this technique on tasks pertaining to syntactic agreement and\nco-reference resolution and discover that the model strongly relies on a\ndefault reasoning effect to perform these tasks.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 13:24:29 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Jumelet", "Jaap", ""], ["Zuidema", "Willem", ""], ["Hupkes", "Dieuwke", ""]]}, {"id": "1909.09001", "submitter": "Nora Hollenstein", "authors": "Nora Hollenstein, Antonio de la Torre, Nicolas Langer, Ce Zhang", "title": "CogniVal: A Framework for Cognitive Word Embedding Evaluation", "comments": "accepted at CoNLL 2019", "journal-ref": "Proceedings of the 23rd Conference on Computational Natural\n  Language Learning (CoNLL). 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An interesting method of evaluating word representations is by how much they\nreflect the semantic representations in the human brain. However, most, if not\nall, previous works only focus on small datasets and a single modality. In this\npaper, we present the first multi-modal framework for evaluating English word\nrepresentations based on cognitive lexical semantics. Six types of word\nembeddings are evaluated by fitting them to 15 datasets of eye-tracking, EEG\nand fMRI signals recorded during language processing. To achieve a global score\nover all evaluation hypotheses, we apply statistical significance testing\naccounting for the multiple comparisons problem. This framework is easily\nextensible and available to include other intrinsic and extrinsic evaluation\nmethods. We find strong correlations in the results between cognitive datasets,\nacross recording modalities and to their performance on extrinsic NLP tasks.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 13:57:17 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 08:54:19 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Hollenstein", "Nora", ""], ["de la Torre", "Antonio", ""], ["Langer", "Nicolas", ""], ["Zhang", "Ce", ""]]}, {"id": "1909.09010", "submitter": "Yiheng Huang", "authors": "Yiheng Huang and Jinchuan Tian and Lei Han and Guangsen Wang and\n  Xingcheng Song and Dan Su and Dong Yu", "title": "A Random Gossip BMUF Process for Neural Language Modeling", "comments": "This paper is accepted in the technical program in ICASSP 2020.\n  Session FR1.L3: Language Modeling, Location Room 118-119, Presentation\n  Lecture,Presentation Time: Friday, 08 May, 09:40 - 10:00, Topic Human\n  Language Technology:[HLT-LANG] Language Modeling", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network language model (NNLM) is an essential component of industrial\nASR systems. One important challenge of training an NNLM is to leverage between\nscaling the learning process and handling big data. Conventional approaches\nsuch as block momentum provides a blockwise model update filtering (BMUF)\nprocess and achieves almost linear speedups with no performance degradation for\nspeech recognition. However, it needs to calculate the model average from all\ncomputing nodes (e.g., GPUs) and when the number of computing nodes is large,\nthe learning suffers from the severe communication latency. As a consequence,\nBMUF is not suitable under restricted network conditions. In this paper, we\npresent a decentralized BMUF process, in which the model is split into\ndifferent components, each of which is updated by communicating to some\nrandomly chosen neighbor nodes with the same component, followed by a BMUF-like\nprocess. We apply this method to several LSTM language modeling tasks.\nExperimental results show that our approach achieves consistently better\nperformance than conventional BMUF. In particular, we obtain a lower perplexity\nthan the single-GPU baseline on the wiki-text-103 benchmark using 4 GPUs. In\naddition, no performance degradation is observed when scaling to 8 and 16 GPUs.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 14:11:36 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 09:13:45 GMT"}, {"version": "v3", "created": "Fri, 28 Feb 2020 06:17:51 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Huang", "Yiheng", ""], ["Tian", "Jinchuan", ""], ["Han", "Lei", ""], ["Wang", "Guangsen", ""], ["Song", "Xingcheng", ""], ["Su", "Dan", ""], ["Yu", "Dong", ""]]}, {"id": "1909.09018", "submitter": "Kuruparan Shanmugalingam", "authors": "Kuruparan Shanmugalingam, Nisal Chandrasekara, Calvin Hindle, Gihan\n  Fernando, Chanaka Gunawardhana", "title": "Corporate IT-support Help-Desk Process Hybrid-Automation Solution with\n  Machine Learning Approach", "comments": "7 pages, 8 Figures, 2 Tables", "journal-ref": "The International Conference on Digital Image Computing:\n  Techniques and Applications (DICTA) 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comprehensive IT support teams in large scale organizations require more man\npower for handling engagement and requests of employees from different channels\non a 24*7 basis. Automated email technical queries help desk is proposed to\nhave instant real-time quick solutions and email categorisation. Email topic\nmodelling with various machine learning, deep-learning approaches are compared\nwith different features for a scalable, generalised solution along with\nsure-shot static rules. Email's title, body, attachment, OCR text, and some\nfeature engineered custom features are given as input elements. XGBoost\ncascaded hierarchical models, Bi-LSTM model with word embeddings perform well\nshowing 77.3 overall accuracy For the real world corporate email data set. By\nintroducing the thresholding techniques, the overall automation system\narchitecture provides 85.6 percentage of accuracy for real world corporate\nemails. Combination of quick fixes, static rules, ML categorization as a low\ncost inference solution reduces 81 percentage of the human effort in the\nprocess of automation and real time implementation.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 10:07:01 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Shanmugalingam", "Kuruparan", ""], ["Chandrasekara", "Nisal", ""], ["Hindle", "Calvin", ""], ["Fernando", "Gihan", ""], ["Gunawardhana", "Chanaka", ""]]}, {"id": "1909.09031", "submitter": "Juri Opitz", "authors": "Juri Opitz", "title": "Argumentative Relation Classification as Plausibility Ranking", "comments": "15th Conference on Natural Language Processing (KONVENS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate argumentative relation classification (support vs. attack) as a\ntext-plausibility ranking task. To this aim, we propose a simple reconstruction\ntrick which enables us to build minimal pairs of plausible and implausible\ntexts by simulating natural contexts in which two argumentative units are\nlikely or unlikely to appear. We show that this method is competitive with\nprevious work albeit it is considerably simpler. In a recently introduced\ncontent-based version of the task, where contextual discourse clues are hidden,\nthe approach offers a performance increase of more than 10% macro F1. With\nrespect to the scarce attack-class, the method achieves a large increase in\nprecision while the incurred loss in recall is small or even nonexistent.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 15:01:46 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Opitz", "Juri", ""]]}, {"id": "1909.09060", "submitter": "Lun Huang", "authors": "Lun Huang and Wenmin Wang and Yaxian Xia and Jie Chen", "title": "Adaptively Aligned Image Captioning via Adaptive Attention Time", "comments": "Accepted to NeurIPS 2019. Code is available at\n  https://github.com/husthuaan/AAT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent neural models for image captioning usually employ an encoder-decoder\nframework with an attention mechanism. However, the attention mechanism in such\na framework aligns one single (attended) image feature vector to one caption\nword, assuming one-to-one mapping from source image regions and target caption\nwords, which is never possible. In this paper, we propose a novel attention\nmodel, namely Adaptive Attention Time (AAT), to align the source and the target\nadaptively for image captioning. AAT allows the framework to learn how many\nattention steps to take to output a caption word at each decoding step. With\nAAT, an image region can be mapped to an arbitrary number of caption words\nwhile a caption word can also attend to an arbitrary number of image regions.\nAAT is deterministic and differentiable, and doesn't introduce any noise to the\nparameter gradients. In this paper, we empirically show that AAT improves over\nstate-of-the-art methods on the task of image captioning. Code is available at\nhttps://github.com/husthuaan/AAT.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 15:59:33 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 04:04:38 GMT"}, {"version": "v3", "created": "Mon, 6 Jan 2020 09:26:01 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Huang", "Lun", ""], ["Wang", "Wenmin", ""], ["Xia", "Yaxian", ""], ["Chen", "Jie", ""]]}, {"id": "1909.09067", "submitter": "Alessia Battisti", "authors": "Alessia Battisti and Sarah Ebling", "title": "A Corpus for Automatic Readability Assessment and Text Simplification of\n  German", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a corpus for use in automatic readability\nassessment and automatic text simplification of German. The corpus is compiled\nfrom web sources and consists of approximately 211,000 sentences. As a novel\ncontribution, it contains information on text structure, typography, and\nimages, which can be exploited as part of machine learning approaches to\nreadability assessment and text simplification. The focus of this publication\nis on representing such information as an extension to an existing corpus\nstandard.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 16:07:32 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Battisti", "Alessia", ""], ["Ebling", "Sarah", ""]]}, {"id": "1909.09070", "submitter": "Jose Manuel Gomez-Perez", "authors": "Jose Manuel Gomez-Perez and Raul Ortega", "title": "Look, Read and Enrich. Learning from Scientific Figures and their\n  Captions", "comments": "Accepted in the 10th International Conference on Knowledge capture\n  (K-CAP 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compared to natural images, understanding scientific figures is particularly\nhard for machines. However, there is a valuable source of information in\nscientific literature that until now has remained untapped: the correspondence\nbetween a figure and its caption. In this paper we investigate what can be\nlearnt by looking at a large number of figures and reading their captions, and\nintroduce a figure-caption correspondence learning task that makes use of our\nobservations. Training visual and language networks without supervision other\nthan pairs of unconstrained figures and captions is shown to successfully solve\nthis task. We also show that transferring lexical and semantic knowledge from a\nknowledge graph significantly enriches the resulting features. Finally, we\ndemonstrate the positive impact of such features in other tasks involving\nscientific text and figures, like multi-modal classification and machine\ncomprehension for question answering, outperforming supervised baselines and\nad-hoc approaches.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 16:10:15 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Gomez-Perez", "Jose Manuel", ""], ["Ortega", "Raul", ""]]}, {"id": "1909.09116", "submitter": "Jacob Kahn", "authors": "Jacob Kahn, Ann Lee, Awni Hannun", "title": "Self-Training for End-to-End Speech Recognition", "comments": "To be published in the 45th IEEE International Conference on\n  Acoustics, Speech, and Signal Processing (ICASSP) 2020", "journal-ref": null, "doi": "10.1109/ICASSP40776.2020.9054295", "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit self-training in the context of end-to-end speech recognition. We\ndemonstrate that training with pseudo-labels can substantially improve the\naccuracy of a baseline model. Key to our approach are a strong baseline\nacoustic and language model used to generate the pseudo-labels, filtering\nmechanisms tailored to common errors from sequence-to-sequence models, and a\nnovel ensemble approach to increase pseudo-label diversity. Experiments on the\nLibriSpeech corpus show that with an ensemble of four models and label\nfiltering, self-training yields a 33.9% relative improvement in WER compared\nwith a baseline trained on 100 hours of labelled data in the noisy speech\nsetting. In the clean speech setting, self-training recovers 59.3% of the gap\nbetween the baseline and an oracle model, which is at least 93.8% relatively\nhigher than what previous approaches can achieve.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 17:42:56 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 22:16:10 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Kahn", "Jacob", ""], ["Lee", "Ann", ""], ["Hannun", "Awni", ""]]}, {"id": "1909.09192", "submitter": "Vardaan Pahuja", "authors": "Vardaan Pahuja, Jie Fu, Christopher J. Pal", "title": "Learning Sparse Mixture of Experts for Visual Question Answering", "comments": "Accepted in Visual Question Answering and Dialog Workshop, CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a rapid progress in the task of Visual Question Answering with\nimproved model architectures. Unfortunately, these models are usually\ncomputationally intensive due to their sheer size which poses a serious\nchallenge for deployment. We aim to tackle this issue for the specific task of\nVisual Question Answering (VQA). A Convolutional Neural Network (CNN) is an\nintegral part of the visual processing pipeline of a VQA model (assuming the\nCNN is trained along with entire VQA model). In this project, we propose an\nefficient and modular neural architecture for the VQA task with focus on the\nCNN module. Our experiments demonstrate that a sparsely activated CNN based VQA\nmodel achieves comparable performance to a standard CNN based VQA model\narchitecture.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 18:55:54 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Pahuja", "Vardaan", ""], ["Fu", "Jie", ""], ["Pal", "Christopher J.", ""]]}, {"id": "1909.09220", "submitter": "Yi-An Lai", "authors": "Yi-An Lai, Arshit Gupta and Yi Zhang", "title": "Goal-Embedded Dual Hierarchical Model for Task-Oriented Dialogue\n  Generation", "comments": "Accepted by CoNLL-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical neural networks are often used to model inherent structures\nwithin dialogues. For goal-oriented dialogues, these models miss a mechanism\nadhering to the goals and neglect the distinct conversational patterns between\ntwo interlocutors. In this work, we propose Goal-Embedded Dual Hierarchical\nAttentional Encoder-Decoder (G-DuHA) able to center around goals and capture\ninterlocutor-level disparity while modeling goal-oriented dialogues.\nExperiments on dialogue generation, response generation, and human evaluations\ndemonstrate that the proposed model successfully generates higher-quality, more\ndiverse and goal-centric dialogues. Moreover, we apply data augmentation via\ngoal-oriented dialogue generation for task-oriented dialog systems with better\nperformance achieved.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 20:12:10 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Lai", "Yi-An", ""], ["Gupta", "Arshit", ""], ["Zhang", "Yi", ""]]}, {"id": "1909.09237", "submitter": "Arya D. McCarthy", "authors": "Arya D. McCarthy and Xian Li and Jiatao Gu and Ning Dong", "title": "Improved Variational Neural Machine Translation by Promoting Mutual\n  Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Posterior collapse plagues VAEs for text, especially for conditional text\ngeneration with strong autoregressive decoders. In this work, we address this\nproblem in variational neural machine translation by explicitly promoting\nmutual information between the latent variables and the data. Our model extends\nthe conditional variational autoencoder (CVAE) with two new ingredients: first,\nwe propose a modified evidence lower bound (ELBO) objective which explicitly\npromotes mutual information; second, we regularize the probabilities of the\ndecoder by mixing an auxiliary factorized distribution which is directly\npredicted by the latent variables. We present empirical results on the\nTransformer architecture and show the proposed model effectively addressed\nposterior collapse: latent variables are no longer ignored in the presence of\npowerful decoder. As a result, the proposed model yields improved translation\nquality while demonstrating superior performance in terms of data efficiency\nand robustness.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 21:16:29 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["McCarthy", "Arya D.", ""], ["Li", "Xian", ""], ["Gu", "Jiatao", ""], ["Dong", "Ning", ""]]}, {"id": "1909.09251", "submitter": "Eric Wallace", "authors": "Eric Wallace, Jens Tuyls, Junlin Wang, Sanjay Subramanian, Matt\n  Gardner, Sameer Singh", "title": "AllenNLP Interpret: A Framework for Explaining Predictions of NLP Models", "comments": "EMNLP 2019 Demo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural NLP models are increasingly accurate but are imperfect and\nopaque---they break in counterintuitive ways and leave end users puzzled at\ntheir behavior. Model interpretation methods ameliorate this opacity by\nproviding explanations for specific model predictions. Unfortunately, existing\ninterpretation codebases make it difficult to apply these methods to new models\nand tasks, which hinders adoption for practitioners and burdens\ninterpretability researchers. We introduce AllenNLP Interpret, a flexible\nframework for interpreting NLP models. The toolkit provides interpretation\nprimitives (e.g., input gradients) for any AllenNLP model and task, a suite of\nbuilt-in interpretation methods, and a library of front-end visualization\ncomponents. We demonstrate the toolkit's flexibility and utility by\nimplementing live demos for five interpretation methods (e.g., saliency maps\nand adversarial attacks) on a variety of models and tasks (e.g., masked\nlanguage modeling using BERT and reading comprehension using BiDAF). These\ndemos, alongside our code and tutorials, are available at\nhttps://allennlp.org/interpret .\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 22:35:36 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Wallace", "Eric", ""], ["Tuyls", "Jens", ""], ["Wang", "Junlin", ""], ["Subramanian", "Sanjay", ""], ["Gardner", "Matt", ""], ["Singh", "Sameer", ""]]}, {"id": "1909.09253", "submitter": "Tushar Khot", "authors": "Tushar Khot and Ashish Sabharwal and Peter Clark", "title": "What's Missing: A Knowledge Gap Guided Approach for Multi-hop Question\n  Answering", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-hop textual question answering requires combining information from\nmultiple sentences. We focus on a natural setting where, unlike typical reading\ncomprehension, only partial information is provided with each question. The\nmodel must retrieve and use additional knowledge to correctly answer the\nquestion. To tackle this challenge, we develop a novel approach that explicitly\nidentifies the knowledge gap between a key span in the provided knowledge and\nthe answer choices. The model, GapQA, learns to fill this gap by determining\nthe relationship between the span and an answer choice, based on retrieved\nknowledge targeting this gap. We propose jointly training a model to\nsimultaneously fill this knowledge gap and compose it with the provided partial\nknowledge. On the OpenBookQA dataset, given partial knowledge, explicitly\nidentifying what's missing substantially outperforms previous approaches.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 22:49:04 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Khot", "Tushar", ""], ["Sabharwal", "Ashish", ""], ["Clark", "Peter", ""]]}, {"id": "1909.09265", "submitter": "Wasi Ahmad", "authors": "Wasi Uddin Ahmad, Zhisong Zhang, Xuezhe Ma, Kai-Wei Chang, Nanyun Peng", "title": "Cross-lingual Dependency Parsing with Unlabeled Auxiliary Languages", "comments": "CoNLL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual transfer learning has become an important weapon to battle the\nunavailability of annotated resources for low-resource languages. One of the\nfundamental techniques to transfer across languages is learning\n\\emph{language-agnostic} representations, in the form of word embeddings or\ncontextual encodings. In this work, we propose to leverage unannotated\nsentences from auxiliary languages to help learning language-agnostic\nrepresentations. Specifically, we explore adversarial training for learning\ncontextual encoders that produce invariant representations across languages to\nfacilitate cross-lingual transfer. We conduct experiments on cross-lingual\ndependency parsing where we train a dependency parser on a source language and\ntransfer it to a wide range of target languages. Experiments on 28 target\nlanguages demonstrate that adversarial training significantly improves the\noverall transfer performances under several different settings. We conduct a\ncareful analysis to evaluate the language-agnostic representations resulted\nfrom adversarial training.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 00:12:39 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Ahmad", "Wasi Uddin", ""], ["Zhang", "Zhisong", ""], ["Ma", "Xuezhe", ""], ["Chang", "Kai-Wei", ""], ["Peng", "Nanyun", ""]]}, {"id": "1909.09268", "submitter": "Hassan Kane", "authors": "Hassan Kan\\'e, Yusuf Kocyigit, Pelkins Ajanoh, Ali Abdalla, Mohamed\n  Coulibali", "title": "Towards Neural Language Evaluators", "comments": "Accepted to NeurIPS 2019 Document Intelligence Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review three limitations of BLEU and ROUGE -- the most popular metrics\nused to assess reference summaries against hypothesis summaries, come up with\ncriteria for what a good metric should behave like and propose concrete ways to\nuse recent Transformers-based Language Models to assess reference summaries\nagainst hypothesis summaries.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 00:24:59 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 19:56:02 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Kan\u00e9", "Hassan", ""], ["Kocyigit", "Yusuf", ""], ["Ajanoh", "Pelkins", ""], ["Abdalla", "Ali", ""], ["Coulibali", "Mohamed", ""]]}, {"id": "1909.09270", "submitter": "Stephen Mayhew", "authors": "Stephen Mayhew, Snigdha Chaturvedi, Chen-Tse Tsai, Dan Roth", "title": "Named Entity Recognition with Partially Annotated Training Data", "comments": "Accepted to CoNLL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Supervised machine learning assumes the availability of fully-labeled data,\nbut in many cases, such as low-resource languages, the only data available is\npartially annotated. We study the problem of Named Entity Recognition (NER)\nwith partially annotated training data in which a fraction of the named\nentities are labeled, and all other tokens, entities or otherwise, are labeled\nas non-entity by default. In order to train on this noisy dataset, we need to\ndistinguish between the true and false negatives. To this end, we introduce a\nconstraint-driven iterative algorithm that learns to detect false negatives in\nthe noisy set and downweigh them, resulting in a weighted training set. With\nthis set, we train a weighted NER model. We evaluate our algorithm with\nweighted variants of neural and non-neural NER models on data in 8 languages\nfrom several language and script families, showing strong ability to learn from\npartial data. Finally, to show real-world efficacy, we evaluate on a Bengali\nNER corpus annotated by non-speakers, outperforming the prior state-of-the-art\nby over 5 points F1.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 00:39:07 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Mayhew", "Stephen", ""], ["Chaturvedi", "Snigdha", ""], ["Tsai", "Chen-Tse", ""], ["Roth", "Dan", ""]]}, {"id": "1909.09279", "submitter": "Adam Fisch", "authors": "Adam Fisch and Jiang Guo and Regina Barzilay", "title": "Working Hard or Hardly Working: Challenges of Integrating Typology into\n  Neural Dependency Parsers", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the task of leveraging typology in the context of\ncross-lingual dependency parsing. While this linguistic information has shown\ngreat promise in pre-neural parsing, results for neural architectures have been\nmixed. The aim of our investigation is to better understand this\nstate-of-the-art. Our main findings are as follows: 1) The benefit of\ntypological information is derived from coarsely grouping languages into\nsyntactically-homogeneous clusters rather than from learning to leverage\nvariations along individual typological dimensions in a compositional manner;\n2) Typology consistent with the actual corpus statistics yields better transfer\nperformance; 3) Typological similarity is only a rough proxy of cross-lingual\ntransferability with respect to parsing.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 01:07:11 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Fisch", "Adam", ""], ["Guo", "Jiang", ""], ["Barzilay", "Regina", ""]]}, {"id": "1909.09292", "submitter": "Haiqin Yang", "authors": "Haiqin Yang", "title": "BERT Meets Chinese Word Segmentation", "comments": "13 pages; 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chinese word segmentation (CWS) is a fundamental task for Chinese language\nunderstanding. Recently, neural network-based models have attained superior\nperformance in solving the in-domain CWS task. Last year, Bidirectional Encoder\nRepresentation from Transformers (BERT), a new language representation model,\nhas been proposed as a backbone model for many natural language tasks and\nredefined the corresponding performance. The excellent performance of BERT\nmotivates us to apply it to solve the CWS task. By conducting intensive\nexperiments in the benchmark datasets from the second International Chinese\nWord Segmentation Bake-off, we obtain several keen observations. BERT can\nslightly improve the performance even when the datasets contain the issue of\nlabeling inconsistency. When applying sufficiently learned features, Softmax, a\nsimpler classifier, can attain the same performance as that of a more\ncomplicated classifier, e.g., Conditional Random Field (CRF). The performance\nof BERT usually increases as the model size increases. The features extracted\nby BERT can be also applied as good candidates for other neural network models.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 01:53:19 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Yang", "Haiqin", ""]]}, {"id": "1909.09317", "submitter": "Yuting Wu", "authors": "Yuting Wu, Xiao Liu, Yansong Feng, Zheng Wang and Dongyan Zhao", "title": "Jointly Learning Entity and Relation Representations for Entity\n  Alignment", "comments": "to appear in EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity alignment is a viable means for integrating heterogeneous knowledge\namong different knowledge graphs (KGs). Recent developments in the field often\ntake an embedding-based approach to model the structural information of KGs so\nthat entity alignment can be easily performed in the embedding space. However,\nmost existing works do not explicitly utilize useful relation representations\nto assist in entity alignment, which, as we will show in the paper, is a simple\nyet effective way for improving entity alignment. This paper presents a novel\njoint learning framework for entity alignment. At the core of our approach is a\nGraph Convolutional Network (GCN) based framework for learning both entity and\nrelation representations. Rather than relying on pre-aligned relation seeds to\nlearn relation representations, we first approximate them using entity\nembeddings learned by the GCN. We then incorporate the relation approximation\ninto entities to iteratively learn better representations for both. Experiments\nperformed on three real-world cross-lingual datasets show that our approach\nsubstantially outperforms state-of-the-art entity alignment methods.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 04:35:07 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Wu", "Yuting", ""], ["Liu", "Xiao", ""], ["Feng", "Yansong", ""], ["Wang", "Zheng", ""], ["Zhao", "Dongyan", ""]]}, {"id": "1909.09389", "submitter": "Ameya Prabhu", "authors": "Ameya Prabhu, Charles Dognin and Maneesh Singh", "title": "Sampling Bias in Deep Active Classification: An Empirical Study", "comments": "Accepted at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The exploding cost and time needed for data labeling and model training are\nbottlenecks for training DNN models on large datasets. Identifying smaller\nrepresentative data samples with strategies like active learning can help\nmitigate such bottlenecks. Previous works on active learning in NLP identify\nthe problem of sampling bias in the samples acquired by uncertainty-based\nquerying and develop costly approaches to address it. Using a large empirical\nstudy, we demonstrate that active set selection using the posterior entropy of\ndeep models like FastText.zip (FTZ) is robust to sampling biases and to various\nalgorithmic choices (query size and strategies) unlike that suggested by\ntraditional literature. We also show that FTZ based query strategy produces\nsample sets similar to those from more sophisticated approaches (e.g ensemble\nnetworks). Finally, we show the effectiveness of the selected samples by\ncreating tiny high-quality datasets, and utilizing them for fast and cheap\ntraining of large models. Based on the above, we propose a simple baseline for\ndeep active text classification that outperforms the state-of-the-art. We\nexpect the presented work to be useful and informative for dataset compression\nand for problems involving active, semi-supervised or online learning\nscenarios. Code and models are available at:\nhttps://github.com/drimpossible/Sampling-Bias-Active-Learning\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 09:35:20 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Prabhu", "Ameya", ""], ["Dognin", "Charles", ""], ["Singh", "Maneesh", ""]]}, {"id": "1909.09428", "submitter": "Chris Dyer", "authors": "Chris Dyer, G\\'abor Melis, Phil Blunsom", "title": "A Critical Analysis of Biased Parsers in Unsupervised Parsing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A series of recent papers has used a parsing algorithm due to Shen et al.\n(2018) to recover phrase-structure trees based on proxies for \"syntactic\ndepth.\" These proxy depths are obtained from the representations learned by\nrecurrent language models augmented with mechanisms that encourage the\n(unsupervised) discovery of hierarchical structure latent in natural language\nsentences. Using the same parser, we show that proxies derived from a\nconventional LSTM language model produce trees comparably well to the\nspecialized architectures used in previous work. However, we also provide a\ndetailed analysis of the parsing algorithm, showing (1) that it is\nincomplete---that is, it can recover only a fraction of possible trees---and\n(2) that it has a marked bias for right-branching structures which results in\ninflated performance in right-branching languages like English. Our analysis\nshows that evaluating with biased parsing algorithms can inflate the apparent\nstructural competence of language models.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 11:09:52 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Dyer", "Chris", ""], ["Melis", "G\u00e1bor", ""], ["Blunsom", "Phil", ""]]}, {"id": "1909.09480", "submitter": "Thomas Winters", "authors": "Thomas Winters", "title": "Generating Philosophical Statements using Interpolated Markov Models and\n  Dynamic Templates", "comments": "Winters T. (2019) Imitating Philosophical Statements using Stacked\n  Markov Chains and Dynamic Templates, In: 31st European Summer School in\n  Logic, Language and Information (ESSLLI2019): Student Session, University of\n  Latvia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatically imitating input text is a common task in natural language\ngeneration, often used to create humorous results. Classic algorithms for\nlearning to imitate text, e.g. simple Markov chains, usually have a trade-off\nbetween originality and syntactic correctness. We present two ways of\nautomatically parodying philosophical statements from examples overcoming this\nissue, and show how these can work in interactive systems as well. The first\nalgorithm uses interpolated Markov models with extensions to improve the\nquality of the generated texts. For the second algorithm, we propose\ndynamically extracting templates and filling these with new content. To\nillustrate these algorithms, we implemented TorfsBot, a Twitterbot imitating\nthe witty, semi-philosophical tweets of professor Rik Torfs, the previous KU\nLeuven rector. We found that users preferred generative models that focused on\nlocal coherent sentences, rather than those mimicking the global structure of a\nphilosophical statement. The proposed algorithms are thus valuable new tools\nfor automatic parody as well as template learning systems.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 11:37:12 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Winters", "Thomas", ""]]}, {"id": "1909.09482", "submitter": "Christopher Ormerod", "authors": "Pedro Uria Rodriguez, Amir Jafari and Christopher M. Ormerod", "title": "Language models and Automated Essay Scoring", "comments": "17 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new comparative study on automatic essay scoring\n(AES). The current state-of-the-art natural language processing (NLP) neural\nnetwork architectures are used in this work to achieve above human-level\naccuracy on the publicly available Kaggle AES dataset. We compare two powerful\nlanguage models, BERT and XLNet, and describe all the layers and network\narchitectures in these models. We elucidate the network architectures of BERT\nand XLNet using clear notation and diagrams and explain the advantages of\ntransformer architectures over traditional recurrent neural network\narchitectures. Linear algebra notation is used to clarify the functions of\ntransformers and attention mechanisms. We compare the results with more\ntraditional methods, such as bag of words (BOW) and long short term memory\n(LSTM) networks.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 18:50:18 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Rodriguez", "Pedro Uria", ""], ["Jafari", "Amir", ""], ["Ormerod", "Christopher M.", ""]]}, {"id": "1909.09483", "submitter": "Ruimin Zhu", "authors": "Ruimin Zhu, Thanapon Noraset, Alisa Liu, Wenxin Jiang, Doug Downey", "title": "Multi-sense Definition Modeling using Word Sense Decompositions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings capture syntactic and semantic information about words.\nDefinition modeling aims to make the semantic content in each embedding\nexplicit, by outputting a natural language definition based on the embedding.\nHowever, existing definition models are limited in their ability to generate\naccurate definitions for different senses of the same word. In this paper, we\nintroduce a new method that enables definition modeling for multiple senses. We\nshow how a Gumble-Softmax approach outperforms baselines at matching\nsense-specific embeddings to definitions during training. In experiments, our\nmulti-sense definition model improves recall over a state-of-the-art\nsingle-sense definition model by a factor of three, without harming precision.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 01:34:52 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Zhu", "Ruimin", ""], ["Noraset", "Thanapon", ""], ["Liu", "Alisa", ""], ["Jiang", "Wenxin", ""], ["Downey", "Doug", ""]]}, {"id": "1909.09484", "submitter": "Tian Lan", "authors": "Tian Lan and Xianling Mao and Heyan Huang", "title": "Generative Dialog Policy for Task-oriented Dialog Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an increasing demand for task-oriented dialogue systems which can\nassist users in various activities such as booking tickets and restaurant\nreservations. In order to complete dialogues effectively, dialogue policy plays\na key role in task-oriented dialogue systems. As far as we know, the existing\ntask-oriented dialogue systems obtain the dialogue policy through\nclassification, which can assign either a dialogue act and its corresponding\nparameters or multiple dialogue acts without their corresponding parameters for\na dialogue action. In fact, a good dialogue policy should construct multiple\ndialogue acts and their corresponding parameters at the same time. However,\nit's hard for existing classification-based methods to achieve this goal. Thus,\nto address the issue above, we propose a novel generative dialogue policy\nlearning method. Specifically, the proposed method uses attention mechanism to\nfind relevant segments of given dialogue context and input utterance and then\nconstructs the dialogue policy by a seq2seq way for task-oriented dialogue\nsystems. Extensive experiments on two benchmark datasets show that the proposed\nmodel significantly outperforms the state-of-the-art baselines. In addition, we\nhave publicly released our codes.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 15:50:56 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Lan", "Tian", ""], ["Mao", "Xianling", ""], ["Huang", "Heyan", ""]]}, {"id": "1909.09485", "submitter": "Iftitahu Ni'mah", "authors": "Iftitahu Ni'mah, Vlado Menkovski, Mykola Pechenizkiy", "title": "BSDAR: Beam Search Decoding with Attention Reward in Neural Keyphrase\n  Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study mainly investigates two decoding problems in neural keyphrase\ngeneration: sequence length bias and beam diversity. We introduce an extension\nof beam search inference based on word-level and n-gram level attention score\nto adjust and constrain Seq2Seq prediction at test time. Results show that our\nproposed solution can overcome the algorithm bias to shorter and nearly\nidentical sequences, resulting in a significant improvement of the decoding\nperformance on generating keyphrases that are present and absent in source\ntext.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 18:44:54 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Ni'mah", "Iftitahu", ""], ["Menkovski", "Vlado", ""], ["Pechenizkiy", "Mykola", ""]]}, {"id": "1909.09490", "submitter": "Hussein Al-Natsheh", "authors": "Hesham Al-Bataineh, Wael Farhan, Ahmad Mustafa, Haitham Seelawi,\n  Hussein T. Al-Natsheh", "title": "Deep Contextualized Pairwise Semantic Similarity for Arabic Language\n  Questions", "comments": "Accepted at ICTAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question semantic similarity is a challenging and active research problem\nthat is very useful in many NLP applications, such as detecting duplicate\nquestions in community question answering platforms such as Quora. Arabic is\nconsidered to be an under-resourced language, has many dialects, and rich in\nmorphology. Combined together, these challenges make identifying semantically\nsimilar questions in Arabic even more difficult. In this paper, we introduce a\nnovel approach to tackle this problem, and test it on two benchmarks; one for\nModern Standard Arabic (MSA), and another for the 24 major Arabic dialects. We\nare able to show that our new system outperforms state-of-the-art approaches by\nachieving 93% F1-score on the MSA benchmark and 82% on the dialectical one.\nThis is achieved by utilizing contextualized word representations (ELMo\nembeddings) trained on a text corpus containing MSA and dialectic sentences.\nThis in combination with a pairwise fine-grained similarity layer, helps our\nquestion-to-question similarity model to generalize predictions on different\ndialects while being trained only on question-to-question MSA data.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 11:58:18 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Al-Bataineh", "Hesham", ""], ["Farhan", "Wael", ""], ["Mustafa", "Ahmad", ""], ["Seelawi", "Haitham", ""], ["Al-Natsheh", "Hussein T.", ""]]}, {"id": "1909.09491", "submitter": "Tian Xia", "authors": "Tian Xia, Shaodan Zhai, Shaojun Wang", "title": "A simple discriminative training method for machine translation with\n  large-scale features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Margin infused relaxed algorithms (MIRAs) dominate model tuning in\nstatistical machine translation in the case of large scale features, but also\nthey are famous for the complexity in implementation. We introduce a new\nmethod, which regards an N-best list as a permutation and minimizes the\nPlackett-Luce loss of ground-truth permutations. Experiments with large-scale\nfeatures demonstrate that, the new method is more robust than MERT; though it\nis only matchable with MIRAs, it has a comparatively advantage, easier to\nimplement.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 18:18:35 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Xia", "Tian", ""], ["Zhai", "Shaodan", ""], ["Wang", "Shaojun", ""]]}, {"id": "1909.09492", "submitter": "Junyi Bian", "authors": "Junyi Bian, Baojun Lin, Ke Zhang, Zhaohui Yan, Hong Tang and Yonghe\n  Zhang", "title": "Controllable Length Control Neural Encoder-Decoder via Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Controlling output length in neural language generation is valuable in many\nscenarios, especially for the tasks that have length constraints. A model with\nstronger length control capacity can produce sentences with more specific\nlength, however, it usually sacrifices semantic accuracy of the generated\nsentences. Here, we denote a concept of Controllable Length Control (CLC) for\nthe trade-off between length control capacity and semantic accuracy of the\nlanguage generation model. More specifically, CLC is to alter length control\ncapacity of the model so as to generate sentence with corresponding quality.\nThis is meaningful in real applications when length control capacity and\noutputs quality are requested with different priorities, or to overcome\nunstability of length control during model training. In this paper, we propose\ntwo reinforcement learning (RL) methods to adjust the trade-off between length\ncontrol capacity and semantic accuracy of length control models. Results show\nthat our RL methods improve scores across a wide range of target lengths and\nachieve the goal of CLC. Additionally, two models LenMC and LenLInit modified\non previous length-control models are proposed to obtain better performance in\nsummarization task while still maintain the ability to control length.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 08:57:07 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Bian", "Junyi", ""], ["Lin", "Baojun", ""], ["Zhang", "Ke", ""], ["Yan", "Zhaohui", ""], ["Tang", "Hong", ""], ["Zhang", "Yonghe", ""]]}, {"id": "1909.09524", "submitter": "Yunsu Kim", "authors": "Yunsu Kim, Petre Petrov, Pavel Petrushkov, Shahram Khadivi, Hermann\n  Ney", "title": "Pivot-based Transfer Learning for Neural Machine Translation between\n  Non-English Languages", "comments": "EMNLP 2019 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present effective pre-training strategies for neural machine translation\n(NMT) using parallel corpora involving a pivot language, i.e., source-pivot and\npivot-target, leading to a significant improvement in source-target\ntranslation. We propose three methods to increase the relation among source,\npivot, and target languages in the pre-training: 1) step-wise training of a\nsingle model for different language pairs, 2) additional adapter component to\nsmoothly connect pre-trained encoder and decoder, and 3) cross-lingual encoder\ntraining via autoencoding of the pivot language. Our methods greatly outperform\nmultilingual models up to +2.6% BLEU in WMT 2019 French-German and German-Czech\ntasks. We show that our improvements are valid also in zero-shot/zero-resource\nscenarios.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 14:16:27 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Kim", "Yunsu", ""], ["Petrov", "Petre", ""], ["Petrushkov", "Pavel", ""], ["Khadivi", "Shahram", ""], ["Ney", "Hermann", ""]]}, {"id": "1909.09531", "submitter": "Suzana Ilic", "authors": "Suzana Ili\\'c, Reiichiro Nakano, Ivo Hajnal", "title": "Designing dialogue systems: A mean, grumpy, sarcastic chatbot in the\n  browser", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we explore a deep learning-based dialogue system that generates\nsarcastic and humorous responses from a conversation design perspective. We\ntrained a seq2seq model on a carefully curated dataset of 3000\nquestion-answering pairs, the core of our mean, grumpy, sarcastic chatbot. We\nshow that end-to-end systems learn patterns very quickly from small datasets\nand thus, are able to transfer simple linguistic structures representing\nabstract concepts to unseen settings. We also deploy our LSTM-based\nencoder-decoder model in the browser, where users can directly interact with\nthe chatbot. Human raters evaluated linguistic quality, creativity and\nhuman-like traits, revealing the system's strengths, limitations and potential\nfor future research.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 14:37:05 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Ili\u0107", "Suzana", ""], ["Nakano", "Reiichiro", ""], ["Hajnal", "Ivo", ""]]}, {"id": "1909.09534", "submitter": "Suzana Ilic", "authors": "Asir Saeed, Suzana Ili\\'c, Eva Zangerle", "title": "Creative GANs for generating poems, lyrics, and metaphors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models for text have substantially contributed to tasks like\nmachine translation and language modeling, using maximum likelihood\noptimization (MLE). However, for creative text generation, where multiple\noutputs are possible and originality and uniqueness are encouraged, MLE falls\nshort. Methods optimized for MLE lead to outputs that can be generic,\nrepetitive and incoherent. In this work, we use a Generative Adversarial\nNetwork framework to alleviate this problem. We evaluate our framework on\npoetry, lyrics and metaphor datasets, each with widely different\ncharacteristics, and report better performance of our objective function over\nother generative models.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 14:40:18 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Saeed", "Asir", ""], ["Ili\u0107", "Suzana", ""], ["Zangerle", "Eva", ""]]}, {"id": "1909.09551", "submitter": "Hamed Jelodar", "authors": "Hamed Jelodar, Yongli Wang, Mahdi Rabbani, SeyedValyAllah Ayobi", "title": "Natural Language Processing via LDA Topic Model in Recommendation\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Today, Internet is one of the widest available media worldwide.\nRecommendation systems are increasingly being used in various applications such\nas movie recommendation, mobile recommendation, article recommendation and etc.\nCollaborative Filtering (CF) and Content-Based (CB) are Well-known techniques\nfor building recommendation systems. Topic modeling based on LDA, is a powerful\ntechnique for semantic mining and perform topic extraction. In the past few\nyears, many articles have been published based on LDA technique for building\nrecommendation systems. In this paper, we present taxonomy of recommendation\nsystems and applications based on LDA. In addition, we utilize LDA and Gibbs\nsampling algorithms to evaluate ISWC and WWW conference publications in\ncomputer science. Our study suggest that the recommendation systems based on\nLDA could be effective in building smart recommendation system in online\ncommunities.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 15:08:51 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Jelodar", "Hamed", ""], ["Wang", "Yongli", ""], ["Rabbani", "Mahdi", ""], ["Ayobi", "SeyedValyAllah", ""]]}, {"id": "1909.09577", "submitter": "Oleksii Kuchaiev", "authors": "Oleksii Kuchaiev, Jason Li, Huyen Nguyen, Oleksii Hrinchuk, Ryan\n  Leary, Boris Ginsburg, Samuel Kriman, Stanislav Beliaev, Vitaly Lavrukhin,\n  Jack Cook, Patrice Castonguay, Mariya Popova, Jocelyn Huang, Jonathan M.\n  Cohen", "title": "NeMo: a toolkit for building AI applications using Neural Modules", "comments": "6 pages plus references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NeMo (Neural Modules) is a Python framework-agnostic toolkit for creating AI\napplications through re-usability, abstraction, and composition. NeMo is built\naround neural modules, conceptual blocks of neural networks that take typed\ninputs and produce typed outputs. Such modules typically represent data layers,\nencoders, decoders, language models, loss functions, or methods of combining\nactivations. NeMo makes it easy to combine and re-use these building blocks\nwhile providing a level of semantic correctness checking via its neural type\nsystem. The toolkit comes with extendable collections of pre-built modules for\nautomatic speech recognition and natural language processing. Furthermore, NeMo\nprovides built-in support for distributed training and mixed precision on\nlatest NVIDIA GPUs. NeMo is open-source https://github.com/NVIDIA/NeMo\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 03:51:46 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Kuchaiev", "Oleksii", ""], ["Li", "Jason", ""], ["Nguyen", "Huyen", ""], ["Hrinchuk", "Oleksii", ""], ["Leary", "Ryan", ""], ["Ginsburg", "Boris", ""], ["Kriman", "Samuel", ""], ["Beliaev", "Stanislav", ""], ["Lavrukhin", "Vitaly", ""], ["Cook", "Jack", ""], ["Castonguay", "Patrice", ""], ["Popova", "Mariya", ""], ["Huang", "Jocelyn", ""], ["Cohen", "Jonathan M.", ""]]}, {"id": "1909.09586", "submitter": "Ralf C. Staudemeyer", "authors": "Ralf C. Staudemeyer and Eric Rothstein Morris", "title": "Understanding LSTM -- a tutorial into Long Short-Term Memory Recurrent\n  Neural Networks", "comments": "42 pages, 11 figures, tutorial", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long Short-Term Memory Recurrent Neural Networks (LSTM-RNN) are one of the\nmost powerful dynamic classifiers publicly known. The network itself and the\nrelated learning algorithms are reasonably well documented to get an idea how\nit works. This paper will shed more light into understanding how LSTM-RNNs\nevolved and why they work impressively well, focusing on the early,\nground-breaking publications. We significantly improved documentation and fixed\na number of errors and inconsistencies that accumulated in previous\npublications. To support understanding we as well revised and unified the\nnotation used.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 15:44:51 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Staudemeyer", "Ralf C.", ""], ["Morris", "Eric Rothstein", ""]]}, {"id": "1909.09587", "submitter": "Tsung-Yuan Hsu", "authors": "Tsung-yuan Hsu, Chi-liang Liu, Hung-yi Lee", "title": "Zero-shot Reading Comprehension by Cross-lingual Transfer Learning with\n  Multi-lingual Language Representation Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Because it is not feasible to collect training data for every language, there\nis a growing interest in cross-lingual transfer learning. In this paper, we\nsystematically explore zero-shot cross-lingual transfer learning on reading\ncomprehension tasks with a language representation model pre-trained on\nmulti-lingual corpus. The experimental results show that with pre-trained\nlanguage representation zero-shot learning is feasible, and translating the\nsource data into the target language is not necessary and even degrades the\nperformance. We further explore what does the model learn in zero-shot setting.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 10:33:05 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Hsu", "Tsung-yuan", ""], ["Liu", "Chi-liang", ""], ["Lee", "Hung-yi", ""]]}, {"id": "1909.09595", "submitter": "Cheonbok  Park", "authors": "Cheonbok Park, Inyoup Na, Yongjang Jo, Sungbok Shin, Jaehyo Yoo, Bum\n  Chul Kwon, Jian Zhao, Hyungjong Noh, Yeonsoo Lee, Jaegul Choo", "title": "SANVis: Visual Analytics for Understanding Self-Attention Networks", "comments": "VAST Short - IEEE VIS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention networks, a deep neural network architecture inspired by humans'\nattention mechanism, have seen significant success in image captioning, machine\ntranslation, and many other applications. Recently, they have been further\nevolved into an advanced approach called multi-head self-attention networks,\nwhich can encode a set of input vectors, e.g., word vectors in a sentence, into\nanother set of vectors. Such encoding aims at simultaneously capturing diverse\nsyntactic and semantic features within a set, each of which corresponds to a\nparticular attention head, forming altogether multi-head attention. Meanwhile,\nthe increased model complexity prevents users from easily understanding and\nmanipulating the inner workings of models. To tackle the challenges, we present\na visual analytics system called SANVis, which helps users understand the\nbehaviors and the characteristics of multi-head self-attention networks. Using\na state-of-the-art self-attention model called Transformer, we demonstrate\nusage scenarios of SANVis in machine translation tasks. Our system is available\nat http://short.sanvis.org\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 05:59:40 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Park", "Cheonbok", ""], ["Na", "Inyoup", ""], ["Jo", "Yongjang", ""], ["Shin", "Sungbok", ""], ["Yoo", "Jaehyo", ""], ["Kwon", "Bum Chul", ""], ["Zhao", "Jian", ""], ["Noh", "Hyungjong", ""], ["Lee", "Yeonsoo", ""], ["Choo", "Jaegul", ""]]}, {"id": "1909.09690", "submitter": "Hossein Keshavarz", "authors": "Hossein Keshavarz, Shohreh Tabatabayi Seifi, Mohammad Izadi", "title": "A Deep Learning-Based Approach for Measuring the Domain Similarity of\n  Persian Texts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel approach for measuring the degree of\nsimilarity between categories of two pieces of Persian text, which were\npublished as descriptions of two separate advertisements. We built an\nappropriate dataset for this work using a dataset which consists of\nadvertisements posted on an e-commerce website. We generated a significant\nnumber of paired texts from this dataset and assigned each pair a score from 0\nto 3, which demonstrates the degree of similarity between the domains of the\npair. In this work, we represent words with word embedding vectors derived from\nword2vec. Then deep neural network models are used to represent texts.\nEventually, we employ concatenation of absolute difference and bit-wise\nmultiplication and a fully-connected neural network to produce a probability\ndistribution vector for the score of the pairs. Through a supervised learning\napproach, we trained our model on a GPU, and our best model achieved an F1\nscore of 0.9865.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 16:29:14 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 06:20:11 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Keshavarz", "Hossein", ""], ["Seifi", "Shohreh Tabatabayi", ""], ["Izadi", "Mohammad", ""]]}, {"id": "1909.09691", "submitter": "Hussein Al-Natsheh", "authors": "Haitham Seelawi, Ahmad Mustafa, Hesham Al-Bataineh, Wael Farhan,\n  Hussein T. Al-Natsheh", "title": "NSURL-2019 Shared Task 8: Semantic Question Similarity in Arabic", "comments": "8 pages, 2 figure, 3 tables, conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question semantic similarity (Q2Q) is a challenging task that is very useful\nin many NLP applications, such as detecting duplicate questions and question\nanswering systems. In this paper, we present the results and findings of the\nshared task (Semantic Question Similarity in Arabic). The task was organized as\npart of the first workshop on NLP Solutions for Under Resourced Languages\n(NSURL 2019) The goal of the task is to predict whether two questions are\nsemantically similar or not, even if they are phrased differently. A total of 9\nteams participated in the task. The datasets created for this task are made\npublicly available to support further research on Arabic Q2Q.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 14:45:43 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Seelawi", "Haitham", ""], ["Mustafa", "Ahmad", ""], ["Al-Bataineh", "Hesham", ""], ["Farhan", "Wael", ""], ["Al-Natsheh", "Hussein T.", ""]]}, {"id": "1909.09696", "submitter": "Tuan Manh Lai", "authors": "Tuan Lai, Quan Hung Tran, Trung Bui, Daisuke Kihara", "title": "A Gated Self-attention Memory Network for Answer Selection", "comments": "Accepted at the 2019 Conference on Empirical Methods in Natural\n  Language Processing (EMNLP 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer selection is an important research problem, with applications in many\nareas. Previous deep learning based approaches for the task mainly adopt the\nCompare-Aggregate architecture that performs word-level comparison followed by\naggregation. In this work, we take a departure from the popular\nCompare-Aggregate architecture, and instead, propose a new gated self-attention\nmemory network for the task. Combined with a simple transfer learning technique\nfrom a large-scale online corpus, our model outperforms previous methods by a\nlarge margin, achieving new state-of-the-art results on two standard answer\nselection datasets: TrecQA and WikiQA.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 17:56:58 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Lai", "Tuan", ""], ["Tran", "Quan Hung", ""], ["Bui", "Trung", ""], ["Kihara", "Daisuke", ""]]}, {"id": "1909.09699", "submitter": "Khyathi Raghavi Chandu", "authors": "Ruo-Ping Dong, Khyathi Raghavi Chandu, Alan W Black", "title": "Induction and Reference of Entities in a Visual Story", "comments": "9 pages, 4 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are enveloped by stories of visual interpretations in our everyday lives.\nThe way we narrate a story often comprises of two stages, which are, forming a\ncentral mind map of entities and then weaving a story around them. A\ncontributing factor to coherence is not just basing the story on these entities\nbut also, referring to them using appropriate terms to avoid repetition. In\nthis paper, we address these two stages of introducing the right entities at\nseemingly reasonable junctures and also referring them coherently in the\ncontext of visual storytelling. The building blocks of the central mind map,\nalso known as entity skeleton are entity chains including nominal and\ncoreference expressions. This entity skeleton is also represented in different\nlevels of abstractions to compose a generalized frame to weave the story. We\nbuild upon an encoder-decoder framework to penalize the model when the decoded\nstory does not adhere to this entity skeleton. We establish a strong baseline\nfor skeleton informed generation and then extend this to have the capability of\nmultitasking by predicting the skeleton in addition to generating the story.\nFinally, we build upon this model and propose a glocal hierarchical attention\nmodel that attends to the skeleton both at the sentence (local) and the story\n(global) levels. We observe that our proposed models outperform the baseline in\nterms of automatic evaluation metric, METEOR. We perform various analysis\ntargeted to evaluate the performance of our task of enforcing the entity\nskeleton such as the number and diversity of the entities generated. We also\nconduct human evaluation from which it is concluded that the visual stories\ngenerated by our model are preferred 82% of the times. In addition, we show\nthat our glocal hierarchical attention model improves coherence by introducing\nmore pronouns as required by the presence of nouns.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 01:09:01 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Dong", "Ruo-Ping", ""], ["Chandu", "Khyathi Raghavi", ""], ["Black", "Alan W", ""]]}, {"id": "1909.09700", "submitter": "Weijia Shi", "authors": "Weijia Shi, Muhao Chen, Pei Zhou and Kai-Wei Chang", "title": "Retrofitting Contextualized Word Embeddings with Paraphrases", "comments": null, "journal-ref": "EMNLP-IJCNLP2019", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextualized word embedding models, such as ELMo, generate meaningful\nrepresentations of words and their context. These models have been shown to\nhave a great impact on downstream applications. However, in many cases, the\ncontextualized embedding of a word changes drastically when the context is\nparaphrased. As a result, the downstream model is not robust to paraphrasing\nand other linguistic variations. To enhance the stability of contextualized\nword embedding models, we propose an approach to retrofitting contextualized\nembedding models with paraphrase contexts. Our method learns an orthogonal\ntransformation on the input space, which seeks to minimize the variance of word\nrepresentations on paraphrased contexts. Experiments show that the retrofitted\nmodel significantly outperforms the original ELMo on various sentence\nclassification and language inference tasks.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 22:35:53 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Shi", "Weijia", ""], ["Chen", "Muhao", ""], ["Zhou", "Pei", ""], ["Chang", "Kai-Wei", ""]]}, {"id": "1909.09702", "submitter": "Karan Aggarwal", "authors": "Swaraj Khadanga, Karan Aggarwal, Shafiq Joty, Jaideep Srivastava", "title": "Using Clinical Notes with Time Series Data for ICU Management", "comments": "Accepted at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monitoring patients in ICU is a challenging and high-cost task. Hence,\npredicting the condition of patients during their ICU stay can help provide\nbetter acute care and plan the hospital's resources. There has been continuous\nprogress in machine learning research for ICU management, and most of this work\nhas focused on using time series signals recorded by ICU instruments. In our\nwork, we show that adding clinical notes as another modality improves the\nperformance of the model for three benchmark tasks: in-hospital mortality\nprediction, modeling decompensation, and length of stay forecasting that play\nan important role in ICU management. While the time-series data is measured at\nregular intervals, doctor notes are charted at irregular times, making it\nchallenging to model them together. We propose a method to model them jointly,\nachieving considerable improvement across benchmark tasks over baseline\ntime-series model. Our implementation can be found at\n\\url{https://github.com/kaggarwal/ClinicalNotesICU}.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 04:27:32 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 18:21:02 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Khadanga", "Swaraj", ""], ["Aggarwal", "Karan", ""], ["Joty", "Shafiq", ""], ["Srivastava", "Jaideep", ""]]}, {"id": "1909.09704", "submitter": "Stefan Hosein", "authors": "Stefan Hosein, Daniel Andor, and Ryan McDonald", "title": "Measuring Domain Portability and ErrorPropagation in Biomedical QA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we present Google's submission to the BioASQ 7 biomedical\nquestion answering (QA) task (specifically Task 7b, Phase B). The core of our\nsystems are based on BERT QA models, specifically the model of\n\\cite{alberti2019bert}. In this report, and via our submissions, we aimed to\ninvestigate two research questions. We start by studying how domain portable\nare QA systems that have been pre-trained and fine-tuned on general texts,\ne.g., Wikipedia. We measure this via two submissions. The first is a\nnon-adapted model that uses a public pre-trained BERT model and is fine-tuned\non the Natural Questions data set \\cite{kwiatkowski2019natural}. The second\nsystem takes this non-adapted model and fine-tunes it with the BioASQ training\ndata. Next, we study the impact of error propagation in end-to-end retrieval\nand QA systems. Again we test this via two submissions. The first uses human\nannotated relevant documents and snippets as input to the model and the second\npredicted documents and snippets. Our main findings are that domain specific\nfine-tuning can benefit Biomedical QA. However, the biggest quality bottleneck\nis at the retrieval stage, where we see large drops in metrics -- over 10pts\nabsolute -- when using non gold inputs to the QA model.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 17:25:24 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 09:23:45 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Hosein", "Stefan", ""], ["Andor", "Daniel", ""], ["McDonald", "Ryan", ""]]}, {"id": "1909.09708", "submitter": "Tomas Veloz", "authors": "Tomas Veloz, Xiazhao Zhao, Diederik Aerts", "title": "Measuring Conceptual Entanglement in Collections of Documents", "comments": "14 pages, 3 figures, Symposium Quantum Interaction 2013", "journal-ref": "In International Symposium on Quantum Interaction (pp. 134-146).\n  Springer, Berlin, Heidelberg (2013, July)", "doi": null, "report-no": null, "categories": "cs.CL cs.AI quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conceptual entanglement is a crucial phenomenon in quantum cognition because\nit implies that classical probabilities cannot model non--compositional\nconceptual phenomena. While several psychological experiments have been\ndeveloped to test conceptual entanglement, this has not been explored in the\ncontext of Natural Language Processing. In this paper, we apply the hypothesis\nthat words of a document are traces of the concepts that a person has in mind\nwhen writing the document. Therefore, if these concepts are entangled, we\nshould be able to observe traces of their entanglement in the documents. In\nparticular, we test conceptual entanglement by contrasting language simulations\nwith results obtained from a text corpus. Our analysis indicates that\nconceptual entanglement is strongly linked to the way in which language is\nstructured. We discuss the implications of this finding in the context of\nconceptual modeling and of Natural Language Processing.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 20:22:15 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Veloz", "Tomas", ""], ["Zhao", "Xiazhao", ""], ["Aerts", "Diederik", ""]]}, {"id": "1909.09779", "submitter": "Siddhant Srivastava", "authors": "Siddhant Srivastava, Ritu Tiwari", "title": "Self-attention based end-to-end Hindi-English Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Translation (MT) is a zone of concentrate in Natural Language\nprocessing which manages the programmed interpretation of human language,\nstarting with one language then onto the next by the PC. Having a rich research\nhistory spreading over about three decades, Machine interpretation is a\nstandout amongst the most looked for after region of research in the\ncomputational linguistics network. As a piece of this current ace's proposal,\nthe fundamental center examines the Deep-learning based strategies that have\ngained critical ground as of late and turning into the de facto strategy in MT.\nWe would like to point out the recent advances that have been put forward in\nthe field of Neural Translation models, different domains under which NMT has\nreplaced conventional SMT models and would also like to mention future avenues\nin the field. Consequently, we propose an end-to-end self-attention transformer\nnetwork for Neural Machine Translation, trained on Hindi-English parallel\ncorpus and compare the model's efficiency with other state of art models like\nencoder-decoder and attention-based encoder-decoder neural models on the basis\nof BLEU. We conclude this paper with a comparative analysis of the three\nproposed models.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 06:16:52 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Srivastava", "Siddhant", ""], ["Tiwari", "Ritu", ""]]}, {"id": "1909.09788", "submitter": "Albert Gatt", "authors": "Somaye Jafaritazehjani and Albert Gatt and Marc Tanti", "title": "Visuallly Grounded Generation of Entailments from Premises", "comments": "Proceedings of the 12th International Conference on Natural Language\n  Generation (INLG 2019), 11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Natural Language Inference (NLI) is the task of determining the semantic\nrelationship between a premise and a hypothesis. In this paper, we focus on the\n{\\em generation} of hypotheses from premises in a multimodal setting, to\ngenerate a sentence (hypothesis) given an image and/or its description\n(premise) as the input. The main goals of this paper are (a) to investigate\nwhether it is reasonable to frame NLI as a generation task; and (b) to consider\nthe degree to which grounding textual premises in visual information is\nbeneficial to generation. We compare different neural architectures, showing\nthrough automatic and human evaluation that entailments can indeed be generated\nsuccessfully. We also show that multimodal models outperform unimodal models in\nthis task, albeit marginally.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 07:56:09 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Jafaritazehjani", "Somaye", ""], ["Gatt", "Albert", ""], ["Tanti", "Marc", ""]]}, {"id": "1909.09814", "submitter": "Diego Marcheggiani", "authors": "Diego Marcheggiani, Ivan Titov", "title": "Graph Convolutions over Constituent Trees for Syntax-Aware Semantic Role\n  Labeling", "comments": "Published in proceedings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic role labeling (SRL) is the task of identifying predicates and\nlabeling argument spans with semantic roles. Even though most semantic-role\nformalisms are built upon constituent syntax and only syntactic constituents\ncan be labeled as arguments (e.g., FrameNet and PropBank), all the recent work\non syntax-aware SRL relies on dependency representations of syntax. In\ncontrast, we show how graph convolutional networks (GCNs) can be used to encode\nconstituent structures and inform an SRL system. Nodes in our SpanGCN\ncorrespond to constituents. The computation is done in 3 stages. First, initial\nnode representations are produced by `composing' word representations of the\nfirst and the last word in the constituent. Second, graph convolutions relying\non the constituent tree are performed, yielding syntactically-informed\nconstituent representations. Finally, the constituent representations are\n`decomposed' back into word representations which in turn are used as input to\nthe SRL classifier. We evaluate SpanGCN against alternatives, including a model\nusing GCNs over dependency trees, and show its effectiveness on standard\nCoNLL-2005, CoNLL-2012, and FrameNet benchmarks.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 11:37:23 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 16:54:01 GMT"}, {"version": "v3", "created": "Sat, 21 Nov 2020 11:33:45 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Marcheggiani", "Diego", ""], ["Titov", "Ivan", ""]]}, {"id": "1909.09855", "submitter": "Alena Sorokina", "authors": "Alena Sorokina, Aidana Karipbayeva, Zhenisbek Assylbekov", "title": "Low-Rank Approximation of Matrices for PMI-based Word Embeddings", "comments": "10 pages, 4 figures, CICLing 2019, Springer \"Lecture Notes in\n  Computer Science\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We perform an empirical evaluation of several methods of low-rank\napproximation in the problem of obtaining PMI-based word embeddings. All word\nvectors were trained on parts of a large corpus extracted from English\nWikipedia (enwik9) which was divided into two equal-sized datasets, from which\nPMI matrices were obtained. A repeated measures design was used in assigning a\nmethod of low-rank approximation (SVD, NMF, QR) and dimensionality of the\nvectors (250, 500) to each of the PMI matrix replicates. Our experiments show\nthat word vectors obtained from the truncated SVD achieve the best performance\non two downstream tasks, similarity and analogy, compare to the other two\nlow-rank approximation methods.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 16:58:46 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Sorokina", "Alena", ""], ["Karipbayeva", "Aidana", ""], ["Assylbekov", "Zhenisbek", ""]]}, {"id": "1909.09907", "submitter": "Guy Rosin", "authors": "Guy D. Rosin and Kira Radinsky", "title": "Generating Timelines by Modeling Semantic Change", "comments": "10 pages, CoNLL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Though languages can evolve slowly, they can also react strongly to dramatic\nworld events. By studying the connection between words and events, it is\npossible to identify which events change our vocabulary and in what way. In\nthis work, we tackle the task of creating timelines - records of historical\n\"turning points\", represented by either words or events, to understand the\ndynamics of a target word. Our approach identifies these points by leveraging\nboth static and time-varying word embeddings to measure the influence of words\nand events. In addition to quantifying changes, we show how our technique can\nhelp isolate semantic changes. Our qualitative and quantitative evaluations\nshow that we are able to capture this semantic change and event influence.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 21:57:38 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Rosin", "Guy D.", ""], ["Radinsky", "Kira", ""]]}, {"id": "1909.09922", "submitter": "Chan Hee Song", "authors": "Arijit Sehanobish, Chan Hee Song", "title": "Using Chinese Glyphs for Named Entity Recognition", "comments": "Extended abstract accepted to AAAI-2020, student track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most Named Entity Recognition (NER) systems use additional features like\npart-of-speech (POS) tags, shallow parsing, gazetteers, etc. Such kind of\ninformation requires external knowledge like unlabeled texts and trained\ntaggers. Adding these features to NER systems have been shown to have a\npositive impact. However, sometimes creating gazetteers or taggers can take a\nlot of time and may require extensive data cleaning. In this paper for Chinese\nNER systems, we do not use these traditional features but we use lexicographic\nfeatures of Chinese characters. Chinese characters are composed of graphical\ncomponents called radicals and these components often have some semantic\nindicators. We propose CNN based models that incorporate this semantic\ninformation and use them for NER. Our models show an improvement over the\nbaseline BERT-BiLSTM-CRF model. We set a new baseline score for Chinese\nOntoNotes v5.0 and show an improvement of +.64 F1 score. We present a\nstate-of-the-art F1 score on Weibo dataset of 71.81 and show a competitive\nimprovement of +0.72 over baseline on ResumeNER dataset.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 01:12:18 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 03:41:14 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Sehanobish", "Arijit", ""], ["Song", "Chan Hee", ""]]}, {"id": "1909.09962", "submitter": "Gaurav Verma", "authors": "Bakhtiyar Syed, Gaurav Verma, Balaji Vasan Srinivasan, Anandhavelu\n  Natarajan, Vasudeva Varma", "title": "Adapting Language Models for Non-Parallel Author-Stylized Rewriting", "comments": "Accepted for publication in Main Technical Track at AAAI 20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the recent progress in language modeling using Transformer-based neural\nmodels and an active interest in generating stylized text, we present an\napproach to leverage the generalization capabilities of a language model to\nrewrite an input text in a target author's style. Our proposed approach adapts\na pre-trained language model to generate author-stylized text by fine-tuning on\nthe author-specific corpus using a denoising autoencoder (DAE) loss in a\ncascaded encoder-decoder framework. Optimizing over DAE loss allows our model\nto learn the nuances of an author's style without relying on parallel data,\nwhich has been a severe limitation of the previous related works in this space.\nTo evaluate the efficacy of our approach, we propose a linguistically-motivated\nframework to quantify stylistic alignment of the generated text to the target\nauthor at lexical, syntactic and surface levels. The evaluation framework is\nboth interpretable as it leads to several insights about the model, and\nself-contained as it does not rely on external classifiers, e.g. sentiment or\nformality classifiers. Qualitative and quantitative assessment indicates that\nthe proposed approach rewrites the input text with better alignment to the\ntarget style while preserving the original content better than state-of-the-art\nbaselines.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 08:13:28 GMT"}, {"version": "v2", "created": "Sun, 17 Nov 2019 09:19:29 GMT"}, {"version": "v3", "created": "Sat, 31 Oct 2020 06:43:02 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Syed", "Bakhtiyar", ""], ["Verma", "Gaurav", ""], ["Srinivasan", "Balaji Vasan", ""], ["Natarajan", "Anandhavelu", ""], ["Varma", "Vasudeva", ""]]}, {"id": "1909.09986", "submitter": "Amit Moryossef", "authors": "Amit Moryossef, Ido Dagan, Yoav Goldberg", "title": "Improving Quality and Efficiency in Plan-based Neural Data-to-Text\n  Generation", "comments": "5 pages, INLG-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We follow the step-by-step approach to neural data-to-text generation we\nproposed in Moryossef et al (2019), in which the generation process is divided\ninto a text-planning stage followed by a plan-realization stage. We suggest\nfour extensions to that framework: (1) we introduce a trainable neural planning\ncomponent that can generate effective plans several orders of magnitude faster\nthan the original planner; (2) we incorporate typing hints that improve the\nmodel's ability to deal with unseen relations and entities; (3) we introduce a\nverification-by-reranking stage that substantially improves the faithfulness of\nthe resulting texts; (4) we incorporate a simple but effective referring\nexpression generation module. These extensions result in a generation process\nthat is faster, more fluent, and more accurate.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 11:41:53 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Moryossef", "Amit", ""], ["Dagan", "Ido", ""], ["Goldberg", "Yoav", ""]]}, {"id": "1909.09993", "submitter": "Hirofumi Inaguma", "authors": "Hirofumi Inaguma, Masato Mimura, Shinsuke Sakai, Tatsuya Kawahara", "title": "Improving OOV Detection and Resolution with External Language Models in\n  Acoustic-to-Word ASR", "comments": "SLT2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustic-to-word (A2W) end-to-end automatic speech recognition (ASR) systems\nhave attracted attention because of an extremely simplified architecture and\nfast decoding. To alleviate data sparseness issues due to infrequent words, the\ncombination with an acoustic-to-character (A2C) model is investigated.\nMoreover, the A2C model can be used to recover out-of-vocabulary (OOV) words\nthat are not covered by the A2W model, but this requires accurate detection of\nOOV words. A2W models learn contexts with both acoustic and transcripts;\ntherefore they tend to falsely recognize OOV words as words in the vocabulary.\nIn this paper, we tackle this problem by using external language models (LM),\nwhich are trained only with transcriptions and have better linguistic\ninformation to detect OOV words. The A2C model is used to resolve these OOV\nwords. Experimental evaluations show that external LMs have the effects of not\nonly reducing errors but also increasing the number of detected OOV words, and\nthe proposed method significantly improves performances in English\nconversational and Japanese lecture corpora, especially for out-of-domain\nscenario. We also investigate the impact of the vocabulary size of A2W models\nand the data size for training LMs. Moreover, our approach can reduce the\nvocabulary size several times with marginal performance degradation.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 12:41:05 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Inaguma", "Hirofumi", ""], ["Mimura", "Masato", ""], ["Sakai", "Shinsuke", ""], ["Kawahara", "Tatsuya", ""]]}, {"id": "1909.10012", "submitter": "Neha Pathak", "authors": "Kumari Neha, Shashank Srikanth, Sonali Singhal, Shwetanshu Singh, Arun\n  Balaji Buduru, Ponnurangam Kumaraguru", "title": "Is change the only constant? Profile change perspective on\n  #LokSabhaElections2019", "comments": "8 pages, 11 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Users on Twitter are identified with the help of their profile attributes\nthat consists of username, display name, profile image, to name a few. The\nprofile attributes that users adopt can reflect their interests, belief, or\nthematic inclinations. Literature has proposed the implications and\nsignificance of profile attribute change for a random population of users.\nHowever, the use of profile attribute for endorsements and to start a movement\nhave been under-explored. In this work, we consider #LokSabhaElections2019 as a\nmovement and perform a large-scale study of the profile of users who actively\nmade changes to profile attributes centered around #LokSabhaElections2019. We\ncollect the profile metadata for 49.4M users for a period of 2 months from\nApril 5, 2019 to June 5, 2019 amid #LokSabhaElections2019. We investigate how\nthe profile changes vary for the influential leaders and their followers over\nthe social movement. We further differentiate the organic and inorganic ways to\nshow the political inclination from the prism of profile changes. We report how\nthe addition of election campaign related keywords lead to spread of behavior\ncontagion and further investigate it with respect to \"Chowkidar Movement\" in\ndetail.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 14:17:50 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Neha", "Kumari", ""], ["Srikanth", "Shashank", ""], ["Singhal", "Sonali", ""], ["Singh", "Shwetanshu", ""], ["Buduru", "Arun Balaji", ""], ["Kumaraguru", "Ponnurangam", ""]]}, {"id": "1909.10056", "submitter": "Phu Mon Htut", "authors": "Phu Mon Htut, Kyunghyun Cho, Samuel R. Bowman", "title": "Inducing Constituency Trees through Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent tree learning(LTL) methods learn to parse sentences using only\nindirect supervision from a downstream task. Recent advances in latent tree\nlearning have made it possible to recover moderately high quality tree\nstructures by training with language modeling or auto-encoding objectives. In\nthis work, we explore the hypothesis that decoding in machine translation, as a\nconditional language modeling task, will produce better tree structures since\nit offers a similar training signal as language modeling, but with more\nsemantic signal. We adapt two existing latent-tree language models--PRPN\nandON-LSTM--for use in translation. We find that they indeed recover trees that\nare better in F1 score than those seen in language modeling on WSJ test set,\nwhile maintaining strong translation quality. We observe that translation is a\nbetter objective than language modeling for inducing trees, marking the first\nsuccess at latent tree learning using a machine translation objective.\nAdditionally, our findings suggest that, although translation provides better\nsignal for inducing trees than language modeling, translation models can\nperform well without exploiting the latent tree structure.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 18:01:36 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Htut", "Phu Mon", ""], ["Cho", "Kyunghyun", ""], ["Bowman", "Samuel R.", ""]]}, {"id": "1909.10063", "submitter": "Muthiah Annamalai", "authors": "Muthiah Annamalai, T. Shrinivasan", "title": "Algorithms for certain classes of Tamil Spelling correction", "comments": "10 pages, 2 figures, Tamil Internet Conference - 2019, at Anna\n  University, Chennai, India (INFITT) [Sep, 2019]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tamil language has an agglutinative, diglossic, alpha-syllabary structure\nwhich provides a significant combinatorial explosion of morphological forms all\nof which are effectively used in Tamil prose, poetry from antiquity to the\nmodern age in an unbroken chain of continuity. However, for the language\nunderstanding, spelling correction purposes some of these present challenges as\nout-of-dictionary words. In this paper the authors propose algorithmic\ntechniques to handle specific problems of conjoined-words (out-of-dictionary)\n(transliteration)[thendRalkattRu] = [thendRal]+[kattRu] when parts are alone\npresent in word-list in efficient way. Morphological structure of Tamil makes\nit necessary to depend on synthesis-analysis approach and dictionary lists will\nnever be sufficient to truly capture the language. In this paper we have\nattempted to make a summary of various known algorithms for specific classes of\nTamil spelling errors. We believe this collection of suggestions to improve\nfuture spelling checkers. We also note do not cover many important techniques\nlike affix removal and other such techniques of key importance in rule-based\nspell checkers.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 18:24:41 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Annamalai", "Muthiah", ""], ["Shrinivasan", "T.", ""]]}, {"id": "1909.10094", "submitter": "I-Hung Hsu", "authors": "Rujun Han, I-Hung Hsu, Mu Yang, Aram Galstyan, Ralph Weischedel,\n  Nanyun Peng", "title": "Deep Structured Neural Network for Event Temporal Relation Extraction", "comments": "This paper will be published in CoNLL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel deep structured learning framework for event temporal\nrelation extraction. The model consists of 1) a recurrent neural network (RNN)\nto learn scoring functions for pair-wise relations, and 2) a structured support\nvector machine (SSVM) to make joint predictions. The neural network\nautomatically learns representations that account for long-term contexts to\nprovide robust features for the structured model, while the SSVM incorporates\ndomain knowledge such as transitive closure of temporal relations as\nconstraints to make better globally consistent decisions. By jointly training\nthe two components, our model combines the benefits of both data-driven\nlearning and knowledge exploitation. Experimental results on three high-quality\nevent temporal relation datasets (TCR, MATRES, and TB-Dense) demonstrate that\nincorporated with pre-trained contextualized embeddings, the proposed model\nachieves significantly better performances than the state-of-the-art methods on\nall three datasets. We also provide thorough ablation studies to investigate\nour model.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 21:11:08 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 22:18:39 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Han", "Rujun", ""], ["Hsu", "I-Hung", ""], ["Yang", "Mu", ""], ["Galstyan", "Aram", ""], ["Weischedel", "Ralph", ""], ["Peng", "Nanyun", ""]]}, {"id": "1909.10122", "submitter": "Sashank Santhanam", "authors": "Sashank Santhanam, Samira Shaikh", "title": "Towards Best Experiment Design for Evaluating Dialogue System Output", "comments": "Accepted at INLG 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To overcome the limitations of automated metrics (e.g. BLEU, METEOR) for\nevaluating dialogue systems, researchers typically use human judgments to\nprovide convergent evidence. While it has been demonstrated that human\njudgments can suffer from the inconsistency of ratings, extant research has\nalso found that the design of the evaluation task affects the consistency and\nquality of human judgments. We conduct a between-subjects study to understand\nthe impact of four experiment conditions on human ratings of dialogue system\noutput. In addition to discrete and continuous scale ratings, we also\nexperiment with a novel application of Best-Worst scaling to dialogue\nevaluation. Through our systematic study with 40 crowdsourced workers in each\ntask, we find that using continuous scales achieves more consistent ratings\nthan Likert scale or ranking-based experiment design. Additionally, we find\nthat factors such as time taken to complete the task and no prior experience of\nparticipating in similar studies of rating dialogue system output positively\nimpact consistency and agreement amongst raters\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 01:45:55 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Santhanam", "Sashank", ""], ["Shaikh", "Samira", ""]]}, {"id": "1909.10148", "submitter": "Zhanming Jie", "authors": "Zhanming Jie, Wei Lu", "title": "Dependency-Guided LSTM-CRF for Named Entity Recognition", "comments": "13 pages, 6 figures, accepted by EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dependency tree structures capture long-distance and syntactic relationships\nbetween words in a sentence. The syntactic relations (e.g., nominal subject,\nobject) can potentially infer the existence of certain named entities. In\naddition, the performance of a named entity recognizer could benefit from the\nlong-distance dependencies between the words in dependency trees. In this work,\nwe propose a simple yet effective dependency-guided LSTM-CRF model to encode\nthe complete dependency trees and capture the above properties for the task of\nnamed entity recognition (NER). The data statistics show strong correlations\nbetween the entity types and dependency relations. We conduct extensive\nexperiments on several standard datasets and demonstrate the effectiveness of\nthe proposed model in improving NER and achieving state-of-the-art performance.\nOur analysis reveals that the significant improvements mainly result from the\ndependency relations and long-distance interactions provided by dependency\ntrees.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 04:21:35 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Jie", "Zhanming", ""], ["Lu", "Wei", ""]]}, {"id": "1909.10166", "submitter": "Zitao Liu", "authors": "Tiaoqiao Liu, Wenbiao Ding, Zhiwei Wang, Jiliang Tang, Gale Yan Huang,\n  Zitao Liu", "title": "Automatic Short Answer Grading via Multiway Attention Networks", "comments": "The 20th International Conference on Artificial Intelligence in\n  Education(AIED), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic short answer grading (ASAG), which autonomously score student\nanswers according to reference answers, provides a cost-effective and\nconsistent approach to teaching professionals and can reduce their monotonous\nand tedious grading workloads. However, ASAG is a very challenging task due to\ntwo reasons: (1) student answers are made up of free text which requires a deep\nsemantic understanding; and (2) the questions are usually open-ended and across\nmany domains in K-12 scenarios. In this paper, we propose a generalized\nend-to-end ASAG learning framework which aims to (1) autonomously extract\nlinguistic information from both student and reference answers; and (2)\naccurately model the semantic relations between free-text student and reference\nanswers in open-ended domain. The proposed ASAG model is evaluated on a large\nreal-world K-12 dataset and can outperform the state-of-the-art baselines in\nterms of various evaluation metrics.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 05:29:04 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Liu", "Tiaoqiao", ""], ["Ding", "Wenbiao", ""], ["Wang", "Zhiwei", ""], ["Tang", "Jiliang", ""], ["Huang", "Gale Yan", ""], ["Liu", "Zitao", ""]]}, {"id": "1909.10171", "submitter": "Chen Zhang", "authors": "Chen Zhang, Qiuchi Li, Dawei Song", "title": "Syntax-Aware Aspect-Level Sentiment Classification with\n  Proximity-Weighted Convolution Network", "comments": "4 pages, 2 figures, SIGIR 2019 (Short)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been widely accepted that Long Short-Term Memory (LSTM) network,\ncoupled with attention mechanism and memory module, is useful for aspect-level\nsentiment classification. However, existing approaches largely rely on the\nmodelling of semantic relatedness of an aspect with its context words, while to\nsome extent ignore their syntactic dependencies within sentences. Consequently,\nthis may lead to an undesirable result that the aspect attends on contextual\nwords that are descriptive of other aspects. In this paper, we propose a\nproximity-weighted convolution network to offer an aspect-specific syntax-aware\nrepresentation of contexts. In particular, two ways of determining proximity\nweight are explored, namely position proximity and dependency proximity. The\nrepresentation is primarily abstracted by a bidirectional LSTM architecture and\nfurther enhanced by a proximity-weighted convolution. Experiments conducted on\nthe SemEval 2014 benchmark demonstrate the effectiveness of our proposed\napproach compared with a range of state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 05:56:13 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Zhang", "Chen", ""], ["Li", "Qiuchi", ""], ["Song", "Dawei", ""]]}, {"id": "1909.10261", "submitter": "Danny Hucke", "authors": "Moses Ganardi, Danny Hucke, Markus Lohrey, Tatiana Starikovskaya", "title": "Sliding window property testing for regular languages", "comments": "A short version of this paper was accepted for presentation at ISAAC\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CL cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of recognizing regular languages in a variant of the\nstreaming model of computation, called the sliding window model. In this model,\nwe are given a size of the sliding window $n$ and a stream of symbols. At each\ntime instant, we must decide whether the suffix of length $n$ of the current\nstream (\"the active window\") belongs to a given regular language.\n  Recent works showed that the space complexity of an optimal deterministic\nsliding window algorithm for this problem is either constant, logarithmic or\nlinear in the window size $n$ and provided natural language theoretic\ncharacterizations of the space complexity classes. Subsequently, those results\nwere extended to randomized algorithms to show that any such algorithm admits\neither constant, double logarithmic, logarithmic or linear space complexity.\n  In this work, we make an important step forward and combine the sliding\nwindow model with the property testing setting, which results in\nultra-efficient algorithms for all regular languages. Informally, a sliding\nwindow property tester must accept the active window if it belongs to the\nlanguage and reject it if it is far from the language. We consider\ndeterministic and randomized sliding window property testers with one-sided and\ntwo-sided errors. In particular, we show that for any regular language, there\nis a deterministic sliding window property tester that uses logarithmic space\nand a randomized sliding window property tester with two-sided error that uses\nconstant space.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 10:12:13 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Ganardi", "Moses", ""], ["Hucke", "Danny", ""], ["Lohrey", "Markus", ""], ["Starikovskaya", "Tatiana", ""]]}, {"id": "1909.10309", "submitter": "Kailun Wang", "authors": "Kailun Wang", "title": "An Evalutation of Programming Language Models' performance on Software\n  Defect Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This dissertation presents an evaluation of several language models on\nsoftware defect datasets. A language Model (LM) \"can provide word\nrepresentation and probability indication of word sequences as the core\ncomponent of an NLP system.\" Language models for source code are specified for\ntasks in the software engineering field. While some models are directly the NLP\nones, others contain structural information that is uniquely owned by source\ncode. Software defects are defects in the source code that lead to unexpected\nbehaviours and malfunctions at all levels. This study provides an original\nattempt to detect these defects at three different levels (syntactical,\nalgorithmic and general) We also provide a tool chain that researchers can use\nto reproduce the experiments. We have tested the different models against\ndifferent datasets, and performed an analysis over the results. Our original\nattempt to deploy bert, the state-of-the-art model for multitasks, leveled or\noutscored all other models compared.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 19:07:15 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Wang", "Kailun", ""]]}, {"id": "1909.10324", "submitter": "Joanna Rownicka", "authors": "Jennifer Williams and Joanna Rownicka", "title": "Speech Replay Detection with x-Vector Attack Embeddings and Spectral\n  Features", "comments": "Presented at Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present our system submission to the ASVspoof 2019 Challenge Physical\nAccess (PA) task. The objective for this challenge was to develop a\ncountermeasure that identifies speech audio as either bona fide or intercepted\nand replayed. The target prediction was a value indicating that a speech\nsegment was bona fide (positive values) or \"spoofed\" (negative values). Our\nsystem used convolutional neural networks (CNNs) and a representation of the\nspeech audio that combined x-vector attack embeddings with signal processing\nfeatures. The x-vector attack embeddings were created from mel-frequency\ncepstral coefficients (MFCCs) using a time-delay neural network (TDNN). These\nembeddings jointly modeled 27 different environments and 9 types of attacks\nfrom the labeled data. We also used sub-band spectral centroid magnitude\ncoefficients (SCMCs) as features. We included an additive Gaussian noise layer\nduring training as a way to augment the data to make our system more robust to\npreviously unseen attack examples. We report system performance using the\ntandem detection cost function (tDCF) and equal error rate (EER). Our approach\nperformed better that both of the challenge baselines. Our technique suggests\nthat our x-vector attack embeddings can help regularize the CNN predictions\neven when environments or attacks are more challenging.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 12:27:04 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Williams", "Jennifer", ""], ["Rownicka", "Joanna", ""]]}, {"id": "1909.10351", "submitter": "Yichun Yin", "authors": "Xiaoqi Jiao, Yichun Yin, Lifeng Shang, Xin Jiang, Xiao Chen, Linlin\n  Li, Fang Wang and Qun Liu", "title": "TinyBERT: Distilling BERT for Natural Language Understanding", "comments": "Findings of EMNLP 2020; results have been updated; code and model:\n  https://github.com/huawei-noah/Pretrained-Language-Model/tree/master/TinyBERT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language model pre-training, such as BERT, has significantly improved the\nperformances of many natural language processing tasks. However, pre-trained\nlanguage models are usually computationally expensive, so it is difficult to\nefficiently execute them on resource-restricted devices. To accelerate\ninference and reduce model size while maintaining accuracy, we first propose a\nnovel Transformer distillation method that is specially designed for knowledge\ndistillation (KD) of the Transformer-based models. By leveraging this new KD\nmethod, the plenty of knowledge encoded in a large teacher BERT can be\neffectively transferred to a small student Tiny-BERT. Then, we introduce a new\ntwo-stage learning framework for TinyBERT, which performs Transformer\ndistillation at both the pretraining and task-specific learning stages. This\nframework ensures that TinyBERT can capture he general-domain as well as the\ntask-specific knowledge in BERT.\n  TinyBERT with 4 layers is empirically effective and achieves more than 96.8%\nthe performance of its teacher BERTBASE on GLUE benchmark, while being 7.5x\nsmaller and 9.4x faster on inference. TinyBERT with 4 layers is also\nsignificantly better than 4-layer state-of-the-art baselines on BERT\ndistillation, with only about 28% parameters and about 31% inference time of\nthem. Moreover, TinyBERT with 6 layers performs on-par with its teacher\nBERTBASE.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 13:05:35 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 12:39:36 GMT"}, {"version": "v3", "created": "Tue, 3 Dec 2019 01:29:39 GMT"}, {"version": "v4", "created": "Wed, 4 Dec 2019 01:50:34 GMT"}, {"version": "v5", "created": "Fri, 16 Oct 2020 02:12:46 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Jiao", "Xiaoqi", ""], ["Yin", "Yichun", ""], ["Shang", "Lifeng", ""], ["Jiang", "Xin", ""], ["Chen", "Xiao", ""], ["Li", "Linlin", ""], ["Wang", "Fang", ""], ["Liu", "Qun", ""]]}, {"id": "1909.10368", "submitter": "Blake Howald", "authors": "Berk Ekmekci, Eleanor Hagerman, Blake Howald", "title": "A Consolidated System for Robust Multi-Document Entity Risk Extraction\n  and Taxonomy Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a hybrid human-automated system that provides scalable\nentity-risk relation extractions across large data sets. Given an\nexpert-defined keyword taxonomy, entities, and data sources, the system returns\ntext extractions based on bidirectional token distances between entities and\nkeywords and expands taxonomy coverage with word vector encodings. Our system\nrepresents a more simplified architecture compared to alerting focused systems\n- motivated by high coverage use cases in the risk mining space such as due\ndiligence activities and intelligence gathering. We provide an overview of the\nsystem and expert evaluations for a range of token distances. We demonstrate\nthat single and multi-sentence distance groups significantly outperform\nbaseline extractions with shorter, single sentences being preferred by\nanalysts. As the taxonomy expands, the amount of relevant information increases\nand multi-sentence extractions become more preferred, but this is tempered\nagainst entity-risk relations become more indirect. We discuss the implications\nof these observations on users, management of ambiguity and taxonomy expansion,\nand future system modifications.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 13:57:47 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Ekmekci", "Berk", ""], ["Hagerman", "Eleanor", ""], ["Howald", "Blake", ""]]}, {"id": "1909.10390", "submitter": "Maksim Belousov", "authors": "Maksim Belousov, Nikola Milosevic, Ghada Alfattni, Haifa Alrdahi,\n  Goran Nenadic", "title": "GNTeam at 2018 n2c2: Feature-augmented BiLSTM-CRF for drug-related\n  entity recognition in hospital discharge summaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monitoring the administration of drugs and adverse drug reactions are key\nparts of pharmacovigilance. In this paper, we explore the extraction of drug\nmentions and drug-related information (reason for taking a drug, route,\nfrequency, dosage, strength, form, duration, and adverse events) from hospital\ndischarge summaries through deep learning that relies on various\nrepresentations for clinical named entity recognition. This work was officially\npart of the 2018 n2c2 shared task, and we use the data supplied as part of the\ntask. We developed two deep learning architecture based on recurrent neural\nnetworks and pre-trained language models. We also explore the effect of\naugmenting word representations with semantic features for clinical named\nentity recognition. Our feature-augmented BiLSTM-CRF model performed with\nF1-score of 92.67% and ranked 4th for entity extraction sub-task among\nsubmitted systems to n2c2 challenge. The recurrent neural networks that use the\npre-trained domain-specific word embeddings and a CRF layer for label\noptimization perform drug, adverse event and related entities extraction with\nmicro-averaged F1-score of over 91%. The augmentation of word vectors with\nsemantic features extracted using available clinical NLP toolkits can further\nimprove the performance. Word embeddings that are pre-trained on a large\nunannotated corpus of relevant documents and further fine-tuned to the task\nperform rather well. However, the augmentation of word embeddings with semantic\nfeatures can help improve the performance (primarily by boosting precision) of\ndrug-related named entity recognition from electronic health records.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 14:35:23 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Belousov", "Maksim", ""], ["Milosevic", "Nikola", ""], ["Alfattni", "Ghada", ""], ["Alrdahi", "Haifa", ""], ["Nenadic", "Goran", ""]]}, {"id": "1909.10393", "submitter": "Blake Howald", "authors": "Berk Ekmekci, Eleanor Hagerman, Blake Howald", "title": "Specificity-Based Sentence Ordering for Multi-Document Extractive Risk\n  Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Risk mining technologies seek to find relevant textual extractions that\ncapture entity-risk relationships. However, when high volume data sets are\nprocessed, a multitude of relevant extractions can be returned, shifting the\nfocus to how best to present the results. We provide the details of a risk\nmining multi-document extractive summarization system that produces high\nquality output by modeling shifts in specificity that are characteristic of\nwell-formed discourses. In particular, we propose a novel selection algorithm\nthat alternates between extracts based on human curated or expanded autoencoded\nkey terms, which exhibit greater specificity or generality as it relates to an\nentity-risk relationship. Through this extract ordering, and without the need\nfor more complex discourse-aware NLP, we induce felicitous shifts in\nspecificity in the alternating summaries that outperform non-alternating\nsummaries on automatic ROUGE and BLEU scores, and manual understandability and\npreferences evaluations - achieving no statistically significant difference\nwhen compared to human authored summaries.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 14:37:30 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Ekmekci", "Berk", ""], ["Hagerman", "Eleanor", ""], ["Howald", "Blake", ""]]}, {"id": "1909.10411", "submitter": "Alane Suhr", "authors": "Alane Suhr, Yoav Artzi", "title": "NLVR2 Visual Bias Analysis", "comments": "Corresponding notebook available at\n  http://lil.nlp.cornell.edu/nlvr/NLVR2BiasAnalysis.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NLVR2 (Suhr et al., 2019) was designed to be robust for language bias through\na data collection process that resulted in each natural language sentence\nappearing with both true and false labels. The process did not provide a\nsimilar measure of control for visual bias. This technical report analyzes the\npotential for visual bias in NLVR2. We show that some amount of visual bias\nlikely exists. Finally, we identify a subset of the test data that allows to\ntest for model performance in a way that is robust to such potential biases. We\nshow that the performance of existing models (Li et al., 2019; Tan and Bansal\n2019) is relatively robust to this potential bias. We propose to add the\nevaluation on this subset of the data to the NLVR2 evaluation protocol, and\nupdate the official release to include it. A notebook including an\nimplementation of the code used to replicate this analysis is available at\nhttp://nlvr.ai/NLVR2BiasAnalysis.html.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 15:10:41 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Suhr", "Alane", ""], ["Artzi", "Yoav", ""]]}, {"id": "1909.10413", "submitter": "Hongyu Zang", "authors": "Hongyu Zang, Zhiwei Yu, Xiaojun Wan", "title": "Automated Chess Commentator Powered by Neural Chess Engine", "comments": "The first two authors contributed equally to this paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore a new approach for automated chess commentary\ngeneration, which aims to generate chess commentary texts in different\ncategories (e.g., description, comparison, planning, etc.). We introduce a\nneural chess engine into text generation models to help with encoding boards,\npredicting moves, and analyzing situations. By jointly training the neural\nchess engine and the generation models for different categories, the models\nbecome more effective. We conduct experiments on 5 categories in a benchmark\nChess Commentary dataset and achieve inspiring results in both automatic and\nhuman evaluations.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 15:12:45 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Zang", "Hongyu", ""], ["Yu", "Zhiwei", ""], ["Wan", "Xiaojun", ""]]}, {"id": "1909.10416", "submitter": "Chih-Hsuan Wei", "authors": "Chih-Hsuan Wei, Kyubum Lee, Robert Leaman, Zhiyong Lu", "title": "Biomedical Mention Disambiguation using a Deep Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Automatically locating named entities in natural language text - named entity\nrecognition - is an important task in the biomedical domain. Many named entity\nmentions are ambiguous between several bioconcept types, however, causing text\nspans to be annotated as more than one type when simultaneously recognizing\nmultiple entity types. The straightforward solution is a rule-based approach\napplying a priority order based on the precision of each entity tagger (from\nhighest to lowest). While this method is straightforward and useful, imprecise\ndisambiguation remains a significant source of error. We address this issue by\ngenerating a partially labeled corpus of ambiguous concept mentions. We first\ncollect named entity mentions from multiple human-curated databases (e.g.\nCTDbase, gene2pubmed), then correlate them with the text mined span from\nPubTator to provide the context where the mention appears. Our corpus contains\nmore than 3 million concept mentions that ambiguous between one or more concept\ntypes in PubTator (about 3% of all mentions). We approached this task as a\nclassification problem and developed a deep learning-based method which uses\nthe semantics of the span being classified and the surrounding words to\nidentify the most likely bioconcept type. More specifically, we develop a\nconvolutional neural network (CNN) and along short-term memory (LSTM) network\nto respectively handle the semantic syntax features, then concatenate these\nwithin a fully connected layer for final classification. The priority ordering\nrule-based approach demonstrated F1-scores of 71.29% (micro-averaged) and\n41.19% (macro-averaged), while the new disambiguation method demonstrated\nF1-scores of 91.94% (micro-averaged) and 85.42% (macro-averaged), a very\nsubstantial increase.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 15:14:56 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Wei", "Chih-Hsuan", ""], ["Lee", "Kyubum", ""], ["Leaman", "Robert", ""], ["Lu", "Zhiyong", ""]]}, {"id": "1909.10430", "submitter": "Gregor Wiedemann", "authors": "Gregor Wiedemann, Steffen Remus, Avi Chawla, Chris Biemann", "title": "Does BERT Make Any Sense? Interpretable Word Sense Disambiguation with\n  Contextualized Embeddings", "comments": "10 pages, 3 figures, 6 tables, Accepted for Konferenz zur\n  Verarbeitung nat\\\"urlicher Sprache / Conference on Natural Language\n  Processing (KONVENS) 2019, Erlangen/Germany", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextualized word embeddings (CWE) such as provided by ELMo (Peters et al.,\n2018), Flair NLP (Akbik et al., 2018), or BERT (Devlin et al., 2019) are a\nmajor recent innovation in NLP. CWEs provide semantic vector representations of\nwords depending on their respective context. Their advantage over static word\nembeddings has been shown for a number of tasks, such as text classification,\nsequence tagging, or machine translation. Since vectors of the same word type\ncan vary depending on the respective context, they implicitly provide a model\nfor word sense disambiguation (WSD). We introduce a simple but effective\napproach to WSD using a nearest neighbor classification on CWEs. We compare the\nperformance of different CWE models for the task and can report improvements\nabove the current state of the art for two standard WSD benchmark datasets. We\nfurther show that the pre-trained BERT model is able to place polysemic words\ninto distinct 'sense' regions of the embedding space, while ELMo and Flair NLP\ndo not seem to possess this ability.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 15:38:02 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 13:26:04 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Wiedemann", "Gregor", ""], ["Remus", "Steffen", ""], ["Chawla", "Avi", ""], ["Biemann", "Chris", ""]]}, {"id": "1909.10447", "submitter": "Pranava Madhyastha", "authors": "Pranava Madhyastha, Rishabh Jain", "title": "On Model Stability as a Function of Random Seed", "comments": "v1; Accepted for publication at CoNLL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we focus on quantifying model stability as a function of\nrandom seed by investigating the effects of the induced randomness on model\nperformance and the robustness of the model in general. We specifically perform\na controlled study on the effect of random seeds on the behaviour of attention,\ngradient-based and surrogate model based (LIME) interpretations. Our analysis\nsuggests that random seeds can adversely affect the consistency of models\nresulting in counterfactual interpretations. We propose a technique called\nAggressive Stochastic Weight Averaging (ASWA)and an extension called\nNorm-filtered Aggressive Stochastic Weight Averaging (NASWA) which improves the\nstability of models over random seeds. With our ASWA and NASWA based\noptimization, we are able to improve the robustness of the original model, on\naverage reducing the standard deviation of the model's performance by 72%.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 16:00:06 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Madhyastha", "Pranava", ""], ["Jain", "Rishabh", ""]]}, {"id": "1909.10470", "submitter": "Vishvak Murahari", "authors": "Vishvak Murahari, Prithvijit Chattopadhyay, Dhruv Batra, Devi Parikh,\n  Abhishek Das", "title": "Improving Generative Visual Dialog by Answering Diverse Questions", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior work on training generative Visual Dialog models with reinforcement\nlearning(Das et al.) has explored a Qbot-Abot image-guessing game and shown\nthat this 'self-talk' approach can lead to improved performance at the\ndownstream dialog-conditioned image-guessing task. However, this improvement\nsaturates and starts degrading after a few rounds of interaction, and does not\nlead to a better Visual Dialog model. We find that this is due in part to\nrepeated interactions between Qbot and Abot during self-talk, which are not\ninformative with respect to the image. To improve this, we devise a simple\nauxiliary objective that incentivizes Qbot to ask diverse questions, thus\nreducing repetitions and in turn enabling Abot to explore a larger state space\nduring RL ie. be exposed to more visual concepts to talk about, and varied\nquestions to answer. We evaluate our approach via a host of automatic metrics\nand human studies, and demonstrate that it leads to better dialog, ie. dialog\nthat is more diverse (ie. less repetitive), consistent (ie. has fewer\nconflicting exchanges), fluent (ie. more human-like),and detailed, while still\nbeing comparably image-relevant as prior work and ablations.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 16:47:15 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 03:01:48 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Murahari", "Vishvak", ""], ["Chattopadhyay", "Prithvijit", ""], ["Batra", "Dhruv", ""], ["Parikh", "Devi", ""], ["Das", "Abhishek", ""]]}, {"id": "1909.10481", "submitter": "Li Dong", "authors": "Zewen Chi, Li Dong, Furu Wei, Wenhui Wang, Xian-Ling Mao, Heyan Huang", "title": "Cross-Lingual Natural Language Generation via Pre-Training", "comments": "Accepted by AAAI-20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we focus on transferring supervision signals of natural language\ngeneration (NLG) tasks between multiple languages. We propose to pretrain the\nencoder and the decoder of a sequence-to-sequence model under both monolingual\nand cross-lingual settings. The pre-training objective encourages the model to\nrepresent different languages in the shared space, so that we can conduct\nzero-shot cross-lingual transfer. After the pre-training procedure, we use\nmonolingual data to fine-tune the pre-trained model on downstream NLG tasks.\nThen the sequence-to-sequence model trained in a single language can be\ndirectly evaluated beyond that language (i.e., accepting multi-lingual input\nand producing multi-lingual output). Experimental results on question\ngeneration and abstractive summarization show that our model outperforms the\nmachine-translation-based pipeline methods for zero-shot cross-lingual\ngeneration. Moreover, cross-lingual transfer improves NLG performance of\nlow-resource languages by leveraging rich-resource language data. Our\nimplementation and data are available at https://github.com/CZWin32768/xnlg.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 16:59:28 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 16:39:27 GMT"}, {"version": "v3", "created": "Fri, 22 Nov 2019 09:24:46 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Chi", "Zewen", ""], ["Dong", "Li", ""], ["Wei", "Furu", ""], ["Wang", "Wenhui", ""], ["Mao", "Xian-Ling", ""], ["Huang", "Heyan", ""]]}, {"id": "1909.10493", "submitter": "Chunhui Guo", "authors": "Chunhui Guo, Zhicheng Fu, Zhenyu Zhang, Shangping Ren, Lui Sha", "title": "Formalism for Supporting the Development of Verifiably Safe Medical\n  Guidelines with Statecharts", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL cs.FL cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improving the effectiveness and safety of patient care is the ultimate\nobjective for medical cyber-physical systems. Many medical best practice\nguidelines exist, but most of the existing guidelines in handbooks are\ndifficult for medical staff to remember and apply clinically. Furthermore,\nalthough the guidelines have gone through clinical validations, validations by\nmedical professionals alone do not provide guarantees for the safety of medical\ncyber-physical systems. Hence, formal verification is also needed. The paper\npresents the formal semantics for a framework that we developed to support the\ndevelopment of verifiably safe medical guidelines.\n  The framework allows computer scientists to work together with medical\nprofessionals to transform medical best practice guidelines into executable\nstatechart models, Yakindu in particular, so that medical functionalities and\nproperties can be quickly prototyped and validated. Existing formal\nverification technologies, UPPAAL timed automata in particular, is integrated\ninto the framework to provide formal verification capabilities to verify safety\nproperties. However, some components used/built into the framework, such as the\nopen-source Yakindu statecharts as well as the transformation rules from\nstatecharts to timed automata, do not have built-in semantics. The ambiguity\nbecomes unavoidable unless formal semantics is defined for the framework, which\nis what the paper is to present.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 17:25:50 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Guo", "Chunhui", ""], ["Fu", "Zhicheng", ""], ["Zhang", "Zhenyu", ""], ["Ren", "Shangping", ""], ["Sha", "Lui", ""]]}, {"id": "1909.10506", "submitter": "Daniel Gillick", "authors": "Daniel Gillick, Sayali Kulkarni, Larry Lansing, Alessandro Presta,\n  Jason Baldridge, Eugene Ie, Diego Garcia-Olano", "title": "Learning Dense Representations for Entity Retrieval", "comments": "CoNLL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that it is feasible to perform entity linking by training a dual\nencoder (two-tower) model that encodes mentions and entities in the same dense\nvector space, where candidate entities are retrieved by approximate nearest\nneighbor search. Unlike prior work, this setup does not rely on an alias table\nfollowed by a re-ranker, and is thus the first fully learned entity retrieval\nmodel. We show that our dual encoder, trained using only anchor-text links in\nWikipedia, outperforms discrete alias table and BM25 baselines, and is\ncompetitive with the best comparable results on the standard TACKBP-2010\ndataset. In addition, it can retrieve candidates extremely fast, and\ngeneralizes well to a new dataset derived from Wikinews. On the modeling side,\nwe demonstrate the dramatic value of an unsupervised negative mining algorithm\nfor this task.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 17:52:34 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Gillick", "Daniel", ""], ["Kulkarni", "Sayali", ""], ["Lansing", "Larry", ""], ["Presta", "Alessandro", ""], ["Baldridge", "Jason", ""], ["Ie", "Eugene", ""], ["Garcia-Olano", "Diego", ""]]}, {"id": "1909.10572", "submitter": "Sarthak Dash", "authors": "Sarthak Dash, Md Faisal Mahbub Chowdhury, Alfio Gliozzo, Nandana\n  Mihindukulasooriya, Nicolas Rodolfo Fauceglia", "title": "Hypernym Detection Using Strict Partial Order Networks", "comments": "8 pages", "journal-ref": "AAAI 2020", "doi": "10.1609/aaai.v34i05.6263", "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Strict Partial Order Networks (SPON), a novel neural\nnetwork architecture designed to enforce asymmetry and transitive properties as\nsoft constraints. We apply it to induce hypernymy relations by training with\nis-a pairs. We also present an augmented variant of SPON that can generalize\ntype information learned for in-vocabulary terms to previously unseen ones. An\nextensive evaluation over eleven benchmarks across different tasks shows that\nSPON consistently either outperforms or attains the state of the art on all but\none of these benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 18:54:52 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 22:40:23 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Dash", "Sarthak", ""], ["Chowdhury", "Md Faisal Mahbub", ""], ["Gliozzo", "Alfio", ""], ["Mihindukulasooriya", "Nandana", ""], ["Fauceglia", "Nicolas Rodolfo", ""]]}, {"id": "1909.10579", "submitter": "Grusha Prasad", "authors": "Grusha Prasad and Marten van Schijndel and Tal Linzen", "title": "Using Priming to Uncover the Organization of Syntactic Representations\n  in Neural Language Models", "comments": "9 pages paper, 2 pages references and 3 pages supplementary\n  materials. Code for the templates and analyses can be found here:\n  https://github.com/grushaprasad/RNN-Priming", "journal-ref": "CoNLL 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural language models (LMs) perform well on tasks that require sensitivity\nto syntactic structure. Drawing on the syntactic priming paradigm from\npsycholinguistics, we propose a novel technique to analyze the representations\nthat enable such success. By establishing a gradient similarity metric between\nstructures, this technique allows us to reconstruct the organization of the\nLMs' syntactic representational space. We use this technique to demonstrate\nthat LSTM LMs' representations of different types of sentences with relative\nclauses are organized hierarchically in a linguistically interpretable manner,\nsuggesting that the LMs track abstract properties of the sentence.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 19:13:33 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Prasad", "Grusha", ""], ["van Schijndel", "Marten", ""], ["Linzen", "Tal", ""]]}, {"id": "1909.10599", "submitter": "Sebastian Goodman", "authors": "Sebastian Goodman, Zhenzhong Lan, Radu Soricut", "title": "Multi-stage Pretraining for Abstractive Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural models for abstractive summarization tend to achieve the best\nperformance in the presence of highly specialized, summarization specific\nmodeling add-ons such as pointer-generator, coverage-modeling, and\ninferencetime heuristics. We show here that pretraining can complement such\nmodeling advancements to yield improved results in both short-form and\nlong-form abstractive summarization using two key concepts: full-network\ninitialization and multi-stage pretraining. Our method allows the model to\ntransitively benefit from multiple pretraining tasks, from generic language\ntasks to a specialized summarization task to an even more specialized one such\nas bullet-based summarization. Using this approach, we demonstrate improvements\nof 1.05 ROUGE-L points on the Gigaword benchmark and 1.78 ROUGE-L points on the\nCNN/DailyMail benchmark, compared to a randomly-initialized baseline.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 20:10:56 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Goodman", "Sebastian", ""], ["Lan", "Zhenzhong", ""], ["Soricut", "Radu", ""]]}, {"id": "1909.10642", "submitter": "Siddhant Garg", "authors": "Siddhant Garg", "title": "Data Ordering Patterns for Neural Machine Translation: An Empirical\n  Study", "comments": "Submitted to 3rd Workshop on Neural Generation and Translation, EMNLP\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works show that ordering of the training data affects the model\nperformance for Neural Machine Translation. Several approaches involving\ndynamic data ordering and data sharding based on curriculum learning have been\nanalysed for the their performance gains and faster convergence. In this work\nwe propose to empirically study several ordering approaches for the training\ndata based on different metrics and evaluate their impact on the model\nperformance. Results from our study show that pre-fixing the ordering of the\ntraining data based on perplexity scores from a pre-trained model performs the\nbest and outperforms the default approach of randomly shuffling the training\ndata every epoch.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 22:20:03 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Garg", "Siddhant", ""]]}, {"id": "1909.10649", "submitter": "F\\'abio Souza", "authors": "F\\'abio Souza, Rodrigo Nogueira, Roberto Lotufo", "title": "Portuguese Named Entity Recognition using BERT-CRF", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in language representation using neural networks have made it\nviable to transfer the learned internal states of a trained model to downstream\nnatural language processing tasks, such as named entity recognition (NER) and\nquestion answering. It has been shown that the leverage of pre-trained language\nmodels improves the overall performance on many tasks and is highly beneficial\nwhen labeled data is scarce. In this work, we train Portuguese BERT models and\nemploy a BERT-CRF architecture to the NER task on the Portuguese language,\ncombining the transfer capabilities of BERT with the structured predictions of\nCRF. We explore feature-based and fine-tuning training strategies for the BERT\nmodel. Our fine-tuning approach obtains new state-of-the-art results on the\nHAREM I dataset, improving the F1-score by 1 point on the selective scenario (5\nNE classes) and by 4 points on the total scenario (10 NE classes).\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 23:21:42 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 15:06:49 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Souza", "F\u00e1bio", ""], ["Nogueira", "Rodrigo", ""], ["Lotufo", "Roberto", ""]]}, {"id": "1909.10666", "submitter": "Yiming Cui", "authors": "Wentao Ma, Yiming Cui, Nan Shao, Su He, Wei-Nan Zhang, Ting Liu,\n  Shijin Wang, Guoping Hu", "title": "TripleNet: Triple Attention Network for Multi-Turn Response Selection in\n  Retrieval-based Chatbots", "comments": "10 pages, accepted as a conference paper at CoNLL 2019", "journal-ref": "CoNLL 2019 737-746", "doi": "10.18653/v1/K19-1069", "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the importance of different utterances in the context for\nselecting the response usually depends on the current query. In this paper, we\npropose the model TripleNet to fully model the task with the triple <context,\nquery, response> instead of <context, response> in previous works. The heart of\nTripleNet is a novel attention mechanism named triple attention to model the\nrelationships within the triple at four levels. The new mechanism updates the\nrepresentation for each element based on the attention with the other two\nconcurrently and symmetrically. We match the triple <C, Q, R> centered on the\nresponse from char to context level for prediction. Experimental results on two\nlarge-scale multi-turn response selection datasets show that the proposed model\ncan significantly outperform the state-of-the-art methods. TripleNet source\ncode is available at https://github.com/wtma/TripleNet\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 00:45:32 GMT"}, {"version": "v2", "created": "Sun, 29 Sep 2019 06:31:38 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Ma", "Wentao", ""], ["Cui", "Yiming", ""], ["Shao", "Nan", ""], ["He", "Su", ""], ["Zhang", "Wei-Nan", ""], ["Liu", "Ting", ""], ["Wang", "Shijin", ""], ["Hu", "Guoping", ""]]}, {"id": "1909.10681", "submitter": "Peixiang Zhong", "authors": "Peixiang Zhong, Di Wang, Chunyan Miao", "title": "Knowledge-Enriched Transformer for Emotion Detection in Textual\n  Conversations", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Messages in human conversations inherently convey emotions. The task of\ndetecting emotions in textual conversations leads to a wide range of\napplications such as opinion mining in social networks. However, enabling\nmachines to analyze emotions in conversations is challenging, partly because\nhumans often rely on the context and commonsense knowledge to express emotions.\nIn this paper, we address these challenges by proposing a Knowledge-Enriched\nTransformer (KET), where contextual utterances are interpreted using\nhierarchical self-attention and external commonsense knowledge is dynamically\nleveraged using a context-aware affective graph attention mechanism.\nExperiments on multiple textual conversation datasets demonstrate that both\ncontext and commonsense knowledge are consistently beneficial to the emotion\ndetection performance. In addition, the experimental results show that our KET\nmodel outperforms the state-of-the-art models on most of the tested datasets in\nF1 score.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 02:08:29 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 14:00:22 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Zhong", "Peixiang", ""], ["Wang", "Di", ""], ["Miao", "Chunyan", ""]]}, {"id": "1909.10699", "submitter": "Allen Nie", "authors": "Allen Nie, Arturo L. Pineda, Matt W. Wright Hannah Wand, Bryan Wulf,\n  Helio A. Costa, Ronak Y. Patel, Carlos D. Bustamante, James Zou", "title": "LitGen: Genetic Literature Recommendation Guided by Human Explanations", "comments": "12 pages; 5 figures. Accepted by PSB 2020 (Pacific Symposium on\n  Biocomputing) track: Artificial Intelligence for Enhancing Clinical Medicine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As genetic sequencing costs decrease, the lack of clinical interpretation of\nvariants has become the bottleneck in using genetics data. A major rate\nlimiting step in clinical interpretation is the manual curation of evidence in\nthe genetic literature by highly trained biocurators. What makes curation\nparticularly time-consuming is that the curator needs to identify papers that\nstudy variant pathogenicity using different types of approaches and\nevidences---e.g. biochemical assays or case control analysis. In collaboration\nwith the Clinical Genomic Resource (ClinGen)---the flagship NIH program for\nclinical curation---we propose the first machine learning system, LitGen, that\ncan retrieve papers for a particular variant and filter them by specific\nevidence types used by curators to assess for pathogenicity. LitGen uses\nsemi-supervised deep learning to predict the type of evidence provided by each\npaper. It is trained on papers annotated by ClinGen curators and systematically\nevaluated on new test data collected by ClinGen. LitGen further leverages rich\nhuman explanations and unlabeled data to gain 7.9%-12.6% relative performance\nimprovement over models learned only on the annotated papers. It is a useful\nframework to improve clinical variant curation.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 03:56:48 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Nie", "Allen", ""], ["Pineda", "Arturo L.", ""], ["Wand", "Matt W. Wright Hannah", ""], ["Wulf", "Bryan", ""], ["Costa", "Helio A.", ""], ["Patel", "Ronak Y.", ""], ["Bustamante", "Carlos D.", ""], ["Zou", "James", ""]]}, {"id": "1909.10705", "submitter": "Abigail See", "authors": "Abigail See, Aneesh Pappu, Rohun Saxena, Akhila Yerukola, Christopher\n  D. Manning", "title": "Do Massively Pretrained Language Models Make Better Storytellers?", "comments": "Accepted to CoNLL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large neural language models trained on massive amounts of text have emerged\nas a formidable strategy for Natural Language Understanding tasks. However, the\nstrength of these models as Natural Language Generators is less clear. Though\nanecdotal evidence suggests that these models generate better quality text,\nthere has been no detailed study characterizing their generation abilities. In\nthis work, we compare the performance of an extensively pretrained model,\nOpenAI GPT2-117 (Radford et al., 2019), to a state-of-the-art neural story\ngeneration model (Fan et al., 2018). By evaluating the generated text across a\nwide variety of automatic metrics, we characterize the ways in which pretrained\nmodels do, and do not, make better storytellers. We find that although GPT2-117\nconditions more strongly on context, is more sensitive to ordering of events,\nand uses more unusual words, it is just as likely to produce repetitive and\nunder-diverse text when using likelihood-maximizing decoding algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 04:26:27 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["See", "Abigail", ""], ["Pappu", "Aneesh", ""], ["Saxena", "Rohun", ""], ["Yerukola", "Akhila", ""], ["Manning", "Christopher D.", ""]]}, {"id": "1909.10724", "submitter": "Lucy H. Lin", "authors": "Lucy H. Lin, Noah A. Smith", "title": "Situating Sentence Embedders with Nearest Neighbor Overlap", "comments": "17 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As distributed approaches to natural language semantics have developed and\ndiversified, embedders for linguistic units larger than words have come to play\nan increasingly important role. To date, such embedders have been evaluated\nusing benchmark tasks (e.g., GLUE) and linguistic probes. We propose a\ncomparative approach, nearest neighbor overlap (N2O), that quantifies\nsimilarity between embedders in a task-agnostic manner. N2O requires only a\ncollection of examples and is simple to understand: two embedders are more\nsimilar if, for the same set of inputs, there is greater overlap between the\ninputs' nearest neighbors. Though applicable to embedders of texts of any size,\nwe focus on sentence embedders and use N2O to show the effects of different\ndesign choices and architectures.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 06:03:35 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Lin", "Lucy H.", ""], ["Smith", "Noah A.", ""]]}, {"id": "1909.10743", "submitter": "Ting-Rui Chiang", "authors": "Ting-Rui Chiang, Hao-Tong Ye, Yun-Nung Chen", "title": "An Empirical Study of Content Understanding in Conversational Question\n  Answering", "comments": "Published at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With a lot of work about context-free question answering systems, there is an\nemerging trend of conversational question answering models in the natural\nlanguage processing field. Thanks to the recently collected datasets, including\nQuAC and CoQA, there has been more work on conversational question answering,\nand recent work has achieved competitive performance on both datasets. However,\nto best of our knowledge, two important questions for conversational\ncomprehension research have not been well studied: 1) How well can the\nbenchmark dataset reflect models' content understanding? 2) Do the models well\nutilize the conversation content when answering questions? To investigate these\nquestions, we design different training settings, testing settings, as well as\nan attack to verify the models' capability of content understanding on QuAC and\nCoQA. The experimental results indicate some potential hazards in the benchmark\ndatasets, QuAC and CoQA, for conversational comprehension research. Our\nanalysis also sheds light on both what models may learn and how datasets may\nbias the models. With deep investigation of the task, it is believed that this\nwork can benefit the future progress of conversation comprehension. The source\ncode is available at https://github.com/MiuLab/CQA-Study.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 07:36:45 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 09:49:46 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Chiang", "Ting-Rui", ""], ["Ye", "Hao-Tong", ""], ["Chen", "Yun-Nung", ""]]}, {"id": "1909.10772", "submitter": "Xuefeng Yang", "authors": "Ying Ju, Fubang Zhao, Shijie Chen, Bowen Zheng, Xuefeng Yang, Yunfeng\n  Liu", "title": "Technical report on Conversational Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational Question Answering is a challenging task since it requires\nunderstanding of conversational history. In this project, we propose a new\nsystem RoBERTa + AT +KD, which involves rationale tagging multi-task,\nadversarial training, knowledge distillation and a linguistic post-process\nstrategy. Our single model achieves 90.4(F1) on the CoQA test set without data\naugmentation, outperforming the current state-of-the-art single model by 2.6%\nF1.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 09:26:24 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Ju", "Ying", ""], ["Zhao", "Fubang", ""], ["Chen", "Shijie", ""], ["Zheng", "Bowen", ""], ["Yang", "Xuefeng", ""], ["Liu", "Yunfeng", ""]]}, {"id": "1909.10812", "submitter": "Kim Hammar", "authors": "Kim Hammar, Shatha Jaradat, Nima Dokoohaki and Mihhail Matskin", "title": "Deep Text Mining of Instagram Data Without Strong Supervision", "comments": "8 pages, 5 figures. Pre-print for paper to appear in conference\n  proceedings for the Web Intelligence Conference", "journal-ref": null, "doi": "10.1109/WI.2018.00-94", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of social media, our online feeds increasingly consist of\nshort, informal, and unstructured text. This textual data can be analyzed for\nthe purpose of improving user recommendations and detecting trends. Instagram\nis one of the largest social media platforms, containing both text and images.\nHowever, most of the prior research on text processing in social media is\nfocused on analyzing Twitter data, and little attention has been paid to text\nmining of Instagram data. Moreover, many text mining methods rely on annotated\ntraining data, which in practice is both difficult and expensive to obtain. In\nthis paper, we present methods for unsupervised mining of fashion attributes\nfrom Instagram text, which can enable a new kind of user recommendation in the\nfashion domain. In this context, we analyze a corpora of Instagram posts from\nthe fashion domain, introduce a system for extracting fashion attributes from\nInstagram, and train a deep clothing classifier with weak supervision to\nclassify Instagram posts based on the associated text.\n  With our experiments, we confirm that word embeddings are a useful asset for\ninformation extraction. Experimental results show that information extraction\nusing word embeddings outperforms a baseline that uses Levenshtein distance.\nThe results also show the benefit of combining weak supervision signals using\ngenerative models instead of majority voting. Using weak supervision and\ngenerative modeling, an F1 score of 0.61 is achieved on the task of classifying\nthe image contents of Instagram posts based solely on the associated text,\nwhich is on level with human performance. Finally, our empirical study provides\none of the few available studies on Instagram text and shows that the text is\nnoisy, that the text distribution exhibits the long-tail phenomenon, and that\ncomment sections on Instagram are multi-lingual.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 11:04:02 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Hammar", "Kim", ""], ["Jaradat", "Shatha", ""], ["Dokoohaki", "Nima", ""], ["Matskin", "Mihhail", ""]]}, {"id": "1909.10838", "submitter": "Thierry Deruyttere", "authors": "Thierry Deruyttere, Simon Vandenhende, Dusan Grujicic, Luc Van Gool\n  and Marie-Francine Moens", "title": "Talk2Car: Taking Control of Your Self-Driving Car", "comments": "14 pages, accepted at emnlp-ijcnlp 2019 - Added Talk2Nav Reference", "journal-ref": null, "doi": "10.18653/v1/D19-1215", "report-no": null, "categories": "cs.AI cs.CL cs.RO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A long-term goal of artificial intelligence is to have an agent execute\ncommands communicated through natural language. In many cases the commands are\ngrounded in a visual environment shared by the human who gives the command and\nthe agent. Execution of the command then requires mapping the command into the\nphysical visual space, after which the appropriate action can be taken. In this\npaper we consider the former. Or more specifically, we consider the problem in\nan autonomous driving setting, where a passenger requests an action that can be\nassociated with an object found in a street scene. Our work presents the\nTalk2Car dataset, which is the first object referral dataset that contains\ncommands written in natural language for self-driving cars. We provide a\ndetailed comparison with related datasets such as ReferIt, RefCOCO, RefCOCO+,\nRefCOCOg, Cityscape-Ref and CLEVR-Ref. Additionally, we include a performance\nanalysis using strong state-of-the-art models. The results show that the\nproposed object referral task is a challenging one for which the models show\npromising results but still require additional research in natural language\nprocessing, computer vision and the intersection of these fields. The dataset\ncan be found on our website: http://macchina-ai.eu/\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 12:29:27 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2020 06:27:52 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Deruyttere", "Thierry", ""], ["Vandenhende", "Simon", ""], ["Grujicic", "Dusan", ""], ["Van Gool", "Luc", ""], ["Moens", "Marie-Francine", ""]]}, {"id": "1909.10852", "submitter": "Wei Liu", "authors": "Lei Li, Wei Liu, Marina Litvak, Natalia Vanetik, Zuying Huang", "title": "In Conclusion Not Repetition: Comprehensive Abstractive Summarization\n  With Diversified Attention Based On Determinantal Point Processes", "comments": "11 pages, 7 figures, 4 tables", "journal-ref": null, "doi": "10.18653/v1/K19-1077", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various Seq2Seq learning models designed for machine translation were applied\nfor abstractive summarization task recently. Despite these models provide high\nROUGE scores, they are limited to generate comprehensive summaries with a high\nlevel of abstraction due to its degenerated attention distribution. We\nintroduce Diverse Convolutional Seq2Seq Model(DivCNN Seq2Seq) using\nDeterminantal Point Processes methods(Micro DPPs and Macro DPPs) to produce\nattention distribution considering both quality and diversity. Without breaking\nthe end to end architecture, DivCNN Seq2Seq achieves a higher level of\ncomprehensiveness compared to vanilla models and strong baselines. All the\nreproducible codes and datasets are available online.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 12:53:36 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 10:31:57 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Li", "Lei", ""], ["Liu", "Wei", ""], ["Litvak", "Marina", ""], ["Vanetik", "Natalia", ""], ["Huang", "Zuying", ""]]}, {"id": "1909.10861", "submitter": "Chao-Wei Huang", "authors": "Chao-Wei Huang and Yun-Nung Chen", "title": "Learning ASR-Robust Contextualized Embeddings for Spoken Language\n  Understanding", "comments": "ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Employing pre-trained language models (LM) to extract contextualized word\nrepresentations has achieved state-of-the-art performance on various NLP tasks.\nHowever, applying this technique to noisy transcripts generated by automatic\nspeech recognizer (ASR) is concerned. Therefore, this paper focuses on making\ncontextualized representations more ASR-robust. We propose a novel\nconfusion-aware fine-tuning method to mitigate the impact of ASR errors to\npre-trained LMs. Specifically, we fine-tune LMs to produce similar\nrepresentations for acoustically confusable words that are obtained from word\nconfusion networks (WCNs) produced by ASR. Experiments on the benchmark ATIS\ndataset show that the proposed method significantly improves the performance of\nspoken language understanding when performing on ASR transcripts. Our source\ncode is available at https://github.com/MiuLab/SpokenVec\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 13:06:43 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 06:59:49 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Huang", "Chao-Wei", ""], ["Chen", "Yun-Nung", ""]]}, {"id": "1909.10881", "submitter": "Amir Karami", "authors": "Amir Karami", "title": "Application of Fuzzy Clustering for Text Data Dimensionality Reduction", "comments": "arXiv admin note: text overlap with arXiv:1712.05997", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.AP stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large textual corpora are often represented by the document-term frequency\nmatrix whose elements are the frequency of terms; however, this matrix has two\nproblems: sparsity and high dimensionality. Four dimension reduction strategies\nare used to address these problems. Of the four strategies, unsupervised\nfeature transformation (UFT) is a popular and efficient strategy to map the\nterms to a new basis in the document-term frequency matrix. Although several\nUFT-based methods have been developed, fuzzy clustering has not been considered\nfor dimensionality reduction. This research explores fuzzy clustering as a new\nUFT-based approach to create a lower-dimensional representation of documents.\nPerformance of fuzzy clustering with and without using global term weighting\nmethods is shown to exceed principal component analysis and singular value\ndecomposition. This study also explores the effect of applying different\nfuzzifier values on fuzzy clustering for dimensionality reduction purpose.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 03:15:04 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Karami", "Amir", ""]]}, {"id": "1909.10892", "submitter": "Injy Hamed", "authors": "Injy Hamed, Moritz Zhu, Mohamed Elmahdy, Slim Abdennadher, Ngoc Thang\n  Vu", "title": "Code-switching Language Modeling With Bilingual Word Embeddings: A Case\n  Study for Egyptian Arabic-English", "comments": "11 pages, 1 figure (having 2 sub-figures), submitted to the 21st\n  International Conference on Speech and Computer (SPECOM'19),", "journal-ref": "Proceedings of the 21st International Conference on Speech and\n  Computer (SPECOM'19), Istanbul, Turkey, August 20-25, 2019\n  https://link.springer.com/book/10.1007/978-3-030-26061-3", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Code-switching (CS) is a widespread phenomenon among bilingual and\nmultilingual societies. The lack of CS resources hinders the performance of\nmany NLP tasks. In this work, we explore the potential use of bilingual word\nembeddings for code-switching (CS) language modeling (LM) in the low resource\nEgyptian Arabic-English language. We evaluate different state-of-the-art\nbilingual word embeddings approaches that require cross-lingual resources at\ndifferent levels and propose an innovative but simple approach that jointly\nlearns bilingual word representations without the use of any parallel data,\nrelying only on monolingual and a small amount of CS data. While all\nrepresentations improve CS LM, ours performs the best and improves perplexity\n33.5% relative over the baseline.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 13:27:30 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Hamed", "Injy", ""], ["Zhu", "Moritz", ""], ["Elmahdy", "Mohamed", ""], ["Abdennadher", "Slim", ""], ["Vu", "Ngoc Thang", ""]]}, {"id": "1909.10911", "submitter": "Robert Schwarzenberg", "authors": "Robert Schwarzenberg, Marc H\\\"ubner, David Harbecke, Christoph Alt,\n  Leonhard Hennig", "title": "Layerwise Relevance Visualization in Convolutional Text Graph\n  Classifiers", "comments": "Accepted at EMNLP 2019 Workshop on Graph-Based Natural Language\n  Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representations in the hidden layers of Deep Neural Networks (DNN) are often\nhard to interpret since it is difficult to project them into an interpretable\ndomain. Graph Convolutional Networks (GCN) allow this projection, but existing\nexplainability methods do not exploit this fact, i.e. do not focus their\nexplanations on intermediate states. In this work, we present a novel method\nthat traces and visualizes features that contribute to a classification\ndecision in the visible and hidden layers of a GCN. Our method exposes hidden\ncross-layer dynamics in the input graph structure. We experimentally\ndemonstrate that it yields meaningful layerwise explanations for a GCN sentence\nclassifier.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 13:37:02 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Schwarzenberg", "Robert", ""], ["H\u00fcbner", "Marc", ""], ["Harbecke", "David", ""], ["Alt", "Christoph", ""], ["Hennig", "Leonhard", ""]]}, {"id": "1909.10924", "submitter": "Pengwei Wang", "authors": "Pengwei Wang, Liangchen Wei, Yong Cao, Jinghui Xie, Yuji Cao, Zaiqing\n  Nie", "title": "Understanding Semantics from Speech Through Pre-training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end Spoken Language Understanding (SLU) is proposed to infer the\nsemantic meaning directly from audio features without intermediate text\nrepresentation. Although the acoustic model component of an end-to-end SLU\nsystem can be pre-trained with Automatic Speech Recognition (ASR) targets, the\nSLU component can only learn semantic features from limited task-specific\ntraining data. In this paper, for the first time we propose to do large-scale\nunsupervised pre-training for the SLU component of an end-to-end SLU system, so\nthat the SLU component may preserve semantic features from massive unlabeled\naudio data. As the output of the acoustic model component, i.e. phoneme\nposterior sequences, has much different characteristic from text sequences, we\npropose a novel pre-training model called BERT-PLM, which stands for\nBidirectional Encoder Representations from Transformers through Permutation\nLanguage Modeling. BERT-PLM trains the SLU component on unlabeled data through\na regression objective equivalent to the partial permutation language modeling\nobjective, while leverages full bi-directional context information with BERT\nnetworks. The experiment results show that our approach out-perform the\nstate-of-the-art end-to-end systems with over 12.5% error reduction.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 13:49:14 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Wang", "Pengwei", ""], ["Wei", "Liangchen", ""], ["Cao", "Yong", ""], ["Xie", "Jinghui", ""], ["Cao", "Yuji", ""], ["Nie", "Zaiqing", ""]]}, {"id": "1909.10955", "submitter": "Tom Kocmi", "authors": "Tom Kocmi and Ond\\v{r}ej Bojar", "title": "Efficiently Reusing Old Models Across Languages via Transfer Learning", "comments": "Accepted to EAMT 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in neural machine translation is directed towards larger\nneural networks trained on an increasing amount of hardware resources. As a\nresult, NMT models are costly to train, both financially, due to the\nelectricity and hardware cost, and environmentally, due to the carbon\nfootprint. It is especially true in transfer learning for its additional cost\nof training the \"parent\" model before transferring knowledge and training the\ndesired \"child\" model. In this paper, we propose a simple method of re-using an\nalready trained model for different language pairs where there is no need for\nmodifications in model architecture. Our approach does not need a separate\nparent model for each investigated language pair, as it is typical in NMT\ntransfer learning. To show the applicability of our method, we recycle a\nTransformer model trained by different researchers and use it to seed models\nfor different language pairs. We achieve better translation quality and shorter\nconvergence times than when training from random initialization.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 14:32:52 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 06:46:26 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Kocmi", "Tom", ""], ["Bojar", "Ond\u0159ej", ""]]}, {"id": "1909.11042", "submitter": "Jose Manuel Gomez-Perez", "authors": "Ronald Denaux and Jose Manuel Gomez-Perez", "title": "Assessing the Lexico-Semantic Relational Knowledge Captured by Word and\n  Concept Embeddings", "comments": "Accepted at the 10th International Conference on Knowledge Capture\n  (K-CAP 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning currently dominates the benchmarks for various NLP tasks and,\nat the basis of such systems, words are frequently represented as embeddings\n--vectors in a low dimensional space-- learned from large text corpora and\nvarious algorithms have been proposed to learn both word and concept\nembeddings. One of the claimed benefits of such embeddings is that they capture\nknowledge about semantic relations. Such embeddings are most often evaluated\nthrough tasks such as predicting human-rated similarity and analogy which only\ntest a few, often ill-defined, relations. In this paper, we propose a method\nfor (i) reliably generating word and concept pair datasets for a wide number of\nrelations by using a knowledge graph and (ii) evaluating to what extent\npre-trained embeddings capture those relations. We evaluate the approach\nagainst a proprietary and a public knowledge graph and analyze the results,\nshowing which lexico-semantic relational knowledge is captured by current\nembedding learning approaches.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 16:52:18 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Denaux", "Ronald", ""], ["Gomez-Perez", "Jose Manuel", ""]]}, {"id": "1909.11049", "submitter": "Amandla Mabona", "authors": "Amandla Mabona, Laura Rimell, Stephen Clark, Andreas Vlachos", "title": "Neural Generative Rhetorical Structure Parsing", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rhetorical structure trees have been shown to be useful for several\ndocument-level tasks including summarization and document classification.\nPrevious approaches to RST parsing have used discriminative models; however,\nthese are less sample efficient than generative models, and RST parsing\ndatasets are typically small. In this paper, we present the first generative\nmodel for RST parsing. Our model is a document-level RNN grammar (RNNG) with a\nbottom-up traversal order. We show that, for our parser's traversal order,\nprevious beam search algorithms for RNNGs have a left-branching bias which is\nill-suited for RST parsing. We develop a novel beam search algorithm that keeps\ntrack of both structure- and word-generating actions without exhibiting this\nbranching bias and results in absolute improvements of 6.8 and 2.9 on\nunlabelled and labelled F1 over previous algorithms. Overall, our generative\nmodel outperforms a discriminative model with the same features by 2.6 F1\npoints and achieves performance comparable to the state-of-the-art,\noutperforming all published parsers from a recent replication study that do not\nuse additional training data.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 17:02:32 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Mabona", "Amandla", ""], ["Rimell", "Laura", ""], ["Clark", "Stephen", ""], ["Vlachos", "Andreas", ""]]}, {"id": "1909.11060", "submitter": "Shane Steinert-Threlkeld", "authors": "Shane Steinert-Threlkeld", "title": "Paying Attention to Function Words", "comments": "Emergent Communication Workshop @ NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  All natural languages exhibit a distinction between content words (like nouns\nand adjectives) and function words (like determiners, auxiliaries,\nprepositions). Yet surprisingly little has been said about the emergence of\nthis universal architectural feature of natural languages. Why have human\nlanguages evolved to exhibit this division of labor between content and\nfunction words? How could such a distinction have emerged in the first place?\nThis paper takes steps towards answering these questions by showing how the\ndistinction can emerge through reinforcement learning in agents playing a\nsignaling game across contexts which contain multiple objects that possess\nmultiple perceptually salient gradable properties.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 17:18:48 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Steinert-Threlkeld", "Shane", ""]]}, {"id": "1909.11189", "submitter": "Thomas Haider", "authors": "Thomas N. Haider", "title": "Diachronic Topics in New High German Poetry", "comments": null, "journal-ref": "In Proceedings of the International Digital Humanities Conference\n  DH2019, Utrecht, Link: https://dev.clariah.nl/files/dh2019/boa/1031.html", "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Statistical topic models are increasingly and popularly used by Digital\nHumanities scholars to perform distant reading tasks on literary data. It\nallows us to estimate what people talk about. Especially Latent Dirichlet\nAllocation (LDA) has shown its usefulness, as it is unsupervised, robust, easy\nto use, scalable, and it offers interpretable results. In a preliminary study,\nwe apply LDA to a corpus of New High German poetry (textgrid, with 51k poems,\n8m token), and use the distribution of topics over documents for a\nclassification of poems into time periods and for authorship attribution.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 21:19:01 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Haider", "Thomas N.", ""]]}, {"id": "1909.11200", "submitter": "Yanpei Shi", "authors": "Yanpei Shi, Qiang Huang, Thomas Hain", "title": "Improving Noise Robustness In Speaker Identification Using A Two-Stage\n  Attention Model", "comments": "Submitted to Interspeech2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the use of deep neural networks has significantly boosted speaker\nrecognition performance, it is still challenging to separate speakers in poor\nacoustic environments. To improve robustness of speaker recognition system\nperformance in noise, a novel two-stage attention mechanism which can be used\nin existing architectures such as Time Delay Neural Networks (TDNNs) and\nConvolutional Neural Networks (CNNs) is proposed. Noise is known to often mask\nimportant information in both time and frequency domain. The proposed mechanism\nallows the models to concentrate on reliable time/frequency components of the\nsignal. The proposed approach is evaluated using the Voxceleb1 dataset, which\naims at assessment of speaker recognition in real world situations. In addition\nthree types of noise at different signal-noise-ratios (SNRs) were added for\nthis work. The proposed mechanism is compared with three strong baselines:\nX-vectors, Attentive X-vector, and Resnet-34. Results on both identification\nand verification tasks show that the two-stage attention mechanism consistently\nimproves upon these for all noise conditions.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 21:46:42 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 22:53:15 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Shi", "Yanpei", ""], ["Huang", "Qiang", ""], ["Hain", "Thomas", ""]]}, {"id": "1909.11218", "submitter": "Manaal Faruqui", "authors": "Shikhar Vashishth, Shyam Upadhyay, Gaurav Singh Tomar, Manaal Faruqui", "title": "Attention Interpretability Across NLP Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": "2019", "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The attention layer in a neural network model provides insights into the\nmodel's reasoning behind its prediction, which are usually criticized for being\nopaque. Recently, seemingly contradictory viewpoints have emerged about the\ninterpretability of attention weights (Jain & Wallace, 2019; Vig & Belinkov,\n2019). Amid such confusion arises the need to understand attention mechanism\nmore systematically. In this work, we attempt to fill this gap by giving a\ncomprehensive explanation which justifies both kinds of observations (i.e.,\nwhen is attention interpretable and when it is not). Through a series of\nexperiments on diverse NLP tasks, we validate our observations and reinforce\nour claim of interpretability of attention through manual evaluation.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 22:58:44 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Vashishth", "Shikhar", ""], ["Upadhyay", "Shyam", ""], ["Tomar", "Gaurav Singh", ""], ["Faruqui", "Manaal", ""]]}, {"id": "1909.11232", "submitter": "Al Amin Hosain", "authors": "Al Amin Hosain, Panneer Selvam Santhalingam, Parth Pathak, Jana\n  Kosecka and Huzefa Rangwala", "title": "Sign Language Recognition Analysis using Multimodal Data", "comments": "conference : IEEE DSAA, 2019, Washington DC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice-controlled personal and home assistants (such as the Amazon Echo and\nApple Siri) are becoming increasingly popular for a variety of applications.\nHowever, the benefits of these technologies are not readily accessible to Deaf\nor Hard-ofHearing (DHH) users. The objective of this study is to develop and\nevaluate a sign recognition system using multiple modalities that can be used\nby DHH signers to interact with voice-controlled devices. With the advancement\nof depth sensors, skeletal data is used for applications like video analysis\nand activity recognition. Despite having similarity with the well-studied human\nactivity recognition, the use of 3D skeleton data in sign language recognition\nis rare. This is because unlike activity recognition, sign language is mostly\ndependent on hand shape pattern. In this work, we investigate the feasibility\nof using skeletal and RGB video data for sign language recognition using a\ncombination of different deep learning architectures. We validate our results\non a large-scale American Sign Language (ASL) dataset of 12 users and 13107\nsamples across 51 signs. It is named as GMUASL51. We collected the dataset over\n6 months and it will be publicly released in the hope of spurring further\nmachine learning research towards providing improved accessibility for digital\nassistants.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 23:44:49 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Hosain", "Al Amin", ""], ["Santhalingam", "Panneer Selvam", ""], ["Pathak", "Parth", ""], ["Kosecka", "Jana", ""], ["Rangwala", "Huzefa", ""]]}, {"id": "1909.11241", "submitter": "Franco M. Luque", "authors": "Franco M. Luque", "title": "Atalaya at TASS 2019: Data Augmentation and Robust Embeddings for\n  Sentiment Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this article we describe our participation in TASS 2019, a shared task\naimed at the detection of sentiment polarity of Spanish tweets. We combined\ndifferent representations such as bag-of-words, bag-of-characters, and tweet\nembeddings. In particular, we trained robust subword-aware word embeddings and\ncomputed tweet representations using a weighted-averaging strategy. We also\nused two data augmentation techniques to deal with data scarcity: two-way\ntranslation augmentation, and instance crossover augmentation, a novel\ntechnique that generates new instances by combining halves of tweets. In\nexperiments, we trained linear classifiers and ensemble models, obtaining\nhighly competitive results despite the simplicity of our approaches.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 00:28:50 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Luque", "Franco M.", ""]]}, {"id": "1909.11258", "submitter": "Omer Anjum", "authors": "Omer Anjum, Hongyu Gong, Suma Bhat, Wen-Mei Hwu, Jinjun Xiong", "title": "PaRe: A Paper-Reviewer Matching Approach Using a Common Topic Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding the right reviewers to assess the quality of conference submissions\nis a time consuming process for conference organizers. Given the importance of\nthis step, various automated reviewer-paper matching solutions have been\nproposed to alleviate the burden. Prior approaches, including bag-of-words\nmodels and probabilistic topic models have been inadequate to deal with the\nvocabulary mismatch and partial topic overlap between a paper submission and\nthe reviewer's expertise. Our approach, the common topic model, jointly models\nthe topics common to the submission and the reviewer's profile while relying on\nabstract topic vectors. Experiments and insightful evaluations on two datasets\ndemonstrate that the proposed method achieves consistent improvements compared\nto available state-of-the-art implementations of paper-reviewer matching.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 02:25:23 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Anjum", "Omer", ""], ["Gong", "Hongyu", ""], ["Bhat", "Suma", ""], ["Hwu", "Wen-Mei", ""], ["Xiong", "Jinjun", ""]]}, {"id": "1909.11272", "submitter": "Zijian Wang", "authors": "Zijian Wang and Christopher Potts", "title": "TalkDown: A Corpus for Condescension Detection in Context", "comments": "To appear at EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Condescending language use is caustic; it can bring dialogues to an end and\nbifurcate communities. Thus, systems for condescension detection could have a\nlarge positive impact. A challenge here is that condescension is often\nimpossible to detect from isolated utterances, as it depends on the discourse\nand social context. To address this, we present TalkDown, a new labeled dataset\nof condescending linguistic acts in context. We show that extending a\nlanguage-only model with representations of the discourse improves performance,\nand we motivate techniques for dealing with the low rates of condescension\noverall. We also use our model to estimate condescension rates in various\nonline communities and relate these differences to differing community norms.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 03:39:00 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Wang", "Zijian", ""], ["Potts", "Christopher", ""]]}, {"id": "1909.11287", "submitter": "Zehao Lin", "authors": "Zehao Lin, Xinjing Huang, Feng Ji, Haiqing Chen, Ying Zhang", "title": "Task-Oriented Conversation Generation Using Heterogeneous Memory\n  Networks", "comments": "Accepted as a long paper at EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to incorporate external knowledge into a neural dialogue model is\ncritically important for dialogue systems to behave like real humans. To handle\nthis problem, memory networks are usually a great choice and a promising way.\nHowever, existing memory networks do not perform well when leveraging\nheterogeneous information from different sources. In this paper, we propose a\nnovel and versatile external memory networks called Heterogeneous Memory\nNetworks (HMNs), to simultaneously utilize user utterances, dialogue history\nand background knowledge tuples. In our method, historical sequential dialogues\nare encoded and stored into the context-aware memory enhanced by gating\nmechanism while grounding knowledge tuples are encoded and stored into the\ncontext-free memory. During decoding, the decoder augmented with HMNs\nrecurrently selects each word in one response utterance from these two memories\nand a general vocabulary. Experimental results on multiple real-world datasets\nshow that HMNs significantly outperform the state-of-the-art data-driven\ntask-oriented dialogue models in most domains.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 04:40:27 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Lin", "Zehao", ""], ["Huang", "Xinjing", ""], ["Ji", "Feng", ""], ["Chen", "Haiqing", ""], ["Zhang", "Ying", ""]]}, {"id": "1909.11288", "submitter": "Nway Han Nway", "authors": "Nway Nway Han, Aye Thida", "title": "Annotated Guidelines and Building Reference Corpus for Myanmar-English\n  Word Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reference corpus for word alignment is an important resource for developing\nand evaluating word alignment methods. For Myanmar-English language pairs,\nthere is no reference corpus to evaluate the word alignment tasks. Therefore,\nwe created the guidelines for Myanmar-English word alignment annotation between\ntwo languages over contrastive learning and built the Myanmar-English reference\ncorpus consisting of verified alignments from Myanmar ALT of the Asian Language\nTreebank (ALT). This reference corpus contains confident labels sure (S) and\npossible (P) for word alignments which are used to test for the purpose of\nevaluation of the word alignments tasks. We discuss the most linking\nambiguities to define consistent and systematic instructions to align manual\nwords. We evaluated the results of annotators agreement using our reference\ncorpus in terms of alignment error rate (AER) in word alignment tasks and\ndiscuss the words relationships in terms of BLEU scores.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 04:47:49 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Han", "Nway Nway", ""], ["Thida", "Aye", ""]]}, {"id": "1909.11291", "submitter": "Matt Gardner", "authors": "Matt Gardner, Jonathan Berant, Hannaneh Hajishirzi, Alon Talmor, and\n  Sewon Min", "title": "Question Answering is a Format; When is it Useful?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent years have seen a dramatic expansion of tasks and datasets posed as\nquestion answering, from reading comprehension, semantic role labeling, and\neven machine translation, to image and video understanding. With this\nexpansion, there are many differing views on the utility and definition of\n\"question answering\" itself. Some argue that its scope should be narrow, or\nbroad, or that it is overused in datasets today. In this opinion piece, we\nargue that question answering should be considered a format which is sometimes\nuseful for studying particular phenomena, not a phenomenon or task in itself.\nWe discuss when a task is correctly described as question answering, and when a\ntask is usefully posed as question answering, instead of using some other\nformat.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 05:16:15 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Gardner", "Matt", ""], ["Berant", "Jonathan", ""], ["Hajishirzi", "Hannaneh", ""], ["Talmor", "Alon", ""], ["Min", "Sewon", ""]]}, {"id": "1909.11297", "submitter": "Shiwan Zhao Mr", "authors": "Mengting Hu, Shiwan Zhao, Honglei Guo, Renhong Cheng, Zhong Su", "title": "Learning to Detect Opinion Snippet for Aspect-Based Sentiment Analysis", "comments": "Accepted by CoNLL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect-based sentiment analysis (ABSA) is to predict the sentiment polarity\ntowards a particular aspect in a sentence. Recently, this task has been widely\naddressed by the neural attention mechanism, which computes attention weights\nto softly select words for generating aspect-specific sentence representations.\nThe attention is expected to concentrate on opinion words for accurate\nsentiment prediction. However, attention is prone to be distracted by noisy or\nmisleading words, or opinion words from other aspects. In this paper, we\npropose an alternative hard-selection approach, which determines the start and\nend positions of the opinion snippet, and selects the words between these two\npositions for sentiment prediction. Specifically, we learn deep associations\nbetween the sentence and aspect, and the long-term dependencies within the\nsentence by leveraging the pre-trained BERT model. We further detect the\nopinion snippet by self-critical reinforcement learning. Especially,\nexperimental results demonstrate the effectiveness of our method and prove that\nour hard-selection approach outperforms soft-selection approaches when handling\nmulti-aspect sentences.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 05:43:28 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Hu", "Mengting", ""], ["Zhao", "Shiwan", ""], ["Guo", "Honglei", ""], ["Cheng", "Renhong", ""], ["Su", "Zhong", ""]]}, {"id": "1909.11359", "submitter": "Zihao Wang", "authors": "Zihao Wang, Kwun Ping Lai, Piji Li, Lidong Bing, Wai Lam", "title": "Tackling Long-Tailed Relations and Uncommon Entities in Knowledge Graph\n  Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For large-scale knowledge graphs (KGs), recent research has been focusing on\nthe large proportion of infrequent relations which have been ignored by\nprevious studies. For example few-shot learning paradigm for relations has been\ninvestigated. In this work, we further advocate that handling uncommon entities\nis inevitable when dealing with infrequent relations. Therefore, we propose a\nmeta-learning framework that aims at handling infrequent relations with\nfew-shot learning and uncommon entities by using textual descriptions. We\ndesign a novel model to better extract key information from textual\ndescriptions. Besides, we also develop a novel generative model in our\nframework to enhance the performance by generating extra triplets during the\ntraining stage. Experiments are conducted on two datasets from real-world KGs,\nand the results show that our framework outperforms previous methods when\ndealing with infrequent relations and their accompanying uncommon entities.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 09:20:39 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Wang", "Zihao", ""], ["Lai", "Kwun Ping", ""], ["Li", "Piji", ""], ["Bing", "Lidong", ""], ["Lam", "Wai", ""]]}, {"id": "1909.11386", "submitter": "Diego Antognini", "authors": "Diego Antognini, Claudiu Musat, Boi Faltings", "title": "Multi-Dimensional Explanation of Target Variables from Documents", "comments": "Accepted in AAAI 2021. 18 pages, 14 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated predictions require explanations to be interpretable by humans.\nPast work used attention and rationale mechanisms to find words that predict\nthe target variable of a document. Often though, they result in a tradeoff\nbetween noisy explanations or a drop in accuracy. Furthermore, rationale\nmethods cannot capture the multi-faceted nature of justifications for multiple\ntargets, because of the non-probabilistic nature of the mask. In this paper, we\npropose the Multi-Target Masker (MTM) to address these shortcomings. The\nnovelty lies in the soft multi-dimensional mask that models a relevance\nprobability distribution over the set of target variables to handle\nambiguities. Additionally, two regularizers guide MTM to induce long,\nmeaningful explanations. We evaluate MTM on two datasets and show, using\nstandard metrics and human annotations, that the resulting masks are more\naccurate and coherent than those generated by the state-of-the-art methods.\nMoreover, MTM is the first to also achieve the highest F1 scores for all the\ntarget variables simultaneously.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 10:26:36 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 14:49:03 GMT"}, {"version": "v3", "created": "Tue, 29 Sep 2020 13:52:27 GMT"}, {"version": "v4", "created": "Mon, 21 Dec 2020 08:18:43 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Antognini", "Diego", ""], ["Musat", "Claudiu", ""], ["Faltings", "Boi", ""]]}, {"id": "1909.11430", "submitter": "Qiao Cheng", "authors": "Qiao Cheng, Meiyuan Fang, Yaqian Han, Jin Huang, Yitao Duan", "title": "Breaking the Data Barrier: Towards Robust Speech Translation via\n  Adversarial Stability Training", "comments": "Accepted at the 16th International Workshop on Spoken Language\n  Translation (IWSLT 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a pipeline speech translation system, automatic speech recognition (ASR)\nsystem will transmit errors in recognition to the downstream machine\ntranslation (MT) system. A standard machine translation system is usually\ntrained on parallel corpus composed of clean text and will perform poorly on\ntext with recognition noise, a gap well known in speech translation community.\nIn this paper, we propose a training architecture which aims at making a neural\nmachine translation model more robust against speech recognition errors. Our\napproach addresses the encoder and the decoder simultaneously using adversarial\nlearning and data augmentation, respectively. Experimental results on IWSLT2018\nspeech translation task show that our approach can bridge the gap between the\nASR output and the MT input, outperforms the baseline by up to 2.83 BLEU on\nnoisy ASR output, while maintaining close performance on clean text.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 12:13:43 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 10:33:45 GMT"}, {"version": "v3", "created": "Mon, 28 Oct 2019 11:16:53 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Cheng", "Qiao", ""], ["Fang", "Meiyuan", ""], ["Han", "Yaqian", ""], ["Huang", "Jin", ""], ["Duan", "Yitao", ""]]}, {"id": "1909.11467", "submitter": "Hossein Hassani", "authors": "Roshna Omer Abdulrahman, Hossein Hassani, Sina Ahmadi", "title": "Developing a Fine-Grained Corpus for a Less-resourced Language: the case\n  of Kurdish", "comments": "4 pages, 1 table, 1 figure", "journal-ref": "In Proceedings of the 2019 Workshop on Widening NLP (pp. 106-109),\n  August 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kurdish is a less-resourced language consisting of different dialects written\nin various scripts. Approximately 30 million people in different countries\nspeak the language. The lack of corpora is one of the main obstacles in Kurdish\nlanguage processing. In this paper, we present KTC-the Kurdish Textbooks\nCorpus, which is composed of 31 K-12 textbooks in Sorani dialect. The corpus is\nnormalized and categorized into 12 educational subjects containing 693,800\ntokens (110,297 types). Our resource is publicly available for non-commercial\nuse under the CC BY-NC-SA 4.0 license.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 13:10:15 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Abdulrahman", "Roshna Omer", ""], ["Hassani", "Hossein", ""], ["Ahmadi", "Sina", ""]]}, {"id": "1909.11493", "submitter": "Zhenxin Fu", "authors": "Mingyue Shang, Piji Li, Zhenxin Fu, Lidong Bing, Dongyan Zhao, Shuming\n  Shi, Rui Yan", "title": "Semi-supervised Text Style Transfer: Cross Projection in Latent Space", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text style transfer task requires the model to transfer a sentence of one\nstyle to another style while retaining its original content meaning, which is a\nchallenging problem that has long suffered from the shortage of parallel data.\nIn this paper, we first propose a semi-supervised text style transfer model\nthat combines the small-scale parallel data with the large-scale nonparallel\ndata. With these two types of training data, we introduce a projection function\nbetween the latent space of different styles and design two constraints to\ntrain it. We also introduce two other simple but effective semi-supervised\nmethods to compare with. To evaluate the performance of the proposed methods,\nwe build and release a novel style transfer dataset that alters sentences\nbetween the style of ancient Chinese poem and the modern Chinese.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 13:46:29 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Shang", "Mingyue", ""], ["Li", "Piji", ""], ["Fu", "Zhenxin", ""], ["Bing", "Lidong", ""], ["Zhao", "Dongyan", ""], ["Shi", "Shuming", ""], ["Yan", "Rui", ""]]}, {"id": "1909.11535", "submitter": "Xiao Huang", "authors": "Xiao Huang, Li Dong, Elizabeth Boschee, Nanyun Peng", "title": "Learning A Unified Named Entity Tagger From Multiple Partially Annotated\n  Corpora For Efficient Adaptation", "comments": "9 pages of main content + 4 pages of references and appendix. 4\n  figures and 2 tables in the main content. Accepted by CoNLL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named entity recognition (NER) identifies typed entity mentions in raw text.\nWhile the task is well-established, there is no universally used tagset: often,\ndatasets are annotated for use in downstream applications and accordingly only\ncover a small set of entity types relevant to a particular task. For instance,\nin the biomedical domain, one corpus might annotate genes, another chemicals,\nand another diseases---despite the texts in each corpus containing references\nto all three types of entities. In this paper, we propose a deep structured\nmodel to integrate these \"partially annotated\" datasets to jointly identify all\nentity types appearing in the training corpora. By leveraging multiple\ndatasets, the model can learn robust input representations; by building a joint\nstructured model, it avoids potential conflicts caused by combining several\nmodels' predictions at test time. Experiments show that the proposed model\nsignificantly outperforms strong multi-task learning baselines when training on\nmultiple, partially annotated datasets and testing on datasets that contain\ntags from more than one of the training corpora.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 14:53:57 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 23:10:55 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Huang", "Xiao", ""], ["Dong", "Li", ""], ["Boschee", "Elizabeth", ""], ["Peng", "Nanyun", ""]]}, {"id": "1909.11556", "submitter": "Angela Fan", "authors": "Angela Fan, Edouard Grave, Armand Joulin", "title": "Reducing Transformer Depth on Demand with Structured Dropout", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overparameterized transformer networks have obtained state of the art results\nin various natural language processing tasks, such as machine translation,\nlanguage modeling, and question answering. These models contain hundreds of\nmillions of parameters, necessitating a large amount of computation and making\nthem prone to overfitting. In this work, we explore LayerDrop, a form of\nstructured dropout, which has a regularization effect during training and\nallows for efficient pruning at inference time. In particular, we show that it\nis possible to select sub-networks of any depth from one large network without\nhaving to finetune them and with limited impact on performance. We demonstrate\nthe effectiveness of our approach by improving the state of the art on machine\ntranslation, language modeling, summarization, question answering, and language\nunderstanding benchmarks. Moreover, we show that our approach leads to small\nBERT-like models of higher quality compared to training from scratch or using\ndistillation.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 15:35:03 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Fan", "Angela", ""], ["Grave", "Edouard", ""], ["Joulin", "Armand", ""]]}, {"id": "1909.11687", "submitter": "Raghav Gupta", "authors": "Sanqiang Zhao, Raghav Gupta, Yang Song, Denny Zhou", "title": "Extremely Small BERT Models from Mixed-Vocabulary Training", "comments": "To appear at EACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Pretrained language models like BERT have achieved good results on NLP tasks,\nbut are impractical on resource-limited devices due to memory footprint. A\nlarge fraction of this footprint comes from the input embeddings with large\ninput vocabulary and embedding dimensions. Existing knowledge distillation\nmethods used for model compression cannot be directly applied to train student\nmodels with reduced vocabulary sizes. To this end, we propose a distillation\nmethod to align the teacher and student embeddings via mixed-vocabulary\ntraining. Our method compresses BERT-LARGE to a task-agnostic model with\nsmaller vocabulary and hidden dimensions, which is an order of magnitude\nsmaller than other distilled BERT models and offers a better size-accuracy\ntrade-off on language understanding benchmarks as well as a practical dialogue\ntask.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 18:07:35 GMT"}, {"version": "v2", "created": "Sat, 6 Feb 2021 04:34:27 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Zhao", "Sanqiang", ""], ["Gupta", "Raghav", ""], ["Song", "Yang", ""], ["Zhou", "Denny", ""]]}, {"id": "1909.11699", "submitter": "Andrew Rosenberg", "authors": "Andrew Rosenberg, Yu Zhang, Bhuvana Ramabhadran, Ye Jia, Pedro Moreno,\n  Yonghui Wu, Zelin Wu", "title": "Speech Recognition with Augmented Synthesized Speech", "comments": "Accepted for publication at ASRU 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent success of the Tacotron speech synthesis architecture and its variants\nin producing natural sounding multi-speaker synthesized speech has raised the\nexciting possibility of replacing expensive, manually transcribed,\ndomain-specific, human speech that is used to train speech recognizers. The\nmulti-speaker speech synthesis architecture can learn latent embedding spaces\nof prosody, speaker and style variations derived from input acoustic\nrepresentations thereby allowing for manipulation of the synthesized speech. In\nthis paper, we evaluate the feasibility of enhancing speech recognition\nperformance using speech synthesis using two corpora from different domains. We\nexplore algorithms to provide the necessary acoustic and lexical diversity\nneeded for robust speech recognition. Finally, we demonstrate the feasibility\nof this approach as a data augmentation strategy for domain-transfer.\n  We find that improvements to speech recognition performance is achievable by\naugmenting training data with synthesized material. However, there remains a\nsubstantial gap in performance between recognizers trained on human speech\nthose trained on synthesized speech.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 18:32:50 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Rosenberg", "Andrew", ""], ["Zhang", "Yu", ""], ["Ramabhadran", "Bhuvana", ""], ["Jia", "Ye", ""], ["Moreno", "Pedro", ""], ["Wu", "Yonghui", ""], ["Wu", "Zelin", ""]]}, {"id": "1909.11706", "submitter": "Minjun Kim", "authors": "Minjun Kim and Hiroki Sayama", "title": "The Power of Communities: A Text Classification Model with Automated\n  Labeling Process Using Network Community Detection", "comments": "13 pages, 5 figures, 1 table. Accepted by NetSci-X 2020 Tokyo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text classification is one of the most critical areas in machine learning and\nartificial intelligence research. It has been actively adopted in many business\napplications such as conversational intelligence systems, news articles\ncategorizations, sentiment analysis, emotion detection systems, and many other\nrecommendation systems in our daily life. One of the problems in supervised\ntext classification models is that the models' performance depends heavily on\nthe quality of data labeling that is typically done by humans. In this study,\nwe propose a new network community detection-based approach to automatically\nlabel and classify text data into multiclass value spaces. Specifically, we\nbuild networks with sentences as the network nodes and pairwise cosine\nsimilarities between the Term Frequency-Inversed Document Frequency (TFIDF)\nvector representations of the sentences as the network link weights. We use the\nLouvain method to detect the communities in the sentence networks. We train and\ntest the Support Vector Machine and the Random Forest models on both the\nhuman-labeled data and network community detection labeled data. Results showed\nthat models with the data labeled by the network community detection\noutperformed the models with the human-labeled data by 2.68-3.75% of\nclassification accuracy. Our method may help developments of more accurate\nconversational intelligence and other text classification systems.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 18:43:22 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 03:18:20 GMT"}, {"version": "v3", "created": "Thu, 14 Nov 2019 16:41:43 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Kim", "Minjun", ""], ["Sayama", "Hiroki", ""]]}, {"id": "1909.11740", "submitter": "Yen-Chun Chen", "authors": "Yen-Chun Chen, Linjie Li, Licheng Yu, Ahmed El Kholy, Faisal Ahmed,\n  Zhe Gan, Yu Cheng, Jingjing Liu", "title": "UNITER: UNiversal Image-TExt Representation Learning", "comments": "ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Joint image-text embedding is the bedrock for most Vision-and-Language (V+L)\ntasks, where multimodality inputs are simultaneously processed for joint visual\nand textual understanding. In this paper, we introduce UNITER, a UNiversal\nImage-TExt Representation, learned through large-scale pre-training over four\nimage-text datasets (COCO, Visual Genome, Conceptual Captions, and SBU\nCaptions), which can power heterogeneous downstream V+L tasks with joint\nmultimodal embeddings. We design four pre-training tasks: Masked Language\nModeling (MLM), Masked Region Modeling (MRM, with three variants), Image-Text\nMatching (ITM), and Word-Region Alignment (WRA). Different from previous work\nthat applies joint random masking to both modalities, we use conditional\nmasking on pre-training tasks (i.e., masked language/region modeling is\nconditioned on full observation of image/text). In addition to ITM for global\nimage-text alignment, we also propose WRA via the use of Optimal Transport (OT)\nto explicitly encourage fine-grained alignment between words and image regions\nduring pre-training. Comprehensive analysis shows that both conditional masking\nand OT-based WRA contribute to better pre-training. We also conduct a thorough\nablation study to find an optimal combination of pre-training tasks. Extensive\nexperiments show that UNITER achieves new state of the art across six V+L tasks\n(over nine datasets), including Visual Question Answering, Image-Text\nRetrieval, Referring Expression Comprehension, Visual Commonsense Reasoning,\nVisual Entailment, and NLVR$^2$. Code is available at\nhttps://github.com/ChenRocks/UNITER.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 20:02:54 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 05:03:12 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2020 22:19:59 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Chen", "Yen-Chun", ""], ["Li", "Linjie", ""], ["Yu", "Licheng", ""], ["Kholy", "Ahmed El", ""], ["Ahmed", "Faisal", ""], ["Gan", "Zhe", ""], ["Cheng", "Yu", ""], ["Liu", "Jingjing", ""]]}, {"id": "1909.11764", "submitter": "Chen Zhu", "authors": "Chen Zhu, Yu Cheng, Zhe Gan, Siqi Sun, Tom Goldstein, Jingjing Liu", "title": "FreeLB: Enhanced Adversarial Training for Natural Language Understanding", "comments": "Adding results with ALBERT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training, which minimizes the maximal risk for label-preserving\ninput perturbations, has proved to be effective for improving the\ngeneralization of language models. In this work, we propose a novel adversarial\ntraining algorithm, FreeLB, that promotes higher invariance in the embedding\nspace, by adding adversarial perturbations to word embeddings and minimizing\nthe resultant adversarial risk inside different regions around input samples.\nTo validate the effectiveness of the proposed approach, we apply it to\nTransformer-based models for natural language understanding and commonsense\nreasoning tasks. Experiments on the GLUE benchmark show that when applied only\nto the finetuning stage, it is able to improve the overall test scores of\nBERT-base model from 78.3 to 79.4, and RoBERTa-large model from 88.5 to 88.8.\nIn addition, the proposed approach achieves state-of-the-art single-model test\naccuracies of 85.44\\% and 67.75\\% on ARC-Easy and ARC-Challenge. Experiments on\nCommonsenseQA benchmark further demonstrate that FreeLB can be generalized and\nboost the performance of RoBERTa-large model on other tasks as well. Code is\navailable at \\url{https://github.com/zhuchen03/FreeLB .\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 20:50:32 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 18:53:21 GMT"}, {"version": "v3", "created": "Sat, 5 Oct 2019 04:05:46 GMT"}, {"version": "v4", "created": "Wed, 19 Feb 2020 01:57:24 GMT"}, {"version": "v5", "created": "Thu, 23 Apr 2020 07:19:00 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Zhu", "Chen", ""], ["Cheng", "Yu", ""], ["Gan", "Zhe", ""], ["Sun", "Siqi", ""], ["Goldstein", "Tom", ""], ["Liu", "Jingjing", ""]]}, {"id": "1909.11824", "submitter": "Jianming Zheng", "authors": "Jianming Zheng, Fei Cai, Honghui Chen, Maarten de Rijke", "title": "Pre-train, Interact, Fine-tune: A Novel Interaction Representation for\n  Text Classification", "comments": "32 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text representation can aid machines in understanding text. Previous work on\ntext representation often focuses on the so-called forward implication, i.e.,\npreceding words are taken as the context of later words for creating\nrepresentations, thus ignoring the fact that the semantics of a text segment is\na product of the mutual implication of words in the text: later words\ncontribute to the meaning of preceding words. We introduce the concept of\ninteraction and propose a two-perspective interaction representation, that\nencapsulates a local and a global interaction representation. Here, a local\ninteraction representation is one that interacts among words with\nparent-children relationships on the syntactic trees and a global interaction\ninterpretation is one that interacts among all the words in a sentence. We\ncombine the two interaction representations to develop a Hybrid Interaction\nRepresentation (HIR).\n  Inspired by existing feature-based and fine-tuning-based pretrain-finetuning\napproaches to language models, we integrate the advantages of feature-based and\nfine-tuning-based methods to propose the Pre-train, Interact, Fine-tune (PIF)\narchitecture.\n  We evaluate our proposed models on five widely-used datasets for text\nclassification tasks. Our ensemble method, outperforms state-of-the-art\nbaselines with improvements ranging from 2.03% to 3.15% in terms of error rate.\nIn addition, we find that, the improvements of PIF against most\nstate-of-the-art methods is not affected by increasing of the length of the\ntext.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 00:14:22 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Zheng", "Jianming", ""], ["Cai", "Fei", ""], ["Chen", "Honghui", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1909.11833", "submitter": "Chenguang Zhu", "authors": "Chenguang Zhu, Michael Zeng, Xuedong Huang", "title": "SIM: A Slot-Independent Neural Model for Dialogue State Tracking", "comments": "6 pages, 1 figure", "journal-ref": "SIGDial 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue state tracking is an important component in task-oriented dialogue\nsystems to identify users' goals and requests as a dialogue proceeds. However,\nas most previous models are dependent on dialogue slots, the model complexity\nsoars when the number of slots increases. In this paper, we put forward a\nslot-independent neural model (SIM) to track dialogue states while keeping the\nmodel complexity invariant to the number of dialogue slots. The model utilizes\nattention mechanisms between user utterance and system actions. SIM achieves\nstate-of-the-art results on WoZ and DSTC2 tasks, with only 20% of the model\nsize of previous models.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 00:51:58 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Zhu", "Chenguang", ""], ["Zeng", "Michael", ""], ["Huang", "Xuedong", ""]]}, {"id": "1909.11861", "submitter": "Jiwei Li", "authors": "Yuxian Meng, Xiangyuan Ren, Zijun Sun, Xiaoya Li, Arianna Yuan, Fei\n  Wu, Jiwei Li", "title": "Large-scale Pretraining for Neural Machine Translation with Tens of\n  Billions of Sentence Pairs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the problem of training neural machine\ntranslation (NMT) systems with a dataset of more than 40 billion bilingual\nsentence pairs, which is larger than the largest dataset to date by orders of\nmagnitude. Unprecedented challenges emerge in this situation compared to\nprevious NMT work, including severe noise in the data and prohibitively long\ntraining time. We propose practical solutions to handle these issues and\ndemonstrate that large-scale pretraining significantly improves NMT\nperformance. We are able to push the BLEU score of WMT17 Chinese-English\ndataset to 32.3, with a significant performance boost of +3.2 over existing\nstate-of-the-art results.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 03:06:47 GMT"}, {"version": "v2", "created": "Sat, 28 Sep 2019 18:57:37 GMT"}, {"version": "v3", "created": "Sun, 6 Oct 2019 04:01:39 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Meng", "Yuxian", ""], ["Ren", "Xiangyuan", ""], ["Sun", "Zijun", ""], ["Li", "Xiaoya", ""], ["Yuan", "Arianna", ""], ["Wu", "Fei", ""], ["Li", "Jiwei", ""]]}, {"id": "1909.11879", "submitter": "Ali Septiandri", "authors": "Yosef Ardhito Winatmoko, Ali Akbar Septiandri, Arie Pratama Sutiono", "title": "Aspect and Opinion Term Extraction for Hotel Reviews using Transfer\n  Learning and Auxiliary Labels", "comments": "Updated from (Septiandri & Sutiono, 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect and opinion term extraction is a critical step in Aspect-Based\nSentiment Analysis (ABSA). Our study focuses on evaluating transfer learning\nusing pre-trained BERT (Devlin et al., 2018) to classify tokens from hotel\nreviews in bahasa Indonesia. The primary challenge is the language informality\nof the review texts. By utilizing transfer learning from a multilingual model,\nwe achieved up to 2% difference on token level F1-score compared to the\nstate-of-the-art Bi-LSTM model with fewer training epochs (3 vs. 200 epochs).\nThe fine-tuned model clearly outperforms the Bi-LSTM model on the entity level.\nFurthermore, we propose a method to include CRF with auxiliary labels as an\noutput layer for the BERT-based models. The CRF addition further improves the\nF1-score for both token and entity level.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 04:17:48 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 11:02:03 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2020 07:09:56 GMT"}, {"version": "v4", "created": "Fri, 28 Feb 2020 04:33:04 GMT"}, {"version": "v5", "created": "Thu, 1 Oct 2020 10:14:02 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Winatmoko", "Yosef Ardhito", ""], ["Septiandri", "Ali Akbar", ""], ["Sutiono", "Arie Pratama", ""]]}, {"id": "1909.11886", "submitter": "Youngmoon Jung", "authors": "Youngmoon Jung, Yeunju Choi, Hoirin Kim", "title": "Self-Adaptive Soft Voice Activity Detection using Deep Neural Networks\n  for Robust Speaker Verification", "comments": "Accepted at 2019 IEEE Automatic Speech Recognition and Understanding\n  Workshop (ASRU 2019)", "journal-ref": "Proc. of ASRU 2019, pp. 365-372", "doi": "10.1109/ASRU46091.2019.9003935", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice activity detection (VAD), which classifies frames as speech or\nnon-speech, is an important module in many speech applications including\nspeaker verification. In this paper, we propose a novel method, called\nself-adaptive soft VAD, to incorporate a deep neural network (DNN)-based VAD\ninto a deep speaker embedding system. The proposed method is a combination of\nthe following two approaches. The first approach is soft VAD, which performs a\nsoft selection of frame-level features extracted from a speaker feature\nextractor. The frame-level features are weighted by their corresponding speech\nposteriors estimated from the DNN-based VAD, and then aggregated to generate a\nspeaker embedding. The second approach is self-adaptive VAD, which fine-tunes\nthe pre-trained VAD on the speaker verification data to reduce the domain\nmismatch. Here, we introduce two unsupervised domain adaptation (DA) schemes,\nnamely speech posterior-based DA (SP-DA) and joint learning-based DA (JL-DA).\nExperiments on a Korean speech database demonstrate that the verification\nperformance is improved significantly in real-world environments by using\nself-adaptive soft VAD.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 04:38:01 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Jung", "Youngmoon", ""], ["Choi", "Yeunju", ""], ["Kim", "Hoirin", ""]]}, {"id": "1909.11898", "submitter": "Hong Wang", "authors": "Hong Wang, Christfried Focke, Rob Sylvester, Nilesh Mishra, William\n  Wang", "title": "Fine-tune Bert for DocRED with Two-step Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modelling relations between multiple entities has attracted increasing\nattention recently, and a new dataset called DocRED has been collected in order\nto accelerate the research on the document-level relation extraction. Current\nbaselines for this task uses BiLSTM to encode the whole document and are\ntrained from scratch. We argue that such simple baselines are not strong enough\nto model to complex interaction between entities. In this paper, we further\napply a pre-trained language model (BERT) to provide a stronger baseline for\nthis task. We also find that solving this task in phases can further improve\nthe performance. The first step is to predict whether or not two entities have\na relation, the second step is to predict the specific relation.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 05:25:10 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Wang", "Hong", ""], ["Focke", "Christfried", ""], ["Sylvester", "Rob", ""], ["Mishra", "Nilesh", ""], ["Wang", "William", ""]]}, {"id": "1909.11942", "submitter": "Zhenzhong Lan", "authors": "Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush\n  Sharma, Radu Soricut", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language\n  Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing model size when pretraining natural language representations often\nresults in improved performance on downstream tasks. However, at some point\nfurther model increases become harder due to GPU/TPU memory limitations and\nlonger training times. To address these problems, we present two\nparameter-reduction techniques to lower memory consumption and increase the\ntraining speed of BERT. Comprehensive empirical evidence shows that our\nproposed methods lead to models that scale much better compared to the original\nBERT. We also use a self-supervised loss that focuses on modeling\ninter-sentence coherence, and show it consistently helps downstream tasks with\nmulti-sentence inputs. As a result, our best model establishes new\nstate-of-the-art results on the GLUE, RACE, and \\squad benchmarks while having\nfewer parameters compared to BERT-large. The code and the pretrained models are\navailable at https://github.com/google-research/ALBERT.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 07:06:13 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 03:22:00 GMT"}, {"version": "v3", "created": "Wed, 30 Oct 2019 02:19:07 GMT"}, {"version": "v4", "created": "Fri, 10 Jan 2020 19:00:02 GMT"}, {"version": "v5", "created": "Mon, 3 Feb 2020 04:01:33 GMT"}, {"version": "v6", "created": "Sun, 9 Feb 2020 03:00:18 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Lan", "Zhenzhong", ""], ["Chen", "Mingda", ""], ["Goodman", "Sebastian", ""], ["Gimpel", "Kevin", ""], ["Sharma", "Piyush", ""], ["Soricut", "Radu", ""]]}, {"id": "1909.11968", "submitter": "Ze Yang", "authors": "Ze Yang, Wei Wu, Jian Yang, Can Xu, Zhoujun Li", "title": "Low-Resource Response Generation with Template Prior", "comments": "Accepted by EMNLP2019", "journal-ref": null, "doi": "10.18653/v1/D19-1197", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study open domain response generation with limited message-response pairs.\nThe problem exists in real-world applications but is less explored by the\nexisting work. Since the paired data now is no longer enough to train a neural\ngeneration model, we consider leveraging the large scale of unpaired data that\nare much easier to obtain, and propose response generation with both paired and\nunpaired data. The generation model is defined by an encoder-decoder\narchitecture with templates as prior, where the templates are estimated from\nthe unpaired data as a neural hidden semi-markov model. By this means, response\ngeneration learned from the small paired data can be aided by the semantic and\nsyntactic knowledge in the large unpaired data. To balance the effect of the\nprior and the input message to response generation, we propose learning the\nwhole generation model with an adversarial approach. Empirical studies on\nquestion response generation and sentiment response generation indicate that\nwhen only a few pairs are available, our model can significantly outperform\nseveral state-of-the-art response generation models in terms of both automatic\nand human evaluation.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 08:19:34 GMT"}, {"version": "v2", "created": "Fri, 27 Dec 2019 10:00:52 GMT"}, {"version": "v3", "created": "Mon, 30 Dec 2019 02:45:42 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Yang", "Ze", ""], ["Wu", "Wei", ""], ["Yang", "Jian", ""], ["Xu", "Can", ""], ["Li", "Zhoujun", ""]]}, {"id": "1909.11974", "submitter": "Ze Yang", "authors": "Ze Yang, Can Xu, Wei Wu, Zhoujun Li", "title": "Read, Attend and Comment: A Deep Architecture for Automatic News Comment\n  Generation", "comments": "Accepted by EMNLP2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic news comment generation is a new testbed for techniques of natural\nlanguage generation. In this paper, we propose a \"read-attend-comment\"\nprocedure for news comment generation and formalize the procedure with a\nreading network and a generation network. The reading network comprehends a\nnews article and distills some important points from it, then the generation\nnetwork creates a comment by attending to the extracted discrete points and the\nnews title. We optimize the model in an end-to-end manner by maximizing a\nvariational lower bound of the true objective using the back-propagation\nalgorithm. Experimental results on two datasets indicate that our model can\nsignificantly outperform existing methods in terms of both automatic evaluation\nand human judgment.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 08:34:05 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 06:33:29 GMT"}, {"version": "v3", "created": "Tue, 1 Oct 2019 17:55:14 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Yang", "Ze", ""], ["Xu", "Can", ""], ["Wu", "Wei", ""], ["Li", "Zhoujun", ""]]}, {"id": "1909.11980", "submitter": "Lina Rojas-Barahona", "authors": "Lina M. Rojas-Barahona, Pascal Bellec, Benoit Besset, Martinho\n  Dos-Santos, Johannes Heinecke, Munshi Asadullah, Olivier Le-Blouch, Jean Y.\n  Lancien, G\\'eraldine Damnati, Emmanuel Mory and Fr\\'ed\\'eric Herledan", "title": "Spoken Conversational Search for General Knowledge", "comments": "SIGDial2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a spoken conversational question answering proof of concept that\nis able to answer questions about general knowledge from Wikidata. The dialogue\ncomponent does not only orchestrate various components but also solve\ncoreferences and ellipsis.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 08:46:02 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Rojas-Barahona", "Lina M.", ""], ["Bellec", "Pascal", ""], ["Besset", "Benoit", ""], ["Dos-Santos", "Martinho", ""], ["Heinecke", "Johannes", ""], ["Asadullah", "Munshi", ""], ["Le-Blouch", "Olivier", ""], ["Lancien", "Jean Y.", ""], ["Damnati", "G\u00e9raldine", ""], ["Mory", "Emmanuel", ""], ["Herledan", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "1909.12016", "submitter": "Alberto Poncelas", "authors": "Alberto Poncelas and Andy Way", "title": "Selecting Artificially-Generated Sentences for Fine-Tuning Neural\n  Machine Translation", "comments": "Proceedings of the 12th International Conference on Natural Language\n  Generation (INLG 2019)", "journal-ref": "Proceedings of the 12th International Conference on Natural\n  Language Generation (INLG 2019)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) models tend to achieve best performance when\nlarger sets of parallel sentences are provided for training. For this reason,\naugmenting the training set with artificially-generated sentence pairs can\nboost performance.\n  Nonetheless, the performance can also be improved with a small number of\nsentences if they are in the same domain as the test set. Accordingly, we want\nto explore the use of artificially-generated sentences along with\ndata-selection algorithms to improve German-to-English NMT models trained\nsolely with authentic data.\n  In this work, we show how artificially-generated sentences can be more\nbeneficial than authentic pairs, and demonstrate their advantages when used in\ncombination with data-selection algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 10:37:39 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Poncelas", "Alberto", ""], ["Way", "Andy", ""]]}, {"id": "1909.12066", "submitter": "Jan Deriu", "authors": "Jan Deriu, Mark Cieliebak", "title": "Towards a Metric for Automated Conversational Dialogue System Evaluation\n  and Improvement", "comments": "8 Pages, To be published at the INLG 2019 converence", "journal-ref": "Proceedings of the 12th International Conference on Natural\n  Language Generation. 2019", "doi": "10.18653/v1/W19-8654", "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present \"AutoJudge\", an automated evaluation method for conversational\ndialogue systems. The method works by first generating dialogues based on\nself-talk, i.e. dialogue systems talking to itself. Then, it uses human ratings\non these dialogues to train an automated judgement model. Our experiments show\nthat AutoJudge correlates well with the human ratings and can be used to\nautomatically evaluate dialogue systems, even in deployed systems. In a second\npart, we attempt to apply AutoJudge to improve existing systems. This works\nwell for re-ranking a set of candidate utterances. However, our experiments\nshow that AutoJudge cannot be applied as reward for reinforcement learning,\nalthough the metric can distinguish good from bad dialogues. We discuss\npotential reasons, but state here already that this is still an open question\nfor further research.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 12:55:14 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 08:00:47 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Deriu", "Jan", ""], ["Cieliebak", "Mark", ""]]}, {"id": "1909.12079", "submitter": "Hongliang Dai", "authors": "Hongliang Dai, Donghong Du, Xin Li, Yangqiu Song", "title": "Improving Fine-grained Entity Typing with Entity Linking", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-grained entity typing is a challenging problem since it usually involves\na relatively large tag set and may require to understand the context of the\nentity mention. In this paper, we use entity linking to help with the\nfine-grained entity type classification process. We propose a deep neural model\nthat makes predictions based on both the context and the information obtained\nfrom entity linking results. Experimental results on two commonly used datasets\ndemonstrates the effectiveness of our approach. On both datasets, it achieves\nmore than 5\\% absolute strict accuracy improvement over the state of the art.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 13:20:10 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Dai", "Hongliang", ""], ["Du", "Donghong", ""], ["Li", "Xin", ""], ["Song", "Yangqiu", ""]]}, {"id": "1909.12086", "submitter": "Jun Quan", "authors": "Jun Quan, Deyi Xiong, Bonnie Webber and Changjian Hu", "title": "GECOR: An End-to-End Generative Ellipsis and Co-reference Resolution\n  Model for Task-Oriented Dialogue", "comments": "accepted to appear at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ellipsis and co-reference are common and ubiquitous especially in multi-turn\ndialogues. In this paper, we treat the resolution of ellipsis and co-reference\nin dialogue as a problem of generating omitted or referred expressions from the\ndialogue context. We therefore propose a unified end-to-end Generative Ellipsis\nand CO-reference Resolution model (GECOR) in the context of dialogue. The model\ncan generate a new pragmatically complete user utterance by alternating the\ngeneration and copy mode for each user utterance. A multi-task learning\nframework is further proposed to integrate the GECOR into an end-to-end\ntask-oriented dialogue. In order to train both the GECOR and the multi-task\nlearning framework, we manually construct a new dataset on the basis of the\npublic dataset CamRest676 with both ellipsis and co-reference annotation. On\nthis dataset, intrinsic evaluations on the resolution of ellipsis and\nco-reference show that the GECOR model significantly outperforms the\nsequence-to-sequence (seq2seq) baseline model in terms of EM, BLEU and F1 while\nextrinsic evaluations on the downstream dialogue task demonstrate that our\nmulti-task learning framework with GECOR achieves a higher success rate of task\ncompletion than TSCP, a state-of-the-art end-to-end task-oriented dialogue\nmodel.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 13:34:26 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Quan", "Jun", ""], ["Xiong", "Deyi", ""], ["Webber", "Bonnie", ""], ["Hu", "Changjian", ""]]}, {"id": "1909.12131", "submitter": "Christina Niklaus", "authors": "Christina Niklaus, Andre Freitas and Siegfried Handschuh", "title": "MinWikiSplit: A Sentence Splitting Corpus with Minimal Propositions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We compiled a new sentence splitting corpus that is composed of 203K pairs of\naligned complex source and simplified target sentences. Contrary to previously\nproposed text simplification corpora, which contain only a small number of\nsplit examples, we present a dataset where each input sentence is broken down\ninto a set of minimal propositions, i.e. a sequence of sound, self-contained\nutterances with each of them presenting a minimal semantic unit that cannot be\nfurther decomposed into meaningful propositions. This corpus is useful for\ndeveloping sentence splitting approaches that learn how to transform sentences\nwith a complex linguistic structure into a fine-grained representation of short\nsentences that present a simple and more regular structure which is easier to\nprocess for downstream applications and thus facilitates and improves their\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 14:13:39 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Niklaus", "Christina", ""], ["Freitas", "Andre", ""], ["Handschuh", "Siegfried", ""]]}, {"id": "1909.12136", "submitter": "Thomas Haider", "authors": "Thomas Haider, Steffen Eger", "title": "Semantic Change and Emerging Tropes In a Large Corpus of New High German\n  Poetry", "comments": "Historical Language Change Workshop at ACL 2019, Florence", "journal-ref": "Proceedings of the 1st International Workshop on Computational\n  Approaches to Historical Language Change (pp. 216-222). At ACL 2019,\n  Florence. https://www.aclweb.org/anthology/W19-4727", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Due to its semantic succinctness and novelty of expression, poetry is a great\ntest bed for semantic change analysis. However, so far there is a scarcity of\nlarge diachronic corpora. Here, we provide a large corpus of German poetry\nwhich consists of about 75k poems with more than 11 million tokens, with poems\nranging from the 16th to early 20th century. We then track semantic change in\nthis corpus by investigating the rise of tropes (`love is magic') over time and\ndetecting change points of meaning, which we find to occur particularly within\nthe German Romantic period. Additionally, through self-similarity, we\nreconstruct literary periods and find evidence that the law of linear semantic\nchange also applies to poetry.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 14:18:09 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Haider", "Thomas", ""], ["Eger", "Steffen", ""]]}, {"id": "1909.12140", "submitter": "Christina Niklaus", "authors": "Christina Niklaus, Matthias Cetto, Andre Freitas and Siegfried\n  Handschuh", "title": "DisSim: A Discourse-Aware Syntactic Text Simplification Frameworkfor\n  English and German", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce DisSim, a discourse-aware sentence splitting framework for\nEnglish and German whose goal is to transform syntactically complex sentences\ninto an intermediate representation that presents a simple and more regular\nstructure which is easier to process for downstream semantic applications. For\nthis purpose, we turn input sentences into a two-layered semantic hierarchy in\nthe form of core facts and accompanying contexts, while identifying the\nrhetorical relations that hold between them. In that way, we preserve the\ncoherence structure of the input and, hence, its interpretability for\ndownstream tasks.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 14:21:33 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Niklaus", "Christina", ""], ["Cetto", "Matthias", ""], ["Freitas", "Andre", ""], ["Handschuh", "Siegfried", ""]]}, {"id": "1909.12163", "submitter": "Ahmed Ali", "authors": "Sameer Khurana, Ahmed Ali, James Glass", "title": "DARTS: Dialectal Arabic Transcription System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the speech to text transcription system, called DARTS, for low\nresource Egyptian Arabic dialect. We analyze the following; transfer learning\nfrom high resource broadcast domain to low-resource dialectal domain and\nsemi-supervised learning where we use in-domain unlabeled audio data collected\nfrom YouTube. Key features of our system are: A deep neural network acoustic\nmodel that consists of a front end Convolutional Neural Network (CNN) followed\nby several layers of Time Delayed Neural Network (TDNN) and Long-Short Term\nMemory Recurrent Neural Network (LSTM); sequence discriminative training of the\nacoustic model; n-gram and recurrent neural network language model for decoding\nand N-best list rescoring. We show that a simple transfer learning method can\nachieve good results. The results are further improved by using unlabeled data\nfrom YouTube in a semi-supervised setup. Various systems are combined to give\nthe final system that achieves the lowest word error on on the community\nstandard Egyptian-Arabic speech dataset (MGB-3).\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 14:46:58 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Khurana", "Sameer", ""], ["Ali", "Ahmed", ""], ["Glass", "James", ""]]}, {"id": "1909.12208", "submitter": "C\\u{a}t\\u{a}lin Zoril\\u{a}", "authors": "Catalin Zorila, Christoph Boeddeker, Rama Doddipatla and Reinhold\n  Haeb-Umbach", "title": "An Investigation into the Effectiveness of Enhancement in ASR Training\n  and Test for CHiME-5 Dinner Party Transcription", "comments": "Accepted for ASRU 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the strong modeling power of neural network acoustic models, speech\nenhancement has been shown to deliver additional word error rate improvements\nif multi-channel data is available. However, there has been a longstanding\ndebate whether enhancement should also be carried out on the ASR training data.\nIn an extensive experimental evaluation on the acoustically very challenging\nCHiME-5 dinner party data we show that: (i) cleaning up the training data can\nlead to substantial error rate reductions, and (ii) enhancement in training is\nadvisable as long as enhancement in test is at least as strong as in training.\nThis approach stands in contrast and delivers larger gains than the common\nstrategy reported in the literature to augment the training database with\nadditional artificially degraded speech. Together with an acoustic model\ntopology consisting of initial CNN layers followed by factorized TDNN layers we\nachieve with 41.6% and 43.2% WER on the DEV and EVAL test sets, respectively, a\nnew single-system state-of-the-art result on the CHiME-5 data. This is a 8%\nrelative improvement compared to the best word error rate published so far for\na speech recognizer without system combination.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 15:59:37 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Zorila", "Catalin", ""], ["Boeddeker", "Christoph", ""], ["Doddipatla", "Rama", ""], ["Haeb-Umbach", "Reinhold", ""]]}, {"id": "1909.12229", "submitter": "Avinash Swaminathan", "authors": "Avinash Swaminathan, Raj Kuwar Gupta, Haimin Zhang, Debanjan Mahata,\n  Rakesh Gosangi, Rajiv Ratn Shah", "title": "Keyphrase Generation for Scientific Articles using GANs", "comments": "2 pages, 1 fig, 8 references, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a keyphrase generation approach using conditional\nGenerative Adversarial Networks (GAN). In our GAN model, the generator outputs\na sequence of keyphrases based on the title and abstract of a scientific\narticle. The discriminator learns to distinguish between machine-generated and\nhuman-curated keyphrases. We evaluate this approach on standard benchmark\ndatasets. Our model achieves state-of-the-art performance in generation of\nabstractive keyphrases and is also comparable to the best performing extractive\ntechniques. We also demonstrate that our method generates more diverse\nkeyphrases and make our implementation publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 02:46:58 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Swaminathan", "Avinash", ""], ["Gupta", "Raj Kuwar", ""], ["Zhang", "Haimin", ""], ["Mahata", "Debanjan", ""], ["Gosangi", "Rakesh", ""], ["Shah", "Rajiv Ratn", ""]]}, {"id": "1909.12230", "submitter": "Aditya Saligrama", "authors": "Aditya Saligrama", "title": "KnowBias: Detecting Political Polarity in Long Text Content", "comments": "2 pages, 2 figures, to appear in AAAI 2020 Student Abstract and\n  Poster Program", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a classification scheme for detecting political bias in long\ntext content such as newspaper opinion articles. Obtaining long text data and\nannotations at sufficient scale for training is difficult, but it is relatively\neasy to extract political polarity from tweets through their authorship. We\ntrain on tweets and perform inference on articles. Universal sentence encoders\nand other existing methods that aim to address this domain-adaptation scenario\ndeliver inaccurate and inconsistent predictions on articles, which we show is\ndue to a difference in opinion concentration between tweets and articles. We\npropose a two-step classification scheme that uses a neutral detector trained\non tweets to remove neutral sentences from articles in order to align opinion\nconcentration and therefore improve accuracy on that domain. Our implementation\nis available for public use at https://knowbias.ml.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 20:19:29 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 18:54:05 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Saligrama", "Aditya", ""]]}, {"id": "1909.12231", "submitter": "Diego Antognini", "authors": "Diego Antognini and Boi Faltings", "title": "Learning to Create Sentence Semantic Relation Graphs for Multi-Document\n  Summarization", "comments": "10 pages, 4 tables, 1 figure, Accepted at 2019 Empirical Methods in\n  Natural Language Processing - Workshop on New Frontiers in Summarization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linking facts across documents is a challenging task, as the language used to\nexpress the same information in a sentence can vary significantly, which\ncomplicates the task of multi-document summarization. Consequently, existing\napproaches heavily rely on hand-crafted features, which are domain-dependent\nand hard to craft, or additional annotated data, which is costly to gather. To\novercome these limitations, we present a novel method, which makes use of two\ntypes of sentence embeddings: universal embeddings, which are trained on a\nlarge unrelated corpus, and domain-specific embeddings, which are learned\nduring training.\n  To this end, we develop SemSentSum, a fully data-driven model able to\nleverage both types of sentence embeddings by building a sentence semantic\nrelation graph. SemSentSum achieves competitive results on two types of\nsummary, consisting of 665 bytes and 100 words. Unlike other state-of-the-art\nmodels, neither hand-crafted features nor additional annotated data are\nnecessary, and the method is easily adaptable for other tasks. To our\nknowledge, we are the first to use multiple sentence embeddings for the task of\nmulti-document summarization.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 10:21:55 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Antognini", "Diego", ""], ["Faltings", "Boi", ""]]}, {"id": "1909.12232", "submitter": "Sebastian Bayerl", "authors": "Sebastian P. Bayerl and Korbinian Riedhammer", "title": "A Comparison of Hybrid and End-to-End Models for Syllable Recognition", "comments": "22th International Conference of Text, Speech and Dialogue TSD2019", "journal-ref": null, "doi": "10.1007/978-3-030-27947-9_30", "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a comparison of a traditional hybrid speech recognition\nsystem (kaldi using WFST and TDNN with lattice-free MMI) and a lexicon-free\nend-to-end (TensorFlow implementation of multi-layer LSTM with CTC training)\nmodels for German syllable recognition on the Verbmobil corpus. The results\nshow that explicitly modeling prior knowledge is still valuable in building\nrecognition systems. With a strong language model (LM) based on syllables, the\nstructured approach significantly outperforms the end-to-end model. The best\nword error rate (WER) regarding syllables was achieved using kaldi with a\n4-gram LM, modeling all syllables observed in the training set. It achieved\n10.0% WER w.r.t. the syllables, compared to the end-to-end approach where the\nbest WER was 27.53%. The work presented here has implications for building\nfuture recognition systems that operate independent of a large vocabulary, as\ntypically used in a tasks such as recognition of syllabic or agglutinative\nlanguages, out-of-vocabulary techniques, keyword search indexing and medical\nspeech processing.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 09:51:35 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Bayerl", "Sebastian P.", ""], ["Riedhammer", "Korbinian", ""]]}, {"id": "1909.12233", "submitter": "Wenjun Liao", "authors": "Wenjun Liao, Chenghua Lin", "title": "Deep Ensemble Learning for News Stance Detection", "comments": "Poster presenataion of 5th IC2S2 in University of Amsterdam", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stance detection in fake news is an important component in news veracity\nassessment because this process helps fact-checking by understanding stance to\na central claim from different information sources. The Fake News Challenge\nStage 1 (FNC-1) held in 2017 was setup for this purpose, which involves\nestimating the stance of a news article body relative to a given headline. This\nthesis starts from the error analysis for the three top-performing systems in\nFNC-1. Based on the analysis, a simple but tough-to-beat Multilayer Perceptron\nsystem is chosen as the baseline. Afterwards, three approaches are explored to\nimprove baseline.The first approach explores the possibility of improving the\nprediction accuracy by adding extra keywords features when training a model,\nwhere keywords are converted to an indicator vector and then concatenated to\nthe baseline features. A list of keywords is manually selected based on the\nerror analysis, which may best reflect some characteristics of fake news titles\nand bodies. To make this selection process automatically, three algorithms are\ncreated based on Mutual Information (MI) theory: keywords generator based on MI\nstance class, MI customised class, and Pointwise MI algorithm. The second\napproach is based on word embedding, where word2vec model is introduced and two\ndocument similarities calculation algorithms are implemented: wor2vec cosine\nsimilarity and WMD distance. The third approach is ensemble learning. Different\nmodels are configured together with two continuous outputs combining\nalgorithms. The 10-fold cross validation reveals that the ensemble of three\nneural network models trained from simple bag-of-words features gives the best\nperformance. It is therefore selected to compete in FNC-1. After\nhyperparameters fine tuning, the selected deep ensemble model beats the FNC-1\nwinner team by a remarkable 34.25 marks under FNC-1's evaluation metric.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 13:39:59 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Liao", "Wenjun", ""], ["Lin", "Chenghua", ""]]}, {"id": "1909.12289", "submitter": "Qingyun Dou", "authors": "Qingyun Dou, Yiting Lu, Joshua Efiong and Mark J. F. Gales", "title": "Attention Forcing for Sequence-to-sequence Model Training", "comments": "11 pages, 4 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Auto-regressive sequence-to-sequence models with attention mechanism have\nachieved state-of-the-art performance in many tasks such as machine translation\nand speech synthesis. These models can be difficult to train. The standard\napproach, teacher forcing, guides a model with reference output history during\ntraining. The problem is that the model is unlikely to recover from its\nmistakes during inference, where the reference output is replaced by generated\noutput. Several approaches deal with this problem, largely by guiding the model\nwith generated output history. To make training stable, these approaches often\nrequire a heuristic schedule or an auxiliary classifier. This paper introduces\nattention forcing, which guides the model with generated output history and\nreference attention. This approach can train the model to recover from its\nmistakes, in a stable fashion, without the need for a schedule or a classifier.\nIn addition, it allows the model to generate output sequences aligned with the\nreferences, which can be important for cascaded systems like many speech\nsynthesis systems. Experiments on speech synthesis show that attention forcing\nyields significant performance gain. Experiments on machine translation show\nthat for tasks where various re-orderings of the output are valid, guiding the\nmodel with generated output history is challenging, while guiding the model\nwith reference attention is beneficial.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 17:52:15 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 19:17:11 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Dou", "Qingyun", ""], ["Lu", "Yiting", ""], ["Efiong", "Joshua", ""], ["Gales", "Mark J. F.", ""]]}, {"id": "1909.12299", "submitter": "Subba Reddy Oota", "authors": "Subba Reddy Oota and Naresh Manwani and Raju S. Bapi", "title": "Expert2Coder: Capturing Divergent Brain Regions Using Mixture of\n  Regression Experts", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  fMRI semantic category understanding using linguistic encoding models\nattempts to learn a forward mapping that relates stimuli to the corresponding\nbrain activation. State-of-the-art encoding models use a single global model\n(linear or non-linear) to predict brain activation given the stimulus. However,\nthe critical assumption in these methods is that a priori different brain\nregions respond the same way to all the stimuli, that is, there is no\nmodularity or specialization assumed for any region. This goes against the\nmodularity theory, supported by many cognitive neuroscience investigations\nsuggesting that there are functionally specialized regions in the brain. In\nthis paper, we achieve this by clustering similar regions together and for\nevery cluster we learn a different linear regression model using a mixture of\nlinear experts model. The key idea here is that each linear expert captures the\nbehaviour of similar brain regions. Given a new stimulus, the utility of the\nproposed model is twofold (i) predicts the brain activation as a weighted\nlinear combination of the activations of multiple linear experts and (ii) to\nlearn multiple experts corresponding to different brain regions. We argue that\neach expert captures activity patterns related to a particular region of\ninterest (ROI) in the human brain. This study helps in understanding the brain\nregions that are activated together given different kinds of stimuli.\nImportantly, we suggest that the mixture of regression experts (MoRE) framework\nsuccessfully combines the two principles of organization of function in the\nbrain, namely that of specialization and integration. Experiments on fMRI data\nfrom paradigm 1 [1]where participants view linguistic stimuli show that the\nproposed MoRE model has better prediction accuracy compared to that of\nconventional models.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 17:59:33 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 19:45:25 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Oota", "Subba Reddy", ""], ["Manwani", "Naresh", ""], ["Bapi", "Raju S.", ""]]}, {"id": "1909.12335", "submitter": "Yao Fu", "authors": "Yao Fu, Hao Zhou, Jiaze Chen, and Lei Li", "title": "Rethinking Text Attribute Transfer: A Lexical Analysis", "comments": "INLG 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text attribute transfer is modifying certain linguistic attributes (e.g.\nsentiment, style, authorship, etc.) of a sentence and transforming them from\none type to another. In this paper, we aim to analyze and interpret what is\nchanged during the transfer process. We start from the observation that in many\nexisting models and datasets, certain words within a sentence play important\nroles in determining the sentence attribute class. These words are referred to\nas \\textit{the Pivot Words}. Based on these pivot words, we propose a lexical\nanalysis framework, \\textit{the Pivot Analysis}, to quantitatively analyze the\neffects of these words in text attribute classification and transfer. We apply\nthis framework to existing datasets and models and show that: (1) the pivot\nwords are strong features for the classification of sentence attributes; (2) to\nchange the attribute of a sentence, many datasets only requires to change\ncertain pivot words; (3) consequently, many transfer models only perform the\nlexical-level modification, while leaving higher-level sentence structures\nunchanged. Our work provides an in-depth understanding of linguistic attribute\ntransfer and further identifies the future requirements and challenges of this\ntask\\footnote{Our code can be found at\nhttps://github.com/FranxYao/pivot_analysis}.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 18:59:53 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Fu", "Yao", ""], ["Zhou", "Hao", ""], ["Chen", "Jiaze", ""], ["Li", "Lei", ""]]}, {"id": "1909.12339", "submitter": "Neus Catal\\`a", "authors": "Neus Catal\\`a and Mario Martin", "title": "Coin_flipper at eHealth-KD Challenge 2019: Voting LSTMs for Key Phrases\n  and Semantic Relation Identification Applied to Spanish eHealth Texts", "comments": "9 pages, 2 figures, 1 table", "journal-ref": "Proceedings of the Iberian Languages Evaluation Forum (IberLEF\n  2019) co-located with 35th Conference of the Spanish Society for Natural\n  Language Processing (SEPLN 2019) http://ceur-ws.org/Vol-2421/", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This paper describes our approach presented for the eHealth-KD 2019\nchallenge. Our participation was aimed at testing how far we could go using\ngeneric tools for Text-Processing but, at the same time, using common\noptimization techniques in the field of Data Mining. The architecture proposed\nfor both tasks of the challenge is a standard stacked 2-layer bi-LSTM. The main\nparticularities of our approach are: (a) The use of a surrogate function of F1\nas loss function to close the gap between the minimization function and the\nevaluation metric, and (b) The generation of an ensemble of models for\ngenerating predictions by majority vote. Our system ranked second with an F1\nscore of 62.18% in the main task by a narrow margin with the winner that scored\n63.94%.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 19:03:54 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Catal\u00e0", "Neus", ""], ["Martin", "Mario", ""]]}, {"id": "1909.12375", "submitter": "Yi Zhu", "authors": "Yi Zhu, Benjamin Heinzerling, Ivan Vuli\\'c, Michael Strube, Roi\n  Reichart, Anna Korhonen", "title": "On the Importance of Subword Information for Morphological Tasks in\n  Truly Low-Resource Languages", "comments": "CONLL2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has validated the importance of subword information for word\nrepresentation learning. Since subwords increase parameter sharing ability in\nneural models, their value should be even more pronounced in low-data regimes.\nIn this work, we therefore provide a comprehensive analysis focused on the\nusefulness of subwords for word representation learning in truly low-resource\nscenarios and for three representative morphological tasks: fine-grained entity\ntyping, morphological tagging, and named entity recognition. We conduct a\nsystematic study that spans several dimensions of comparison: 1) type of data\nscarcity which can stem from the lack of task-specific training data, or even\nfrom the lack of unannotated data required to train word embeddings, or both;\n2) language type by working with a sample of 16 typologically diverse languages\nincluding some truly low-resource ones (e.g. Rusyn, Buryat, and Zulu); 3) the\nchoice of the subword-informed word representation method. Our main results\nshow that subword-informed models are universally useful across all language\ntypes, with large gains over subword-agnostic embeddings. They also suggest\nthat the effective use of subwords largely depends on the language (type) and\nthe task at hand, as well as on the amount of available data for training the\nembeddings and task-based models, where having sufficient in-task data is a\nmore critical requirement.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 20:26:51 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Zhu", "Yi", ""], ["Heinzerling", "Benjamin", ""], ["Vuli\u0107", "Ivan", ""], ["Strube", "Michael", ""], ["Reichart", "Roi", ""], ["Korhonen", "Anna", ""]]}, {"id": "1909.12401", "submitter": "Brent Harrison", "authors": "Md Sultan Al Nahian, Tasmia Tasrin, Sagar Gandhi, Ryan Gaines, and\n  Brent Harrison", "title": "A Hierarchical Approach for Visual Storytelling Using Image Description", "comments": "Accepted at the 2019 International Conference on Interactive Digital\n  Storytelling (ICIDS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the primary challenges of visual storytelling is developing techniques\nthat can maintain the context of the story over long event sequences to\ngenerate human-like stories. In this paper, we propose a hierarchical deep\nlearning architecture based on encoder-decoder networks to address this\nproblem. To better help our network maintain this context while also generating\nlong and diverse sentences, we incorporate natural language image descriptions\nalong with the images themselves to generate each story sentence. We evaluate\nour system on the Visual Storytelling (VIST) dataset and show that our method\noutperforms state-of-the-art techniques on a suite of different automatic\nevaluation metrics. The empirical results from this evaluation demonstrate the\nnecessities of different components of our proposed architecture and shows the\neffectiveness of the architecture for visual storytelling.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 21:25:41 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Nahian", "Md Sultan Al", ""], ["Tasrin", "Tasmia", ""], ["Gandhi", "Sagar", ""], ["Gaines", "Ryan", ""], ["Harrison", "Brent", ""]]}, {"id": "1909.12406", "submitter": "Juan Pino", "authors": "Xutai Ma, Juan Pino, James Cross, Liezl Puzon, Jiatao Gu", "title": "Monotonic Multihead Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simultaneous machine translation models start generating a target sequence\nbefore they have encoded or read the source sequence. Recent approaches for\nthis task either apply a fixed policy on a state-of-the art Transformer model,\nor a learnable monotonic attention on a weaker recurrent neural network-based\nstructure. In this paper, we propose a new attention mechanism, Monotonic\nMultihead Attention (MMA), which extends the monotonic attention mechanism to\nmultihead attention. We also introduce two novel and interpretable approaches\nfor latency control that are specifically designed for multiple attentions\nheads. We apply MMA to the simultaneous machine translation task and\ndemonstrate better latency-quality tradeoffs compared to MILk, the previous\nstate-of-the-art approach. We also analyze how the latency controls affect the\nattention span and we motivate the introduction of our model by analyzing the\neffect of the number of decoder layers and heads on quality and latency.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 21:32:50 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Ma", "Xutai", ""], ["Pino", "Juan", ""], ["Cross", "James", ""], ["Puzon", "Liezl", ""], ["Gu", "Jiatao", ""]]}, {"id": "1909.12408", "submitter": "Yuan Shangguan", "authors": "Yuan Shangguan, Jian Li, Qiao Liang, Raziel Alvarez, Ian McGraw", "title": "Optimizing Speech Recognition For The Edge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While most deployed speech recognition systems today still run on servers, we\nare in the midst of a transition towards deployments on edge devices. This leap\nto the edge is powered by the progression from traditional speech recognition\npipelines to end-to-end (E2E) neural architectures, and the parallel\ndevelopment of more efficient neural network topologies and optimization\ntechniques. Thus, we are now able to create highly accurate speech recognizers\nthat are both small and fast enough to execute on typical mobile devices. In\nthis paper, we begin with a baseline RNN-Transducer architecture comprised of\nLong Short-Term Memory (LSTM) layers. We then experiment with a variety of more\ncomputationally efficient layer types, as well as apply optimization techniques\nlike neural connection pruning and parameter quantization to construct a small,\nhigh quality, on-device speech recognizer that is an order of magnitude smaller\nthan the baseline system without any optimizations.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 21:43:53 GMT"}, {"version": "v2", "created": "Sat, 4 Jan 2020 21:57:39 GMT"}, {"version": "v3", "created": "Fri, 7 Feb 2020 00:15:41 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Shangguan", "Yuan", ""], ["Li", "Jian", ""], ["Liang", "Qiao", ""], ["Alvarez", "Raziel", ""], ["McGraw", "Ian", ""]]}, {"id": "1909.12411", "submitter": "Ashok Thillaisundaram", "authors": "Ashok Thillaisundaram and Theodosia Togia", "title": "Biomedical relation extraction with pre-trained language representations\n  and minimal task-specific architecture", "comments": "EMNLP-IJCNLP 2019: International Workshop on BioNLP Open Shared Tasks\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents our participation in the AGAC Track from the 2019 BioNLP\nOpen Shared Tasks. We provide a solution for Task 3, which aims to extract\n\"gene - function change - disease\" triples, where \"gene\" and \"disease\" are\nmentions of particular genes and diseases respectively and \"function change\" is\none of four pre-defined relationship types. Our system extends BERT (Devlin et\nal., 2018), a state-of-the-art language model, which learns contextual language\nrepresentations from a large unlabelled corpus and whose parameters can be\nfine-tuned to solve specific tasks with minimal additional architecture. We\nencode the pair of mentions and their textual context as two consecutive\nsequences in BERT, separated by a special symbol. We then use a single linear\nlayer to classify their relationship into five classes (four pre-defined, as\nwell as 'no relation'). Despite considerable class imbalance, our system\nsignificantly outperforms a random baseline while relying on an extremely\nsimple setup with no specially engineered features.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 21:58:26 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Thillaisundaram", "Ashok", ""], ["Togia", "Theodosia", ""]]}, {"id": "1909.12415", "submitter": "Jinyu Li", "authors": "Jinyu Li, Rui Zhao, Hu Hu, and Yifan Gong", "title": "Improving RNN Transducer Modeling for End-to-End Speech Recognition", "comments": "Accepted by IEEE ASRU workshop, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last few years, an emerging trend in automatic speech recognition\nresearch is the study of end-to-end (E2E) systems. Connectionist Temporal\nClassification (CTC), Attention Encoder-Decoder (AED), and RNN Transducer\n(RNN-T) are the most popular three methods. Among these three methods, RNN-T\nhas the advantages to do online streaming which is challenging to AED and it\ndoesn't have CTC's frame-independence assumption. In this paper, we improve the\nRNN-T training in two aspects. First, we optimize the training algorithm of\nRNN-T to reduce the memory consumption so that we can have larger training\nminibatch for faster training speed. Second, we propose better model structures\nso that we obtain RNN-T models with the very good accuracy but small footprint.\nTrained with 30 thousand hours anonymized and transcribed Microsoft production\ndata, the best RNN-T model with even smaller model size (216 Megabytes)\nachieves up-to 11.8% relative word error rate (WER) reduction from the baseline\nRNN-T model. This best RNN-T model is significantly better than the device\nhybrid model with similar size by achieving up-to 15.0% relative WER reduction,\nand obtains similar WERs as the server hybrid model of 5120 Megabytes in size.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 22:09:09 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Li", "Jinyu", ""], ["Zhao", "Rui", ""], ["Hu", "Hu", ""], ["Gong", "Yifan", ""]]}, {"id": "1909.12434", "submitter": "Divyansh Kaushik", "authors": "Divyansh Kaushik, Eduard Hovy, Zachary C. Lipton", "title": "Learning the Difference that Makes a Difference with\n  Counterfactually-Augmented Data", "comments": "Published at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite alarm over the reliance of machine learning systems on so-called\nspurious patterns, the term lacks coherent meaning in standard statistical\nframeworks. However, the language of causality offers clarity: spurious\nassociations are due to confounding (e.g., a common cause), but not direct or\nindirect causal effects. In this paper, we focus on natural language\nprocessing, introducing methods and resources for training models less\nsensitive to spurious patterns. Given documents and their initial labels, we\ntask humans with revising each document so that it (i) accords with a\ncounterfactual target label; (ii) retains internal coherence; and (iii) avoids\nunnecessary changes. Interestingly, on sentiment analysis and natural language\ninference tasks, classifiers trained on original data fail on their\ncounterfactually-revised counterparts and vice versa. Classifiers trained on\ncombined datasets perform remarkably well, just shy of those specialized to\neither domain. While classifiers trained on either original or manipulated data\nalone are sensitive to spurious features (e.g., mentions of genre), models\ntrained on the combined data are less sensitive to this signal. Both datasets\nare publicly available.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 23:25:25 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 22:32:46 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Kaushik", "Divyansh", ""], ["Hovy", "Eduard", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "1909.12440", "submitter": "Hai Wang", "authors": "Hai Wang, Dian Yu, Kai Sun, Janshu Chen, Dong Yu", "title": "Improving Pre-Trained Multilingual Models with Vocabulary Expansion", "comments": "CONLL 2019 final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, pre-trained language models have achieved remarkable success in a\nbroad range of natural language processing tasks. However, in multilingual\nsetting, it is extremely resource-consuming to pre-train a deep language model\nover large-scale corpora for each language. Instead of exhaustively\npre-training monolingual language models independently, an alternative solution\nis to pre-train a powerful multilingual deep language model over large-scale\ncorpora in hundreds of languages. However, the vocabulary size for each\nlanguage in such a model is relatively small, especially for low-resource\nlanguages. This limitation inevitably hinders the performance of these\nmultilingual models on tasks such as sequence labeling, wherein in-depth\ntoken-level or sentence-level understanding is essential.\n  In this paper, inspired by previous methods designed for monolingual\nsettings, we investigate two approaches (i.e., joint mapping and mixture\nmapping) based on a pre-trained multilingual model BERT for addressing the\nout-of-vocabulary (OOV) problem on a variety of tasks, including part-of-speech\ntagging, named entity recognition, machine translation quality estimation, and\nmachine reading comprehension. Experimental results show that using mixture\nmapping is more promising. To the best of our knowledge, this is the first work\nthat attempts to address and discuss the OOV issue in multilingual settings.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 23:56:07 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Wang", "Hai", ""], ["Yu", "Dian", ""], ["Sun", "Kai", ""], ["Chen", "Janshu", ""], ["Yu", "Dong", ""]]}, {"id": "1909.12486", "submitter": "Fu-Ming Guo", "authors": "Fu-Ming Guo, Sijia Liu, Finlay S. Mungall, Xue Lin and Yanzhi Wang", "title": "Reweighted Proximal Pruning for Large-Scale Language Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, pre-trained language representation flourishes as the mainstay of\nthe natural language understanding community, e.g., BERT. These pre-trained\nlanguage representations can create state-of-the-art results on a wide range of\ndownstream tasks. Along with continuous significant performance improvement,\nthe size and complexity of these pre-trained neural models continue to increase\nrapidly. Is it possible to compress these large-scale language representation\nmodels? How will the pruned language representation affect the downstream\nmulti-task transfer learning objectives? In this paper, we propose Reweighted\nProximal Pruning (RPP), a new pruning method specifically designed for a\nlarge-scale language representation model. Through experiments on SQuAD and the\nGLUE benchmark suite, we show that proximal pruned BERT keeps high accuracy for\nboth the pre-training task and the downstream multiple fine-tuning tasks at\nhigh prune ratio. RPP provides a new perspective to help us analyze what\nlarge-scale language representation might learn. Additionally, RPP makes it\npossible to deploy a large state-of-the-art language representation model such\nas BERT on a series of distinct devices (e.g., online servers, mobile phones,\nand edge devices).\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 04:10:10 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 01:23:53 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Guo", "Fu-Ming", ""], ["Liu", "Sijia", ""], ["Mungall", "Finlay S.", ""], ["Lin", "Xue", ""], ["Wang", "Yanzhi", ""]]}, {"id": "1909.12622", "submitter": "Jan Ka{\\ss}el", "authors": "Maryam Foradi, Jan Ka{\\ss}el, Johannes Pein, Gregory R. Crane", "title": "Multi-Modal Citizen Science: From Disambiguation to Transcription of\n  Classical Literature", "comments": null, "journal-ref": "Proceedings of the 30th ACM Conference on Hypertext and Social\n  Media - HT 2019, 49-53. Hof, Germany: ACM Press", "doi": "10.1145/3342220.3343667", "report-no": null, "categories": "cs.CL cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The engagement of citizens in the research projects, including Digital\nHumanities projects, has risen in prominence in recent years. This type of\nengagement not only leads to incidental learning of participants but also\nindicates the added value of corpus enrichment via different types of\nannotations undertaken by users generating so-called smart texts. Our work\nfocuses on the continuous task of adding new layers of annotation to Classical\nLiterature. We aim to provide more extensive tools for readers of smart texts,\nenhancing their reading comprehension and at the same time empowering the\nlanguage learning by introducing intellectual tasks, i.e., linking, tagging,\nand disambiguation. The current study adds a new mode of annotation-audio\nannotations-to the extensively annotated corpus of poetry by the Persian poet\nHafiz. By proposing tasks with three different difficulty levels, we estimate\nthe users' ability of providing correct annotations in order to rate their\nanswers in further stages of the project, where no ground truth data is\navailable. While proficiency in Persian is beneficial, annotators with no\nknowledge of Persian are also able to add annotations to the corpus.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 11:19:21 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Foradi", "Maryam", ""], ["Ka\u00dfel", "Jan", ""], ["Pein", "Johannes", ""], ["Crane", "Gregory R.", ""]]}, {"id": "1909.12642", "submitter": "Punyajoy Saha", "authors": "Punyajoy Saha, Binny Mathew, Pawan Goyal and Animesh Mukherjee", "title": "HateMonitors: Language Agnostic Abuse Detection in Social Media", "comments": "8 pages, 1 figure, 4 tables, models available at\n  https://github.com/punyajoy/HateMonitors-HASOC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reducing hateful and offensive content in online social media pose a dual\nproblem for the moderators. On the one hand, rigid censorship on social media\ncannot be imposed. On the other, the free flow of such content cannot be\nallowed. Hence, we require efficient abusive language detection system to\ndetect such harmful content in social media. In this paper, we present our\nmachine learning model, HateMonitor, developed for Hate Speech and Offensive\nContent Identification in Indo-European Languages (HASOC), a shared task at\nFIRE 2019. We have used a Gradient Boosting model, along with BERT and LASER\nembeddings, to make the system language agnostic. Our model came at First\nposition for the German sub-task A. We have also made our model public at\nhttps://github.com/punyajoy/HateMonitors-HASOC .\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 12:15:58 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Saha", "Punyajoy", ""], ["Mathew", "Binny", ""], ["Goyal", "Pawan", ""], ["Mukherjee", "Animesh", ""]]}, {"id": "1909.12673", "submitter": "Jonathan Rosenfeld", "authors": "Jonathan S. Rosenfeld, Amir Rosenfeld, Yonatan Belinkov, Nir Shavit", "title": "A Constructive Prediction of the Generalization Error Across Scales", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dependency of the generalization error of neural networks on model and\ndataset size is of critical importance both in practice and for understanding\nthe theory of neural networks. Nevertheless, the functional form of this\ndependency remains elusive. In this work, we present a functional form which\napproximates well the generalization error in practice. Capitalizing on the\nsuccessful concept of model scaling (e.g., width, depth), we are able to\nsimultaneously construct such a form and specify the exact models which can\nattain it across model/data scales. Our construction follows insights obtained\nfrom observations conducted over a range of model/data scales, in various model\ntypes and datasets, in vision and language tasks. We show that the form both\nfits the observations well across scales, and provides accurate predictions\nfrom small- to large-scale models and data.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 13:27:53 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 18:20:34 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Rosenfeld", "Jonathan S.", ""], ["Rosenfeld", "Amir", ""], ["Belinkov", "Yonatan", ""], ["Shavit", "Nir", ""]]}, {"id": "1909.12681", "submitter": "Emre Yilmaz", "authors": "Xianghu Yue, Grandee Lee, Emre Y{\\i}lmaz, Fang Deng, Haizhou Li", "title": "End-to-End Code-Switching ASR for Low-Resourced Language Pairs", "comments": "Accepted for publication at IEEE ASRU Workshop 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the significant progress in end-to-end (E2E) automatic speech\nrecognition (ASR), E2E ASR for low resourced code-switching (CS) speech has not\nbeen well studied. In this work, we describe an E2E ASR pipeline for the\nrecognition of CS speech in which a low-resourced language is mixed with a high\nresourced language. Low-resourcedness in acoustic data hinders the performance\nof E2E ASR systems more severely than the conventional ASR systems.~To mitigate\nthis problem in the transcription of archives with code-switching Frisian-Dutch\nspeech, we integrate a designated decoding scheme and perform rescoring with\nneural network-based language models to enable better utilization of the\navailable textual resources. We first incorporate a multi-graph decoding\napproach which creates parallel search spaces for each monolingual and mixed\nrecognition tasks to maximize the utilization of the textual resources from\neach language. Further, language model rescoring is performed using a recurrent\nneural network pre-trained with cross-lingual embedding and further adapted\nwith the limited amount of in-domain CS text. The ASR experiments demonstrate\nthe effectiveness of the described techniques in improving the recognition\nperformance of an E2E CS ASR system in a low-resourced scenario.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 13:38:20 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 06:17:59 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Yue", "Xianghu", ""], ["Lee", "Grandee", ""], ["Y\u0131lmaz", "Emre", ""], ["Deng", "Fang", ""], ["Li", "Haizhou", ""]]}, {"id": "1909.12744", "submitter": "St\\'ephane Clinchant", "authors": "St\\'ephane Clinchant, Kweon Woo Jung and Vassilina Nikoulina", "title": "On the use of BERT for Neural Machine Translation", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploiting large pretrained models for various NMT tasks have gained a lot of\nvisibility recently. In this work we study how BERT pretrained models could be\nexploited for supervised Neural Machine Translation. We compare various ways to\nintegrate pretrained BERT model with NMT model and study the impact of the\nmonolingual data used for BERT training on the final translation quality. We\nuse WMT-14 English-German, IWSLT15 English-German and IWSLT14 English-Russian\ndatasets for these experiments. In addition to standard task test set\nevaluation, we perform evaluation on out-of-domain test sets and noise injected\ntest sets, in order to assess how BERT pretrained representations affect model\nrobustness.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 15:23:17 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Clinchant", "St\u00e9phane", ""], ["Jung", "Kweon Woo", ""], ["Nikoulina", "Vassilina", ""]]}, {"id": "1909.12764", "submitter": "Gaurav Singh Tomar", "authors": "Huseyin A. Inan, Gaurav Singh Tomar, Huapu Pan", "title": "Improving Semantic Parsing with Neural Generator-Reranker Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic parsing is the problem of deriving machine interpretable meaning\nrepresentations from natural language utterances. Neural models with\nencoder-decoder architectures have recently achieved substantial improvements\nover traditional methods. Although neural semantic parsers appear to have\nrelatively high recall using large beam sizes, there is room for improvement\nwith respect to one-best precision. In this work, we propose a\ngenerator-reranker architecture for semantic parsing. The generator produces a\nlist of potential candidates and the reranker, which consists of a\npre-processing step for the candidates followed by a novel critic network,\nreranks these candidates based on the similarity between each candidate and the\ninput sentence. We show the advantages of this approach along with how it\nimproves the parsing performance through extensive analysis. We experiment our\nmodel on three semantic parsing datasets (GEO, ATIS, and OVERNIGHT). The\noverall architecture achieves the state-of-the-art results in all three\ndatasets.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 16:10:06 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Inan", "Huseyin A.", ""], ["Tomar", "Gaurav Singh", ""], ["Pan", "Huapu", ""]]}, {"id": "1909.12868", "submitter": "Tong Niu", "authors": "Tong Niu, Mohit Bansal", "title": "Automatically Learning Data Augmentation Policies for Dialogue Tasks", "comments": "7 pages (EMNLP 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic data augmentation (AutoAugment) (Cubuk et al., 2019) searches for\noptimal perturbation policies via a controller trained using performance\nrewards of a sampled policy on the target task, hence reducing data-level model\nbias. While being a powerful algorithm, their work has focused on computer\nvision tasks, where it is comparatively easy to apply imperceptible\nperturbations without changing an image's semantic meaning. In our work, we\nadapt AutoAugment to automatically discover effective perturbation policies for\nnatural language processing (NLP) tasks such as dialogue generation. We start\nwith a pool of atomic operations that apply subtle semantic-preserving\nperturbations to the source inputs of a dialogue task (e.g., different POS-tag\ntypes of stopword dropout, grammatical errors, and paraphrasing). Next, we\nallow the controller to learn more complex augmentation policies by searching\nover the space of the various combinations of these atomic operations.\nMoreover, we also explore conditioning the controller on the source inputs of\nthe target task, since certain strategies may not apply to inputs that do not\ncontain that strategy's required linguistic features. Empirically, we\ndemonstrate that both our input-agnostic and input-aware controllers discover\nuseful data augmentation policies, and achieve significant improvements over\nthe previous state-of-the-art, including trained on manually-designed policies.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 18:40:23 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Niu", "Tong", ""], ["Bansal", "Mohit", ""]]}, {"id": "1909.12928", "submitter": "Ivan P Yamshchikov", "authors": "Ivan P. Yamshchikov, Viacheslav Shibaev, Aleksander Nagaev, J\\\"urgen\n  Jost and Alexey Tikhonov", "title": "Decomposing Textual Information For Style Transfer", "comments": "arXiv admin note: substantial text overlap with arXiv:1908.06809", "journal-ref": null, "doi": "10.18653/v1/D19-5613", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on latent representations that could effectively decompose\ndifferent aspects of textual information. Using a framework of style transfer\nfor texts, we propose several empirical methods to assess information\ndecomposition quality. We validate these methods with several state-of-the-art\ntextual style transfer methods. Higher quality of information decomposition\ncorresponds to higher performance in terms of bilingual evaluation understudy\n(BLEU) between output and human-written reformulations.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 11:34:04 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Yamshchikov", "Ivan P.", ""], ["Shibaev", "Viacheslav", ""], ["Nagaev", "Aleksander", ""], ["Jost", "J\u00fcrgen", ""], ["Tikhonov", "Alexey", ""]]}, {"id": "1909.12940", "submitter": "Ashiqur KhudaBukhsh Ashiqur Rahman KhudaBukhsh", "authors": "Shriphani Palakodety, Ashiqur R. KhudaBukhsh, Jaime G. Carbonell", "title": "Hope Speech Detection: A Computational Analysis of the Voice of Peace", "comments": "Minor edits", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent Pulwama terror attack (February 14, 2019, Pulwama, Kashmir)\ntriggered a chain of escalating events between India and Pakistan adding\nanother episode to their 70-year-old dispute over Kashmir. The present era of\nubiquitious social media has never seen nuclear powers closer to war. In this\npaper, we analyze this evolving international crisis via a substantial corpus\nconstructed using comments on YouTube videos (921,235 English comments posted\nby 392,460 users out of 2.04 million overall comments by 791,289 users on 2,890\nvideos). Our main contributions in the paper are three-fold. First, we present\nan observation that polyglot word-embeddings reveal precise and accurate\nlanguage clusters, and subsequently construct a document\nlanguage-identification technique with negligible annotation requirements. We\ndemonstrate the viability and utility across a variety of data sets involving\nseveral low-resource languages. Second, we present an analysis on temporal\ntrends of pro-peace and pro-war intent observing that when tensions between the\ntwo nations were at their peak, pro-peace intent in the corpus was at its\nhighest point. Finally, in the context of heated discussions in a politically\ntense situation where two nations are at the brink of a full-fledged war, we\nargue the importance of automatic identification of user-generated web content\nthat can diffuse hostility and address this prediction task, dubbed\n\\emph{hope-speech detection}.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 04:22:20 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 20:21:37 GMT"}, {"version": "v3", "created": "Tue, 28 Jan 2020 22:37:43 GMT"}, {"version": "v4", "created": "Mon, 24 Feb 2020 05:11:46 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Palakodety", "Shriphani", ""], ["KhudaBukhsh", "Ashiqur R.", ""], ["Carbonell", "Jaime G.", ""]]}, {"id": "1909.13006", "submitter": "Fahad AlGhamdi", "authors": "Fahad AlGhamdi, Giovanni Molina, Mona Diab, Thamar Solorio, Abdelati\n  Hawwari, Victor Soto, Julia Hirschberg", "title": "Part of speech tagging for code switched data", "comments": "Association for Computational Linguistics", "journal-ref": null, "doi": "10.18653/v1/W16-5812", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of Part of Speech tagging (POS) in the context of\nlinguistic code switching (CS). CS is the phenomenon where a speaker switches\nbetween two languages or variants of the same language within or across\nutterances, known as intra-sentential or inter-sentential CS, respectively.\nProcessing CS data is especially challenging in intra-sentential data given\nstate of the art monolingual NLP technology since such technology is geared\ntoward the processing of one language at a time. In this paper we explore\nmultiple strategies of applying state of the art POS taggers to CS data. We\ninvestigate the landscape in two CS language pairs, Spanish-English and Modern\nStandard Arabic-Arabic dialects. We compare the use of two POS taggers vs. a\nunified tagger trained on CS data. Our results show that applying a machine\nlearning framework using two state of the art POS taggers achieves better\nperformance compared to all other approaches that we investigate.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 02:12:39 GMT"}, {"version": "v2", "created": "Sun, 3 Nov 2019 22:41:51 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["AlGhamdi", "Fahad", ""], ["Molina", "Giovanni", ""], ["Diab", "Mona", ""], ["Solorio", "Thamar", ""], ["Hawwari", "Abdelati", ""], ["Soto", "Victor", ""], ["Hirschberg", "Julia", ""]]}, {"id": "1909.13008", "submitter": "Fahad AlGhamdi", "authors": "Fahad AlGhamdi, Mona Diab", "title": "WASA: A Web Application for Sequence Annotation", "comments": null, "journal-ref": "Proceedings of the Eleventh International Conference on Language\n  Resources and Evaluation, 2018 , LREC", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data annotation is an important and necessary task for all NLP applications.\nDesigning and implementing a web-based application that enables many annotators\nto annotate and enter their input into one central database is not a trivial\ntask. These kinds of web-based applications require a consistent and robust\nbackup for the underlying database and support to enhance the efficiency and\nspeed of the annotation. Also, they need to ensure that the annotations are\nstored with a minimal amount of redundancy in order to take advantage of the\navailable resources(e.g, storage space). In this paper, we introduce WASA, a\nweb-based annotation system for managing large-scale multilingual Code\nSwitching (CS) data annotation. Although WASA has the ability to perform the\nannotation for any token sequence with arbitrary tag sets, we will focus on how\nWASA is used for CS annotation. The system supports concurrent annotation,\nhandles multiple encodings, allows for several levels of management control,\nand enables quality control measures while seamlessly reporting annotation\nstatistics from various perspectives and at different levels of granularity.\nMoreover, the system is integrated with a robust language specific date\nprepossessing tool to enhance the speed and efficiency of the annotation. We\ndescribe the annotation and the administration interfaces as well as the\nbackend engine.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 02:37:23 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["AlGhamdi", "Fahad", ""], ["Diab", "Mona", ""]]}, {"id": "1909.13009", "submitter": "Fahad AlGhamdi", "authors": "Mona Diab, Mahmoud Ghoneim, Abdelati Hawwari, Fahad AlGhamdi, Nada\n  AlMarwani, Mohamed Al-Badrashiny", "title": "Creating a Large Multi-Layered Representational Repository of Linguistic\n  Code Switched Arabic Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present our effort to create a large Multi-Layered representational\nrepository of Linguistic Code-Switched Arabic data. The process involves\ndeveloping clear annotation standards and Guidelines, streamlining the\nannotation process, and implementing quality control measures. We used two main\nprotocols for annotation: in-lab gold annotations and crowd sourcing\nannotations. We developed a web-based annotation tool to facilitate the\nmanagement of the annotation process. The current version of the repository\ncontains a total of 886,252 tokens that are tagged into one of sixteen\ncode-switching tags. The data exhibits code switching between Modern Standard\nArabic and Egyptian Dialectal Arabic representing three data genres: Tweets,\ncommentaries, and discussion fora. The overall Inter-Annotator Agreement is\n93.1%.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 02:42:18 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Diab", "Mona", ""], ["Ghoneim", "Mahmoud", ""], ["Hawwari", "Abdelati", ""], ["AlGhamdi", "Fahad", ""], ["AlMarwani", "Nada", ""], ["Al-Badrashiny", "Mohamed", ""]]}, {"id": "1909.13016", "submitter": "Fahad AlGhamdi", "authors": "Giovanni Molina, Fahad AlGhamdi, Mahmoud Ghoneim, Abdelati Hawwari,\n  Nicolas Rey-Villamizar, Mona Diab, Thamar Solorio", "title": "Overview for the Second Shared Task on Language Identification in\n  Code-Switched Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an overview of the second shared task on language identification\nin code-switched data. For the shared task, we had code-switched data from two\ndifferent language pairs: Modern Standard Arabic-Dialectal Arabic (MSA-DA) and\nSpanish-English (SPA-ENG). We had a total of nine participating teams, with all\nteams submitting a system for SPA-ENG and four submitting for MSA-DA. Through\nevaluation, we found that once again language identification is more difficult\nfor the language pair that is more closely related. We also found that this\nyear's systems performed better overall than the systems from the previous\nshared task indicating overall progress in the state of the art for this task.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 03:26:31 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Molina", "Giovanni", ""], ["AlGhamdi", "Fahad", ""], ["Ghoneim", "Mahmoud", ""], ["Hawwari", "Abdelati", ""], ["Rey-Villamizar", "Nicolas", ""], ["Diab", "Mona", ""], ["Solorio", "Thamar", ""]]}, {"id": "1909.13037", "submitter": "Zhengkun Tian", "authors": "Zhengkun Tian, Jiangyan Yi, Jianhua Tao, Ye Bai, Zhengqi Wen", "title": "Self-Attention Transducers for End-to-End Speech Recognition", "comments": null, "journal-ref": "Proc. Interspeech 2019, 4395-4399", "doi": "10.21437/Interspeech.2019-2203", "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural network transducers (RNN-T) have been successfully applied\nin end-to-end speech recognition. However, the recurrent structure makes it\ndifficult for parallelization . In this paper, we propose a self-attention\ntransducer (SA-T) for speech recognition. RNNs are replaced with self-attention\nblocks, which are powerful to model long-term dependencies inside sequences and\nable to be efficiently parallelized. Furthermore, a path-aware regularization\nis proposed to assist SA-T to learn alignments and improve the performance.\nAdditionally, a chunk-flow mechanism is utilized to achieve online decoding.\nAll experiments are conducted on a Mandarin Chinese dataset AISHELL-1. The\nresults demonstrate that our proposed approach achieves a 21.3% relative\nreduction in character error rate compared with the baseline RNN-T. In\naddition, the SA-T with chunk-flow mechanism can perform online decoding with\nonly a little degradation of the performance.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 06:48:47 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Tian", "Zhengkun", ""], ["Yi", "Jiangyan", ""], ["Tao", "Jianhua", ""], ["Bai", "Ye", ""], ["Wen", "Zhengqi", ""]]}, {"id": "1909.13070", "submitter": "Ismail Shahin", "authors": "Ismail Shahin and Ali Bou Nassif", "title": "Emirati-Accented Speaker Identification in Stressful Talking Conditions", "comments": "6 pages, this work has been accepted in The International Conference\n  on Electrical and Computing Technologies and Applications, 2019 (ICECTA 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research is dedicated to improving text-independent Emirati-accented\nspeaker identification performance in stressful talking conditions using three\ndistinct classifiers: First-Order Hidden Markov Models (HMM1s), Second-Order\nHidden Markov Models (HMM2s), and Third-Order Hidden Markov Models (HMM3s). The\ndatabase that has been used in this work was collected from 25 per gender\nEmirati native speakers uttering eight widespread Emirati sentences in each of\nneutral, shouted, slow, loud, soft, and fast talking conditions. The extracted\nfeatures of the captured database are called Mel-Frequency Cepstral\nCoefficients (MFCCs). Based on HMM1s, HMM2s, and HMM3s, average\nEmirati-accented speaker identification accuracy in stressful conditions is\n58.6%, 61.1%, and 65.0%, respectively. The achieved average speaker\nidentification accuracy in stressful conditions based on HMM3s is so similar to\nthat attained in subjective assessment by human listeners.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 11:16:50 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 10:27:31 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Shahin", "Ismail", ""], ["Nassif", "Ali Bou", ""]]}, {"id": "1909.13078", "submitter": "Han Xu", "authors": "Xu Han, Tianyu Gao, Yuan Yao, Demin Ye, Zhiyuan Liu, Maosong Sun", "title": "OpenNRE: An Open and Extensible Toolkit for Neural Relation Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  OpenNRE is an open-source and extensible toolkit that provides a unified\nframework to implement neural models for relation extraction (RE).\nSpecifically, by implementing typical RE methods, OpenNRE not only allows\ndevelopers to train custom models to extract structured relational facts from\nthe plain text but also supports quick model validation for researchers.\nBesides, OpenNRE provides various functional RE modules based on both\nTensorFlow and PyTorch to maintain sufficient modularity and extensibility,\nmaking it becomes easy to incorporate new models into the framework. Besides\nthe toolkit, we also release an online system to meet real-time extraction\nwithout any training and deploying. Meanwhile, the online system can extract\nfacts in various scenarios as well as aligning the extracted facts to Wikidata,\nwhich may benefit various downstream knowledge-driven applications (e.g.,\ninformation retrieval and question answering). More details of the toolkit and\nonline system can be obtained from http://github.com/thunlp/OpenNRE.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 12:26:07 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Han", "Xu", ""], ["Gao", "Tianyu", ""], ["Yao", "Yuan", ""], ["Ye", "Demin", ""], ["Liu", "Zhiyuan", ""], ["Sun", "Maosong", ""]]}, {"id": "1909.13104", "submitter": "Christos Karatsalos", "authors": "Christos Karatsalos, Yannis Panagiotakis", "title": "Attention-based method for categorizing different types of online\n  harassment language", "comments": "Accepted in \"SIMAH (SocIaL Media And Harassment): First workshop on\n  categorizing different types of online harassment languages in social media\"\n  @ ECML-PKDD 2019", "journal-ref": null, "doi": "10.1007/978-3-030-43887-6_26", "report-no": null, "categories": "cs.CL cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the era of social media and networking platforms, Twitter has been doomed\nfor abuse and harassment toward users specifically women. Monitoring the\ncontents including sexism and sexual harassment in traditional media is easier\nthan monitoring on the online social media platforms like Twitter, because of\nthe large amount of user generated content in these media. So, the research\nabout the automated detection of content containing sexual or racist harassment\nis an important issue and could be the basis for removing that content or\nflagging it for human evaluation. Previous studies have been focused on\ncollecting data about sexism and racism in very broad terms. However, there is\nno much study focusing on different types of online harassment attracting\nnatural language processing techniques. In this work, we present an\nmulti-attention based approach for the detection of different types of\nharassment in tweets. Our approach is based on the Recurrent Neural Networks\nand particularly we are using a deep, classification specific multi-attention\nmechanism. Moreover, we tackle the problem of imbalanced data, using a\nback-translation method. Finally, we present a comparison between different\napproaches based on the Recurrent Neural Networks.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 14:32:46 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 00:36:10 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Karatsalos", "Christos", ""], ["Panagiotakis", "Yannis", ""]]}, {"id": "1909.13128", "submitter": "Felix Wu", "authors": "Felix Wu, Boyi Li, Lequn Wang, Ni Lao, John Blitzer, Kilian Q.\n  Weinberger", "title": "Integrated Triaging for Fast Reading Comprehension", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although according to several benchmarks automatic machine reading\ncomprehension (MRC) systems have recently reached super-human performance, less\nattention has been paid to their computational efficiency. However, efficiency\nis of crucial importance for training and deployment in real world\napplications. This paper introduces Integrated Triaging, a framework that\nprunes almost all context in early layers of a network, leaving the remaining\n(deep) layers to scan only a tiny fraction of the full corpus. This pruning\ndrastically increases the efficiency of MRC models and further prevents the\nlater layers from overfitting to prevalent short paragraphs in the training\nset. Our framework is extremely flexible and naturally applicable to a wide\nvariety of models. Our experiment on doc-SQuAD and TriviaQA tasks demonstrates\nits effectiveness in consistently improving both speed and quality of several\ndiverse MRC models.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 18:28:56 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Wu", "Felix", ""], ["Li", "Boyi", ""], ["Wang", "Lequn", ""], ["Lao", "Ni", ""], ["Blitzer", "John", ""], ["Weinberger", "Kilian Q.", ""]]}, {"id": "1909.13151", "submitter": "Jiajun Shen", "authors": "Jiajun Shen, Peng-Jen Chen, Matt Le, Junxian He, Jiatao Gu, Myle Ott,\n  Michael Auli, Marc'Aurelio Ranzato", "title": "The Source-Target Domain Mismatch Problem in Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While we live in an increasingly interconnected world, different places still\nexhibit strikingly different cultures and many events we experience in our\nevery day life pertain only to the specific place we live in. As a result,\npeople often talk about different things in different parts of the world. In\nthis work we study the effect of local context in machine translation and\npostulate that particularly in low resource settings this causes the domains of\nthe source and target language to greatly mismatch, as the two languages are\noften spoken in further apart regions of the world with more distinctive\ncultural traits and unrelated local events. We first formalize the concept of\nsource-target domain mismatch, propose a metric to quantify it, and provide\nempirical evidence corroborating our intuition that organic text produced by\npeople speaking very different languages exhibits the most dramatic\ndifferences. We conclude with an empirical study of how source-target domain\nmismatch affects training of machine translation systems for low resource\nlanguage pairs. In particular, we find that it severely affects\nback-translation, but the degradation can be alleviated by combining\nback-translation with self-training and by increasing the relative amount of\ntarget side monolingual data.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 21:03:09 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 19:58:00 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Shen", "Jiajun", ""], ["Chen", "Peng-Jen", ""], ["Le", "Matt", ""], ["He", "Junxian", ""], ["Gu", "Jiatao", ""], ["Ott", "Myle", ""], ["Auli", "Michael", ""], ["Ranzato", "Marc'Aurelio", ""]]}, {"id": "1909.13154", "submitter": "Congzheng Song", "authors": "Congzheng Song, Shanghang Zhang, Najmeh Sadoughi, Pengtao Xie, Eric\n  Xing", "title": "Generalized Zero-shot ICD Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The International Classification of Diseases (ICD) is a list of\nclassification codes for the diagnoses. Automatic ICD coding is in high demand\nas the manual coding can be labor-intensive and error-prone. It is a\nmulti-label text classification task with extremely long-tailed label\ndistribution, making it difficult to perform fine-grained classification on\nboth frequent and zero-shot codes at the same time. In this paper, we propose a\nlatent feature generation framework for generalized zero-shot ICD coding, where\nwe aim to improve the prediction on codes that have no labeled data without\ncompromising the performance on seen codes. Our framework generates pseudo\nfeatures conditioned on the ICD code descriptions and exploits the ICD code\nhierarchical structure. To guarantee the semantic consistency between the\ngenerated features and real features, we reconstruct the keywords in the input\ndocuments that are related to the conditioned ICD codes. To the best of our\nknowledge, this works represents the first one that proposes an adversarial\ngenerative model for the generalized zero-shot learning on multi-label text\nclassification. Extensive experiments demonstrate the effectiveness of our\napproach. On the public MIMIC-III dataset, our methods improve the F1 score\nfrom nearly 0 to 20.91% for the zero-shot codes, and increase the AUC score by\n3% (absolute improvement) from previous state of the art. We also show that the\nframework improves the performance on few-shot codes.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 21:32:55 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Song", "Congzheng", ""], ["Zhang", "Shanghang", ""], ["Sadoughi", "Najmeh", ""], ["Xie", "Pengtao", ""], ["Xing", "Eric", ""]]}, {"id": "1909.13162", "submitter": "Aneek Barman Roy", "authors": "Aneek Barman Roy", "title": "Translation, Sentiment and Voices: A Computational Model to Translate\n  and Analyse Voices from Real-Time Video Calling", "comments": "79 Pages, 19 Tables, 24 Figures, A M.Sc Dissertation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With internet quickly becoming an easy access to many, voice calling over\ninternet is slowly gaining momentum. Individuals has been engaging in video\ncommunication across the world in different languages. The decade saw the\nemergence of language translation using neural networks as well. With more data\nbeing generated in audio and visual forms, there has become a need and a\nchallenge to analyse such information for many researchers from academia and\nindustry. The availability of video chat corpora is limited as organizations\nprotect user privacy and ensure data security. For this reason, an audio-visual\ncommunication system (VidALL) has been developed and audio-speeches were\nextracted. To understand human nature while answering a video call, an analysis\nwas conducted where polarity and vocal intensity were considered as parameters.\nSimultaneously, a translation model using a neural approach was developed to\ntranslate English sentences to French. Simple RNN-based and Embedded-RNN based\nmodels were used for the translation model. BLEU score and target sentence\ncomparators were used to check sentence correctness. Embedded-RNN showed an\naccuracy of 88.71 percentage and predicted correct sentences. A key finding\nsuggest that polarity is a good estimator to understand human emotion.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 22:11:03 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Roy", "Aneek Barman", ""]]}, {"id": "1909.13180", "submitter": "Shuyan Zhou", "authors": "Shuyan Zhou and Shruti Rijhwani and Graham Neubig", "title": "Towards Zero-resource Cross-lingual Entity Linking", "comments": "Accepted by EMNLP DeepLo workshop 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual entity linking (XEL) grounds named entities in a source\nlanguage to an English Knowledge Base (KB), such as Wikipedia. XEL is\nchallenging for most languages because of limited availability of requisite\nresources. However, much previous work on XEL has been on simulated settings\nthat actually use significant resources (e.g. source language Wikipedia,\nbilingual entity maps, multilingual embeddings) that are unavailable in truly\nlow-resource languages. In this work, we first examine the effect of these\nresource assumptions and quantify how much the availability of these resource\naffects overall quality of existing XEL systems. Next, we propose three\nimprovements to both entity candidate generation and disambiguation that make\nbetter use of the limited data we do have in resource-scarce scenarios. With\nexperiments on four extremely low-resource languages, we show that our model\nresults in gains of 6-23% in end-to-end linking accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 01:36:19 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 03:34:30 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Zhou", "Shuyan", ""], ["Rijhwani", "Shruti", ""], ["Neubig", "Graham", ""]]}, {"id": "1909.13184", "submitter": "Anahita Davoudi", "authors": "Anahita Davoudi, Ari Z. Klein, Abeed Sarker, Graciela\n  Gonzalez-Hernandez", "title": "Towards Automatic Bot Detection in Twitter for Health-related Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing use of social media data for health-related research, the\ncredibility of the information from this source has been questioned as the\nposts may originate from automated accounts or \"bots\". While automatic bot\ndetection approaches have been proposed, there are none that have been\nevaluated on users posting health-related information. In this paper, we extend\nan existing bot detection system and customize it for health-related research.\nUsing a dataset of Twitter users, we first show that the system, which was\ndesigned for political bot detection, underperforms when applied to\nhealth-related Twitter users. We then incorporate additional features and a\nstatistical machine learning classifier to significantly improve bot detection\nperformance. Our approach obtains F_1 scores of 0.7 for the \"bot\" class,\nrepresenting improvements of 0.339. Our approach is customizable and\ngeneralizable for bot detection in other health-related social media cohorts.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 01:58:15 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Davoudi", "Anahita", ""], ["Klein", "Ari Z.", ""], ["Sarker", "Abeed", ""], ["Gonzalez-Hernandez", "Graciela", ""]]}, {"id": "1909.13193", "submitter": "Isaac Ampomah", "authors": "Isaac K. E. Ampomah, Sally McClean, Zhiwei Lin and Glenn Hawe", "title": "Gated Task Interaction Framework for Multi-task Sequence Tagging", "comments": "8 pages", "journal-ref": "2019 International Joint Conference on Neural Networks (IJCNN)", "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent studies have shown that neural models can achieve high performance on\nseveral sequence labelling/tagging problems without the explicit use of\nlinguistic features such as part-of-speech (POS) tags. These models are trained\nonly using the character-level and the word embedding vectors as inputs. Others\nhave shown that linguistic features can improve the performance of neural\nmodels on tasks such as chunking and named entity recognition (NER). However,\nthe change in performance depends on the degree of semantic relatedness between\nthe linguistic features and the target task; in some instances, linguistic\nfeatures can have a negative impact on performance. This paper presents an\napproach to jointly learn these linguistic features along with the target\nsequence labelling tasks with a new multi-task learning (MTL) framework called\nGated Tasks Interaction (GTI) network for solving multiple sequence tagging\ntasks. The GTI network exploits the relations between the multiple tasks via\nneural gate modules. These gate modules control the flow of information between\nthe different tasks. Experiments on benchmark datasets for chunking and NER\nshow that our framework outperforms other competitive baselines trained with\nand without external training resources.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 02:56:24 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Ampomah", "Isaac K. E.", ""], ["McClean", "Sally", ""], ["Lin", "Zhiwei", ""], ["Hawe", "Glenn", ""]]}, {"id": "1909.13293", "submitter": "Qingkai Min", "authors": "Qingkai Min, Yuefeng Shi and Yue Zhang", "title": "A Pilot Study for Chinese SQL Semantic Parsing", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of semantic parsing is highly useful for dialogue and question\nanswering systems. Many datasets have been proposed to map natural language\ntext into SQL, among which the recent Spider dataset provides cross-domain\nsamples with multiple tables and complex queries. We build a Spider dataset for\nChinese, which is currently a low-resource language in this task area.\nInteresting research questions arise from the uniqueness of the language, which\nrequires word segmentation, and also from the fact that SQL keywords and\ncolumns of DB tables are typically written in English. We compare character-\nand word-based encoders for a semantic parser, and different embedding schemes.\nResults show that word-based semantic parser is subject to segmentation errors\nand cross-lingual word embeddings are useful for text-to-SQL.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 14:41:47 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 14:20:19 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Min", "Qingkai", ""], ["Shi", "Yuefeng", ""], ["Zhang", "Yue", ""]]}, {"id": "1909.13302", "submitter": "Liner Yang", "authors": "Chencheng Wang, Liner Yang, Yun Chen, Yongping Du, Erhong Yang", "title": "Controllable Data Synthesis Method for Grammatical Error Correction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Due to the lack of parallel data in current Grammatical Error Correction\n(GEC) task, models based on Sequence to Sequence framework cannot be adequately\ntrained to obtain higher performance. We propose two data synthesis methods\nwhich can control the error rate and the ratio of error types on synthetic\ndata. The first approach is to corrupt each word in the monolingual corpus with\na fixed probability, including replacement, insertion and deletion. Another\napproach is to train error generation models and further filtering the decoding\nresults of the models. The experiments on different synthetic data show that\nthe error rate is 40% and the ratio of error types is the same can improve the\nmodel performance better. Finally, we synthesize about 100 million data and\nachieve comparable performance as the state of the art, which uses twice as\nmuch data as we use.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 15:35:08 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 08:08:35 GMT"}, {"version": "v3", "created": "Sat, 7 Mar 2020 02:35:21 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Wang", "Chencheng", ""], ["Yang", "Liner", ""], ["Chen", "Yun", ""], ["Du", "Yongping", ""], ["Yang", "Erhong", ""]]}, {"id": "1909.13315", "submitter": "Yatin Chaudhary", "authors": "Yatin Chaudhary, Pankaj Gupta, Thomas Runkler", "title": "Lifelong Neural Topic Learning in Contextualized Autoregressive Topic\n  Models of Language via Informative Transfers", "comments": "94 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic models such as LDA, DocNADE, iDocNADEe have been popular in document\nanalysis. However, the traditional topic models have several limitations\nincluding: (1) Bag-of-words (BoW) assumption, where they ignore word ordering,\n(2) Data sparsity, where the application of topic models is challenging due to\nlimited word co-occurrences, leading to incoherent topics and (3) No Continuous\nLearning framework for topic learning in lifelong fashion, exploiting\nhistorical knowledge (or latent topics) and minimizing catastrophic forgetting.\nThis thesis focuses on addressing the above challenges within neural topic\nmodeling framework. We propose: (1) Contextualized topic model that combines a\ntopic and a language model and introduces linguistic structures (such as word\nordering, syntactic and semantic features, etc.) in topic modeling, (2) A novel\nlifelong learning mechanism into neural topic modeling framework to demonstrate\ncontinuous learning in sequential document collections and minimizing\ncatastrophic forgetting. Additionally, we perform a selective data augmentation\nto alleviate the need for complete historical corpora during data hallucination\nor replay.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 16:43:30 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Chaudhary", "Yatin", ""], ["Gupta", "Pankaj", ""], ["Runkler", "Thomas", ""]]}, {"id": "1909.13332", "submitter": "Natalia Tomashenko", "authors": "Natalia Tomashenko, Antoine Caubriere, Yannick Esteve, Antoine\n  Laurent, Emmanuel Morin", "title": "Recent Advances in End-to-End Spoken Language Understanding", "comments": null, "journal-ref": "Statistical Language and Speech Processing. SLSP 2019", "doi": "10.1007/978-3-030-31372-2_4", "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates spoken language understanding (SLU) systems in the\nscenario when the semantic information is extracted directly from the speech\nsignal by means of a single end-to-end neural network model. Two SLU tasks are\nconsidered: named entity recognition (NER) and semantic slot filling (SF). For\nthese tasks, in order to improve the model performance, we explore various\ntechniques including speaker adaptation, a modification of the connectionist\ntemporal classification (CTC) training criterion, and sequential pretraining.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 18:01:00 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Tomashenko", "Natalia", ""], ["Caubriere", "Antoine", ""], ["Esteve", "Yannick", ""], ["Laurent", "Antoine", ""], ["Morin", "Emmanuel", ""]]}, {"id": "1909.13362", "submitter": "Jacob Krantz", "authors": "Jacob Krantz, Maxwell Dulin, Paul De Palma", "title": "Language-Agnostic Syllabification with Neural Sequence Labeling", "comments": "Accepted as full paper for presentation at the 18th IEEE\n  International Conference on Machine Learning and Applications (ICMLA 2019). 7\n  pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The identification of syllables within phonetic sequences is known as\nsyllabification. This task is thought to play an important role in natural\nlanguage understanding, speech production, and the development of speech\nrecognition systems. The concept of the syllable is cross-linguistic, though\nformal definitions are rarely agreed upon, even within a language. In response,\ndata-driven syllabification methods have been developed to learn from\nsyllabified examples. These methods often employ classical machine learning\nsequence labeling models. In recent years, recurrence-based neural networks\nhave been shown to perform increasingly well for sequence labeling tasks such\nas named entity recognition (NER), part of speech (POS) tagging, and chunking.\nWe present a novel approach to the syllabification problem which leverages\nmodern neural network techniques. Our network is constructed with long\nshort-term memory (LSTM) cells, a convolutional component, and a conditional\nrandom field (CRF) output layer. Existing syllabification approaches are rarely\nevaluated across multiple language families. To demonstrate cross-linguistic\ngeneralizability, we show that the network is competitive with state of the art\nsystems in syllabifying English, Dutch, Italian, French, Manipuri, and Basque\ndatasets.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 20:32:27 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Krantz", "Jacob", ""], ["Dulin", "Maxwell", ""], ["De Palma", "Paul", ""]]}, {"id": "1909.13375", "submitter": "Elad Segal", "authors": "Elad Segal, Avia Efrat, Mor Shoham, Amir Globerson, Jonathan Berant", "title": "A Simple and Effective Model for Answering Multi-span Questions", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models for reading comprehension (RC) commonly restrict their output space to\nthe set of all single contiguous spans from the input, in order to alleviate\nthe learning problem and avoid the need for a model that generates text\nexplicitly. However, forcing an answer to be a single span can be restrictive,\nand some recent datasets also include multi-span questions, i.e., questions\nwhose answer is a set of non-contiguous spans in the text. Naturally, models\nthat return single spans cannot answer these questions. In this work, we\npropose a simple architecture for answering multi-span questions by casting the\ntask as a sequence tagging problem, namely, predicting for each input token\nwhether it should be part of the output or not. Our model substantially\nimproves performance on span extraction questions from DROP and Quoref by 9.9\nand 5.5 EM points respectively.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 21:49:36 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 05:51:55 GMT"}, {"version": "v3", "created": "Mon, 27 Apr 2020 16:42:28 GMT"}, {"version": "v4", "created": "Mon, 5 Oct 2020 14:02:00 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Segal", "Elad", ""], ["Efrat", "Avia", ""], ["Shoham", "Mor", ""], ["Globerson", "Amir", ""], ["Berant", "Jonathan", ""]]}, {"id": "1909.13425", "submitter": "Yiheng Zhou", "authors": "Yiheng Zhou, Yulia Tsvetkov, Alan W Black, Zhou Yu", "title": "Augmenting Non-Collaborative Dialog Systems with Explicit Semantic and\n  Strategic Dialog History", "comments": "Unpublished preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study non-collaborative dialogs, where two agents have a conflict of\ninterest but must strategically communicate to reach an agreement (e.g.,\nnegotiation). This setting poses new challenges for modeling dialog history\nbecause the dialog's outcome relies not only on the semantic intent, but also\non tactics that convey the intent. We propose to model both semantic and tactic\nhistory using finite state transducers (FSTs). Unlike RNN, FSTs can explicitly\nrepresent dialog history through all the states traversed, facilitating\ninterpretability of dialog structure. We train FSTs on a set of strategies and\ntactics used in negotiation dialogs. The trained FSTs show plausible tactic\nstructure and can be generalized to other non-collaborative domains (e.g.,\npersuasion). We evaluate the FSTs by incorporating them in an automated\nnegotiating system that attempts to sell products and a persuasion system that\npersuades people to donate to a charity. Experiments show that explicitly\nmodeling both semantic and tactic history is an effective way to improve both\ndialog policy planning and generation performance.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 02:08:47 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Zhou", "Yiheng", ""], ["Tsvetkov", "Yulia", ""], ["Black", "Alan W", ""], ["Yu", "Zhou", ""]]}, {"id": "1909.13426", "submitter": "Yiheng Zhou", "authors": "Yiheng Zhou, He He, Alan W Black, Yulia Tsvetkov", "title": "A Dynamic Strategy Coach for Effective Negotiation", "comments": "In Proceedings of SigDial 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Negotiation is a complex activity involving strategic reasoning, persuasion,\nand psychology. An average person is often far from an expert in negotiation.\nOur goal is to assist humans to become better negotiators through a\nmachine-in-the-loop approach that combines machine's advantage at data-driven\ndecision-making and human's language generation ability. We consider a\nbargaining scenario where a seller and a buyer negotiate the price of an item\nfor sale through a text-based dialog. Our negotiation coach monitors messages\nbetween them and recommends tactics in real time to the seller to get a better\ndeal (e.g., \"reject the proposal and propose a price\", \"talk about your\npersonal experience with the product\"). The best strategy and tactics largely\ndepend on the context (e.g., the current price, the buyer's attitude).\nTherefore, we first identify a set of negotiation tactics, then learn to\npredict the best strategy and tactics in a given dialog context from a set of\nhuman-human bargaining dialogs. Evaluation on human-human dialogs shows that\nour coach increases the profits of the seller by almost 60%.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 02:15:29 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Zhou", "Yiheng", ""], ["He", "He", ""], ["Black", "Alan W", ""], ["Tsvetkov", "Yulia", ""]]}, {"id": "1909.13434", "submitter": "Lifu Tu", "authors": "Lifu Tu, Xiaoan Ding, Dong Yu, Kevin Gimpel", "title": "Generating Diverse Story Continuations with Controllable Semantics", "comments": "WNGT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a simple and effective modeling framework for controlled\ngeneration of multiple, diverse outputs. We focus on the setting of generating\nthe next sentence of a story given its context. As controllable dimensions, we\nconsider several sentence attributes, including sentiment, length, predicates,\nframes, and automatically-induced clusters. Our empirical results demonstrate:\n(1) our framework is accurate in terms of generating outputs that match the\ntarget control values; (2) our model yields increased maximum metric scores\ncompared to standard n-best list generation via beam search; (3) controlling\ngeneration with semantic frames leads to a stronger combination of diversity\nand quality than other control variables as measured by automatic metrics. We\nalso conduct a human evaluation to assess the utility of providing multiple\nsuggestions for creative writing, demonstrating promising results for the\npotential of controllable, diverse generation in a collaborative writing\nsystem.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 02:40:48 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 02:22:10 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Tu", "Lifu", ""], ["Ding", "Xiaoan", ""], ["Yu", "Dong", ""], ["Gimpel", "Kevin", ""]]}, {"id": "1909.13447", "submitter": "Maarten Van Segbroeck", "authors": "Maarten Van Segbroeck, Ahmed Zaid, Ksenia Kutsenko, Cirenia Huerta,\n  Tinh Nguyen, Xuewen Luo, Bj\\\"orn Hoffmeister, Jan Trmal, Maurizio Omologo,\n  Roland Maas", "title": "DiPCo -- Dinner Party Corpus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a speech data corpus that simulates a \"dinner party\" scenario\ntaking place in an everyday home environment. The corpus was created by\nrecording multiple groups of four Amazon employee volunteers having a natural\nconversation in English around a dining table. The participants were recorded\nby a single-channel close-talk microphone and by five far-field 7-microphone\narray devices positioned at different locations in the recording room. The\ndataset contains the audio recordings and human labeled transcripts of a total\nof 10 sessions with a duration between 15 and 45 minutes. The corpus was\ncreated to advance in the field of noise robust and distant speech processing\nand is intended to serve as a public research and benchmarking data set.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 04:15:59 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Van Segbroeck", "Maarten", ""], ["Zaid", "Ahmed", ""], ["Kutsenko", "Ksenia", ""], ["Huerta", "Cirenia", ""], ["Nguyen", "Tinh", ""], ["Luo", "Xuewen", ""], ["Hoffmeister", "Bj\u00f6rn", ""], ["Trmal", "Jan", ""], ["Omologo", "Maurizio", ""], ["Maas", "Roland", ""]]}, {"id": "1909.13456", "submitter": "Zhe Gan", "authors": "Wenlin Wang, Chenyang Tao, Zhe Gan, Guoyin Wang, Liqun Chen, Xinyuan\n  Zhang, Ruiyi Zhang, Qian Yang, Ricardo Henao, Lawrence Carin", "title": "Improving Textual Network Learning with Variational Homophilic\n  Embeddings", "comments": "Accepted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of many network learning applications crucially hinges on the\nsuccess of network embedding algorithms, which aim to encode rich network\ninformation into low-dimensional vertex-based vector representations. This\npaper considers a novel variational formulation of network embeddings, with\nspecial focus on textual networks. Different from most existing methods that\noptimize a discriminative objective, we introduce Variational Homophilic\nEmbedding (VHE), a fully generative model that learns network embeddings by\nmodeling the semantic (textual) information with a variational autoencoder,\nwhile accounting for the structural (topology) information through a novel\nhomophilic prior design. Homophilic vertex embeddings encourage similar\nembedding vectors for related (connected) vertices. The proposed VHE promises\nbetter generalization for downstream tasks, robustness to incomplete\nobservations, and the ability to generalize to unseen vertices. Extensive\nexperiments on real-world networks, for multiple tasks, demonstrate that the\nproposed method consistently achieves superior performance relative to\ncompeting state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 05:03:25 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Wang", "Wenlin", ""], ["Tao", "Chenyang", ""], ["Gan", "Zhe", ""], ["Wang", "Guoyin", ""], ["Chen", "Liqun", ""], ["Zhang", "Xinyuan", ""], ["Zhang", "Ruiyi", ""], ["Yang", "Qian", ""], ["Henao", "Ricardo", ""], ["Carin", "Lawrence", ""]]}, {"id": "1909.13466", "submitter": "Inigo Jauregi Unanue", "authors": "Inigo Jauregi Unanue, Ehsan Zare Borzeshi, Massimo Piccardi", "title": "Regressing Word and Sentence Embeddings for Regularization of Neural\n  Machine Translation", "comments": "\\c{opyright} 2019 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, neural machine translation (NMT) has become the dominant\napproach in automated translation. However, like many other deep learning\napproaches, NMT suffers from overfitting when the amount of training data is\nlimited. This is a serious issue for low-resource language pairs and many\nspecialized translation domains that are inherently limited in the amount of\navailable supervised data. For this reason, in this paper we propose regressing\nword (ReWE) and sentence (ReSE) embeddings at training time as a way to\nregularize NMT models and improve their generalization. During training, our\nmodels are trained to jointly predict categorical (words in the vocabulary) and\ncontinuous (word and sentence embeddings) outputs. An extensive set of\nexperiments over four language pairs of variable training set size has showed\nthat ReWE and ReSE can outperform strong state-of-the-art baseline models, with\nan improvement that is larger for smaller training sets (e.g., up to +5:15 BLEU\npoints in Basque-English translation). Visualizations of the decoder's output\nspace show that the proposed regularizers improve the clustering of unique\nwords, facilitating correct predictions. In a final experiment on unsupervised\nNMT, we show that ReWE and ReSE are also able to improve the quality of machine\ntranslation when no parallel data are available.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 05:55:06 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Unanue", "Inigo Jauregi", ""], ["Borzeshi", "Ehsan Zare", ""], ["Piccardi", "Massimo", ""]]}, {"id": "1909.13494", "submitter": "Alena Sorokina", "authors": "Aidana Karipbayeva, Alena Sorokina, Zhenisbek Assylbekov", "title": "A Critique of the Smooth Inverse Frequency Sentence Embeddings", "comments": "2 pages, 2 figures, Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We critically review the smooth inverse frequency sentence embedding method\nof Arora, Liang, and Ma (2017), and show inconsistencies in its setup,\nderivation, and evaluation.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 07:38:25 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Karipbayeva", "Aidana", ""], ["Sorokina", "Alena", ""], ["Assylbekov", "Zhenisbek", ""]]}, {"id": "1909.13537", "submitter": "Joanna Rownicka", "authors": "Joanna Rownicka, Peter Bell, Steve Renals", "title": "Embeddings for DNN speaker adaptive training", "comments": "Accepted at ASRU 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigate the use of embeddings for speaker-adaptive\ntraining of DNNs (DNN-SAT) focusing on a small amount of adaptation data per\nspeaker. DNN-SAT can be viewed as learning a mapping from each embedding to\ntransformation parameters that are applied to the shared parameters of the DNN.\nWe investigate different approaches to applying these transformations, and find\nthat with a good training strategy, a multi-layer adaptation network applied to\nall hidden layers is no more effective than a single linear layer acting on the\nembeddings to transform the input features. In the second part of our work, we\nevaluate different embeddings (i-vectors, x-vectors and deep CNN embeddings) in\nan additional speaker recognition task in order to gain insight into what\nshould characterize an embedding for DNN-SAT. We find the performance for\nspeaker recognition of a given representation is not correlated with its ASR\nperformance; in fact, ability to capture more speech attributes than just\nspeaker identity was the most important characteristic of the embeddings for\nefficient DNN-SAT ASR. Our best models achieved relative WER gains of 4% and 9%\nover DNN baselines using speaker-level cepstral mean normalisation (CMN), and a\nfully speaker-independent model, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 09:04:16 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Rownicka", "Joanna", ""], ["Bell", "Peter", ""], ["Renals", "Steve", ""]]}, {"id": "1909.13568", "submitter": "Mandar Gogate", "authors": "Kia Dashtipour, Mandar Gogate, Jingpeng Li, Fengling Jiang, Bin Kong,\n  Amir Hussain", "title": "A Hybrid Persian Sentiment Analysis Framework: Integrating Dependency\n  Grammar Based Rules and Deep Neural Networks", "comments": "Accepted in Neurocomputing, Demo available at:\n  https://cogbid.napier.ac.uk/demo/persian-sentiment-analysis/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media hold valuable, vast and unstructured information on public\nopinion that can be utilized to improve products and services. The automatic\nanalysis of such data, however, requires a deep understanding of natural\nlanguage. Current sentiment analysis approaches are mainly based on word\nco-occurrence frequencies, which are inadequate in most practical cases. In\nthis work, we propose a novel hybrid framework for concept-level sentiment\nanalysis in Persian language, that integrates linguistic rules and deep\nlearning to optimize polarity detection. When a pattern is triggered, the\nframework allows sentiments to flow from words to concepts based on symbolic\ndependency relations. When no pattern is triggered, the framework switches to\nits subsymbolic counterpart and leverages deep neural networks (DNN) to perform\nthe classification. The proposed framework outperforms state-of-the-art\napproaches (including support vector machine, and logistic regression) and DNN\nclassifiers (long short-term memory, and Convolutional Neural Networks) with a\nmargin of 10-15% and 3-4% respectively, using benchmark Persian product and\nhotel reviews corpora.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 10:29:45 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Dashtipour", "Kia", ""], ["Gogate", "Mandar", ""], ["Li", "Jingpeng", ""], ["Jiang", "Fengling", ""], ["Kong", "Bin", ""], ["Hussain", "Amir", ""]]}, {"id": "1909.13668", "submitter": "Victor Prokhorov", "authors": "Victor Prokhorov, Ehsan Shareghi, Yingzhen Li, Mohammad Taher\n  Pilehvar, Nigel Collier", "title": "On the Importance of the Kullback-Leibler Divergence Term in Variational\n  Autoencoders for Text Generation", "comments": "10 pages; Accepted in 3rd Workshop on Neural Generation and\n  Translation (WNGT 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Autoencoders (VAEs) are known to suffer from learning\nuninformative latent representation of the input due to issues such as\napproximated posterior collapse, or entanglement of the latent space. We impose\nan explicit constraint on the Kullback-Leibler (KL) divergence term inside the\nVAE objective function. While the explicit constraint naturally avoids\nposterior collapse, we use it to further understand the significance of the KL\nterm in controlling the information transmitted through the VAE channel. Within\nthis framework, we explore different properties of the estimated posterior\ndistribution, and highlight the trade-off between the amount of information\nencoded in a latent code during training, and the generative capacity of the\nmodel.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 13:05:55 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Prokhorov", "Victor", ""], ["Shareghi", "Ehsan", ""], ["Li", "Yingzhen", ""], ["Pilehvar", "Mohammad Taher", ""], ["Collier", "Nigel", ""]]}, {"id": "1909.13695", "submitter": "Linlin Wang", "authors": "Linlin Wang, Yu Wang, Mark J. F. Gales", "title": "Non-native Speaker Verification for Spoken Language Assessment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic spoken language assessment systems are becoming more popular in\norder to handle increasing interests in second language learning. One challenge\nfor these systems is to detect malpractice. Malpractice can take a range of\nforms, this paper focuses on detecting when a candidate attempts to impersonate\nanother in a speaking test. This form of malpractice is closely related to\nspeaker verification, but applied in the specific domain of spoken language\nassessment. Advanced speaker verification systems, which leverage deep-learning\napproaches to extract speaker representations, have been successfully applied\nto a range of native speaker verification tasks. These systems are explored for\nnon-native spoken English data in this paper. The data used for speaker\nenrolment and verification is mainly taken from the BULATS test, which assesses\nEnglish language skills for business. Performance of systems trained on\nrelatively limited amounts of BULATS data, and standard large speaker\nverification corpora, is compared. Experimental results on large-scale test\nsets with millions of trials show that the best performance is achieved by\nadapting the imported model to non-native data. Breakdown of impostor trials\nacross different first languages (L1s) and grades is analysed, which shows that\ninter-L1 impostors are more challenging for speaker verification systems.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 13:42:06 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Wang", "Linlin", ""], ["Wang", "Yu", ""], ["Gales", "Mark J. F.", ""]]}, {"id": "1909.13705", "submitter": "Pengfei Liu", "authors": "Ming Zhong, Danqing Wang, Pengfei Liu, Xipeng Qiu, Xuanjing Huang", "title": "A Closer Look at Data Bias in Neural Extractive Summarization Models", "comments": "EMNLP 2019 Workshop on New Frontiers in Summarization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we take stock of the current state of summarization datasets\nand explore how different factors of datasets influence the generalization\nbehaviour of neural extractive summarization models. Specifically, we first\npropose several properties of datasets, which matter for the generalization of\nsummarization models. Then we build the connection between priors residing in\ndatasets and model designs, analyzing how different properties of datasets\ninfluence the choices of model structure design and training methods. Finally,\nby taking a typical dataset as an example, we rethink the process of the model\ndesign based on the experience of the above analysis. We demonstrate that when\nwe have a deep understanding of the characteristics of datasets, a simple\napproach can bring significant improvements to the existing state-of-the-art\nmodel.A\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 13:55:10 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Zhong", "Ming", ""], ["Wang", "Danqing", ""], ["Liu", "Pengfei", ""], ["Qiu", "Xipeng", ""], ["Huang", "Xuanjing", ""]]}, {"id": "1909.13714", "submitter": "Eda Okur", "authors": "Eda Okur, Shachi H Kumar, Saurav Sahay, Lama Nachman", "title": "Towards Multimodal Understanding of Passenger-Vehicle Interactions in\n  Autonomous Vehicles: Intent/Slot Recognition Utilizing Audio-Visual Data", "comments": "Presented as a short-paper at the 23rd Workshop on the Semantics and\n  Pragmatics of Dialogue (SemDial 2019 - LondonLogue), Sep 4-6, 2019, London,\n  UK", "journal-ref": "Proceedings of the 23rd Workshop on the Semantics and Pragmatics\n  of Dialogue (SEMDIAL), pp. 213-215, London, United Kingdom, September 2019", "doi": null, "report-no": null, "categories": "cs.MM cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding passenger intents from spoken interactions and car's vision\n(both inside and outside the vehicle) are important building blocks towards\ndeveloping contextual dialog systems for natural interactions in autonomous\nvehicles (AV). In this study, we continued exploring AMIE (Automated-vehicle\nMultimodal In-cabin Experience), the in-cabin agent responsible for handling\ncertain multimodal passenger-vehicle interactions. When the passengers give\ninstructions to AMIE, the agent should parse such commands properly considering\navailable three modalities (language/text, audio, video) and trigger the\nappropriate functionality of the AV system. We had collected a multimodal\nin-cabin dataset with multi-turn dialogues between the passengers and AMIE\nusing a Wizard-of-Oz scheme via realistic scavenger hunt game. In our previous\nexplorations, we experimented with various RNN-based models to detect\nutterance-level intents (set destination, change route, go faster, go slower,\nstop, park, pull over, drop off, open door, and others) along with intent\nkeywords and relevant slots (location, position/direction, object,\ngesture/gaze, time-guidance, person) associated with the action to be performed\nin our AV scenarios. In this recent work, we propose to discuss the benefits of\nmultimodal understanding of in-cabin utterances by incorporating\nverbal/language input (text and speech embeddings) together with the\nnon-verbal/acoustic and visual input from inside and outside the vehicle (i.e.,\npassenger gestures and gaze from in-cabin video stream, referred objects\noutside of the vehicle from the road view camera stream). Our experimental\nresults outperformed text-only baselines and with multimodality, we achieved\nimproved performances for utterance-level intent detection and slot filling.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 00:00:41 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Okur", "Eda", ""], ["Kumar", "Shachi H", ""], ["Sahay", "Saurav", ""], ["Nachman", "Lama", ""]]}, {"id": "1909.13717", "submitter": "Ana Valeria Gonzalez-Gardu\\~no", "authors": "Ana Valeria Gonzalez, Isabelle Augenstein and Anders S{\\o}gaard", "title": "Retrieval-based Goal-Oriented Dialogue Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most research on dialogue has focused either on dialogue generation for\nopenended chit chat or on state tracking for goal-directed dialogue. In this\nwork, we explore a hybrid approach to goal-oriented dialogue generation that\ncombines retrieval from past history with a hierarchical, neural\nencoder-decoder architecture. We evaluate this approach in the customer support\ndomain using the Multiwoz dataset (Budzianowski et al., 2018). We show that\nadding this retrieval step to a hierarchical, neural encoder-decoder\narchitecture leads to significant improvements, including responses that are\nrated more appropriate and fluent by human evaluators. Finally, we compare our\nretrieval-based model to various semantically conditioned models explicitly\nusing past dialog act information, and find that our proposed model is\ncompetitive with the current state of the art (Chen et al., 2019), while not\nrequiring explicit labels about past machine acts.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 14:02:53 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Gonzalez", "Ana Valeria", ""], ["Augenstein", "Isabelle", ""], ["S\u00f8gaard", "Anders", ""]]}, {"id": "1909.13759", "submitter": "Joachim Fainberg", "authors": "Joachim Fainberg, Ond\\v{r}ej Klejch, Erfan Loweimi, Peter Bell, Steve\n  Renals", "title": "Acoustic Model Adaptation from Raw Waveforms with SincNet", "comments": "Accepted to IEEE ASRU 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Raw waveform acoustic modelling has recently gained interest due to neural\nnetworks' ability to learn feature extraction, and the potential for finding\nbetter representations for a given scenario than hand-crafted features. SincNet\nhas been proposed to reduce the number of parameters required in raw-waveform\nmodelling, by restricting the filter functions, rather than having to learn\nevery tap of each filter. We study the adaptation of the SincNet filter\nparameters from adults' to children's speech, and show that the\nparameterisation of the SincNet layer is well suited for adaptation in\npractice: we can efficiently adapt with a very small number of parameters,\nproducing error rates comparable to techniques using orders of magnitude more\nparameters.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 14:49:24 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Fainberg", "Joachim", ""], ["Klejch", "Ond\u0159ej", ""], ["Loweimi", "Erfan", ""], ["Bell", "Peter", ""], ["Renals", "Steve", ""]]}, {"id": "1909.13788", "submitter": "Junxian He", "authors": "Junxian He, Jiatao Gu, Jiajun Shen, Marc'Aurelio Ranzato", "title": "Revisiting Self-Training for Neural Sequence Generation", "comments": "ICLR 2020. The first two authors contributed equally. Updated to fix\n  typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-training is one of the earliest and simplest semi-supervised methods.\nThe key idea is to augment the original labeled dataset with unlabeled data\npaired with the model's prediction (i.e. the pseudo-parallel data). While\nself-training has been extensively studied on classification problems, in\ncomplex sequence generation tasks (e.g. machine translation) it is still\nunclear how self-training works due to the compositionality of the target\nspace. In this work, we first empirically show that self-training is able to\ndecently improve the supervised baseline on neural sequence generation tasks.\nThrough careful examination of the performance gains, we find that the\nperturbation on the hidden states (i.e. dropout) is critical for self-training\nto benefit from the pseudo-parallel data, which acts as a regularizer and\nforces the model to yield close predictions for similar unlabeled inputs. Such\neffect helps the model correct some incorrect predictions on unlabeled data. To\nfurther encourage this mechanism, we propose to inject noise to the input\nspace, resulting in a \"noisy\" version of self-training. Empirical study on\nstandard machine translation and text summarization benchmarks shows that noisy\nself-training is able to effectively utilize unlabeled data and improve the\nperformance of the supervised baseline by a large margin.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 15:30:00 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 08:35:41 GMT"}, {"version": "v3", "created": "Sun, 18 Oct 2020 22:49:31 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["He", "Junxian", ""], ["Gu", "Jiatao", ""], ["Shen", "Jiajun", ""], ["Ranzato", "Marc'Aurelio", ""]]}, {"id": "1909.13790", "submitter": "Stefan Constantin", "authors": "Stefan Constantin, Jan Niehues, Alex Waibel", "title": "Incremental processing of noisy user utterances in the spoken language\n  understanding task", "comments": "10 pages, 3 figures, 7 tables, forthcoming in W-NUT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state-of-the-art neural network architectures make it possible to create\nspoken language understanding systems with high quality and fast processing\ntime. One major challenge for real-world applications is the high latency of\nthese systems caused by triggered actions with high executions times. If an\naction can be separated into subactions, the reaction time of the systems can\nbe improved through incremental processing of the user utterance and starting\nsubactions while the utterance is still being uttered. In this work, we present\na model-agnostic method to achieve high quality in processing incrementally\nproduced partial utterances. Based on clean and noisy versions of the ATIS\ndataset, we show how to create datasets with our method to create low-latency\nnatural language understanding components. We get improvements of up to 47.91\nabsolute percentage points in the metric F1-score.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 15:35:07 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Constantin", "Stefan", ""], ["Niehues", "Jan", ""], ["Waibel", "Alex", ""]]}, {"id": "1909.13827", "submitter": "Zhecheng An", "authors": "Zhecheng An, Sicong Liu", "title": "Towards Diverse Paraphrase Generation Using Multi-Class Wasserstein GAN", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Paraphrase generation is an important and challenging natural language\nprocessing (NLP) task. In this work, we propose a deep generative model to\ngenerate paraphrase with diversity. Our model is based on an encoder-decoder\narchitecture. An additional transcoder is used to convert a sentence into its\nparaphrasing latent code. The transcoder takes an explicit pattern embedding\nvariable as condition, so diverse paraphrase can be generated by sampling on\nthe pattern embedding variable. We use a Wasserstein GAN to align the\ndistributions of the real and generated paraphrase samples. We propose a\nmulti-class extension to the Wasserstein GAN, which allows our generative model\nto learn from both positive and negative samples. The generated paraphrase\ndistribution is forced to get closer to the positive real distribution, and be\npushed away from the negative distribution in Wasserstein distance. We test our\nmodel in two datasets with both automatic metrics and human evaluation. Results\nshow that our model can generate fluent and reliable paraphrase samples that\noutperform the state-of-art results, while also provides reasonable variability\nand diversity.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 16:40:15 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["An", "Zhecheng", ""], ["Liu", "Sicong", ""]]}, {"id": "1909.13838", "submitter": "Tal Schuster", "authors": "Darsh J Shah, Tal Schuster, Regina Barzilay", "title": "Automatic Fact-guided Sentence Modification", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online encyclopediae like Wikipedia contain large amounts of text that need\nfrequent corrections and updates. The new information may contradict existing\ncontent in encyclopediae. In this paper, we focus on rewriting such dynamically\nchanging articles. This is a challenging constrained generation task, as the\noutput must be consistent with the new information and fit into the rest of the\nexisting document. To this end, we propose a two-step solution: (1) We identify\nand remove the contradicting components in a target text for a given claim,\nusing a neutralizing stance model; (2) We expand the remaining text to be\nconsistent with the given claim, using a novel two-encoder sequence-to-sequence\nmodel with copy attention. Applied to a Wikipedia fact update dataset, our\nmethod successfully generates updated sentences for new claims, achieving the\nhighest SARI score. Furthermore, we demonstrate that generating synthetic data\nthrough such rewritten sentences can successfully augment the FEVER\nfact-checking training dataset, leading to a relative error reduction of 13%.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 17:02:57 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 23:39:02 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Shah", "Darsh J", ""], ["Schuster", "Tal", ""], ["Barzilay", "Regina", ""]]}, {"id": "1909.13851", "submitter": "Aaron Steven White", "authors": "Aaron Steven White, Elias Stengel-Eskin, Siddharth Vashishtha, Venkata\n  Govindarajan, Dee Ann Reisinger, Tim Vieira, Keisuke Sakaguchi, Sheng Zhang,\n  Francis Ferraro, Rachel Rudinger, Kyle Rawlins, Benjamin Van Durme", "title": "The Universal Decompositional Semantics Dataset and Decomp Toolkit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Universal Decompositional Semantics (UDS) dataset (v1.0),\nwhich is bundled with the Decomp toolkit (v0.1). UDS1.0 unifies five\nhigh-quality, decompositional semantics-aligned annotation sets within a single\nsemantic graph specification---with graph structures defined by the predicative\npatterns produced by the PredPatt tool and real-valued node and edge attributes\nconstructed using sophisticated normalization procedures. The Decomp toolkit\nprovides a suite of Python 3 tools for querying UDS graphs using SPARQL. Both\nUDS1.0 and Decomp0.1 are publicly available at http://decomp.io.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 17:15:57 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["White", "Aaron Steven", ""], ["Stengel-Eskin", "Elias", ""], ["Vashishtha", "Siddharth", ""], ["Govindarajan", "Venkata", ""], ["Reisinger", "Dee Ann", ""], ["Vieira", "Tim", ""], ["Sakaguchi", "Keisuke", ""], ["Zhang", "Sheng", ""], ["Ferraro", "Francis", ""], ["Rudinger", "Rachel", ""], ["Rawlins", "Kyle", ""], ["Van Durme", "Benjamin", ""]]}, {"id": "1909.13872", "submitter": "John Wieting", "authors": "John Wieting, Kevin Gimpel, Graham Neubig, and Taylor Berg-Kirkpatrick", "title": "Simple and Effective Paraphrastic Similarity from Parallel Translations", "comments": "Published as a short paper at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a model and methodology for learning paraphrastic sentence\nembeddings directly from bitext, removing the time-consuming intermediate step\nof creating paraphrase corpora. Further, we show that the resulting model can\nbe applied to cross-lingual tasks where it both outperforms and is orders of\nmagnitude faster than more complex state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 17:54:50 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Wieting", "John", ""], ["Gimpel", "Kevin", ""], ["Neubig", "Graham", ""], ["Berg-Kirkpatrick", "Taylor", ""]]}]