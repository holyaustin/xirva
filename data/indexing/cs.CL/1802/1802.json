[{"id": "1802.00033", "submitter": "Peter Sch\\\"uller", "authors": "Peter Sch\\\"uller", "title": "Technical Report: Adjudication of Coreference Annotations via Answer Set\n  Optimization", "comments": "3 tables, 10 figures, preliminary version presented at LPNMR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe the first automatic approach for merging coreference annotations\nobtained from multiple annotators into a single gold standard. This merging is\nsubject to certain linguistic hard constraints and optimization criteria that\nprefer solutions with minimal divergence from annotators. The representation\ninvolves an equivalence relation over a large number of elements. We use Answer\nSet Programming to describe two representations of the problem and four\nobjective functions suitable for different datasets. We provide two\nstructurally different real-world benchmark datasets based on the METU-Sabanci\nTurkish Treebank and we report our experiences in using the Gringo, Clasp, and\nWasp tools for computing optimal adjudication results on these datasets.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 19:41:19 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Sch\u00fcller", "Peter", ""]]}, {"id": "1802.00209", "submitter": "Ahmed Osman", "authors": "Ahmed Osman and Wojciech Samek", "title": "Dual Recurrent Attention Units for Visual Question Answering", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual Question Answering (VQA) requires AI models to comprehend data in two\ndomains, vision and text. Current state-of-the-art models use learned attention\nmechanisms to extract relevant information from the input domains to answer a\ncertain question. Thus, robust attention mechanisms are essential for powerful\nVQA models. In this paper, we propose a recurrent attention mechanism and show\nits benefits compared to the traditional convolutional approach. We perform two\nablation studies to evaluate recurrent attention. First, we introduce a\nbaseline VQA model with visual attention and test the performance difference\nbetween convolutional and recurrent attention on the VQA 2.0 dataset. Secondly,\nwe design an architecture for VQA which utilizes dual (textual and visual)\nRecurrent Attention Units (RAUs). Using this model, we show the effect of all\npossible combinations of recurrent and convolutional dual attention. Our single\nmodel outperforms the first place winner on the VQA 2016 challenge and to the\nbest of our knowledge, it is the second best performing single model on the VQA\n1.0 dataset. Furthermore, our model noticeably improves upon the winner of the\nVQA 2017 challenge. Moreover, we experiment replacing attention mechanisms in\nstate-of-the-art models with our RAUs and show increased performance.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 09:35:33 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 16:27:26 GMT"}, {"version": "v3", "created": "Tue, 26 Mar 2019 13:41:21 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Osman", "Ahmed", ""], ["Samek", "Wojciech", ""]]}, {"id": "1802.00231", "submitter": "Binny Mathew", "authors": "Binny Mathew, Suman Kalyan Maity, Pratip Sarkar, Animesh Mukherjee and\n  Pawan Goyal", "title": "Adapting predominant and novel sense discovery algorithms for\n  identifying corpus-specific sense differences", "comments": "10 pages,2 figures, Accepted in TextGraphs-11", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word senses are not static and may have temporal, spatial or corpus-specific\nscopes. Identifying such scopes might benefit the existing WSD systems largely.\nIn this paper, while studying corpus specific word senses, we adapt three\nexisting predominant and novel-sense discovery algorithms to identify these\ncorpus-specific senses. We make use of text data available in the form of\nmillions of digitized books and newspaper archives as two different sources of\ncorpora and propose automated methods to identify corpus-specific word senses\nat various time points. We conduct an extensive and thorough human judgment\nexperiment to rigorously evaluate and compare the performance of these\napproaches. Post adaptation, the output of the three algorithms are in the same\nformat and the accuracy results are also comparable, with roughly 45-60% of the\nreported corpus-specific senses being judged as genuine.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 10:35:17 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Mathew", "Binny", ""], ["Maity", "Suman Kalyan", ""], ["Sarkar", "Pratip", ""], ["Mukherjee", "Animesh", ""], ["Goyal", "Pawan", ""]]}, {"id": "1802.00254", "submitter": "Yu Wang", "authors": "Yu Wang, Xie Chen, Mark Gales, Anton Ragni and Jeremy Wong", "title": "Phonetic and Graphemic Systems for Multi-Genre Broadcast Transcription", "comments": "5 pages, 6 tables, to appear in 2018 IEEE International Conference on\n  Acoustics, Speech and Signal Processing (ICASSP 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art English automatic speech recognition systems typically use\nphonetic rather than graphemic lexicons. Graphemic systems are known to perform\nless well for English as the mapping from the written form to the spoken form\nis complicated. However, in recent years the representational power of\ndeep-learning based acoustic models has improved, raising interest in graphemic\nacoustic models for English, due to the simplicity of generating the lexicon.\nIn this paper, phonetic and graphemic models are compared for an English\nMulti-Genre Broadcast transcription task. A range of acoustic models based on\nlattice-free MMI training are constructed using phonetic and graphemic\nlexicons. For this task, it is found that having a long-span temporal history\nreduces the difference in performance between the two forms of models. In\naddition, system combination is examined, using parameter smoothing and\nhypothesis combination. As the combination approaches become more complicated\nthe difference between the phonetic and graphemic systems further decreases.\nFinally, for all configurations examined the combination of phonetic and\ngraphemic systems yields consistent gains.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 12:00:45 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Wang", "Yu", ""], ["Chen", "Xie", ""], ["Gales", "Mark", ""], ["Ragni", "Anton", ""], ["Wong", "Jeremy", ""]]}, {"id": "1802.00273", "submitter": "J\\\"org Tiedemann", "authors": "J\\\"org Tiedemann", "title": "Emerging Language Spaces Learned From Massively Multilingual Corpora", "comments": "to be published at the 3rd conference of the association of Digital\n  Humanities in the Nordic Countries (DHN), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Translations capture important information about languages that can be used\nas implicit supervision in learning linguistic properties and semantic\nrepresentations. In an information-centric view, translated texts may be\nconsidered as semantic mirrors of the original text and the significant\nvariations that we can observe across various languages can be used to\ndisambiguate a given expression using the linguistic signal that is grounded in\ntranslation. Parallel corpora consisting of massive amounts of human\ntranslations with a large linguistic variation can be applied to increase\nabstractions and we propose the use of highly multilingual machine translation\nmodels to find language-independent meaning representations. Our initial\nexperiments show that neural machine translation models can indeed learn in\nsuch a setup and we can show that the learning algorithm picks up information\nabout the relation between languages in order to optimize transfer leaning with\nshared parameters. The model creates a continuous language space that\nrepresents relationships in terms of geometric distances, which we can\nvisualize to illustrate how languages cluster according to language families\nand groups. Does this open the door for new ideas of data-driven language\ntypology with promising models and techniques in empirical cross-linguistic\nresearch?\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 12:58:16 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Tiedemann", "J\u00f6rg", ""]]}, {"id": "1802.00382", "submitter": "Amitabha Karmakar", "authors": "Amitabha Karmakar", "title": "Classifying medical notes into standard disease codes using Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the automatic classification of patient discharge notes into\nstandard disease labels. We find that Convolutional Neural Networks with\nAttention outperform previous algorithms used in this task, and suggest further\nareas for improvement.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 16:46:00 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Karmakar", "Amitabha", ""]]}, {"id": "1802.00385", "submitter": "Antigoni-Maria Founta", "authors": "Antigoni-Maria Founta, Despoina Chatzakou, Nicolas Kourtellis, Jeremy\n  Blackburn, Athena Vakali, Ilias Leontiadis", "title": "A Unified Deep Learning Architecture for Abuse Detection", "comments": "abusive behavior, Twitter, aggression, bullying, deep learning,\n  machine learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hate speech, offensive language, sexism, racism and other types of abusive\nbehavior have become a common phenomenon in many online social media platforms.\nIn recent years, such diverse abusive behaviors have been manifesting with\nincreased frequency and levels of intensity. This is due to the openness and\nwillingness of popular media platforms, such as Twitter and Facebook, to host\ncontent of sensitive or controversial topics. However, these platforms have not\nadequately addressed the problem of online abusive behavior, and their\nresponsiveness to the effective detection and blocking of such inappropriate\nbehavior remains limited.\n  In the present paper, we study this complex problem by following a more\nholistic approach, which considers the various aspects of abusive behavior. To\nmake the approach tangible, we focus on Twitter data and analyze user and\ntextual properties from different angles of abusive posting behavior. We\npropose a deep learning architecture, which utilizes a wide variety of\navailable metadata, and combines it with automatically-extracted hidden\npatterns within the text of the tweets, to detect multiple abusive behavioral\nnorms which are highly inter-related. We apply this unified architecture in a\nseamless, transparent fashion to detect different types of abusive behavior\n(hate speech, sexism vs. racism, bullying, sarcasm, etc.) without the need for\nany tuning of the model architecture for each task. We test the proposed\napproach with multiple datasets addressing different and multiple abusive\nbehaviors on Twitter. Our results demonstrate that it largely outperforms the\nstate-of-art methods (between 21 and 45\\% improvement in AUC, depending on the\ndataset).\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 16:48:39 GMT"}, {"version": "v2", "created": "Wed, 21 Feb 2018 14:19:57 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Founta", "Antigoni-Maria", ""], ["Chatzakou", "Despoina", ""], ["Kourtellis", "Nicolas", ""], ["Blackburn", "Jeremy", ""], ["Vakali", "Athena", ""], ["Leontiadis", "Ilias", ""]]}, {"id": "1802.00396", "submitter": "Slava Jankin Mikhaylov", "authors": "Caleb Pomeroy and Niheer Dasandi and Slava J. Mikhaylov", "title": "Disunited Nations? A Multiplex Network Approach to Detecting Preference\n  Affinity Blocs using Texts and Votes", "comments": "This paper has been withdrawn by the authors. This paper has been\n  superseded by arXiv:1806.00615", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper contributes to an emerging literature that models votes and text\nin tandem to better understand polarization of expressed preferences. It\nintroduces a new approach to estimate preference polarization in\nmultidimensional settings, such as international relations, based on\ndevelopments in the natural language processing and network science literatures\n-- namely word embeddings, which retain valuable syntactical qualities of human\nlanguage, and community detection in multilayer networks, which locates densely\nconnected actors across multiple, complex networks. We find that the employment\nof these tools in tandem helps to better estimate states' foreign policy\npreferences expressed in UN votes and speeches beyond that permitted by votes\nalone. The utility of these located affinity blocs is demonstrated through an\napplication to conflict onset in International Relations, though these tools\nwill be of interest to all scholars faced with the measurement of preferences\nand polarization in multidimensional settings.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 17:08:48 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 11:50:04 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Pomeroy", "Caleb", ""], ["Dasandi", "Niheer", ""], ["Mikhaylov", "Slava J.", ""]]}, {"id": "1802.00500", "submitter": "Vladimir Ilievski Mr.", "authors": "Vladimir Ilievski, Claudiu Musat, Andreea Hossmann, Michael Baeriswyl", "title": "Goal-Oriented Chatbot Dialog Management Bootstrapping with Transfer\n  Learning", "comments": "7 pages (6 pages plus 1 page of references), 5 figures, 1 pseudocode\n  figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Goal-Oriented (GO) Dialogue Systems, colloquially known as goal oriented\nchatbots, help users achieve a predefined goal (e.g. book a movie ticket)\nwithin a closed domain. A first step is to understand the user's goal by using\nnatural language understanding techniques. Once the goal is known, the bot must\nmanage a dialogue to achieve that goal, which is conducted with respect to a\nlearnt policy. The success of the dialogue system depends on the quality of the\npolicy, which is in turn reliant on the availability of high-quality training\ndata for the policy learning method, for instance Deep Reinforcement Learning.\n  Due to the domain specificity, the amount of available data is typically too\nlow to allow the training of good dialogue policies. In this paper we introduce\na transfer learning method to mitigate the effects of the low in-domain data\navailability. Our transfer learning based approach improves the bot's success\nrate by 20% in relative terms for distant domains and we more than double it\nfor close domains, compared to the model without transfer learning. Moreover,\nthe transfer learning chatbots learn the policy up to 5 to 10 times faster.\nFinally, as the transfer learning approach is complementary to additional\nprocessing such as warm-starting, we show that their joint application gives\nthe best outcomes.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 21:50:40 GMT"}, {"version": "v2", "created": "Tue, 24 Jul 2018 19:45:11 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Ilievski", "Vladimir", ""], ["Musat", "Claudiu", ""], ["Hossmann", "Andreea", ""], ["Baeriswyl", "Michael", ""]]}, {"id": "1802.00510", "submitter": "Asim Kadav", "authors": "Daniel Li, Asim Kadav", "title": "Adaptive Memory Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Adaptive Memory Networks (AMN) that processes input-question pairs\nto dynamically construct a network architecture optimized for lower inference\ntimes for Question Answering (QA) tasks. AMN processes the input story to\nextract entities and stores them in memory banks. Starting from a single bank,\nas the number of input entities increases, AMN learns to create new banks as\nthe entropy in a single bank becomes too high. Hence, after processing an\ninput-question(s) pair, the resulting network represents a hierarchical\nstructure where entities are stored in different banks, distanced by question\nrelevance. At inference, one or few banks are used, creating a tradeoff between\naccuracy and performance. AMN is enabled by dynamic networks that allow input\ndependent network creation and efficiency in dynamic mini-batching as well as\nour novel bank controller that allows learning discrete decision making with\nhigh accuracy. In our results, we demonstrate that AMN learns to create\nvariable depth networks depending on task complexity and reduces inference\ntimes for QA tasks.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 22:33:56 GMT"}], "update_date": "2018-02-05", "authors_parsed": [["Li", "Daniel", ""], ["Kadav", "Asim", ""]]}, {"id": "1802.00757", "submitter": "Mladen Dimovski", "authors": "Mladen Dimovski, Claudiu Musat, Vladimir Ilievski, Andreea Hossmann,\n  Michael Baeriswyl", "title": "Submodularity-Inspired Data Selection for Goal-Oriented Chatbot Training\n  Based on Sentence Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spoken language understanding (SLU) systems, such as goal-oriented chatbots\nor personal assistants, rely on an initial natural language understanding (NLU)\nmodule to determine the intent and to extract the relevant information from the\nuser queries they take as input. SLU systems usually help users to solve\nproblems in relatively narrow domains and require a large amount of in-domain\ntraining data. This leads to significant data availability issues that inhibit\nthe development of successful systems. To alleviate this problem, we propose a\ntechnique of data selection in the low-data regime that enables us to train\nwith fewer labeled sentences, thus smaller labelling costs.\n  We propose a submodularity-inspired data ranking function, the ratio-penalty\nmarginal gain, for selecting data points to label based only on the information\nextracted from the textual embedding space. We show that the distances in the\nembedding space are a viable source of information that can be used for data\nselection. Our method outperforms two known active learning techniques and\nenables cost-efficient training of the NLU unit. Moreover, our proposed\nselection technique does not need the model to be retrained in between the\nselection steps, making it time efficient as well.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 16:26:39 GMT"}, {"version": "v2", "created": "Sun, 8 Jul 2018 16:27:47 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Dimovski", "Mladen", ""], ["Musat", "Claudiu", ""], ["Ilievski", "Vladimir", ""], ["Hossmann", "Andreea", ""], ["Baeriswyl", "Michael", ""]]}, {"id": "1802.00768", "submitter": "Philip Huebner", "authors": "Philip A Huebner, Jon A Willits", "title": "Order matters: Distributional properties of speech to young children\n  bootstraps learning of semantic representations", "comments": "Submitted to CogSci 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some researchers claim that language acquisition is critically dependent on\nexperiencing linguistic input in order of increasing complexity. We set out to\ntest this hypothesis using a simple recurrent neural network (SRN) trained to\npredict word sequences in CHILDES, a 5-million-word corpus of speech directed\nto children. First, we demonstrated that age-ordered CHILDES exhibits a gradual\nincrease in linguistic complexity. Next, we compared the performance of two\ngroups of SRNs trained on CHILDES which had either been age-ordered or not.\nSpecifically, we assessed learning of grammatical and semantic structure and\nshowed that training on age-ordered input facilitates learning of semantic, but\nnot of sequential structure. We found that this advantage is eliminated when\nthe models were trained on input with utterance boundary information removed.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 16:57:18 GMT"}], "update_date": "2018-02-05", "authors_parsed": [["Huebner", "Philip A", ""], ["Willits", "Jon A", ""]]}, {"id": "1802.00840", "submitter": "Andrei Amatuni", "authors": "Andrei Amatuni, Estelle He, Elika Bergelson", "title": "Preserved Structure Across Vector Space Representations", "comments": "presented at CogSci 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Certain concepts, words, and images are intuitively more similar than others\n(dog vs. cat, dog vs. spoon), though quantifying such similarity is notoriously\ndifficult. Indeed, this kind of computation is likely a critical part of\nlearning the category boundaries for words within a given language. Here, we\nuse a set of 27 items (e.g. 'dog') that are highly common in infants' input,\nand use both image- and word-based algorithms to independently compute\nsimilarity among them. We find three key results. First, the pairwise item\nsimilarities derived within image-space and word-space are correlated,\nsuggesting preserved structure among these extremely different representational\nformats. Second, the closest 'neighbors' for each item, within each space,\nshowed significant overlap (e.g. both found 'egg' as a neighbor of 'apple').\nThird, items with the most overlapping neighbors are later-learned by infants\nand toddlers. We conclude that this approach, which does not rely on human\nratings of similarity, may nevertheless reflect stable within-class structure\nacross these two spaces. We speculate that such invariance might aid lexical\nacquisition, by serving as an informative marker of category boundaries.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 20:35:36 GMT"}, {"version": "v2", "created": "Mon, 14 May 2018 21:11:13 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Amatuni", "Andrei", ""], ["He", "Estelle", ""], ["Bergelson", "Elika", ""]]}, {"id": "1802.00889", "submitter": "Rui Xia", "authors": "Zixiang Ding, Rui Xia, Jianfei Yu, Xiang Li, Jian Yang", "title": "Densely Connected Bidirectional LSTM with Applications to Sentence\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have recently been shown to achieve highly competitive\nperformance in many computer vision tasks due to their abilities of exploring\nin a much larger hypothesis space. However, since most deep architectures like\nstacked RNNs tend to suffer from the vanishing-gradient and overfitting\nproblems, their effects are still understudied in many NLP tasks. Inspired by\nthis, we propose a novel multi-layer RNN model called densely connected\nbidirectional long short-term memory (DC-Bi-LSTM) in this paper, which\nessentially represents each layer by the concatenation of its hidden state and\nall preceding layers' hidden states, followed by recursively passing each\nlayer's representation to all subsequent layers. We evaluate our proposed model\non five benchmark datasets of sentence classification. DC-Bi-LSTM with depth up\nto 20 can be successfully trained and obtain significant improvements over the\ntraditional Bi-LSTM with the same or even less parameters. Moreover, our model\nhas promising performance compared with the state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Sat, 3 Feb 2018 01:40:20 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Ding", "Zixiang", ""], ["Xia", "Rui", ""], ["Yu", "Jianfei", ""], ["Li", "Xiang", ""], ["Yang", "Jian", ""]]}, {"id": "1802.00892", "submitter": "Rui Xia", "authors": "Shiliang Zheng, Rui Xia", "title": "Left-Center-Right Separated Neural Network for Aspect-based Sentiment\n  Analysis with Rotatory Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning techniques have achieved success in aspect-based sentiment\nanalysis in recent years. However, there are two important issues that still\nremain to be further studied, i.e., 1) how to efficiently represent the target\nespecially when the target contains multiple words; 2) how to utilize the\ninteraction between target and left/right contexts to capture the most\nimportant words in them. In this paper, we propose an approach, called\nleft-center-right separated neural network with rotatory attention (LCR-Rot),\nto better address the two problems. Our approach has two characteristics: 1) it\nhas three separated LSTMs, i.e., left, center and right LSTMs, corresponding to\nthree parts of a review (left context, target phrase and right context); 2) it\nhas a rotatory attention mechanism which models the relation between target and\nleft/right contexts. The target2context attention is used to capture the most\nindicative sentiment words in left/right contexts. Subsequently, the\ncontext2target attention is used to capture the most important word in the\ntarget. This leads to a two-side representation of the target: left-aware\ntarget and right-aware target. We compare our approach on three benchmark\ndatasets with ten related methods proposed recently. The results show that our\napproach significantly outperforms the state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Sat, 3 Feb 2018 01:43:37 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Zheng", "Shiliang", ""], ["Xia", "Rui", ""]]}, {"id": "1802.00923", "submitter": "Paul Pu Liang", "authors": "Amir Zadeh, Paul Pu Liang, Soujanya Poria, Prateek Vij, Erik Cambria,\n  Louis-Philippe Morency", "title": "Multi-attention Recurrent Network for Human Communication Comprehension", "comments": "AAAI 2018 Oral Presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human face-to-face communication is a complex multimodal signal. We use words\n(language modality), gestures (vision modality) and changes in tone (acoustic\nmodality) to convey our intentions. Humans easily process and understand\nface-to-face communication, however, comprehending this form of communication\nremains a significant challenge for Artificial Intelligence (AI). AI must\nunderstand each modality and the interactions between them that shape human\ncommunication. In this paper, we present a novel neural architecture for\nunderstanding human communication called the Multi-attention Recurrent Network\n(MARN). The main strength of our model comes from discovering interactions\nbetween modalities through time using a neural component called the\nMulti-attention Block (MAB) and storing them in the hybrid memory of a\nrecurrent component called the Long-short Term Hybrid Memory (LSTHM). We\nperform extensive comparisons on six publicly available datasets for multimodal\nsentiment analysis, speaker trait recognition and emotion recognition. MARN\nshows state-of-the-art performance on all the datasets.\n", "versions": [{"version": "v1", "created": "Sat, 3 Feb 2018 06:29:17 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Zadeh", "Amir", ""], ["Liang", "Paul Pu", ""], ["Poria", "Soujanya", ""], ["Vij", "Prateek", ""], ["Cambria", "Erik", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "1802.00924", "submitter": "Paul Pu Liang", "authors": "Minghai Chen, Sen Wang, Paul Pu Liang, Tadas Baltru\\v{s}aitis, Amir\n  Zadeh, Louis-Philippe Morency", "title": "Multimodal Sentiment Analysis with Word-Level Fusion and Reinforcement\n  Learning", "comments": "ICMI 2017 Oral Presentation, Honorable Mention Award", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing popularity of video sharing websites such as YouTube and\nFacebook, multimodal sentiment analysis has received increasing attention from\nthe scientific community. Contrary to previous works in multimodal sentiment\nanalysis which focus on holistic information in speech segments such as bag of\nwords representations and average facial expression intensity, we develop a\nnovel deep architecture for multimodal sentiment analysis that performs\nmodality fusion at the word level. In this paper, we propose the Gated\nMultimodal Embedding LSTM with Temporal Attention (GME-LSTM(A)) model that is\ncomposed of 2 modules. The Gated Multimodal Embedding alleviates the\ndifficulties of fusion when there are noisy modalities. The LSTM with Temporal\nAttention performs word level fusion at a finer fusion resolution between input\nmodalities and attends to the most important time steps. As a result, the\nGME-LSTM(A) is able to better model the multimodal structure of speech through\ntime and perform better sentiment comprehension. We demonstrate the\neffectiveness of this approach on the publicly-available Multimodal Corpus of\nSentiment Intensity and Subjectivity Analysis (CMU-MOSI) dataset by achieving\nstate-of-the-art sentiment classification and regression results. Qualitative\nanalysis on our model emphasizes the importance of the Temporal Attention Layer\nin sentiment prediction because the additional acoustic and visual modalities\nare noisy. We also demonstrate the effectiveness of the Gated Multimodal\nEmbedding in selectively filtering these noisy modalities out. Our results and\nanalysis open new areas in the study of sentiment analysis in human\ncommunication and provide new models for multimodal fusion.\n", "versions": [{"version": "v1", "created": "Sat, 3 Feb 2018 06:30:09 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Chen", "Minghai", ""], ["Wang", "Sen", ""], ["Liang", "Paul Pu", ""], ["Baltru\u0161aitis", "Tadas", ""], ["Zadeh", "Amir", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "1802.00946", "submitter": "Parth Mehta", "authors": "Parth Mehta and Prasenjit Majumder", "title": "Content based Weighted Consensus Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-document summarization has received a great deal of attention in the\npast couple of decades. Several approaches have been proposed, many of which\nperform equally well and it is becoming in- creasingly difficult to choose one\nparticular system over another. An ensemble of such systems that is able to\nleverage the strengths of each individual systems can build a better and more\nrobust summary. Despite this, few attempts have been made in this direction. In\nthis paper, we describe a category of ensemble systems which use consensus\nbetween the candidate systems to build a better meta-summary. We highlight two\nmajor shortcomings of such systems: the inability to take into account relative\nperformance of individual systems and overlooking content of candidate\nsummaries in favour of the sentence rankings. We propose an alternate method,\ncontent-based weighted consensus summarization, which address these concerns.\nWe use pseudo-relevant summaries to estimate the performance of individual\ncandidate systems, and then use this information to generate a better aggregate\nranking. Experiments on DUC 2003 and DUC 2004 datasets show that the proposed\nsystem outperforms existing consensus-based techniques by a large margin.\n", "versions": [{"version": "v1", "created": "Sat, 3 Feb 2018 09:56:54 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Mehta", "Parth", ""], ["Majumder", "Prasenjit", ""]]}, {"id": "1802.01021", "submitter": "Jonathan Raiman", "authors": "Jonathan Raiman and Olivier Raiman", "title": "DeepType: Multilingual Entity Linking by Neural Type System Evolution", "comments": "Presented at AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wealth of structured (e.g. Wikidata) and unstructured data about the\nworld available today presents an incredible opportunity for tomorrow's\nArtificial Intelligence. So far, integration of these two different modalities\nis a difficult process, involving many decisions concerning how best to\nrepresent the information so that it will be captured or useful, and\nhand-labeling large amounts of data. DeepType overcomes this challenge by\nexplicitly integrating symbolic information into the reasoning process of a\nneural network with a type system. First we construct a type system, and\nsecond, we use it to constrain the outputs of a neural network to respect the\nsymbolic structure. We achieve this by reformulating the design problem into a\nmixed integer problem: create a type system and subsequently train a neural\nnetwork with it. In this reformulation discrete variables select which\nparent-child relations from an ontology are types within the type system, while\ncontinuous variables control a classifier fit to the type system. The original\nproblem cannot be solved exactly, so we propose a 2-step algorithm: 1)\nheuristic search or stochastic optimization over discrete variables that define\na type system informed by an Oracle and a Learnability heuristic, 2) gradient\ndescent to fit classifier parameters. We apply DeepType to the problem of\nEntity Linking on three standard datasets (i.e. WikiDisamb30, CoNLL (YAGO), TAC\nKBP 2010) and find that it outperforms all existing solutions by a wide margin,\nincluding approaches that rely on a human-designed type system or recent deep\nlearning-based entity embeddings, while explicitly using symbolic information\nlets it integrate new entities without retraining.\n", "versions": [{"version": "v1", "created": "Sat, 3 Feb 2018 20:13:42 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Raiman", "Jonathan", ""], ["Raiman", "Olivier", ""]]}, {"id": "1802.01074", "submitter": "Minh C. Phan", "authors": "Minh C. Phan and Aixin Sun and Yi Tay and Jialong Han and Chenliang Li", "title": "Pair-Linking for Collective Entity Disambiguation: Two Could Be Better\n  Than All", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collective entity disambiguation aims to jointly resolve multiple mentions by\nlinking them to their associated entities in a knowledge base. Previous works\nare primarily based on the underlying assumption that entities within the same\ndocument are highly related. However, the extend to which these mentioned\nentities are actually connected in reality is rarely studied and therefore\nraises interesting research questions. For the first time, we show that the\nsemantic relationships between the mentioned entities are in fact less dense\nthan expected. This could be attributed to several reasons such as noise, data\nsparsity and knowledge base incompleteness. As a remedy, we introduce MINTREE,\na new tree-based objective for the entity disambiguation problem. The key\nintuition behind MINTREE is the concept of coherence relaxation which utilizes\nthe weight of a minimum spanning tree to measure the coherence between\nentities. Based on this new objective, we design a novel entity disambiguation\nalgorithms which we call Pair-Linking. Instead of considering all the given\nmentions, Pair-Linking iteratively selects a pair with the highest confidence\nat each step for decision making. Via extensive experiments, we show that our\napproach is not only more accurate but also surprisingly faster than many\nstate-of-the-art collective linking algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 4 Feb 2018 05:50:39 GMT"}, {"version": "v2", "created": "Sat, 7 Jul 2018 21:17:33 GMT"}, {"version": "v3", "created": "Mon, 16 Jul 2018 05:24:37 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Phan", "Minh C.", ""], ["Sun", "Aixin", ""], ["Tay", "Yi", ""], ["Han", "Jialong", ""], ["Li", "Chenliang", ""]]}, {"id": "1802.01191", "submitter": "Matti Wiegmann", "authors": "Matti Wiegmann and Michael V\\\"olske and Benno Stein and Matthias Hagen\n  and Martin Potthast", "title": "Heuristic Feature Selection for Clickbait Detection", "comments": "Clickbait Challenge 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study feature selection as a means to optimize the baseline clickbait\ndetector employed at the Clickbait Challenge 2017. The challenge's task is to\nscore the \"clickbaitiness\" of a given Twitter tweet on a scale from 0 (no\nclickbait) to 1 (strong clickbait). Unlike most other approaches submitted to\nthe challenge, the baseline approach is based on manual feature engineering and\ndoes not compete out of the box with many of the deep learning-based\napproaches. We show that scaling up feature selection efforts to heuristically\nidentify better-performing feature subsets catapults the performance of the\nbaseline classifier to second rank overall, beating 12 other competing\napproaches and improving over the baseline performance by 20%. This\ndemonstrates that traditional classification approaches can still keep up with\ndeep learning on this task.\n", "versions": [{"version": "v1", "created": "Sun, 4 Feb 2018 20:45:20 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Wiegmann", "Matti", ""], ["V\u00f6lske", "Michael", ""], ["Stein", "Benno", ""], ["Hagen", "Matthias", ""], ["Potthast", "Martin", ""]]}, {"id": "1802.01241", "submitter": "Gabriel Grand", "authors": "Gabriel Grand, Idan Asher Blank, Francisco Pereira and Evelina\n  Fedorenko", "title": "Semantic projection: recovering human knowledge of multiple, distinct\n  object features from word embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The words of a language reflect the structure of the human mind, allowing us\nto transmit thoughts between individuals. However, language can represent only\na subset of our rich and detailed cognitive architecture. Here, we ask what\nkinds of common knowledge (semantic memory) are captured by word meanings\n(lexical semantics). We examine a prominent computational model that represents\nwords as vectors in a multidimensional space, such that proximity between\nword-vectors approximates semantic relatedness. Because related words appear in\nsimilar contexts, such spaces - called \"word embeddings\" - can be learned from\npatterns of lexical co-occurrences in natural language. Despite their\npopularity, a fundamental concern about word embeddings is that they appear to\nbe semantically \"rigid\": inter-word proximity captures only overall similarity,\nyet human judgments about object similarities are highly context-dependent and\ninvolve multiple, distinct semantic features. For example, dolphins and\nalligators appear similar in size, but differ in intelligence and\naggressiveness. Could such context-dependent relationships be recovered from\nword embeddings? To address this issue, we introduce a powerful, domain-general\nsolution: \"semantic projection\" of word-vectors onto lines that represent\nvarious object features, like size (the line extending from the word \"small\" to\n\"big\"), intelligence (from \"dumb\" to \"smart\"), or danger (from \"safe\" to\n\"dangerous\"). This method, which is intuitively analogous to placing objects\n\"on a mental scale\" between two extremes, recovers human judgments across a\nrange of object categories and properties. We thus show that word embeddings\ninherit a wealth of common knowledge from word co-occurrence statistics and can\nbe flexibly manipulated to express context-dependent meanings.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 02:42:40 GMT"}, {"version": "v2", "created": "Tue, 6 Mar 2018 06:15:46 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Grand", "Gabriel", ""], ["Blank", "Idan Asher", ""], ["Pereira", "Francisco", ""], ["Fedorenko", "Evelina", ""]]}, {"id": "1802.01255", "submitter": "Yifan Peng", "authors": "Yifan Peng, Anthony Rios, Ramakanth Kavuluru, Zhiyong Lu", "title": "Chemical-protein relation extraction with ensembles of SVM, CNN, and RNN\n  models", "comments": "Accepted in Proceedings of the BioCreative VI Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text mining the relations between chemicals and proteins is an increasingly\nimportant task. The CHEMPROT track at BioCreative VI aims to promote the\ndevelopment and evaluation of systems that can automatically detect the\nchemical-protein relations in running text (PubMed abstracts). This manuscript\ndescribes our submission, which is an ensemble of three systems, including a\nSupport Vector Machine, a Convolutional Neural Network, and a Recurrent Neural\nNetwork. Their output is combined using a decision based on majority voting or\nstacking. Our CHEMPROT system obtained 0.7266 in precision and 0.5735 in recall\nfor an f-score of 0.6410, demonstrating the effectiveness of machine\nlearning-based approaches for automatic relation extraction from biomedical\nliterature. Our submission achieved the highest performance in the task during\nthe 2017 challenge.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 03:42:36 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Peng", "Yifan", ""], ["Rios", "Anthony", ""], ["Kavuluru", "Ramakanth", ""], ["Lu", "Zhiyong", ""]]}, {"id": "1802.01345", "submitter": "Jingjing Xu", "authors": "Jingjing Xu, Xuancheng Ren, Junyang Lin, Xu Sun", "title": "DP-GAN: Diversity-Promoting Generative Adversarial Network for\n  Generating Informative and Diversified Text", "comments": "Accepted by EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing text generation methods tend to produce repeated and \"boring\"\nexpressions. To tackle this problem, we propose a new text generation model,\ncalled Diversity-Promoting Generative Adversarial Network (DP-GAN). The\nproposed model assigns low reward for repeatedly generated text and high reward\nfor \"novel\" and fluent text, encouraging the generator to produce diverse and\ninformative text. Moreover, we propose a novel language-model based\ndiscriminator, which can better distinguish novel text from repeated text\nwithout the saturation problem compared with existing classifier-based\ndiscriminators. The experimental results on review generation and dialogue\ngeneration tasks demonstrate that our model can generate substantially more\ndiverse and informative text than existing baselines. The code is available at\nhttps://github.com/lancopku/DPGAN\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 10:54:29 GMT"}, {"version": "v2", "created": "Tue, 6 Feb 2018 01:59:08 GMT"}, {"version": "v3", "created": "Tue, 21 Aug 2018 13:19:07 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Xu", "Jingjing", ""], ["Ren", "Xuancheng", ""], ["Lin", "Junyang", ""], ["Sun", "Xu", ""]]}, {"id": "1802.01405", "submitter": "Guozhen An", "authors": "Guozhen An, Rivka Levitan", "title": "Comparing approaches for mitigating intergroup variability in\n  personality recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personality have been found to predict many life outcomes, and there have\nbeen huge interests on automatic personality recognition from a speaker's\nutterance. Previously, we achieved accuracies between 37%-44% for three-way\nclassification of high, medium or low for each of the Big Five personality\ntraits (Openness to Experience, Conscientiousness, Extraversion, Agreeableness,\nNeuroticism). We show here that we can improve performance on this task by\naccounting for heterogeneity of gender and L1 in our data, which has English\nspeech from female and male native speakers of Chinese and Standard American\nEnglish (SAE). We experiment with personalizing models by L1 and gender and\nnormalizing features by speaker, L1 group, and/or gender.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 22:18:56 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["An", "Guozhen", ""], ["Levitan", "Rivka", ""]]}, {"id": "1802.01429", "submitter": "Jean-Baptiste Camps", "authors": "Jean-Baptiste Camps (CJM (EA 3624))", "title": "Manuscripts in Time and Space: Experiments in Scriptometrics on an Old\n  French Corpus", "comments": "Andrew U. Frank; Christine Ivanovic; Francesco Mambrini; Marco\n  Passarotti; Caroline Sporleder. Corpus-Based Research in the Humanities\n  CRH-2, Jan 2018, Vienna, Austria. Available, online:\n  https://www.oeaw.ac.at/fileadmin/subsites/academiaecorpora/PDF/CRH2.pdf", "journal-ref": "Proceedings of the Second Workshop on Corpus-Based Research in the\n  Humanities CRH-2, 25-26 January 2018, Vienna, Austria, pp.55-64, 2018", "doi": "10.5281/zenodo.1117924", "report-no": null, "categories": "cs.CL stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Witnesses of medieval literary texts, preserved in manuscript, are layered\nobjects , being almost exclusively copies of copies. This results in multiple\nand hard to distinguish linguistic strata -- the author's scripta interacting\nwith the scriptae of the various scribes -- in a context where literary written\nlanguage is already a dialectal hybrid. Moreover, no single linguistic\nphenomenon allows to distinguish between different scriptae, and only the\ncombination of multiple characteristics is likely to be significant [9] -- but\nwhich ones? The most common approach is to search for these features in a set\nof previously selected texts, that are supposed to be representative of a given\nscripta. This can induce a circularity, in which texts are used to select\nfeatures that in turn characterise them as belonging to a linguistic area. To\ncounter this issue, this paper offers an unsupervised and corpus-based\napproach, in which clustering methods are applied to an Old French corpus to\nidentify main divisions and groups. Ultimately, scriptometric profiles are\nbuilt for each of them.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 09:07:05 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Camps", "Jean-Baptiste", "", "CJM"]]}, {"id": "1802.01433", "submitter": "Haonan Yu", "authors": "Haonan Yu, Haichao Zhang, Wei Xu", "title": "Interactive Grounded Language Acquisition and Generalization in a 2D\n  World", "comments": "ICLR 2018 (Figure 6 caption improved)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We build a virtual agent for learning language in a 2D maze-like world. The\nagent sees images of the surrounding environment, listens to a virtual teacher,\nand takes actions to receive rewards. It interactively learns the teacher's\nlanguage from scratch based on two language use cases: sentence-directed\nnavigation and question answering. It learns simultaneously the visual\nrepresentations of the world, the language, and the action control. By\ndisentangling language grounding from other computational routines and sharing\na concept detection function between language grounding and prediction, the\nagent reliably interpolates and extrapolates to interpret sentences that\ncontain new word combinations or new words missing from training sentences. The\nnew words are transferred from the answers of language prediction. Such a\nlanguage ability is trained and evaluated on a population of over 1.6 million\ndistinct sentences consisting of 119 object words, 8 color words, 9\nspatial-relation words, and 50 grammatical words. The proposed model\nsignificantly outperforms five comparison methods for interpreting zero-shot\nsentences. In addition, we demonstrate human-interpretable intermediate outputs\nof the model in the appendix.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 01:35:46 GMT"}, {"version": "v2", "created": "Wed, 21 Feb 2018 22:03:27 GMT"}, {"version": "v3", "created": "Tue, 24 Apr 2018 19:36:51 GMT"}, {"version": "v4", "created": "Mon, 13 Aug 2018 23:29:31 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Yu", "Haonan", ""], ["Zhang", "Haichao", ""], ["Xu", "Wei", ""]]}, {"id": "1802.01451", "submitter": "Filip Klubicka", "authors": "Filip Klubi\\v{c}ka, Antonio Toral, V\\'ictor M. S\\'anchez-Cartagena", "title": "Quantitative Fine-Grained Human Evaluation of Machine Translation\n  Systems: a Case Study on English to Croatian", "comments": "22 pages, 2 figures, 9 tables, 1 equation. This is a\n  post-peer-review, pre-copyedit version of an article published in Machine\n  Translation Journal. The final authenticated version will be available online\n  at the journal page. arXiv admin note: substantial text overlap with\n  arXiv:1706.04389", "journal-ref": "Machine Translation, pp 1-21, (2018), http://rdcu.be/GIkb", "doi": "10.1007/s10590-018-9214-x", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a quantitative fine-grained manual evaluation approach to\ncomparing the performance of different machine translation (MT) systems. We\nbuild upon the well-established Multidimensional Quality Metrics (MQM) error\ntaxonomy and implement a novel method that assesses whether the differences in\nperformance for MQM error types between different MT systems are statistically\nsignificant. We conduct a case study for English-to-Croatian, a language\ndirection that involves translating into a morphologically rich language, for\nwhich we compare three MT systems belonging to different paradigms: pure\nphrase-based, factored phrase-based and neural. First, we design an\nMQM-compliant error taxonomy tailored to the relevant linguistic phenomena of\nSlavic languages, which made the annotation process feasible and accurate.\nErrors in MT outputs were then annotated by two annotators following this\ntaxonomy. Subsequently, we carried out a statistical analysis which showed that\nthe best-performing system (neural) reduces the errors produced by the worst\nsystem (pure phrase-based) by more than half (54\\%). Moreover, we conducted an\nadditional analysis of agreement errors in which we distinguished between short\n(phrase-level) and long distance (sentence-level) errors. We discovered that\nphrase-based MT approaches are of limited use for long distance agreement\nphenomena, for which neural MT was found to be especially effective.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 14:41:08 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Klubi\u010dka", "Filip", ""], ["Toral", "Antonio", ""], ["S\u00e1nchez-Cartagena", "V\u00edctor M.", ""]]}, {"id": "1802.01457", "submitter": "Andr\\'e Cibils", "authors": "Andr\\'e Cibils, Claudiu Musat, Andreea Hossman, Michael Baeriswyl", "title": "Diverse Beam Search for Increased Novelty in Abstractive Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text summarization condenses a text to a shorter version while retaining the\nimportant informations. Abstractive summarization is a recent development that\ngenerates new phrases, rather than simply copying or rephrasing sentences\nwithin the original text. Recently neural sequence-to-sequence models have\nachieved good results in the field of abstractive summarization, which opens\nnew possibilities and applications for industrial purposes. However, most\npractitioners observe that these models still use large parts of the original\ntext in the output summaries, making them often similar to extractive\nframeworks. To address this drawback, we first introduce a new metric to\nmeasure how much of a summary is extracted from the input text. Secondly, we\npresent a novel method, that relies on a diversity factor in computing the\nneural network loss, to improve the diversity of the summaries generated by any\nneural abstractive model implementing beam search. Finally, we show that this\nmethod not only makes the system less extractive, but also improves the overall\nrouge score of state-of-the-art methods by at least 2 points.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 15:17:01 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Cibils", "Andr\u00e9", ""], ["Musat", "Claudiu", ""], ["Hossman", "Andreea", ""], ["Baeriswyl", "Michael", ""]]}, {"id": "1802.01766", "submitter": "Girish Kumar", "authors": "Girish Kumar, Matthew Henderson, Shannon Chan, Hoang Nguyen, Lucas\n  Ngoo", "title": "Question-Answer Selection in User to User Marketplace Conversations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sellers in user to user marketplaces can be inundated with questions from\npotential buyers. Answers are often already available in the product\ndescription. We collected a dataset of around 590K such questions and answers\nfrom conversations in an online marketplace. We propose a question answering\nsystem that selects a sentence from the product description using a\nneural-network ranking model. We explore multiple encoding strategies, with\nrecurrent neural networks and feed-forward attention layers yielding good\nresults. This paper presents a demo to interactively pose buyer questions and\nvisualize the ranking scores of product description sentences from live online\nlistings.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 02:39:54 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Kumar", "Girish", ""], ["Henderson", "Matthew", ""], ["Chan", "Shannon", ""], ["Nguyen", "Hoang", ""], ["Ngoo", "Lucas", ""]]}, {"id": "1802.01786", "submitter": "Amir Karami", "authors": "Amir Karami, London S. Bennett, Xiaoyun He", "title": "Mining Public Opinion about Economic Issues: Twitter and the U.S.\n  Presidential Election", "comments": null, "journal-ref": null, "doi": "10.4018/IJSDS.2018010102", "report-no": null, "categories": "cs.SI cs.CL cs.IR stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Opinion polls have been the bridge between public opinion and politicians in\nelections. However, developing surveys to disclose people's feedback with\nrespect to economic issues is limited, expensive, and time-consuming. In recent\nyears, social media such as Twitter has enabled people to share their opinions\nregarding elections. Social media has provided a platform for collecting a\nlarge amount of social media data. This paper proposes a computational public\nopinion mining approach to explore the discussion of economic issues in social\nmedia during an election. Current related studies use text mining methods\nindependently for election analysis and election prediction; this research\ncombines two text mining methods: sentiment analysis and topic modeling. The\nproposed approach has effectively been deployed on millions of tweets to\nanalyze economic concerns of people during the 2012 US presidential election.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 03:55:37 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Karami", "Amir", ""], ["Bennett", "London S.", ""], ["He", "Xiaoyun", ""]]}, {"id": "1802.01812", "submitter": "Shuming Ma", "authors": "Junyang Lin, Shuming Ma, Qi Su, Xu Sun", "title": "Decoding-History-Based Adaptive Control of Attention for Neural Machine\n  Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based sequence-to-sequence model has proved successful in Neural\nMachine Translation (NMT). However, the attention without consideration of\ndecoding history, which includes the past information in the decoder and the\nattention mechanism, often causes much repetition. To address this problem, we\npropose the decoding-history-based Adaptive Control of Attention (ACA) for the\nNMT model. ACA learns to control the attention by keeping track of the decoding\nhistory and the current information with a memory vector, so that the model can\ntake the translated contents and the current information into consideration.\nExperiments on Chinese-English translation and the English-Vietnamese\ntranslation have demonstrated that our model significantly outperforms the\nstrong baselines. The analysis shows that our model is capable of generating\ntranslation with less repetition and higher accuracy. The code will be\navailable at https://github.com/lancopku\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 06:18:56 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Lin", "Junyang", ""], ["Ma", "Shuming", ""], ["Su", "Qi", ""], ["Sun", "Xu", ""]]}, {"id": "1802.01817", "submitter": "Xiang Zhang", "authors": "Xiang Zhang, Yann LeCun", "title": "Byte-Level Recursive Convolutional Auto-Encoder for Text", "comments": "Rejected from ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article proposes to auto-encode text at byte-level using convolutional\nnetworks with a recursive architecture. The motivation is to explore whether it\nis possible to have scalable and homogeneous text generation at byte-level in a\nnon-sequential fashion through the simple task of auto-encoding. We show that\nnon-sequential text generation from a fixed-length representation is not only\npossible, but also achieved much better auto-encoding results than recurrent\nnetworks. The proposed model is a multi-stage deep convolutional\nencoder-decoder framework using residual connections, containing up to 160\nparameterized layers. Each encoder or decoder contains a shared group of\nmodules that consists of either pooling or upsampling layers, making the\nnetwork recursive in terms of abstraction levels in representation. Results for\n6 large-scale paragraph datasets are reported, in 3 languages including Arabic,\nChinese and English. Analyses are conducted to study several properties of the\nproposed model.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 06:47:09 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Zhang", "Xiang", ""], ["LeCun", "Yann", ""]]}, {"id": "1802.01830", "submitter": "Akira Utsumi", "authors": "Akira Utsumi", "title": "A Neurobiologically Motivated Analysis of Distributional Semantic Models", "comments": "submitted to CogSci 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pervasive use of distributional semantic models or word embeddings in a\nvariety of research fields is due to their remarkable ability to represent the\nmeanings of words for both practical application and cognitive modeling.\nHowever, little has been known about what kind of information is encoded in\ntext-based word vectors. This lack of understanding is particularly problematic\nwhen word vectors are regarded as a model of semantic representation for\nabstract concepts. This paper attempts to reveal the internal information of\ndistributional word vectors by the analysis using Binder et al.'s (2016)\nbrain-based vectors, explicitly structured conceptual representations based on\nneurobiologically motivated attributes. In the analysis, the mapping from\ntext-based vectors to brain-based vectors is trained and prediction performance\nis evaluated by comparing the estimated and original brain-based vectors. The\nanalysis demonstrates that social and cognitive information is better encoded\nin text-based word vectors, but emotional information is not. This result is\ndiscussed in terms of embodied theories for abstract concepts.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 07:41:14 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Utsumi", "Akira", ""]]}, {"id": "1802.01886", "submitter": "Weinan Zhang", "authors": "Yaoming Zhu, Sidi Lu, Lei Zheng, Jiaxian Guo, Weinan Zhang, Jun Wang,\n  Yong Yu", "title": "Texygen: A Benchmarking Platform for Text Generation Models", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce Texygen, a benchmarking platform to support research on\nopen-domain text generation models. Texygen has not only implemented a majority\nof text generation models, but also covered a set of metrics that evaluate the\ndiversity, the quality and the consistency of the generated texts. The Texygen\nplatform could help standardize the research on text generation and facilitate\nthe sharing of fine-tuned open-source implementations among researchers for\ntheir work. As a consequence, this would help in improving the reproductivity\nand reliability of future research work in text generation.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 11:30:32 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Zhu", "Yaoming", ""], ["Lu", "Sidi", ""], ["Zheng", "Lei", ""], ["Guo", "Jiaxian", ""], ["Zhang", "Weinan", ""], ["Wang", "Jun", ""], ["Yu", "Yong", ""]]}, {"id": "1802.02032", "submitter": "Hui Su", "authors": "Xiaoyu Shen, Hui Su, Shuzi Niu and Vera Demberg", "title": "Improving Variational Encoder-Decoders in Dialogue Generation", "comments": "Accepted by AAAI2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational encoder-decoders (VEDs) have shown promising results in dialogue\ngeneration. However, the latent variable distributions are usually approximated\nby a much simpler model than the powerful RNN structure used for encoding and\ndecoding, yielding the KL-vanishing problem and inconsistent training\nobjective. In this paper, we separate the training step into two phases: The\nfirst phase learns to autoencode discrete texts into continuous embeddings,\nfrom which the second phase learns to generalize latent representations by\nreconstructing the encoded embedding. In this case, latent variables are\nsampled by transforming Gaussian noise through multi-layer perceptrons and are\ntrained with a separate VED model, which has the potential of realizing a much\nmore flexible distribution. We compare our model with current popular models\nand the experiment demonstrates substantial improvement in both metric-based\nand human evaluations.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 16:19:05 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Shen", "Xiaoyu", ""], ["Su", "Hui", ""], ["Niu", "Shuzi", ""], ["Demberg", "Vera", ""]]}, {"id": "1802.02053", "submitter": "Marwa Hadj Salah", "authors": "Marwa Hadj Salah, Didier Schwab, Herv\\'e Blanchon and Mounir Zrigui", "title": "Syst\\`eme de traduction automatique statistique Anglais-Arabe", "comments": "in French", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine translation (MT) is the process of translating text written in a\nsource language into text in a target language. In this article, we present our\nEnglish-Arabic statistical machine translation system. First, we present the\ngeneral process for setting up a statistical machine translation system, then\nwe describe the tools as well as the different corpora we used to build our MT\nsystem. Our system was evaluated in terms of the BLUE score (24.51%)\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 16:36:44 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Salah", "Marwa Hadj", ""], ["Schwab", "Didier", ""], ["Blanchon", "Herv\u00e9", ""], ["Zrigui", "Mounir", ""]]}, {"id": "1802.02114", "submitter": "Peng Xu", "authors": "Peng Xu, and Denilson Barbosa", "title": "Investigations on Knowledge Base Embedding for Relation Prediction and\n  Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report an evaluation of the effectiveness of the existing knowledge base\nembedding models for relation prediction and for relation extraction on a wide\nrange of benchmarks. We also describe a new benchmark, which is much larger and\ncomplex than previous ones, which we introduce to help validate the\neffectiveness of both tasks. The results demonstrate that knowledge base\nembedding models are generally effective for relation prediction but unable to\ngive improvements for the state-of-art neural relation extraction model with\nthe existing strategies, while pointing limitations of existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 18:20:17 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Xu", "Peng", ""], ["Barbosa", "Denilson", ""]]}, {"id": "1802.02116", "submitter": "Matteo Grella", "authors": "Matteo Grella and Simone Cangialosi", "title": "Non-Projective Dependency Parsing via Latent Heads Representation (LHR)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a novel approach based on a bidirectional\nrecurrent autoencoder to perform globally optimized non-projective dependency\nparsing via semi-supervised learning. The syntactic analysis is completed at\nthe end of the neural process that generates a Latent Heads Representation\n(LHR), without any algorithmic constraint and with a linear complexity. The\nresulting \"latent syntactic structure\" can be used directly in other semantic\ntasks. The LHR is transformed into the usual dependency tree computing a simple\nvectors similarity. We believe that our model has the potential to compete with\nmuch more complex state-of-the-art parsing architectures.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 18:28:45 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Grella", "Matteo", ""], ["Cangialosi", "Simone", ""]]}, {"id": "1802.02163", "submitter": "Brandon Stewart", "authors": "Naoki Egami, Christian J. Fong, Justin Grimmer, Margaret E. Roberts,\n  Brandon M. Stewart", "title": "How to Make Causal Inferences Using Texts", "comments": "47 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New text as data techniques offer a great promise: the ability to inductively\ndiscover measures that are useful for testing social science theories of\ninterest from large collections of text. We introduce a conceptual framework\nfor making causal inferences with discovered measures as a treatment or\noutcome. Our framework enables researchers to discover high-dimensional textual\ninterventions and estimate the ways that observed treatments affect text-based\noutcomes. We argue that nearly all text-based causal inferences depend upon a\nlatent representation of the text and we provide a framework to learn the\nlatent representation. But estimating this latent representation, we show,\ncreates new risks: we may introduce an identification problem or overfit. To\naddress these risks we describe a split-sample framework and apply it to\nestimate causal effects from an experiment on immigration attitudes and a study\non bureaucratic response. Our work provides a rigorous foundation for\ntext-based causal inferences.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 19:00:12 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Egami", "Naoki", ""], ["Fong", "Christian J.", ""], ["Grimmer", "Justin", ""], ["Roberts", "Margaret E.", ""], ["Stewart", "Brandon M.", ""]]}, {"id": "1802.02311", "submitter": "Jinmiao Huang", "authors": "Jinmiao Huang, Cesar Osorio, Luke Wicent Sy", "title": "An Empirical Evaluation of Deep Learning for ICD-9 Code Assignment using\n  MIMIC-III Clinical Notes", "comments": null, "journal-ref": null, "doi": "10.1016/j.cmpb.2019.05.024", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background and Objective: Code assignment is of paramount importance in many\nlevels in modern hospitals, from ensuring accurate billing process to creating\na valid record of patient care history. However, the coding process is tedious\nand subjective, and it requires medical coders with extensive training. This\nstudy aims to evaluate the performance of deep-learning-based systems to\nautomatically map clinical notes to ICD-9 medical codes. Methods: The\nevaluations of this research are focused on end-to-end learning methods without\nmanually defined rules. Traditional machine learning algorithms, as well as\nstate-of-the-art deep learning methods such as Recurrent Neural Networks and\nConvolution Neural Networks, were applied to the Medical Information Mart for\nIntensive Care (MIMIC-III) dataset. An extensive number of experiments was\napplied to different settings of the tested algorithm. Results: Findings showed\nthat the deep learning-based methods outperformed other conventional machine\nlearning methods. From our assessment, the best models could predict the top 10\nICD-9 codes with 0.6957 F1 and 0.8967 accuracy and could estimate the top 10\nICD-9 categories with 0.7233 F1 and 0.8588 accuracy. Our implementation also\noutperformed existing work under certain evaluation metrics. Conclusion: A set\nof standard metrics was utilized in assessing the performance of ICD-9 code\nassignment on MIMIC-III dataset. All the developed evaluation tools and\nresources are available online, which can be used as a baseline for further\nresearch.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 05:23:21 GMT"}, {"version": "v2", "created": "Sat, 8 Jun 2019 16:35:12 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Huang", "Jinmiao", ""], ["Osorio", "Cesar", ""], ["Sy", "Luke Wicent", ""]]}, {"id": "1802.02550", "submitter": "Yoon Kim", "authors": "Yoon Kim, Sam Wiseman, Andrew C. Miller, David Sontag, Alexander M.\n  Rush", "title": "Semi-Amortized Variational Autoencoders", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Amortized variational inference (AVI) replaces instance-specific local\ninference with a global inference network. While AVI has enabled efficient\ntraining of deep generative models such as variational autoencoders (VAE),\nrecent empirical work suggests that inference networks can produce suboptimal\nvariational parameters. We propose a hybrid approach, to use AVI to initialize\nthe variational parameters and run stochastic variational inference (SVI) to\nrefine them. Crucially, the local SVI procedure is itself differentiable, so\nthe inference network and generative model can be trained end-to-end with\ngradient-based optimization. This semi-amortized approach enables the use of\nrich generative models without experiencing the posterior-collapse phenomenon\ncommon in training VAEs for problems like text generation. Experiments show\nthis approach outperforms strong autoregressive and variational baselines on\nstandard text and image datasets.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 18:06:42 GMT"}, {"version": "v2", "created": "Sun, 25 Feb 2018 17:02:04 GMT"}, {"version": "v3", "created": "Mon, 12 Mar 2018 05:18:57 GMT"}, {"version": "v4", "created": "Mon, 26 Mar 2018 17:05:42 GMT"}, {"version": "v5", "created": "Thu, 24 May 2018 20:06:49 GMT"}, {"version": "v6", "created": "Fri, 8 Jun 2018 21:17:42 GMT"}, {"version": "v7", "created": "Mon, 23 Jul 2018 19:31:28 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Kim", "Yoon", ""], ["Wiseman", "Sam", ""], ["Miller", "Andrew C.", ""], ["Sontag", "David", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1802.02561", "submitter": "Hamza Harkous", "authors": "Hamza Harkous, Kassem Fawaz, R\\'emi Lebret, Florian Schaub, Kang G.\n  Shin, Karl Aberer", "title": "Polisis: Automated Analysis and Presentation of Privacy Policies Using\n  Deep Learning", "comments": "Published at USENIX Security 2018; associated website:\n  https://pribot.org", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy policies are the primary channel through which companies inform users\nabout their data collection and sharing practices. These policies are often\nlong and difficult to comprehend. Short notices based on information extracted\nfrom privacy policies have been shown to be useful but face a significant\nscalability hurdle, given the number of policies and their evolution over time.\nCompanies, users, researchers, and regulators still lack usable and scalable\ntools to cope with the breadth and depth of privacy policies. To address these\nhurdles, we propose an automated framework for privacy policy analysis\n(Polisis). It enables scalable, dynamic, and multi-dimensional queries on\nnatural language privacy policies. At the core of Polisis is a privacy-centric\nlanguage model, built with 130K privacy policies, and a novel hierarchy of\nneural-network classifiers that accounts for both high-level aspects and\nfine-grained details of privacy practices. We demonstrate Polisis' modularity\nand utility with two applications supporting structured and free-form querying.\nThe structured querying application is the automated assignment of privacy\nicons from privacy policies. With Polisis, we can achieve an accuracy of 88.4%\non this task. The second application, PriBot, is the first freeform\nquestion-answering system for privacy policies. We show that PriBot can produce\na correct answer among its top-3 results for 82% of the test questions. Using\nan MTurk user study with 700 participants, we show that at least one of\nPriBot's top-3 answers is relevant to users for 89% of the test questions.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 18:36:38 GMT"}, {"version": "v2", "created": "Fri, 29 Jun 2018 09:27:17 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Harkous", "Hamza", ""], ["Fawaz", "Kassem", ""], ["Lebret", "R\u00e9mi", ""], ["Schaub", "Florian", ""], ["Shin", "Kang G.", ""], ["Aberer", "Karl", ""]]}, {"id": "1802.02605", "submitter": "Jean-Fran\\c{c}ois Delpech", "authors": "Jean-Fran\\c{c}ois Delpech", "title": "Unsupervised word sense disambiguation in dynamic semantic spaces", "comments": "7 pages, 1 table, 5 examples", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we are mainly concerned with the ability to quickly and\nautomatically distinguish word senses in dynamic semantic spaces in which new\nterms and new senses appear frequently. Such spaces are built '\"on the fly\"\nfrom constantly evolving data sets such as Wikipedia, repositories of patent\ngrants and applications, or large sets of legal documents for Technology\nAssisted Review and e-discovery. This immediacy rules out supervision as well\nas the use of a priori training sets. We show that the various senses of a term\ncan be automatically made apparent with a simple clustering algorithm, each\nsense being a vector in the semantic space. While we only consider here\nsemantic spaces built by using random vectors, this algorithm should work with\nany kind of embedding, provided meaningful similarities between terms can be\ncomputed and do fulfill at least the two basic conditions that terms which\nclose meanings have high similarities and terms with unrelated meanings have\nnear-zero similarities.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 19:27:27 GMT"}, {"version": "v2", "created": "Fri, 16 Feb 2018 13:58:10 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Delpech", "Jean-Fran\u00e7ois", ""]]}, {"id": "1802.02607", "submitter": "Panayiotis Georgiou", "authors": "Prashanth Gurunath Shivakumar, Haoqi Li, Kevin Knight, Panayiotis\n  Georgiou", "title": "Learning from Past Mistakes: Improving Automatic Speech Recognition\n  Output via Noisy-Clean Phrase Context Modeling", "comments": null, "journal-ref": "APSIPA Transactions on Signal and Information Processing 8.\n  Cambridge University Press: e8, 2019", "doi": "10.1017/ATSIP.2018.31", "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic speech recognition (ASR) systems often make unrecoverable errors\ndue to subsystem pruning (acoustic, language and pronunciation models); for\nexample pruning words due to acoustics using short-term context, prior to\nrescoring with long-term context based on linguistics. In this work we model\nASR as a phrase-based noisy transformation channel and propose an error\ncorrection system that can learn from the aggregate errors of all the\nindependent modules constituting the ASR and attempt to invert those. The\nproposed system can exploit long-term context using a neural network language\nmodel and can better choose between existing ASR output possibilities as well\nas re-introduce previously pruned or unseen (out-of-vocabulary) phrases. It\nprovides corrections under poorly performing ASR conditions without degrading\nany accurate transcriptions; such corrections are greater on top of\nout-of-domain and mismatched data ASR. Our system consistently provides\nimprovements over the baseline ASR, even when baseline is further optimized\nthrough recurrent neural network language model rescoring. This demonstrates\nthat any ASR improvements can be exploited independently and that our proposed\nsystem can potentially still provide benefits on highly optimized ASR. Finally,\nwe present an extensive analysis of the type of errors corrected by our system.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 19:30:17 GMT"}, {"version": "v2", "created": "Thu, 28 Mar 2019 23:28:46 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Shivakumar", "Prashanth Gurunath", ""], ["Li", "Haoqi", ""], ["Knight", "Kevin", ""], ["Georgiou", "Panayiotis", ""]]}, {"id": "1802.02614", "submitter": "Jianxiong Dong", "authors": "Jianxiong Dong, Jim Huang", "title": "Enhance word representation for out-of-vocabulary on Ubuntu dialogue\n  corpus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ubuntu dialogue corpus is the largest public available dialogue corpus to\nmake it feasible to build end-to-end deep neural network models directly from\nthe conversation data. One challenge of Ubuntu dialogue corpus is the large\nnumber of out-of-vocabulary words. In this paper we proposed a method which\ncombines the general pre-trained word embedding vectors with those generated on\nthe task-specific training set to address this issue. We integrated character\nembedding into Chen et al's Enhanced LSTM method (ESIM) and used it to evaluate\nthe effectiveness of our proposed method. For the task of next utterance\nselection, the proposed method has demonstrated a significant performance\nimprovement against original ESIM and the new model has achieved\nstate-of-the-art results on both Ubuntu dialogue corpus and Douban conversation\ncorpus. In addition, we investigated the performance impact of end-of-utterance\nand end-of-turn token tags.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 19:41:02 GMT"}, {"version": "v2", "created": "Mon, 7 May 2018 04:20:45 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Dong", "Jianxiong", ""], ["Huang", "Jim", ""]]}, {"id": "1802.02656", "submitter": "Xuesong Yang", "authors": "Xuesong Yang, Kartik Audhkhasi, Andrew Rosenberg, Samuel Thomas,\n  Bhuvana Ramabhadran, Mark Hasegawa-Johnson", "title": "Joint Modeling of Accents and Acoustics for Multi-Accent Speech\n  Recognition", "comments": "Accepted in The 43rd IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of automatic speech recognition systems degrades with\nincreasing mismatch between the training and testing scenarios. Differences in\nspeaker accents are a significant source of such mismatch. The traditional\napproach to deal with multiple accents involves pooling data from several\naccents during training and building a single model in multi-task fashion,\nwhere tasks correspond to individual accents. In this paper, we explore an\nalternate model where we jointly learn an accent classifier and a multi-task\nacoustic model. Experiments on the American English Wall Street Journal and\nBritish English Cambridge corpora demonstrate that our joint model outperforms\nthe strong multi-task acoustic model baseline. We obtain a 5.94% relative\nimprovement in word error rate on British English, and 9.47% relative\nimprovement on American English. This illustrates that jointly modeling with\naccent information improves acoustic model performance.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 22:05:18 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Yang", "Xuesong", ""], ["Audhkhasi", "Kartik", ""], ["Rosenberg", "Andrew", ""], ["Thomas", "Samuel", ""], ["Ramabhadran", "Bhuvana", ""], ["Hasegawa-Johnson", "Mark", ""]]}, {"id": "1802.02745", "submitter": "Reuben Feinman", "authors": "Reuben Feinman, Brenden M. Lake", "title": "Learning Inductive Biases with Simple Neural Networks", "comments": "Published in Proceedings of the 40th Annual Meeting of the Cognitive\n  Science Society, July 2018", "journal-ref": "Feinman, R. and Lake, B.M. (2018). Learning inductive biases with\n  simple neural networks. In Proceedings of the 40th Annual Meeting of the\n  Cognitive Science Society", "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People use rich prior knowledge about the world in order to efficiently learn\nnew concepts. These priors - also known as \"inductive biases\" - pertain to the\nspace of internal models considered by a learner, and they help the learner\nmake inferences that go beyond the observed data. A recent study found that\ndeep neural networks optimized for object recognition develop the shape bias\n(Ritter et al., 2017), an inductive bias possessed by children that plays an\nimportant role in early word learning. However, these networks use\nunrealistically large quantities of training data, and the conditions required\nfor these biases to develop are not well understood. Moreover, it is unclear\nhow the learning dynamics of these networks relate to developmental processes\nin childhood. We investigate the development and influence of the shape bias in\nneural networks using controlled datasets of abstract patterns and synthetic\nimages, allowing us to systematically vary the quantity and form of the\nexperience provided to the learning algorithms. We find that simple neural\nnetworks develop a shape bias after seeing as few as 3 examples of 4 object\ncategories. The development of these biases predicts the onset of vocabulary\nacceleration in our networks, consistent with the developmental process in\nchildren.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 08:25:51 GMT"}, {"version": "v2", "created": "Wed, 13 Jun 2018 18:01:21 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Feinman", "Reuben", ""], ["Lake", "Brenden M.", ""]]}, {"id": "1802.02870", "submitter": "Naiara P\\'erez Miguel", "authors": "Naiara Perez, Montse Cuadros, German Rigau", "title": "Biomedical term normalization of EHRs with UMLS", "comments": null, "journal-ref": "Perez, N., Cuadros, M., & Rigau, G. (2018). Biomedical term\n  normalization of EHRs with UMLS. In Proceedings of the Eleventh International\n  Conference on Language Resources and Evaluation (LREC 2018). ELRA", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel prototype for biomedical term normalization of\nelectronic health record excerpts with the Unified Medical Language System\n(UMLS) Metathesaurus. Despite being multilingual and cross-lingual by design,\nwe first focus on processing clinical text in Spanish because there is no\nexisting tool for this language and for this specific purpose. The tool is\nbased on Apache Lucene to index the Metathesaurus and generate mapping\ncandidates from input text. It uses the IXA pipeline for basic language\nprocessing and resolves ambiguities with the UKB toolkit. It has been evaluated\nby measuring its agreement with MetaMap in two English-Spanish parallel\ncorpora. In addition, we present a web-based interface for the tool.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 14:16:18 GMT"}, {"version": "v2", "created": "Thu, 24 May 2018 07:13:11 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Perez", "Naiara", ""], ["Cuadros", "Montse", ""], ["Rigau", "German", ""]]}, {"id": "1802.02892", "submitter": "Douwe Kiela", "authors": "D. Kiela, E. Grave, A. Joulin, T. Mikolov", "title": "Efficient Large-Scale Multi-Modal Classification", "comments": "Published at AAAI-18, 7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the incipient internet was largely text-based, the modern digital world\nis becoming increasingly multi-modal. Here, we examine multi-modal\nclassification where one modality is discrete, e.g. text, and the other is\ncontinuous, e.g. visual representations transferred from a convolutional neural\nnetwork. In particular, we focus on scenarios where we have to be able to\nclassify large quantities of data quickly. We investigate various methods for\nperforming multi-modal fusion and analyze their trade-offs in terms of\nclassification accuracy and computational efficiency. Our findings indicate\nthat the inclusion of continuous information improves performance over\ntext-only on a range of multi-modal classification tasks, even with simple\nfusion methods. In addition, we experiment with discretizing the continuous\nfeatures in order to speed up and simplify the fusion process even further. Our\nresults show that fusion with discretized features outperforms text-only\nclassification, at a fraction of the computational cost of full multi-modal\nfusion, with the additional benefit of improved interpretability.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 20:30:59 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Kiela", "D.", ""], ["Grave", "E.", ""], ["Joulin", "A.", ""], ["Mikolov", "T.", ""]]}, {"id": "1802.02914", "submitter": "George Christodoulides", "authors": "George Christodoulides (ILC)", "title": "Praaline: Integrating Tools for Speech Corpus Research", "comments": null, "journal-ref": "Proceedings of the 9th International Conference on Language\n  Resources and Evaluation (LREC), May 2014, Reykjavik, Iceland", "doi": null, "report-no": null, "categories": "cs.CL cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents Praaline, an open-source software system for managing,\nannotating, analysing and visualising speech corpora. Researchers working with\nspeech corpora are often faced with multiple tools and formats, and they need\nto work with ever-increasing amounts of data in a collaborative way. Praaline\nintegrates and extends existing time-proven tools for spoken corpora analysis\n(Praat, Sonic Visualiser and a bridge to the R statistical package) in a\nmodular system, facilitating automation and reuse. Users are exposed to an\nintegrated, user-friendly interface from which to access multiple tools. Corpus\nmetadata and annotations may be stored in a database, locally or remotely, and\nusers can define the metadata and annotation structure. Users may run a\ncustomisable cascade of analysis steps, based on plug-ins and scripts, and\nupdate the database with the results. The corpus database may be queried, to\nproduce aggregated data-sets. Praaline is extensible using Python or C++\nplug-ins, while Praat and R scripts may be executed against the corpus data. A\nseries of visualisations, editors and plug-ins are provided. Praaline is free\nsoftware, released under the GPL license.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 15:15:51 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Christodoulides", "George", "", "ILC"]]}, {"id": "1802.02926", "submitter": "George Christodoulides", "authors": "George Christodoulides (ILC), Mathieu Avanzi, Jean-Philippe Goldman\n  (UNIGE)", "title": "DisMo: A Morphosyntactic, Disfluency and Multi-Word Unit Annotator. An\n  Evaluation on a Corpus of French Spontaneous and Read Speech", "comments": null, "journal-ref": "Proceedings of the 9th International Conference on Language\n  Resources and Evaluation (LREC), May 2014, Reykjavik, Iceland", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present DisMo, a multi-level annotator for spoken language corpora that\nintegrates part-of-speech tagging with basic disfluency detection and\nannotation, and multi-word unit recognition. DisMo is a hybrid system that uses\na combination of lexical resources, rules, and statistical models based on\nConditional Random Fields (CRF). In this paper, we present the first public\nversion of DisMo for French. The system is trained and its performance\nevaluated on a 57k-token corpus, including different varieties of French spoken\nin three countries (Belgium, France and Switzerland). DisMo supports a\nmulti-level annotation scheme, in which the tokenisation to minimal word units\nis complemented with multi-word unit groupings (each having associated POS\ntags), as well as separate levels for annotating disfluencies and discourse\nphenomena. We present the system's architecture, linguistic resources and its\nhierarchical tag-set. Results show that DisMo achieves a precision of 95%\n(finest tag-set) to 96.8% (coarse tag-set) in POS-tagging non-punctuated,\nsound-aligned transcriptions of spoken French, while also offering substantial\npossibilities for automated multi-level annotation.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 15:38:54 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Christodoulides", "George", "", "ILC"], ["Avanzi", "Mathieu", "", "UNIGE"], ["Goldman", "Jean-Philippe", "", "UNIGE"]]}, {"id": "1802.03052", "submitter": "Peter Jansen", "authors": "Peter A. Jansen, Elizabeth Wainwright, Steven Marmorstein, Clayton T.\n  Morrison", "title": "WorldTree: A Corpus of Explanation Graphs for Elementary Science\n  Questions supporting Multi-Hop Inference", "comments": "Accepted at the Language Resource and Evaluation Conference (LREC)\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing methods of automated inference that are able to provide users with\ncompelling human-readable justifications for why the answer to a question is\ncorrect is critical for domains such as science and medicine, where user trust\nand detecting costly errors are limiting factors to adoption. One of the\ncentral barriers to training question answering models on explainable inference\ntasks is the lack of gold explanations to serve as training data. In this paper\nwe present a corpus of explanations for standardized science exams, a recent\nchallenge task for question answering. We manually construct a corpus of\ndetailed explanations for nearly all publicly available standardized elementary\nscience question (approximately 1,680 3rd through 5th grade questions) and\nrepresent these as \"explanation graphs\" -- sets of lexically overlapping\nsentences that describe how to arrive at the correct answer to a question\nthrough a combination of domain and world knowledge. We also provide an\nexplanation-centered tablestore, a collection of semi-structured tables that\ncontain the knowledge to construct these elementary science explanations.\nTogether, these two knowledge resources map out a substantial portion of the\nknowledge required for answering and explaining elementary science exams, and\nprovide both structured and free-text training data for the explainable\ninference task.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 21:26:03 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Jansen", "Peter A.", ""], ["Wainwright", "Elizabeth", ""], ["Marmorstein", "Steven", ""], ["Morrison", "Clayton T.", ""]]}, {"id": "1802.03116", "submitter": "Yun Chen", "authors": "Yun Chen, Yang Liu, Victor O.K. Li", "title": "Zero-Resource Neural Machine Translation with Multi-Agent Communication\n  Game", "comments": "Published at AAAI-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While end-to-end neural machine translation (NMT) has achieved notable\nsuccess in the past years in translating a handful of resource-rich language\npairs, it still suffers from the data scarcity problem for low-resource\nlanguage pairs and domains. To tackle this problem, we propose an interactive\nmultimodal framework for zero-resource neural machine translation. Instead of\nbeing passively exposed to large amounts of parallel corpora, our learners\n(implemented as encoder-decoder architecture) engage in cooperative image\ndescription games, and thus develop their own image captioning or neural\nmachine translation model from the need to communicate in order to succeed at\nthe game. Experimental results on the IAPR-TC12 and Multi30K datasets show that\nthe proposed learning mechanism significantly improves over the\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 03:53:13 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Chen", "Yun", ""], ["Liu", "Yang", ""], ["Li", "Victor O. K.", ""]]}, {"id": "1802.03142", "submitter": "Laurent Besacier", "authors": "Ali Can Kocabiyikoglu, Laurent Besacier, Olivier Kraif", "title": "Augmenting Librispeech with French Translations: A Multimodal Corpus for\n  Direct Speech Translation Evaluation", "comments": "LREC 2018, Japan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent works in spoken language translation (SLT) have attempted to build\nend-to-end speech-to-text translation without using source language\ntranscription during learning or decoding. However, while large quantities of\nparallel texts (such as Europarl, OpenSubtitles) are available for training\nmachine translation systems, there are no large (100h) and open source parallel\ncorpora that include speech in a source language aligned to text in a target\nlanguage. This paper tries to fill this gap by augmenting an existing\n(monolingual) corpus: LibriSpeech. This corpus, used for automatic speech\nrecognition, is derived from read audiobooks from the LibriVox project, and has\nbeen carefully segmented and aligned. After gathering French e-books\ncorresponding to the English audio-books from LibriSpeech, we align speech\nsegments at the sentence level with their respective translations and obtain\n236h of usable parallel data. This paper presents the details of the processing\nas well as a manual evaluation conducted on a small subset of the corpus. This\nevaluation shows that the automatic alignments scores are reasonably correlated\nwith the human judgments of the bilingual alignment quality. We believe that\nthis corpus (which is made available online) is useful for replicable\nexperiments in direct speech translation or more general spoken language\ntranslation experiments.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 06:29:43 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Kocabiyikoglu", "Ali Can", ""], ["Besacier", "Laurent", ""], ["Kraif", "Olivier", ""]]}, {"id": "1802.03198", "submitter": "Hrant Khachatrian", "authors": "Martin Mirakyan, Karen Hambardzumyan, Hrant Khachatrian", "title": "Natural Language Inference over Interaction Space: ICLR 2018\n  Reproducibility Report", "comments": "as part of ICLR 2018 Reproducibility Challenge", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have tried to reproduce the results of the paper \"Natural Language\nInference over Interaction Space\" submitted to ICLR 2018 conference as part of\nthe ICLR 2018 Reproducibility Challenge. Initially, we were not aware that the\ncode was available, so we started to implement the network from scratch. We\nhave evaluated our version of the model on Stanford NLI dataset and reached\n86.38% accuracy on the test set, while the paper claims 88.0% accuracy. The\nmain difference, as we understand it, comes from the optimizers and the way\nmodel selection is performed.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 10:49:47 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Mirakyan", "Martin", ""], ["Hambardzumyan", "Karen", ""], ["Khachatrian", "Hrant", ""]]}, {"id": "1802.03238", "submitter": "Myeongjun Jang", "authors": "Myeongjun Jang, Seungwan Seo, Pilsung Kang", "title": "Recurrent Neural Network-Based Semantic Variational Autoencoder for\n  Sequence-to-Sequence Learning", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-to-sequence (Seq2seq) models have played an important role in the\nrecent success of various natural language processing methods, such as machine\ntranslation, text summarization, and speech recognition. However, current\nSeq2seq models have trouble preserving global latent information from a long\nsequence of words. Variational autoencoder (VAE) alleviates this problem by\nlearning a continuous semantic space of the input sentence. However, it does\nnot solve the problem completely. In this paper, we propose a new recurrent\nneural network (RNN)-based Seq2seq model, RNN semantic variational autoencoder\n(RNN--SVAE), to better capture the global latent information of a sequence of\nwords. To reflect the meaning of words in a sentence properly, without regard\nto its position within the sentence, we construct a document information vector\nusing the attention information between the final state of the encoder and\nevery prior hidden state. Then, the mean and standard deviation of the\ncontinuous semantic space are learned by using this vector to take advantage of\nthe variational method. By using the document information vector to find the\nsemantic space of the sentence, it becomes possible to better capture the\nglobal latent feature of the sentence. Experimental results of three natural\nlanguage tasks (i.e., language modeling, missing word imputation, paraphrase\nidentification) confirm that the proposed RNN--SVAE yields higher performance\nthan two benchmark models.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 12:58:29 GMT"}, {"version": "v2", "created": "Sat, 2 Jun 2018 11:44:01 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Jang", "Myeongjun", ""], ["Seo", "Seungwan", ""], ["Kang", "Pilsung", ""]]}, {"id": "1802.03268", "submitter": "Hieu Pham", "authors": "Hieu Pham, Melody Y. Guan, Barret Zoph, Quoc V. Le, Jeff Dean", "title": "Efficient Neural Architecture Search via Parameter Sharing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Efficient Neural Architecture Search (ENAS), a fast and\ninexpensive approach for automatic model design. In ENAS, a controller learns\nto discover neural network architectures by searching for an optimal subgraph\nwithin a large computational graph. The controller is trained with policy\ngradient to select a subgraph that maximizes the expected reward on the\nvalidation set. Meanwhile the model corresponding to the selected subgraph is\ntrained to minimize a canonical cross entropy loss. Thanks to parameter sharing\nbetween child models, ENAS is fast: it delivers strong empirical performances\nusing much fewer GPU-hours than all existing automatic model design approaches,\nand notably, 1000x less expensive than standard Neural Architecture Search. On\nthe Penn Treebank dataset, ENAS discovers a novel architecture that achieves a\ntest perplexity of 55.8, establishing a new state-of-the-art among all methods\nwithout post-training processing. On the CIFAR-10 dataset, ENAS designs novel\narchitectures that achieve a test error of 2.89%, which is on par with NASNet\n(Zoph et al., 2018), whose test error is 2.65%.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 14:14:37 GMT"}, {"version": "v2", "created": "Mon, 12 Feb 2018 03:34:00 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Pham", "Hieu", ""], ["Guan", "Melody Y.", ""], ["Zoph", "Barret", ""], ["Le", "Quoc V.", ""], ["Dean", "Jeff", ""]]}, {"id": "1802.03594", "submitter": "\\'Alvaro Peris", "authors": "\\'Alvaro Peris and Francisco Casacuberta", "title": "Online Learning for Effort Reduction in Interactive Neural Machine\n  Translation", "comments": "Accepted in Computer Speech & Language", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Neural machine translation systems require large amounts of training data and\nresources. Even with this, the quality of the translations may be insufficient\nfor some users or domains. In such cases, the output of the system must be\nrevised by a human agent. This can be done in a post-editing stage or following\nan interactive machine translation protocol.\n  We explore the incremental update of neural machine translation systems\nduring the post-editing or interactive translation processes. Such\nmodifications aim to incorporate the new knowledge, from the edited sentences,\ninto the translation system. Updates to the model are performed on-the-fly, as\nsentences are corrected, via online learning techniques. In addition, we\nimplement a novel interactive, adaptive system, able to react to\nsingle-character interactions. This system greatly reduces the human effort\nrequired for obtaining high-quality translations.\n  In order to stress our proposals, we conduct exhaustive experiments varying\nthe amount and type of data available for training. Results show that online\nlearning effectively achieves the objective of reducing the human effort\nrequired during the post-editing or the interactive machine translation stages.\nMoreover, these adaptive systems also perform well in scenarios with scarce\nresources. We show that a neural machine translation system can be rapidly\nadapted to a specific domain, exclusively by means of online learning\ntechniques.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 14:07:58 GMT"}, {"version": "v2", "created": "Mon, 8 Apr 2019 08:18:33 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Peris", "\u00c1lvaro", ""], ["Casacuberta", "Francisco", ""]]}, {"id": "1802.03606", "submitter": "Ibrahim Riza Hallac", "authors": "Galip Aydin, Ibrahim Riza Hallac", "title": "Distributed NLP", "comments": "Presented at Third International Symposium on Innovative Technologies\n  in Engineering and Science 3-5 June, 2015, Valencia, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the performance of parallel text processing with Map\nReduce on a cloud platform. Scientific papers in Turkish language are processed\nusing Zemberek NLP library. Experiments were run on a Hadoop cluster and\ncompared with the single machines performance.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 15:08:56 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Aydin", "Galip", ""], ["Hallac", "Ibrahim Riza", ""]]}, {"id": "1802.03656", "submitter": "Benyou Wang", "authors": "Benyou Wang, Li Wang, Qikang Wei, Lichun Liu", "title": "TextZoo, a New Benchmark for Reconsidering Text Classification", "comments": "a benchmark need to be completed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text representation is a fundamental concern in Natural Language Processing,\nespecially in text classification. Recently, many neural network approaches\nwith delicate representation model (e.g. FASTTEXT, CNN, RNN and many hybrid\nmodels with attention mechanisms) claimed that they achieved state-of-art in\nspecific text classification datasets. However, it lacks an unified benchmark\nto compare these models and reveals the advantage of each sub-components for\nvarious settings. We re-implement more than 20 popular text representation\nmodels for classification in more than 10 datasets. In this paper, we\nreconsider the text classification task in the perspective of neural network\nand get serval effects with analysis of the above results.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 22:34:38 GMT"}, {"version": "v2", "created": "Mon, 19 Mar 2018 03:07:10 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Wang", "Benyou", ""], ["Wang", "Li", ""], ["Wei", "Qikang", ""], ["Liu", "Lichun", ""]]}, {"id": "1802.03701", "submitter": "Ankur Padia", "authors": "Sourish Dasgupta, Ankur Padia, Gaurav Maheshwari, Priyansh Trivedi,\n  Jens Lehmann", "title": "Formal Ontology Learning from English IS-A Sentences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Ontology learning (OL) is the process of automatically generating an\nontological knowledge base from a plain text document. In this paper, we\npropose a new ontology learning approach and tool, called DLOL, which generates\na knowledge base in the description logic (DL) SHOQ(D) from a collection of\nfactual non-negative IS-A sentences in English. We provide extensive\nexperimental results on the accuracy of DLOL, giving experimental comparisons\nto three state-of-the-art existing OL tools, namely Text2Onto, FRED, and LExO.\nHere, we use the standard OL accuracy measure, called lexical accuracy, and a\nnovel OL accuracy measure, called instance-based inference model. In our\nexperimental results, DLOL turns out to be about 21% and 46%, respectively,\nbetter than the best of the other three approaches.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 06:41:54 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Dasgupta", "Sourish", ""], ["Padia", "Ankur", ""], ["Maheshwari", "Gaurav", ""], ["Trivedi", "Priyansh", ""], ["Lehmann", "Jens", ""]]}, {"id": "1802.03712", "submitter": "Rodolfo Delmonte", "authors": "Rodolfo Delmonte", "title": "Syntax and Semantics of Italian Poetry in the First Half of the 20th\n  Century", "comments": "To appear in Proceedings of AIUCD 2016 (revised version as of March\n  19, 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper we study, analyse and comment rhetorical figures present in\nsome of most interesting poetry of the first half of the twentieth century.\nThese figures are at first traced back to some famous poet of the past and then\ncompared to classical Latin prose. Linguistic theory is then called in to show\nhow they can be represented in syntactic structures and classified as\nnoncanonical structures, by positioning discontinuous or displaced linguistic\nelements in Spec XP projections at various levels of constituency. Then we\nintroduce LFG (Lexical Functional Grammar) as the theory that allows us to\nconnect syntactic noncanonical structures with informational structure and\npsycholinguistic theories for complexity evaluation. We end up with two\ncomputational linguistics experiments and then evaluate the results. The first\none uses best online parsers of Italian to parse poetic structures; the second\none uses Getarun, the system created at Ca Foscari Computational Linguistics\nLaboratory. As will be shown, the first approach is unable to cope with these\nstructures due to the use of only statistical probabilistic information. On the\ncontrary, the second one, being a symbolic rule based system, is by far\nsuperior and allows also to complete both semantic an pragmatic analysis.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 08:54:58 GMT"}, {"version": "v2", "created": "Sun, 1 Apr 2018 09:13:50 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Delmonte", "Rodolfo", ""]]}, {"id": "1802.03753", "submitter": "Pawe{\\l} Budzianowski", "authors": "Gell\\'ert Weisz, Pawe{\\l} Budzianowski, Pei-Hao Su, Milica Ga\\v{s}i\\'c", "title": "Sample Efficient Deep Reinforcement Learning for Dialogue Systems with\n  Large Action Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spoken dialogue systems, we aim to deploy artificial intelligence to build\nautomated dialogue agents that can converse with humans. A part of this effort\nis the policy optimisation task, which attempts to find a policy describing how\nto respond to humans, in the form of a function taking the current state of the\ndialogue and returning the response of the system. In this paper, we\ninvestigate deep reinforcement learning approaches to solve this problem.\nParticular attention is given to actor-critic methods, off-policy reinforcement\nlearning with experience replay, and various methods aimed at reducing the bias\nand variance of estimators. When combined, these methods result in the\npreviously proposed ACER algorithm that gave competitive results in gaming\nenvironments. These environments however are fully observable and have a\nrelatively small action set so in this paper we examine the application of ACER\nto dialogue policy optimisation. We show that this method beats the current\nstate-of-the-art in deep learning approaches for spoken dialogue systems. This\nnot only leads to a more sample efficient algorithm that can train faster, but\nalso allows us to apply the algorithm in more difficult environments than\nbefore. We thus experiment with learning in a very large action space, which\nhas two orders of magnitude more actions than previously considered. We find\nthat ACER trains significantly faster than the current state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 15:37:37 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Weisz", "Gell\u00e9rt", ""], ["Budzianowski", "Pawe\u0142", ""], ["Su", "Pei-Hao", ""], ["Ga\u0161i\u0107", "Milica", ""]]}, {"id": "1802.03793", "submitter": "Justin Sybrandt", "authors": "Justin Sybrandt, Michael Shtutman and Ilya Safro", "title": "Large-Scale Validation of Hypothesis Generation Systems via Candidate\n  Ranking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The first step of many research projects is to define and rank a short list\nof candidates for study. In the modern rapidity of scientific progress, some\nturn to automated hypothesis generation (HG) systems to aid this process. These\nsystems can identify implicit or overlooked connections within a large\nscientific corpus, and while their importance grows alongside the pace of\nscience, they lack thorough validation. Without any standard numerical\nevaluation method, many validate general-purpose HG systems by rediscovering a\nhandful of historical findings, and some wishing to be more thorough may run\nlaboratory experiments based on automatic suggestions. These methods are\nexpensive, time consuming, and cannot scale. Thus, we present a numerical\nevaluation framework for the purpose of validating HG systems that leverages\nthousands of validation hypotheses. This method evaluates a HG system by its\nability to rank hypotheses by plausibility; a process reminiscent of human\ncandidate selection. Because HG systems do not produce a ranking criteria,\nspecifically those that produce topic models, we additionally present novel\nmetrics to quantify the plausibility of hypotheses given topic model system\noutput. Finally, we demonstrate that our proposed validation method aligns with\nreal-world research goals by deploying our method within Moliere, our recent\ntopic-driven HG system, in order to automatically generate a set of candidate\ngenes related to HIV-associated neurodegenerative disease (HAND). By performing\nlaboratory experiments based on this candidate set, we discover a new\nconnection between HAND and Dead Box RNA Helicase 3 (DDX3). Reproducibility:\ncode, validation data, and results can be found at\nsybrandt.com/2018/validation.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 19:04:49 GMT"}, {"version": "v2", "created": "Wed, 22 Aug 2018 17:35:22 GMT"}, {"version": "v3", "created": "Fri, 19 Oct 2018 15:21:13 GMT"}, {"version": "v4", "created": "Wed, 5 Dec 2018 21:06:44 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Sybrandt", "Justin", ""], ["Shtutman", "Michael", ""], ["Safro", "Ilya", ""]]}, {"id": "1802.03816", "submitter": "Skanda Koppula", "authors": "Skanda Koppula, Khe Chai Sim, and Kean Chin", "title": "Understanding Recurrent Neural State Using Memory Signatures", "comments": "Accepted to 2018 IEEE International Conference on Acoustics, Speech\n  and Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate a network visualization technique to analyze the recurrent\nstate inside the LSTMs/GRUs used commonly in language and acoustic models.\nInterpreting intermediate state and network activations inside end-to-end\nmodels remains an open challenge. Our method allows users to understand exactly\nhow much and what history is encoded inside recurrent state in grapheme\nsequence models. Our procedure trains multiple decoders that predict prior\ninput history. Compiling results from these decoders, a user can obtain a\nsignature of the recurrent kernel that characterizes its memory behavior. We\ndemonstrate this method's usefulness in revealing information divergence in the\nbases of recurrent factorized kernels, visualizing the character-level\ndifferences between the memory of n-gram and recurrent language models, and\nextracting knowledge of history encoded in the layers of grapheme-based\nend-to-end ASR networks.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 20:59:56 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Koppula", "Skanda", ""], ["Sim", "Khe Chai", ""], ["Chin", "Kean", ""]]}, {"id": "1802.03821", "submitter": "Ibrahim Riza Hallac", "authors": "Betul Karakus, Ibrahim Riza Hallac, Galip Aydin", "title": "Distributed Readability Analysis Of Turkish Elementary School Textbooks", "comments": "Proceedings of International Conference on Information Technology and\n  Computer Science July 11-12, 2015, ISBN:9788193137307", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The readability assessment deals with estimating the level of difficulty in\nreading texts.Many readability tests, which do not indicate execution\nefficiency, have been applied on specific texts to measure the reading grade\nlevel in science textbooks. In this paper, we analyze the content covered in\nelementary school Turkish textbooks by employing a distributed parallel\nprocessing framework based on popular MapReduce paradigm. We outline the\narchitecture of a distributed Big Data processing system which uses Hadoop for\nfull-text readability analysis. The readability scores of the textbooks and\nsystem performance measurements are also given in the paper.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 21:18:45 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Karakus", "Betul", ""], ["Hallac", "Ibrahim Riza", ""], ["Aydin", "Galip", ""]]}, {"id": "1802.03881", "submitter": "Sang-Woo Lee", "authors": "Sang-Woo Lee, Yu-Jung Heo, Byoung-Tak Zhang", "title": "Answerer in Questioner's Mind: Information Theoretic Approach to\n  Goal-Oriented Visual Dialog", "comments": "Selected for a spotlight presentation at NIPS, 2018. Camera ready\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Goal-oriented dialog has been given attention due to its numerous\napplications in artificial intelligence. Goal-oriented dialogue tasks occur\nwhen a questioner asks an action-oriented question and an answerer responds\nwith the intent of letting the questioner know a correct action to take. To ask\nthe adequate question, deep learning and reinforcement learning have been\nrecently applied. However, these approaches struggle to find a competent\nrecurrent neural questioner, owing to the complexity of learning a series of\nsentences. Motivated by theory of mind, we propose \"Answerer in Questioner's\nMind\" (AQM), a novel information theoretic algorithm for goal-oriented dialog.\nWith AQM, a questioner asks and infers based on an approximated probabilistic\nmodel of the answerer. The questioner figures out the answerer's intention via\nselecting a plausible question by explicitly calculating the information gain\nof the candidate intentions and possible answers to each question. We test our\nframework on two goal-oriented visual dialog tasks: \"MNIST Counting Dialog\" and\n\"GuessWhat?!\". In our experiments, AQM outperforms comparative algorithms by a\nlarge margin.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 04:08:06 GMT"}, {"version": "v2", "created": "Fri, 21 Sep 2018 07:31:24 GMT"}, {"version": "v3", "created": "Wed, 28 Nov 2018 05:07:23 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Lee", "Sang-Woo", ""], ["Heo", "Yu-Jung", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "1802.04028", "submitter": "Sarai Duek", "authors": "Sarai Duek and Shaul Markovitch", "title": "Automatic Generation of Language-Independent Features for Cross-Lingual\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications require categorization of text documents using predefined\ncategories. The main approach to performing text categorization is learning\nfrom labeled examples. For many tasks, it may be difficult to find examples in\none language but easy in others. The problem of learning from examples in one\nor more languages and classifying (categorizing) in another is called\ncross-lingual learning. In this work, we present a novel approach that solves\nthe general cross-lingual text categorization problem. Our method generates,\nfor each training document, a set of language-independent features. Using these\nfeatures for training yields a language-independent classifier. At the\nclassification stage, we generate language-independent features for the\nunlabeled document, and apply the classifier on the new representation.\n  To build the feature generator, we utilize a hierarchical\nlanguage-independent ontology, where each concept has a set of support\ndocuments for each language involved. In the preprocessing stage, we use the\nsupport documents to build a set of language-independent feature generators,\none for each language. The collection of these generators is used to map any\ndocument into the language-independent feature space.\n  Our methodology works on the most general cross-lingual text categorization\nproblems, being able to learn from any mix of languages and classify documents\nin any other language. We also present a method for exploiting the hierarchical\nstructure of the ontology to create virtual supporting documents for languages\nthat do not have them. We tested our method, using Wikipedia as our ontology,\non the most commonly used test collections in cross-lingual text\ncategorization, and found that it outperforms existing methods.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 13:20:57 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Duek", "Sarai", ""], ["Markovitch", "Shaul", ""]]}, {"id": "1802.04140", "submitter": "Ian Stewart", "authors": "Ian Stewart and Jacob Eisenstein", "title": "Making \"fetch\" happen: The influence of social and linguistic context on\n  nonstandard word growth and decline", "comments": "replaced by arXiv:1709.00345", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an online community, new words come and go: today's \"haha\" may be replaced\nby tomorrow's \"lol.\" Changes in online writing are usually studied as a social\nprocess, with innovations diffusing through a network of individuals in a\nspeech community. But unlike other types of innovation, language change is\nshaped and constrained by the system in which it takes part. To investigate the\nlinks between social and structural factors in language change, we undertake a\nlarge-scale analysis of nonstandard word growth in the online community Reddit.\nWe find that dissemination across many linguistic contexts is a sign of growth:\nwords that appear in more linguistic contexts grow faster and survive longer.\nWe also find that social dissemination likely plays a less important role in\nexplaining word growth and decline than previously hypothesized.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 15:32:01 GMT"}, {"version": "v2", "created": "Tue, 13 Feb 2018 21:11:52 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Stewart", "Ian", ""], ["Eisenstein", "Jacob", ""]]}, {"id": "1802.04200", "submitter": "Alexandre B\\'erard", "authors": "Alexandre B\\'erard, Laurent Besacier, Ali Can Kocabiyikoglu, Olivier\n  Pietquin", "title": "End-to-End Automatic Speech Translation of Audiobooks", "comments": "Accepted to ICASSP 2018 (poster presentation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate end-to-end speech-to-text translation on a corpus of\naudiobooks specifically augmented for this task. Previous works investigated\nthe extreme case where source language transcription is not available during\nlearning nor decoding, but we also study a midway case where source language\ntranscription is available at training time only. In this case, a single model\nis trained to decode source speech into target text in a single pass.\nExperimental results show that it is possible to train compact and efficient\nend-to-end speech translation models in this setup. We also distribute the\ncorpus and hope that our speech translation baseline on this corpus will be\nchallenged in the future.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 17:37:11 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["B\u00e9rard", "Alexandre", ""], ["Besacier", "Laurent", ""], ["Kocabiyikoglu", "Ali Can", ""], ["Pietquin", "Olivier", ""]]}, {"id": "1802.04223", "submitter": "Vlad Niculae", "authors": "Vlad Niculae, Andr\\'e F. T. Martins, Mathieu Blondel, Claire Cardie", "title": "SparseMAP: Differentiable Sparse Structured Inference", "comments": "Published in ICML 2018. 14 pages, including appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured prediction requires searching over a combinatorial number of\nstructures. To tackle it, we introduce SparseMAP: a new method for sparse\nstructured inference, and its natural loss function. SparseMAP automatically\nselects only a few global structures: it is situated between MAP inference,\nwhich picks a single structure, and marginal inference, which assigns\nprobability mass to all structures, including implausible ones. Importantly,\nSparseMAP can be computed using only calls to a MAP oracle, making it\napplicable to problems with intractable marginal inference, e.g., linear\nassignment. Sparsity makes gradient backpropagation efficient regardless of the\nstructure, enabling us to augment deep neural networks with generic and sparse\nstructured hidden layers. Experiments in dependency parsing and natural\nlanguage inference reveal competitive accuracy, improved interpretability, and\nthe ability to capture natural language ambiguities, which is attractive for\npipeline systems.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 18:07:34 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2018 16:09:16 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Niculae", "Vlad", ""], ["Martins", "Andr\u00e9 F. T.", ""], ["Blondel", "Mathieu", ""], ["Cardie", "Claire", ""]]}, {"id": "1802.04302", "submitter": "Ishita Dasgupta", "authors": "Ishita Dasgupta, Demi Guo, Andreas Stuhlm\\\"uller, Samuel J. Gershman\n  and Noah D. Goodman", "title": "Evaluating Compositionality in Sentence Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important challenge for human-like AI is compositional semantics. Recent\nresearch has attempted to address this by using deep neural networks to learn\nvector space embeddings of sentences, which then serve as input to other tasks.\nWe present a new dataset for one such task, `natural language inference' (NLI),\nthat cannot be solved using only word-level knowledge and requires some\ncompositionality. We find that the performance of state of the art sentence\nembeddings (InferSent; Conneau et al., 2017) on our new dataset is poor. We\nanalyze the decision rules learned by InferSent and find that they are\nconsistent with simple heuristics that are ecologically valid in its training\ndataset. Further, we find that augmenting training with our dataset improves\ntest performance on our dataset without loss of performance on the original\ntraining dataset. This highlights the importance of structured datasets in\nbetter understanding and improving AI systems.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 19:02:52 GMT"}, {"version": "v2", "created": "Thu, 17 May 2018 19:01:47 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Dasgupta", "Ishita", ""], ["Guo", "Demi", ""], ["Stuhlm\u00fcller", "Andreas", ""], ["Gershman", "Samuel J.", ""], ["Goodman", "Noah D.", ""]]}, {"id": "1802.04335", "submitter": "Illia Polosukhin", "authors": "Illia Polosukhin, Alexander Skidanov", "title": "Neural Program Search: Solving Programming Tasks from Description and\n  Examples", "comments": "9 pages, 3 figures, ICLR workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Neural Program Search, an algorithm to generate programs from\nnatural language description and a small number of input/output examples. The\nalgorithm combines methods from Deep Learning and Program Synthesis fields by\ndesigning rich domain-specific language (DSL) and defining efficient search\nalgorithm guided by a Seq2Tree model on it. To evaluate the quality of the\napproach we also present a semi-synthetic dataset of descriptions with test\nexamples and corresponding programs. We show that our algorithm significantly\noutperforms a sequence-to-sequence model with attention baseline.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 20:05:26 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Polosukhin", "Illia", ""], ["Skidanov", "Alexander", ""]]}, {"id": "1802.04358", "submitter": "Chulaka Gunasekara", "authors": "Song Feng, R. Chulaka Gunasekara, Sunil Shashidhara, Kshitij P. Fadnis\n  and Lazaros C. Polymenakos", "title": "A Unified Implicit Dialog Framework for Conversational Search", "comments": "Appeared as a demo in AAAI-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose a unified Implicit Dialog framework for goal-oriented, information\nseeking tasks of Conversational Search applications. It aims to enable dialog\ninteractions with domain data without replying on explicitly encoded the rules\nbut utilizing the underlying data representation to build the components\nrequired for dialog interaction, which we refer as Implicit Dialog in this\nwork. The proposed framework consists of a pipeline of End-to-End trainable\nmodules. A centralized knowledge representation is used to semantically ground\nmultiple dialog modules. An associated set of tools are integrated with the\nframework to gather end users' input for continuous improvement of the system.\nThe goal is to facilitate development of conversational systems by identifying\nthe components and the data that can be adapted and reused across many end-user\napplications. We demonstrate our approach by creating conversational agents for\nseveral independent domains.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 20:53:50 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Feng", "Song", ""], ["Gunasekara", "R. Chulaka", ""], ["Shashidhara", "Sunil", ""], ["Fadnis", "Kshitij P.", ""], ["Polymenakos", "Lazaros C.", ""]]}, {"id": "1802.04394", "submitter": "Jianshu Chen", "authors": "Yelong Shen, Jianshu Chen, Po-Sen Huang, Yuqing Guo, Jianfeng Gao", "title": "M-Walk: Learning to Walk over Graphs using Monte Carlo Tree Search", "comments": "Yelong Shen, Jianshu Chen and Po-Sen Huang contributed equally to the\n  paper. Published at 32nd Conference on Neural Information Processing Systems\n  (NeurIPS 2018), Montr\\'eal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to walk over a graph towards a target node for a given query and a\nsource node is an important problem in applications such as knowledge base\ncompletion (KBC). It can be formulated as a reinforcement learning (RL) problem\nwith a known state transition model. To overcome the challenge of sparse\nrewards, we develop a graph-walking agent called M-Walk, which consists of a\ndeep recurrent neural network (RNN) and Monte Carlo Tree Search (MCTS). The RNN\nencodes the state (i.e., history of the walked path) and maps it separately to\na policy and Q-values. In order to effectively train the agent from sparse\nrewards, we combine MCTS with the neural policy to generate trajectories\nyielding more positive rewards. From these trajectories, the network is\nimproved in an off-policy manner using Q-learning, which modifies the RNN\npolicy via parameter sharing. Our proposed RL algorithm repeatedly applies this\npolicy-improvement step to learn the model. At test time, MCTS is combined with\nthe neural policy to predict the target node. Experimental results on several\ngraph-walking benchmarks show that M-Walk is able to learn better policies than\nother RL-based methods, which are mainly based on policy gradients. M-Walk also\noutperforms traditional KBC baselines.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 23:27:23 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 21:02:01 GMT"}, {"version": "v3", "created": "Thu, 1 Nov 2018 00:19:45 GMT"}, {"version": "v4", "created": "Wed, 28 Nov 2018 19:16:36 GMT"}, {"version": "v5", "created": "Tue, 18 Dec 2018 17:43:47 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Shen", "Yelong", ""], ["Chen", "Jianshu", ""], ["Huang", "Po-Sen", ""], ["Guo", "Yuqing", ""], ["Gao", "Jianfeng", ""]]}, {"id": "1802.04425", "submitter": "Hannah Morrison", "authors": "Hannah Morrison and Chris Martens", "title": "\"How Was Your Weekend?\" A Generative Model of Phatic Conversation", "comments": "Accepted submission at FLAIRS-31", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unspoken social rules, such as those that govern choosing a proper discussion\ntopic and when to change discussion topics, guide conversational behaviors. We\npropose a computational model of conversation that can follow or break such\nrules, with participant agents that respond accordingly. Additionally, we\ndemonstrate an application of the model: the Experimental Social Tutor (EST), a\nfirst step toward a social skills training tool that generates human-readable\nconversation and a conversational guideline at each point in the dialogue.\nFinally, we discuss the design and results of a pilot study evaluating the EST.\nResults show that our model is capable of producing conversations that follow\nsocial norms.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 01:43:44 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Morrison", "Hannah", ""], ["Martens", "Chris", ""]]}, {"id": "1802.04559", "submitter": "Carlos-Emiliano Gonz\\'alez-Gallardo", "authors": "Carlos-Emiliano Gonz\\'alez-Gallardo and Juan-Manuel Torres-Moreno", "title": "Sentence Boundary Detection for French with Subword-Level Information\n  Vectors and Convolutional Neural Networks", "comments": "In proceedings of the International Conference on Natural Language,\n  Signal and Speech Processing (ICNLSSP) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we tackle the problem of sentence boundary detection applied to\nFrench as a binary classification task (\"sentence boundary\" or \"not sentence\nboundary\"). We combine convolutional neural networks with subword-level\ninformation vectors, which are word embedding representations learned from\nWikipedia that take advantage of the words morphology; so each word is\nrepresented as a bag of their character n-grams.\n  We decide to use a big written dataset (French Gigaword) instead of standard\nsize transcriptions to train and evaluate the proposed architectures with the\nintention of using the trained models in posterior real life ASR\ntranscriptions.\n  Three different architectures are tested showing similar results; general\naccuracy for all models overpasses 0.96. All three models have good F1 scores\nreaching values over 0.97 regarding the \"not sentence boundary\" class. However,\nthe \"sentence boundary\" class reflects lower scores decreasing the F1 metric to\n0.778 for one of the models.\n  Using subword-level information vectors seem to be very effective leading to\nconclude that the morphology of words encoded in the embeddings representations\nbehave like pixels in an image making feasible the use of convolutional neural\nnetwork architectures.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 11:04:07 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Gonz\u00e1lez-Gallardo", "Carlos-Emiliano", ""], ["Torres-Moreno", "Juan-Manuel", ""]]}, {"id": "1802.04609", "submitter": "Abhik Jana", "authors": "Abhik Jana and Pawan Goyal", "title": "Network Features Based Co-hyponymy Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distinguishing lexical relations has been a long term pursuit in natural\nlanguage processing (NLP) domain. Recently, in order to detect lexical\nrelations like hypernymy, meronymy, co-hyponymy etc., distributional semantic\nmodels are being used extensively in some form or the other. Even though a lot\nof efforts have been made for detecting hypernymy relation, the problem of\nco-hyponymy detection has been rarely investigated. In this paper, we are\nproposing a novel supervised model where various network measures have been\nutilized to identify co-hyponymy relation with high accuracy performing better\nor at par with the state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 13:22:19 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Jana", "Abhik", ""], ["Goyal", "Pawan", ""]]}, {"id": "1802.04675", "submitter": "Parth Mehta", "authors": "Parth Mehta, Gaurav Arora, Prasenjit Majumder", "title": "Attention based Sentence Extraction from Scientific Articles using\n  Pseudo-Labeled data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a weakly supervised sentence extraction technique\nfor identifying important sentences in scientific papers that are worthy of\ninclusion in the abstract. We propose a new attention based deep learning\narchitecture that jointly learns to identify important content, as well as the\ncue phrases that are indicative of summary worthy sentences. We propose a new\ncontext embedding technique for determining the focus of a given paper using\ntopic models and use it jointly with an LSTM based sequence encoder to learn\nattention weights across the sentence words. We use a collection of articles\npublicly available through ACL anthology for our experiments. Our system\nachieves a performance that is better, in terms of several ROUGE metrics, as\ncompared to several state of art extractive techniques. It also generates more\ncoherent summaries and preserves the overall structure of the document.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 15:13:28 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Mehta", "Parth", ""], ["Arora", "Gaurav", ""], ["Majumder", "Prasenjit", ""]]}, {"id": "1802.04681", "submitter": "Marzieh Fadaee", "authors": "Marzieh Fadaee, Arianna Bisazza, Christof Monz", "title": "Examining the Tip of the Iceberg: A Data Set for Idiom Translation", "comments": "Accepted at LREC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) has been widely used in recent years with\nsignificant improvements for many language pairs. Although state-of-the-art NMT\nsystems are generating progressively better translations, idiom translation\nremains one of the open challenges in this field. Idioms, a category of\nmultiword expressions, are an interesting language phenomenon where the overall\nmeaning of the expression cannot be composed from the meanings of its parts. A\nfirst important challenge is the lack of dedicated data sets for learning and\nevaluating idiom translation. In this paper we address this problem by creating\nthe first large-scale data set for idiom translation. Our data set is\nautomatically extracted from a widely used German-English translation corpus\nand includes, for each language direction, a targeted evaluation set where all\nsentences contain idioms and a regular training corpus where sentences\nincluding idioms are marked. We release this data set and use it to perform\npreliminary NMT experiments as the first step towards better idiom translation.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 15:25:21 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Fadaee", "Marzieh", ""], ["Bisazza", "Arianna", ""], ["Monz", "Christof", ""]]}, {"id": "1802.04744", "submitter": "Tommaso Pasini", "authors": "Tommaso Pasini and Jose Camacho-Collados", "title": "A Short Survey on Sense-Annotated Corpora", "comments": "7 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large sense-annotated datasets are increasingly necessary for training deep\nsupervised systems in Word Sense Disambiguation. However, gathering\nhigh-quality sense-annotated data for as many instances as possible is a\nlaborious and expensive task. This has led to the proliferation of automatic\nand semi-automatic methods for overcoming the so-called knowledge-acquisition\nbottleneck. In this short survey we present an overview of sense-annotated\ncorpora, annotated either manually- or (semi)automatically, that are currently\navailable for different languages and featuring distinct lexical resources as\ninventory of senses, i.e. WordNet, Wikipedia, BabelNet. Furthermore, we provide\nthe reader with general statistics of each dataset and an analysis of their\nspecific features.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 17:10:54 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 12:54:10 GMT"}, {"version": "v3", "created": "Mon, 8 Apr 2019 08:05:57 GMT"}, {"version": "v4", "created": "Fri, 13 Mar 2020 07:56:40 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Pasini", "Tommaso", ""], ["Camacho-Collados", "Jose", ""]]}, {"id": "1802.05014", "submitter": "Amaru Cuba Gyllensten", "authors": "Amaru Cuba Gyllensten and Magnus Sahlgren", "title": "Distributional Term Set Expansion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper is a short empirical study of the performance of centrality and\nclassification based iterative term set expansion methods for distributional\nsemantic models. Iterative term set expansion is an interactive process using\ndistributional semantics models where a user labels terms as belonging to some\nsought after term set, and a system uses this labeling to supply the user with\nnew, candidate, terms to label, trying to maximize the number of positive\nexamples found. While centrality based methods have a long history in term set\nexpansion, we compare them to classification methods based on the the Simple\nMargin method, an Active Learning approach to classification using Support\nVector Machines. Examining the performance of various centrality and\nclassification based methods for a variety of distributional models over five\ndifferent term sets, we can show that active learning based methods\nconsistently outperform centrality based methods.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 10:04:48 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Gyllensten", "Amaru Cuba", ""], ["Sahlgren", "Magnus", ""]]}, {"id": "1802.05092", "submitter": "Laurent Besacier", "authors": "Odette Scharenborg, Laurent Besacier, Alan Black, Mark\n  Hasegawa-Johnson, Florian Metze, Graham Neubig, Sebastian Stueker, Pierre\n  Godard, Markus Mueller, Lucas Ondel, Shruti Palaskar, Philip Arthur,\n  Francesco Ciannella, Mingxing Du, Elin Larsen, Danny Merkx, Rachid Riad,\n  Liming Wang, Emmanuel Dupoux", "title": "Linguistic unit discovery from multi-modal inputs in unwritten\n  languages: Summary of the \"Speaking Rosetta\" JSALT 2017 Workshop", "comments": "Accepted to ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We summarize the accomplishments of a multi-disciplinary workshop exploring\nthe computational and scientific issues surrounding the discovery of linguistic\nunits (subwords and words) in a language without orthography. We study the\nreplacement of orthographic transcriptions by images and/or translated text in\na well-resourced language to help unsupervised discovery from raw speech.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 13:46:03 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Scharenborg", "Odette", ""], ["Besacier", "Laurent", ""], ["Black", "Alan", ""], ["Hasegawa-Johnson", "Mark", ""], ["Metze", "Florian", ""], ["Neubig", "Graham", ""], ["Stueker", "Sebastian", ""], ["Godard", "Pierre", ""], ["Mueller", "Markus", ""], ["Ondel", "Lucas", ""], ["Palaskar", "Shruti", ""], ["Arthur", "Philip", ""], ["Ciannella", "Francesco", ""], ["Du", "Mingxing", ""], ["Larsen", "Elin", ""], ["Merkx", "Danny", ""], ["Riad", "Rachid", ""], ["Wang", "Liming", ""], ["Dupoux", "Emmanuel", ""]]}, {"id": "1802.05121", "submitter": "Shashank Gupta", "authors": "Shashank Gupta, Manish Gupta, Vasudeva Varma, Sachin Pawar, Nitin\n  Ramrakhiyani, Girish K. Palshikar", "title": "Co-training for Extraction of Adverse Drug Reaction Mentions from Tweets", "comments": "Accepted at ECIR18 as short paper (6 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adverse drug reactions (ADRs) are one of the leading causes of mortality in\nhealth care. Current ADR surveillance systems are often associated with a\nsubstantial time lag before such events are officially published. On the other\nhand, online social media such as Twitter contain information about ADR events\nin real-time, much before any official reporting. Current state-of-the-art\nmethods in ADR mention extraction use Recurrent Neural Networks (RNN), which\ntypically need large labeled corpora. Towards this end, we propose a\nsemi-supervised method based on co-training which can exploit a large pool of\nunlabeled tweets to augment the limited supervised training data, and as a\nresult enhance the performance. Experiments with 0.1M tweets show that the\nproposed approach outperforms the state-of-the-art methods for the ADR mention\nextraction task by 5% in terms of F1 score.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 14:47:56 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Gupta", "Shashank", ""], ["Gupta", "Manish", ""], ["Varma", "Vasudeva", ""], ["Pawar", "Sachin", ""], ["Ramrakhiyani", "Nitin", ""], ["Palshikar", "Girish K.", ""]]}, {"id": "1802.05130", "submitter": "Shashank Gupta", "authors": "Shashank Gupta, Manish Gupta, Vasudeva Varma, Sachin Pawar, Nitin\n  Ramrakhiyani and Girish K. Palshikar", "title": "Multi-Task Learning for Extraction of Adverse Drug Reaction Mentions\n  from Tweets", "comments": "Accepted at ECIR18 as full paper (12 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adverse drug reactions (ADRs) are one of the leading causes of mortality in\nhealth care. Current ADR surveillance systems are often associated with a\nsubstantial time lag before such events are officially published. On the other\nhand, online social media such as Twitter contain information about ADR events\nin real-time, much before any official reporting. Current state-of-the-art in\nADR mention extraction uses Recurrent Neural Networks (RNN), which typically\nneed large labeled corpora. Towards this end, we propose a multi-task learning\nbased method which can utilize a similar auxiliary task (adverse drug event\ndetection) to enhance the performance of the main task, i.e., ADR extraction.\nFurthermore, in the absence of auxiliary task dataset, we propose a novel joint\nmulti-task learning method to automatically generate weak supervision dataset\nfor the auxiliary task when a large pool of unlabeled tweets is available.\nExperiments with 0.48M tweets show that the proposed approach outperforms the\nstate-of-the-art methods for the ADR mention extraction task by 7.2% in terms\nof F1 score.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 14:53:06 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Gupta", "Shashank", ""], ["Gupta", "Manish", ""], ["Varma", "Vasudeva", ""], ["Pawar", "Sachin", ""], ["Ramrakhiyani", "Nitin", ""], ["Palshikar", "Girish K.", ""]]}, {"id": "1802.05300", "submitter": "Mantas Mazeika", "authors": "Dan Hendrycks, Mantas Mazeika, Duncan Wilson, Kevin Gimpel", "title": "Using Trusted Data to Train Deep Networks on Labels Corrupted by Severe\n  Noise", "comments": "NeurIPS 2018. PyTorch code available at\n  https://github.com/mmazeika/glc", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing importance of massive datasets used for deep learning makes\nrobustness to label noise a critical property for classifiers to have. Sources\nof label noise include automatic labeling, non-expert labeling, and label\ncorruption by data poisoning adversaries. Numerous previous works assume that\nno source of labels can be trusted. We relax this assumption and assume that a\nsmall subset of the training data is trusted. This enables substantial label\ncorruption robustness performance gains. In addition, particularly severe label\nnoise can be combated by using a set of trusted data with clean labels. We\nutilize trusted data by proposing a loss correction technique that utilizes\ntrusted examples in a data-efficient manner to mitigate the effects of label\nnoise on deep neural network classifiers. Across vision and natural language\nprocessing tasks, we experiment with various label noises at several strengths,\nand show that our method significantly outperforms existing methods.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 19:48:50 GMT"}, {"version": "v2", "created": "Thu, 6 Sep 2018 19:07:19 GMT"}, {"version": "v3", "created": "Tue, 30 Oct 2018 17:41:23 GMT"}, {"version": "v4", "created": "Mon, 28 Jan 2019 19:55:36 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Hendrycks", "Dan", ""], ["Mazeika", "Mantas", ""], ["Wilson", "Duncan", ""], ["Gimpel", "Kevin", ""]]}, {"id": "1802.05322", "submitter": "Adam Nyberg", "authors": "Adam Nyberg", "title": "Classifying movie genres by analyzing text reviews", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a method for classifying movie genres by only looking at\ntext reviews. The data used are from Large Movie Review Dataset v1.0 and IMDb.\nThis paper compared a K-nearest neighbors (KNN) model and a multilayer\nperceptron (MLP) that uses tf-idf as input features. The paper also discusses\ndifferent evaluation metrics used when doing multi-label classification. For\nthe data used in this research, the KNN model performed the best with an\naccuracy of 55.4\\% and a Hamming loss of 0.047.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 21:04:15 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Nyberg", "Adam", ""]]}, {"id": "1802.05365", "submitter": "Matthew Peters", "authors": "Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner,\n  Christopher Clark, Kenton Lee, Luke Zettlemoyer", "title": "Deep contextualized word representations", "comments": "NAACL 2018. Originally posted to openreview 27 Oct 2017. v2 updated\n  for NAACL camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new type of deep contextualized word representation that\nmodels both (1) complex characteristics of word use (e.g., syntax and\nsemantics), and (2) how these uses vary across linguistic contexts (i.e., to\nmodel polysemy). Our word vectors are learned functions of the internal states\nof a deep bidirectional language model (biLM), which is pre-trained on a large\ntext corpus. We show that these representations can be easily added to existing\nmodels and significantly improve the state of the art across six challenging\nNLP problems, including question answering, textual entailment and sentiment\nanalysis. We also present an analysis showing that exposing the deep internals\nof the pre-trained network is crucial, allowing downstream models to mix\ndifferent types of semi-supervision signals.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 00:05:11 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2018 21:59:40 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Peters", "Matthew E.", ""], ["Neumann", "Mark", ""], ["Iyyer", "Mohit", ""], ["Gardner", "Matt", ""], ["Clark", "Christopher", ""], ["Lee", "Kenton", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1802.05368", "submitter": "Hany Hassan Awadalla", "authors": "Jiatao Gu, Hany Hassan, Jacob Devlin, Victor O.K. Li", "title": "Universal Neural Machine Translation for Extremely Low Resource\n  Languages", "comments": "NAACL-HLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new universal machine translation approach\nfocusing on languages with a limited amount of parallel data. Our proposed\napproach utilizes a transfer-learning approach to share lexical and sentence\nlevel representations across multiple source languages into one target\nlanguage. The lexical part is shared through a Universal Lexical Representation\nto support multilingual word-level sharing. The sentence-level sharing is\nrepresented by a model of experts from all source languages that share the\nsource encoders with all other languages. This enables the low-resource\nlanguage to utilize the lexical and sentence representations of the higher\nresource languages. Our approach is able to achieve 23 BLEU on Romanian-English\nWMT2016 using a tiny parallel corpus of 6k sentences, compared to the 18 BLEU\nof strong baseline system which uses multilingual training and\nback-translation. Furthermore, we show that the proposed approach can achieve\nalmost 20 BLEU on the same dataset through fine-tuning a pre-trained\nmulti-lingual system in a zero-shot setting.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 00:35:08 GMT"}, {"version": "v2", "created": "Tue, 17 Apr 2018 02:15:20 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Gu", "Jiatao", ""], ["Hassan", "Hany", ""], ["Devlin", "Jacob", ""], ["Li", "Victor O. K.", ""]]}, {"id": "1802.05373", "submitter": "Guozhen An", "authors": "Guozhen An, Mehrnoosh Shafiee, Davood Shamsi", "title": "Improving Retrieval Modeling Using Cross Convolution Networks And Multi\n  Frequency Word Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To build a satisfying chatbot that has the ability of managing a\ngoal-oriented multi-turn dialogue, accurate modeling of human conversation is\ncrucial. In this paper we concentrate on the task of response selection for\nmulti-turn human-computer conversation with a given context. Previous\napproaches show weakness in capturing information of rare keywords that appear\nin either or both context and correct response, and struggle with long input\nsequences. We propose Cross Convolution Network (CCN) and Multi Frequency word\nembedding to address both problems. We train several models using the Ubuntu\nDialogue dataset which is the largest freely available multi-turn based\ndialogue corpus. We further build an ensemble model by averaging predictions of\nmultiple models. We achieve a new state-of-the-art on this dataset with\nconsiderable improvements compared to previous best results.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 00:49:52 GMT"}, {"version": "v2", "created": "Fri, 16 Feb 2018 14:24:03 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["An", "Guozhen", ""], ["Shafiee", "Mehrnoosh", ""], ["Shamsi", "Davood", ""]]}, {"id": "1802.05383", "submitter": "Xuesong Yang", "authors": "Kaizhi Qian, Yang Zhang, Shiyu Chang, Xuesong Yang, Dinei Florencio,\n  Mark Hasegawa-Johnson", "title": "Deep Learning Based Speech Beamforming", "comments": "Accepted in The 43rd IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.SD eess.AS eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-channel speech enhancement with ad-hoc sensors has been a challenging\ntask. Speech model guided beamforming algorithms are able to recover natural\nsounding speech, but the speech models tend to be oversimplified or the\ninference would otherwise be too complicated. On the other hand, deep learning\nbased enhancement approaches are able to learn complicated speech distributions\nand perform efficient inference, but they are unable to deal with variable\nnumber of input channels. Also, deep learning approaches introduce a lot of\nerrors, particularly in the presence of unseen noise types and settings. We\nhave therefore proposed an enhancement framework called DEEPBEAM, which\ncombines the two complementary classes of algorithms. DEEPBEAM introduces a\nbeamforming filter to produce natural sounding speech, but the filter\ncoefficients are determined with the help of a monaural speech enhancement\nneural network. Experiments on synthetic and real-world data show that DEEPBEAM\nis able to produce clean, dry and natural sounding speech, and is robust\nagainst unseen noise.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 02:00:54 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Qian", "Kaizhi", ""], ["Zhang", "Yang", ""], ["Chang", "Shiyu", ""], ["Yang", "Xuesong", ""], ["Florencio", "Dinei", ""], ["Hasegawa-Johnson", "Mark", ""]]}, {"id": "1802.05412", "submitter": "Chan Woo Kim", "authors": "Chan Woo Kim", "title": "NtMalDetect: A Machine Learning Approach to Malware Detection Using\n  Native API System Calls", "comments": "8 pages, Intel International Science and Engineering Fair Project -\n  SOFT006T", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As computing systems become increasingly advanced and as users increasingly\nengage themselves in technology, security has never been a greater concern. In\nmalware detection, static analysis, the method of analyzing potentially\nmalicious files, has been the prominent approach. This approach, however,\nquickly falls short as malicious programs become more advanced and adopt the\ncapabilities of obfuscating its binaries to execute the same malicious\nfunctions, making static analysis extremely difficult for newer variants. The\napproach assessed in this paper is a novel dynamic malware analysis method,\nwhich may generalize better than static analysis to newer variants. Inspired by\nrecent successes in Natural Language Processing (NLP), widely used document\nclassification techniques were assessed in detecting malware by doing such\nanalysis on system calls, which contain useful information about the operation\nof a program as requests that the program makes of the kernel. Features\nconsidered are extracted from system call traces of benign and malicious\nprograms, and the task to classify these traces is treated as a binary document\nclassification task of system call traces. The system call traces were\nprocessed to remove the parameters to only leave the system call function\nnames. The features were grouped into various n-grams and weighted with Term\nFrequency-Inverse Document Frequency. This paper shows that Linear Support\nVector Machines (SVM) optimized by Stochastic Gradient Descent and the\ntraditional Coordinate Descent on the Wolfe Dual form of the SVM are effective\nin this approach, achieving a highest of 96% accuracy with 95% recall score.\nAdditional contributions include the identification of significant system call\nsequences that could be avenues for further research.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 05:34:21 GMT"}, {"version": "v2", "created": "Sat, 19 May 2018 19:27:36 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Kim", "Chan Woo", ""]]}, {"id": "1802.05415", "submitter": "Sumeet Sohan Singh", "authors": "Sumeet S. Singh", "title": "Teaching Machines to Code: Neural Markup Generation with Visual\n  Attention", "comments": "For datasets, visualizations and ancillary material see:\n  https://untrix.github.io/i2l . For source code go to:\n  https://github.com/untrix/im2latex", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a neural transducer model with visual attention that learns to\ngenerate LaTeX markup of a real-world math formula given its image. Applying\nsequence modeling and transduction techniques that have been very successful\nacross modalities such as natural language, image, handwriting, speech and\naudio; we construct an image-to-markup model that learns to produce\nsyntactically and semantically correct LaTeX markup code over 150 words long\nand achieves a BLEU score of 89%; improving upon the previous state-of-art for\nthe Im2Latex problem. We also demonstrate with heat-map visualization how\nattention helps in interpreting the model and can pinpoint (detect and\nlocalize) symbols on the image accurately despite having been trained without\nany bounding box data.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 06:17:51 GMT"}, {"version": "v2", "created": "Fri, 15 Jun 2018 21:36:10 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Singh", "Sumeet S.", ""]]}, {"id": "1802.05574", "submitter": "Paul Groth", "authors": "Paul Groth and Michael Lauruhn and Antony Scerri and Ron Daniel Jr", "title": "Open Information Extraction on Scientific Text: An Evaluation", "comments": "10 pages", "journal-ref": "The 27th International Conference on Computational Linguistics\n  (COLING 2018)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open Information Extraction (OIE) is the task of the unsupervised creation of\nstructured information from text. OIE is often used as a starting point for a\nnumber of downstream tasks including knowledge base construction, relation\nextraction, and question answering. While OIE methods are targeted at being\ndomain independent, they have been evaluated primarily on newspaper,\nencyclopedic or general web text. In this article, we evaluate the performance\nof OIE on scientific texts originating from 10 different disciplines. To do so,\nwe use two state-of-the-art OIE systems applying a crowd-sourcing approach. We\nfind that OIE systems perform significantly worse on scientific text than\nencyclopedic text. We also provide an error analysis and suggest areas of work\nto reduce errors. Our corpus of sentences and judgments are made available.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 14:38:46 GMT"}, {"version": "v2", "created": "Mon, 4 Jun 2018 12:18:23 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Groth", "Paul", ""], ["Lauruhn", "Michael", ""], ["Scerri", "Antony", ""], ["Daniel", "Ron", "Jr"]]}, {"id": "1802.05577", "submitter": "Reza Ghaeini", "authors": "Reza Ghaeini, Sadid A. Hasan, Vivek Datla, Joey Liu, Kathy Lee,\n  Ashequl Qadir, Yuan Ling, Aaditya Prakash, Xiaoli Z. Fern and Oladimeji Farri", "title": "DR-BiLSTM: Dependent Reading Bidirectional LSTM for Natural Language\n  Inference", "comments": "18 pages, Accepted as a long paper at NAACL HLT 2018", "journal-ref": "NAACL 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel deep learning architecture to address the natural language\ninference (NLI) task. Existing approaches mostly rely on simple reading\nmechanisms for independent encoding of the premise and hypothesis. Instead, we\npropose a novel dependent reading bidirectional LSTM network (DR-BiLSTM) to\nefficiently model the relationship between a premise and a hypothesis during\nencoding and inference. We also introduce a sophisticated ensemble strategy to\ncombine our proposed models, which noticeably improves final predictions.\nFinally, we demonstrate how the results can be improved further with an\nadditional preprocessing step. Our evaluation shows that DR-BiLSTM obtains the\nbest single model and ensemble model results achieving the new state-of-the-art\nscores on the Stanford NLI dataset.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 14:39:47 GMT"}, {"version": "v2", "created": "Wed, 11 Apr 2018 02:45:25 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Ghaeini", "Reza", ""], ["Hasan", "Sadid A.", ""], ["Datla", "Vivek", ""], ["Liu", "Joey", ""], ["Lee", "Kathy", ""], ["Qadir", "Ashequl", ""], ["Ling", "Yuan", ""], ["Prakash", "Aaditya", ""], ["Fern", "Xiaoli Z.", ""], ["Farri", "Oladimeji", ""]]}, {"id": "1802.05583", "submitter": "Tiberiu Boros", "authors": "Tiberiu Boros, Stefan Daniel Dumitrescu and Vasile Pais", "title": "Tools and resources for Romanian text-to-speech and speech-to-text\n  applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a set of resources and tools aimed at providing\nsupport for natural language processing, text-to-speech synthesis and speech\nrecognition for Romanian. While the tools are general purpose and can be used\nfor any language (we successfully trained our system for more than 50 languages\nand participated in the Universal Dependencies Shared Task), the resources are\nonly relevant for Romanian language processing.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 14:50:54 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Boros", "Tiberiu", ""], ["Dumitrescu", "Stefan Daniel", ""], ["Pais", "Vasile", ""]]}, {"id": "1802.05630", "submitter": "Andrei Petrovskii", "authors": "Caroline Etienne, Guillaume Fidanza, Andrei Petrovskii, Laurence\n  Devillers and Benoit Schmauch", "title": "CNN+LSTM Architecture for Speech Emotion Recognition with Data\n  Augmentation", "comments": "5 pages, 3 figures", "journal-ref": "Workshop on Speech, Music and Mind 2018", "doi": "10.21437/SMM.2018-5", "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we design a neural network for recognizing emotions in speech,\nusing the IEMOCAP dataset. Following the latest advances in audio analysis, we\nuse an architecture involving both convolutional layers, for extracting\nhigh-level features from raw spectrograms, and recurrent ones for aggregating\nlong-term dependencies. We examine the techniques of data augmentation with\nvocal track length perturbation, layer-wise optimizer adjustment, batch\nnormalization of recurrent layers and obtain highly competitive results of\n64.5% for weighted accuracy and 61.7% for unweighted accuracy on four emotions.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 16:05:02 GMT"}, {"version": "v2", "created": "Tue, 11 Sep 2018 18:05:16 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Etienne", "Caroline", ""], ["Fidanza", "Guillaume", ""], ["Petrovskii", "Andrei", ""], ["Devillers", "Laurence", ""], ["Schmauch", "Benoit", ""]]}, {"id": "1802.05667", "submitter": "Atish Pawar", "authors": "Atish Pawar and Vijay Mago", "title": "Calculating the similarity between words and sentences using a lexical\n  database and corpus statistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Calculating the semantic similarity between sentences is a long dealt problem\nin the area of natural language processing. The semantic analysis field has a\ncrucial role to play in the research related to the text analytics. The\nsemantic similarity differs as the domain of operation differs. In this paper,\nwe present a methodology which deals with this issue by incorporating semantic\nsimilarity and corpus statistics. To calculate the semantic similarity between\nwords and sentences, the proposed method follows an edge-based approach using a\nlexical database. The methodology can be applied in a variety of domains. The\nmethodology has been tested on both benchmark standards and mean human\nsimilarity dataset. When tested on these two datasets, it gives highest\ncorrelation value for both word and sentence similarity outperforming other\nsimilar models. For word similarity, we obtained Pearson correlation\ncoefficient of 0.8753 and for sentence similarity, the correlation obtained is\n0.8794.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 17:15:25 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 22:38:27 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Pawar", "Atish", ""], ["Mago", "Vijay", ""]]}, {"id": "1802.05672", "submitter": "Reza Ghaeini", "authors": "Reza Ghaeini, Xiaoli Z. Fern, Liang Huang, Prasad Tadepalli", "title": "Event Nugget Detection with Forward-Backward Recurrent Neural Networks", "comments": "Published as a short paper at ACL 2016. The main purpose of this\n  submission is to add this paper to arxiv", "journal-ref": "ACL 2016", "doi": null, "report-no": "http://www.aclweb.org/anthology/P16-2060", "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional event detection methods heavily rely on manually engineered rich\nfeatures. Recent deep learning approaches alleviate this problem by automatic\nfeature engineering. But such efforts, like tradition methods, have so far only\nfocused on single-token event mentions, whereas in practice events can also be\na phrase. We instead use forward-backward recurrent neural networks (FBRNNs) to\ndetect events that can be either words or phrases. To the best our knowledge,\nthis is one of the first efforts to handle multi-word events and also the first\nattempt to use RNNs for event detection. Experimental results demonstrate that\nFBRNN is competitive with the state-of-the-art methods on the ACE 2005 and the\nRich ERE 2015 event detection tasks.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 17:28:46 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Ghaeini", "Reza", ""], ["Fern", "Xiaoli Z.", ""], ["Huang", "Liang", ""], ["Tadepalli", "Prasad", ""]]}, {"id": "1802.05694", "submitter": "Xilun Chen", "authors": "Xilun Chen, Claire Cardie", "title": "Multinomial Adversarial Networks for Multi-Domain Text Classification", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many text classification tasks are known to be highly domain-dependent.\nUnfortunately, the availability of training data can vary drastically across\ndomains. Worse still, for some domains there may not be any annotated data at\nall. In this work, we propose a multinomial adversarial network (MAN) to tackle\nthe text classification problem in this real-world multidomain setting (MDTC).\nWe provide theoretical justifications for the MAN framework, proving that\ndifferent instances of MANs are essentially minimizers of various f-divergence\nmetrics (Ali and Silvey, 1966) among multiple probability distributions. MANs\nare thus a theoretically sound generalization of traditional adversarial\nnetworks that discriminate over two distributions. More specifically, for the\nMDTC task, MAN learns features that are invariant across multiple domains by\nresorting to its ability to reduce the divergence among the feature\ndistributions of each domain. We present experimental results showing that MANs\nsignificantly outperform the prior art on the MDTC task. We also show that MANs\nachieve state-of-the-art performance for domains with no labeled data.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 18:22:58 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Chen", "Xilun", ""], ["Cardie", "Claire", ""]]}, {"id": "1802.05695", "submitter": "James Mullenbach", "authors": "James Mullenbach, Sarah Wiegreffe, Jon Duke, Jimeng Sun, Jacob\n  Eisenstein", "title": "Explainable Prediction of Medical Codes from Clinical Text", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical notes are text documents that are created by clinicians for each\npatient encounter. They are typically accompanied by medical codes, which\ndescribe the diagnosis and treatment. Annotating these codes is labor intensive\nand error prone; furthermore, the connection between the codes and the text is\nnot annotated, obscuring the reasons and details behind specific diagnoses and\ntreatments. We present an attentional convolutional network that predicts\nmedical codes from clinical text. Our method aggregates information across the\ndocument using a convolutional neural network, and uses an attention mechanism\nto select the most relevant segments for each of the thousands of possible\ncodes. The method is accurate, achieving precision@8 of 0.71 and a Micro-F1 of\n0.54, which are both better than the prior state of the art. Furthermore,\nthrough an interpretability evaluation by a physician, we show that the\nattention mechanism identifies meaningful explanations for each code assignment\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 18:25:32 GMT"}, {"version": "v2", "created": "Mon, 16 Apr 2018 21:45:35 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Mullenbach", "James", ""], ["Wiegreffe", "Sarah", ""], ["Duke", "Jon", ""], ["Sun", "Jimeng", ""], ["Eisenstein", "Jacob", ""]]}, {"id": "1802.05737", "submitter": "Kamal Sarkar", "authors": "Kamal Sarkar", "title": "JU_KS@SAIL_CodeMixed-2017: Sentiment Analysis for Indian Code Mixed\n  Social Media Texts", "comments": "NLP Tool Contest on Sentiment Analysis for Indian Languages (Code\n  Mixed) held in conjunction with the 14th International Conference on Natural\n  Language Processing, 2017", "journal-ref": "Kamal Sarkar, JU_KS@SAIL_CodeMixed-2017: Sentiment Analysis for\n  Indian Code Mixed Social Media Texts, NLP Tool Contest@the 14th International\n  Conference on Natural Language Processing, 2017", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reports about our work in the NLP Tool Contest @ICON-2017, shared\ntask on Sentiment Analysis for Indian Languages (SAIL) (code mixed). To\nimplement our system, we have used a machine learning algo-rithm called\nMultinomial Na\\\"ive Bayes trained using n-gram and SentiWordnet features. We\nhave also used a small SentiWordnet for English and a small SentiWordnet for\nBengali. But we have not used any SentiWordnet for Hindi language. We have\ntested our system on Hindi-English and Bengali-English code mixed social media\ndata sets released for the contest. The performance of our system is very close\nto the best system participated in the contest. For both Bengali-English and\nHindi-English runs, our system was ranked at the 3rd position out of all\nsubmitted runs and awarded the 3rd prize in the contest.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 20:02:43 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Sarkar", "Kamal", ""]]}, {"id": "1802.05758", "submitter": "Christian Stab", "authors": "Christian Stab and Tristan Miller and Iryna Gurevych", "title": "Cross-topic Argument Mining from Heterogeneous Sources Using\n  Attention-based Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Argument mining is a core technology for automating argument search in large\ndocument collections. Despite its usefulness for this task, most current\napproaches to argument mining are designed for use only with specific text\ntypes and fall short when applied to heterogeneous texts. In this paper, we\npropose a new sentential annotation scheme that is reliably applicable by crowd\nworkers to arbitrary Web texts. We source annotations for over 25,000 instances\ncovering eight controversial topics. The results of cross-topic experiments\nshow that our attention-based neural network generalizes best to unseen topics\nand outperforms vanilla BiLSTM models by 6% in accuracy and 11% in F-score.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 20:49:19 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Stab", "Christian", ""], ["Miller", "Tristan", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1802.05766", "submitter": "Yan Zhang", "authors": "Yan Zhang, Jonathon Hare, Adam Pr\\\"ugel-Bennett", "title": "Learning to Count Objects in Natural Images for Visual Question\n  Answering", "comments": "Published in ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual Question Answering (VQA) models have struggled with counting objects\nin natural images so far. We identify a fundamental problem due to soft\nattention in these models as a cause. To circumvent this problem, we propose a\nneural network component that allows robust counting from object proposals.\nExperiments on a toy task show the effectiveness of this component and we\nobtain state-of-the-art accuracy on the number category of the VQA v2 dataset\nwithout negatively affecting other categories, even outperforming ensemble\nmodels with our single model. On a difficult balanced pair metric, the\ncomponent gives a substantial improvement in counting over a strong baseline by\n6.6%.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 21:16:59 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Zhang", "Yan", ""], ["Hare", "Jonathon", ""], ["Pr\u00fcgel-Bennett", "Adam", ""]]}, {"id": "1802.05818", "submitter": "Shuai Wang", "authors": "Shuai Wang, Mianwei Zhou, Sahisnu Mazumder, Bing Liu, Yi Chang", "title": "Disentangling Aspect and Opinion Words in Target-based Sentiment\n  Analysis using Lifelong Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a target name, which can be a product aspect or entity, identifying its\naspect words and opinion words in a given corpus is a fine-grained task in\ntarget-based sentiment analysis (TSA). This task is challenging, especially\nwhen we have no labeled data and we want to perform it for any given domain. To\naddress it, we propose a general two-stage approach. Stage one extracts/groups\nthe target-related words (call t-words) for a given target. This is relatively\neasy as we can apply an existing semantics-based learning technique. Stage two\nseparates the aspect and opinion words from the grouped t-words, which is\nchallenging because we often do not have enough word-level aspect and opinion\nlabels. In this work, we formulate this problem in a PU learning setting and\nincorporate the idea of lifelong learning to solve it. Experimental results\nshow the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 02:00:10 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Wang", "Shuai", ""], ["Zhou", "Mianwei", ""], ["Mazumder", "Sahisnu", ""], ["Liu", "Bing", ""], ["Chang", "Yi", ""]]}, {"id": "1802.05853", "submitter": "Vikramjit Mitra", "authors": "Vikramjit Mitra, Wen Wang, Chris Bartels, Horacio Franco and Dimitra\n  Vergyri", "title": "Articulatory information and Multiview Features for Large Vocabulary\n  Continuous Speech Recognition", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the use of multi-view features and their discriminative\ntransforms in a convolutional deep neural network (CNN) architecture for a\ncontinuous large vocabulary speech recognition task. Mel-filterbank energies\nand perceptually motivated forced damped oscillator coefficient (DOC) features\nare used after feature-space maximum-likelihood linear regression (fMLLR)\ntransforms, which are combined and fed as a multi-view feature to a single CNN\nacoustic model. Use of multi-view feature representation demonstrated\nsignificant reduction in word error rates (WERs) compared to the use of\nindividual features by themselves. In addition, when articulatory information\nwas used as an additional input to a fused deep neural network (DNN) and CNN\nacoustic model, it was found to demonstrate further reduction in WER for the\nSwitchboard subset and the CallHome subset (containing partly non-native\naccented speech) of the NIST 2000 conversational telephone speech test set,\nreducing the error rate by 12% relative to the baseline in both cases. This\nwork shows that multi-view features in association with articulatory\ninformation can improve speech recognition robustness to spontaneous and\nnon-native speech.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 07:45:53 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Mitra", "Vikramjit", ""], ["Wang", "Wen", ""], ["Bartels", "Chris", ""], ["Franco", "Horacio", ""], ["Vergyri", "Dimitra", ""]]}, {"id": "1802.05883", "submitter": "Wilker Aziz", "authors": "Miguel Rios and Wilker Aziz and Khalil Sima'an", "title": "Deep Generative Model for Joint Alignment and Word Representation", "comments": "Accepted at NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work exploits translation data as a source of semantically relevant\nlearning signal for models of word representation. In particular, we exploit\nequivalence through translation as a form of distributed context and jointly\nlearn how to embed and align with a deep generative model. Our EmbedAlign model\nembeds words in their complete observed context and learns by marginalisation\nof latent lexical alignments. Besides, it embeds words as posterior probability\ndensities, rather than point estimates, which allows us to compare words in\ncontext using a measure of overlap between distributions (e.g. KL divergence).\nWe investigate our model's performance on a range of lexical semantics tasks\nachieving competitive results on several standard benchmarks including natural\nlanguage inference, paraphrasing, and text similarity.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 10:11:39 GMT"}, {"version": "v2", "created": "Mon, 26 Feb 2018 11:43:08 GMT"}, {"version": "v3", "created": "Mon, 23 Apr 2018 09:32:46 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Rios", "Miguel", ""], ["Aziz", "Wilker", ""], ["Sima'an", "Khalil", ""]]}, {"id": "1802.05930", "submitter": "Somnath Basu Roy Chowdhury", "authors": "K M Annervaz and Somnath Basu Roy Chowdhury and Ambedkar Dukkipati", "title": "Learning beyond datasets: Knowledge Graph Augmented Neural Networks for\n  Natural language Processing", "comments": "Accepted at NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning has been the quintessential solution for many AI problems,\nbut learning is still heavily dependent on the specific training data. Some\nlearning models can be incorporated with a prior knowledge in the Bayesian set\nup, but these learning models do not have the ability to access any organised\nworld knowledge on demand. In this work, we propose to enhance learning models\nwith world knowledge in the form of Knowledge Graph (KG) fact triples for\nNatural Language Processing (NLP) tasks. Our aim is to develop a deep learning\nmodel that can extract relevant prior support facts from knowledge graphs\ndepending on the task using attention mechanism. We introduce a\nconvolution-based model for learning representations of knowledge graph entity\nand relation clusters in order to reduce the attention space. We show that the\nproposed method is highly scalable to the amount of prior information that has\nto be processed and can be applied to any generic NLP task. Using this method\nwe show significant improvement in performance for text classification with\nNews20, DBPedia datasets and natural language inference with Stanford Natural\nLanguage Inference (SNLI) dataset. We also demonstrate that a deep learning\nmodel can be trained well with substantially less amount of labeled training\ndata, when it has access to organised world knowledge in the form of knowledge\ngraph.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 13:38:00 GMT"}, {"version": "v2", "created": "Mon, 21 May 2018 03:44:48 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Annervaz", "K M", ""], ["Chowdhury", "Somnath Basu Roy", ""], ["Dukkipati", "Ambedkar", ""]]}, {"id": "1802.05934", "submitter": "K. M. Annervaz", "authors": "Somnath Basu Roy Chowdhury and K M Annervaz and Ambedkar Dukkipati", "title": "Instance-based Inductive Deep Transfer Learning by Cross-Dataset\n  Querying with Locality Sensitive Hashing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised learning models are typically trained on a single dataset and the\nperformance of these models rely heavily on the size of the dataset, i.e.,\namount of data available with the ground truth. Learning algorithms try to\ngeneralize solely based on the data that is presented with during the training.\nIn this work, we propose an inductive transfer learning method that can augment\nlearning models by infusing similar instances from different learning tasks in\nthe Natural Language Processing (NLP) domain. We propose to use instance\nrepresentations from a source dataset, \\textit{without inheriting anything}\nfrom the source learning model. Representations of the instances of\n\\textit{source} \\& \\textit{target} datasets are learned, retrieval of relevant\nsource instances is performed using soft-attention mechanism and\n\\textit{locality sensitive hashing}, and then, augmented into the model during\ntraining on the target dataset. Our approach simultaneously exploits the local\n\\textit{instance level information} as well as the macro statistical viewpoint\nof the dataset. Using this approach we have shown significant improvements for\nthree major news classification datasets over the baseline. Experimental\nevaluations also show that the proposed approach reduces dependency on labeled\ndata by a significant margin for comparable performance. With our proposed\ncross dataset learning procedure we show that one can achieve\ncompetitive/better performance than learning from a single dataset.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 13:59:15 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Chowdhury", "Somnath Basu Roy", ""], ["Annervaz", "K M", ""], ["Dukkipati", "Ambedkar", ""]]}, {"id": "1802.06003", "submitter": "Takatomo Kano", "authors": "Takatomo Kano, Sakriani Sakti, Satoshi Nakamura", "title": "Structured-based Curriculum Learning for End-to-end English-Japanese\n  Speech Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-to-sequence attentional-based neural network architectures have been\nshown to provide a powerful model for machine translation and speech\nrecognition. Recently, several works have attempted to extend the models for\nend-to-end speech translation task. However, the usefulness of these models\nwere only investigated on language pairs with similar syntax and word order\n(e.g., English-French or English-Spanish). In this work, we focus on end-to-end\nspeech translation tasks on syntactically distant language pairs (e.g.,\nEnglish-Japanese) that require distant word reordering.\n  To guide the encoder-decoder attentional model to learn this difficult\nproblem, we propose a structured-based curriculum learning strategy.\n  Unlike conventional curriculum learning that gradually emphasizes difficult\ndata examples, we formalize learning strategies from easier network structures\nto more difficult network structures. Here, we start the training with\nend-to-end encoder-decoder for speech recognition or text-based machine\ntranslation task then gradually move to end-to-end speech translation task. The\nexperiment results show that the proposed approach could provide significant\nimprovements in comparison with the one without curriculum learning.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 11:33:27 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Kano", "Takatomo", ""], ["Sakti", "Sakriani", ""], ["Nakamura", "Satoshi", ""]]}, {"id": "1802.06006", "submitter": "Sercan Arik", "authors": "Sercan O. Arik, Jitong Chen, Kainan Peng, Wei Ping, Yanqi Zhou", "title": "Neural Voice Cloning with a Few Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice cloning is a highly desired feature for personalized speech interfaces.\nNeural network based speech synthesis has been shown to generate high quality\nspeech for a large number of speakers. In this paper, we introduce a neural\nvoice cloning system that takes a few audio samples as input. We study two\napproaches: speaker adaptation and speaker encoding. Speaker adaptation is\nbased on fine-tuning a multi-speaker generative model with a few cloning\nsamples. Speaker encoding is based on training a separate model to directly\ninfer a new speaker embedding from cloning audios and to be used with a\nmulti-speaker generative model. In terms of naturalness of the speech and its\nsimilarity to original speaker, both approaches can achieve good performance,\neven with very few cloning audios. While speaker adaptation can achieve better\nnaturalness and similarity, the cloning time or required memory for the speaker\nencoding approach is significantly less, making it favorable for low-resource\ndeployment.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 18:24:41 GMT"}, {"version": "v2", "created": "Tue, 20 Mar 2018 21:58:02 GMT"}, {"version": "v3", "created": "Fri, 12 Oct 2018 06:27:26 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Arik", "Sercan O.", ""], ["Chen", "Jitong", ""], ["Peng", "Kainan", ""], ["Ping", "Wei", ""], ["Zhou", "Yanqi", ""]]}, {"id": "1802.06007", "submitter": "Catalin Stoean", "authors": "Daniel Lichtblau, Catalin Stoean", "title": "Authorship Attribution Using the Chaos Game Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Chaos Game Representation, a method for creating images from nucleotide\nsequences, is modified to make images from chunks of text documents. Machine\nlearning methods are then applied to train classifiers based on authorship.\nExperiments are conducted on several benchmark data sets in English, including\nthe widely used Federalist Papers, and one in Portuguese. Validation results\nfor the trained classifiers are competitive with the best methods in prior\nliterature. The methodology is also successfully applied for text\ncategorization with encouraging results. One classifier method is moreover seen\nto hold promise for the task of digital fingerprinting.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 19:44:24 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Lichtblau", "Daniel", ""], ["Stoean", "Catalin", ""]]}, {"id": "1802.06024", "submitter": "Sahisnu Mazumder", "authors": "Sahisnu Mazumder, Nianzu Ma and Bing Liu", "title": "Towards a Continuous Knowledge Learning Engine for Chatbots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although chatbots have been very popular in recent years, they still have\nsome serious weaknesses which limit the scope of their applications. One major\nweakness is that they cannot learn new knowledge during the conversation\nprocess, i.e., their knowledge is fixed beforehand and cannot be expanded or\nupdated during conversation. In this paper, we propose to build a general\nknowledge learning engine for chatbots to enable them to continuously and\ninteractively learn new knowledge during conversations. As time goes by, they\nbecome more and more knowledgeable and better and better at learning and\nconversation. We model the task as an open-world knowledge base completion\nproblem and propose a novel technique called lifelong interactive learning and\ninference (LiLi) to solve it. LiLi works by imitating how humans acquire\nknowledge and perform inference during an interactive conversation. Our\nexperimental results show LiLi is highly promising.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 16:50:27 GMT"}, {"version": "v2", "created": "Sat, 24 Feb 2018 06:50:11 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Mazumder", "Sahisnu", ""], ["Ma", "Nianzu", ""], ["Liu", "Bing", ""]]}, {"id": "1802.06041", "submitter": "Marianna J. Martindale", "authors": "Marianna J. Martindale and Marine Carpuat", "title": "Fluency Over Adequacy: A Pilot Study in Measuring User Trust in\n  Imperfect MT", "comments": "To appear at AMTA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although measuring intrinsic quality has been a key factor in the advancement\nof Machine Translation (MT), successfully deploying MT requires considering not\njust intrinsic quality but also the user experience, including aspects such as\ntrust. This work introduces a method of studying how users modulate their trust\nin an MT system after seeing errorful (disfluent or inadequate) output amidst\ngood (fluent and adequate) output. We conduct a survey to determine how users\nrespond to good translations compared to translations that are either adequate\nbut not fluent, or fluent but not adequate. In this pilot study, users\nresponded strongly to disfluent translations, but were, surprisingly, much less\nconcerned with adequacy.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 17:34:32 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Martindale", "Marianna J.", ""], ["Carpuat", "Marine", ""]]}, {"id": "1802.06053", "submitter": "Lucas Ondel", "authors": "Lucas Ondel, Pierre Godard, Laurent Besacier, Elin Larsen, Mark\n  Hasegawa-Johnson, Odette Scharenborg, Emmanuel Dupoux, Lukas Burget,\n  Fran\\c{c}ois Yvon, Sanjeev Khudanpur", "title": "Bayesian Models for Unit Discovery on a Very Low Resource Language", "comments": "Accepted to ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing speech technologies for low-resource languages has become a very\nactive research field over the last decade. Among others, Bayesian models have\nshown some promising results on artificial examples but still lack of in situ\nexperiments. Our work applies state-of-the-art Bayesian models to unsupervised\nAcoustic Unit Discovery (AUD) in a real low-resource language scenario. We also\nshow that Bayesian models can naturally integrate information from other\nresourceful languages by means of informative prior leading to more consistent\ndiscovered units. Finally, discovered acoustic units are used, either as the\n1-best sequence or as a lattice, to perform word segmentation. Word\nsegmentation results show that this Bayesian approach clearly outperforms a\nSegmental-DTW baseline on the same corpus.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 17:58:43 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 15:35:32 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Ondel", "Lucas", ""], ["Godard", "Pierre", ""], ["Besacier", "Laurent", ""], ["Larsen", "Elin", ""], ["Hasegawa-Johnson", "Mark", ""], ["Scharenborg", "Odette", ""], ["Dupoux", "Emmanuel", ""], ["Burget", "Lukas", ""], ["Yvon", "Fran\u00e7ois", ""], ["Khudanpur", "Sanjeev", ""]]}, {"id": "1802.06079", "submitter": "Gerhard J\\\"ager", "authors": "Gerhard J\\\"ager", "title": "Global-scale phylogenetic linguistic inference from lexical resources", "comments": null, "journal-ref": null, "doi": "10.1038/sdata.2018.189", "report-no": null, "categories": "cs.CL q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic phylogenetic inference plays an increasingly important role in\ncomputational historical linguistics. Most pertinent work is currently based on\nexpert cognate judgments. This limits the scope of this approach to a small\nnumber of well-studied language families. We used machine learning techniques\nto compile data suitable for phylogenetic inference from the ASJP database, a\ncollection of almost 7,000 phonetically transcribed word lists over 40\nconcepts, covering two third of the extant world-wide linguistic diversity.\nFirst, we estimated Pointwise Mutual Information scores between sound classes\nusing weighted sequence alignment and general-purpose optimization. From this\nwe computed a dissimilarity matrix over all ASJP word lists. This matrix is\nsuitable for distance-based phylogenetic inference. Second, we applied cognate\nclustering to the ASJP data, using supervised training of an SVM classifier on\nexpert cognacy judgments. Third, we defined two types of binary characters,\nbased on automatically inferred cognate classes and on sound-class occurrences.\nSeveral tests are reported demonstrating the suitability of these characters\nfor character-based phylogenetic inference.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 13:51:59 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["J\u00e4ger", "Gerhard", ""]]}, {"id": "1802.06185", "submitter": "Amrith Krishna", "authors": "Vikas Reddy, Amrith Krishna, Vishnu Dutt Sharma, Prateek Gupta,\n  Vineeth M R, Pawan Goyal", "title": "Building a Word Segmenter for Sanskrit Overnight", "comments": "The work is accepted at LREC 2018, Miyazaki, Japan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an abundance of digitised texts available in Sanskrit. However, the\nword segmentation task in such texts are challenging due to the issue of\n'Sandhi'. In Sandhi, words in a sentence often fuse together to form a single\nchunk of text, where the word delimiter vanishes and sounds at the word\nboundaries undergo transformations, which is also reflected in the written\ntext. Here, we propose an approach that uses a deep sequence to sequence\n(seq2seq) model that takes only the sandhied string as the input and predicts\nthe unsandhied string. The state of the art models are linguistically involved\nand have external dependencies for the lexical and morphological analysis of\nthe input. Our model can be trained \"overnight\" and be used for production. In\nspite of the knowledge lean approach, our system preforms better than the\ncurrent state of the art by gaining a percentage increase of 16.79 % than the\ncurrent state of the art.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 04:05:36 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Reddy", "Vikas", ""], ["Krishna", "Amrith", ""], ["Sharma", "Vishnu Dutt", ""], ["Gupta", "Prateek", ""], ["R", "Vineeth M", ""], ["Goyal", "Pawan", ""]]}, {"id": "1802.06196", "submitter": "Abhik Jana", "authors": "Abhik Jana, Pawan Goyal", "title": "Can Network Embedding of Distributional Thesaurus be Combined with Word\n  Vectors for Better Representation?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed representations of words learned from text have proved to be\nsuccessful in various natural language processing tasks in recent times. While\nsome methods represent words as vectors computed from text using predictive\nmodel (Word2vec) or dense count based model (GloVe), others attempt to\nrepresent these in a distributional thesaurus network structure where the\nneighborhood of a word is a set of words having adequate context overlap. Being\nmotivated by recent surge of research in network embedding techniques\n(DeepWalk, LINE, node2vec etc.), we turn a distributional thesaurus network\ninto dense word vectors and investigate the usefulness of distributional\nthesaurus embedding in improving overall word representation. This is the first\nattempt where we show that combining the proposed word representation obtained\nby distributional thesaurus embedding with the state-of-the-art word\nrepresentations helps in improving the performance by a significant margin when\nevaluated against NLP tasks like word similarity and relatedness, synonym\ndetection, analogy detection. Additionally, we show that even without using any\nhandcrafted lexical resources we can come up with representations having\ncomparable performance in the word similarity and relatedness tasks compared to\nthe representations where a lexical resource has been used.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 05:52:23 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Jana", "Abhik", ""], ["Goyal", "Pawan", ""]]}, {"id": "1802.06209", "submitter": "Rajesh Kumar Muthu", "authors": "Maghilnan S, Rajesh Kumar M", "title": "Sentiment Analysis on Speaker Specific Speech Data", "comments": "Accepted and Published in 2017 IEEE International Conference on\n  Intelligent Computing and Control (I2C2), 23 Jun - 24 Jun 2017, India", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sentiment analysis has evolved over past few decades, most of the work in it\nrevolved around textual sentiment analysis with text mining techniques. But\naudio sentiment analysis is still in a nascent stage in the research community.\nIn this proposed research, we perform sentiment analysis on speaker\ndiscriminated speech transcripts to detect the emotions of the individual\nspeakers involved in the conversation. We analyzed different techniques to\nperform speaker discrimination and sentiment analysis to find efficient\nalgorithms to perform this task.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 08:39:47 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["S", "Maghilnan", ""], ["M", "Rajesh Kumar", ""]]}, {"id": "1802.06412", "submitter": "Florian Kreyssig", "authors": "Florian Kreyssig, Chao Zhang, Philip Woodland", "title": "Improved TDNNs using Deep Kernels and Frequency Dependent Grid-RNNs", "comments": "5 pages, 3 figures, 2 tables, to appear in 2018 IEEE International\n  Conference on Acoustics, Speech and Signal Processing (ICASSP 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time delay neural networks (TDNNs) are an effective acoustic model for large\nvocabulary speech recognition. The strength of the model can be attributed to\nits ability to effectively model long temporal contexts. However, current TDNN\nmodels are relatively shallow, which limits the modelling capability. This\npaper proposes a method of increasing the network depth by deepening the kernel\nused in the TDNN temporal convolutions. The best performing kernel consists of\nthree fully connected layers with a residual (ResNet) connection from the\noutput of the first to the output of the third. The addition of\nspectro-temporal processing as the input to the TDNN in the form of a\nconvolutional neural network (CNN) and a newly designed Grid-RNN was\ninvestigated. The Grid-RNN strongly outperforms a CNN if different sets of\nparameters for different frequency bands are used and can be further enhanced\nby using a bi-directional Grid-RNN. Experiments using the multi-genre broadcast\n(MGB3) English data (275h) show that deep kernel TDNNs reduces the word error\nrate (WER) by 6% relative and when combined with the frequency dependent\nGrid-RNN gives a relative WER reduction of 9%.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 17:54:19 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 14:07:05 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Kreyssig", "Florian", ""], ["Zhang", "Chao", ""], ["Woodland", "Philip", ""]]}, {"id": "1802.06428", "submitter": "Fengyi Tang", "authors": "Fengyi Tang, Kaixiang Lin, Ikechukwu Uchendu, Hiroko H. Dodge, Jiayu\n  Zhou", "title": "Improving Mild Cognitive Impairment Prediction via Reinforcement\n  Learning and Dialogue Simulation", "comments": "9 pages, 4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mild cognitive impairment (MCI) is a prodromal phase in the progression from\nnormal aging to dementia, especially Alzheimers disease. Even though there is\nmild cognitive decline in MCI patients, they have normal overall cognition and\nthus is challenging to distinguish from normal aging. Using transcribed data\nobtained from recorded conversational interactions between participants and\ntrained interviewers, and applying supervised learning models to these data, a\nrecent clinical trial has shown a promising result in differentiating MCI from\nnormal aging. However, the substantial amount of interactions with medical\nstaff can still incur significant medical care expenses in practice. In this\npaper, we propose a novel reinforcement learning (RL) framework to train an\nefficient dialogue agent on existing transcripts from clinical trials.\nSpecifically, the agent is trained to sketch disease-specific lexical\nprobability distribution, and thus to converse in a way that maximizes the\ndiagnosis accuracy and minimizes the number of conversation turns. We evaluate\nthe performance of the proposed reinforcement learning framework on the MCI\ndiagnosis from a real clinical trial. The results show that while using only a\nfew turns of conversation, our framework can significantly outperform\nstate-of-the-art supervised learning approaches.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 19:27:24 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Tang", "Fengyi", ""], ["Lin", "Kaixiang", ""], ["Uchendu", "Ikechukwu", ""], ["Dodge", "Hiroko H.", ""], ["Zhou", "Jiayu", ""]]}, {"id": "1802.06613", "submitter": "Ivan Habernal", "authors": "Ivan Habernal and Henning Wachsmuth and Iryna Gurevych and Benno Stein", "title": "Before Name-calling: Dynamics and Triggers of Ad Hominem Fallacies in\n  Web Argumentation", "comments": "Accepted as NAACL 2018 Long Paper; see details on the front page", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arguing without committing a fallacy is one of the main requirements of an\nideal debate. But even when debating rules are strictly enforced and fallacious\narguments punished, arguers often lapse into attacking the opponent by an ad\nhominem argument. As existing research lacks solid empirical investigation of\nthe typology of ad hominem arguments as well as their potential causes, this\npaper fills this gap by (1) performing several large-scale annotation studies,\n(2) experimenting with various neural architectures and validating our working\nhypotheses, such as controversy or reasonableness, and (3) providing linguistic\ninsights into triggers of ad hominem using explainable neural network\narchitectures.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 12:57:56 GMT"}, {"version": "v2", "created": "Fri, 23 Feb 2018 09:46:21 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Habernal", "Ivan", ""], ["Wachsmuth", "Henning", ""], ["Gurevych", "Iryna", ""], ["Stein", "Benno", ""]]}, {"id": "1802.06655", "submitter": "Antonios Anastasopoulos", "authors": "Antonios Anastasopoulos and David Chiang", "title": "Tied Multitask Learning for Neural Speech Translation", "comments": "accepted at NAACL-HLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore multitask models for neural translation of speech, augmenting them\nin order to reflect two intuitive notions. First, we introduce a model where\nthe second task decoder receives information from the decoder of the first\ntask, since higher-level intermediate representations should provide useful\ninformation. Second, we apply regularization that encourages transitivity and\ninvertibility. We show that the application of these notions on jointly trained\nmodels improves performance on the tasks of low-resource speech transcription\nand translation. It also leads to better performance when using attention\ninformation for word discovery over unsegmented input.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 14:49:42 GMT"}, {"version": "v2", "created": "Thu, 26 Apr 2018 07:19:25 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Anastasopoulos", "Antonios", ""], ["Chiang", "David", ""]]}, {"id": "1802.06757", "submitter": "Pau Rodr\\'iguez L\\'opez", "authors": "Guillem Cucurull, Pau Rodr\\'iguez, V. Oguz Yazici, Josep M. Gonfaus,\n  F. Xavier Roca, Jordi Gonz\\`alez", "title": "Deep Inference of Personality Traits by Integrating Image and Word Use\n  in Social Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media, as a major platform for communication and information exchange,\nis a rich repository of the opinions and sentiments of 2.3 billion users about\na vast spectrum of topics. To sense the whys of certain social user's demands\nand cultural-driven interests, however, the knowledge embedded in the 1.8\nbillion pictures which are uploaded daily in public profiles has just started\nto be exploited since this process has been typically been text-based.\nFollowing this trend on visual-based social analysis, we present a novel\nmethodology based on Deep Learning to build a combined image-and-text based\npersonality trait model, trained with images posted together with words found\nhighly correlated to specific personality traits. So the key contribution here\nis to explore whether OCEAN personality trait modeling can be addressed based\non images, here called \\emph{Mind{P}ics}, appearing with certain tags with\npsychological insights. We found that there is a correlation between those\nposted images and their accompanying texts, which can be successfully modeled\nusing deep neural networks for personality estimation. The experimental results\nare consistent with previous cyber-psychology results based on texts or images.\nIn addition, classification results on some traits show that some patterns\nemerge in the set of images corresponding to a specific text, in essence to\nthose representing an abstract concept. These results open new avenues of\nresearch for further refining the proposed personality model under the\nsupervision of psychology experts.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 11:58:58 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Cucurull", "Guillem", ""], ["Rodr\u00edguez", "Pau", ""], ["Yazici", "V. Oguz", ""], ["Gonfaus", "Josep M.", ""], ["Roca", "F. Xavier", ""], ["Gonz\u00e0lez", "Jordi", ""]]}, {"id": "1802.06764", "submitter": "Maurizio Serva", "authors": "Michele Pasquini and Maurizio Serva", "title": "Stability of meanings versus rate of replacement of words: an\n  experimental test", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The words of a language are randomly replaced in time by new ones, but it has\nlong been known that words corresponding to some items (meanings) are less\nfrequently replaced than others. Usually, the rate of replacement for a given\nitem is not directly observable, but it is inferred by the estimated stability\nwhich, on the contrary, is observable. This idea goes back a long way in the\nlexicostatistical literature, nevertheless nothing ensures that it gives the\ncorrect answer. The family of Romance languages allows for a direct test of the\nestimated stabilities against the replacement rates since the proto-language\n(Latin) is known and the replacement rates can be explicitly computed. The\noutput of the test is threefold:first, we prove that the standard approach\nwhich tries to infer the replacement rates trough the estimated stabilities is\nsound; second, we are able to rewrite the fundamental formula of\nGlottochronology for a non universal replacement rate (a rate which depends on\nthe item); third, we give indisputable evidence that the stability ranking is\nfar from being the same for different families of languages. This last result\nis also supported by comparison with the Malagasy family of dialects. As a side\nresult we also provide some evidence that Vulgar Latin and not Late Classical\nLatin is at the root of modern Romance languages.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 17:45:53 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 12:41:15 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Pasquini", "Michele", ""], ["Serva", "Maurizio", ""]]}, {"id": "1802.06842", "submitter": "Hady Elsahar", "authors": "Hady Elsahar, Christophe Gravier, Frederique Laforest", "title": "Zero-Shot Question Generation from Knowledge Graphs for Unseen\n  Predicates and Entity Types", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a neural model for question generation from knowledge base triples\nin a \"Zero-Shot\" setup, that is generating questions for triples containing\npredicates, subject types or object types that were not seen at training time.\nOur model leverages triples occurrences in the natural language corpus in an\nencoder-decoder architecture, paired with an original part-of-speech copy\naction mechanism to generate questions. Benchmark and human evaluation show\nthat our model sets a new state-of-the-art for zero-shot QG.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 20:43:53 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Elsahar", "Hady", ""], ["Gravier", "Christophe", ""], ["Laforest", "Frederique", ""]]}, {"id": "1802.06861", "submitter": "Vikramjit Mitra", "authors": "Vikramjit Mitra and Horacio Franco", "title": "Interpreting DNN output layer activations: A strategy to cope with\n  unseen data in speech recognition", "comments": "5 pages. arXiv admin note: substantial text overlap with\n  arXiv:1708.09516", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unseen data can degrade performance of deep neural net acoustic models. To\ncope with unseen data, adaptation techniques are deployed. For unlabeled unseen\ndata, one must generate some hypothesis given an existing model, which is used\nas the label for model adaptation. However, assessing the goodness of the\nhypothesis can be difficult, and an erroneous hypothesis can lead to poorly\ntrained models. In such cases, a strategy to select data having reliable\nhypothesis can ensure better model adaptation. This work proposes a\ndata-selection strategy for DNN model adaptation, where DNN output layer\nactivations are used to ascertain the goodness of a generated hypothesis. In a\nDNN acoustic model, the output layer activations are used to generate target\nclass probabilities. Under unseen data conditions, the difference between the\nmost probable target and the next most probable target is decreased compared to\nthe same for seen data, indicating that the model may be uncertain while\ngenerating its hypothesis. This work proposes a strategy to assess a model's\nperformance by analyzing the output layer activations by using a distance\nmeasure between the most likely target and the next most likely target, which\nis used for data selection for performing unsupervised adaptation.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 07:42:35 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Mitra", "Vikramjit", ""], ["Franco", "Horacio", ""]]}, {"id": "1802.06893", "submitter": "Edouard Grave", "authors": "Edouard Grave, Piotr Bojanowski, Prakhar Gupta, Armand Joulin, Tomas\n  Mikolov", "title": "Learning Word Vectors for 157 Languages", "comments": "Accepted to LREC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed word representations, or word vectors, have recently been applied\nto many tasks in natural language processing, leading to state-of-the-art\nperformance. A key ingredient to the successful application of these\nrepresentations is to train them on very large corpora, and use these\npre-trained models in downstream tasks. In this paper, we describe how we\ntrained such high quality word representations for 157 languages. We used two\nsources of data to train these models: the free online encyclopedia Wikipedia\nand data from the common crawl project. We also introduce three new word\nanalogy datasets to evaluate these word vectors, for French, Hindi and Polish.\nFinally, we evaluate our pre-trained word vectors on 10 languages for which\nevaluation datasets exists, showing very strong performance compared to\nprevious models.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 22:32:47 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 18:00:30 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Grave", "Edouard", ""], ["Bojanowski", "Piotr", ""], ["Gupta", "Prakhar", ""], ["Joulin", "Armand", ""], ["Mikolov", "Tomas", ""]]}, {"id": "1802.06894", "submitter": "Kejun Huang", "authors": "Kejun Huang, Xiao Fu, Nicholas D. Sidiropoulos", "title": "Learning Hidden Markov Models from Pairwise Co-occurrences with\n  Application to Topic Modeling", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm for identifying the transition and emission\nprobabilities of a hidden Markov model (HMM) from the emitted data.\nExpectation-maximization becomes computationally prohibitive for long\nobservation records, which are often required for identification. The new\nalgorithm is particularly suitable for cases where the available sample size is\nlarge enough to accurately estimate second-order output probabilities, but not\nhigher-order ones. We show that if one is only able to obtain a reliable\nestimate of the pairwise co-occurrence probabilities of the emissions, it is\nstill possible to uniquely identify the HMM if the emission probability is\n\\emph{sufficiently scattered}. We apply our method to hidden topic Markov\nmodeling, and demonstrate that we can learn topics with higher quality if\ndocuments are modeled as observations of HMMs sharing the same emission (topic)\nprobability, compared to the simple but widely used bag-of-words model.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 22:33:56 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2018 21:15:46 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Huang", "Kejun", ""], ["Fu", "Xiao", ""], ["Sidiropoulos", "Nicholas D.", ""]]}, {"id": "1802.06901", "submitter": "Jason Lee", "authors": "Jason Lee, Elman Mansimov, Kyunghyun Cho", "title": "Deterministic Non-Autoregressive Neural Sequence Modeling by Iterative\n  Refinement", "comments": "Accepted to EMNLP'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a conditional non-autoregressive neural sequence model based on\niterative refinement. The proposed model is designed based on the principles of\nlatent variable models and denoising autoencoders, and is generally applicable\nto any sequence generation task. We extensively evaluate the proposed model on\nmachine translation (En-De and En-Ro) and image caption generation, and observe\nthat it significantly speeds up decoding while maintaining the generation\nquality comparable to the autoregressive counterpart.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 22:57:54 GMT"}, {"version": "v2", "created": "Tue, 17 Apr 2018 21:20:55 GMT"}, {"version": "v3", "created": "Mon, 27 Aug 2018 18:00:08 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Lee", "Jason", ""], ["Mansimov", "Elman", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1802.06941", "submitter": "Jiangyan Yi", "authors": "Jiangyan Yi, Jianhua Tao, Zhengqi Wen, Bin Liu", "title": "Distilling Knowledge Using Parallel Data for Far-field Speech\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to improve the performance for far-field speech recognition, this\npaper proposes to distill knowledge from the close-talking model to the\nfar-field model using parallel data. The close-talking model is called the\nteacher model. The far-field model is called the student model. The student\nmodel is trained to imitate the output distributions of the teacher model. This\nconstraint can be realized by minimizing the Kullback-Leibler (KL) divergence\nbetween the output distribution of the student model and the teacher model.\nExperimental results on AMI corpus show that the best student model achieves up\nto 4.7% absolute word error rate (WER) reduction when compared with the\nconventionally-trained baseline models.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 02:51:34 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Yi", "Jiangyan", ""], ["Tao", "Jianhua", ""], ["Wen", "Zhengqi", ""], ["Liu", "Bin", ""]]}, {"id": "1802.06950", "submitter": "Tirthankar Ghosal", "authors": "Tirthankar Ghosal, Amitra Salam, Swati Tiwari, Asif Ekbal, Pushpak\n  Bhattacharyya", "title": "TAP-DLND 1.0 : A Corpus for Document Level Novelty Detection", "comments": "Accepted for publication in Language Resources and Evaluation\n  Conference (LREC) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Detecting novelty of an entire document is an Artificial Intelligence (AI)\nfrontier problem that has widespread NLP applications, such as extractive\ndocument summarization, tracking development of news events, predicting impact\nof scholarly articles, etc. Important though the problem is, we are unaware of\nany benchmark document level data that correctly addresses the evaluation of\nautomatic novelty detection techniques in a classification framework. To bridge\nthis gap, we present here a resource for benchmarking the techniques for\ndocument level novelty detection. We create the resource via event-specific\ncrawling of news documents across several domains in a periodic manner. We\nrelease the annotated corpus with necessary statistics and show its use with a\ndeveloped system for the problem in concern.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 03:42:11 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Ghosal", "Tirthankar", ""], ["Salam", "Amitra", ""], ["Tiwari", "Swati", ""], ["Ekbal", "Asif", ""], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "1802.07089", "submitter": "Qiuyuan Huang", "authors": "Qiuyuan Huang, Li Deng, Dapeng Wu, Chang Liu, Xiaodong He", "title": "Attentive Tensor Product Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new architecture - Attentive Tensor Product Learning\n(ATPL) - to represent grammatical structures in deep learning models. ATPL is a\nnew architecture to bridge this gap by exploiting Tensor Product\nRepresentations (TPR), a structured neural-symbolic model developed in\ncognitive science, aiming to integrate deep learning with explicit language\nstructures and rules. The key ideas of ATPL are: 1) unsupervised learning of\nrole-unbinding vectors of words via TPR-based deep neural network; 2) employing\nattention modules to compute TPR; and 3) integration of TPR with typical deep\nlearning architectures including Long Short-Term Memory (LSTM) and Feedforward\nNeural Network (FFNN). The novelty of our approach lies in its ability to\nextract the grammatical structure of a sentence by using role-unbinding\nvectors, which are obtained in an unsupervised manner. This ATPL approach is\napplied to 1) image captioning, 2) part of speech (POS) tagging, and 3)\nconstituency parsing of a sentence. Experimental results demonstrate the\neffectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 12:42:07 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 05:14:18 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Huang", "Qiuyuan", ""], ["Deng", "Li", ""], ["Wu", "Dapeng", ""], ["Liu", "Chang", ""], ["He", "Xiaodong", ""]]}, {"id": "1802.07117", "submitter": "Ana Paula Appel", "authors": "Ana Paula Appel, Paulo Rodrigo Cavalin, Marisa Affonso Vasconcelos,\n  Claudio Santos Pinhanez", "title": "Combining Textual Content and Structure to Improve Dialog Similarity", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chatbots, taking advantage of the success of the messaging apps and recent\nadvances in Artificial Intelligence, have become very popular, from helping\nbusiness to improve customer services to chatting to users for the sake of\nconversation and engagement (celebrity or personal bots). However, developing\nand improving a chatbot requires understanding their data generated by its\nusers. Dialog data has a different nature of a simple question and answering\ninteraction, in which context and temporal properties (turn order) creates a\ndifferent understanding of such data. In this paper, we propose a novelty\nmetric to compute dialogs' similarity based not only on the text content but\nalso on the information related to the dialog structure. Our experimental\nresults performed over the Switchboard dataset show that using evidence from\nboth textual content and the dialog structure leads to more accurate results\nthan using each measure in isolation.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 14:05:48 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Appel", "Ana Paula", ""], ["Cavalin", "Paulo Rodrigo", ""], ["Vasconcelos", "Marisa Affonso", ""], ["Pinhanez", "Claudio Santos", ""]]}, {"id": "1802.07170", "submitter": "Xiaolin Wang", "authors": "Xiaolin Wang, Masao Utiyama, Eiichiro Sumita", "title": "CytonMT: an Efficient Neural Machine Translation Open-source Toolkit\n  Implemented in C++", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an open-source neural machine translation toolkit named\nCytonMT (https://github.com/arthurxlw/cytonMt). The toolkit is built from\nscratch only using C++ and NVIDIA's GPU-accelerated libraries. The toolkit\nfeatures training efficiency, code simplicity and translation quality.\nBenchmarks show that CytonMT accelerates the training speed by 64.5% to 110.8%\non neural networks of various sizes, and achieves competitive translation\nquality.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 03:11:50 GMT"}, {"version": "v2", "created": "Sat, 2 Jun 2018 06:03:39 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Wang", "Xiaolin", ""], ["Utiyama", "Masao", ""], ["Sumita", "Eiichiro", ""]]}, {"id": "1802.07226", "submitter": "Pengxiang Cheng", "authors": "Pengxiang Cheng, Katrin Erk", "title": "Implicit Argument Prediction with Event Knowledge", "comments": "NAACL 2018; Camera-Ready Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit arguments are not syntactically connected to their predicates, and\nare therefore hard to extract. Previous work has used models with large numbers\nof features, evaluated on very small datasets. We propose to train models for\nimplicit argument prediction on a simple cloze task, for which data can be\ngenerated automatically at scale. This allows us to use a neural model, which\ndraws on narrative coherence and entity salience for predictions. We show that\nour model has superior performance on both synthetic and natural data.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 18:04:46 GMT"}, {"version": "v2", "created": "Fri, 13 Apr 2018 00:34:00 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Cheng", "Pengxiang", ""], ["Erk", "Katrin", ""]]}, {"id": "1802.07370", "submitter": "Siddhartha Brahma", "authors": "Siddhartha Brahma", "title": "SufiSent - Universal Sentence Representations Using Suffix Encodings", "comments": "4 pages, Submitted to ICLR 2018 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing universal distributed representations of sentences is a fundamental\ntask in natural language processing. We propose a method to learn such\nrepresentations by encoding the suffixes of word sequences in a sentence and\ntraining on the Stanford Natural Language Inference (SNLI) dataset. We\ndemonstrate the effectiveness of our approach by evaluating it on the SentEval\nbenchmark, improving on existing approaches on several transfer tasks.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 23:08:19 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Brahma", "Siddhartha", ""]]}, {"id": "1802.07374", "submitter": "Siddhartha Brahma", "authors": "Siddhartha Brahma", "title": "On the scaling of polynomial features for representation matching", "comments": "4 pages, Submitted to ICLR 2018 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many neural models, new features as polynomial functions of existing ones\nare used to augment representations. Using the natural language inference task\nas an example, we investigate the use of scaled polynomials of degree 2 and\nabove as matching features. We find that scaling degree 2 features has the\nhighest impact on performance, reducing classification error by 5% in the best\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 23:22:25 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Brahma", "Siddhartha", ""]]}, {"id": "1802.07420", "submitter": "Siddharth Dalmia", "authors": "Siddharth Dalmia, Ramon Sanabria, Florian Metze and Alan W. Black", "title": "Sequence-based Multi-lingual Low Resource Speech Recognition", "comments": "5 pages, 5 figures, to appear in 2018 IEEE International Conference\n  on Acoustics, Speech and Signal Processing (ICASSP 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Techniques for multi-lingual and cross-lingual speech recognition can help in\nlow resource scenarios, to bootstrap systems and enable analysis of new\nlanguages and domains. End-to-end approaches, in particular sequence-based\ntechniques, are attractive because of their simplicity and elegance. While it\nis possible to integrate traditional multi-lingual bottleneck feature\nextractors as front-ends, we show that end-to-end multi-lingual training of\nsequence models is effective on context independent models trained using\nConnectionist Temporal Classification (CTC) loss. We show that our model\nimproves performance on Babel languages by over 6% absolute in terms of\nword/phoneme error rate when compared to mono-lingual systems built in the same\nsetting for these languages. We also show that the trained model can be adapted\ncross-lingually to an unseen language using just 25% of the target data. We\nshow that training on multiple languages is important for very low resource\ncross-lingual target scenarios, but not for multi-lingual testing scenarios.\nHere, it appears beneficial to include large well prepared datasets.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 04:09:26 GMT"}, {"version": "v2", "created": "Tue, 6 Mar 2018 19:51:21 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Dalmia", "Siddharth", ""], ["Sanabria", "Ramon", ""], ["Metze", "Florian", ""], ["Black", "Alan W.", ""]]}, {"id": "1802.07459", "submitter": "Bang Liu", "authors": "Bang Liu, Di Niu, Haojie Wei, Jinghong Lin, Yancheng He, Kunfeng Lai,\n  Yu Xu", "title": "Matching Article Pairs with Graphical Decomposition and Convolutions", "comments": "Accepted by ACL 2019 as long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying the relationship between two articles, e.g., whether two articles\npublished from different sources describe the same breaking news, is critical\nto many document understanding tasks. Existing approaches for modeling and\nmatching sentence pairs do not perform well in matching longer documents, which\nembody more complex interactions between the enclosed entities than a sentence\ndoes. To model article pairs, we propose the Concept Interaction Graph to\nrepresent an article as a graph of concepts. We then match a pair of articles\nby comparing the sentences that enclose the same concept vertex through a\nseries of encoding techniques, and aggregate the matching signals through a\ngraph convolutional network. To facilitate the evaluation of long article\nmatching, we have created two datasets, each consisting of about 30K pairs of\nbreaking news articles covering diverse topics in the open domain. Extensive\nevaluations of the proposed methods on the two datasets demonstrate significant\nimprovements over a wide range of state-of-the-art methods for natural language\nmatching.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 08:01:41 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 12:40:06 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Liu", "Bang", ""], ["Niu", "Di", ""], ["Wei", "Haojie", ""], ["Lin", "Jinghong", ""], ["He", "Yancheng", ""], ["Lai", "Kunfeng", ""], ["Xu", "Yu", ""]]}, {"id": "1802.07839", "submitter": "Kevin Tian", "authors": "Kevin Tian, Teng Zhang, James Zou", "title": "CoVeR: Learning Covariate-Specific Vector Representations with Tensor\n  Decompositions", "comments": "12 pages. Appears in ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embedding is a useful approach to capture co-occurrence structures in\nlarge text corpora. However, in addition to the text data itself, we often have\nadditional covariates associated with individual corpus documents---e.g. the\ndemographic of the author, time and venue of publication---and we would like\nthe embedding to naturally capture this information. We propose CoVeR, a new\ntensor decomposition model for vector embeddings with covariates. CoVeR jointly\nlearns a \\emph{base} embedding for all the words as well as a weighted diagonal\nmatrix to model how each covariate affects the base embedding. To obtain author\nor venue-specific embedding, for example, we can then simply multiply the base\nembedding by the associated transformation matrix. The main advantages of our\napproach are data efficiency and interpretability of the covariate\ntransformation. Our experiments demonstrate that our joint model learns\nsubstantially better covariate-specific embeddings compared to the standard\napproach of learning a separate embedding for each covariate using only the\nrelevant subset of data, as well as other related methods. Furthermore, CoVeR\nencourages the embeddings to be \"topic-aligned\" in that the dimensions have\nspecific independent meanings. This allows our covariate-specific embeddings to\nbe compared by topic, enabling downstream differential analysis. We empirically\nevaluate the benefits of our algorithm on datasets, and demonstrate how it can\nbe used to address many natural questions about covariate effects.\n  Accompanying code to this paper can be found at\nhttp://github.com/kjtian/CoVeR.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 22:52:35 GMT"}, {"version": "v2", "created": "Sat, 7 Jul 2018 07:19:41 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Tian", "Kevin", ""], ["Zhang", "Teng", ""], ["Zou", "James", ""]]}, {"id": "1802.07858", "submitter": "Sudipta Kar", "authors": "Sudipta Kar and Suraj Maharjan and A. Pastor L\\'opez-Monroy and Thamar\n  Solorio", "title": "MPST: A Corpus of Movie Plot Synopses with Tags", "comments": "Accepted at LREC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social tagging of movies reveals a wide range of heterogeneous information\nabout movies, like the genre, plot structure, soundtracks, metadata, visual and\nemotional experiences. Such information can be valuable in building automatic\nsystems to create tags for movies. Automatic tagging systems can help\nrecommendation engines to improve the retrieval of similar movies as well as\nhelp viewers to know what to expect from a movie in advance. In this paper, we\nset out to the task of collecting a corpus of movie plot synopses and tags. We\ndescribe a methodology that enabled us to build a fine-grained set of around 70\ntags exposing heterogeneous characteristics of movie plots and the multi-label\nassociations of these tags with some 14K movie plot synopses. We investigate\nhow these tags correlate with movies and the flow of emotions throughout\ndifferent types of movies. Finally, we use this corpus to explore the\nfeasibility of inferring tags from plot synopses. We expect the corpus will be\nuseful in other tasks where analysis of narratives is relevant.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 00:27:54 GMT"}, {"version": "v2", "created": "Fri, 23 Feb 2018 04:04:44 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Kar", "Sudipta", ""], ["Maharjan", "Suraj", ""], ["L\u00f3pez-Monroy", "A. Pastor", ""], ["Solorio", "Thamar", ""]]}, {"id": "1802.07859", "submitter": "Zubair Shah", "authors": "Zubair Shah, Paige Martin, Enrico Coiera, Kenneth D. Mandl, Adam G.\n  Dunn", "title": "Modeling Spatiotemporal Factors Associated With Sentiment on Twitter:\n  Synthesis and Suggestions for Improving the Identification of Localized\n  Deviations", "comments": "18 pages, 7 figures, published in JMIR (doi:10.2196/12881)", "journal-ref": "(J Med Internet Res 2019;21(5):e12881", "doi": "10.2196/12881", "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Studies examining how sentiment on social media varies depending\non timing and location appear to produce inconsistent results, making it hard\nto design systems that use sentiment to detect localized events for public\nhealth applications.\n  Objective: The aim of this study was to measure how common timing and\nlocation confounders explain variation in sentiment on Twitter.\n  Methods: Using a dataset of 16.54 million English-language tweets from 100\ncities posted between July 13 and November 30, 2017, we estimated the positive\nand negative sentiment for each of the cities using a dictionary-based\nsentiment analysis and constructed models to explain the differences in\nsentiment using time of day, day of week, weather, city, and interaction type\n(conversations or broadcasting) as factors and found that all factors were\nindependently associated with sentiment.\n  Results: In the full multivariable model of positive (Pearson r in test data\n0.236; 95\\% CI 0.231-0.241) and negative (Pearson r in test data 0.306; 95\\% CI\n0.301-0.310) sentiment, the city and time of day explained more of the variance\nthan weather and day of week. Models that account for these confounders produce\na different distribution and ranking of important events compared with models\nthat do not account for these confounders.\n  Conclusions: In public health applications that aim to detect localized\nevents by aggregating sentiment across populations of Twitter users, it is\nworthwhile accounting for baseline differences before looking for unexpected\nchanges.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 00:37:32 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 03:16:03 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Shah", "Zubair", ""], ["Martin", "Paige", ""], ["Coiera", "Enrico", ""], ["Mandl", "Kenneth D.", ""], ["Dunn", "Adam G.", ""]]}, {"id": "1802.07860", "submitter": "Panayiotis Georgiou", "authors": "Arindam Jati and Panayiotis Georgiou", "title": "Neural Predictive Coding using Convolutional Neural Networks towards\n  Unsupervised Learning of Speaker Characteristics", "comments": null, "journal-ref": "IEEE/ACM Transactions on Audio, Speech, and Language Processing,\n  vol. 27, no. 10, pp. 1577-1589, Oct. 2019", "doi": "10.1109/TASLP.2019.2921890", "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning speaker-specific features is vital in many applications like speaker\nrecognition, diarization and speech recognition. This paper provides a novel\napproach, we term Neural Predictive Coding (NPC), to learn speaker-specific\ncharacteristics in a completely unsupervised manner from large amounts of\nunlabeled training data that even contain many non-speech events and\nmulti-speaker audio streams. The NPC framework exploits the proposed short-term\nactive-speaker stationarity hypothesis which assumes two temporally-close short\nspeech segments belong to the same speaker, and thus a common representation\nthat can encode the commonalities of both the segments, should capture the\nvocal characteristics of that speaker. We train a convolutional deep siamese\nnetwork to produce \"speaker embeddings\" by learning to separate `same' vs\n`different' speaker pairs which are generated from an unlabeled data of audio\nstreams. Two sets of experiments are done in different scenarios to evaluate\nthe strength of NPC embeddings and compare with state-of-the-art in-domain\nsupervised methods. First, two speaker identification experiments with\ndifferent context lengths are performed in a scenario with comparatively\nlimited within-speaker channel variability. NPC embeddings are found to perform\nthe best at short duration experiment, and they provide complementary\ninformation to i-vectors for full utterance experiments. Second, a large scale\nspeaker verification task having a wide range of within-speaker channel\nvariability is adopted as an upper-bound experiment where comparisons are drawn\nwith in-domain supervised methods.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 00:37:49 GMT"}, {"version": "v2", "created": "Thu, 25 Apr 2019 23:27:08 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Jati", "Arindam", ""], ["Georgiou", "Panayiotis", ""]]}, {"id": "1802.07862", "submitter": "Seungwhan Moon", "authors": "Seungwhan Moon, Leonardo Neves, Vitor Carvalho", "title": "Multimodal Named Entity Recognition for Short Social Media Posts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new task called Multimodal Named Entity Recognition (MNER) for\nnoisy user-generated data such as tweets or Snapchat captions, which comprise\nshort text with accompanying images. These social media posts often come in\ninconsistent or incomplete syntax and lexical notations with very limited\nsurrounding textual contexts, bringing significant challenges for NER. To this\nend, we create a new dataset for MNER called SnapCaptions (Snapchat\nimage-caption pairs submitted to public and crowd-sourced stories with fully\nannotated named entities). We then build upon the state-of-the-art Bi-LSTM\nword/character based NER models with 1) a deep image network which incorporates\nrelevant visual context to augment textual information, and 2) a generic\nmodality-attention module which learns to attenuate irrelevant modalities while\namplifying the most informative ones to extract contexts from, adaptive to each\nsample and token. The proposed MNER model with modality attention significantly\noutperforms the state-of-the-art text-only NER models by successfully\nleveraging provided visual contexts, opening up potential applications of MNER\non myriads of social media platforms.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 00:54:47 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Moon", "Seungwhan", ""], ["Neves", "Leonardo", ""], ["Carvalho", "Vitor", ""]]}, {"id": "1802.07997", "submitter": "Dar\\'io Garigliotti", "authors": "Heng Ding, Shuo Zhang, Dar\\'io Garigliotti, and Krisztian Balog", "title": "Generating High-Quality Query Suggestion Candidates for Task-Based\n  Search", "comments": "Advances in Information Retrieval. Proceedings of the 40th European\n  Conference on Information Retrieval (ECIR '18), 2018", "journal-ref": null, "doi": "10.1007/978-3-319-76941-7_54", "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the task of generating query suggestions for task-based search.\nThe current state of the art relies heavily on suggestions provided by a major\nsearch engine. In this paper, we solve the task without reliance on search\nengines. Specifically, we focus on the first step of a two-stage pipeline\napproach, which is dedicated to the generation of query suggestion candidates.\nWe present three methods for generating candidate suggestions and apply them on\nmultiple information sources. Using a purpose-built test collection, we find\nthat these methods are able to generate high-quality suggestion candidates.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 11:55:28 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Ding", "Heng", ""], ["Zhang", "Shuo", ""], ["Garigliotti", "Dar\u00edo", ""], ["Balog", "Krisztian", ""]]}, {"id": "1802.08010", "submitter": "Dar\\'io Garigliotti", "authors": "Dar\\'io Garigliotti and Krisztian Balog", "title": "Towards an Understanding of Entity-Oriented Search Intents", "comments": "Advances in Information Retrieval. Proceedings of the 40th European\n  Conference on Information Retrieval (ECIR '18), 2018", "journal-ref": null, "doi": "10.1007/978-3-319-76941-7_57", "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity-oriented search deals with a wide variety of information needs, from\ndisplaying direct answers to interacting with services. In this work, we aim to\nunderstand what are prominent entity-oriented search intents and how they can\nbe fulfilled. We develop a scheme of entity intent categories, and use them to\nannotate a sample of queries. Specifically, we annotate unique query refiners\non the level of entity types. We observe that, on average, over half of those\nrefiners seek to interact with a service, while over a quarter of the refiners\nsearch for information that may be looked up in a knowledge base.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 12:30:13 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Garigliotti", "Dar\u00edo", ""], ["Balog", "Krisztian", ""]]}, {"id": "1802.08129", "submitter": "Dong Huk Park", "authors": "Dong Huk Park, Lisa Anne Hendricks, Zeynep Akata, Anna Rohrbach, Bernt\n  Schiele, Trevor Darrell, Marcus Rohrbach", "title": "Multimodal Explanations: Justifying Decisions and Pointing to the\n  Evidence", "comments": "arXiv admin note: text overlap with arXiv:1612.04757", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep models that are both effective and explainable are desirable in many\nsettings; prior explainable models have been unimodal, offering either\nimage-based visualization of attention weights or text-based generation of\npost-hoc justifications. We propose a multimodal approach to explanation, and\nargue that the two modalities provide complementary explanatory strengths. We\ncollect two new datasets to define and evaluate this task, and propose a novel\nmodel which can provide joint textual rationale generation and attention\nvisualization. Our datasets define visual and textual justifications of a\nclassification decision for activity recognition tasks (ACT-X) and for visual\nquestion answering tasks (VQA-X). We quantitatively show that training with the\ntextual explanations not only yields better textual justification models, but\nalso better localizes the evidence that supports the decision. We also\nqualitatively show cases where visual explanation is more insightful than\ntextual explanation, and vice versa, supporting our thesis that multimodal\nexplanation models offer significant benefits over unimodal approaches.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 19:12:03 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Park", "Dong Huk", ""], ["Hendricks", "Lisa Anne", ""], ["Akata", "Zeynep", ""], ["Rohrbach", "Anna", ""], ["Schiele", "Bernt", ""], ["Darrell", "Trevor", ""], ["Rohrbach", "Marcus", ""]]}, {"id": "1802.08148", "submitter": "Diego Moussallem", "authors": "Diego Moussallem, Mohamed Ahmed Sherif, Diego Esteves, Marcos Zampieri\n  and Axel-Cyrille Ngonga Ngomo", "title": "LIDIOMS: A Multilingual Linked Idioms Data Set", "comments": "Accepted for publication in Language Resources and Evaluation\n  Conference (LREC) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe the LIDIOMS data set, a multilingual RDF\nrepresentation of idioms currently containing five languages: English, German,\nItalian, Portuguese, and Russian. The data set is intended to support natural\nlanguage processing applications by providing links between idioms across\nlanguages. The underlying data was crawled and integrated from various sources.\nTo ensure the quality of the crawled data, all idioms were evaluated by at\nleast two native speakers. Herein, we present the model devised for structuring\nthe data. We also provide the details of linking LIDIOMS to well-known\nmultilingual data sets such as BabelNet. The resulting data set complies with\nbest practices according to Linguistic Linked Open Data Community.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 16:38:40 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Moussallem", "Diego", ""], ["Sherif", "Mohamed Ahmed", ""], ["Esteves", "Diego", ""], ["Zampieri", "Marcos", ""], ["Ngomo", "Axel-Cyrille Ngonga", ""]]}, {"id": "1802.08150", "submitter": "Diego Moussallem", "authors": "Diego Moussallem, Thiago Castro Ferreira, Marcos Zampieri, Maria\n  Claudia Cavalcanti, Geraldo Xex\\'eo, Mariana Neves, Axel-Cyrille Ngonga Ngomo", "title": "RDF2PT: Generating Brazilian Portuguese Texts from RDF Data", "comments": "Accepted for publication in Language Resources and Evaluation\n  Conference (LREC) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generation of natural language from Resource Description Framework (RDF)\ndata has recently gained significant attention due to the continuous growth of\nLinked Data. A number of these approaches generate natural language in\nlanguages other than English, however, no work has been proposed to generate\nBrazilian Portuguese texts out of RDF. We address this research gap by\npresenting RDF2PT, an approach that verbalizes RDF data to Brazilian Portuguese\nlanguage. We evaluated RDF2PT in an open questionnaire with 44 native speakers\ndivided into experts and non-experts. Our results suggest that RDF2PT is able\nto generate text which is similar to that generated by humans and can hence be\neasily understood.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 16:41:56 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Moussallem", "Diego", ""], ["Ferreira", "Thiago Castro", ""], ["Zampieri", "Marcos", ""], ["Cavalcanti", "Maria Claudia", ""], ["Xex\u00e9o", "Geraldo", ""], ["Neves", "Mariana", ""], ["Ngomo", "Axel-Cyrille Ngonga", ""]]}, {"id": "1802.08218", "submitter": "Danna Gurari", "authors": "Danna Gurari, Qing Li, Abigale J. Stangl, Anhong Guo, Chi Lin, Kristen\n  Grauman, Jiebo Luo, and Jeffrey P. Bigham", "title": "VizWiz Grand Challenge: Answering Visual Questions from Blind People", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of algorithms to automatically answer visual questions currently is\nmotivated by visual question answering (VQA) datasets constructed in artificial\nVQA settings. We propose VizWiz, the first goal-oriented VQA dataset arising\nfrom a natural VQA setting. VizWiz consists of over 31,000 visual questions\noriginating from blind people who each took a picture using a mobile phone and\nrecorded a spoken question about it, together with 10 crowdsourced answers per\nvisual question. VizWiz differs from the many existing VQA datasets because (1)\nimages are captured by blind photographers and so are often poor quality, (2)\nquestions are spoken and so are more conversational, and (3) often visual\nquestions cannot be answered. Evaluation of modern algorithms for answering\nvisual questions and deciding if a visual question is answerable reveals that\nVizWiz is a challenging dataset. We introduce this dataset to encourage a\nlarger community to develop more generalized algorithms that can assist blind\npeople.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 18:16:53 GMT"}, {"version": "v2", "created": "Thu, 29 Mar 2018 19:52:08 GMT"}, {"version": "v3", "created": "Mon, 2 Apr 2018 15:53:07 GMT"}, {"version": "v4", "created": "Wed, 9 May 2018 17:26:40 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Gurari", "Danna", ""], ["Li", "Qing", ""], ["Stangl", "Abigale J.", ""], ["Guo", "Anhong", ""], ["Lin", "Chi", ""], ["Grauman", "Kristen", ""], ["Luo", "Jiebo", ""], ["Bigham", "Jeffrey P.", ""]]}, {"id": "1802.08301", "submitter": "Chandra Sekhar Bhagavatula", "authors": "Chandra Bhagavatula and Sergey Feldman and Russell Power and Waleed\n  Ammar", "title": "Content-Based Citation Recommendation", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a content-based method for recommending citations in an academic\npaper draft. We embed a given query document into a vector space, then use its\nnearest neighbors as candidates, and rerank the candidates using a\ndiscriminative model trained to distinguish between observed and unobserved\ncitations. Unlike previous work, our method does not require metadata such as\nauthor names which can be missing, e.g., during the peer review process.\nWithout using metadata, our method outperforms the best reported results on\nPubMed and DBLP datasets with relative improvements of over 18% in F1@20 and\nover 22% in MRR. We show empirically that, although adding metadata improves\nthe performance on standard metrics, it favors self-citations which are less\nuseful in a citation recommendation setup. We release an online portal\n(http://labs.semanticscholar.org/citeomatic/) for citation recommendation based\non our method, and a new dataset OpenCorpus of 7 million research articles to\nfacilitate future research on this task.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 21:13:47 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Bhagavatula", "Chandra", ""], ["Feldman", "Sergey", ""], ["Power", "Russell", ""], ["Ammar", "Waleed", ""]]}, {"id": "1802.08314", "submitter": "Chao Zhang", "authors": "Chao Zhang, Philip Woodland", "title": "High Order Recurrent Neural Networks for Acoustic Modelling", "comments": "5 pages, 2 figures, 2 tables, to appear in 2018 IEEE International\n  Conference on Acoustics, Speech and Signal Processing (ICASSP 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vanishing long-term gradients are a major issue in training standard\nrecurrent neural networks (RNNs), which can be alleviated by long short-term\nmemory (LSTM) models with memory cells. However, the extra parameters\nassociated with the memory cells mean an LSTM layer has four times as many\nparameters as an RNN with the same hidden vector size. This paper addresses the\nvanishing gradient problem using a high order RNN (HORNN) which has additional\nconnections from multiple previous time steps. Speech recognition experiments\nusing British English multi-genre broadcast (MGB3) data showed that the\nproposed HORNN architectures for rectified linear unit and sigmoid activation\nfunctions reduced word error rates (WER) by 4.2% and 6.3% over the\ncorresponding RNNs, and gave similar WERs to a (projected) LSTM while using\nonly 20%--50% of the recurrent layer parameters and computation.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 22:01:05 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Zhang", "Chao", ""], ["Woodland", "Philip", ""]]}, {"id": "1802.08332", "submitter": "Yue Gu", "authors": "Yue Gu, Shuhong Chen, Ivan Marsic", "title": "Deep Multimodal Learning for Emotion Recognition in Spoken Language", "comments": "ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel deep multimodal framework to predict human\nemotions based on sentence-level spoken language. Our architecture has two\ndistinctive characteristics. First, it extracts the high-level features from\nboth text and audio via a hybrid deep multimodal structure, which considers the\nspatial information from text, temporal information from audio, and high-level\nassociations from low-level handcrafted features. Second, we fuse all features\nby using a three-layer deep neural network to learn the correlations across\nmodalities and train the feature extraction and fusion modules together,\nallowing optimal global fine-tuning of the entire structure. We evaluated the\nproposed framework on the IEMOCAP dataset. Our result shows promising\nperformance, achieving 60.4% in weighted accuracy for five emotion categories.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 22:34:24 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Gu", "Yue", ""], ["Chen", "Shuhong", ""], ["Marsic", "Ivan", ""]]}, {"id": "1802.08375", "submitter": "Zhenisbek Assylbekov", "authors": "Zhenisbek Assylbekov and Rustem Takhanov", "title": "Reusing Weights in Subword-aware Neural Language Models", "comments": "accepted to NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose several ways of reusing subword embeddings and other weights in\nsubword-aware neural language models. The proposed techniques do not benefit a\ncompetitive character-aware model, but some of them improve the performance of\nsyllable- and morpheme-aware models while showing significant reductions in\nmodel sizes. We discover a simple hands-on principle: in a multi-layer input\nembedding model, layers should be tied consecutively bottom-up if reused at\noutput. Our best morpheme-aware model with properly reused weights beats the\ncompetitive word-level model by a large margin across multiple languages and\nhas 20%-87% fewer parameters.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 03:44:15 GMT"}, {"version": "v2", "created": "Wed, 25 Apr 2018 04:53:59 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Assylbekov", "Zhenisbek", ""], ["Takhanov", "Rustem", ""]]}, {"id": "1802.08379", "submitter": "Chao-Chun Hsu", "authors": "Sheng-Yeh Chen and Chao-Chun Hsu, Chuan-Chun Kuo, Ting-Hao (Kenneth)\n  Huang, Lun-Wei Ku", "title": "EmotionLines: An Emotion Corpus of Multi-Party Conversations", "comments": "LREC2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feeling emotion is a critical characteristic to distinguish people from\nmachines. Among all the multi-modal resources for emotion detection, textual\ndatasets are those containing the least additional information in addition to\nsemantics, and hence are adopted widely for testing the developed systems.\nHowever, most of the textual emotional datasets consist of emotion labels of\nonly individual words, sentences or documents, which makes it challenging to\ndiscuss the contextual flow of emotions. In this paper, we introduce\nEmotionLines, the first dataset with emotions labeling on all utterances in\neach dialogue only based on their textual content. Dialogues in EmotionLines\nare collected from Friends TV scripts and private Facebook messenger dialogues.\nThen one of seven emotions, six Ekman's basic emotions plus the neutral\nemotion, is labeled on each utterance by 5 Amazon MTurkers. A total of 29,245\nutterances from 2,000 dialogues are labeled in EmotionLines. We also provide\nseveral strong baselines for emotion detection models on EmotionLines in this\npaper.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 04:06:38 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 09:15:57 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Chen", "Sheng-Yeh", "", "Kenneth"], ["Hsu", "Chao-Chun", "", "Kenneth"], ["Kuo", "Chuan-Chun", "", "Kenneth"], ["Ting-Hao", "", "", "Kenneth"], ["Huang", "", ""], ["Ku", "Lun-Wei", ""]]}, {"id": "1802.08395", "submitter": "Yongqiang Wang", "authors": "Dmitriy Serdyuk and Yongqiang Wang and Christian Fuegen and Anuj Kumar\n  and Baiyang Liu and Yoshua Bengio", "title": "Towards end-to-end spoken language understanding", "comments": "submitted to ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spoken language understanding system is traditionally designed as a pipeline\nof a number of components. First, the audio signal is processed by an automatic\nspeech recognizer for transcription or n-best hypotheses. With the recognition\nresults, a natural language understanding system classifies the text to\nstructured data as domain, intent and slots for down-streaming consumers, such\nas dialog system, hands-free applications. These components are usually\ndeveloped and optimized independently. In this paper, we present our study on\nan end-to-end learning system for spoken language understanding. With this\nunified approach, we can infer the semantic meaning directly from audio\nfeatures without the intermediate text representation. This study showed that\nthe trained model can achieve reasonable good result and demonstrated that the\nmodel can capture the semantic attention directly from the audio features.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 05:39:46 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Serdyuk", "Dmitriy", ""], ["Wang", "Yongqiang", ""], ["Fuegen", "Christian", ""], ["Kumar", "Anuj", ""], ["Liu", "Baiyang", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1802.08504", "submitter": "Hai Ye", "authors": "Hai Ye, Xin Jiang, Zhunchen Luo, Wenhan Chao", "title": "Interpretable Charge Predictions for Criminal Cases: Learning to\n  Generate Court Views from Fact Descriptions", "comments": "To appear in NAACL 2018, Long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose to study the problem of COURT VIEW GENeration from\nthe fact description in a criminal case. The task aims to improve the\ninterpretability of charge prediction systems and help automatic legal document\ngeneration. We formulate this task as a text-to-text natural language\ngeneration (NLG) problem. Sequenceto-sequence model has achieved cutting-edge\nperformances in many NLG tasks. However, due to the non-distinctions of fact\ndescriptions, it is hard for Seq2Seq model to generate charge-discriminative\ncourt views. In this work, we explore charge labels to tackle this issue. We\npropose a label-conditioned Seq2Seq model with attention for this problem, to\ndecode court views conditioned on encoded charge labels. Experimental results\nshow the effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 12:33:29 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Ye", "Hai", ""], ["Jiang", "Xin", ""], ["Luo", "Zhunchen", ""], ["Chao", "Wenhan", ""]]}, {"id": "1802.08545", "submitter": "Lifeng Jin", "authors": "Lifeng Jin, Finale Doshi-Velez, Timothy Miller, William Schuler, Lane\n  Schwartz", "title": "Unsupervised Grammar Induction with Depth-bounded PCFG", "comments": "Accepted by Transactions of the Association for Computational\n  Linguistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been recent interest in applying cognitively or empirically\nmotivated bounds on recursion depth to limit the search space of grammar\ninduction models (Ponvert et al., 2011; Noji and Johnson, 2016; Shain et al.,\n2016). This work extends this depth-bounding approach to probabilistic\ncontext-free grammar induction (DB-PCFG), which has a smaller parameter space\nthan hierarchical sequence models, and therefore more fully exploits the space\nreductions of depth-bounding. Results for this model on grammar acquisition\nfrom transcribed child-directed speech and newswire text exceed or are\ncompetitive with those of other models when evaluated on parse accuracy.\nMoreover, gram- mars acquired from this model demonstrate a consistent use of\ncategory labels, something which has not been demonstrated by other acquisition\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 14:30:00 GMT"}, {"version": "v2", "created": "Mon, 26 Feb 2018 01:55:14 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Jin", "Lifeng", ""], ["Doshi-Velez", "Finale", ""], ["Miller", "Timothy", ""], ["Schuler", "William", ""], ["Schwartz", "Lane", ""]]}, {"id": "1802.08599", "submitter": "Rik van Noord", "authors": "Rik van Noord, Lasha Abzianidze, Hessel Haagsma, Johan Bos", "title": "Evaluating Scoped Meaning Representations", "comments": "Camera-ready for LREC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic parsing offers many opportunities to improve natural language\nunderstanding. We present a semantically annotated parallel corpus for English,\nGerman, Italian, and Dutch where sentences are aligned with scoped meaning\nrepresentations in order to capture the semantics of negation, modals,\nquantification, and presupposition triggers. The semantic formalism is based on\nDiscourse Representation Theory, but concepts are represented by WordNet\nsynsets and thematic roles by VerbNet relations. Translating scoped meaning\nrepresentations to sets of clauses enables us to compare them for the purpose\nof semantic parser evaluation and checking translations. This is done by\ncomputing precision and recall on matching clauses, in a similar way as is done\nfor Abstract Meaning Representations. We show that our matching tool for\nevaluating scoped meaning representations is both accurate and efficient.\nApplying this matching tool to three baseline semantic parsers yields F-scores\nbetween 43% and 54%. A pilot study is performed to automatically find changes\nin meaning by comparing meaning representations of translations. This\ncomparison turns out to be an additional way of (i) finding annotation mistakes\nand (ii) finding instances where our semantic analysis needs to be improved.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 15:31:19 GMT"}, {"version": "v2", "created": "Tue, 10 Apr 2018 09:55:10 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["van Noord", "Rik", ""], ["Abzianidze", "Lasha", ""], ["Haagsma", "Hessel", ""], ["Bos", "Johan", ""]]}, {"id": "1802.08614", "submitter": "Baoxu Shi", "authors": "Baoxu Shi and Tim Weninger", "title": "Visualizing the Flow of Discourse with a Concept Ontology", "comments": "2 pages, accepted to WWW2018", "journal-ref": null, "doi": "10.1145/3184558.3186943", "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding and visualizing human discourse has long being a challenging\ntask. Although recent work on argument mining have shown success in classifying\nthe role of various sentences, the task of recognizing concepts and\nunderstanding the ways in which they are discussed remains challenging. Given\nan email thread or a transcript of a group discussion, our task is to extract\nthe relevant concepts and understand how they are referenced and re-referenced\nthroughout the discussion. In the present work, we present a preliminary\napproach for extracting and visualizing group discourse by adapting Wikipedia's\ncategory hierarchy to be an external concept ontology. From a user study, we\nfound that our method achieved better results than 4 strong alternative\napproaches, and we illustrate our visualization method based on the extracted\ndiscourse flows.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 15:56:07 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Shi", "Baoxu", ""], ["Weninger", "Tim", ""]]}, {"id": "1802.08636", "submitter": "Shashi Narayan", "authors": "Shashi Narayan, Shay B. Cohen, Mirella Lapata", "title": "Ranking Sentences for Extractive Summarization with Reinforcement\n  Learning", "comments": "NAACL 2018, 13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single document summarization is the task of producing a shorter version of a\ndocument while preserving its principal information content. In this paper we\nconceptualize extractive summarization as a sentence ranking task and propose a\nnovel training algorithm which globally optimizes the ROUGE evaluation metric\nthrough a reinforcement learning objective. We use our algorithm to train a\nneural summarization model on the CNN and DailyMail datasets and demonstrate\nexperimentally that it outperforms state-of-the-art extractive and abstractive\nsystems when evaluated automatically and by humans.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 16:55:31 GMT"}, {"version": "v2", "created": "Mon, 16 Apr 2018 14:03:41 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Narayan", "Shashi", ""], ["Cohen", "Shay B.", ""], ["Lapata", "Mirella", ""]]}, {"id": "1802.08690", "submitter": "Chenhao Tan", "authors": "Chenhao Tan and Hao Peng and Noah A. Smith", "title": "\"You are no Jack Kennedy\": On Media Selection of Highlights from\n  Presidential Debates", "comments": "10 pages, 5 figures, to appear in Proceedings of WWW 2018, data and\n  more at https://chenhaot.com/papers/debate-quotes.html", "journal-ref": null, "doi": "10.1145/3178876.3186142", "report-no": null, "categories": "cs.SI cs.CL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Political speeches and debates play an important role in shaping the images\nof politicians, and the public often relies on media outlets to select bits of\npolitical communication from a large pool of utterances. It is an important\nresearch question to understand what factors impact this selection process.\n  To quantitatively explore the selection process, we build a three- decade\ndataset of presidential debate transcripts and post-debate coverage. We first\nexamine the effect of wording and propose a binary classification framework\nthat controls for both the speaker and the debate situation. We find that\ncrowdworkers can only achieve an accuracy of 60% in this task, indicating that\nmedia choices are not entirely obvious. Our classifiers outperform crowdworkers\non average, mainly in primary debates. We also compare important factors from\ncrowdworkers' free-form explanations with those from data-driven methods and\nfind interesting differences. Few crowdworkers mentioned that \"context\nmatters\", whereas our data show that well-quoted sentences are more distinct\nfrom the previous utterance by the same speaker than less-quoted sentences.\nFinally, we examine the aggregate effect of media preferences towards different\nwordings to understand the extent of fragmentation among media outlets. By\nanalyzing a bipartite graph built from quoting behavior in our data, we observe\na decreasing trend in bipartisan coverage.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 19:00:01 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Tan", "Chenhao", ""], ["Peng", "Hao", ""], ["Smith", "Noah A.", ""]]}, {"id": "1802.08731", "submitter": "Chunxi Liu", "authors": "Matthew Wiesner, Chunxi Liu, Lucas Ondel, Craig Harman, Vimal Manohar,\n  Jan Trmal, Zhongqiang Huang, Najim Dehak, Sanjeev Khudanpur", "title": "Automatic Speech Recognition and Topic Identification for\n  Almost-Zero-Resource Languages", "comments": "Accepted for publication at Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic speech recognition (ASR) systems often need to be developed for\nextremely low-resource languages to serve end-uses such as audio content\ncategorization and search. While universal phone recognition is natural to\nconsider when no transcribed speech is available to train an ASR system in a\nlanguage, adapting universal phone models using very small amounts (minutes\nrather than hours) of transcribed speech also needs to be studied, particularly\nwith state-of-the-art DNN-based acoustic models. The DARPA LORELEI program\nprovides a framework for such very-low-resource ASR studies, and provides an\nextrinsic metric for evaluating ASR performance in a humanitarian assistance,\ndisaster relief setting. This paper presents our Kaldi-based systems for the\nprogram, which employ a universal phone modeling approach to ASR, and describes\nrecipes for very rapid adaptation of this universal ASR system. The results we\nobtain significantly outperform results obtained by many competing approaches\non the NIST LoReHLT 2017 Evaluation datasets.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 20:47:51 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2018 19:50:33 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Wiesner", "Matthew", ""], ["Liu", "Chunxi", ""], ["Ondel", "Lucas", ""], ["Harman", "Craig", ""], ["Manohar", "Vimal", ""], ["Trmal", "Jan", ""], ["Huang", "Zhongqiang", ""], ["Dehak", "Najim", ""], ["Khudanpur", "Sanjeev", ""]]}, {"id": "1802.08786", "submitter": "Hanjun Dai", "authors": "Hanjun Dai, Yingtao Tian, Bo Dai, Steven Skiena, Le Song", "title": "Syntax-Directed Variational Autoencoder for Structured Data", "comments": "to appear in ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models have been enjoying success in modeling continuous\ndata. However it remains challenging to capture the representations for\ndiscrete structures with formal grammars and semantics, e.g., computer programs\nand molecular structures. How to generate both syntactically and semantically\ncorrect data still remains largely an open problem. Inspired by the theory of\ncompiler where the syntax and semantics check is done via syntax-directed\ntranslation (SDT), we propose a novel syntax-directed variational autoencoder\n(SD-VAE) by introducing stochastic lazy attributes. This approach converts the\noffline SDT check into on-the-fly generated guidance for constraining the\ndecoder. Comparing to the state-of-the-art methods, our approach enforces\nconstraints on the output space so that the output will be not only\nsyntactically valid, but also semantically reasonable. We evaluate the proposed\nmodel with applications in programming language and molecules, including\nreconstruction and program/molecule optimization. The results demonstrate the\neffectiveness in incorporating syntactic and semantic constraints in discrete\ngenerative models, which is significantly better than current state-of-the-art\napproaches.\n", "versions": [{"version": "v1", "created": "Sat, 24 Feb 2018 02:34:40 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Dai", "Hanjun", ""], ["Tian", "Yingtao", ""], ["Dai", "Bo", ""], ["Skiena", "Steven", ""], ["Song", "Le", ""]]}, {"id": "1802.08949", "submitter": "Dushyanta Dhyani", "authors": "Dushyanta Dhyani", "title": "OhioState at SemEval-2018 Task 7: Exploiting Data Augmentation for\n  Relation Classification in Scientific Papers using Piecewise Convolutional\n  Neural Networks", "comments": "To apperar in Proceedings of International Workshop on Semantic\n  Evaluation (SemEval-2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe our system for SemEval-2018 Shared Task on Semantic Relation\nExtraction and Classification in Scientific Papers where we focus on the\nClassification task. Our simple piecewise convolution neural encoder performs\ndecently in an end to end manner. A simple inter-task data augmentation\nsignifi- cantly boosts the performance of the model. Our best-performing\nsystems stood 8th out of 20 teams on the classification task on noisy data and\n12th out of 28 teams on the classification task on clean data.\n", "versions": [{"version": "v1", "created": "Sun, 25 Feb 2018 03:49:21 GMT"}, {"version": "v2", "created": "Mon, 30 Apr 2018 19:26:40 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Dhyani", "Dushyanta", ""]]}, {"id": "1802.08969", "submitter": "Xipeng Qiu", "authors": "Junkun Chen, Xipeng Qiu, Pengfei Liu, Xuanjing Huang", "title": "Meta Multi-Task Learning for Sequence Modeling", "comments": "published in The Thirty-Second AAAI Conference on Artificial\n  Intelligence (AAAI-18), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic composition functions have been playing a pivotal role in neural\nrepresentation learning of text sequences. In spite of their success, most\nexisting models suffer from the underfitting problem: they use the same shared\ncompositional function on all the positions in the sequence, thereby lacking\nexpressive power due to incapacity to capture the richness of compositionality.\nBesides, the composition functions of different tasks are independent and\nlearned from scratch. In this paper, we propose a new sharing scheme of\ncomposition function across multiple tasks. Specifically, we use a shared\nmeta-network to capture the meta-knowledge of semantic composition and generate\nthe parameters of the task-specific semantic composition models. We conduct\nextensive experiments on two types of tasks, text classification and sequence\ntagging, which demonstrate the benefits of our approach. Besides, we show that\nthe shared meta-knowledge learned by our proposed model can be regarded as\noff-the-shelf knowledge and easily transferred to new tasks.\n", "versions": [{"version": "v1", "created": "Sun, 25 Feb 2018 09:01:25 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Chen", "Junkun", ""], ["Qiu", "Xipeng", ""], ["Liu", "Pengfei", ""], ["Huang", "Xuanjing", ""]]}, {"id": "1802.08970", "submitter": "Xipeng Qiu", "authors": "Jinyue Su, Jiacheng Xu, Xipeng Qiu, Xuanjing Huang", "title": "Incorporating Discriminator in Sentence Generation: a Gibbs Sampling\n  Method", "comments": "published in The Thirty-Second AAAI Conference on Artificial\n  Intelligence (AAAI-18), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating plausible and fluent sentence with desired properties has long\nbeen a challenge. Most of the recent works use recurrent neural networks (RNNs)\nand their variants to predict following words given previous sequence and\ntarget label. In this paper, we propose a novel framework to generate\nconstrained sentences via Gibbs Sampling. The candidate sentences are revised\nand updated iteratively, with sampled new words replacing old ones. Our\nexperiments show the effectiveness of the proposed method to generate plausible\nand diverse sentences.\n", "versions": [{"version": "v1", "created": "Sun, 25 Feb 2018 09:01:55 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Su", "Jinyue", ""], ["Xu", "Jiacheng", ""], ["Qiu", "Xipeng", ""], ["Huang", "Xuanjing", ""]]}, {"id": "1802.08979", "submitter": "Xi Victoria Lin", "authors": "Xi Victoria Lin and Chenglong Wang and Luke Zettlemoyer and Michael D.\n  Ernst", "title": "NL2Bash: A Corpus and Semantic Parser for Natural Language Interface to\n  the Linux Operating System", "comments": "Accepted at the Language Resource and Evaluation Conference (LREC)\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new data and semantic parsing methods for the problem of mapping\nEnglish sentences to Bash commands (NL2Bash). Our long-term goal is to enable\nany user to perform operations such as file manipulation, search, and\napplication-specific scripting by simply stating their goals in English. We\ntake a first step in this domain, by providing a new dataset of challenging but\ncommonly used Bash commands and expert-written English descriptions, along with\nbaseline methods to establish performance levels on this task.\n", "versions": [{"version": "v1", "created": "Sun, 25 Feb 2018 09:52:24 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 17:46:59 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Lin", "Xi Victoria", ""], ["Wang", "Chenglong", ""], ["Zettlemoyer", "Luke", ""], ["Ernst", "Michael D.", ""]]}, {"id": "1802.09059", "submitter": "Ahmad Pesaranghader", "authors": "Ahmad Pesaranghader, Ali Pesaranghader, Stan Matwin, Marina Sokolova", "title": "One Single Deep Bidirectional LSTM Network for Word Sense Disambiguation\n  of Text Data", "comments": "12 pages, 1 figure, to appear in the Proceedings of the 31st Canadian\n  Conference on Artificial Intelligence, 8-11 May, 2018, Toronto, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to recent technical and scientific advances, we have a wealth of\ninformation hidden in unstructured text data such as offline/online narratives,\nresearch articles, and clinical reports. To mine these data properly,\nattributable to their innate ambiguity, a Word Sense Disambiguation (WSD)\nalgorithm can avoid numbers of difficulties in Natural Language Processing\n(NLP) pipeline. However, considering a large number of ambiguous words in one\nlanguage or technical domain, we may encounter limiting constraints for proper\ndeployment of existing WSD models. This paper attempts to address the problem\nof one-classifier-per-one-word WSD algorithms by proposing a single\nBidirectional Long Short-Term Memory (BLSTM) network which by considering\nsenses and context sequences works on all ambiguous words collectively.\nEvaluated on SensEval-3 benchmark, we show the result of our model is\ncomparable with top-performing WSD algorithms. We also discuss how applying\nadditional modifications alleviates the model fault and the need for more\ntraining data.\n", "versions": [{"version": "v1", "created": "Sun, 25 Feb 2018 18:51:53 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Pesaranghader", "Ahmad", ""], ["Pesaranghader", "Ali", ""], ["Matwin", "Stan", ""], ["Sokolova", "Marina", ""]]}, {"id": "1802.09091", "submitter": "Tom McCoy", "authors": "R. Thomas McCoy and Robert Frank and Tal Linzen", "title": "Revisiting the poverty of the stimulus: hierarchical generalization\n  without a hierarchical bias in recurrent neural networks", "comments": "Proceedings of the 40th Annual Conference of the Cognitive Science\n  Society; 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Syntactic rules in natural language typically need to make reference to\nhierarchical sentence structure. However, the simple examples that language\nlearners receive are often equally compatible with linear rules. Children\nconsistently ignore these linear explanations and settle instead on the correct\nhierarchical one. This fact has motivated the proposal that the learner's\nhypothesis space is constrained to include only hierarchical rules. We examine\nthis proposal using recurrent neural networks (RNNs), which are not constrained\nin such a way. We simulate the acquisition of question formation, a\nhierarchical transformation, in a fragment of English. We find that some RNN\narchitectures tend to learn the hierarchical rule, suggesting that hierarchical\ncues within the language, combined with the implicit architectural biases\ninherent in certain RNNs, may be sufficient to induce hierarchical\ngeneralizations. The likelihood of acquiring the hierarchical generalization\nincreased when the language included an additional cue to hierarchy in the form\nof subject-verb agreement, underscoring the role of cues to hierarchy in the\nlearner's input.\n", "versions": [{"version": "v1", "created": "Sun, 25 Feb 2018 21:52:37 GMT"}, {"version": "v2", "created": "Wed, 28 Feb 2018 05:11:18 GMT"}, {"version": "v3", "created": "Fri, 8 Jun 2018 04:20:31 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["McCoy", "R. Thomas", ""], ["Frank", "Robert", ""], ["Linzen", "Tal", ""]]}, {"id": "1802.09130", "submitter": "Payam Karisani", "authors": "Payam Karisani and Eugene Agichtein", "title": "Did You Really Just Have a Heart Attack? Towards Robust Detection of\n  Personal Health Mentions in Social Media", "comments": "WWW 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millions of users share their experiences on social media sites, such as\nTwitter, which in turn generate valuable data for public health monitoring,\ndigital epidemiology, and other analyses of population health at global scale.\nThe first, critical, task for these applications is classifying whether a\npersonal health event was mentioned, which we call the (PHM) problem. This task\nis challenging for many reasons, including typically short length of social\nmedia posts, inventive spelling and lexicons, and figurative language,\nincluding hyperbole using diseases like \"heart attack\" or \"cancer\" for\nemphasis, and not as a health self-report. This problem is even more\nchallenging for rarely reported, or frequent but ambiguously expressed\nconditions, such as \"stroke\". To address this problem, we propose a general,\nrobust method for detecting PHMs in social media, which we call WESPAD, that\ncombines lexical, syntactic, word embedding-based, and context-based features.\nWESPAD is able to generalize from few examples by automatically distorting the\nword embedding space to most effectively detect the true health mentions.\nUnlike previously proposed state-of-the-art supervised and deep-learning\ntechniques, WESPAD requires relatively little training data, which makes it\npossible to adapt, with minimal effort, to each new disease and condition. We\nevaluate WESPAD on both an established publicly available Flu detection\nbenchmark, and on a new dataset that we have constructed with mentions of\nmultiple health conditions. Our experiments show that WESPAD outperforms the\nbaselines and state-of-the-art methods, especially in cases when the number and\nproportion of true health mentions in the training data is small.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 02:08:28 GMT"}, {"version": "v2", "created": "Sun, 4 Mar 2018 03:02:39 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Karisani", "Payam", ""], ["Agichtein", "Eugene", ""]]}, {"id": "1802.09189", "submitter": "Xingyu Fu", "authors": "XingYu Fu, ZiYi Yang, XiuWen Duan", "title": "Language Distribution Prediction based on Batch Markov Monte Carlo\n  Simulation with Migration", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language spreading is a complex mechanism that involves issues like culture,\neconomics, migration, population etc. In this paper, we propose a set of\nmethods to model the dynamics of the spreading system. To model the randomness\nof language spreading, we propose the Batch Markov Monte Carlo Simulation with\nMigration(BMMCSM) algorithm, in which each agent is treated as a language\nstack. The agent learns languages and migrates based on the proposed Batch\nMarkov Property according to the transition matrix T and migration matrix M.\nSince population plays a crucial role in language spreading, we also introduce\nthe Mortality and Fertility Mechanism, which controls the birth and death of\nthe simulated agents, into the BMMCSM algorithm. The simulation results of\nBMMCSM show that the numerical and geographic distribution of languages varies\nacross the time. The change of distribution fits the world cultural and\neconomic development trend. Next, when we construct Matrix T, there are some\nentries of T can be directly calculated from historical statistics while some\nentries of T is unknown. Thus, the key to the success of the BMMCSM lies in the\naccurate estimation of transition matrix T by estimating the unknown entries of\nT under the supervision of the known entries. To achieve this, we first\nconstruct a 20 by 20 by 5 factor tensor X to characterize each entry of T. Then\nwe train a Random Forest Regressor on the known entries of T and use the\ntrained regressor to predict the unknown entries. The reason why we choose\nRandom Forest(RF) is that, compared to Single Decision Tree, it conquers the\nproblem of over fitting and the Shapiro test also suggests that the residual of\nRF subjects to the Normal distribution.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 07:52:30 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Fu", "XingYu", ""], ["Yang", "ZiYi", ""], ["Duan", "XiuWen", ""]]}, {"id": "1802.09194", "submitter": "Mengxiao Bi", "authors": "Mengxiao Bi, Heng Lu, Shiliang Zhang, Ming Lei, Zhijie Yan", "title": "Deep Feed-forward Sequential Memory Networks for Speech Synthesis", "comments": "5 pages, ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Bidirectional LSTM (BLSTM) RNN based speech synthesis system is among the\nbest parametric Text-to-Speech (TTS) systems in terms of the naturalness of\ngenerated speech, especially the naturalness in prosody. However, the model\ncomplexity and inference cost of BLSTM prevents its usage in many runtime\napplications. Meanwhile, Deep Feed-forward Sequential Memory Networks (DFSMN)\nhas shown its consistent out-performance over BLSTM in both word error rate\n(WER) and the runtime computation cost in speech recognition tasks. Since\nspeech synthesis also requires to model long-term dependencies compared to\nspeech recognition, in this paper, we investigate the Deep-FSMN (DFSMN) in\nspeech synthesis. Both objective and subjective experiments show that, compared\nwith BLSTM TTS method, the DFSMN system can generate synthesized speech with\ncomparable speech quality while drastically reduce model complexity and speech\ngeneration time.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 08:21:26 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Bi", "Mengxiao", ""], ["Lu", "Heng", ""], ["Zhang", "Shiliang", ""], ["Lei", "Ming", ""], ["Yan", "Zhijie", ""]]}, {"id": "1802.09233", "submitter": "Mohammed Jabreel", "authors": "Mohammed Jabreel and Antonio Moreno", "title": "EiTAKA at SemEval-2018 Task 1: An Ensemble of N-Channels ConvNet and\n  XGboost Regressors for Emotion Analysis of Tweets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper describes our system that has been used in Task1 Affect in Tweets.\nWe combine two different approaches. The first one called N-Stream ConvNets,\nwhich is a deep learning approach where the second one is XGboost regresseor\nbased on a set of embedding and lexicons based features. Our system was\nevaluated on the testing sets of the tasks outperforming all other approaches\nfor the Arabic version of valence intensity regression task and valence ordinal\nclassification task.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 10:20:09 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Jabreel", "Mohammed", ""], ["Moreno", "Antonio", ""]]}, {"id": "1802.09287", "submitter": "Mostafa ElAraby", "authors": "Mostafa Elaraby, Ahmed Y. Tawfik, Mahmoud Khaled, Hany Hassan, Aly\n  Osama", "title": "Gender Aware Spoken Language Translation Applied to English-Arabic", "comments": "Proceedings of the Second International Conference on Natural\n  Language and Speech Processing, 2018 IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spoken Language Translation (SLT) is becoming more widely used and becoming a\ncommunication tool that helps in crossing language barriers. One of the\nchallenges of SLT is the translation from a language without gender agreement\nto a language with gender agreement such as English to Arabic. In this paper,\nwe introduce an approach to tackle such limitation by enabling a Neural Machine\nTranslation system to produce gender-aware translation. We show that NMT system\ncan model the speaker/listener gender information to produce gender-aware\ntranslation. We propose a method to generate data used in adapting a NMT system\nto produce gender-aware. The proposed approach can achieve significant\nimprovement of the translation quality by 2 BLEU points.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 13:26:43 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Elaraby", "Mostafa", ""], ["Tawfik", "Ahmed Y.", ""], ["Khaled", "Mahmoud", ""], ["Hassan", "Hany", ""], ["Osama", "Aly", ""]]}, {"id": "1802.09296", "submitter": "Sherzod Hakimov", "authors": "Sherzod Hakimov, Soufian Jebbara, Philipp Cimiano", "title": "AMUSE: Multilingual Semantic Parsing for Question Answering over Linked\n  Data", "comments": "International Semantic Web Conference, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The task of answering natural language questions over RDF data has received\nwide interest in recent years, in particular in the context of the series of\nQALD benchmarks. The task consists of mapping a natural language question to an\nexecutable form, e.g. SPARQL, so that answers from a given KB can be extracted.\nSo far, most systems proposed are i) monolingual and ii) rely on a set of\nhard-coded rules to interpret questions and map them into a SPARQL query. We\npresent the first multilingual QALD pipeline that induces a model from training\ndata for mapping a natural language question into logical form as probabilistic\ninference. In particular, our approach learns to map universal syntactic\ndependency representations to a language-independent logical form based on\nDUDES (Dependency-based Underspecified Discourse Representation Structures)\nthat are then mapped to a SPARQL query as a deterministic second step. Our\nmodel builds on factor graphs that rely on features extracted from the\ndependency graph and corresponding semantic representations. We rely on\napproximate inference techniques, Markov Chain Monte Carlo methods in\nparticular, as well as Sample Rank to update parameters using a ranking\nobjective. Our focus lies on developing methods that overcome the lexical gap\nand present a novel combination of machine translation and word embedding\napproaches for this purpose. As a proof of concept for our approach, we\nevaluate our approach on the QALD-6 datasets for English, German & Spanish.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 13:50:14 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Hakimov", "Sherzod", ""], ["Jebbara", "Soufian", ""], ["Cimiano", "Philipp", ""]]}, {"id": "1802.09375", "submitter": "Johannes Bjerva", "authors": "Johannes Bjerva and Isabelle Augenstein", "title": "From Phonology to Syntax: Unsupervised Linguistic Typology at Different\n  Levels with Language Embeddings", "comments": "Accepted to NAACL 2018 (long paper). arXiv admin note: text overlap\n  with arXiv:1711.05468", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A core part of linguistic typology is the classification of languages\naccording to linguistic properties, such as those detailed in the World Atlas\nof Language Structure (WALS). Doing this manually is prohibitively\ntime-consuming, which is in part evidenced by the fact that only 100 out of\nover 7,000 languages spoken in the world are fully covered in WALS.\n  We learn distributed language representations, which can be used to predict\ntypological properties on a massively multilingual scale. Additionally,\nquantitative and qualitative analyses of these language embeddings can tell us\nhow language similarities are encoded in NLP models for tasks at different\ntypological levels. The representations are learned in an unsupervised manner\nalongside tasks at three typological levels: phonology (grapheme-to-phoneme\nprediction, and phoneme reconstruction), morphology (morphological inflection),\nand syntax (part-of-speech tagging).\n  We consider more than 800 languages and find significant differences in the\nlanguage representations encoded, depending on the target task. For instance,\nalthough Norwegian Bokm{\\aa}l and Danish are typologically close to one\nanother, they are phonologically distant, which is reflected in their language\nembeddings growing relatively distant in a phonological task. We are also able\nto predict typological features in WALS with high accuracies, even for unseen\nlanguage families.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 11:55:44 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Bjerva", "Johannes", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "1802.09416", "submitter": "Mohammadreza Rezvan", "authors": "Mohammadreza Rezvan, Saeedeh Shekarpour, Lakshika Balasuriya,\n  Krishnaprasad Thirunarayan, Valerie Shalin, Amit Sheth", "title": "A Quality Type-aware Annotated Corpus and Lexicon for Harassment\n  Research", "comments": null, "journal-ref": null, "doi": "10.1145/3201064.3201103", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Having a quality annotated corpus is essential especially for applied\nresearch. Despite the recent focus of Web science community on researching\nabout cyberbullying, the community dose not still have standard benchmarks. In\nthis paper, we publish first, a quality annotated corpus and second, an\noffensive words lexicon capturing different types type of harassment as (i)\nsexual harassment, (ii) racial harassment, (iii) appearance-related harassment,\n(iv) intellectual harassment, and (v) political harassment.We crawled data from\nTwitter using our offensive lexicon. Then relied on the human judge to annotate\nthe collected tweets w.r.t. the contextual types because using offensive words\nis not sufficient to reliably detect harassment. Our corpus consists of 25,000\nannotated tweets in five contextual types. We are pleased to share this novel\nannotated corpus and the lexicon with the research community. The instruction\nto acquire the corpus has been published on the Git repository.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 15:59:22 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 18:10:17 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Rezvan", "Mohammadreza", ""], ["Shekarpour", "Saeedeh", ""], ["Balasuriya", "Lakshika", ""], ["Thirunarayan", "Krishnaprasad", ""], ["Shalin", "Valerie", ""], ["Sheth", "Amit", ""]]}, {"id": "1802.09426", "submitter": "Mayank Chaudhari", "authors": "Mayank Chaudhari, Aakash Nelson Mattukoyya", "title": "Tone Biased MMR Text Summarization", "comments": "4 pages, 4 figures, IJCRT, Feb 2018", "journal-ref": "Mayank Chaudhari, Aakash Nelson Mattukoyya,Tone Biased MMR Text\n  Summarization,IJCRT, Feb 2018", "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text summarization is an interesting area for researchers to develop new\ntechniques to provide human like summaries for vast amounts of information.\nSummarization techniques tend to focus on providing accurate representation of\ncontent, and often the tone of the content is ignored. Tone of the content sets\na baseline for how a reader perceives the content. As such being able to\ngenerate summary with tone that is appropriate for the reader is important. In\nour work we implement Maximal Marginal Relevance [MMR] based multi-document\ntext summarization and propose a naive model to change tone of the\nsummarization by setting a bias to specific set of words and restricting other\nwords in the summarization output. This bias towards a specified set of words\nproduces a summary whose tone is same as tone of specified words.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 16:12:40 GMT"}, {"version": "v2", "created": "Tue, 27 Feb 2018 10:25:07 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Chaudhari", "Mayank", ""], ["Mattukoyya", "Aakash Nelson", ""]]}, {"id": "1802.09777", "submitter": "Niko Br\\\"ummer", "authors": "Niko Brummer and Anna Silnova and Lukas Burget and Themos Stafylakis", "title": "Gaussian meta-embeddings for efficient scoring of a heavy-tailed PLDA\n  model", "comments": "submittted to Odyssey 2018: The Speaker and Language Recognition\n  Workshop, Les Sables d'Olonne, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embeddings in machine learning are low-dimensional representations of complex\ninput patterns, with the property that simple geometric operations like\nEuclidean distances and dot products can be used for classification and\ncomparison tasks. The proposed meta-embeddings are special embeddings that live\nin more general inner product spaces. They are designed to propagate\nuncertainty to the final output in speaker recognition and similar\napplications. The familiar Gaussian PLDA model (GPLDA) can be re-formulated as\nan extractor for Gaussian meta-embeddings (GMEs), such that likelihood ratio\nscores are given by Hilbert space inner products between Gaussian likelihood\nfunctions. GMEs extracted by the GPLDA model have fixed precisions and do not\npropagate uncertainty. We show that a generalization to heavy-tailed PLDA gives\nGMEs with variable precisions, which do propagate uncertainty. Experiments on\nNIST SRE 2010 and 2016 show that the proposed method applied to i-vectors\nwithout length normalization is up to 20% more accurate than GPLDA applied to\nlength-normalized ivectors.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 08:55:05 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Brummer", "Niko", ""], ["Silnova", "Anna", ""], ["Burget", "Lukas", ""], ["Stafylakis", "Themos", ""]]}, {"id": "1802.09884", "submitter": "Avinesh P.V.S.", "authors": "Avinesh P.V.S., Maxime Peyrard, Christian M. Meyer", "title": "Live Blog Corpus for Summarization", "comments": "To appear in the Proceedings of LREC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Live blogs are an increasingly popular news format to cover breaking news and\nlive events in online journalism. Online news websites around the world are\nusing this medium to give their readers a minute by minute update on an event.\nGood summaries enhance the value of the live blogs for a reader but are often\nnot available. In this paper, we study a way of collecting corpora for\nautomatic live blog summarization. In an empirical evaluation using well-known\nstate-of-the-art summarization systems, we show that live blogs corpus poses\nnew challenges in the field of summarization. We make our tools publicly\navailable to reconstruct the corpus to encourage the research community and\nreplicate our results.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 13:51:30 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["S.", "Avinesh P. V.", ""], ["Peyrard", "Maxime", ""], ["Meyer", "Christian M.", ""]]}, {"id": "1802.09913", "submitter": "Isabelle Augenstein", "authors": "Isabelle Augenstein, Sebastian Ruder, Anders S{\\o}gaard", "title": "Multi-task Learning of Pairwise Sequence Classification Tasks Over\n  Disparate Label Spaces", "comments": "To appear at NAACL 2018 (long)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We combine multi-task learning and semi-supervised learning by inducing a\njoint embedding space between disparate label spaces and learning transfer\nfunctions between label embeddings, enabling us to jointly leverage unlabelled\ndata and auxiliary, annotated datasets. We evaluate our approach on a variety\nof sequence classification tasks with disparate label spaces. We outperform\nstrong single and multi-task baselines and achieve a new state-of-the-art for\ntopic-based sentiment analysis.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 14:38:43 GMT"}, {"version": "v2", "created": "Mon, 9 Apr 2018 07:34:47 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Augenstein", "Isabelle", ""], ["Ruder", "Sebastian", ""], ["S\u00f8gaard", "Anders", ""]]}, {"id": "1802.09914", "submitter": "Mircea Andrecut Dr", "authors": "M. Andrecut", "title": "High-Dimensional Vector Semantics", "comments": "12 pages, 5 figures, Int. J. Mod. Phys. C, 2018", "journal-ref": null, "doi": "10.1142/S0129183118500158", "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore the \"vector semantics\" problem from the perspective\nof \"almost orthogonal\" property of high-dimensional random vectors. We show\nthat this intriguing property can be used to \"memorize\" random vectors by\nsimply adding them, and we provide an efficient probabilistic solution to the\nset membership problem. Also, we discuss several applications to word context\nvector embeddings, document sentences similarity, and spam filtering.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 16:50:16 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Andrecut", "M.", ""]]}, {"id": "1802.09944", "submitter": "Jaimie Murdock", "authors": "Jaimie Murdock and Colin Allen and Simon DeDeo", "title": "The Development of Darwin's Origin of Species", "comments": "8 pages, 3 figures. Pre-print of Current Research in Digital History\n  (CRDH)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  From 1837, when he returned to England aboard the $\\textit{HMS Beagle}$, to\n1860, just after publication of $\\textit{The Origin of Species}$, Charles\nDarwin kept detailed notes of each book he read or wanted to read. His notes\nand manuscripts provide information about decades of individual scientific\npractice. Previously, we trained topic models on the full texts of each\nreading, and applied information-theoretic measures to detect that changes in\nhis reading patterns coincided with the boundaries of his three major\nintellectual projects in the period 1837-1860. In this new work we apply the\nreading model to five additional documents, four of them by Darwin: the first\nedition of $\\textit{The Origin of Species}$, two private essays stating\nintermediate forms of his theory in 1842 and 1844, a third essay of disputed\ndating, and Alfred Russel Wallace's essay, which Darwin received in 1858. We\naddress three historical inquiries, previously treated qualitatively: 1) the\nmythology of \"Darwin's Delay,\" that despite completing an extensive draft in\n1844, Darwin waited until 1859 to publish $\\textit{The Origin of Species}$ due\nto external pressures; 2) the relationship between Darwin and Wallace's\ncontemporaneous theories, especially in light of their joint presentation; and\n3) dating of the \"Outline and Draft\" which was rediscovered in 1975 and\npostulated first as an 1839 draft preceding the Sketch of 1842, then as an\ninterstitial draft between the 1842 and 1844 essays.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 16:22:14 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Murdock", "Jaimie", ""], ["Allen", "Colin", ""], ["DeDeo", "Simon", ""]]}, {"id": "1802.09957", "submitter": "Spiros Georgakopoulos", "authors": "Spiros V. Georgakopoulos, Sotiris K. Tasoulis, Aristidis G. Vrahatis\n  and Vassilis P. Plagianakos", "title": "Convolutional Neural Networks for Toxic Comment Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flood of information is produced in a daily basis through the global Internet\nusage arising from the on-line interactive communications among users. While\nthis situation contributes significantly to the quality of human life,\nunfortunately it involves enormous dangers, since on-line texts with high\ntoxicity can cause personal attacks, on-line harassment and bullying behaviors.\nThis has triggered both industrial and research community in the last few years\nwhile there are several tries to identify an efficient model for on-line toxic\ncomment prediction. However, these steps are still in their infancy and new\napproaches and frameworks are required. On parallel, the data explosion that\nappears constantly, makes the construction of new machine learning\ncomputational tools for managing this information, an imperative need.\nThankfully advances in hardware, cloud computing and big data management allow\nthe development of Deep Learning approaches appearing very promising\nperformance so far. For text classification in particular the use of\nConvolutional Neural Networks (CNN) have recently been proposed approaching\ntext analytics in a modern manner emphasizing in the structure of words in a\ndocument. In this work, we employ this approach to discover toxic comments in a\nlarge pool of documents provided by a current Kaggle's competition regarding\nWikipedia's talk page edits. To justify this decision we choose to compare CNNs\nagainst the traditional bag-of-words approach for text analysis combined with a\nselection of algorithms proven to be very effective in text classification. The\nreported results provide enough evidence that CNN enhance toxic comment\nclassification reinforcing research interest towards this direction.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 15:11:28 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Georgakopoulos", "Spiros V.", ""], ["Tasoulis", "Sotiris K.", ""], ["Vrahatis", "Aristidis G.", ""], ["Plagianakos", "Vassilis P.", ""]]}, {"id": "1802.09961", "submitter": "Anna Feldman", "authors": "Jing Peng, Anna Feldman, Ekaterina Vylomova", "title": "Classifying Idiomatic and Literal Expressions Using Topic Models and\n  Intensity of Emotions", "comments": "EMNLP 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an algorithm for automatic classification of idiomatic and\nliteral expressions. Our starting point is that words in a given text segment,\nsuch as a paragraph, that are highranking representatives of a common topic of\ndiscussion are less likely to be a part of an idiomatic expression. Our\nadditional hypothesis is that contexts in which idioms occur, typically, are\nmore affective and therefore, we incorporate a simple analysis of the intensity\nof the emotions expressed by the contexts. We investigate the bag of words\ntopic representation of one to three paragraphs containing an expression that\nshould be classified as idiomatic or literal (a target phrase). We extract\ntopics from paragraphs containing idioms and from paragraphs containing\nliterals using an unsupervised clustering method, Latent Dirichlet Allocation\n(LDA) (Blei et al., 2003). Since idiomatic expressions exhibit the property of\nnon-compositionality, we assume that they usually present different semantics\nthan the words used in the local topic. We treat idioms as semantic outliers,\nand the identification of a semantic shift as outlier detection. Thus, this\ntopic representation allows us to differentiate idioms from literals using\nlocal semantic contexts. Our results are encouraging.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 15:20:43 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Peng", "Jing", ""], ["Feldman", "Anna", ""], ["Vylomova", "Ekaterina", ""]]}, {"id": "1802.09968", "submitter": "Chieh-Teng Chang", "authors": "Chieh-Teng Chang, Chi-Chia Huang, Chih-Yuan Yang and Jane Yung-Jen Hsu", "title": "A Hybrid Word-Character Approach to Abstractive Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic abstractive text summarization is an important and challenging\nresearch topic of natural language processing. Among many widely used\nlanguages, the Chinese language has a special property that a Chinese character\ncontains rich information comparable to a word. Existing Chinese text\nsummarization methods, either adopt totally character-based or word-based\nrepresentations, fail to fully exploit the information carried by both\nrepresentations. To accurately capture the essence of articles, we propose a\nhybrid word-character approach (HWC) which preserves the advantages of both\nword-based and character-based representations. We evaluate the advantage of\nthe proposed HWC approach by applying it to two existing methods, and discover\nthat it generates state-of-the-art performance with a margin of 24 ROUGE points\non a widely used dataset LCSTS. In addition, we find an issue contained in the\nLCSTS dataset and offer a script to remove overlapping pairs (a summary and a\nshort text) to create a clean dataset for the community. The proposed HWC\napproach also generates the best performance on the new, clean LCSTS dataset.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 15:31:11 GMT"}, {"version": "v2", "created": "Sat, 8 Sep 2018 04:59:55 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Chang", "Chieh-Teng", ""], ["Huang", "Chi-Chia", ""], ["Yang", "Chih-Yuan", ""], ["Hsu", "Jane Yung-Jen", ""]]}, {"id": "1802.10078", "submitter": "Nicolas Fiorini", "authors": "Sunil Mohan, Nicolas Fiorini, Sun Kim, Zhiyong Lu", "title": "A Fast Deep Learning Model for Textual Relevance in Biomedical\n  Information Retrieval", "comments": "To appear in proceeding of WWW 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Publications in the life sciences are characterized by a large technical\nvocabulary, with many lexical and semantic variations for expressing the same\nconcept. Towards addressing the problem of relevance in biomedical literature\nsearch, we introduce a deep learning model for the relevance of a document's\ntext to a keyword style query. Limited by a relatively small amount of training\ndata, the model uses pre-trained word embeddings. With these, the model first\ncomputes a variable-length Delta matrix between the query and document,\nrepresenting a difference between the two texts, which is then passed through a\ndeep convolution stage followed by a deep feed-forward network to compute a\nrelevance score. This results in a fast model suitable for use in an online\nsearch engine. The model is robust and outperforms comparable state-of-the-art\ndeep learning approaches.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 21:43:23 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Mohan", "Sunil", ""], ["Fiorini", "Nicolas", ""], ["Kim", "Sun", ""], ["Lu", "Zhiyong", ""]]}, {"id": "1802.10137", "submitter": "Aakash Sinha", "authors": "Aakash Sinha, Abhishek Yadav, Akshay Gahlot", "title": "Extractive Text Summarization using Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text Summarization has been an extensively studied problem. Traditional\napproaches to text summarization rely heavily on feature engineering. In\ncontrast to this, we propose a fully data-driven approach using feedforward\nneural networks for single document summarization. We train and evaluate the\nmodel on standard DUC 2002 dataset which shows results comparable to the state\nof the art models. The proposed model is scalable and is able to produce the\nsummary of arbitrarily sized documents by breaking the original document into\nfixed sized parts and then feeding it recursively to the network.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 19:48:51 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Sinha", "Aakash", ""], ["Yadav", "Abhishek", ""], ["Gahlot", "Akshay", ""]]}, {"id": "1802.10229", "submitter": "Yi Yang", "authors": "Yi Yang, Ozan Irsoy, Kazi Shefaet Rahman", "title": "Collective Entity Disambiguation with Structured Gradient Tree Boosting", "comments": "Accepted by NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a gradient-tree-boosting-based structured learning model for\njointly disambiguating named entities in a document. Gradient tree boosting is\na widely used machine learning algorithm that underlies many top-performing\nnatural language processing systems. Surprisingly, most works limit the use of\ngradient tree boosting as a tool for regular classification or regression\nproblems, despite the structured nature of language. To the best of our\nknowledge, our work is the first one that employs the structured gradient tree\nboosting (SGTB) algorithm for collective entity disambiguation. By defining\nglobal features over previous disambiguation decisions and jointly modeling\nthem with local features, our system is able to produce globally optimized\nentity assignments for mentions in a document. Exact inference is prohibitively\nexpensive for our globally normalized model. To solve this problem, we propose\nBidirectional Beam Search with Gold path (BiBSG), an approximate inference\nalgorithm that is a variant of the standard beam search algorithm. BiBSG makes\nuse of global information from both past and future to perform better local\nsearch. Experiments on standard benchmark datasets show that SGTB significantly\nimproves upon published results. Specifically, SGTB outperforms the previous\nstate-of-the-art neural system by near 1\\% absolute accuracy on the popular\nAIDA-CoNLL dataset.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 02:01:30 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2018 01:23:48 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Yang", "Yi", ""], ["Irsoy", "Ozan", ""], ["Rahman", "Kazi Shefaet", ""]]}, {"id": "1802.10279", "submitter": "Xiao Zhang", "authors": "Xiao Zhang, Ji Wu, Zhiyang He, Xien Liu, Ying Su", "title": "Medical Exam Question Answering with Large-scale Reading Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reading and understanding text is one important component in computer aided\ndiagnosis in clinical medicine, also being a major research problem in the\nfield of NLP. In this work, we introduce a question-answering task called MedQA\nto study answering questions in clinical medicine using knowledge in a\nlarge-scale document collection. The aim of MedQA is to answer real-world\nquestions with large-scale reading comprehension. We propose our solution\nSeaReader--a modular end-to-end reading comprehension model based on LSTM\nnetworks and dual-path attention architecture. The novel dual-path attention\nmodels information flow from two perspectives and has the ability to\nsimultaneously read individual documents and integrate information across\nmultiple documents. In experiments our SeaReader achieved a large increase in\naccuracy on MedQA over competing models. Additionally, we develop a series of\nnovel techniques to demonstrate the interpretation of the question answering\nprocess in SeaReader.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 06:27:37 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Zhang", "Xiao", ""], ["Wu", "Ji", ""], ["He", "Zhiyang", ""], ["Liu", "Xien", ""], ["Su", "Ying", ""]]}, {"id": "1802.10411", "submitter": "Massimo Stella", "authors": "Massimo Stella and Manlio De Domenico", "title": "Distance entropy cartography characterises centrality in complex\n  networks", "comments": "11 pages", "journal-ref": null, "doi": "10.3390/e20040268", "report-no": null, "categories": "physics.soc-ph cond-mat.stat-mech cs.CL cs.SI physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce distance entropy as a measure of homogeneity in the distribution\nof path lengths between a given node and its neighbours in a complex network.\nDistance entropy defines a new centrality measure whose properties are\ninvestigated for a variety of synthetic network models. By coupling distance\nentropy information with closeness centrality, we introduce a network\ncartography which allows one to reduce the degeneracy of ranking based on\ncloseness alone. We apply this methodology to the empirical multiplex lexical\nnetwork encoding the linguistic relationships known to English speaking\ntoddlers. We show that the distance entropy cartography better predicts how\nchildren learn words compared to closeness centrality. Our results highlight\nthe importance of distance entropy for gaining insights from distance patterns\nin complex networks.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 13:53:34 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Stella", "Massimo", ""], ["De Domenico", "Manlio", ""]]}, {"id": "1802.10569", "submitter": "Patrick Verga", "authors": "Patrick Verga and Emma Strubell and Andrew McCallum", "title": "Simultaneously Self-Attending to All Mentions for Full-Abstract\n  Biological Relation Extraction", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most work in relation extraction forms a prediction by looking at a short\nspan of text within a single sentence containing a single entity pair mention.\nThis approach often does not consider interactions across mentions, requires\nredundant computation for each mention pair, and ignores relationships\nexpressed across sentence boundaries. These problems are exacerbated by the\ndocument- (rather than sentence-) level annotation common in biological text.\nIn response, we propose a model which simultaneously predicts relationships\nbetween all mention pairs in a document. We form pairwise predictions over\nentire paper abstracts using an efficient self-attention encoder. All-pairs\nmention scores allow us to perform multi-instance learning by aggregating over\nmentions to form entity pair representations. We further adapt to settings\nwithout mention-level annotation by jointly training to predict named entities\nand adding a corpus of weakly labeled data. In experiments on two Biocreative\nbenchmark datasets, we achieve state of the art performance on the Biocreative\nV Chemical Disease Relation dataset for models without external KB resources.\nWe also introduce a new dataset an order of magnitude larger than existing\nhuman-annotated biological information extraction datasets and more accurate\nthan distantly supervised alternatives.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 18:17:40 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Verga", "Patrick", ""], ["Strubell", "Emma", ""], ["McCallum", "Andrew", ""]]}]