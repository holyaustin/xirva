[{"id": "1903.00041", "submitter": "George Foster", "authors": "Gaurav Kumar, George Foster, Colin Cherry, Maxim Krikun", "title": "Reinforcement Learning based Curriculum Optimization for Neural Machine\n  Translation", "comments": "NAACL 2019 short paper. Reviewer comments not yet addressed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We consider the problem of making efficient use of heterogeneous training\ndata in neural machine translation (NMT). Specifically, given a training\ndataset with a sentence-level feature such as noise, we seek an optimal\ncurriculum, or order for presenting examples to the system during training. Our\ncurriculum framework allows examples to appear an arbitrary number of times,\nand thus generalizes data weighting, filtering, and fine-tuning schemes. Rather\nthan relying on prior knowledge to design a curriculum, we use reinforcement\nlearning to learn one automatically, jointly with the NMT system, in the course\nof a single training run. We show that this approach can beat uniform and\nfiltering baselines on Paracrawl and WMT English-to-French datasets by up to\n+3.4 BLEU, and match the performance of a hand-designed, state-of-the-art\ncurriculum.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 19:35:09 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Kumar", "Gaurav", ""], ["Foster", "George", ""], ["Cherry", "Colin", ""], ["Krikun", "Maxim", ""]]}, {"id": "1903.00058", "submitter": "Ankur Bapna", "authors": "Ankur Bapna and Orhan Firat", "title": "Non-Parametric Adaptation for Neural Machine Translation", "comments": "Accepted at NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Networks trained with gradient descent are known to be susceptible to\ncatastrophic forgetting caused by parameter shift during the training process.\nIn the context of Neural Machine Translation (NMT) this results in poor\nperformance on heterogeneous datasets and on sub-tasks like rare phrase\ntranslation. On the other hand, non-parametric approaches are immune to\nforgetting, perfectly complementing the generalization ability of NMT. However,\nattempts to combine non-parametric or retrieval based approaches with NMT have\nonly been successful on narrow domains, possibly due to over-reliance on\nsentence level retrieval. We propose a novel n-gram level retrieval approach\nthat relies on local phrase level similarities, allowing us to retrieve\nneighbors that are useful for translation even when overall sentence similarity\nis low. We complement this with an expressive neural network, allowing our\nmodel to extract information from the noisy retrieved context. We evaluate our\nsemi-parametric NMT approach on a heterogeneous dataset composed of WMT, IWSLT,\nJRC-Acquis and OpenSubtitles, and demonstrate gains on all 4 evaluation sets.\nThe semi-parametric nature of our approach opens the door for non-parametric\ndomain adaptation, demonstrating strong inference-time adaptation performance\non new domains without the need for any parameter updates.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 20:33:00 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 18:57:37 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Bapna", "Ankur", ""], ["Firat", "Orhan", ""]]}, {"id": "1903.00089", "submitter": "Roee Aharoni", "authors": "Roee Aharoni, Melvin Johnson, Orhan Firat", "title": "Massively Multilingual Neural Machine Translation", "comments": "Accepted as a long paper in NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual neural machine translation (NMT) enables training a single model\nthat supports translation from multiple source languages into multiple target\nlanguages. In this paper, we push the limits of multilingual NMT in terms of\nnumber of languages being used. We perform extensive experiments in training\nmassively multilingual NMT models, translating up to 102 languages to and from\nEnglish within a single model. We explore different setups for training such\nmodels and analyze the trade-offs between translation quality and various\nmodeling decisions. We report results on the publicly available TED talks\nmultilingual corpus where we show that massively multilingual many-to-many\nmodels are effective in low resource settings, outperforming the previous\nstate-of-the-art while supporting up to 59 languages. Our experiments on a\nlarge-scale dataset with 102 languages to and from English and up to one\nmillion examples per direction also show promising results, surpassing strong\nbilingual baselines and encouraging future work on massively multilingual NMT.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 22:26:12 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 10:19:44 GMT"}, {"version": "v3", "created": "Tue, 2 Jul 2019 16:44:03 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Aharoni", "Roee", ""], ["Johnson", "Melvin", ""], ["Firat", "Orhan", ""]]}, {"id": "1903.00122", "submitter": "Jesse Thomason", "authors": "Jesse Thomason, Aishwarya Padmakumar, Jivko Sinapov, Nick Walker,\n  Yuqian Jiang, Harel Yedidsion, Justin Hart, Peter Stone and Raymond J. Mooney", "title": "Improving Grounded Natural Language Understanding through Human-Robot\n  Dialog", "comments": null, "journal-ref": null, "doi": "10.1109/ICRA.2019.8794287", "report-no": null, "categories": "cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language understanding for robotics can require substantial domain-\nand platform-specific engineering. For example, for mobile robots to\npick-and-place objects in an environment to satisfy human commands, we can\nspecify the language humans use to issue such commands, and connect concept\nwords like red can to physical object properties. One way to alleviate this\nengineering for a new domain is to enable robots in human environments to adapt\ndynamically---continually learning new language constructions and perceptual\nconcepts. In this work, we present an end-to-end pipeline for translating\nnatural language commands to discrete robot actions, and use clarification\ndialogs to jointly improve language parsing and concept grounding. We train and\nevaluate this agent in a virtual setting on Amazon Mechanical Turk, and we\ntransfer the learned agent to a physical robot platform to demonstrate it in\nthe real world.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 01:43:11 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Thomason", "Jesse", ""], ["Padmakumar", "Aishwarya", ""], ["Sinapov", "Jivko", ""], ["Walker", "Nick", ""], ["Jiang", "Yuqian", ""], ["Yedidsion", "Harel", ""], ["Hart", "Justin", ""], ["Stone", "Peter", ""], ["Mooney", "Raymond J.", ""]]}, {"id": "1903.00138", "submitter": "Wei Zhao", "authors": "Wei Zhao, Liang Wang, Kewei Shen, Ruoyu Jia, Jingming Liu", "title": "Improving Grammatical Error Correction via Pre-Training a Copy-Augmented\n  Architecture with Unlabeled Data", "comments": "Accepted by NAACL 2019 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation systems have become state-of-the-art approaches\nfor Grammatical Error Correction (GEC) task. In this paper, we propose a\ncopy-augmented architecture for the GEC task by copying the unchanged words\nfrom the source sentence to the target sentence. Since the GEC suffers from not\nhaving enough labeled training data to achieve high accuracy. We pre-train the\ncopy-augmented architecture with a denoising auto-encoder using the unlabeled\nOne Billion Benchmark and make comparisons between the fully pre-trained model\nand a partially pre-trained model. It is the first time copying words from the\nsource context and fully pre-training a sequence to sequence model are\nexperimented on the GEC task. Moreover, We add token-level and sentence-level\nmulti-task learning for the GEC task. The evaluation results on the CoNLL-2014\ntest set show that our approach outperforms all recently published\nstate-of-the-art results by a large margin. The code and pre-trained models are\nreleased at https://github.com/zhawe01/fairseq-gec.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 03:08:03 GMT"}, {"version": "v2", "created": "Sat, 4 May 2019 10:46:43 GMT"}, {"version": "v3", "created": "Tue, 11 Jun 2019 10:53:08 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Zhao", "Wei", ""], ["Wang", "Liang", ""], ["Shen", "Kewei", ""], ["Jia", "Ruoyu", ""], ["Liu", "Jingming", ""]]}, {"id": "1903.00149", "submitter": "Mamoru Komachi", "authors": "Longtu Zhang and Mamoru Komachi", "title": "Chinese-Japanese Unsupervised Neural Machine Translation Using\n  Sub-character Level Information", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unsupervised neural machine translation (UNMT) requires only monolingual data\nof similar language pairs during training and can produce bi-directional\ntranslation models with relatively good performance on alphabetic languages\n(Lample et al., 2018). However, no research has been done to logographic\nlanguage pairs. This study focuses on Chinese-Japanese UNMT trained by data\ncontaining sub-character (ideograph or stroke) level information which is\ndecomposed from character level data. BLEU scores of both character and\nsub-character level systems were compared against each other and the results\nshowed that despite the effectiveness of UNMT on character level data,\nsub-character level data could further enhance the performance, in which the\nstroke level system outperformed the ideograph level system.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 03:57:15 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Zhang", "Longtu", ""], ["Komachi", "Mamoru", ""]]}, {"id": "1903.00161", "submitter": "Dheeru Dua", "authors": "Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Stanovsky, Sameer\n  Singh, Matt Gardner", "title": "DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning\n  Over Paragraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reading comprehension has recently seen rapid progress, with systems matching\nhumans on the most popular datasets for the task. However, a large body of work\nhas highlighted the brittleness of these systems, showing that there is much\nwork left to be done. We introduce a new English reading comprehension\nbenchmark, DROP, which requires Discrete Reasoning Over the content of\nParagraphs. In this crowdsourced, adversarially-created, 96k-question\nbenchmark, a system must resolve references in a question, perhaps to multiple\ninput positions, and perform discrete operations over them (such as addition,\ncounting, or sorting). These operations require a much more comprehensive\nunderstanding of the content of paragraphs than what was necessary for prior\ndatasets. We apply state-of-the-art methods from both the reading comprehension\nand semantic parsing literature on this dataset and show that the best systems\nonly achieve 32.7% F1 on our generalized accuracy metric, while expert human\nperformance is 96.0%. We additionally present a new model that combines reading\ncomprehension methods with simple numerical reasoning to achieve 47.0% F1.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 05:32:01 GMT"}, {"version": "v2", "created": "Tue, 16 Apr 2019 21:22:39 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Dua", "Dheeru", ""], ["Wang", "Yizhong", ""], ["Dasigi", "Pradeep", ""], ["Stanovsky", "Gabriel", ""], ["Singh", "Sameer", ""], ["Gardner", "Matt", ""]]}, {"id": "1903.00172", "submitter": "Yoshihiko Suhara", "authors": "Nikita Bhutani, Yoshihiko Suhara, Wang-Chiew Tan, Alon Halevy, H. V.\n  Jagadish", "title": "Open Information Extraction from Question-Answer Pairs", "comments": "NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open Information Extraction (OpenIE) extracts meaningful structured tuples\nfrom free-form text. Most previous work on OpenIE considers extracting data\nfrom one sentence at a time. We describe NeurON, a system for extracting tuples\nfrom question-answer pairs. Since real questions and answers often contain\nprecisely the information that users care about, such information is\nparticularly desirable to extend a knowledge base with.\n  NeurON addresses several challenges. First, an answer text is often hard to\nunderstand without knowing the question, and second, relevant information can\nspan multiple sentences. To address these, NeurON formulates extraction as a\nmulti-source sequence-to-sequence learning task, wherein it combines\ndistributed representations of a question and an answer to generate knowledge\nfacts. We describe experiments on two real-world datasets that demonstrate that\nNeurON can find a significant number of new and interesting facts to extend a\nknowledge base compared to state-of-the-art OpenIE methods.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 06:26:50 GMT"}, {"version": "v2", "created": "Sat, 6 Apr 2019 08:56:40 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Bhutani", "Nikita", ""], ["Suhara", "Yoshihiko", ""], ["Tan", "Wang-Chiew", ""], ["Halevy", "Alon", ""], ["Jagadish", "H. V.", ""]]}, {"id": "1903.00216", "submitter": "Egor Lakomkin", "authors": "Egor Lakomkin and Sven Magg and Cornelius Weber and Stefan Wermter", "title": "KT-Speech-Crawler: Automatic Dataset Construction for Speech Recognition\n  from YouTube Videos", "comments": "Accepted at the Conference on Empirical Methods in Natural Language\n  Processing 2018, Brussels, Belgium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe KT-Speech-Crawler: an approach for automatic\ndataset construction for speech recognition by crawling YouTube videos. We\noutline several filtering and post-processing steps, which extract samples that\ncan be used for training end-to-end neural speech recognition systems. In our\nexperiments, we demonstrate that a single-core version of the crawler can\nobtain around 150 hours of transcribed speech within a day, containing an\nestimated 3.5% word error rate in the transcriptions. Automatically collected\nsamples contain reading and spontaneous speech recorded in various conditions\nincluding background noise and music, distant microphone recordings, and a\nvariety of accents and reverberation. When training a deep neural network on\nspeech recognition, we observed around 40\\% word error rate reduction on the\nWall Street Journal dataset by integrating 200 hours of the collected samples\ninto the training set. The demo (http://emnlp-demo.lakomkin.me/) and the\ncrawler code (https://github.com/EgorLakomkin/KTSpeechCrawler) are publicly\navailable.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 09:14:50 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Lakomkin", "Egor", ""], ["Magg", "Sven", ""], ["Weber", "Cornelius", ""], ["Wermter", "Stefan", ""]]}, {"id": "1903.00232", "submitter": "Muhammad Aslam Jarwar", "authors": "Muhammad Aslam Jarwar", "title": "A Framework for Detecting Event related Sentiments of a Community", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media has revolutionized human communication and styles of\ninteraction. Due to its easiness and effective medium, people share and\nexchange information, carry out discussion on various events, and express their\nopinions. For effective policy making and understanding the response of a\ncommunity on different events, we need to monitor and analyze the social media.\nIn social media, there are some users who are more influential, for example, a\nfamous politician may have more influence than a common person. These\ninfluential users belong to specific communities. The main object of this\nresearch is to know the sentiments of a specific community on various events.\nFor detecting the event based sentiments of a community we propose a generic\nframework. Our framework identifies the users of a specific community on\ntwitter. After identifying the users of a community, we fetch their tweets and\nidentify tweets belonging to specific events. The event based tweets are\npre-processed. Pre-processed tweets are then analyzed for detecting sentiments\nof a community for specific events. Qualitative and quantitative evaluation\nconfirms the effectiveness and usefulness of our proposed framework.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 10:10:36 GMT"}, {"version": "v2", "created": "Thu, 25 Apr 2019 02:42:45 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Jarwar", "Muhammad Aslam", ""]]}, {"id": "1903.00384", "submitter": "Lu Xu", "authors": "Lu Xu, Jinhai Xiang, Yating Wang, Fuchuan Ni", "title": "Data-driven Approach for Quality Evaluation on Knowledge Sharing\n  Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, voice knowledge sharing and question answering (Q&A)\nplatforms have attracted much attention, which greatly facilitate the knowledge\nacquisition for people. However, little research has evaluated on the quality\nevaluation on voice knowledge sharing. This paper presents a data-driven\napproach to automatically evaluate the quality of a specific Q&A platform\n(Zhihu Live). Extensive experiments demonstrate the effectiveness of the\nproposed method. Furthermore, we introduce a dataset of Zhihu Live as an open\nresource for researchers in related areas. This dataset will facilitate the\ndevelopment of new methods on knowledge sharing services quality evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 16:04:27 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Xu", "Lu", ""], ["Xiang", "Jinhai", ""], ["Wang", "Yating", ""], ["Ni", "Fuchuan", ""]]}, {"id": "1903.00401", "submitter": "Karl Moritz Hermann", "authors": "Karl Moritz Hermann, Mateusz Malinowski, Piotr Mirowski, Andras\n  Banki-Horvath, Keith Anderson, Raia Hadsell", "title": "Learning To Follow Directions in Street View", "comments": null, "journal-ref": "AAAI 2020", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Navigating and understanding the real world remains a key challenge in\nmachine learning and inspires a great variety of research in areas such as\nlanguage grounding, planning, navigation and computer vision. We propose an\ninstruction-following task that requires all of the above, and which combines\nthe practicality of simulated environments with the challenges of ambiguous,\nnoisy real world data. StreetNav is built on top of Google Street View and\nprovides visually accurate environments representing real places. Agents are\ngiven driving instructions which they must learn to interpret in order to\nsuccessfully navigate in this environment. Since humans equipped with driving\ninstructions can readily navigate in previously unseen cities, we set a high\nbar and test our trained agents for similar cognitive capabilities. Although\ndeep reinforcement learning (RL) methods are frequently evaluated only on data\nthat closely follow the training distribution, our dataset extends to multiple\ncities and has a clean train/test separation. This allows for thorough testing\nof generalisation ability. This paper presents the StreetNav environment and\ntasks, models that establish strong baselines, and extensive analysis of the\ntask and the trained agents.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 16:50:02 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 22:38:35 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Hermann", "Karl Moritz", ""], ["Malinowski", "Mateusz", ""], ["Mirowski", "Piotr", ""], ["Banki-Horvath", "Andras", ""], ["Anderson", "Keith", ""], ["Hadsell", "Raia", ""]]}, {"id": "1903.00415", "submitter": "Daniel Elton", "authors": "Daniel C. Elton, Dhruv Turakhia, Nischal Reddy, Zois Boukouvalas, Mark\n  D. Fuge, Ruth M. Doherty, Peter W. Chung", "title": "Using natural language processing techniques to extract information on\n  the properties and functionalities of energetic materials from large text\n  corpora", "comments": "accepted for publication in the 2019 NTREM proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cond-mat.mtrl-sci", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The number of scientific journal articles and reports being published about\nenergetic materials every year is growing exponentially, and therefore\nextracting relevant information and actionable insights from the latest\nresearch is becoming a considerable challenge. In this work we explore how\ntechniques from natural language processing and machine learning can be used to\nautomatically extract chemical insights from large collections of documents. We\nfirst describe how to download and process documents from a variety of sources\n- journal articles, conference proceedings (including NTREM), the US Patent &\nTrademark Office, and the Defense Technical Information Center archive on\narchive.org. We present a custom NLP pipeline which uses open source NLP tools\nto identify the names of chemical compounds and relates them to function words\n(\"underwater\", \"rocket\", \"pyrotechnic\") and property words (\"elastomer\",\n\"non-toxic\"). After explaining how word embeddings work we compare the utility\nof two popular word embeddings - word2vec and GloVe. Chemical-chemical and\nchemical-application relationships are obtained by doing computations with word\nvectors. We show that word embeddings capture latent information about\nenergetic materials, so that related materials appear close together in the\nword embedding space.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 17:14:33 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Elton", "Daniel C.", ""], ["Turakhia", "Dhruv", ""], ["Reddy", "Nischal", ""], ["Boukouvalas", "Zois", ""], ["Fuge", "Mark D.", ""], ["Doherty", "Ruth M.", ""], ["Chung", "Peter W.", ""]]}, {"id": "1903.00665", "submitter": "Andrei-Octavian Brabete Mr", "authors": "Andrei-Bogdan Puiu, Andrei-Octavian Brabete", "title": "Towards NLP with Deep Learning: Convolutional Neural Networks and\n  Recurrent Neural Networks for Offensive Language Identification in Social\n  Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short paper presents the design decisions taken and challenges\nencountered in completing SemEval Task 6, which poses the problem of\nidentifying and categorizing offensive language in tweets. Our proposed\nsolutions explore Deep Learning techniques, Linear Support Vector\nclassification and Random Forests to identify offensive tweets, to classify\noffenses as targeted or untargeted and eventually to identify the target\nsubject type.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 09:42:54 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 20:03:19 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Puiu", "Andrei-Bogdan", ""], ["Brabete", "Andrei-Octavian", ""]]}, {"id": "1903.00724", "submitter": "Jean-Samuel Leboeuf", "authors": "Nicolas Garneau, Jean-Samuel Leboeuf and Luc Lamontagne", "title": "Predicting and interpreting embeddings for out of vocabulary words in\n  downstream tasks", "comments": "2 pages, 0 figures, 2 tables", "journal-ref": "Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and\n  Interpreting Neural Networks for NLP", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel way to handle out of vocabulary (OOV) words in downstream\nnatural language processing (NLP) tasks. We implement a network that predicts\nuseful embeddings for OOV words based on their morphology and on the context in\nwhich they appear. Our model also incorporates an attention mechanism\nindicating the focus allocated to the left context words, the right context\nwords or the word's characters, hence making the prediction more interpretable.\nThe model is a ``drop-in'' module that is jointly trained with the downstream\ntask's neural network, thus producing embeddings specialized for the task at\nhand. When the task is mostly syntactical, we observe that our model aims most\nof its attention on surface form characters. On the other hand, for tasks more\nsemantical, the network allocates more attention to the surrounding words. In\nall our tests, the module helps the network to achieve better performances in\ncomparison to the use of simple random embeddings.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 15:32:39 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Garneau", "Nicolas", ""], ["Leboeuf", "Jean-Samuel", ""], ["Lamontagne", "Luc", ""]]}, {"id": "1903.00802", "submitter": "Aviral Kumar", "authors": "Aviral Kumar, Sunita Sarawagi", "title": "Calibration of Encoder Decoder Models for Neural Machine Translation", "comments": "12 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the calibration of several state of the art neural machine\ntranslation(NMT) systems built on attention-based encoder-decoder models. For\nstructured outputs like in NMT, calibration is important not just for reliable\nconfidence with predictions, but also for proper functioning of beam-search\ninference. We show that most modern NMT models are surprisingly miscalibrated\neven when conditioned on the true previous tokens. Our investigation leads to\ntwo main reasons -- severe miscalibration of EOS (end of sequence marker) and\nsuppression of attention uncertainty. We design recalibration methods based on\nthese signals and demonstrate improved accuracy, better sequence-level\ncalibration, and more intuitive results from beam-search.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 01:08:47 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Kumar", "Aviral", ""], ["Sarawagi", "Sunita", ""]]}, {"id": "1903.00830", "submitter": "Vinayak Athavale", "authors": "Vinayak Athavale, Aayush Naik, Rajas Vanjape, Manish Shrivastava", "title": "Predicting Algorithm Classes for Programming Word Problems", "comments": "Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the task of algorithm class prediction for programming word\nproblems. A programming word problem is a problem written in natural language,\nwhich can be solved using an algorithm or a program. We define classes of\nvarious programming word problems which correspond to the class of algorithms\nrequired to solve the problem. We present four new datasets for this task, two\nmulticlass datasets with 550 and 1159 problems each and two multilabel datasets\nhaving 3737 and 3960 problems each. We pose the problem as a text\nclassification problem and train neural network and non-neural network-based\nmodels on this task. Our best performing classifier gets an accuracy of 62.7\npercent for the multiclass case on the five class classification dataset,\nCodeforces Multiclass-5 (CFMC5). We also do some human-level analysis and\ncompare human performance with that of our text classification models. Our best\nclassifier has an accuracy only 9 percent lower than that of a human on this\ntask. To the best of our knowledge, these are the first reported results on\nsuch a task. We make our code and datasets publicly available.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 04:39:33 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 17:24:56 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Athavale", "Vinayak", ""], ["Naik", "Aayush", ""], ["Vanjape", "Rajas", ""], ["Shrivastava", "Manish", ""]]}, {"id": "1903.00839", "submitter": "Xihui Liu", "authors": "Xihui Liu, Zihao Wang, Jing Shao, Xiaogang Wang, Hongsheng Li", "title": "Improving Referring Expression Grounding with Cross-modal\n  Attention-guided Erasing", "comments": "Accepted by CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Referring expression grounding aims at locating certain objects or persons in\nan image with a referring expression, where the key challenge is to comprehend\nand align various types of information from visual and textual domain, such as\nvisual attributes, location and interactions with surrounding regions. Although\nthe attention mechanism has been successfully applied for cross-modal\nalignments, previous attention models focus on only the most dominant features\nof both modalities, and neglect the fact that there could be multiple\ncomprehensive textual-visual correspondences between images and referring\nexpressions. To tackle this issue, we design a novel cross-modal\nattention-guided erasing approach, where we discard the most dominant\ninformation from either textual or visual domains to generate difficult\ntraining samples online, and to drive the model to discover complementary\ntextual-visual correspondences. Extensive experiments demonstrate the\neffectiveness of our proposed method, which achieves state-of-the-art\nperformance on three referring expression grounding datasets.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 05:55:15 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 07:33:37 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Liu", "Xihui", ""], ["Wang", "Zihao", ""], ["Shao", "Jing", ""], ["Wang", "Xiaogang", ""], ["Li", "Hongsheng", ""]]}, {"id": "1903.00933", "submitter": "Bai Li", "authors": "Bai Li, Yi-Te Hsu, Frank Rudzicz", "title": "Detecting dementia in Mandarin Chinese using transfer learning from a\n  parallel corpus", "comments": "NAACL 2019 (Short paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has shown promise for automatic detection of Alzheimer's\ndisease (AD) through speech; however, efforts are hampered by a scarcity of\ndata, especially in languages other than English. We propose a method to learn\na correspondence between independently engineered lexicosyntactic features in\ntwo languages, using a large parallel corpus of out-of-domain movie dialogue\ndata. We apply it to dementia detection in Mandarin Chinese, and demonstrate\nthat our method outperforms both unilingual and machine translation-based\nbaselines. This appears to be the first study that transfers feature domains in\ndetecting cognitive decline.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 16:07:10 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 16:11:36 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Li", "Bai", ""], ["Hsu", "Yi-Te", ""], ["Rudzicz", "Frank", ""]]}, {"id": "1903.00943", "submitter": "Ethan Wilcox", "authors": "Ethan Wilcox, Peng Qian, Richard Futrell, Miguel Ballesteros and Roger\n  Levy", "title": "Structural Supervision Improves Learning of Non-Local Grammatical\n  Dependencies", "comments": "To appear: Proceedings of the 2019 Conference of the North American\n  Chapter of the Association for Computational Linguistics: Human Language\n  Technologies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art LSTM language models trained on large corpora learn\nsequential contingencies in impressive detail and have been shown to acquire a\nnumber of non-local grammatical dependencies with some success. Here we\ninvestigate whether supervision with hierarchical structure enhances learning\nof a range of grammatical dependencies, a question that has previously been\naddressed only for subject-verb agreement. Using controlled experimental\nmethods from psycholinguistics, we compare the performance of word-based LSTM\nmodels versus two models that represent hierarchical structure and deploy it in\nleft-to-right processing: Recurrent Neural Network Grammars (RNNGs) (Dyer et\nal., 2016) and a incrementalized version of the Parsing-as-Language-Modeling\nconfiguration from Chariak et al., (2016). Models are tested on a diverse range\nof configurations for two classes of non-local grammatical dependencies in\nEnglish---Negative Polarity licensing and Filler--Gap Dependencies. Using the\nsame training data across models, we find that structurally-supervised models\noutperform the LSTM, with the RNNG demonstrating best results on both types of\ngrammatical dependencies and even learning many of the Island Constraints on\nthe filler--gap dependency. Structural supervision thus provides data\nefficiency advantages over purely string-based training of neural language\nmodels in acquiring human-like generalizations about non-local grammatical\ndependencies.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 17:08:00 GMT"}, {"version": "v2", "created": "Sat, 6 Apr 2019 17:48:38 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Wilcox", "Ethan", ""], ["Qian", "Peng", ""], ["Futrell", "Richard", ""], ["Ballesteros", "Miguel", ""], ["Levy", "Roger", ""]]}, {"id": "1903.01039", "submitter": "Katikapalli Subramanyam Kalyan", "authors": "Kalyan KS, S Sangeetha", "title": "SECNLP: A Survey of Embeddings in Clinical Natural Language Processing", "comments": "Published in Journal of Biomedical Informatics (For updated version,\n  refer 10.1016/j.jbi.2019.103323)", "journal-ref": "Journal of Biomedical Informatics, Volume 101, January 2020,\n  103323", "doi": "10.1016/j.jbi.2019.103323", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional representations like Bag of words are high dimensional, sparse\nand ignore the order as well as syntactic and semantic information. Distributed\nvector representations or embeddings map variable length text to dense fixed\nlength vectors as well as capture the prior knowledge which can transferred to\ndownstream tasks. Even though embedding has become de facto standard for\nrepresentations in deep learning based NLP tasks in both general and clinical\ndomains, there is no survey paper which presents a detailed review of\nembeddings in Clinical Natural Language Processing. In this survey paper, we\ndiscuss various medical corpora and their characteristics, medical codes and\npresent a brief overview as well as comparison of popular embeddings models. We\nclassify clinical embeddings into nine types and discuss each embedding type in\ndetail. We discuss various evaluation methods followed by possible solutions to\nvarious challenges in clinical embeddings. Finally, we conclude with some of\nthe future directions which will advance the research in clinical embeddings.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 01:37:52 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 03:16:20 GMT"}, {"version": "v3", "created": "Sun, 17 Mar 2019 15:01:33 GMT"}, {"version": "v4", "created": "Wed, 25 Nov 2020 02:06:42 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["KS", "Kalyan", ""], ["Sangeetha", "S", ""]]}, {"id": "1903.01080", "submitter": "Ruixue Liu", "authors": "Ruixue Liu, Baoyang Chen, Xiaoyu Guo, Yan Dai, Meng Chen, Zhijie Qiu,\n  Xiaodong He", "title": "From Knowledge Map to Mind Map: Artificial Imagination", "comments": "It's accepted by IEEE MIPR 2019, Workshop on Artificial Intelligence\n  for Art Creation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imagination is one of the most important factors which makes an artistic\npainting unique and impressive. With the rapid development of Artificial\nIntelligence, more and more researchers try to create painting with AI\ntechnology automatically. However, lacking of imagination is still a main\nproblem for AI painting. In this paper, we propose a novel approach to inject\nrich imagination into a special painting art Mind Map creation. We firstly\nconsider lexical and phonological similarities of seed word, then learn and\ninherit original painting style of the author, and finally apply Dadaism and\nimpossibility of improvisation principles into painting process. We also design\nseveral metrics for imagination evaluation. Experimental results show that our\nproposed method can increase imagination of painting and also improve its\noverall quality.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 05:38:29 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 06:35:56 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Liu", "Ruixue", ""], ["Chen", "Baoyang", ""], ["Guo", "Xiaoyu", ""], ["Dai", "Yan", ""], ["Chen", "Meng", ""], ["Qiu", "Zhijie", ""], ["He", "Xiaodong", ""]]}, {"id": "1903.01275", "submitter": "Gerhard Wohlgenannt Dr.", "authors": "Gerhard Wohlgenannt and Nikolay Klimov and Dmitry Mouromtsev and\n  Daniil Razdyakonov and Dmitry Pavlov and Yury Emelyanov", "title": "Using Word Embeddings for Visual Data Exploration with Ontodia and\n  Wikidata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the big challenges in Linked Data consumption is to create visual and\nnatural language interfaces to the data usable for non-technical users. Ontodia\nprovides support for diagrammatic data exploration, showcased in this\npublication in combination with the Wikidata dataset. We present improvements\nto the natural language interface regarding exploring and querying Linked Data\nentities. The method uses models of distributional semantics to find and rank\nentity properties related to user input in Ontodia. Various word embedding\ntypes and model settings are evaluated, and the results show that user\nexperience in visual data exploration benefits from the proposed approach.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 14:36:21 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Wohlgenannt", "Gerhard", ""], ["Klimov", "Nikolay", ""], ["Mouromtsev", "Dmitry", ""], ["Razdyakonov", "Daniil", ""], ["Pavlov", "Dmitry", ""], ["Emelyanov", "Yury", ""]]}, {"id": "1903.01284", "submitter": "Gerhard Wohlgenannt Dr.", "authors": "Gerhard Wohlgenannt and Ekaterina Chernyak and Dmitry Ilvovsky and\n  Ariadna Barinova and Dmitry Mouromtsev", "title": "Relation Extraction Datasets in the Digital Humanities Domain and their\n  Evaluation with Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this research, we manually create high-quality datasets in the digital\nhumanities domain for the evaluation of language models, specifically word\nembedding models. The first step comprises the creation of unigram and n-gram\ndatasets for two fantasy novel book series for two task types each, analogy and\ndoesn't-match. This is followed by the training of models on the two book\nseries with various popular word embedding model types such as word2vec, GloVe,\nfastText, or LexVec. Finally, we evaluate the suitability of word embedding\nmodels for such specific relation extraction tasks in a situation of comparably\nsmall corpus sizes. In the evaluations, we also investigate and analyze\nparticular aspects such as the impact of corpus term frequencies and task\ndifficulty on accuracy. The datasets, and the underlying system and word\nembedding models are available on github and can be easily extended with new\ndatasets and tasks, be used to reproduce the presented results, or be\ntransferred to other domains.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 14:46:20 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Wohlgenannt", "Gerhard", ""], ["Chernyak", "Ekaterina", ""], ["Ilvovsky", "Dmitry", ""], ["Barinova", "Ariadna", ""], ["Mouromtsev", "Dmitry", ""]]}, {"id": "1903.01290", "submitter": "Thomas Drugman", "authors": "Thomas Drugman, Goeric Huybrechts, Viacheslav Klimkov, Alexis Moinet", "title": "Traditional Machine Learning for Pitch Detection", "comments": null, "journal-ref": "IEEE Signal Processing Letters, Vol. 25, Issue 11, pp. 1745-1749,\n  2018", "doi": "10.1109/LSP.2018.2874155", "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pitch detection is a fundamental problem in speech processing as F0 is used\nin a large number of applications. Recent articles have proposed deep learning\nfor robust pitch tracking. In this paper, we consider voicing detection as a\nclassification problem and F0 contour estimation as a regression problem. For\nboth tasks, acoustic features from multiple domains and traditional machine\nlearning methods are used. The discrimination power of existing and proposed\nfeatures is assessed through mutual information. Multiple supervised and\nunsupervised approaches are compared. A significant relative reduction of\nvoicing errors over the best baseline is obtained: 20% with the best clustering\nmethod (K-means) and 45% with a Multi-Layer Perceptron. For F0 contour\nestimation, the benefits of regression techniques are limited though. We\ninvestigate whether those objective gains translate in a parametric synthesis\ntask. Clear perceptual preferences are observed for the proposed approach over\ntwo widely-used baselines (RAPT and DIO).\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 14:53:26 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Drugman", "Thomas", ""], ["Huybrechts", "Goeric", ""], ["Klimkov", "Viacheslav", ""], ["Moinet", "Alexis", ""]]}, {"id": "1903.01306", "submitter": "Ningyu Zhang", "authors": "Ningyu Zhang, Shumin Deng, Zhanlin Sun, Guanying Wang, Xi Chen, Wei\n  Zhang, Huajun Chen", "title": "Long-tail Relation Extraction via Knowledge Graph Embeddings and Graph\n  Convolution Networks", "comments": "To be published in NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a distance supervised relation extraction approach for\nlong-tailed, imbalanced data which is prevalent in real-world settings. Here,\nthe challenge is to learn accurate \"few-shot\" models for classes existing at\nthe tail of the class distribution, for which little data is available.\nInspired by the rich semantic correlations between classes at the long tail and\nthose at the head, we take advantage of the knowledge from data-rich classes at\nthe head of the distribution to boost the performance of the data-poor classes\nat the tail. First, we propose to leverage implicit relational knowledge among\nclass labels from knowledge graph embeddings and learn explicit relational\nknowledge using graph convolution networks. Second, we integrate that\nrelational knowledge into relation extraction model by coarse-to-fine\nknowledge-aware attention mechanism. We demonstrate our results for a\nlarge-scale benchmark dataset which show that our approach significantly\noutperforms other baselines, especially for long-tail relations.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 15:32:39 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Zhang", "Ningyu", ""], ["Deng", "Shumin", ""], ["Sun", "Zhanlin", ""], ["Wang", "Guanying", ""], ["Chen", "Xi", ""], ["Zhang", "Wei", ""], ["Chen", "Huajun", ""]]}, {"id": "1903.01411", "submitter": "Mihael Arcan", "authors": "Mihael Arcan and John McCrae and Paul Buitelaar", "title": "Polylingual Wordnet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Princeton WordNet is one of the most important resources for natural language\nprocessing, but is only available for English. While it has been translated\nusing the expand approach to many other languages, this is an expensive manual\nprocess. Therefore it would be beneficial to have a high-quality automatic\ntranslation approach that would support NLP techniques, which rely on WordNet\nin new languages. The translation of wordnets is fundamentally complex because\nof the need to translate all senses of a word including low frequency senses,\nwhich is very challenging for current machine translation approaches. For this\nreason we leverage existing translations of WordNet in other languages to\nidentify contextual information for wordnet senses from a large set of generic\nparallel corpora. We evaluate our approach using 10 translated wordnets for\nEuropean languages. Our experiment shows a significant improvement over\ntranslation without any contextual information. Furthermore, we evaluate how\nthe choice of pivot languages affects performance of multilingual word sense\ndisambiguation.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 18:10:52 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Arcan", "Mihael", ""], ["McCrae", "John", ""], ["Buitelaar", "Paul", ""]]}, {"id": "1903.01698", "submitter": "Yuxiao Ye", "authors": "Yuxiao Ye, Yue Zhang, Weikang Li, Likun Qiu, Jian Sun", "title": "Improving Cross-Domain Chinese Word Segmentation with Word Embeddings", "comments": null, "journal-ref": "NAACL 2019", "doi": "10.18653/v1/N19-1279", "report-no": "N19-1279", "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-domain Chinese Word Segmentation (CWS) remains a challenge despite\nrecent progress in neural-based CWS. The limited amount of annotated data in\nthe target domain has been the key obstacle to a satisfactory performance. In\nthis paper, we propose a semi-supervised word-based approach to improving\ncross-domain CWS given a baseline segmenter. Particularly, our model only\ndeploys word embeddings trained on raw text in the target domain, discarding\ncomplex hand-crafted features and domain-specific dictionaries. Innovative\nsubsampling and negative sampling methods are proposed to derive word\nembeddings optimized for CWS. We conduct experiments on five datasets in\nspecial domains, covering domains in novels, medicine, and patent. Results show\nthat our model can obviously improve cross-domain CWS, especially in the\nsegmentation of domain-specific noun entities. The word F-measure increases by\nover 3.0% on four datasets, outperforming state-of-the-art semi-supervised and\nunsupervised cross-domain CWS approaches with a large margin. We make our code\nand data available on Github.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 06:56:12 GMT"}, {"version": "v2", "created": "Mon, 11 Mar 2019 05:01:33 GMT"}, {"version": "v3", "created": "Fri, 29 Mar 2019 03:31:41 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Ye", "Yuxiao", ""], ["Zhang", "Yue", ""], ["Li", "Weikang", ""], ["Qiu", "Likun", ""], ["Sun", "Jian", ""]]}, {"id": "1903.01728", "submitter": "Xueyao Zhang", "authors": "Xueyao Zhang, Juan Cao, Xirong Li, Qiang Sheng, Lei Zhong, Kai Shu", "title": "Mining Dual Emotion for Fake News Detection", "comments": "Accepted by WWW 2021", "journal-ref": null, "doi": "10.1145/3442381.3450004", "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion plays an important role in detecting fake news online. When\nleveraging emotional signals, the existing methods focus on exploiting the\nemotions of news contents that conveyed by the publishers (i.e., publisher\nemotion). However, fake news often evokes high-arousal or activating emotions\nof people, so the emotions of news comments aroused in the crowd (i.e., social\nemotion) should not be ignored. Furthermore, it remains to be explored whether\nthere exists a relationship between publisher emotion and social emotion (i.e.,\ndual emotion), and how the dual emotion appears in fake news. In this paper, we\nverify that dual emotion is distinctive between fake and real news and propose\nDual Emotion Features to represent dual emotion and the relationship between\nthem for fake news detection. Further, we exhibit that our proposed features\ncan be easily plugged into existing fake news detectors as an enhancement.\nExtensive experiments on three real-world datasets (one in English and the\nothers in Chinese) show that our proposed feature set: 1) outperforms the\nstate-of-the-art task-related emotional features; 2) can be well compatible\nwith existing fake news detectors and effectively improve the performance of\ndetecting fake news.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 08:52:33 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 02:47:16 GMT"}, {"version": "v3", "created": "Mon, 19 Oct 2020 17:11:35 GMT"}, {"version": "v4", "created": "Sun, 14 Feb 2021 08:23:51 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Zhang", "Xueyao", ""], ["Cao", "Juan", ""], ["Li", "Xirong", ""], ["Sheng", "Qiang", ""], ["Zhong", "Lei", ""], ["Shu", "Kai", ""]]}, {"id": "1903.01891", "submitter": "Tommi Jauhiainen", "authors": "Tommi Jauhiainen, Heidi Jauhiainen, Tero Alstola, Krister Lind\\'en", "title": "Language and Dialect Identification of Cuneiform Texts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This article introduces a corpus of cuneiform texts from which the dataset\nfor the use of the Cuneiform Language Identification (CLI) 2019 shared task was\nderived as well as some preliminary language identification experiments\nconducted using that corpus. We also describe the CLI dataset and how it was\nderived from the corpus. In addition, we provide some baseline language\nidentification results using the CLI dataset. To the best of our knowledge, the\nexperiments detailed here are the first time automatic language identification\nmethods have been used on cuneiform data.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 15:17:18 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 08:41:29 GMT"}, {"version": "v3", "created": "Wed, 13 Mar 2019 14:54:22 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Jauhiainen", "Tommi", ""], ["Jauhiainen", "Heidi", ""], ["Alstola", "Tero", ""], ["Lind\u00e9n", "Krister", ""]]}, {"id": "1903.02134", "submitter": "Tianxing He", "authors": "Tianxing He and James Glass", "title": "Negative Training for Neural Dialogue Response Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep learning models have brought tremendous advancements to the\nfield of open-domain dialogue response generation, recent research results have\nrevealed that the trained models have undesirable generation behaviors, such as\nmalicious responses and generic (boring) responses. In this work, we propose a\nframework named \"Negative Training\" to minimize such behaviors. Given a trained\nmodel, the framework will first find generated samples that exhibit the\nundesirable behavior, and then use them to feed negative training signals for\nfine-tuning the model. Our experiments show that negative training can\nsignificantly reduce the hit rate of malicious responses, or discourage\nfrequent responses and improve response diversity.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 01:37:51 GMT"}, {"version": "v2", "created": "Mon, 2 Sep 2019 19:59:16 GMT"}, {"version": "v3", "created": "Mon, 6 Apr 2020 13:58:21 GMT"}, {"version": "v4", "created": "Tue, 7 Apr 2020 01:37:11 GMT"}, {"version": "v5", "created": "Tue, 18 Aug 2020 16:27:57 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["He", "Tianxing", ""], ["Glass", "James", ""]]}, {"id": "1903.02156", "submitter": "Piji Li", "authors": "Piji Li, Zihao Wang, Lidong Bing, Wai Lam", "title": "Persona-Aware Tips Generation", "comments": "Accepted to WWW'2019, 11 pages", "journal-ref": null, "doi": "10.1145/3308558.3313496", "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tips, as a compacted and concise form of reviews, were paid less attention by\nresearchers. In this paper, we investigate the task of tips generation by\nconsidering the `persona' information which captures the intrinsic language\nstyle of the users or the different characteristics of the product items. In\norder to exploit the persona information, we propose a framework based on\nadversarial variational auto-encoders (aVAE) for persona modeling from the\nhistorical tips and reviews of users and items. The latent variables from aVAE\nare regarded as persona embeddings. Besides representing persona using the\nlatent embeddings, we design a persona memory for storing the persona related\nwords for users and items. Pointer Network is used to retrieve persona wordings\nfrom the memory when generating tips. Moreover, the persona embeddings are used\nas latent factors by a rating prediction component to predict the sentiment of\na user over an item. Finally, the persona embeddings and the sentiment\ninformation are incorporated into a recurrent neural networks based tips\ngeneration component. Extensive experimental results are reported and discussed\nto elaborate the peculiarities of our framework.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 03:36:29 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 12:42:59 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Li", "Piji", ""], ["Wang", "Zihao", ""], ["Bing", "Lidong", ""], ["Lam", "Wai", ""]]}, {"id": "1903.02163", "submitter": "Sanghwan Bae", "authors": "Sanghwan Bae, Jihun Choi, Sang-goo Lee", "title": "SNU_IDS at SemEval-2019 Task 3: Addressing Training-Test Class\n  Distribution Mismatch in Conversational Classification", "comments": "International Workshop on Semantic Evaluation (SemEval 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present several techniques to tackle the mismatch in class distributions\nbetween training and test data in the Contextual Emotion Detection task of\nSemEval 2019, by extending the existing methods for class imbalance problem.\nReducing the distance between the distribution of prediction and ground truth,\nthey consistently show positive effects on the performance. Also we propose a\nnovel neural architecture which utilizes representation of overall context as\nwell as of each utterance. The combination of the methods and the models\nachieved micro F1 score of about 0.766 on the final evaluation.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 03:53:19 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 11:55:47 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Bae", "Sanghwan", ""], ["Choi", "Jihun", ""], ["Lee", "Sang-goo", ""]]}, {"id": "1903.02172", "submitter": "Marwan Mattar", "authors": "Marwan Mattar, Roozbeh Mottaghi, Julian Togelius, Danny Lange", "title": "AAAI-2019 Workshop on Games and Simulations for Artificial Intelligence", "comments": "AAAI-2019 Workshop on Games and Simulations for Artificial\n  Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume represents the accepted submissions from the AAAI-2019 Workshop\non Games and Simulations for Artificial Intelligence held on January 29, 2019\nin Honolulu, Hawaii, USA. https://www.gamesim.ai\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 04:49:07 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Mattar", "Marwan", ""], ["Mottaghi", "Roozbeh", ""], ["Togelius", "Julian", ""], ["Lange", "Danny", ""]]}, {"id": "1903.02188", "submitter": "Yu Chen", "authors": "Yu Chen, Lingfei Wu and Mohammed J. Zaki", "title": "Bidirectional Attentive Memory Networks for Question Answering over\n  Knowledge Bases", "comments": "11 pages. Accepted as NAACL 2019 Long Paper. Final Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When answering natural language questions over knowledge bases (KBs),\ndifferent question components and KB aspects play different roles. However,\nmost existing embedding-based methods for knowledge base question answering\n(KBQA) ignore the subtle inter-relationships between the question and the KB\n(e.g., entity types, relation paths and context). In this work, we propose to\ndirectly model the two-way flow of interactions between the questions and the\nKB via a novel Bidirectional Attentive Memory Network, called BAMnet. Requiring\nno external resources and only very few hand-crafted features, on the\nWebQuestions benchmark, our method significantly outperforms existing\ninformation-retrieval based methods, and remains competitive with\n(hand-crafted) semantic parsing based methods. Also, since we use attention\nmechanisms, our method offers better interpretability compared to other\nbaselines.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 06:09:02 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 03:14:08 GMT"}, {"version": "v3", "created": "Tue, 28 May 2019 18:51:14 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Chen", "Yu", ""], ["Wu", "Lingfei", ""], ["Zaki", "Mohammed J.", ""]]}, {"id": "1903.02230", "submitter": "Chao-Chun Hsu", "authors": "Chao-Chun Hsu and Yu-Hua Chen and Zi-Yuan Chen, Hsin-Yu Lin, Ting-Hao\n  'Kenneth' Huang, Lun-Wei Ku", "title": "Dixit: Interactive Visual Storytelling via Term Manipulation", "comments": "WWW'19 Demo, demo video: https://www.youtube.com/watch?v=CUu1MOwnveI", "journal-ref": null, "doi": "10.1145/3308558.3314131", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce Dixit, an interactive visual storytelling system\nthat the user interacts with iteratively to compose a short story for a photo\nsequence. The user initiates the process by uploading a sequence of photos.\nDixit first extracts text terms from each photo which describe the objects\n(e.g., boy, bike) or actions (e.g., sleep) in the photo, and then allows the\nuser to add new terms or remove existing terms. Dixit then generates a short\nstory based on these terms. Behind the scenes, Dixit uses an LSTM-based model\ntrained on image caption data and FrameNet to distill terms from each image and\nutilizes a transformer decoder to compose a context-coherent story. Users\nchange images or terms iteratively with Dixit to create the most ideal story.\nDixit also allows users to manually edit and rate stories. The proposed\nprocedure opens up possibilities for interpretable and controllable visual\nstorytelling, allowing users to understand the story formation rationale and to\nintervene in the generation process.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 08:08:01 GMT"}, {"version": "v2", "created": "Mon, 11 Mar 2019 06:03:56 GMT"}, {"version": "v3", "created": "Fri, 31 May 2019 05:57:15 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Hsu", "Chao-Chun", ""], ["Chen", "Yu-Hua", ""], ["Chen", "Zi-Yuan", ""], ["Lin", "Hsin-Yu", ""], ["Huang", "Ting-Hao 'Kenneth'", ""], ["Ku", "Lun-Wei", ""]]}, {"id": "1903.02419", "submitter": "Wanyun Cui", "authors": "Wanyun Cui, Yanghua Xiao, Haixun Wang, Yangqiu Song, Seung-won Hwang\n  and Wei Wang", "title": "KBQA: Learning Question Answering over QA Corpora and Knowledge Bases", "comments": null, "journal-ref": "Proceedings of the VLDB Endowment, Volume 10 Issue 5, January 2017", "doi": "10.14778/3055540.3055549", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question answering (QA) has become a popular way for humans to access\nbillion-scale knowledge bases. Unlike web search, QA over a knowledge base\ngives out accurate and concise results, provided that natural language\nquestions can be understood and mapped precisely to structured queries over the\nknowledge base. The challenge, however, is that a human can ask one question in\nmany different ways. Previous approaches have natural limits due to their\nrepresentations: rule based approaches only understand a small set of \"canned\"\nquestions, while keyword based or synonym based approaches cannot fully\nunderstand the questions. In this paper, we design a new kind of question\nrepresentation: templates, over a billion scale knowledge base and a million\nscale QA corpora. For example, for questions about a city's population, we\nlearn templates such as What's the population of $city?, How many people are\nthere in $city?. We learned 27 million templates for 2782 intents. Based on\nthese templates, our QA system KBQA effectively supports binary factoid\nquestions, as well as complex questions which are composed of a series of\nbinary factoid questions. Furthermore, we expand predicates in RDF knowledge\nbase, which boosts the coverage of knowledge base by 57 times. Our QA system\nbeats all other state-of-art works on both effectiveness and efficiency over\nQALD benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 14:38:28 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Cui", "Wanyun", ""], ["Xiao", "Yanghua", ""], ["Wang", "Haixun", ""], ["Song", "Yangqiu", ""], ["Hwang", "Seung-won", ""], ["Wang", "Wei", ""]]}, {"id": "1903.02547", "submitter": "Xiujun Li", "authors": "Liyiming Ke and Xiujun Li and Yonatan Bisk and Ari Holtzman and Zhe\n  Gan and Jingjing Liu and Jianfeng Gao and Yejin Choi and Siddhartha Srinivasa", "title": "Tactical Rewind: Self-Correction via Backtracking in Vision-and-Language\n  Navigation", "comments": "CVPR 2019 Oral, video demo: https://youtu.be/AD9TNohXoPA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Frontier Aware Search with backTracking (FAST) Navigator, a\ngeneral framework for action decoding, that achieves state-of-the-art results\non the Room-to-Room (R2R) Vision-and-Language navigation challenge of Anderson\net. al. (2018). Given a natural language instruction and photo-realistic image\nviews of a previously unseen environment, the agent was tasked with navigating\nfrom source to target location as quickly as possible. While all current\napproaches make local action decisions or score entire trajectories using beam\nsearch, ours balances local and global signals when exploring an unobserved\nenvironment. Importantly, this lets us act greedily but use global signals to\nbacktrack when necessary. Applying FAST framework to existing state-of-the-art\nmodels achieved a 17% relative gain, an absolute 6% gain on Success rate\nweighted by Path Length (SPL).\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 18:54:55 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 17:48:26 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Ke", "Liyiming", ""], ["Li", "Xiujun", ""], ["Bisk", "Yonatan", ""], ["Holtzman", "Ari", ""], ["Gan", "Zhe", ""], ["Liu", "Jingjing", ""], ["Gao", "Jianfeng", ""], ["Choi", "Yejin", ""], ["Srinivasa", "Siddhartha", ""]]}, {"id": "1903.02588", "submitter": "Hong Wang", "authors": "Hong Wang, Wenhan Xiong, Mo Yu, Xiaoxiao Guo, Shiyu Chang, William\n  Yang Wang", "title": "Sentence Embedding Alignment for Lifelong Relation Extraction", "comments": "Accepted to NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional approaches to relation extraction usually require a fixed set of\npre-defined relations. Such requirement is hard to meet in many real\napplications, especially when new data and relations are emerging incessantly\nand it is computationally expensive to store all data and re-train the whole\nmodel every time new data and relations come in. We formulate such a\nchallenging problem as lifelong relation extraction and investigate\nmemory-efficient incremental learning methods without catastrophically\nforgetting knowledge learned from previous tasks. We first investigate a\nmodified version of the stochastic gradient methods with a replay memory, which\nsurprisingly outperforms recent state-of-the-art lifelong learning methods. We\nfurther propose to improve this approach to alleviate the forgetting problem by\nanchoring the sentence embedding space. Specifically, we utilize an explicit\nalignment model to mitigate the sentence embedding distortion of the learned\nmodel when training on new data and new relations. Experiment results on\nmultiple benchmarks show that our proposed method significantly outperforms the\nstate-of-the-art lifelong learning approaches.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 19:22:24 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 21:28:15 GMT"}, {"version": "v3", "created": "Tue, 26 Mar 2019 16:00:10 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Wang", "Hong", ""], ["Xiong", "Wenhan", ""], ["Yu", "Mo", ""], ["Guo", "Xiaoxiao", ""], ["Chang", "Shiyu", ""], ["Wang", "William Yang", ""]]}, {"id": "1903.02591", "submitter": "Wenhan Xiong", "authors": "Wenhan Xiong, Jiawei Wu, Deren Lei, Mo Yu, Shiyu Chang, Xiaoxiao Guo,\n  William Yang Wang", "title": "Imposing Label-Relational Inductive Bias for Extremely Fine-Grained\n  Entity Typing", "comments": "NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing entity typing systems usually exploit the type hierarchy provided by\nknowledge base (KB) schema to model label correlations and thus improve the\noverall performance. Such techniques, however, are not directly applicable to\nmore open and practical scenarios where the type set is not restricted by KB\nschema and includes a vast number of free-form types. To model the underly-ing\nlabel correlations without access to manually annotated label structures, we\nintroduce a novel label-relational inductive bias, represented by a graph\npropagation layer that effectively encodes both global label co-occurrence\nstatistics and word-level similarities.On a large dataset with over 10,000\nfree-form types, the graph-enhanced model equipped with an attention-based\nmatching module is able to achieve a much higher recall score while maintaining\na high-level precision. Specifically, it achieves a 15.3% relative F1\nimprovement and also less inconsistency in the outputs. We further show that a\nsimple modification of our proposed graph layer can also improve the\nperformance on a conventional and widely-tested dataset that only includes\nKB-schema types.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 19:42:19 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Xiong", "Wenhan", ""], ["Wu", "Jiawei", ""], ["Lei", "Deren", ""], ["Yu", "Mo", ""], ["Chang", "Shiyu", ""], ["Guo", "Xiaoxiao", ""], ["Wang", "William Yang", ""]]}, {"id": "1903.02642", "submitter": "Adri\\'an Javaloy Born\\'as", "authors": "Adri\\'an Javaloy Born\\'as and Gin\\'es Garc\\'ia Mateos", "title": "A Character-Level Approach to the Text Normalization Problem Based on a\n  New Causal Encoder", "comments": "19 pages, 14 figures, journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text normalization is a ubiquitous process that appears as the first step of\nmany Natural Language Processing problems. However, previous Deep Learning\napproaches have suffered from so-called silly errors, which are undetectable on\nunsupervised frameworks, making those models unsuitable for deployment. In this\nwork, we make use of an attention-based encoder-decoder architecture that\novercomes these undetectable errors by using a fine-grained character-level\napproach rather than a word-level one. Furthermore, our new general-purpose\nencoder based on causal convolutions, called Causal Feature Extractor (CFE), is\nintroduced and compared to other common encoders. The experimental results show\nthe feasibility of this encoder, which leverages the attention mechanisms the\nmost and obtains better results in terms of accuracy, number of parameters and\nconvergence time. While our method results in a slightly worse initial accuracy\n(92.74%), errors can be automatically detected and, thus, more readily solved,\nobtaining a more robust model for deployment. Furthermore, there is still\nplenty of room for future improvements that will push even further these\nadvantages.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 22:48:21 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Born\u00e1s", "Adri\u00e1n Javaloy", ""], ["Mateos", "Gin\u00e9s Garc\u00eda", ""]]}, {"id": "1903.02652", "submitter": "Yifan He", "authors": "Mengxi Wei, Yifan He, Qiong Zhang, Luo Si", "title": "Multi-Instance Learning for End-to-End Knowledge Base Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end training has been a popular approach for knowledge base question\nanswering (KBQA). However, real world applications often contain answers of\nvaried quality for users' questions. It is not appropriate to treat all\navailable answers of a user question equally.\n  This paper proposes a novel approach based on multiple instance learning to\naddress the problem of noisy answers by exploring consensus among answers to\nthe same question in training end-to-end KBQA models. In particular, the QA\npairs are organized into bags with dynamic instance selection and different\noptions of instance weighting. Curriculum learning is utilized to select\ninstance bags during training. On the public CQA dataset, the new method\nsignificantly improves both entity accuracy and the Rouge-L score over a\nstate-of-the-art end-to-end KBQA baseline.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 23:14:49 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Wei", "Mengxi", ""], ["He", "Yifan", ""], ["Zhang", "Qiong", ""], ["Si", "Luo", ""]]}, {"id": "1903.02671", "submitter": "Gerhard Wohlgenannt Dr.", "authors": "Gerhard Wohlgenannt and Ariadna Barinova and Dmitry Ilvovsky and\n  Ekaterina Chernyak", "title": "Creation and Evaluation of Datasets for Distributional Semantics Tasks\n  in the Digital Humanities Domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings are already well studied in the general domain, usually\ntrained on large text corpora, and have been evaluated for example on word\nsimilarity and analogy tasks, but also as an input to downstream NLP processes.\nIn contrast, in this work we explore the suitability of word embedding\ntechnologies in the specialized digital humanities domain. After training\nembedding models of various types on two popular fantasy novel book series, we\nevaluate their performance on two task types: term analogies, and word\nintrusion. To this end, we manually construct test datasets with domain\nexperts. Among the contributions are the evaluation of various word embedding\ntechniques on the different task types, with the findings that even embeddings\ntrained on small corpora perform well for example on the word intrusion task.\nFurthermore, we provide extensive and high-quality datasets in digital\nhumanities for further investigation, as well as the implementation to easily\nreproduce or extend the experiments.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 00:54:02 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Wohlgenannt", "Gerhard", ""], ["Barinova", "Ariadna", ""], ["Ilvovsky", "Dmitry", ""], ["Chernyak", "Ekaterina", ""]]}, {"id": "1903.02784", "submitter": "Imane Guellil", "authors": "Imane Guellil, Houda Sa\\^adane, Faical Azouaou, Billel Gueni, Damien\n  Nouvel", "title": "Arabic natural language processing: An overview", "comments": null, "journal-ref": null, "doi": "10.1016/j.jksuci.2019.02.006", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Arabic is recognised as the 4th most used language of the Internet. Arabic\nhas three main varieties: (1) classical Arabic (CA), (2) Modern Standard Arabic\n(MSA), (3) Arabic Dialect (AD). MSA and AD could be written either in Arabic or\nin Roman script (Arabizi), which corresponds to Arabic written with Latin\nletters, numerals and punctuation. Due to the complexity of this language and\nthe number of corresponding challenges for NLP, many surveys have been\nconducted, in order to synthesise the work done on Arabic. However these\nsurveys principally focus on two varieties of Arabic (MSA and AD, written in\nArabic letters only), they are slightly old (no such survey since 2015) and\ntherefore do not cover recent resources and tools. To bridge the gap, we\npropose a survey focusing on 90 recent research papers (74% of which were\npublished after 2015). Our study presents and classifies the work done on the\nthree varieties of Arabic, by concentrating on both Arabic and Arabizi, and\nassociates each work to its publicly available resources whenever available.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 09:22:35 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Guellil", "Imane", ""], ["Sa\u00e2dane", "Houda", ""], ["Azouaou", "Faical", ""], ["Gueni", "Billel", ""], ["Nouvel", "Damien", ""]]}, {"id": "1903.02831", "submitter": "Steffen Eger", "authors": "Steffen Eger, Chao Li, Florian Netzer, Iryna Gurevych", "title": "Predicting Research Trends From Arxiv", "comments": "Refresh workshop paper (December 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We perform trend detection on two datasets of Arxiv papers, derived from its\nmachine learning (cs.LG) and natural language processing (cs.CL) categories.\nOur approach is bottom-up: we first rank papers by their normalized citation\ncounts, then group top-ranked papers into different categories based on the\ntasks that they pursue and the methods they use. We then analyze these\nresulting topics. We find that the dominating paradigm in cs.CL revolves around\nnatural language generation problems and those in cs.LG revolve around\nreinforcement learning and adversarial principles. By extrapolation, we predict\nthat these topics will remain lead problems/approaches in their fields in the\nshort- and mid-term.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 11:06:10 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Eger", "Steffen", ""], ["Li", "Chao", ""], ["Netzer", "Florian", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1903.02852", "submitter": "Thomas Drugman", "authors": "Thomas Drugman, Janne Pylkkonen, Reinhard Kneser", "title": "Active and Semi-Supervised Learning in ASR: Benefits on the Acoustic and\n  Language Models", "comments": null, "journal-ref": "Interspeech, pp. 2318-2322, 2016", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to simulate the benefits of jointly applying active\nlearning (AL) and semi-supervised training (SST) in a new speech recognition\napplication. Our data selection approach relies on confidence filtering, and\nits impact on both the acoustic and language models (AM and LM) is studied.\nWhile AL is known to be beneficial to AM training, we show that it also carries\nout substantial improvements to the LM when combined with SST. Sophisticated\nconfidence models, on the other hand, did not prove to yield any data selection\ngain. Our results indicate that, while SST is crucial at the beginning of the\nlabeling process, its gains degrade rapidly as AL is set in place. The final\nsimulation reports that AL allows a transcription cost reduction of about 70%\nover random selection. Alternatively, for a fixed transcription budget, the\nproposed approach improves the word error rate by about 12.5% relative.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 11:38:36 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Drugman", "Thomas", ""], ["Pylkkonen", "Janne", ""], ["Kneser", "Reinhard", ""]]}, {"id": "1903.02861", "submitter": "Milad Moradi", "authors": "Milad Moradi", "title": "Small-world networks for summarization of biomedical articles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, many methods have been developed to identify important\nportions of text documents. Summarization tools can utilize these methods to\nextract summaries from large volumes of textual information. However, to\nidentify concepts representing central ideas within a text document and to\nextract the most informative sentences that best convey those concepts still\nremain two crucial tasks in summarization methods. In this paper, we introduce\na graph-based method to address these two challenges in the context of\nbiomedical text summarization. We show that how a summarizer can discover\nmeaningful concepts within a biomedical text document using the Helmholtz\nprinciple. The summarizer considers the meaningful concepts as the main topics\nand constructs a graph based on the topics that the sentences share. The\nsummarizer can produce an informative summary by extracting those sentences\nhaving higher values of the degree. We assess the performance of our method for\nsummarization of biomedical articles using the Recall-Oriented Understudy for\nGisting Evaluation (ROUGE) toolkit. The results show that the degree can be a\nuseful centrality measure to identify important sentences in this type of\ngraph-based modelling. Our method can improve the performance of biomedical\ntext summarization compared to some state-of-the-art and publicly available\nsummarizers. Combining a concept-based modelling strategy and a graph-based\napproach to sentence extraction, our summarizer can produce summaries with the\nhighest scores of informativeness among the comparison methods. This research\nwork can be regarded as a start point to the study of small-world networks in\nsummarization of biomedical texts.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 12:12:17 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Moradi", "Milad", ""]]}, {"id": "1903.02930", "submitter": "Antonios Anastasopoulos", "authors": "Antonios Anastasopoulos, Shankar Kumar, and Hank Liao", "title": "Neural Language Modeling with Visual Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal language models attempt to incorporate non-linguistic features for\nthe language modeling task. In this work, we extend a standard recurrent neural\nnetwork (RNN) language model with features derived from videos. We train our\nmodels on data that is two orders-of-magnitude bigger than datasets used in\nprior work. We perform a thorough exploration of model architectures for\ncombining visual and text features. Our experiments on two corpora (YouCookII\nand 20bn-something-something-v2) show that the best performing architecture\nconsists of middle fusion of visual and text features, yielding over 25%\nrelative improvement in perplexity. We report analysis that provides insights\ninto why our multimodal language model improves upon a standard RNN language\nmodel.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 14:20:01 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Anastasopoulos", "Antonios", ""], ["Kumar", "Shankar", ""], ["Liao", "Hank", ""]]}, {"id": "1903.02953", "submitter": "Daniel Hershcovich", "authors": "Daniel Hershcovich, Zohar Aizenbud, Leshem Choshen, Elior Sulem, Ari\n  Rappoport, Omri Abend", "title": "SemEval-2019 Task 1: Cross-lingual Semantic Parsing with UCCA", "comments": "SemEval 2019 Shared task. arXiv admin note: substantial text overlap\n  with arXiv:1805.12386", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the SemEval 2019 shared task on UCCA parsing in English, German\nand French, and discuss the participating systems and results. UCCA is a\ncross-linguistically applicable framework for semantic representation, which\nbuilds on extensive typological work and supports rapid annotation. UCCA poses\na challenge for existing parsing techniques, as it exhibits reentrancy\n(resulting in DAG structures), discontinuous structures and non-terminal nodes\ncorresponding to complex semantic units. The shared task has yielded\nimprovements over the state-of-the-art baseline in all languages and settings.\nFull results can be found in the task's website\n\\url{https://competitions.codalab.org/competitions/19160}.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 16:55:58 GMT"}, {"version": "v2", "created": "Thu, 25 Apr 2019 05:18:27 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 09:20:56 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Hershcovich", "Daniel", ""], ["Aizenbud", "Zohar", ""], ["Choshen", "Leshem", ""], ["Sulem", "Elior", ""], ["Rappoport", "Ari", ""], ["Abend", "Omri", ""]]}, {"id": "1903.02978", "submitter": "Nico Herbig", "authors": "Nico Herbig, Santanu Pal, Josef van Genabith, Antonio Kr\\\"uger", "title": "Integrating Artificial and Human Intelligence for Efficient Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current advances in machine translation increase the need for translators to\nswitch from traditional translation to post-editing of machine-translated text,\na process that saves time and improves quality. Human and artificial\nintelligence need to be integrated in an efficient way to leverage the\nadvantages of both for the translation task. This paper outlines approaches at\nthis boundary of AI and HCI and discusses open research questions to further\nadvance the field.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 15:14:42 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Herbig", "Nico", ""], ["Pal", "Santanu", ""], ["van Genabith", "Josef", ""], ["Kr\u00fcger", "Antonio", ""]]}, {"id": "1903.03033", "submitter": "Peng Li", "authors": "Qiu Ran, Peng Li, Weiwei Hu, Jie Zhou", "title": "Option Comparison Network for Multiple-choice Reading Comprehension", "comments": "6 pages, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple-choice reading comprehension (MCRC) is the task of selecting the\ncorrect answer from multiple options given a question and an article. Existing\nMCRC models typically either read each option independently or compute a\nfixed-length representation for each option before comparing them. However,\nhumans typically compare the options at multiple-granularity level before\nreading the article in detail to make reasoning more efficient. Mimicking\nhumans, we propose an option comparison network (OCN) for MCRC which compares\noptions at word-level to better identify their correlations to help reasoning.\nSpecially, each option is encoded into a vector sequence using a skimmer to\nretain fine-grained information as much as possible. An attention mechanism is\nleveraged to compare these sequences vector-by-vector to identify more subtle\ncorrelations between options, which is potentially valuable for reasoning.\nExperimental results on the human English exam MCRC dataset RACE show that our\nmodel outperforms existing methods significantly. Moreover, it is also the\nfirst model that surpasses Amazon Mechanical Turker performance on the whole\ndataset.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 16:43:50 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Ran", "Qiu", ""], ["Li", "Peng", ""], ["Hu", "Weiwei", ""], ["Zhou", "Jie", ""]]}, {"id": "1903.03094", "submitter": "Jason  Weston", "authors": "Jack Urbanek, Angela Fan, Siddharth Karamcheti, Saachi Jain, Samuel\n  Humeau, Emily Dinan, Tim Rockt\\\"aschel, Douwe Kiela, Arthur Szlam, Jason\n  Weston", "title": "Learning to Speak and Act in a Fantasy Text Adventure Game", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a large scale crowdsourced text adventure game as a research\nplatform for studying grounded dialogue. In it, agents can perceive, emote, and\nact whilst conducting dialogue with other agents. Models and humans can both\nact as characters within the game. We describe the results of training\nstate-of-the-art generative and retrieval models in this setting. We show that\nin addition to using past dialogue, these models are able to effectively use\nthe state of the underlying world to condition their predictions. In\nparticular, we show that grounding on the details of the local environment,\nincluding location descriptions, and the objects (and their affordances) and\ncharacters (and their previous actions) present within it allows better\npredictions of agent behavior and dialogue. We analyze the ingredients\nnecessary for successful grounding in this setting, and how each of these\nfactors relate to agents that can talk and act successfully.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 18:45:52 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Urbanek", "Jack", ""], ["Fan", "Angela", ""], ["Karamcheti", "Siddharth", ""], ["Jain", "Saachi", ""], ["Humeau", "Samuel", ""], ["Dinan", "Emily", ""], ["Rockt\u00e4schel", "Tim", ""], ["Kiela", "Douwe", ""], ["Szlam", "Arthur", ""], ["Weston", "Jason", ""]]}, {"id": "1903.03166", "submitter": "Satwik Kottur", "authors": "Satwik Kottur, Jos\\'e M. F. Moura, Devi Parikh, Dhruv Batra, Marcus\n  Rohrbach", "title": "CLEVR-Dialog: A Diagnostic Dataset for Multi-Round Reasoning in Visual\n  Dialog", "comments": "13 pages, 11 figures, 3 tables, accepted as a short paper at NAACL\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual Dialog is a multimodal task of answering a sequence of questions\ngrounded in an image, using the conversation history as context. It entails\nchallenges in vision, language, reasoning, and grounding. However, studying\nthese subtasks in isolation on large, real datasets is infeasible as it\nrequires prohibitively-expensive complete annotation of the 'state' of all\nimages and dialogs.\n  We develop CLEVR-Dialog, a large diagnostic dataset for studying multi-round\nreasoning in visual dialog. Specifically, we construct a dialog grammar that is\ngrounded in the scene graphs of the images from the CLEVR dataset. This\ncombination results in a dataset where all aspects of the visual dialog are\nfully annotated. In total, CLEVR-Dialog contains 5 instances of 10-round\ndialogs for about 85k CLEVR images, totaling to 4.25M question-answer pairs.\n  We use CLEVR-Dialog to benchmark performance of standard visual dialog\nmodels; in particular, on visual coreference resolution (as a function of the\ncoreference distance). This is the first analysis of its kind for visual dialog\nmodels that was not possible without this dataset. We hope the findings from\nCLEVR-Dialog will help inform the development of future models for visual\ndialog. Our dataset and code are publicly available.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 20:18:39 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 18:04:43 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Kottur", "Satwik", ""], ["Moura", "Jos\u00e9 M. F.", ""], ["Parikh", "Devi", ""], ["Batra", "Dhruv", ""], ["Rohrbach", "Marcus", ""]]}, {"id": "1903.03243", "submitter": "Hanan Aldarmaki", "authors": "Hanan Aldarmaki and Mona Diab", "title": "Context-Aware Cross-Lingual Mapping", "comments": "NAACL-HLT 2019 (short paper). 5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual word vectors are typically obtained by fitting an orthogonal\nmatrix that maps the entries of a bilingual dictionary from a source to a\ntarget vector space. Word vectors, however, are most commonly used for sentence\nor document-level representations that are calculated as the weighted average\nof word embeddings. In this paper, we propose an alternative to word-level\nmapping that better reflects sentence-level cross-lingual similarity. We\nincorporate context in the transformation matrix by directly mapping the\naveraged embeddings of aligned sentences in a parallel corpus. We also\nimplement cross-lingual mapping of deep contextualized word embeddings using\nparallel sentences with word alignments. In our experiments, both approaches\nresulted in cross-lingual sentence embeddings that outperformed\ncontext-independent word mapping in sentence translation retrieval.\nFurthermore, the sentence-level transformation could be used for word-level\nmapping without loss in word translation quality.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 01:46:37 GMT"}, {"version": "v2", "created": "Sun, 31 Mar 2019 20:57:20 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Aldarmaki", "Hanan", ""], ["Diab", "Mona", ""]]}, {"id": "1903.03260", "submitter": "Richard Futrell", "authors": "Richard Futrell, Ethan Wilcox, Takashi Morita, Peng Qian, Miguel\n  Ballesteros, and Roger Levy", "title": "Neural Language Models as Psycholinguistic Subjects: Representations of\n  Syntactic State", "comments": "Accepted to NAACL 2019. Not yet edited into the camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We deploy the methods of controlled psycholinguistic experimentation to shed\nlight on the extent to which the behavior of neural network language models\nreflects incremental representations of syntactic state. To do so, we examine\nmodel behavior on artificial sentences containing a variety of syntactically\ncomplex structures. We test four models: two publicly available LSTM sequence\nmodels of English (Jozefowicz et al., 2016; Gulordava et al., 2018) trained on\nlarge datasets; an RNNG (Dyer et al., 2016) trained on a small, parsed dataset;\nand an LSTM trained on the same small corpus as the RNNG. We find evidence that\nthe LSTMs trained on large datasets represent syntactic state over large spans\nof text in a way that is comparable to the RNNG, while the LSTM trained on the\nsmall dataset does not or does so only weakly.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 03:02:28 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Futrell", "Richard", ""], ["Wilcox", "Ethan", ""], ["Morita", "Takashi", ""], ["Qian", "Peng", ""], ["Ballesteros", "Miguel", ""], ["Levy", "Roger", ""]]}, {"id": "1903.03282", "submitter": "Tianwen Jiang", "authors": "Tianwen Jiang, Ming Liu, Bing Qin, Ting Liu", "title": "Attribute Acquisition in Ontology based on Representation Learning of\n  Hierarchical Classes and Attributes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attribute acquisition for classes is a key step in ontology construction,\nwhich is often achieved by community members manually. This paper investigates\nan attention-based automatic paradigm called TransATT for attribute\nacquisition, by learning the representation of hierarchical classes and\nattributes in Chinese ontology. The attributes of an entity can be acquired by\nmerely inspecting its classes, because the entity can be regard as the instance\nof its classes and inherit their attributes. For explicitly describing of the\nclass of an entity unambiguously, we propose class-path to represent the\nhierarchical classes in ontology, instead of the terminal class word of the\nhypernym-hyponym relation (i.e., is-a relation) based hierarchy. The high\nperformance of TransATT on attribute acquisition indicates the promising\nability of the learned representation of class-paths and attributes. Moreover,\nwe construct a dataset named \\textbf{BigCilin11k}. To the best of our\nknowledge, this is the first Chinese dataset with abundant hierarchical classes\nand entities with attributes.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 04:44:59 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Jiang", "Tianwen", ""], ["Liu", "Ming", ""], ["Qin", "Bing", ""], ["Liu", "Ting", ""]]}, {"id": "1903.03289", "submitter": "Tianwen Jiang", "authors": "Tianwen Jiang, Sendong Zhao, Jing Liu, Jin-Ge Yao, Ming Liu, Bing Qin,\n  Ting Liu, Chin-Yew Lin", "title": "Towards Time-Aware Distant Supervision for Relation Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distant supervision for relation extraction heavily suffers from the wrong\nlabeling problem. To alleviate this issue in news data with the timestamp, we\ntake a new factor time into consideration and propose a novel time-aware\ndistant supervision framework (Time-DS). Time-DS is composed of a time series\ninstance-popularity and two strategies. Instance-popularity is to encode the\nstrong relevance of time and true relation mention. Therefore,\ninstance-popularity would be an effective clue to reduce the noises generated\nthrough distant supervision labeling. The two strategies, i.e., hard filter and\ncurriculum learning are both ways to implement instance-popularity for better\nrelation extraction in the manner of Time-DS. The curriculum learning is a more\nsophisticated and flexible way to exploit instance-popularity to eliminate the\nbad effects of noises, thus get better relation extraction performance.\nExperiments on our collected multi-source news corpus show that Time-DS\nachieves significant improvements for relation extraction.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 05:10:00 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Jiang", "Tianwen", ""], ["Zhao", "Sendong", ""], ["Liu", "Jing", ""], ["Yao", "Jin-Ge", ""], ["Liu", "Ming", ""], ["Qin", "Bing", ""], ["Liu", "Ting", ""], ["Lin", "Chin-Yew", ""]]}, {"id": "1903.03467", "submitter": "Amit Moryossef", "authors": "Amit Moryossef, Roee Aharoni and Yoav Goldberg", "title": "Filling Gender & Number Gaps in Neural Machine Translation with\n  Black-box Context Injection", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When translating from a language that does not morphologically mark\ninformation such as gender and number into a language that does, translation\nsystems must \"guess\" this missing information, often leading to incorrect\ntranslations in the given context. We propose a black-box approach for\ninjecting the missing information to a pre-trained neural machine translation\nsystem, allowing to control the morphological variations in the generated\ntranslations without changing the underlying model or training data. We\nevaluate our method on an English to Hebrew translation task, and show that it\nis effective in injecting the gender and number information and that supplying\nthe correct information improves the translation accuracy in up to 2.3 BLEU on\na female-speaker test set for a state-of-the-art online black-box system.\nFinally, we perform a fine-grained syntactic analysis of the generated\ntranslations that shows the effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 14:33:34 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Moryossef", "Amit", ""], ["Aharoni", "Roee", ""], ["Goldberg", "Yoav", ""]]}, {"id": "1903.03530", "submitter": "Zhengyuan Liu", "authors": "Zhengyuan Liu, Hazel Lim, Nur Farah Ain Binte Suhaimi, Shao Chuen\n  Tong, Sharon Ong, Angela Ng, Sheldon Lee, Michael R. Macdonald, Savitha\n  Ramasamy, Pavitra Krishnaswamy, Wai Leng Chow, Nancy F. Chen", "title": "Fast Prototyping a Dialogue Comprehension System for Nurse-Patient\n  Conversations on Symptom Monitoring", "comments": "8 pages. To appear in NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data for human-human spoken dialogues for research and development are\ncurrently very limited in quantity, variety, and sources; such data are even\nscarcer in healthcare. In this work, we investigate fast prototyping of a\ndialogue comprehension system by leveraging on minimal nurse-to-patient\nconversations. We propose a framework inspired by nurse-initiated clinical\nsymptom monitoring conversations to construct a simulated human-human dialogue\ndataset, embodying linguistic characteristics of spoken interactions like\nthinking aloud, self-contradiction, and topic drift. We then adopt an\nestablished bidirectional attention pointer network on this simulated dataset,\nachieving more than 80% F1 score on a held-out test set from real-world\nnurse-to-patient conversations. The ability to automatically comprehend\nconversations in the healthcare domain by exploiting only limited data has\nimplications for improving clinical workflows through red flag symptom\ndetection and triaging capabilities. We demonstrate the feasibility for\nefficient and effective extraction, retrieval and comprehension of symptom\nchecking information discussed in multi-turn human-human spoken conversations.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 16:20:42 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 07:06:39 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Liu", "Zhengyuan", ""], ["Lim", "Hazel", ""], ["Suhaimi", "Nur Farah Ain Binte", ""], ["Tong", "Shao Chuen", ""], ["Ong", "Sharon", ""], ["Ng", "Angela", ""], ["Lee", "Sheldon", ""], ["Macdonald", "Michael R.", ""], ["Ramasamy", "Savitha", ""], ["Krishnaswamy", "Pavitra", ""], ["Chow", "Wai Leng", ""], ["Chen", "Nancy F.", ""]]}, {"id": "1903.03762", "submitter": "Senzhang Wang", "authors": "Jianping Cao, Senzhang Wang (Corresponding author), Danyan Wen,\n  Zhaohui Peng, Philip S. Yu and Fei-yue Wang", "title": "Mutual Clustering on Comparative Texts via Heterogeneous Information\n  Networks", "comments": null, "journal-ref": "Knowledge and Information System, 2019", "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, many intelligence systems contain the texts from multi-sources,\ne.g., bulletin board system (BBS) posts, tweets and news. These texts can be\n``comparative'' since they may be semantically correlated and thus provide us\nwith different perspectives toward the same topics or events. To better\norganize the multi-sourced texts and obtain more comprehensive knowledge, we\npropose to study the novel problem of Mutual Clustering on Comparative Texts\n(MCCT), which aims to cluster the comparative texts simultaneously and\ncollaboratively. The MCCT problem is difficult to address because 1)\ncomparative texts usually present different data formats and structures and\nthus they are hard to organize, and 2) there lacks an effective method to\nconnect the semantically correlated comparative texts to facilitate clustering\nthem in an unified way. To this aim, in this paper we propose a Heterogeneous\nInformation Network-based Text clustering framework HINT. HINT first models\nmulti-sourced texts (e.g. news and tweets) as heterogeneous information\nnetworks by introducing the shared ``anchor texts'' to connect the comparative\ntexts. Next, two similarity matrices based on HINT as well as a transition\nmatrix for cross-text-source knowledge transfer are constructed. Comparative\ntexts clustering are then conducted by utilizing the constructed matrices.\nFinally, a mutual clustering algorithm is also proposed to further unify the\nseparate clustering results of the comparative texts by introducing a\nclustering consistency constraint. We conduct extensive experimental on three\ntweets-news datasets, and the results demonstrate the effectiveness and\nrobustness of the proposed method in addressing the MCCT problem.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 08:24:15 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Cao", "Jianping", "", "Corresponding author"], ["Wang", "Senzhang", "", "Corresponding author"], ["Wen", "Danyan", ""], ["Peng", "Zhaohui", ""], ["Yu", "Philip S.", ""], ["Wang", "Fei-yue", ""]]}, {"id": "1903.03772", "submitter": "Pengwei Wang", "authors": "Pengwei Wang, Dejing Dou, Fangzhao Wu, Nisansa de Silva, Lianwen Jin", "title": "Logic Rules Powered Knowledge Graph Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large scale knowledge graph embedding has attracted much attention from both\nacademia and industry in the field of Artificial Intelligence. However, most\nexisting methods concentrate solely on fact triples contained in the given\nknowledge graph. Inspired by the fact that logic rules can provide a flexible\nand declarative language for expressing rich background knowledge, it is\nnatural to integrate logic rules into knowledge graph embedding, to transfer\nhuman knowledge to entity and relation embedding, and strengthen the learning\nprocess. In this paper, we propose a novel logic rule-enhanced method which can\nbe easily integrated with any translation based knowledge graph embedding\nmodel, such as TransE . We first introduce a method to automatically mine the\nlogic rules and corresponding confidences from the triples. And then, to put\nboth triples and mined logic rules within the same semantic space, all triples\nin the knowledge graph are represented as first-order logic. Finally, we define\nseveral operations on the first-order logic and minimize a global loss over\nboth of the mined logic rules and the transformed first-order logics. We\nconduct extensive experiments for link prediction and triple classification on\nthree datasets: WN18, FB166, and FB15K. Experiments show that the rule-enhanced\nmethod can significantly improve the performance of several baselines. The\nhighlight of our model is that the filtered Hits@1, which is a pivotal\nevaluation in the knowledge inference task, has a significant improvement (up\nto 700% improvement).\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 10:01:12 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Wang", "Pengwei", ""], ["Dou", "Dejing", ""], ["Wu", "Fangzhao", ""], ["de Silva", "Nisansa", ""], ["Jin", "Lianwen", ""]]}, {"id": "1903.03862", "submitter": "Hila Gonen", "authors": "Hila Gonen and Yoav Goldberg", "title": "Lipstick on a Pig: Debiasing Methods Cover up Systematic Gender Biases\n  in Word Embeddings But do not Remove Them", "comments": "Accepted to NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Word embeddings are widely used in NLP for a vast range of tasks. It was\nshown that word embeddings derived from text corpora reflect gender biases in\nsociety. This phenomenon is pervasive and consistent across different word\nembedding models, causing serious concern. Several recent works tackle this\nproblem, and propose methods for significantly reducing this gender bias in\nword embeddings, demonstrating convincing results. However, we argue that this\nremoval is superficial. While the bias is indeed substantially reduced\naccording to the provided bias definition, the actual effect is mostly hiding\nthe bias, not removing it. The gender bias information is still reflected in\nthe distances between \"gender-neutralized\" words in the debiased embeddings,\nand can be recovered from them. We present a series of experiments to support\nthis claim, for two debiasing methods. We conclude that existing bias removal\ntechniques are insufficient, and should not be trusted for providing\ngender-neutral modeling.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 19:56:47 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 07:43:00 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Gonen", "Hila", ""], ["Goldberg", "Yoav", ""]]}, {"id": "1903.03985", "submitter": "Beatrice Alex", "authors": "Philip John Gorinski, Honghan Wu, Claire Grover, Richard Tobin, Conn\n  Talbot, Heather Whalley, Cathie Sudlow, William Whiteley, Beatrice Alex", "title": "Named Entity Recognition for Electronic Health Records: A Comparison of\n  Rule-based and Machine Learning Approaches", "comments": "8 pages, presented at HealTAC 2019, Cardiff, 24-25/04/2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates multiple approaches to Named Entity Recognition (NER)\nfor text in Electronic Health Record (EHR) data. In particular, we look into\nthe application of (i) rule-based, (ii) deep learning and (iii) transfer\nlearning systems for the task of NER on brain imaging reports with a focus on\nrecords from patients with stroke. We explore the strengths and weaknesses of\neach approach, develop rules and train on a common dataset, and evaluate each\nsystem's performance on common test sets of Scottish radiology reports from two\nsources (brain imaging reports in ESS -- Edinburgh Stroke Study data collected\nby NHS Lothian as well as radiology reports created in NHS Tayside). Our\ncomparison shows that a hand-crafted system is the most accurate way to\nautomatically label EHR, but machine learning approaches can provide a feasible\nalternative where resources for a manual system are not readily available.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 13:16:37 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 15:55:53 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Gorinski", "Philip John", ""], ["Wu", "Honghan", ""], ["Grover", "Claire", ""], ["Tobin", "Richard", ""], ["Talbot", "Conn", ""], ["Whalley", "Heather", ""], ["Sudlow", "Cathie", ""], ["Whiteley", "William", ""], ["Alex", "Beatrice", ""]]}, {"id": "1903.03995", "submitter": "Honghan Wu", "authors": "Honghan Wu, Karen Hodgson, Sue Dyson, Katherine I. Morley, Zina M.\n  Ibrahim, Ehtesham Iqbal, Robert Stewart, Richard JB Dobson, Cathie Sudlow", "title": "Efficiently Reusing Natural Language Processing Models for\n  Phenotype-Mention Identification in Free-text Electronic Medical Records:\n  Methodology Study", "comments": null, "journal-ref": null, "doi": "10.2196/14782", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Many efforts have been put into the use of automated approaches,\nsuch as natural language processing (NLP), to mine or extract data from\nfree-text medical records to construct comprehensive patient profiles for\ndelivering better health-care. Reusing NLP models in new settings, however,\nremains cumbersome - requiring validation and/or retraining on new data\niteratively to achieve convergent results.\n  Objective: The aim of this work is to minimize the effort involved in reusing\nNLP models on free-text medical records.\n  Methods: We formally define and analyse the model adaptation problem in\nphenotype-mention identification tasks. We identify \"duplicate waste\" and\n\"imbalance waste\", which collectively impede efficient model reuse. We propose\na phenotype embedding based approach to minimize these sources of waste without\nthe need for labelled data from new settings.\n  Results: We conduct experiments on data from a large mental health registry\nto reuse NLP models in four phenotype-mention identification tasks. The\nproposed approach can choose the best model for a new task, identifying up to\n76% (duplicate waste), i.e. phenotype mentions without the need for validation\nand model retraining, and with very good performance (93-97% accuracy). It can\nalso provide guidance for validating and retraining the selected model for\nnovel language patterns in new tasks, saving around 80% (imbalance waste), i.e.\nthe effort required in \"blind\" model-adaptation approaches.\n  Conclusions: Adapting pre-trained NLP models for new tasks can be more\nefficient and effective if the language pattern landscapes of old settings and\nnew settings can be made explicit and comparable. Our experiments show that the\nphenotype-mention embedding approach is an effective way to model language\npatterns for phenotype-mention identification tasks and that its use can guide\nefficient NLP model reuse.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 14:05:08 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 14:26:51 GMT"}, {"version": "v3", "created": "Wed, 23 Oct 2019 21:32:15 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Wu", "Honghan", ""], ["Hodgson", "Karen", ""], ["Dyson", "Sue", ""], ["Morley", "Katherine I.", ""], ["Ibrahim", "Zina M.", ""], ["Iqbal", "Ehtesham", ""], ["Stewart", "Robert", ""], ["Dobson", "Richard JB", ""], ["Sudlow", "Cathie", ""]]}, {"id": "1903.04081", "submitter": "John Lu", "authors": "John Lu and Sumati Sridhar and Ritika Pandey and Mohammad Al Hasan and\n  George Mohler", "title": "Redditors in Recovery: Text Mining Reddit to Investigate Transitions\n  into Drug Addiction", "comments": "2018 IEEE International Conference on Big Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing rates of opioid drug abuse and heightened prevalence of online\nsupport communities underscore the necessity of employing data mining\ntechniques to better understand drug addiction using these rapidly developing\nonline resources. In this work, we obtain data from Reddit, an online\ncollection of forums, to gather insight into drug use/misuse using text data\nfrom users themselves. Specifically, using user posts, we trained 1) a binary\nclassifier which predicts transitions from casual drug discussion forums to\ndrug recovery forums and 2) a Cox regression model that outputs likelihoods of\nsuch transitions. In doing so, we found that utterances of select drugs and\ncertain linguistic features contained in one's posts can help predict these\ntransitions. Using unfiltered drug-related posts, our research delineates drugs\nthat are associated with higher rates of transitions from recreational drug\ndiscussion to support/recovery discussion, offers insight into modern drug\nculture, and provides tools with potential applications in combating the opioid\ncrisis.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 00:10:29 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Lu", "John", ""], ["Sridhar", "Sumati", ""], ["Pandey", "Ritika", ""], ["Hasan", "Mohammad Al", ""], ["Mohler", "George", ""]]}, {"id": "1903.04146", "submitter": "Amr Amr", "authors": "Amr Adel Helmy, Yasser M.K. Omar, Rania Hodhod", "title": "An Innovative Word Encoding Method For Text Classification Using\n  Convolutional Neural Network", "comments": "Accepted @ 14th International Computer Engineering Conference\n  (ICENCO2018), Faculty of Engineering , Cairo University, Egypt, Dec. 29-30,\n  2018", "journal-ref": null, "doi": "10.1109/ICENCO.2018.8636143", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text classification plays a vital role today especially with the intensive\nuse of social networking media. Recently, different architectures of\nconvolutional neural networks have been used for text classification in which\none-hot vector, and word embedding methods are commonly used. This paper\npresents a new language independent word encoding method for text\nclassification. The proposed model converts raw text data to low-level feature\ndimension with minimal or no preprocessing steps by using a new approach called\nbinary unique number of word \"BUNOW\". BUNOW allows each unique word to have an\ninteger ID in a dictionary that is represented as a k-dimensional vector of its\nbinary equivalent. The output vector of this encoding is fed into a\nconvolutional neural network (CNN) model for classification. Moreover, the\nproposed model reduces the neural network parameters, allows faster computation\nwith few network layers, where a word is atomic representation the document as\nin word level, and decrease memory consumption for character level\nrepresentation. The provided CNN model is able to work with other languages or\nmulti-lingual text without the need for any changes in the encoding method. The\nmodel outperforms the character level and very deep character level CNNs models\nin terms of accuracy, network parameters, and memory consumption; the results\nshow total classification accuracy 91.99% and error 8.01% using AG's News\ndataset compared to the state of art methods that have total classification\naccuracy 91.45% and error 8.55%, in addition to the reduction in input feature\nvector and neural network parameters by 62% and 34%, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 07:08:39 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Helmy", "Amr Adel", ""], ["Omar", "Yasser M. K.", ""], ["Hodhod", "Rania", ""]]}, {"id": "1903.04153", "submitter": "Wei Jiang", "authors": "Wei Jiang, Zhenghua Li, Yu Zhang, Min Zhang", "title": "HLT@SUDA at SemEval 2019 Task 1: UCCA Graph Parsing as Constituent Tree\n  Parsing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a simple UCCA semantic graph parsing approach. The key\nidea is to convert a UCCA semantic graph into a constituent tree, in which\nextra labels are deliberately designed to mark remote edges and discontinuous\nnodes for future recovery. In this way, we can make use of existing syntactic\nparsing techniques. Based on the data statistics, we recover discontinuous\nnodes directly according to the output labels of the constituent parser and use\na biaffine classification model to recover the more complex remote edges. The\nclassification model and the constituent parser are simultaneously trained\nunder the multi-task learning framework. We use the multilingual BERT as extra\nfeatures in the open tracks. Our system ranks the first place in the six\nEnglish/German closed/open tracks among seven participating systems. For the\nseventh cross-lingual track, where there is little training data for French, we\npropose a language embedding approach to utilize English and German training\ndata, and our result ranks the second place.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 07:46:03 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 11:12:31 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Jiang", "Wei", ""], ["Li", "Zhenghua", ""], ["Zhang", "Yu", ""], ["Zhang", "Min", ""]]}, {"id": "1903.04167", "submitter": "Ofir Press", "authors": "Ofir Press", "title": "Partially Shuffling the Training Data to Improve Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although SGD requires shuffling the training data between epochs, currently\nnone of the word-level language modeling systems do this. Naively shuffling all\nsentences in the training data would not permit the model to learn\ninter-sentence dependencies. Here we present a method that partially shuffles\nthe training data between epochs. This method makes each batch random, while\nkeeping most sentence ordering intact. It achieves new state of the art results\non word-level language modeling on both the Penn Treebank and WikiText-2\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 08:20:13 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 04:59:04 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Press", "Ofir", ""]]}, {"id": "1903.04190", "submitter": "Xingyi Cheng", "authors": "Weipeng Huang, Xingyi Cheng, Kunlong Chen, Taifeng Wang, Wei Chu", "title": "Toward Fast and Accurate Neural Chinese Word Segmentation with\n  Multi-Criteria Learning", "comments": "Accepted at COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ambiguous annotation criteria lead to divergence of Chinese Word\nSegmentation (CWS) datasets in various granularities. Multi-criteria Chinese\nword segmentation aims to capture various annotation criteria among datasets\nand leverage their common underlying knowledge. In this paper, we propose a\ndomain adaptive segmenter to exploit diverse criteria of various datasets. Our\nmodel is based on Bidirectional Encoder Representations from Transformers\n(BERT), which is responsible for introducing open-domain knowledge. Private and\nshared projection layers are proposed to capture domain-specific knowledge and\ncommon knowledge, respectively. We also optimize computational efficiency via\ndistillation, quantization, and compiler optimization. Experiments show that\nour segmenter outperforms the previous state of the art (SOTA) models on 10 CWS\ndatasets with superior efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 09:48:39 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 07:58:36 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Huang", "Weipeng", ""], ["Cheng", "Xingyi", ""], ["Chen", "Kunlong", ""], ["Wang", "Taifeng", ""], ["Chu", "Wei", ""]]}, {"id": "1903.04329", "submitter": "Eszter Bok\\'anyi", "authors": "Eszter Bok\\'anyi, D\\'aniel Kondor, G\\'abor Vattay", "title": "Scaling in Words on Twitter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scaling properties of language are a useful tool for understanding generative\nprocesses in texts. We investigate the scaling relations in citywise Twitter\ncorpora coming from the Metropolitan and Micropolitan Statistical Areas of the\nUnited States. We observe a slightly superlinear urban scaling with the city\npopulation for the total volume of the tweets and words created in a city. We\nthen find that a certain core vocabulary follows the scaling relationship of\nthat of the bulk text, but most words are sensitive to city size, exhibiting a\nsuper- or a sublinear urban scaling. For both regimes we can offer a plausible\nexplanation based on the meaning of the words. We also show that the parameters\nfor Zipf's law and Heaps law differ on Twitter from that of other texts, and\nthat the exponent of Zipf's law changes with city size.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 14:41:07 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Bok\u00e1nyi", "Eszter", ""], ["Kondor", "D\u00e1niel", ""], ["Vattay", "G\u00e1bor", ""]]}, {"id": "1903.04433", "submitter": "Xuan-Son Vu", "authors": "Xuan-Son Vu, Thanh Vu, Son N. Tran, Lili Jiang", "title": "ETNLP: a visual-aided systematic approach to select pre-trained\n  embeddings for a downstream task", "comments": "10 pages", "journal-ref": "Proceedings of the International Conference Recent Advances in\n  Natural Language Processing (RANLP), 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given many recent advanced embedding models, selecting pre-trained word\nembedding (a.k.a., word representation) models best fit for a specific\ndownstream task is non-trivial. In this paper, we propose a systematic\napproach, called ETNLP, for extracting, evaluating, and visualizing multiple\nsets of pre-trained word embeddings to determine which embeddings should be\nused in a downstream task. For extraction, we provide a method to extract\nsubsets of the embeddings to be used in the downstream task. For evaluation, we\nanalyse the quality of pre-trained embeddings using an input word analogy list.\nFinally, we visualize the word representations in the embedding space to\nexplore the embedded words interactively.\n  We demonstrate the effectiveness of the proposed approach on our pre-trained\nword embedding models in Vietnamese to select which models are suitable for a\nnamed entity recognition (NER) task. Specifically, we create a large Vietnamese\nword analogy list to evaluate and select the pre-trained embedding models for\nthe task. We then utilize the selected embeddings for the NER task and achieve\nthe new state-of-the-art results on the task benchmark dataset. We also apply\nthe approach to another downstream task of privacy-guaranteed embedding\nselection, and show that it helps users quickly select the most suitable\nembeddings. In addition, we create an open-source system using the proposed\nsystematic approach to facilitate similar studies on other NLP tasks. The\nsource code and data are available at https://github.com/vietnlp/etnlp.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 16:48:25 GMT"}, {"version": "v2", "created": "Sat, 3 Aug 2019 20:19:36 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Vu", "Xuan-Son", ""], ["Vu", "Thanh", ""], ["Tran", "Son N.", ""], ["Jiang", "Lili", ""]]}, {"id": "1903.04484", "submitter": "Mimansa Jaiswal", "authors": "Mimansa Jaiswal, Sairam Tabibu, Rajiv Bajpai", "title": "The Truth and Nothing but the Truth: Multimodal Analysis for Deception\n  Detection", "comments": "6pages, ICDMW", "journal-ref": null, "doi": "10.1109/ICDMW.2016.0137", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a data-driven method for automatic deception detection in\nreal-life trial data using visual and verbal cues. Using OpenFace with facial\naction unit recognition, we analyze the movement of facial features of the\nwitness when posed with questions and the acoustic patterns using OpenSmile. We\nthen perform a lexical analysis on the spoken words, emphasizing the use of\npauses and utterance breaks, feeding that to a Support Vector Machine to test\ndeceit or truth prediction. We then try out a method to incorporate\nutterance-based fusion of visual and lexical analysis, using string based\nmatching.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 18:11:23 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Jaiswal", "Mimansa", ""], ["Tabibu", "Sairam", ""], ["Bajpai", "Rajiv", ""]]}, {"id": "1903.04521", "submitter": "Marco Damonte", "authors": "Marco Damonte, Rahul Goel, Tagyoung Chung", "title": "Practical Semantic Parsing for Spoken Language Understanding", "comments": null, "journal-ref": "Proceedings of NAACL 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Executable semantic parsing is the task of converting natural language\nutterances into logical forms that can be directly used as queries to get a\nresponse. We build a transfer learning framework for executable semantic\nparsing. We show that the framework is effective for Question Answering (Q&A)\nas well as for Spoken Language Understanding (SLU). We further investigate the\ncase where a parser on a new domain can be learned by exploiting data on other\ndomains, either via multi-task learning between the target domain and an\nauxiliary domain or via pre-training on the auxiliary domain and fine-tuning on\nthe target domain. With either flavor of transfer learning, we are able to\nimprove performance on most domains; we experiment with public data sets such\nas Overnight and NLmaps as well as with commercial SLU data. The experiments\ncarried out on data sets that are different in nature show how executable\nsemantic parsing can unify different areas of NLP such as Q&A and SLU.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 18:12:28 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 11:30:56 GMT"}, {"version": "v3", "created": "Tue, 19 Mar 2019 10:11:54 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Damonte", "Marco", ""], ["Goel", "Rahul", ""], ["Chung", "Tagyoung", ""]]}, {"id": "1903.04561", "submitter": "Nithum Thain", "authors": "Daniel Borkan, Lucas Dixon, Jeffrey Sorensen, Nithum Thain, Lucy\n  Vasserman", "title": "Nuanced Metrics for Measuring Unintended Bias with Real Data for Text\n  Classification", "comments": "Updated to fix typo in Equation 4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unintended bias in Machine Learning can manifest as systemic differences in\nperformance for different demographic groups, potentially compounding existing\nchallenges to fairness in society at large. In this paper, we introduce a suite\nof threshold-agnostic metrics that provide a nuanced view of this unintended\nbias, by considering the various ways that a classifier's score distribution\ncan vary across designated groups. We also introduce a large new test set of\nonline comments with crowd-sourced annotations for identity references. We use\nthis to show how our metrics can be used to find new and potentially subtle\nunintended bias in existing public models.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 19:45:54 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 14:39:41 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Borkan", "Daniel", ""], ["Dixon", "Lucas", ""], ["Sorensen", "Jeffrey", ""], ["Thain", "Nithum", ""], ["Vasserman", "Lucy", ""]]}, {"id": "1903.04567", "submitter": "Peidong Wang", "authors": "Peidong Wang, Ke Tan, DeLiang Wang", "title": "Bridging the Gap Between Monaural Speech Enhancement and Recognition\n  with Distortion-Independent Acoustic Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monaural speech enhancement has made dramatic advances since the introduction\nof deep learning a few years ago. Although enhanced speech has been\ndemonstrated to have better intelligibility and quality for human listeners,\nfeeding it directly to automatic speech recognition (ASR) systems trained with\nnoisy speech has not produced expected improvements in ASR performance. The\nlack of an enhancement benefit on recognition, or the gap between monaural\nspeech enhancement and recognition, is often attributed to speech distortions\nintroduced in the enhancement process. In this study, we analyze the distortion\nproblem, compare different acoustic models, and investigate a\ndistortion-independent training scheme for monaural speech recognition.\nExperimental results suggest that distortion-independent acoustic modeling is\nable to overcome the distortion problem. Such an acoustic model can also work\nwith speech enhancement models different from the one used during training.\nMoreover, the models investigated in this paper outperform the previous best\nsystem on the CHiME-2 corpus.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 19:51:34 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 00:34:13 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Wang", "Peidong", ""], ["Tan", "Ke", ""], ["Wang", "DeLiang", ""]]}, {"id": "1903.04715", "submitter": "Sebastien Jean", "authors": "S\\'ebastien Jean, Kyunghyun Cho", "title": "Context-Aware Learning for Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interest in larger-context neural machine translation, including\ndocument-level and multi-modal translation, has been growing. Multiple works\nhave proposed new network architectures or evaluation schemes, but potentially\nhelpful context is still sometimes ignored by larger-context translation\nmodels. In this paper, we propose a novel learning algorithm that explicitly\nencourages a neural translation model to take into account additional context\nusing a multilevel pair-wise ranking loss. We evaluate the proposed learning\nalgorithm with a transformer-based larger-context translation system on\ndocument-level translation. By comparing performance using actual and random\ncontexts, we show that a model trained with the proposed algorithm is more\nsensitive to the additional context.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 03:55:13 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Jean", "S\u00e9bastien", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1903.04739", "submitter": "Hsu Myat Mo", "authors": "Hsu Myat Mo and Khin Mar Soe", "title": "Syllable-based Neural Named Entity Recognition for Myanmar Language", "comments": "Myanmar NER", "journal-ref": "International Journal on Natural Language Computing (IJNLC) Vol.8,\n  No.1, February 2019", "doi": "10.5121/ijnlc.2019.8101", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Named Entity Recognition (NER) for Myanmar Language is essential to Myanmar\nnatural language processing research work. In this work, NER for Myanmar\nlanguage is treated as a sequence tagging problem and the effectiveness of deep\nneural networks on NER for Myanmar language has been investigated. Experiments\nare performed by applying deep neural network architectures on syllable level\nMyanmar contexts. Very first manually annotated NER corpus for Myanmar language\nis also constructed and proposed. In developing our in-house NER corpus,\nsentences from online news website and also sentences supported from\nALT-Parallel-Corpus are also used. This ALT corpus is one part of the Asian\nLanguage Treebank (ALT) project under ASEAN IVO. This paper contributes the\nfirst evaluation of neural network models on NER task for Myanmar language. The\nexperimental results show that those neural sequence models can produce\npromising results compared to the baseline CRF model. Among those neural\narchitectures, bidirectional LSTM network added CRF layer above gives the\nhighest F-score value. This work also aims to discover the effectiveness of\nneural network approaches to Myanmar textual processing as well as to promote\nfurther researches on this understudied language.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 05:52:41 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Mo", "Hsu Myat", ""], ["Soe", "Khin Mar", ""]]}, {"id": "1903.04750", "submitter": "Wen Zhang", "authors": "Wen Zhang, Bibek Paudel, Wei Zhang, Abraham Bernstein and Huajun Chen", "title": "Interaction Embeddings for Prediction and Explanation in Knowledge\n  Graphs", "comments": "This paper is accepted by WSDM2019", "journal-ref": null, "doi": "10.1145/3289600.3291014", "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph embedding aims to learn distributed representations for\nentities and relations, and is proven to be effective in many applications.\nCrossover interactions --- bi-directional effects between entities and\nrelations --- help select related information when predicting a new triple, but\nhaven't been formally discussed before. In this paper, we propose CrossE, a\nnovel knowledge graph embedding which explicitly simulates crossover\ninteractions. It not only learns one general embedding for each entity and\nrelation as most previous methods do, but also generates multiple triple\nspecific embeddings for both of them, named interaction embeddings. We evaluate\nembeddings on typical link prediction tasks and find that CrossE achieves\nstate-of-the-art results on complex and more challenging datasets. Furthermore,\nwe evaluate embeddings from a new perspective --- giving explanations for\npredicted triples, which is important for real applications. In this work, an\nexplanation for a triple is regarded as a reliable closed-path between the head\nand the tail entity. Compared to other baselines, we show experimentally that\nCrossE, benefiting from interaction embeddings, is more capable of generating\nreliable explanations to support its predictions.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 07:12:46 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Zhang", "Wen", ""], ["Paudel", "Bibek", ""], ["Zhang", "Wei", ""], ["Bernstein", "Abraham", ""], ["Chen", "Huajun", ""]]}, {"id": "1903.04870", "submitter": "Marcel Bollmann", "authors": "Marcel Bollmann, Natalia Korchagina, Anders S{\\o}gaard", "title": "Few-Shot and Zero-Shot Learning for Historical Text Normalization", "comments": "Accepted at DeepLo-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Historical text normalization often relies on small training datasets. Recent\nwork has shown that multi-task learning can lead to significant improvements by\nexploiting synergies with related datasets, but there has been no systematic\nstudy of different multi-task learning architectures. This paper evaluates\n63~multi-task learning configurations for sequence-to-sequence-based historical\ntext normalization across ten datasets from eight languages, using\nautoencoding, grapheme-to-phoneme mapping, and lemmatization as auxiliary\ntasks. We observe consistent, significant improvements across languages when\ntraining data for the target task is limited, but minimal or no improvements\nwhen training data is abundant. We also show that zero-shot learning\noutperforms the simple, but relatively strong, identity baseline.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 12:30:54 GMT"}, {"version": "v2", "created": "Sun, 13 Oct 2019 13:42:32 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Bollmann", "Marcel", ""], ["Korchagina", "Natalia", ""], ["S\u00f8gaard", "Anders", ""]]}, {"id": "1903.05041", "submitter": "Yuval Pinter", "authors": "Yuval Pinter, Marc Marone, Jacob Eisenstein", "title": "Character Eyes: Seeing Language through Character-Level Taggers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Character-level models have been used extensively in recent years in NLP\ntasks as both supplements and replacements for closed-vocabulary token-level\nword representations. In one popular architecture, character-level LSTMs are\nused to feed token representations into a sequence tagger predicting\ntoken-level annotations such as part-of-speech (POS) tags. In this work, we\nexamine the behavior of POS taggers across languages from the perspective of\nindividual hidden units within the character LSTM. We aggregate the behavior of\nthese units into language-level metrics which quantify the challenges that\ntaggers face on languages with different morphological properties, and identify\nlinks between synthesis and affixation preference and emergent behavior of the\nhidden tagger layer. In a comparative experiment, we show how modifying the\nbalance between forward and backward hidden units affects model arrangement and\nperformance in these types of languages.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 16:42:39 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Pinter", "Yuval", ""], ["Marone", "Marc", ""], ["Eisenstein", "Jacob", ""]]}, {"id": "1903.05164", "submitter": "Arpit Gupta", "authors": "Pushpendre Rastogi, Arpit Gupta, Tongfei Chen, Lambert Mathias", "title": "Scaling Multi-Domain Dialogue State Tracking via Query Reformulation", "comments": "Accepted to NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach to dialogue state tracking and referring\nexpression resolution tasks. Successful contextual understanding of multi-turn\nspoken dialogues requires resolving referring expressions across turns and\ntracking the entities relevant to the conversation across turns. Tracking\nconversational state is particularly challenging in a multi-domain scenario\nwhen there exist multiple spoken language understanding (SLU) sub-systems, and\neach SLU sub-system operates on its domain-specific meaning representation.\nWhile previous approaches have addressed the disparate schema issue by learning\ncandidate transformations of the meaning representation, in this paper, we\ninstead model the reference resolution as a dialogue context-aware user query\nreformulation task -- the dialog state is serialized to a sequence of natural\nlanguage tokens representing the conversation. We develop our model for query\nreformulation using a pointer-generator network and a novel multi-task learning\nsetup. In our experiments, we show a significant improvement in absolute F1 on\nan internal as well as a, soon to be released, public benchmark respectively.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 19:26:39 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 23:07:06 GMT"}, {"version": "v3", "created": "Fri, 29 Mar 2019 20:20:38 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Rastogi", "Pushpendre", ""], ["Gupta", "Arpit", ""], ["Chen", "Tongfei", ""], ["Mathias", "Lambert", ""]]}, {"id": "1903.05168", "submitter": "Ryan Lowe T.", "authors": "Ryan Lowe and Jakob Foerster and Y-Lan Boureau and Joelle Pineau and\n  Yann Dauphin", "title": "On the Pitfalls of Measuring Emergent Communication", "comments": "AAMAS 2019. 13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How do we know if communication is emerging in a multi-agent system? The vast\nmajority of recent papers on emergent communication show that adding a\ncommunication channel leads to an increase in reward or task success. This is a\nuseful indicator, but provides only a coarse measure of the agent's learned\ncommunication abilities. As we move towards more complex environments, it\nbecomes imperative to have a set of finer tools that allow qualitative and\nquantitative insights into the emergence of communication. This may be\nespecially useful to allow humans to monitor agents' behaviour, whether for\nfault detection, assessing performance, or even building trust. In this paper,\nwe examine a few intuitive existing metrics for measuring communication, and\nshow that they can be misleading. Specifically, by training deep reinforcement\nlearning agents to play simple matrix games augmented with a communication\nchannel, we find a scenario where agents appear to communicate (their messages\nprovide information about their subsequent action), and yet the messages do not\nimpact the environment or other agent in any way. We explain this phenomenon\nusing ablation studies and by visualizing the representations of the learned\npolicies. We also survey some commonly used metrics for measuring emergent\ncommunication, and provide recommendations as to when these metrics should be\nused.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 19:33:49 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Lowe", "Ryan", ""], ["Foerster", "Jakob", ""], ["Boureau", "Y-Lan", ""], ["Pineau", "Joelle", ""], ["Dauphin", "Yann", ""]]}, {"id": "1903.05181", "submitter": "Matilde Marcolli", "authors": "Alexander Port, Taelin Karidi, Matilde Marcolli", "title": "Topological Analysis of Syntactic Structures", "comments": "83 pages, LaTeX, 44 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use the persistent homology method of topological data analysis and\ndimensional analysis techniques to study data of syntactic structures of world\nlanguages. We analyze relations between syntactic parameters in terms of\ndimensionality, of hierarchical clustering structures, and of non-trivial\nloops. We show there are relations that hold across language families and\nadditional relations that are family-specific. We then analyze the trees\ndescribing the merging structure of persistent connected components for\nlanguages in different language families and we show that they partly correlate\nto historical phylogenetic trees but with significant differences. We also show\nthe existence of interesting non-trivial persistent first homology groups in\nvarious language families. We give examples where explicit generators for the\npersistent first homology can be identified, some of which appear to correspond\nto homoplasy phenomena, while others may have an explanation in terms of\nhistorical linguistics, corresponding to known cases of syntactic borrowing\nacross different language subfamilies.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 19:57:34 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Port", "Alexander", ""], ["Karidi", "Taelin", ""], ["Marcolli", "Matilde", ""]]}, {"id": "1903.05210", "submitter": "Mimansa Jaiswal", "authors": "Mimansa Jaiswal, Sairam Tabibu, Erik Cambria", "title": "\"Hang in There\": Lexical and Visual Analysis to Identify Posts\n  Warranting Empathetic Responses", "comments": "4 pages, FLAIRS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few years, social media has risen as a platform where people\nexpress and share personal incidences about abuse, violence and mental health\nissues. There is a need to pinpoint such posts and learn the kind of response\nexpected. For this purpose, we understand the sentiment that a personal story\nelicits on different posts present on different social media sites, on the\ntopics of abuse or mental health. In this paper, we propose a method supported\nby hand-crafted features to judge if the post requires an empathetic response.\nThe model is trained upon posts from various web-pages and corresponding\ncomments, on both the captions and the images. We were able to obtain 80%\naccuracy in tagging posts requiring empathetic responses.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 20:55:09 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Jaiswal", "Mimansa", ""], ["Tabibu", "Sairam", ""], ["Cambria", "Erik", ""]]}, {"id": "1903.05225", "submitter": "Ikechukwu Onyenwe", "authors": "Onyenwe Ikechukwu E, Onyedinma Ebele G, Aniegwu Godwin E and Ezeani\n  Ignatius M", "title": "Bootstrapping Method for Developing Part-of-Speech Tagged Corpus in Low\n  Resource Languages Tagset - A Focus on an African Igbo", "comments": null, "journal-ref": "International Journal on Natural Language Computing (IJNLC) Vol\n  8(1) (2019)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most languages, especially in Africa, have fewer or no established\npart-of-speech (POS) tagged corpus. However, POS tagged corpus is essential for\nnatural language processing (NLP) to support advanced researches such as\nmachine translation, speech recognition, etc. Even in cases where there is no\nPOS tagged corpus, there are some languages for which parallel texts are\navailable online. The task of POS tagging a new language corpus with a new\ntagset usually face a bootstrapping problem at the initial stages of the\nannotation process. The unavailability of automatic taggers to help the human\nannotator makes the annotation process to appear infeasible to quickly produce\nadequate amounts of POS tagged corpus for advanced NLP research and training\nthe taggers. In this paper, we demonstrate the efficacy of a POS annotation\nmethod that employed the services of two automatic approaches to assist POS\ntagged corpus creation for a novel language in NLP. The two approaches are\ncross-lingual and monolingual POS tags projection. We used cross-lingual to\nautomatically create an initial 'errorful' tagged corpus for a target language\nvia word-alignment. The resources for creating this are derived from a source\nlanguage rich in NLP resources. A monolingual method is applied to clean the\ninduce noise via an alignment process and to transform the source language tags\nto the target language tags. We used English and Igbo as our case study. This\nis possible because there are parallel texts that exist between English and\nIgbo, and the source language English has available NLP resources. The results\nof the experiment show a steady improvement in accuracy and rate of tags\ntransformation with score ranges of 6.13% to 83.79% and 8.67% to 98.37%\nrespectively. The rate of tags transformation evaluates the rate at which\nsource language tags are translated to target language tags.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 21:24:25 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["E", "Onyenwe Ikechukwu", ""], ["G", "Onyedinma Ebele", ""], ["E", "Aniegwu Godwin", ""], ["M", "Ezeani Ignatius", ""]]}, {"id": "1903.05260", "submitter": "Jungo Kasai", "authors": "Jungo Kasai, Dan Friedman, Robert Frank, Dragomir Radev, Owen Rambow", "title": "Syntax-aware Neural Semantic Role Labeling with Supertags", "comments": "NAACL 2019, Added Spanish ELMo results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new syntax-aware model for dependency-based semantic role\nlabeling that outperforms syntax-agnostic models for English and Spanish. We\nuse a BiLSTM to tag the text with supertags extracted from dependency parses,\nand we feed these supertags, along with words and parts of speech, into a deep\nhighway BiLSTM for semantic role labeling. Our model combines the strengths of\nearlier models that performed SRL on the basis of a full dependency parse with\nmore recent models that use no syntactic information at all. Our local and\nnon-ensemble model achieves state-of-the-art performance on the CoNLL 09\nEnglish and Spanish datasets. SRL models benefit from syntactic information,\nand we show that supertagging is a simple, powerful, and robust way to\nincorporate syntax into a neural SRL system.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 23:35:32 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2019 22:45:40 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Kasai", "Jungo", ""], ["Friedman", "Dan", ""], ["Frank", "Robert", ""], ["Radev", "Dragomir", ""], ["Rambow", "Owen", ""]]}, {"id": "1903.05261", "submitter": "Yangyang Shi", "authors": "Yangyang Shi and Mei-Yuh Hwang and Xin Lei", "title": "End-To-End Speech Recognition Using A High Rank LSTM-CTC Based Model", "comments": "ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long Short Term Memory Connectionist Temporal Classification (LSTM-CTC) based\nend-to-end models are widely used in speech recognition due to its simplicity\nin training and efficiency in decoding. In conventional LSTM-CTC based models,\na bottleneck projection matrix maps the hidden feature vectors obtained from\nLSTM to softmax output layer. In this paper, we propose to use a high rank\nprojection layer to replace the projection matrix. The output from the high\nrank projection layer is a weighted combination of vectors that are projected\nfrom the hidden feature vectors via different projection matrices and\nnon-linear activation function. The high rank projection layer is able to\nimprove the expressiveness of LSTM-CTC models. The experimental results show\nthat on Wall Street Journal (WSJ) corpus and LibriSpeech data set, the proposed\nmethod achieves 4%-6% relative word error rate (WER) reduction over the\nbaseline CTC system. They outperform other published CTC based end-to-end (E2E)\nmodels under the condition that no external data or data augmentation is\napplied. Code has been made available at https://github.com/mobvoi/lstm_ctc.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 23:40:27 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Shi", "Yangyang", ""], ["Hwang", "Mei-Yuh", ""], ["Lei", "Xin", ""]]}, {"id": "1903.05280", "submitter": "Ryan Ong", "authors": "Ryan Ong", "title": "Offensive Language Analysis using Deep Learning Architecture", "comments": "6 pages, 8 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SemEval-2019 Task 6 (Zampieri et al., 2019b) requires us to identify and\ncategorise offensive language in social media. In this paper we will describe\nthe process we took to tackle this challenge. Our process is heavily inspired\nby Sosa (2017) where he proposed CNN-LSTM and LSTM-CNN models to conduct\ntwitter sentiment analysis. We decided to follow his approach as well as\nfurther his work by testing out different variations of RNN models with CNN.\nSpecifically, we have divided the challenge into two parts: data processing and\nsampling and choosing the optimal deep learning architecture. In preprocessing,\nwe experimented with two techniques, SMOTE and Class Weights to counter the\nimbalance between classes. Once we are happy with the quality of our input\ndata, we proceed to choosing the optimal deep learning architecture for this\ntask. Given the quality and quantity of data we have been given, we found that\nthe addition of CNN layer provides very little to no additional improvement to\nour model's performance and sometimes even lead to a decrease in our F1-score.\nIn the end, the deep learning architecture that gives us the highest macro\nF1-score is a simple BiLSTM-CNN.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 09:36:25 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2019 15:01:47 GMT"}, {"version": "v3", "created": "Tue, 19 Mar 2019 17:23:43 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Ong", "Ryan", ""]]}, {"id": "1903.05396", "submitter": "Giannis Bekoulis", "authors": "Giannis Bekoulis, Johannes Deleu, Thomas Demeester, Chris Develder", "title": "Sub-event detection from Twitter streams as a sequence labeling problem", "comments": "NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces improved methods for sub-event detection in social\nmedia streams, by applying neural sequence models not only on the level of\nindividual posts, but also directly on the stream level. Current approaches to\nidentify sub-events within a given event, such as a goal during a soccer match,\nessentially do not exploit the sequential nature of social media streams. We\naddress this shortcoming by framing the sub-event detection problem in social\nmedia streams as a sequence labeling task and adopt a neural sequence\narchitecture that explicitly accounts for the chronological order of posts.\nSpecifically, we (i) establish a neural baseline that outperforms a graph-based\nstate-of-the-art method for binary sub-event detection (2.7% micro-F1\nimprovement), as well as (ii) demonstrate superiority of a recurrent neural\nnetwork model on the posts sequence level for labeled sub-events (2.4%\nbin-level F1 improvement over non-sequential models).\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 10:23:38 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Bekoulis", "Giannis", ""], ["Deleu", "Johannes", ""], ["Demeester", "Thomas", ""], ["Develder", "Chris", ""]]}, {"id": "1903.05440", "submitter": "Mark Levene", "authors": "Andrius Mudinas and Dell Zhang and Mark Levene", "title": "Market Trend Prediction using Sentiment Analysis: Lessons Learned and\n  Paths Forward", "comments": "10 pages, 4 figues, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial market forecasting is one of the most attractive practical\napplications of sentiment analysis. In this paper, we investigate the potential\nof using sentiment \\emph{attitudes} (positive vs negative) and also sentiment\n\\emph{emotions} (joy, sadness, etc.) extracted from financial news or tweets to\nhelp predict stock price movements. Our extensive experiments using the\n\\emph{Granger-causality} test have revealed that (i) in general sentiment\nattitudes do not seem to Granger-cause stock price changes; and (ii) while on\nsome specific occasions sentiment emotions do seem to Granger-cause stock price\nchanges, the exhibited pattern is not universal and must be looked at on a case\nby case basis. Furthermore, it has been observed that at least for certain\nstocks, integrating sentiment emotions as additional features into the machine\nlearning based market trend prediction model could improve its accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 12:19:45 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Mudinas", "Andrius", ""], ["Zhang", "Dell", ""], ["Levene", "Mark", ""]]}, {"id": "1903.05485", "submitter": "Ye Liu", "authors": "Ye Liu, Hui Li, Alberto Garcia-Duran, Mathias Niepert, Daniel\n  Onoro-Rubio, David S. Rosenblum", "title": "MMKG: Multi-Modal Knowledge Graphs", "comments": "ESWC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present MMKG, a collection of three knowledge graphs that contain both\nnumerical features and (links to) images for all entities as well as entity\nalignments between pairs of KGs. Therefore, multi-relational link prediction\nand entity matching communities can benefit from this resource. We believe this\ndata set has the potential to facilitate the development of novel multi-modal\nlearning approaches for knowledge graphs.We validate the utility ofMMKG in the\nsameAs link prediction task with an extensive set of experiments. These\nexperiments show that the task at hand benefits from learning of multiple\nfeature types.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 13:48:32 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Liu", "Ye", ""], ["Li", "Hui", ""], ["Garcia-Duran", "Alberto", ""], ["Niepert", "Mathias", ""], ["Onoro-Rubio", "Daniel", ""], ["Rosenblum", "David S.", ""]]}, {"id": "1903.05498", "submitter": "Pierre Nugues", "authors": "Marcus Klang, Firas Dib, Pierre Nugues", "title": "Overview of the Ugglan Entity Discovery and Linking System", "comments": null, "journal-ref": "Proceedings of the Tenth Text Analysis Conference (TAC 2017)\n  November 13-14, 2017, National Institute of Standards and Technology,\n  Gaithersburg, Maryland, USA", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Ugglan is a system designed to discover named entities and link them to\nunique identifiers in a knowledge base. It is based on a combination of a name\nand nominal dictionary derived from Wikipedia and Wikidata, a named entity\nrecognition module (NER) using fixed ordinally-forgetting encoding (FOFE)\ntrained on the TAC EDL data from 2014-2016, a candidate generation module from\nthe Wikipedia link graph across multiple editions, a PageRank link and\ncooccurrence graph disambiguator, and finally a reranker trained on the TAC EDL\n2015-2016 data.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 14:03:50 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Klang", "Marcus", ""], ["Dib", "Firas", ""], ["Nugues", "Pierre", ""]]}, {"id": "1903.05538", "submitter": "Panayiotis Smeros", "authors": "Panayiotis Smeros, Carlos Castillo, Karl Aberer", "title": "SciLens: Evaluating the Quality of Scientific News Articles Using Social\n  Media and Scientific Literature Indicators", "comments": null, "journal-ref": "Proceedings of the 28th International Conference on World Wide Web\n  (WWW '19), San Francisco, CA, USA, May 13-17, 2019", "doi": "10.1145/3308558.3313657", "report-no": null, "categories": "cs.IR cs.CL cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes, develops, and validates SciLens, a method to evaluate\nthe quality of scientific news articles. The starting point for our work are\nstructured methodologies that define a series of quality aspects for manually\nevaluating news. Based on these aspects, we describe a series of indicators of\nnews quality. According to our experiments, these indicators help non-experts\nevaluate more accurately the quality of a scientific news article, compared to\nnon-experts that do not have access to these indicators. Furthermore, SciLens\ncan also be used to produce a completely automated quality score for an\narticle, which agrees more with expert evaluators than manual evaluations done\nby non-experts. One of the main elements of SciLens is the focus on both\ncontent and context of articles, where context is provided by (1) explicit and\nimplicit references on the article to scientific literature, and (2) reactions\nin social media referencing the article. We show that both contextual elements\ncan be valuable sources of information for determining article quality. The\nvalidation of SciLens, done through a combination of expert and non-expert\nannotation, demonstrates its effectiveness for both semi-automatic and\nautomatic quality evaluation of scientific news.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 15:13:57 GMT"}, {"version": "v2", "created": "Tue, 23 Apr 2019 16:23:07 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Smeros", "Panayiotis", ""], ["Castillo", "Carlos", ""], ["Aberer", "Karl", ""]]}, {"id": "1903.05543", "submitter": "James Thorne", "authors": "James Thorne and Andreas Vlachos", "title": "Adversarial attacks against Fact Extraction and VERification", "comments": "Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a baseline for the second iteration of the Fact\nExtraction and VERification shared task (FEVER2.0) which explores the\nresilience of systems through adversarial evaluation. We present a collection\nof simple adversarial attacks against systems that participated in the first\nFEVER shared task. FEVER modeled the assessment of truthfulness of written\nclaims as a joint information retrieval and natural language inference task\nusing evidence from Wikipedia. A large number of participants made use of deep\nneural networks in their submissions to the shared task. The extent as to\nwhether such models understand language has been the subject of a number of\nrecent investigations and discussion in literature. In this paper, we present a\nsimple method of generating entailment-preserving and entailment-altering\nperturbations of instances by common patterns within the training data. We find\nthat a number of systems are greatly affected with absolute losses in\nclassification accuracy of up to $29\\%$ on the newly perturbed instances. Using\nthese newly generated instances, we construct a sample submission for the\nFEVER2.0 shared task. Addressing these types of attacks will aid in building\nmore robust fact-checking models, as well as suggest directions to expand the\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 15:29:22 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Thorne", "James", ""], ["Vlachos", "Andreas", ""]]}, {"id": "1903.05566", "submitter": "Xingkun Liu", "authors": "Xingkun Liu, Arash Eshghi, Pawel Swietojanski and Verena Rieser", "title": "Benchmarking Natural Language Understanding Services for building\n  Conversational Agents", "comments": "Accepted by IWSDS2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have recently seen the emergence of several publicly available Natural\nLanguage Understanding (NLU) toolkits, which map user utterances to structured,\nbut more abstract, Dialogue Act (DA) or Intent specifications, while making\nthis process accessible to the lay developer. In this paper, we present the\nfirst wide coverage evaluation and comparison of some of the most popular NLU\nservices, on a large, multi-domain (21 domains) dataset of 25K user utterances\nthat we have collected and annotated with Intent and Entity Type specifications\nand which will be released as part of this submission. The results show that on\nIntent classification Watson significantly outperforms the other platforms,\nnamely, Dialogflow, LUIS and Rasa; though these also perform well.\nInterestingly, on Entity Type recognition, Watson performs significantly worse\ndue to its low Precision. Again, Dialogflow, LUIS and Rasa perform well on this\ntask.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 16:08:46 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2019 11:28:11 GMT"}, {"version": "v3", "created": "Tue, 26 Mar 2019 14:57:28 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Liu", "Xingkun", ""], ["Eshghi", "Arash", ""], ["Swietojanski", "Pawel", ""], ["Rieser", "Verena", ""]]}, {"id": "1903.05587", "submitter": "Valerio Perrone", "authors": "Valerio Perrone, Marco Palma, Simon Hengchen, Alessandro Vatri, Jim Q.\n  Smith, Barbara McGillivray", "title": "GASC: Genre-Aware Semantic Change for Ancient Greek", "comments": null, "journal-ref": null, "doi": "10.18653/v1/W19-4707", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word meaning changes over time, depending on linguistic and extra-linguistic\nfactors. Associating a word's correct meaning in its historical context is a\ncentral challenge in diachronic research, and is relevant to a range of NLP\ntasks, including information retrieval and semantic search in historical texts.\nBayesian models for semantic change have emerged as a powerful tool to address\nthis challenge, providing explicit and interpretable representations of\nsemantic change phenomena. However, while corpora typically come with rich\nmetadata, existing models are limited by their inability to exploit contextual\ninformation (such as text genre) beyond the document time-stamp. This is\nparticularly critical in the case of ancient languages, where lack of data and\nlong diachronic span make it harder to draw a clear distinction between\npolysemy (the fact that a word has several senses) and semantic change (the\nprocess of acquiring, losing, or changing senses), and current systems perform\npoorly on these languages. We develop GASC, a dynamic semantic change model\nthat leverages categorical metadata about the texts' genre to boost inference\nand uncover the evolution of meanings in Ancient Greek corpora. In a new\nevaluation framework, our model achieves improved predictive performance\ncompared to the state of the art.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 17:32:51 GMT"}, {"version": "v2", "created": "Sun, 2 Jun 2019 12:48:56 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Perrone", "Valerio", ""], ["Palma", "Marco", ""], ["Hengchen", "Simon", ""], ["Vatri", "Alessandro", ""], ["Smith", "Jim Q.", ""], ["McGillivray", "Barbara", ""]]}, {"id": "1903.05683", "submitter": "Mohammad Sadegh Rasooli", "authors": "Mohammad Sadegh Rasooli and Michael Collins", "title": "Low-Resource Syntactic Transfer with Unsupervised Source Reordering", "comments": "Accepted in NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a cross-lingual transfer method for dependency parsing that takes\ninto account the problem of word order differences between source and target\nlanguages. Our model only relies on the Bible, a considerably smaller parallel\ndata than the commonly used parallel data in transfer methods. We use the\nconcatenation of projected trees from the Bible corpus, and the gold-standard\ntreebanks in multiple source languages along with cross-lingual word\nrepresentations. We demonstrate that reordering the source treebanks before\ntraining on them for a target language improves the accuracy of languages\noutside the European language family. Our experiments on 68 treebanks (38\nlanguages) in the Universal Dependencies corpus achieve a high accuracy for all\nlanguages. Among them, our experiments on 16 treebanks of 12 non-European\nlanguages achieve an average UAS absolute improvement of 3.3% over a\nstate-of-the-art method.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 19:01:00 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Rasooli", "Mohammad Sadegh", ""], ["Collins", "Michael", ""]]}, {"id": "1903.05759", "submitter": "Yizhe Zhang", "authors": "Yizhe Zhang, Xiang Gao, Sungjin Lee, Chris Brockett, Michel Galley,\n  Jianfeng Gao, Bill Dolan", "title": "Consistent Dialogue Generation with Self-supervised Feature Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating responses that are consistent with the dialogue context is one of\nthe central challenges in building engaging conversational agents. In this\npaper, we propose a neural conversation model that generates consistent\nresponses by maintaining certain features related to topics and personas\nthroughout the conversation. Unlike past work that requires external\nsupervision such as user identities, which are often unavailable or classified\nas sensitive information, our approach trains topic and persona feature\nextractors in a self-supervised way by utilizing the natural structure of\ndialogue data. Moreover, we adopt a binary feature representation and introduce\na feature disentangling loss which, paired with controllable response\ngeneration techniques, allows us to promote or demote certain learned topics\nand personas features. The evaluation result demonstrates the model's\ncapability of capturing meaningful topics and personas features, and the\nincorporation of the learned features brings significant improvement in terms\nof the quality of generated responses on two datasets, even comparing with\nmodel which explicit persona information.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 23:45:31 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 20:01:02 GMT"}, {"version": "v3", "created": "Thu, 30 Apr 2020 05:19:00 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Zhang", "Yizhe", ""], ["Gao", "Xiang", ""], ["Lee", "Sungjin", ""], ["Brockett", "Chris", ""], ["Galley", "Michel", ""], ["Gao", "Jianfeng", ""], ["Dolan", "Bill", ""]]}, {"id": "1903.05801", "submitter": "Aditya Joshi PhD", "authors": "Aditya Joshi, Sarvnaz Karimi, Ross Sparks, Cecile Paris, C Raina\n  MacIntyre", "title": "Survey of Text-based Epidemic Intelligence: A Computational Linguistic\n  Perspective", "comments": "This paper is under review at ACM Computing Surveys. This version of\n  the paper does not use the ACM Computing Surveys stylesheet. This arXiv\n  version is to solicit feedback", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epidemic intelligence deals with the detection of disease outbreaks using\nformal (such as hospital records) and informal sources (such as user-generated\ntext on the web) of information. In this survey, we discuss approaches for\nepidemic intelligence that use textual datasets, referring to it as `text-based\nepidemic intelligence'. We view past work in terms of two broad categories:\nhealth mention classification (selecting relevant text from a large volume) and\nhealth event detection (predicting epidemic events from a collection of\nrelevant text). The focus of our discussion is the underlying computational\nlinguistic techniques in the two categories. The survey also provides details\nof the state-of-the-art in annotation techniques, resources and evaluation\nstrategies for epidemic intelligence.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 03:23:15 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Joshi", "Aditya", ""], ["Karimi", "Sarvnaz", ""], ["Sparks", "Ross", ""], ["Paris", "Cecile", ""], ["MacIntyre", "C Raina", ""]]}, {"id": "1903.05823", "submitter": "Sungchul Choi", "authors": "Seokkyu Choi, Hyeonju Lee, Eunjeong Lucy Park, Sungchul Choi", "title": "Deep Patent Landscaping Model Using Transformer and Graph Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patent landscaping is a method used for searching related patents during a\nresearch and development (R&D) project. To avoid the risk of patent\ninfringement and to follow current trends in technology, patent landscaping is\na crucial task required during the early stages of an R&D project. As the\nprocess of patent landscaping requires advanced resources and can be tedious,\nthe demand for automated patent landscaping has been gradually increasing.\nHowever, a shortage of well-defined benchmark datasets and comparable models\nmakes it difficult to find related research studies. In this paper, we propose\nan automated patent landscaping model based on deep learning. To analyze the\ntext of patents, the proposed model uses a modified transformer structure. To\nanalyze the metadata of patents, we propose a graph embedding method that uses\na diffusion graph called Diff2Vec. Furthermore, we introduce four benchmark\ndatasets for comparing related research studies in patent landscaping. The\ndatasets are produced by querying Google BigQuery, based on a search formula\nfrom a Korean patent attorney. The obtained results indicate that the proposed\nmodel and datasets can attain state-of-the-art performance, as compared with\ncurrent patent landscaping models.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 05:53:22 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 09:51:43 GMT"}, {"version": "v3", "created": "Thu, 14 Nov 2019 17:43:42 GMT"}, {"version": "v4", "created": "Fri, 22 Nov 2019 00:54:27 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Choi", "Seokkyu", ""], ["Lee", "Hyeonju", ""], ["Park", "Eunjeong Lucy", ""], ["Choi", "Sungchul", ""]]}, {"id": "1903.05854", "submitter": "Tingting Qiao", "authors": "Tingting Qiao, Jing Zhang, Duanqing Xu and Dacheng Tao", "title": "MirrorGAN: Learning Text-to-image Generation by Redescription", "comments": "Accepted by CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating an image from a given text description has two goals: visual\nrealism and semantic consistency. Although significant progress has been made\nin generating high-quality and visually realistic images using generative\nadversarial networks, guaranteeing semantic consistency between the text\ndescription and visual content remains very challenging. In this paper, we\naddress this problem by proposing a novel global-local attentive and\nsemantic-preserving text-to-image-to-text framework called MirrorGAN. MirrorGAN\nexploits the idea of learning text-to-image generation by redescription and\nconsists of three modules: a semantic text embedding module (STEM), a\nglobal-local collaborative attentive module for cascaded image generation\n(GLAM), and a semantic text regeneration and alignment module (STREAM). STEM\ngenerates word- and sentence-level embeddings. GLAM has a cascaded architecture\nfor generating target images from coarse to fine scales, leveraging both local\nword attention and global sentence attention to progressively enhance the\ndiversity and semantic consistency of the generated images. STREAM seeks to\nregenerate the text description from the generated image, which semantically\naligns with the given text description. Thorough experiments on two public\nbenchmark datasets demonstrate the superiority of MirrorGAN over other\nrepresentative state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 08:31:05 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Qiao", "Tingting", ""], ["Zhang", "Jing", ""], ["Xu", "Duanqing", ""], ["Tao", "Dacheng", ""]]}, {"id": "1903.05872", "submitter": "Markus Schr\\\"oder", "authors": "Markus Schr\\\"oder, Christian Jilek, Andreas Dengel", "title": "Interactive Concept Mining on Personal Data -- Bootstrapping Semantic\n  Services", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic services (e.g. Semantic Desktops) are still afflicted by a cold\nstart problem: in the beginning, the user's personal information sphere, i.e.\nfiles, mails, bookmarks, etc., is not represented by the system. Information\nextraction tools used to kick-start the system typically create 1:1\nrepresentations of the different information items. Higher level concepts, for\nexample found in file names, mail subjects or in the content body of these\nitems, are not extracted. Leaving these concepts out may lead to\nunderperformance, having to many of them (e.g. by making every found term a\nconcept) will clutter the arising knowledge graph with non-helpful relations.\nIn this paper, we present an interactive concept mining approach proposing\nconcept candidates gathered by exploiting given schemata of usual personal\ninformation management applications and analysing the personal information\nsphere using various metrics. To heed the subjective view of the user, a\ngraphical user interface allows to easily rank and give feedback on proposed\nconcept candidates, thus keeping only those actually considered relevant. A\nprototypical implementation demonstrates major steps of our approach.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 09:37:53 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Schr\u00f6der", "Markus", ""], ["Jilek", "Christian", ""], ["Dengel", "Andreas", ""]]}, {"id": "1903.05929", "submitter": "Silvia Sapora", "authors": "Silvia Sapora, Bogdan Lazarescu, Christo Lolov", "title": "Absit invidia verbo: Comparing Deep Learning methods for offensive\n  language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document describes our approach to building an Offensive Language\nClassifier. More specifically, the OffensEval 2019 competition required us to\nbuild three classifiers with slightly different goals:\n  - Offensive language identification: would classify a tweet as offensive or\nnot.\n  - Automatic categorization of offense types: would recognize if the target of\nthe offense was an individual or not.\n  - Offense target identification: would identify the target of the offense\nbetween an individual, group or other.\n  In this report, we will discuss the different architectures, algorithms and\npre-processing strategies we tried, together with a detailed description of the\ndesigns of our final classifiers and the reasons we choose them over others.\n  We evaluated our classifiers on the official test set provided for the\nOffenseEval 2019 competition, obtaining a macro-averaged F1-score of 0.7189 for\nTask A, 0.6708 on Task B and 0.5442 on Task C.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 11:59:01 GMT"}, {"version": "v2", "created": "Sat, 16 Mar 2019 13:43:22 GMT"}, {"version": "v3", "created": "Mon, 25 Mar 2019 15:36:48 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Sapora", "Silvia", ""], ["Lazarescu", "Bogdan", ""], ["Lolov", "Christo", ""]]}, {"id": "1903.05942", "submitter": "Dong-Jin Kim", "authors": "Dong-Jin Kim, Jinsoo Choi, Tae-Hyun Oh, In So Kweon", "title": "Dense Relational Captioning: Triple-Stream Networks for\n  Relationship-Based Captioning", "comments": "CVPR 2019 (Under review for journal extension). Project page :\n  https://sites.google.com/view/relcap", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our goal in this work is to train an image captioning model that generates\nmore dense and informative captions. We introduce \"relational captioning,\" a\nnovel image captioning task which aims to generate multiple captions with\nrespect to relational information between objects in an image. Relational\ncaptioning is a framework that is advantageous in both diversity and amount of\ninformation, leading to image understanding based on relationships. Part-of\nspeech (POS, i.e. subject-object-predicate categories) tags can be assigned to\nevery English word. We leverage the POS as a prior to guide the correct\nsequence of words in a caption. To this end, we propose a multi-task\ntriple-stream network (MTTSNet) which consists of three recurrent units for the\nrespective POS and jointly performs POS prediction and captioning. We\ndemonstrate more diverse and richer representations generated by the proposed\nmodel against several baselines and competing methods.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 12:36:01 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 05:06:16 GMT"}, {"version": "v3", "created": "Mon, 1 Apr 2019 05:07:54 GMT"}, {"version": "v4", "created": "Sun, 22 Sep 2019 07:24:51 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Kim", "Dong-Jin", ""], ["Choi", "Jinsoo", ""], ["Oh", "Tae-Hyun", ""], ["Kweon", "In So", ""]]}, {"id": "1903.05955", "submitter": "Bajibabu Bollepalli Mr", "authors": "Bajibabu Bollepalli and Lauri Juvela and Paavo Alku", "title": "Generative adversarial network-based glottal waveform model for\n  statistical parametric speech synthesis", "comments": "Accepted in Interspeech", "journal-ref": "Interspeech-2017", "doi": "10.21437/Interspeech.2017-1288", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that text-to-speech synthesis quality can be\nimproved by using glottal vocoding. This refers to vocoders that parameterize\nspeech into two parts, the glottal excitation and vocal tract, that occur in\nthe human speech production apparatus. Current glottal vocoders generate the\nglottal excitation waveform by using deep neural networks (DNNs). However, the\nsquared error-based training of the present glottal excitation models is\nlimited to generating conditional average waveforms, which fails to capture the\nstochastic variation of the waveforms. As a result, shaped noise is added as\npost-processing. In this study, we propose a new method for predicting glottal\nwaveforms by generative adversarial networks (GANs). GANs are generative models\nthat aim to embed the data distribution in a latent space, enabling generation\nof new instances very similar to the original by randomly sampling the latent\ndistribution. The glottal pulses generated by GANs show a stochastic component\nsimilar to natural glottal pulses. In our experiments, we compare synthetic\nspeech generated using glottal waveforms produced by both DNNs and GANs. The\nresults show that the newly proposed GANs achieve synthesis quality comparable\nto that of widely-used DNNs, without using an additive noise component.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 12:53:45 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Bollepalli", "Bajibabu", ""], ["Juvela", "Lauri", ""], ["Alku", "Paavo", ""]]}, {"id": "1903.05987", "submitter": "Sebastian Ruder", "authors": "Matthew E. Peters, Sebastian Ruder, Noah A. Smith", "title": "To Tune or Not to Tune? Adapting Pretrained Representations to Diverse\n  Tasks", "comments": "Proceedings of the 4th Workshop on Representation Learning for NLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While most previous work has focused on different pretraining objectives and\narchitectures for transfer learning, we ask how to best adapt the pretrained\nmodel to a given target task. We focus on the two most common forms of\nadaptation, feature extraction (where the pretrained weights are frozen), and\ndirectly fine-tuning the pretrained model. Our empirical results across diverse\nNLP tasks with two state-of-the-art models show that the relative performance\nof fine-tuning vs. feature extraction depends on the similarity of the\npretraining and target tasks. We explore possible explanations for this finding\nand provide a set of adaptation guidelines for the NLP practitioner.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 13:32:31 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 13:13:46 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Peters", "Matthew E.", ""], ["Ruder", "Sebastian", ""], ["Smith", "Noah A.", ""]]}, {"id": "1903.06164", "submitter": "Moonsu Han", "authors": "Moonsu Han, Minki Kang, Hyunwoo Jung, Sung Ju Hwang", "title": "Episodic Memory Reader: Learning What to Remember for Question Answering\n  from Streaming Data", "comments": "18 pages, 20 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a novel question answering (QA) task where the machine needs to\nread from large streaming data (long documents or videos) without knowing when\nthe questions will be given, which is difficult to solve with existing QA\nmethods due to their lack of scalability. To tackle this problem, we propose a\nnovel end-to-end deep network model for reading comprehension, which we refer\nto as Episodic Memory Reader (EMR) that sequentially reads the input contexts\ninto an external memory, while replacing memories that are less important for\nanswering \\emph{unseen} questions. Specifically, we train an RL agent to\nreplace a memory entry when the memory is full, in order to maximize its QA\naccuracy at a future timepoint, while encoding the external memory using either\nthe GRU or the Transformer architecture to learn representations that considers\nrelative importance between the memory entries. We validate our model on a\nsynthetic dataset (bAbI) as well as real-world large-scale textual QA\n(TriviaQA) and video QA (TVQA) datasets, on which it achieves significant\nimprovements over rule-based memory scheduling policies or an RL-based baseline\nthat independently learns the query-specific importance of each memory.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 14:00:56 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2019 07:46:25 GMT"}, {"version": "v3", "created": "Sun, 9 Jun 2019 06:58:01 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Han", "Moonsu", ""], ["Kang", "Minki", ""], ["Jung", "Hyunwoo", ""], ["Hwang", "Sung Ju", ""]]}, {"id": "1903.06353", "submitter": "Ruochen Xu", "authors": "Ruochen Xu, Tao Ge, Furu Wei", "title": "Formality Style Transfer with Hybrid Textual Annotations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formality style transformation is the task of modifying the formality of a\ngiven sentence without changing its content. Its challenge is the lack of\nlarge-scale sentence-aligned parallel data. In this paper, we propose an\nomnivorous model that takes parallel data and formality-classified data jointly\nto alleviate the data sparsity issue. We empirically demonstrate the\neffectiveness of our approach by achieving the state-of-art performance on a\nrecently proposed benchmark dataset of formality transfer. Furthermore, our\nmodel can be readily adapted to other unsupervised text style transfer tasks\nlike unsupervised sentiment transfer and achieve competitive results on three\nwidely recognized benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 04:08:49 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Xu", "Ruochen", ""], ["Ge", "Tao", ""], ["Wei", "Furu", ""]]}, {"id": "1903.06400", "submitter": "Shauli Ravfogel", "authors": "Shauli Ravfogel, Yoav Goldberg, Tal Linzen", "title": "Studying the Inductive Biases of RNNs with Synthetic Variations of\n  Natural Languages", "comments": "Accepted as a long paper in NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  How do typological properties such as word order and morphological case\nmarking affect the ability of neural sequence models to acquire the syntax of a\nlanguage? Cross-linguistic comparisons of RNNs' syntactic performance (e.g., on\nsubject-verb agreement prediction) are complicated by the fact that any two\nlanguages differ in multiple typological properties, as well as by differences\nin training corpus. We propose a paradigm that addresses these issues: we\ncreate synthetic versions of English, which differ from English in one or more\ntypological parameters, and generate corpora for those languages based on a\nparsed English corpus. We report a series of experiments in which RNNs were\ntrained to predict agreement features for verbs in each of those synthetic\nlanguages. Among other findings, (1) performance was higher in\nsubject-verb-object order (as in English) than in subject-object-verb order (as\nin Japanese), suggesting that RNNs have a recency bias; (2) predicting\nagreement with both subject and object (polypersonal agreement) improves over\npredicting each separately, suggesting that underlying syntactic knowledge\ntransfers across the two tasks; and (3) overt morphological case makes\nagreement prediction significantly easier, regardless of word order.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 08:06:03 GMT"}, {"version": "v2", "created": "Tue, 26 Mar 2019 18:50:43 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Ravfogel", "Shauli", ""], ["Goldberg", "Yoav", ""], ["Linzen", "Tal", ""]]}, {"id": "1903.06409", "submitter": "Daniele Falavigna", "authors": "Roberto Gretter, Katharina Allgaier, Svetlana Tchistiakova, Daniele\n  Falavigna", "title": "Automatic assessment of spoken language proficiency of non-native\n  children", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes technology developed to automatically grade Italian\nstudents (ages 9-16) on their English and German spoken language proficiency.\nThe students' spoken answers are first transcribed by an automatic speech\nrecognition (ASR) system and then scored using a feedforward neural network\n(NN) that processes features extracted from the automatic transcriptions.\nIn-domain acoustic models, employing deep neural networks (DNNs), are derived\nby adapting the parameters of an original out of domain DNN.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 08:48:20 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Gretter", "Roberto", ""], ["Allgaier", "Katharina", ""], ["Tchistiakova", "Svetlana", ""], ["Falavigna", "Daniele", ""]]}, {"id": "1903.06464", "submitter": "Chanwoo Jeong", "authors": "Chanwoo Jeong, Sion Jang, Hyuna Shin, Eunjeong Park, Sungchul Choi", "title": "A Context-Aware Citation Recommendation Model with BERT and Graph\n  Convolutional Networks", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the tremendous growth in the number of scientific papers being\npublished, searching for references while writing a scientific paper is a\ntime-consuming process. A technique that could add a reference citation at the\nappropriate place in a sentence will be beneficial. In this perspective,\ncontext-aware citation recommendation has been researched upon for around two\ndecades. Many researchers have utilized the text data called the context\nsentence, which surrounds the citation tag, and the metadata of the target\npaper to find the appropriate cited research. However, the lack of\nwell-organized benchmarking datasets and no model that can attain high\nperformance has made the research difficult.\n  In this paper, we propose a deep learning based model and well-organized\ndataset for context-aware paper citation recommendation. Our model comprises a\ndocument encoder and a context encoder, which uses Graph Convolutional Networks\n(GCN) layer and Bidirectional Encoder Representations from Transformers (BERT),\nwhich is a pre-trained model of textual data. By modifying the related PeerRead\ndataset, we propose a new dataset called FullTextPeerRead containing context\nsentences to cited references and paper metadata. To the best of our knowledge,\nThis dataset is the first well-organized dataset for context-aware paper\nrecommendation. The results indicate that the proposed model with the proposed\ndatasets can attain state-of-the-art performance and achieve a more than 28%\nimprovement in mean average precision (MAP) and recall@k.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 11:13:22 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Jeong", "Chanwoo", ""], ["Jang", "Sion", ""], ["Shin", "Hyuna", ""], ["Park", "Eunjeong", ""], ["Choi", "Sungchul", ""]]}, {"id": "1903.06494", "submitter": "Daniel Hershcovich", "authors": "Daniel Hershcovich and Omri Abend and Ari Rappoport", "title": "Content Differences in Syntactic and Semantic Representations", "comments": "NAACL-HLT 2019 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Syntactic analysis plays an important role in semantic parsing, but the\nnature of this role remains a topic of ongoing debate. The debate has been\nconstrained by the scarcity of empirical comparative studies between syntactic\nand semantic schemes, which hinders the development of parsing methods informed\nby the details of target schemes and constructions. We target this gap, and\ntake Universal Dependencies (UD) and UCCA as a test case. After abstracting\naway from differences of convention or formalism, we find that most content\ndivergences can be ascribed to: (1) UCCA's distinction between a Scene and a\nnon-Scene; (2) UCCA's distinction between primary relations, secondary ones and\nparticipants; (3) different treatment of multi-word expressions, and (4)\ndifferent treatment of inter-clause linkage. We further discuss the long tail\nof cases where the two schemes take markedly different approaches. Finally, we\nshow that the proposed comparison methodology can be used for fine-grained\nevaluation of UCCA parsing, highlighting both challenges and potential sources\nfor improvement. The substantial differences between the schemes suggest that\nsemantic parsers are likely to benefit downstream text understanding\napplications beyond their syntactic counterparts.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 12:44:36 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2019 08:14:55 GMT"}, {"version": "v3", "created": "Thu, 28 Mar 2019 16:10:24 GMT"}, {"version": "v4", "created": "Fri, 29 Mar 2019 09:50:20 GMT"}, {"version": "v5", "created": "Wed, 1 May 2019 06:28:11 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Hershcovich", "Daniel", ""], ["Abend", "Omri", ""], ["Rappoport", "Ari", ""]]}, {"id": "1903.06607", "submitter": "Jimmy Lin", "authors": "Michael Azmy, Peng Shi, Jimmy Lin, and Ihab F. Ilyas", "title": "Matching Entities Across Different Knowledge Graphs with Graph\n  Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the problem of matching entities across different\nknowledge graphs. Given a query entity in one knowledge graph, we wish to find\nthe corresponding real-world entity in another knowledge graph. We formalize\nthis problem and present two large-scale datasets for this task based on\nexiting cross-ontology links between DBpedia and Wikidata, focused on several\nhundred thousand ambiguous entities. Using a classification-based approach, we\nfind that a simple multi-layered perceptron based on representations derived\nfrom RDF2Vec graph embeddings of entities in each knowledge graph is sufficient\nto achieve high accuracy, with only small amounts of training data. The\ncontributions of our work are datasets for examining this problem and strong\nbaselines on which future work can be based.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 15:45:34 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Azmy", "Michael", ""], ["Shi", "Peng", ""], ["Lin", "Jimmy", ""], ["Ilyas", "Ihab F.", ""]]}, {"id": "1903.06620", "submitter": "Paul Michel", "authors": "Paul Michel, Xian Li, Graham Neubig, Juan Miguel Pino", "title": "On Evaluation of Adversarial Perturbations for Sequence-to-Sequence\n  Models", "comments": "NAACL-HLT 2019 long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples --- perturbations to the input of a model that elicit\nlarge changes in the output --- have been shown to be an effective way of\nassessing the robustness of sequence-to-sequence (seq2seq) models. However,\nthese perturbations only indicate weaknesses in the model if they do not change\nthe input so significantly that it legitimately results in changes in the\nexpected output. This fact has largely been ignored in the evaluations of the\ngrowing body of related literature. Using the example of untargeted attacks on\nmachine translation (MT), we propose a new evaluation framework for adversarial\nattacks on seq2seq models that takes the semantic equivalence of the pre- and\npost-perturbation input into account. Using this framework, we demonstrate that\nexisting methods may not preserve meaning in general, breaking the\naforementioned assumption that source side perturbations should not result in\nchanges in the expected output. We further use this framework to demonstrate\nthat adding additional constraints on attacks allows for adversarial\nperturbations that are more meaning-preserving, but nonetheless largely change\nthe output sequence. Finally, we show that performing untargeted adversarial\ntraining with meaning-preserving attacks is beneficial to the model in terms of\nadversarial robustness, without hurting test performance. A toolkit\nimplementing our evaluation framework is released at\nhttps://github.com/pmichel31415/teapot-nlp.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 16:04:11 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2019 01:37:05 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Michel", "Paul", ""], ["Li", "Xian", ""], ["Neubig", "Graham", ""], ["Pino", "Juan Miguel", ""]]}, {"id": "1903.06765", "submitter": "Navoneel Chakrabarty", "authors": "Navoneel Chakrabarty", "title": "A Machine Learning Approach to Comment Toxicity Classification", "comments": "INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE IN PATTERN\n  RECOGNITION (CIPR 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Now-a-days, derogatory comments are often made by one another, not only in\noffline environment but also immensely in online environments like social\nnetworking websites and online communities. So, an Identification combined with\nPrevention System in all social networking websites and applications, including\nall the communities, existing in the digital world is a necessity. In such a\nsystem, the Identification Block should identify any negative online behaviour\nand should signal the Prevention Block to take action accordingly. This study\naims to analyse any piece of text and detecting different types of toxicity\nlike obscenity, threats, insults and identity-based hatred. The labelled\nWikipedia Comment Dataset prepared by Jigsaw is used for the purpose. A\n6-headed Machine Learning tf-idf Model has been made and trained separately,\nyielding a Mean Validation Accuracy of 98.08% and Absolute Validation Accuracy\nof 91.61%. Such an Automated System should be deployed for enhancing healthy\nonline conversation\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 07:21:44 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Chakrabarty", "Navoneel", ""]]}, {"id": "1903.06901", "submitter": "Pengyuan Liu", "authors": "Pengyuan Liu, Chengyu Du, Shuofeng Zhao, Chenghao Zhu", "title": "Emotion Action Detection and Emotion Inference: the Task and Dataset", "comments": "arXiv admin note: text overlap with arXiv:1805.06939 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many Natural Language Processing works on emotion analysis only focus on\nsimple emotion classification without exploring the potentials of putting\nemotion into \"event context\", and ignore the analysis of emotion-related\nevents. One main reason is the lack of this kind of corpus. Here we present\nCause-Emotion-Action Corpus, which manually annotates not only emotion, but\nalso cause events and action events. We propose two new tasks based on the\ndata-set: emotion causality and emotion inference. The first task is to extract\na triple (cause, emotion, action). The second task is to infer the probable\nemotion. We are currently releasing the data-set with 10,603 samples and 15,892\nevents, basic statistic analysis and baseline on both emotion causality and\nemotion inference tasks. Baseline performance demonstrates that there is much\nroom for both tasks to be improved.\n", "versions": [{"version": "v1", "created": "Sat, 16 Mar 2019 09:46:29 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Liu", "Pengyuan", ""], ["Du", "Chengyu", ""], ["Zhao", "Shuofeng", ""], ["Zhu", "Chenghao", ""]]}, {"id": "1903.06939", "submitter": "Enrique Manjavacas Ar\\'evalo", "authors": "Enrique Manjavacas, \\'Akos K\\'ad\\'ar, Mike Kestemont", "title": "Improving Lemmatization of Non-Standard Languages with Joint Learning", "comments": null, "journal-ref": "NAACL-HLT 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lemmatization of standard languages is concerned with (i) abstracting over\nmorphological differences and (ii) resolving token-lemma ambiguities of\ninflected words in order to map them to a dictionary headword. In the present\npaper we aim to improve lemmatization performance on a set of non-standard\nhistorical languages in which the difficulty is increased by an additional\naspect (iii): spelling variation due to lacking orthographic standards. We\napproach lemmatization as a string-transduction task with an encoder-decoder\narchitecture which we enrich with sentence context information using a\nhierarchical sentence encoder. We show significant improvements over the\nstate-of-the-art when training the sentence encoder jointly for lemmatization\nand language modeling. Crucially, our architecture does not require POS or\nmorphological annotations, which are not always available for historical\ncorpora. Additionally, we also test the proposed model on a set of\ntypologically diverse standard languages showing results on par or better than\na model without enhanced sentence representations and previous state-of-the-art\nsystems. Finally, to encourage future work on processing of non-standard\nvarieties, we release the dataset of non-standard languages underlying the\npresent study, based on openly accessible sources.\n", "versions": [{"version": "v1", "created": "Sat, 16 Mar 2019 14:59:13 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Manjavacas", "Enrique", ""], ["K\u00e1d\u00e1r", "\u00c1kos", ""], ["Kestemont", "Mike", ""]]}, {"id": "1903.06963", "submitter": "John Brandt", "authors": "John Brandt", "title": "Imbalanced multi-label classification using multi-task learning with\n  extractive summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extractive summarization and imbalanced multi-label classification often\nrequire vast amounts of training data to avoid overfitting. In situations where\ntraining data is expensive to generate, leveraging information between tasks is\nan attractive approach to increasing the amount of available information. This\npaper employs multi-task training of an extractive summarizer and an RNN-based\nclassifier to improve summarization and classification accuracy by 50% and 75%,\nrespectively, relative to RNN baselines. We hypothesize that concatenating\nsentence encodings based on document and class context increases\ngeneralizability for highly variable corpuses.\n", "versions": [{"version": "v1", "created": "Sat, 16 Mar 2019 17:31:29 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Brandt", "John", ""]]}, {"id": "1903.07037", "submitter": "Ido Cohn", "authors": "Ido Cohn, Itay Laish, Genady Beryozkin, Gang Li, Izhak Shafran, Idan\n  Szpektor, Tzvika Hartman, Avinatan Hassidim, Yossi Matias", "title": "Audio De-identification: A New Entity Recognition Task", "comments": "Accepted to NAACL 2019 Industry Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Named Entity Recognition (NER) has been mostly studied in the context of\nwritten text. Specifically, NER is an important step in de-identification\n(de-ID) of medical records, many of which are recorded conversations between a\npatient and a doctor. In such recordings, audio spans with personal information\nshould be redacted, similar to the redaction of sensitive character spans in\nde-ID for written text. The application of NER in the context of audio\nde-identification has yet to be fully investigated. To this end, we define the\ntask of audio de-ID, in which audio spans with entity mentions should be\ndetected. We then present our pipeline for this task, which involves Automatic\nSpeech Recognition (ASR), NER on the transcript text, and text-to-audio\nalignment. Finally, we introduce a novel metric for audio de-ID and a new\nevaluation benchmark consisting of a large labeled segment of the Switchboard\nand Fisher audio datasets and detail our pipeline's results on it.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 07:07:44 GMT"}, {"version": "v2", "created": "Sun, 5 May 2019 06:36:02 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Cohn", "Ido", ""], ["Laish", "Itay", ""], ["Beryozkin", "Genady", ""], ["Li", "Gang", ""], ["Shafran", "Izhak", ""], ["Szpektor", "Idan", ""], ["Hartman", "Tzvika", ""], ["Hassidim", "Avinatan", ""], ["Matias", "Yossi", ""]]}, {"id": "1903.07091", "submitter": "Naveen Arivazhagan", "authors": "Naveen Arivazhagan, Ankur Bapna, Orhan Firat, Roee Aharoni, Melvin\n  Johnson, Wolfgang Macherey", "title": "The Missing Ingredient in Zero-Shot Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual Neural Machine Translation (NMT) models are capable of\ntranslating between multiple source and target languages. Despite various\napproaches to train such models, they have difficulty with zero-shot\ntranslation: translating between language pairs that were not together seen\nduring training. In this paper we first diagnose why state-of-the-art\nmultilingual NMT models that rely purely on parameter sharing, fail to\ngeneralize to unseen language pairs. We then propose auxiliary losses on the\nNMT encoder that impose representational invariance across languages. Our\nsimple approach vastly improves zero-shot translation quality without\nregressing on supervised directions. For the first time, on WMT14\nEnglish-FrenchGerman, we achieve zero-shot performance that is on par with\npivoting. We also demonstrate the easy scalability of our approach to multiple\nlanguages on the IWSLT 2017 shared task.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 14:01:53 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Arivazhagan", "Naveen", ""], ["Bapna", "Ankur", ""], ["Firat", "Orhan", ""], ["Aharoni", "Roee", ""], ["Johnson", "Melvin", ""], ["Macherey", "Wolfgang", ""]]}, {"id": "1903.07113", "submitter": "Anthony Tomasic", "authors": "Bhavya Karki and Fan Hu and Nithin Haridas and Suhail Barot and Zihua\n  Liu and Lucile Callebert and Matthias Grabmair and Anthony Tomasic", "title": "Question Answering via Web Extracted Tables and Pipelined Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe a dataset and baseline result for a question\nanswering that utilizes web tables. It contains commonly asked questions on the\nweb and their corresponding answers found in tables on websites. Our dataset is\nnovel in that every question is paired with a table of a different signature.\nIn particular, the dataset contains two classes of tables: entity-instance\ntables and the key-value tables. Each QA instance comprises a table of either\nkind, a natural language question, and a corresponding structured SQL query. We\nbuild our model by dividing question answering into several tasks, including\ntable retrieval and question element classification, and conduct experiments to\nmeasure the performance of each task. We extract various features specific to\neach task and compose a full pipeline which constructs the SQL query from its\nparts. Our work provides qualitative results and error analysis for each task,\nand identifies in detail the reasoning required to generate SQL expressions\nfrom natural language questions. This analysis of reasoning informs future\nmodels based on neural machine learning.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 15:46:05 GMT"}, {"version": "v2", "created": "Tue, 16 Apr 2019 03:07:49 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Karki", "Bhavya", ""], ["Hu", "Fan", ""], ["Haridas", "Nithin", ""], ["Barot", "Suhail", ""], ["Liu", "Zihua", ""], ["Callebert", "Lucile", ""], ["Grabmair", "Matthias", ""], ["Tomasic", "Anthony", ""]]}, {"id": "1903.07137", "submitter": "Wenlin Wang", "authors": "Wenlin Wang, Zhe Gan, Hongteng Xu, Ruiyi Zhang, Guoyin Wang, Dinghan\n  Shen, Changyou Chen, Lawrence Carin", "title": "Topic-Guided Variational Autoencoders for Text Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a topic-guided variational autoencoder (TGVAE) model for text\ngeneration. Distinct from existing variational autoencoder (VAE) based\napproaches, which assume a simple Gaussian prior for the latent code, our model\nspecifies the prior as a Gaussian mixture model (GMM) parametrized by a neural\ntopic module. Each mixture component corresponds to a latent topic, which\nprovides guidance to generate sentences under the topic. The neural topic\nmodule and the VAE-based neural sequence module in our model are learned\njointly. In particular, a sequence of invertible Householder transformations is\napplied to endow the approximate posterior of the latent code with high\nflexibility during model inference. Experimental results show that our TGVAE\noutperforms alternative approaches on both unconditional and conditional text\ngeneration, which can generate semantically-meaningful sentences with various\ntopics.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 17:42:29 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Wang", "Wenlin", ""], ["Gan", "Zhe", ""], ["Xu", "Hongteng", ""], ["Zhang", "Ruiyi", ""], ["Wang", "Guoyin", ""], ["Shen", "Dinghan", ""], ["Chen", "Changyou", ""], ["Carin", "Lawrence", ""]]}, {"id": "1903.07161", "submitter": "Matteo Grella", "authors": "Matteo Grella", "title": "Technical notes: Syntax-aware Representation Learning With Pointer\n  Networks", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a work-in-progress report, which aims to share preliminary results of\na novel sequence-to-sequence schema for dependency parsing that relies on a\ncombination of a BiLSTM and two Pointer Networks (Vinyals et al., 2015), in\nwhich the final softmax function has been replaced with the logistic\nregression. The two pointer networks co-operate to develop a latent syntactic\nknowledge, by learning the lexical properties of \"selection\" and the lexical\nproperties of \"selectability\", respectively. At the moment and without\nfine-tuning, the parser implementation gets a UAS of 93.14% on the English\nPenn-treebank (Marcus et al., 1993) annotated with Stanford Dependencies: 2-3%\nunder the SOTA but yet attractive as a baseline of the approach.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 20:26:56 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Grella", "Matteo", ""]]}, {"id": "1903.07288", "submitter": "Mahidhar Dwarampudi", "authors": "Mahidhar Dwarampudi, N V Subba Reddy", "title": "Effects of padding on LSTMs and CNNs", "comments": "5 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Long Short-Term Memory (LSTM) Networks and Convolutional Neural Networks\n(CNN) have become very common and are used in many fields as they were\neffective in solving many problems where the general neural networks were\ninefficient. They were applied to various problems mostly related to images and\nsequences. Since LSTMs and CNNs take inputs of the same length and dimension,\ninput images and sequences are padded to maximum length while testing and\ntraining. This padding can affect the way the networks function and can make a\ngreat deal when it comes to performance and accuracies. This paper studies this\nand suggests the best way to pad an input sequence. This paper uses a simple\nsentiment analysis task for this purpose. We use the same dataset on both the\nnetworks with various padding to show the difference. This paper also discusses\nsome preprocessing techniques done on the data to ensure effective analysis of\nthe data.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 07:52:59 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Dwarampudi", "Mahidhar", ""], ["Reddy", "N V Subba", ""]]}, {"id": "1903.07319", "submitter": "Jing Li", "authors": "Jichuan Zeng, Jing Li, Yulan He, Cuiyun Gao, Michael R. Lyu, Irwin\n  King", "title": "What You Say and How You Say it: Joint Modeling of Topics and Discourse\n  in Microblog Conversations", "comments": "Accepted in Transactions of the Association for Computational\n  Linguistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an unsupervised framework for jointly modeling topic\ncontent and discourse behavior in microblog conversations. Concretely, we\npropose a neural model to discover word clusters indicating what a conversation\nconcerns (i.e., topics) and those reflecting how participants voice their\nopinions (i.e., discourse). Extensive experiments show that our model can yield\nboth coherent topics and meaningful discourse behavior. Further study shows\nthat our topic and discourse representations can benefit the classification of\nmicroblog messages, especially when they are jointly trained with the\nclassifier.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 09:21:30 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Zeng", "Jichuan", ""], ["Li", "Jing", ""], ["He", "Yulan", ""], ["Gao", "Cuiyun", ""], ["Lyu", "Michael R.", ""], ["King", "Irwin", ""]]}, {"id": "1903.07389", "submitter": "Hamid Karimi", "authors": "Hamid Karimi and Jiliang Tang", "title": "Learning Hierarchical Discourse-level Structure for Fake News Detection", "comments": "Accepted to 2019 Annual Conference of the North American Chapter of\n  the Association for Computational Linguistics June 2-7, 2019 Minneapolis, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  On the one hand, nowadays, fake news articles are easily propagated through\nvarious online media platforms and have become a grand threat to the\ntrustworthiness of information. On the other hand, our understanding of the\nlanguage of fake news is still minimal. Incorporating hierarchical\ndiscourse-level structure of fake and real news articles is one crucial step\ntoward a better understanding of how these articles are structured.\nNevertheless, this has rarely been investigated in the fake news detection\ndomain and faces tremendous challenges. First, existing methods for capturing\ndiscourse-level structure rely on annotated corpora which are not available for\nfake news datasets. Second, how to extract out useful information from such\ndiscovered structures is another challenge. To address these challenges, we\npropose Hierarchical Discourse-level Structure for Fake news detection. HDSF\nlearns and constructs a discourse-level structure for fake/real news articles\nin an automated and data-driven manner. Moreover, we identify insightful\nstructure-related properties, which can explain the discovered structures and\nboost our understating of fake news. Conducted experiments show the\neffectiveness of the proposed approach. Further structural analysis suggests\nthat real and fake news present substantial differences in the hierarchical\ndiscourse-level structures.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 00:03:17 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2019 01:15:14 GMT"}, {"version": "v3", "created": "Tue, 2 Apr 2019 16:18:00 GMT"}, {"version": "v4", "created": "Thu, 4 Apr 2019 02:38:36 GMT"}, {"version": "v5", "created": "Fri, 5 Apr 2019 17:39:05 GMT"}, {"version": "v6", "created": "Wed, 10 Apr 2019 14:20:53 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Karimi", "Hamid", ""], ["Tang", "Jiliang", ""]]}, {"id": "1903.07395", "submitter": "Nicholas Cummins Dr", "authors": "Thomas Wiest, Nicholas Cummins, Alice Baird, Simone Hantke, Judith\n  Dineley, Bj\\\"orn Schuller", "title": "Voice command generation using Progressive Wavegans", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have become exceedingly popular in a\nwide range of data-driven research fields, due in part to their success in\nimage generation. Their ability to generate new samples, often from only a\nsmall amount of input data, makes them an exciting research tool in areas with\nlimited data resources. One less-explored application of GANs is the synthesis\nof speech and audio samples. Herein, we propose a set of extensions to the\nWaveGAN paradigm, a recently proposed approach for sound generation using GANs.\nThe aim of these extensions - preprocessing, Audio-to-Audio generation, skip\nconnections and progressive structures - is to improve the human likeness of\nsynthetic speech samples. Scores from listening tests with 30 volunteers\ndemonstrated a moderate improvement (Cohen's d coefficient of 0.65) in human\nlikeness using the proposed extensions compared to the original WaveGAN\napproach.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 18:43:31 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Wiest", "Thomas", ""], ["Cummins", "Nicholas", ""], ["Baird", "Alice", ""], ["Hantke", "Simone", ""], ["Dineley", "Judith", ""], ["Schuller", "Bj\u00f6rn", ""]]}, {"id": "1903.07397", "submitter": "Juan-Manuel Torres-Moreno", "authors": "Marc El-B\\`eze, Juan-Manuel Torres-Moreno, Fr\\'ed\\'eric B\\'echet", "title": "Un duel probabiliste pour d\\'epartager deux pr\\'esidents (LIA @\n  DEFT'2005)", "comments": "27 figures, 1 table (in French)", "journal-ref": "RNTI (E10)776:1889-1918, 2007", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a set of probabilistic models applied to binary classification as\ndefined in the DEFT'05 challenge. The challenge consisted a mixture of two\ndifferents problems in Natural Language Processing : identification of author\n(a sequence of Fran\\c{c}ois Mitterrand's sentences might have been inserted\ninto a speech of Jacques Chirac) and thematic break detection (the subjects\naddressed by the two authors are supposed to be different). Markov chains,\nBayes models and an adaptative process have been used to identify the paternity\nof these sequences. A probabilistic model of the internal coherence of speeches\nwhich has been employed to identify thematic breaks. Adding this model has\nshown to improve the quality results. A comparison with different approaches\ndemostrates the superiority of a strategy that combines learning, coherence and\nadaptation. Applied to the DEFT'05 data test the results in terms of precision\n(0.890), recall (0.955) and Fscore (0.925) measure are very promising.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 11:02:24 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["El-B\u00e8ze", "Marc", ""], ["Torres-Moreno", "Juan-Manuel", ""], ["B\u00e9chet", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "1903.07398", "submitter": "Gary Wang", "authors": "Gary Wang", "title": "Deep Text-to-Speech System with Seq2Seq Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent trends in neural network based text-to-speech/speech synthesis\npipelines have employed recurrent Seq2seq architectures that can synthesize\nrealistic sounding speech directly from text characters. These systems however\nhave complex architectures and takes a substantial amount of time to train. We\nintroduce several modifications to these Seq2seq architectures that allow for\nfaster training time, and also allows us to reduce the complexity of the model\narchitecture at the same time. We show that our proposed model can achieve\nattention alignment much faster than previous architectures and that good audio\nquality can be achieved with a model that's much smaller in size. Sample audio\navailable at https://soundcloud.com/gary-wang-23/sets/tts-samples-for-cmpt-419.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 18:18:38 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Wang", "Gary", ""]]}, {"id": "1903.07402", "submitter": "Hongfei Xu", "authors": "Hongfei Xu and Qiuhui Liu", "title": "Neutron: An Implementation of the Transformer Translation Model and its\n  Variants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Transformer translation model is easier to parallelize and provides\nbetter performance compared to recurrent seq2seq models, which makes it popular\namong industry and research community. We implement the Neutron in this work,\nincluding the Transformer model and its several variants from most recent\nresearches. It is highly optimized, easy to modify and provides comparable\nperformance with interesting features while keeping readability.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 12:54:22 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 12:21:06 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Xu", "Hongfei", ""], ["Liu", "Qiuhui", ""]]}, {"id": "1903.07406", "submitter": "Shivam Kalra", "authors": "Shivam Kalra, Larry Li, Hamid R. Tizhoosh", "title": "Automatic Classification of Pathology Reports using TF-IDF Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Pathology report is arguably one of the most important documents in\nmedicine containing interpretive information about the visual findings from the\npatient's biopsy sample. Each pathology report has a retention period of up to\n20 years after the treatment of a patient. Cancer registries process and encode\nhigh volumes of free-text pathology reports for surveillance of cancer and\ntumor diseases all across the world. In spite of their extremely valuable\ninformation they hold, pathology reports are not used in any systematic way to\nfacilitate computational pathology. Therefore, in this study, we investigate\nautomated machine-learning techniques to identify/predict the primary diagnosis\n(based on ICD-O code) from pathology reports. We performed experiments by\nextracting the TF-IDF features from the reports and classifying them using\nthree different methods---SVM, XGBoost, and Logistic Regression. We constructed\na new dataset with 1,949 pathology reports arranged into 37 ICD-O categories,\ncollected from four different primary sites, namely lung, kidney, thymus, and\ntestis. The reports were manually transcribed into text format after collecting\nthem as PDF files from NCI Genomic Data Commons public dataset. We subsequently\npre-processed the reports by removing irrelevant textual artifacts produced by\nOCR software. The highest classification accuracy we achieved was 92\\% using\nXGBoost classifier on TF-IDF feature vectors, the linear SVM scored 87\\%\naccuracy. Furthermore, the study shows that TF-IDF vectors are suitable for\nhighlighting the important keywords within a report which can be helpful for\nthe cancer research and diagnostic workflow. The results are encouraging in\ndemonstrating the potential of machine learning methods for classification and\nencoding of pathology reports.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 09:11:53 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Kalra", "Shivam", ""], ["Li", "Larry", ""], ["Tizhoosh", "Hamid R.", ""]]}, {"id": "1903.07416", "submitter": "Ernesto Est\\'evez-Rams", "authors": "E. Estevez-Rams, A. Mesa Rodriguez and D. Estevez-Moya", "title": "Complexity-entropy analysis at different levels of organization in\n  written language", "comments": null, "journal-ref": "PLOS ONE, 2019, https://doi.org/10.1371/journal.pone.0214863", "doi": "10.1371/journal.pone.0214863", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Written language is complex. A written text can be considered an attempt to\nconvey a meaningful message which ends up being constrained by language rules,\ncontext dependence and highly redundant in its use of resources. Despite all\nthese constraints, unpredictability is an essential element of natural\nlanguage. Here we present the use of entropic measures to assert the balance\nbetween predictability and surprise in written text. In short, it is possible\nto measure innovation and context preservation in a document. It is shown that\nthis can also be done at the different levels of organization of a text. The\ntype of analysis presented is reasonably general, and can also be used to\nanalyze the same balance in other complex messages such as DNA, where a\nhierarchy of organizational levels are known to exist.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 02:56:03 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Estevez-Rams", "E.", ""], ["Rodriguez", "A. Mesa", ""], ["Estevez-Moya", "D.", ""]]}, {"id": "1903.07435", "submitter": "Yair Lakretz", "authors": "Yair Lakretz, German Kruszewski, Theo Desbordes, Dieuwke Hupkes,\n  Stanislas Dehaene and Marco Baroni", "title": "The emergence of number and syntax units in LSTM language models", "comments": "To appear in Proceedings of NAACL, Minneapolis, MN, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that LSTMs trained on a generic language modeling\nobjective capture syntax-sensitive generalizations such as long-distance number\nagreement. We have however no mechanistic understanding of how they accomplish\nthis remarkable feat. Some have conjectured it depends on heuristics that do\nnot truly take hierarchical structure into account. We present here a detailed\nstudy of the inner mechanics of number tracking in LSTMs at the single neuron\nlevel. We discover that long-distance number information is largely managed by\ntwo `number units'. Importantly, the behaviour of these units is partially\ncontrolled by other units independently shown to track syntactic structure. We\nconclude that LSTMs are, to some extent, implementing genuinely syntactic\nprocessing mechanisms, paving the way to a more general understanding of\ngrammatical encoding in LSTMs.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 13:38:54 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 12:49:36 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Lakretz", "Yair", ""], ["Kruszewski", "German", ""], ["Desbordes", "Theo", ""], ["Hupkes", "Dieuwke", ""], ["Dehaene", "Stanislas", ""], ["Baroni", "Marco", ""]]}, {"id": "1903.07445", "submitter": "Harrison Uglow", "authors": "Harrison Uglow, Martin Zlocha, Szymon Zmy\\'slony", "title": "An Exploration of State-of-the-art Methods for Offensive Language\n  Detection", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a comprehensive investigation of different custom and\noff-the-shelf architectures as well as different approaches to generating\nfeature vectors for offensive language detection. We also show that these\napproaches work well on small and noisy datasets such as on the Offensive\nLanguage Identification Dataset (OLID), so it should be possible to use them\nfor other applications.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 13:05:23 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2019 17:53:30 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Uglow", "Harrison", ""], ["Zlocha", "Martin", ""], ["Zmy\u015blony", "Szymon", ""]]}, {"id": "1903.07507", "submitter": "Ishan Jindal", "authors": "Ishan Jindal, Daniel Pressel, Brian Lester, Matthew Nokleby", "title": "An Effective Label Noise Model for DNN Text Classification", "comments": "Accepted at NAACL-HLT 2019 Main Conference Long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Because large, human-annotated datasets suffer from labeling errors, it is\ncrucial to be able to train deep neural networks in the presence of label\nnoise. While training image classification models with label noise have\nreceived much attention, training text classification models have not. In this\npaper, we propose an approach to training deep networks that is robust to label\nnoise. This approach introduces a non-linear processing layer (noise model)\nthat models the statistics of the label noise into a convolutional neural\nnetwork (CNN) architecture. The noise model and the CNN weights are learned\njointly from noisy training data, which prevents the model from overfitting to\nerroneous labels. Through extensive experiments on several text classification\ndatasets, we show that this approach enables the CNN to learn better sentence\nrepresentations and is robust even to extreme label noise. We find that proper\ninitialization and regularization of this noise model is critical. Further, by\ncontrast to results focusing on large batch sizes for mitigating label noise\nfor image classification, we find that altering the batch size does not have\nmuch effect on classification performance.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 15:27:50 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Jindal", "Ishan", ""], ["Pressel", "Daniel", ""], ["Lester", "Brian", ""], ["Nokleby", "Matthew", ""]]}, {"id": "1903.07588", "submitter": "Amr Amr", "authors": "Amr Adel Helmy", "title": "A Multilingual Encoding Method for Text Classification and Dialect\n  Identification Using Convolutional Neural Network", "comments": "A dissertation submitted to the AASTMT on February 2019 in partial\n  fulfillment of the requirements for the degree of Master of Science in\n  Computer Science. arXiv admin note: text overlap with arXiv:1807.10854 by\n  other authors without attribution", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis presents a language-independent text classification model by\nintroduced two new encoding methods \"BUNOW\" and \"BUNOC\" used for feeding the\nraw text data into a new CNN spatial architecture with vertical and horizontal\nconvolutional process instead of commonly used methods like one hot vector or\nword representation (i.e. word2vec) with temporal CNN architecture. The\nproposed model can be classified as hybrid word-character model in its work\nmethodology because it consumes less memory space by using a fewer neural\nnetwork parameters as in character level representation, in addition to\nproviding much faster computations with fewer network layers depth, as in word\nlevel representation. A promising result achieved compared to state of art\nmodels in two different morphological benchmarked dataset one for Arabic\nlanguage and one for English language.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 17:31:14 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Helmy", "Amr Adel", ""]]}, {"id": "1903.07666", "submitter": "Bhaskar Mitra", "authors": "Bhaskar Mitra and Nick Craswell", "title": "An Updated Duet Model for Passage Re-ranking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose several small modifications to Duet---a deep neural ranking\nmodel---and evaluate the updated model on the MS MARCO passage ranking task. We\nreport significant improvements from the proposed changes based on an ablation\nstudy.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 18:44:07 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Mitra", "Bhaskar", ""], ["Craswell", "Nick", ""]]}, {"id": "1903.07766", "submitter": "Devi Parikh", "authors": "X. Alice Li and Devi Parikh", "title": "Lemotif: An Affective Visual Journal Using Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Lemotif, an integrated natural language processing and image\ngeneration system that uses machine learning to (1) parse a text-based input\njournal entry describing the user's day for salient themes and emotions and (2)\nvisualize the detected themes and emotions in creative and appealing image\nmotifs. Synthesizing approaches from artificial intelligence and psychology,\nLemotif acts as an affective visual journal, encouraging users to regularly\nwrite and reflect on their daily experiences through visual reinforcement. By\nmaking patterns in emotions and their sources more apparent, Lemotif aims to\nhelp users better understand their emotional lives, identify opportunities for\naction, and track the effectiveness of behavioral changes over time. We verify\nvia human studies that prospective users prefer motifs generated by Lemotif\nover corresponding baselines, find the motifs representative of their journal\nentries, and think they would be more likely to journal regularly using a\nLemotif-based app.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 23:35:31 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 16:21:41 GMT"}, {"version": "v3", "created": "Wed, 1 Apr 2020 16:48:35 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Li", "X. Alice", ""], ["Parikh", "Devi", ""]]}, {"id": "1903.07785", "submitter": "Michael Auli", "authors": "Alexei Baevski, Sergey Edunov, Yinhan Liu, Luke Zettlemoyer, Michael\n  Auli", "title": "Cloze-driven Pretraining of Self-attention Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach for pretraining a bi-directional transformer model\nthat provides significant performance gains across a variety of language\nunderstanding problems. Our model solves a cloze-style word reconstruction\ntask, where each word is ablated and must be predicted given the rest of the\ntext. Experiments demonstrate large performance gains on GLUE and new state of\nthe art results on NER as well as constituency parsing benchmarks, consistent\nwith the concurrently introduced BERT model. We also present a detailed\nanalysis of a number of factors that contribute to effective pretraining,\nincluding data domain and size, model capacity, and variations on the cloze\nobjective.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 01:19:06 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Baevski", "Alexei", ""], ["Edunov", "Sergey", ""], ["Liu", "Yinhan", ""], ["Zettlemoyer", "Luke", ""], ["Auli", "Michael", ""]]}, {"id": "1903.07860", "submitter": "Guangneng Hu", "authors": "Guangneng Hu", "title": "Personalized Neural Embeddings for Collaborative Filtering with Text", "comments": "NAACL 2019 short papers, oral presentation", "journal-ref": "NAACL 2019", "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative filtering (CF) is a core technique for recommender systems.\nTraditional CF approaches exploit user-item relations (e.g., clicks, likes, and\nviews) only and hence they suffer from the data sparsity issue. Items are\nusually associated with unstructured text such as article abstracts and product\nreviews. We develop a Personalized Neural Embedding (PNE) framework to exploit\nboth interactions and words seamlessly. We learn such embeddings of users,\nitems, and words jointly, and predict user preferences on items based on these\nlearned representations. PNE estimates the probability that a user will like an\nitem by two terms---behavior factors and semantic factors. On two real-world\ndatasets, PNE shows better performance than four state-of-the-art baselines in\nterms of three metrics. We also show that PNE learns meaningful word embeddings\nby visualization.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 07:05:59 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Hu", "Guangneng", ""]]}, {"id": "1903.07879", "submitter": "Xavier Tannier", "authors": "Xavier Tannier, Nicolas Paris, Hugo Cisneros, Christel Daniel,\n  Matthieu Doutreligne, Catherine Duclos, Nicolas Griffon, Claire\n  Hassen-Khodja, Ivan Lerner, Adrien Parrot, \\'Eric Sadou, Cyrina Saussol,\n  Pascal Vaillant", "title": "Hybrid Approaches for our Participation to the n2c2 Challenge on Cohort\n  Selection for Clinical Trials", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: Natural language processing can help minimize human intervention\nin identifying patients meeting eligibility criteria for clinical trials, but\nthere is still a long way to go to obtain a general and systematic approach\nthat is useful for researchers. We describe two methods taking a step in this\ndirection and present their results obtained during the n2c2 challenge on\ncohort selection for clinical trials. Materials and Methods: The first method\nis a weakly supervised method using an unlabeled corpus (MIMIC) to build a\nsilver standard, by producing semi-automatically a small and very precise set\nof rules to detect some samples of positive and negative patients. This silver\nstandard is then used to train a traditional supervised model. The second\nmethod is a terminology-based approach where a medical expert selects the\nappropriate concepts, and a procedure is defined to search the terms and check\nthe structural or temporal constraints. Results: On the n2c2 dataset containing\nannotated data about 13 selection criteria on 288 patients, we obtained an\noverall F1-measure of 0.8969, which is the third best result out of 45\nparticipant teams, with no statistically significant difference with the\nbest-ranked team. Discussion: Both approaches obtained very encouraging results\nand apply to different types of criteria. The weakly supervised method requires\nexplicit descriptions of positive and negative examples in some reports. The\nterminology-based method is very efficient when medical concepts carry most of\nthe relevant information. Conclusion: It is unlikely that much more annotated\ndata will be soon available for the task of identifying a wide range of patient\nphenotypes. One must focus on weakly or non-supervised learning methods using\nboth structured and unstructured data and relying on a comprehensive\nrepresentation of the patients.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 08:37:04 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 07:37:26 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Tannier", "Xavier", ""], ["Paris", "Nicolas", ""], ["Cisneros", "Hugo", ""], ["Daniel", "Christel", ""], ["Doutreligne", "Matthieu", ""], ["Duclos", "Catherine", ""], ["Griffon", "Nicolas", ""], ["Hassen-Khodja", "Claire", ""], ["Lerner", "Ivan", ""], ["Parrot", "Adrien", ""], ["Sadou", "\u00c9ric", ""], ["Saussol", "Cyrina", ""], ["Vaillant", "Pascal", ""]]}, {"id": "1903.07917", "submitter": "Jerin Philip", "authors": "Jerin Philip, Vinay P. Namboodiri and C.V. Jawahar", "title": "CVIT-MT Systems for WAT-2018", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document describes the machine translation system used in the\nsubmissions of IIIT-Hyderabad CVIT-MT for the WAT-2018 English-Hindi\ntranslation task. Performance is evaluated on the associated corpus provided by\nthe organizers. We experimented with convolutional sequence to sequence\narchitectures. We also train with additional data obtained through\nbacktranslation.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 10:18:57 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Philip", "Jerin", ""], ["Namboodiri", "Vinay P.", ""], ["Jawahar", "C. V.", ""]]}, {"id": "1903.07926", "submitter": "Graham Neubig", "authors": "Graham Neubig, Zi-Yi Dou, Junjie Hu, Paul Michel, Danish Pruthi, Xinyi\n  Wang and John Wieting", "title": "compare-mt: A Tool for Holistic Comparison of Language Generation\n  Systems", "comments": "Updated and longer version of NAACL 2019 Demo Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe compare-mt, a tool for holistic analysis and\ncomparison of the results of systems for language generation tasks such as\nmachine translation. The main goal of the tool is to give the user a high-level\nand coherent view of the salient differences between systems that can then be\nused to guide further analysis or system improvement. It implements a number of\ntools to do so, such as analysis of accuracy of generation of particular types\nof words, bucketed histograms of sentence accuracies or counts based on salient\ncharacteristics, and extraction of characteristic $n$-grams for each system. It\nalso has a number of advanced features such as use of linguistic labels, source\nside data, or comparison of log likelihoods for probabilistic models, and also\naims to be easily extensible by users to new types of analysis. The code is\navailable at https://github.com/neulab/compare-mt\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 10:40:23 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 08:31:38 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Neubig", "Graham", ""], ["Dou", "Zi-Yi", ""], ["Hu", "Junjie", ""], ["Michel", "Paul", ""], ["Pruthi", "Danish", ""], ["Wang", "Xinyi", ""], ["Wieting", "John", ""]]}, {"id": "1903.08097", "submitter": "Alessandra Cervone", "authors": "Alessandra Cervone, Chandra Khatri, Rahul Goel, Behnam Hedayatnia, Anu\n  Venkatesh, Dilek Hakkani-Tur, Raefer Gabriel", "title": "Natural Language Generation at Scale: A Case Study for Open Domain\n  Question Answering", "comments": "Accepted to INLG 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current approaches to Natural Language Generation (NLG) for dialog mainly\nfocus on domain-specific, task-oriented applications (e.g. restaurant booking)\nusing limited ontologies (up to 20 slot types), usually without considering the\nprevious conversation context. Furthermore, these approaches require large\namounts of data for each domain, and do not benefit from examples that may be\navailable for other domains. This work explores the feasibility of applying\nstatistical NLG to scenarios requiring larger ontologies, such as multi-domain\ndialog applications or open-domain question answering (QA) based on knowledge\ngraphs. We model NLG through an Encoder-Decoder framework using a large dataset\nof interactions between real-world users and a conversational agent for\nopen-domain QA. First, we investigate the impact of increasing the number of\nslot types on the generation quality and experiment with different partitions\nof the QA data with progressively larger ontologies (up to 369 slot types).\nSecond, we perform multi-task learning experiments between open-domain QA and\ntask-oriented dialog, and benchmark our model on a popular NLG dataset.\nMoreover, we experiment with using the conversational context as an additional\ninput to improve response generation quality. Our experiments show the\nfeasibility of learning statistical NLG models for open-domain QA with larger\nontologies.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 16:35:29 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 21:25:39 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Cervone", "Alessandra", ""], ["Khatri", "Chandra", ""], ["Goel", "Rahul", ""], ["Hedayatnia", "Behnam", ""], ["Venkatesh", "Anu", ""], ["Hakkani-Tur", "Dilek", ""], ["Gabriel", "Raefer", ""]]}, {"id": "1903.08206", "submitter": "Rafael S. Gon\\c{c}alves", "authors": "Rafael S. Gon\\c{c}alves, Maulik R. Kamdar, and Mark A. Musen", "title": "Aligning Biomedical Metadata with Ontologies Using Clustering and\n  Embeddings", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-21348-0_10", "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The metadata about scientific experiments published in online repositories\nhave been shown to suffer from a high degree of representational\nheterogeneity---there are often many ways to represent the same type of\ninformation, such as a geographical location via its latitude and longitude. To\nharness the potential that metadata have for discovering scientific data, it is\ncrucial that they be represented in a uniform way that can be queried\neffectively. One step toward uniformly-represented metadata is to normalize the\nmultiple, distinct field names used in metadata (e.g., lat lon, lat and long)\nto describe the same type of value. To that end, we present a new method based\non clustering and embeddings (i.e., vector representations of words) to align\nmetadata field names with ontology terms. We apply our method to biomedical\nmetadata by generating embeddings for terms in biomedical ontologies from the\nBioPortal repository. We carried out a comparative study between our method and\nthe NCBO Annotator, which revealed that our method yields more and\nsubstantially better alignments between metadata and ontology terms.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 18:31:23 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 20:23:54 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Gon\u00e7alves", "Rafael S.", ""], ["Kamdar", "Maulik R.", ""], ["Musen", "Mark A.", ""]]}, {"id": "1903.08237", "submitter": "Judith Degen", "authors": "Judith Degen, Robert D. Hawkins, Caroline Graf, Elisa Kreiss, Noah D.\n  Goodman", "title": "When redundancy is useful: A Bayesian approach to 'overinformative'\n  referring expressions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Referring is one of the most basic and prevalent uses of language. How do\nspeakers choose from the wealth of referring expressions at their disposal?\nRational theories of language use have come under attack for decades for not\nbeing able to account for the seemingly irrational overinformativeness\nubiquitous in referring expressions. Here we present a novel production model\nof referring expressions within the Rational Speech Act framework that treats\nspeakers as agents that rationally trade off cost and informativeness of\nutterances. Crucially, we relax the assumption that informativeness is computed\nwith respect to a deterministic Boolean semantics, in favor of a\nnon-deterministic continuous semantics. This innovation allows us to capture a\nlarge number of seemingly disparate phenomena within one unified framework: the\nbasic asymmetry in speakers' propensity to overmodify with color rather than\nsize; the increase in overmodification in complex scenes; the increase in\novermodification with atypical features; and the increase in specificity in\nnominal reference as a function of typicality. These findings cast a new light\non the production of referring expressions: rather than being wastefully\noverinformative, reference is usefully redundant.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 19:49:12 GMT"}, {"version": "v2", "created": "Sat, 14 Sep 2019 04:30:28 GMT"}, {"version": "v3", "created": "Tue, 10 Dec 2019 07:35:06 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Degen", "Judith", ""], ["Hawkins", "Robert D.", ""], ["Graf", "Caroline", ""], ["Kreiss", "Elisa", ""], ["Goodman", "Noah D.", ""]]}, {"id": "1903.08268", "submitter": "Arshit Gupta", "authors": "Arshit Gupta, John Hewitt and Katrin Kirchhoff", "title": "Simple, Fast, Accurate Intent Classification and Slot Labeling for\n  Goal-Oriented Dialogue Systems", "comments": "SIGDIAL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of conversational assistants, like Amazon Alexa, Google Now,\netc., dialogue systems are gaining a lot of traction, especially in industrial\nsetting. These systems typically consist of Spoken Language understanding\ncomponent which, in turn, consists of two tasks - Intent Classification (IC)\nand Slot Labeling (SL). Generally, these two tasks are modeled together jointly\nto achieve best performance. However, this joint modeling adds to model\nobfuscation. In this work, we first design framework for a modularization of\njoint IC-SL task to enhance architecture transparency. Then, we explore a\nnumber of self-attention, convolutional, and recurrent models, contributing a\nlarge-scale analysis of modeling paradigms for IC+SL across two datasets.\nFinally, using this framework, we propose a class of 'label-recurrent' models\nthat otherwise non-recurrent, with a 10-dimensional representation of the label\nhistory, and show that our proposed systems are easy to interpret, highly\naccurate (achieving over 30% error reduction in SL over the state-of-the-art on\nthe Snips dataset), as well as fast, at 2x the inference and 2/3 to 1/2 the\ntraining time of comparable recurrent models, thus giving an edge in critical\nreal-world systems.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 21:58:24 GMT"}, {"version": "v2", "created": "Wed, 17 Jul 2019 18:26:36 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Gupta", "Arshit", ""], ["Hewitt", "John", ""], ["Kirchhoff", "Katrin", ""]]}, {"id": "1903.08309", "submitter": "Chris Paxton", "authors": "Chris Paxton, Yonatan Bisk, Jesse Thomason, Arunkumar Byravan, Dieter\n  Fox", "title": "Prospection: Interpretable Plans From Language By Predicting the Future", "comments": "Accepted to ICRA 2019; extended version with appendix containing\n  additional results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-level human instructions often correspond to behaviors with multiple\nimplicit steps. In order for robots to be useful in the real world, they must\nbe able to to reason over both motions and intermediate goals implied by human\ninstructions. In this work, we propose a framework for learning representations\nthat convert from a natural-language command to a sequence of intermediate\ngoals for execution on a robot. A key feature of this framework is prospection,\ntraining an agent not just to correctly execute the prescribed command, but to\npredict a horizon of consequences of an action before taking it. We demonstrate\nthe fidelity of plans generated by our framework when interpreting real,\ncrowd-sourced natural language commands for a robot in simulated scenes.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 01:52:37 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Paxton", "Chris", ""], ["Bisk", "Yonatan", ""], ["Thomason", "Jesse", ""], ["Byravan", "Arunkumar", ""], ["Fox", "Dieter", ""]]}, {"id": "1903.08389", "submitter": "Christina Lioma Assoc. Prof", "authors": "Dongsheng Wang, Quichi Li, Lucas Chaves Lima, Jakob grue Simonsen,\n  Christina Lioma", "title": "Contextual Compositionality Detection with External Knowledge Bases\n  andWord Embeddings", "comments": "WWW '19 Companion, May 13-17, 2019, San Francisco, CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When the meaning of a phrase cannot be inferred from the individual meanings\nof its words (e.g., hot dog), that phrase is said to be non-compositional.\nAutomatic compositionality detection in multi-word phrases is critical in any\napplication of semantic processing, such as search engines; failing to detect\nnon-compositional phrases can hurt system effectiveness notably. Existing\nresearch treats phrases as either compositional or non-compositional in a\ndeterministic manner. In this paper, we operationalize the viewpoint that\ncompositionality is contextual rather than deterministic, i.e., that whether a\nphrase is compositional or non-compositional depends on its context. For\nexample, the phrase `green card' is compositional when referring to a green\ncolored card, whereas it is non-compositional when meaning permanent residence\nauthorization. We address the challenge of detecting this type of contextual\ncompositionality as follows: given a multi-word phrase, we enrich the word\nembedding representing its semantics with evidence about its global context\n(terms it often collocates with) as well as its local context (narratives where\nthat phrase is used, which we call usage scenarios). We further extend this\nrepresentation with information extracted from external knowledge bases. The\nresulting representation incorporates both localized context and more general\nusage of the phrase and allows to detect its compositionality in a\nnon-deterministic and contextual way. Empirical evaluation of our model on a\ndataset of phrase compositionality, manually collected by crowdsourcing\ncontextual compositionality assessments, shows that our model outperforms\nstate-of-the-art baselines notably on detecting phrase compositionality.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 08:53:05 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Wang", "Dongsheng", ""], ["Li", "Quichi", ""], ["Lima", "Lucas Chaves", ""], ["Simonsen", "Jakob grue", ""], ["Lioma", "Christina", ""]]}, {"id": "1903.08404", "submitter": "Casper Hansen", "authors": "Casper Hansen, Christian Hansen, Stephen Alstrup, Jakob Grue Simonsen,\n  Christina Lioma", "title": "Neural Check-Worthiness Ranking with Weak Supervision: Finding Sentences\n  for Fact-Checking", "comments": "6 pages", "journal-ref": "In Companion Proceedings of the 2019 World Wide Web Conference", "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic fact-checking systems detect misinformation, such as fake news, by\n(i) selecting check-worthy sentences for fact-checking, (ii) gathering related\ninformation to the sentences, and (iii) inferring the factuality of the\nsentences. Most prior research on (i) uses hand-crafted features to select\ncheck-worthy sentences, and does not explicitly account for the recent finding\nthat the top weighted terms in both check-worthy and non-check-worthy sentences\nare actually overlapping [15]. Motivated by this, we present a neural\ncheck-worthiness sentence ranking model that represents each word in a sentence\nby \\textit{both} its embedding (aiming to capture its semantics) and its\nsyntactic dependencies (aiming to capture its role in modifying the semantics\nof other terms in the sentence). Our model is an end-to-end trainable neural\nnetwork for check-worthiness ranking, which is trained on large amounts of\nunlabelled data through weak supervision. Thorough experimental evaluation\nagainst state of the art baselines, with and without weak supervision, shows\nour model to be superior at all times (+13% in MAP and +28% at various\nPrecision cut-offs from the best baseline with statistical significance).\nEmpirical analysis of the use of weak supervision, word embedding pretraining\non domain-specific data, and the use of syntactic dependencies of our model\nreveals that check-worthy sentences contain notably more identical syntactic\ndependencies than non-check-worthy sentences.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 09:40:19 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Hansen", "Casper", ""], ["Hansen", "Christian", ""], ["Alstrup", "Stephen", ""], ["Simonsen", "Jakob Grue", ""], ["Lioma", "Christina", ""]]}, {"id": "1903.08445", "submitter": "Daniel Fern\\'andez-Gonz\\'alez", "authors": "Daniel Fern\\'andez-Gonz\\'alez and Carlos G\\'omez-Rodr\\'iguez", "title": "Left-to-Right Dependency Parsing with Pointer Networks", "comments": "Proceedings of NAACL 2019. 7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel transition-based algorithm that straightforwardly parses\nsentences from left to right by building $n$ attachments, with $n$ being the\nlength of the input sentence. Similarly to the recent stack-pointer parser by\nMa et al. (2018), we use the pointer network framework that, given a word, can\ndirectly point to a position from the sentence. However, our left-to-right\napproach is simpler than the original top-down stack-pointer parser (not\nrequiring a stack) and reduces transition sequence length in half, from 2$n$-1\nactions to $n$. This results in a quadratic non-projective parser that runs\ntwice as fast as the original while achieving the best accuracy to date on the\nEnglish PTB dataset (96.04% UAS, 94.43% LAS) among fully-supervised\nsingle-model dependency parsers, and improves over the former top-down\ntransition system in the majority of languages tested.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 11:19:58 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Fern\u00e1ndez-Gonz\u00e1lez", "Daniel", ""], ["G\u00f3mez-Rodr\u00edguez", "Carlos", ""]]}, {"id": "1903.08450", "submitter": "Jonggu Kim", "authors": "Jonggu Kim and Jong-Hyeok Lee", "title": "Decay-Function-Free Time-Aware Attention to Context and Speaker\n  Indicator for Spoken Language Understanding", "comments": "Accepted as a long paper at NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To capture salient contextual information for spoken language understanding\n(SLU) of a dialogue, we propose time-aware models that automatically learn the\nlatent time-decay function of the history without a manual time-decay function.\nWe also propose a method to identify and label the current speaker to improve\nthe SLU accuracy. In experiments on the benchmark dataset used in Dialog State\nTracking Challenge 4, the proposed models achieved significantly higher F1\nscores than the state-of-the-art contextual models. Finally, we analyze the\neffectiveness of the introduced models in detail. The analysis demonstrates\nthat the proposed methods were effective to improve SLU accuracy individually.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 11:28:06 GMT"}, {"version": "v2", "created": "Fri, 29 Mar 2019 03:38:17 GMT"}, {"version": "v3", "created": "Tue, 18 Jun 2019 07:13:40 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Kim", "Jonggu", ""], ["Lee", "Jong-Hyeok", ""]]}, {"id": "1903.08678", "submitter": "Ozan Caglayan", "authors": "Ozan Caglayan, Pranava Madhyastha, Lucia Specia, Lo\\\"ic Barrault", "title": "Probing the Need for Visual Context in Multimodal Machine Translation", "comments": "Accepted to NAACL-HLT 2019, reviewer comments addressed, camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current work on multimodal machine translation (MMT) has suggested that the\nvisual modality is either unnecessary or only marginally beneficial. We posit\nthat this is a consequence of the very simple, short and repetitive sentences\nused in the only available dataset for the task (Multi30K), rendering the\nsource text sufficient as context. In the general case, however, we believe\nthat it is possible to combine visual and textual information in order to\nground translations. In this paper we probe the contribution of the visual\nmodality to state-of-the-art MMT models by conducting a systematic analysis\nwhere we partially deprive the models from source-side textual context. Our\nresults show that under limited textual context, models are capable of\nleveraging the visual input to generate better translations. This contradicts\nthe current belief that MMT models disregard the visual modality because of\neither the quality of the image features or the way they are integrated into\nthe model.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 18:11:59 GMT"}, {"version": "v2", "created": "Sun, 2 Jun 2019 11:56:10 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Caglayan", "Ozan", ""], ["Madhyastha", "Pranava", ""], ["Specia", "Lucia", ""], ["Barrault", "Lo\u00efc", ""]]}, {"id": "1903.08718", "submitter": "Dafydd Gibbon", "authors": "Dafydd Gibbon", "title": "CRAFT: A multifunction online platform for speech prosody visualisation", "comments": "5 pages, 4 figures, 2 tables; ICPhS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many research tools which are also used for teaching the acoustic\nphonetics of speech rhythm and speech melody. But they were not\npurpose-designed for teaching-learning situations, and some have a steep\nlearning curve. CRAFT (Creation and Recovery of Amplitude and Frequency Tracks)\nis custom-designed as a novel flexible online tool for visualisation and\ncritical comparison of functions and transforms, with implementations of the\nReaper, RAPT, PyRapt, YAAPT, YIN and PySWIPE F0 estimators, three Praat\nconfigurations, and two purpose-built estimators, PyAMDF, S0FT. Visualisations\nof amplitude and frequency envelope spectra, spectral edge detection of rhythm\nzones, and a parametrised spectrogram are included. A selection of audio clips\nfrom tone and intonation languages is provided for demonstration purposes. The\nmain advantages of online tools are consistency (users have the same version\nand the same data selection), interoperability over different platforms, and\nease of maintenance. The code is available on GitHub.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 11:35:10 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Gibbon", "Dafydd", ""]]}, {"id": "1903.08734", "submitter": "Nicolo Frisiani", "authors": "Nicol\\`o Frisiani, Alexis Laignelet, Batuhan G\\\"uler", "title": "Combination of multiple Deep Learning architectures for Offensive\n  Language Detection in Tweets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report contains the details regarding our submission to the OffensEval\n2019 (SemEval 2019 - Task 6). The competition was based on the Offensive\nLanguage Identification Dataset. We first discuss the details of the classifier\nimplemented and the type of input data used and pre-processing performed. We\nthen move onto critically evaluating our performance. We have achieved a\nmacro-average F1-score of 0.76, 0.68, 0.54, respectively for Task a, Task b,\nand Task c, which we believe reflects on the level of sophistication of the\nmodels implemented. Finally, we will be discussing the difficulties encountered\nand possible improvements for the future.\n", "versions": [{"version": "v1", "created": "Sat, 16 Mar 2019 11:19:38 GMT"}, {"version": "v2", "created": "Mon, 25 Mar 2019 16:13:31 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Frisiani", "Nicol\u00f2", ""], ["Laignelet", "Alexis", ""], ["G\u00fcler", "Batuhan", ""]]}, {"id": "1903.08739", "submitter": "Gerhard Wohlgenannt Dr.", "authors": "Gerhard Wohlgenannt and Artemii Babushkin and Denis Romashov and Igor\n  Ukrainets and Anton Maskaykin and Ilya Shutov", "title": "Russian Language Datasets in the Digitial Humanities Domain and Their\n  Evaluation with Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present Russian language datasets in the digital humanities\ndomain for the evaluation of word embedding techniques or similar language\nmodeling and feature learning algorithms. The datasets are split into two task\ntypes, word intrusion and word analogy, and contain 31362 task units in total.\nThe characteristics of the tasks and datasets are that they build upon small,\ndomain-specific corpora, and that the datasets contain a high number of named\nentities. The datasets were created manually for two fantasy novel book series\n(\"A Song of Ice and Fire\" and \"Harry Potter\"). We provide baseline evaluations\nwith popular word embedding models trained on the book corpora for the given\ntasks, both for the Russian and English language versions of the datasets.\nFinally, we compare and analyze the results and discuss specifics of Russian\nlanguage with regards to the problem setting.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 14:18:48 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Wohlgenannt", "Gerhard", ""], ["Babushkin", "Artemii", ""], ["Romashov", "Denis", ""], ["Ukrainets", "Igor", ""], ["Maskaykin", "Anton", ""], ["Shutov", "Ilya", ""]]}, {"id": "1903.08756", "submitter": "Aitor Arronte Alvarez", "authors": "Aitor Arronte-Alvarez, Francisco G\\'omez-Martin", "title": "Distributed Vector Representations of Folksong Motifs", "comments": "MCM 19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents a distributed vector representation model for learning\nfolksong motifs. A skip-gram version of word2vec with negative sampling is used\nto represent high quality embeddings. Motifs from the Essen Folksong collection\nare compared based on their cosine similarity. A new evaluation method for\ntesting the quality of the embeddings based on a melodic similarity task is\npresented to show how the vector space can represent complex contextual\nfeatures, and how it can be utilized for the study of folksong variation.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 21:52:13 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Arronte-Alvarez", "Aitor", ""], ["G\u00f3mez-Martin", "Francisco", ""]]}, {"id": "1903.08788", "submitter": "Sameen Maruf", "authors": "Sameen Maruf, Andr\\'e F. T. Martins and Gholamreza Haffari", "title": "Selective Attention for Context-aware Neural Machine Translation", "comments": "Accepted at NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the progress made in sentence-level NMT, current systems still fall\nshort at achieving fluent, good quality translation for a full document. Recent\nworks in context-aware NMT consider only a few previous sentences as context\nand may not scale to entire documents. To this end, we propose a novel and\nscalable top-down approach to hierarchical attention for context-aware NMT\nwhich uses sparse attention to selectively focus on relevant sentences in the\ndocument context and then attends to key words in those sentences. We also\npropose single-level attention approaches based on sentence or word-level\ninformation in the context. The document-level context representation, produced\nfrom these attention modules, is integrated into the encoder or decoder of the\nTransformer model depending on whether we use monolingual or bilingual context.\nOur experiments and evaluation on English-German datasets in different document\nMT settings show that our selective attention approach not only significantly\noutperforms context-agnostic baselines but also surpasses context-aware\nbaselines in most cases.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 01:01:22 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 03:47:14 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Maruf", "Sameen", ""], ["Martins", "Andr\u00e9 F. T.", ""], ["Haffari", "Gholamreza", ""]]}, {"id": "1903.08808", "submitter": "Aleix Cambray", "authors": "Aleix Cambray and Norbert Podsadowski", "title": "Bidirectional Recurrent Models for Offensive Tweet Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we propose four deep recurrent architectures to tackle the task\nof offensive tweet detection as well as further classification into targeting\nand subject of said targeting. Our architectures are based on LSTMs and GRUs,\nwe present a simple bidirectional LSTM as a baseline system and then further\nincrease the complexity of the models by adding convolutional layers and\nimplementing a split-process-merge architecture with LSTM and GRU as\nprocessors. Multiple pre-processing techniques were also investigated. The\nvalidation F1-score results from each model are presented for the three\nsubtasks as well as the final F1-score performance on the private competition\ntest set. It was found that model complexity did not necessarily yield better\nresults. Our best-performing model was also the simplest, a bidirectional LSTM;\nclosely followed by a two-branch bidirectional LSTM and GRU architecture.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 17:31:44 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Cambray", "Aleix", ""], ["Podsadowski", "Norbert", ""]]}, {"id": "1903.08855", "submitter": "Nelson F. Liu", "authors": "Nelson F. Liu and Matt Gardner and Yonatan Belinkov and Matthew E.\n  Peters and Noah A. Smith", "title": "Linguistic Knowledge and Transferability of Contextual Representations", "comments": "22 pages, 4 figures; to appear at NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual word representations derived from large-scale neural language\nmodels are successful across a diverse set of NLP tasks, suggesting that they\nencode useful and transferable features of language. To shed light on the\nlinguistic knowledge they capture, we study the representations produced by\nseveral recent pretrained contextualizers (variants of ELMo, the OpenAI\ntransformer language model, and BERT) with a suite of seventeen diverse probing\ntasks. We find that linear models trained on top of frozen contextual\nrepresentations are competitive with state-of-the-art task-specific models in\nmany cases, but fail on tasks requiring fine-grained linguistic knowledge\n(e.g., conjunct identification). To investigate the transferability of\ncontextual word representations, we quantify differences in the transferability\nof individual layers within contextualizers, especially between recurrent\nneural networks (RNNs) and transformers. For instance, higher layers of RNNs\nare more task-specific, while transformer layers do not exhibit the same\nmonotonic trend. In addition, to better understand what makes contextual word\nrepresentations transferable, we compare language model pretraining with eleven\nsupervised pretraining tasks. For any given task, pretraining on a closely\nrelated task yields better performance than language model pretraining (which\nis better on average) when the pretraining dataset is fixed. However, language\nmodel pretraining on more data gives the best results.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 07:19:45 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 15:21:58 GMT"}, {"version": "v3", "created": "Fri, 5 Apr 2019 18:42:38 GMT"}, {"version": "v4", "created": "Thu, 11 Apr 2019 15:46:05 GMT"}, {"version": "v5", "created": "Thu, 25 Apr 2019 18:35:16 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Liu", "Nelson F.", ""], ["Gardner", "Matt", ""], ["Belinkov", "Yonatan", ""], ["Peters", "Matthew E.", ""], ["Smith", "Noah A.", ""]]}, {"id": "1903.08905", "submitter": "Chao-Wei Huang", "authors": "Chao-Wei Huang, Ting-Rui Chiang, Shang-Yu Su, Yun-Nung Chen", "title": "RAP-Net: Recurrent Attention Pooling Networks for Dialogue Response\n  Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The response selection has been an emerging research topic due to the growing\ninterest in dialogue modeling, where the goal of the task is to select an\nappropriate response for continuing dialogues. To further push the end-to-end\ndialogue model toward real-world scenarios, the seventh Dialog System\nTechnology Challenge (DSTC7) proposed a challenging track based on real chatlog\ndatasets. The competition focuses on dialogue modeling with several advanced\ncharacteristics: (1) natural language diversity, (2) capability of precisely\nselecting a proper response from a large set of candidates or the scenario\nwithout any correct answer, and (3) knowledge grounding. This paper introduces\nrecurrent attention pooling networks (RAP-Net), a novel framework for response\nselection, which can well estimate the relevance between the dialogue contexts\nand the candidates. The proposed RAP-Net is shown to be effective and can be\ngeneralized across different datasets and settings in the DSTC7 experiments.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 10:09:43 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Huang", "Chao-Wei", ""], ["Chiang", "Ting-Rui", ""], ["Su", "Shang-Yu", ""], ["Chen", "Yun-Nung", ""]]}, {"id": "1903.08948", "submitter": "Wen Zhang", "authors": "Wen Zhang, Bibek Paudel, Liang Wang, Jiaoyan Chen, Hai Zhu, Wei Zhang,\n  Abraham Bernstein and Huajun Chen", "title": "Iteratively Learning Embeddings and Rules for Knowledge Graph Reasoning", "comments": "This paper is accepted by WWW'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning is essential for the development of large knowledge graphs,\nespecially for completion, which aims to infer new triples based on existing\nones. Both rules and embeddings can be used for knowledge graph reasoning and\nthey have their own advantages and difficulties. Rule-based reasoning is\naccurate and explainable but rule learning with searching over the graph always\nsuffers from efficiency due to huge search space. Embedding-based reasoning is\nmore scalable and efficient as the reasoning is conducted via computation\nbetween embeddings, but it has difficulty learning good representations for\nsparse entities because a good embedding relies heavily on data richness. Based\non this observation, in this paper we explore how embedding and rule learning\ncan be combined together and complement each other's difficulties with their\nadvantages. We propose a novel framework IterE iteratively learning embeddings\nand rules, in which rules are learned from embeddings with proper pruning\nstrategy and embeddings are learned from existing triples and new triples\ninferred by rules. Evaluations on embedding qualities of IterE show that rules\nhelp improve the quality of sparse entity embeddings and their link prediction\nresults. We also evaluate the efficiency of rule learning and quality of rules\nfrom IterE compared with AMIE+, showing that IterE is capable of generating\nhigh quality rules more efficiently. Experiments show that iteratively learning\nembeddings and rules benefit each other during learning and prediction.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 12:26:44 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Zhang", "Wen", ""], ["Paudel", "Bibek", ""], ["Wang", "Liang", ""], ["Chen", "Jiaoyan", ""], ["Zhu", "Hai", ""], ["Zhang", "Wei", ""], ["Bernstein", "Abraham", ""], ["Chen", "Huajun", ""]]}, {"id": "1903.08953", "submitter": "Ting-Rui Chiang", "authors": "Ting-Rui Chiang, Chao-Wei Huang, Shang-Yu Su, Yun-Nung Chen", "title": "Learning Multi-Level Information for Dialogue Response Selection by\n  Highway Recurrent Transformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the increasing research interest in dialogue response generation, there\nis an emerging branch formulating this task as selecting next sentences, where\ngiven the partial dialogue contexts, the goal is to determine the most probable\nnext sentence. Following the recent success of the Transformer model, this\npaper proposes (1) a new variant of attention mechanism based on multi-head\nattention, called highway attention, and (2) a recurrent model based on\ntransformer and the proposed highway attention, so-called Highway Recurrent\nTransformer. Experiments on the response selection task in the seventh Dialog\nSystem Technology Challenge (DSTC7) show the capability of the proposed model\nof modeling both utterance-level and dialogue-level information; the\neffectiveness of each module is further analyzed as well.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 12:39:02 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Chiang", "Ting-Rui", ""], ["Huang", "Chao-Wei", ""], ["Su", "Shang-Yu", ""], ["Chen", "Yun-Nung", ""]]}, {"id": "1903.08983", "submitter": "Marcos Zampieri", "authors": "Marcos Zampieri, Shervin Malmasi, Preslav Nakov, Sara Rosenthal, Noura\n  Farra, Ritesh Kumar", "title": "SemEval-2019 Task 6: Identifying and Categorizing Offensive Language in\n  Social Media (OffensEval)", "comments": "Proceedings of the International Workshop on Semantic Evaluation\n  (SemEval)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the results and the main findings of SemEval-2019 Task 6 on\nIdentifying and Categorizing Offensive Language in Social Media (OffensEval).\nThe task was based on a new dataset, the Offensive Language Identification\nDataset (OLID), which contains over 14,000 English tweets. It featured three\nsub-tasks. In sub-task A, the goal was to discriminate between offensive and\nnon-offensive posts. In sub-task B, the focus was on the type of offensive\ncontent in the post. Finally, in sub-task C, systems had to detect the target\nof the offensive posts. OffensEval attracted a large number of participants and\nit was one of the most popular tasks in SemEval-2019. In total, about 800 teams\nsigned up to participate in the task, and 115 of them submitted results, which\nwe present and analyze in this report.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 20:22:02 GMT"}, {"version": "v2", "created": "Tue, 16 Apr 2019 16:34:54 GMT"}, {"version": "v3", "created": "Sat, 27 Apr 2019 02:05:15 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Zampieri", "Marcos", ""], ["Malmasi", "Shervin", ""], ["Nakov", "Preslav", ""], ["Rosenthal", "Sara", ""], ["Farra", "Noura", ""], ["Kumar", "Ritesh", ""]]}, {"id": "1903.09025", "submitter": "Maali Mnasri", "authors": "Maali Mnasri", "title": "Recent advances in conversational NLP : Towards the standardization of\n  Chatbot building", "comments": "8 pages with references, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue systems have become recently essential in our life. Their use is\ngetting more and more fluid and easy throughout the time. This boils down to\nthe improvements made in NLP and AI fields. In this paper, we try to provide an\noverview to the current state of the art of dialogue systems, their categories\nand the different approaches to build them. We end up with a discussion that\ncompares all the techniques and analyzes the strengths and weaknesses of each.\nFinally, we present an opinion piece suggesting to orientate the research\ntowards the standardization of dialogue systems building.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 14:30:55 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Mnasri", "Maali", ""]]}, {"id": "1903.09243", "submitter": "Matthew Walter", "authors": "Siddharth Patki and Andrea F. Daniele and Matthew R. Walter and Thomas\n  M. Howard", "title": "Inferring Compact Representations for Efficient Natural Language\n  Understanding of Robot Instructions", "comments": "Accepted to ICRA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The speed and accuracy with which robots are able to interpret natural\nlanguage is fundamental to realizing effective human-robot interaction. A great\ndeal of attention has been paid to developing models and approximate inference\nalgorithms that improve the efficiency of language understanding. However,\nexisting methods still attempt to reason over a representation of the\nenvironment that is flat and unnecessarily detailed, which limits scalability.\nAn open problem is then to develop methods capable of producing the most\ncompact environment model sufficient for accurate and efficient natural\nlanguage understanding. We propose a model that leverages environment-related\ninformation encoded within instructions to identify the subset of observations\nand perceptual classifiers necessary to perceive a succinct,\ninstruction-specific environment representation. The framework uses three\nprobabilistic graphical models trained from a corpus of annotated instructions\nto infer salient scene semantics, perceptual classifiers, and grounded symbols.\nExperimental results on two robots operating in different environments\ndemonstrate that by exploiting the content and the structure of the\ninstructions, our method learns compact environment representations that\nsignificantly improve the efficiency of natural language symbol grounding.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 21:38:20 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Patki", "Siddharth", ""], ["Daniele", "Andrea F.", ""], ["Walter", "Matthew R.", ""], ["Howard", "Thomas M.", ""]]}, {"id": "1903.09244", "submitter": "Sam Shleifer", "authors": "Sam Shleifer", "title": "Low Resource Text Classification with ULMFit and Backtranslation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In computer vision, virtually every state-of-the-art deep learning system is\ntrained with data augmentation. In text classification, however, data\naugmentation is less widely practiced because it must be performed before\ntraining and risks introducing label noise. We augment the IMDB movie reviews\ndataset with examples generated by two families of techniques: random token\nperturbations introduced by Wei and Zou [2019] and backtranslation --\ntranslating to a second language then back to English. In low resource\nenvironments, backtranslation generates significant improvement on top of the\nstate of-the-art ULMFit model. A ULMFit model pretrained on wikitext103 and\nthen fine-tuned on only 50 IMDB examples and 500 synthetic examples generated\nby backtranslation achieves 80.6% accuracy, an 8.1% improvement over the\naugmentation-free baseline with only 9 minutes of additional training time.\nRandom token perturbations do not yield any improvements but incur equivalent\ncomputational cost. The benefits of training with backtranslated examples\ndecreases with the size of the available training data. On the full dataset,\nneither augmentation technique improves upon ULMFit's state of the art\nperformance. We address this by using backtranslations as a form of test time\naugmentation as well as ensembling ULMFit with other models, and achieve small\nimprovements.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 21:40:09 GMT"}, {"version": "v2", "created": "Mon, 25 Mar 2019 18:48:16 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Shleifer", "Sam", ""]]}, {"id": "1903.09333", "submitter": "Gene Louis Kim", "authors": "Gene Louis Kim and Lenhart Schubert", "title": "A Type-coherent, Expressive Representation as an Initial Step to\n  Language Understanding", "comments": "Accepted for publication at The 13th International Conference on\n  Computational Semantics (IWCS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A growing interest in tasks involving language understanding by the NLP\ncommunity has led to the need for effective semantic parsing and inference.\nModern NLP systems use semantic representations that do not quite fulfill the\nnuanced needs for language understanding: adequately modeling language\nsemantics, enabling general inferences, and being accurately recoverable. This\ndocument describes underspecified logical forms (ULF) for Episodic Logic (EL),\nwhich is an initial form for a semantic representation that balances these\nneeds. ULFs fully resolve the semantic type structure while leaving issues such\nas quantifier scope, word sense, and anaphora unresolved; they provide a\nstarting point for further resolution into EL, and enable certain structural\ninferences without further resolution. This document also presents preliminary\nresults of creating a hand-annotated corpus of ULFs for the purpose of training\na precise ULF parser, showing a three-person pairwise interannotator agreement\nof 0.88 on confident annotations. We hypothesize that a divide-and-conquer\napproach to semantic parsing starting with derivation of ULFs will lead to\nsemantic analyses that do justice to subtle aspects of linguistic meaning, and\nwill enable construction of more accurate semantic parsers.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 03:06:36 GMT"}, {"version": "v2", "created": "Thu, 28 Mar 2019 21:58:38 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Kim", "Gene Louis", ""], ["Schubert", "Lenhart", ""]]}, {"id": "1903.09424", "submitter": "Jie Zhou", "authors": "Jie Zhou and Xingyi Cheng and Jinchao Zhang", "title": "An end-to-end Neural Network Framework for Text Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The unsupervised text clustering is one of the major tasks in natural\nlanguage processing (NLP) and remains a difficult and complex problem.\nConventional \\mbox{methods} generally treat this task using separated steps,\nincluding text representation learning and clustering the representations. As\nan improvement, neural methods have also been introduced for continuous\nrepresentation learning to address the sparsity problem. However, the\nmulti-step process still deviates from the unified optimization target.\nEspecially the second step of cluster is generally performed with conventional\nmethods such as k-Means. We propose a pure neural framework for text clustering\nin an end-to-end manner. It jointly learns the text representation and the\nclustering model. Our model works well when the context can be obtained, which\nis nearly always the case in the field of NLP. We have our method\n\\mbox{evaluated} on two widely used benchmarks: IMDB movie reviews for\nsentiment classification and $20$-Newsgroup for topic categorization. Despite\nits simplicity, experiments show the model outperforms previous clustering\nmethods by a large margin. Furthermore, the model is also verified on English\nwiki dataset as a large corpus.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 09:54:36 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Zhou", "Jie", ""], ["Cheng", "Xingyi", ""], ["Zhang", "Jinchao", ""]]}, {"id": "1903.09442", "submitter": "G\\\"ozde G\\\"ul \\c{S}ahin", "authors": "G\\\"ozde G\\\"ul \\c{S}ahin, Clara Vania, Ilia Kuznetsov, Iryna Gurevych", "title": "LINSPECTOR: Multilingual Probing Tasks for Word Representations", "comments": "Demo is available from:\n  https://linspector.ukp.informatik.tu-darmstadt.de/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Despite an ever growing number of word representation models introduced for a\nlarge number of languages, there is a lack of a standardized technique to\nprovide insights into what is captured by these models. Such insights would\nhelp the community to get an estimate of the downstream task performance, as\nwell as to design more informed neural architectures, while avoiding extensive\nexperimentation which requires substantial computational resources not all\nresearchers have access to. A recent development in NLP is to use simple\nclassification tasks, also called probing tasks, that test for a single\nlinguistic feature such as part-of-speech. Existing studies mostly focus on\nexploring the linguistic information encoded by the continuous representations\nof English text. However, from a typological perspective the morphologically\npoor English is rather an outlier: the information encoded by the word order\nand function words in English is often stored on a morphological level in other\nlanguages. To address this, we introduce 15 type-level probing tasks such as\ncase marking, possession, word length, morphological tag count and pseudoword\nidentification for 24 languages. We present a reusable methodology for creation\nand evaluation of such tests in a multilingual setting. We then present\nexperiments on several diverse multilingual word embedding models, in which we\nrelate the probing task performance for a diverse set of languages to a range\nof five classic NLP tasks: POS-tagging, dependency parsing, semantic role\nlabeling, named entity recognition and natural language inference. We find that\na number of probing tests have significantly high positive correlation to the\ndownstream tasks, especially for morphologically rich languages. We show that\nour tests can be used to explore word embeddings or black-box neural models for\nlinguistic cues in a multilingual setting.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 11:01:16 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 12:20:20 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["\u015eahin", "G\u00f6zde G\u00fcl", ""], ["Vania", "Clara", ""], ["Kuznetsov", "Ilia", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1903.09460", "submitter": "G\\\"ozde G\\\"ul \\c{S}ahin", "authors": "G\\\"ozde G\\\"ul \\c{S}ahin, Mark Steedman", "title": "Data Augmentation via Dependency Tree Morphing for Low-Resource\n  Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Neural NLP systems achieve high scores in the presence of sizable training\ndataset. Lack of such datasets leads to poor system performances in the case\nlow-resource languages. We present two simple text augmentation techniques\nusing dependency trees, inspired from image processing. We crop sentences by\nremoving dependency links, and we rotate sentences by moving the tree fragments\naround the root. We apply these techniques to augment the training sets of\nlow-resource languages in Universal Dependencies project. We implement a\ncharacter-level sequence tagging model and evaluate the augmented datasets on\npart-of-speech tagging task. We show that crop and rotate provides improvements\nover the models trained with non-augmented data for majority of the languages,\nespecially for languages with rich case marking systems.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 11:55:21 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["\u015eahin", "G\u00f6zde G\u00fcl", ""], ["Steedman", "Mark", ""]]}, {"id": "1903.09588", "submitter": "Chi Sun", "authors": "Chi Sun, Luyao Huang, Xipeng Qiu", "title": "Utilizing BERT for Aspect-Based Sentiment Analysis via Constructing\n  Auxiliary Sentence", "comments": "Accepted to NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect-based sentiment analysis (ABSA), which aims to identify fine-grained\nopinion polarity towards a specific aspect, is a challenging subtask of\nsentiment analysis (SA). In this paper, we construct an auxiliary sentence from\nthe aspect and convert ABSA to a sentence-pair classification task, such as\nquestion answering (QA) and natural language inference (NLI). We fine-tune the\npre-trained model from BERT and achieve new state-of-the-art results on\nSentiHood and SemEval-2014 Task 4 datasets.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 16:29:18 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Sun", "Chi", ""], ["Huang", "Luyao", ""], ["Qiu", "Xipeng", ""]]}, {"id": "1903.09722", "submitter": "Michael Auli", "authors": "Sergey Edunov, Alexei Baevski, Michael Auli", "title": "Pre-trained Language Model Representations for Language Generation", "comments": "NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained language model representations have been successful in a wide\nrange of language understanding tasks. In this paper, we examine different\nstrategies to integrate pre-trained representations into sequence to sequence\nmodels and apply it to neural machine translation and abstractive\nsummarization. We find that pre-trained representations are most effective when\nadded to the encoder network which slows inference by only 14%. Our experiments\nin machine translation show gains of up to 5.3 BLEU in a simulated\nresource-poor setup. While returns diminish with more labeled data, we still\nobserve improvements when millions of sentence-pairs are available. Finally, on\nabstractive summarization we achieve a new state of the art on the full text\nversion of CNN/DailyMail.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 22:14:51 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 17:49:39 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Edunov", "Sergey", ""], ["Baevski", "Alexei", ""], ["Auli", "Michael", ""]]}, {"id": "1903.09813", "submitter": "Hao-Tong Ye", "authors": "Hao-Tong Ye, Kai-Ling Lo, Shang-Yu Su, Yun-Nung Chen", "title": "Knowledge-Grounded Response Generation with Deep Attentional\n  Latent-Variable Model", "comments": "Published in DSTC7 workshop at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  End-to-end dialogue generation has achieved promising results without using\nhandcrafted features and attributes specific for each task and corpus. However,\none of the fatal drawbacks in such approaches is that they are unable to\ngenerate informative utterances, so it limits their usage from some real-world\nconversational applications. This paper attempts at generating diverse and\ninformative responses with a variational generation model, which contains a\njoint attention mechanism conditioning on the information from both dialogue\ncontexts and extra knowledge.\n", "versions": [{"version": "v1", "created": "Sat, 23 Mar 2019 12:19:11 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Ye", "Hao-Tong", ""], ["Lo", "Kai-Ling", ""], ["Su", "Shang-Yu", ""], ["Chen", "Yun-Nung", ""]]}, {"id": "1903.09846", "submitter": "Sergio Jimenez", "authors": "Fabio N. Silva and Sergio Jimenez and George Due\\~nas", "title": "Toward the Evaluation of Written Proficiency on a Collaborative Social\n  Network for Learning Languages: Yask", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Yask is an online social collaborative network for practicing languages in a\nframework that includes requests, answers, and votes. Since measuring\nlinguistic competence using current approaches is difficult, expensive and in\nmany cases imprecise, we present a new alternative approach based on social\nnetworks. Our method, called Proficiency Rank, extends the well-known Page Rank\nalgorithm to measure the reputation of users in a collaborative social graph.\nFirst, we extended Page Rank so that it not only considers positive links\n(votes) but also negative links. Second, in addition to using explicit links,\nwe also incorporate other 4 types of signals implicit in the social graph.\nThese extensions allow Proficiency Rank to produce proficiency rankings for\nalmost all users in the data set used, where only a minority contributes by\nanswering, while the majority contributes only by voting. This overcomes the\nintrinsic limitation of Page Rank of only being able to rank the nodes that\nhave incoming links. Our experimental validation showed that the\nreputation/importance of the users in Yask is significantly correlated with\ntheir language proficiency. In contrast, their written production was poorly\ncorrelated with the vocabulary profiles of the Common European Framework of\nReference. In addition, we found that negative signals (votes) are considerably\nmore informative than positive ones. We concluded that the use of this\ntechnology is a promising tool for measuring second language proficiency, even\nfor relatively small groups of people.\n", "versions": [{"version": "v1", "created": "Sat, 23 Mar 2019 16:40:17 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Silva", "Fabio N.", ""], ["Jimenez", "Sergio", ""], ["Due\u00f1as", "George", ""]]}, {"id": "1903.09848", "submitter": "Emmanouil Antonios Platanios", "authors": "Emmanouil Antonios Platanios and Otilia Stretcu and Graham Neubig and\n  Barnabas Poczos and Tom M. Mitchell", "title": "Competence-based Curriculum Learning for Neural Machine Translation", "comments": null, "journal-ref": "NAACL 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current state-of-the-art NMT systems use large neural networks that are not\nonly slow to train, but also often require many heuristics and optimization\ntricks, such as specialized learning rate schedules and large batch sizes. This\nis undesirable as it requires extensive hyperparameter tuning. In this paper,\nwe propose a curriculum learning framework for NMT that reduces training time,\nreduces the need for specialized heuristics or large batch sizes, and results\nin overall better performance. Our framework consists of a principled way of\ndeciding which training samples are shown to the model at different times\nduring training, based on the estimated difficulty of a sample and the current\ncompetence of the model. Filtering training samples in this manner prevents the\nmodel from getting stuck in bad local optima, making it converge faster and\nreach a better solution than the common approach of uniformly sampling training\nexamples. Furthermore, the proposed method can be easily applied to existing\nNMT models by simply modifying their input data pipelines. We show that our\nframework can help improve the training time and the performance of both\nrecurrent neural network models and Transformers, achieving up to a 70%\ndecrease in training time, while at the same time obtaining accuracy\nimprovements of up to 2.2 BLEU.\n", "versions": [{"version": "v1", "created": "Sat, 23 Mar 2019 17:33:38 GMT"}, {"version": "v2", "created": "Tue, 26 Mar 2019 12:39:04 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Platanios", "Emmanouil Antonios", ""], ["Stretcu", "Otilia", ""], ["Neubig", "Graham", ""], ["Poczos", "Barnabas", ""], ["Mitchell", "Tom M.", ""]]}, {"id": "1903.09878", "submitter": "Meryem M'hamdi", "authors": "Meryem M'hamdi, Robert West, Andreea Hossmann, Michael Baeriswyl, and\n  Claudiu Musat", "title": "Expanding the Text Classification Toolbox with Cross-Lingual Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most work in text classification and Natural Language Processing (NLP)\nfocuses on English or a handful of other languages that have text corpora of\nhundreds of millions of words. This is creating a new version of the digital\ndivide: the artificial intelligence (AI) divide. Transfer-based approaches,\nsuch as Cross-Lingual Text Classification (CLTC) - the task of categorizing\ntexts written in different languages into a common taxonomy, are a promising\nsolution to the emerging AI divide. Recent work on CLTC has focused on\ndemonstrating the benefits of using bilingual word embeddings as features,\nrelegating the CLTC problem to a mere benchmark based on a simple averaged\nperceptron.\n  In this paper, we explore more extensively and systematically two flavors of\nthe CLTC problem: news topic classification and textual churn intent detection\n(TCID) in social media. In particular, we test the hypothesis that embeddings\nwith context are more effective, by multi-tasking the learning of multilingual\nword embeddings and text classification; we explore neural architectures for\nCLTC; and we move from bi- to multi-lingual word embeddings. For all\narchitectures, types of word embeddings and datasets, we notice a consistent\ngain trend in favor of multilingual joint training, especially for\nlow-resourced languages.\n", "versions": [{"version": "v1", "created": "Sat, 23 Mar 2019 20:25:40 GMT"}, {"version": "v2", "created": "Tue, 26 Mar 2019 18:14:17 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["M'hamdi", "Meryem", ""], ["West", "Robert", ""], ["Hossmann", "Andreea", ""], ["Baeriswyl", "Michael", ""], ["Musat", "Claudiu", ""]]}, {"id": "1903.09941", "submitter": "Shweta Yadav Shweta", "authors": "Dhanachandra Ningthoujam, Shweta Yadav, Pushpak Bhattacharyya, Asif\n  Ekbal", "title": "Relation extraction between the clinical entities based on the shortest\n  dependency path based LSTM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Owing to the exponential rise in the electronic medical records, information\nextraction in this domain is becoming an important area of research in recent\nyears. Relation extraction between the medical concepts such as medical\nproblem, treatment, and test etc. is also one of the most important tasks in\nthis area. In this paper, we present an efficient relation extraction system\nbased on the shortest dependency path (SDP) generated from the dependency\nparsed tree of the sentence. Instead of relying on many handcrafted features\nand the whole sequence of tokens present in a sentence, our system relies only\non the SDP between the target entities. For every pair of entities, the system\ntakes only the words in the SDP, their dependency labels, Part-of-Speech\ninformation and the types of the entities as the input. We develop a dependency\nparser for extracting dependency information. We perform our experiments on the\nbenchmark i2b2 dataset for clinical relation extraction challenge 2010.\nExperimental results show that our system outperforms the existing systems.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 07:54:57 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Ningthoujam", "Dhanachandra", ""], ["Yadav", "Shweta", ""], ["Bhattacharyya", "Pushpak", ""], ["Ekbal", "Asif", ""]]}, {"id": "1903.09942", "submitter": "Andrei Damian I", "authors": "Laurentiu Piciu, Andrei Damian, Nicolae Tapus, Andrei\n  Simion-Constantinescu, Bogdan Dumitrescu", "title": "Deep recommender engine based on efficient product embeddings neural\n  pipeline", "comments": "2018 17th RoEduNet Conference: Networking in Education and Research\n  (RoEduNet)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Predictive analytics systems are currently one of the most important areas of\nresearch and development within the Artificial Intelligence domain and\nparticularly in Machine Learning. One of the \"holy grails\" of predictive\nanalytics is the research and development of the \"perfect\" recommendation\nsystem. In our paper, we propose an advanced pipeline model for the multi-task\nobjective of determining product complementarity, similarity and sales\nprediction using deep neural models applied to big-data sequential transaction\nsystems. Our highly parallelized hybrid model pipeline consists of both\nunsupervised and supervised models, used for the objectives of generating\nsemantic product embeddings and predicting sales, respectively. Our\nexperimentation and benchmarking processes have been done using pharma industry\nretail real-life transactional Big-Data streams.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 08:11:58 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2019 13:39:33 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Piciu", "Laurentiu", ""], ["Damian", "Andrei", ""], ["Tapus", "Nicolae", ""], ["Simion-Constantinescu", "Andrei", ""], ["Dumitrescu", "Bogdan", ""]]}, {"id": "1903.09952", "submitter": "Chenglin Xu", "authors": "Chenglin Xu, Wei Rao, Eng Siong Chng, Haizhou Li", "title": "Optimization of Speaker Extraction Neural Network with Magnitude and\n  Temporal Spectrum Approximation Loss", "comments": "Accepted in ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The SpeakerBeam-FE (SBF) method is proposed for speaker extraction. It\nattempts to overcome the problem of unknown number of speakers in an audio\nrecording during source separation. The mask approximation loss of SBF is\nsub-optimal, which doesn't calculate direct signal reconstruction error and\nconsider the speech context. To address these problems, this paper proposes a\nmagnitude and temporal spectrum approximation loss to estimate a phase\nsensitive mask for the target speaker with the speaker characteristics.\nMoreover, this paper explores a concatenation framework instead of the context\nadaptive deep neural network in the SBF method to encode a speaker embedding\ninto the mask estimation network. Experimental results under open evaluation\ncondition show that the proposed method achieves 70.4% and 17.7% relative\nimprovement over the SBF baseline on signal-to-distortion ratio (SDR) and\nperceptual evaluation of speech quality (PESQ), respectively. A further\nanalysis demonstrates 69.1% and 72.3% relative SDR improvements obtained by the\nproposed method for different and same gender mixtures.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 09:25:26 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Xu", "Chenglin", ""], ["Rao", "Wei", ""], ["Chng", "Eng Siong", ""], ["Li", "Haizhou", ""]]}, {"id": "1903.10104", "submitter": "Xinyu Hua", "authors": "Xinyu Hua, Mitko Nikolov, Nikhil Badugu, Lu Wang", "title": "Argument Mining for Understanding Peer Reviews", "comments": "Accepted to NAACL 2019 as a short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Peer-review plays a critical role in the scientific writing and publication\necosystem. To assess the efficiency and efficacy of the reviewing process, one\nessential element is to understand and evaluate the reviews themselves. In this\nwork, we study the content and structure of peer reviews under the argument\nmining framework, through automatically detecting (1) argumentative\npropositions put forward by reviewers, and (2) their types (e.g., evaluating\nthe work or making suggestions for improvement). We first collect 14.2K reviews\nfrom major machine learning and natural language processing venues. 400 reviews\nare annotated with 10,386 propositions and corresponding types of Evaluation,\nRequest, Fact, Reference, or Quote. We then train state-of-the-art proposition\nsegmentation and classification models on the data to evaluate their utilities\nand identify new challenges for this new domain, motivating future directions\nfor argument mining. Further experiments show that proposition usage varies\nacross venues in amount, type, and topic.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 02:26:54 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Hua", "Xinyu", ""], ["Nikolov", "Mitko", ""], ["Badugu", "Nikhil", ""], ["Wang", "Lu", ""]]}, {"id": "1903.10118", "submitter": "Keisuke Hagiwara", "authors": "Keisuke Hagiwara, Yusuke Mukuta, Tatsuya Harada", "title": "End-to-End Learning Using Cycle Consistency for Image-to-Caption\n  Transformations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  So far, research to generate captions from images has been carried out from\nthe viewpoint that a caption holds sufficient information for an image. If it\nis possible to generate an image that is close to the input image from a\ngenerated caption, i.e., if it is possible to generate a natural language\ncaption containing sufficient information to reproduce the image, then the\ncaption is considered to be faithful to the image. To make such regeneration\npossible, learning using the cycle-consistency loss is effective. In this\nstudy, we propose a method of generating captions by learning end-to-end mutual\ntransformations between images and texts. To evaluate our method, we perform\ncomparative experiments with and without the cycle consistency. The results are\nevaluated by an automatic evaluation and crowdsourcing, demonstrating that our\nproposed method is effective.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 03:40:15 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Hagiwara", "Keisuke", ""], ["Mukuta", "Yusuke", ""], ["Harada", "Tatsuya", ""]]}, {"id": "1903.10126", "submitter": "Peng Xu", "authors": "Peng Xu and Denilson Barbosa", "title": "Connecting Language and Knowledge with Heterogeneous Representations for\n  Neural Relation Extraction", "comments": "Camera-ready for NAACL HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Bases (KBs) require constant up-dating to reflect changes to the\nworld they represent. For general purpose KBs, this is often done through\nRelation Extraction (RE), the task of predicting KB relations expressed in text\nmentioning entities known to the KB. One way to improve RE is to use KB\nEmbeddings (KBE) for link prediction. However, despite clear connections\nbetween RE and KBE, little has been done toward properly unifying these models\nsystematically. We help close the gap with a framework that unifies the\nlearning of RE and KBE models leading to significant improvements over the\nstate-of-the-art in RE. The code is available at\nhttps://github.com/billy-inn/HRERE.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 04:09:59 GMT"}, {"version": "v2", "created": "Tue, 26 Mar 2019 01:00:23 GMT"}, {"version": "v3", "created": "Thu, 9 May 2019 21:30:22 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Xu", "Peng", ""], ["Barbosa", "Denilson", ""]]}, {"id": "1903.10145", "submitter": "Chunyuan Li", "authors": "Hao Fu, Chunyuan Li, Xiaodong Liu, Jianfeng Gao, Asli Celikyilmaz,\n  Lawrence Carin", "title": "Cyclical Annealing Schedule: A Simple Approach to Mitigating KL\n  Vanishing", "comments": "Published in NAACL 2019; The first two authors contribute equally;\n  Code: https://github.com/haofuml/cyclical_annealing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders (VAEs) with an auto-regressive decoder have been\napplied for many natural language processing (NLP) tasks. The VAE objective\nconsists of two terms, (i) reconstruction and (ii) KL regularization, balanced\nby a weighting hyper-parameter \\beta. One notorious training difficulty is that\nthe KL term tends to vanish. In this paper we study scheduling schemes for\n\\beta, and show that KL vanishing is caused by the lack of good latent codes in\ntraining the decoder at the beginning of optimization. To remedy this, we\npropose a cyclical annealing schedule, which repeats the process of increasing\n\\beta multiple times. This new procedure allows the progressive learning of\nmore meaningful latent codes, by leveraging the informative representations of\nprevious cycles as warm re-starts. The effectiveness of cyclical annealing is\nvalidated on a broad range of NLP tasks, including language modeling, dialog\nresponse generation and unsupervised language pre-training.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 06:28:24 GMT"}, {"version": "v2", "created": "Sun, 26 May 2019 06:50:06 GMT"}, {"version": "v3", "created": "Mon, 10 Jun 2019 21:43:02 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Fu", "Hao", ""], ["Li", "Chunyuan", ""], ["Liu", "Xiaodong", ""], ["Gao", "Jianfeng", ""], ["Celikyilmaz", "Asli", ""], ["Carin", "Lawrence", ""]]}, {"id": "1903.10222", "submitter": "Aditi Sharma", "authors": "Akshi Kumar, Aditi Sharma, Anshika Arora", "title": "Anxious Depression Prediction in Real-time Social Data", "comments": null, "journal-ref": null, "doi": null, "report-no": "as11", "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mental well-being and social media have been closely related domains of\nstudy. In this research a novel model, AD prediction model, for anxious\ndepression prediction in real-time tweets is proposed. This mixed\nanxiety-depressive disorder is a predominantly associated with erratic thought\nprocess, restlessness and sleeplessness. Based on the linguistic cues and user\nposting patterns, the feature set is defined using a 5-tuple vector <word,\ntiming, frequency, sentiment, contrast>. An anxiety-related lexicon is built to\ndetect the presence of anxiety indicators. Time and frequency of tweet is\nanalyzed for irregularities and opinion polarity analytics is done to find\ninconsistencies in posting behaviour. The model is trained using three\nclassifiers (multinomial na\\\"ive bayes, gradient boosting, and random forest)\nand majority voting using an ensemble voting classifier is done. Preliminary\nresults are evaluated for tweets of sampled 100 users and the proposed model\nachieves a classification accuracy of 85.09%.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 10:21:43 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Kumar", "Akshi", ""], ["Sharma", "Aditi", ""], ["Arora", "Anshika", ""]]}, {"id": "1903.10238", "submitter": "Noa Yehezkel Lubin", "authors": "Noa Yehezkel Lubin, Jacob Goldberger and Yoav Goldberg", "title": "Aligning Vector-spaces with Noisy Supervised Lexicons", "comments": "Accepted as a short paper in NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of learning to translate between two vector spaces given a set of\naligned points arises in several application areas of NLP. Current solutions\nassume that the lexicon which defines the alignment pairs is noise-free. We\nconsider the case where the set of aligned points is allowed to contain an\namount of noise, in the form of incorrect lexicon pairs and show that this\narises in practice by analyzing the edited dictionaries after the cleaning\nprocess. We demonstrate that such noise substantially degrades the accuracy of\nthe learned translation when using current methods. We propose a model that\naccounts for noisy pairs. This is achieved by introducing a generative model\nwith a compatible iterative EM algorithm. The algorithm jointly learns the\nnoise level in the lexicon, finds the set of noisy pairs, and learns the\nmapping between the spaces. We demonstrate the effectiveness of our proposed\nalgorithm on two alignment problems: bilingual word embedding translation, and\nmapping between diachronic embedding spaces for recovering the semantic shifts\nof words across time periods.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 11:00:20 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Lubin", "Noa Yehezkel", ""], ["Goldberger", "Jacob", ""], ["Goldberg", "Yoav", ""]]}, {"id": "1903.10245", "submitter": "Zheng-Yu Niu", "authors": "Zhibin Liu, Zheng-Yu Niu, Hua Wu, Haifeng Wang", "title": "Knowledge Aware Conversation Generation with Explainable Reasoning over\n  Augmented Graphs", "comments": "Accepted by EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two types of knowledge, triples from knowledge graphs and texts from\ndocuments, have been studied for knowledge aware open-domain conversation\ngeneration, in which graph paths can narrow down vertex candidates for\nknowledge selection decision, and texts can provide rich information for\nresponse generation. Fusion of a knowledge graph and texts might yield mutually\nreinforcing advantages, but there is less study on that. To address this\nchallenge, we propose a knowledge aware chatting machine with three components,\nan augmented knowledge graph with both triples and texts, knowledge selector,\nand knowledge aware response generator. For knowledge selection on the graph,\nwe formulate it as a problem of multi-hop graph reasoning to effectively\ncapture conversation flow, which is more explainable and flexible in comparison\nwith previous work. To fully leverage long text information that differentiates\nour graph from others, we improve a state of the art reasoning algorithm with\nmachine reading comprehension technology. We demonstrate the effectiveness of\nour system on two datasets in comparison with state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 11:23:17 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2019 10:12:48 GMT"}, {"version": "v3", "created": "Fri, 19 Apr 2019 02:24:09 GMT"}, {"version": "v4", "created": "Tue, 3 Sep 2019 04:36:06 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Liu", "Zhibin", ""], ["Niu", "Zheng-Yu", ""], ["Wu", "Hua", ""], ["Wang", "Haifeng", ""]]}, {"id": "1903.10246", "submitter": "Pierre-Yves Oudeyer", "authors": "Pierre-Yves Oudeyer, George Kachergis, William Schueller", "title": "Computational and Robotic Models of Early Language Development: A Review", "comments": "to appear in International Handbook on Language Development, ed. J.\n  Horst and J. von Koss Torkildsen, Routledge", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review computational and robotics models of early language learning and\ndevelopment. We first explain why and how these models are used to understand\nbetter how children learn language. We argue that they provide concrete\ntheories of language learning as a complex dynamic system, complementing\ntraditional methods in psychology and linguistics. We review different modeling\nformalisms, grounded in techniques from machine learning and artificial\nintelligence such as Bayesian and neural network approaches. We then discuss\ntheir role in understanding several key mechanisms of language development:\ncross-situational statistical learning, embodiment, situated social\ninteraction, intrinsically motivated learning, and cultural evolution. We\nconclude by discussing future challenges for research, including modeling of\nlarge-scale empirical data about language acquisition in real-world\nenvironments.\n  Keywords: Early language learning, Computational and robotic models, machine\nlearning, development, embodiment, social interaction, intrinsic motivation,\nself-organization, dynamical systems, complexity.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 11:28:36 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Oudeyer", "Pierre-Yves", ""], ["Kachergis", "George", ""], ["Schueller", "William", ""]]}, {"id": "1903.10318", "submitter": "Yang Liu", "authors": "Yang Liu", "title": "Fine-tune BERT for Extractive Summarization", "comments": "fix figure 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BERT, a pre-trained Transformer model, has achieved ground-breaking\nperformance on multiple NLP tasks. In this paper, we describe BERTSUM, a simple\nvariant of BERT, for extractive summarization. Our system is the state of the\nart on the CNN/Dailymail dataset, outperforming the previous best-performed\nsystem by 1.65 on ROUGE-L. The codes to reproduce our results are available at\nhttps://github.com/nlpyang/BertSum\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 13:42:45 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 15:35:21 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Liu", "Yang", ""]]}, {"id": "1903.10421", "submitter": "Costanza Catalano", "authors": "Costanza Catalano, Umer Azfar, Ludovic Charlier and Rapha\\\"el Jungers", "title": "A linear bound on the k-rendezvous time for primitive sets of NZ\n  matrices", "comments": "27 pages, 10 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CL math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A set of nonnegative matrices is called primitive if there exists a product\nof these matrices that is entrywise positive. Motivated by recent results\nrelating synchronizing automata and primitive sets, we study the length of the\nshortest product of a primitive set having a column or a row with k positive\nentries, called its k-rendezvous time (k-RT}), in the case of sets of matrices\nhaving no zero rows and no zero columns. We prove that the k-RT is at most\nlinear w.r.t. the matrix size n for small k, while the problem is still open\nfor synchronizing automata. We provide two upper bounds on the k-RT: the second\nis an improvement of the first one, although the latter can be written in\nclosed form. We then report numerical results comparing our upper bounds on the\nk-RT with heuristic approximation methods.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 16:05:47 GMT"}, {"version": "v2", "created": "Sun, 15 Mar 2020 21:23:17 GMT"}, {"version": "v3", "created": "Wed, 20 Jan 2021 11:25:54 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Catalano", "Costanza", ""], ["Azfar", "Umer", ""], ["Charlier", "Ludovic", ""], ["Jungers", "Rapha\u00ebl", ""]]}, {"id": "1903.10453", "submitter": "Xuan-Son Vu", "authors": "Xuan-Son Vu, Son N. Tran, Lili Jiang", "title": "dpUGC: Learn Differentially Private Representation for User Generated\n  Contents", "comments": null, "journal-ref": "Proceedings of the 20th International Conference on Computational\n  Linguistics and Intelligent Text Processing, La Rochelle, France, 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper firstly proposes a simple yet efficient generalized approach to\napply differential privacy to text representation (i.e., word embedding). Based\non it, we propose a user-level approach to learn personalized differentially\nprivate word embedding model on user generated contents (UGC). To our best\nknowledge, this is the first work of learning user-level differentially private\nword embedding model from text for sharing. The proposed approaches protect the\nprivacy of the individual from re-identification, especially provide better\ntrade-off of privacy and data utility on UGC data for sharing. The experimental\nresults show that the trained embedding models are applicable for the classic\ntext analysis tasks (e.g., regression). Moreover, the proposed approaches of\nlearning differentially private embedding models are both framework- and data-\nindependent, which facilitates the deployment and sharing. The source code is\navailable at https://github.com/sonvx/dpText.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 16:41:20 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Vu", "Xuan-Son", ""], ["Tran", "Son N.", ""], ["Jiang", "Lili", ""]]}, {"id": "1903.10548", "submitter": "Mohammad Reza Samsami", "authors": "Fahimeh Hosseini, Hosein Fooladi, Mohammad Reza Samsami", "title": "Recognizing Arrow Of Time In The Short Stories", "comments": "WiNLP 2019 workshop, 3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recognizing arrow of time in short stories is a challenging task. i.e., given\nonly two paragraphs, determining which comes first and which comes next is a\ndifficult task even for humans. In this paper, we have collected and curated a\nnovel dataset for tackling this challenging task. We have shown that a\npre-trained BERT architecture achieves reasonable accuracy on the task, and\noutperforms RNN-based architectures.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 18:45:29 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Hosseini", "Fahimeh", ""], ["Fooladi", "Hosein", ""], ["Samsami", "Mohammad Reza", ""]]}, {"id": "1903.10561", "submitter": "Alex Wang", "authors": "Chandler May, Alex Wang, Shikha Bordia, Samuel R. Bowman, Rachel\n  Rudinger", "title": "On Measuring Social Biases in Sentence Encoders", "comments": "NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Word Embedding Association Test shows that GloVe and word2vec word\nembeddings exhibit human-like implicit biases based on gender, race, and other\nsocial constructs (Caliskan et al., 2017). Meanwhile, research on learning\nreusable text representations has begun to explore sentence-level texts, with\nsome sentence encoders seeing enthusiastic adoption. Accordingly, we extend the\nWord Embedding Association Test to measure bias in sentence encoders. We then\ntest several sentence encoders, including state-of-the-art methods such as ELMo\nand BERT, for the social biases studied in prior work and two important biases\nthat are difficult or impossible to test at the word level. We observe mixed\nresults including suspicious patterns of sensitivity that suggest the test's\nassumptions may not hold in general. We conclude by proposing directions for\nfuture work on measuring bias in sentence encoders.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 19:30:21 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["May", "Chandler", ""], ["Wang", "Alex", ""], ["Bordia", "Shikha", ""], ["Bowman", "Samuel R.", ""], ["Rudinger", "Rachel", ""]]}, {"id": "1903.10625", "submitter": "Felix Stahlberg", "authors": "Felix Stahlberg, Christopher Bryant, Bill Byrne", "title": "Neural Grammatical Error Correction with Finite State Transducers", "comments": "NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grammatical error correction (GEC) is one of the areas in natural language\nprocessing in which purely neural models have not yet superseded more\ntraditional symbolic models. Hybrid systems combining phrase-based statistical\nmachine translation (SMT) and neural sequence models are currently among the\nmost effective approaches to GEC. However, both SMT and neural\nsequence-to-sequence models require large amounts of annotated data. Language\nmodel based GEC (LM-GEC) is a promising alternative which does not rely on\nannotated training data. We show how to improve LM-GEC by applying modelling\ntechniques based on finite state transducers. We report further gains by\nrescoring with neural language models. We show that our methods developed for\nLM-GEC can also be used with SMT systems if annotated training data is\navailable. Our best system outperforms the best published result on the\nCoNLL-2014 test set, and achieves far better relative improvements over the SMT\nbaselines than previous hybrid systems.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 23:05:11 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 08:49:51 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Stahlberg", "Felix", ""], ["Bryant", "Christopher", ""], ["Byrne", "Bill", ""]]}, {"id": "1903.10630", "submitter": "Budhaditya Deb", "authors": "Budhaditya Deb and Peter Bailey and Milad Shokouhi", "title": "Diversifying Reply Suggestions using a Matching-Conditional Variational\n  Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of diversifying automated reply suggestions for a\ncommercial instant-messaging (IM) system (Skype). Our conversation model is a\nstandard matching based information retrieval architecture, which consists of\ntwo parallel encoders to project messages and replies into a common feature\nrepresentation. During inference, we select replies from a fixed response set\nusing nearest neighbors in the feature space. To diversify responses, we\nformulate the model as a generative latent variable model with Conditional\nVariational Auto-Encoder (M-CVAE). We propose a constrained-sampling approach\nto make the variational inference in M-CVAE efficient for our production\nsystem. In offline experiments, M-CVAE consistently increased diversity by\n~30-40% without significant impact on relevance. This translated to a 5% gain\nin click-rate in our online production system.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 23:12:56 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Deb", "Budhaditya", ""], ["Bailey", "Peter", ""], ["Shokouhi", "Milad", ""]]}, {"id": "1903.10635", "submitter": "Mingqing Chen", "authors": "Mingqing Chen, Rajiv Mathews, Tom Ouyang, Fran\\c{c}oise Beaufays", "title": "Federated Learning Of Out-Of-Vocabulary Words", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that a character-level recurrent neural network is able to\nlearn out-of-vocabulary (OOV) words under federated learning settings, for the\npurpose of expanding the vocabulary of a virtual keyboard for smartphones\nwithout exporting sensitive text to servers. High-frequency words can be\nsampled from the trained generative model by drawing from the joint posterior\ndirectly. We study the feasibility of the approach in two settings: (1) using\nsimulated federated learning on a publicly available non-IID per-user dataset\nfrom a popular social networking website, (2) using federated learning on data\nhosted on user mobile devices. The model achieves good recall and precision\ncompared to ground-truth OOV words in setting (1). With (2) we demonstrate the\npracticality of this approach by showing that we can learn meaningful OOV words\nwith good character-level prediction accuracy and cross entropy loss.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 00:01:47 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Chen", "Mingqing", ""], ["Mathews", "Rajiv", ""], ["Ouyang", "Tom", ""], ["Beaufays", "Fran\u00e7oise", ""]]}, {"id": "1903.10671", "submitter": "Hongyu Gong", "authors": "Hongyu Gong, Suma Bhat, Lingfei Wu, Jinjun Xiong, Wen-mei Hwu", "title": "Reinforcement Learning Based Text Style Transfer without Parallel\n  Training Corpus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text style transfer rephrases a text from a source style (e.g., informal) to\na target style (e.g., formal) while keeping its original meaning. Despite the\nsuccess existing works have achieved using a parallel corpus for the two\nstyles, transferring text style has proven significantly more challenging when\nthere is no parallel training corpus. In this paper, we address this challenge\nby using a reinforcement-learning-based generator-evaluator architecture. Our\ngenerator employs an attention-based encoder-decoder to transfer a sentence\nfrom the source style to the target style. Our evaluator is an adversarially\ntrained style discriminator with semantic and syntactic constraints that score\nthe generated sentence for style, meaning preservation, and fluency.\nExperimental results on two different style transfer tasks (sentiment transfer\nand formality transfer) show that our model outperforms state-of-the-art\napproaches. Furthermore, we perform a manual evaluation that demonstrates the\neffectiveness of the proposed method using subjective metrics of generated text\nquality.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 04:33:23 GMT"}, {"version": "v2", "created": "Mon, 8 Apr 2019 05:43:22 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Gong", "Hongyu", ""], ["Bhat", "Suma", ""], ["Wu", "Lingfei", ""], ["Xiong", "Jinjun", ""], ["Hwu", "Wen-mei", ""]]}, {"id": "1903.10675", "submitter": "Hongyu Gong", "authors": "Hongyu Gong, Tarek Sakakini, Suma Bhat, Jinjun Xiong", "title": "Document Similarity for Texts of Varying Lengths via Hidden Topics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring similarity between texts is an important task for several\napplications. Available approaches to measure document similarity are\ninadequate for document pairs that have non-comparable lengths, such as a long\ndocument and its summary. This is because of the lexical, contextual and the\nabstraction gaps between a long document of rich details and its concise\nsummary of abstract information. In this paper, we present a document matching\napproach to bridge this gap, by comparing the texts in a common space of hidden\ntopics. We evaluate the matching algorithm on two matching tasks and find that\nit consistently and widely outperforms strong baselines. We also highlight the\nbenefits of incorporating domain knowledge to text matching.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 04:42:17 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Gong", "Hongyu", ""], ["Sakakini", "Tarek", ""], ["Bhat", "Suma", ""], ["Xiong", "Jinjun", ""]]}, {"id": "1903.10676", "submitter": "Iz Beltagy", "authors": "Iz Beltagy, Kyle Lo, Arman Cohan", "title": "SciBERT: A Pretrained Language Model for Scientific Text", "comments": "https://github.com/allenai/scibert", "journal-ref": "EMNLP 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obtaining large-scale annotated data for NLP tasks in the scientific domain\nis challenging and expensive. We release SciBERT, a pretrained language model\nbased on BERT (Devlin et al., 2018) to address the lack of high-quality,\nlarge-scale labeled scientific data. SciBERT leverages unsupervised pretraining\non a large multi-domain corpus of scientific publications to improve\nperformance on downstream scientific NLP tasks. We evaluate on a suite of tasks\nincluding sequence tagging, sentence classification and dependency parsing,\nwith datasets from a variety of scientific domains. We demonstrate\nstatistically significant improvements over BERT and achieve new\nstate-of-the-art results on several of these tasks. The code and pretrained\nmodels are available at https://github.com/allenai/scibert/.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 05:11:46 GMT"}, {"version": "v2", "created": "Wed, 28 Aug 2019 19:23:59 GMT"}, {"version": "v3", "created": "Tue, 10 Sep 2019 18:10:35 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Beltagy", "Iz", ""], ["Lo", "Kyle", ""], ["Cohan", "Arman", ""]]}, {"id": "1903.10716", "submitter": "Cunxiang Wang", "authors": "Cunxiang Wang, Feiliang Ren, Zhichao Lin, Chenxv Zhao, Tian Xie and\n  Yue Zhang", "title": "Domain Representation for Knowledge Graph Embedding", "comments": "Acceptted by NLPCC2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding entities and relations into a continuous multi-dimensional vector\nspace have become the dominant method for knowledge graph embedding in\nrepresentation learning. However, most existing models ignore to represent\nhierarchical knowledge, such as the similarities and dissimilarities of\nentities in one domain. We proposed to learn a Domain Representations over\nexisting knowledge graph embedding models, such that entities that have similar\nattributes are organized into the same domain. Such hierarchical knowledge of\ndomains can give further evidence in link prediction. Experimental results show\nthat domain embeddings give a significant improvement over the most recent\nstate-of-art baseline knowledge graph embedding models.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 07:44:39 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 13:35:14 GMT"}, {"version": "v3", "created": "Thu, 16 May 2019 08:36:37 GMT"}, {"version": "v4", "created": "Wed, 11 Sep 2019 12:58:44 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Wang", "Cunxiang", ""], ["Ren", "Feiliang", ""], ["Lin", "Zhichao", ""], ["Zhao", "Chenxv", ""], ["Xie", "Tian", ""], ["Zhang", "Yue", ""]]}, {"id": "1903.10728", "submitter": "Diana Sousa", "authors": "Diana Sousa, Andre Lamurias and Francisco M. Couto", "title": "A Silver Standard Corpus of Human Phenotype-Gene Relations", "comments": "NAACL 2019", "journal-ref": "Proceedings of the 2019 Conference of the North American Chapter\n  of the Association for Computational Linguistics: Human Language\n  Technologies, Volume 1 (Long and Short Papers). 2019. pp. 1487-1492", "doi": "10.18653/v1/N19-1152", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human phenotype-gene relations are fundamental to fully understand the origin\nof some phenotypic abnormalities and their associated diseases. Biomedical\nliterature is the most comprehensive source of these relations, however, we\nneed Relation Extraction tools to automatically recognize them. Most of these\ntools require an annotated corpus and to the best of our knowledge, there is no\ncorpus available annotated with human phenotype-gene relations. This paper\npresents the Phenotype-Gene Relations (PGR) corpus, a silver standard corpus of\nhuman phenotype and gene annotations and their relations. The corpus consists\nof 1712 abstracts, 5676 human phenotype annotations, 13835 gene annotations,\nand 4283 relations. We generated this corpus using Named-Entity Recognition\ntools, whose results were partially evaluated by eight curators, obtaining a\nprecision of 87.01%. By using the corpus we were able to obtain promising\nresults with two state-of-the-art deep learning tools, namely 78.05% of\nprecision. The PGR corpus was made publicly available to the research\ncommunity.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 08:26:58 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 10:45:20 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Sousa", "Diana", ""], ["Lamurias", "Andre", ""], ["Couto", "Francisco M.", ""]]}, {"id": "1903.10735", "submitter": "Jacob Nilsson", "authors": "Jacob Nilsson and Fredrik Sandin and Jerker Delsing", "title": "Interoperability and machine-to-machine translation model with mappings\n  to machine learning tasks", "comments": "7 pages, 2 figures, 1 table, 1 listing. Submitted to the IEEE\n  International Conference on Industrial Informatics 2019, INDIN'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern large-scale automation systems integrate thousands to hundreds of\nthousands of physical sensors and actuators. Demands for more flexible\nreconfiguration of production systems and optimization across different\ninformation models, standards and legacy systems challenge current system\ninteroperability concepts. Automatic semantic translation across information\nmodels and standards is an increasingly important problem that needs to be\naddressed to fulfill these demands in a cost-efficient manner under constraints\nof human capacity and resources in relation to timing requirements and system\ncomplexity. Here we define a translator-based operational interoperability\nmodel for interacting cyber-physical systems in mathematical terms, which\nincludes system identification and ontology-based translation as special cases.\nWe present alternative mathematical definitions of the translator learning task\nand mappings to similar machine learning tasks and solutions based on recent\ndevelopments in machine learning. Possibilities to learn translators between\nartefacts without a common physical context, for example in simulations of\ndigital twins and across layers of the automation pyramid are briefly\ndiscussed.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 08:43:38 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Nilsson", "Jacob", ""], ["Sandin", "Fredrik", ""], ["Delsing", "Jerker", ""]]}, {"id": "1903.10842", "submitter": "Yuchi Zhang", "authors": "Yuchi Zhang, Yongliang Wang, Liping Zhang, Zhiqiang Zhang, Kun Gai", "title": "Improve Diverse Text Generation by Self Labeling Conditional Variational\n  Auto Encoder", "comments": "Accepted as a conference paper in ICASSP 2019. But this copy is an\n  extended version of the submitted manuscript. With more theoretical analysis\n  and human evaluation", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diversity plays a vital role in many text generating applications. In recent\nyears, Conditional Variational Auto Encoders (CVAE) have shown promising\nperformances for this task. However, they often encounter the so called\nKL-Vanishing problem. Previous works mitigated such problem by heuristic\nmethods such as strengthening the encoder or weakening the decoder while\noptimizing the CVAE objective function. Nevertheless, the optimizing direction\nof these methods are implicit and it is hard to find an appropriate degree to\nwhich these methods should be applied. In this paper, we propose an explicit\noptimizing objective to complement the CVAE to directly pull away from\nKL-vanishing. In fact, this objective term guides the encoder towards the \"best\nencoder\" of the decoder to enhance the expressiveness. A labeling network is\nintroduced to estimate the \"best encoder\". It provides a continuous label in\nthe latent space of CVAE to help build a close connection between latent\nvariables and targets. The whole proposed method is named Self Labeling\nCVAE~(SLCVAE). To accelerate the research of diverse text generation, we also\npropose a large native one-to-many dataset. Extensive experiments are conducted\non two tasks, which show that our method largely improves the generating\ndiversity while achieving comparable accuracy compared with state-of-art\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 12:53:26 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Zhang", "Yuchi", ""], ["Wang", "Yongliang", ""], ["Zhang", "Liping", ""], ["Zhang", "Zhiqiang", ""], ["Gai", "Kun", ""]]}, {"id": "1903.10915", "submitter": "Tommi Jauhiainen", "authors": "Tommi Jauhiainen, Krister Lind\\'en, Heidi Jauhiainen", "title": "Language Model Adaptation for Language and Dialect Identification of\n  Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This article describes an unsupervised language model adaptation approach\nthat can be used to enhance the performance of language identification methods.\nThe approach is applied to a current version of the HeLI language\nidentification method, which is now called HeLI 2.0. We describe the HeLI 2.0\nmethod in detail. The resulting system is evaluated using the datasets from the\nGerman dialect identification and Indo-Aryan language identification shared\ntasks of the VarDial workshops 2017 and 2018. The new approach with language\nidentification provides considerably higher F1-scores than the previous HeLI\nmethod or the other systems which participated in the shared tasks. The results\nindicate that unsupervised language model adaptation should be considered as an\noption in all language identification tasks, especially in those where\nencountering out-of-domain data is likely.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 14:19:19 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Jauhiainen", "Tommi", ""], ["Lind\u00e9n", "Krister", ""], ["Jauhiainen", "Heidi", ""]]}, {"id": "1903.10921", "submitter": "Adam Rambousek", "authors": "Adam Rambousek, Ales Horak, Vit Suchomel, Vit Baisa", "title": "A New Approach for Semi-automatic Building and Extending a Multilingual\n  Terminology Thesaurus", "comments": "Preprint of an article accepted for publication in International\n  Journal on Artificial Intelligence Tools (c) 2019 copyright World Scientific\n  Publishing Company https://www.worldscientific.com/worldscinet/ijait", "journal-ref": "International Journal on Artifical Intelligence Tools, World\n  Scientific Publishing, 2019, vol. 28, No 2", "doi": "10.1142/S0218213019500088", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a new system for semi-automatically building, extending\nand managing a terminological thesaurus---a multilingual terminology dictionary\nenriched with relationships between the terms themselves to form a thesaurus.\nThe system allows to radically enhance the workflow of current terminology\nexpert groups, where most of the editing decisions still come from\nintrospection. The presented system supplements the lexicographic process with\nnatural language processing techniques, which are seamlessly integrated to the\nthesaurus editing environment. The system's methodology and the resulting\nthesaurus are closely connected to new domain corpora in the six languages\ninvolved. They are used for term usage examples as well as for the automatic\nextraction of new candidate terms. The terminological thesaurus is now\naccessible via a web-based application, which a) presents rich detailed\ninformation on each term, b) visualizes term relations, and c) displays\nreal-life usage examples of the term in the domain-related documents and in the\ncontext-based similar terms. Furthermore, the specialized corpora are used to\ndetect candidate translations of terms from the central language (Czech) to the\nother languages (English, French, German, Russian and Slovak) as well as to\ndetect broader Czech terms, which help to place new terms in the actual\nthesaurus hierarchy. This project has been realized as a terminological\nthesaurus of land surveying, but the presented tools and methodology are\nreusable for other terminology domains.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 14:32:55 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 09:25:26 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Rambousek", "Adam", ""], ["Horak", "Ales", ""], ["Suchomel", "Vit", ""], ["Baisa", "Vit", ""]]}, {"id": "1903.10950", "submitter": "Johannes Bjerva", "authors": "Johannes Bjerva and Yova Kementchedjhieva and Ryan Cotterell and\n  Isabelle Augenstein", "title": "A Probabilistic Generative Model of Linguistic Typology", "comments": "NAACL 2019, 12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In the principles-and-parameters framework, the structural features of\nlanguages depend on parameters that may be toggled on or off, with a single\nparameter often dictating the status of multiple features. The implied\ncovariance between features inspires our probabilisation of this line of\nlinguistic inquiry---we develop a generative model of language based on\nexponential-family matrix factorisation. By modelling all languages and\nfeatures within the same architecture, we show how structural similarities\nbetween languages can be exploited to predict typological features with\nnear-perfect accuracy, outperforming several baselines on the task of\npredicting held-out features. Furthermore, we show that language embeddings\npre-trained on monolingual text allow for generalisation to unobserved\nlanguages. This finding has clear practical and also theoretical implications:\nthe results confirm what linguists have hypothesised, i.e.~that there are\nsignificant correlations between typological features and languages.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 15:14:31 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 14:34:57 GMT"}, {"version": "v3", "created": "Wed, 15 May 2019 07:59:51 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Bjerva", "Johannes", ""], ["Kementchedjhieva", "Yova", ""], ["Cotterell", "Ryan", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "1903.10963", "submitter": "Shin Nishio", "authors": "Shin Nishio, Yulu Pan, Takahiko Satoh, Hideharu Amano, and Rodney Van\n  Meter", "title": "Extracting Success from IBM's 20-Qubit Machines Using Error-Aware\n  Compilation", "comments": "15 pages, 18figures", "journal-ref": "ACM Journal on Emerging Technologies in Computing Systems (May\n  2020) Vol.16, No.3", "doi": "10.1145/3386162", "report-no": null, "categories": "quant-ph cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NISQ (Noisy, Intermediate-Scale Quantum) computing requires error mitigation\nto achieve meaningful computation. Our compilation tool development focuses on\nthe fact that the error rates of individual qubits are not equal, with a goal\nof maximizing the success probability of real-world subroutines such as an\nadder circuit. We begin by establishing a metric for choosing among possible\npaths and circuit alternatives for executing gates between variables placed far\napart within the processor, and test our approach on two IBM 20-qubit systems\nnamed Tokyo and Poughkeepsie. We find that a single-number metric describing\nthe fidelity of individual gates is a useful but imperfect guide. Our compiler\nuses this subsystem and maps complete circuits onto the machine using a beam\nsearch-based heuristic that will scale as processor and program sizes grow. To\nevaluate the whole compilation process, we compiled and executed adder\ncircuits, then calculated the KL-divergence (a measure of the distance between\ntwo probability distributions). For a circuit within the capabilities of the\nhardware, our compilation increases estimated success probability and reduces\nKL-divergence relative to an error-oblivious placement.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 15:43:36 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Nishio", "Shin", ""], ["Pan", "Yulu", ""], ["Satoh", "Takahiko", ""], ["Amano", "Hideharu", ""], ["Van Meter", "Rodney", ""]]}, {"id": "1903.10972", "submitter": "Jimmy Lin", "authors": "Wei Yang, Haotian Zhang, and Jimmy Lin", "title": "Simple Applications of BERT for Ad Hoc Document Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following recent successes in applying BERT to question answering, we explore\nsimple applications to ad hoc document retrieval. This required confronting the\nchallenge posed by documents that are typically longer than the length of input\nBERT was designed to handle. We address this issue by applying inference on\nsentences individually, and then aggregating sentence scores to produce\ndocument scores. Experiments on TREC microblog and newswire test collections\nshow that our approach is simple yet effective, as we report the highest\naverage precision on these datasets by neural approaches that we are aware of.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 15:58:33 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Yang", "Wei", ""], ["Zhang", "Haotian", ""], ["Lin", "Jimmy", ""]]}, {"id": "1903.11024", "submitter": "Reem ALRashdi", "authors": "Reem ALRashdi and Simon O'Keefe", "title": "Deep Learning and Word Embeddings for Tweet Classification for Crisis\n  Response", "comments": "This paper has been accepted and presented in the 3rd National\n  Computing Colleges Conference (NC3) in Abha, Saudi Arabia on 9th October 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tradition tweet classification models for crisis response focus on\nconvolutional layers and domain-specific word embeddings. In this paper, we\nstudy the application of different neural networks with general-purpose and\ndomain-specific word embeddings to investigate their ability to improve the\nperformance of tweet classification models. We evaluate four tweet\nclassification models on CrisisNLP dataset and obtain comparable results which\nindicates that general-purpose word embedding such as GloVe can be used instead\nof domain-specific word embedding especially with Bi-LSTM where results\nreported the highest performance of 62.04% F1 score.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 17:10:07 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["ALRashdi", "Reem", ""], ["O'Keefe", "Simon", ""]]}, {"id": "1903.11112", "submitter": "Oluwaseyi Feyisetan", "authors": "Oluwaseyi Feyisetan, Thomas Drake, Borja Balle, Tom Diethe", "title": "Privacy-preserving Active Learning on Sensitive Data for User Intent\n  Classification", "comments": "To appear at PAL: Privacy-Enhancing Artificial Intelligence and\n  Language Technologies as part of the AAAI Spring Symposium Series (AAAI-SSS\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning holds promise of significantly reducing data annotation costs\nwhile maintaining reasonable model performance. However, it requires sending\ndata to annotators for labeling. This presents a possible privacy leak when the\ntraining set includes sensitive user data. In this paper, we describe an\napproach for carrying out privacy preserving active learning with quantifiable\nguarantees. We evaluate our approach by showing the tradeoff between privacy,\nutility and annotation budget on a binary classification task in a active\nlearning setting.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 18:48:43 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Feyisetan", "Oluwaseyi", ""], ["Drake", "Thomas", ""], ["Balle", "Borja", ""], ["Diethe", "Tom", ""]]}, {"id": "1903.11222", "submitter": "Stephen Mayhew", "authors": "Stephen Mayhew, Tatiana Tsygankova, Dan Roth", "title": "ner and pos when nothing is capitalized", "comments": "Accepted to EMNLP2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For those languages which use it, capitalization is an important signal for\nthe fundamental NLP tasks of Named Entity Recognition (NER) and Part of Speech\n(POS) tagging. In fact, it is such a strong signal that model performance on\nthese tasks drops sharply in common lowercased scenarios, such as noisy web\ntext or machine translation outputs. In this work, we perform a systematic\nanalysis of solutions to this problem, modifying only the casing of the train\nor test data using lowercasing and truecasing methods. While prior work and\nfirst impressions might suggest training a caseless model, or using a truecaser\nat test time, we show that the most effective strategy is a concatenation of\ncased and lowercased training data, producing a single model with high\nperformance on both cased and uncased text. As shown in our experiments, this\nresult holds across tasks and input representations. Finally, we show that our\nproposed solution gives an 8% F1 improvement in mention detection on noisy\nout-of-domain Twitter data.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 01:57:18 GMT"}, {"version": "v2", "created": "Sat, 31 Aug 2019 13:37:55 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Mayhew", "Stephen", ""], ["Tsygankova", "Tatiana", ""], ["Roth", "Dan", ""]]}, {"id": "1903.11245", "submitter": "Mengnan Du", "authors": "Mengnan Du, Ninghao Liu, Fan Yang, Shuiwang Ji, Xia Hu", "title": "On Attribution of Recurrent Neural Network Predictions via Additive\n  Decomposition", "comments": "The 2019 Web Conference (WWW 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RNN models have achieved the state-of-the-art performance in a wide range of\ntext mining tasks. However, these models are often regarded as black-boxes and\nare criticized due to the lack of interpretability. In this paper, we enhance\nthe interpretability of RNNs by providing interpretable rationales for RNN\npredictions. Nevertheless, interpreting RNNs is a challenging problem. Firstly,\nunlike existing methods that rely on local approximation, we aim to provide\nrationales that are more faithful to the decision making process of RNN models.\nSecondly, a flexible interpretation method should be able to assign\ncontribution scores to text segments of varying lengths, instead of only to\nindividual words. To tackle these challenges, we propose a novel attribution\nmethod, called REAT, to provide interpretations to RNN predictions. REAT\ndecomposes the final prediction of a RNN into additive contribution of each\nword in the input text. This additive decomposition enables REAT to further\nobtain phrase-level attribution scores. In addition, REAT is generally\napplicable to various RNN architectures, including GRU, LSTM and their\nbidirectional versions. Experimental results demonstrate the faithfulness and\ninterpretability of the proposed attribution method. Comprehensive analysis\nshows that our attribution method could unveil the useful linguistic knowledge\ncaptured by RNNs. Some analysis further demonstrates our method could be\nutilized as a debugging tool to examine the vulnerability and failure reasons\nof RNNs, which may lead to several promising future directions to promote\ngeneralization ability of RNNs.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 04:25:57 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Du", "Mengnan", ""], ["Liu", "Ninghao", ""], ["Yang", "Fan", ""], ["Ji", "Shuiwang", ""], ["Hu", "Xia", ""]]}, {"id": "1903.11269", "submitter": "Thomas Mulc", "authors": "Kyubyong Park and Thomas Mulc", "title": "CSS10: A Collection of Single Speaker Speech Datasets for 10 Languages", "comments": "Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We describe our development of CSS10, a collection of single speaker speech\ndatasets for ten languages. It is composed of short audio clips from LibriVox\naudiobooks and their aligned texts. To validate its quality we train two neural\ntext-to-speech models on each dataset. Subsequently, we conduct Mean Opinion\nScore tests on the synthesized speech samples. We make our datasets,\npre-trained models, and test resources publicly available. We hope they will be\nused for future speech tasks.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 07:15:21 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2019 23:32:25 GMT"}, {"version": "v3", "created": "Mon, 5 Aug 2019 00:12:23 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Park", "Kyubyong", ""], ["Mulc", "Thomas", ""]]}, {"id": "1903.11283", "submitter": "Mark Fishel", "authors": "Elizaveta Korotkova, Agnes Luhtaru, Maksym Del, Krista Liin, Daiga\n  Deksne and Mark Fishel", "title": "Grammatical Error Correction and Style Transfer via Zero-shot\n  Monolingual Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Both grammatical error correction and text style transfer can be viewed as\nmonolingual sequence-to-sequence transformation tasks, but the scarcity of\ndirectly annotated data for either task makes them unfeasible for most\nlanguages. We present an approach that does both tasks within the same trained\nmodel, and only uses regular language parallel data, without requiring\nerror-corrected or style-adapted texts. We apply our model to three languages\nand present a thorough evaluation on both tasks, showing that the model is\nreliable for a number of error types and style transfer aspects.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 08:16:10 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 08:31:07 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Korotkova", "Elizaveta", ""], ["Luhtaru", "Agnes", ""], ["Del", "Maksym", ""], ["Liin", "Krista", ""], ["Deksne", "Daiga", ""], ["Fishel", "Mark", ""]]}, {"id": "1903.11299", "submitter": "Maxime Portaz", "authors": "Maxime Portaz, Hicham Randrianarivo (CEDRIC), Adrien Nivaggioli,\n  Estelle Maudet, Christophe Servan (LIUM), Sylvain Peyronnet (ELM)", "title": "Image search using multilingual texts: a cross-modal learning approach\n  between image and text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual (or cross-lingual) embeddings represent several languages in a\nunique vector space. Using a common embedding space enables for a shared\nsemantic between words from different languages. In this paper, we propose to\nembed images and texts into a unique distributional vector space, enabling to\nsearch images by using text queries expressing information needs related to the\n(visual) content of images, as well as using image similarity. Our framework\nforces the representation of an image to be similar to the representation of\nthe text that describes it. Moreover, by using multilingual embeddings we\nensure that words from two different languages have close descriptors and thus\nare attached to similar images. We provide experimental evidence of the\nefficiency of our approach by experimenting it on two datasets: Common Objects\nin COntext (COCO) [19] and Multi30K [7].\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 09:02:41 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 09:19:45 GMT"}, {"version": "v3", "created": "Tue, 14 May 2019 09:34:25 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Portaz", "Maxime", "", "CEDRIC"], ["Randrianarivo", "Hicham", "", "CEDRIC"], ["Nivaggioli", "Adrien", "", "LIUM"], ["Maudet", "Estelle", "", "LIUM"], ["Servan", "Christophe", "", "LIUM"], ["Peyronnet", "Sylvain", "", "ELM"]]}, {"id": "1903.11340", "submitter": "Tatyana Ruzsics", "authors": "Tatyana Ruzsics and Tanja Samard\\v{z}i\\'c", "title": "Multilevel Text Normalization with Sequence-to-Sequence Networks and\n  Multisource Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define multilevel text normalization as sequence-to-sequence processing\nthat transforms naturally noisy text into a sequence of normalized units of\nmeaning (morphemes) in three steps: 1) writing normalization, 2) lemmatization,\n3) canonical segmentation. These steps are traditionally considered separate\nNLP tasks, with diverse solutions, evaluation schemes and data sources. We\nexploit the fact that all these tasks involve sub-word sequence-to-sequence\ntransformation to propose a systematic solution for all of them using neural\nencoder-decoder technology. The specific challenge that we tackle in this paper\nis integrating the traditional know-how on separate tasks into the neural\nsequence-to-sequence framework to improve the state of the art. We address this\nchallenge by enriching the general framework with mechanisms that allow\nprocessing the information on multiple levels of text organization (characters,\nmorphemes, words, sentences) in combination with structural information\n(multilevel language model, part-of-speech) and heterogeneous sources (text,\ndictionaries). We show that our solution consistently improves on the current\nmethods in all three steps. In addition, we analyze the performance of our\nsystem to show the specific contribution of the integrating components to the\noverall improvement.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 10:50:23 GMT"}, {"version": "v2", "created": "Fri, 29 Mar 2019 06:38:35 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Ruzsics", "Tatyana", ""], ["Samard\u017ei\u0107", "Tanja", ""]]}, {"id": "1903.11367", "submitter": "Yang Gao", "authors": "Yang Gao, Steffen Eger, Ilia Kuznetsov, Iryna Gurevych, Yusuke Miyao", "title": "Does My Rebuttal Matter? Insights from a Major NLP Conference", "comments": "Accepted to NAACL-HLT 2019. Main paper plus supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Peer review is a core element of the scientific process, particularly in\nconference-centered fields such as ML and NLP. However, only few studies have\nevaluated its properties empirically. Aiming to fill this gap, we present a\ncorpus that contains over 4k reviews and 1.2k author responses from ACL-2018.\nWe quantitatively and qualitatively assess the corpus. This includes a pilot\nstudy on paper weaknesses given by reviewers and on quality of author\nresponses. We then focus on the role of the rebuttal phase, and propose a novel\ntask to predict after-rebuttal (i.e., final) scores from initial reviews and\nauthor responses. Although author responses do have a marginal (and\nstatistically significant) influence on the final scores, especially for\nborderline papers, our results suggest that a reviewer's final score is largely\ndetermined by her initial score and the distance to the other reviewers'\ninitial scores. In this context, we discuss the conformity bias inherent to\npeer reviewing, a bias that has largely been overlooked in previous research.\nWe hope our analyses will help better assess the usefulness of the rebuttal\nphase in NLP conferences.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 12:00:20 GMT"}, {"version": "v2", "created": "Thu, 28 Mar 2019 08:40:05 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Gao", "Yang", ""], ["Eger", "Steffen", ""], ["Kuznetsov", "Ilia", ""], ["Gurevych", "Iryna", ""], ["Miyao", "Yusuke", ""]]}, {"id": "1903.11393", "submitter": "Danny Merkx", "authors": "Danny Merkx and Stefan Frank", "title": "Learning semantic sentence representations from visually grounded\n  language without lexical knowledge", "comments": null, "journal-ref": "Natural Language Engineering, Volume 25 - Issue 4 - July 2019", "doi": "10.1017/S1351324919000196", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current approaches to learning semantic representations of sentences often\nuse prior word-level knowledge. The current study aims to leverage visual\ninformation in order to capture sentence level semantics without the need for\nword embeddings. We use a multimodal sentence encoder trained on a corpus of\nimages with matching text captions to produce visually grounded sentence\nembeddings. Deep Neural Networks are trained to map the two modalities to a\ncommon embedding space such that for an image the corresponding caption can be\nretrieved and vice versa. We show that our model achieves results comparable to\nthe current state-of-the-art on two popular image-caption retrieval benchmark\ndata sets: MSCOCO and Flickr8k. We evaluate the semantic content of the\nresulting sentence embeddings using the data from the Semantic Textual\nSimilarity benchmark task and show that the multimodal embeddings correlate\nwell with human semantic similarity judgements. The system achieves\nstate-of-the-art results on several of these benchmarks, which shows that a\nsystem trained solely on multimodal data, without assuming any word\nrepresentations, is able to capture sentence level semantics. Importantly, this\nresult shows that we do not need prior knowledge of lexical level semantics in\norder to model sentence level semantics. These findings demonstrate the\nimportance of visual information in semantics.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 12:56:37 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Merkx", "Danny", ""], ["Frank", "Stefan", ""]]}, {"id": "1903.11410", "submitter": "Marco Damonte", "authors": "Marco Damonte, Shay B. Cohen", "title": "Structural Neural Encoders for AMR-to-text Generation", "comments": "Proceedings of NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AMR-to-text generation is a problem recently introduced to the NLP community,\nin which the goal is to generate sentences from Abstract Meaning Representation\n(AMR) graphs. Sequence-to-sequence models can be used to this end by converting\nthe AMR graphs to strings. Approaching the problem while working directly with\ngraphs requires the use of graph-to-sequence models that encode the AMR graph\ninto a vector representation. Such encoding has been shown to be beneficial in\nthe past, and unlike sequential encoding, it allows us to explicitly capture\nreentrant structures in the AMR graphs. We investigate the extent to which\nreentrancies (nodes with multiple parents) have an impact on AMR-to-text\ngeneration by comparing graph encoders to tree encoders, where reentrancies are\nnot preserved. We show that improvements in the treatment of reentrancies and\nlong-range dependencies contribute to higher overall scores for graph encoders.\nOur best model achieves 24.40 BLEU on LDC2015E86, outperforming the state of\nthe art by 1.1 points and 24.54 BLEU on LDC2017T10, outperforming the state of\nthe art by 1.24 points.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 13:21:51 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 18:18:37 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Damonte", "Marco", ""], ["Cohen", "Shay B.", ""]]}, {"id": "1903.11437", "submitter": "Franck Burlot", "authors": "Franck Burlot and Fran\\c{c}ois Yvon", "title": "Using Monolingual Data in Neural Machine Translation: a Systematic Study", "comments": "Published in the Proceedings of the Third Conference on Machine\n  Translation (Research Papers), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (MT) has radically changed the way systems are\ndeveloped. A major difference with the previous generation (Phrase-Based MT) is\nthe way monolingual target data, which often abounds, is used in these two\nparadigms. While Phrase-Based MT can seamlessly integrate very large language\nmodels trained on billions of sentences, the best option for Neural MT\ndevelopers seems to be the generation of artificial parallel data through\n\\textsl{back-translation} - a technique that fails to fully take advantage of\nexisting datasets. In this paper, we conduct a systematic study of\nback-translation, comparing alternative uses of monolingual data, as well as\nmultiple data generation procedures. Our findings confirm that back-translation\nis very effective and give new explanations as to why this is the case. We also\nintroduce new data simulation techniques that are almost as effective, yet much\ncheaper to implement.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 14:11:18 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Burlot", "Franck", ""], ["Yvon", "Fran\u00e7ois", ""]]}, {"id": "1903.11508", "submitter": "Steffen Eger", "authors": "Steffen Eger and G\\\"ozde G\\\"ul \\c{S}ahin and Andreas R\\\"uckl\\'e and\n  Ji-Ung Lee and Claudia Schulz and Mohsen Mesgar and Krishnkant Swarnkar and\n  Edwin Simpson and Iryna Gurevych", "title": "Text Processing Like Humans Do: Visually Attacking and Shielding NLP\n  Systems", "comments": "Accepted as long paper at NAACL-2019; fixed one ungrammatical\n  sentence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual modifications to text are often used to obfuscate offensive comments\nin social media (e.g., \"!d10t\") or as a writing style (\"1337\" in \"leet speak\"),\namong other scenarios. We consider this as a new type of adversarial attack in\nNLP, a setting to which humans are very robust, as our experiments with both\nsimple and more difficult visual input perturbations demonstrate. We then\ninvestigate the impact of visual adversarial attacks on current NLP systems on\ncharacter-, word-, and sentence-level tasks, showing that both neural and\nnon-neural models are, in contrast to humans, extremely sensitive to such\nattacks, suffering performance decreases of up to 82\\%. We then explore three\nshielding methods---visual character embeddings, adversarial training, and\nrule-based recovery---which substantially improve the robustness of the models.\nHowever, the shielding methods still fall behind performances achieved in\nnon-attack scenarios, which demonstrates the difficulty of dealing with visual\nattacks.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 16:01:18 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 12:20:04 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Eger", "Steffen", ""], ["\u015eahin", "G\u00f6zde G\u00fcl", ""], ["R\u00fcckl\u00e9", "Andreas", ""], ["Lee", "Ji-Ung", ""], ["Schulz", "Claudia", ""], ["Mesgar", "Mohsen", ""], ["Swarnkar", "Krishnkant", ""], ["Simpson", "Edwin", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1903.11570", "submitter": "No\\'e Tits", "authors": "No\\'e Tits, Fengna Wang, Kevin El Haddad, Vincent Pagel, Thierry\n  Dutoit", "title": "Visualization and Interpretation of Latent Spaces for Controlling\n  Expressive Speech Synthesis through Audio Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of Text-to-Speech has experienced huge improvements last years\nbenefiting from deep learning techniques. Producing realistic speech becomes\npossible now. As a consequence, the research on the control of the\nexpressiveness, allowing to generate speech in different styles or manners, has\nattracted increasing attention lately. Systems able to control style have been\ndeveloped and show impressive results. However the control parameters often\nconsist of latent variables and remain complex to interpret. In this paper, we\nanalyze and compare different latent spaces and obtain an interpretation of\ntheir influence on expressive speech. This will enable the possibility to build\ncontrollable speech synthesis systems with an understandable behaviour.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 17:33:33 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Tits", "No\u00e9", ""], ["Wang", "Fengna", ""], ["Haddad", "Kevin El", ""], ["Pagel", "Vincent", ""], ["Dutoit", "Thierry", ""]]}, {"id": "1903.11770", "submitter": "Austin Blodgett", "authors": "Austin Blodgett and Nathan Schneider", "title": "An Improved Approach for Semantic Graph Composition with CCG", "comments": "IWCS 2019 Camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper builds on previous work using Combinatory Categorial Grammar (CCG)\nto derive a transparent syntax-semantics interface for Abstract Meaning\nRepresentation (AMR) parsing. We define new semantics for the CCG combinators\nthat is better suited to deriving AMR graphs. In particular, we define\nrelation-wise alternatives for the application and composition combinators:\nthese require that the two constituents being combined overlap in one AMR\nrelation. We also provide a new semantics for type raising, which is necessary\nfor certain constructions. Using these mechanisms, we suggest an analysis of\neventive nouns, which present a challenge for deriving AMR graphs. Our\ntheoretical analysis will facilitate future work on robust and transparent AMR\nparsing using CCG.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 03:09:11 GMT"}, {"version": "v2", "created": "Wed, 10 Apr 2019 18:25:12 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Blodgett", "Austin", ""], ["Schneider", "Nathan", ""]]}, {"id": "1903.11771", "submitter": "Yuta Hitomi", "authors": "Yuta Hitomi, Yuya Taguchi, Hideaki Tamori, Ko Kikuta, Jiro Nishitoba,\n  Naoaki Okazaki, Kentaro Inui, Manabu Okumura", "title": "A Large-Scale Multi-Length Headline Corpus for Analyzing\n  Length-Constrained Headline Generation Model Evaluation", "comments": "Accepted by INLG 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Browsing news articles on multiple devices is now possible. The lengths of\nnews article headlines have precise upper bounds, dictated by the size of the\ndisplay of the relevant device or interface. Therefore, controlling the length\nof headlines is essential when applying the task of headline generation to news\nproduction. However, because there is no corpus of headlines of multiple\nlengths for a given article, previous research on controlling output length in\nheadline generation has not discussed whether the system outputs could be\nadequately evaluated without multiple references of different lengths. In this\npaper, we introduce two corpora, which are Japanese News Corpus (JNC) and\nJApanese MUlti-Length Headline Corpus (JAMUL), to confirm the validity of\nprevious evaluation settings. The JNC provides common supervision data for\nheadline generation. The JAMUL is a large-scale evaluation dataset for\nheadlines of three different lengths composed by professional editors. We\nreport new findings on these corpora; for example, although the longest length\nreference summary can appropriately evaluate the existing methods controlling\noutput length, this evaluation setting has several problems.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 03:09:33 GMT"}, {"version": "v2", "created": "Fri, 29 Mar 2019 02:42:38 GMT"}, {"version": "v3", "created": "Tue, 24 Sep 2019 02:24:28 GMT"}, {"version": "v4", "created": "Thu, 26 Sep 2019 10:35:14 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Hitomi", "Yuta", ""], ["Taguchi", "Yuya", ""], ["Tamori", "Hideaki", ""], ["Kikuta", "Ko", ""], ["Nishitoba", "Jiro", ""], ["Okazaki", "Naoaki", ""], ["Inui", "Kentaro", ""], ["Okumura", "Manabu", ""]]}, {"id": "1903.11783", "submitter": "Arpit Gupta", "authors": "Michael Regan, Pushpendre Rastogi, Arpit Gupta, Lambert Mathias", "title": "A dataset for resolving referring expressions in spoken dialogue via\n  contextual query rewrites (CQR)", "comments": "9 pages, 4 figures, public corpora release", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Contextual Query Rewrite (CQR) a dataset for multi-domain\ntask-oriented spoken dialogue systems that is an extension of the Stanford\ndialog corpus (Eric et al., 2017a). While previous approaches have addressed\nthe issue of diverse schemas by learning candidate transformations (Naik et\nal., 2018), we instead model the reference resolution task as a user query\nreformulation task, where the dialog state is serialized into a natural\nlanguage query that can be executed by the downstream spoken language\nunderstanding system. In this paper, we describe our methodology for creating\nthe query reformulation extension to the dialog corpus, and present an initial\nset of experiments to establish a baseline for the CQR task. We have released\nthe corpus to the public [1] to support further research in this area.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 04:39:34 GMT"}, {"version": "v2", "created": "Fri, 29 Mar 2019 01:19:14 GMT"}, {"version": "v3", "created": "Mon, 1 Apr 2019 01:37:24 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Regan", "Michael", ""], ["Rastogi", "Pushpendre", ""], ["Gupta", "Arpit", ""], ["Mathias", "Lambert", ""]]}, {"id": "1903.11848", "submitter": "Jindou Wu", "authors": "Jindou Wu, Yunlun Yang, Chao Deng, Hongyi Tang, Bingning Wang, Haoze\n  Sun, Ting Yao, Qi Zhang", "title": "Sogou Machine Reading Comprehension Toolkit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine reading comprehension have been intensively studied in recent years,\nand neural network-based models have shown dominant performances. In this\npaper, we present a Sogou Machine Reading Comprehension (SMRC) toolkit that can\nbe used to provide the fast and efficient development of modern machine\ncomprehension models, including both published models and original prototypes.\nTo achieve this goal, the toolkit provides dataset readers, a flexible\npreprocessing pipeline, necessary neural network components, and built-in\nmodels, which make the whole process of data preparation, model construction,\nand training easier.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 09:27:23 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 11:44:10 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Wu", "Jindou", ""], ["Yang", "Yunlun", ""], ["Deng", "Chao", ""], ["Tang", "Hongyi", ""], ["Wang", "Bingning", ""], ["Sun", "Haoze", ""], ["Yao", "Ting", ""], ["Zhang", "Qi", ""]]}, {"id": "1903.11850", "submitter": "Damien Sileo", "authors": "Damien Sileo, Tim Van-De-Cruys, Camille Pradel, Philippe Muller", "title": "Mining Discourse Markers for Unsupervised Sentence Representation\n  Learning", "comments": "Camera-ready for NAACL HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current state of the art systems in NLP heavily rely on manually annotated\ndatasets, which are expensive to construct. Very little work adequately\nexploits unannotated data -- such as discourse markers between sentences --\nmainly because of data sparseness and ineffective extraction methods. In the\npresent work, we propose a method to automatically discover sentence pairs with\nrelevant discourse markers, and apply it to massive amounts of data. Our\nresulting dataset contains 174 discourse markers with at least 10k examples\neach, even for rare markers such as coincidentally or amazingly We use the\nresulting data as supervision for learning transferable sentence embeddings. In\naddition, we show that even though sentence representation learning through\nprediction of discourse markers yields state of the art results across\ndifferent transfer tasks, it is not clear that our models made use of the\nsemantic relation between sentences, thus leaving room for further\nimprovements. Our datasets are publicly available\n(https://github.com/synapse-developpement/Discovery)\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 09:30:16 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Sileo", "Damien", ""], ["Van-De-Cruys", "Tim", ""], ["Pradel", "Camille", ""], ["Muller", "Philippe", ""]]}, {"id": "1903.11919", "submitter": "Wu Xing", "authors": "Tao Zhang, Xing Wu, Meng Lin, Jizhong Han, Songlin Hu", "title": "Imbalanced Sentiment Classification Enhanced with Discourse Marker", "comments": "12 pages, 1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imbalanced data commonly exists in real world, espacially in\nsentiment-related corpus, making it difficult to train a classifier to\ndistinguish latent sentiment in text data. We observe that humans often express\ntransitional emotion between two adjacent discourses with discourse markers\nlike \"but\", \"though\", \"while\", etc, and the head discourse and the tail\ndiscourse 3 usually indicate opposite emotional tendencies. Based on this\nobservation, we propose a novel plug-and-play method, which first samples\ndiscourses according to transitional discourse markers and then validates\nsentimental polarities with the help of a pretrained attention-based model. Our\nmethod increases sample diversity in the first place, can serve as a upstream\npreprocessing part in data augmentation. We conduct experiments on three public\nsentiment datasets, with several frequently used algorithms. Results show that\nour method is found to be consistently effective, even in highly imbalanced\nscenario, and easily be integrated with oversampling method to boost the\nperformance on imbalanced sentiment classification.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 12:38:58 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Zhang", "Tao", ""], ["Wu", "Xing", ""], ["Lin", "Meng", ""], ["Han", "Jizhong", ""], ["Hu", "Songlin", ""]]}, {"id": "1903.11983", "submitter": "Adil \\c{C}oban", "authors": "\\.Ilhan Tar{\\i}mer, Adil \\c{C}oban and Arif Emre Kocaman", "title": "Sentiment Analysis on IMDB Movie Comments and Twitter Data by Machine\n  Learning and Vector Space Techniques", "comments": "8 pages, submitted to CIEA2018 (http://iciea.cumhuriyet.edu.tr/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This study's goal is to create a model of sentiment analysis on a 2000 rows\nIMDB movie comments and 3200 Twitter data by using machine learning and vector\nspace techniques; positive or negative preliminary information about the text\nis to provide. In the study, a vector space was created in the KNIME Analytics\nplatform, and a classification study was performed on this vector space by\nDecision Trees, Na\\\"ive Bayes and Support Vector Machines classification\nalgorithms. The conclusions obtained were compared in terms of each algorithms.\nThe classification results for IMDB movie comments are obtained as 94,00%,\n73,20%, and 85,50% by Decision Tree, Naive Bayes and SVM algorithms. The\nclassification results for Twitter data set are presented as 82,76%, 75,44% and\n72,50% by Decision Tree, Naive Bayes SVM algorithms as well. It is seen that\nthe best classification results presented in both data sets are which\ncalculated by SVM algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 09:25:10 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Tar\u0131mer", "\u0130lhan", ""], ["\u00c7oban", "Adil", ""], ["Kocaman", "Arif Emre", ""]]}, {"id": "1903.12008", "submitter": "Debjit Paul", "authors": "Debjit Paul, Mittul Singh, Michael A. Hedderich and Dietrich Klakow", "title": "Handling Noisy Labels for Robustly Learning from Self-Training Data for\n  Low-Resource Sequence Labeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the problem of effectively self-training neural\nnetworks in a low-resource setting. Self-training is frequently used to\nautomatically increase the amount of training data. However, in a low-resource\nscenario, it is less effective due to unreliable annotations created using\nself-labeling of unlabeled data. We propose to combine self-training with noise\nhandling on the self-labeled data. Directly estimating noise on the combined\nclean training set and self-labeled data can lead to corruption of the clean\ndata and hence, performs worse. Thus, we propose the Clean and Noisy Label\nNeural Network which trains on clean and noisy self-labeled data simultaneously\nby explicitly modelling clean and noisy labels separately. In our experiments\non Chunking and NER, this approach performs more robustly than the baselines.\nComplementary to this explicit approach, noise can also be handled implicitly\nwith the help of an auxiliary learning task. To such a complementary approach,\nour method is more beneficial than other baseline methods and together provides\nthe best performance overall.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 14:33:50 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Paul", "Debjit", ""], ["Singh", "Mittul", ""], ["Hedderich", "Michael A.", ""], ["Klakow", "Dietrich", ""]]}, {"id": "1903.12017", "submitter": "Robert Schwarzenberg", "authors": "Robert Schwarzenberg, David Harbecke, Vivien Macketanz, Eleftherios\n  Avramidis, Sebastian M\\\"oller", "title": "Train, Sort, Explain: Learning to Diagnose Translation Models", "comments": "NAACL-HLT 2019: Demonstrations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluating translation models is a trade-off between effort and detail. On\nthe one end of the spectrum there are automatic count-based methods such as\nBLEU, on the other end linguistic evaluations by humans, which arguably are\nmore informative but also require a disproportionately high effort. To narrow\nthe spectrum, we propose a general approach on how to automatically expose\nsystematic differences between human and machine translations to human experts.\nInspired by adversarial settings, we train a neural text classifier to\ndistinguish human from machine translations. A classifier that performs and\ngeneralizes well after training should recognize systematic differences between\nthe two classes, which we uncover with neural explainability methods. Our\nproof-of-concept implementation, DiaMaT, is open source. Applied to a dataset\ntranslated by a state-of-the-art neural Transformer model, DiaMaT achieves a\nclassification accuracy of 75% and exposes meaningful differences between\nhumans and the Transformer, amidst the current discussion about human parity.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 14:45:42 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Schwarzenberg", "Robert", ""], ["Harbecke", "David", ""], ["Macketanz", "Vivien", ""], ["Avramidis", "Eleftherios", ""], ["M\u00f6ller", "Sebastian", ""]]}, {"id": "1903.12136", "submitter": "Raphael Tang", "authors": "Raphael Tang, Yao Lu, Linqing Liu, Lili Mou, Olga Vechtomova, Jimmy\n  Lin", "title": "Distilling Task-Specific Knowledge from BERT into Simple Neural Networks", "comments": "8 pages, 2 figures; first three authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the natural language processing literature, neural networks are becoming\nincreasingly deeper and complex. The recent poster child of this trend is the\ndeep language representation model, which includes BERT, ELMo, and GPT. These\ndevelopments have led to the conviction that previous-generation, shallower\nneural networks for language understanding are obsolete. In this paper,\nhowever, we demonstrate that rudimentary, lightweight neural networks can still\nbe made competitive without architecture changes, external training data, or\nadditional input features. We propose to distill knowledge from BERT, a\nstate-of-the-art language representation model, into a single-layer BiLSTM, as\nwell as its siamese counterpart for sentence-pair tasks. Across multiple\ndatasets in paraphrasing, natural language inference, and sentiment\nclassification, we achieve comparable results with ELMo, while using roughly\n100 times fewer parameters and 15 times less inference time.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 17:23:50 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Tang", "Raphael", ""], ["Lu", "Yao", ""], ["Liu", "Linqing", ""], ["Mou", "Lili", ""], ["Vechtomova", "Olga", ""], ["Lin", "Jimmy", ""]]}, {"id": "1903.12157", "submitter": "Athanasios Giannakopoulos", "authors": "Athanasios Giannakopoulos, Maxime Coriou, Andreea Hossmann, Michael\n  Baeriswyl, Claudiu Musat", "title": "Resilient Combination of Complementary CNN and RNN Features for Text\n  Classification through Attention and Ensembling", "comments": "5 pages, 1 figure, SDS 2019 - The 6th Swiss Conference on Data\n  Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art methods for text classification include several distinct\nsteps of pre-processing, feature extraction and post-processing. In this work,\nwe focus on end-to-end neural architectures and show that the best performance\nin text classification is obtained by combining information from different\nneural modules. Concretely, we combine convolution, recurrent and attention\nmodules with ensemble methods and show that they are complementary. We\nintroduce ECGA, an end-to-end go-to architecture for novel text classification\ntasks. We prove that it is efficient and robust, as it attains or surpasses the\nstate-of-the-art on varied datasets, including both low and high data regimes.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 17:43:09 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Giannakopoulos", "Athanasios", ""], ["Coriou", "Maxime", ""], ["Hossmann", "Andreea", ""], ["Baeriswyl", "Michael", ""], ["Musat", "Claudiu", ""]]}, {"id": "1903.12238", "submitter": "Sushant Kafle", "authors": "Sushant Kafle, Cecilia O. Alm, Matt Huenerfauth", "title": "Modeling Acoustic-Prosodic Cues for Word Importance Prediction in Spoken\n  Dialogues", "comments": "8 pages, 2 figures", "journal-ref": "Proceedings of the Eighth Workshop on Speech and Language\n  Processing for Assistive Technologies. 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prosodic cues in conversational speech aid listeners in discerning a message.\nWe investigate whether acoustic cues in spoken dialogue can be used to identify\nthe importance of individual words to the meaning of a conversation turn.\nIndividuals who are Deaf and Hard of Hearing often rely on real-time captions\nin live meetings. Word error rate, a traditional metric for evaluating\nautomatic speech recognition, fails to capture that some words are more\nimportant for a system to transcribe correctly than others. We present and\nevaluate neural architectures that use acoustic features for 3-class word\nimportance prediction. Our model performs competitively against\nstate-of-the-art text-based word-importance prediction models, and it\ndemonstrates particular benefits when operating on imperfect ASR output.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 19:43:57 GMT"}, {"version": "v2", "created": "Tue, 16 Jul 2019 21:58:17 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Kafle", "Sushant", ""], ["Alm", "Cecilia O.", ""], ["Huenerfauth", "Matt", ""]]}, {"id": "1903.12271", "submitter": "Mahmoud El-Haj", "authors": "Mahmoud El-Haj, Paul Rayson, Martin Walker, Steven Young, Vasiliki\n  Simaki", "title": "In Search of Meaning: Lessons, Resources and Next Steps for\n  Computational Analysis of Financial Discourse", "comments": "70 page, 18 pages of references, Journal Article", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We critically assess mainstream accounting and finance research applying\nmethods from computational linguistics (CL) to study financial discourse. We\nalso review common themes and innovations in the literature and assess the\nincremental contributions of work applying CL methods over manual content\nanalysis. Key conclusions emerging from our analysis are: (a) accounting and\nfinance research is behind the curve in terms of CL methods generally and word\nsense disambiguation in particular; (b) implementation issues mean the proposed\nbenefits of CL are often less pronounced than proponents suggest; (c)\nstructural issues limit practical relevance; and (d) CL methods and high\nquality manual analysis represent complementary approaches to analyzing\nfinancial discourse. We describe four CL tools that have yet to gain traction\nin mainstream AF research but which we believe offer promising ways to enhance\nthe study of meaning in financial discourse. The four tools are named entity\nrecognition (NER), summarization, semantics and corpus linguistics.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 21:12:59 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["El-Haj", "Mahmoud", ""], ["Rayson", "Paul", ""], ["Walker", "Martin", ""], ["Young", "Steven", ""], ["Simaki", "Vasiliki", ""]]}, {"id": "1903.12306", "submitter": "Shane Settle", "authors": "Shane Settle, Kartik Audhkhasi, Karen Livescu, Michael Picheny", "title": "Acoustically Grounded Word Embeddings for Improved Acoustics-to-Word\n  Speech Recognition", "comments": "To appear at ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Direct acoustics-to-word (A2W) systems for end-to-end automatic speech\nrecognition are simpler to train, and more efficient to decode with, than\nsub-word systems. However, A2W systems can have difficulties at training time\nwhen data is limited, and at decoding time when recognizing words outside the\ntraining vocabulary. To address these shortcomings, we investigate the use of\nrecently proposed acoustic and acoustically grounded word embedding techniques\nin A2W systems. The idea is based on treating the final pre-softmax weight\nmatrix of an AWE recognizer as a matrix of word embedding vectors, and using an\nexternally trained set of word embeddings to improve the quality of this\nmatrix. In particular we introduce two ideas: (1) Enforcing similarity at\ntraining time between the external embeddings and the recognizer weights, and\n(2) using the word embeddings at test time for predicting out-of-vocabulary\nwords. Our word embedding model is acoustically grounded, that is it is learned\njointly with acoustic embeddings so as to encode the words' acoustic-phonetic\ncontent; and it is parametric, so that it can embed any arbitrary (potentially\nout-of-vocabulary) sequence of characters. We find that both techniques improve\nthe performance of an A2W recognizer on conversational telephone speech.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 00:44:14 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Settle", "Shane", ""], ["Audhkhasi", "Kartik", ""], ["Livescu", "Karen", ""], ["Picheny", "Michael", ""]]}, {"id": "1903.12354", "submitter": "Ivan Vankov", "authors": "Ivan Vankov, Jeffrey Bowers", "title": "Training neural networks to encode symbols enables combinatorial\n  generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combinatorial generalization - the ability to understand and produce novel\ncombinations of already familiar elements - is considered to be a core capacity\nof the human mind and a major challenge to neural network models. A significant\nbody of research suggests that conventional neural networks can't solve this\nproblem unless they are endowed with mechanisms specifically engineered for the\npurpose of representing symbols. In this paper we introduce a novel way of\nrepresenting symbolic structures in connectionist terms - the vectors approach\nto representing symbols (VARS), which allows training standard neural\narchitectures to encode symbolic knowledge explicitly at their output layers.\nIn two simulations, we show that neural networks not only can learn to produce\nVARS representations, but in doing so they achieve combinatorial generalization\nin their symbolic and non-symbolic output. This adds to other recent work that\nhas shown improved combinatorial generalization under specific training\nconditions, and raises the question of whether specific mechanisms or training\nroutines are needed to support symbolic processing.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 05:02:51 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 08:40:06 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Vankov", "Ivan", ""], ["Bowers", "Jeffrey", ""]]}, {"id": "1903.12356", "submitter": "Dekun Wu", "authors": "Dekun Wu, Nana Nosirova, Hui Jiang, Mingbin Xu", "title": "A General FOFE-net Framework for Simple and Effective Question Answering\n  over Knowledge Bases", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question answering over knowledge base (KB-QA) has recently become a popular\nresearch topic in NLP. One popular way to solve the KB-QA problem is to make\nuse of a pipeline of several NLP modules, including entity discovery and\nlinking (EDL) and relation detection. Recent success on KB-QA task usually\ninvolves complex network structures with sophisticated heuristics. Inspired by\na previous work that builds a strong KB-QA baseline, we propose a simple but\ngeneral neural model composed of fixed-size ordinally forgetting encoding\n(FOFE) and deep neural networks, called FOFE-net to solve KB-QA problem at\ndifferent stages. For evaluation, we use two popular KB-QA datasets,\nSimpleQuestions and WebQSP, and a newly created dataset, FreebaseQA. The\nexperimental results show that FOFE-net performs well on KB-QA subtasks, entity\ndiscovery and linking (EDL) and relation detection, and in turn pushing overall\nKB-QA system to achieve strong results on all datasets.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 05:15:58 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Wu", "Dekun", ""], ["Nosirova", "Nana", ""], ["Jiang", "Hui", ""], ["Xu", "Mingbin", ""]]}, {"id": "1903.12389", "submitter": "Junichi Yamagishi", "authors": "Mingyang Zhang, Xin Wang, Fuming Fang, Haizhou Li, Junichi Yamagishi", "title": "Joint training framework for text-to-speech and voice conversion using\n  multi-source Tacotron and WaveNet", "comments": "Submitted to Interspeech 2019, Graz, Austria", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigated the training of a shared model for both text-to-speech (TTS)\nand voice conversion (VC) tasks. We propose using an extended model\narchitecture of Tacotron, that is a multi-source sequence-to-sequence model\nwith a dual attention mechanism as the shared model for both the TTS and VC\ntasks. This model can accomplish these two different tasks respectively\naccording to the type of input. An end-to-end speech synthesis task is\nconducted when the model is given text as the input while a\nsequence-to-sequence voice conversion task is conducted when it is given the\nspeech of a source speaker as the input. Waveform signals are generated by\nusing WaveNet, which is conditioned by using a predicted mel-spectrogram. We\npropose jointly training a shared model as a decoder for a target speaker that\nsupports multiple sources. Listening experiments show that our proposed\nmulti-source encoder-decoder model can efficiently achieve both the TTS and VC\ntasks.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 08:26:13 GMT"}, {"version": "v2", "created": "Sun, 7 Apr 2019 23:40:14 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Zhang", "Mingyang", ""], ["Wang", "Xin", ""], ["Fang", "Fuming", ""], ["Li", "Haizhou", ""], ["Yamagishi", "Junichi", ""]]}, {"id": "1903.12392", "submitter": "Junichi Yamagishi", "authors": "Shinji Takaki, Hirokazu Kameoka, Junichi Yamagishi", "title": "Training a Neural Speech Waveform Model using Spectral Losses of\n  Short-Time Fourier Transform and Continuous Wavelet Transform", "comments": "Submitted to Interspeech 2019, Graz, Austria", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, we proposed short-time Fourier transform (STFT)-based loss\nfunctions for training a neural speech waveform model. In this paper, we\ngeneralize the above framework and propose a training scheme for such models\nbased on spectral amplitude and phase losses obtained by either STFT or\ncontinuous wavelet transform (CWT), or both of them. Since CWT is capable of\nhaving time and frequency resolutions different from those of STFT and is cable\nof considering those closer to human auditory scales, the proposed loss\nfunctions could provide complementary information on speech signals.\nExperimental results showed that it is possible to train a high-quality model\nby using the proposed CWT spectral loss and is as good as one using STFT-based\nloss.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 08:36:06 GMT"}, {"version": "v2", "created": "Sun, 7 Apr 2019 23:37:21 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Takaki", "Shinji", ""], ["Kameoka", "Hirokazu", ""], ["Yamagishi", "Junichi", ""]]}, {"id": "1903.12424", "submitter": "Zixing Zhang", "authors": "Zixing Zhang, Bingwen Wu, Bjoern Schuller", "title": "Attention-Augmented End-to-End Multi-Task Learning for Emotion\n  Prediction from Speech", "comments": "accepted by ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the increasing research interest in end-to-end learning systems for\nspeech emotion recognition, conventional systems either suffer from the\noverfitting due in part to the limited training data, or do not explicitly\nconsider the different contributions of automatically learnt representations\nfor a specific task. In this contribution, we propose a novel end-to-end\nframework which is enhanced by learning other auxiliary tasks and an attention\nmechanism. That is, we jointly train an end-to-end network with several\ndifferent but related emotion prediction tasks, i.e., arousal, valence, and\ndominance predictions, to extract more robust representations shared among\nvarious tasks than traditional systems with the hope that it is able to relieve\nthe overfitting problem. Meanwhile, an attention layer is implemented on top of\nthe layers for each task, with the aim to capture the contribution distribution\nof different segment parts for each individual task. To evaluate the\neffectiveness of the proposed system, we conducted a set of experiments on the\nwidely used database IEMOCAP. The empirical results show that the proposed\nsystems significantly outperform corresponding baseline systems.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 09:57:45 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Zhang", "Zixing", ""], ["Wu", "Bingwen", ""], ["Schuller", "Bjoern", ""]]}, {"id": "1903.12431", "submitter": "Lahari Poddar", "authors": "Lahari Poddar, Leonardo Neves, William Brendel, Luis Marujo, Sergey\n  Tulyakov, Pradeep Karuturi", "title": "Train One Get One Free: Partially Supervised Neural Network for Bug\n  Report Duplicate Detection and Clustering", "comments": "Accepted for publication in NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tracking user reported bugs requires considerable engineering effort in going\nthrough many repetitive reports and assigning them to the correct teams. This\npaper proposes a neural architecture that can jointly (1) detect if two bug\nreports are duplicates, and (2) aggregate them into latent topics. Leveraging\nthe assumption that learning the topic of a bug is a sub-task for detecting\nduplicates, we design a loss function that can jointly perform both tasks but\nneeds supervision for only duplicate classification, achieving topic clustering\nin an unsupervised fashion. We use a two-step attention module that uses\nself-attention for topic clustering and conditional attention for duplicate\ndetection. We study the characteristics of two types of real world datasets\nthat have been marked for duplicate bugs by engineers and by non-technical\nannotators. The results demonstrate that our model not only can outperform\nstate-of-the-art methods for duplicate classification on both cases, but can\nalso learn meaningful latent clusters without additional supervision.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 10:15:45 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 03:18:28 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Poddar", "Lahari", ""], ["Neves", "Leonardo", ""], ["Brendel", "William", ""], ["Marujo", "Luis", ""], ["Tulyakov", "Sergey", ""], ["Karuturi", "Pradeep", ""]]}, {"id": "1903.12452", "submitter": "Oscar Araque", "authors": "Rodrigo Barbado, Oscar Araque and Carlos A. Iglesias", "title": "A framework for fake review detection in online consumer electronics\n  retailers", "comments": "Information Processing & Management, 11 pages", "journal-ref": "Information Processing & Management, ISSN 0306-4573, Volume 56,\n  Issue 4, July 2019", "doi": "10.1016/j.ipm.2019.03.002", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The impact of online reviews on businesses has grown significantly during\nlast years, being crucial to determine business success in a wide array of\nsectors, ranging from restaurants, hotels to e-commerce. Unfortunately, some\nusers use unethical means to improve their online reputation by writing fake\nreviews of their businesses or competitors. Previous research has addressed\nfake review detection in a number of domains, such as product or business\nreviews in restaurants and hotels. However, in spite of its economical\ninterest, the domain of consumer electronics businesses has not yet been\nthoroughly studied. This article proposes a feature framework for detecting\nfake reviews that has been evaluated in the consumer electronics domain. The\ncontributions are fourfold: (i) Construction of a dataset for classifying fake\nreviews in the consumer electronics domain in four different cities based on\nscraping techniques; (ii) definition of a feature framework for fake review\ndetection; (iii) development of a fake review classification method based on\nthe proposed framework and (iv) evaluation and analysis of the results for each\nof the cities under study. We have reached an 82% F-Score on the classification\ntask and the Ada Boost classifier has been proven to be the best one by\nstatistical means according to the Friedman test.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 11:24:40 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Barbado", "Rodrigo", ""], ["Araque", "Oscar", ""], ["Iglesias", "Carlos A.", ""]]}, {"id": "1903.12453", "submitter": "Roman Klinger", "authors": "Evgeny Kim and Roman Klinger", "title": "Frowning Frodo, Wincing Leia, and a Seriously Great Friendship: Learning\n  to Classify Emotional Relationships of Fictional Characters", "comments": "Accepted for publication at NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The development of a fictional plot is centered around characters who closely\ninteract with each other forming dynamic social networks. In literature\nanalysis, such networks have mostly been analyzed without particular relation\ntypes or focusing on roles which the characters take with respect to each\nother. We argue that an important aspect for the analysis of stories and their\ndevelopment is the emotion between characters. In this paper, we combine these\naspects into a unified framework to classify emotional relationships of\nfictional characters. We formalize it as a new task and describe the annotation\nof a corpus, based on fan-fiction short stories. The extraction pipeline which\nwe propose consists of character identification (which we treat as given by an\noracle here) and the relation classification. For the latter, we provide\nresults using several approaches previously proposed for relation\nidentification with neural methods. The best result of 0.45 F1 is achieved with\na GRU with character position indicators on the task of predicting undirected\nemotion relations in the associated social network graph.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 11:26:14 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 07:53:33 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Kim", "Evgeny", ""], ["Klinger", "Roman", ""]]}, {"id": "1903.12457", "submitter": "Qibin Chen", "authors": "Qibin Chen, Junyang Lin, Yichang Zhang, Hongxia Yang, Jingren Zhou,\n  Jie Tang", "title": "Towards Knowledge-Based Personalized Product Description Generation in\n  E-commerce", "comments": "KDD 2019 Camera-ready. Website:\n  https://sites.google.com/view/kobe2019", "journal-ref": null, "doi": "10.1145/3292500.3330725", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quality product descriptions are critical for providing competitive customer\nexperience in an e-commerce platform. An accurate and attractive description\nnot only helps customers make an informed decision but also improves the\nlikelihood of purchase. However, crafting a successful product description is\ntedious and highly time-consuming. Due to its importance, automating the\nproduct description generation has attracted considerable interests from both\nresearch and industrial communities. Existing methods mainly use templates or\nstatistical methods, and their performance could be rather limited. In this\npaper, we explore a new way to generate the personalized product description by\ncombining the power of neural networks and knowledge base. Specifically, we\npropose a KnOwledge Based pErsonalized (or KOBE) product description generation\nmodel in the context of e-commerce. In KOBE, we extend the encoder-decoder\nframework, the Transformer, to a sequence modeling formulation using\nself-attention. In order to make the description both informative and\npersonalized, KOBE considers a variety of important factors during text\ngeneration, including product aspects, user categories, and knowledge base,\netc. Experiments on real-world datasets demonstrate that the proposed method\nout-performs the baseline on various metrics. KOBE can achieve an improvement\nof 9.7% over state-of-the-arts in terms of BLEU. We also present several case\nstudies as the anecdotal evidence to further prove the effectiveness of the\nproposed approach. The framework has been deployed in Taobao, the largest\nonline e-commerce platform in China.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 11:57:24 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2019 04:26:33 GMT"}, {"version": "v3", "created": "Wed, 5 Jun 2019 07:35:08 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Chen", "Qibin", ""], ["Lin", "Junyang", ""], ["Zhang", "Yichang", ""], ["Yang", "Hongxia", ""], ["Zhou", "Jingren", ""], ["Tang", "Jie", ""]]}, {"id": "1903.12495", "submitter": "Deepak Thukral", "authors": "Deepak Thukral, Darvesh Punia", "title": "Crowd Sourced Data Analysis: Mapping of Programming Concepts to\n  Syntactical Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Since programming concepts do not match their syntactic representations, code\nsearch is a very tedious task. For instance in Java or C, array doesn't match\n[], so using \"array\" as a query, one cannot find what they are looking for.\nOften developers have to search code whether to understand any code, or to\nreuse some part of that code, or just to read it, without natural language\nsearching, developers have to often scroll back and forth or use variable names\nas their queries. In our work, we have used Stackoverflow (SO) question and\nanswers to make a mapping of programming concepts with their respective natural\nlanguage keywords, and then tag these natural language terms to every line of\ncode, which can further we used in searching using natural language keywords.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 15:13:20 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Thukral", "Deepak", ""], ["Punia", "Darvesh", ""]]}, {"id": "1903.12520", "submitter": "Anurag Illendula", "authors": "Anurag Illendula, Amit Sheth", "title": "Multimodal Emotion Classification", "comments": "Accepted at the 2nd Emoji Workshop co-located with The Web Conference\n  2019", "journal-ref": "Companion Proceedings of the 2019 World Wide Web Conference", "doi": "10.1145/3308560.3316549", "report-no": null, "categories": "cs.CV cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most NLP and Computer Vision tasks are limited to scarcity of labelled data.\nIn social media emotion classification and other related tasks, hashtags have\nbeen used as indicators to label data. With the rapid increase in emoji usage\nof social media, emojis are used as an additional feature for major social NLP\ntasks. However, this is less explored in case of multimedia posts on social\nmedia where posts are composed of both image and text. At the same time, w.e\nhave seen a surge in the interest to incorporate domain knowledge to improve\nmachine understanding of text. In this paper, we investigate whether domain\nknowledge for emoji can improve the accuracy of emotion classification task. We\nexploit the importance of different modalities from social media post for\nemotion classification task using state-of-the-art deep learning architectures.\nOur experiments demonstrate that the three modalities (text, emoji and images)\nencode different information to express emotion and therefore can complement\neach other. Our results also demonstrate that emoji sense depends on the\ntextual context, and emoji combined with text encodes better information than\nconsidered separately. The highest accuracy of 71.98\\% is achieved with a\ntraining data of 550k posts.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 07:54:29 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Illendula", "Anurag", ""], ["Sheth", "Amit", ""]]}, {"id": "1903.12542", "submitter": "Areej Alokaili", "authors": "Areej Alokaili, Nikolaos Aletras and Mark Stevenson", "title": "Re-Ranking Words to Improve Interpretability of Automatically Generated\n  Topics", "comments": "Paper accepted for publication at IWCS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topics models, such as LDA, are widely used in Natural Language Processing.\nMaking their output interpretable is an important area of research with\napplications to areas such as the enhancement of exploratory search interfaces\nand the development of interpretable machine learning models. Conventionally,\ntopics are represented by their n most probable words, however, these\nrepresentations are often difficult for humans to interpret. This paper\nexplores the re-ranking of topic words to generate more interpretable topic\nrepresentations. A range of approaches are compared and evaluated in two\nexperiments. The first uses crowdworkers to associate topics represented by\ndifferent word rankings with related documents. The second experiment is an\nautomatic approach based on a document retrieval task applied on multiple\ndomains. Results in both experiments demonstrate that re-ranking words improves\ntopic interpretability and that the most effective re-ranking schemes were\nthose which combine information about the importance of words both within\ntopics and their relative frequency in the entire corpus. In addition, close\ncorrelation between the results of the two evaluation approaches suggests that\nthe automatic method proposed here could be used to evaluate re-ranking methods\nwithout the need for human judgements.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 14:32:02 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Alokaili", "Areej", ""], ["Aletras", "Nikolaos", ""], ["Stevenson", "Mark", ""]]}, {"id": "1903.12626", "submitter": "Jingqing Zhang", "authors": "Jingqing Zhang, Piyawat Lertvittayakumjorn, Yike Guo", "title": "Integrating Semantic Knowledge to Tackle Zero-shot Text Classification", "comments": "Accepted NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Insufficient or even unavailable training data of emerging classes is a big\nchallenge of many classification tasks, including text classification.\nRecognising text documents of classes that have never been seen in the learning\nstage, so-called zero-shot text classification, is therefore difficult and only\nlimited previous works tackled this problem. In this paper, we propose a\ntwo-phase framework together with data augmentation and feature augmentation to\nsolve this problem. Four kinds of semantic knowledge (word embeddings, class\ndescriptions, class hierarchy, and a general knowledge graph) are incorporated\ninto the proposed framework to deal with instances of unseen classes\neffectively. Experimental results show that each and the combination of the two\nphases achieve the best overall accuracy compared with baselines and recent\napproaches in classifying real-world texts under the zero-shot scenario.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 17:22:40 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Zhang", "Jingqing", ""], ["Lertvittayakumjorn", "Piyawat", ""], ["Guo", "Yike", ""]]}]