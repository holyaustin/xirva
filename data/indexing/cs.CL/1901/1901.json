[{"id": "1901.00056", "submitter": "Chenwei Zhang", "authors": "Chenwei Zhang, Yaliang Li, Nan Du, Wei Fan, Philip S. Yu", "title": "Entity Synonym Discovery via Multipiece Bilateral Context Matching", "comments": "In IJCAI 2020 as a long paper. Code and data are available at\n  https://github.com/czhang99/SynonymNet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Being able to automatically discover synonymous entities in an open-world\nsetting benefits various tasks such as entity disambiguation or knowledge graph\ncanonicalization. Existing works either only utilize entity features, or rely\non structured annotations from a single piece of context where the entity is\nmentioned. To leverage diverse contexts where entities are mentioned, in this\npaper, we generalize the distributional hypothesis to a multi-context setting\nand propose a synonym discovery framework that detects entity synonyms from\nfree-text corpora with considerations on effectiveness and robustness. As one\nof the key components in synonym discovery, we introduce a neural network model\nSYNONYMNET to determine whether or not two given entities are synonym with each\nother. Instead of using entities features, SYNONYMNET makes use of multiple\npieces of contexts in which the entity is mentioned, and compares the\ncontext-level similarity via a bilateral matching schema. Experimental results\ndemonstrate that the proposed model is able to detect synonym sets that are not\nobserved during training on both generic and domain-specific datasets:\nWiki+Freebase, PubMed+UMLS, and MedBook+MKG, with up to 4.16% improvement in\nterms of Area Under the Curve and 3.19% in terms of Mean Average Precision\ncompared to the best baseline method.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 22:05:05 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 01:01:12 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Zhang", "Chenwei", ""], ["Li", "Yaliang", ""], ["Du", "Nan", ""], ["Fan", "Wei", ""], ["Yu", "Philip S.", ""]]}, {"id": "1901.00066", "submitter": "Mahtab Ahmed", "authors": "Mahtab Ahmed, Muhammad Rifayat Samee, Robert E. Mercer", "title": "Improving Tree-LSTM with Tree Attention", "comments": "8 Pages, 3 figures, Accepted in The 13th IEEE International\n  Conference on Semantic Computing (ICSC 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In Natural Language Processing (NLP), we often need to extract information\nfrom tree topology. Sentence structure can be represented via a dependency tree\nor a constituency tree structure. For this reason, a variant of LSTMs, named\nTree-LSTM, was proposed to work on tree topology. In this paper, we design a\ngeneralized attention framework for both dependency and constituency trees by\nencoding variants of decomposable attention inside a Tree-LSTM cell. We\nevaluated our models on a semantic relatedness task and achieved notable\nresults compared to Tree-LSTM based methods with no attention as well as other\nneural and non-neural methods and good results compared to Tree-LSTM based\nmethods with attention.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2019 00:15:45 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Ahmed", "Mahtab", ""], ["Samee", "Muhammad Rifayat", ""], ["Mercer", "Robert E.", ""]]}, {"id": "1901.00072", "submitter": "Sean Robertson", "authors": "Sean Robertson, Gerald Penn, Yingxue Wang", "title": "Exploring spectro-temporal features in end-to-end convolutional neural\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Triangular, overlapping Mel-scaled filters (\"f-banks\") are the current\nstandard input for acoustic models that exploit their input's time-frequency\ngeometry, because they provide a psycho-acoustically motivated time-frequency\ngeometry for a speech signal. F-bank coefficients are provably robust to small\ndeformations in the scale. In this paper, we explore two ways in which filter\nbanks can be adjusted for the purposes of speech recognition. First, triangular\nfilters can be replaced with Gabor filters, a compactly supported filter that\nbetter localizes events in time, or Gammatone filters, a\npsychoacoustically-motivated filter. Second, by rearranging the order of\noperations in computing filter bank features, features can be integrated over\nsmaller time scales while simultaneously providing better frequency resolution.\nWe make all feature implementations available online through open-source\nrepositories. Initial experimentation with a modern end-to-end CNN phone\nrecognizer yielded no significant improvements to phone error rate due to\neither modification. The result, and its ramifications with respect to learned\nfilter banks, is discussed.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2019 01:17:26 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Robertson", "Sean", ""], ["Penn", "Gerald", ""], ["Wang", "Yingxue", ""]]}, {"id": "1901.00158", "submitter": "Wanrong Zhu", "authors": "Wanrong Zhu, Zhiting Hu, Eric Xing", "title": "Text Infilling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen remarkable progress of text generation in different\ncontexts, such as the most common setting of generating text from scratch, and\nthe emerging paradigm of retrieval-and-rewriting. Text infilling, which fills\nmissing text portions of a sentence or paragraph, is also of numerous use in\nreal life, yet is under-explored. Previous work has focused on restricted\nsettings by either assuming single word per missing portion or limiting to a\nsingle missing portion to the end of the text. This paper studies the general\ntask of text infilling, where the input text can have an arbitrary number of\nportions to be filled, each of which may require an arbitrary unknown number of\ntokens. We study various approaches for the task, including a self-attention\nmodel with segment-aware position encoding and bidirectional context modeling.\nWe create extensive supervised data by masking out text with varying\nstrategies. Experiments show the self-attention model greatly outperforms\nothers, creating a strong baseline for future research.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2019 14:41:17 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2019 17:55:36 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Zhu", "Wanrong", ""], ["Hu", "Zhiting", ""], ["Xing", "Eric", ""]]}, {"id": "1901.00297", "submitter": "Vidya Prasad K", "authors": "Vidya Prasad K, Akarsh S, Vinayakumar R, Soman KP", "title": "A Deep Learning Approach for Similar Languages, Varieties and Dialects", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep learning mechanisms are prevailing approaches in recent days for the\nvarious tasks in natural language processing, speech recognition, image\nprocessing and many others. To leverage this we use deep learning based\nmechanism specifically Bidirectional- Long Short-Term Memory (B-LSTM) for the\ntask of dialectic identification in Arabic and German broadcast speech and Long\nShort-Term Memory (LSTM) for discriminating between similar Languages. Two\nunique B-LSTM models are created using the Large-vocabulary Continuous Speech\nRecognition (LVCSR) based lexical features and a fixed length of 400 per\nutterance bottleneck features generated by i-vector framework. These models\nwere evaluated on the VarDial 2017 datasets for the tasks Arabic, German\ndialect identification with dialects of Egyptian, Gulf, Levantine, North\nAfrican, and MSA for Arabic and Basel, Bern, Lucerne, and Zurich for German.\nAlso for the task of Discriminating between Similar Languages like Bosnian,\nCroatian and Serbian. The B-LSTM model showed accuracy of 0.246 on lexical\nfeatures and accuracy of 0.577 bottleneck features of i-Vector framework.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 08:47:38 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["K", "Vidya Prasad", ""], ["S", "Akarsh", ""], ["R", "Vinayakumar", ""], ["KP", "Soman", ""]]}, {"id": "1901.00398", "submitter": "Cristina Garbacea", "authors": "Cristina Garbacea, Samuel Carton, Shiyan Yan, Qiaozhu Mei", "title": "Judge the Judges: A Large-Scale Evaluation Study of Neural Language\n  Models for Online Review Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conduct a large-scale, systematic study to evaluate the existing\nevaluation methods for natural language generation in the context of generating\nonline product reviews. We compare human-based evaluators with a variety of\nautomated evaluation procedures, including discriminative evaluators that\nmeasure how well machine-generated text can be distinguished from human-written\ntext, as well as word overlap metrics that assess how similar the generated\ntext compares to human-written references. We determine to what extent these\ndifferent evaluators agree on the ranking of a dozen of state-of-the-art\ngenerators for online product reviews. We find that human evaluators do not\ncorrelate well with discriminative evaluators, leaving a bigger question of\nwhether adversarial accuracy is the correct objective for natural language\ngeneration. In general, distinguishing machine-generated text is challenging\neven for human evaluators, and human decisions correlate better with lexical\noverlaps. We find lexical diversity an intriguing metric that is indicative of\nthe assessments of different evaluators. A post-experiment survey of\nparticipants provides insights into how to evaluate and improve the quality of\nnatural language generation systems.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 14:45:02 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 18:25:57 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Garbacea", "Cristina", ""], ["Carton", "Samuel", ""], ["Yan", "Shiyan", ""], ["Mei", "Qiaozhu", ""]]}, {"id": "1901.00399", "submitter": "Oren Halvani", "authors": "Oren Halvani, Christian Winter, Lukas Graner", "title": "Unary and Binary Classification Approaches and their Implications for\n  Authorship Verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Retrieving indexed documents, not by their topical content but their writing\nstyle opens the door for a number of applications in information retrieval\n(IR). One application is to retrieve textual content of a certain author X,\nwhere the queried IR system is provided beforehand with a set of reference\ntexts of X. Authorship verification (AV), which is a research subject in the\nfield of digital text forensics, is suitable for this purpose. The task of AV\nis to determine if two documents (i.e. an indexed and a reference document)\nhave been written by the same author X. Even though AV represents a unary\nclassification problem, a number of existing approaches consider it as a binary\nclassification task. However, the underlying classification model of an AV\nmethod has a number of serious implications regarding its prerequisites,\nevaluability, and applicability. In our comprehensive literature review, we\nobserved several misunderstandings regarding the differentiation of unary and\nbinary AV approaches that require consideration. The objective of this paper\nis, therefore, to clarify these by proposing clear criteria and new properties\nthat aim to improve the characterization of existing and future AV approaches.\nGiven both, we investigate the applicability of eleven existing unary and\nbinary AV methods as well as four generic unary classification algorithms on\ntwo self-compiled corpora. Furthermore, we highlight an important issue\nconcerning the evaluation of AV methods based on fixed decision criterions,\nwhich has not been paid attention in previous AV studies.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 16:04:16 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Halvani", "Oren", ""], ["Winter", "Christian", ""], ["Graner", "Lukas", ""]]}, {"id": "1901.00400", "submitter": "Nicolas Pr\\\"ollochs", "authors": "Bernhard Lutz, Nicolas Pr\\\"ollochs, Dirk Neumann", "title": "Sentence-Level Sentiment Analysis of Financial News Using Distributed\n  Text Representations and Multi-Instance Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Researchers and financial professionals require robust computerized tools\nthat allow users to rapidly operationalize and assess the semantic textual\ncontent in financial news. However, existing methods commonly work at the\ndocument-level while deeper insights into the actual structure and the\nsentiment of individual sentences remain blurred. As a result, investors are\nrequired to apply the utmost attention and detailed, domain-specific knowledge\nin order to assess the information on a fine-grained basis. To facilitate this\nmanual process, this paper proposes the use of distributed text representations\nand multi-instance learning to transfer information from the document-level to\nthe sentence-level. Compared to alternative approaches, this method features\nsuperior predictive performance while preserving context and interpretability.\nOur analysis of a manually-labeled dataset yields a predictive accuracy of up\nto 69.90%, exceeding the performance of alternative approaches by at least 3.80\npercentage points. Accordingly, this study not only benefits investors with\nregard to their financial decision-making, but also helps companies to\ncommunicate their messages as intended.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 16:30:21 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Lutz", "Bernhard", ""], ["Pr\u00f6llochs", "Nicolas", ""], ["Neumann", "Dirk", ""]]}, {"id": "1901.00439", "submitter": "Oguzhan Gencoglu", "authors": "Oguzhan Gencoglu", "title": "Deep Representation Learning for Clustering of Health Tweets", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Twitter has been a prominent social media platform for mining\npopulation-level health data and accurate clustering of health-related tweets\ninto topics is important for extracting relevant health insights. In this work,\nwe propose deep convolutional autoencoders for learning compact representations\nof health-related tweets, further to be employed in clustering. We compare our\nmethod to several conventional tweet representation methods including\nbag-of-words, term frequency-inverse document frequency, Latent Dirichlet\nAllocation and Non-negative Matrix Factorization with 3 different clustering\nalgorithms. Our results show that the clustering performance using proposed\nrepresentation learning scheme significantly outperforms that of conventional\nmethods for all experiments of different number of clusters. In addition, we\npropose a constraint on the learned representations during the neural network\ntraining in order to further enhance the clustering performance. All in all,\nthis study introduces utilization of deep neural network-based architectures,\ni.e., deep convolutional autoencoders, for learning informative representations\nof health-related tweets.\n", "versions": [{"version": "v1", "created": "Tue, 25 Dec 2018 00:31:22 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Gencoglu", "Oguzhan", ""]]}, {"id": "1901.00519", "submitter": "Mason A. Porter", "authors": "Alexandra N. M. Darmon, Marya Bazzi, Sam D. Howison, and Mason A.\n  Porter", "title": "Pull out all the stops: Textual analysis via punctuation sequences", "comments": "Figure 7 has some panels of lower graphical quality because of file\n  sizes", "journal-ref": null, "doi": "10.1017/S0956792520000157", "report-no": null, "categories": "cs.CL cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whether enjoying the lucid prose of a favorite author or slogging through\nsome other writer's cumbersome, heavy-set prattle (full of parentheses, em\ndashes, compound adjectives, and Oxford commas), readers will notice stylistic\nsignatures not only in word choice and grammar, but also in punctuation itself.\nIndeed, visual sequences of punctuation from different authors produce\nmarvelously different (and visually striking) sequences. Punctuation is a\nlargely overlooked stylistic feature in \"stylometry\", the quantitative analysis\nof written text. In this paper, we examine punctuation sequences in a corpus of\nliterary documents and ask the following questions: Are the properties of such\nsequences a distinctive feature of different authors? Is it possible to\ndistinguish literary genres based on their punctuation sequences? Do the\npunctuation styles of authors evolve over time? Are we on to something\ninteresting in trying to do stylometry without words, or are we full of sound\nand fury (signifying nothing)?\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 18:48:20 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2020 17:02:45 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Darmon", "Alexandra N. M.", ""], ["Bazzi", "Marya", ""], ["Howison", "Sam D.", ""], ["Porter", "Mason A.", ""]]}, {"id": "1901.00521", "submitter": "Victor Davis", "authors": "Victor Davis", "title": "Types, Tokens, and Hapaxes: A New Heap's Law", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Heap's Law states that in a large enough text corpus, the number of types as\na function of tokens grows as $N=KM^\\beta$ for some free parameters $K,\\beta$.\nMuch has been written about how this result and various generalizations can be\nderived from Zipf's Law. Here we derive from first principles a completely\nnovel expression of the type-token curve and prove its superior accuracy on\nreal text. This expression naturally generalizes to equally accurate estimates\nfor counting hapaxes and higher $n$-legomena.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 15:00:38 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Davis", "Victor", ""]]}, {"id": "1901.00570", "submitter": "Lewis Mitchell", "authors": "Ahmad Hany Hossny, Lewis Mitchell", "title": "Event detection in Twitter: A keyword volume approach", "comments": "In: Proceedings of the 2nd International Workshop on Social Computing\n  (IWSC '18): Spatial Social Behavior Analytics in Urban Society", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event detection using social media streams needs a set of informative\nfeatures with strong signals that need minimal preprocessing and are highly\nassociated with events of interest. Identifying these informative features as\nkeywords from Twitter is challenging, as people use informal language to\nexpress their thoughts and feelings. This informality includes acronyms,\nmisspelled words, synonyms, transliteration and ambiguous terms. In this paper,\nwe propose an efficient method to select the keywords frequently used in\nTwitter that are mostly associated with events of interest such as protests.\nThe volume of these keywords is tracked in real time to identify the events of\ninterest in a binary classification scheme. We use keywords within word-pairs\nto capture the context. The proposed method is to binarize vectors of daily\ncounts for each word-pair by applying a spike detection temporal filter, then\nuse the Jaccard metric to measure the similarity of the binary vector for each\nword-pair with the binary vector describing event occurrence. The top n\nword-pairs are used as features to classify any day to be an event or non-event\nday. The selected features are tested using multiple classifiers such as Naive\nBayes, SVM, Logistic Regression, KNN and decision trees. They all produced AUC\nROC scores up to 0.91 and F1 scores up to 0.79. The experiment is performed\nusing the English language in multiple cities such as Melbourne, Sydney and\nBrisbane as well as the Indonesian language in Jakarta. The two experiments,\ncomprising different languages and locations, yielded similar results.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 01:06:55 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Hossny", "Ahmad Hany", ""], ["Mitchell", "Lewis", ""]]}, {"id": "1901.00603", "submitter": "Victor Zhong", "authors": "Victor Zhong, Caiming Xiong, Nitish Shirish Keskar, Richard Socher", "title": "Coarse-grain Fine-grain Coattention Network for Multi-evidence Question\n  Answering", "comments": "ICLR 2019; 9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end neural models have made significant progress in question\nanswering, however recent studies show that these models implicitly assume that\nthe answer and evidence appear close together in a single document. In this\nwork, we propose the Coarse-grain Fine-grain Coattention Network (CFC), a new\nquestion answering model that combines information from evidence across\nmultiple documents. The CFC consists of a coarse-grain module that interprets\ndocuments with respect to the query then finds a relevant answer, and a\nfine-grain module which scores each candidate answer by comparing its\noccurrences across all of the documents with the query. We design these modules\nusing hierarchies of coattention and self-attention, which learn to emphasize\ndifferent parts of the input. On the Qangaroo WikiHop multi-evidence question\nanswering task, the CFC obtains a new state-of-the-art result of 70.6% on the\nblind test set, outperforming the previous best by 3% accuracy despite not\nusing pretrained contextual encoders.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 03:55:49 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 17:33:02 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Zhong", "Victor", ""], ["Xiong", "Caiming", ""], ["Keskar", "Nitish Shirish", ""], ["Socher", "Richard", ""]]}, {"id": "1901.00707", "submitter": "Huaiping Ming", "authors": "Huaiping Ming, Lei He, Haohan Guo, Frank K. Soong", "title": "Feature reinforcement with word embedding and parsing information in\n  neural TTS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a feature reinforcement method under the\nsequence-to-sequence neural text-to-speech (TTS) synthesis framework. The\nproposed method utilizes the multiple input encoder to take three levels of\ntext information, i.e., phoneme sequence, pre-trained word embedding, and\ngrammatical structure of sentences from parser as the input feature for the\nneural TTS system. The added word and sentence level information can be viewed\nas the feature based pre-training strategy, which clearly enhances the model\ngeneralization ability. The proposed method not only improves the system\nrobustness significantly but also improves the synthesized speech to near\nrecording quality in our experiments for out-of-domain text.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 13:15:19 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 15:24:38 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Ming", "Huaiping", ""], ["He", "Lei", ""], ["Guo", "Haohan", ""], ["Soong", "Frank K.", ""]]}, {"id": "1901.00850", "submitter": "Chenxi Liu", "authors": "Runtao Liu, Chenxi Liu, Yutong Bai, Alan Yuille", "title": "CLEVR-Ref+: Diagnosing Visual Reasoning with Referring Expressions", "comments": "To appear in CVPR 2019. All data and code concerning CLEVR-Ref+ and\n  IEP-Ref have been released at https://cs.jhu.edu/~cxliu/2019/clevr-ref+", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Referring object detection and referring image segmentation are important\ntasks that require joint understanding of visual information and natural\nlanguage. Yet there has been evidence that current benchmark datasets suffer\nfrom bias, and current state-of-the-art models cannot be easily evaluated on\ntheir intermediate reasoning process. To address these issues and complement\nsimilar efforts in visual question answering, we build CLEVR-Ref+, a synthetic\ndiagnostic dataset for referring expression comprehension. The precise\nlocations and attributes of the objects are readily available, and the\nreferring expressions are automatically associated with functional programs.\nThe synthetic nature allows control over dataset bias (through sampling\nstrategy), and the modular programs enable intermediate reasoning ground truth\nwithout human annotators.\n  In addition to evaluating several state-of-the-art models on CLEVR-Ref+, we\nalso propose IEP-Ref, a module network approach that significantly outperforms\nother models on our dataset. In particular, we present two interesting and\nimportant findings using IEP-Ref: (1) the module trained to transform feature\nmaps into segmentation masks can be attached to any intermediate module to\nreveal the entire reasoning process step-by-step; (2) even if all training data\nhas at least one object referred, IEP-Ref can correctly predict no-foreground\nwhen presented with false-premise referring expressions. To the best of our\nknowledge, this is the first direct and quantitative proof that neural modules\nbehave in the way they are intended.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 18:58:06 GMT"}, {"version": "v2", "created": "Sat, 6 Apr 2019 19:59:25 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Liu", "Runtao", ""], ["Liu", "Chenxi", ""], ["Bai", "Yutong", ""], ["Yuille", "Alan", ""]]}, {"id": "1901.01010", "submitter": "Aili Shen", "authors": "Aili Shen, Bahar Salehi, Timothy Baldwin, and Jianzhong Qi", "title": "A Joint Model for Multimodal Document Quality Assessment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quality of a document is affected by various factors, including\ngrammaticality, readability, stylistics, and expertise depth, making the task\nof document quality assessment a complex one. In this paper, we explore this\ntask in the context of assessing the quality of Wikipedia articles and academic\npapers. Observing that the visual rendering of a document can capture implicit\nquality indicators that are not present in the document text --- such as\nimages, font choices, and visual layout --- we propose a joint model that\ncombines the text content with a visual rendering of the document for document\nquality assessment. Experimental results over two datasets reveal that textual\nand visual features are complementary, achieving state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 08:05:56 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 00:46:42 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Shen", "Aili", ""], ["Salehi", "Bahar", ""], ["Baldwin", "Timothy", ""], ["Qi", "Jianzhong", ""]]}, {"id": "1901.01122", "submitter": "Mayank Agarwal", "authors": "Ankush Garg, Mayank Agarwal", "title": "Machine Translation: A Literature Review", "comments": "17 pages, 3 figures. arXiv admin note: text overlap with\n  arXiv:1409.0473, arXiv:1508.04025, arXiv:1410.8206 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine translation (MT) plays an important role in benefiting linguists,\nsociologists, computer scientists, etc. by processing natural language to\ntranslate it into some other natural language. And this demand has grown\nexponentially over past couple of years, considering the enormous exchange of\ninformation between different regions with different regional languages.\nMachine Translation poses numerous challenges, some of which are: a) Not all\nwords in one language has equivalent word in another language b) Two given\nlanguages may have completely different structures c) Words can have more than\none meaning. Owing to these challenges, along with many others, MT has been\nactive area of research for more than five decades. Numerous methods have been\nproposed in the past which either aim at improving the quality of the\ntranslations generated by them, or study the robustness of these systems by\nmeasuring their performance on many different languages. In this literature\nreview, we discuss statistical approaches (in particular word-based and\nphrase-based) and neural approaches which have gained widespread prominence\nowing to their state-of-the-art results across multiple major languages.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 19:04:36 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Garg", "Ankush", ""], ["Agarwal", "Mayank", ""]]}, {"id": "1901.01183", "submitter": "Erfan Ghadery", "authors": "Sajad Movahedi, Erfan Ghadery, Heshaam Faili, Azadeh Shakery", "title": "Aspect Category Detection via Topic-Attention Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The e-commerce has started a new trend in natural language processing through\nsentiment analysis of user-generated reviews. Different consumers have\ndifferent concerns about various aspects of a specific product or service.\nAspect category detection, as a subtask of aspect-based sentiment analysis,\ntackles the problem of categorizing a given review sentence into a set of\npre-defined aspect categories. In recent years, deep learning approaches have\nbrought revolutionary advances in multiple branches of natural language\nprocessing including sentiment analysis. In this paper, we propose a deep\nneural network method based on attention mechanism to identify different aspect\ncategories of a given review sentence. Our model utilizes several attentions\nwith different topic contexts, enabling it to attend to different parts of a\nreview sentence based on different topics. Experimental results on two datasets\nin the restaurant domain released by SemEval workshop demonstrates that our\napproach outperforms existing methods on both datasets. Visualization of the\ntopic attention weights shows the effectiveness of our model in identifying\nwords related to different topics.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 15:52:49 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 06:37:26 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Movahedi", "Sajad", ""], ["Ghadery", "Erfan", ""], ["Faili", "Heshaam", ""], ["Shakery", "Azadeh", ""]]}, {"id": "1901.01216", "submitter": "Marc Tanti", "authors": "Marc Tanti, Albert Gatt, Kenneth P. Camilleri", "title": "Transfer learning from language models to image caption generators:\n  Better models may not transfer better", "comments": "17 pages, 4 figures, 3 tables, unpublished (comments welcome)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When designing a neural caption generator, a convolutional neural network can\nbe used to extract image features. Is it possible to also use a neural language\nmodel to extract sentence prefix features? We answer this question by trying\ndifferent ways to transfer the recurrent neural network and embedding layer\nfrom a neural language model to an image caption generator. We find that image\ncaption generators with transferred parameters perform better than those\ntrained from scratch, even when simply pre-training them on the text of the\nsame captions dataset it will later be trained on. We also find that the best\nlanguage models (in terms of perplexity) do not result in the best caption\ngenerators after transfer learning.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2019 20:23:40 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Tanti", "Marc", ""], ["Gatt", "Albert", ""], ["Camilleri", "Kenneth P.", ""]]}, {"id": "1901.01239", "submitter": "Jinyu Li", "authors": "Ke Li, Jinyu Li, Yong Zhao, Kshitiz Kumar, Yifan Gong", "title": "Speaker Adaptation for End-to-End CTC Models", "comments": "published at IEEE Workshop of Spoken Language Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose two approaches for speaker adaptation in end-to-end (E2E)\nautomatic speech recognition systems. One is Kullback-Leibler divergence (KLD)\nregularization and the other is multi-task learning (MTL). Both approaches aim\nto address the data sparsity especially output target sparsity issue of speaker\nadaptation in E2E systems. The KLD regularization adapts a model by forcing the\noutput distribution from the adapted model to be close to the unadapted one.\nThe MTL utilizes a jointly trained auxiliary task to improve the performance of\nthe main task. We investigated our approaches on E2E connectionist temporal\nclassification (CTC) models with three different types of output units.\nExperiments on the Microsoft short message dictation task demonstrated that MTL\noutperforms KLD regularization. In particular, the MTL adaptation obtained\n8.8\\% and 4.0\\% relative word error rate reductions (WERRs) for supervised and\nunsupervised adaptations for the word CTC model, and 9.6% and 3.8% relative\nWERRs for the mix-unit CTC model, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 18:38:11 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Li", "Ke", ""], ["Li", "Jinyu", ""], ["Zhao", "Yong", ""], ["Kumar", "Kshitiz", ""], ["Gong", "Yifan", ""]]}, {"id": "1901.01466", "submitter": "Stefan Ultes", "authors": "Stefan Ultes, Pawe\\l\\ Budzianowski, I\\~nigo Casanueva, Lina\n  Rojas-Barahona, Bo-Hsiang Tseng, Yen-Chen Wu, Steve Young and Milica\n  Ga\\v{s}i\\'c", "title": "Addressing Objects and Their Relations: The Conversational Entity\n  Dialogue Model", "comments": "Accepted at SIGDial 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical spoken dialogue systems usually rely on a single- or multi-domain\ndialogue model that is restricted in its capabilities of modelling complex\ndialogue structures, e.g., relations. In this work, we propose a novel dialogue\nmodel that is centred around entities and is able to model relations as well as\nmultiple entities of the same type. We demonstrate in a prototype\nimplementation benefits of relation modelling on the dialogue level and show\nthat a trained policy using these relations outperforms the multi-domain\nbaseline. Furthermore, we show that by modelling the relations on the dialogue\nlevel, the system is capable of processing relations present in the user input\nand even learns to address them in the system response.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jan 2019 20:27:19 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Ultes", "Stefan", ""], ["Budzianowski", "Pawe\u0142\\", ""], ["Casanueva", "I\u00f1igo", ""], ["Rojas-Barahona", "Lina", ""], ["Tseng", "Bo-Hsiang", ""], ["Wu", "Yen-Chen", ""], ["Young", "Steve", ""], ["Ga\u0161i\u0107", "Milica", ""]]}, {"id": "1901.01574", "submitter": "Yunsu Kim", "authors": "Yunsu Kim, Andreas Guta, Joern Wuebker, Hermann Ney", "title": "A Comparative Study on Vocabulary Reduction for Phrase Table Smoothing", "comments": "Published in WMT 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work systematically analyzes the smoothing effect of vocabulary\nreduction for phrase translation models. We extensively compare various\nword-level vocabularies to show that the performance of smoothing is not\nsignificantly affected by the choice of vocabulary. This result provides\nempirical evidence that the standard phrase translation model is extremely\nsparse. Our experiments also reveal that vocabulary reduction is more effective\nfor smoothing large-scale phrase tables.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2019 17:20:24 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Kim", "Yunsu", ""], ["Guta", "Andreas", ""], ["Wuebker", "Joern", ""], ["Ney", "Hermann", ""]]}, {"id": "1901.01577", "submitter": "Yunsu Kim", "authors": "Yunsu Kim, Julian Schamper, Hermann Ney", "title": "Unsupervised Training for Large Vocabulary Translation Using Sparse\n  Lexicon and Word Classes", "comments": "Published in EACL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address for the first time unsupervised training for a translation task\nwith hundreds of thousands of vocabulary words. We scale up the\nexpectation-maximization (EM) algorithm to learn a large translation table\nwithout any parallel text or seed lexicon. First, we solve the memory\nbottleneck and enforce the sparsity with a simple thresholding scheme for the\nlexicon. Second, we initialize the lexicon training with word classes, which\nefficiently boosts the performance. Our methods produced promising results on\ntwo large-scale unsupervised translation tasks.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2019 17:29:24 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Kim", "Yunsu", ""], ["Schamper", "Julian", ""], ["Ney", "Hermann", ""]]}, {"id": "1901.01590", "submitter": "Yunsu Kim", "authors": "Yunsu Kim, Jiahui Geng, Hermann Ney", "title": "Improving Unsupervised Word-by-Word Translation with Language Model and\n  Denoising Autoencoder", "comments": "Published in EMNLP 2018, with links to the source code", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised learning of cross-lingual word embedding offers elegant matching\nof words across languages, but has fundamental limitations in translating\nsentences. In this paper, we propose simple yet effective methods to improve\nword-by-word translation of cross-lingual embeddings, using only monolingual\ncorpora but without any back-translation. We integrate a language model for\ncontext-aware search, and use a novel denoising autoencoder to handle\nreordering. Our system surpasses state-of-the-art unsupervised neural\ntranslation systems without costly iterative training. We also analyze the\neffect of vocabulary size and denoising type on the translation performance,\nwhich provides better understanding of learning the cross-lingual word\nembedding and its usage in translation.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2019 18:30:50 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Kim", "Yunsu", ""], ["Geng", "Jiahui", ""], ["Ney", "Hermann", ""]]}, {"id": "1901.01592", "submitter": "Andrey Kormilitzin", "authors": "Luka Gligic, Andrey Kormilitzin, Paul Goldberg, Alejo Nevado-Holgado", "title": "Named Entity Recognition in Electronic Health Records Using Transfer\n  Learning Bootstrapped Neural Networks", "comments": "11 pages, 4 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks (NNs) have become the state of the art in many machine\nlearning applications, especially in image and sound processing [1]. The same,\nalthough to a lesser extent [2,3], could be said in natural language processing\n(NLP) tasks, such as named entity recognition. However, the success of NNs\nremains dependent on the availability of large labelled datasets, which is a\nsignificant hurdle in many important applications. One such case are electronic\nhealth records (EHRs), which are arguably the largest source of medical data,\nmost of which lies hidden in natural text [4,5]. Data access is difficult due\nto data privacy concerns, and therefore annotated datasets are scarce. With\nscarce data, NNs will likely not be able to extract this hidden information\nwith practical accuracy. In our study, we develop an approach that solves these\nproblems for named entity recognition, obtaining 94.6 F1 score in I2B2 2009\nMedical Extraction Challenge [6], 4.3 above the architecture that won the\ncompetition. Beyond the official I2B2 challenge, we further achieve 82.4 F1 on\nextracting relationships between medical terms. To reach this state-of-the-art\naccuracy, our approach applies transfer learning to leverage on datasets\nannotated for other I2B2 tasks, and designs and trains embeddings that\nspecially benefit from such transfer.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2019 18:53:12 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 15:26:21 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Gligic", "Luka", ""], ["Kormilitzin", "Andrey", ""], ["Goldberg", "Paul", ""], ["Nevado-Holgado", "Alejo", ""]]}, {"id": "1901.01642", "submitter": "Jovelyn Cuizon", "authors": "Jovelyn C. Cuizon, Jesserine Lopez and Danica Rose Jones", "title": "Text Mining Customer Reviews For Aspect-based Restaurant Rating", "comments": null, "journal-ref": "International Journal of Computer Science & Information Technology\n  (IJCSIT) Vol 10, No 6, December 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study applies text mining to analyze customer reviews and automatically\nassign a collective restaurant star rating based on five predetermined aspects:\nambiance, cost, food, hygiene, and service. The application provides a web and\nmobile crowd sourcing platform where users share dining experiences and get\ninsights about the strengths and weaknesses of a restaurant through user\ncontributed feedback. Text reviews are tokenized into sentences. Noun-adjective\npairs are extracted from each sentence using Stanford Core NLP library and are\nassociated to aspects based on the bag of associated words fed into the system.\nThe sentiment weight of the adjectives is determined through AFINN library. An\noverall restaurant star rating is computed based on the individual aspect\nrating. Further, a word cloud is generated to provide visual display of the\nmost frequently occurring terms in the reviews. The more feedbacks are added\nthe more reflective the sentiment score to the restaurants' performance.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 01:57:21 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Cuizon", "Jovelyn C.", ""], ["Lopez", "Jesserine", ""], ["Jones", "Danica Rose", ""]]}, {"id": "1901.01695", "submitter": "Karol Grzegorczyk", "authors": "Karol Grzegorczyk", "title": "Vector representations of text data in deep learning", "comments": "Doctoral dissertation. Submitted on July 4, 2018. Defended on\n  December 18, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this dissertation we report results of our research on dense distributed\nrepresentations of text data. We propose two novel neural models for learning\nsuch representations. The first model learns representations at the document\nlevel, while the second model learns word-level representations.\n  For document-level representations we propose Binary Paragraph Vector: a\nneural network models for learning binary representations of text documents,\nwhich can be used for fast document retrieval. We provide a thorough evaluation\nof these models and demonstrate that they outperform the seminal method in the\nfield in the information retrieval task. We also report strong results in\ntransfer learning settings, where our models are trained on a generic text\ncorpus and then used to infer codes for documents from a domain-specific\ndataset. In contrast to previously proposed approaches, Binary Paragraph Vector\nmodels learn embeddings directly from raw text data.\n  For word-level representations we propose Disambiguated Skip-gram: a neural\nnetwork model for learning multi-sense word embeddings. Representations learned\nby this model can be used in downstream tasks, like part-of-speech tagging or\nidentification of semantic relations. In the word sense induction task\nDisambiguated Skip-gram outperforms state-of-the-art models on three out of\nfour benchmarks datasets. Our model has an elegant probabilistic\ninterpretation. Furthermore, unlike previous models of this kind, it is\ndifferentiable with respect to all its parameters and can be trained with\nbackpropagation. In addition to quantitative results, we present qualitative\nevaluation of Disambiguated Skip-gram, including two-dimensional visualisations\nof selected word-sense embeddings.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 08:03:35 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Grzegorczyk", "Karol", ""]]}, {"id": "1901.01824", "submitter": "Jia-Chen Gu", "authors": "Jia-Chen Gu, Zhen-Hua Ling, Quan Liu", "title": "Interactive Matching Network for Multi-Turn Response Selection in\n  Retrieval-Based Chatbots", "comments": "Accepted by CIKM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an interactive matching network (IMN) for the\nmulti-turn response selection task. First, IMN constructs word representations\nfrom three aspects to address the challenge of out-of-vocabulary (OOV) words.\nSecond, an attentive hierarchical recurrent encoder (AHRE), which is capable of\nencoding sentences hierarchically and generating more descriptive\nrepresentations by aggregating with an attention mechanism, is designed.\nFinally, the bidirectional interactions between whole multi-turn contexts and\nresponse candidates are calculated to derive the matching information between\nthem. Experiments on four public datasets show that IMN outperforms the\nbaseline models on all metrics, achieving a new state-of-the-art performance\nand demonstrating compatibility across domains for multi-turn response\nselection.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 14:17:29 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 09:29:00 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Gu", "Jia-Chen", ""], ["Ling", "Zhen-Hua", ""], ["Liu", "Quan", ""]]}, {"id": "1901.01911", "submitter": "Viviana Patti", "authors": "Endang Wahyu Pamungkas, Valerio Basile, Viviana Patti", "title": "Stance Classification for Rumour Analysis in Twitter: Exploiting\n  Affective Information and Conversation Structure", "comments": "To appear in Proceedings of the 2nd International Workshop on Rumours\n  and Deception in Social Media (RDSM), co-located with CIKM 2018, Turin,\n  Italy, October 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysing how people react to rumours associated with news in social media is\nan important task to prevent the spreading of misinformation, which is nowadays\nwidely recognized as a dangerous tendency. In social media conversations, users\nshow different stances and attitudes towards rumourous stories. Some users take\na definite stance, supporting or denying the rumour at issue, while others just\ncomment it, or ask for additional evidence related to the veracity of the\nrumour. On this line, a new shared task has been proposed at SemEval-2017 (Task\n8, SubTask A), which is focused on rumour stance classification in English\ntweets. The goal is predicting user stance towards emerging rumours in Twitter,\nin terms of supporting, denying, querying, or commenting the original rumour,\nlooking at the conversation threads originated by the rumour. This paper\ndescribes a new approach to this task, where the use of conversation-based and\naffective-based features, covering different facets of affect, has been\nexplored. Our classification model outperforms the best-performing systems for\nstance classification at SemEval-2017 Task 8, showing the effectiveness of the\nfeature set proposed.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 16:38:16 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Pamungkas", "Endang Wahyu", ""], ["Basile", "Valerio", ""], ["Patti", "Viviana", ""]]}, {"id": "1901.02081", "submitter": "Artur Nowak", "authors": "Artur Nowak, Pawe{\\l} Kunstman", "title": "Team EP at TAC 2018: Automating data extraction in systematic reviews of\n  environmental agents", "comments": "7 pages, 3 figures, to appear in the proceedings of Text Analysis\n  Conference (TAC) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe our entry for the Systematic Review Information Extraction track\nof the 2018 Text Analysis Conference. Our solution is an end-to-end, deep\nlearning, sequence tagging model based on the BI-LSTM-CRF architecture.\nHowever, we use interleaved, alternating LSTM layers with highway connections\ninstead of the more traditional approach, where last hidden states of both\ndirections are concatenated to create an input to the next layer. We also make\nextensive use of pre-trained word embeddings, namely GloVe and ELMo. Thanks to\na number of regularization techniques, we were able to achieve relatively large\ncapacity of the model (31.3M+ of trainable parameters) for the size of training\nset (100 documents, less than 200K tokens). The system's official score was\n60.9% (micro-F1) and it ranked first for the Task 1. Additionally, after\nrectifying an obvious mistake in the submission format, the system scored\n67.35%.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 21:49:51 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Nowak", "Artur", ""], ["Kunstman", "Pawe\u0142", ""]]}, {"id": "1901.02222", "submitter": "Chunhua Liu", "authors": "Chunhua Liu, Shan Jiang, Hainan Yu, Dong Yu", "title": "Multi-turn Inference Matching Network for Natural Language Inference", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-319-99501-4_11", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural Language Inference (NLI) is a fundamental and challenging task in\nNatural Language Processing (NLP). Most existing methods only apply one-pass\ninference process on a mixed matching feature, which is a concatenation of\ndifferent matching features between a premise and a hypothesis. In this paper,\nwe propose a new model called Multi-turn Inference Matching Network (MIMN) to\nperform multi-turn inference on different matching features. In each turn, the\nmodel focuses on one particular matching feature instead of the mixed matching\nfeature. To enhance the interaction between different matching features, a\nmemory component is employed to store the history inference information. The\ninference of each turn is performed on the current matching feature and the\nmemory. We conduct experiments on three different NLI datasets. The\nexperimental results show that our model outperforms or achieves the\nstate-of-the-art performance on all the three datasets.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 09:48:41 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Liu", "Chunhua", ""], ["Jiang", "Shan", ""], ["Yu", "Hainan", ""], ["Yu", "Dong", ""]]}, {"id": "1901.02252", "submitter": "Chunhua Liu", "authors": "Chunhua Liu, Haiou Zhang, Shan Jiang, Dong Yu", "title": "DEMN: Distilled-Exposition Enhanced Matching Network for Story\n  Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a Distilled-Exposition Enhanced Matching Network (DEMN)\nfor story-cloze test, which is still a challenging task in story comprehension.\nWe divide a complete story into three narrative segments: an\n\\textit{exposition}, a \\textit{climax}, and an \\textit{ending}. The model\nconsists of three modules: input module, matching module, and distillation\nmodule. The input module provides semantic representations for the three\nsegments and then feeds them into the other two modules. The matching module\ncollects interaction features between the ending and the climax. The\ndistillation module distills the crucial semantic information in the exposition\nand infuses it into the matching module in two different ways. We evaluate our\nsingle and ensemble model on ROCStories Corpus \\cite{Mostafazadeh2016ACA},\nachieving an accuracy of 80.1\\% and 81.2\\% on the test set respectively. The\nexperimental results demonstrate that our DEMN model achieves a\nstate-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 11:06:42 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Liu", "Chunhua", ""], ["Zhang", "Haiou", ""], ["Jiang", "Shan", ""], ["Yu", "Dong", ""]]}, {"id": "1901.02257", "submitter": "Chunhua Liu", "authors": "Chunhua Liu, Yan Zhao, Qingyi Si, Haiou Zhang, Bohan Li, Dong Yu", "title": "Multi-Perspective Fusion Network for Commonsense Reading Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commonsense Reading Comprehension (CRC) is a significantly challenging task,\naiming at choosing the right answer for the question referring to a narrative\npassage, which may require commonsense knowledge inference. Most of the\nexisting approaches only fuse the interaction information of choice, passage,\nand question in a simple combination manner from a \\emph{union} perspective,\nwhich lacks the comparison information on a deeper level. Instead, we propose a\nMulti-Perspective Fusion Network (MPFN), extending the single fusion method\nwith multiple perspectives by introducing the \\emph{difference} and\n\\emph{similarity} fusion\\deleted{along with the \\emph{union}}. More\ncomprehensive and accurate information can be captured through the three types\nof fusion. We design several groups of experiments on MCScript dataset\n\\cite{Ostermann:LREC18:MCScript} to evaluate the effectiveness of the three\ntypes of fusion respectively. From the experimental results, we can conclude\nthat the difference fusion is comparable with union fusion, and the similarity\nfusion needs to be activated by the union fusion. The experimental result also\nshows that our MPFN model achieves the state-of-the-art with an accuracy of\n83.52\\% on the official test set.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 11:15:07 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Liu", "Chunhua", ""], ["Zhao", "Yan", ""], ["Si", "Qingyi", ""], ["Zhang", "Haiou", ""], ["Li", "Bohan", ""], ["Yu", "Dong", ""]]}, {"id": "1901.02262", "submitter": "Kyosuke Nishida", "authors": "Kyosuke Nishida, Itsumi Saito, Kosuke Nishida, Kazutoshi Shinoda,\n  Atsushi Otsuka, Hisako Asano, Junji Tomita", "title": "Multi-style Generative Reading Comprehension", "comments": "Accepted as a long paper at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study tackles generative reading comprehension (RC), which consists of\nanswering questions based on textual evidence and natural language generation\n(NLG). We propose a multi-style abstractive summarization model for question\nanswering, called Masque. The proposed model has two key characteristics.\nFirst, unlike most studies on RC that have focused on extracting an answer span\nfrom the provided passages, our model instead focuses on generating a summary\nfrom the question and multiple passages. This serves to cover various answer\nstyles required for real-world applications. Second, whereas previous studies\nbuilt a specific model for each answer style because of the difficulty of\nacquiring one general model, our approach learns multi-style answers within a\nmodel to improve the NLG capability for all styles involved. This also enables\nour model to give an answer in the target style. Experiments show that our\nmodel achieves state-of-the-art performance on the Q&A task and the Q&A + NLG\ntask of MS MARCO 2.1 and the summary task of NarrativeQA. We observe that the\ntransfer of the style-independent NLG capability to the target style is the key\nto its success.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 11:27:58 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 09:30:50 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Nishida", "Kyosuke", ""], ["Saito", "Itsumi", ""], ["Nishida", "Kosuke", ""], ["Shinoda", "Kazutoshi", ""], ["Otsuka", "Atsushi", ""], ["Asano", "Hisako", ""], ["Tomita", "Junji", ""]]}, {"id": "1901.02348", "submitter": "Minhua Wu", "authors": "Ladislav Mo\\v{s}ner, Minhua Wu, Anirudh Raju, Sree Hari Krishnan\n  Parthasarathi, Kenichi Kumatani, Shiva Sundaram, Roland Maas, Bj\\\"orn\n  Hoffmeister", "title": "Improving noise robustness of automatic speech recognition via parallel\n  data and teacher-student learning", "comments": "To Appear in ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For real-world speech recognition applications, noise robustness is still a\nchallenge. In this work, we adopt the teacher-student (T/S) learning technique\nusing a parallel clean and noisy corpus for improving automatic speech\nrecognition (ASR) performance under multimedia noise. On top of that, we apply\na logits selection method which only preserves the k highest values to prevent\nwrong emphasis of knowledge from the teacher and to reduce bandwidth needed for\ntransferring data. We incorporate up to 8000 hours of untranscribed data for\ntraining and present our results on sequence trained models apart from cross\nentropy trained ones. The best sequence trained student model yields relative\nword error rate (WER) reductions of approximately 10.1%, 28.7% and 19.6% on our\nclean, simulated noisy and real test sets respectively comparing to a sequence\ntrained teacher.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jan 2019 06:22:40 GMT"}, {"version": "v2", "created": "Fri, 11 Jan 2019 06:15:47 GMT"}, {"version": "v3", "created": "Fri, 15 Mar 2019 20:16:57 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Mo\u0161ner", "Ladislav", ""], ["Wu", "Minhua", ""], ["Raju", "Anirudh", ""], ["Parthasarathi", "Sree Hari Krishnan", ""], ["Kumatani", "Kenichi", ""], ["Sundaram", "Shiva", ""], ["Maas", "Roland", ""], ["Hoffmeister", "Bj\u00f6rn", ""]]}, {"id": "1901.02360", "submitter": "Thanh Hieu Le", "authors": "Thanh-Hieu Le and Nhat-Thien Pham", "title": "Sum-of-square-of-rational-function based representations of positive\n  semidefinite polynomial matrices", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper proves sum-of-square-of-rational-function based representations\n(shortly, sosrf-based representations) of polynomial matrices that are positive\nsemidefinite on some special sets: $\\mathbb{R}^n;$ $\\mathbb{R}$ and its\nintervals $[a,b]$, $[0,\\infty)$; and the strips $[a,b] \\times \\mathbb{R}\n\\subset \\mathbb{R}^2.$ A method for numerically computing such representations\nis also presented. The methodology is divided into two stages:\n  (S1) diagonalizing the initial polynomial matrix based on the Schm\\\"{u}dgen's\nprocedure \\cite{Schmudgen09};\n  (S2) for each diagonal element of the resulting matrix, find its low rank\nsosrf-representation satisfying the Artin's theorem solving the Hilbert's 17th\nproblem.\n  Some numerical tests and illustrations with \\textsf{OCTAVE} are also\npresented for each type of polynomial matrices.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jan 2019 23:34:29 GMT"}, {"version": "v2", "created": "Thu, 28 Mar 2019 08:00:13 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Le", "Thanh-Hieu", ""], ["Pham", "Nhat-Thien", ""]]}, {"id": "1901.02490", "submitter": "Victor Makarenkov", "authors": "Victor Makarenkov, Lior Rokach and Bracha Shapira", "title": "Choosing the Right Word: Using Bidirectional LSTM Tagger for Writing\n  Support Systems", "comments": null, "journal-ref": "Elsevier Engineering Applications of Artificial Intelligence,\n  Volume 84, September 2019, Pages 1-10", "doi": "10.1016/2019.05.003", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific writing is difficult. It is even harder for those for whom English\nis a second language (ESL learners). Scholars around the world spend a\nsignificant amount of time and resources proofreading their work before\nsubmitting it for review or publication.\n  In this paper we present a novel machine learning based application for\nproper word choice task. Proper word choice is a generalization the lexical\nsubstitution (LS) and grammatical error correction (GEC) tasks. We demonstrate\nand evaluate the usefulness of applying bidirectional Long Short Term Memory\n(LSTM) tagger, for this task. While state-of-the-art grammatical error\ncorrection uses error-specific classifiers and machine translation methods, we\ndemonstrate an unsupervised method that is based solely on a high quality text\ncorpus and does not require manually annotated data. We use a bidirectional\nRecurrent Neural Network (RNN) with LSTM for learning the proper word choice\nbased on a word's sentential context. We demonstrate and evaluate our\napplication on both a domain-specific (scientific), writing task and a\ngeneral-purpose writing task. We show that our domain-specific and\ngeneral-purpose models outperform state-of-the-art general context learning. As\nan additional contribution of this research, we also share our code,\npre-trained models, and a new ESL learner test set with the research community.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 19:59:33 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Makarenkov", "Victor", ""], ["Rokach", "Lior", ""], ["Shapira", "Bracha", ""]]}, {"id": "1901.02522", "submitter": "Daniel Khashabi Mr.", "authors": "Daniel Khashabi, Erfan Sadeqi Azer, Tushar Khot, Ashish Sabharwal, Dan\n  Roth", "title": "On the Possibilities and Limitations of Multi-hop Reasoning Under\n  Linguistic Imperfections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systems for language understanding have become remarkably strong at\novercoming linguistic imperfections in tasks involving phrase matching or\nsimple reasoning. Yet, their accuracy drops dramatically as the number of\nreasoning steps increases. We present the first formal framework to study such\nempirical observations. It allows one to quantify the amount and effect of\nambiguity, redundancy, incompleteness, and inaccuracy that the use of language\nintroduces when representing a hidden conceptual space. The idea is to consider\ntwo interrelated spaces: a conceptual meaning space that is unambiguous and\ncomplete but hidden, and a linguistic space that captures a noisy grounding of\nthe meaning space in the words of a language---the level at which all systems,\nwhether neural or symbolic, operate. Applying this framework to a special class\nof multi-hop reasoning, namely the connectivity problem in graphs of\nrelationships between concepts, we derive rigorous intuitions and impossibility\nresults even under this simplified setting. For instance, if a query requires a\nmoderately large (logarithmic) number of hops in the meaning graph, no\nreasoning system operating over a noisy graph grounded in language is likely to\ncorrectly answer it. This highlights a fundamental barrier that extends to a\nbroader class of reasoning problems and systems, and suggests an alternative\npath forward: focusing on aligning the two spaces via richer representations,\nbefore investing in reasoning with many hops.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 21:19:34 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 05:00:14 GMT"}, {"version": "v3", "created": "Fri, 1 May 2020 04:43:45 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Khashabi", "Daniel", ""], ["Azer", "Erfan Sadeqi", ""], ["Khot", "Tushar", ""], ["Sabharwal", "Ashish", ""], ["Roth", "Dan", ""]]}, {"id": "1901.02534", "submitter": "Christopher Malon", "authors": "Christopher Malon", "title": "Team Papelo: Transformer Networks at FEVER", "comments": "Appeared at EMNLP 2018 First Workshop on Fact Extraction and\n  Verification (FEVER)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a system for the FEVER fact extraction and verification challenge\nthat uses a high precision entailment classifier based on transformer networks\npretrained with language modeling, to classify a broad set of potential\nevidence. The precision of the entailment classifier allows us to enhance\nrecall by considering every statement from several articles to decide upon each\nclaim. We include not only the articles best matching the claim text by TFIDF\nscore, but read additional articles whose titles match named entities and\ncapitalized expressions occurring in the claim text. The entailment module\nevaluates potential evidence one statement at a time, together with the title\nof the page the evidence came from (providing a hint about possible pronoun\nantecedents). In preliminary evaluation, the system achieves .5736 FEVER score,\n.6108 label accuracy, and .6485 evidence F1 on the FEVER shared task test set.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 21:57:30 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Malon", "Christopher", ""]]}, {"id": "1901.02539", "submitter": "Tuan Manh Lai", "authors": "Tuan Manh Lai, Trung Bui, Nedim Lipka, Sheng Li", "title": "Supervised Transfer Learning for Product Information Question Answering", "comments": "2018 17th IEEE International Conference on Machine Learning and\n  Applications", "journal-ref": null, "doi": "10.1109/ICMLA.2018.00180", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Popular e-commerce websites such as Amazon offer community question answering\nsystems for users to pose product related questions and experienced customers\nmay provide answers voluntarily. In this paper, we show that the large volume\nof existing community question answering data can be beneficial when building a\nsystem for answering questions related to product facts and specifications. Our\nexperimental results demonstrate that the performance of a model for answering\nquestions related to products listed in the Home Depot website can be improved\nby a large margin via a simple transfer learning technique from an existing\nlarge-scale Amazon community question answering dataset. Transfer learning can\nresult in an increase of about 10% in accuracy in the experimental setting\nwhere we restrict the size of the data of the target task used for training. As\nan application of this work, we integrate the best performing model trained in\nthis work into a mobile-based shopping assistant and show its usefulness.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 22:24:59 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Lai", "Tuan Manh", ""], ["Bui", "Trung", ""], ["Lipka", "Nedim", ""], ["Li", "Sheng", ""]]}, {"id": "1901.02543", "submitter": "Shlomo Argamon", "authors": "Shlomo Engelson Argamon", "title": "Computational Register Analysis and Synthesis", "comments": "A version of this article is to appear in Register Studies, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of register in computational language research has historically\nbeen divided into register analysis, seeking to determine the registerial\ncharacter of a text or corpus, and register synthesis, seeking to generate a\ntext in a desired register. This article surveys the different approaches to\nthese disparate tasks. Register synthesis has tended to use more theoretically\narticulated notions of register and genre than analysis work, which often seeks\nto categorize on the basis of intuitive and somewhat incoherent notions of\nprelabeled 'text types'. I argue that an integration of computational register\nanalysis and synthesis will benefit register studies as a whole, by enabling a\nnew large-scale research program in register studies. It will enable\ncomprehensive global mapping of functional language varieties in multiple\nlanguages, including the relationships between them. Furthermore, computational\nmethods together with high coverage systematically collected and analyzed data\nwill thus enable rigorous empirical validation and refinement of different\ntheories of register, which will have also implications for our understanding\nof linguistic variation in general.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 22:35:03 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Argamon", "Shlomo Engelson", ""]]}, {"id": "1901.02609", "submitter": "Qian Chen", "authors": "Qian Chen, Wen Wang", "title": "Sequential Attention-based Network for Noetic End-to-End Response\n  Selection", "comments": "Ranked first in DSTC7 Track 1. Accepted for an oral presentation at\n  the DSTC7 workshop at AAAI 2019. The source code is available now", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The noetic end-to-end response selection challenge as one track in Dialog\nSystem Technology Challenges 7 (DSTC7) aims to push the state of the art of\nutterance classification for real world goal-oriented dialog systems, for which\nparticipants need to select the correct next utterances from a set of\ncandidates for the multi-turn context. This paper describes our systems that\nare ranked the top on both datasets under this challenge, one focused and small\n(Advising) and the other more diverse and large (Ubuntu). Previous\nstate-of-the-art models use hierarchy-based (utterance-level and token-level)\nneural networks to explicitly model the interactions among different turns'\nutterances for context modeling. In this paper, we investigate a sequential\nmatching model based only on chain sequence for multi-turn response selection.\nOur results demonstrate that the potentials of sequential matching approaches\nhave not yet been fully exploited in the past for multi-turn response\nselection. In addition to ranking the top in the challenge, the proposed model\noutperforms all previous models, including state-of-the-art hierarchy-based\nmodels, and achieves new state-of-the-art performances on two large-scale\npublic multi-turn response selection benchmark datasets.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 05:45:41 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 09:31:18 GMT"}, {"version": "v3", "created": "Tue, 19 Nov 2019 03:12:37 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Chen", "Qian", ""], ["Wang", "Wen", ""]]}, {"id": "1901.02646", "submitter": "Johannes Bjerva", "authors": "Johannes Bjerva and Robert \\\"Ostling and Maria Han Veiga and J\\\"org\n  Tiedemann and Isabelle Augenstein", "title": "What do Language Representations Really Represent?", "comments": "8 pages, accepted for publication in Computational Linguistics\n  (squib)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A neural language model trained on a text corpus can be used to induce\ndistributed representations of words, such that similar words end up with\nsimilar representations. If the corpus is multilingual, the same model can be\nused to learn distributed representations of languages, such that similar\nlanguages end up with similar representations. We show that this holds even\nwhen the multilingual corpus has been translated into English, by picking up\nthe faint signal left by the source languages. However, just like it is a\nthorny problem to separate semantic from syntactic similarity in word\nrepresentations, it is not obvious what type of similarity is captured by\nlanguage representations. We investigate correlations and causal relationships\nbetween language representations learned from translations on one hand, and\ngenetic, geographical, and several levels of structural similarity between\nlanguages on the other. Of these, structural similarity is found to correlate\nmost strongly with language representation similarity, while genetic\nrelationships---a convenient benchmark used for evaluation in previous\nwork---appears to be a confounding factor. Apart from implications about\ntranslation effects, we see this more generally as a case where NLP and\nlinguistic typology can interact and benefit one another.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 09:19:28 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Bjerva", "Johannes", ""], ["\u00d6stling", "Robert", ""], ["Veiga", "Maria Han", ""], ["Tiedemann", "J\u00f6rg", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "1901.02671", "submitter": "Steffen Eger", "authors": "Steffen Eger and Paul Youssef and Iryna Gurevych", "title": "Is it Time to Swish? Comparing Deep Learning Activation Functions Across\n  NLP tasks", "comments": "Published at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Activation functions play a crucial role in neural networks because they are\nthe nonlinearities which have been attributed to the success story of deep\nlearning. One of the currently most popular activation functions is ReLU, but\nseveral competitors have recently been proposed or 'discovered', including\nLReLU functions and swish. While most works compare newly proposed activation\nfunctions on few tasks (usually from image classification) and against few\ncompetitors (usually ReLU), we perform the first large-scale comparison of 21\nactivation functions across eight different NLP tasks. We find that a largely\nunknown activation function performs most stably across all tasks, the\nso-called penalized tanh function. We also show that it can successfully\nreplace the sigmoid and tanh gates in LSTM cells, leading to a 2 percentage\npoint (pp) improvement over the standard choices on a challenging NLP task.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 10:45:20 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Eger", "Steffen", ""], ["Youssef", "Paul", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1901.02780", "submitter": "Erion \\c{C}ano", "authors": "Erion \\c{C}ano, Ond\\v{r}ej Bojar", "title": "Sentiment Analysis of Czech Texts: An Algorithmic Survey", "comments": "7 pages, 2 figures, 7 tables. Published in proceedings of the 11th\n  International Conference on Agents and Artificial Intelligence - ICAART 2019\n  and can be found at\n  http://www.scitepress.org/PublicationsDetail.aspx?ID=1InVq6xKdwE=&t=1 The\n  paper content is identical to the previous one, only updated publication\n  metadata", "journal-ref": null, "doi": "10.5220/0007695709730979", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In the area of online communication, commerce and transactions, analyzing\nsentiment polarity of texts written in various natural languages has become\ncrucial. While there have been a lot of contributions in resources and studies\nfor the English language, \"smaller\" languages like Czech have not received much\nattention. In this survey, we explore the effectiveness of many existing\nmachine learning algorithms for sentiment analysis of Czech Facebook posts and\nproduct reviews. We report the sets of optimal parameter values for each\nalgorithm and the scores in both datasets. We finally observe that support\nvector machines are the best classifier and efforts to increase performance\neven more with bagging, boosting or voting ensemble schemes fail to do so.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 15:30:39 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2019 16:01:10 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["\u00c7ano", "Erion", ""], ["Bojar", "Ond\u0159ej", ""]]}, {"id": "1901.02860", "submitter": "Zihang Dai", "authors": "Zihang Dai, Zhilin Yang, Yiming Yang, Jaime Carbonell, Quoc V. Le,\n  Ruslan Salakhutdinov", "title": "Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context", "comments": "ACL 2019 long paper. Code and pretrained models are available at\n  https://github.com/kimiyoung/transformer-xl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Transformers have a potential of learning longer-term dependency, but are\nlimited by a fixed-length context in the setting of language modeling. We\npropose a novel neural architecture Transformer-XL that enables learning\ndependency beyond a fixed length without disrupting temporal coherence. It\nconsists of a segment-level recurrence mechanism and a novel positional\nencoding scheme. Our method not only enables capturing longer-term dependency,\nbut also resolves the context fragmentation problem. As a result,\nTransformer-XL learns dependency that is 80% longer than RNNs and 450% longer\nthan vanilla Transformers, achieves better performance on both short and long\nsequences, and is up to 1,800+ times faster than vanilla Transformers during\nevaluation. Notably, we improve the state-of-the-art results of bpc/perplexity\nto 0.99 on enwiki8, 1.08 on text8, 18.3 on WikiText-103, 21.8 on One Billion\nWord, and 54.5 on Penn Treebank (without finetuning). When trained only on\nWikiText-103, Transformer-XL manages to generate reasonably coherent, novel\ntext articles with thousands of tokens. Our code, pretrained models, and\nhyperparameters are available in both Tensorflow and PyTorch.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 18:28:19 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2019 18:38:00 GMT"}, {"version": "v3", "created": "Sun, 2 Jun 2019 21:21:48 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Dai", "Zihang", ""], ["Yang", "Zhilin", ""], ["Yang", "Yiming", ""], ["Carbonell", "Jaime", ""], ["Le", "Quoc V.", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1901.02998", "submitter": "Bo Chen", "authors": "Bo Chen, Le Sun, Xianpei Han, Bo An", "title": "Sentence Rewriting for Semantic Parsing", "comments": "Accepted as ACL 2016 long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge of semantic parsing is the vocabulary mismatch problem\nbetween natural language and target ontology. In this paper, we propose a\nsentence rewriting based semantic parsing method, which can effectively resolve\nthe mismatch problem by rewriting a sentence into a new form which has the same\nstructure with its target logical form. Specifically, we propose two\nsentence-rewriting methods for two common types of mismatch: a dictionary-based\nmethod for 1-N mismatch and a template-based method for N-1 mismatch. We\nevaluate our entence rewriting based semantic parser on the benchmark semantic\nparsing dataset -- WEBQUESTIONS. Experimental results show that our system\noutperforms the base system with a 3.4% gain in F1, and generates logical forms\nmore accurately and parses sentences more robustly.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 02:23:18 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["Chen", "Bo", ""], ["Sun", "Le", ""], ["Han", "Xianpei", ""], ["An", "Bo", ""]]}, {"id": "1901.03035", "submitter": "Chih-Yao Ma", "authors": "Chih-Yao Ma, Jiasen Lu, Zuxuan Wu, Ghassan AlRegib, Zsolt Kira,\n  Richard Socher, Caiming Xiong", "title": "Self-Monitoring Navigation Agent via Auxiliary Progress Estimation", "comments": "ICLR 2019, code is available at\n  https://github.com/chihyaoma/selfmonitoring-agent", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Vision-and-Language Navigation (VLN) task entails an agent following\nnavigational instruction in photo-realistic unknown environments. This\nchallenging task demands that the agent be aware of which instruction was\ncompleted, which instruction is needed next, which way to go, and its\nnavigation progress towards the goal. In this paper, we introduce a\nself-monitoring agent with two complementary components: (1) visual-textual\nco-grounding module to locate the instruction completed in the past, the\ninstruction required for the next action, and the next moving direction from\nsurrounding images and (2) progress monitor to ensure the grounded instruction\ncorrectly reflects the navigation progress. We test our self-monitoring agent\non a standard benchmark and analyze our proposed approach through a series of\nablation studies that elucidate the contributions of the primary components.\nUsing our proposed method, we set the new state of the art by a significant\nmargin (8% absolute increase in success rate on the unseen test set). Code is\navailable at https://github.com/chihyaoma/selfmonitoring-agent .\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 06:46:50 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["Ma", "Chih-Yao", ""], ["Lu", "Jiasen", ""], ["Wu", "Zuxuan", ""], ["AlRegib", "Ghassan", ""], ["Kira", "Zsolt", ""], ["Socher", "Richard", ""], ["Xiong", "Caiming", ""]]}, {"id": "1901.03116", "submitter": "Joel Escud\\'e Font", "authors": "Joel Escud\\'e Font and Marta R. Costa-juss\\`a", "title": "Equalizing Gender Biases in Neural Machine Translation with Word\n  Embeddings Techniques", "comments": "This paper has been accepted for publication at the 1st ACL Workshop\n  on Gender Bias for Natural Language Processing (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Neural machine translation has significantly pushed forward the quality of\nthe field. However, there are remaining big issues with the output translations\nand one of them is fairness. Neural models are trained on large text corpora\nwhich contain biases and stereotypes. As a consequence, models inherit these\nsocial biases. Recent methods have shown results in reducing gender bias in\nother natural language processing tools such as word embeddings. We take\nadvantage of the fact that word embeddings are used in neural machine\ntranslation to propose a method to equalize gender biases in neural machine\ntranslation using these representations. Specifically, we propose, experiment\nand analyze the integration of two debiasing techniques over GloVe embeddings\nin the Transformer translation architecture. We evaluate our proposed system on\nthe WMT English-Spanish benchmark task, showing gains up to one BLEU point. As\nfor the gender bias evaluation, we generate a test set of occupations and we\nshow that our proposed system learns to equalize existing biases from the\nbaseline system.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 12:06:31 GMT"}, {"version": "v2", "created": "Sun, 2 Jun 2019 22:20:06 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Font", "Joel Escud\u00e9", ""], ["Costa-juss\u00e0", "Marta R.", ""]]}, {"id": "1901.03141", "submitter": "Vinayakumar R", "authors": "Naveenkumar K S, Vinayakumar R, Soman KP", "title": "Emotion Detection using Data Driven Models", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Text is the major method that is used for communication now a days, each and\nevery day lots of text are created. In this paper the text data is used for the\nclassification of the emotions. Emotions are the way of expression of the\npersons feelings which has an high influence on the decision making tasks.\nDatasets are collected which are available publically and combined together\nbased on the three emotions that are considered here positive, negative and\nneutral. In this paper we have proposed the text representation method TFIDF\nand keras embedding and then given to the classical machine learning algorithms\nof which Logistics Regression gives the highest accuracy of about 75.6%, after\nwhich it is passed to the deep learning algorithm which is the CNN which gives\nthe state of art accuracy of about 45.25%. For the research purpose the\ndatasets that has been collected are released.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 13:15:46 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["S", "Naveenkumar K", ""], ["R", "Vinayakumar", ""], ["KP", "Soman", ""]]}, {"id": "1901.03253", "submitter": "Robert West", "authors": "Robert West and Eric Horvitz", "title": "Reverse-Engineering Satire, or \"Paper on Computational Humor Accepted\n  Despite Making Serious Advances\"", "comments": "Proceedings of the 33rd AAAI Conference on Artificial Intelligence,\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humor is an essential human trait. Efforts to understand humor have called\nout links between humor and the foundations of cognition, as well as the\nimportance of humor in social engagement. As such, it is a promising and\nimportant subject of study, with relevance for artificial intelligence and\nhuman-computer interaction. Previous computational work on humor has mostly\noperated at a coarse level of granularity, e.g., predicting whether an entire\nsentence, paragraph, document, etc., is humorous. As a step toward deep\nunderstanding of humor, we seek fine-grained models of attributes that make a\ngiven text humorous. Starting from the observation that satirical news\nheadlines tend to resemble serious news headlines, we build and analyze a\ncorpus of satirical headlines paired with nearly identical but serious\nheadlines. The corpus is constructed via Unfun.me, an online game that\nincentivizes players to make minimal edits to satirical headlines with the goal\nof making other players believe the results are serious headlines. The edit\noperations used to successfully remove humor pinpoint the words and concepts\nthat play a key role in making the original, satirical headline funny. Our\nanalysis reveals that the humor tends to reside toward the end of headlines,\nand primarily in noun phrases, and that most satirical headlines follow a\ncertain logical pattern, which we term false analogy. Overall, this paper\ndeepens our understanding of the syntactic and semantic structure of satirical\nnews headlines and provides insights for building humor-producing systems.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 16:25:53 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 16:04:31 GMT"}, {"version": "v3", "created": "Tue, 13 Aug 2019 09:35:52 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["West", "Robert", ""], ["Horvitz", "Eric", ""]]}, {"id": "1901.03438", "submitter": "Alex Warstadt", "authors": "Alex Warstadt and Samuel R. Bowman", "title": "Linguistic Analysis of Pretrained Sentence Encoders with Acceptability\n  Judgments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on evaluating grammatical knowledge in pretrained sentence\nencoders gives a fine-grained view of a small number of phenomena. We introduce\na new analysis dataset that also has broad coverage of linguistic phenomena. We\nannotate the development set of the Corpus of Linguistic Acceptability (CoLA;\nWarstadt et al., 2018) for the presence of 13 classes of syntactic phenomena\nincluding various forms of argument alternations, movement, and modification.\nWe use this analysis set to investigate the grammatical knowledge of three\npretrained encoders: BERT (Devlin et al., 2018), GPT (Radford et al., 2018),\nand the BiLSTM baseline from Warstadt et al. We find that these models have a\nstrong command of complex or non-canonical argument structures like\nditransitives (Sue gave Dan a book) and passives (The book was read). Sentences\nwith long distance dependencies like questions (What do you think I ate?)\nchallenge all models, but for these, BERT and GPT have a distinct advantage\nover the baseline. We conclude that recent sentence encoders, despite showing\nnear-human performance on acceptability classification overall, still fail to\nmake fine-grained grammaticality distinctions for many complex syntactic\nstructures.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 00:25:10 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 03:10:27 GMT"}, {"version": "v3", "created": "Fri, 20 Sep 2019 18:54:55 GMT"}, {"version": "v4", "created": "Fri, 22 May 2020 01:59:21 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Warstadt", "Alex", ""], ["Bowman", "Samuel R.", ""]]}, {"id": "1901.03459", "submitter": "Yan Zhao", "authors": "Yan Zhao, Lu Liu, Chunhua Liu, Ruoyao Yang and Dong Yu", "title": "From Plots to Endings: A Reinforced Pointer Generator for Story Ending\n  Generation", "comments": "12 pages, 1 figure, NLPCC 2018", "journal-ref": "Natural Language Processing and Chinese Computing. NLPCC 2018.\n  Lecture Notes in Computer Science, vol 11108. Springer, Cham", "doi": "10.1007/978-3-319-99495-6_5", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new task named Story Ending Generation (SEG), whic-h aims at\ngenerating a coherent story ending from a sequence of story plot. Wepropose a\nframework consisting of a Generator and a Reward Manager for thistask. The\nGenerator follows the pointer-generator network with coverage mech-anism to\ndeal with out-of-vocabulary (OOV) and repetitive words. Moreover, amixed loss\nmethod is introduced to enable the Generator to produce story endingsof high\nsemantic relevance with story plots. In the Reward Manager, the rewardis\ncomputed to fine-tune the Generator with policy-gradient reinforcement\nlearn-ing (PGRL). We conduct experiments on the recently-introduced\nROCStoriesCorpus. We evaluate our model in both automatic evaluation and human\nevalua-tion. Experimental results show that our model exceeds the\nsequence-to-sequencebaseline model by 15.75% and 13.57% in terms of CIDEr and\nconsistency scorerespectively.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 02:28:38 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Zhao", "Yan", ""], ["Liu", "Lu", ""], ["Liu", "Chunhua", ""], ["Yang", "Ruoyao", ""], ["Yu", "Dong", ""]]}, {"id": "1901.03461", "submitter": "Koichiro Yoshino Ph.D.", "authors": "Koichiro Yoshino, Chiori Hori, Julien Perez, Luis Fernando D'Haro,\n  Lazaros Polymenakos, Chulaka Gunasekara, Walter S. Lasecki, Jonathan K.\n  Kummerfeld, Michel Galley, Chris Brockett, Jianfeng Gao, Bill Dolan, Xiang\n  Gao, Huda Alamari, Tim K. Marks, Devi Parikh, Dhruv Batra", "title": "Dialog System Technology Challenge 7", "comments": "This paper is presented at NIPS2018 2nd Conversational AI workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the Seventh Dialog System Technology Challenges (DSTC),\nwhich use shared datasets to explore the problem of building dialog systems.\nRecently, end-to-end dialog modeling approaches have been applied to various\ndialog tasks. The seventh DSTC (DSTC7) focuses on developing technologies\nrelated to end-to-end dialog systems for (1) sentence selection, (2) sentence\ngeneration and (3) audio visual scene aware dialog. This paper summarizes the\noverall setup and results of DSTC7, including detailed descriptions of the\ndifferent tracks and provided datasets. We also describe overall trends in the\nsubmitted systems and the key results. Each track introduced new datasets and\nparticipants achieved impressive results using state-of-the-art end-to-end\ntechnologies.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 02:43:12 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Yoshino", "Koichiro", ""], ["Hori", "Chiori", ""], ["Perez", "Julien", ""], ["D'Haro", "Luis Fernando", ""], ["Polymenakos", "Lazaros", ""], ["Gunasekara", "Chulaka", ""], ["Lasecki", "Walter S.", ""], ["Kummerfeld", "Jonathan K.", ""], ["Galley", "Michel", ""], ["Brockett", "Chris", ""], ["Gao", "Jianfeng", ""], ["Dolan", "Bill", ""], ["Gao", "Xiang", ""], ["Alamari", "Huda", ""], ["Marks", "Tim K.", ""], ["Parikh", "Devi", ""], ["Batra", "Dhruv", ""]]}, {"id": "1901.03489", "submitter": "Chen Qu", "authors": "Chen Qu, Liu Yang, Bruce Croft, Yongfeng Zhang, Johanne R. Trippas and\n  Minghui Qiu", "title": "User Intent Prediction in Information-seeking Conversations", "comments": "Accepted to CHIIR 2019", "journal-ref": null, "doi": "10.1145/3295750.3298924", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational assistants are being progressively adopted by the general\npopulation. However, they are not capable of handling complicated\ninformation-seeking tasks that involve multiple turns of information exchange.\nDue to the limited communication bandwidth in conversational search, it is\nimportant for conversational assistants to accurately detect and predict user\nintent in information-seeking conversations. In this paper, we investigate two\naspects of user intent prediction in an information-seeking setting. First, we\nextract features based on the content, structural, and sentiment\ncharacteristics of a given utterance, and use classic machine learning methods\nto perform user intent prediction. We then conduct an in-depth feature\nimportance analysis to identify key features in this prediction task. We find\nthat structural features contribute most to the prediction performance. Given\nthis finding, we construct neural classifiers to incorporate context\ninformation and achieve better performance without feature engineering. Our\nfindings can provide insights into the important factors and effective methods\nof user intent prediction in information-seeking conversations.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 05:53:13 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Qu", "Chen", ""], ["Yang", "Liu", ""], ["Croft", "Bruce", ""], ["Zhang", "Yongfeng", ""], ["Trippas", "Johanne R.", ""], ["Qiu", "Minghui", ""]]}, {"id": "1901.03491", "submitter": "Chen Qu", "authors": "Chen Qu, Liu Yang, Bruce Croft, Falk Scholer and Yongfeng Zhang", "title": "Answer Interaction in Non-factoid Question Answering Systems", "comments": "Accepted to CHIIR 2019", "journal-ref": null, "doi": "10.1145/3295750.3298946", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information retrieval systems are evolving from document retrieval to answer\nretrieval. Web search logs provide large amounts of data about how people\ninteract with ranked lists of documents, but very little is known about\ninteraction with answer texts. In this paper, we use Amazon Mechanical Turk to\ninvestigate three answer presentation and interaction approaches in a\nnon-factoid question answering setting. We find that people perceive and react\nto good and bad answers very differently, and can identify good answers\nrelatively quickly. Our results provide the basis for further investigation of\neffective answer interaction and feedback methods.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 06:02:22 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2019 05:09:48 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Qu", "Chen", ""], ["Yang", "Liu", ""], ["Croft", "Bruce", ""], ["Scholer", "Falk", ""], ["Zhang", "Yongfeng", ""]]}, {"id": "1901.03526", "submitter": "Md Saiful Islam", "authors": "Humayun Kayesh, Md. Saiful Islam and Junhu Wang", "title": "On Event Causality Detection in Tweets", "comments": null, "journal-ref": "Griffith University Technical Report, 2019", "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, Twitter has become a great source of user-generated information\nabout events. Very often people report causal relationships between events in\ntheir tweets. Automatic detection of causality information in these events\nmight play an important role in predictive event analytics. Existing approaches\ninclude both rule-based and data-driven supervised methods. However, it is\nchallenging to correctly identify event causality using only linguistic rules\ndue to the highly unstructured nature and grammatical incorrectness of social\nmedia short text such as tweets. Also, it is difficult to develop a data-driven\nsupervised method for event causality detection in tweets due to insufficient\ncontextual information. This paper proposes a novel event context word\nextension technique based on background knowledge. To demonstrate the\neffectiveness of our proposed event context word extension technique, we\ndevelop a feed-forward neural network based approach to detect event causality\nfrom tweets. Extensive experiments demonstrate the superiority of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 09:39:55 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Kayesh", "Humayun", ""], ["Islam", "Md. Saiful", ""], ["Wang", "Junhu", ""]]}, {"id": "1901.03601", "submitter": "Tanel Alum\\\"ae", "authors": "Tanel Alum\\\"ae, Ottokar Tilk and Asadullah", "title": "Advanced Rich Transcription System for Estonian Speech", "comments": "Published in Baltic HLT 2018 (putting it on arXiv because Google\n  Scholar doesn't index it properly)", "journal-ref": "Series: Frontiers in Artificial Intelligence and Applications;\n  Ebook Volume 307: Human Language Technologies -- The Baltic Perspective, 2018", "doi": "10.3233/978-1-61499-912-6-1", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the current TT\\\"U speech transcription system for\nEstonian speech. The system is designed to handle semi-spontaneous speech, such\nas broadcast conversations, lecture recordings and interviews recorded in\ndiverse acoustic conditions. The system is based on the Kaldi toolkit.\nMulti-condition training using background noise profiles extracted\nautomatically from untranscribed data is used to improve the robustness of the\nsystem. Out-of-vocabulary words are recovered using a phoneme n-gram based\ndecoding subgraph and a FST-based phoneme-to-grapheme model. The system\nachieves a word error rate of 8.1% on a test set of broadcast conversations.\nThe system also performs punctuation recovery and speaker identification.\nSpeaker identification models are trained using a recently proposed weakly\nsupervised training method.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 14:51:02 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Alum\u00e4e", "Tanel", ""], ["Tilk", "Ottokar", ""], ["Asadullah", "", ""]]}, {"id": "1901.03644", "submitter": "Edward Hu", "authors": "J. Edward Hu, Rachel Rudinger, Matt Post, Benjamin Van Durme", "title": "ParaBank: Monolingual Bitext Generation and Sentential Paraphrasing via\n  Lexically-constrained Neural Machine Translation", "comments": "To be presented at AAAI 2019. 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ParaBank, a large-scale English paraphrase dataset that surpasses\nprior work in both quantity and quality. Following the approach of ParaNMT, we\ntrain a Czech-English neural machine translation (NMT) system to generate novel\nparaphrases of English reference sentences. By adding lexical constraints to\nthe NMT decoding procedure, however, we are able to produce multiple\nhigh-quality sentential paraphrases per source sentence, yielding an English\nparaphrase resource with more than 4 billion generated tokens and exhibiting\ngreater lexical diversity. Using human judgments, we also demonstrate that\nParaBank's paraphrases improve over ParaNMT on both semantic similarity and\nfluency. Finally, we use ParaBank to train a monolingual NMT model with the\nsame support for lexically-constrained decoding for sentence rewriting tasks.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 16:42:43 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Hu", "J. Edward", ""], ["Rudinger", "Rachel", ""], ["Post", "Matt", ""], ["Van Durme", "Benjamin", ""]]}, {"id": "1901.03735", "submitter": "Aakanksha Naik", "authors": "Abhilasha Ravichander, Aakanksha Naik, Carolyn Rose, Eduard Hovy", "title": "EQUATE: A Benchmark Evaluation Framework for Quantitative Reasoning in\n  Natural Language Inference", "comments": "To appear at CoNLL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Quantitative reasoning is a higher-order reasoning skill that any intelligent\nnatural language understanding system can reasonably be expected to handle. We\npresent EQUATE (Evaluating Quantitative Understanding Aptitude in Textual\nEntailment), a new framework for quantitative reasoning in textual entailment.\nWe benchmark the performance of 9 published NLI models on EQUATE, and find that\non average, state-of-the-art methods do not achieve an absolute improvement\nover a majority-class baseline, suggesting that they do not implicitly learn to\nreason with quantities. We establish a new baseline Q-REAS that manipulates\nquantities symbolically. In comparison to the best performing NLI model, it\nachieves success on numerical reasoning tests (+24.2%), but has limited verbal\nreasoning capabilities (-8.1%). We hope our evaluation framework will support\nthe development of models of quantitative reasoning in language understanding.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 20:27:25 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 03:38:23 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Ravichander", "Abhilasha", ""], ["Naik", "Aakanksha", ""], ["Rose", "Carolyn", ""], ["Hovy", "Eduard", ""]]}, {"id": "1901.03788", "submitter": "Qing Yin", "authors": "Qing Yin, Guan Luo, Xiaodong Zhu, Qinghua Hu and Ou Wu", "title": "Semi-interactive Attention Network for Answer Understanding in\n  Reverse-QA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question answering (QA) is an important natural language processing (NLP)\ntask and has received much attention in academic research and industry\ncommunities. Existing QA studies assume that questions are raised by humans and\nanswers are generated by machines. Nevertheless, in many real applications,\nmachines are also required to determine human needs or perceive human states.\nIn such scenarios, machines may proactively raise questions and humans supply\nanswers. Subsequently, machines should attempt to understand the true meaning\nof these answers. This new QA approach is called reverse-QA (rQA) throughout\nthis paper. In this work, the human answer understanding problem is\ninvestigated and solved by classifying the answers into predefined answer-label\ncategories (e.g., True, False, Uncertain). To explore the relationships between\nquestions and answers, we use the interactive attention network (IAN) model and\npropose an improved structure called semi-interactive attention network\n(Semi-IAN). Two Chinese data sets for rQA are compiled. We evaluate several\nconventional text classification models for comparison, and experimental\nresults indicate the promising performance of our proposed models.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2019 02:50:40 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Yin", "Qing", ""], ["Luo", "Guan", ""], ["Zhu", "Xiaodong", ""], ["Hu", "Qinghua", ""], ["Wu", "Ou", ""]]}, {"id": "1901.03859", "submitter": "Jingyun Liu", "authors": "Jingyun Liu, Jackie C.K.Cheung, Annie Louis", "title": "What comes next? Extractive summarization by next-sentence prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing approaches to automatic summarization assume that a length limit for\nthe summary is given, and view content selection as an optimization problem to\nmaximize informativeness and minimize redundancy within this budget. This\nframework ignores the fact that human-written summaries have rich internal\nstructure which can be exploited to train a summarization system. We present\nNEXTSUM, a novel approach to summarization based on a model that predicts the\nnext sentence to include in the summary using not only the source article, but\nalso the summary produced so far. We show that such a model successfully\ncaptures summary-specific discourse moves, and leads to better content\nselection performance, in addition to automatically predicting how long the\ntarget summary should be. We perform experiments on the New York Times\nAnnotated Corpus of summaries, where NEXTSUM outperforms lead and content-model\nsummarization baselines by significant margins. We also show that the lengths\nof summaries produced by our system correlates with the lengths of the\nhuman-written gold standards.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2019 13:00:30 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Liu", "Jingyun", ""], ["Cheung", "Jackie C. K.", ""], ["Louis", "Annie", ""]]}, {"id": "1901.03860", "submitter": "Muktabh Mayank Srivastava", "authors": "Harshita Seth, Pulkit Kumar, Muktabh Mayank Srivastava", "title": "Prototypical Metric Transfer Learning for Continuous Speech Keyword\n  Spotting With Limited Training Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Continuous Speech Keyword Spotting (CSKS) is the problem of spotting keywords\nin recorded conversations, when a small number of instances of keywords are\navailable in training data. Unlike the more common Keyword Spotting, where an\nalgorithm needs to detect lone keywords or short phrases like \"Alexa\",\n\"Cortana\", \"Hi Alexa!\", \"Whatsup Octavia?\" etc. in speech, CSKS needs to filter\nout embedded words from a continuous flow of speech, ie. spot \"Anna\" and\n\"github\" in \"I know a developer named Anna who can look into this github\nissue.\" Apart from the issue of limited training data availability, CSKS is an\nextremely imbalanced classification problem. We address the limitations of\nsimple keyword spotting baselines for both aforementioned challenges by using a\nnovel combination of loss functions (Prototypical networks' loss and metric\nloss) and transfer learning. Our method improves F1 score by over 10%.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2019 13:20:54 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Seth", "Harshita", ""], ["Kumar", "Pulkit", ""], ["Srivastava", "Muktabh Mayank", ""]]}, {"id": "1901.03866", "submitter": "Liang Pang", "authors": "Liang Pang, Yanyan Lan, Jiafeng Guo, Jun Xu, Lixin Su, Xueqi Cheng", "title": "HAS-QA: Hierarchical Answer Spans Model for Open-domain Question\n  Answering", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with open-domain question answering (i.e., OpenQA).\nRecently, some works have viewed this problem as a reading comprehension (RC)\ntask, and directly applied successful RC models to it. However, the\nperformances of such models are not so good as that in the RC task. In our\nopinion, the perspective of RC ignores three characteristics in OpenQA task: 1)\nmany paragraphs without the answer span are included in the data collection; 2)\nmultiple answer spans may exist within one given paragraph; 3) the end position\nof an answer span is dependent with the start position. In this paper, we first\npropose a new probabilistic formulation of OpenQA, based on a three-level\nhierarchical structure, i.e.,~the question level, the paragraph level and the\nanswer span level. Then a Hierarchical Answer Spans Model (HAS-QA) is designed\nto capture each probability. HAS-QA has the ability to tackle the above three\nproblems, and experiments on public OpenQA datasets show that it significantly\noutperforms traditional RC baselines and recent OpenQA baselines.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2019 14:29:35 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Pang", "Liang", ""], ["Lan", "Yanyan", ""], ["Guo", "Jiafeng", ""], ["Xu", "Jun", ""], ["Su", "Lixin", ""], ["Cheng", "Xueqi", ""]]}, {"id": "1901.03904", "submitter": "Mohammad Reza Feizi Derakhshi", "authors": "Zoleikha Jahanbakhsh-Nagadeh, Mohammad-Reza Feizi-Derakhshi, Arash\n  Sharifi", "title": "A Speech Act Classifier for Persian Texts and its Application in\n  Identifying Rumors", "comments": "Published Link: http://jscit.nit.ac.ir/article_103557.html", "journal-ref": "Journal of Soft Computing and Information Technology, 9, 1, 1399\n  (2020), 18-27", "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Speech Acts (SAs) are one of the important areas of pragmatics, which give us\na better understanding of the state of mind of the people and convey an\nintended language function. Knowledge of the SA of a text can be helpful in\nanalyzing that text in natural language processing applications. This study\npresents a dictionary-based statistical technique for Persian SA recognition.\nThe proposed technique classifies a text into seven classes of SA based on four\ncriteria: lexical, syntactic, semantic, and surface features. WordNet as the\ntool for extracting synonym and enriching features dictionary is utilized. To\nevaluate the proposed technique, we utilized four classification methods\nincluding Random Forest (RF), Support Vector Machine (SVM), Naive Bayes (NB),\nand K-Nearest Neighbors (KNN). The experimental results demonstrate that the\nproposed method using RF and SVM as the best classifiers achieved a\nstate-of-the-art performance with an accuracy of 0.95 for classification of\nPersian SAs. Our original vision of this work is introducing an application of\nSA recognition on social media content, especially the common SA in rumors.\nTherefore, the proposed system utilized to determine the common SAs in rumors.\nThe results showed that Persian rumors are often expressed in three SA classes\nincluding narrative, question, and threat, and in some cases with the request\nSA.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2019 21:54:23 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2019 15:08:44 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2020 08:19:03 GMT"}, {"version": "v4", "created": "Sun, 12 Jul 2020 10:42:12 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Jahanbakhsh-Nagadeh", "Zoleikha", ""], ["Feizi-Derakhshi", "Mohammad-Reza", ""], ["Sharifi", "Arash", ""]]}, {"id": "1901.04085", "submitter": "Rodrigo Nogueira", "authors": "Rodrigo Nogueira, Kyunghyun Cho", "title": "Passage Re-ranking with BERT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, neural models pretrained on a language modeling task, such as ELMo\n(Peters et al., 2017), OpenAI GPT (Radford et al., 2018), and BERT (Devlin et\nal., 2018), have achieved impressive results on various natural language\nprocessing tasks such as question-answering and natural language inference. In\nthis paper, we describe a simple re-implementation of BERT for query-based\npassage re-ranking. Our system is the state of the art on the TREC-CAR dataset\nand the top entry in the leaderboard of the MS MARCO passage retrieval task,\noutperforming the previous state of the art by 27% (relative) in MRR@10. The\ncode to reproduce our results is available at\nhttps://github.com/nyu-dl/dl4marco-bert\n", "versions": [{"version": "v1", "created": "Sun, 13 Jan 2019 23:27:58 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2019 14:05:34 GMT"}, {"version": "v3", "created": "Wed, 30 Jan 2019 02:25:25 GMT"}, {"version": "v4", "created": "Mon, 18 Feb 2019 22:04:21 GMT"}, {"version": "v5", "created": "Tue, 14 Apr 2020 14:57:40 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Nogueira", "Rodrigo", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1901.04112", "submitter": "Shuo Ren", "authors": "Shuo Ren, Zhirui Zhang, Shujie Liu, Ming Zhou, Shuai Ma", "title": "Unsupervised Neural Machine Translation with SMT as Posterior\n  Regularization", "comments": "To be presented at AAAI 2019; 9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Without real bilingual corpus available, unsupervised Neural Machine\nTranslation (NMT) typically requires pseudo parallel data generated with the\nback-translation method for the model training. However, due to weak\nsupervision, the pseudo data inevitably contain noises and errors that will be\naccumulated and reinforced in the subsequent training process, leading to bad\ntranslation performance. To address this issue, we introduce phrase based\nStatistic Machine Translation (SMT) models which are robust to noisy data, as\nposterior regularizations to guide the training of unsupervised NMT models in\nthe iterative back-translation process. Our method starts from SMT models built\nwith pre-trained language models and word-level translation tables inferred\nfrom cross-lingual embeddings. Then SMT and NMT models are optimized jointly\nand boost each other incrementally in a unified EM framework. In this way, (1)\nthe negative effect caused by errors in the iterative back-translation process\ncan be alleviated timely by SMT filtering noises from its phrase tables;\nmeanwhile, (2) NMT can compensate for the deficiency of fluency inherent in\nSMT. Experiments conducted on en-fr and en-de translation tasks show that our\nmethod outperforms the strong baseline and achieves new state-of-the-art\nunsupervised machine translation performance.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 03:34:27 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Ren", "Shuo", ""], ["Zhang", "Zhirui", ""], ["Liu", "Shujie", ""], ["Zhou", "Ming", ""], ["Ma", "Shuai", ""]]}, {"id": "1901.04140", "submitter": "Zihan Zhou", "authors": "Xuehui Sun, Zihan Zhou, Yuda Fan", "title": "Image Based Review Text Generation with Emotional Guidance", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the current field of computer vision, automatically generating texts from\ngiven images has been a fully worked technique. Up till now, most works of this\narea focus on image content describing, namely image-captioning. However, rare\nresearches focus on generating product review texts, which is ubiquitous in the\nonline shopping malls and is crucial for online shopping selection and\nevaluation. Different from content describing, review texts include more\nsubjective information of customers, which may bring difference to the results.\nTherefore, we aimed at a new field concerning generating review text from\ncustomers based on images together with the ratings of online shopping\nproducts, which appear as non-image attributes. We made several adjustments to\nthe existing image-captioning model to fit our task, in which we should also\ntake non-image features into consideration. We also did experiments based on\nour model and get effective primary results.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 05:42:51 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Sun", "Xuehui", ""], ["Zhou", "Zihan", ""], ["Fan", "Yuda", ""]]}, {"id": "1901.04216", "submitter": "Klesti Hoxha", "authors": "Klesti Hoxha and Artur Baxhaku", "title": "Albanian Language Identification in Text Documents", "comments": null, "journal-ref": "Buletini i Shkencave te Natyres, Vol. 23, 2017", "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we investigate the accuracy of standard and state-of-the-art\nlanguage identification methods in identifying Albanian in written text\ndocuments. A dataset consisting of news articles written in Albanian has been\nconstructed for this purpose. We noticed a considerable decrease of accuracy\nwhen using test documents that miss the Albanian alphabet letters \" \\\"E \" and \"\n\\c{C} \" and created a custom training corpus that solved this problem by\nachieving an accuracy of more than 99%. Based on our experiments, the most\nperforming language identification methods for Albanian use a na\\\"ive Bayes\nclassifier and n-gram based classification features.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 10:05:52 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Hoxha", "Klesti", ""], ["Baxhaku", "Artur", ""]]}, {"id": "1901.04276", "submitter": "No\\'e Tits", "authors": "No\\'e Tits, Kevin El Haddad and Thierry Dutoit", "title": "Exploring Transfer Learning for Low Resource Emotional TTS", "comments": "Accepted at IntelliSys 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last few years, spoken language technologies have known a big\nimprovement thanks to Deep Learning. However Deep Learning-based algorithms\nrequire amounts of data that are often difficult and costly to gather.\nParticularly, modeling the variability in speech of different speakers,\ndifferent styles or different emotions with few data remains challenging. In\nthis paper, we investigate how to leverage fine-tuning on a pre-trained Deep\nLearning-based TTS model to synthesize speech with a small dataset of another\nspeaker. Then we investigate the possibility to adapt this model to have\nemotional TTS by fine-tuning the neutral TTS model with a small emotional\ndataset.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 13:05:48 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Tits", "No\u00e9", ""], ["Haddad", "Kevin El", ""], ["Dutoit", "Thierry", ""]]}, {"id": "1901.04299", "submitter": "Lester Beltran", "authors": "Diederik Aerts, Lester Beltran, Suzette Geriente and Sandro Sozzo", "title": "Quantum-theoretic Modeling in Computer Science A complex Hilbert space\n  model for entangled concepts in corpuses of documents", "comments": "15 pages, no figures", "journal-ref": null, "doi": "10.1007/s10773-019-04155-y", "report-no": null, "categories": "cs.CL quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We work out a quantum-theoretic model in complex Hilbert space of a recently\nperformed test on co-occurrencies of two concepts and their combination in\nretrieval processes on specific corpuses of documents. The test violated the\nClauser-Horne-Shimony-Holt version of the Bell inequalities ('CHSH\ninequality'), thus indicating the presence of entanglement between the combined\nconcepts. We make use of a recently elaborated 'entanglement scheme' and\nrepresent the collected data in the tensor product of Hilbert spaces of the\nindividual concepts, showing that the identified violation is due to the\noccurrence of a strong form of entanglement, involving both states and\nmeasurements and reflecting the meaning connection between the component\nconcepts. These results provide a significant confirmation of the presence of\nquantum structures in corpuses of documents, like it is the case for the\nentanglement identified in human cognition.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jan 2019 20:33:28 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Aerts", "Diederik", ""], ["Beltran", "Lester", ""], ["Geriente", "Suzette", ""], ["Sozzo", "Sandro", ""]]}, {"id": "1901.04379", "submitter": "Adrian Lancucki", "authors": "Jan Chorowski, Adrian Lancucki, Bartosz Kostka, Michal Zapotoczny", "title": "Towards Using Context-Dependent Symbols in CTC Without State-Tying\n  Decision Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural acoustic models benefit from context-dependent (CD) modeling of\noutput symbols. We consider direct training of CTC networks with CD outputs,\nand identify two issues. The first one is frame-level normalization of\nprobabilities in CTC, which induces strong language modeling behavior that\nleads to overfitting and interference with external language models. The second\none is poor generalization in the presence of numerous lexical units like\ntriphones or tri-chars. We mitigate the former with utterance-level\nnormalization of probabilities. The latter typically requires reducing the CD\nsymbol inventory with state-tying decision trees, which have to be transferred\nfrom classical GMM-HMM systems. We replace the trees with a CD symbol embedding\nnetwork, which saves parameters and ensures generalization to unseen and\nundersampled CD symbols. The embedding network is trained together with the\nrest of the acoustic model and removes one of the last cases in which neural\nsystems have to be bootstrapped from GMM-HMM ones.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 16:23:35 GMT"}, {"version": "v2", "created": "Tue, 23 Apr 2019 13:38:29 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Chorowski", "Jan", ""], ["Lancucki", "Adrian", ""], ["Kostka", "Bartosz", ""], ["Zapotoczny", "Michal", ""]]}, {"id": "1901.04587", "submitter": "Brenden Lake", "authors": "Brenden M. Lake, Tal Linzen, Marco Baroni", "title": "Human few-shot learning of compositional instructions", "comments": "Please cite as: Lake, B. M., Linzen, T., and Baroni, M. (2019). Human\n  few-shot learning of compositional instructions. In Proceedings of the 41st\n  Annual Conference of the Cognitive Science Society", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People learn in fast and flexible ways that have not been emulated by\nmachines. Once a person learns a new verb \"dax,\" he or she can effortlessly\nunderstand how to \"dax twice,\" \"walk and dax,\" or \"dax vigorously.\" There have\nbeen striking recent improvements in machine learning for natural language\nprocessing, yet the best algorithms require vast amounts of experience and\nstruggle to generalize new concepts in compositional ways. To better understand\nthese distinctively human abilities, we study the compositional skills of\npeople through language-like instruction learning tasks. Our results show that\npeople can learn and use novel functional concepts from very few examples\n(few-shot learning), successfully applying familiar functions to novel inputs.\nPeople can also compose concepts in complex ways that go beyond the provided\ndemonstrations. Two additional experiments examined the assumptions and\ninductive biases that people make when solving these tasks, revealing three\nbiases: mutual exclusivity, one-to-one mappings, and iconic concatenation. We\ndiscuss the implications for cognitive modeling and the potential for building\nmachines with more human-like language learning capabilities.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 22:19:35 GMT"}, {"version": "v2", "created": "Sat, 11 May 2019 02:43:03 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Lake", "Brenden M.", ""], ["Linzen", "Tal", ""], ["Baroni", "Marco", ""]]}, {"id": "1901.04713", "submitter": "Chien-Sheng Wu", "authors": "Chien-Sheng Wu, Richard Socher, Caiming Xiong", "title": "Global-to-local Memory Pointer Networks for Task-Oriented Dialogue", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end task-oriented dialogue is challenging since knowledge bases are\nusually large, dynamic and hard to incorporate into a learning framework. We\npropose the global-to-local memory pointer (GLMP) networks to address this\nissue. In our model, a global memory encoder and a local memory decoder are\nproposed to share external knowledge. The encoder encodes dialogue history,\nmodifies global contextual representation, and generates a global memory\npointer. The decoder first generates a sketch response with unfilled slots.\nNext, it passes the global memory pointer to filter the external knowledge for\nrelevant information, then instantiates the slots via the local memory\npointers. We empirically show that our model can improve copy accuracy and\nmitigate the common out-of-vocabulary problem. As a result, GLMP is able to\nimprove over the previous state-of-the-art models in both simulated bAbI\nDialogue dataset and human-human Stanford Multi-domain Dialogue dataset on\nautomatic and human evaluation.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 08:55:53 GMT"}, {"version": "v2", "created": "Fri, 29 Mar 2019 05:13:11 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Wu", "Chien-Sheng", ""], ["Socher", "Richard", ""], ["Xiong", "Caiming", ""]]}, {"id": "1901.04787", "submitter": "Dilek K\\\"u\\c{c}\\\"uk", "authors": "Dilek K\\\"u\\c{c}\\\"uk and Fazli Can", "title": "A Tweet Dataset Annotated for Named Entity Recognition and Stance\n  Detection", "comments": "4 pages; resource URLs are made properly accessible (by clicking\n  them)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Annotated datasets in different domains are critical for many supervised\nlearning-based solutions to related problems and for the evaluation of the\nproposed solutions. Topics in natural language processing (NLP) similarly\nrequire annotated datasets to be used for such purposes. In this paper, we\ntarget at two NLP problems, named entity recognition and stance detection, and\npresent the details of a tweet dataset in Turkish annotated for named entity\nand stance information. Within the course of the current study, both the named\nentity and stance annotations of the included tweets are made publicly\navailable, although previously the dataset has been publicly shared with stance\nannotations only. We believe that this dataset will be useful for uncovering\nthe possible relationships between named entity recognition and stance\ndetection in tweets.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 12:16:13 GMT"}, {"version": "v2", "created": "Wed, 16 Jan 2019 09:01:08 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["K\u00fc\u00e7\u00fck", "Dilek", ""], ["Can", "Fazli", ""]]}, {"id": "1901.04831", "submitter": "Loreto Parisi", "authors": "Loreto Parisi, Simone Francia, Silvio Olivastri, Maria Stella Tavella", "title": "Exploiting Synchronized Lyrics And Vocal Features For Music Emotion\n  Detection", "comments": "8 pages, 5 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key points in music recommendation is authoring engaging playlists\naccording to sentiment and emotions. While previous works were mostly based on\naudio for music discovery and playlists generation, we take advantage of our\nsynchronized lyrics dataset to combine text representations and music features\nin a novel way; we therefore introduce the Synchronized Lyrics Emotion Dataset.\nUnlike other approaches that randomly exploited the audio samples and the whole\ntext, our data is split according to the temporal information provided by the\nsynchronization between lyrics and audio. This work shows a comparison between\ntext-based and audio-based deep learning classification models using different\ntechniques from Natural Language Processing and Music Information Retrieval\ndomains. From the experiments on audio we conclude that using vocals only,\ninstead of the whole audio data improves the overall performances of the audio\nclassifier. In the lyrics experiments we exploit the state-of-the-art word\nrepresentations applied to the main Deep Learning architectures available in\nliterature. In our benchmarks the results show how the Bilinear LSTM classifier\nwith Attention based on fastText word embedding performs better than the CNN\napplied on audio.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 14:10:25 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Parisi", "Loreto", ""], ["Francia", "Simone", ""], ["Olivastri", "Silvio", ""], ["Tavella", "Maria Stella", ""]]}, {"id": "1901.04899", "submitter": "Shachi Hullumane Kumar", "authors": "Eda Okur, Shachi H Kumar, Saurav Sahay, Asli Arslan Esme, Lama Nachman", "title": "Conversational Intent Understanding for Passengers in Autonomous\n  Vehicles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding passenger intents and extracting relevant slots are important\nbuilding blocks towards developing a contextual dialogue system responsible for\nhandling certain vehicle-passenger interactions in autonomous vehicles (AV).\nWhen the passengers give instructions to AMIE (Automated-vehicle Multimodal\nIn-cabin Experience), the agent should parse such commands properly and trigger\nthe appropriate functionality of the AV system. In our AMIE scenarios, we\ndescribe usages and support various natural commands for interacting with the\nvehicle. We collected a multimodal in-cabin data-set with multi-turn dialogues\nbetween the passengers and AMIE using a Wizard-of-Oz scheme. We explored\nvarious recent Recurrent Neural Networks (RNN) based techniques and built our\nown hierarchical models to recognize passenger intents along with relevant\nslots associated with the action to be performed in AV scenarios. Our\nexperimental results achieved F1-score of 0.91 on utterance-level intent\nrecognition and 0.96 on slot extraction models.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 00:43:58 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Okur", "Eda", ""], ["Kumar", "Shachi H", ""], ["Sahay", "Saurav", ""], ["Esme", "Asli Arslan", ""], ["Nachman", "Lama", ""]]}, {"id": "1901.04911", "submitter": "Yuri Gurevich", "authors": "Yuri Gurevich", "title": "Unconstrained Church-Turing thesis cannot possibly be true", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CL cs.DS math.LO quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Church-Turing thesis asserts that if a partial strings-to-strings\nfunction is effectively computable then it is computable by a Turing machine.\n  In the 1930s, when Church and Turing worked on their versions of the thesis,\nthere was a robust notion of algorithm. These traditional algorithms are known\nalso as classical or sequential. In the original thesis, effectively computable\nmeant computable by an effective classical algorithm. Based on an earlier\naxiomatization of classical algorithms, the original thesis was proven in 2008.\n  Since the 1930s, the notion of algorithm has changed dramatically. New\nspecies of algorithms have been and are being introduced. We argue that the\ngeneralization of the original thesis, where effectively computable means\ncomputable by an effective algorithm of any species, cannot possibly be true.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 16:24:07 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Gurevich", "Yuri", ""]]}, {"id": "1901.04936", "submitter": "Samira Abnar", "authors": "Samira Abnar, Tania Bedrax-weiss, Tom Kwiatkowski, William W. Cohen", "title": "Incremental Reading for Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Any system which performs goal-directed continual learning must not only\nlearn incrementally but process and absorb information incrementally. Such a\nsystem also has to understand when its goals have been achieved. In this paper,\nwe consider these issues in the context of question answering. Current\nstate-of-the-art question answering models reason over an entire passage, not\nincrementally. As we will show, naive approaches to incremental reading, such\nas restriction to unidirectional language models in the model, perform poorly.\nWe present extensions to the DocQA [2] model to allow incremental reading\nwithout loss of accuracy. The model also jointly learns to provide the best\nanswer given the text that is seen so far and predict whether this best-so-far\nanswer is sufficient.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 17:03:32 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Abnar", "Samira", ""], ["Bedrax-weiss", "Tania", ""], ["Kwiatkowski", "Tom", ""], ["Cohen", "William W.", ""]]}, {"id": "1901.05041", "submitter": "Alexander Panchenko", "authors": "Matthias Schildw\\\"achter, Alexander Bondarenko, Julian Zenker,\n  Matthias Hagen, Chris Biemann, and Alexander Panchenko", "title": "Answering Comparative Questions: Better than Ten-Blue-Links?", "comments": "In Proceeding of 2019 Conference on Human Information Interaction and\n  Retrieval (CHIIR '19), March 10--14, 2019, Glasgow, United Kingdom", "journal-ref": null, "doi": "10.1145/3295750.3298916", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present CAM (comparative argumentative machine), a novel open-domain IR\nsystem to argumentatively compare objects with respect to information extracted\nfrom the Common Crawl. In a user study, the participants obtained 15% more\naccurate answers using CAM compared to a \"traditional\" keyword-based search and\nwere 20% faster in finding the answer to comparative questions.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 20:50:28 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Schildw\u00e4chter", "Matthias", ""], ["Bondarenko", "Alexander", ""], ["Zenker", "Julian", ""], ["Hagen", "Matthias", ""], ["Biemann", "Chris", ""], ["Panchenko", "Alexander", ""]]}, {"id": "1901.05066", "submitter": "Saptarshi Sengupta", "authors": "Saptarshi Sengupta", "title": "Investigating Antigram Behaviour using Distributional Semantics", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language is an extremely interesting subject to study, each day presenting\nnew challenges and new topics for research. Words in particular have several\nunique characteristics which when explored, prove to be astonishing. Anagrams\nand Antigrams are such words possessing these amazing properties. The presented\nwork is an exploration into generating anagrams from a given word and\ndetermining whether there exists antigram relationships between the pairs of\ngenerated anagrams in light of the Word2Vec distributional semantic similarity\nmodel. The experiments conducted, showed promising results for detecting\nantigrams.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 21:56:32 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Sengupta", "Saptarshi", ""]]}, {"id": "1901.05115", "submitter": "Giulio Giorcelli", "authors": "Giulio Giorcelli", "title": "Variable-sized input, character-level recurrent neural networks in lead\n  generation: predicting close rates from raw user inputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting lead close rates is one of the most problematic tasks in the lead\ngeneration industry. In most cases, the only available data on the prospect is\nthe self-reported information inputted by the user on the lead form and a few\nother data points publicly available through social media and search engine\nusage. All the major market niches for lead generation [1], such as insurance,\nhealth & medical and real estate, deal with life-altering decision making that\nno amount of data will be ever be able to describe or predict. This paper\nillustrates how character-level, deep long short-term memory networks can be\napplied to raw user inputs to help predict close rates. The output of the model\nis then used as an additional, highly predictive feature to significantly boost\nperformance of lead scoring models.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 02:37:59 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Giorcelli", "Giulio", ""]]}, {"id": "1901.05180", "submitter": "Dieuwke Hupkes", "authors": "Willem Zuidema, Dieuwke Hupkes, Geraint Wiggins, Constance Scharff,\n  Martin Rohrmeier", "title": "Formal models of Structure Building in Music, Language and Animal Songs", "comments": "Pre-edited version of Zuidema, W., Hupkes, D., Wiggins, G. A.,\n  Scharff, C., & Rohrmeirer, M. (2018). Formal Models of Structure Building in\n  Music, Language, and Animal Song. The Origins of Musicality, 253", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human language, music and a variety of animal vocalisations constitute ways\nof sonic communication that exhibit remarkable structural complexity. While the\ncomplexities of language and possible parallels in animal communication have\nbeen discussed intensively, reflections on the complexity of music and animal\nsong, and their comparisons are underrepresented. In some ways, music and\nanimal songs are more comparable to each other than to language, as\npropositional semantics cannot be used as as indicator of communicative success\nor well-formedness, and notions of grammaticality are less easily defined. This\nreview brings together accounts of the principles of structure building in\nlanguage, music and animal song, relating them to the corresponding models in\nformal language theory, with a special focus on evaluating the benefits of\nusing the Chomsky hierarchy (CH). We further discuss common misunderstandings\nand shortcomings concerning the CH, as well as extensions or augmentations of\nit that address some of these issues, and suggest ways to move beyond.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 08:47:47 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Zuidema", "Willem", ""], ["Hupkes", "Dieuwke", ""], ["Wiggins", "Geraint", ""], ["Scharff", "Constance", ""], ["Rohrmeier", "Martin", ""]]}, {"id": "1901.05219", "submitter": "Myeongjun Jang", "authors": "Myeongjun Jang, Pilsung Kang", "title": "Sentence transition matrix: An efficient approach that preserves\n  sentence semantics", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence embedding is a significant research topic in the field of natural\nlanguage processing (NLP). Generating sentence embedding vectors reflecting the\nintrinsic meaning of a sentence is a key factor to achieve an enhanced\nperformance in various NLP tasks such as sentence classification and document\nsummarization. Therefore, various sentence embedding models based on supervised\nand unsupervised learning have been proposed after the advent of researches\nregarding the distributed representation of words. They were evaluated through\nsemantic textual similarity (STS) tasks, which measure the degree of semantic\npreservation of a sentence and neural network-based supervised embedding models\ngenerally yielded state-of-the-art performance. However, these models have a\nlimitation in that they have multiple parameters to update, thereby requiring a\ntremendous amount of labeled training data. In this study, we propose an\nefficient approach that learns a transition matrix that refines a sentence\nembedding vector to reflect the latent semantic meaning of a sentence. The\nproposed method has two practical advantages; (1) it can be applied to any\nsentence embedding method, and (2) it can achieve robust performance in STS\ntasks irrespective of the number of training examples.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 10:40:18 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Jang", "Myeongjun", ""], ["Kang", "Pilsung", ""]]}, {"id": "1901.05280", "submitter": "Zuchao Li", "authors": "Zuchao Li, Shexia He, Hai Zhao, Yiqing Zhang, Zhuosheng Zhang, Xi\n  Zhou, Xiang Zhou", "title": "Dependency or Span, End-to-End Uniform Semantic Role Labeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic role labeling (SRL) aims to discover the predicateargument structure\nof a sentence. End-to-end SRL without syntactic input has received great\nattention. However, most of them focus on either span-based or dependency-based\nsemantic representation form and only show specific model optimization\nrespectively. Meanwhile, handling these two SRL tasks uniformly was less\nsuccessful. This paper presents an end-to-end model for both dependency and\nspan SRL with a unified argument representation to deal with two different\ntypes of argument annotations in a uniform fashion. Furthermore, we jointly\npredict all predicates and arguments, especially including long-term ignored\npredicate identification subtask. Our single model achieves new\nstate-of-the-art results on both span (CoNLL 2005, 2012) and dependency (CoNLL\n2008, 2009) SRL benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 13:48:53 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Li", "Zuchao", ""], ["He", "Shexia", ""], ["Zhao", "Hai", ""], ["Zhang", "Yiqing", ""], ["Zhang", "Zhuosheng", ""], ["Zhou", "Xi", ""], ["Zhou", "Xiang", ""]]}, {"id": "1901.05287", "submitter": "Yoav Goldberg", "authors": "Yoav Goldberg", "title": "Assessing BERT's Syntactic Abilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I assess the extent to which the recently introduced BERT model captures\nEnglish syntactic phenomena, using (1) naturally-occurring subject-verb\nagreement stimuli; (2) \"coloreless green ideas\" subject-verb agreement stimuli,\nin which content words in natural sentences are randomly replaced with words\nsharing the same part-of-speech and inflection; and (3) manually crafted\nstimuli for subject-verb agreement and reflexive anaphora phenomena. The BERT\nmodel performs remarkably well on all cases.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 14:01:15 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Goldberg", "Yoav", ""]]}, {"id": "1901.05389", "submitter": "M\\'arton Karsai", "authors": "Jacobo Levy Abitbol, M\\'arton Karsai, and Eric Fleury", "title": "Location, Occupation, and Semantics based Socioeconomic Status Inference\n  on Twitter", "comments": "Accepted as a full paper in the 2018 IEEE 18th International\n  Conference on Data Mining - IWSC'18 2nd International Workshop on Social\n  Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.CY physics.data-an physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The socioeconomic status of people depends on a combination of individual\ncharacteristics and environmental variables, thus its inference from online\nbehavioral data is a difficult task. Attributes like user semantics in\ncommunication, habitat, occupation, or social network are all known to be\ndeterminant predictors of this feature. In this paper we propose three\ndifferent data collection and combination methods to first estimate and, in\nturn, infer the socioeconomic status of French Twitter users from their online\nsemantics. Our methods are based on open census data, crawled professional\nprofiles, and remotely sensed, expert annotated information on living\nenvironment. Our inference models reach similar performance of earlier results\nwith the advantage of relying on broadly available datasets and of providing a\ngeneralizable framework to estimate socioeconomic status of large numbers of\nTwitter users. These results may contribute to the scientific discussion on\nsocial stratification and inequalities, and may fuel several applications.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 16:56:14 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Abitbol", "Jacobo Levy", ""], ["Karsai", "M\u00e1rton", ""], ["Fleury", "Eric", ""]]}, {"id": "1901.05415", "submitter": "Braden Hancock", "authors": "Braden Hancock, Antoine Bordes, Pierre-Emmanuel Mazar\\'e, Jason Weston", "title": "Learning from Dialogue after Deployment: Feed Yourself, Chatbot!", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The majority of conversations a dialogue agent sees over its lifetime occur\nafter it has already been trained and deployed, leaving a vast store of\npotential training signal untapped. In this work, we propose the self-feeding\nchatbot, a dialogue agent with the ability to extract new training examples\nfrom the conversations it participates in. As our agent engages in\nconversation, it also estimates user satisfaction in its responses. When the\nconversation appears to be going well, the user's responses become new training\nexamples to imitate. When the agent believes it has made a mistake, it asks for\nfeedback; learning to predict the feedback that will be given improves the\nchatbot's dialogue abilities further. On the PersonaChat chit-chat dataset with\nover 131k training examples, we find that learning from dialogue with a\nself-feeding chatbot significantly improves performance, regardless of the\namount of traditional supervision.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 18:02:44 GMT"}, {"version": "v2", "created": "Sun, 3 Feb 2019 07:03:17 GMT"}, {"version": "v3", "created": "Wed, 5 Jun 2019 03:23:04 GMT"}, {"version": "v4", "created": "Thu, 13 Jun 2019 06:01:04 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Hancock", "Braden", ""], ["Bordes", "Antoine", ""], ["Mazar\u00e9", "Pierre-Emmanuel", ""], ["Weston", "Jason", ""]]}, {"id": "1901.05531", "submitter": "Abhishek Das", "authors": "Abhishek Das, Devi Parikh, Dhruv Batra", "title": "Response to \"Visual Dialogue without Vision or Dialogue\" (Massiceti et\n  al., 2018)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent workshop paper, Massiceti et al. presented a baseline model and\nsubsequent critique of Visual Dialog (Das et al., CVPR 2017) that raises what\nwe believe to be unfounded concerns about the dataset and evaluation. This\narticle intends to rebut the critique and clarify potential confusions for\npractitioners and future participants in the Visual Dialog challenge.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 21:27:57 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Das", "Abhishek", ""], ["Parikh", "Devi", ""], ["Batra", "Dhruv", ""]]}, {"id": "1901.05816", "submitter": "Yung-Sung Chuang", "authors": "Yung-Sung Chuang", "title": "Robust Chinese Word Segmentation with Contextualized Word\n  Representations", "comments": "6 pages, 1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, after the neural-network-based method was proposed, the\naccuracy of the Chinese word segmentation task has made great progress.\nHowever, when dealing with out-of-vocabulary words, there is still a large\nerror rate. We used a simple bidirectional LSTM architecture and a large-scale\npretrained language model to generate high-quality contextualize character\nrepresentations, which successfully reduced the weakness of the ambiguous\nmeanings of each Chinese character that widely appears in Chinese characters,\nand hence effectively reduced OOV error rate. State-of-the-art performance is\nachieved on many datasets.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 14:42:38 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Chuang", "Yung-Sung", ""]]}, {"id": "1901.06039", "submitter": "Theresa Breiner", "authors": "Theresa Breiner, Chieu Nguyen, Daan van Esch, Jeremy O'Brien", "title": "Automatic Keyboard Layout Design for Low-Resource Latin-Script Languages", "comments": "4 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present our approach to automatically designing and implementing keyboard\nlayouts on mobile devices for typing low-resource languages written in the\nLatin script. For many speakers, one of the barriers in accessing and creating\ntext content on the web is the absence of input tools for their language. Ease\nin typing in these languages would lower technological barriers to online\ncommunication and collaboration, likely leading to the creation of more web\ncontent. Unfortunately, it can be time-consuming to develop layouts manually\neven for language communities that use a keyboard layout very similar to\nEnglish; starting from scratch requires many configuration files to describe\nmultiple possible behaviors for each key. With our approach, we only need a\nsmall amount of data in each language to generate keyboard layouts with very\nlittle human effort. This process can help serve speakers of low-resource\nlanguages in a scalable way, allowing us to develop input tools for more\nlanguages. Having input tools that reflect the linguistic diversity of the\nworld will let as many people as possible use technology to learn, communicate,\nand express themselves in their own native languages.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 00:09:24 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Breiner", "Theresa", ""], ["Nguyen", "Chieu", ""], ["van Esch", "Daan", ""], ["O'Brien", "Jeremy", ""]]}, {"id": "1901.06079", "submitter": "Deng Cai", "authors": "Hai Zhao and Deng Cai and Changning Huang and Chunyu Kit", "title": "Chinese Word Segmentation: Another Decade Review (2007-2017)", "comments": "in Chinese", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reviews the development of Chinese word segmentation (CWS) in the\nmost recent decade, 2007-2017. Special attention was paid to the deep learning\ntechnologies that has already permeated into most areas of natural language\nprocessing (NLP). The basic view we have arrived at is that compared to\ntraditional supervised learning methods, neural network based methods have not\nshown any superior performance. The most critical challenge still lies on\nbalancing of recognition of in-vocabulary (IV) and out-of-vocabulary (OOV)\nwords. However, as neural models have potentials to capture the essential\nlinguistic structure of natural language, we are optimistic about significant\nprogresses may arrive in the near future.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 04:16:56 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Zhao", "Hai", ""], ["Cai", "Deng", ""], ["Huang", "Changning", ""], ["Kit", "Chunyu", ""]]}, {"id": "1901.06103", "submitter": "Yijia Zhang", "authors": "Yijia Zhang and Zhiyong Lu", "title": "Exploring Semi-supervised Variational Autoencoders for Biomedical\n  Relation Extraction", "comments": "13 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The biomedical literature provides a rich source of knowledge such as\nprotein-protein interactions (PPIs), drug-drug interactions (DDIs) and\nchemical-protein interactions (CPIs). Biomedical relation extraction aims to\nautomatically extract biomedical relations from biomedical text for various\nbiomedical research. State-of-the-art methods for biomedical relation\nextraction are primarily based on supervised machine learning and therefore\ndepend on (sufficient) labeled data. However, creating large sets of training\ndata is prohibitively expensive and labor-intensive, especially so in\nbiomedicine as domain knowledge is required. In contrast, there is a large\namount of unlabeled biomedical text available in PubMed. Hence, computational\nmethods capable of employing unlabeled data to reduce the burden of manual\nannotation are of particular interest in biomedical relation extraction. We\npresent a novel semi-supervised approach based on variational autoencoder (VAE)\nfor biomedical relation extraction. Our model consists of the following three\nparts, a classifier, an encoder and a decoder. The classifier is implemented\nusing multi-layer convolutional neural networks (CNNs), and the encoder and\ndecoder are implemented using both bidirectional long short-term memory\nnetworks (Bi-LSTMs) and CNNs, respectively. The semi-supervised mechanism\nallows our model to learn features from both the labeled and unlabeled data. We\nevaluate our method on multiple public PPI, DDI and CPI corpora. Experimental\nresults show that our method effectively exploits the unlabeled data to improve\nthe performance and reduce the dependence on labeled data. To our best\nknowledge, this is the first semi-supervised VAE-based method for (biomedical)\nrelation extraction. Our results suggest that exploiting such unlabeled data\ncan be greatly beneficial to improved performance in various biomedical\nrelation extraction.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 06:48:53 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Zhang", "Yijia", ""], ["Lu", "Zhiyong", ""]]}, {"id": "1901.06168", "submitter": "Jan Trienes", "authors": "Jan Trienes, Krisztian Balog", "title": "Identifying Unclear Questions in Community Question Answering Websites", "comments": "Proceedings of the 41th European Conference on Information Retrieval\n  (ECIR '19), 2019", "journal-ref": null, "doi": "10.1007/978-3-030-15712-8_18", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thousands of complex natural language questions are submitted to community\nquestion answering websites on a daily basis, rendering them as one of the most\nimportant information sources these days. However, oftentimes submitted\nquestions are unclear and cannot be answered without further clarification\nquestions by expert community members. This study is the first to investigate\nthe complex task of classifying a question as clear or unclear, i.e., if it\nrequires further clarification. We construct a novel dataset and propose a\nclassification approach that is based on the notion of similar questions. This\napproach is compared to state-of-the-art text classification baselines. Our\nmain finding is that the similar questions approach is a viable alternative\nthat can be used as a stepping stone towards the development of supportive user\ninterfaces for question formulation.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 10:29:20 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Trienes", "Jan", ""], ["Balog", "Krisztian", ""]]}, {"id": "1901.06283", "submitter": "Liqun Chen", "authors": "Liqun Chen, Yizhe Zhang, Ruiyi Zhang, Chenyang Tao, Zhe Gan, Haichao\n  Zhang, Bai Li, Dinghan Shen, Changyou Chen, Lawrence Carin", "title": "Improving Sequence-to-Sequence Learning via Optimal Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-to-sequence models are commonly trained via maximum likelihood\nestimation (MLE). However, standard MLE training considers a word-level\nobjective, predicting the next word given the previous ground-truth partial\nsentence. This procedure focuses on modeling local syntactic patterns, and may\nfail to capture long-range semantic structure. We present a novel solution to\nalleviate these issues. Our approach imposes global sequence-level guidance via\nnew supervision based on optimal transport, enabling the overall\ncharacterization and preservation of semantic features. We further show that\nthis method can be understood as a Wasserstein gradient flow trying to match\nour model to the ground truth sequence distribution. Extensive experiments are\nconducted to validate the utility of the proposed approach, showing consistent\nimprovements over a wide variety of NLP tasks, including machine translation,\nabstractive text summarization, and image captioning.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 14:52:34 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Chen", "Liqun", ""], ["Zhang", "Yizhe", ""], ["Zhang", "Ruiyi", ""], ["Tao", "Chenyang", ""], ["Gan", "Zhe", ""], ["Zhang", "Haichao", ""], ["Li", "Bai", ""], ["Shen", "Dinghan", ""], ["Chen", "Changyou", ""], ["Carin", "Lawrence", ""]]}, {"id": "1901.06436", "submitter": "Jasmijn Bastings", "authors": "Jasmijn Bastings, Wilker Aziz, Ivan Titov, Khalil Sima'an", "title": "Modeling Latent Sentence Structure in Neural Machine Translation", "comments": "Accepted as an extended abstract to ACL NMT workshop 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently it was shown that linguistic structure predicted by a supervised\nparser can be beneficial for neural machine translation (NMT). In this work we\ninvestigate a more challenging setup: we incorporate sentence structure as a\nlatent variable in a standard NMT encoder-decoder and induce it in such a way\nas to benefit the translation task. We consider German-English and\nJapanese-English translation benchmarks and observe that when using RNN\nencoders the model makes no or very limited use of the structure induction\napparatus. In contrast, CNN and word-embedding-based encoders rely on latent\ngraphs and force them to encode useful, potentially long-distance,\ndependencies.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 22:43:17 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 20:33:40 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Bastings", "Jasmijn", ""], ["Aziz", "Wilker", ""], ["Titov", "Ivan", ""], ["Sima'an", "Khalil", ""]]}, {"id": "1901.06486", "submitter": "Dario Bertero", "authors": "Dario Bertero, Onno Kampman and Pascale Fung", "title": "Towards Universal End-to-End Affect Recognition from Multilingual Speech\n  by ConvNets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an end-to-end affect recognition approach using a Convolutional\nNeural Network (CNN) that handles multiple languages, with applications to\nemotion and personality recognition from speech. We lay the foundation of a\nuniversal model that is trained on multiple languages at once. As affect is\nshared across all languages, we are able to leverage shared information between\nlanguages and improve the overall performance for each one. We obtained an\naverage improvement of 12.8% on emotion and 10.1% on personality when compared\nwith the same model trained on each language only. It is end-to-end because we\ndirectly take narrow-band raw waveforms as input. This allows us to accept as\ninput audio recorded from any source and to avoid the overhead and information\nloss of feature extraction. It outperforms a similar CNN using spectrograms as\ninput by 12.8% for emotion and 6.3% for personality, based on F-scores.\nAnalysis of the network parameters and layers activation shows that the network\nlearns and extracts significant features in the first layer, in particular\npitch, energy and contour variations. Subsequent convolutional layers instead\ncapture language-specific representations through the analysis of\nsupra-segmental features. Our model represents an important step for the\ndevelopment of a fully universal affect recognizer, able to recognize\nadditional descriptors, such as stress, and for the future implementation into\naffective interactive systems.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2019 09:11:03 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Bertero", "Dario", ""], ["Kampman", "Onno", ""], ["Fung", "Pascale", ""]]}, {"id": "1901.06543", "submitter": "Radu Tudor Ionescu", "authors": "Andrei M. Butnaru and Radu Tudor Ionescu", "title": "MOROCO: The Moldavian and Romanian Dialectal Corpus", "comments": "Accepted at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we introduce the MOldavian and ROmanian Dialectal COrpus\n(MOROCO), which is freely available for download at\nhttps://github.com/butnaruandrei/MOROCO. The corpus contains 33564 samples of\ntext (with over 10 million tokens) collected from the news domain. The samples\nbelong to one of the following six topics: culture, finance, politics, science,\nsports and tech. The data set is divided into 21719 samples for training, 5921\nsamples for validation and another 5924 samples for testing. For each sample,\nwe provide corresponding dialectal and category labels. This allows us to\nperform empirical studies on several classification tasks such as (i) binary\ndiscrimination of Moldavian versus Romanian text samples, (ii) intra-dialect\nmulti-class categorization by topic and (iii) cross-dialect multi-class\ncategorization by topic. We perform experiments using a shallow approach based\non string kernels, as well as a novel deep approach based on character-level\nconvolutional neural networks containing Squeeze-and-Excitation blocks. We also\npresent and analyze the most discriminative features of our best performing\nmodel, before and after named entity removal.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2019 15:40:08 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 22:59:20 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Butnaru", "Andrei M.", ""], ["Ionescu", "Radu Tudor", ""]]}, {"id": "1901.06595", "submitter": "Hexiang Hu", "authors": "Hexiang Hu, Ishan Misra, Laurens van der Maaten", "title": "Evaluating Text-to-Image Matching using Binary Image Selection (BISON)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Providing systems the ability to relate linguistic and visual content is one\nof the hallmarks of computer vision. Tasks such as text-based image retrieval\nand image captioning were designed to test this ability but come with\nevaluation measures that have a high variance or are difficult to interpret. We\nstudy an alternative task for systems that match text and images: given a text\nquery, the system is asked to select the image that best matches the query from\na pair of semantically similar images. The system's accuracy on this Binary\nImage SelectiON (BISON) task is interpretable, eliminates the reliability\nproblems of retrieval evaluations, and focuses on the system's ability to\nunderstand fine-grained visual structure. We gather a BISON dataset that\ncomplements the COCO dataset and use it to evaluate modern text-based image\nretrieval and image captioning systems. Our results provide novel insights into\nthe performance of these systems. The COCO-BISON dataset and corresponding\nevaluation code are publicly available from \\url{http://hexianghu.com/bison/}.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2019 22:12:01 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 16:34:48 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Hu", "Hexiang", ""], ["Misra", "Ishan", ""], ["van der Maaten", "Laurens", ""]]}, {"id": "1901.06610", "submitter": "Luis Fred", "authors": "Jader Abreu, Luis Fred, David Mac\\^edo, Cleber Zanchettin", "title": "Hierarchical Attentional Hybrid Neural Networks for Document\n  Classification", "comments": "Paper accepted at International Conference on Artificial Neural\n  Networks - ICANN 2019", "journal-ref": "2019 International Conference on Artificial Neural Networks\n  (ICANN)", "doi": "10.1007/978-3-030-30493-5_39", "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Document classification is a challenging task with important applications.\nThe deep learning approaches to the problem have gained much attention\nrecently. Despite the progress, the proposed models do not incorporate the\nknowledge of the document structure in the architecture efficiently and not\ntake into account the contexting importance of words and sentences. In this\npaper, we propose a new approach based on a combination of convolutional neural\nnetworks, gated recurrent units, and attention mechanisms for document\nclassification tasks. The main contribution of this work is the use of\nconvolution layers to extract more meaningful, generalizable and abstract\nfeatures by the hierarchical representation. The proposed method in this paper\nimproves the results of the current attention-based approaches for document\nclassification.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2019 01:48:43 GMT"}, {"version": "v2", "created": "Fri, 28 Jun 2019 17:49:18 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Abreu", "Jader", ""], ["Fred", "Luis", ""], ["Mac\u00eado", "David", ""], ["Zanchettin", "Cleber", ""]]}, {"id": "1901.06613", "submitter": "Tiancheng Zhao", "authors": "Maxine Eskenazi, Shikib Mehri, Evgeniia Razumovskaia and Tiancheng\n  Zhao", "title": "Beyond Turing: Intelligent Agents Centered on the User", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most research on intelligent agents centers on the agent and not on the user.\nWe look at the origins of agent-centric research for slot-filling, gaming and\nchatbot agents. We then argue that it is important to concentrate more on the\nuser. After reviewing relevant literature, some approaches for creating and\nassessing user-centric systems are proposed.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2019 02:25:23 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2019 12:28:57 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Eskenazi", "Maxine", ""], ["Mehri", "Shikib", ""], ["Razumovskaia", "Evgeniia", ""], ["Zhao", "Tiancheng", ""]]}, {"id": "1901.06796", "submitter": "Wei Emma Zhang", "authors": "Wei Emma Zhang, Quan Z. Sheng, Ahoud Alhazmi, and Chenliang Li", "title": "Adversarial Attacks on Deep Learning Models in Natural Language\n  Processing: A Survey", "comments": "40", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of high computational devices, deep neural networks\n(DNNs), in recent years, have gained significant popularity in many Artificial\nIntelligence (AI) applications. However, previous efforts have shown that DNNs\nwere vulnerable to strategically modified samples, named adversarial examples.\nThese samples are generated with some imperceptible perturbations but can fool\nthe DNNs to give false predictions. Inspired by the popularity of generating\nadversarial examples for image DNNs, research efforts on attacking DNNs for\ntextual applications emerges in recent years. However, existing perturbation\nmethods for images cannotbe directly applied to texts as text data is discrete.\nIn this article, we review research works that address this difference and\ngeneratetextual adversarial examples on DNNs. We collect, select, summarize,\ndiscuss and analyze these works in a comprehensive way andcover all the related\ninformation to make the article self-contained. Finally, drawing on the\nreviewed literature, we provide further discussions and suggestions on this\ntopic.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 05:55:42 GMT"}, {"version": "v2", "created": "Sun, 27 Jan 2019 02:02:58 GMT"}, {"version": "v3", "created": "Thu, 11 Apr 2019 00:04:22 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Zhang", "Wei Emma", ""], ["Sheng", "Quan Z.", ""], ["Alhazmi", "Ahoud", ""], ["Li", "Chenliang", ""]]}, {"id": "1901.07002", "submitter": "James O' Neill", "authors": "James O' Neill and Danushka Bollegala", "title": "Error-Correcting Neural Sequence Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel neural sequence prediction method based on\n\\textit{error-correcting output codes} that avoids exact softmax normalization\nand allows for a tradeoff between speed and performance. Instead of minimizing\nmeasures between the predicted probability distribution and true distribution,\nwe use error-correcting codes to represent both predictions and outputs.\nSecondly, we propose multiple ways to improve accuracy and convergence rates by\nmaximizing the separability between codes that correspond to classes\nproportional to word embedding similarities. Lastly, we introduce our main\ncontribution called \\textit{Latent Variable Mixture Sampling}, a technique that\nis used to mitigate exposure bias, which can be integrated into training latent\nvariable-based neural sequence predictors such as ECOC. This involves mixing\nthe latent codes of past predictions and past targets in one of two ways: (1)\naccording to a predefined sampling schedule or (2) a differentiable sampling\nprocedure whereby the mixing probability is learned throughout training by\nreplacing the greedy argmax operation with a smooth approximation. ECOC-NSP\nleads to consistent improvements on language modelling datasets and the\nproposed Latent Variable mixture sampling methods are found to perform well for\ntext generation tasks such as image captioning.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 17:17:06 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 21:39:49 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Neill", "James O'", ""], ["Bollegala", "Danushka", ""]]}, {"id": "1901.07003", "submitter": "Junlang Zhan", "authors": "Junlang Zhan and Hai Zhao", "title": "Chemical Names Standardization using Neural Sequence to Sequence Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chemical information extraction is to convert chemical knowledge in text into\ntrue chemical database, which is a text processing task heavily relying on\nchemical compound name identification and standardization. Once a systematic\nname for a chemical compound is given, it will naturally and much simply\nconvert the name into the eventually required molecular formula. However, for\nmany chemical substances, they have been shown in many other names besides\ntheir systematic names which poses a great challenge for this task. In this\npaper, we propose a framework to do the auto standardization from the\nnon-systematic names to the corresponding systematic names by using the\nspelling error correction, byte pair encoding tokenization and neural sequence\nto sequence model. Our framework is trained end to end and is fully\ndata-driven. Our standardization accuracy on the test dataset achieves 54.04%\nwhich has a great improvement compared to previous state-of-the-art result.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 17:24:54 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Zhan", "Junlang", ""], ["Zhao", "Hai", ""]]}, {"id": "1901.07005", "submitter": "Canwen Xu", "authors": "Canwen Xu, Jing Li, Xiangyang Luo, Jiaxin Pei, Chenliang Li and\n  Donghong Ji", "title": "DLocRL: A Deep Learning Pipeline for Fine-Grained Location Recognition\n  and Linking in Tweets", "comments": "7 pages, 4 figures, accepted by The Web Conf (WWW) 2019; final\n  version", "journal-ref": null, "doi": "10.1145/3308558.3313491", "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, with the prevalence of social media and smart devices,\npeople causally reveal their locations such as shops, hotels, and restaurants\nin their tweets. Recognizing and linking such fine-grained location mentions to\nwell-defined location profiles are beneficial for retrieval and recommendation\nsystems. In this paper, we propose DLocRL, a new deep learning pipeline for\nfine-grained location recognition and linking in tweets, and verify its\neffectiveness on a real-world Twitter dataset.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 17:36:19 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 15:48:52 GMT"}, {"version": "v3", "created": "Sat, 2 Mar 2019 14:20:55 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Xu", "Canwen", ""], ["Li", "Jing", ""], ["Luo", "Xiangyang", ""], ["Pei", "Jiaxin", ""], ["Li", "Chenliang", ""], ["Ji", "Donghong", ""]]}, {"id": "1901.07067", "submitter": "Solomia Fedushko", "authors": "S. S. Fedushko", "title": "Development of verification system of socio-demographic data of virtual\n  community member", "comments": "in Ukrainian", "journal-ref": "Radio Electronics, Computer Science, Control. 2016", "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The important task of developing verification system of data of virtual\ncommunity member on the basis of computer-linguistic analysis of the content of\na large sample of Ukrainian virtual communities is solved. The subject of\nresearch is methods and tools for verification of web-members socio-demographic\ncharacteristics based on computer-linguistic analysis of their communicative\ninteraction results. The aim of paper is to verifying web-user personal data on\nthe basis of computer-linguistic analysis of web-members information tracks.\nThe structure of verification software for web-user profile is designed for a\npractical implementation of assigned tasks. The method of personal data\nverification of web-members by analyzing information track of virtual community\nmember is conducted. For the first time the method for checking the\nauthenticity of web members personal data, which helped to design of\nverification tool for socio-demographic characteristics of web-member is\ndeveloped. The verification system of data of web-members, which forms the\nverified socio-demographic profiles of web-members, is developed as a result of\nconducted experiments. Also the user interface of the developed verification\nsystem web-members data is presented. Effectiveness and efficiency of use of\nthe developed methods and means for solving tasks in web-communities\nadministration is proved by their approbation. The number of false results of\nverification system is 18%.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 20:21:05 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Fedushko", "S. S.", ""]]}, {"id": "1901.07129", "submitter": "Xiang Kong", "authors": "Xiang Kong, Bohan Li, Graham Neubig, Eduard Hovy, Yiming Yang", "title": "An Adversarial Approach to High-Quality, Sentiment-Controlled Neural\n  Dialogue Generation", "comments": "DEEP-DIAL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a method for neural dialogue response generation\nthat allows not only generating semantically reasonable responses according to\nthe dialogue history, but also explicitly controlling the sentiment of the\nresponse via sentiment labels. Our proposed model is based on the paradigm of\nconditional adversarial learning; the training of a sentiment-controlled\ndialogue generator is assisted by an adversarial discriminator which assesses\nthe fluency and feasibility of the response generating from the dialogue\nhistory and a given sentiment label. Because of the flexibility of our\nframework, the generator could be a standard sequence-to-sequence (SEQ2SEQ)\nmodel or a more complicated one such as a conditional variational\nautoencoder-based SEQ2SEQ model. Experimental results using automatic and human\nevaluation both demonstrate that our proposed framework is able to generate\nboth semantically reasonable and sentiment-controlled dialogue responses.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 00:29:27 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Kong", "Xiang", ""], ["Li", "Bohan", ""], ["Neubig", "Graham", ""], ["Hovy", "Eduard", ""], ["Yang", "Yiming", ""]]}, {"id": "1901.07132", "submitter": "Danilo Vasconcellos  Vargas", "authors": "Di Li, Danilo Vasconcellos Vargas, Sakurai Kouichi", "title": "Universal Rules for Fooling Deep Neural Networks based Text\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep learning based natural language processing techniques are\nbeing extensively used to deal with spam mail, censorship evaluation in social\nnetworks, among others. However, there is only a couple of works evaluating the\nvulnerabilities of such deep neural networks. Here, we go beyond attacks to\ninvestigate, for the first time, universal rules, i.e., rules that are sample\nagnostic and therefore could turn any text sample in an adversarial one. In\nfact, the universal rules do not use any information from the method itself (no\ninformation from the method, gradient information or training dataset\ninformation is used), making them black-box universal attacks. In other words,\nthe universal rules are sample and method agnostic. By proposing a\ncoevolutionary optimization algorithm we show that it is possible to create\nuniversal rules that can automatically craft imperceptible adversarial samples\n(only less than five perturbations which are close to misspelling are inserted\nin the text sample). A comparison with a random search algorithm further\njustifies the strength of the method. Thus, universal rules for fooling\nnetworks are here shown to exist. Hopefully, the results from this work will\nimpact the development of yet more sample and model agnostic attacks as well as\ntheir defenses, culminating in perhaps a new age for artificial intelligence.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 00:54:30 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2019 05:55:49 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Li", "Di", ""], ["Vargas", "Danilo Vasconcellos", ""], ["Kouichi", "Sakurai", ""]]}, {"id": "1901.07291", "submitter": "Alexis Conneau", "authors": "Guillaume Lample and Alexis Conneau", "title": "Cross-lingual Language Model Pretraining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have demonstrated the efficiency of generative pretraining for\nEnglish natural language understanding. In this work, we extend this approach\nto multiple languages and show the effectiveness of cross-lingual pretraining.\nWe propose two methods to learn cross-lingual language models (XLMs): one\nunsupervised that only relies on monolingual data, and one supervised that\nleverages parallel data with a new cross-lingual language model objective. We\nobtain state-of-the-art results on cross-lingual classification, unsupervised\nand supervised machine translation. On XNLI, our approach pushes the state of\nthe art by an absolute gain of 4.9% accuracy. On unsupervised machine\ntranslation, we obtain 34.3 BLEU on WMT'16 German-English, improving the\nprevious state of the art by more than 9 BLEU. On supervised machine\ntranslation, we obtain a new state of the art of 38.5 BLEU on WMT'16\nRomanian-English, outperforming the previous best approach by more than 4 BLEU.\nOur code and pretrained models will be made publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 13:22:34 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Lample", "Guillaume", ""], ["Conneau", "Alexis", ""]]}, {"id": "1901.07426", "submitter": "Krzysztof Wo{\\l}k", "authors": "Krzysztof Wo{\\l}k, Emilia Zawadzka-Gosk, Wojciech Czarnowski", "title": "Deep learning and sub-word-unit approach in written art generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic poetry generation is novel and interesting application of natural\nlanguage processing research. It became more popular during the last few years\ndue to the rapid development of technology and neural computing power. This\nline of research can be applied to the study of linguistics and literature, for\nsocial science experiments, or simply for entertainment. The most effective\nknown method of artificial poem generation uses recurrent neural networks\n(RNN). We also used RNNs to generate poems in the style of Adam Mickiewicz. Our\nnetwork was trained on the Sir Thaddeus poem. For data pre-processing, we used\na specialized stemming tool, which is one of the major innovations and\ncontributions of this work. Our experiment was conducted on the source text,\ndivided into sub-word units (at a level of resolution close to syllables). This\napproach is novel and is not often employed in the published literature. The\nsubwords units seem to be a natural choice for analysis of the Polish language,\nas the language is morphologically rich due to cases, gender forms and a large\nvocabulary. Moreover, Sir Thaddeus contains rhymes, so the analysis of\nsyllables can be meaningful. We verified our model with different settings for\nthe temperature parameter, which controls the randomness of the generated text.\nWe also compared our results with similar models trained on the same text but\ndivided into characters (which is the most common approach alongside the use of\nfull word units). The differences were tremendous. Our solution generated much\nbetter poems that were able to follow the metre and vocabulary of the source\ndata text.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 15:42:51 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Wo\u0142k", "Krzysztof", ""], ["Zawadzka-Gosk", "Emilia", ""], ["Czarnowski", "Wojciech", ""]]}, {"id": "1901.07475", "submitter": "Alexandre Kabbach", "authors": "Alexandre Kabbach", "title": "Debugging Frame Semantic Role Labeling", "comments": "Chapter 5 of this memoir has been augmented and published at\n  COLING2018 under the reference: Butterfly Effects in Frame Semantic Parsing:\n  impact of data processing on model ranking", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a quantitative and qualitative analysis of the performances of\nstatistical models for frame semantic structure extraction. We report on a\nreplication study on FrameNet 1.7 data and show that preprocessing toolkits\nplay a major role in argument identification performances, observing gains\nsimilar in their order of magnitude to those reported by recent models for\nframe semantic parsing. We report on the robustness of a recent statistical\nclassifier for frame semantic parsing to lexical configurations of\npredicate-argument structures, relying on an artificially augmented dataset\ngenerated using a rule-based algorithm combining valence pattern matching and\nlexical substitution. We prove that syntactic pre-processing plays a major role\nin the performances of statistical classifiers to argument identification, and\ndiscuss the core reasons of syntactic mismatch between dependency parsers\noutput and FrameNet syntactic formalism. Finally, we suggest new leads for\nimproving statistical models for frame semantic parsing, including joint\nsyntax-semantic parsing relying on FrameNet syntactic formalism, latent classes\ninference via split-and-merge algorithms and neural network architectures\nrelying on rich input representations of words.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 17:17:02 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Kabbach", "Alexandre", ""]]}, {"id": "1901.07651", "submitter": "Hwiyeol Jo", "authors": "Hwiyeol Jo, Ceyda Cinarel", "title": "Delta-training: Simple Semi-Supervised Text Classification using\n  Pretrained Word Embeddings", "comments": "Accepted at EMNLP-IJCNLP2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel and simple method for semi-supervised text classification.\nThe method stems from the hypothesis that a classifier with pretrained word\nembeddings always outperforms the same classifier with randomly initialized\nword embeddings, as empirically observed in NLP tasks. Our method first builds\ntwo sets of classifiers as a form of model ensemble, and then initializes their\nword embeddings differently: one using random, the other using pretrained word\nembeddings. We focus on different predictions between the two classifiers on\nunlabeled data while following the self-training framework. We also use\nearly-stopping in meta-epoch to improve the performance of our method. Our\nmethod, Delta-training, outperforms the self-training and the co-training\nframework in 4 different text classification datasets, showing robustness\nagainst error accumulation.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 23:55:49 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 03:59:39 GMT"}, {"version": "v3", "created": "Sat, 28 Sep 2019 06:55:37 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Jo", "Hwiyeol", ""], ["Cinarel", "Ceyda", ""]]}, {"id": "1901.07656", "submitter": "Sunipa Dev", "authors": "Sunipa Dev, Jeff Phillips", "title": "Attenuating Bias in Word Vectors", "comments": "To appear in AIStats 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Word vector representations are well developed tools for various NLP and\nMachine Learning tasks and are known to retain significant semantic and\nsyntactic structure of languages. But they are prone to carrying and amplifying\nbias which can perpetrate discrimination in various applications. In this work,\nwe explore new simple ways to detect the most stereotypically gendered words in\nan embedding and remove the bias from them. We verify how names are masked\ncarriers of gender bias and then use that as a tool to attenuate bias in\nembeddings. Further, we extend this property of names to show how names can be\nused to detect other types of bias in the embeddings such as bias based on\nrace, ethnicity, and age.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 00:25:48 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Dev", "Sunipa", ""], ["Phillips", "Jeff", ""]]}, {"id": "1901.07688", "submitter": "Hongyu Gong", "authors": "Hongyu Gong, Yuchen Li, Suma Bhat, Pramod Viswanath", "title": "Context-Sensitive Malicious Spelling Error Correction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Misspelled words of the malicious kind work by changing specific keywords and\nare intended to thwart existing automated applications for cyber-environment\ncontrol such as harassing content detection on the Internet and email spam\ndetection. In this paper, we focus on malicious spelling correction, which\nrequires an approach that relies on the context and the surface forms of\ntargeted keywords. In the context of two applications--profanity detection and\nemail spam detection--we show that malicious misspellings seriously degrade\ntheir performance. We then propose a context-sensitive approach for malicious\nspelling correction using word embeddings and demonstrate its superior\nperformance compared to state-of-the-art spell checkers.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 02:11:11 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Gong", "Hongyu", ""], ["Li", "Yuchen", ""], ["Bhat", "Suma", ""], ["Viswanath", "Pramod", ""]]}, {"id": "1901.07696", "submitter": "Shen Gao", "authors": "Shen Gao, Zhaochun Ren, Yihong Eric Zhao, Dongyan Zhao, Dawei Yin, Rui\n  Yan", "title": "Product-Aware Answer Generation in E-Commerce Question-Answering", "comments": "Accepted by WSDM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In e-commerce portals, generating answers for product-related questions has\nbecome a crucial task. In this paper, we propose the task of product-aware\nanswer generation, which tends to generate an accurate and complete answer from\nlarge-scale unlabeled e-commerce reviews and product attributes. Unlike\nexisting question-answering problems, answer generation in e-commerce confronts\nthree main challenges: (1) Reviews are informal and noisy; (2) joint modeling\nof reviews and key-value product attributes is challenging; (3) traditional\nmethods easily generate meaningless answers. To tackle above challenges, we\npropose an adversarial learning based model, named PAAG, which is composed of\nthree components: a question-aware review representation module, a key-value\nmemory network encoding attributes, and a recurrent neural network as a\nsequence generator. Specifically, we employ a convolutional discriminator to\ndistinguish whether our generated answer matches the facts. To extract the\nsalience part of reviews, an attention-based review reader is proposed to\ncapture the most relevant words given the question. Conducted on a large-scale\nreal-world e-commerce dataset, our extensive experiments verify the\neffectiveness of each module in our proposed model. Moreover, our experiments\nshow that our model achieves the state-of-the-art performance in terms of both\nautomatic metrics and human evaluations.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 02:33:52 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 04:31:56 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Gao", "Shen", ""], ["Ren", "Zhaochun", ""], ["Zhao", "Yihong Eric", ""], ["Zhao", "Dongyan", ""], ["Yin", "Dawei", ""], ["Yan", "Rui", ""]]}, {"id": "1901.07744", "submitter": "Yang Xu", "authors": "Jiawei Liu, Yang Xu, Yaguang Zhu", "title": "Automated Essay Scoring based on Two-Stage Learning", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current state-of-art feature-engineered and end-to-end Automated Essay Score\n(AES) methods are proven to be unable to detect adversarial samples, e.g. the\nessays composed of permuted sentences and the prompt-irrelevant essays.\nFocusing on the problem, we develop a Two-Stage Learning Framework (TSLF) which\nintegrates the advantages of both feature-engineered and end-to-end AES models.\nIn experiments, we compare TSLF against a number of strong baselines, and the\nresults demonstrate the effectiveness and robustness of our models. TSLF\nsurpasses all the baselines on five-eighths of prompts and achieves new\nstate-of-the-art average performance when without negative samples. After\nadding some adversarial essays to the original datasets, TSLF outperforms the\nfeature-engineered and end-to-end baselines to a great extent, and shows great\nrobustness.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 06:37:12 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 05:49:28 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Liu", "Jiawei", ""], ["Xu", "Yang", ""], ["Zhu", "Yaguang", ""]]}, {"id": "1901.07786", "submitter": "Valentin Malykh", "authors": "Daniil Gavrilov and Pavel Kalaidin and Valentin Malykh", "title": "Self-Attentive Model for Headline Generation", "comments": "accepted for ECIR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Headline generation is a special type of text summarization task. While the\namount of available training data for this task is almost unlimited, it still\nremains challenging, as learning to generate headlines for news articles\nimplies that the model has strong reasoning about natural language. To overcome\nthis issue, we applied recent Universal Transformer architecture paired with\nbyte-pair encoding technique and achieved new state-of-the-art results on the\nNew York Times Annotated corpus with ROUGE-L F1-score 24.84 and ROUGE-2\nF1-score 13.48. We also present the new RIA corpus and reach ROUGE-L F1-score\n36.81 and ROUGE-2 F1-score 22.15 on it.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 09:39:45 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Gavrilov", "Daniil", ""], ["Kalaidin", "Pavel", ""], ["Malykh", "Valentin", ""]]}, {"id": "1901.07829", "submitter": "Valentin Malykh", "authors": "Sergey I. Nikolenko, Elena Tutubalina, Valentin Malykh, Ilya Shenbin,\n  Anton Alekseev", "title": "AspeRa: Aspect-based Rating Prediction Model", "comments": "accepted to ECIR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel end-to-end Aspect-based Rating Prediction model (AspeRa)\nthat estimates user rating based on review texts for the items and at the same\ntime discovers coherent aspects of reviews that can be used to explain\npredictions or profile users. The AspeRa model uses max-margin losses for joint\nitem and user embedding learning and a dual-headed architecture; it\nsignificantly outperforms recently proposed state-of-the-art models such as\nDeepCoNN, HFT, NARRE, and TransRev on two real world data sets of user reviews.\nWith qualitative examination of the aspects and quantitative evaluation of\nrating prediction models based on these aspects, we show how aspect embeddings\ncan be used in a recommender system.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 11:38:15 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Nikolenko", "Sergey I.", ""], ["Tutubalina", "Elena", ""], ["Malykh", "Valentin", ""], ["Shenbin", "Ilya", ""], ["Alekseev", "Anton", ""]]}, {"id": "1901.07867", "submitter": "Mohd Zeeshan Ansari", "authors": "Mohd Zeeshan Ansari and Lubna Khan", "title": "Context based Analysis of Lexical Semantics for Hindi Language", "comments": "Accepted in NGCT-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A word having multiple senses in a text introduces the lexical semantic task\nto find out which particular sense is appropriate for the given context. One\nsuch task is Word sense disambiguation which refers to the identification of\nthe most appropriate meaning of the polysemous word in a given context using\ncomputational algorithms. The language processing research in Hindi, the\nofficial language of India, and other Indian languages is restricted by\nunavailability of the standard corpus. For Hindi word sense disambiguation\nalso, the large corpus is not available. In this work, we prepared the text\ncontaining new senses of certain words leading to the enrichment of the\nsense-tagged Hindi corpus of sixty polysemous words. Furthermore, we analyzed\ntwo novel lexical associations for Hindi word sense disambiguation based on the\ncontextual features of the polysemous word. The evaluation of these methods is\ncarried out over learning algorithms and favorable results are achieved.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 13:23:10 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Ansari", "Mohd Zeeshan", ""], ["Khan", "Lubna", ""]]}, {"id": "1901.07878", "submitter": "Christian Otto", "authors": "Christian Otto and Sebastian Holzki and Ralph Ewerth", "title": "\"Is this an example image?\" -- Predicting the Relative Abstractness\n  Level of Image and Text", "comments": "14 pages, 6 figures, accepted at ECIR2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Successful multimodal search and retrieval requires the automatic\nunderstanding of semantic cross-modal relations, which, however, is still an\nopen research problem. Previous work has suggested the metrics cross-modal\nmutual information and semantic correlation to model and predict cross-modal\nsemantic relations of image and text. In this paper, we present an approach to\npredict the (cross-modal) relative abstractness level of a given image-text\npair, that is whether the image is an abstraction of the text or vice versa.\nFor this purpose, we introduce a new metric that captures this specific\nrelationship between image and text at the Abstractness Level (ABS). We present\na deep learning approach to predict this metric, which relies on an autoencoder\narchitecture that allows us to significantly reduce the required amount of\nlabeled training data. A comprehensive set of publicly available scientific\ndocuments has been gathered. Experimental results on a challenging test set\ndemonstrate the feasibility of the approach.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 13:42:02 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Otto", "Christian", ""], ["Holzki", "Sebastian", ""], ["Ewerth", "Ralph", ""]]}, {"id": "1901.07880", "submitter": "Soujanya Poria", "authors": "Haiyun Peng, Yukun Ma, Soujanya Poria, Yang Li, Erik Cambria", "title": "Phonetic-enriched Text Representation for Chinese Sentiment Analysis\n  with Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The Chinese pronunciation system offers two characteristics that distinguish\nit from other languages: deep phonemic orthography and intonation variations.\nWe are the first to argue that these two important properties can play a major\nrole in Chinese sentiment analysis. Particularly, we propose two effective\nfeatures to encode phonetic information. Next, we develop a Disambiguate\nIntonation for Sentiment Analysis (DISA) network using a reinforcement network.\nIt functions as disambiguating intonations for each Chinese character (pinyin).\nThus, a precise phonetic representation of Chinese is learned. Furthermore, we\nalso fuse phonetic features with textual and visual features in order to mimic\nthe way humans read and understand Chinese text. Experimental results on five\ndifferent Chinese sentiment analysis datasets show that the inclusion of\nphonetic features significantly and consistently improves the performance of\ntextual and visual representations and outshines the state-of-the-art Chinese\ncharacter level representations.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 13:53:24 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Peng", "Haiyun", ""], ["Ma", "Yukun", ""], ["Poria", "Soujanya", ""], ["Li", "Yang", ""], ["Cambria", "Erik", ""]]}, {"id": "1901.07910", "submitter": "Oscar J. Romero", "authors": "Oscar J. Romero, Ankit Dangi, Sushma A. Akoju", "title": "NLSC: Unrestricted Natural Language-based Service Composition through\n  Sentence Embeddings", "comments": "This paper will appear on SCC'19 (IEEE International Conference on\n  Services Computing) on July 13", "journal-ref": "2019 IEEE International Conference on Services Computing (SCC)", "doi": "10.1109/SCC.2019.00031", "report-no": null, "categories": "cs.SE cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current approaches for service composition (assemblies of atomic services)\nrequire developers to use: (a) domain-specific semantics to formalize services\nthat restrict the vocabulary for their descriptions, and (b) translation\nmechanisms for service retrieval to convert unstructured user requests to\nstrongly-typed semantic representations. In our work, we argue that effort to\ndeveloping service descriptions, request translations, and matching mechanisms\ncould be reduced using unrestricted natural language; allowing both: (1)\nend-users to intuitively express their needs using natural language, and (2)\nservice developers to develop services without relying on syntactic/semantic\ndescription languages. Although there are some natural language-based service\ncomposition approaches, they restrict service retrieval to syntactic/semantic\nmatching. With recent developments in Machine learning and Natural Language\nProcessing, we motivate the use of Sentence Embeddings by leveraging richer\nsemantic representations of sentences for service description, matching and\nretrieval. Experimental results show that service composition development\neffort may be reduced by more than 44\\% while keeping a high precision/recall\nwhen matching high-level user requests with low-level service method\ninvocations.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 14:18:26 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 20:01:02 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 13:03:00 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Romero", "Oscar J.", ""], ["Dangi", "Ankit", ""], ["Akoju", "Sushma A.", ""]]}, {"id": "1901.07931", "submitter": "Ond\\v{r}ej Du\\v{s}ek", "authors": "Ond\\v{r}ej Du\\v{s}ek, Jekaterina Novikova and Verena Rieser", "title": "Evaluating the State-of-the-Art of End-to-End Natural Language\n  Generation: The E2E NLG Challenge", "comments": "Computer Speech and Language, final accepted manuscript (in press)", "journal-ref": null, "doi": "10.1016/j.csl.2019.06.009", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a comprehensive analysis of the first shared task on\nEnd-to-End Natural Language Generation (NLG) and identifies avenues for future\nresearch based on the results. This shared task aimed to assess whether recent\nend-to-end NLG systems can generate more complex output by learning from\ndatasets containing higher lexical richness, syntactic complexity and diverse\ndiscourse phenomena. Introducing novel automatic and human metrics, we compare\n62 systems submitted by 17 institutions, covering a wide range of approaches,\nincluding machine learning architectures -- with the majority implementing\nsequence-to-sequence models (seq2seq) -- as well as systems based on\ngrammatical rules and templates. Seq2seq-based systems have demonstrated a\ngreat potential for NLG in the challenge. We find that seq2seq systems\ngenerally score high in terms of word-overlap metrics and human evaluations of\nnaturalness -- with the winning SLUG system (Juraska et al., 2018) being\nseq2seq-based. However, vanilla seq2seq models often fail to correctly express\na given meaning representation if they lack a strong semantic control mechanism\napplied during decoding. Moreover, seq2seq models can be outperformed by\nhand-engineered systems in terms of overall quality, as well as complexity,\nlength and diversity of outputs. This research has influenced, inspired and\nmotivated a number of recent studies outwith the original competition, which we\nalso summarise as part of this paper.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 14:54:53 GMT"}, {"version": "v2", "created": "Sat, 27 Apr 2019 10:40:51 GMT"}, {"version": "v3", "created": "Wed, 24 Jul 2019 10:12:36 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Du\u0161ek", "Ond\u0159ej", ""], ["Novikova", "Jekaterina", ""], ["Rieser", "Verena", ""]]}, {"id": "1901.08014", "submitter": "Soujanya Poria", "authors": "Navonil Majumder, Soujanya Poria, Haiyun Peng, Niyati Chhaya, Erik\n  Cambria, and Alexander Gelbukh", "title": "Sentiment and Sarcasm Classification with Multitask Learning", "comments": null, "journal-ref": "IEEE Intelligent Systems 34(3) (2019)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Sentiment classification and sarcasm detection are both important natural\nlanguage processing (NLP) tasks. Sentiment is always coupled with sarcasm where\nintensive emotion is expressed. Nevertheless, most literature considers them as\ntwo separate tasks. We argue that knowledge in sarcasm detection can also be\nbeneficial to sentiment classification and vice versa. We show that these two\ntasks are correlated, and present a multi-task learning-based framework using a\ndeep neural network that models this correlation to improve the performance of\nboth tasks in a multi-task learning setting. Our method outperforms the state\nof the art by 3-4% in the benchmark dataset.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 17:18:50 GMT"}, {"version": "v2", "created": "Sat, 9 Mar 2019 01:02:35 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Majumder", "Navonil", ""], ["Poria", "Soujanya", ""], ["Peng", "Haiyun", ""], ["Chhaya", "Niyati", ""], ["Cambria", "Erik", ""], ["Gelbukh", "Alexander", ""]]}, {"id": "1901.08079", "submitter": "Asma Ben Abacha", "authors": "Asma Ben Abacha and Dina Demner-Fushman", "title": "A Question-Entailment Approach to Question Answering", "comments": null, "journal-ref": "BMC Bioinformatics 20, 511 (2019)", "doi": "10.1186/s12859-019-3119-4", "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the challenges in large-scale information retrieval (IR) is to develop\nfine-grained and domain-specific methods to answer natural language questions.\nDespite the availability of numerous sources and datasets for answer retrieval,\nQuestion Answering (QA) remains a challenging problem due to the difficulty of\nthe question understanding and answer extraction tasks. One of the promising\ntracks investigated in QA is to map new questions to formerly answered\nquestions that are `similar'. In this paper, we propose a novel QA approach\nbased on Recognizing Question Entailment (RQE) and we describe the QA system\nand resources that we built and evaluated on real medical questions. First, we\ncompare machine learning and deep learning methods for RQE using different\nkinds of datasets, including textual inference, question similarity and\nentailment in both the open and clinical domains. Second, we combine IR models\nwith the best RQE method to select entailed questions and rank the retrieved\nanswers. To study the end-to-end QA approach, we built the MedQuAD collection\nof 47,457 question-answer pairs from trusted medical sources, that we introduce\nand share in the scope of this paper. Following the evaluation process used in\nTREC 2017 LiveQA, we find that our approach exceeds the best results of the\nmedical task with a 29.8% increase over the best official score. The evaluation\nresults also support the relevance of question entailment for QA and highlight\nthe effectiveness of combining IR and RQE for future QA efforts. Our findings\nalso show that relying on a restricted set of reliable answer sources can bring\na substantial improvement in medical QA.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 19:02:27 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Abacha", "Asma Ben", ""], ["Demner-Fushman", "Dina", ""]]}, {"id": "1901.08149", "submitter": "Thomas Wolf", "authors": "Thomas Wolf, Victor Sanh, Julien Chaumond, Clement Delangue", "title": "TransferTransfo: A Transfer Learning Approach for Neural Network Based\n  Conversational Agents", "comments": "6 pages, 2 figures, 2 tables, NeurIPS 2018 CAI Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new approach to generative data-driven dialogue systems (e.g.\nchatbots) called TransferTransfo which is a combination of a Transfer learning\nbased training scheme and a high-capacity Transformer model. Fine-tuning is\nperformed by using a multi-task objective which combines several unsupervised\nprediction tasks. The resulting fine-tuned model shows strong improvements over\nthe current state-of-the-art end-to-end conversational models like memory\naugmented seq2seq and information-retrieval models. On the privately held\nPERSONA-CHAT dataset of the Conversational Intelligence Challenge 2, this\napproach obtains a new state-of-the-art, with respective perplexity, Hits@1 and\nF1 metrics of 16.28 (45 % absolute improvement), 80.7 (46 % absolute\nimprovement) and 19.5 (20 % absolute improvement).\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 22:08:01 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 11:38:52 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Wolf", "Thomas", ""], ["Sanh", "Victor", ""], ["Chaumond", "Julien", ""], ["Delangue", "Clement", ""]]}, {"id": "1901.08158", "submitter": "Joohong Lee", "authors": "Joohong Lee, Dongyoung Son and Yong Suk Choi", "title": "A Tool for Spatio-Temporal Analysis of Social Anxiety with Twitter Data", "comments": "In proceedings of the 34th ACM/SIGAPP Symposium On Applied Computing\n  (SAC 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a tool for analyzing spatio-temporal distribution\nof social anxiety. Twitter, one of the most popular social network services,\nhas been chosen as data source for analysis of social anxiety. Tweets (posted\non the Twitter) contain various emotions and thus these individual emotions\nreflect social atmosphere and public opinion, which are often dependent on\nspatial and temporal factors. The reason why we choose anxiety among various\nemotions is that anxiety is very important emotion that is useful for observing\nand understanding social events of communities. We develop a machine learning\nbased tool to analyze the changes of social atmosphere spatially and\ntemporally. Our tool classifies whether each Tweet contains anxious content or\nnot, and also estimates degree of Tweet anxiety. Furthermore, it also\nvisualizes spatio-temporal distribution of anxiety as a form of web\napplication, which is incorporated with physical map, word cloud, search engine\nand chart viewer. Our tool is applied to a big tweet data in South Korea to\nillustrate its usefulness for exploring social atmosphere and public opinion\nspatio-temporally.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 22:37:11 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Lee", "Joohong", ""], ["Son", "Dongyoung", ""], ["Choi", "Yong Suk", ""]]}, {"id": "1901.08163", "submitter": "Joohong Lee", "authors": "Joohong Lee, Sangwoo Seo and Yong Suk Choi", "title": "Semantic Relation Classification via Bidirectional LSTM Networks with\n  Entity-aware Attention using Latent Entity Typing", "comments": null, "journal-ref": "Symmetry 2019, 11 (6), 785", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifying semantic relations between entity pairs in sentences is an\nimportant task in Natural Language Processing (NLP). Most previous models for\nrelation classification rely on the high-level lexical and syntactic features\nobtained by NLP tools such as WordNet, dependency parser, part-of-speech (POS)\ntagger, and named entity recognizers (NER). In addition, state-of-the-art\nneural models based on attention mechanisms do not fully utilize information of\nentity that may be the most crucial features for relation classification. To\naddress these issues, we propose a novel end-to-end recurrent neural model\nwhich incorporates an entity-aware attention mechanism with a latent entity\ntyping (LET) method. Our model not only utilizes entities and their latent\ntypes as features effectively but also is more interpretable by visualizing\nattention mechanisms applied to our model and results of LET. Experimental\nresults on the SemEval-2010 Task 8, one of the most popular relation\nclassification task, demonstrate that our model outperforms existing\nstate-of-the-art models without any high-level features.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 23:19:45 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Lee", "Joohong", ""], ["Seo", "Sangwoo", ""], ["Choi", "Yong Suk", ""]]}, {"id": "1901.08241", "submitter": "Jyoti Prakash Singh", "authors": "Abhinav Kumar and Jyoti Prakash Singh", "title": "Location reference identification from tweets during emergencies: A deep\n  learning approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Twitter is recently being used during crises to communicate with officials\nand provide rescue and relief operation in real time. The geographical location\ninformation of the event, as well as users, are vitally important in such\nscenarios. The identification of geographic location is one of the challenging\ntasks as the location information fields, such as user location and place name\nof tweets are not reliable. The extraction of location information from tweet\ntext is difficult as it contains a lot of non-standard English, grammatical\nerrors, spelling mistakes, non-standard abbreviations, and so on. This research\naims to extract location words used in the tweet using a Convolutional Neural\nNetwork (CNN) based model. We achieved the exact matching score of 0.929,\nHamming loss of 0.002, and $F_1$-score of 0.96 for the tweets related to the\nearthquake. Our model was able to extract even three- to four-word long\nlocation references which is also evident from the exact matching score of over\n92\\%. The findings of this paper can help in early event localization,\nemergency situations, real-time road traffic management, localized\nadvertisement, and in various location-based services.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 05:54:13 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Kumar", "Abhinav", ""], ["Singh", "Jyoti Prakash", ""]]}, {"id": "1901.08259", "submitter": "Qian Liu", "authors": "Qian Liu, Bei Chen, Jian-Guang Lou, Ge Jin, Dongmei Zhang", "title": "FANDA: A Novel Approach to Perform Follow-up Query Analysis", "comments": "Accepted by AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on Natural Language Interfaces to Databases (NLIDB) has attracted\nconsiderable attention. NLIDB allow users to search databases using natural\nlanguage instead of SQL-like query languages. While saving the users from\nhaving to learn query languages, multi-turn interaction with NLIDB usually\ninvolves multiple queries where contextual information is vital to understand\nthe users' query intents. In this paper, we address a typical contextual\nunderstanding problem, termed as follow-up query analysis. In spite of its\nubiquity, follow-up query analysis has not been well studied due to two primary\nobstacles: the multifarious nature of follow-up query scenarios and the lack of\nhigh-quality datasets. Our work summarizes typical follow-up query scenarios\nand provides a new FollowUp dataset with $1000$ query triples on 120 tables.\nMoreover, we propose a novel approach FANDA, which takes into account the\nstructures of queries and employs a ranking model with weakly supervised\nmax-margin learning. The experimental results on FollowUp demonstrate the\nsuperiority of FANDA over multiple baselines across multiple metrics.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 07:25:16 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Liu", "Qian", ""], ["Chen", "Bei", ""], ["Lou", "Jian-Guang", ""], ["Jin", "Ge", ""], ["Zhang", "Dongmei", ""]]}, {"id": "1901.08319", "submitter": "Maurizio Naldi", "authors": "Maurizio Naldi", "title": "A review of sentiment computation methods with R packages", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Four packages in R are analyzed to carry out sentiment analysis. All packages\nallow to define custom dictionaries. Just one - Sentiment R - properly accounts\nfor the presence of negators.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 10:02:45 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Naldi", "Maurizio", ""]]}, {"id": "1901.08351", "submitter": "Yuan Xia", "authors": "Xia Yuan, Liao xiaoli, Li Shilei, Shi Qinwen, Wu Jinfa, Li Ke", "title": "Extracting PICO elements from RCT abstracts using 1-2gram analysis and\n  multitask classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The core of evidence-based medicine is to read and analyze numerous papers in\nthe medical literature on a specific clinical problem and summarize the\nauthoritative answers to that problem. Currently, to formulate a clear and\nfocused clinical problem, the popular PICO framework is usually adopted, in\nwhich each clinical problem is considered to consist of four parts:\npatient/problem (P), intervention (I), comparison (C) and outcome (O). In this\nstudy, we compared several classification models that are commonly used in\ntraditional machine learning. Next, we developed a multitask classification\nmodel based on a soft-margin SVM with a specialized feature engineering method\nthat combines 1-2gram analysis with TF-IDF analysis. Finally, we trained and\ntested several generic models on an open-source data set from BioNLP 2018. The\nresults show that the proposed multitask SVM classification model based on\n1-2gram TF-IDF features exhibits the best performance among the tested models.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 11:14:49 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Yuan", "Xia", ""], ["xiaoli", "Liao", ""], ["Shilei", "Li", ""], ["Qinwen", "Shi", ""], ["Jinfa", "Wu", ""], ["Ke", "Li", ""]]}, {"id": "1901.08407", "submitter": "Diego Krivochen", "authors": "Diego Gabriel Krivochen and Beth Phillips", "title": "A model for a Lindenmayer reconstruction algorithm", "comments": "Manuscript. Comments welcomed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an input string s and a specific Lindenmayer system (the so-called\nFibonacci grammar), we define an automaton which is capable of (i) determining\nwhether s belongs to the set of strings that the Fibonacci grammar can generate\n(in other words, if s corresponds to a generation of the grammar) and, if so,\n(ii) reconstructing the previous generation.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 13:53:17 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Krivochen", "Diego Gabriel", ""], ["Phillips", "Beth", ""]]}, {"id": "1901.08422", "submitter": "Georgios Pitsilis", "authors": "Georgios K. Pitsilis, Heri Ramampiaro, Helge Langseth", "title": "Securing Tag-based recommender systems against profile injection\n  attacks: A comparative study. (Extended Report)", "comments": "20 pages, 5 figures, 4 tables, Extended report of paper presented at\n  \"Late Breaking Results\" poster session, RecSys 2018, October 2-7, Vancouver,\n  BC, Canada", "journal-ref": null, "doi": null, "report-no": "arXiv:1808.10550; arXiv:1809.04106", "categories": "cs.IR cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work addresses the challenges related to attacks on collaborative\ntagging systems, which often comes in a form of malicious annotations or\nprofile injection attacks. In particular, we study various countermeasures\nagainst two types of such attacks for social tagging systems, the Overload\nattack and the Piggyback attack. The countermeasure schemes studied here\ninclude baseline classifiers such as, Naive Bayes filter and Support Vector\nMachine, as well as a Deep Learning approach. Our evaluation performed over\nsynthetic spam data generated from del.icio.us dataset, shows that in most\ncases, Deep Learning can outperform the classical solutions, providing\nhigh-level protection against threats.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 14:20:11 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Pitsilis", "Georgios K.", ""], ["Ramampiaro", "Heri", ""], ["Langseth", "Helge", ""]]}, {"id": "1901.08456", "submitter": "Numa Dhamani", "authors": "Paul Azunre, Craig Corcoran, Numa Dhamani, Jeffrey Gleason, Garrett\n  Honke, David Sullivan, Rebecca Ruppel, Sandeep Verma, Jonathon Morgan", "title": "Semantic Classification of Tabular Datasets via Character-Level\n  Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A character-level convolutional neural network (CNN) motivated by\napplications in \"automated machine learning\" (AutoML) is proposed to\nsemantically classify columns in tabular data. Simulated data containing a set\nof base classes is first used to learn an initial set of weights. Hand-labeled\ndata from the CKAN repository is then used in a transfer-learning paradigm to\nadapt the initial weights to a more sophisticated representation of the problem\n(e.g., including more classes). In doing so, realistic data imperfections are\nlearned and the set of classes handled can be expanded from the base set with\nreduced labeled data and computing power requirements. Results show the\neffectiveness and flexibility of this approach in three diverse domains:\nsemantic classification of tabular data, age prediction from social media\nposts, and email spam classification. In addition to providing further evidence\nof the effectiveness of transfer learning in natural language processing (NLP),\nour experiments suggest that analyzing the semantic structure of language at\nthe character level without additional metadata---i.e., network structure,\nheaders, etc.---can produce competitive accuracy for type classification, spam\nclassification, and social media age prediction. We present our open-source\ntoolkit SIMON, an acronym for Semantic Inference for the Modeling of\nONtologies, which implements this approach in a user-friendly and\nscalable/parallelizable fashion.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 15:31:11 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Azunre", "Paul", ""], ["Corcoran", "Craig", ""], ["Dhamani", "Numa", ""], ["Gleason", "Jeffrey", ""], ["Honke", "Garrett", ""], ["Sullivan", "David", ""], ["Ruppel", "Rebecca", ""], ["Verma", "Sandeep", ""], ["Morgan", "Jonathon", ""]]}, {"id": "1901.08625", "submitter": "Aditya Pathak Kumar", "authors": "Aditya Kumar Pathak, Priyankit Acharya, Dilpreet Kaur and Rakesh\n  Chandra Balabantaray", "title": "Automatic Parallel Corpus Creation for Hindi-English News Translation\n  Task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The parallel corpus for multilingual NLP tasks, deep learning applications\nlike Statistical Machine Translation Systems is very important. The parallel\ncorpus of Hindi-English language pair available for news translation task till\ndate is of very limited size as per the requirement of the systems are\nconcerned. In this work we have developed an automatic parallel corpus\ngeneration system prototype, which creates Hindi-English parallel corpus for\nnews translation task. Further to verify the quality of generated parallel\ncorpus we have experimented by taking various performance metrics and the\nresults are quite interesting.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 19:49:43 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Pathak", "Aditya Kumar", ""], ["Acharya", "Priyankit", ""], ["Kaur", "Dilpreet", ""], ["Balabantaray", "Rakesh Chandra", ""]]}, {"id": "1901.08634", "submitter": "Chris Alberti", "authors": "Chris Alberti, Kenton Lee, Michael Collins", "title": "A BERT Baseline for the Natural Questions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This technical note describes a new baseline for the Natural Questions. Our\nmodel is based on BERT and reduces the gap between the model F1 scores reported\nin the original dataset paper and the human upper bound by 30% and 50% relative\nfor the long and short answer tasks respectively. This baseline has been\nsubmitted to the official NQ leaderboard at\nai.google.com/research/NaturalQuestions. Code, preprocessed data and pretrained\nmodel are available at\nhttps://github.com/google-research/language/tree/master/language/question_answering/bert_joint.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 20:22:14 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2019 17:06:01 GMT"}, {"version": "v3", "created": "Mon, 9 Dec 2019 17:32:42 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Alberti", "Chris", ""], ["Lee", "Kenton", ""], ["Collins", "Michael", ""]]}, {"id": "1901.08706", "submitter": "Douwe Kiela", "authors": "Laura Graesser, Kyunghyun Cho, Douwe Kiela", "title": "Emergent Linguistic Phenomena in Multi-Agent Communication Games", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a computational framework in which agents equipped\nwith communication capabilities simultaneously play a series of referential\ngames, where agents are trained using deep reinforcement learning. We\ndemonstrate that the framework mirrors linguistic phenomena observed in natural\nlanguage: i) the outcome of contact between communities is a function of inter-\nand intra-group connectivity; ii) linguistic contact either converges to the\nmajority protocol, or in balanced cases leads to novel creole languages of\nlower complexity; and iii) a linguistic continuum emerges where neighboring\nlanguages are more mutually intelligible than farther removed languages. We\nconclude that intricate properties of language evolution need not depend on\ncomplex evolved linguistic capabilities, but can emerge from simple social\nexchanges between perceptually-enabled agents playing communication games.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 01:18:04 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 19:32:05 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Graesser", "Laura", ""], ["Cho", "Kyunghyun", ""], ["Kiela", "Douwe", ""]]}, {"id": "1901.08746", "submitter": "Jinhyuk Lee", "authors": "Jinhyuk Lee, Wonjin Yoon, Sungdong Kim, Donghyeon Kim, Sunkyu Kim,\n  Chan Ho So, Jaewoo Kang", "title": "BioBERT: a pre-trained biomedical language representation model for\n  biomedical text mining", "comments": "Bioinformatics", "journal-ref": null, "doi": "10.1093/bioinformatics/btz682", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biomedical text mining is becoming increasingly important as the number of\nbiomedical documents rapidly grows. With the progress in natural language\nprocessing (NLP), extracting valuable information from biomedical literature\nhas gained popularity among researchers, and deep learning has boosted the\ndevelopment of effective biomedical text mining models. However, directly\napplying the advancements in NLP to biomedical text mining often yields\nunsatisfactory results due to a word distribution shift from general domain\ncorpora to biomedical corpora. In this article, we investigate how the recently\nintroduced pre-trained language model BERT can be adapted for biomedical\ncorpora. We introduce BioBERT (Bidirectional Encoder Representations from\nTransformers for Biomedical Text Mining), which is a domain-specific language\nrepresentation model pre-trained on large-scale biomedical corpora. With almost\nthe same architecture across tasks, BioBERT largely outperforms BERT and\nprevious state-of-the-art models in a variety of biomedical text mining tasks\nwhen pre-trained on biomedical corpora. While BERT obtains performance\ncomparable to that of previous state-of-the-art models, BioBERT significantly\noutperforms them on the following three representative biomedical text mining\ntasks: biomedical named entity recognition (0.62% F1 score improvement),\nbiomedical relation extraction (2.80% F1 score improvement) and biomedical\nquestion answering (12.24% MRR improvement). Our analysis results show that\npre-training BERT on biomedical corpora helps it to understand complex\nbiomedical texts. We make the pre-trained weights of BioBERT freely available\nat https://github.com/naver/biobert-pretrained, and the source code for\nfine-tuning BioBERT available at https://github.com/dmis-lab/biobert.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 05:57:24 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 06:43:51 GMT"}, {"version": "v3", "created": "Sun, 3 Feb 2019 09:06:53 GMT"}, {"version": "v4", "created": "Fri, 18 Oct 2019 02:51:31 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Lee", "Jinhyuk", ""], ["Yoon", "Wonjin", ""], ["Kim", "Sungdong", ""], ["Kim", "Donghyeon", ""], ["Kim", "Sunkyu", ""], ["So", "Chan Ho", ""], ["Kang", "Jaewoo", ""]]}, {"id": "1901.08759", "submitter": "Priyank Palod", "authors": "Priyank Palod, Ayush Patwari, Sudhanshu Bahety, Saurabh Bagchi and\n  Pawan Goyal", "title": "Misleading Metadata Detection on YouTube", "comments": "Accepted at European Conference on Information Retrieval(ECIR) 2019.\n  7 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  YouTube is the leading social media platform for sharing videos. As a result,\nit is plagued with misleading content that includes staged videos presented as\nreal footages from an incident, videos with misrepresented context and videos\nwhere audio/video content is morphed. We tackle the problem of detecting such\nmisleading videos as a supervised classification task. We develop UCNet - a\ndeep network to detect fake videos and perform our experiments on two datasets\n- VAVD created by us and publicly available FVC [8]. We achieve a macro\naveraged F-score of 0.82 while training and testing on a 70:30 split of FVC,\nwhile the baseline model scores 0.36. We find that the proposed model\ngeneralizes well when trained on one dataset and tested on the other.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 07:09:14 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Palod", "Priyank", ""], ["Patwari", "Ayush", ""], ["Bahety", "Sudhanshu", ""], ["Bagchi", "Saurabh", ""], ["Goyal", "Pawan", ""]]}, {"id": "1901.09037", "submitter": "Ziwei Xu", "authors": "Ziwei Xu (Polytech Nantes, DUKe, LS2N), Mounira Harzallah (LINA),\n  Fabrice Guillet (LINA)", "title": "Comparing of Term Clustering Frameworks for Modular Ontology Learning", "comments": null, "journal-ref": "10th International Joint Conference on Knowledge Discovery,\n  Knowledge Engineering and Knowledge Management, Sep 2018, Seville, Spain.\n  SCITEPRESS - Science and Technology Publications; SCITEPRESS - Science and\n  Technology Publications, pp.128-135, 2018, Proceedings of the 10th\n  International Joint Conference on Knowledge Discovery, Knowledge Engineering\n  and Knowledge Management - Volume 2: KEOD", "doi": "10.5220/0006960401280135", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to use term clustering to build a modular ontology according\nto core ontology from domain-specific text. The acquisition of semantic\nknowledge focuses on noun phrase appearing with the same syntactic roles in\nrelation to a verb or its preposition combination in a sentence. The\nconstruction of this co-occurrence matrix from context helps to build feature\nspace of noun phrases, which is then transformed to several encoding\nrepresentations including feature selection and dimensionality reduction. In\naddition, the content has also been presented with the construction of word\nvectors. These representations are clustered respectively with K-Means and\nAffinity Propagation (AP) methods, which differentiate into the term clustering\nframeworks. Due to the randomness of K-Means, iteration efforts are adopted to\nfind the optimal parameter. The frameworks are evaluated extensively where AP\nshows dominant effectiveness for co-occurred terms and NMF encoding technique\nis salient by its promising facilities in feature compression.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 15:04:02 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Xu", "Ziwei", "", "Polytech Nantes, DUKe, LS2N"], ["Harzallah", "Mounira", "", "LINA"], ["Guillet", "Fabrice", "", "LINA"]]}, {"id": "1901.09066", "submitter": "Quanshi Zhang", "authors": "Kyoung-Woon On, Eun-Sol Kim, Yu-Jung Heo and Byoung-Tak Zhang", "title": "Visualizing Semantic Structures of Sequential Data by Learning Temporal\n  Dependencies", "comments": "In AAAI-19 Workshop on Network Interpretability for Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While conventional methods for sequential learning focus on interaction\nbetween consecutive inputs, we suggest a new method which captures composite\nsemantic flows with variable-length dependencies. In addition, the semantic\nstructures within given sequential data can be interpreted by visualizing\ntemporal dependencies learned from the method. The proposed method, called\nTemporal Dependency Network (TDN), represents a video as a temporal graph whose\nnode represents a frame of the video and whose edge represents the temporal\ndependency between two frames of a variable distance. The temporal dependency\nstructure of semantic is discovered by learning parameterized kernels of graph\nconvolutional methods. We evaluate the proposed method on the large-scale video\ndataset, Youtube-8M. By visualizing the temporal dependency structures as\nexperimental results, we show that the suggested method can find the temporal\ndependency structures of video semantic.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2019 18:46:21 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["On", "Kyoung-Woon", ""], ["Kim", "Eun-Sol", ""], ["Heo", "Yu-Jung", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "1901.09069", "submitter": "Felipe Almeida", "authors": "Felipe Almeida and Geraldo Xex\\'eo", "title": "Word Embeddings: A Survey", "comments": "10 pages, 2 tables, 1 image", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work lists and describes the main recent strategies for building\nfixed-length, dense and distributed representations for words, based on the\ndistributional hypothesis. These representations are now commonly called word\nembeddings and, in addition to encoding surprisingly good syntactic and\nsemantic information, have been proven useful as extra features in many\ndownstream NLP tasks.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 20:31:02 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Almeida", "Felipe", ""], ["Xex\u00e9o", "Geraldo", ""]]}, {"id": "1901.09102", "submitter": "Michele Tufano", "authors": "Michele Tufano, Jevgenija Pantiuchina, Cody Watson, Gabriele Bavota,\n  Denys Poshyvanyk", "title": "On Learning Meaningful Code Changes via Neural Machine Translation", "comments": "Accepted to the 41st ACM/IEEE International Conference on Software\n  Engineering (ICSE 2019) - Montreal, QC, Canada, May 25-31, 2019, 12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen the rise of Deep Learning (DL) techniques applied to\nsource code. Researchers have exploited DL to automate several development and\nmaintenance tasks, such as writing commit messages, generating comments and\ndetecting vulnerabilities among others. One of the long lasting dreams of\napplying DL to source code is the possibility to automate non-trivial coding\nactivities. While some steps in this direction have been taken (e.g., learning\nhow to fix bugs), there is still a glaring lack of empirical evidence on the\ntypes of code changes that can be learned and automatically applied by DL. Our\ngoal is to make this first important step by quantitatively and qualitatively\ninvestigating the ability of a Neural Machine Translation (NMT) model to learn\nhow to automatically apply code changes implemented by developers during pull\nrequests. We train and experiment with the NMT model on a set of 236k pairs of\ncode components before and after the implementation of the changes provided in\nthe pull requests. We show that, when applied in a narrow enough context (i.e.,\nsmall/medium-sized pairs of methods before/after the pull request changes), NMT\ncan automatically replicate the changes implemented by developers during pull\nrequests in up to 36% of the cases. Moreover, our qualitative analysis shows\nthat the model is capable of learning and replicating a wide variety of\nmeaningful code changes, especially refactorings and bug-fixing activities. Our\nresults pave the way for novel research in the area of DL on code, such as the\nautomatic learning and applications of refactoring.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 22:12:39 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Tufano", "Michele", ""], ["Pantiuchina", "Jevgenija", ""], ["Watson", "Cody", ""], ["Bavota", "Gabriele", ""], ["Poshyvanyk", "Denys", ""]]}, {"id": "1901.09115", "submitter": "Andrei Popescu-Belis", "authors": "Andrei Popescu-Belis", "title": "Context in Neural Machine Translation: A Review of Models and\n  Evaluations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This review paper discusses how context has been used in neural machine\ntranslation (NMT) in the past two years (2017-2018). Starting with a brief\nretrospect on the rapid evolution of NMT models, the paper then reviews studies\nthat evaluate NMT output from various perspectives, with emphasis on those\nanalyzing limitations of the translation of contextual phenomena. In a\nsubsequent version, the paper will then present the main methods that were\nproposed to leverage context for improving translation quality, and\ndistinguishes methods that aim to improve the translation of specific phenomena\nfrom those that consider a wider unstructured context.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 23:25:18 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Popescu-Belis", "Andrei", ""]]}, {"id": "1901.09118", "submitter": "Michael Bloodgood", "authors": "Michael Altschuler and Michael Bloodgood", "title": "Stopping Active Learning based on Predicted Change of F Measure for Text\n  Classification", "comments": "8 pages, 12 tables; published in Proceedings of the 2019 IEEE 13th\n  International Conference on Semantic Computing (ICSC), Newport Beach, CA,\n  USA, pages 47-54, January 2019", "journal-ref": "In Proceedings of the 2019 IEEE 13th International Conference on\n  Semantic Computing (ICSC), pages 47-54, Newport Beach, CA, USA, January 2019.\n  IEEE", "doi": "10.1109/ICOSC.2019.8665646", "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During active learning, an effective stopping method allows users to limit\nthe number of annotations, which is cost effective. In this paper, a new\nstopping method called Predicted Change of F Measure will be introduced that\nattempts to provide the users an estimate of how much performance of the model\nis changing at each iteration. This stopping method can be applied with any\nbase learner. This method is useful for reducing the data annotation bottleneck\nencountered when building text classification systems.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 00:01:27 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 23:56:41 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Altschuler", "Michael", ""], ["Bloodgood", "Michael", ""]]}, {"id": "1901.09126", "submitter": "Michael Bloodgood", "authors": "Garrett Beatty, Ethan Kochis and Michael Bloodgood", "title": "The Use of Unlabeled Data versus Labeled Data for Stopping Active\n  Learning for Text Classification", "comments": "8 pages, 4 figures, 3 tables; published in Proceedings of the IEEE\n  13th International Conference on Semantic Computing (ICSC), Newport Beach,\n  CA, USA, pages 287-294, January 2019", "journal-ref": "In Proceedings of the 2019 IEEE 13th International Conference on\n  Semantic Computing (ICSC), pages 287-294, Newport Beach, CA, USA, January\n  2019. IEEE", "doi": "10.1109/ICOSC.2019.8665546", "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Annotation of training data is the major bottleneck in the creation of text\nclassification systems. Active learning is a commonly used technique to reduce\nthe amount of training data one needs to label. A crucial aspect of active\nlearning is determining when to stop labeling data. Three potential sources for\ninforming when to stop active learning are an additional labeled set of data,\nan unlabeled set of data, and the training data that is labeled during the\nprocess of active learning. To date, no one has compared and contrasted the\nadvantages and disadvantages of stopping methods based on these three\ninformation sources. We find that stopping methods that use unlabeled data are\nmore effective than methods that use labeled data.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 00:27:02 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 23:36:51 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Beatty", "Garrett", ""], ["Kochis", "Ethan", ""], ["Bloodgood", "Michael", ""]]}, {"id": "1901.09128", "submitter": "Ming-Wei Chang", "authors": "Ming-Wei Chang, Kristina Toutanova, Kenton Lee, Jacob Devlin", "title": "Language Model Pre-training for Hierarchical Document Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical neural architectures are often used to capture long-distance\ndependencies and have been applied to many document-level tasks such as\nsummarization, document segmentation, and sentiment analysis. However,\neffective usage of such a large context can be difficult to learn, especially\nin the case where there is limited labeled data available. Building on the\nrecent success of language model pretraining methods for learning flat\nrepresentations of text, we propose algorithms for pre-training hierarchical\ndocument representations from unlabeled data. Unlike prior work, which has\nfocused on pre-training contextual token representations or context-independent\n{sentence/paragraph} representations, our hierarchical document representations\ninclude fixed-length sentence/paragraph representations which integrate\ncontextual information from the entire documents. Experiments on document\nsegmentation, document-level question answering, and extractive document\nsummarization demonstrate the effectiveness of the proposed pre-training\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 00:35:35 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Chang", "Ming-Wei", ""], ["Toutanova", "Kristina", ""], ["Lee", "Kenton", ""], ["Devlin", "Jacob", ""]]}, {"id": "1901.09219", "submitter": "Victor Makarenkov", "authors": "Victor Makarenkov, Ido Guy, Niva Hazon, Tamar Meisels, Bracha Shapira,\n  Lior Rokach", "title": "Implicit Dimension Identification in User-Generated Text with LSTM\n  Networks", "comments": null, "journal-ref": null, "doi": "10.1016/j.ipm.2019.02.007", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the process of online storytelling, individual users create and consume\nhighly diverse content that contains a great deal of implicit beliefs and not\nplainly expressed narrative. It is hard to manually detect these implicit\nbeliefs, intentions and moral foundations of the writers. We study and\ninvestigate two different tasks, each of which reflect the difficulty of\ndetecting an implicit user's knowledge, intent or belief that may be based on\nwriter's moral foundation: 1) political perspective detection in news articles\n2) identification of informational vs. conversational questions in community\nquestion answering (CQA) archives and. In both tasks we first describe new\ninteresting annotated datasets and make the datasets publicly available.\nSecond, we compare various classification algorithms, and show the differences\nin their performance on both tasks. Third, in political perspective detection\ntask we utilize a narrative representation language of local press to identify\nperspective differences between presumably neutral American and British press.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 14:18:57 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2019 12:09:16 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Makarenkov", "Victor", ""], ["Guy", "Ido", ""], ["Hazon", "Niva", ""], ["Meisels", "Tamar", ""], ["Shapira", "Bracha", ""], ["Rokach", "Lior", ""]]}, {"id": "1901.09296", "submitter": "Lingpeng Kong", "authors": "Lingpeng Kong, Gabor Melis, Wang Ling, Lei Yu, Dani Yogatama", "title": "Variational Smoothing in Recurrent Neural Network Language Models", "comments": "Accepted as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new theoretical perspective of data noising in recurrent neural\nnetwork language models (Xie et al., 2017). We show that each variant of data\nnoising is an instance of Bayesian recurrent neural networks with a particular\nvariational distribution (i.e., a mixture of Gaussians whose weights depend on\nstatistics derived from the corpus such as the unigram distribution). We use\nthis insight to propose a more principled method to apply at prediction time\nand propose natural extensions to data noising under the variational framework.\nIn particular, we propose variational smoothing with tied input and output\nembedding matrices and an element-wise variational smoothing method. We\nempirically verify our analysis on two benchmark language modeling datasets and\ndemonstrate performance improvements over existing data noising methods.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 00:46:27 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Kong", "Lingpeng", ""], ["Melis", "Gabor", ""], ["Ling", "Wang", ""], ["Yu", "Lei", ""], ["Yogatama", "Dani", ""]]}, {"id": "1901.09381", "submitter": "Zhan Shuailiang", "authors": "Shuailiang Zhang, Hai Zhao, Yuwei Wu, Zhuosheng Zhang, Xi Zhou, Xiang\n  Zhou", "title": "Dual Co-Matching Network for Multi-choice Reading Comprehension", "comments": "arXiv admin note: text overlap with arXiv:1806.04068 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-choice reading comprehension is a challenging task that requires\ncomplex reasoning procedure. Given passage and question, a correct answer need\nto be selected from a set of candidate answers. In this paper, we propose\n\\textbf{D}ual \\textbf{C}o-\\textbf{M}atching \\textbf{N}etwork (\\textbf{DCMN})\nwhich model the relationship among passage, question and answer\nbidirectionally. Different from existing approaches which only calculate\nquestion-aware or option-aware passage representation, we calculate\npassage-aware question representation and passage-aware answer representation\nat the same time. To demonstrate the effectiveness of our model, we evaluate\nour model on a large-scale multiple choice machine reading comprehension\ndataset (i.e. RACE). Experimental result show that our proposed model achieves\nnew state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 14:15:37 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 08:53:02 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Zhang", "Shuailiang", ""], ["Zhao", "Hai", ""], ["Wu", "Yuwei", ""], ["Zhang", "Zhuosheng", ""], ["Zhou", "Xi", ""], ["Zhou", "Xiang", ""]]}, {"id": "1901.09444", "submitter": "Yu-Ping Ruan", "authors": "Yu-Ping Ruan, Zhen-Hua Ling, Quan Liu, Jia-Chen Gu, Xiaodan Zhu", "title": "Promoting Diversity for End-to-End Conversation Response Generation", "comments": "To be present on AAAI19 Workshop---Dialog System Technology\n  Challenges 7 (DSTC7)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present our work on Track 2 in the Dialog System Technology Challenges 7\n(DSTC7). The DSTC7-Track 2 aims to evaluate the response generation of fully\ndata-driven conversation models in knowledge-grounded settings, which provides\nthe contextual-relevant factual texts. The Sequenceto-Sequence models have been\nwidely used for end-to-end generative conversation modelling and achieved\nimpressive results. However, they tend to output dull and repeated responses in\nprevious studies. Our work aims to promote the diversity for end-to-end\nconversation response generation, which follows a two-stage pipeline: 1)\nGenerate multiple responses. At this stage, two different models are proposed,\ni.e., a variational generative (VariGen) model and a retrieval based\n(Retrieval) model. 2) Rank and return the most related response by training a\ntopic coherence discrimination (TCD) model for the ranking process. According\nto the official evaluation results, our proposed Retrieval and VariGen systems\nranked first and second respectively on objective diversity metrics, i.e.,\nEntropy, among all participant systems. And the VariGen system ranked second on\nNIST and METEOR metrics.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 21:40:10 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2019 21:14:20 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Ruan", "Yu-Ping", ""], ["Ling", "Zhen-Hua", ""], ["Liu", "Quan", ""], ["Gu", "Jia-Chen", ""], ["Zhu", "Xiaodan", ""]]}, {"id": "1901.09492", "submitter": "Yongzhen Wang", "authors": "Yongzhen Wang, Xiaozhong Liu, Zheng Gao", "title": "Neural Related Work Summarization with a Joint Context-driven Attention\n  Mechanism", "comments": "11 pages, 3 figures, in the Proceedings of EMNLP 2018", "journal-ref": null, "doi": "10.18653/v1/D18-1204", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional solutions to automatic related work summarization rely heavily\non human-engineered features. In this paper, we develop a neural data-driven\nsummarizer by leveraging the seq2seq paradigm, in which a joint context-driven\nattention mechanism is proposed to measure the contextual relevance within full\ntexts and a heterogeneous bibliography graph simultaneously. Our motivation is\nto maintain the topic coherency between a related work section and its target\ndocument, where both the textual and graphic contexts play a big role in\ncharacterizing the relationship among scientific publications accurately.\nExperimental results on a large dataset show that our approach achieves a\nconsiderable improvement over a typical seq2seq summarizer and five classical\nsummarization baselines.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 03:00:06 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Wang", "Yongzhen", ""], ["Liu", "Xiaozhong", ""], ["Gao", "Zheng", ""]]}, {"id": "1901.09501", "submitter": "Shuai Lin", "authors": "Shuai Lin, Wentao Wang, Zichao Yang, Xiaodan Liang, Frank F. Xu, Eric\n  Xing and Zhiting Hu", "title": "Data-to-Text Generation with Style Imitation", "comments": "Accepted by EMNLP 2020 Findings. Significant updates over the\n  previous version. Code & data are available at\n  https://github.com/ha-lins/DTG-SI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent neural approaches to data-to-text generation have mostly focused on\nimproving content fidelity while lacking explicit control over writing styles\n(e.g., word choices, sentence structures). More traditional systems use\ntemplates to determine the realization of text. Yet manual or automatic\nconstruction of high-quality templates is difficult, and a template acting as\nhard constraints could harm content fidelity when it does not match the record\nperfectly. We study a new way of stylistic control by using existing sentences\nas soft templates. That is, the model learns to imitate the writing style of\nany given exemplar sentence, with automatic adaptions to faithfully describe\nthe content record. The problem is challenging due to the lack of parallel\ndata. We develop a neural approach that includes a hybrid attention-copy\nmechanism, learns with weak supervisions, and is enhanced with a new content\ncoverage constraint. We conduct experiments in restaurants and sports domains.\nResults show our approach achieves stronger performance than a range of\ncomparison methods. Our approach balances well between content fidelity and\nstyle control given exemplars that match the records to varying degrees.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 03:38:08 GMT"}, {"version": "v2", "created": "Fri, 8 Feb 2019 17:08:56 GMT"}, {"version": "v3", "created": "Fri, 9 Oct 2020 08:09:14 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Lin", "Shuai", ""], ["Wang", "Wentao", ""], ["Yang", "Zichao", ""], ["Liang", "Xiaodan", ""], ["Xu", "Frank F.", ""], ["Xing", "Eric", ""], ["Hu", "Zhiting", ""]]}, {"id": "1901.09657", "submitter": "Zhixuan Zhou", "authors": "Zhixuan Zhou, Huankang Guan, Meghana Moorthy Bhat and Justin Hsu", "title": "Fake News Detection via NLP is Vulnerable to Adversarial Attacks", "comments": "11th International Conference on Agents and Artificial Intelligence\n  (ICAART 2019)", "journal-ref": null, "doi": "10.5220/0007566307940800", "report-no": null, "categories": "cs.SI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  News plays a significant role in shaping people's beliefs and opinions. Fake\nnews has always been a problem, which wasn't exposed to the mass public until\nthe past election cycle for the 45th President of the United States. While\nquite a few detection methods have been proposed to combat fake news since\n2015, they focus mainly on linguistic aspects of an article without any fact\nchecking. In this paper, we argue that these models have the potential to\nmisclassify fact-tampering fake news as well as under-written real news.\nThrough experiments on Fakebox, a state-of-the-art fake news detector, we show\nthat fact tampering attacks can be effective. To address these weaknesses, we\nargue that fact checking should be adopted in conjunction with linguistic\ncharacteristics analysis, so as to truly separate fake news from real news. A\ncrowdsourced knowledge graph is proposed as a straw man solution to collecting\ntimely facts about news events.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jan 2019 11:56:13 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Zhou", "Zhixuan", ""], ["Guan", "Huankang", ""], ["Bhat", "Meghana Moorthy", ""], ["Hsu", "Justin", ""]]}, {"id": "1901.09672", "submitter": "Yinhe Zheng Dr.", "authors": "Yinhe Zheng, Guanyi Chen, Minlie Huang, Song Liu, Xuan Zhu", "title": "Personalized Dialogue Generation with Diversified Traits", "comments": "Please contact [zhengyinhe1 at 163 dot com] for the PersonalDialog\n  dataset", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Endowing a dialogue system with particular personality traits is essential to\ndeliver more human-like conversations. However, due to the challenge of\nembodying personality via language expression and the lack of large-scale\npersona-labeled dialogue data, this research problem is still far from\nwell-studied. In this paper, we investigate the problem of incorporating\nexplicit personality traits in dialogue generation to deliver personalized\ndialogues.\n  To this end, firstly, we construct PersonalDialog, a large-scale multi-turn\ndialogue dataset containing various traits from a large number of speakers. The\ndataset consists of 20.83M sessions and 56.25M utterances from 8.47M speakers.\nEach utterance is associated with a speaker who is marked with traits like Age,\nGender, Location, Interest Tags, etc. Several anonymization schemes are\ndesigned to protect the privacy of each speaker. This large-scale dataset will\nfacilitate not only the study of personalized dialogue generation, but also\nother researches on sociolinguistics or social science.\n  Secondly, to study how personality traits can be captured and addressed in\ndialogue generation, we propose persona-aware dialogue generation models within\nthe sequence to sequence learning framework. Explicit personality traits\n(structured by key-value pairs) are embedded using a trait fusion module.\nDuring the decoding process, two techniques, namely persona-aware attention and\npersona-aware bias, are devised to capture and address trait-related\ninformation. Experiments demonstrate that our model is able to address proper\ntraits in different contexts. Case studies also show interesting results for\nthis challenging research problem.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 14:22:15 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 02:57:06 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Zheng", "Yinhe", ""], ["Chen", "Guanyi", ""], ["Huang", "Minlie", ""], ["Liu", "Song", ""], ["Zhu", "Xuan", ""]]}, {"id": "1901.09755", "submitter": "Rodrigo Agerri", "authors": "Rodrigo Agerri, German Rigau", "title": "Language Independent Sequence Labelling for Opinion Target Extraction", "comments": "17 pages", "journal-ref": "Artificial Intelligence (2018), 268: 65-85", "doi": "10.1016/j.artint.2018.12.002", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this research note we present a language independent system to model\nOpinion Target Extraction (OTE) as a sequence labelling task. The system\nconsists of a combination of clustering features implemented on top of a simple\nset of shallow local features. Experiments on the well known Aspect Based\nSentiment Analysis (ABSA) benchmarks show that our approach is very competitive\nacross languages, obtaining best results for six languages in seven different\ndatasets. Furthermore, the results provide further insights into the behaviour\nof clustering features for sequence labelling tasks. The system and models\ngenerated in this work are available for public use and to facilitate\nreproducibility of results.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 15:55:22 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Agerri", "Rodrigo", ""], ["Rigau", "German", ""]]}, {"id": "1901.09785", "submitter": "Bin Wang", "authors": "Bin Wang, Angela Wang, Fenxiao Chen, Yuncheng Wang and C.-C. Jay Kuo", "title": "Evaluating Word Embedding Models: Methods and Experimental Results", "comments": "13 pages", "journal-ref": "APSIPA Transactions on Signal and Information Processing 8 (2019)\n  e19", "doi": "10.1017/ATSIP.2019.12", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extensive evaluation on a large number of word embedding models for language\nprocessing applications is conducted in this work. First, we introduce popular\nword embedding models and discuss desired properties of word models and\nevaluation methods (or evaluators). Then, we categorize evaluators into\nintrinsic and extrinsic two types. Intrinsic evaluators test the quality of a\nrepresentation independent of specific natural language processing tasks while\nextrinsic evaluators use word embeddings as input features to a downstream task\nand measure changes in performance metrics specific to that task. We report\nexperimental results of intrinsic and extrinsic evaluators on six word\nembedding models. It is shown that different evaluators focus on different\naspects of word models, and some are more correlated with natural language\nprocessing tasks. Finally, we adopt correlation analysis to study performance\nconsistency of extrinsic and intrinsic evalutors.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 16:33:25 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 16:20:47 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Wang", "Bin", ""], ["Wang", "Angela", ""], ["Chen", "Fenxiao", ""], ["Wang", "Yuncheng", ""], ["Kuo", "C. -C. Jay", ""]]}, {"id": "1901.09813", "submitter": "Carl Allen", "authors": "Carl Allen and Timothy Hospedales", "title": "Analogies Explained: Towards Understanding Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Word embeddings generated by neural network methods such as word2vec (W2V)\nare well known to exhibit seemingly linear behaviour, e.g. the embeddings of\nanalogy \"woman is to queen as man is to king\" approximately describe a\nparallelogram. This property is particularly intriguing since the embeddings\nare not trained to achieve it. Several explanations have been proposed, but\neach introduces assumptions that do not hold in practice. We derive a\nprobabilistically grounded definition of paraphrasing that we re-interpret as\nword transformation, a mathematical description of \"$w_x$ is to $w_y$\". From\nthese concepts we prove existence of linear relationships between W2V-type\nembeddings that underlie the analogical phenomenon, identifying explicit error\nterms.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 17:04:25 GMT"}, {"version": "v2", "created": "Sat, 11 May 2019 19:02:42 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Allen", "Carl", ""], ["Hospedales", "Timothy", ""]]}, {"id": "1901.09821", "submitter": "David Mac\\^edo", "authors": "Andr\\'ea B. Duque, Lu\\~a L\\'azaro J. Santos, David Mac\\^edo, Cleber\n  Zanchettin", "title": "Squeezed Very Deep Convolutional Neural Networks for Text Classification", "comments": null, "journal-ref": "2019 International Conference on Artificial Neural Networks\n  (ICANN)", "doi": "10.1007/978-3-030-30487-4_16", "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the research in convolutional neural networks has focused on\nincreasing network depth to improve accuracy, resulting in a massive number of\nparameters which restricts the trained network to platforms with memory and\nprocessing constraints. We propose to modify the structure of the Very Deep\nConvolutional Neural Networks (VDCNN) model to fit mobile platforms constraints\nand keep performance. In this paper, we evaluate the impact of Temporal\nDepthwise Separable Convolutions and Global Average Pooling in the network\nparameters, storage size, and latency. The squeezed model (SVDCNN) is between\n10x and 20x smaller, depending on the network depth, maintaining a maximum size\nof 6MB. Regarding accuracy, the network experiences a loss between 0.4% and\n1.3% and obtains lower latencies compared to the baseline model.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 17:14:12 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Duque", "Andr\u00e9a B.", ""], ["Santos", "Lu\u00e3 L\u00e1zaro J.", ""], ["Mac\u00eado", "David", ""], ["Zanchettin", "Cleber", ""]]}, {"id": "1901.09848", "submitter": "Martin Gerlach", "authors": "Hanyu Shi, Martin Gerlach, Isabel Diersen, Doug Downey, Luis A. N.\n  Amaral", "title": "A new evaluation framework for topic modeling algorithms based on\n  synthetic corpora", "comments": "accepted for AISTATS 2019; code available at\n  https://github.com/amarallab/synthetic_benchmark_topic_model; Main text (11\n  pages, 5 figures) and Supplementary Material (14 pages, 11 figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic models are in widespread use in natural language processing and beyond.\nHere, we propose a new framework for the evaluation of probabilistic topic\nmodeling algorithms based on synthetic corpora containing an unambiguously\ndefined ground truth topic structure. The major innovation of our approach is\nthe ability to quantify the agreement between the planted and inferred topic\nstructures by comparing the assigned topic labels at the level of the tokens.\nIn experiments, our approach yields novel insights about the relative strengths\nof topic models as corpus characteristics vary, and the first evidence of an\n\"undetectable phase\" for topic models when the planted structure is weak. We\nalso establish the practical relevance of the insights gained for synthetic\ncorpora by predicting the performance of topic modeling algorithms in\nclassification tasks in real-world corpora.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 17:41:19 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Shi", "Hanyu", ""], ["Gerlach", "Martin", ""], ["Diersen", "Isabel", ""], ["Downey", "Doug", ""], ["Amaral", "Luis A. N.", ""]]}, {"id": "1901.09957", "submitter": "Fanchao Qi", "authors": "Fanchao Qi, Chenghao Yang, Zhiyuan Liu, Qiang Dong, Maosong Sun,\n  Zhendong Dong", "title": "OpenHowNet: An Open Sememe-based Lexical Knowledge Base", "comments": "4 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we present an open sememe-based lexical knowledge base\nOpenHowNet. Based on well-known HowNet, OpenHowNet comprises three components:\ncore data which is composed of more than 100 thousand senses annotated with\nsememes, OpenHowNet Web which gives a brief introduction to OpenHowNet as well\nas provides online exhibition of OpenHowNet information, and OpenHowNet API\nwhich includes several useful APIs such as accessing OpenHowNet core data and\ndrawing sememe tree structures of senses. In the main text, we first give some\nbackgrounds including definition of sememe and details of HowNet. And then we\nintroduce some previous HowNet and sememe-based research works. Last but not\nleast, we detail the constituents of OpenHowNet and their basic features and\nfunctionalities. Additionally, we briefly make a summary and list some future\nworks.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 19:35:17 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Qi", "Fanchao", ""], ["Yang", "Chenghao", ""], ["Liu", "Zhiyuan", ""], ["Dong", "Qiang", ""], ["Sun", "Maosong", ""], ["Dong", "Zhendong", ""]]}, {"id": "1901.10055", "submitter": "Julian Salazar", "authors": "Julian Salazar, Katrin Kirchhoff, Zhiheng Huang", "title": "Self-Attention Networks for Connectionist Temporal Classification in\n  Speech Recognition", "comments": "Accepted to ICASSP 2019", "journal-ref": null, "doi": "10.1109/ICASSP.2019.8682539", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of self-attention in NLP has led to recent applications in\nend-to-end encoder-decoder architectures for speech recognition. Separately,\nconnectionist temporal classification (CTC) has matured as an alignment-free,\nnon-autoregressive approach to sequence transduction, either by itself or in\nvarious multitask and decoding frameworks. We propose SAN-CTC, a deep, fully\nself-attentional network for CTC, and show it is tractable and competitive for\nend-to-end speech recognition. SAN-CTC trains quickly and outperforms existing\nCTC models and most encoder-decoder models, with character error rates (CERs)\nof 4.7% in 1 day on WSJ eval92 and 2.8% in 1 week on LibriSpeech test-clean,\nwith a fixed architecture and one GPU. Similar improvements hold for WERs after\nLM decoding. We motivate the architecture for speech, evaluate position and\ndownsampling approaches, and explore how label alphabets (character, phoneme,\nsubword) affect attention heads and performance.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 21:37:07 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 10:12:52 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Salazar", "Julian", ""], ["Kirchhoff", "Katrin", ""], ["Huang", "Zhiheng", ""]]}, {"id": "1901.10125", "submitter": "Jiwei Li", "authors": "Yuxian Meng, Wei Wu, Fei Wang, Xiaoya Li, Ping Nie, Fan Yin, Muyu Li,\n  Qinghong Han, Xiaofei Sun, Jiwei Li", "title": "Glyce: Glyph-vectors for Chinese Character Representations", "comments": "Accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is intuitive that NLP tasks for logographic languages like Chinese should\nbenefit from the use of the glyph information in those languages. However, due\nto the lack of rich pictographic evidence in glyphs and the weak generalization\nability of standard computer vision models on character data, an effective way\nto utilize the glyph information remains to be found. In this paper, we address\nthis gap by presenting Glyce, the glyph-vectors for Chinese character\nrepresentations. We make three major innovations: (1) We use historical Chinese\nscripts (e.g., bronzeware script, seal script, traditional Chinese, etc) to\nenrich the pictographic evidence in characters; (2) We design CNN structures\n(called tianzege-CNN) tailored to Chinese character image processing; and (3)\nWe use image-classification as an auxiliary task in a multi-task learning setup\nto increase the model's ability to generalize. We show that glyph-based models\nare able to consistently outperform word/char ID-based models in a wide range\nof Chinese NLP tasks. We are able to set new state-of-the-art results for a\nvariety of Chinese NLP tasks, including tagging (NER, CWS, POS), sentence pair\nclassification, single sentence classification tasks, dependency parsing, and\nsemantic role labeling. For example, the proposed model achieves an F1 score of\n80.6 on the OntoNotes dataset of NER, +1.5 over BERT; it achieves an almost\nperfect accuracy of 99.8\\% on the Fudan corpus for text classification. Code\nfound at https://github.com/ShannonAI/glyce.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 06:15:36 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 17:20:19 GMT"}, {"version": "v3", "created": "Fri, 31 May 2019 06:36:27 GMT"}, {"version": "v4", "created": "Wed, 4 Sep 2019 12:15:19 GMT"}, {"version": "v5", "created": "Thu, 21 May 2020 09:05:11 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Meng", "Yuxian", ""], ["Wu", "Wei", ""], ["Wang", "Fei", ""], ["Li", "Xiaoya", ""], ["Nie", "Ping", ""], ["Yin", "Fan", ""], ["Li", "Muyu", ""], ["Han", "Qinghong", ""], ["Sun", "Xiaofei", ""], ["Li", "Jiwei", ""]]}, {"id": "1901.10133", "submitter": "C Ravindranath Chowdary", "authors": "Shashank Yadav, Tejas Shimpi, C. Ravindranath Chowdary, Prashant\n  Sharma, Deepansh Agrawal, Shivang Agarwal", "title": "Structuring an unordered text document", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Segmenting an unordered text document into different sections is a very\nuseful task in many text processing applications like multiple document\nsummarization, question answering, etc. This paper proposes structuring of an\nunordered text document based on the keywords in the document. We test our\napproach on Wikipedia documents using both statistical and predictive methods\nsuch as the TextRank algorithm and Google's USE (Universal Sentence Encoder).\nFrom our experimental results, we show that the proposed model can effectively\nstructure an unordered document into sections.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 06:53:21 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Yadav", "Shashank", ""], ["Shimpi", "Tejas", ""], ["Chowdary", "C. Ravindranath", ""], ["Sharma", "Prashant", ""], ["Agrawal", "Deepansh", ""], ["Agarwal", "Shivang", ""]]}, {"id": "1901.10188", "submitter": "Dima Taji", "authors": "Dima Taji, Jamila El Gizuli and Nizar Habash", "title": "An Arabic Dependency Treebank in the Travel Domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we present a dependency treebank of travel domain sentences in\nModern Standard Arabic. The text comes from a translation of the English\nequivalent sentences in the Basic Traveling Expressions Corpus. The treebank\ndependency representation is in the style of the Columbia Arabic Treebank. The\npaper motivates the effort and discusses the construction process and\nguidelines. We also present parsing results and discuss the effect of domain\nand genre difference on parsing.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 09:24:15 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Taji", "Dima", ""], ["Gizuli", "Jamila El", ""], ["Habash", "Nizar", ""]]}, {"id": "1901.10196", "submitter": "Mamoru Komachi", "authors": "Tomoya Ogata, Mamoru Komachi, Tomoya Takatani", "title": "Divide and Generate: Neural Generation of Complex Sentences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a task to generate a complex sentence from a simple sentence in\norder to amplify various kinds of responses in the database. We first divide a\ncomplex sentence into a main clause and a subordinate clause to learn a\ngenerator model of modifiers, and then use the model to generate a modifier\nclause to create a complex sentence from a simple sentence. We present an\nautomatic evaluation metric to estimate the quality of the models and show that\na pipeline model outperforms an end-to-end model.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 10:00:54 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Ogata", "Tomoya", ""], ["Komachi", "Mamoru", ""], ["Takatani", "Tomoya", ""]]}, {"id": "1901.10219", "submitter": "Ming Siang Huang", "authors": "Ming-Siang Huang, Po-Ting Lai, Richard Tzong-Han Tsai, Wen-Lian Hsu", "title": "Revised JNLPBA Corpus: A Revised Version of Biomedical NER Corpus for\n  Relation Extraction Task", "comments": "17 pages", "journal-ref": "Briefings in Bioinformatics, 2020, bbaa054", "doi": "10.1093/bib/bbaa054", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advancement of biomedical named entity recognition (BNER) and biomedical\nrelation extraction (BRE) researches promotes the development of text mining in\nbiological domains. As a cornerstone of BRE, robust BNER system is required to\nidentify the mentioned NEs in plain texts for further relation extraction\nstage. However, the current BNER corpora, which play important roles in these\ntasks, paid less attention to achieve the criteria for BRE task. In this study,\nwe present Revised JNLPBA corpus, the revision of JNLPBA corpus, to broaden the\napplicability of a NER corpus from BNER to BRE task. We preserve the original\nentity types including protein, DNA, RNA, cell line and cell type while all the\nabstracts in JNLPBA corpus are manually curated by domain experts again basis\non the new annotation guideline focusing on the specific NEs instead of general\nterms. Simultaneously, several imperfection issues in JNLPBA are pointed out\nand made up in the new corpus. To compare the adaptability of different NER\nsystems in Revised JNLPBA and JNLPBA corpora, the F1-measure was measured in\nthree open sources NER systems including BANNER, Gimli and NERSuite. In the\nsame circumstance, all the systems perform average 10% better in Revised JNLPBA\nthan in JNLPBA. Moreover, the cross-validation test is carried out which we\ntrain the NER systems on JNLPBA/Revised JNLPBA corpora and access the\nperformance in both protein-protein interaction extraction (PPIE) and\nbiomedical event extraction (BEE) corpora to confirm that the newly refined\nRevised JNLPBA is a competent NER corpus in biomedical relation application.\nThe revised JNLPBA corpus is freely available at\niasl-btm.iis.sinica.edu.tw/BNER/Content/Revised_JNLPBA.zip.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 11:12:58 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Huang", "Ming-Siang", ""], ["Lai", "Po-Ting", ""], ["Tsai", "Richard Tzong-Han", ""], ["Hsu", "Wen-Lian", ""]]}, {"id": "1901.10263", "submitter": "Simon Razniewski", "authors": "Cuong Xuan Chu, Simon Razniewski, Gerhard Weikum", "title": "TiFi: Taxonomy Induction for Fictional Domains [Extended version]", "comments": "Extended version of The Web Conference 2019 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Taxonomies are important building blocks of structured knowledge bases, and\ntheir construction from text sources and Wikipedia has received much attention.\nIn this paper we focus on the construction of taxonomies for fictional domains,\nusing noisy category systems from fan wikis or text extraction as input. Such\nfictional domains are archetypes of entity universes that are poorly covered by\nWikipedia, such as also enterprise-specific knowledge bases or highly\nspecialized verticals. Our fiction-targeted approach, called TiFi, consists of\nthree phases: (i) category cleaning, by identifying candidate categories that\ntruly represent classes in the domain of interest, (ii) edge cleaning, by\nselecting subcategory relationships that correspond to class subsumption, and\n(iii) top-level construction, by mapping classes onto a subset of high-level\nWordNet categories. A comprehensive evaluation shows that TiFi is able to\nconstruct taxonomies for a diverse range of fictional domains such as Lord of\nthe Rings, The Simpsons or Greek Mythology with very high precision and that it\noutperforms state-of-the-art baselines for taxonomy induction by a substantial\nmargin.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 13:07:13 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Chu", "Cuong Xuan", ""], ["Razniewski", "Simon", ""], ["Weikum", "Gerhard", ""]]}, {"id": "1901.10265", "submitter": "Vijay Keswani", "authors": "L. Elisa Celis and Vijay Keswani", "title": "Implicit Diversity in Image Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studies have shown that the people depicted in image search results tend to\nbe of majority groups with respect to socially salient attributes. This skew\ngoes beyond that which already exists in the world - e.g., Kay et al. showed\nthat although 28% of CEOs in US are women, only 10% of the top 100 results for\nCEO in Google Image Search are women. Most existing approaches to correct for\nthis kind of bias assume that the images of people include socially salient\nattribute labels. However, such labels are often unknown. Further, using\nautomated techniques to infer these labels may often not be possible within\nacceptable accuracy ranges, and may not be desirable due to the additional\nbiases this process could incur. We develop a novel approach that takes as\ninput a visibly diverse control set of images and uses this set to select a set\nof images of people in response to a query. The goal is to have a resulting set\nthat is more visibly diverse in a manner that emulates the diversity depicted\nin the control set. Importantly, this approach does not require images to be\nlabelled at any point; effectively, it gives a way to implicitly diversify the\nset of images selected. We provide two variants of our approach: the first is a\nmodification of the MMR algorithm to incorporate the diversity scores, and\nsecond is a more efficient variant that does not consider within-list\nredundancy. We evaluate these approaches empirically on two datasets 1) a new\ndataset containing top Google image results for 96 occupations, for which we\nevaluate gender and skin-tone diversity with respect to occupations and 2) the\nCelebA dataset for which we evaluate gender diversity with respect to facial\nfeatures. Our approaches produce image sets that significantly improve the\nvisible diversity of the results, compared to current Google search and other\ndiverse image summarization algorithms, at a minimal cost to accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 13:13:16 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 14:45:53 GMT"}, {"version": "v3", "created": "Fri, 14 Aug 2020 21:00:06 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Celis", "L. Elisa", ""], ["Keswani", "Vijay", ""]]}, {"id": "1901.10408", "submitter": "Jo\\~ao Ranhel", "authors": "Jo\\~ao Ranhel, Cacilda Vilela", "title": "Guidelines for creating man-machine multimodal interfaces", "comments": "The pseudo-code in section \"5.2.2 The Algorithm Kernel\" needs\n  revision. We are working on systems description using SDL, instead of showing\n  a pseudo-code algorithm. Describing the system using \"Specification and\n  Description Language\" can make reading easier and precise. Explanations of\n  linguistic theories need to be simplified. Tables and figures will also help\n  on understanding the article", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding details of human multimodal interaction can elucidate many\naspects of the type of information processing machines must perform to interact\nwith humans. This article gives an overview of recent findings from Linguistics\nregarding the organization of conversation in turns, adjacent pairs,\n(dis)preferred responses, (self)repairs, etc. Besides, we describe how multiple\nmodalities of signs interfere with each other modifying meanings. Then, we\npropose an abstract algorithm that describes how a machine can implement a\ndouble-feedback system that can reproduces a human-like face-to-face\ninteraction by processing various signs, such as verbal, prosodic, facial\nexpressions, gestures, etc. Multimodal face-to-face interactions enrich the\nexchange of information between agents, mainly because these agents are active\nall the time by emitting and interpreting signs simultaneously. This article is\nnot about an untested new computational model. Instead, it translates findings\nfrom Linguistics as guidelines for designs of multimodal man-machine\ninterfaces. An algorithm is presented. Brought from Linguistics, it is a\ndescription pointing out how human face-to-face interactions work. The\nlinguistic findings reported here are the first steps towards the integration\nof multimodal communication. Some developers involved on interface designs\ncarry on working on isolated models for interpreting text, grammar, gestures\nand facial expressions, neglecting the interwoven between these signs. In\ncontrast, for linguists working on the state-of-the-art multimodal integration,\nthe interpretation of separated modalities leads to an incomplete\ninterpretation, if not to a miscomprehension of information. The algorithm\nproposed herein intends to guide man-machine interface designers who want to\nintegrate multimodal components on face-to-face interactions as close as\npossible to those performed between humans.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 17:23:32 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2020 19:01:13 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Ranhel", "Jo\u00e3o", ""], ["Vilela", "Cacilda", ""]]}, {"id": "1901.10430", "submitter": "Michael Auli", "authors": "Felix Wu, Angela Fan, Alexei Baevski, Yann N. Dauphin, Michael Auli", "title": "Pay Less Attention with Lightweight and Dynamic Convolutions", "comments": "14 pages, ICLR oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-attention is a useful mechanism to build generative models for language\nand images. It determines the importance of context elements by comparing each\nelement to the current time step. In this paper, we show that a very\nlightweight convolution can perform competitively to the best reported\nself-attention results. Next, we introduce dynamic convolutions which are\nsimpler and more efficient than self-attention. We predict separate convolution\nkernels based solely on the current time-step in order to determine the\nimportance of context elements. The number of operations required by this\napproach scales linearly in the input length, whereas self-attention is\nquadratic. Experiments on large-scale machine translation, language modeling\nand abstractive summarization show that dynamic convolutions improve over\nstrong self-attention models. On the WMT'14 English-German test set dynamic\nconvolutions achieve a new state of the art of 29.7 BLEU.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 18:01:35 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2019 23:46:38 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Wu", "Felix", ""], ["Fan", "Angela", ""], ["Baevski", "Alexei", ""], ["Dauphin", "Yann N.", ""], ["Auli", "Michael", ""]]}, {"id": "1901.10444", "submitter": "John Wieting", "authors": "John Wieting, Douwe Kiela", "title": "No Training Required: Exploring Random Encoders for Sentence\n  Classification", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore various methods for computing sentence representations from\npre-trained word embeddings without any training, i.e., using nothing but\nrandom parameterizations. Our aim is to put sentence embeddings on more solid\nfooting by 1) looking at how much modern sentence embeddings gain over random\nmethods---as it turns out, surprisingly little; and by 2) providing the field\nwith more appropriate baselines going forward---which are, as it turns out,\nquite strong. We also make important observations about proper experimental\nprotocol for sentence classification evaluation, together with recommendations\nfor future research.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 18:44:01 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Wieting", "John", ""], ["Kiela", "Douwe", ""]]}, {"id": "1901.10457", "submitter": "Peng Qi", "authors": "Peng Qi, Timothy Dozat, Yuhao Zhang, Christopher D. Manning", "title": "Universal Dependency Parsing from Scratch", "comments": "In Proceedings of the CoNLL 2018 UD Shared Task. First three authors\n  contributed roughly equally. Github repo:\n  https://github.com/stanfordnlp/stanfordnlp Website:\n  https://stanfordnlp.github.io/stanfordnlp/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes Stanford's system at the CoNLL 2018 UD Shared Task. We\nintroduce a complete neural pipeline system that takes raw text as input, and\nperforms all tasks required by the shared task, ranging from tokenization and\nsentence segmentation, to POS tagging and dependency parsing. Our single system\nsubmission achieved very competitive performance on big treebanks. Moreover,\nafter fixing an unfortunate bug, our corrected system would have placed the\n2nd, 1st, and 3rd on the official evaluation metrics LAS,MLAS, and BLEX, and\nwould have outperformed all submission systems on low-resource treebank\ncategories on all metrics by a large margin. We further show the effectiveness\nof different model components through extensive ablation studies.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 18:58:29 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Qi", "Peng", ""], ["Dozat", "Timothy", ""], ["Zhang", "Yuhao", ""], ["Manning", "Christopher D.", ""]]}, {"id": "1901.10496", "submitter": "Trond Linjordet", "authors": "Trond Linjordet and Krisztian Balog", "title": "Impact of Training Dataset Size on Neural Answer Selection Models", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is held as a truism that deep neural networks require large datasets to\ntrain effective models. However, large datasets, especially with high-quality\nlabels, can be expensive to obtain. This study sets out to investigate (i) how\nlarge a dataset must be to train well-performing models, and (ii) what impact\ncan be shown from fractional changes to the dataset size. A practical method to\ninvestigate these questions is to train a collection of deep neural answer\nselection models using fractional subsets of varying sizes of an initial\ndataset. We observe that dataset size has a conspicuous lack of effect on the\ntraining of some of these models, bringing the underlying algorithms into\nquestion.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 19:00:21 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Linjordet", "Trond", ""], ["Balog", "Krisztian", ""]]}, {"id": "1901.10548", "submitter": "Zachary Ziegler", "authors": "Zachary M. Ziegler, Alexander M. Rush", "title": "Latent Normalizing Flows for Discrete Sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalizing flows are a powerful class of generative models for continuous\nrandom variables, showing both strong model flexibility and the potential for\nnon-autoregressive generation. These benefits are also desired when modeling\ndiscrete random variables such as text, but directly applying normalizing flows\nto discrete sequences poses significant additional challenges. We propose a\nVAE-based generative model which jointly learns a normalizing flow-based\ndistribution in the latent space and a stochastic mapping to an observed\ndiscrete space. In this setting, we find that it is crucial for the flow-based\ndistribution to be highly multimodal. To capture this property, we propose\nseveral normalizing flow architectures to maximize model flexibility.\nExperiments consider common discrete sequence tasks of character-level language\nmodeling and polyphonic music generation. Our results indicate that an\nautoregressive flow-based model can match the performance of a comparable\nautoregressive baseline, and a non-autoregressive flow-based model can improve\ngeneration speed with a penalty to performance.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 21:05:46 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 17:41:04 GMT"}, {"version": "v3", "created": "Wed, 29 May 2019 17:57:00 GMT"}, {"version": "v4", "created": "Tue, 4 Jun 2019 18:34:05 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Ziegler", "Zachary M.", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1901.10619", "submitter": "Tong Liu", "authors": "Tong Liu, Christopher M. Homan", "title": "Twitter Job/Employment Corpus: A Dataset of Job-Related Discourse Built\n  with Humans in the Loop", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Twitter Job/Employment Corpus, a collection of tweets\nannotated by a humans-in-the-loop supervised learning framework that integrates\ncrowdsourcing contributions and expertise on the local community and employment\nenvironment. Previous computational studies of job-related phenomena have used\ncorpora collected from workplace social media that are hosted internally by the\nemployers, and so lacks independence from latent job-related coercion and the\nbroader context that an open domain, general-purpose medium such as Twitter\nprovides. Our new corpus promises to be a benchmark for the extraction of\njob-related topics and advanced analysis and modeling, and can potentially\nbenefit a wide range of research communities in the future.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 00:01:14 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Liu", "Tong", ""], ["Homan", "Christopher M.", ""]]}, {"id": "1901.10623", "submitter": "Lin Xu", "authors": "Lin Xu, Qixian Zhou, Ke Gong, Xiaodan Liang, Jianheng Tang, Liang Lin", "title": "End-to-End Knowledge-Routed Relational Dialogue System for Automatic\n  Diagnosis", "comments": "8 pages, 5 figues, AAAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Beyond current conversational chatbots or task-oriented dialogue systems that\nhave attracted increasing attention, we move forward to develop a dialogue\nsystem for automatic medical diagnosis that converses with patients to collect\nadditional symptoms beyond their self-reports and automatically makes a\ndiagnosis. Besides the challenges for conversational dialogue systems (e.g.\ntopic transition coherency and question understanding), automatic medical\ndiagnosis further poses more critical requirements for the dialogue rationality\nin the context of medical knowledge and symptom-disease relations. Existing\ndialogue systems (Madotto, Wu, and Fung 2018; Wei et al. 2018; Li et al. 2017)\nmostly rely on data-driven learning and cannot be able to encode extra expert\nknowledge graph. In this work, we propose an End-to-End Knowledge-routed\nRelational Dialogue System (KR-DS) that seamlessly incorporates rich medical\nknowledge graph into the topic transition in dialogue management, and makes it\ncooperative with natural language understanding and natural language\ngeneration. A novel Knowledge-routed Deep Q-network (KR-DQN) is introduced to\nmanage topic transitions, which integrates a relational refinement branch for\nencoding relations among different symptoms and symptom-disease pairs, and a\nknowledge-routed graph branch for topic decision-making. Extensive experiments\non a public medical dialogue dataset show our KR-DS significantly beats\nstate-of-the-art methods (by more than 8% in diagnosis accuracy). We further\nshow the superiority of our KR-DS on a newly collected medical dialogue system\ndataset, which is more challenging retaining original self-reports and\nconversational data between patients and doctors.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 00:34:05 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2019 08:06:12 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Xu", "Lin", ""], ["Zhou", "Qixian", ""], ["Gong", "Ke", ""], ["Liang", "Xiaodan", ""], ["Tang", "Jianheng", ""], ["Lin", "Liang", ""]]}, {"id": "1901.10680", "submitter": "Guy De Pauw", "authors": "Janneke van de Loo and Jort F. Gemmeke and Guy De Pauw and Bart Ons\n  and Walter Daelemans and Hugo Van hamme", "title": "Effective weakly supervised semantic frame induction using expression\n  sharing in hierarchical hidden Markov models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We present a framework for the induction of semantic frames from utterances\nin the context of an adaptive command-and-control interface. The system is\ntrained on an individual user's utterances and the corresponding semantic\nframes representing controls. During training, no prior information on the\nalignment between utterance segments and frame slots and values is available.\nIn addition, semantic frames in the training data can contain information that\nis not expressed in the utterances. To tackle this weakly supervised\nclassification task, we propose a framework based on Hidden Markov Models\n(HMMs). Structural modifications, resulting in a hierarchical HMM, and an\nextension called expression sharing are introduced to minimize the amount of\ntraining time and effort required for the user.\n  The dataset used for the present study is PATCOR, which contains commands\nuttered in the context of a vocally guided card game, Patience. Experiments\nwere carried out on orthographic and phonetic transcriptions of commands,\nsegmented on different levels of n-gram granularity. The experimental results\nshow positive effects of all the studied system extensions, with some effect\ndifferences between the different input representations. Moreover, evaluation\nexperiments on held-out data with the optimal system configuration show that\nthe extended system is able to achieve high accuracies with relatively small\namounts of training data.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 05:49:17 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["van de Loo", "Janneke", ""], ["Gemmeke", "Jort F.", ""], ["De Pauw", "Guy", ""], ["Ons", "Bart", ""], ["Daelemans", "Walter", ""], ["Van hamme", "Hugo", ""]]}, {"id": "1901.10723", "submitter": "Martha Lewis", "authors": "Martha Lewis", "title": "Compositionality for Recursive Neural Networks", "comments": "presented at NeSy2018, Thirteenth International Workshop on\n  Neural-Symbolic Learning and Reasoning, co-located with Human-Level AI 2018,\n  Prague, CZ, August 23-24, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modelling compositionality has been a longstanding area of research in the\nfield of vector space semantics. The categorical approach to compositionality\nmaps grammar onto vector spaces in a principled way, but comes under fire for\nrequiring the formation of very high-dimensional matrices and tensors, and\ntherefore being computationally infeasible. In this paper I show how a linear\nsimplification of recursive neural tensor network models can be mapped directly\nonto the categorical approach, giving a way of computing the required matrices\nand tensors. This mapping suggests a number of lines of research for both\ncategorical compositional vector space models of meaning and for recursive\nneural network models of compositionality.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 09:32:51 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Lewis", "Martha", ""]]}, {"id": "1901.10746", "submitter": "Louis Martin", "authors": "Louis Martin (FAIR, ALMAnaCH), Samuel Humeau (FAIR), Pierre-Emmanuel\n  Mazar\\'e (FAIR), Antoine Bordes (FAIR), \\'Eric Villemonte de La Clergerie\n  (ALMAnaCH), Beno\\^it Sagot (ALMAnaCH)", "title": "Reference-less Quality Estimation of Text Simplification Systems", "comments": null, "journal-ref": "1st Workshop on Automatic Text Adaptation (ATA), Nov 2018,\n  Tilburg, Netherlands. https://www.ida.liu.se/~evere22/ATA-18/", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evaluation of text simplification (TS) systems remains an open challenge.\nAs the task has common points with machine translation (MT), TS is often\nevaluated using MT metrics such as BLEU. However, such metrics require high\nquality reference data, which is rarely available for TS. TS has the advantage\nover MT of being a monolingual task, which allows for direct comparisons to be\nmade between the simplified text and its original version. In this paper, we\ncompare multiple approaches to reference-less quality estimation of\nsentence-level text simplification systems, based on the dataset used for the\nQATS 2016 shared task. We distinguish three different dimensions:\ngram-maticality, meaning preservation and simplicity. We show that n-gram-based\nMT metrics such as BLEU and METEOR correlate the most with human judgment of\ngrammaticality and meaning preservation, whereas simplicity is best evaluated\nby basic length-based metrics.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 10:21:04 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Martin", "Louis", "", "FAIR, ALMAnaCH"], ["Humeau", "Samuel", "", "FAIR"], ["Mazar\u00e9", "Pierre-Emmanuel", "", "FAIR"], ["Bordes", "Antoine", "", "FAIR"], ["de La Clergerie", "\u00c9ric Villemonte", "", "ALMAnaCH"], ["Sagot", "Beno\u00eet", "", "ALMAnaCH"]]}, {"id": "1901.10787", "submitter": "Valentin Khrulkov", "authors": "Oleksii Hrinchuk, Valentin Khrulkov, Leyla Mirvakhabova, Elena Orlova,\n  Ivan Oseledets", "title": "Tensorized Embedding Layers for Efficient Model Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The embedding layers transforming input words into real vectors are the key\ncomponents of deep neural networks used in natural language processing.\nHowever, when the vocabulary is large, the corresponding weight matrices can be\nenormous, which precludes their deployment in a limited resource setting. We\nintroduce a novel way of parametrizing embedding layers based on the Tensor\nTrain (TT) decomposition, which allows compressing the model significantly at\nthe cost of a negligible drop or even a slight gain in performance. We evaluate\nour method on a wide range of benchmarks in natural language processing and\nanalyze the trade-off between performance and compression ratios for a wide\nrange of architectures, from MLPs to LSTMs and Transformers.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 12:43:50 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 07:23:21 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Hrinchuk", "Oleksii", ""], ["Khrulkov", "Valentin", ""], ["Mirvakhabova", "Leyla", ""], ["Orlova", "Elena", ""], ["Oseledets", "Ivan", ""]]}, {"id": "1901.10826", "submitter": "David Mac\\^edo", "authors": "Jo\\~ao Ant\\^onio Chagas Nunes, David Mac\\^edo, Cleber Zanchettin", "title": "Additive Margin SincNet for Speaker Recognition", "comments": null, "journal-ref": "2019 International Joint Conference on Neural Networks (IJCNN)", "doi": "10.1109/IJCNN.2019.8852112", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.NE cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker Recognition is a challenging task with essential applications such as\nauthentication, automation, and security. The SincNet is a new deep learning\nbased model which has produced promising results to tackle the mentioned task.\nTo train deep learning systems, the loss function is essential to the network\nperformance. The Softmax loss function is a widely used function in deep\nlearning methods, but it is not the best choice for all kind of problems. For\ndistance-based problems, one new Softmax based loss function called Additive\nMargin Softmax (AM-Softmax) is proving to be a better choice than the\ntraditional Softmax. The AM-Softmax introduces a margin of separation between\nthe classes that forces the samples from the same class to be closer to each\nother and also maximizes the distance between classes. In this paper, we\npropose a new approach for speaker recognition systems called AM-SincNet, which\nis based on the SincNet but uses an improved AM-Softmax layer. The proposed\nmethod is evaluated in the TIMIT dataset and obtained an improvement of\napproximately 40% in the Frame Error Rate compared to SincNet.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 16:16:34 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Nunes", "Jo\u00e3o Ant\u00f4nio Chagas", ""], ["Mac\u00eado", "David", ""], ["Zanchettin", "Cleber", ""]]}, {"id": "1901.10879", "submitter": "Junlang Zhan", "authors": "Junlang Zhan and Hai Zhao", "title": "Span Model for Open Information Extraction on Accurate Corpus", "comments": "this paper has been accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open information extraction (Open IE) is a challenging task especially due to\nits brittle data basis. Most of Open IE systems have to be trained on\nautomatically built corpus and evaluated on inaccurate test set. In this work,\nwe first alleviate this difficulty from both sides of training and test sets.\nFor the former, we propose an improved model design to more sufficiently\nexploit training dataset. For the latter, we present our accurately\nre-annotated benchmark test set (Re-OIE6) according to a series of linguistic\nobservation and analysis. Then, we introduce a span model instead of previous\nadopted sequence labeling formulization for n-ary Open IE. Our newly introduced\nmodel achieves new state-of-the-art performance on both benchmark evaluation\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 15:04:16 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 15:40:33 GMT"}, {"version": "v3", "created": "Wed, 4 Sep 2019 07:02:32 GMT"}, {"version": "v4", "created": "Mon, 18 Nov 2019 02:38:52 GMT"}, {"version": "v5", "created": "Tue, 19 Nov 2019 07:43:13 GMT"}, {"version": "v6", "created": "Thu, 21 Nov 2019 08:24:07 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Zhan", "Junlang", ""], ["Zhao", "Hai", ""]]}, {"id": "1901.11117", "submitter": "David So", "authors": "David R. So and Chen Liang and Quoc V. Le", "title": "The Evolved Transformer", "comments": "ICML version with SOTA results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent works have highlighted the strength of the Transformer architecture on\nsequence tasks while, at the same time, neural architecture search (NAS) has\nbegun to outperform human-designed models. Our goal is to apply NAS to search\nfor a better alternative to the Transformer. We first construct a large search\nspace inspired by the recent advances in feed-forward sequence models and then\nrun evolutionary architecture search with warm starting by seeding our initial\npopulation with the Transformer. To directly search on the computationally\nexpensive WMT 2014 English-German translation task, we develop the Progressive\nDynamic Hurdles method, which allows us to dynamically allocate more resources\nto more promising candidate models. The architecture found in our experiments\n-- the Evolved Transformer -- demonstrates consistent improvement over the\nTransformer on four well-established language tasks: WMT 2014 English-German,\nWMT 2014 English-French, WMT 2014 English-Czech and LM1B. At a big model size,\nthe Evolved Transformer establishes a new state-of-the-art BLEU score of 29.8\non WMT'14 English-German; at smaller sizes, it achieves the same quality as the\noriginal \"big\" Transformer with 37.6% less parameters and outperforms the\nTransformer by 0.7 BLEU at a mobile-friendly model size of 7M parameters.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 22:03:01 GMT"}, {"version": "v2", "created": "Wed, 6 Feb 2019 21:35:28 GMT"}, {"version": "v3", "created": "Fri, 15 Feb 2019 22:23:12 GMT"}, {"version": "v4", "created": "Fri, 17 May 2019 19:47:49 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["So", "David R.", ""], ["Liang", "Chen", ""], ["Le", "Quoc V.", ""]]}, {"id": "1901.11167", "submitter": "Lipeng Zhang", "authors": "Lipeng Zhang, Peng Zhang, Xindian Ma, Shuqin Gu, Zhan Su, Dawei Song", "title": "A Generalized Language Model in Tensor Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the literature, tensors have been effectively used for capturing the\ncontext information in language models. However, the existing methods usually\nadopt relatively-low order tensors, which have limited expressive power in\nmodeling language. Developing a higher-order tensor representation is\nchallenging, in terms of deriving an effective solution and showing its\ngenerality. In this paper, we propose a language model named Tensor Space\nLanguage Model (TSLM), by utilizing tensor networks and tensor decomposition.\nIn TSLM, we build a high-dimensional semantic space constructed by the tensor\nproduct of word vectors. Theoretically, we prove that such tensor\nrepresentation is a generalization of the n-gram language model. We further\nshow that this high-order tensor representation can be decomposed to a\nrecursive calculation of conditional probability for language modeling. The\nexperimental results on Penn Tree Bank (PTB) dataset and WikiText benchmark\ndemonstrate the effectiveness of TSLM.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 01:46:35 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Zhang", "Lipeng", ""], ["Zhang", "Peng", ""], ["Ma", "Xindian", ""], ["Gu", "Shuqin", ""], ["Su", "Zhan", ""], ["Song", "Dawei", ""]]}, {"id": "1901.11196", "submitter": "Jason Wei", "authors": "Jason Wei and Kai Zou", "title": "EDA: Easy Data Augmentation Techniques for Boosting Performance on Text\n  Classification Tasks", "comments": "EMNLP-IJCNLP 2019 short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present EDA: easy data augmentation techniques for boosting performance on\ntext classification tasks. EDA consists of four simple but powerful operations:\nsynonym replacement, random insertion, random swap, and random deletion. On\nfive text classification tasks, we show that EDA improves performance for both\nconvolutional and recurrent neural networks. EDA demonstrates particularly\nstrong results for smaller datasets; on average, across five datasets, training\nwith EDA while using only 50% of the available training set achieved the same\naccuracy as normal training with all available data. We also performed\nextensive ablation studies and suggest parameters for practical use.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 03:20:52 GMT"}, {"version": "v2", "created": "Sun, 25 Aug 2019 23:11:07 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Wei", "Jason", ""], ["Zou", "Kai", ""]]}, {"id": "1901.11281", "submitter": "Vincent Labatut", "authors": "Etienne Papegnies (LIA), Vincent Labatut (LIA), Richard Dufour (LIA),\n  Georges Linares (LIA)", "title": "Conversational Networks for Automatic Online Moderation", "comments": null, "journal-ref": "IEEE Transactions on Computational Social Systems, 2019,\n  https://ieeexplore.ieee.org/document/8629298", "doi": "10.1109/tcss.2018.2887240", "report-no": null, "categories": "cs.IR cs.CL cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Moderation of user-generated content in an online community is a challenge\nthat has great socio-economical ramifications. However, the costs incurred by\ndelegating this work to human agents are high. For this reason, an automatic\nsystem able to detect abuse in user-generated content is of great interest.\nThere are a number of ways to tackle this problem, but the most commonly seen\nin practice are word filtering or regular expression matching. The main\nlimitations are their vulnerability to intentional obfuscation on the part of\nthe users, and their context-insensitive nature. Moreover, they are\nlanguage-dependent and may require appropriate corpora for training. In this\npaper, we propose a system for automatic abuse detection that completely\ndisregards message content. We first extract a conversational network from raw\nchat logs and characterize it through topological measures. We then use these\nas features to train a classifier on our abuse detection task. We thoroughly\nassess our system on a dataset of user comments originating from a French\nMassively Multiplayer Online Game. We identify the most appropriate network\nextraction parameters and discuss the discriminative power of our features,\nrelatively to their topological and temporal nature. Our method reaches an\nF-measure of 83.89 when using the full feature set, improving on existing\napproaches. With a selection of the most discriminative features, we\ndramatically cut computing time while retaining most of the performance\n(82.65).\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 09:23:57 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Papegnies", "Etienne", "", "LIA"], ["Labatut", "Vincent", "", "LIA"], ["Dufour", "Richard", "", "LIA"], ["Linares", "Georges", "", "LIA"]]}, {"id": "1901.11333", "submitter": "Zhijing Jin", "authors": "Zhijing Jin, Di Jin, Jonas Mueller, Nicholas Matthews, Enrico Santus", "title": "IMaT: Unsupervised Text Attribute Transfer via Iterative Matching and\n  Translation", "comments": "EMNLP 2019 (Long Paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Text attribute transfer aims to automatically rewrite sentences such that\nthey possess certain linguistic attributes, while simultaneously preserving\ntheir semantic content. This task remains challenging due to a lack of\nsupervised parallel data. Existing approaches try to explicitly disentangle\ncontent and attribute information, but this is difficult and often results in\npoor content-preservation and ungrammaticality. In contrast, we propose a\nsimpler approach, Iterative Matching and Translation (IMaT), which: (1)\nconstructs a pseudo-parallel corpus by aligning a subset of semantically\nsimilar sentences from the source and the target corpora; (2) applies a\nstandard sequence-to-sequence model to learn the attribute transfer; (3)\niteratively improves the learned transfer function by refining imperfections in\nthe alignment. In sentiment modification and formality transfer tasks, our\nmethod outperforms complex state-of-the-art systems by a large margin. As an\nauxiliary contribution, we produce a publicly-available test set with\nhuman-generated transfer references.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 12:41:57 GMT"}, {"version": "v2", "created": "Sun, 18 Aug 2019 05:53:24 GMT"}, {"version": "v3", "created": "Wed, 4 Sep 2019 05:18:44 GMT"}, {"version": "v4", "created": "Fri, 24 Jan 2020 05:12:45 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Jin", "Zhijing", ""], ["Jin", "Di", ""], ["Mueller", "Jonas", ""], ["Matthews", "Nicholas", ""], ["Santus", "Enrico", ""]]}, {"id": "1901.11344", "submitter": "Ya Li", "authors": "Ya Li, Xinyu Liu, Dan Liu, Xueqiang Zhang, Junhua Liu", "title": "Learning Efficient Lexically-Constrained Neural Machine Translation with\n  External Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years has witnessed dramatic progress of neural machine translation\n(NMT), however, the method of manually guiding the translation procedure\nremains to be better explored. Previous works proposed to handle such problem\nthrough lexcially-constrained beam search in the decoding phase. Unfortunately,\nthese lexically-constrained beam search methods suffer two fatal disadvantages:\nhigh computational complexity and hard beam search which generates unexpected\ntranslations. In this paper, we propose to learn the ability of\nlexically-constrained translation with external memory, which can overcome the\nabove mentioned disadvantages. For the training process, automatically\nextracted phrase pairs are extracted from alignment and sentence parsing, then\nfurther be encoded into an external memory. This memory is then used to provide\nlexically-constrained information for training through a memory-attention\nmachanism. Various experiments are conducted on WMT Chinese to English and\nEnglish to German tasks. All the results can demonstrate the effectiveness of\nour method.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 13:26:28 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Li", "Ya", ""], ["Liu", "Xinyu", ""], ["Liu", "Dan", ""], ["Zhang", "Xueqiang", ""], ["Liu", "Junhua", ""]]}, {"id": "1901.11359", "submitter": "Thomas Zenkel", "authors": "Thomas Zenkel, Joern Wuebker, John DeNero", "title": "Adding Interpretable Attention to Neural Translation Models Improves\n  Word Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-layer models with multiple attention heads per layer provide superior\ntranslation quality compared to simpler and shallower models, but determining\nwhat source context is most relevant to each target word is more challenging as\na result. Therefore, deriving high-accuracy word alignments from the\nactivations of a state-of-the-art neural machine translation model is an open\nchallenge. We propose a simple model extension to the Transformer architecture\nthat makes use of its hidden representations and is restricted to attend solely\non encoder information to predict the next word. It can be trained on bilingual\ndata without word-alignment information. We further introduce a novel alignment\ninference procedure which applies stochastic gradient descent to directly\noptimize the attention activations towards a given target word. The resulting\nalignments dramatically outperform the naive approach to interpreting\nTransformer attention activations, and are comparable to Giza++ on two publicly\navailable data sets.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 14:05:02 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Zenkel", "Thomas", ""], ["Wuebker", "Joern", ""], ["DeNero", "John", ""]]}, {"id": "1901.11373", "submitter": "Dani Yogatama", "authors": "Dani Yogatama, Cyprien de Masson d'Autume, Jerome Connor, Tomas\n  Kocisky, Mike Chrzanowski, Lingpeng Kong, Angeliki Lazaridou, Wang Ling, Lei\n  Yu, Chris Dyer, Phil Blunsom", "title": "Learning and Evaluating General Linguistic Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define general linguistic intelligence as the ability to reuse previously\nacquired knowledge about a language's lexicon, syntax, semantics, and pragmatic\nconventions to adapt to new tasks quickly. Using this definition, we analyze\nstate-of-the-art natural language understanding models and conduct an extensive\nempirical investigation to evaluate them against these criteria through a\nseries of experiments that assess the task-independence of the knowledge being\nacquired by the learning process. In addition to task performance, we propose a\nnew evaluation metric based on an online encoding of the test data that\nquantifies how quickly an existing agent (model) learns a new task. Our results\nshow that while the field has made impressive progress in terms of model\narchitectures that generalize to many tasks, these models still require a lot\nof in-domain training examples (e.g., for fine tuning, training task-specific\nmodules), and are prone to catastrophic forgetting. Moreover, we find that far\nfrom solving general tasks (e.g., document question answering), our models are\noverfitting to the quirks of particular datasets (e.g., SQuAD). We discuss\nmissing components and conjecture on how to make progress toward general\nlinguistic intelligence.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 14:29:35 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Yogatama", "Dani", ""], ["d'Autume", "Cyprien de Masson", ""], ["Connor", "Jerome", ""], ["Kocisky", "Tomas", ""], ["Chrzanowski", "Mike", ""], ["Kong", "Lingpeng", ""], ["Lazaridou", "Angeliki", ""], ["Ling", "Wang", ""], ["Yu", "Lei", ""], ["Dyer", "Chris", ""], ["Blunsom", "Phil", ""]]}, {"id": "1901.11429", "submitter": "Venkata Subrahmanyan Govindarajan", "authors": "Venkata Subrahmanyan Govindarajan, Benjamin Van Durme, Aaron Steven\n  White", "title": "Decomposing Generalization: Models of Generic, Habitual, and Episodic\n  Statements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel semantic framework for modeling linguistic expressions of\ngeneralization---generic, habitual, and episodic statements---as combinations\nof simple, real-valued referential properties of predicates and their\narguments. We use this framework to construct a dataset covering the entirety\nof the Universal Dependencies English Web Treebank. We use this dataset to\nprobe the efficacy of type-level and token-level information---including\nhand-engineered features and static (GloVe) and contextual (ELMo) word\nembeddings---for predicting expressions of generalization. Data and code are\navailable at decomp.io.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 15:30:37 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 17:25:35 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Govindarajan", "Venkata Subrahmanyan", ""], ["Van Durme", "Benjamin", ""], ["White", "Aaron Steven", ""]]}, {"id": "1901.11462", "submitter": "Gerasimos Spanakis", "authors": "Raffaele Piccini, Gerasimos Spanakis", "title": "Exploring the context of recurrent neural network based conversational\n  agents", "comments": "Accepted at ICAART 2019, 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational agents have begun to rise both in the academic (in terms of\nresearch) and commercial (in terms of applications) world. This paper\ninvestigates the task of building a non-goal driven conversational agent, using\nneural network generative models and analyzes how the conversation context is\nhandled. It compares a simpler Encoder-Decoder with a Hierarchical Recurrent\nEncoder-Decoder architecture, which includes an additional module to model the\ncontext of the conversation using previous utterances information. We found\nthat the hierarchical model was able to extract relevant context information\nand include them in the generation of the output. However, it performed worse\n(35-40%) than the simple Encoder-Decoder model regarding both grammatically\ncorrect output and meaningful response. Despite these results, experiments\ndemonstrate how conversations about similar topics appear close to each other\nin the context space due to the increased frequency of specific topic-related\nwords, thus leaving promising directions for future research and how the\ncontext of a conversation can be exploited.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 16:40:26 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Piccini", "Raffaele", ""], ["Spanakis", "Gerasimos", ""]]}, {"id": "1901.11467", "submitter": "Gerasimos Spanakis", "authors": "Wouter Leeftink, Gerasimos Spanakis", "title": "Towards Controlled Transformation of Sentiment in Sentences", "comments": "Accepted at ICAART 2019, 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An obstacle to the development of many natural language processing products\nis the vast amount of training examples necessary to get satisfactory results.\nThe generation of these examples is often a tedious and time-consuming task.\nThis paper this paper proposes a method to transform the sentiment of sentences\nin order to limit the work necessary to generate more training data. This means\nthat one sentence can be transformed to an opposite sentiment sentence and\nshould reduce by half the work required in the generation of text. The proposed\npipeline consists of a sentiment classifier with an attention mechanism to\nhighlight the short phrases that determine the sentiment of a sentence. Then,\nthese phrases are changed to phrases of the opposite sentiment using a baseline\nmodel and an autoencoder approach. Experiments are run on both the separate\nparts of the pipeline as well as on the end-to-end model. The sentiment\nclassifier is tested on its accuracy and is found to perform adequately. The\nautoencoder is tested on how well it is able to change the sentiment of an\nencoded phrase and it was found that such a task is possible. We use human\nevaluation to judge the performance of the full (end-to-end) pipeline and that\nreveals that a model using word vectors outperforms the encoder model.\nNumerical evaluation shows that a success rate of 54.7% is achieved on the\nsentiment change.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 16:51:49 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Leeftink", "Wouter", ""], ["Spanakis", "Gerasimos", ""]]}, {"id": "1901.11492", "submitter": "Quanshi Zhang", "authors": "Kushal Chawla, Kundan Krishna, Balaji Vasan Srinivasan", "title": "Improving generation quality of pointer networks via guided attention", "comments": "In AAAI-19 Workshop on Network Interpretability for Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pointer generator networks have been used successfully for abstractive\nsummarization. Along with the capability to generate novel words, it also\nallows the model to copy from the input text to handle out-of-vocabulary words.\nIn this paper, we point out two key shortcomings of the summaries generated\nwith this framework via manual inspection, statistical analysis and human\nevaluation. The first shortcoming is the extractive nature of the generated\nsummaries, since the network eventually learns to copy from the input article\nmost of the times, affecting the abstractive nature of the generated summaries.\nThe second shortcoming is the factual inaccuracies in the generated text\ndespite grammatical correctness. Our analysis indicates that this arises due to\nincorrect attention transition between different parts of the article. We\npropose an initial attempt towards addressing both these shortcomings by\nexternally appending traditional linguistic information parsed from the input\ntext, thereby teaching networks on the structure of the underlying text.\nResults indicate feasibility and potential of such additional cues for improved\ngeneration.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2019 18:50:58 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Chawla", "Kushal", ""], ["Krishna", "Kundan", ""], ["Srinivasan", "Balaji Vasan", ""]]}, {"id": "1901.11504", "submitter": "Xiaodong Liu", "authors": "Xiaodong Liu, Pengcheng He, Weizhu Chen and Jianfeng Gao", "title": "Multi-Task Deep Neural Networks for Natural Language Understanding", "comments": "10 pages, 2 figures and 5 tables; Accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a Multi-Task Deep Neural Network (MT-DNN) for\nlearning representations across multiple natural language understanding (NLU)\ntasks. MT-DNN not only leverages large amounts of cross-task data, but also\nbenefits from a regularization effect that leads to more general\nrepresentations in order to adapt to new tasks and domains. MT-DNN extends the\nmodel proposed in Liu et al. (2015) by incorporating a pre-trained\nbidirectional transformer language model, known as BERT (Devlin et al., 2018).\nMT-DNN obtains new state-of-the-art results on ten NLU tasks, including SNLI,\nSciTail, and eight out of nine GLUE tasks, pushing the GLUE benchmark to 82.7%\n(2.2% absolute improvement). We also demonstrate using the SNLI and SciTail\ndatasets that the representations learned by MT-DNN allow domain adaptation\nwith substantially fewer in-domain labels than the pre-trained BERT\nrepresentations. The code and pre-trained models are publicly available at\nhttps://github.com/namisan/mt-dnn.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 18:07:25 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 00:01:20 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Liu", "Xiaodong", ""], ["He", "Pengcheng", ""], ["Chen", "Weizhu", ""], ["Gao", "Jianfeng", ""]]}, {"id": "1901.11528", "submitter": "Kory W Mathewson", "authors": "Kory W. Mathewson, Pablo Samuel Castro, Colin Cherry, George Foster,\n  Marc G. Bellemare", "title": "Shaping the Narrative Arc: An Information-Theoretic Approach to\n  Collaborative Dialogue", "comments": "20 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We consider the problem of designing an artificial agent capable of\ninteracting with humans in collaborative dialogue to produce creative, engaging\nnarratives. In this task, the goal is to establish universe details, and to\ncollaborate on an interesting story in that universe, through a series of\nnatural dialogue exchanges. Our model can augment any probabilistic\nconversational agent by allowing it to reason about universe information\nestablished and what potential next utterances might reveal. Ideally, with each\nutterance, agents would reveal just enough information to add specificity and\nreduce ambiguity without limiting the conversation. We empirically show that\nour model allows control over the rate at which the agent reveals information\nand that doing so significantly improves accuracy in predicting the next line\nof dialogues from movies. We close with a case-study with four professional\ntheatre performers, who preferred interactions with our model-augmented agent\nover an unaugmented agent.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 18:48:19 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Mathewson", "Kory W.", ""], ["Castro", "Pablo Samuel", ""], ["Cherry", "Colin", ""], ["Foster", "George", ""], ["Bellemare", "Marc G.", ""]]}]