[{"id": "1703.00050", "submitter": "Manolis Savva", "authors": "Angel X. Chang, Mihail Eric, Manolis Savva, Christopher D. Manning", "title": "SceneSeer: 3D Scene Design with Natural Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing 3D scenes is currently a creative task that requires significant\nexpertise and effort in using complex 3D design interfaces. This effortful\ndesign process starts in stark contrast to the easiness with which people can\nuse language to describe real and imaginary environments. We present SceneSeer:\nan interactive text to 3D scene generation system that allows a user to design\n3D scenes using natural language. A user provides input text from which we\nextract explicit constraints on the objects that should appear in the scene.\nGiven these explicit constraints, the system then uses a spatial knowledge base\nlearned from an existing database of 3D scenes and 3D object models to infer an\narrangement of the objects forming a natural scene matching the input\ndescription. Using textual commands the user can then iteratively refine the\ncreated scene by adding, removing, replacing, and manipulating objects. We\nevaluate the quality of 3D scenes generated by SceneSeer in a perceptual\nevaluation experiment where we compare against manually designed scenes and\nsimpler baselines for 3D scene generation. We demonstrate how the generated\nscenes can be iteratively refined through simple natural language commands.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 20:47:47 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Chang", "Angel X.", ""], ["Eric", "Mihail", ""], ["Savva", "Manolis", ""], ["Manning", "Christopher D.", ""]]}, {"id": "1703.00089", "submitter": "Fan Zhang", "authors": "Fan Zhang, Diane Litman", "title": "A Joint Identification Approach for Argumentative Writing Revisions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior work on revision identification typically uses a pipeline method:\nrevision extraction is first conducted to identify the locations of revisions\nand revision classification is then conducted on the identified revisions. Such\na setting propagates the errors of the revision extraction step to the revision\nclassification step. This paper proposes an approach that identifies the\nrevision location and the revision type jointly to solve the issue of error\npropagation. It utilizes a sequence representation of revisions and conducts\nsequence labeling for revision identification. A mutation-based approach is\nutilized to update identification sequences. Results demonstrate that our\nproposed approach yields better performance on both revision location\nextraction and revision type classification compared to a pipeline baseline.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 23:54:57 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Zhang", "Fan", ""], ["Litman", "Diane", ""]]}, {"id": "1703.00096", "submitter": "Zhenyao Zhu", "authors": "Hairong Liu, Zhenyao Zhu, Xiangang Li, Sanjeev Satheesh", "title": "Gram-CTC: Automatic Unit Selection and Target Decomposition for Sequence\n  Labelling", "comments": "Published at ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing sequence labelling models rely on a fixed decomposition of a\ntarget sequence into a sequence of basic units. These methods suffer from two\nmajor drawbacks: 1) the set of basic units is fixed, such as the set of words,\ncharacters or phonemes in speech recognition, and 2) the decomposition of\ntarget sequences is fixed. These drawbacks usually result in sub-optimal\nperformance of modeling sequences. In this pa- per, we extend the popular CTC\nloss criterion to alleviate these limitations, and propose a new loss function\ncalled Gram-CTC. While preserving the advantages of CTC, Gram-CTC automatically\nlearns the best set of basic units (grams), as well as the most suitable\ndecomposition of tar- get sequences. Unlike CTC, Gram-CTC allows the model to\noutput variable number of characters at each time step, which enables the model\nto capture longer term dependency and improves the computational efficiency. We\ndemonstrate that the proposed Gram-CTC improves CTC in terms of both\nperformance and efficiency on the large vocabulary speech recognition task at\nmultiple scales of data, and that with Gram-CTC we can outperform the\nstate-of-the-art on a standard speech benchmark.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 00:59:17 GMT"}, {"version": "v2", "created": "Sat, 12 Aug 2017 00:02:26 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Liu", "Hairong", ""], ["Zhu", "Zhenyao", ""], ["Li", "Xiangang", ""], ["Satheesh", "Sanjeev", ""]]}, {"id": "1703.00099", "submitter": "Zhou Yu", "authors": "Zhou Yu, Alan W Black and Alexander I. Rudnicky", "title": "Learning Conversational Systems that Interleave Task and Non-Task\n  Content", "comments": "Dialog Systems, Reinforcement Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task-oriented dialog systems have been applied in various tasks, such as\nautomated personal assistants, customer service providers and tutors. These\nsystems work well when users have clear and explicit intentions that are\nwell-aligned to the systems' capabilities. However, they fail if users\nintentions are not explicit. To address this shortcoming, we propose a\nframework to interleave non-task content (i.e. everyday social conversation)\ninto task conversations. When the task content fails, the system can still keep\nthe user engaged with the non-task content. We trained a policy using\nreinforcement learning algorithms to promote long-turn conversation coherence\nand consistency, so that the system can have smooth transitions between task\nand non-task content. To test the effectiveness of the proposed framework, we\ndeveloped a movie promotion dialog system. Experiments with human users\nindicate that a system that interleaves social and task content achieves a\nbetter task success rate and is also rated as more engaging compared to a pure\ntask-oriented system.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 01:27:32 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Yu", "Zhou", ""], ["Black", "Alan W", ""], ["Rudnicky", "Alexander I.", ""]]}, {"id": "1703.00203", "submitter": "Quentin Feltgen", "authors": "Quentin Feltgen, Benjamin Fagard and Jean-Pierre Nadal", "title": "Frequency patterns of semantic change: Corpus-based evidence of a\n  near-critical dynamics in language change", "comments": null, "journal-ref": "R. Soc. open sci. 2017 4 170830; DOI: 10.1098/rsos.170830.\n  Published 8 November 2017", "doi": "10.1098/rsos.170830", "report-no": null, "categories": "physics.soc-ph cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is generally believed that, when a linguistic item acquires a new meaning,\nits overall frequency of use in the language rises with time with an S-shaped\ngrowth curve. Yet, this claim has only been supported by a limited number of\ncase studies. In this paper, we provide the first corpus-based quantitative\nconfirmation of the genericity of the S-curve in language change. Moreover, we\nuncover another generic pattern, a latency phase of variable duration preceding\nthe S-growth, during which the frequency of use of the semantically expanding\nword remains low and more or less constant. We also propose a usage-based model\nof language change supported by cognitive considerations, which predicts that\nboth phases, the latency and the fast S-growth, take place. The driving\nmechanism is a stochastic dynamics, a random walk in the space of frequency of\nuse. The underlying deterministic dynamics highlights the role of a control\nparameter, the strength of the cognitive impetus governing the onset of change,\nwhich tunes the system at the vicinity of a saddle-node bifurcation. In the\nneighborhood of the critical point, the latency phase corresponds to the\ndiffusion time over the critical region, and the S-growth to the fast\nconvergence that follows. The duration of the two phases is computed as\nspecific first passage times of the random walk process, leading to\ndistributions that fit well the ones extracted from our dataset. We argue that\nour results are not specific to the studied corpus, but apply to semantic\nchange in general.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 10:02:04 GMT"}, {"version": "v2", "created": "Fri, 3 Mar 2017 15:33:07 GMT"}, {"version": "v3", "created": "Thu, 30 Nov 2017 21:07:54 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Feltgen", "Quentin", ""], ["Fagard", "Benjamin", ""], ["Nadal", "Jean-Pierre", ""]]}, {"id": "1703.00317", "submitter": "Ceyda Sanli", "authors": "Ceyda Sanli, Anupam Mondal, Erik Cambria", "title": "Tracing Linguistic Relations in Winning and Losing Sides of Explicit\n  Opposing Groups", "comments": "Full paper, Proceedings of FLAIRS-2017 (30th Florida Artificial\n  Intelligence Research Society), Special Track, Artificial Intelligence for\n  Big Social Data Analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linguistic relations in oral conversations present how opinions are\nconstructed and developed in a restricted time. The relations bond ideas,\narguments, thoughts, and feelings, re-shape them during a speech, and finally\nbuild knowledge out of all information provided in the conversation. Speakers\nshare a common interest to discuss. It is expected that each speaker's reply\nincludes duplicated forms of words from previous speakers. However, linguistic\nadaptation is observed and evolves in a more complex path than just\ntransferring slightly modified versions of common concepts. A conversation\naiming a benefit at the end shows an emergent cooperation inducing the\nadaptation. Not only cooperation, but also competition drives the adaptation or\nan opposite scenario and one can capture the dynamic process by tracking how\nthe concepts are linguistically linked. To uncover salient complex dynamic\nevents in verbal communications, we attempt to discover self-organized\nlinguistic relations hidden in a conversation with explicitly stated winners\nand losers. We examine open access data of the United States Supreme Court. Our\nunderstanding is crucial in big data research to guide how transition states in\nopinion mining and decision-making should be modeled and how this required\nknowledge to guide the model should be pinpointed, by filtering large amount of\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 14:40:22 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Sanli", "Ceyda", ""], ["Mondal", "Anupam", ""], ["Cambria", "Erik", ""]]}, {"id": "1703.00538", "submitter": "Jinying Chen", "authors": "Jinying Chen and Hong Yu", "title": "Unsupervised Ensemble Ranking of Terms in Electronic Health Record Notes\n  Based on Their Importance to Patients", "comments": null, "journal-ref": null, "doi": "10.1016/j.jbi.2017.02.016", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Electronic health record (EHR) notes contain abundant medical\njargon that can be difficult for patients to comprehend. One way to help\npatients is to reduce information overload and help them focus on medical terms\nthat matter most to them.\n  Objective: The aim of this work was to develop FIT (Finding Important Terms\nfor patients), an unsupervised natural language processing (NLP) system that\nranks medical terms in EHR notes based on their importance to patients.\n  Methods: We built FIT on a new unsupervised ensemble ranking model derived\nfrom the biased random walk algorithm to combine heterogeneous information\nresources for ranking candidate terms from each EHR note. Specifically, FIT\nintegrates four single views for term importance: patient use of medical\nconcepts, document-level term salience, word-occurrence based term relatedness,\nand topic coherence. It also incorporates partial information of term\nimportance as conveyed by terms' unfamiliarity levels and semantic types. We\nevaluated FIT on 90 expert-annotated EHR notes and compared it with three\nbenchmark unsupervised ensemble ranking methods.\n  Results: FIT achieved 0.885 AUC-ROC for ranking candidate terms from EHR\nnotes to identify important terms. When including term identification, the\nperformance of FIT for identifying important terms from EHR notes was 0.813\nAUC-ROC. It outperformed the three ensemble rankers for most metrics. Its\nperformance is relatively insensitive to its parameter.\n  Conclusions: FIT can automatically identify EHR terms important to patients\nand may help develop personalized interventions to improve quality of care. By\nusing unsupervised learning as well as a robust and flexible framework for\ninformation fusion, FIT can be readily applied to other domains and\napplications.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 22:37:02 GMT"}, {"version": "v2", "created": "Sat, 25 Mar 2017 21:34:10 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Chen", "Jinying", ""], ["Yu", "Hong", ""]]}, {"id": "1703.00565", "submitter": "Jason Kessler", "authors": "Jason S. Kessler", "title": "Scattertext: a Browser-Based Tool for Visualizing how Corpora Differ", "comments": "ACL 2017 Demos. 6 pages, 5 figures. See the Githup repo\n  https://github.com/JasonKessler/scattertext for source code and documentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scattertext is an open source tool for visualizing linguistic variation\nbetween document categories in a language-independent way. The tool presents a\nscatterplot, where each axis corresponds to the rank-frequency a term occurs in\na category of documents. Through a tie-breaking strategy, the tool is able to\ndisplay thousands of visible term-representing points and find space to legibly\nlabel hundreds of them. Scattertext also lends itself to a query-based\nvisualization of how the use of terms with similar embeddings differs between\ndocument categories, as well as a visualization for comparing the importance\nscores of bag-of-words features to univariate metrics.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 00:48:15 GMT"}, {"version": "v2", "created": "Mon, 6 Mar 2017 19:15:04 GMT"}, {"version": "v3", "created": "Thu, 20 Apr 2017 21:39:34 GMT"}], "update_date": "2017-04-24", "authors_parsed": [["Kessler", "Jason S.", ""]]}, {"id": "1703.00572", "submitter": "Zi Yang", "authors": "Rui Liu, Junjie Hu, Wei Wei, Zi Yang, Eric Nyberg", "title": "Structural Embedding of Syntactic Trees for Machine Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks for machine comprehension typically utilizes only word\nor character embeddings without explicitly taking advantage of structured\nlinguistic information such as constituency trees and dependency trees. In this\npaper, we propose structural embedding of syntactic trees (SEST), an algorithm\nframework to utilize structured information and encode them into vector\nrepresentations that can boost the performance of algorithms for the machine\ncomprehension. We evaluate our approach using a state-of-the-art neural\nattention model on the SQuAD dataset. Experimental results demonstrate that our\nmodel can accurately identify the syntactic boundaries of the sentences and\nextract answers that are syntactically coherent over the baseline methods.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 01:08:10 GMT"}, {"version": "v2", "created": "Thu, 20 Apr 2017 00:45:25 GMT"}, {"version": "v3", "created": "Thu, 31 Aug 2017 23:20:59 GMT"}], "update_date": "2017-09-04", "authors_parsed": [["Liu", "Rui", ""], ["Hu", "Junjie", ""], ["Wei", "Wei", ""], ["Yang", "Zi", ""], ["Nyberg", "Eric", ""]]}, {"id": "1703.00607", "submitter": "Zijun Yao", "authors": "Zijun Yao, Yifan Sun, Weicong Ding, Nikhil Rao, Hui Xiong", "title": "Dynamic Word Embeddings for Evolving Semantic Discovery", "comments": "9 pages, published in the International Conference on Web Search and\n  Data Mining (WSDM 2018)", "journal-ref": null, "doi": "10.1145/3159652.3159703", "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word evolution refers to the changing meanings and associations of words\nthroughout time, as a byproduct of human language evolution. By studying word\nevolution, we can infer social trends and language constructs over different\nperiods of human history. However, traditional techniques such as word\nrepresentation learning do not adequately capture the evolving language\nstructure and vocabulary. In this paper, we develop a dynamic statistical model\nto learn time-aware word vector representation. We propose a model that\nsimultaneously learns time-aware embeddings and solves the resulting \"alignment\nproblem\". This model is trained on a crawled NYTimes dataset. Additionally, we\ndevelop multiple intuitive evaluation strategies of temporal word embeddings.\nOur qualitative and quantitative tests indicate that our method not only\nreliably captures this evolution over time, but also consistently outperforms\nstate-of-the-art temporal embedding approaches on both semantic accuracy and\nalignment quality.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 03:59:18 GMT"}, {"version": "v2", "created": "Tue, 13 Feb 2018 17:10:42 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Yao", "Zijun", ""], ["Sun", "Yifan", ""], ["Ding", "Weicong", ""], ["Rao", "Nikhil", ""], ["Xiong", "Hui", ""]]}, {"id": "1703.00782", "submitter": "Shuming Ma", "authors": "Xu Sun and Shuming Ma", "title": "Lock-Free Parallel Perceptron for Graph-based Dependency Parsing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dependency parsing is an important NLP task. A popular approach for\ndependency parsing is structured perceptron. Still, graph-based dependency\nparsing has the time complexity of $O(n^3)$, and it suffers from slow training.\nTo deal with this problem, we propose a parallel algorithm called parallel\nperceptron. The parallel algorithm can make full use of a multi-core computer\nwhich saves a lot of training time. Based on experiments we observe that\ndependency parsing with parallel perceptron can achieve 8-fold faster training\nspeed than traditional structured perceptron methods when using 10 threads, and\nwith no loss at all in accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 13:49:23 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Sun", "Xu", ""], ["Ma", "Shuming", ""]]}, {"id": "1703.00786", "submitter": "Shuming Ma", "authors": "Shuming Ma and Xu Sun", "title": "A Generic Online Parallel Learning Framework for Large Margin Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To speed up the training process, many existing systems use parallel\ntechnology for online learning algorithms. However, most research mainly focus\non stochastic gradient descent (SGD) instead of other algorithms. We propose a\ngeneric online parallel learning framework for large margin models, and also\nanalyze our framework on popular large margin algorithms, including MIRA and\nStructured Perceptron. Our framework is lock-free and easy to implement on\nexisting systems. Experiments show that systems with our framework can gain\nnear linear speed up by increasing running threads, and with no loss in\naccuracy.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 13:52:47 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Ma", "Shuming", ""], ["Sun", "Xu", ""]]}, {"id": "1703.00948", "submitter": "Preeti Bhargava", "authors": "Nemanja Spasojevic, Preeti Bhargava, Guoning Hu", "title": "DAWT: Densely Annotated Wikipedia Texts across multiple languages", "comments": "8 pages, 3 figures, 7 tables, WWW2017, WWW 2017 Companion proceedings", "journal-ref": null, "doi": "10.1145/3041021.3053367", "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we open up the DAWT dataset - Densely Annotated Wikipedia Texts\nacross multiple languages. The annotations include labeled text mentions\nmapping to entities (represented by their Freebase machine ids) as well as the\ntype of the entity. The data set contains total of 13.6M articles, 5.0B tokens,\n13.8M mention entity co-occurrences. DAWT contains 4.8 times more anchor text\nto entity links than originally present in the Wikipedia markup. Moreover, it\nspans several languages including English, Spanish, Italian, German, French and\nArabic. We also present the methodology used to generate the dataset which\nenriches Wikipedia markup in order to increase number of links. In addition to\nthe main dataset, we open up several derived datasets including mention entity\nco-occurrence counts and entity embeddings, as well as mappings between\nFreebase ids and Wikidata item ids. We also discuss two applications of these\ndatasets and hope that opening them up would prove useful for the Natural\nLanguage Processing and Information Retrieval communities, as well as\nfacilitate multi-lingual research.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 20:55:20 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Spasojevic", "Nemanja", ""], ["Bhargava", "Preeti", ""], ["Hu", "Guoning", ""]]}, {"id": "1703.00955", "submitter": "Zhiting Hu", "authors": "Zhiting Hu, Zichao Yang, Xiaodan Liang, Ruslan Salakhutdinov, Eric P.\n  Xing", "title": "Toward Controlled Generation of Text", "comments": "Code adapted for text style transfer is released at:\n  https://github.com/asyml/texar/tree/master/examples/text_style_transfer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generic generation and manipulation of text is challenging and has limited\nsuccess compared to recent deep generative modeling in visual domain. This\npaper aims at generating plausible natural language sentences, whose attributes\nare dynamically controlled by learning disentangled latent representations with\ndesignated semantics. We propose a new neural generative model which combines\nvariational auto-encoders and holistic attribute discriminators for effective\nimposition of semantic structures. With differentiable approximation to\ndiscrete text samples, explicit constraints on independent attribute controls,\nand efficient collaborative learning of generator and discriminators, our model\nlearns highly interpretable representations from even only word annotations,\nand produces realistic sentences with desired attributes. Quantitative\nevaluation validates the accuracy of sentence and attribute generation.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 21:23:47 GMT"}, {"version": "v2", "created": "Tue, 11 Jul 2017 21:15:43 GMT"}, {"version": "v3", "created": "Tue, 23 Jan 2018 08:01:18 GMT"}, {"version": "v4", "created": "Thu, 13 Sep 2018 02:16:40 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Hu", "Zhiting", ""], ["Yang", "Zichao", ""], ["Liang", "Xiaodan", ""], ["Salakhutdinov", "Ruslan", ""], ["Xing", "Eric P.", ""]]}, {"id": "1703.00993", "submitter": "Bhuwan Dhingra", "authors": "Bhuwan Dhingra, Hanxiao Liu, Ruslan Salakhutdinov, William W. Cohen", "title": "A Comparative Study of Word Embeddings for Reading Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The focus of past machine learning research for Reading Comprehension tasks\nhas been primarily on the design of novel deep learning architectures. Here we\nshow that seemingly minor choices made on (1) the use of pre-trained word\nembeddings, and (2) the representation of out-of-vocabulary tokens at test\ntime, can turn out to have a larger impact than architectural choices on the\nfinal performance. We systematically explore several options for these choices,\nand provide recommendations to researchers working in this area.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 23:58:54 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Dhingra", "Bhuwan", ""], ["Liu", "Hanxiao", ""], ["Salakhutdinov", "Ruslan", ""], ["Cohen", "William W.", ""]]}, {"id": "1703.01008", "submitter": "Xiujun Li", "authors": "Xiujun Li and Yun-Nung Chen and Lihong Li and Jianfeng Gao and Asli\n  Celikyilmaz", "title": "End-to-End Task-Completion Neural Dialogue Systems", "comments": "11 pages, IJCNLP 2017, arXiv admin note: substantial text overlap\n  with arXiv:1703.07055", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major drawbacks of modularized task-completion dialogue systems is\nthat each module is trained individually, which presents several challenges.\nFor example, downstream modules are affected by earlier modules, and the\nperformance of the entire system is not robust to the accumulated errors. This\npaper presents a novel end-to-end learning framework for task-completion\ndialogue systems to tackle such issues. Our neural dialogue system can directly\ninteract with a structured database to assist users in accessing information\nand accomplishing certain tasks. The reinforcement learning based dialogue\nmanager offers robust capabilities to handle noises caused by other components\nof the dialogue system. Our experiments in a movie-ticket booking domain show\nthat our end-to-end system not only outperforms modularized dialogue system\nbaselines for both objective and subjective evaluation, but also is robust to\nnoises as demonstrated by several systematic experiments with different error\ngranularity and rates specific to the language understanding module.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 01:29:11 GMT"}, {"version": "v2", "created": "Thu, 9 Mar 2017 05:50:21 GMT"}, {"version": "v3", "created": "Tue, 19 Sep 2017 17:47:23 GMT"}, {"version": "v4", "created": "Sun, 11 Feb 2018 23:19:21 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Li", "Xiujun", ""], ["Chen", "Yun-Nung", ""], ["Li", "Lihong", ""], ["Gao", "Jianfeng", ""], ["Celikyilmaz", "Asli", ""]]}, {"id": "1703.01024", "submitter": "Jun Zhang", "authors": "Xu Tian, Jun Zhang, Zejun Ma, Yi He, Juan Wei", "title": "Exponential Moving Average Model in Parallel Speech Recognition Training", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As training data rapid growth, large-scale parallel training with multi-GPUs\ncluster is widely applied in the neural network model learning currently.We\npresent a new approach that applies exponential moving average method in\nlarge-scale parallel training of neural network model. It is a non-interference\nstrategy that the exponential moving average model is not broadcasted to\ndistributed workers to update their local models after model synchronization in\nthe training process, and it is implemented as the final model of the training\nsystem. Fully-connected feed-forward neural networks (DNNs) and deep\nunidirectional Long short-term memory (LSTM) recurrent neural networks (RNNs)\nare successfully trained with proposed method for large vocabulary continuous\nspeech recognition on Shenma voice search data in Mandarin. The character error\nrate (CER) of Mandarin speech recognition further degrades than\nstate-of-the-art approaches of parallel training.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 03:14:28 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Tian", "Xu", ""], ["Zhang", "Jun", ""], ["Ma", "Zejun", ""], ["He", "Yi", ""], ["Wei", "Juan", ""]]}, {"id": "1703.01485", "submitter": "Sreelekha S", "authors": "Sreelekha S, Pushpak Bhattacharyya", "title": "Lexical Resources for Hindi Marathi MT", "comments": "9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe some ways to utilize various lexical resources to\nimprove the quality of statistical machine translation system. We have\naugmented the training corpus with various lexical resources such as\nIndoWordnet semantic relation set, function words, kridanta pairs and verb\nphrases etc. Our research on the usage of lexical resources mainly focused on\ntwo ways such as augmenting parallel corpus with more vocabulary and augmenting\nwith various word forms. We have described case studies, evaluations and\ndetailed error analysis for both Marathi to Hindi and Hindi to Marathi machine\ntranslation systems. From the evaluations we observed that, there is an\nincremental growth in the quality of machine translation as the usage of\nvarious lexical resources increases. Moreover usage of various lexical\nresources helps to improve the coverage and quality of machine translation\nwhere limited parallel corpus is available.\n", "versions": [{"version": "v1", "created": "Sat, 4 Mar 2017 15:55:01 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["S", "Sreelekha", ""], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "1703.01557", "submitter": "Lidong Bing", "authors": "Lidong Bing and William W. Cohen and Bhuwan Dhingra", "title": "Using Graphs of Classifiers to Impose Declarative Constraints on\n  Semi-supervised Learning", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general approach to modeling semi-supervised learning (SSL)\nalgorithms. Specifically, we present a declarative language for modeling both\ntraditional supervised classification tasks and many SSL heuristics, including\nboth well-known heuristics such as co-training and novel domain-specific\nheuristics. In addition to representing individual SSL heuristics, we show that\nmultiple heuristics can be automatically combined using Bayesian optimization\nmethods. We experiment with two classes of tasks, link-based text\nclassification and relation extraction. We show modest improvements on\nwell-studied link-based classification benchmarks, and state-of-the-art results\non relation-extraction tasks for two realistic domains.\n", "versions": [{"version": "v1", "created": "Sun, 5 Mar 2017 04:43:41 GMT"}, {"version": "v2", "created": "Thu, 23 Mar 2017 07:46:21 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Bing", "Lidong", ""], ["Cohen", "William W.", ""], ["Dhingra", "Bhuwan", ""]]}, {"id": "1703.01619", "submitter": "Graham Neubig", "authors": "Graham Neubig", "title": "Neural Machine Translation and Sequence-to-sequence Models: A Tutorial", "comments": "65 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This tutorial introduces a new and powerful set of techniques variously\ncalled \"neural machine translation\" or \"neural sequence-to-sequence models\".\nThese techniques have been used in a number of tasks regarding the handling of\nhuman language, and can be a powerful tool in the toolbox of anyone who wants\nto model sequential data of some sort. The tutorial assumes that the reader\nknows the basics of math and programming, but does not assume any particular\nexperience with neural networks or natural language processing. It attempts to\nexplain the intuition behind the various methods covered, then delves into them\nwith enough mathematical detail to understand them concretely, and culiminates\nwith a suggestion for an implementation exercise, where readers can test that\nthey understood the content in practice.\n", "versions": [{"version": "v1", "created": "Sun, 5 Mar 2017 16:10:11 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Neubig", "Graham", ""]]}, {"id": "1703.01671", "submitter": "Virgile Landeiro", "authors": "Virgile Landeiro, Aron Culotta", "title": "Controlling for Unobserved Confounds in Classification Using\n  Correlational Constraints", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As statistical classifiers become integrated into real-world applications, it\nis important to consider not only their accuracy but also their robustness to\nchanges in the data distribution. In this paper, we consider the case where\nthere is an unobserved confounding variable $z$ that influences both the\nfeatures $\\mathbf{x}$ and the class variable $y$. When the influence of $z$\nchanges from training to testing data, we find that the classifier accuracy can\ndegrade rapidly. In our approach, we assume that we can predict the value of\n$z$ at training time with some error. The prediction for $z$ is then fed to\nPearl's back-door adjustment to build our model. Because of the attenuation\nbias caused by measurement error in $z$, standard approaches to controlling for\n$z$ are ineffective. In response, we propose a method to properly control for\nthe influence of $z$ by first estimating its relationship with the class\nvariable $y$, then updating predictions for $z$ to match that estimated\nrelationship. By adjusting the influence of $z$, we show that we can build a\nmodel that exceeds competing baselines on accuracy as well as on robustness\nover a range of confounding relationships.\n", "versions": [{"version": "v1", "created": "Sun, 5 Mar 2017 21:57:25 GMT"}, {"version": "v2", "created": "Thu, 11 Jan 2018 15:35:43 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Landeiro", "Virgile", ""], ["Culotta", "Aron", ""]]}, {"id": "1703.01694", "submitter": "Stephan Meylan", "authors": "Stephan C. Meylan and Thomas L. Griffiths", "title": "Word forms - not just their lengths- are optimized for efficient\n  communication", "comments": "16 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inverse relationship between the length of a word and the frequency of\nits use, first identified by G.K. Zipf in 1935, is a classic empirical law that\nholds across a wide range of human languages. We demonstrate that length is one\naspect of a much more general property of words: how distinctive they are with\nrespect to other words in a language. Distinctiveness plays a critical role in\nrecognizing words in fluent speech, in that it reflects the strength of\npotential competitors when selecting the best candidate for an ambiguous\nsignal. Phonological information content, a measure of a word's string\nprobability under a statistical model of a language's sound or character\nsequences, concisely captures distinctiveness. Examining large-scale corpora\nfrom 13 languages, we find that distinctiveness significantly outperforms word\nlength as a predictor of frequency. This finding provides evidence that\nlisteners' processing constraints shape fine-grained aspects of word forms\nacross languages.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 00:38:51 GMT"}, {"version": "v2", "created": "Wed, 31 May 2017 18:40:08 GMT"}], "update_date": "2017-06-02", "authors_parsed": [["Meylan", "Stephan C.", ""], ["Griffiths", "Thomas L.", ""]]}, {"id": "1703.01720", "submitter": "Ashwin Vijayakumar", "authors": "Ashwin K Vijayakumar, Ramakrishna Vedantam, Devi Parikh", "title": "Sound-Word2Vec: Learning Word Representations Grounded in Sounds", "comments": "Accepted at EMNLP 2017. Contains 6 pages; 3 tables; 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To be able to interact better with humans, it is crucial for machines to\nunderstand sound - a primary modality of human perception. Previous works have\nused sound to learn embeddings for improved generic textual similarity\nassessment. In this work, we treat sound as a first-class citizen, studying\ndownstream textual tasks which require aural grounding. To this end, we propose\nsound-word2vec - a new embedding scheme that learns specialized word embeddings\ngrounded in sounds. For example, we learn that two seemingly (semantically)\nunrelated concepts, like leaves and paper are similar due to the similar\nrustling sounds they make. Our embeddings prove useful in textual tasks\nrequiring aural reasoning like text-based sound retrieval and discovering foley\nsound effects (used in movies). Moreover, our embedding space captures\ninteresting dependencies between words and onomatopoeia and outperforms prior\nwork on aurally-relevant word relatedness datasets such as AMEN and ASLex.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 04:30:12 GMT"}, {"version": "v2", "created": "Fri, 28 Apr 2017 06:35:16 GMT"}, {"version": "v3", "created": "Thu, 10 Aug 2017 04:26:57 GMT"}, {"version": "v4", "created": "Tue, 29 Aug 2017 15:54:31 GMT"}], "update_date": "2017-08-30", "authors_parsed": [["Vijayakumar", "Ashwin K", ""], ["Vedantam", "Ramakrishna", ""], ["Parikh", "Devi", ""]]}, {"id": "1703.01725", "submitter": "Jack Hessel", "authors": "Jack Hessel, Lillian Lee, David Mimno", "title": "Cats and Captions vs. Creators and the Clock: Comparing Multimodal\n  Content to Context in Predicting Relative Popularity", "comments": "10 pages, data and models available at\n  http://www.cs.cornell.edu/~jhessel/cats/cats.html, Proceedings of WWW 2017", "journal-ref": null, "doi": "10.1145/3038912.3052684", "report-no": null, "categories": "cs.SI cs.CL cs.CV physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The content of today's social media is becoming more and more rich,\nincreasingly mixing text, images, videos, and audio. It is an intriguing\nresearch question to model the interplay between these different modes in\nattracting user attention and engagement. But in order to pursue this study of\nmultimodal content, we must also account for context: timing effects, community\npreferences, and social factors (e.g., which authors are already popular) also\naffect the amount of feedback and reaction that social-media posts receive. In\nthis work, we separate out the influence of these non-content factors in\nseveral ways. First, we focus on ranking pairs of submissions posted to the\nsame community in quick succession, e.g., within 30 seconds, this framing\nencourages models to focus on time-agnostic and community-specific content\nfeatures. Within that setting, we determine the relative performance of author\nvs. content features. We find that victory usually belongs to \"cats and\ncaptions,\" as visual and textual features together tend to outperform\nidentity-based features. Moreover, our experiments show that when considered in\nisolation, simple unigram text features and deep neural network visual features\nyield the highest accuracy individually, and that the combination of the two\nmodalities generally leads to the best accuracies overall.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 04:56:19 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Hessel", "Jack", ""], ["Lee", "Lillian", ""], ["Mimno", "David", ""]]}, {"id": "1703.01726", "submitter": "Xiaogang Zhang", "authors": "Xiao-gang Zhang, Shou-qian Sun, Ke-jun Zhang", "title": "A Novel Comprehensive Approach for Estimating Concept Semantic\n  Similarity in WordNet", "comments": "11pages, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Computation of semantic similarity between concepts is an important\nfoundation for many research works. This paper focuses on IC computing methods\nand IC measures, which estimate the semantic similarities between concepts by\nexploiting the topological parameters of the taxonomy. Based on analyzing\nrepresentative IC computing methods and typical semantic similarity measures,\nwe propose a new hybrid IC computing method. Through adopting the parameter\ndhyp and lch, we utilize the new IC computing method and propose a novel\ncomprehensive measure of semantic similarity between concepts. An experiment\nbased on WordNet \"is a\" taxonomy has been designed to test representative\nmeasures and our measure on benchmark dataset R&G, and the results show that\nour measure can obviously improve the similarity accuracy. We evaluate the\nproposed approach by comparing the correlation coefficients between five\nmeasures and the artificial data. The results show that our proposal\noutperforms the previous measures.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 05:07:12 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Zhang", "Xiao-gang", ""], ["Sun", "Shou-qian", ""], ["Zhang", "Ke-jun", ""]]}, {"id": "1703.01898", "submitter": "Dani Yogatama", "authors": "Dani Yogatama, Chris Dyer, Wang Ling, Phil Blunsom", "title": "Generative and Discriminative Text Classification with Recurrent Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We empirically characterize the performance of discriminative and generative\nLSTM models for text classification. We find that although RNN-based generative\nmodels are more powerful than their bag-of-words ancestors (e.g., they account\nfor conditional dependencies across words in a document), they have higher\nasymptotic error rates than discriminatively trained RNN models. However we\nalso find that generative models approach their asymptotic error rate more\nrapidly than their discriminative counterparts---the same pattern that Ng &\nJordan (2001) proved holds for linear classification models that make more\nnaive conditional independence assumptions. Building on this finding, we\nhypothesize that RNN-based generative classification models will be more robust\nto shifts in the data distribution. This hypothesis is confirmed in a series of\nexperiments in zero-shot and continual learning settings that show that\ngenerative models substantially outperform discriminative models.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 14:40:09 GMT"}, {"version": "v2", "created": "Fri, 26 May 2017 01:27:23 GMT"}], "update_date": "2017-05-29", "authors_parsed": [["Yogatama", "Dani", ""], ["Dyer", "Chris", ""], ["Ling", "Wang", ""], ["Blunsom", "Phil", ""]]}, {"id": "1703.02019", "submitter": "Gourav Ganesh Shenoy", "authors": "Gourav G. Shenoy, Erika H. Dsouza, Sandra K\\\"ubler", "title": "Performing Stance Detection on Twitter Data using Computational\n  Linguistics Techniques", "comments": "8 pages, 9 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As humans, we can often detect from a persons utterances if he or she is in\nfavor of or against a given target entity (topic, product, another person,\netc). But from the perspective of a computer, we need means to automatically\ndeduce the stance of the tweeter, given just the tweet text. In this paper, we\npresent our results of performing stance detection on twitter data using a\nsupervised approach. We begin by extracting bag-of-words to perform\nclassification using TIMBL, then try and optimize the features to improve\nstance detection accuracy, followed by extending the dataset with two sets of\nlexicons - arguing, and MPQA subjectivity; next we explore the MALT parser and\nconstruct features using its dependency triples, finally we perform analysis\nusing Scikit-learn Random Forest implementation.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 18:44:49 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Shenoy", "Gourav G.", ""], ["Dsouza", "Erika H.", ""], ["K\u00fcbler", "Sandra", ""]]}, {"id": "1703.02031", "submitter": "Jean-Fran\\c{c}ois Delpech", "authors": "Jean-Fran\\c{c}ois Delpech and Sabine Ploux", "title": "Random vector generation of a semantic space", "comments": "10 pages,5 figures, 7 tables, 17 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how random vectors and random projection can be implemented in the\nusual vector space model to construct a Euclidean semantic space from a French\nsynonym dictionary. We evaluate theoretically the resulting noise and show the\nexperimental distribution of the similarities of terms in a neighborhood\naccording to the choice of parameters. We also show that the Schmidt\northogonalization process is applicable and can be used to separate homonyms\nwith distinct semantic meanings. Neighboring terms are easily arranged into\nsemantically significant clusters which are well suited to the generation of\nrealistic lists of synonyms and to such applications as word selection for\nautomatic text generation. This process, applicable to any language, can easily\nbe extended to collocations, is extremely fast and can be updated in real time,\nwhenever new synonyms are proposed.\n", "versions": [{"version": "v1", "created": "Sun, 5 Mar 2017 15:07:10 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Delpech", "Jean-Fran\u00e7ois", ""], ["Ploux", "Sabine", ""]]}, {"id": "1703.02136", "submitter": "George Saon", "authors": "George Saon, Gakuto Kurata, Tom Sercu, Kartik Audhkhasi, Samuel\n  Thomas, Dimitrios Dimitriadis, Xiaodong Cui, Bhuvana Ramabhadran, Michael\n  Picheny, Lynn-Li Lim, Bergul Roomi, Phil Hall", "title": "English Conversational Telephone Speech Recognition by Humans and\n  Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most difficult speech recognition tasks is accurate recognition of\nhuman to human communication. Advances in deep learning over the last few years\nhave produced major speech recognition improvements on the representative\nSwitchboard conversational corpus. Word error rates that just a few years ago\nwere 14% have dropped to 8.0%, then 6.6% and most recently 5.8%, and are now\nbelieved to be within striking range of human performance. This then raises two\nissues - what IS human performance, and how far down can we still drive speech\nrecognition error rates? A recent paper by Microsoft suggests that we have\nalready achieved human performance. In trying to verify this statement, we\nperformed an independent set of human performance measurements on two\nconversational tasks and found that human performance may be considerably\nbetter than what was earlier reported, giving the community a significantly\nharder goal to achieve. We also report on our own efforts in this area,\npresenting a set of acoustic and language modeling techniques that lowered the\nword error rate of our own English conversational telephone LVCSR system to the\nlevel of 5.5%/10.3% on the Switchboard/CallHome subsets of the Hub5 2000\nevaluation, which - at least at the writing of this paper - is a new\nperformance milestone (albeit not at what we measure to be human performance!).\nOn the acoustic side, we use a score fusion of three models: one LSTM with\nmultiple feature inputs, a second LSTM trained with speaker-adversarial\nmulti-task learning and a third residual net (ResNet) with 25 convolutional\nlayers and time-dilated convolutions. On the language modeling side, we use\nword and character LSTMs and convolutional WaveNet-style language models.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 22:37:43 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Saon", "George", ""], ["Kurata", "Gakuto", ""], ["Sercu", "Tom", ""], ["Audhkhasi", "Kartik", ""], ["Thomas", "Samuel", ""], ["Dimitriadis", "Dimitrios", ""], ["Cui", "Xiaodong", ""], ["Ramabhadran", "Bhuvana", ""], ["Picheny", "Michael", ""], ["Lim", "Lynn-Li", ""], ["Roomi", "Bergul", ""], ["Hall", "Phil", ""]]}, {"id": "1703.02166", "submitter": "Tran Nam Van", "authors": "Nam Tran Van", "title": "Building a Syllable Database to Solve the Problem of Khmer Word\n  Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word segmentation is a basic problem in natural language processing. With the\nlanguages having the complex writing system like the Khmer language in Southern\nof Vietnam, this problem really very intractable, posing the significant\nchallenges. Although there are some experts in Vietnam as well as international\nhaving deeply researched this problem, there are still no reasonable results\nmeeting the demand, in particular, no treated thoroughly the ambiguous\nphenomenon, in the process of Khmer language processing so far. This paper\npresent a solution based on the syllable division into component clusters using\ntwo syllable models proposed, thereby building a Khmer syllable database, is\nstill not actually available. This method using a lexical database updated from\nthe online Khmer dictionaries and some supported dictionaries serving role of\ntraining data and complementary linguistic characteristics. Each component\ncluster is labelled and located by the first and last letter to identify\nentirety a syllable. This approach is workable and the test results achieve\nhigh accuracy, eliminate the ambiguity, contribute to solving the problem of\nword segmentation and applying efficiency in Khmer language processing.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 01:13:39 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Van", "Nam Tran", ""]]}, {"id": "1703.02504", "submitter": "Martin Jaggi", "authors": "Jan Deriu, Aurelien Lucchi, Valeria De Luca, Aliaksei Severyn, Simon\n  M\\\"uller, Mark Cieliebak, Thomas Hofmann, Martin Jaggi", "title": "Leveraging Large Amounts of Weakly Supervised Data for Multi-Language\n  Sentiment Classification", "comments": "appearing at WWW 2017 - 26th International World Wide Web Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a novel approach for multi-lingual sentiment\nclassification in short texts. This is a challenging task as the amount of\ntraining data in languages other than English is very limited. Previously\nproposed multi-lingual approaches typically require to establish a\ncorrespondence to English for which powerful classifiers are already available.\nIn contrast, our method does not require such supervision. We leverage large\namounts of weakly-supervised data in various languages to train a multi-layer\nconvolutional network and demonstrate the importance of using pre-training of\nsuch networks. We thoroughly evaluate our approach on various multi-lingual\ndatasets, including the recent SemEval-2016 sentiment prediction benchmark\n(Task 4), where we achieved state-of-the-art performance. We also compare the\nperformance of our model trained individually for each language to a variant\ntrained for all languages at once. We show that the latter model reaches\nslightly worse - but still acceptable - performance when compared to the single\nlanguage model, while benefiting from better generalization properties across\nlanguages.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 18:15:57 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Deriu", "Jan", ""], ["Lucchi", "Aurelien", ""], ["De Luca", "Valeria", ""], ["Severyn", "Aliaksei", ""], ["M\u00fcller", "Simon", ""], ["Cieliebak", "Mark", ""], ["Hofmann", "Thomas", ""], ["Jaggi", "Martin", ""]]}, {"id": "1703.02507", "submitter": "Martin Jaggi", "authors": "Matteo Pagliardini, Prakhar Gupta, Martin Jaggi", "title": "Unsupervised Learning of Sentence Embeddings using Compositional n-Gram\n  Features", "comments": "NAACL 2018", "journal-ref": "NAACL 2018 - Conference of the North American Chapter of the\n  Association for Computational Linguistics, pages 528-540", "doi": "10.18653/v1/N18-1049", "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The recent tremendous success of unsupervised word embeddings in a multitude\nof applications raises the obvious question if similar methods could be derived\nto improve embeddings (i.e. semantic representations) of word sequences as\nwell. We present a simple but efficient unsupervised objective to train\ndistributed representations of sentences. Our method outperforms the\nstate-of-the-art unsupervised models on most benchmark tasks, highlighting the\nrobustness of the produced general-purpose sentence embeddings.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 18:19:11 GMT"}, {"version": "v2", "created": "Mon, 10 Jul 2017 18:05:48 GMT"}, {"version": "v3", "created": "Fri, 28 Dec 2018 15:12:58 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Pagliardini", "Matteo", ""], ["Gupta", "Prakhar", ""], ["Jaggi", "Martin", ""]]}, {"id": "1703.02517", "submitter": "Aleksei Nazarov", "authors": "Aleksei Nazarov and Joe Pater", "title": "Learning opacity in Stratal Maximum Entropy Grammar", "comments": "23 pages; to appear in Phonology; pre-publication version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Opaque phonological patterns are sometimes claimed to be difficult to learn;\nspecific hypotheses have been advanced about the relative difficulty of\nparticular kinds of opaque processes (Kiparsky 1971, 1973), and the kind of\ndata that will be helpful in learning an opaque pattern (Kiparsky 2000). In\nthis paper, we present a computationally implemented learning theory for one\ngrammatical theory of opacity: a Maximum Entropy version of Stratal OT\n(Berm\\'udez-Otero 1999, Kiparsky 2000), and test it on simplified versions of\nopaque French tense-lax vowel alternations and the opaque interaction of\ndiphthong raising and flapping in Canadian English. We find that the difficulty\nof opacity can be influenced by evidence for stratal affiliation: the Canadian\nEnglish case is easier if the learner encounters application of raising outside\nthe flapping context, or non-application of raising between words (i.e., <life>\nwith a raised vowel; <lie for> with a non-raised vowel).\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 18:35:33 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Nazarov", "Aleksei", ""], ["Pater", "Joe", ""]]}, {"id": "1703.02573", "submitter": "Ziang Xie", "authors": "Ziang Xie, Sida I. Wang, Jiwei Li, Daniel L\\'evy, Aiming Nie, Dan\n  Jurafsky, Andrew Y. Ng", "title": "Data Noising as Smoothing in Neural Network Language Models", "comments": "ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data noising is an effective technique for regularizing neural network\nmodels. While noising is widely adopted in application domains such as vision\nand speech, commonly used noising primitives have not been developed for\ndiscrete sequence-level settings such as language modeling. In this paper, we\nderive a connection between input noising in neural network language models and\nsmoothing in $n$-gram models. Using this connection, we draw upon ideas from\nsmoothing to develop effective noising schemes. We demonstrate performance\ngains when applying the proposed schemes to language modeling and machine\ntranslation. Finally, we provide empirical analysis validating the relationship\nbetween noising and smoothing.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 19:56:26 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Xie", "Ziang", ""], ["Wang", "Sida I.", ""], ["Li", "Jiwei", ""], ["L\u00e9vy", "Daniel", ""], ["Nie", "Aiming", ""], ["Jurafsky", "Dan", ""], ["Ng", "Andrew Y.", ""]]}, {"id": "1703.02620", "submitter": "Bhuwan Dhingra", "authors": "Bhuwan Dhingra, Zhilin Yang, William W. Cohen, Ruslan Salakhutdinov", "title": "Linguistic Knowledge as Memory for Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training recurrent neural networks to model long term dependencies is\ndifficult. Hence, we propose to use external linguistic knowledge as an\nexplicit signal to inform the model which memories it should utilize.\nSpecifically, external knowledge is used to augment a sequence with typed edges\nbetween arbitrarily distant elements, and the resulting graph is decomposed\ninto directed acyclic subgraphs. We introduce a model that encodes such graphs\nas explicit memory in recurrent neural networks, and use it to model\ncoreference relations in text. We apply our model to several text comprehension\ntasks and achieve new state-of-the-art results on all considered benchmarks,\nincluding CNN, bAbi, and LAMBADA. On the bAbi QA tasks, our model solves 15 out\nof the 20 tasks with only 1000 training examples per task. Analysis of the\nlearned representations further demonstrates the ability of our model to encode\nfine-grained entity information across a document.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 22:13:17 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Dhingra", "Bhuwan", ""], ["Yang", "Zhilin", ""], ["Cohen", "William W.", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1703.02819", "submitter": "Dmitry Ignatov", "authors": "Dmitry I. Ignatov", "title": "Introduction to Formal Concept Analysis and Its Applications in\n  Information Retrieval and Related Fields", "comments": null, "journal-ref": "RuSSIR 2014, Nizhniy Novgorod, Russia, CCIS vol. 505, Springer\n  42-141", "doi": "10.1007/978-3-319-25485-2_3", "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.DM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is a tutorial on Formal Concept Analysis (FCA) and its\napplications. FCA is an applied branch of Lattice Theory, a mathematical\ndiscipline which enables formalisation of concepts as basic units of human\nthinking and analysing data in the object-attribute form. Originated in early\n80s, during the last three decades, it became a popular human-centred tool for\nknowledge representation and data analysis with numerous applications. Since\nthe tutorial was specially prepared for RuSSIR 2014, the covered FCA topics\ninclude Information Retrieval with a focus on visualisation aspects, Machine\nLearning, Data Mining and Knowledge Discovery, Text Mining and several others.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 12:53:21 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Ignatov", "Dmitry I.", ""]]}, {"id": "1703.02859", "submitter": "Tianran Hu", "authors": "Tianran Hu, Ruihua Song, Maya Abtahian, Philip Ding, Xing Xie, Jiebo\n  Luo", "title": "A World of Difference: Divergent Word Interpretations among People", "comments": "4 pages, 1 figure, published at ICWSM'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Divergent word usages reflect differences among people. In this paper, we\npresent a novel angle for studying word usage divergence -- word\ninterpretations. We propose an approach that quantifies semantic differences in\ninterpretations among different groups of people. The effectiveness of our\napproach is validated by quantitative evaluations. Experiment results indicate\nthat divergences in word interpretations exist. We further apply the approach\nto two well studied types of differences between people -- gender and region.\nThe detected words with divergent interpretations reveal the unique features of\nspecific groups of people. For gender, we discover that certain different\ninterests, social attitudes, and characters between males and females are\nreflected in their divergent interpretations of many words. For region, we find\nthat specific interpretations of certain words reveal the geographical and\ncultural features of different regions.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 14:51:09 GMT"}, {"version": "v2", "created": "Tue, 28 Mar 2017 18:31:22 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Hu", "Tianran", ""], ["Song", "Ruihua", ""], ["Abtahian", "Maya", ""], ["Ding", "Philip", ""], ["Xie", "Xing", ""], ["Luo", "Jiebo", ""]]}, {"id": "1703.02860", "submitter": "Tianran Hu", "authors": "Tianran Hu, Han Guo, Hao Sun, Thuy-vy Thi Nguyen, Jiebo Luo", "title": "Spice up Your Chat: The Intentions and Sentiment Effects of Using Emoji", "comments": "10 pages, published at ICWSM'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Emojis, as a new way of conveying nonverbal cues, are widely adopted in\ncomputer-mediated communications. In this paper, first from a message sender\nperspective, we focus on people's motives in using four types of emojis --\npositive, neutral, negative, and non-facial. We compare the willingness levels\nof using these emoji types for seven typical intentions that people usually\napply nonverbal cues for in communication. The results of extensive statistical\nhypothesis tests not only report the popularities of the intentions, but also\nuncover the subtle differences between emoji types in terms of intended uses.\nSecond, from a perspective of message recipients, we further study the\nsentiment effects of emojis, as well as their duplications, on verbal messages.\nDifferent from previous studies in emoji sentiment, we study the sentiments of\nemojis and their contexts as a whole. The experiment results indicate that the\npowers of conveying sentiment are different between four emoji types, and the\nsentiment effects of emojis vary in the contexts of different valences.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 14:57:10 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Hu", "Tianran", ""], ["Guo", "Han", ""], ["Sun", "Hao", ""], ["Nguyen", "Thuy-vy Thi", ""], ["Luo", "Jiebo", ""]]}, {"id": "1703.03091", "submitter": "Jugal Kalita", "authors": "Marc Moreno Lopez and Jugal Kalita", "title": "Deep Learning applied to NLP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Network (CNNs) are typically associated with Computer\nVision. CNNs are responsible for major breakthroughs in Image Classification\nand are the core of most Computer Vision systems today. More recently CNNs have\nbeen applied to problems in Natural Language Processing and gotten some\ninteresting results. In this paper, we will try to explain the basics of CNNs,\nits different variations and how they have been applied to NLP.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 01:04:07 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Lopez", "Marc Moreno", ""], ["Kalita", "Jugal", ""]]}, {"id": "1703.03097", "submitter": "Mayank Kejriwal", "authors": "Mayank Kejriwal, Pedro Szekely", "title": "Information Extraction in Illicit Domains", "comments": "10 pages, ACM WWW 2017", "journal-ref": null, "doi": "10.1145/3038912.3052642", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting useful entities and attribute values from illicit domains such as\nhuman trafficking is a challenging problem with the potential for widespread\nsocial impact. Such domains employ atypical language models, have `long tails'\nand suffer from the problem of concept drift. In this paper, we propose a\nlightweight, feature-agnostic Information Extraction (IE) paradigm specifically\ndesigned for such domains. Our approach uses raw, unlabeled text from an\ninitial corpus, and a few (12-120) seed annotations per domain-specific\nattribute, to learn robust IE models for unobserved pages and websites.\nEmpirically, we demonstrate that our approach can outperform feature-centric\nConditional Random Field baselines by over 18\\% F-Measure on five annotated\nsets of real-world human trafficking datasets in both low-supervision and\nhigh-supervision settings. We also show that our approach is demonstrably\nrobust to concept drift, and can be efficiently bootstrapped even in a serial\ncomputing environment.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 01:28:00 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Kejriwal", "Mayank", ""], ["Szekely", "Pedro", ""]]}, {"id": "1703.03130", "submitter": "Zhouhan Lin", "authors": "Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing\n  Xiang, Bowen Zhou, Yoshua Bengio", "title": "A Structured Self-attentive Sentence Embedding", "comments": "15 pages with appendix, 7 figures, 4 tables. Conference paper in 5th\n  International Conference on Learning Representations (ICLR 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new model for extracting an interpretable sentence\nembedding by introducing self-attention. Instead of using a vector, we use a\n2-D matrix to represent the embedding, with each row of the matrix attending on\na different part of the sentence. We also propose a self-attention mechanism\nand a special regularization term for the model. As a side effect, the\nembedding comes with an easy way of visualizing what specific parts of the\nsentence are encoded into the embedding. We evaluate our model on 3 different\ntasks: author profiling, sentiment classification, and textual entailment.\nResults show that our model yields a significant performance gain compared to\nother sentence embedding methods in all of the 3 tasks.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 04:42:30 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Lin", "Zhouhan", ""], ["Feng", "Minwei", ""], ["Santos", "Cicero Nogueira dos", ""], ["Yu", "Mo", ""], ["Xiang", "Bing", ""], ["Zhou", "Bowen", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1703.03149", "submitter": "Marjan Hosseinia", "authors": "Marjan Hosseinia and Arjun Mukherjee", "title": "Detecting Sockpuppets in Deceptive Opinion Spam", "comments": "18 pages, Accepted at CICLing 2017, 18th International Conference on\n  Intelligent Text Processing and Computational Linguistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the problem of sockpuppet detection in deceptive opinion\nspam using authorship attribution and verification approaches. Two methods are\nexplored. The first is a feature subsampling scheme that uses the KL-Divergence\non stylistic language models of an author to find discriminative features. The\nsecond is a transduction scheme, spy induction that leverages the diversity of\nauthors in the unlabeled test set by sending a set of spies (positive samples)\nfrom the training set to retrieve hidden samples in the unlabeled test set\nusing nearest and farthest neighbors. Experiments using ground truth sockpuppet\ndata show the effectiveness of the proposed schemes.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 06:20:49 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Hosseinia", "Marjan", ""], ["Mukherjee", "Arjun", ""]]}, {"id": "1703.03200", "submitter": "Murahtan Kurfal{\\i}", "authors": "Burcu Can, Ahmet \\\"Ust\\\"un, Murathan Kurfal{\\i}", "title": "Turkish PoS Tagging by Reducing Sparsity with Morpheme Tags in Small\n  Datasets", "comments": "13 pages, accepted and presented in 17th International Conference on\n  Intelligent Text Processing and Computational Linguistics (CICLING)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparsity is one of the major problems in natural language processing. The\nproblem becomes even more severe in agglutinating languages that are highly\nprone to be inflected. We deal with sparsity in Turkish by adopting\nmorphological features for part-of-speech tagging. We learn inflectional and\nderivational morpheme tags in Turkish by using conditional random fields (CRF)\nand we employ the morpheme tags in part-of-speech (PoS) tagging by using hidden\nMarkov models (HMMs) to mitigate sparsity. Results show that using morpheme\ntags in PoS tagging helps alleviate the sparsity in emission probabilities. Our\nmodel outperforms other hidden Markov model based PoS tagging models for small\ntraining datasets in Turkish. We obtain an accuracy of 94.1% in morpheme\ntagging and 89.2% in PoS tagging on a 5K training dataset.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 09:46:56 GMT"}, {"version": "v2", "created": "Fri, 10 Mar 2017 08:11:22 GMT"}], "update_date": "2017-03-13", "authors_parsed": [["Can", "Burcu", ""], ["\u00dcst\u00fcn", "Ahmet", ""], ["Kurfal\u0131", "Murathan", ""]]}, {"id": "1703.03386", "submitter": "Cristian Danescu-Niculescu-Mizil", "authors": "William L. Hamilton, Justine Zhang, Cristian Danescu-Niculescu-Mizil,\n  Dan Jurafsky, Jure Leskovec", "title": "Loyalty in Online Communities", "comments": "Extended version of a paper appearing in the Proceedings of ICWSM\n  2017 (with the same title); please cite the official ICWSM version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Loyalty is an essential component of multi-community engagement. When users\nhave the choice to engage with a variety of different communities, they often\nbecome loyal to just one, focusing on that community at the expense of others.\nHowever, it is unclear how loyalty is manifested in user behavior, or whether\nloyalty is encouraged by certain community characteristics.\n  In this paper we operationalize loyalty as a user-community relation: users\nloyal to a community consistently prefer it over all others; loyal communities\nretain their loyal users over time. By exploring this relation using a large\ndataset of discussion communities from Reddit, we reveal that loyalty is\nmanifested in remarkably consistent behaviors across a wide spectrum of\ncommunities. Loyal users employ language that signals collective identity and\nengage with more esoteric, less popular content, indicating they may play a\ncurational role in surfacing new material. Loyal communities have denser\nuser-user interaction networks and lower rates of triadic closure, suggesting\nthat community-level loyalty is associated with more cohesive interactions and\nless fragmentation into subgroups. We exploit these general patterns to predict\nfuture rates of loyalty. Our results show that a user's propensity to become\nloyal is apparent from their first interactions with a community, suggesting\nthat some users are intrinsically loyal from the very beginning.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 18:37:50 GMT"}, {"version": "v2", "created": "Tue, 4 Apr 2017 01:09:26 GMT"}, {"version": "v3", "created": "Wed, 24 May 2017 14:45:13 GMT"}], "update_date": "2017-05-25", "authors_parsed": [["Hamilton", "William L.", ""], ["Zhang", "Justine", ""], ["Danescu-Niculescu-Mizil", "Cristian", ""], ["Jurafsky", "Dan", ""], ["Leskovec", "Jure", ""]]}, {"id": "1703.03429", "submitter": "Nancy Fulda", "authors": "Nancy Fulda and Daniel Ricks and Ben Murdoch and David Wingate", "title": "What can you do with a rock? Affordance extraction via word embeddings", "comments": "7 pages, 7 figures, 2 algorithms, data runs were performed using the\n  Autoplay learning environment for interactive fiction", "journal-ref": "Proceedings of the Twenty-Sixth International Joint Conference on\n  Artificial Intelligence (IJCAI), Pages 1039-1045, 2017", "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous agents must often detect affordances: the set of behaviors enabled\nby a situation. Affordance detection is particularly helpful in domains with\nlarge action spaces, allowing the agent to prune its search space by avoiding\nfutile behaviors. This paper presents a method for affordance extraction via\nword embeddings trained on a Wikipedia corpus. The resulting word vectors are\ntreated as a common knowledge database which can be queried using linear\nalgebra. We apply this method to a reinforcement learning agent in a text-only\nenvironment and show that affordance-based action selection improves\nperformance most of the time. Our method increases the computational complexity\nof each learning step but significantly reduces the total number of steps\nneeded. In addition, the agent's action selections begin to resemble those a\nhuman would choose.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 19:16:14 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Fulda", "Nancy", ""], ["Ricks", "Daniel", ""], ["Murdoch", "Ben", ""], ["Wingate", "David", ""]]}, {"id": "1703.03442", "submitter": "Vanessa Ferdinand PhD", "authors": "Vanessa Ferdinand, Simon Kirby, Kenny Smith", "title": "The cognitive roots of regularization in language", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization occurs when the output a learner produces is less variable\nthan the linguistic data they observed. In an artificial language learning\nexperiment, we show that there exist at least two independent sources of\nregularization bias in cognition: a domain-general source based on cognitive\nload and a domain-specific source triggered by linguistic stimuli. Both of\nthese factors modulate how frequency information is encoded and produced, but\nonly the production-side modulations result in regularization (i.e. cause\nlearners to eliminate variation from the observed input). We formalize the\ndefinition of regularization as the reduction of entropy and find that entropy\nmeasures are better at identifying regularization behavior than frequency-based\nanalyses. Using our experimental data and a model of cultural transmission, we\ngenerate predictions for the amount of regularity that would develop in each\nexperimental condition if the artificial language were transmitted over several\ngenerations of learners. Here we find that the effect of cognitive constraints\ncan become more complex when put into the context of cultural evolution:\nalthough learning biases certainly carry information about the course of\nlanguage evolution, we should not expect a one-to-one correspondence between\nthe micro-level processes that regularize linguistic datasets and the\nmacro-level evolution of linguistic regularity.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 19:50:00 GMT"}, {"version": "v2", "created": "Thu, 18 Oct 2018 21:33:46 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Ferdinand", "Vanessa", ""], ["Kirby", "Simon", ""], ["Smith", "Kenny", ""]]}, {"id": "1703.03609", "submitter": "Mostafa Salehi", "authors": "Saeedreza Shehnepoor, Mostafa Salehi, Reza Farahbakhsh and Noel Crespi", "title": "NetSpam: a Network-based Spam Detection Framework for Reviews in Online\n  Social Media", "comments": null, "journal-ref": null, "doi": "10.1109/TIFS.2017.2675361", "report-no": null, "categories": "cs.SI cs.CL cs.IR physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, a big part of people rely on available content in social media in\ntheir decisions (e.g. reviews and feedback on a topic or product). The\npossibility that anybody can leave a review provide a golden opportunity for\nspammers to write spam reviews about products and services for different\ninterests. Identifying these spammers and the spam content is a hot topic of\nresearch and although a considerable number of studies have been done recently\ntoward this end, but so far the methodologies put forth still barely detect\nspam reviews, and none of them show the importance of each extracted feature\ntype. In this study, we propose a novel framework, named NetSpam, which\nutilizes spam features for modeling review datasets as heterogeneous\ninformation networks to map spam detection procedure into a classification\nproblem in such networks. Using the importance of spam features help us to\nobtain better results in terms of different metrics experimented on real-world\nreview datasets from Yelp and Amazon websites. The results show that NetSpam\noutperforms the existing methods and among four categories of features;\nincluding review-behavioral, user-behavioral, reviewlinguistic,\nuser-linguistic, the first type of features performs better than the other\ncategories.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 10:17:27 GMT"}], "update_date": "2017-03-13", "authors_parsed": [["Shehnepoor", "Saeedreza", ""], ["Salehi", "Mostafa", ""], ["Farahbakhsh", "Reza", ""], ["Crespi", "Noel", ""]]}, {"id": "1703.03640", "submitter": "Christina Lioma Assoc. Prof", "authors": "Christina Lioma and Niels Dalum Hansen", "title": "A Study of Metrics of Distance and Correlation Between Ranked Lists for\n  Compositionality Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compositionality in language refers to how much the meaning of some phrase\ncan be decomposed into the meaning of its constituents and the way these\nconstituents are combined. Based on the premise that substitution by synonyms\nis meaning-preserving, compositionality can be approximated as the semantic\nsimilarity between a phrase and a version of that phrase where words have been\nreplaced by their synonyms. Different ways of representing such phrases exist\n(e.g., vectors [1] or language models [2]), and the choice of representation\naffects the measurement of semantic similarity.\n  We propose a new compositionality detection method that represents phrases as\nranked lists of term weights. Our method approximates the semantic similarity\nbetween two ranked list representations using a range of well-known distance\nand correlation metrics. In contrast to most state-of-the-art approaches in\ncompositionality detection, our method is completely unsupervised. Experiments\nwith a publicly available dataset of 1048 human-annotated phrases shows that,\ncompared to strong supervised baselines, our approach provides superior\nmeasurement of compositionality using any of the distance and correlation\nmetrics considered.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 11:58:48 GMT"}], "update_date": "2017-03-13", "authors_parsed": [["Lioma", "Christina", ""], ["Hansen", "Niels Dalum", ""]]}, {"id": "1703.03666", "submitter": "Sreelekha S", "authors": "Sreelekha. S, Pushpak Bhattacharyya", "title": "Comparison of SMT and RBMT; The Requirement of Hybridization for\n  Marathi-Hindi MT", "comments": "6 TABLES, 4 FIGURES. arXiv admin note: substantial text overlap with\n  arXiv:1702.08217; text overlap with arXiv:1703.01485", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present in this paper our work on comparison between Statistical Machine\nTranslation (SMT) and Rule-based machine translation for translation from\nMarathi to Hindi. Rule Based systems although robust take lots of time to\nbuild. On the other hand statistical machine translation systems are easier to\ncreate, maintain and improve upon. We describe the development of a basic\nMarathi-Hindi SMT system and evaluate its performance. Through a detailed error\nanalysis, we, point out the relative strengths and weaknesses of both systems.\nEffectively, we shall see that even with a small amount of training corpus a\nstatistical machine translation system has many advantages for high quality\ndomain specific machine translation over that of a rule-based counterpart.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 12:59:52 GMT"}], "update_date": "2017-03-13", "authors_parsed": [["S", "Sreelekha.", ""], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "1703.03714", "submitter": "Matthew Marge", "authors": "Matthew Marge, Claire Bonial, Brendan Byrne, Taylor Cassidy, A.\n  William Evans, Susan G. Hill, Clare Voss", "title": "Applying the Wizard-of-Oz Technique to Multimodal Human-Robot Dialogue", "comments": "Presented at the 2016 IEEE International Symposium on Robot and Human\n  Interactive Communication (RO-MAN), Interactive Session, August 26-31, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our overall program objective is to provide more natural ways for soldiers to\ninteract and communicate with robots, much like how soldiers communicate with\nother soldiers today. We describe how the Wizard-of-Oz (WOz) method can be\napplied to multimodal human-robot dialogue in a collaborative exploration task.\nWhile the WOz method can help design robot behaviors, traditional approaches\nplace the burden of decisions on a single wizard. In this work, we consider two\nwizards to stand in for robot navigation and dialogue management software\ncomponents. The scenario used to elicit data is one in which a human-robot team\nis tasked with exploring an unknown environment: a human gives verbal\ninstructions from a remote location and the robot follows them, clarifying\npossible misunderstandings as needed via dialogue. We found the division of\nlabor between wizards to be workable, which holds promise for future software\ndevelopment.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 15:27:45 GMT"}], "update_date": "2017-03-13", "authors_parsed": [["Marge", "Matthew", ""], ["Bonial", "Claire", ""], ["Byrne", "Brendan", ""], ["Cassidy", "Taylor", ""], ["Evans", "A. William", ""], ["Hill", "Susan G.", ""], ["Voss", "Clare", ""]]}, {"id": "1703.03771", "submitter": "Jena Hwang", "authors": "Jena D. Hwang, Archna Bhatia, Na-Rae Han, Tim O'Gorman, Vivek\n  Srikumar, Nathan Schneider", "title": "Coping with Construals in Broad-Coverage Semantic Annotation of\n  Adpositions", "comments": "Presentation at Construction Grammar and NLU AAAI Spring Symposium,\n  Stanford, March 27-29 2017; 9 pages including references; 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the semantics of prepositions, revisiting a broad-coverage\nannotation scheme used for annotating all 4,250 preposition tokens in a 55,000\nword corpus of English. Attempts to apply the scheme to adpositions and case\nmarkers in other languages, as well as some problematic cases in English, have\nled us to reconsider the assumption that a preposition's lexical contribution\nis equivalent to the role/relation that it mediates. Our proposal is to embrace\nthe potential for construal in adposition use, expressing such phenomena\ndirectly at the token level to manage complexity and avoid sense proliferation.\nWe suggest a framework to represent both the scene role and the adposition's\nlexical function so they can be annotated at scale---supporting automatic,\nstatistical processing of domain-general language---and sketch how this\nrepresentation would inform a constructional analysis.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 17:27:38 GMT"}], "update_date": "2017-03-13", "authors_parsed": [["Hwang", "Jena D.", ""], ["Bhatia", "Archna", ""], ["Han", "Na-Rae", ""], ["O'Gorman", "Tim", ""], ["Srikumar", "Vivek", ""], ["Schneider", "Nathan", ""]]}, {"id": "1703.03842", "submitter": "Paul Tupper", "authors": "B. Goodman and P. F. Tupper", "title": "Effects of Limiting Memory Capacity on the Behaviour of Exemplar\n  Dynamics", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exemplar models are a popular class of models used to describe language\nchange. Here we study how limiting the memory capacity of an individual in\nthese models affects the system's behaviour. In particular we demonstrate the\neffect this change has on the extinction of categories. Previous work in\nexemplar dynamics has not addressed this question. In order to investigate\nthis, we will inspect a simplified exemplar model. We will prove for the\nsimplified model that all the sound categories but one will always become\nextinct, whether memory storage is limited or not. However, computer\nsimulations show that changing the number of stored memories alters how fast\ncategories become extinct.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 20:54:11 GMT"}, {"version": "v2", "created": "Sun, 10 Dec 2017 18:53:51 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Goodman", "B.", ""], ["Tupper", "P. F.", ""]]}, {"id": "1703.03906", "submitter": "Anna Goldie", "authors": "Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc Le", "title": "Massive Exploration of Neural Machine Translation Architectures", "comments": "9 pages, 2 figures, 8 tables, submitted to ACL 2017, open source code\n  at https://github.com/google/seq2seq/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) has shown remarkable progress over the past\nfew years with production systems now being deployed to end-users. One major\ndrawback of current architectures is that they are expensive to train,\ntypically requiring days to weeks of GPU time to converge. This makes\nexhaustive hyperparameter search, as is commonly done with other neural network\narchitectures, prohibitively expensive. In this work, we present the first\nlarge-scale analysis of NMT architecture hyperparameters. We report empirical\nresults and variance numbers for several hundred experimental runs,\ncorresponding to over 250,000 GPU hours on the standard WMT English to German\ntranslation task. Our experiments lead to novel insights and practical advice\nfor building and extending NMT architectures. As part of this contribution, we\nrelease an open-source NMT framework that enables researchers to easily\nexperiment with novel techniques and reproduce state of the art results.\n", "versions": [{"version": "v1", "created": "Sat, 11 Mar 2017 04:17:46 GMT"}, {"version": "v2", "created": "Tue, 21 Mar 2017 20:34:59 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Britz", "Denny", ""], ["Goldie", "Anna", ""], ["Luong", "Minh-Thang", ""], ["Le", "Quoc", ""]]}, {"id": "1703.03923", "submitter": "Juan-Manuel Torres-Moreno", "authors": "Juan-Manuel Torres-Moreno, Gerardo Sierra, Peter Peinl", "title": "A German Corpus for Text Similarity Detection Tasks", "comments": "1 figure; 13 pages", "journal-ref": "Preprint of International Journal of Computational Linguistics and\n  Applications, vol. 5, no. 2, 2014, pp. 9-24", "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text similarity detection aims at measuring the degree of similarity between\na pair of texts. Corpora available for text similarity detection are designed\nto evaluate the algorithms to assess the paraphrase level among documents. In\nthis paper we present a textual German corpus for similarity detection. The\npurpose of this corpus is to automatically assess the similarity between a pair\nof texts and to evaluate different similarity measures, both for whole\ndocuments or for individual sentences. Therefore we have calculated several\nsimple measures on our corpus based on a library of similarity functions.\n", "versions": [{"version": "v1", "created": "Sat, 11 Mar 2017 07:35:28 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Torres-Moreno", "Juan-Manuel", ""], ["Sierra", "Gerardo", ""], ["Peinl", "Peter", ""]]}, {"id": "1703.03939", "submitter": "Govardana Sachithanandam Ramachandran", "authors": "Govardana Sachithanandam Ramachandran, Ajay Sohmshetty", "title": "Ask Me Even More: Dynamic Memory Tensor Networks (Extended Model)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine Memory Networks for the task of question answering (QA), under\ncommon real world scenario where training examples are scarce and under weakly\nsupervised scenario, that is only extrinsic labels are available for training.\nWe propose extensions for the Dynamic Memory Network (DMN), specifically within\nthe attention mechanism, we call the resulting Neural Architecture as Dynamic\nMemory Tensor Network (DMTN). Ultimately, we see that our proposed extensions\nresults in over 80% improvement in the number of task passed against the\nbaselined standard DMN and 20% more task passed compared to state-of-the-art\nEnd-to-End Memory Network for Facebook's single task weakly trained 1K bAbi\ndataset.\n", "versions": [{"version": "v1", "created": "Sat, 11 Mar 2017 10:05:19 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Ramachandran", "Govardana Sachithanandam", ""], ["Sohmshetty", "Ajay", ""]]}, {"id": "1703.04001", "submitter": "Suman Kalyan Maity", "authors": "Suman Kalyan Maity, Aman Kharb and Animesh Mukherjee", "title": "Language Use Matters: Analysis of the Linguistic Structure of Question\n  Texts Can Characterize Answerability in Quora", "comments": "1 figure, 3 tables, ICWSM 2017 as poster", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Quora is one of the most popular community Q&A sites of recent times.\nHowever, many question posts on this Q&A site often do not get answered. In\nthis paper, we quantify various linguistic activities that discriminates an\nanswered question from an unanswered one. Our central finding is that the way\nusers use language while writing the question text can be a very effective\nmeans to characterize answerability. This characterization helps us to predict\nearly if a question remaining unanswered for a specific time period t will\neventually be answered or not and achieve an accuracy of 76.26% (t = 1 month)\nand 68.33% (t = 3 months). Notably, features representing the language use\npatterns of the users are most discriminative and alone account for an accuracy\nof 74.18%. We also compare our method with some of the similar works (Dror et\nal., Yang et al.) achieving a maximum improvement of ~39% in terms of accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 11 Mar 2017 17:14:55 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Maity", "Suman Kalyan", ""], ["Kharb", "Aman", ""], ["Mukherjee", "Animesh", ""]]}, {"id": "1703.04009", "submitter": "Thomas Davidson", "authors": "Thomas Davidson, Dana Warmsley, Michael Macy, Ingmar Weber", "title": "Automated Hate Speech Detection and the Problem of Offensive Language", "comments": "To appear in the Proceedings of ICWSM 2017. Please cite that version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key challenge for automatic hate-speech detection on social media is the\nseparation of hate speech from other instances of offensive language. Lexical\ndetection methods tend to have low precision because they classify all messages\ncontaining particular terms as hate speech and previous work using supervised\nlearning has failed to distinguish between the two categories. We used a\ncrowd-sourced hate speech lexicon to collect tweets containing hate speech\nkeywords. We use crowd-sourcing to label a sample of these tweets into three\ncategories: those containing hate speech, only offensive language, and those\nwith neither. We train a multi-class classifier to distinguish between these\ndifferent categories. Close analysis of the predictions and the errors shows\nwhen we can reliably separate hate speech from other offensive language and\nwhen this differentiation is more difficult. We find that racist and homophobic\ntweets are more likely to be classified as hate speech but that sexist tweets\nare generally classified as offensive. Tweets without explicit hate keywords\nare also more difficult to classify.\n", "versions": [{"version": "v1", "created": "Sat, 11 Mar 2017 18:20:13 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Davidson", "Thomas", ""], ["Warmsley", "Dana", ""], ["Macy", "Michael", ""], ["Weber", "Ingmar", ""]]}, {"id": "1703.04081", "submitter": "Shravan Vasishth", "authors": "Shravan Vasishth, Lena A. J\\\"ager, Bruno Nicenboim", "title": "Feature overwriting as a finite mixture process: Evidence from\n  comprehension data", "comments": "6 pages, 2 figures, 1 table, submitted to MathPsych/ICCM 2017,\n  Warwick, UK", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ungrammatical sentence \"The key to the cabinets are on the table\" is\nknown to lead to an illusion of grammaticality. As discussed in the\nmeta-analysis by Jaeger et al., 2017, faster reading times are observed at the\nverb are in the agreement-attraction sentence above compared to the equally\nungrammatical sentence \"The key to the cabinet are on the table\". One\nexplanation for this facilitation effect is the feature percolation account:\nthe plural feature on cabinets percolates up to the head noun key, leading to\nthe illusion. An alternative account is in terms of cue-based retrieval (Lewis\n& Vasishth, 2005), which assumes that the non-subject noun cabinets is\nmisretrieved due to a partial feature-match when a dependency completion\nprocess at the auxiliary initiates a memory access for a subject with plural\nmarking. We present evidence for yet another explanation for the observed\nfacilitation. Because the second sentence has two nouns with identical number,\nit is possible that these are, in some proportion of trials, more difficult to\nkeep distinct, leading to slower reading times at the verb in the first\nsentence above; this is the feature overwriting account of Nairne, 1990. We\nshow that the feature overwriting proposal can be implemented as a finite\nmixture process. We reanalysed ten published data-sets, fitting hierarchical\nBayesian mixture models to these data assuming a two-mixture distribution. We\nshow that in nine out of the ten studies, a mixture distribution corresponding\nto feature overwriting furnishes a superior fit over both the feature\npercolation and the cue-based retrieval accounts.\n", "versions": [{"version": "v1", "created": "Sun, 12 Mar 2017 08:11:29 GMT"}, {"version": "v2", "created": "Sat, 20 Jan 2018 08:15:23 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Vasishth", "Shravan", ""], ["J\u00e4ger", "Lena A.", ""], ["Nicenboim", "Bruno", ""]]}, {"id": "1703.04178", "submitter": "Jose Camacho-Collados", "authors": "Jose Camacho-Collados", "title": "Why we have switched from building full-fledged taxonomies to simply\n  detecting hypernymy relations", "comments": "Discussion paper. 6 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of taxonomies and hypernymy relations has been extensive on the\nNatural Language Processing (NLP) literature. However, the evaluation of\ntaxonomy learning approaches has been traditionally troublesome, as it mainly\nrelies on ad-hoc experiments which are hardly reproducible and manually\nexpensive. Partly because of this, current research has been lately focusing on\nthe hypernymy detection task. In this paper we reflect on this trend, analyzing\nissues related to current evaluation procedures. Finally, we propose three\npotential avenues for future work so that is-a relations and resources based on\nthem play a more important role in downstream NLP applications.\n", "versions": [{"version": "v1", "created": "Sun, 12 Mar 2017 21:07:54 GMT"}, {"version": "v2", "created": "Thu, 23 Mar 2017 14:00:55 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Camacho-Collados", "Jose", ""]]}, {"id": "1703.04213", "submitter": "Meng Jiang", "authors": "Meng Jiang, Jingbo Shang, Taylor Cassidy, Xiang Ren, Lance M. Kaplan,\n  Timothy P. Hanratty, Jiawei Han", "title": "MetaPAD: Meta Pattern Discovery from Massive Text Corpora", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mining textual patterns in news, tweets, papers, and many other kinds of text\ncorpora has been an active theme in text mining and NLP research. Previous\nstudies adopt a dependency parsing-based pattern discovery approach. However,\nthe parsing results lose rich context around entities in the patterns, and the\nprocess is costly for a corpus of large scale. In this study, we propose a\nnovel typed textual pattern structure, called meta pattern, which is extended\nto a frequent, informative, and precise subsequence pattern in certain context.\nWe propose an efficient framework, called MetaPAD, which discovers meta\npatterns from massive corpora with three techniques: (1) it develops a\ncontext-aware segmentation method to carefully determine the boundaries of\npatterns with a learnt pattern quality assessment function, which avoids costly\ndependency parsing and generates high-quality patterns; (2) it identifies and\ngroups synonymous meta patterns from multiple facets---their types, contexts,\nand extractions; and (3) it examines type distributions of entities in the\ninstances extracted by each group of patterns, and looks for appropriate type\nlevels to make discovered patterns precise. Experiments demonstrate that our\nproposed framework discovers high-quality typed textual patterns efficiently\nfrom different genres of massive corpora and facilitates information\nextraction.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 01:06:19 GMT"}, {"version": "v2", "created": "Tue, 14 Mar 2017 20:26:32 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Jiang", "Meng", ""], ["Shang", "Jingbo", ""], ["Cassidy", "Taylor", ""], ["Ren", "Xiang", ""], ["Kaplan", "Lance M.", ""], ["Hanratty", "Timothy P.", ""], ["Han", "Jiawei", ""]]}, {"id": "1703.04247", "submitter": "Huifeng Guo", "authors": "Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, Xiuqiang He", "title": "DeepFM: A Factorization-Machine based Neural Network for CTR Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning sophisticated feature interactions behind user behaviors is critical\nin maximizing CTR for recommender systems. Despite great progress, existing\nmethods seem to have a strong bias towards low- or high-order interactions, or\nrequire expertise feature engineering. In this paper, we show that it is\npossible to derive an end-to-end learning model that emphasizes both low- and\nhigh-order feature interactions. The proposed model, DeepFM, combines the power\nof factorization machines for recommendation and deep learning for feature\nlearning in a new neural network architecture. Compared to the latest Wide \\&\nDeep model from Google, DeepFM has a shared input to its \"wide\" and \"deep\"\nparts, with no need of feature engineering besides raw features. Comprehensive\nexperiments are conducted to demonstrate the effectiveness and efficiency of\nDeepFM over the existing models for CTR prediction, on both benchmark data and\ncommercial data.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 04:55:19 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Guo", "Huifeng", ""], ["Tang", "Ruiming", ""], ["Ye", "Yunming", ""], ["Li", "Zhenguo", ""], ["He", "Xiuqiang", ""]]}, {"id": "1703.04330", "submitter": "Todor Mihaylov Todor Mihaylov", "authors": "Todor Mihaylov, Anette Frank", "title": "Story Cloze Ending Selection Baselines and Data Examination", "comments": "Submission for the LSDSem 2017 - Linking Models of Lexical,\n  Sentential and Discourse-level Semantics - Shared Task", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes two supervised baseline systems for the Story Cloze Test\nShared Task (Mostafazadeh et al., 2016a). We first build a classifier using\nfeatures based on word embeddings and semantic similarity computation. We\nfurther implement a neural LSTM system with different encoding strategies that\ntry to model the relation between the story and the provided endings. Our\nexperiments show that a model using representation features based on average\nword embedding vectors over the given story words and the candidate ending\nsentences words, joint with similarity features between the story and candidate\nending representations performed better than the neural models. Our best model\nachieves an accuracy of 72.42, ranking 3rd in the official evaluation.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 11:03:40 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Mihaylov", "Todor", ""], ["Frank", "Anette", ""]]}, {"id": "1703.04336", "submitter": "Sergiu Nisioi", "authors": "Anca Bucur and Sergiu Nisioi", "title": "A Visual Representation of Wittgenstein's Tractatus Logico-Philosophicus", "comments": "Workshop on Language Technology Resources and Tools for Digital\n  Humanities (LT4DH)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a data visualization method together with its\npotential usefulness in digital humanities and philosophy of language. We\ncompile a multilingual parallel corpus from different versions of\nWittgenstein's Tractatus Logico-Philosophicus, including the original in German\nand translations into English, Spanish, French, and Russian. Using this corpus,\nwe compute a similarity measure between propositions and render a visual\nnetwork of relations for different languages.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 11:19:56 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Bucur", "Anca", ""], ["Nisioi", "Sergiu", ""]]}, {"id": "1703.04357", "submitter": "Rico Sennrich", "authors": "Rico Sennrich and Orhan Firat and Kyunghyun Cho and Alexandra Birch\n  and Barry Haddow and Julian Hitschler and Marcin Junczys-Dowmunt and Samuel\n  L\\\"aubli and Antonio Valerio Miceli Barone and Jozef Mokry and Maria\n  N\\u{a}dejde", "title": "Nematus: a Toolkit for Neural Machine Translation", "comments": "EACL 2017 demo track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Nematus, a toolkit for Neural Machine Translation. The toolkit\nprioritizes high translation accuracy, usability, and extensibility. Nematus\nhas been used to build top-performing submissions to shared translation tasks\nat WMT and IWSLT, and has been used to train systems for production\nenvironments.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 12:28:03 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Sennrich", "Rico", ""], ["Firat", "Orhan", ""], ["Cho", "Kyunghyun", ""], ["Birch", "Alexandra", ""], ["Haddow", "Barry", ""], ["Hitschler", "Julian", ""], ["Junczys-Dowmunt", "Marcin", ""], ["L\u00e4ubli", "Samuel", ""], ["Barone", "Antonio Valerio Miceli", ""], ["Mokry", "Jozef", ""], ["N\u0103dejde", "Maria", ""]]}, {"id": "1703.04417", "submitter": "Franco M. Luque", "authors": "Franco M. Luque", "title": "El Lenguaje Natural como Lenguaje Formal", "comments": "survey, 14 pages, 6 figures, in Spanish", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formal languages theory is useful for the study of natural language. In\nparticular, it is of interest to study the adequacy of the grammatical\nformalisms to express syntactic phenomena present in natural language. First,\nit helps to draw hypothesis about the nature and complexity of the\nspeaker-hearer linguistic competence, a fundamental question in linguistics and\nother cognitive sciences. Moreover, from an engineering point of view, it\nallows the knowledge of practical limitations of applications based on those\nformalisms. In this article I introduce the adequacy problem of grammatical\nformalisms for natural language, also introducing some formal language theory\nconcepts required for this discussion. Then, I review the formalisms that have\nbeen proposed in history, and the arguments that have been given to support or\nreject their adequacy.\n  -----\n  La teor\\'ia de lenguajes formales es \\'util para el estudio de los lenguajes\nnaturales. En particular, resulta de inter\\'es estudiar la adecuaci\\'on de los\nformalismos gramaticales para expresar los fen\\'omenos sint\\'acticos presentes\nen el lenguaje natural. Primero, ayuda a trazar hip\\'otesis acerca de la\nnaturaleza y complejidad de las competencias ling\\\"u\\'isticas de los\nhablantes-oyentes del lenguaje, un interrogante fundamental de la\nling\\\"u\\'istica y otras ciencias cognitivas. Adem\\'as, desde el punto de vista\nde la ingenier\\'ia, permite conocer limitaciones pr\\'acticas de las\naplicaciones basadas en dichos formalismos. En este art\\'iculo hago una\nintroducci\\'on al problema de la adecuaci\\'on de los formalismos gramaticales\npara el lenguaje natural, introduciendo tambi\\'en algunos conceptos de la\nteor\\'ia de lenguajes formales necesarios para esta discusi\\'on. Luego, hago un\nrepaso de los formalismos que han sido propuestos a lo largo de la historia, y\nde los argumentos que se han dado para sostener o refutar su adecuaci\\'on.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 14:34:23 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Luque", "Franco M.", ""]]}, {"id": "1703.04474", "submitter": "David Weiss", "authors": "Lingpeng Kong, Chris Alberti, Daniel Andor, Ivan Bogatyy, David Weiss", "title": "DRAGNN: A Transition-based Framework for Dynamically Connected Neural\n  Networks", "comments": "10 pages; Submitted for review to ACL2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a compact, modular framework for constructing novel\nrecurrent neural architectures. Our basic module is a new generic unit, the\nTransition Based Recurrent Unit (TBRU). In addition to hidden layer\nactivations, TBRUs have discrete state dynamics that allow network connections\nto be built dynamically as a function of intermediate activations. By\nconnecting multiple TBRUs, we can extend and combine commonly used\narchitectures such as sequence-to-sequence, attention mechanisms, and\nre-cursive tree-structured models. A TBRU can also serve as both an encoder for\ndownstream tasks and as a decoder for its own task simultaneously, resulting in\nmore accurate multi-task learning. We call our approach Dynamic Recurrent\nAcyclic Graphical Neural Networks, or DRAGNN. We show that DRAGNN is\nsignificantly more accurate and efficient than seq2seq with attention for\nsyntactic dependency parsing and yields more accurate multi-task learning for\nextractive summarization tasks.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 16:36:38 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Kong", "Lingpeng", ""], ["Alberti", "Chris", ""], ["Andor", "Daniel", ""], ["Bogatyy", "Ivan", ""], ["Weiss", "David", ""]]}, {"id": "1703.04481", "submitter": "John A. Goldsmith", "authors": "John Goldsmith and Eric Rosen", "title": "Geometrical morphology", "comments": "42 pages", "journal-ref": null, "doi": null, "report-no": "TR-2017-2", "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore inflectional morphology as an example of the relationship of the\ndiscrete and the continuous in linguistics. The grammar requests a form of a\nlexeme by specifying a set of feature values, which corresponds to a corner M\nof a hypercube in feature value space. The morphology responds to that request\nby providing a morpheme, or a set of morphemes, whose vector sum is\ngeometrically closest to the corner M. In short, the chosen morpheme $\\mu$ is\nthe morpheme (or set of morphemes) that maximizes the inner product of $\\mu$\nand M.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 16:50:36 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Goldsmith", "John", ""], ["Rosen", "Eric", ""]]}, {"id": "1703.04489", "submitter": "Georgiana Dinu", "authors": "Georgiana Dinu, Wael Hamza and Radu Florian", "title": "Reinforcement Learning for Transition-Based Mention Detection", "comments": "Deep Reinforcement Learning Workshop, NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes an application of reinforcement learning to the mention\ndetection task. We define a novel action-based formulation for the mention\ndetection task, in which a model can flexibly revise past labeling decisions by\ngrouping together tokens and assigning partial mention labels. We devise a\nmethod to create mention-level episodes and we train a model by rewarding\ncorrectly labeled complete mentions, irrespective of the inner structure\ncreated. The model yields results which are on par with a competitive\nsupervised counterpart while being more flexible in terms of achieving targeted\nbehavior through reward modeling and generating internal mention structure,\nespecially on longer mentions.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 17:13:51 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Dinu", "Georgiana", ""], ["Hamza", "Wael", ""], ["Florian", "Radu", ""]]}, {"id": "1703.04498", "submitter": "Preeti Bhargava", "authors": "Preeti Bhargava, Nemanja Spasojevic, Guoning Hu", "title": "High-Throughput and Language-Agnostic Entity Disambiguation and Linking\n  on User Generated Data", "comments": "10 pages, 7 figures, 5 tables, WWW2017, Linked Data on the Web\n  workshop 2017, LDOW'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Entity Disambiguation and Linking (EDL) task matches entity mentions in\ntext to a unique Knowledge Base (KB) identifier such as a Wikipedia or Freebase\nid. It plays a critical role in the construction of a high quality information\nnetwork, and can be further leveraged for a variety of information retrieval\nand NLP tasks such as text categorization and document tagging. EDL is a\ncomplex and challenging problem due to ambiguity of the mentions and real world\ntext being multi-lingual. Moreover, EDL systems need to have high throughput\nand should be lightweight in order to scale to large datasets and run on\noff-the-shelf machines. More importantly, these systems need to be able to\nextract and disambiguate dense annotations from the data in order to enable an\nInformation Retrieval or Extraction task running on the data to be more\nefficient and accurate. In order to address all these challenges, we present\nthe Lithium EDL system and algorithm - a high-throughput, lightweight,\nlanguage-agnostic EDL system that extracts and correctly disambiguates 75% more\nentities than state-of-the-art EDL systems and is significantly faster than\nthem.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 17:34:18 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Bhargava", "Preeti", ""], ["Spasojevic", "Nemanja", ""], ["Hu", "Guoning", ""]]}, {"id": "1703.04512", "submitter": "Mokhtar Ben Henda", "authors": "Henri Hudrisier, Ben Henda Mokhtar", "title": "Normalisation de la langue et de lecriture arabe : enjeux culturels\n  regionaux et mondiaux", "comments": "17 p, in French", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Arabic language and writing are now facing a resurgence of international\nnormative solutions that challenge most of their local or network based\noperating principles. Even if the multilingual digital coding solutions,\nespecially those proposed by Unicode, have solved many difficulties of Arabic\nwriting, the linguistic aspect is still in search of more adapted solutions.\nTerminology is one of the sectors in which the Arabic language requires a deep\nmodernization of its classical productivity models. The normative approach, in\nparticular that of the ISO TC37, is proposed as one of the solutions that would\nallow it to combine with international standards to better integrate the\nknowledge society under construction.\n  La langue et lecriture arabe sont aujourdhui confrontees a une recrudescence\nde solutions normatives internationales qui remettent en cause la plupart de\nleurs principes de fonctionnement en site ou sur les reseaux. Meme si les\nsolutions du codage numerique multilingue, notamment celles proposees par\nUnicode, ont resolu beaucoup de difficultes de lecriture arabe, le volet\nlinguistique est encore en quete de solutions plus adaptees. La terminologie\nest lun des secteurs dans lequel la langue arabe necessite une modernisation\nprofonde de ses modeles classiques de production. La voie normative, notamment\ncelle du TC37 de ISO, est proposee comme une des solutions qui lui permettrait\nde se mettre en synergie avec les referentiels internationaux pour mieux\nintegrer la societe du savoir en voie de construction.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 07:00:51 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Hudrisier", "Henri", ""], ["Mokhtar", "Ben Henda", ""]]}, {"id": "1703.04617", "submitter": "Junbei Zhang", "authors": "Junbei Zhang, Xiaodan Zhu, Qian Chen, Lirong Dai, Si Wei, and Hui\n  Jiang", "title": "Exploring Question Understanding and Adaptation in Neural-Network-Based\n  Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last several years have seen intensive interest in exploring\nneural-network-based models for machine comprehension (MC) and question\nanswering (QA). In this paper, we approach the problems by closely modelling\nquestions in a neural network framework. We first introduce syntactic\ninformation to help encode questions. We then view and model different types of\nquestions and the information shared among them as an adaptation task and\nproposed adaptation models for them. On the Stanford Question Answering Dataset\n(SQuAD), we show that these approaches can help attain better results over a\ncompetitive baseline.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 17:43:25 GMT"}, {"version": "v2", "created": "Sat, 25 Mar 2017 16:17:03 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Zhang", "Junbei", ""], ["Zhu", "Xiaodan", ""], ["Chen", "Qian", ""], ["Dai", "Lirong", ""], ["Wei", "Si", ""], ["Jiang", "Hui", ""]]}, {"id": "1703.04650", "submitter": "Anirban Laha", "authors": "Vardaan Pahuja, Anirban Laha, Shachar Mirkin, Vikas Raykar, Lili\n  Kotlerman, Guy Lev", "title": "Joint Learning of Correlated Sequence Labelling Tasks Using\n  Bidirectional Recurrent Neural Networks", "comments": "Accepted in Interspeech 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stream of words produced by Automatic Speech Recognition (ASR) systems is\ntypically devoid of punctuations and formatting. Most natural language\nprocessing applications expect segmented and well-formatted texts as input,\nwhich is not available in ASR output. This paper proposes a novel technique of\njointly modeling multiple correlated tasks such as punctuation and\ncapitalization using bidirectional recurrent neural networks, which leads to\nimproved performance for each of these tasks. This method could be extended for\njoint modeling of any other correlated sequence labeling tasks.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 18:26:12 GMT"}, {"version": "v2", "created": "Tue, 21 Mar 2017 12:56:11 GMT"}, {"version": "v3", "created": "Tue, 18 Jul 2017 06:33:54 GMT"}], "update_date": "2017-07-19", "authors_parsed": [["Pahuja", "Vardaan", ""], ["Laha", "Anirban", ""], ["Mirkin", "Shachar", ""], ["Raykar", "Vikas", ""], ["Kotlerman", "Lili", ""], ["Lev", "Guy", ""]]}, {"id": "1703.04677", "submitter": "Paul M\\\"atzig", "authors": "Paul M\\\"atzig, Shravan Vasishth, Felix Engelmann, David Caplan", "title": "A computational investigation of sources of variability in sentence\n  comprehension difficulty in aphasia", "comments": "6 pages, 4 tables, to appear in Proceedings of MathPsych/ICCM 2017,\n  Warwick, UK", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a computational evaluation of three hypotheses about sources of\ndeficit in sentence comprehension in aphasia: slowed processing, intermittent\ndeficiency, and resource reduction. The ACT-R based Lewis and Vasishth (2005)\nmodel is used to implement these three proposals. Slowed processing is\nimplemented as slowed default production-rule firing time; intermittent\ndeficiency as increased random noise in activation of chunks in memory; and\nresource reduction as reduced goal activation. As data, we considered subject\nvs. object rela- tives whose matrix clause contained either an NP or a\nreflexive, presented in a self-paced listening modality to 56 individuals with\naphasia (IWA) and 46 matched controls. The participants heard the sentences and\ncarried out a picture verification task to decide on an interpretation of the\nsentence. These response accuracies are used to identify the best parameters\n(for each participant) that correspond to the three hypotheses mentioned above.\nWe show that controls have more tightly clustered (less variable) parameter\nvalues than IWA; specifically, compared to controls, among IWA there are more\nindividuals with low goal activations, high noise, and slow default action\ntimes. This suggests that (i) individual patients show differential amounts of\ndeficit along the three dimensions of slowed processing, intermittent\ndeficient, and resource reduction, (ii) overall, there is evidence for all\nthree sources of deficit playing a role, and (iii) IWA have a more variable\nrange of parameter values than controls. In sum, this study contributes a proof\nof concept of a quantitative implementation of, and evidence for, these three\naccounts of comprehension deficits in aphasia.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 19:14:32 GMT"}, {"version": "v2", "created": "Wed, 31 May 2017 11:53:01 GMT"}], "update_date": "2017-06-01", "authors_parsed": [["M\u00e4tzig", "Paul", ""], ["Vasishth", "Shravan", ""], ["Engelmann", "Felix", ""], ["Caplan", "David", ""]]}, {"id": "1703.04718", "submitter": "Juan-Manuel Torres-Moreno", "authors": "Iria da Cunha, Eric SanJuan, Juan-Manuel Torres-Moreno, Irene\n  Castell\\'on", "title": "Extending Automatic Discourse Segmentation for Texts in Spanish to\n  Catalan", "comments": null, "journal-ref": "Proceedings of the First Workshop on Modeling, Learning and Mining\n  for Cross/Multilinguality (MultiLingMine 2016), 38th European Conference on\n  Information Retrieval (ECIR 2016)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At present, automatic discourse analysis is a relevant research topic in the\nfield of NLP. However, discourse is one of the phenomena most difficult to\nprocess. Although discourse parsers have been already developed for several\nlanguages, this tool does not exist for Catalan. In order to implement this\nkind of parser, the first step is to develop a discourse segmenter. In this\narticle we present the first discourse segmenter for texts in Catalan. This\nsegmenter is based on Rhetorical Structure Theory (RST) for Spanish, and uses\nlexical and syntactic information to translate rules valid for Spanish into\nrules for Catalan. We have evaluated the system by using a gold standard corpus\nincluding manually segmented texts and results are promising.\n", "versions": [{"version": "v1", "created": "Sat, 11 Mar 2017 07:37:37 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["da Cunha", "Iria", ""], ["SanJuan", "Eric", ""], ["Torres-Moreno", "Juan-Manuel", ""], ["Castell\u00f3n", "Irene", ""]]}, {"id": "1703.04783", "submitter": "Shinji Watanabe Shinji Watanabe", "authors": "Tsubasa Ochiai, Shinji Watanabe, Takaaki Hori, John R. Hershey", "title": "Multichannel End-to-end Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of speech recognition is in the midst of a paradigm shift:\nend-to-end neural networks are challenging the dominance of hidden Markov\nmodels as a core technology. Using an attention mechanism in a recurrent\nencoder-decoder architecture solves the dynamic time alignment problem,\nallowing joint end-to-end training of the acoustic and language modeling\ncomponents. In this paper we extend the end-to-end framework to encompass\nmicrophone array signal processing for noise suppression and speech enhancement\nwithin the acoustic encoding network. This allows the beamforming components to\nbe optimized jointly within the recognition architecture to improve the\nend-to-end speech recognition objective. Experiments on the noisy speech\nbenchmarks (CHiME-4 and AMI) show that our multichannel end-to-end system\noutperformed the attention-based baseline with input from a conventional\nadaptive beamformer.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 22:28:51 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Ochiai", "Tsubasa", ""], ["Watanabe", "Shinji", ""], ["Hori", "Takaaki", ""], ["Hershey", "John R.", ""]]}, {"id": "1703.04816", "submitter": "Dirk Weissenborn", "authors": "Dirk Weissenborn and Georg Wiese and Laura Seiffe", "title": "Making Neural QA as Simple as Possible but not Simpler", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent development of large-scale question answering (QA) datasets triggered\na substantial amount of research into end-to-end neural architectures for QA.\nIncreasingly complex systems have been conceived without comparison to simpler\nneural baseline systems that would justify their complexity. In this work, we\npropose a simple heuristic that guides the development of neural baseline\nsystems for the extractive QA task. We find that there are two ingredients\nnecessary for building a high-performing neural QA system: first, the awareness\nof question words while processing the context and second, a composition\nfunction that goes beyond simple bag-of-words modeling, such as recurrent\nneural networks. Our results show that FastQA, a system that meets these two\nrequirements, can achieve very competitive performance compared with existing\nmodels. We argue that this surprising finding puts results of previous systems\nand the complexity of recent QA datasets into perspective.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 23:09:45 GMT"}, {"version": "v2", "created": "Fri, 7 Apr 2017 07:40:23 GMT"}, {"version": "v3", "created": "Thu, 8 Jun 2017 14:12:35 GMT"}], "update_date": "2017-06-09", "authors_parsed": [["Weissenborn", "Dirk", ""], ["Wiese", "Georg", ""], ["Seiffe", "Laura", ""]]}, {"id": "1703.04826", "submitter": "Diego Marcheggiani", "authors": "Diego Marcheggiani and Ivan Titov", "title": "Encoding Sentences with Graph Convolutional Networks for Semantic Role\n  Labeling", "comments": "To appear in EMNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic role labeling (SRL) is the task of identifying the\npredicate-argument structure of a sentence. It is typically regarded as an\nimportant step in the standard NLP pipeline. As the semantic representations\nare closely related to syntactic ones, we exploit syntactic information in our\nmodel. We propose a version of graph convolutional networks (GCNs), a recent\nclass of neural networks operating on graphs, suited to model syntactic\ndependency graphs. GCNs over syntactic dependency trees are used as sentence\nencoders, producing latent feature representations of words in a sentence. We\nobserve that GCN layers are complementary to LSTM ones: when we stack both GCN\nand LSTM layers, we obtain a substantial improvement over an already\nstate-of-the-art LSTM SRL model, resulting in the best reported scores on the\nstandard benchmark (CoNLL-2009) both for Chinese and English.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 23:25:34 GMT"}, {"version": "v2", "created": "Tue, 23 May 2017 09:47:59 GMT"}, {"version": "v3", "created": "Wed, 24 May 2017 09:48:05 GMT"}, {"version": "v4", "created": "Sun, 30 Jul 2017 17:24:38 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Marcheggiani", "Diego", ""], ["Titov", "Ivan", ""]]}, {"id": "1703.04854", "submitter": "Junhua He", "authors": "Junhua He, Hankz Hankui Zhuo and Jarvan Law", "title": "Distributed-Representation Based Hybrid Recommender System with Short\n  Item Descriptions", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative filtering (CF) aims to build a model from users' past behaviors\nand/or similar decisions made by other users, and use the model to recommend\nitems for users. Despite of the success of previous collaborative filtering\napproaches, they are all based on the assumption that there are sufficient\nrating scores available for building high-quality recommendation models. In\nreal world applications, however, it is often difficult to collect sufficient\nrating scores, especially when new items are introduced into the system, which\nmakes the recommendation task challenging. We find that there are often \"short\"\ntexts describing features of items, based on which we can approximate the\nsimilarity of items and make recommendation together with rating scores. In\nthis paper we \"borrow\" the idea of vector representation of words to capture\nthe information of short texts and embed it into a matrix factorization\nframework. We empirically show that our approach is effective by comparing it\nwith state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 00:47:28 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["He", "Junhua", ""], ["Zhuo", "Hankz Hankui", ""], ["Law", "Jarvan", ""]]}, {"id": "1703.04879", "submitter": "Mamoru Komachi", "authors": "Ai Hirata and Mamoru Komachi", "title": "Sparse Named Entity Classification using Factorization Machines", "comments": "4+1 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Named entity classification is the task of classifying text-based elements\ninto various categories, including places, names, dates, times, and monetary\nvalues. A bottleneck in named entity classification, however, is the data\nproblem of sparseness, because new named entities continually emerge, making it\nrather difficult to maintain a dictionary for named entity classification.\nThus, in this paper, we address the problem of named entity classification\nusing matrix factorization to overcome the problem of feature sparsity.\nExperimental results show that our proposed model, with fewer features and a\nsmaller size, achieves competitive accuracy to state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 01:54:52 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Hirata", "Ai", ""], ["Komachi", "Mamoru", ""]]}, {"id": "1703.04887", "submitter": "Zhen Yang", "authors": "Zhen Yang, Wei Chen, Feng Wang and Bo Xu", "title": "Improving Neural Machine Translation with Conditional Sequence\n  Generative Adversarial Nets", "comments": "code released, accepted by NAACL2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an approach for applying GANs to NMT. We build a\nconditional sequence generative adversarial net which comprises of two\nadversarial sub models, a generator and a discriminator. The generator aims to\ngenerate sentences which are hard to be discriminated from human-translated\nsentences (i.e., the golden target sentences), And the discriminator makes\nefforts to discriminate the machine-generated sentences from human-translated\nones. The two sub models play a mini-max game and achieve the win-win situation\nwhen they reach a Nash Equilibrium. Additionally, the static sentence-level\nBLEU is utilized as the reinforced objective for the generator, which biases\nthe generation towards high BLEU points. During training, both the dynamic\ndiscriminator and the static BLEU objective are employed to evaluate the\ngenerated sentences and feedback the evaluations to guide the learning of the\ngenerator. Experimental results show that the proposed model consistently\noutperforms the traditional RNNSearch and the newly emerged state-of-the-art\nTransformer on English-German and Chinese-English translation tasks.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 02:26:25 GMT"}, {"version": "v2", "created": "Mon, 17 Apr 2017 02:24:05 GMT"}, {"version": "v3", "created": "Wed, 8 Nov 2017 14:27:29 GMT"}, {"version": "v4", "created": "Sun, 8 Apr 2018 08:23:43 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Yang", "Zhen", ""], ["Chen", "Wei", ""], ["Wang", "Feng", ""], ["Xu", "Bo", ""]]}, {"id": "1703.04908", "submitter": "Igor Mordatch", "authors": "Igor Mordatch, Pieter Abbeel", "title": "Emergence of Grounded Compositional Language in Multi-Agent Populations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By capturing statistical patterns in large corpora, machine learning has\nenabled significant advances in natural language processing, including in\nmachine translation, question answering, and sentiment analysis. However, for\nagents to intelligently interact with humans, simply capturing the statistical\npatterns is insufficient. In this paper we investigate if, and how, grounded\ncompositional language can emerge as a means to achieve goals in multi-agent\npopulations. Towards this end, we propose a multi-agent learning environment\nand learning methods that bring about emergence of a basic compositional\nlanguage. This language is represented as streams of abstract discrete symbols\nuttered by agents over time, but nonetheless has a coherent structure that\npossesses a defined vocabulary and syntax. We also observe emergence of\nnon-verbal communication such as pointing and guiding when language\ncommunication is unavailable.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 03:30:13 GMT"}, {"version": "v2", "created": "Tue, 24 Jul 2018 04:13:05 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Mordatch", "Igor", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1703.04914", "submitter": "Ikuya Yamada", "authors": "Ikuya Yamada, Motoki Sato, Hiroyuki Shindo", "title": "Ensemble of Neural Classifiers for Scoring Knowledge Base Triples", "comments": "WSDM Cup 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes our approach for the triple scoring task at the WSDM Cup\n2017. The task required participants to assign a relevance score for each pair\nof entities and their types in a knowledge base in order to enhance the ranking\nresults in entity retrieval tasks. We propose an approach wherein the outputs\nof multiple neural network classifiers are combined using a supervised machine\nlearning model. The experimental results showed that our proposed method\nachieved the best performance in one out of three measures (i.e., Kendall's\ntau), and performed competitively in the other two measures (i.e., accuracy and\naverage score difference).\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 04:00:27 GMT"}, {"version": "v2", "created": "Wed, 5 Apr 2017 13:58:02 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["Yamada", "Ikuya", ""], ["Sato", "Motoki", ""], ["Shindo", "Hiroyuki", ""]]}, {"id": "1703.04929", "submitter": "David Weiss", "authors": "Chris Alberti, Daniel Andor, Ivan Bogatyy, Michael Collins, Dan\n  Gillick, Lingpeng Kong, Terry Koo, Ji Ma, Mark Omernick, Slav Petrov, Chayut\n  Thanapirom, Zora Tung, David Weiss", "title": "SyntaxNet Models for the CoNLL 2017 Shared Task", "comments": "Tech report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a baseline dependency parsing system for the CoNLL2017 Shared\nTask. This system, which we call \"ParseySaurus,\" uses the DRAGNN framework\n[Kong et al, 2017] to combine transition-based recurrent parsing and tagging\nwith character-based word representations. On the v1.3 Universal Dependencies\nTreebanks, the new system outpeforms the publicly available, state-of-the-art\n\"Parsey's Cousins\" models by 3.47% absolute Labeled Accuracy Score (LAS) across\n52 treebanks.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 04:57:17 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Alberti", "Chris", ""], ["Andor", "Daniel", ""], ["Bogatyy", "Ivan", ""], ["Collins", "Michael", ""], ["Gillick", "Dan", ""], ["Kong", "Lingpeng", ""], ["Koo", "Terry", ""], ["Ma", "Ji", ""], ["Omernick", "Mark", ""], ["Petrov", "Slav", ""], ["Thanapirom", "Chayut", ""], ["Tung", "Zora", ""], ["Weiss", "David", ""]]}, {"id": "1703.05122", "submitter": "Jasabanta Patro", "authors": "Jasabanta Patro, Bidisha Samanta, Saurabh Singh, Prithwish Mukherjee,\n  Monojit Choudhury, Animesh Mukherjee", "title": "Is this word borrowed? An automatic approach to quantify the likeliness\n  of borrowing in social media", "comments": "11 pages, 3 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code-mixing or code-switching are the effortless phenomena of natural\nswitching between two or more languages in a single conversation. Use of a\nforeign word in a language; however, does not necessarily mean that the speaker\nis code-switching because often languages borrow lexical items from other\nlanguages. If a word is borrowed, it becomes a part of the lexicon of a\nlanguage; whereas, during code-switching, the speaker is aware that the\nconversation involves foreign words or phrases. Identifying whether a foreign\nword used by a bilingual speaker is due to borrowing or code-switching is a\nfundamental importance to theories of multilingualism, and an essential\nprerequisite towards the development of language and speech technologies for\nmultilingual communities. In this paper, we present a series of novel\ncomputational methods to identify the borrowed likeliness of a word, based on\nthe social media signals. We first propose context based clustering method to\nsample a set of candidate words from the social media data.Next, we propose\nthree novel and similar metrics based on the usage of these words by the users\nin different tweets; these metrics were used to score and rank the candidate\nwords indicating their borrowed likeliness. We compare these rankings with a\nground truth ranking constructed through a human judgment experiment. The\nSpearman's rank correlation between the two rankings (nearly 0.62 for all the\nthree metric variants) is more than double the value (0.26) of the most\ncompetitive existing baseline reported in the literature. Some other striking\nobservations are, (i) the correlation is higher for the ground truth data\nelicited from the younger participants (age less than 30) than that from the\nolder participants, and (ii )those participants who use mixed-language for\ntweeting the least, provide the best signals of borrowing.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 12:32:34 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Patro", "Jasabanta", ""], ["Samanta", "Bidisha", ""], ["Singh", "Saurabh", ""], ["Mukherjee", "Prithwish", ""], ["Choudhury", "Monojit", ""], ["Mukherjee", "Animesh", ""]]}, {"id": "1703.05123", "submitter": "Svitlana Vakulenko", "authors": "Svitlana Vakulenko, Lyndon Nixon, Mihai Lupu", "title": "Character-based Neural Embeddings for Tweet Clustering", "comments": "Accepted at the SocialNLP 2017 workshop held in conjunction with EACL\n  2017, April 3, 2017, Valencia, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we show how the performance of tweet clustering can be improved\nby leveraging character-based neural networks. The proposed approach overcomes\nthe limitations related to the vocabulary explosion in the word-based models\nand allows for the seamless processing of the multilingual content. Our\nevaluation results and code are available on-line at\nhttps://github.com/vendi12/tweet2vec_clustering\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 12:37:22 GMT"}, {"version": "v2", "created": "Thu, 16 Mar 2017 08:57:29 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Vakulenko", "Svitlana", ""], ["Nixon", "Lyndon", ""], ["Lupu", "Mihai", ""]]}, {"id": "1703.05260", "submitter": "Ashutosh Modi", "authors": "Ashutosh Modi and Tatjana Anikina and Simon Ostermann and Manfred\n  Pinkal", "title": "InScript: Narrative texts annotated with script information", "comments": "Paper accepted at LREC 2016, 9 pages, The corpus can be downloaded\n  at: http://www.sfb1102.uni-saarland.de/?page_id=2582", "journal-ref": "LREC 2016", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the InScript corpus (Narrative Texts Instantiating Script\nstructure). InScript is a corpus of 1,000 stories centered around 10 different\nscenarios. Verbs and noun phrases are annotated with event and participant\ntypes, respectively. Additionally, the text is annotated with coreference\ninformation. The corpus shows rich lexical variation and will serve as a unique\nresource for the study of the role of script knowledge in natural language\nprocessing.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 17:01:20 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Modi", "Ashutosh", ""], ["Anikina", "Tatjana", ""], ["Ostermann", "Simon", ""], ["Pinkal", "Manfred", ""]]}, {"id": "1703.05320", "submitter": "Phong Do Khac", "authors": "Phong-Khac Do, Huy-Tien Nguyen, Chien-Xuan Tran, Minh-Tien Nguyen, and\n  Minh-Le Nguyen", "title": "Legal Question Answering using Ranking SVM and Deep Convolutional Neural\n  Network", "comments": "15 pages, 2 figures, Tenth International Workshop on\n  Juris-informatics (JURISIN 2016) associated with JSAI International Symposia\n  on AI 2016 (IsAI-2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a study of employing Ranking SVM and Convolutional Neural\nNetwork for two missions: legal information retrieval and question answering in\nthe Competition on Legal Information Extraction/Entailment. For the first task,\nour proposed model used a triple of features (LSI, Manhattan, Jaccard), and is\nbased on paragraph level instead of article level as in previous studies. In\nfact, each single-paragraph article corresponds to a particular paragraph in a\nhuge multiple-paragraph article. For the legal question answering task,\nadditional statistical features from information retrieval task integrated into\nConvolutional Neural Network contribute to higher accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 01:06:07 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Do", "Phong-Khac", ""], ["Nguyen", "Huy-Tien", ""], ["Tran", "Chien-Xuan", ""], ["Nguyen", "Minh-Tien", ""], ["Nguyen", "Minh-Le", ""]]}, {"id": "1703.05390", "submitter": "Sercan Arik", "authors": "Sercan O. Arik, Markus Kliegl, Rewon Child, Joel Hestness, Andrew\n  Gibiansky, Chris Fougner, Ryan Prenger, Adam Coates", "title": "Convolutional Recurrent Neural Networks for Small-Footprint Keyword\n  Spotting", "comments": "Accepted to Interspeech 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keyword spotting (KWS) constitutes a major component of human-technology\ninterfaces. Maximizing the detection accuracy at a low false alarm (FA) rate,\nwhile minimizing the footprint size, latency and complexity are the goals for\nKWS. Towards achieving them, we study Convolutional Recurrent Neural Networks\n(CRNNs). Inspired by large-scale state-of-the-art speech recognition systems,\nwe combine the strengths of convolutional layers and recurrent layers to\nexploit local structure and long-range context. We analyze the effect of\narchitecture parameters, and propose training strategies to improve\nperformance. With only ~230k parameters, our CRNN model yields acceptably low\nlatency, and achieves 97.71% accuracy at 0.5 FA/hour for 5 dB signal-to-noise\nratio.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 21:20:44 GMT"}, {"version": "v2", "created": "Wed, 24 May 2017 00:37:05 GMT"}, {"version": "v3", "created": "Tue, 4 Jul 2017 22:49:18 GMT"}], "update_date": "2017-07-06", "authors_parsed": [["Arik", "Sercan O.", ""], ["Kliegl", "Markus", ""], ["Child", "Rewon", ""], ["Hestness", "Joel", ""], ["Gibiansky", "Andrew", ""], ["Fougner", "Chris", ""], ["Prenger", "Ryan", ""], ["Coates", "Adam", ""]]}, {"id": "1703.05423", "submitter": "Florian Strub", "authors": "Florian Strub and Harm de Vries and Jeremie Mary and Bilal Piot and\n  Aaron Courville and Olivier Pietquin", "title": "End-to-end optimization of goal-driven and visually grounded dialogue\n  systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end design of dialogue systems has recently become a popular research\ntopic thanks to powerful tools such as encoder-decoder architectures for\nsequence-to-sequence learning. Yet, most current approaches cast human-machine\ndialogue management as a supervised learning problem, aiming at predicting the\nnext utterance of a participant given the full history of the dialogue. This\nvision is too simplistic to render the intrinsic planning problem inherent to\ndialogue as well as its grounded nature, making the context of a dialogue\nlarger than the sole history. This is why only chit-chat and question answering\ntasks have been addressed so far using end-to-end architectures. In this paper,\nwe introduce a Deep Reinforcement Learning method to optimize visually grounded\ntask-oriented dialogues, based on the policy gradient algorithm. This approach\nis tested on a dataset of 120k dialogues collected through Mechanical Turk and\nprovides encouraging results at solving both the problem of generating natural\ndialogues and the task of discovering a specific object in a complex picture.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 23:34:20 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Strub", "Florian", ""], ["de Vries", "Harm", ""], ["Mary", "Jeremie", ""], ["Piot", "Bilal", ""], ["Courville", "Aaron", ""], ["Pietquin", "Olivier", ""]]}, {"id": "1703.05465", "submitter": "Ernie Chang", "authors": "Wenli Zhuang and Ernie Chang", "title": "Neobility at SemEval-2017 Task 1: An Attention-based Sentence Similarity\n  Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a neural-network model which performed competitively\n(top 6) at the SemEval 2017 cross-lingual Semantic Textual Similarity (STS)\ntask. Our system employs an attention-based recurrent neural network model that\noptimizes the sentence similarity. In this paper, we describe our participation\nin the multilingual STS task which measures similarity across English, Spanish,\nand Arabic.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 03:15:22 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Zhuang", "Wenli", ""], ["Chang", "Ernie", ""]]}, {"id": "1703.05706", "submitter": "Myungha Jang", "authors": "Myungha Jang, Jinho D. Choi, James Allan", "title": "Improving Document Clustering by Eliminating Unnatural Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technical documents contain a fair amount of unnatural language, such as\ntables, formulas, pseudo-codes, etc. Unnatural language can be an important\nfactor of confusing existing NLP tools. This paper presents an effective method\nof distinguishing unnatural language from natural language, and evaluates the\nimpact of unnatural language detection on NLP tasks such as document\nclustering. We view this problem as an information extraction task and build a\nmulticlass classification model identifying unnatural language components into\nfour categories. First, we create a new annotated corpus by collecting slides\nand papers in various formats, PPT, PDF, and HTML, where unnatural language\ncomponents are annotated into four categories. We then explore features\navailable from plain text to build a statistical model that can handle any\nformat as long as it is converted into plain text. Our experiments show that\nremoving unnatural language components gives an absolute improvement in\ndocument clustering up to 15%. Our corpus and tool are publicly available.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 16:32:06 GMT"}, {"version": "v2", "created": "Fri, 17 Mar 2017 04:03:36 GMT"}], "update_date": "2017-03-20", "authors_parsed": [["Jang", "Myungha", ""], ["Choi", "Jinho D.", ""], ["Allan", "James", ""]]}, {"id": "1703.05851", "submitter": "Yuanliang Meng", "authors": "Yuanliang Meng, Anna Rumshisky, Alexey Romanov", "title": "Temporal Information Extraction for Question Answering Using Syntactic\n  Dependencies in an LSTM-based Architecture", "comments": "EMNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose to use a set of simple, uniform in architecture\nLSTM-based models to recover different kinds of temporal relations from text.\nUsing the shortest dependency path between entities as input, the same\narchitecture is used to extract intra-sentence, cross-sentence, and document\ncreation time relations. A \"double-checking\" technique reverses entity pairs in\nclassification, boosting the recall of positive cases and reducing\nmisclassifications between opposite classes. An efficient pruning algorithm\nresolves conflicts globally. Evaluated on QA-TempEval (SemEval2015 Task 5), our\nproposed technique outperforms state-of-the-art methods by a large margin.\n", "versions": [{"version": "v1", "created": "Fri, 17 Mar 2017 00:02:42 GMT"}, {"version": "v2", "created": "Thu, 5 Oct 2017 21:38:08 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Meng", "Yuanliang", ""], ["Rumshisky", "Anna", ""], ["Romanov", "Alexey", ""]]}, {"id": "1703.05880", "submitter": "Lei Xie", "authors": "Wenpeng Li, BinBin Zhang, Lei Xie, Dong Yu", "title": "Empirical Evaluation of Parallel Training Algorithms on Acoustic\n  Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models (DLMs) are state-of-the-art techniques in speech\nrecognition. However, training good DLMs can be time consuming especially for\nproduction-size models and corpora. Although several parallel training\nalgorithms have been proposed to improve training efficiency, there is no clear\nguidance on which one to choose for the task in hand due to lack of systematic\nand fair comparison among them. In this paper we aim at filling this gap by\ncomparing four popular parallel training algorithms in speech recognition,\nnamely asynchronous stochastic gradient descent (ASGD), blockwise model-update\nfiltering (BMUF), bulk synchronous parallel (BSP) and elastic averaging\nstochastic gradient descent (EASGD), on 1000-hour LibriSpeech corpora using\nfeed-forward deep neural networks (DNNs) and convolutional, long short-term\nmemory, DNNs (CLDNNs). Based on our experiments, we recommend using BMUF as the\ntop choice to train acoustic models since it is most stable, scales well with\nnumber of GPUs, can achieve reproducible results, and in many cases even\noutperforms single-GPU SGD. ASGD can be used as a substitute in some cases.\n", "versions": [{"version": "v1", "created": "Fri, 17 Mar 2017 03:38:48 GMT"}, {"version": "v2", "created": "Wed, 26 Jul 2017 06:29:54 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Li", "Wenpeng", ""], ["Zhang", "BinBin", ""], ["Xie", "Lei", ""], ["Yu", "Dong", ""]]}, {"id": "1703.05908", "submitter": "Yao-Hung Tsai", "authors": "Yao-Hung Hubert Tsai and Liang-Kang Huang and Ruslan Salakhutdinov", "title": "Learning Robust Visual-Semantic Embeddings", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many of the existing methods for learning joint embedding of images and text\nuse only supervised information from paired images and its textual attributes.\nTaking advantage of the recent success of unsupervised learning in deep neural\nnetworks, we propose an end-to-end learning framework that is able to extract\nmore robust multi-modal representations across domains. The proposed method\ncombines representation learning models (i.e., auto-encoders) together with\ncross-domain learning criteria (i.e., Maximum Mean Discrepancy loss) to learn\njoint embeddings for semantic and visual features. A novel technique of\nunsupervised-data adaptation inference is introduced to construct more\ncomprehensive embeddings for both labeled and unlabeled data. We evaluate our\nmethod on Animals with Attributes and Caltech-UCSD Birds 200-2011 dataset with\na wide range of applications, including zero and few-shot image recognition and\nretrieval, from inductive to transductive settings. Empirically, we show that\nour framework improves over the current state of the art on many of the\nconsidered tasks.\n", "versions": [{"version": "v1", "created": "Fri, 17 Mar 2017 06:59:51 GMT"}, {"version": "v2", "created": "Mon, 20 Mar 2017 00:28:07 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Tsai", "Yao-Hung Hubert", ""], ["Huang", "Liang-Kang", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1703.05916", "submitter": "Mamoru Komachi", "authors": "Yuya Sakaizawa and Mamoru Komachi", "title": "Construction of a Japanese Word Similarity Dataset", "comments": "LREC 2018; 4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  An evaluation of distributed word representation is generally conducted using\na word similarity task and/or a word analogy task. There are many datasets\nreadily available for these tasks in English. However, evaluating distributed\nrepresentation in languages that do not have such resources (e.g., Japanese) is\ndifficult. Therefore, as a first step toward evaluating distributed\nrepresentations in Japanese, we constructed a Japanese word similarity dataset.\nTo the best of our knowledge, our dataset is the first resource that can be\nused to evaluate distributed representations in Japanese. Moreover, our dataset\ncontains various parts of speech and includes rare words in addition to common\nwords.\n", "versions": [{"version": "v1", "created": "Fri, 17 Mar 2017 07:53:03 GMT"}, {"version": "v2", "created": "Thu, 22 Feb 2018 07:55:54 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Sakaizawa", "Yuya", ""], ["Komachi", "Mamoru", ""]]}, {"id": "1703.06108", "submitter": "Nemanja Spasojevic", "authors": "Prantik Bhattacharyya, Nemanja Spasojevic", "title": "Global Entity Ranking Across Multiple Languages", "comments": "2 Pages, 1 Figure, 2 Tables, WWW2017 Companion, WWW 2017 Companion", "journal-ref": null, "doi": "10.1145/3041021.3054213", "report-no": null, "categories": "cs.IR cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present work on building a global long-tailed ranking of entities across\nmultiple languages using Wikipedia and Freebase knowledge bases. We identify\nmultiple features and build a model to rank entities using a ground-truth\ndataset of more than 10 thousand labels. The final system ranks 27 million\nentities with 75% precision and 48% F1 score. We provide performance evaluation\nand empirical evidence of the quality of ranking across languages, and open the\nfinal ranked lists for future research.\n", "versions": [{"version": "v1", "created": "Fri, 17 Mar 2017 17:16:02 GMT"}], "update_date": "2017-03-20", "authors_parsed": [["Bhattacharyya", "Prantik", ""], ["Spasojevic", "Nemanja", ""]]}, {"id": "1703.06345", "submitter": "Zhilin Yang", "authors": "Zhilin Yang, Ruslan Salakhutdinov, William W. Cohen", "title": "Transfer Learning for Sequence Tagging with Hierarchical Recurrent\n  Networks", "comments": "Accepted as a conference paper at ICLR 2017. This is an extended\n  version of the original paper (https://arxiv.org/abs/1603.06270). The\n  original paper proposes a new architecture, while this version focuses on\n  transfer learning for a general model class", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent papers have shown that neural networks obtain state-of-the-art\nperformance on several different sequence tagging tasks. One appealing property\nof such systems is their generality, as excellent performance can be achieved\nwith a unified architecture and without task-specific feature engineering.\nHowever, it is unclear if such systems can be used for tasks without large\namounts of training data. In this paper we explore the problem of transfer\nlearning for neural sequence taggers, where a source task with plentiful\nannotations (e.g., POS tagging on Penn Treebank) is used to improve performance\non a target task with fewer available annotations (e.g., POS tagging for\nmicroblogs). We examine the effects of transfer learning for deep hierarchical\nrecurrent networks across domains, applications, and languages, and show that\nsignificant improvement can often be obtained. These improvements lead to\nimprovements over the current state-of-the-art on several well-studied tasks.\n", "versions": [{"version": "v1", "created": "Sat, 18 Mar 2017 20:21:44 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Yang", "Zhilin", ""], ["Salakhutdinov", "Ruslan", ""], ["Cohen", "William W.", ""]]}, {"id": "1703.06492", "submitter": "Jia-Hong Huang", "authors": "Jia-Hong Huang, Modar Alfadly, Bernard Ghanem", "title": "VQABQ: Visual Question Answering by Basic Questions", "comments": "Accepted by CVPR 2017 VQA Challenge Workshop. (Tables updated)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Taking an image and question as the input of our method, it can output the\ntext-based answer of the query question about the given image, so called Visual\nQuestion Answering (VQA). There are two main modules in our algorithm. Given a\nnatural language question about an image, the first module takes the question\nas input and then outputs the basic questions of the main given question. The\nsecond module takes the main question, image and these basic questions as input\nand then outputs the text-based answer of the main question. We formulate the\nbasic questions generation problem as a LASSO optimization problem, and also\npropose a criterion about how to exploit these basic questions to help answer\nmain question. Our method is evaluated on the challenging VQA dataset and\nyields state-of-the-art accuracy, 60.34% in open-ended task.\n", "versions": [{"version": "v1", "created": "Sun, 19 Mar 2017 19:14:55 GMT"}, {"version": "v2", "created": "Mon, 28 Aug 2017 22:40:19 GMT"}], "update_date": "2017-08-30", "authors_parsed": [["Huang", "Jia-Hong", ""], ["Alfadly", "Modar", ""], ["Ghanem", "Bernard", ""]]}, {"id": "1703.06501", "submitter": "Juan-Manuel Torres-Moreno", "authors": "Elvys Linhares Pontes, Thiago Gouveia da Silva, Andr\\'ea Carneiro\n  Linhares, Juan-Manuel Torres-Moreno, St\\'ephane Huet", "title": "M\\'etodos de Otimiza\\c{c}\\~ao Combinat\\'oria Aplicados ao Problema de\n  Compress\\~ao MultiFrases", "comments": "12 pages, 1 figure, 3 tables (paper in Portuguese), Preprint of\n  XLVIII Simp\\'osio Brasileiro de Pesquisa Operacional, 2016, Vit\\'oria, ES,\n  (Brazil)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet has led to a dramatic increase in the amount of available\ninformation. In this context, reading and understanding this flow of\ninformation have become costly tasks. In the last years, to assist people to\nunderstand textual data, various Natural Language Processing (NLP) applications\nbased on Combinatorial Optimization have been devised. However, for\nMulti-Sentences Compression (MSC), method which reduces the sentence length\nwithout removing core information, the insertion of optimization methods\nrequires further study to improve the performance of MSC. This article\ndescribes a method for MSC using Combinatorial Optimization and Graph Theory to\ngenerate more informative sentences while maintaining their grammaticality. An\nexperiment led on a corpus of 40 clusters of sentences shows that our system\nhas achieved a very good quality and is better than the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sun, 19 Mar 2017 19:56:25 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Pontes", "Elvys Linhares", ""], ["da Silva", "Thiago Gouveia", ""], ["Linhares", "Andr\u00e9a Carneiro", ""], ["Torres-Moreno", "Juan-Manuel", ""], ["Huet", "St\u00e9phane", ""]]}, {"id": "1703.06541", "submitter": "Shervin Malmasi Ph.D.", "authors": "Shervin Malmasi and Mark Dras", "title": "Native Language Identification using Stacked Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble methods using multiple classifiers have proven to be the most\nsuccessful approach for the task of Native Language Identification (NLI),\nachieving the current state of the art. However, a systematic examination of\nensemble methods for NLI has yet to be conducted. Additionally, deeper ensemble\narchitectures such as classifier stacking have not been closely evaluated. We\npresent a set of experiments using three ensemble-based models, testing each\nwith multiple configurations and algorithms. This includes a rigorous\napplication of meta-classification models for NLI, achieving state-of-the-art\nresults on three datasets from different languages. We also present the first\nuse of statistical significance testing for comparing NLI systems, showing that\nour results are significantly better than the previous state of the art. We\nmake available a collection of test set predictions to facilitate future\nstatistical tests.\n", "versions": [{"version": "v1", "created": "Sun, 19 Mar 2017 23:42:28 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Malmasi", "Shervin", ""], ["Dras", "Mark", ""]]}, {"id": "1703.06585", "submitter": "Abhishek Das", "authors": "Abhishek Das, Satwik Kottur, Jos\\'e M. F. Moura, Stefan Lee, Dhruv\n  Batra", "title": "Learning Cooperative Visual Dialog Agents with Deep Reinforcement\n  Learning", "comments": "11 pages, 4 figures, 2 tables, webpage: http://visualdialog.org/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the first goal-driven training for visual question answering and\ndialog agents. Specifically, we pose a cooperative 'image guessing' game\nbetween two agents -- Qbot and Abot -- who communicate in natural language\ndialog so that Qbot can select an unseen image from a lineup of images. We use\ndeep reinforcement learning (RL) to learn the policies of these agents\nend-to-end -- from pixels to multi-agent multi-round dialog to game reward.\n  We demonstrate two experimental results.\n  First, as a 'sanity check' demonstration of pure RL (from scratch), we show\nresults on a synthetic world, where the agents communicate in ungrounded\nvocabulary, i.e., symbols with no pre-specified meanings (X, Y, Z). We find\nthat two bots invent their own communication protocol and start using certain\nsymbols to ask/answer about certain visual attributes (shape/color/style).\nThus, we demonstrate the emergence of grounded language and communication among\n'visual' dialog agents with no human supervision.\n  Second, we conduct large-scale real-image experiments on the VisDial dataset,\nwhere we pretrain with supervised dialog data and show that the RL 'fine-tuned'\nagents significantly outperform SL agents. Interestingly, the RL Qbot learns to\nask questions that Abot is good at, ultimately resulting in more informative\ndialog and a better team.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 03:50:57 GMT"}, {"version": "v2", "created": "Tue, 21 Mar 2017 17:41:23 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Das", "Abhishek", ""], ["Kottur", "Satwik", ""], ["Moura", "Jos\u00e9 M. F.", ""], ["Lee", "Stefan", ""], ["Batra", "Dhruv", ""]]}, {"id": "1703.06630", "submitter": "Juan-Manuel Torres-Moreno", "authors": "Mohamed Morchid, Juan-Manuel Torres-Moreno, Richard Dufour, Javier\n  Ram\\'irez-Rodr\\'iguez, Georges Linar\\`es", "title": "Automatic Text Summarization Approaches to Speed up Topic Model Learning\n  Process", "comments": "16 pages, 4 tables, 8 figures", "journal-ref": "International Journal of Computational Linguistics and\n  Applications, 7(2):87-109, 2016", "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The number of documents available into Internet moves each day up. For this\nreason, processing this amount of information effectively and expressibly\nbecomes a major concern for companies and scientists. Methods that represent a\ntextual document by a topic representation are widely used in Information\nRetrieval (IR) to process big data such as Wikipedia articles. One of the main\ndifficulty in using topic model on huge data collection is related to the\nmaterial resources (CPU time and memory) required for model estimate. To deal\nwith this issue, we propose to build topic spaces from summarized documents. In\nthis paper, we present a study of topic space representation in the context of\nbig data. The topic space representation behavior is analyzed on different\nlanguages. Experiments show that topic spaces estimated from text summaries are\nas relevant as those estimated from the complete documents. The real advantage\nof such an approach is the processing time gain: we showed that the processing\ntime can be drastically reduced using summarized documents (more than 60\\% in\ngeneral). This study finally points out the differences between thematic\nrepresentations of documents depending on the targeted languages such as\nEnglish or latin languages.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 08:19:43 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Morchid", "Mohamed", ""], ["Torres-Moreno", "Juan-Manuel", ""], ["Dufour", "Richard", ""], ["Ram\u00edrez-Rodr\u00edguez", "Javier", ""], ["Linar\u00e8s", "Georges", ""]]}, {"id": "1703.06642", "submitter": "Diederik Aerts", "authors": "Diederik Aerts, Jonito Aerts Arguelles, Lester Beltran, Lyneth\n  Beltran, Isaac Distrito, Massimiliano Sassoli de Bianchi, Sandro Sozzo and\n  Tomas Veloz", "title": "Towards a Quantum World Wide Web", "comments": "24 pages, no figures", "journal-ref": "Theoretical Computer Science, 752, pp. 116-131 (2018)", "doi": "10.1016/j.tcs.2018.03.019", "report-no": null, "categories": "cs.AI cs.CL quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We elaborate a quantum model for the meaning associated with corpora of\nwritten documents, like the pages forming the World Wide Web. To that end, we\nare guided by how physicists constructed quantum theory for microscopic\nentities, which unlike classical objects cannot be fully represented in our\nspatial theater. We suggest that a similar construction needs to be carried out\nby linguists and computational scientists, to capture the full meaning carried\nby collections of documental entities. More precisely, we show how to associate\na quantum-like 'entity of meaning' to a 'language entity formed by printed\ndocuments', considering the latter as the collection of traces that are left by\nthe former, in specific results of search actions that we describe as\nmeasurements. In other words, we offer a perspective where a collection of\ndocuments, like the Web, is described as the space of manifestation of a more\ncomplex entity - the QWeb - which is the object of our modeling, drawing its\ninspiration from previous studies on operational-realistic approaches to\nquantum physics and quantum modeling of human cognition and decision-making. We\nemphasize that a consistent QWeb model needs to account for the observed\ncorrelations between words appearing in printed documents, e.g.,\nco-occurrences, as the latter would depend on the 'meaning connections'\nexisting between the concepts that are associated with these words. In that\nrespect, we show that both 'context and interference (quantum) effects' are\nrequired to explain the probabilities calculated by counting the relative\nnumber of documents containing certain words and co-ocurrrences of words.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 09:28:38 GMT"}, {"version": "v2", "created": "Mon, 29 Jan 2018 20:00:49 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Aerts", "Diederik", ""], ["Arguelles", "Jonito Aerts", ""], ["Beltran", "Lester", ""], ["Beltran", "Lyneth", ""], ["Distrito", "Isaac", ""], ["de Bianchi", "Massimiliano Sassoli", ""], ["Sozzo", "Sandro", ""], ["Veloz", "Tomas", ""]]}, {"id": "1703.06676", "submitter": "Hao Dong", "authors": "Hao Dong, Jingqing Zhang, Douglas McIlwraith, Yike Guo", "title": "I2T2I: Learning Text to Image Synthesis with Textual Data Augmentation", "comments": "International Conference on Image Processing (ICIP) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Translating information between text and image is a fundamental problem in\nartificial intelligence that connects natural language processing and computer\nvision. In the past few years, performance in image caption generation has seen\nsignificant improvement through the adoption of recurrent neural networks\n(RNN). Meanwhile, text-to-image generation begun to generate plausible images\nusing datasets of specific categories like birds and flowers. We've even seen\nimage generation from multi-category datasets such as the Microsoft Common\nObjects in Context (MSCOCO) through the use of generative adversarial networks\n(GANs). Synthesizing objects with a complex shape, however, is still\nchallenging. For example, animals and humans have many degrees of freedom,\nwhich means that they can take on many complex shapes. We propose a new\ntraining method called Image-Text-Image (I2T2I) which integrates text-to-image\nand image-to-text (image captioning) synthesis to improve the performance of\ntext-to-image synthesis. We demonstrate that %the capability of our method to\nunderstand the sentence descriptions, so as to I2T2I can generate better\nmulti-categories images using MSCOCO than the state-of-the-art. We also\ndemonstrate that I2T2I can achieve transfer learning by using a pre-trained\nimage captioning module to generate human images on the MPII Human Pose\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 11:11:38 GMT"}, {"version": "v2", "created": "Mon, 8 May 2017 18:46:42 GMT"}, {"version": "v3", "created": "Sat, 3 Jun 2017 22:46:46 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Dong", "Hao", ""], ["Zhang", "Jingqing", ""], ["McIlwraith", "Douglas", ""], ["Guo", "Yike", ""]]}, {"id": "1703.07055", "submitter": "Xiujun Li", "authors": "Xiujun Li and Yun-Nung Chen and Lihong Li and Jianfeng Gao and Asli\n  Celikyilmaz", "title": "Investigation of Language Understanding Impact for Reinforcement\n  Learning Based Dialogue Systems", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language understanding is a key component in a spoken dialogue system. In\nthis paper, we investigate how the language understanding module influences the\ndialogue system performance by conducting a series of systematic experiments on\na task-oriented neural dialogue system in a reinforcement learning based\nsetting. The empirical study shows that among different types of language\nunderstanding errors, slot-level errors can have more impact on the overall\nperformance of a dialogue system compared to intent-level errors. In addition,\nour experiments demonstrate that the reinforcement learning based dialogue\nsystem is able to learn when and what to confirm in order to achieve better\nperformance and greater robustness.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 04:56:14 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Li", "Xiujun", ""], ["Chen", "Yun-Nung", ""], ["Li", "Lihong", ""], ["Gao", "Jianfeng", ""], ["Celikyilmaz", "Asli", ""]]}, {"id": "1703.07090", "submitter": "Jun Zhang", "authors": "Xu Tian, Jun Zhang, Zejun Ma, Yi He, Juan Wei, Peihao Wu, Wenchang\n  Situ, Shuai Li, Yang Zhang", "title": "Deep LSTM for Large Vocabulary Continuous Speech Recognition", "comments": "8 pages. arXiv admin note: text overlap with arXiv:1703.01024", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs), especially long short-term memory (LSTM)\nRNNs, are effective network for sequential task like speech recognition. Deeper\nLSTM models perform well on large vocabulary continuous speech recognition,\nbecause of their impressive learning ability. However, it is more difficult to\ntrain a deeper network. We introduce a training framework with layer-wise\ntraining and exponential moving average methods for deeper LSTM models. It is a\ncompetitive framework that LSTM models of more than 7 layers are successfully\ntrained on Shenma voice search data in Mandarin and they outperform the deep\nLSTM models trained by conventional approach. Moreover, in order for online\nstreaming speech recognition applications, the shallow model with low real time\nfactor is distilled from the very deep model. The recognition accuracy have\nlittle loss in the distillation process. Therefore, the model trained with the\nproposed training framework reduces relative 14\\% character error rate,\ncompared to original model which has the similar real-time capability.\nFurthermore, the novel transfer learning strategy with segmental Minimum\nBayes-Risk is also introduced in the framework. The strategy makes it possible\nthat training with only a small part of dataset could outperform full dataset\ntraining from the beginning.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 08:24:50 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Tian", "Xu", ""], ["Zhang", "Jun", ""], ["Ma", "Zejun", ""], ["He", "Yi", ""], ["Wei", "Juan", ""], ["Wu", "Peihao", ""], ["Situ", "Wenchang", ""], ["Li", "Shuai", ""], ["Zhang", "Yang", ""]]}, {"id": "1703.07438", "submitter": "Nathan Schneider", "authors": "Nathan Schneider, Chuck Wooters", "title": "The NLTK FrameNet API: Designing for Discoverability with a Rich\n  Linguistic Resource", "comments": "EMNLP 2017 Demo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new Python API, integrated within the NLTK suite, offers access to the\nFrameNet 1.7 lexical database. The lexicon (structured in terms of frames) as\nwell as annotated sentences can be processed programatically, or browsed with\nhuman-readable displays via the interactive Python prompt.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 21:36:28 GMT"}, {"version": "v2", "created": "Sat, 22 Jul 2017 04:44:38 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Schneider", "Nathan", ""], ["Wooters", "Chuck", ""]]}, {"id": "1703.07476", "submitter": "Chunxi Liu", "authors": "Chunxi Liu, Jan Trmal, Matthew Wiesner, Craig Harman, Sanjeev\n  Khudanpur", "title": "Topic Identification for Speech without ASR", "comments": "5 pages, 2 figures; accepted for publication at Interspeech 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern topic identification (topic ID) systems for speech use automatic\nspeech recognition (ASR) to produce speech transcripts, and perform supervised\nclassification on such ASR outputs. However, under resource-limited conditions,\nthe manually transcribed speech required to develop standard ASR systems can be\nseverely limited or unavailable. In this paper, we investigate alternative\nunsupervised solutions to obtaining tokenizations of speech in terms of a\nvocabulary of automatically discovered word-like or phoneme-like units, without\ndepending on the supervised training of ASR systems. Moreover, using automatic\nphoneme-like tokenizations, we demonstrate that a convolutional neural network\nbased framework for learning spoken document representations provides\ncompetitive performance compared to a standard bag-of-words representation, as\nevidenced by comprehensive topic ID evaluations on both single-label and\nmulti-label classification tasks.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 00:37:33 GMT"}, {"version": "v2", "created": "Tue, 11 Jul 2017 17:11:15 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Liu", "Chunxi", ""], ["Trmal", "Jan", ""], ["Wiesner", "Matthew", ""], ["Harman", "Craig", ""], ["Khudanpur", "Sanjeev", ""]]}, {"id": "1703.07588", "submitter": "Yu-Hsuan Wang", "authors": "Yu-Hsuan Wang, Cheng-Tao Chung, Hung-yi Lee", "title": "Gate Activation Signal Analysis for Gated Recurrent Neural Networks and\n  Its Correlation with Phoneme Boundaries", "comments": "5 pages, The code is available at\n  https://github.com/allyoushawn/timit_gas.git", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we analyze the gate activation signals inside the gated\nrecurrent neural networks, and find the temporal structure of such signals is\nhighly correlated with the phoneme boundaries. This correlation is further\nverified by a set of experiments for phoneme segmentation, in which better\nresults compared to standard approaches were obtained.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 10:08:51 GMT"}, {"version": "v2", "created": "Thu, 31 Aug 2017 12:01:36 GMT"}], "update_date": "2017-09-01", "authors_parsed": [["Wang", "Yu-Hsuan", ""], ["Chung", "Cheng-Tao", ""], ["Lee", "Hung-yi", ""]]}, {"id": "1703.07713", "submitter": "Zhao Meng", "authors": "Zhao Meng, Lili Mou, Zhi Jin", "title": "Hierarchical RNN with Static Sentence-Level Attention for Text-Based\n  Speaker Change Detection", "comments": "In Proceedings of the ACM on Conference on Information and Knowledge\n  Management (CIKM), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker change detection (SCD) is an important task in dialog modeling. Our\npaper addresses the problem of text-based SCD, which differs from existing\naudio-based studies and is useful in various scenarios, for example, processing\ndialog transcripts where speaker identities are missing (e.g., OpenSubtitle),\nand enhancing audio SCD with textual information. We formulate text-based SCD\nas a matching problem of utterances before and after a certain decision point;\nwe propose a hierarchical recurrent neural network (RNN) with static\nsentence-level attention. Experimental results show that neural networks\nconsistently achieve better performance than feature-based approaches, and that\nour attention-based model significantly outperforms non-attention neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 15:42:28 GMT"}, {"version": "v2", "created": "Fri, 28 Sep 2018 17:56:14 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Meng", "Zhao", ""], ["Mou", "Lili", ""], ["Jin", "Zhi", ""]]}, {"id": "1703.07754", "submitter": "Kartik Audhkhasi", "authors": "Kartik Audhkhasi, Bhuvana Ramabhadran, George Saon, Michael Picheny,\n  David Nahamoo", "title": "Direct Acoustics-to-Word Models for English Conversational Speech\n  Recognition", "comments": "Submitted to Interspeech-2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on end-to-end automatic speech recognition (ASR) has shown that\nthe connectionist temporal classification (CTC) loss can be used to convert\nacoustics to phone or character sequences. Such systems are used with a\ndictionary and separately-trained Language Model (LM) to produce word\nsequences. However, they are not truly end-to-end in the sense of mapping\nacoustics directly to words without an intermediate phone representation. In\nthis paper, we present the first results employing direct acoustics-to-word CTC\nmodels on two well-known public benchmark tasks: Switchboard and CallHome.\nThese models do not require an LM or even a decoder at run-time and hence\nrecognize speech with minimal complexity. However, due to the large number of\nword output units, CTC word models require orders of magnitude more data to\ntrain reliably compared to traditional systems. We present some techniques to\nmitigate this issue. Our CTC word model achieves a word error rate of\n13.0%/18.8% on the Hub5-2000 Switchboard/CallHome test sets without any LM or\ndecoder compared with 9.6%/16.0% for phone-based CTC with a 4-gram LM. We also\npresent rescoring results on CTC word model lattices to quantify the\nperformance benefits of a LM, and contrast the performance of word and phone\nCTC models.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 17:17:16 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Audhkhasi", "Kartik", ""], ["Ramabhadran", "Bhuvana", ""], ["Saon", "George", ""], ["Picheny", "Michael", ""], ["Nahamoo", "David", ""]]}, {"id": "1703.07805", "submitter": "Mayank Kejriwal", "authors": "Mayank Kejriwal, Pedro Szekely", "title": "Supervised Typing of Big Graphs using Semantic Embeddings", "comments": "6 pages, to be published in Semantic Big Data Workshop at ACM, SIGMOD\n  2017; extended version in preparation for Open Journal of Semantic Web (OJSW)", "journal-ref": null, "doi": "10.1145/3066911.3066918", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a supervised algorithm for generating type embeddings in the same\nsemantic vector space as a given set of entity embeddings. The algorithm is\nagnostic to the derivation of the underlying entity embeddings. It does not\nrequire any manual feature engineering, generalizes well to hundreds of types\nand achieves near-linear scaling on Big Graphs containing many millions of\ntriples and instances by virtue of an incremental execution. We demonstrate the\nutility of the embeddings on a type recommendation task, outperforming a\nnon-parametric feature-agnostic baseline while achieving 15x speedup and\nnear-constant memory usage on a full partition of DBpedia. Using\nstate-of-the-art visualization, we illustrate the agreement of our\nextensionally derived DBpedia type embeddings with the manually curated domain\nontology. Finally, we use the embeddings to probabilistically cluster about 4\nmillion DBpedia instances into 415 types in the DBpedia ontology.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 18:20:07 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Kejriwal", "Mayank", ""], ["Szekely", "Pedro", ""]]}, {"id": "1703.08002", "submitter": "Mirco Ravanelli", "authors": "Mirco Ravanelli, Philemon Brakel, Maurizio Omologo, Yoshua Bengio", "title": "A network of deep neural networks for distant speech recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the remarkable progress recently made in distant speech recognition,\nstate-of-the-art technology still suffers from a lack of robustness, especially\nwhen adverse acoustic conditions characterized by non-stationary noises and\nreverberation are met. A prominent limitation of current systems lies in the\nlack of matching and communication between the various technologies involved in\nthe distant speech recognition process. The speech enhancement and speech\nrecognition modules are, for instance, often trained independently. Moreover,\nthe speech enhancement normally helps the speech recognizer, but the output of\nthe latter is not commonly used, in turn, to improve the speech enhancement. To\naddress both concerns, we propose a novel architecture based on a network of\ndeep neural networks, where all the components are jointly trained and better\ncooperate with each other thanks to a full communication scheme between them.\nExperiments, conducted using different datasets, tasks and acoustic conditions,\nrevealed that the proposed framework can overtake other competitive solutions,\nincluding recent joint training approaches.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 11:02:47 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Ravanelli", "Mirco", ""], ["Brakel", "Philemon", ""], ["Omologo", "Maurizio", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1703.08052", "submitter": "Maja Rudolph", "authors": "Maja Rudolph, David Blei", "title": "Dynamic Bernoulli Embeddings for Language Evolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings are a powerful approach for unsupervised analysis of\nlanguage. Recently, Rudolph et al. (2016) developed exponential family\nembeddings, which cast word embeddings in a probabilistic framework. Here, we\ndevelop dynamic embeddings, building on exponential family embeddings to\ncapture how the meanings of words change over time. We use dynamic embeddings\nto analyze three large collections of historical texts: the U.S. Senate\nspeeches from 1858 to 2009, the history of computer science ACM abstracts from\n1951 to 2014, and machine learning papers on the Arxiv from 2007 to 2015. We\nfind dynamic embeddings provide better fits than classical embeddings and\ncapture interesting patterns about how language changes.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 13:00:14 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Rudolph", "Maja", ""], ["Blei", "David", ""]]}, {"id": "1703.08068", "submitter": "Youssef Oualil", "authors": "Youssef Oualil, Clayton Greenberg, Mittul Singh, Dietrich Klakow", "title": "Sequential Recurrent Neural Networks for Language Modeling", "comments": "published (INTERSPEECH 2016), 5 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feedforward Neural Network (FNN)-based language models estimate the\nprobability of the next word based on the history of the last N words, whereas\nRecurrent Neural Networks (RNN) perform the same task based only on the last\nword and some context information that cycles in the network. This paper\npresents a novel approach, which bridges the gap between these two categories\nof networks. In particular, we propose an architecture which takes advantage of\nthe explicit, sequential enumeration of the word history in FNN structure while\nenhancing each word representation at the projection layer through recurrent\ncontext information that evolves in the network. The context integration is\nperformed using an additional word-dependent weight matrix that is also learned\nduring the training. Extensive experiments conducted on the Penn Treebank (PTB)\nand the Large Text Compression Benchmark (LTCB) corpus showed a significant\nreduction of the perplexity when compared to state-of-the-art feedforward as\nwell as recurrent neural network architectures.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 13:48:45 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Oualil", "Youssef", ""], ["Greenberg", "Clayton", ""], ["Singh", "Mittul", ""], ["Klakow", "Dietrich", ""]]}, {"id": "1703.08084", "submitter": "Jean-Benoit Delbrouck", "authors": "Jean-Benoit Delbrouck, Stephane Dupont", "title": "Multimodal Compact Bilinear Pooling for Multimodal Neural Machine\n  Translation", "comments": "Submitted to ICLR Workshop 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In state-of-the-art Neural Machine Translation, an attention mechanism is\nused during decoding to enhance the translation. At every step, the decoder\nuses this mechanism to focus on different parts of the source sentence to\ngather the most useful information before outputting its target word. Recently,\nthe effectiveness of the attention mechanism has also been explored for\nmultimodal tasks, where it becomes possible to focus both on sentence parts and\nimage regions. Approaches to pool two modalities usually include element-wise\nproduct, sum or concatenation. In this paper, we evaluate the more advanced\nMultimodal Compact Bilinear pooling method, which takes the outer product of\ntwo vectors to combine the attention features for the two modalities. This has\nbeen previously investigated for visual question answering. We try out this\napproach for multimodal image caption translation and show improvements\ncompared to basic combination methods.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 14:20:52 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Delbrouck", "Jean-Benoit", ""], ["Dupont", "Stephane", ""]]}, {"id": "1703.08088", "submitter": "Vineet John", "authors": "Vineet John", "title": "Rapid-Rate: A Framework for Semi-supervised Real-time Sentiment Trend\n  Detection in Unstructured Big Data", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": "10.13140/RG.2.2.32385.04966", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commercial establishments like restaurants, service centres and retailers\nhave several sources of customer feedback about products and services, most of\nwhich need not be as structured as rated reviews provided by services like\nYelp, or Amazon, in terms of sentiment conveyed. For instance, Amazon provides\na fine-grained score on a numeric scale for product reviews. Some sources,\nhowever, like social media (Twitter, Facebook), mailing lists (Google Groups)\nand forums (Quora) contain text data that is much more voluminous, but\nunstructured and unlabelled. It might be in the best interests of a business\nestablishment to assess the general sentiment towards their brand on these\nplatforms as well. This text could be pipelined into a system with a built-in\nprediction model, with the objective of generating real-time graphs on opinion\nand sentiment trends. Although such tasks like the one described about have\nbeen explored with respect to document classification problems in the past, the\nimplementation described in this paper, by virtue of learning a continuous\nfunction rather than a discrete one, offers a lot more depth of insight as\ncompared to document classification approaches. This study aims to explore the\nvalidity of such a continuous function predicting model to quantify sentiment\nabout an entity, without the additional overhead of manual labelling, and\ncomputational preprocessing & feature extraction. This research project also\naims to design and implement a re-usable document regression pipeline as a\nframework, Rapid-Rate, that can be used to predict document scores in\nreal-time.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 14:37:15 GMT"}, {"version": "v2", "created": "Sat, 25 Mar 2017 00:00:00 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["John", "Vineet", ""]]}, {"id": "1703.08098", "submitter": "Dat Quoc Nguyen", "authors": "Dat Quoc Nguyen", "title": "A survey of embedding models of entities and relationships for knowledge\n  graph completion", "comments": "In Proceedings of the 14th Workshop on Graph-Based Natural Language\n  Processing (TextGraphs 2020); 16 pages, 2 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs (KGs) of real-world facts about entities and their\nrelationships are useful resources for a variety of natural language processing\ntasks. However, because knowledge graphs are typically incomplete, it is useful\nto perform knowledge graph completion or link prediction, i.e. predict whether\na relationship not in the knowledge graph is likely to be true. This paper\nserves as a comprehensive survey of embedding models of entities and\nrelationships for knowledge graph completion, summarizing up-to-date\nexperimental results on standard benchmark datasets and pointing out potential\nfuture research directions.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 15:15:26 GMT"}, {"version": "v2", "created": "Tue, 28 Mar 2017 15:28:08 GMT"}, {"version": "v3", "created": "Sat, 3 Feb 2018 04:39:45 GMT"}, {"version": "v4", "created": "Tue, 9 Apr 2019 02:26:26 GMT"}, {"version": "v5", "created": "Sat, 27 Apr 2019 13:33:30 GMT"}, {"version": "v6", "created": "Fri, 28 Feb 2020 07:06:36 GMT"}, {"version": "v7", "created": "Wed, 22 Apr 2020 11:58:35 GMT"}, {"version": "v8", "created": "Mon, 10 Aug 2020 08:35:07 GMT"}, {"version": "v9", "created": "Tue, 27 Oct 2020 04:11:25 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Nguyen", "Dat Quoc", ""]]}, {"id": "1703.08120", "submitter": "Abhijit Sharang", "authors": "Abhijit Sharang, Eric Lau", "title": "Recurrent and Contextual Models for Visual Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a series of recurrent and contextual neural network models for\nmultiple choice visual question answering on the Visual7W dataset. Motivated by\ndivergent trends in model complexities in the literature, we explore the\nbalance between model expressiveness and simplicity by studying incrementally\nmore complex architectures. We start with LSTM-encoding of input questions and\nanswers; build on this with context generation by LSTM-encodings of neural\nimage and question representations and attention over images; and evaluate the\ndiversity and predictive power of our models and the ensemble thereof. All\nmodels are evaluated against a simple baseline inspired by the current\nstate-of-the-art, consisting of involving simple concatenation of bag-of-words\nand CNN representations for the text and images, respectively. Generally, we\nobserve marked variation in image-reasoning performance between our models not\nobvious from their overall performance, as well as evidence of dataset bias.\nOur standalone models achieve accuracies up to $64.6\\%$, while the ensemble of\nall models achieves the best accuracy of $66.67\\%$, within $0.5\\%$ of the\ncurrent state-of-the-art for Visual7W.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 15:57:23 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Sharang", "Abhijit", ""], ["Lau", "Eric", ""]]}, {"id": "1703.08135", "submitter": "Herman Kamper", "authors": "Herman Kamper, Karen Livescu, Sharon Goldwater", "title": "An embedded segmental K-means model for unsupervised segmentation and\n  clustering of speech", "comments": "8 pages, 3 figures, 3 tables; accepted to ASRU 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised segmentation and clustering of unlabelled speech are core\nproblems in zero-resource speech processing. Most approaches lie at\nmethodological extremes: some use probabilistic Bayesian models with\nconvergence guarantees, while others opt for more efficient heuristic\ntechniques. Despite competitive performance in previous work, the full Bayesian\napproach is difficult to scale to large speech corpora. We introduce an\napproximation to a recent Bayesian model that still has a clear objective\nfunction but improves efficiency by using hard clustering and segmentation\nrather than full Bayesian inference. Like its Bayesian counterpart, this\nembedded segmental K-means model (ES-KMeans) represents arbitrary-length word\nsegments as fixed-dimensional acoustic word embeddings. We first compare\nES-KMeans to previous approaches on common English and Xitsonga data sets (5\nand 2.5 hours of speech): ES-KMeans outperforms a leading heuristic method in\nword segmentation, giving similar scores to the Bayesian model while being 5\ntimes faster with fewer hyperparameters. However, its clusters are less pure\nthan those of the other models. We then show that ES-KMeans scales to larger\ncorpora by applying it to the 5 languages of the Zero Resource Speech Challenge\n2017 (up to 45 hours), where it performs competitively compared to the\nchallenge baseline.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 16:45:22 GMT"}, {"version": "v2", "created": "Tue, 5 Sep 2017 14:14:11 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Kamper", "Herman", ""], ["Livescu", "Karen", ""], ["Goldwater", "Sharon", ""]]}, {"id": "1703.08136", "submitter": "Herman Kamper", "authors": "Herman Kamper, Shane Settle, Gregory Shakhnarovich, Karen Livescu", "title": "Visually grounded learning of keyword prediction from untranscribed\n  speech", "comments": "5 pages, 3 figures, 5 tables; small updates, added link to code;\n  accepted to Interspeech 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During language acquisition, infants have the benefit of visual cues to\nground spoken language. Robots similarly have access to audio and visual\nsensors. Recent work has shown that images and spoken captions can be mapped\ninto a meaningful common space, allowing images to be retrieved using speech\nand vice versa. In this setting of images paired with untranscribed spoken\ncaptions, we consider whether computer vision systems can be used to obtain\ntextual labels for the speech. Concretely, we use an image-to-words multi-label\nvisual classifier to tag images with soft textual labels, and then train a\nneural network to map from the speech to these soft targets. We show that the\nresulting speech system is able to predict which words occur in an\nutterance---acting as a spoken bag-of-words classifier---without seeing any\nparallel speech and text. We find that the model often confuses semantically\nrelated words, e.g. \"man\" and \"person\", making it even more effective as a\nsemantic keyword spotter.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 16:46:00 GMT"}, {"version": "v2", "created": "Thu, 25 May 2017 20:49:15 GMT"}], "update_date": "2017-05-29", "authors_parsed": [["Kamper", "Herman", ""], ["Settle", "Shane", ""], ["Shakhnarovich", "Gregory", ""], ["Livescu", "Karen", ""]]}, {"id": "1703.08244", "submitter": "Maribel Acosta", "authors": "Fabian Fl\\\"ock, Kenan Erdogan, Maribel Acosta", "title": "TokTrack: A Complete Token Provenance and Change Tracking Dataset for\n  the English Wikipedia", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a dataset that contains every instance of all tokens (~ words)\never written in undeleted, non-redirect English Wikipedia articles until\nOctober 2016, in total 13,545,349,787 instances. Each token is annotated with\n(i) the article revision it was originally created in, and (ii) lists with all\nthe revisions in which the token was ever deleted and (potentially) re-added\nand re-deleted from its article, enabling a complete and straightforward\ntracking of its history. This data would be exceedingly hard to create by an\naverage potential user as it is (i) very expensive to compute and as (ii)\naccurately tracking the history of each token in revisioned documents is a\nnon-trivial task. Adapting a state-of-the-art algorithm, we have produced a\ndataset that allows for a range of analyses and metrics, already popular in\nresearch and going beyond, to be generated on complete-Wikipedia scale;\nensuring quality and allowing researchers to forego expensive text-comparison\ncomputation, which so far has hindered scalable usage. We show how this data\nenables, on token-level, computation of provenance, measuring survival of\ncontent over time, very detailed conflict metrics, and fine-grained\ninteractions of editors like partial reverts, re-additions and other metrics,\nin the process gaining several novel insights.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 22:20:45 GMT"}], "update_date": "2017-03-27", "authors_parsed": [["Fl\u00f6ck", "Fabian", ""], ["Erdogan", "Kenan", ""], ["Acosta", "Maribel", ""]]}, {"id": "1703.08314", "submitter": "Martha Lewis", "authors": "Joe Bolt, Bob Coecke, Fabrizio Genovese, Martha Lewis, Dan Marsden and\n  Robin Piedeleu", "title": "Interacting Conceptual Spaces I : Grammatical Composition of Concepts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The categorical compositional approach to meaning has been successfully\napplied in natural language processing, outperforming other models in\nmainstream empirical language processing tasks. We show how this approach can\nbe generalized to conceptual space models of cognition. In order to do this,\nfirst we introduce the category of convex relations as a new setting for\ncategorical compositional semantics, emphasizing the convex structure important\nto conceptual space applications. We then show how to construct conceptual\nspaces for various types such as nouns, adjectives and verbs. Finally we show\nby means of examples how concepts can be systematically combined to establish\nthe meanings of composite phrases from the meanings of their constituent parts.\nThis provides the mathematical underpinnings of a new compositional approach to\ncognition.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 08:46:48 GMT"}, {"version": "v2", "created": "Fri, 29 Sep 2017 11:07:00 GMT"}], "update_date": "2017-10-02", "authors_parsed": [["Bolt", "Joe", ""], ["Coecke", "Bob", ""], ["Genovese", "Fabrizio", ""], ["Lewis", "Martha", ""], ["Marsden", "Dan", ""], ["Piedeleu", "Robin", ""]]}, {"id": "1703.08324", "submitter": "Ramon Ferrer i Cancho", "authors": "Ramon Ferrer-i-Cancho, Carlos Gomez-Rodriguez and J.L. Esteban", "title": "Are crossing dependencies really scarce?", "comments": null, "journal-ref": "Physica A: Statistical Mechanics and its Applications,\n  493:311-329, 2018", "doi": "10.1016/j.physa.2017.10.048", "report-no": null, "categories": "physics.soc-ph cond-mat.stat-mech cs.CL physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The syntactic structure of a sentence can be modelled as a tree, where\nvertices correspond to words and edges indicate syntactic dependencies. It has\nbeen claimed recurrently that the number of edge crossings in real sentences is\nsmall. However, a baseline or null hypothesis has been lacking. Here we\nquantify the amount of crossings of real sentences and compare it to the\npredictions of a series of baselines. We conclude that crossings are really\nscarce in real sentences. Their scarcity is unexpected by the hubiness of the\ntrees. Indeed, real sentences are close to linear trees, where the potential\nnumber of crossings is maximized.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 09:32:23 GMT"}, {"version": "v2", "created": "Tue, 10 Oct 2017 06:01:39 GMT"}], "update_date": "2017-12-14", "authors_parsed": [["Ferrer-i-Cancho", "Ramon", ""], ["Gomez-Rodriguez", "Carlos", ""], ["Esteban", "J. L.", ""]]}, {"id": "1703.08428", "submitter": "Justin Cranshaw", "authors": "Justin Cranshaw, Emad Elwany, Todd Newman, Rafal Kocielnik, Bowen Yu,\n  Sandeep Soni, Jaime Teevan, Andr\\'es Monroy-Hern\\'andez", "title": "Calendar.help: Designing a Workflow-Based Scheduling Agent with Humans\n  in the Loop", "comments": "10 pages", "journal-ref": null, "doi": "10.1145/3025453.3025780", "report-no": null, "categories": "cs.HC cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although information workers may complain about meetings, they are an\nessential part of their work life. Consequently, busy people spend a\nsignificant amount of time scheduling meetings. We present Calendar.help, a\nsystem that provides fast, efficient scheduling through structured workflows.\nUsers interact with the system via email, delegating their scheduling needs to\nthe system as if it were a human personal assistant. Common scheduling\nscenarios are broken down using well-defined workflows and completed as a\nseries of microtasks that are automated when possible and executed by a human\notherwise. Unusual scenarios fall back to a trained human assistant who\nexecutes them as unstructured macrotasks. We describe the iterative approach we\nused to develop Calendar.help, and share the lessons learned from scheduling\nthousands of meetings during a year of real-world deployments. Our findings\nprovide insight into how complex information tasks can be broken down into\nrepeatable components that can be executed efficiently to improve productivity.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 14:40:31 GMT"}], "update_date": "2017-03-27", "authors_parsed": [["Cranshaw", "Justin", ""], ["Elwany", "Emad", ""], ["Newman", "Todd", ""], ["Kocielnik", "Rafal", ""], ["Yu", "Bowen", ""], ["Soni", "Sandeep", ""], ["Teevan", "Jaime", ""], ["Monroy-Hern\u00e1ndez", "Andr\u00e9s", ""]]}, {"id": "1703.08471", "submitter": "Mirco Ravanelli", "authors": "Mirco Ravanelli, Philemon Brakel, Maurizio Omologo, Yoshua Bengio", "title": "Batch-normalized joint training for DNN-based distant speech recognition", "comments": "arXiv admin note: text overlap with arXiv:1703.08002", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improving distant speech recognition is a crucial step towards flexible\nhuman-machine interfaces. Current technology, however, still exhibits a lack of\nrobustness, especially when adverse acoustic conditions are met. Despite the\nsignificant progress made in the last years on both speech enhancement and\nspeech recognition, one potential limitation of state-of-the-art technology\nlies in composing modules that are not well matched because they are not\ntrained jointly. To address this concern, a promising approach consists in\nconcatenating a speech enhancement and a speech recognition deep neural network\nand to jointly update their parameters as if they were within a single bigger\nnetwork. Unfortunately, joint training can be difficult because the output\ndistribution of the speech enhancement system may change substantially during\nthe optimization procedure. The speech recognition module would have to deal\nwith an input distribution that is non-stationary and unnormalized. To mitigate\nthis issue, we propose a joint training approach based on a fully\nbatch-normalized architecture. Experiments, conducted using different datasets,\ntasks and acoustic conditions, revealed that the proposed framework\nsignificantly overtakes other competitive solutions, especially in challenging\nenvironments.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 15:40:19 GMT"}], "update_date": "2017-03-27", "authors_parsed": [["Ravanelli", "Mirco", ""], ["Brakel", "Philemon", ""], ["Omologo", "Maurizio", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1703.08513", "submitter": "Stefan Heinrich", "authors": "Stefan Heinrich and Stefan Wermter", "title": "Interactive Natural Language Acquisition in a Multi-modal Recurrent\n  Neural Architecture", "comments": "Received 25 June 2016; Accepted 1 February 2017", "journal-ref": "Connection Science, vol 30, No 1, pp. 99-133, 2017", "doi": "10.1080/09540091.2017.1318357", "report-no": null, "categories": "cs.CL q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the complex human brain that enables us to communicate in natural\nlanguage, we gathered good understandings of principles underlying language\nacquisition and processing, knowledge about socio-cultural conditions, and\ninsights about activity patterns in the brain. However, we were not yet able to\nunderstand the behavioural and mechanistic characteristics for natural language\nand how mechanisms in the brain allow to acquire and process language. In\nbridging the insights from behavioural psychology and neuroscience, the goal of\nthis paper is to contribute a computational understanding of appropriate\ncharacteristics that favour language acquisition. Accordingly, we provide\nconcepts and refinements in cognitive modelling regarding principles and\nmechanisms in the brain and propose a neurocognitively plausible model for\nembodied language acquisition from real world interaction of a humanoid robot\nwith its environment. In particular, the architecture consists of a continuous\ntime recurrent neural network, where parts have different leakage\ncharacteristics and thus operate on multiple timescales for every modality and\nthe association of the higher level nodes of all modalities into cell\nassemblies. The model is capable of learning language production grounded in\nboth, temporal dynamic somatosensation and vision, and features hierarchical\nconcept abstraction, concept decomposition, multi-modal integration, and\nself-organisation of latent representations.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 17:13:08 GMT"}, {"version": "v2", "created": "Wed, 7 Feb 2018 16:08:05 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Heinrich", "Stefan", ""], ["Wermter", "Stefan", ""]]}, {"id": "1703.08537", "submitter": "Victor Soto", "authors": "Victor Soto, Julia Hirschberg", "title": "Crowdsourcing Universal Part-Of-Speech Tags for Code-Switching", "comments": "Submitted to Interspeech 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code-switching is the phenomenon by which bilingual speakers switch between\nmultiple languages during communication. The importance of developing language\ntechnologies for codeswitching data is immense, given the large populations\nthat routinely code-switch. High-quality linguistic annotations are extremely\nvaluable for any NLP task, and performance is often limited by the amount of\nhigh-quality labeled data. However, little such data exists for code-switching.\nIn this paper, we describe crowd-sourcing universal part-of-speech tags for the\nMiami Bangor Corpus of Spanish-English code-switched speech. We split the\nannotation task into three subtasks: one in which a subset of tokens are\nlabeled automatically, one in which questions are specifically designed to\ndisambiguate a subset of high frequency words, and a more general cascaded\napproach for the remaining data in which questions are displayed to the worker\nfollowing a decision tree structure. Each subtask is extended and adapted for a\nmultilingual setting and the universal tagset. The quality of the annotation\nprocess is measured using hidden check questions annotated with gold labels.\nThe overall agreement between gold standard labels and the majority vote is\nbetween 0.95 and 0.96 for just three labels and the average recall across\npart-of-speech tags is between 0.87 and 0.99, depending on the task.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 17:55:33 GMT"}], "update_date": "2017-03-27", "authors_parsed": [["Soto", "Victor", ""], ["Hirschberg", "Julia", ""]]}, {"id": "1703.08544", "submitter": "Joshua Michalenko", "authors": "Joshua J. Michalenko, Andrew S. Lan, Richard G. Baraniuk", "title": "Data-Mining Textual Responses to Uncover Misconception Patterns", "comments": "7 Pages, Submitted to EDM 2017, Workshop version accepted to L@S\n  2017. Article title and acronym changed to more clearly indicate the\n  scientific goal of the paper of improving the quality of educational\n  instruction", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important, yet largely unstudied, problem in student data analysis is to\ndetect misconceptions from students' responses to open-response questions.\nMisconception detection enables instructors to deliver more targeted feedback\non the misconceptions exhibited by many students in their class, thus improving\nthe quality of instruction. In this paper, we propose a new natural language\nprocessing-based framework to detect the common misconceptions among students'\ntextual responses to short-answer questions. We propose a probabilistic model\nfor students' textual responses involving misconceptions and experimentally\nvalidate it on a real-world student-response dataset. Experimental results show\nthat our proposed framework excels at classifying whether a response exhibits\none or more misconceptions. More importantly, it can also automatically detect\nthe common misconceptions exhibited across responses from multiple students to\nmultiple questions; this property is especially important at large scale, since\ninstructors will no longer need to manually specify all possible misconceptions\nthat students might exhibit.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 14:49:58 GMT"}, {"version": "v2", "created": "Thu, 30 Mar 2017 02:50:33 GMT"}], "update_date": "2017-03-31", "authors_parsed": [["Michalenko", "Joshua J.", ""], ["Lan", "Andrew S.", ""], ["Baraniuk", "Richard G.", ""]]}, {"id": "1703.08581", "submitter": "Ron J Weiss", "authors": "Ron J. Weiss, Jan Chorowski, Navdeep Jaitly, Yonghui Wu, Zhifeng Chen", "title": "Sequence-to-Sequence Models Can Directly Translate Foreign Speech", "comments": "5 pages, 1 figure. Interspeech 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a recurrent encoder-decoder deep neural network architecture that\ndirectly translates speech in one language into text in another. The model does\nnot explicitly transcribe the speech into text in the source language, nor does\nit require supervision from the ground truth source language transcription\nduring training. We apply a slightly modified sequence-to-sequence with\nattention architecture that has previously been used for speech recognition and\nshow that it can be repurposed for this more complex task, illustrating the\npower of attention-based models. A single model trained end-to-end obtains\nstate-of-the-art performance on the Fisher Callhome Spanish-English speech\ntranslation task, outperforming a cascade of independently trained\nsequence-to-sequence speech recognition and machine translation models by 1.8\nBLEU points on the Fisher test set. In addition, we find that making use of the\ntraining data in both languages by multi-task training sequence-to-sequence\nspeech translation and recognition models with a shared encoder network can\nimprove performance by a further 1.4 BLEU points.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 19:45:24 GMT"}, {"version": "v2", "created": "Mon, 12 Jun 2017 13:54:12 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Weiss", "Ron J.", ""], ["Chorowski", "Jan", ""], ["Jaitly", "Navdeep", ""], ["Wu", "Yonghui", ""], ["Chen", "Zhifeng", ""]]}, {"id": "1703.08646", "submitter": "Yohan Jo", "authors": "Yohan Jo", "title": "Simplifying the Bible and Wikipedia Using Statistical Machine\n  Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I started this work with the hope of generating a text synthesizer (like a\nmusical synthesizer) that can imitate certain linguistic styles. Most of the\nreport focuses on text simplification using statistical machine translation\n(SMT) techniques. I applied MOSES to a parallel corpus of the Bible (King James\nVersion and Easy-to-Read Version) and that of Wikipedia articles (normal and\nsimplified). I report the importance of the three main components of\nSMT---phrase translation, language model, and recording---by changing their\nweights and comparing the resulting quality of simplified text in terms of\nMETEOR and BLEU. Toward the end of the report will be presented some examples\nof text \"synthesized\" into the King James style.\n", "versions": [{"version": "v1", "created": "Sat, 25 Mar 2017 04:25:21 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Jo", "Yohan", ""]]}, {"id": "1703.08701", "submitter": "Albert Gatt", "authors": "Claudia Borg and Albert Gatt", "title": "Morphological Analysis for the Maltese Language: The Challenges of a\n  Hybrid System", "comments": "11pages, Proceedings of the 3rd Arabic Natural Language Processing\n  Workshop (WANLP'17)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maltese is a morphologically rich language with a hybrid morphological system\nwhich features both concatenative and non-concatenative processes. This paper\nanalyses the impact of this hybridity on the performance of machine learning\ntechniques for morphological labelling and clustering. In particular, we\nanalyse a dataset of morphologically related word clusters to evaluate the\ndifference in results for concatenative and nonconcatenative clusters. We also\ndescribe research carried out in morphological labelling, with a particular\nfocus on the verb category. Two evaluations were carried out, one using an\nunseen dataset, and another one using a gold standard dataset which was\nmanually labelled. The gold standard dataset was split into concatenative and\nnon-concatenative to analyse the difference in results between the two\nmorphological systems.\n", "versions": [{"version": "v1", "created": "Sat, 25 Mar 2017 14:56:27 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Borg", "Claudia", ""], ["Gatt", "Albert", ""]]}, {"id": "1703.08705", "submitter": "Franck Dernoncourt", "authors": "Sebastian Gehrmann, Franck Dernoncourt, Yeran Li, Eric T. Carlson, Joy\n  T. Wu, Jonathan Welt, John Foote Jr., Edward T. Moseley, David W. Grant,\n  Patrick D. Tyler, Leo Anthony Celi", "title": "Comparing Rule-Based and Deep Learning Models for Patient Phenotyping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: We investigate whether deep learning techniques for natural\nlanguage processing (NLP) can be used efficiently for patient phenotyping.\nPatient phenotyping is a classification task for determining whether a patient\nhas a medical condition, and is a crucial part of secondary analysis of\nhealthcare data. We assess the performance of deep learning algorithms and\ncompare them with classical NLP approaches.\n  Materials and Methods: We compare convolutional neural networks (CNNs),\nn-gram models, and approaches based on cTAKES that extract pre-defined medical\nconcepts from clinical notes and use them to predict patient phenotypes. The\nperformance is tested on 10 different phenotyping tasks using 1,610 discharge\nsummaries extracted from the MIMIC-III database.\n  Results: CNNs outperform other phenotyping algorithms in all 10 tasks. The\naverage F1-score of our model is 76 (PPV of 83, and sensitivity of 71) with our\nmodel having an F1-score up to 37 points higher than alternative approaches. We\nadditionally assess the interpretability of our model by presenting a method\nthat extracts the most salient phrases for a particular prediction.\n  Conclusion: We show that NLP methods based on deep learning improve the\nperformance of patient phenotyping. Our CNN-based algorithm automatically\nlearns the phrases associated with each patient phenotype. As such, it reduces\nthe annotation complexity for clinical domain experts, who are normally\nrequired to develop task-specific annotation rules and identify relevant\nphrases. Our method performs well in terms of both performance and\ninterpretability, which indicates that deep learning is an effective approach\nto patient phenotyping based on clinicians' notes.\n", "versions": [{"version": "v1", "created": "Sat, 25 Mar 2017 15:37:09 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Gehrmann", "Sebastian", ""], ["Dernoncourt", "Franck", ""], ["Li", "Yeran", ""], ["Carlson", "Eric T.", ""], ["Wu", "Joy T.", ""], ["Welt", "Jonathan", ""], ["Foote", "John", "Jr."], ["Moseley", "Edward T.", ""], ["Grant", "David W.", ""], ["Tyler", "Patrick D.", ""], ["Celi", "Leo Anthony", ""]]}, {"id": "1703.08748", "submitter": "Aaron Li-Feng Han", "authors": "Aaron Li-Feng Han", "title": "LEPOR: An Augmented Machine Translation Evaluation Metric", "comments": "132 pages, thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine translation (MT) was developed as one of the hottest research topics\nin the natural language processing (NLP) literature. One important issue in MT\nis that how to evaluate the MT system reasonably and tell us whether the\ntranslation system makes an improvement or not. The traditional manual judgment\nmethods are expensive, time-consuming, unrepeatable, and sometimes with low\nagreement. On the other hand, the popular automatic MT evaluation methods have\nsome weaknesses. Firstly, they tend to perform well on the language pairs with\nEnglish as the target language, but weak when English is used as source.\nSecondly, some methods rely on many additional linguistic features to achieve\ngood performance, which makes the metric unable to replicate and apply to other\nlanguage pairs easily. Thirdly, some popular metrics utilize incomprehensive\nfactors, which result in low performance on some practical tasks. In this\nthesis, to address the existing problems, we design novel MT evaluation methods\nand investigate their performances on different languages. Firstly, we design\naugmented factors to yield highly accurate evaluation.Secondly, we design a\ntunable evaluation model where weighting of factors can be optimised according\nto the characteristics of languages. Thirdly, in the enhanced version of our\nmethods, we design concise linguistic feature using POS to show that our\nmethods can yield even higher performance when using some external linguistic\nresources. Finally, we introduce the practical performance of our metrics in\nthe ACL-WMT workshop shared tasks, which show that the proposed methods are\nrobust across different languages.\n", "versions": [{"version": "v1", "created": "Sun, 26 Mar 2017 00:30:38 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Han", "Aaron Li-Feng", ""]]}, {"id": "1703.08864", "submitter": "Alexander Ororbia II", "authors": "Alexander G. Ororbia II, Tomas Mikolov, and David Reitter", "title": "Learning Simpler Language Models with the Differential State Framework", "comments": "Edits/revisions applied throughout document", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning useful information across long time lags is a critical and difficult\nproblem for temporal neural models in tasks such as language modeling. Existing\narchitectures that address the issue are often complex and costly to train. The\nDifferential State Framework (DSF) is a simple and high-performing design that\nunifies previously introduced gated neural models. DSF models maintain\nlonger-term memory by learning to interpolate between a fast-changing\ndata-driven representation and a slowly changing, implicitly stable state. This\nrequires hardly any more parameters than a classical, simple recurrent network.\nWithin the DSF framework, a new architecture is presented, the Delta-RNN. In\nlanguage modeling at the word and character levels, the Delta-RNN outperforms\npopular complex architectures, such as the Long Short Term Memory (LSTM) and\nthe Gated Recurrent Unit (GRU), and, when regularized, performs comparably to\nseveral state-of-the-art baselines. At the subword level, the Delta-RNN's\nperformance is comparable to that of complex gated architectures.\n", "versions": [{"version": "v1", "created": "Sun, 26 Mar 2017 20:02:44 GMT"}, {"version": "v2", "created": "Thu, 1 Jun 2017 21:19:31 GMT"}, {"version": "v3", "created": "Mon, 5 Jun 2017 14:40:47 GMT"}, {"version": "v4", "created": "Sun, 16 Jul 2017 22:27:29 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Ororbia", "Alexander G.", "II"], ["Mikolov", "Tomas", ""], ["Reitter", "David", ""]]}, {"id": "1703.08885", "submitter": "Yusuke Watanabe Dr.", "authors": "Yusuke Watanabe, Bhuwan Dhingra, Ruslan Salakhutdinov", "title": "Question Answering from Unstructured Text by Retrieval and Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open domain Question Answering (QA) systems must interact with external\nknowledge sources, such as web pages, to find relevant information. Information\nsources like Wikipedia, however, are not well structured and difficult to\nutilize in comparison with Knowledge Bases (KBs). In this work we present a\ntwo-step approach to question answering from unstructured text, consisting of a\nretrieval step and a comprehension step. For comprehension, we present an RNN\nbased attention model with a novel mixture mechanism for selecting answers from\neither retrieved articles or a fixed vocabulary. For retrieval we introduce a\nhand-crafted model and a neural model for ranking relevant articles. We achieve\nstate-of-the-art performance on W IKI M OVIES dataset, reducing the error by\n40%. Our experimental results further demonstrate the importance of each of the\nintroduced components.\n", "versions": [{"version": "v1", "created": "Sun, 26 Mar 2017 23:48:06 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Watanabe", "Yusuke", ""], ["Dhingra", "Bhuwan", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1703.09013", "submitter": "Christina Niklaus", "authors": "Christina Niklaus, Bernhard Bermeitinger, Siegfried Handschuh, Andr\\'e\n  Freitas", "title": "A Sentence Simplification System for Improving Relation Extraction", "comments": "26th International Conference on Computational Linguistics (COLING\n  2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this demo paper, we present a text simplification approach that is\ndirected at improving the performance of state-of-the-art Open Relation\nExtraction (RE) systems. As syntactically complex sentences often pose a\nchallenge for current Open RE approaches, we have developed a simplification\nframework that performs a pre-processing step by taking a single sentence as\ninput and using a set of syntactic-based transformation rules to create a\ntextual input that is easier to process for subsequently applied Open RE\nsystems.\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 11:15:58 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Niklaus", "Christina", ""], ["Bermeitinger", "Bernhard", ""], ["Handschuh", "Siegfried", ""], ["Freitas", "Andr\u00e9", ""]]}, {"id": "1703.09046", "submitter": "Mika M\\\"antyl\\\"a", "authors": "Mika V. M\\\"antyl\\\"a, Nicole Novielli, Filippo Lanubile, Ma\\\"elick\n  Claes, Miikka Kuutila", "title": "Bootstrapping a Lexicon for Emotional Arousal in Software Engineering", "comments": "5 pages. Accepted version. Copyright IEEE", "journal-ref": null, "doi": "10.1109/MSR.2017.47", "report-no": null, "categories": "cs.SE cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotional arousal increases activation and performance but may also lead to\nburnout in software development. We present the first version of a Software\nEngineering Arousal lexicon (SEA) that is specifically designed to address the\nproblem of emotional arousal in the software developer ecosystem. SEA is built\nusing a bootstrapping approach that combines word embedding model trained on\nissue-tracking data and manual scoring of items in the lexicon. We show that\nour lexicon is able to differentiate between issue priorities, which are a\nsource of emotional activation and then act as a proxy for arousal. The best\nperformance is obtained by combining SEA (428 words) with a previously created\ngeneral purpose lexicon by Warriner et al. (13,915 words) and it achieves\nCohen's d effect sizes up to 0.5.\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 13:11:33 GMT"}], "update_date": "2017-05-29", "authors_parsed": [["M\u00e4ntyl\u00e4", "Mika V.", ""], ["Novielli", "Nicole", ""], ["Lanubile", "Filippo", ""], ["Claes", "Ma\u00eblick", ""], ["Kuutila", "Miikka", ""]]}, {"id": "1703.09137", "submitter": "Marc Tanti", "authors": "Marc Tanti (1), Albert Gatt (1), Kenneth P. Camilleri (1) ((1)\n  University of Malta)", "title": "Where to put the Image in an Image Caption Generator", "comments": "Accepted in JNLE Special Issue: Language for Images (24.3) (expanded\n  with content that was removed from journal paper in order to reduce number of\n  pages), 28 pages, 5 figures, 6 tables", "journal-ref": null, "doi": "10.1017/S1351324918000098", "report-no": null, "categories": "cs.NE cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When a recurrent neural network language model is used for caption\ngeneration, the image information can be fed to the neural network either by\ndirectly incorporating it in the RNN -- conditioning the language model by\n`injecting' image features -- or in a layer following the RNN -- conditioning\nthe language model by `merging' image features. While both options are attested\nin the literature, there is as yet no systematic comparison between the two. In\nthis paper we empirically show that it is not especially detrimental to\nperformance whether one architecture is used or another. The merge architecture\ndoes have practical advantages, as conditioning by merging allows the RNN's\nhidden state vector to shrink in size by up to four times. Our results suggest\nthat the visual and linguistic modalities for caption generation need not be\njointly encoded by the RNN as that yields large, memory-intensive models with\nfew tangible advantages in performance; rather, the multimodal integration\nshould be delayed to a subsequent stage.\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 15:13:49 GMT"}, {"version": "v2", "created": "Wed, 14 Mar 2018 08:56:53 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Tanti", "Marc", ""], ["Gatt", "Albert", ""], ["Camilleri", "Kenneth P.", ""]]}, {"id": "1703.09398", "submitter": "Benjamin Horne", "authors": "Benjamin D. Horne and Sibel Adali", "title": "This Just In: Fake News Packs a Lot in Title, Uses Simpler, Repetitive\n  Content in Text Body, More Similar to Satire than Real News", "comments": "Published at The 2nd International Workshop on News and Public\n  Opinion at ICWSM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of fake news has gained a lot of attention as it is claimed to\nhave had a significant impact on 2016 US Presidential Elections. Fake news is\nnot a new problem and its spread in social networks is well-studied. Often an\nunderlying assumption in fake news discussion is that it is written to look\nlike real news, fooling the reader who does not check for reliability of the\nsources or the arguments in its content. Through a unique study of three data\nsets and features that capture the style and the language of articles, we show\nthat this assumption is not true. Fake news in most cases is more similar to\nsatire than to real news, leading us to conclude that persuasion in fake news\nis achieved through heuristics rather than the strength of arguments. We show\noverall title structure and the use of proper nouns in titles are very\nsignificant in differentiating fake from real. This leads us to conclude that\nfake news is targeted for audiences who are not likely to read beyond titles\nand is aimed at creating mental associations between entities and claims.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 04:47:11 GMT"}], "update_date": "2017-03-29", "authors_parsed": [["Horne", "Benjamin D.", ""], ["Adali", "Sibel", ""]]}, {"id": "1703.09400", "submitter": "Naeemul Hassan", "authors": "Md Main Uddin Rony, Naeemul Hassan, Mohammad Yousuf", "title": "Diving Deep into Clickbaits: Who Use Them to What Extents in Which\n  Topics with What Effects?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of alluring headlines (clickbait) to tempt the readers has become a\ngrowing practice nowadays. For the sake of existence in the highly competitive\nmedia industry, most of the on-line media including the mainstream ones, have\nstarted following this practice. Although the wide-spread practice of clickbait\nmakes the reader's reliability on media vulnerable, a large scale analysis to\nreveal this fact is still absent. In this paper, we analyze 1.67 million\nFacebook posts created by 153 media organizations to understand the extent of\nclickbait practice, its impact and user engagement by using our own developed\nclickbait detection model. The model uses distributed sub-word embeddings\nlearned from a large corpus. The accuracy of the model is 98.3%. Powered with\nthis model, we further study the distribution of topics in clickbait and\nnon-clickbait contents.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 05:07:38 GMT"}], "update_date": "2017-03-29", "authors_parsed": [["Rony", "Md Main Uddin", ""], ["Hassan", "Naeemul", ""], ["Yousuf", "Mohammad", ""]]}, {"id": "1703.09439", "submitter": "Phillip Keung", "authors": "Yichao Lu, Phillip Keung, Shaonan Zhang, Jason Sun, Vikas Bhardwaj", "title": "A practical approach to dialogue response generation in closed domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a prototype dialogue response generation model for the customer\nservice domain at Amazon. The model, which is trained in a weakly supervised\nfashion, measures the similarity between customer questions and agent answers\nusing a dual encoder network, a Siamese-like neural network architecture.\nAnswer templates are extracted from embeddings derived from past agent answers,\nwithout turn-by-turn annotations. Responses to customer inquiries are generated\nby selecting the best template from the final set of templates. We show that,\nin a closed domain like customer service, the selected templates cover $>$70\\%\nof past customer inquiries. Furthermore, the relevance of the model-selected\ntemplates is significantly higher than templates selected by a standard tf-idf\nbaseline.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 07:47:27 GMT"}], "update_date": "2017-03-29", "authors_parsed": [["Lu", "Yichao", ""], ["Keung", "Phillip", ""], ["Zhang", "Shaonan", ""], ["Sun", "Jason", ""], ["Bhardwaj", "Vikas", ""]]}, {"id": "1703.09527", "submitter": "Santiago Castro", "authors": "Santiago Castro and Mat\\'ias Cubero and Diego Garat and Guillermo\n  Moncecchi", "title": "Is This a Joke? Detecting Humor in Spanish Tweets", "comments": "Preprint version, without referral", "journal-ref": "Presented in Iberamia 2016. The final publication is available at\n  link.springer.com:\n  https://link.springer.com/chapter/10.1007%2F978-3-319-47955-2_12", "doi": "10.1007/978-3-319-47955-2_12", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While humor has been historically studied from a psychological, cognitive and\nlinguistic standpoint, its study from a computational perspective is an area\nyet to be explored in Computational Linguistics. There exist some previous\nworks, but a characterization of humor that allows its automatic recognition\nand generation is far from being specified. In this work we build a\ncrowdsourced corpus of labeled tweets, annotated according to its humor value,\nletting the annotators subjectively decide which are humorous. A humor\nclassifier for Spanish tweets is assembled based on supervised learning,\nreaching a precision of 84% and a recall of 69%.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 12:08:46 GMT"}], "update_date": "2017-03-29", "authors_parsed": [["Castro", "Santiago", ""], ["Cubero", "Mat\u00edas", ""], ["Garat", "Diego", ""], ["Moncecchi", "Guillermo", ""]]}, {"id": "1703.09570", "submitter": "Taylor Arnold", "authors": "Taylor Arnold", "title": "A Tidy Data Model for Natural Language Processing using cleanNLP", "comments": "20 pages; 4 figures", "journal-ref": "The R Journal, 9.2, 248-267 (2017)", "doi": null, "report-no": null, "categories": "cs.CL stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The package cleanNLP provides a set of fast tools for converting a textual\ncorpus into a set of normalized tables. The underlying natural language\nprocessing pipeline utilizes Stanford's CoreNLP library, exposing a number of\nannotation tasks for text written in English, French, German, and Spanish.\nAnnotators include tokenization, part of speech tagging, named entity\nrecognition, entity linking, sentiment analysis, dependency parsing,\ncoreference resolution, and information extraction.\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 02:18:36 GMT"}, {"version": "v2", "created": "Thu, 3 May 2018 16:45:10 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Arnold", "Taylor", ""]]}, {"id": "1703.09684", "submitter": "Kushal Kafle", "authors": "Kushal Kafle and Christopher Kanan", "title": "An Analysis of Visual Question Answering Algorithms", "comments": "To appear in ICCV 2017. Visit http://kushalkafle.com/projects/tdiuc\n  to download the dataset", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In visual question answering (VQA), an algorithm must answer text-based\nquestions about images. While multiple datasets for VQA have been created since\nlate 2014, they all have flaws in both their content and the way algorithms are\nevaluated on them. As a result, evaluation scores are inflated and\npredominantly determined by answering easier questions, making it difficult to\ncompare different methods. In this paper, we analyze existing VQA algorithms\nusing a new dataset. It contains over 1.6 million questions organized into 12\ndifferent categories. We also introduce questions that are meaningless for a\ngiven image to force a VQA system to reason about image content. We propose new\nevaluation schemes that compensate for over-represented question-types and make\nit easier to study the strengths and weaknesses of algorithms. We analyze the\nperformance of both baseline and state-of-the-art VQA models, including\nmulti-modal compact bilinear pooling (MCB), neural module networks, and\nrecurrent answering units. Our experiments establish how attention helps\ncertain categories more than others, determine which models work better than\nothers, and explain how simple models (e.g. MLP) can surpass more complex\nmodels (MCB) by simply learning to answer large, easy question categories.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 17:48:07 GMT"}, {"version": "v2", "created": "Wed, 13 Sep 2017 18:56:45 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Kafle", "Kushal", ""], ["Kanan", "Christopher", ""]]}, {"id": "1703.09749", "submitter": "Kouakou Ive Koffi", "authors": "Kouakou Ive Arsene Koffi, Konan Marcellin Brou, Souleymane Oumtanaga", "title": "Developpement de Methodes Automatiques pour la Reutilisation des\n  Composants Logiciels", "comments": "in French", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The large amount of information and the increasing complexity of applications\nconstrain developers to have stand-alone and reusable components from libraries\nand component markets.Our approach consists in developing methods to evaluate\nthe quality of the software component of these libraries, on the one hand and\nmoreover to optimize the financial cost and the adaptation's time of these\nselected components. Our objective function defines a metric that maximizes the\nvalue of the software component quality by minimizing the financial cost and\nmaintenance time. This model should make it possible to classify the components\nand order them in order to choose the most optimized.\n  MOTS-CLES : d{\\'e}veloppement de m{\\'e}thode, r{\\'e}utilisation, composants\nlogiciels, qualit{\\'e} de composant\n  KEYWORDS:method development, reuse, software components, component quality .\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 15:34:28 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Koffi", "Kouakou Ive Arsene", ""], ["Brou", "Konan Marcellin", ""], ["Oumtanaga", "Souleymane", ""]]}, {"id": "1703.09817", "submitter": "Joseph Keshet", "authors": "Einat Naaman, Yossi Adi, and Joseph Keshet", "title": "Learning Similarity Functions for Pronunciation Variations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A significant source of errors in Automatic Speech Recognition (ASR) systems\nis due to pronunciation variations which occur in spontaneous and\nconversational speech. Usually ASR systems use a finite lexicon that provides\none or more pronunciations for each word. In this paper, we focus on learning a\nsimilarity function between two pronunciations. The pronunciations can be the\ncanonical and the surface pronunciations of the same word or they can be two\nsurface pronunciations of different words. This task generalizes problems such\nas lexical access (the problem of learning the mapping between words and their\npossible pronunciations), and defining word neighborhoods. It can also be used\nto dynamically increase the size of the pronunciation lexicon, or in predicting\nASR errors. We propose two methods, which are based on recurrent neural\nnetworks, to learn the similarity function. The first is based on binary\nclassification, and the second is based on learning the ranking of the\npronunciations. We demonstrate the efficiency of our approach on the task of\nlexical access using a subset of the Switchboard conversational speech corpus.\nResults suggest that on this task our methods are superior to previous methods\nwhich are based on graphical Bayesian methods.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 21:47:16 GMT"}, {"version": "v2", "created": "Sun, 28 May 2017 19:05:38 GMT"}, {"version": "v3", "created": "Sun, 18 Jun 2017 11:52:54 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Naaman", "Einat", ""], ["Adi", "Yossi", ""], ["Keshet", "Joseph", ""]]}, {"id": "1703.09825", "submitter": "Areej Alhothali", "authors": "Areej Alhothali and Jesse Hoey", "title": "Semi-Supervised Affective Meaning Lexicon Expansion Using Semantic and\n  Distributed Word Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an extension to graph-based sentiment lexicon\ninduction methods by incorporating distributed and semantic word\nrepresentations in building the similarity graph to expand a three-dimensional\nsentiment lexicon. We also implemented and evaluated the label propagation\nusing four different word representations and similarity metrics. Our\ncomprehensive evaluation of the four approaches was performed on a single data\nset, demonstrating that all four methods can generate a significant number of\nnew sentiment assignments with high accuracy. The highest correlations\n(tau=0.51) and the lowest error (mean absolute error < 1.1%), obtained by\ncombining both the semantic and the distributional features, outperformed the\ndistributional-based and semantic-based label-propagation models and approached\na supervised algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 22:05:20 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Alhothali", "Areej", ""], ["Hoey", "Jesse", ""]]}, {"id": "1703.09831", "submitter": "Haonan Yu", "authors": "Haonan Yu, Haichao Zhang, and Wei Xu", "title": "A Deep Compositional Framework for Human-like Language Acquisition in\n  Virtual Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle a task where an agent learns to navigate in a 2D maze-like\nenvironment called XWORLD. In each session, the agent perceives a sequence of\nraw-pixel frames, a natural language command issued by a teacher, and a set of\nrewards. The agent learns the teacher's language from scratch in a grounded and\ncompositional manner, such that after training it is able to correctly execute\nzero-shot commands: 1) the combination of words in the command never appeared\nbefore, and/or 2) the command contains new object concepts that are learned\nfrom another task but never learned from navigation. Our deep framework for the\nagent is trained end to end: it learns simultaneously the visual\nrepresentations of the environment, the syntax and semantics of the language,\nand the action module that outputs actions. The zero-shot learning capability\nof our framework results from its compositionality and modularity with\nparameter tying. We visualize the intermediate outputs of the framework,\ndemonstrating that the agent truly understands how to solve the problem. We\nbelieve that our results provide some preliminary insights on how to train an\nagent with similar abilities in a 3D environment.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 22:29:53 GMT"}, {"version": "v2", "created": "Thu, 13 Apr 2017 20:28:59 GMT"}, {"version": "v3", "created": "Fri, 19 May 2017 23:33:28 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Yu", "Haonan", ""], ["Zhang", "Haichao", ""], ["Xu", "Wei", ""]]}, {"id": "1703.09902", "submitter": "Albert Gatt", "authors": "Albert Gatt and Emiel Krahmer", "title": "Survey of the State of the Art in Natural Language Generation: Core\n  tasks, applications and evaluation", "comments": "Published in Journal of AI Research (JAIR), volume 61, pp 75-170. 118\n  pages, 8 figures, 1 table", "journal-ref": "Journal of AI Research, volume 60, 2017", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper surveys the current state of the art in Natural Language\nGeneration (NLG), defined as the task of generating text or speech from\nnon-linguistic input. A survey of NLG is timely in view of the changes that the\nfield has undergone over the past decade or so, especially in relation to new\n(usually data-driven) methods, as well as new applications of NLG technology.\nThis survey therefore aims to (a) give an up-to-date synthesis of research on\nthe core tasks in NLG and the architectures adopted in which such tasks are\norganised; (b) highlight a number of relatively recent research topics that\nhave arisen partly as a result of growing synergies between NLG and other areas\nof artificial intelligence; (c) draw attention to the challenges in NLG\nevaluation, relating them to similar challenges faced in other areas of Natural\nLanguage Processing, with an emphasis on different evaluation methods and the\nrelationships between them.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 06:51:00 GMT"}, {"version": "v2", "created": "Tue, 12 Dec 2017 18:13:29 GMT"}, {"version": "v3", "created": "Tue, 19 Dec 2017 20:11:03 GMT"}, {"version": "v4", "created": "Mon, 29 Jan 2018 16:09:38 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Gatt", "Albert", ""], ["Krahmer", "Emiel", ""]]}, {"id": "1703.10065", "submitter": "Soumia Bougrine", "authors": "Soumia Bougrine and Hadda Cherroun and Djelloul Ziadi", "title": "Hierarchical Classification for Spoken Arabic Dialect Identification\n  using Prosody: Case of Algerian Dialects", "comments": "33 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In daily communications, Arabs use local dialects which are hard to identify\nautomatically using conventional classification methods. The dialect\nidentification challenging task becomes more complicated when dealing with an\nunder-resourced dialects belonging to a same county/region. In this paper, we\nstart by analyzing statistically Algerian dialects in order to capture their\nspecificities related to prosody information which are extracted at utterance\nlevel after a coarse-grained consonant/vowel segmentation. According to these\nanalysis findings, we propose a Hierarchical classification approach for spoken\nArabic algerian Dialect IDentification (HADID). It takes advantage from the\nfact that dialects have an inherent property of naturally structured into\nhierarchy. Within HADID, a top-down hierarchical classification is applied, in\nwhich we use Deep Neural Networks (DNNs) method to build a local classifier for\nevery parent node into the hierarchy dialect structure. Our framework is\nimplemented and evaluated on Algerian Arabic dialects corpus. Whereas, the\nhierarchy dialect structure is deduced from historic and linguistic knowledges.\nThe results reveal that within {\\HD}, the best classifier is DNNs compared to\nSupport Vector Machine. In addition, compared with a baseline Flat\nclassification system, our HADID gives an improvement of 63.5% in term of\nprecision. Furthermore, overall results evidence the suitability of our\nprosody-based HADID for speaker independent dialect identification while\nrequiring less than 6s test utterances.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 14:26:13 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Bougrine", "Soumia", ""], ["Cherroun", "Hadda", ""], ["Ziadi", "Djelloul", ""]]}, {"id": "1703.10090", "submitter": "Simon \\v{S}uster", "authors": "Simon \\v{S}uster and St\\'ephan Tulkens and Walter Daelemans", "title": "A Short Review of Ethical Challenges in Clinical Natural Language\n  Processing", "comments": "First Workshop on Ethics in Natural Language Processing (EACL'17)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical NLP has an immense potential in contributing to how clinical\npractice will be revolutionized by the advent of large scale processing of\nclinical records. However, this potential has remained largely untapped due to\nslow progress primarily caused by strict data access policies for researchers.\nIn this paper, we discuss the concern for privacy and the measures it entails.\nWe also suggest sources of less sensitive data. Finally, we draw attention to\nbiases that can compromise the validity of empirical research and lead to\nsocially harmful applications.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 15:12:10 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["\u0160uster", "Simon", ""], ["Tulkens", "St\u00e9phan", ""], ["Daelemans", "Walter", ""]]}, {"id": "1703.10135", "submitter": "Yuxuan Wang", "authors": "Yuxuan Wang, RJ Skerry-Ryan, Daisy Stanton, Yonghui Wu, Ron J. Weiss,\n  Navdeep Jaitly, Zongheng Yang, Ying Xiao, Zhifeng Chen, Samy Bengio, Quoc Le,\n  Yannis Agiomyrgiannakis, Rob Clark, Rif A. Saurous", "title": "Tacotron: Towards End-to-End Speech Synthesis", "comments": "Submitted to Interspeech 2017. v2 changed paper title to be\n  consistent with our conference submission (no content change other than typo\n  fixes)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A text-to-speech synthesis system typically consists of multiple stages, such\nas a text analysis frontend, an acoustic model and an audio synthesis module.\nBuilding these components often requires extensive domain expertise and may\ncontain brittle design choices. In this paper, we present Tacotron, an\nend-to-end generative text-to-speech model that synthesizes speech directly\nfrom characters. Given <text, audio> pairs, the model can be trained completely\nfrom scratch with random initialization. We present several key techniques to\nmake the sequence-to-sequence framework perform well for this challenging task.\nTacotron achieves a 3.82 subjective 5-scale mean opinion score on US English,\noutperforming a production parametric system in terms of naturalness. In\naddition, since Tacotron generates speech at the frame level, it's\nsubstantially faster than sample-level autoregressive methods.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 16:55:13 GMT"}, {"version": "v2", "created": "Thu, 6 Apr 2017 21:20:34 GMT"}], "update_date": "2017-04-10", "authors_parsed": [["Wang", "Yuxuan", ""], ["Skerry-Ryan", "RJ", ""], ["Stanton", "Daisy", ""], ["Wu", "Yonghui", ""], ["Weiss", "Ron J.", ""], ["Jaitly", "Navdeep", ""], ["Yang", "Zongheng", ""], ["Xiao", "Ying", ""], ["Chen", "Zhifeng", ""], ["Bengio", "Samy", ""], ["Le", "Quoc", ""], ["Agiomyrgiannakis", "Yannis", ""], ["Clark", "Rob", ""], ["Saurous", "Rif A.", ""]]}, {"id": "1703.10152", "submitter": "Haixia Liu", "authors": "Haixia Liu", "title": "Automatic Argumentative-Zoning Using Word2vec", "comments": "13 pages; 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In comparison with document summarization on the articles from social media\nand newswire, argumentative zoning (AZ) is an important task in scientific\npaper analysis. Traditional methodology to carry on this task relies on feature\nengineering from different levels. In this paper, three models of generating\nsentence vectors for the task of sentence classification were explored and\ncompared. The proposed approach builds sentence representations using learned\nembeddings based on neural network. The learned word embeddings formed a\nfeature space, to which the examined sentence is mapped to. Those features are\ninput into the classifiers for supervised classification. Using\n10-cross-validation scheme, evaluation was conducted on the\nArgumentative-Zoning (AZ) annotated articles. The results showed that simply\naveraging the word vectors in a sentence works better than the paragraph to\nvector algorithm and by integrating specific cuewords into the loss function of\nthe neural network can improve the classification performance. In comparison\nwith the hand-crafted features, the word2vec method won for most of the\ncategories. However, the hand-crafted features showed their strength on\nclassifying some of the categories.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 17:33:27 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Liu", "Haixia", ""]]}, {"id": "1703.10186", "submitter": "Will Monroe", "authors": "Will Monroe, Robert X.D. Hawkins, Noah D. Goodman, Christopher Potts", "title": "Colors in Context: A Pragmatic Neural Model for Grounded Language\n  Understanding", "comments": "14 pages, 3 tables, 6 figures. TACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a model of pragmatic referring expression interpretation in a\ngrounded communication task (identifying colors from descriptions) that draws\nupon predictions from two recurrent neural network classifiers, a speaker and a\nlistener, unified by a recursive pragmatic reasoning framework. Experiments\nshow that this combined pragmatic model interprets color descriptions more\naccurately than the classifiers from which it is built, and that much of this\nimprovement results from combining the speaker and listener perspectives. We\nobserve that pragmatic reasoning helps primarily in the hardest cases: when the\nmodel must distinguish very similar colors, or when few utterances adequately\nexpress the target color. Our findings make use of a newly-collected corpus of\nhuman utterances in color reference games, which exhibit a variety of pragmatic\nbehaviors. We also show that the embedded speaker model reproduces many of\nthese pragmatic behaviors.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 18:15:06 GMT"}, {"version": "v2", "created": "Tue, 16 May 2017 04:03:10 GMT"}], "update_date": "2017-05-17", "authors_parsed": [["Monroe", "Will", ""], ["Hawkins", "Robert X. D.", ""], ["Goodman", "Noah D.", ""], ["Potts", "Christopher", ""]]}, {"id": "1703.10252", "submitter": "Dimitri Kartsaklis", "authors": "Dimitrios Kartsaklis, Sanjaye Ramgoolam, Mehrnoosh Sadrzadeh", "title": "Linguistic Matrix Theory", "comments": "32 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": "QMUL-PH-17-03", "categories": "cs.CL hep-th math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research in computational linguistics has developed algorithms which\nassociate matrices with adjectives and verbs, based on the distribution of\nwords in a corpus of text. These matrices are linear operators on a vector\nspace of context words. They are used to construct the meaning of composite\nexpressions from that of the elementary constituents, forming part of a\ncompositional distributional approach to semantics. We propose a Matrix Theory\napproach to this data, based on permutation symmetry along with Gaussian\nweights and their perturbations. A simple Gaussian model is tested against word\nmatrices created from a large corpus of text. We characterize the cubic and\nquartic departures from the model, which we propose, alongside the Gaussian\nparameters, as signatures for comparison of linguistic corpora. We propose that\nperturbed Gaussian models with permutation symmetry provide a promising\nframework for characterizing the nature of universality in the statistical\nproperties of word matrices. The matrix theory framework developed here\nexploits the view of statistics as zero dimensional perturbative quantum field\ntheory. It perceives language as a physical system realizing a universality\nclass of matrix statistics characterized by permutation symmetry.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 15:20:52 GMT"}], "update_date": "2017-03-31", "authors_parsed": [["Kartsaklis", "Dimitrios", ""], ["Ramgoolam", "Sanjaye", ""], ["Sadrzadeh", "Mehrnoosh", ""]]}, {"id": "1703.10339", "submitter": "Besnik Fetahu", "authors": "Besnik Fetahu and Katja Markert and Wolfgang Nejdl and Avishek Anand", "title": "Finding News Citations for Wikipedia", "comments": null, "journal-ref": null, "doi": "10.1145/2983323.2983808", "report-no": null, "categories": "cs.IR cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important editing policy in Wikipedia is to provide citations for added\nstatements in Wikipedia pages, where statements can be arbitrary pieces of\ntext, ranging from a sentence to a paragraph. In many cases citations are\neither outdated or missing altogether.\n  In this work we address the problem of finding and updating news citations\nfor statements in entity pages. We propose a two-stage supervised approach for\nthis problem. In the first step, we construct a classifier to find out whether\nstatements need a news citation or other kinds of citations (web, book,\njournal, etc.). In the second step, we develop a news citation algorithm for\nWikipedia statements, which recommends appropriate citations from a given news\ncollection. Apart from IR techniques that use the statement to query the news\ncollection, we also formalize three properties of an appropriate citation,\nnamely: (i) the citation should entail the Wikipedia statement, (ii) the\nstatement should be central to the citation, and (iii) the citation should be\nfrom an authoritative source.\n  We perform an extensive evaluation of both steps, using 20 million articles\nfrom a real-world news collection. Our results are quite promising, and show\nthat we can perform this task with high precision and at scale.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 07:48:31 GMT"}, {"version": "v2", "created": "Mon, 24 Apr 2017 18:28:09 GMT"}], "update_date": "2017-04-26", "authors_parsed": [["Fetahu", "Besnik", ""], ["Markert", "Katja", ""], ["Nejdl", "Wolfgang", ""], ["Anand", "Avishek", ""]]}, {"id": "1703.10344", "submitter": "Besnik Fetahu", "authors": "Besnik Fetahu and Katja Markert and Avishek Anand", "title": "Automated News Suggestions for Populating Wikipedia Entity Pages", "comments": null, "journal-ref": null, "doi": "10.1145/2806416.2806531", "report-no": null, "categories": "cs.IR cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wikipedia entity pages are a valuable source of information for direct\nconsumption and for knowledge-base construction, update and maintenance. Facts\nin these entity pages are typically supported by references. Recent studies\nshow that as much as 20\\% of the references are from online news sources.\nHowever, many entity pages are incomplete even if relevant information is\nalready available in existing news articles. Even for the already present\nreferences, there is often a delay between the news article publication time\nand the reference time. In this work, we therefore look at Wikipedia through\nthe lens of news and propose a novel news-article suggestion task to improve\nnews coverage in Wikipedia, and reduce the lag of newsworthy references. Our\nwork finds direct application, as a precursor, to Wikipedia page generation and\nknowledge-base acceleration tasks that rely on relevant and high quality input\nsources.\n  We propose a two-stage supervised approach for suggesting news articles to\nentity pages for a given state of Wikipedia. First, we suggest news articles to\nWikipedia entities (article-entity placement) relying on a rich set of features\nwhich take into account the \\emph{salience} and \\emph{relative authority} of\nentities, and the \\emph{novelty} of news articles to entity pages. Second, we\ndetermine the exact section in the entity page for the input article\n(article-section placement) guided by class-based section templates. We perform\nan extensive evaluation of our approach based on ground-truth data that is\nextracted from external references in Wikipedia. We achieve a high precision\nvalue of up to 93\\% in the \\emph{article-entity} suggestion stage and upto 84\\%\nfor the \\emph{article-section placement}. Finally, we compare our approach\nagainst competitive baselines and show significant improvements.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 07:56:42 GMT"}], "update_date": "2017-03-31", "authors_parsed": [["Fetahu", "Besnik", ""], ["Markert", "Katja", ""], ["Anand", "Avishek", ""]]}, {"id": "1703.10356", "submitter": "Lior Fritz", "authors": "Lior Fritz, David Burshtein", "title": "Simplified End-to-End MMI Training and Voting for ASR", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A simplified speech recognition system that uses the maximum mutual\ninformation (MMI) criterion is considered. End-to-end training using gradient\ndescent is suggested, similarly to the training of connectionist temporal\nclassification (CTC). We use an MMI criterion with a simple language model in\nthe training stage, and a standard HMM decoder. Our method compares favorably\nto CTC in terms of performance, robustness, decoding time, disk footprint and\nquality of alignments. The good alignments enable the use of a straightforward\nensemble method, obtained by simply averaging the predictions of several neural\nnetwork models, that were trained separately end-to-end. The ensemble method\nyields a considerable reduction in the word error rate.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 08:40:19 GMT"}, {"version": "v2", "created": "Sun, 16 Jul 2017 15:12:39 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Fritz", "Lior", ""], ["Burshtein", "David", ""]]}, {"id": "1703.10476", "submitter": "Rakshith Shetty", "authors": "Rakshith Shetty, Marcus Rohrbach, Lisa Anne Hendricks, Mario Fritz,\n  Bernt Schiele", "title": "Speaking the Same Language: Matching Machine to Human Captions by\n  Adversarial Training", "comments": "16 pages, Published in ICCV 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While strong progress has been made in image captioning over the last years,\nmachine and human captions are still quite distinct. A closer look reveals that\nthis is due to the deficiencies in the generated word distribution, vocabulary\nsize, and strong bias in the generators towards frequent captions. Furthermore,\nhumans -- rightfully so -- generate multiple, diverse captions, due to the\ninherent ambiguity in the captioning task which is not considered in today's\nsystems.\n  To address these challenges, we change the training objective of the caption\ngenerator from reproducing groundtruth captions to generating a set of captions\nthat is indistinguishable from human generated captions. Instead of\nhandcrafting such a learning target, we employ adversarial training in\ncombination with an approximate Gumbel sampler to implicitly match the\ngenerated distribution to the human one. While our method achieves comparable\nperformance to the state-of-the-art in terms of the correctness of the\ncaptions, we generate a set of diverse captions, that are significantly less\nbiased and match the word statistics better in several aspects.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 13:54:51 GMT"}, {"version": "v2", "created": "Mon, 6 Nov 2017 15:43:47 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Shetty", "Rakshith", ""], ["Rohrbach", "Marcus", ""], ["Hendricks", "Lisa Anne", ""], ["Fritz", "Mario", ""], ["Schiele", "Bernt", ""]]}, {"id": "1703.10661", "submitter": "Md Shopon", "authors": "Mithun Biswas, Rafiqul Islam, Gautam Kumar Shom, Md Shopon, Nabeel\n  Mohammed, Sifat Momen, Md Anowarul Abedin", "title": "BanglaLekha-Isolated: A Comprehensive Bangla Handwritten Character\n  Dataset", "comments": "Bangla Handwriting Dataset, OCR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bangla handwriting recognition is becoming a very important issue nowadays.\nIt is potentially a very important task specially for Bangla speaking\npopulation of Bangladesh and West Bengal. By keeping that in our mind we are\nintroducing a comprehensive Bangla handwritten character dataset named\nBanglaLekha-Isolated. This dataset contains Bangla handwritten numerals, basic\ncharacters and compound characters. This dataset was collected from multiple\ngeographical location within Bangladesh and includes sample collected from a\nvariety of aged groups. This dataset can also be used for other classification\nproblems i.e: gender, age, district. This is the largest dataset on Bangla\nhandwritten characters yet.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 07:57:14 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Biswas", "Mithun", ""], ["Islam", "Rafiqul", ""], ["Shom", "Gautam Kumar", ""], ["Shopon", "Md", ""], ["Mohammed", "Nabeel", ""], ["Momen", "Sifat", ""], ["Abedin", "Md Anowarul", ""]]}, {"id": "1703.10698", "submitter": "R. Alexander Bentley", "authors": "Damian Ruck, R. Alexander Bentley, Alberto Acerbi, Philip Garnett and\n  Daniel J. Hruschka", "title": "Neutral evolution and turnover over centuries of English word popularity", "comments": "12 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here we test Neutral models against the evolution of English word frequency\nand vocabulary at the population scale, as recorded in annual word frequencies\nfrom three centuries of English language books. Against these data, we test\nboth static and dynamic predictions of two neutral models, including the\nrelation between corpus size and vocabulary size, frequency distributions, and\nturnover within those frequency distributions. Although a commonly used Neutral\nmodel fails to replicate all these emergent properties at once, we find that\nmodified two-stage Neutral model does replicate the static and dynamic\nproperties of the corpus data. This two-stage model is meant to represent a\nrelatively small corpus (population) of English books, analogous to a `canon',\nsampled by an exponentially increasing corpus of books in the wider population\nof authors. More broadly, this mode -- a smaller neutral model within a larger\nneutral model -- could represent more broadly those situations where mass\nattention is focused on a small subset of the cultural variants.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 21:57:37 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Ruck", "Damian", ""], ["Bentley", "R. Alexander", ""], ["Acerbi", "Alberto", ""], ["Garnett", "Philip", ""], ["Hruschka", "Daniel J.", ""]]}, {"id": "1703.10722", "submitter": "Oleksii Kuchaiev", "authors": "Oleksii Kuchaiev, Boris Ginsburg", "title": "Factorization tricks for LSTM networks", "comments": "accepted to ICLR 2017 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two simple ways of reducing the number of parameters and\naccelerating the training of large Long Short-Term Memory (LSTM) networks: the\nfirst one is \"matrix factorization by design\" of LSTM matrix into the product\nof two smaller matrices, and the second one is partitioning of LSTM matrix, its\ninputs and states into the independent groups. Both approaches allow us to\ntrain large LSTM networks significantly faster to the near state-of the art\nperplexity while using significantly less RNN parameters.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 00:50:37 GMT"}, {"version": "v2", "created": "Thu, 4 May 2017 17:17:55 GMT"}, {"version": "v3", "created": "Sat, 24 Feb 2018 22:04:52 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Kuchaiev", "Oleksii", ""], ["Ginsburg", "Boris", ""]]}, {"id": "1703.10724", "submitter": "Ciprian Chelba", "authors": "Ciprian Chelba, Mohammad Norouzi, Samy Bengio", "title": "N-gram Language Modeling using Recurrent Neural Network Estimation", "comments": "10 pages, including references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the effective memory depth of RNN models by using them for\n$n$-gram language model (LM) smoothing.\n  Experiments on a small corpus (UPenn Treebank, one million words of training\ndata and 10k vocabulary) have found the LSTM cell with dropout to be the best\nmodel for encoding the $n$-gram state when compared with feed-forward and\nvanilla RNN models. When preserving the sentence independence assumption the\nLSTM $n$-gram matches the LSTM LM performance for $n=9$ and slightly\noutperforms it for $n=13$. When allowing dependencies across sentence\nboundaries, the LSTM $13$-gram almost matches the perplexity of the unlimited\nhistory LSTM LM.\n  LSTM $n$-gram smoothing also has the desirable property of improving with\nincreasing $n$-gram order, unlike the Katz or Kneser-Ney back-off estimators.\nUsing multinomial distributions as targets in training instead of the usual\none-hot target is only slightly beneficial for low $n$-gram orders.\n  Experiments on the One Billion Words benchmark show that the results hold at\nlarger scale: while LSTM smoothing for short $n$-gram contexts does not provide\nsignificant advantages over classic N-gram models, it becomes effective with\nlong contexts ($n > 5$); depending on the task and amount of data it can match\nfully recurrent LSTM models at about $n=13$. This may have implications when\nmodeling short-format text, e.g. voice search/query LMs.\n  Building LSTM $n$-gram LMs may be appealing for some practical situations:\nthe state in a $n$-gram LM can be succinctly represented with $(n-1)*4$ bytes\nstoring the identity of the words in the context and batches of $n$-gram\ncontexts can be processed in parallel. On the downside, the $n$-gram context\nencoding computed by the LSTM is discarded, making the model more expensive\nthan a regular recurrent LSTM LM.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 01:21:40 GMT"}, {"version": "v2", "created": "Tue, 20 Jun 2017 01:22:18 GMT"}], "update_date": "2017-06-21", "authors_parsed": [["Chelba", "Ciprian", ""], ["Norouzi", "Mohammad", ""], ["Bengio", "Samy", ""]]}, {"id": "1703.10772", "submitter": "Irshad Bhat", "authors": "Irshad Ahmad Bhat, Riyaz Ahmad Bhat, Manish Shrivastava and Dipti\n  Misra Sharma", "title": "Joining Hands: Exploiting Monolingual Treebanks for Parsing of\n  Code-mixing Data", "comments": "5 pages, EACL 2017 short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose efficient and less resource-intensive strategies\nfor parsing of code-mixed data. These strategies are not constrained by\nin-domain annotations, rather they leverage pre-existing monolingual annotated\nresources for training. We show that these methods can produce significantly\nbetter results as compared to an informed baseline. Besides, we also present a\ndata set of 450 Hindi and English code-mixed tweets of Hindi multilingual\nspeakers for evaluation. The data set is manually annotated with Universal\nDependencies.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 07:10:30 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Bhat", "Irshad Ahmad", ""], ["Bhat", "Riyaz Ahmad", ""], ["Shrivastava", "Manish", ""], ["Sharma", "Dipti Misra", ""]]}, {"id": "1703.10931", "submitter": "Xingxing Zhang", "authors": "Xingxing Zhang, Mirella Lapata", "title": "Sentence Simplification with Deep Reinforcement Learning", "comments": "to appear in EMNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence simplification aims to make sentences easier to read and understand.\nMost recent approaches draw on insights from machine translation to learn\nsimplification rewrites from monolingual corpora of complex and simple\nsentences. We address the simplification problem with an encoder-decoder model\ncoupled with a deep reinforcement learning framework. Our model, which we call\n{\\sc Dress} (as shorthand for {\\bf D}eep {\\bf RE}inforcement {\\bf S}entence\n{\\bf S}implification), explores the space of possible simplifications while\nlearning to optimize a reward function that encourages outputs which are\nsimple, fluent, and preserve the meaning of the input. Experiments on three\ndatasets demonstrate that our model outperforms competitive simplification\nsystems.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 15:05:45 GMT"}, {"version": "v2", "created": "Sun, 16 Jul 2017 02:28:14 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Zhang", "Xingxing", ""], ["Lapata", "Mirella", ""]]}, {"id": "1703.10960", "submitter": "Tiancheng Zhao", "authors": "Tiancheng Zhao, Ran Zhao and Maxine Eskenazi", "title": "Learning Discourse-level Diversity for Neural Dialog Models using\n  Conditional Variational Autoencoders", "comments": "Appeared in ACL2017 proceedings as a long paper. Correct a\n  calculation mistake in Table 1 E-bow & A-bow and results into higher scores", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While recent neural encoder-decoder models have shown great promise in\nmodeling open-domain conversations, they often generate dull and generic\nresponses. Unlike past work that has focused on diversifying the output of the\ndecoder at word-level to alleviate this problem, we present a novel framework\nbased on conditional variational autoencoders that captures the discourse-level\ndiversity in the encoder. Our model uses latent variables to learn a\ndistribution over potential conversational intents and generates diverse\nresponses using only greedy decoders. We have further developed a novel variant\nthat is integrated with linguistic prior knowledge for better performance.\nFinally, the training procedure is improved by introducing a bag-of-word loss.\nOur proposed models have been validated to generate significantly more diverse\nresponses than baseline approaches and exhibit competence in discourse-level\ndecision-making.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 15:55:00 GMT"}, {"version": "v2", "created": "Fri, 25 Aug 2017 03:38:58 GMT"}, {"version": "v3", "created": "Sat, 21 Oct 2017 04:58:20 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Zhao", "Tiancheng", ""], ["Zhao", "Ran", ""], ["Eskenazi", "Maxine", ""]]}]