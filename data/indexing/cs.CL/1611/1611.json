[{"id": "1611.00020", "submitter": "Chen Liang", "authors": "Chen Liang, Jonathan Berant, Quoc Le, Kenneth D. Forbus, Ni Lao", "title": "Neural Symbolic Machines: Learning Semantic Parsers on Freebase with\n  Weak Supervision", "comments": "ACL 2017 camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Harnessing the statistical power of neural networks to perform language\nunderstanding and symbolic reasoning is difficult, when it requires executing\nefficient discrete operations against a large knowledge-base. In this work, we\nintroduce a Neural Symbolic Machine, which contains (a) a neural \"programmer\",\ni.e., a sequence-to-sequence model that maps language utterances to programs\nand utilizes a key-variable memory to handle compositionality (b) a symbolic\n\"computer\", i.e., a Lisp interpreter that performs program execution, and helps\nfind good programs by pruning the search space. We apply REINFORCE to directly\noptimize the task reward of this structured prediction problem. To train with\nweak supervision and improve the stability of REINFORCE, we augment it with an\niterative maximum-likelihood training process. NSM outperforms the\nstate-of-the-art on the WebQuestionsSP dataset when trained from\nquestion-answer pairs only, without requiring any feature engineering or\ndomain-specific knowledge.\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2016 20:07:23 GMT"}, {"version": "v2", "created": "Wed, 2 Nov 2016 05:25:19 GMT"}, {"version": "v3", "created": "Thu, 3 Nov 2016 16:24:24 GMT"}, {"version": "v4", "created": "Sun, 23 Apr 2017 07:16:13 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Liang", "Chen", ""], ["Berant", "Jonathan", ""], ["Le", "Quoc", ""], ["Forbus", "Kenneth D.", ""], ["Lao", "Ni", ""]]}, {"id": "1611.00027", "submitter": "Yasser El-Sonbaty", "authors": "Mahmoud El-Defrawy, Yasser El-Sonbaty and Nahla A. Belal", "title": "CBAS: context based arabic stemmer", "comments": null, "journal-ref": "International Journal on Natural Language Computing (IJNLC) Vol.\n  4, No.3, June 2015", "doi": "10.5121/ijnlc.2015.4301", "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arabic morphology encapsulates many valuable features such as word root.\nArabic roots are being utilized for many tasks; the process of extracting a\nword root is referred to as stemming. Stemming is an essential part of most\nNatural Language Processing tasks, especially for derivative languages such as\nArabic. However, stemming is faced with the problem of ambiguity, where two or\nmore roots could be extracted from the same word. On the other hand,\ndistributional semantics is a powerful co-occurrence model. It captures the\nmeaning of a word based on its context. In this paper, a distributional\nsemantics model utilizing Smoothed Pointwise Mutual Information (SPMI) is\nconstructed to investigate its effectiveness on the stemming analysis task. It\nshowed an accuracy of 81.5%, with a at least 9.4% improvement over other\nstemmers.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2015 10:10:51 GMT"}], "update_date": "2016-11-02", "authors_parsed": [["El-Defrawy", "Mahmoud", ""], ["El-Sonbaty", "Yasser", ""], ["Belal", "Nahla A.", ""]]}, {"id": "1611.00068", "submitter": "Richard Sproat", "authors": "Richard Sproat, Navdeep Jaitly", "title": "RNN Approaches to Text Normalization: A Challenge", "comments": "17 pages, 13 tables, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper presents a challenge to the community: given a large corpus of\nwritten text aligned to its normalized spoken form, train an RNN to learn the\ncorrect normalization function. We present a data set of general text where the\nnormalizations were generated using an existing text normalization component of\na text-to-speech system. This data set will be released open-source in the near\nfuture.\n  We also present our own experiments with this data set with a variety of\ndifferent RNN architectures. While some of the architectures do in fact produce\nvery good results when measured in terms of overall accuracy, the errors that\nare produced are problematic, since they would convey completely the wrong\nmessage if such a system were deployed in a speech application. On the other\nhand, we show that a simple FST-based filter can mitigate those errors, and\nachieve a level of accuracy not achievable by the RNN alone.\n  Though our conclusions are largely negative on this point, we are actually\nnot arguing that the text normalization problem is intractable using an pure\nRNN approach, merely that it is not going to be something that can be solved\nmerely by having huge amounts of annotated text data and feeding that to a\ngeneral RNN model. And when we open-source our data, we will be providing a\nnovel data set for sequence-to-sequence modeling in the hopes that the the\ncommunity can find better solutions.\n  The data used in this work have been released and are available at:\nhttps://github.com/rwsproat/text-normalization-data\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2016 22:42:02 GMT"}, {"version": "v2", "created": "Tue, 24 Jan 2017 19:51:12 GMT"}], "update_date": "2017-01-26", "authors_parsed": [["Sproat", "Richard", ""], ["Jaitly", "Navdeep", ""]]}, {"id": "1611.00126", "submitter": "Shufeng Xiong", "authors": "Shufeng Xiong", "title": "Improving Twitter Sentiment Classification via Multi-Level\n  Sentiment-Enriched Word Embeddings", "comments": null, "journal-ref": null, "doi": "10.1016/j.neucom.2017.11.023", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of existing work learn sentiment-specific word representation for\nimproving Twitter sentiment classification, which encoded both n-gram and\ndistant supervised tweet sentiment information in learning process. They assume\nall words within a tweet have the same sentiment polarity as the whole tweet,\nwhich ignores the word its own sentiment polarity. To address this problem, we\npropose to learn sentiment-specific word embedding by exploiting both lexicon\nresource and distant supervised information. We develop a multi-level\nsentiment-enriched word embedding learning method, which uses parallel\nasymmetric neural network to model n-gram, word level sentiment and tweet level\nsentiment in learning process. Experiments on standard benchmarks show our\napproach outperforms state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2016 04:48:09 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Xiong", "Shufeng", ""]]}, {"id": "1611.00138", "submitter": "Sebastian Raschka SR", "authors": "Sebastian Raschka", "title": "MusicMood: Predicting the mood of music from song lyrics using machine\n  learning", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sentiment prediction of contemporary music can have a wide-range of\napplications in modern society, for instance, selecting music for public\ninstitutions such as hospitals or restaurants to potentially improve the\nemotional well-being of personnel, patients, and customers, respectively. In\nthis project, music recommendation system built upon on a naive Bayes\nclassifier, trained to predict the sentiment of songs based on song lyrics\nalone. The experimental results show that music corresponding to a happy mood\ncan be detected with high precision based on text features obtained from song\nlyrics.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2016 06:05:49 GMT"}], "update_date": "2016-11-02", "authors_parsed": [["Raschka", "Sebastian", ""]]}, {"id": "1611.00179", "submitter": "Tao Qin Dr.", "authors": "Yingce Xia, Di He, Tao Qin, Liwei Wang, Nenghai Yu, Tie-Yan Liu,\n  Wei-Ying Ma", "title": "Dual Learning for Machine Translation", "comments": null, "journal-ref": "NIPS 2016", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural machine translation (NMT) is making good progress in the past\ntwo years, tens of millions of bilingual sentence pairs are needed for its\ntraining. However, human labeling is very costly. To tackle this training data\nbottleneck, we develop a dual-learning mechanism, which can enable an NMT\nsystem to automatically learn from unlabeled data through a dual-learning game.\nThis mechanism is inspired by the following observation: any machine\ntranslation task has a dual task, e.g., English-to-French translation (primal)\nversus French-to-English translation (dual); the primal and dual tasks can form\na closed loop, and generate informative feedback signals to train the\ntranslation models, even if without the involvement of a human labeler. In the\ndual-learning mechanism, we use one agent to represent the model for the primal\ntask and the other agent to represent the model for the dual task, then ask\nthem to teach each other through a reinforcement learning process. Based on the\nfeedback signals generated during this process (e.g., the language-model\nlikelihood of the output of a model, and the reconstruction error of the\noriginal sentence after the primal and dual translations), we can iteratively\nupdate the two models until convergence (e.g., using the policy gradient\nmethods). We call the corresponding approach to neural machine translation\n\\emph{dual-NMT}. Experiments show that dual-NMT works very well on\nEnglish$\\leftrightarrow$French translation; especially, by learning from\nmonolingual data (with 10% bilingual data for warm start), it achieves a\ncomparable accuracy to NMT trained from the full bilingual data for the\nFrench-to-English translation task.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2016 10:38:29 GMT"}], "update_date": "2016-11-02", "authors_parsed": [["Xia", "Yingce", ""], ["He", "Di", ""], ["Qin", "Tao", ""], ["Wang", "Liwei", ""], ["Yu", "Nenghai", ""], ["Liu", "Tie-Yan", ""], ["Ma", "Wei-Ying", ""]]}, {"id": "1611.00196", "submitter": "Wei Li", "authors": "Wei Li, Brian Kan Wing Mak", "title": "Recurrent Neural Network Language Model Adaptation Derived Document\n  Vector", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many natural language processing (NLP) tasks, a document is commonly\nmodeled as a bag of words using the term frequency-inverse document frequency\n(TF-IDF) vector. One major shortcoming of the frequency-based TF-IDF feature\nvector is that it ignores word orders that carry syntactic and semantic\nrelationships among the words in a document, and they can be important in some\nNLP tasks such as genre classification. This paper proposes a novel distributed\nvector representation of a document: a simple recurrent-neural-network language\nmodel (RNN-LM) or a long short-term memory RNN language model (LSTM-LM) is\nfirst created from all documents in a task; some of the LM parameters are then\nadapted by each document, and the adapted parameters are vectorized to\nrepresent the document. The new document vectors are labeled as DV-RNN and\nDV-LSTM respectively. We believe that our new document vectors can capture some\nhigh-level sequential information in the documents, which other current\ndocument representations fail to capture. The new document vectors were\nevaluated in the genre classification of documents in three corpora: the Brown\nCorpus, the BNC Baby Corpus and an artificially created Penn Treebank dataset.\nTheir classification performances are compared with the performance of TF-IDF\nvector and the state-of-the-art distributed memory model of paragraph vector\n(PV-DM). The results show that DV-LSTM significantly outperforms TF-IDF and\nPV-DM in most cases, and combinations of the proposed document vectors with\nTF-IDF or PV-DM may further improve performance.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2016 12:14:02 GMT"}], "update_date": "2016-12-15", "authors_parsed": [["Li", "Wei", ""], ["Mak", "Brian Kan Wing", ""]]}, {"id": "1611.00354", "submitter": "Anoop Kunchukuttan", "authors": "Anoop Kunchukuttan, Pushpak Bhattacharyya", "title": "Faster decoding for subword level Phrase-based SMT between related\n  languages", "comments": "Accepted at VarDial3 (Third Workshop on NLP for Similar Languages,\n  Varieties and Dialects) collocated with COLING 2016; 7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A common and effective way to train translation systems between related\nlanguages is to consider sub-word level basic units. However, this increases\nthe length of the sentences resulting in increased decoding time. The increase\nin length is also impacted by the specific choice of data format for\nrepresenting the sentences as subwords. In a phrase-based SMT framework, we\ninvestigate different choices of decoder parameters as well as data format and\ntheir impact on decoding time and translation accuracy. We suggest best options\nfor these settings that significantly improve decoding time with little impact\non the translation accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2016 19:56:36 GMT"}], "update_date": "2016-11-02", "authors_parsed": [["Kunchukuttan", "Anoop", ""], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "1611.00356", "submitter": "Matthew Connelly", "authors": "Renato Rocha Souza, Flavio Codeco Coelho, Rohan Shah, Matthew Connelly", "title": "Using Artificial Intelligence to Identify State Secrets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whether officials can be trusted to protect national security information has\nbecome a matter of great public controversy, reigniting a long-standing debate\nabout the scope and nature of official secrecy. The declassification of\nmillions of electronic records has made it possible to analyze these issues\nwith greater rigor and precision. Using machine-learning methods, we examined\nnearly a million State Department cables from the 1970s to identify features of\nrecords that are more likely to be classified, such as international\nnegotiations, military operations, and high-level communications. Even with\nincomplete data, algorithms can use such features to identify 90% of classified\ncables with <11% false positives. But our results also show that there are\nlongstanding problems in the identification of sensitive information. Error\nanalysis reveals many examples of both overclassification and\nunderclassification. This indicates both the need for research on inter-coder\nreliability among officials as to what constitutes classified material and the\nopportunity to develop recommender systems to better manage both classification\nand declassification.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2016 19:59:48 GMT"}], "update_date": "2016-11-06", "authors_parsed": [["Souza", "Renato Rocha", ""], ["Coelho", "Flavio Codeco", ""], ["Shah", "Rohan", ""], ["Connelly", "Matthew", ""]]}, {"id": "1611.00384", "submitter": "Oren Barkan", "authors": "Oren Barkan, Noam Koenigstein, Eylon Yogev and Ori Katz", "title": "CB2CF: A Neural Multiview Content-to-Collaborative Filtering Model for\n  Completely Cold Item Recommendations", "comments": "In Proceedings of Recsys'19. ACM, Copenhagen, Denmark", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Recommender Systems research, algorithms are often characterized as either\nCollaborative Filtering (CF) or Content Based (CB). CF algorithms are trained\nusing a dataset of user preferences while CB algorithms are typically based on\nitem profiles. These approaches harness different data sources and therefore\nthe resulting recommended items are generally very different. This paper\npresents the CB2CF, a deep neural multiview model that serves as a bridge from\nitems content into their CF representations. CB2CF is a real-world algorithm\ndesigned for Microsoft Store services that handle around a billion users\nworldwide. CB2CF is demonstrated on movies and apps recommendations, where it\nis shown to outperform an alternative CB model on completely cold items.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2016 20:48:34 GMT"}, {"version": "v2", "created": "Sat, 21 Sep 2019 13:59:21 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Barkan", "Oren", ""], ["Koenigstein", "Noam", ""], ["Yogev", "Eylon", ""], ["Katz", "Ori", ""]]}, {"id": "1611.00440", "submitter": "Yustinus Soelistio Eko", "authors": "Elvyna Tunggawan, Yustinus Eko Soelistio", "title": "And the Winner is ...: Bayesian Twitter-based Prediction on 2016 U.S.\n  Presidential Election", "comments": "This is the non-final version of the paper. The final version is\n  published in the IC3INA 2016 Conference (3-5 Oct. 2016,\n  http://situs.opi.lipi.go.id/ic3ina2016/). All citation should be directed to\n  the final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a Naive-Bayesian predictive model for 2016 U.S.\nPresidential Election based on Twitter data. We use 33,708 tweets gathered\nsince December 16, 2015 until February 29, 2016. We introduce a simpler data\npreprocessing method to label the data and train the model. The model achieves\n95.8% accuracy on 10-fold cross validation and predicts Ted Cruz and Bernie\nSanders as Republican and Democratic nominee respectively. It achieves a\ncomparable result to those in its competitor methods.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 01:45:28 GMT"}], "update_date": "2016-11-03", "authors_parsed": [["Tunggawan", "Elvyna", ""], ["Soelistio", "Yustinus Eko", ""]]}, {"id": "1611.00448", "submitter": "Hao Wang", "authors": "Hao Wang, Xingjian Shi, Dit-Yan Yeung", "title": "Natural-Parameter Networks: A Class of Probabilistic Neural Networks", "comments": "To appear at NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks (NN) have achieved state-of-the-art performance in various\napplications. Unfortunately in applications where training data is\ninsufficient, they are often prone to overfitting. One effective way to\nalleviate this problem is to exploit the Bayesian approach by using Bayesian\nneural networks (BNN). Another shortcoming of NN is the lack of flexibility to\ncustomize different distributions for the weights and neurons according to the\ndata, as is often done in probabilistic graphical models. To address these\nproblems, we propose a class of probabilistic neural networks, dubbed\nnatural-parameter networks (NPN), as a novel and lightweight Bayesian treatment\nof NN. NPN allows the usage of arbitrary exponential-family distributions to\nmodel the weights and neurons. Different from traditional NN and BNN, NPN takes\ndistributions as input and goes through layers of transformation before\nproducing distributions to match the target output distributions. As a Bayesian\ntreatment, efficient backpropagation (BP) is performed to learn the natural\nparameters for the distributions over both the weights and neurons. The output\ndistributions of each layer, as byproducts, may be used as second-order\nrepresentations for the associated tasks such as link prediction. Experiments\non real-world datasets show that NPN can achieve state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 02:32:05 GMT"}], "update_date": "2016-11-03", "authors_parsed": [["Wang", "Hao", ""], ["Shi", "Xingjian", ""], ["Yeung", "Dit-Yan", ""]]}, {"id": "1611.00454", "submitter": "Hao Wang", "authors": "Hao Wang, Xingjian Shi, Dit-Yan Yeung", "title": "Collaborative Recurrent Autoencoder: Recommend while Learning to Fill in\n  the Blanks", "comments": "To appear at NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hybrid methods that utilize both content and rating information are commonly\nused in many recommender systems. However, most of them use either handcrafted\nfeatures or the bag-of-words representation as a surrogate for the content\ninformation but they are neither effective nor natural enough. To address this\nproblem, we develop a collaborative recurrent autoencoder (CRAE) which is a\ndenoising recurrent autoencoder (DRAE) that models the generation of content\nsequences in the collaborative filtering (CF) setting. The model generalizes\nrecent advances in recurrent deep learning from i.i.d. input to non-i.i.d.\n(CF-based) input and provides a new denoising scheme along with a novel\nlearnable pooling scheme for the recurrent autoencoder. To do this, we first\ndevelop a hierarchical Bayesian model for the DRAE and then generalize it to\nthe CF setting. The synergy between denoising and CF enables CRAE to make\naccurate recommendations while learning to fill in the blanks in sequences.\nExperiments on real-world datasets from different domains (CiteULike and\nNetflix) show that, by jointly modeling the order-aware generation of sequences\nfor the content information and performing CF for the ratings, CRAE is able to\nsignificantly outperform the state of the art on both the recommendation task\nbased on ratings and the sequence generation task based on content information.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 02:49:44 GMT"}], "update_date": "2016-11-03", "authors_parsed": [["Wang", "Hao", ""], ["Shi", "Xingjian", ""], ["Yeung", "Dit-Yan", ""]]}, {"id": "1611.00456", "submitter": "Bo Wang", "authors": "Bo Wang, Yanshu Yu, Yuan Wang", "title": "Measuring Asymmetric Opinions on Online Social Interrelationship with\n  Language and Network Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Instead of studying the properties of social relationship from an objective\nview, in this paper, we focus on individuals' subjective and asymmetric\nopinions on their interrelationships. Inspired by the theories from\nsociolinguistics, we investigate two individuals' opinions on their\ninterrelationship with their interactive language features. Eliminating the\ndifference of personal language style, we clarify that the asymmetry of\ninteractive language feature values can indicate individuals' asymmetric\nopinions on their interrelationship. We also discuss how the degree of\nopinions' asymmetry is related to the individuals' personality traits.\nFurthermore, to measure the individuals' asymmetric opinions on\ninterrelationship concretely, we develop a novel model synthetizing interactive\nlanguage and social network features. The experimental results with Enron email\ndataset provide multiple evidences of the asymmetric opinions on\ninterrelationship, and also verify the effectiveness of the proposed model in\nmeasuring the degree of opinions' asymmetry.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 03:04:42 GMT"}, {"version": "v2", "created": "Tue, 15 Nov 2016 04:18:51 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Wang", "Bo", ""], ["Yu", "Yanshu", ""], ["Wang", "Yuan", ""]]}, {"id": "1611.00457", "submitter": "Bo Wang", "authors": "Bo Wang, Yingjun Sun, Yuan Wang", "title": "Structure vs. Language: Investigating the Multi-factors of Asymmetric\n  Opinions on Online Social Interrelationship with a Case Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though current researches often study the properties of online social\nrelationship from an objective view, we also need to understand individuals'\nsubjective opinions on their interrelationships in social computing studies.\nInspired by the theories from sociolinguistics, the latest work indicates that\ninteractive language can reveal individuals' asymmetric opinions on their\ninterrelationship. In this work, in order to explain the opinions' asymmetry on\ninterrelationship with more latent factors, we extend the investigation from\nsingle relationship to the structural context in online social network. We\nanalyze the correlation between interactive language features and the\nstructural context of interrelationships. The structural context of vertex,\nedges and triangles in social network are considered. With statistical analysis\non Enron email dataset, we find that individuals' opinions (measured by\ninteractive language features) on their interrelationship are related to some\nof their important structural context in social network. This result can help\nus to understand and measure the individuals' opinions on their\ninterrelationship with more intrinsic information.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 03:11:10 GMT"}], "update_date": "2016-11-03", "authors_parsed": [["Wang", "Bo", ""], ["Sun", "Yingjun", ""], ["Wang", "Yuan", ""]]}, {"id": "1611.00472", "submitter": "Ameya Prabhu", "authors": "Ameya Prabhu, Aditya Joshi, Manish Shrivastava and Vasudeva Varma", "title": "Towards Sub-Word Level Compositions for Sentiment Analysis of\n  Hindi-English Code Mixed Text", "comments": "Accepted paper at COLING 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sentiment analysis (SA) using code-mixed data from social media has several\napplications in opinion mining ranging from customer satisfaction to social\ncampaign analysis in multilingual societies. Advances in this area are impeded\nby the lack of a suitable annotated dataset. We introduce a Hindi-English\n(Hi-En) code-mixed dataset for sentiment analysis and perform empirical\nanalysis comparing the suitability and performance of various state-of-the-art\nSA methods in social media.\n  In this paper, we introduce learning sub-word level representations in LSTM\n(Subword-LSTM) architecture instead of character-level or word-level\nrepresentations. This linguistic prior in our architecture enables us to learn\nthe information about sentiment value of important morphemes. This also seems\nto work well in highly noisy text containing misspellings as shown in our\nexperiments which is demonstrated in morpheme-level feature maps learned by our\nmodel. Also, we hypothesize that encoding this linguistic prior in the\nSubword-LSTM architecture leads to the superior performance. Our system attains\naccuracy 4-5% greater than traditional approaches on our dataset, and also\noutperforms the available system for sentiment analysis in Hi-En code-mixed\ntext by 18%.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 05:23:53 GMT"}], "update_date": "2016-11-03", "authors_parsed": [["Prabhu", "Ameya", ""], ["Joshi", "Aditya", ""], ["Shrivastava", "Manish", ""], ["Varma", "Vasudeva", ""]]}, {"id": "1611.00483", "submitter": "Chaozhuo Li", "authors": "Chaozhuo Li, Yu Wu, Wei Wu, Chen Xing, Zhoujun Li, Ming Zhou", "title": "Detecting Context Dependent Messages in a Conversational Environment", "comments": "Accepted paper at COLING 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While automatic response generation for building chatbot systems has drawn a\nlot of attention recently, there is limited understanding on when we need to\nconsider the linguistic context of an input text in the generation process. The\ntask is challenging, as messages in a conversational environment are short and\ninformal, and evidence that can indicate a message is context dependent is\nscarce. After a study of social conversation data crawled from the web, we\nobserved that some characteristics estimated from the responses of messages are\ndiscriminative for identifying context dependent messages. With the\ncharacteristics as weak supervision, we propose using a Long Short Term Memory\n(LSTM) network to learn a classifier. Our method carries out text\nrepresentation and classifier learning in a unified framework. Experimental\nresults show that the proposed method can significantly outperform baseline\nmethods on accuracy of classification.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 07:01:25 GMT"}, {"version": "v2", "created": "Thu, 3 Nov 2016 08:13:15 GMT"}], "update_date": "2016-11-04", "authors_parsed": [["Li", "Chaozhuo", ""], ["Wu", "Yu", ""], ["Wu", "Wei", ""], ["Xing", "Chen", ""], ["Li", "Zhoujun", ""], ["Zhou", "Ming", ""]]}, {"id": "1611.00514", "submitter": "Abbas Khosravani", "authors": "Abbas Khosravani, Cornelius Glackin, Nazim Dugan, G\\'erard Chollet,\n  Nigel Cannings", "title": "The Intelligent Voice 2016 Speaker Recognition System", "comments": "7 pages, 3 figures, NIST SRE 2016 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the Intelligent Voice (IV) system submitted to the NIST\n2016 Speaker Recognition Evaluation (SRE). The primary emphasis of SRE this\nyear was on developing speaker recognition technology which is robust for novel\nlanguages that are much more heterogeneous than those used in the current\nstate-of-the-art, using significantly less training data, that does not contain\nmeta-data from those languages. The system is based on the state-of-the-art\ni-vector/PLDA which is developed on the fixed training condition, and the\nresults are reported on the protocol defined on the development set of the\nchallenge.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 09:24:10 GMT"}], "update_date": "2016-11-03", "authors_parsed": [["Khosravani", "Abbas", ""], ["Glackin", "Cornelius", ""], ["Dugan", "Nazim", ""], ["Chollet", "G\u00e9rard", ""], ["Cannings", "Nigel", ""]]}, {"id": "1611.00601", "submitter": "Sheng Zhang", "authors": "Sheng Zhang, Rachel Rudinger, Kevin Duh, Benjamin Van Durme", "title": "Ordinal Common-sense Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans have the capacity to draw common-sense inferences from natural\nlanguage: various things that are likely but not certain to hold based on\nestablished discourse, and are rarely stated explicitly. We propose an\nevaluation of automated common-sense inference based on an extension of\nrecognizing textual entailment: predicting ordinal human responses on the\nsubjective likelihood of an inference holding in a given context. We describe a\nframework for extracting common-sense knowledge from corpora, which is then\nused to construct a dataset for this ordinal entailment task. We train a neural\nsequence-to-sequence model on this dataset, which we use to score and generate\npossible inferences. Further, we annotate subsets of previously established\ndatasets via our ordinal annotation protocol in order to then analyze the\ndistinctions between these and what we have constructed.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 13:38:32 GMT"}, {"version": "v2", "created": "Thu, 3 Nov 2016 01:44:41 GMT"}, {"version": "v3", "created": "Fri, 2 Jun 2017 13:54:23 GMT"}], "update_date": "2017-06-05", "authors_parsed": [["Zhang", "Sheng", ""], ["Rudinger", "Rachel", ""], ["Duh", "Kevin", ""], ["Van Durme", "Benjamin", ""]]}, {"id": "1611.00674", "submitter": "Yuanzhi Ke", "authors": "Yuanzhi Ke, Masafumi Hagiwara", "title": "Fuzzy paraphrases in learning word representations with a lexicon", "comments": "Withdrawn. Our recent study shows that there is no significant\n  difference when we remove some part of the lexicon with the method in the\n  paper. We decided to withdraw this paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A synonym of a polysemous word is usually only the paraphrase of one sense\namong many. When lexicons are used to improve vector-space word\nrepresentations, such paraphrases are unreliable and bring noise to the\nvector-space. The prior works use a coefficient to adjust the overall learning\nof the lexicons. They regard the paraphrases equally. In this paper, we propose\na novel approach that regards the paraphrases diversely to alleviate the\nadverse effects of polysemy. We annotate each paraphrase with a degree of\nreliability. The paraphrases are randomly eliminated according to the degrees\nwhen our model learns word representations. In this way, our approach drops the\nunreliable paraphrases, keeping more reliable paraphrases at the same time. The\nexperimental results show that the proposed method improves the word vectors.\nOur approach is an attempt to address the polysemy problem keeping one vector\nper word. It makes the approach easier to use than the conventional methods\nthat estimate multiple vectors for a word. Our approach also outperforms the\nprior works in the experiments.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 16:38:18 GMT"}, {"version": "v2", "created": "Thu, 3 Nov 2016 15:32:40 GMT"}, {"version": "v3", "created": "Fri, 4 Nov 2016 18:51:17 GMT"}, {"version": "v4", "created": "Mon, 28 Nov 2016 10:22:42 GMT"}, {"version": "v5", "created": "Sat, 14 Jan 2017 07:57:01 GMT"}, {"version": "v6", "created": "Thu, 19 Jan 2017 09:10:35 GMT"}, {"version": "v7", "created": "Tue, 7 Feb 2017 10:18:54 GMT"}, {"version": "v8", "created": "Wed, 9 Aug 2017 06:05:46 GMT"}, {"version": "v9", "created": "Fri, 8 Sep 2017 11:46:56 GMT"}], "update_date": "2017-09-11", "authors_parsed": [["Ke", "Yuanzhi", ""], ["Hagiwara", "Masafumi", ""]]}, {"id": "1611.00801", "submitter": "Mingbin Xu", "authors": "Mingbin Xu and Hui Jiang", "title": "A FOFE-based Local Detection Approach for Named Entity Recognition and\n  Mention Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a novel approach for named entity recognition (NER)\nand mention detection in natural language processing. Instead of treating NER\nas a sequence labelling problem, we propose a new local detection approach,\nwhich rely on the recent fixed-size ordinally forgetting encoding (FOFE) method\nto fully encode each sentence fragment and its left/right contexts into a\nfixed-size representation. Afterwards, a simple feedforward neural network is\nused to reject or predict entity label for each individual fragment. The\nproposed method has been evaluated in several popular NER and mention detection\ntasks, including the CoNLL 2003 NER task and TAC-KBP2015 and TAC-KBP2016\nTri-lingual Entity Discovery and Linking (EDL) tasks. Our methods have yielded\npretty strong performance in all of these examined tasks. This local detection\napproach has shown many advantages over the traditional sequence labelling\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 20:52:46 GMT"}], "update_date": "2016-11-04", "authors_parsed": [["Xu", "Mingbin", ""], ["Jiang", "Hui", ""]]}, {"id": "1611.00995", "submitter": "Dat Quoc Nguyen", "authors": "Dat Quoc Nguyen, Mark Dras, Mark Johnson", "title": "An empirical study for Vietnamese dependency parsing", "comments": "To appear in Proceedings of the 14th Annual Workshop of the\n  Australasian Language Technology Association", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an empirical comparison of different dependency parsers\nfor Vietnamese, which has some unusual characteristics such as copula drop and\nverb serialization. Experimental results show that the neural network-based\nparsers perform significantly better than the traditional parsers. We report\nthe highest parsing scores published to date for Vietnamese with the labeled\nattachment score (LAS) at 73.53% and the unlabeled attachment score (UAS) at\n80.66%.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2016 13:14:52 GMT"}], "update_date": "2016-11-04", "authors_parsed": [["Nguyen", "Dat Quoc", ""], ["Dras", "Mark", ""], ["Johnson", "Mark", ""]]}, {"id": "1611.01083", "submitter": "Alok Pal", "authors": "Alok Ranjan Pal, Anirban Kundu, Abhay Singh, Raj Shekhar and Kunal\n  Sinha", "title": "A Hybrid Approach to Word Sense Disambiguation Combining Supervised and\n  Unsupervised Learning", "comments": "13 pages in International Journal of Artificial Intelligence &\n  Applications (IJAIA), Vol. 4, No. 4, July 2013", "journal-ref": null, "doi": "10.5121/ijaia.2013.4409", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we are going to find meaning of words based on distinct\nsituations. Word Sense Disambiguation is used to find meaning of words based on\nlive contexts using supervised and unsupervised approaches. Unsupervised\napproaches use online dictionary for learning, and supervised approaches use\nmanual learning sets. Hand tagged data are populated which might not be\neffective and sufficient for learning procedure. This limitation of information\nis main flaw of the supervised approach. Our proposed approach focuses to\novercome the limitation using learning set which is enriched in dynamic way\nmaintaining new data. Trivial filtering method is utilized to achieve\nappropriate training data. We introduce a mixed methodology having Modified\nLesk approach and Bag-of-Words having enriched bags using learning methods. Our\napproach establishes the superiority over individual Modified Lesk and\nBag-of-Words approaches based on experimentation.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 10:36:52 GMT"}], "update_date": "2016-11-04", "authors_parsed": [["Pal", "Alok Ranjan", ""], ["Kundu", "Anirban", ""], ["Singh", "Abhay", ""], ["Shekhar", "Raj", ""], ["Sinha", "Kunal", ""]]}, {"id": "1611.01101", "submitter": "Enrico Santus", "authors": "Emmanuele Chersoni, Giulia Rambelli, Enrico Santus", "title": "CogALex-V Shared Task: ROOT18", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we describe ROOT 18, a classifier using the scores of several\nunsupervised distributional measures as features to discriminate between\nsemantically related and unrelated words, and then to classify the related\npairs according to their semantic relation (i.e. synonymy, antonymy, hypernymy,\npart-whole meronymy). Our classifier participated in the CogALex-V Shared Task,\nshowing a solid performance on the first subtask, but a poor performance on the\nsecond subtask. The low scores reported on the second subtask suggest that\ndistributional measures are not sufficient to discriminate between multiple\nsemantic relations at once.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2016 17:41:47 GMT"}], "update_date": "2016-11-04", "authors_parsed": [["Chersoni", "Emmanuele", ""], ["Rambelli", "Giulia", ""], ["Santus", "Enrico", ""]]}, {"id": "1611.01116", "submitter": "Karol Grzegorczyk", "authors": "Karol Grzegorczyk and Marcin Kurdziel", "title": "Binary Paragraph Vectors", "comments": "Accepted to appear as a regular paper at the 2nd Workshop on\n  Representation Learning for NLP at ACL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently Le & Mikolov described two log-linear models, called Paragraph\nVector, that can be used to learn state-of-the-art distributed representations\nof documents. Inspired by this work, we present Binary Paragraph Vector models:\nsimple neural networks that learn short binary codes for fast information\nretrieval. We show that binary paragraph vectors outperform autoencoder-based\nbinary codes, despite using fewer bits. We also evaluate their precision in\ntransfer learning settings, where binary codes are inferred for documents\nunrelated to the training corpus. Results from these experiments indicate that\nbinary paragraph vectors can capture semantics relevant for various\ndomain-specific documents. Finally, we present a model that simultaneously\nlearns short binary codes and longer, real-valued representations. This model\ncan be used to rapidly retrieve a short list of highly relevant documents from\na large document collection.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2016 18:10:35 GMT"}, {"version": "v2", "created": "Mon, 14 Nov 2016 17:29:34 GMT"}, {"version": "v3", "created": "Fri, 9 Jun 2017 14:33:06 GMT"}], "update_date": "2017-06-12", "authors_parsed": [["Grzegorczyk", "Karol", ""], ["Kurdziel", "Marcin", ""]]}, {"id": "1611.01242", "submitter": "Mohit Iyyer", "authors": "Mohit Iyyer, Wen-tau Yih, Ming-Wei Chang", "title": "Answering Complicated Question Intents Expressed in Decomposed Question\n  Sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work in semantic parsing for question answering has focused on long\nand complicated questions, many of which would seem unnatural if asked in a\nnormal conversation between two humans. In an effort to explore a\nconversational QA setting, we present a more realistic task: answering\nsequences of simple but inter-related questions. We collect a dataset of 6,066\nquestion sequences that inquire about semi-structured tables from Wikipedia,\nwith 17,553 question-answer pairs in total. Existing QA systems face two major\nproblems when evaluated on our dataset: (1) handling questions that contain\ncoreferences to previous questions or answers, and (2) matching words or\nphrases in a question to corresponding entries in the associated table. We\nconclude by proposing strategies to handle both of these issues.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 01:54:03 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Iyyer", "Mohit", ""], ["Yih", "Wen-tau", ""], ["Chang", "Ming-Wei", ""]]}, {"id": "1611.01259", "submitter": "Nika Haghtalab", "authors": "Avrim Blum, Nika Haghtalab", "title": "Generalized Topic Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.DS cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently there has been significant activity in developing algorithms with\nprovable guarantees for topic modeling. In standard topic models, a topic (such\nas sports, business, or politics) is viewed as a probability distribution $\\vec\na_i$ over words, and a document is generated by first selecting a mixture $\\vec\nw$ over topics, and then generating words i.i.d. from the associated mixture\n$A{\\vec w}$. Given a large collection of such documents, the goal is to recover\nthe topic vectors and then to correctly classify new documents according to\ntheir topic mixture.\n  In this work we consider a broad generalization of this framework in which\nwords are no longer assumed to be drawn i.i.d. and instead a topic is a complex\ndistribution over sequences of paragraphs. Since one could not hope to even\nrepresent such a distribution in general (even if paragraphs are given using\nsome natural feature representation), we aim instead to directly learn a\ndocument classifier. That is, we aim to learn a predictor that given a new\ndocument, accurately predicts its topic mixture, without learning the\ndistributions explicitly. We present several natural conditions under which one\ncan do this efficiently and discuss issues such as noise tolerance and sample\ncomplexity in this model. More generally, our model can be viewed as a\ngeneralization of the multi-view or co-training setting in machine learning.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 03:45:03 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Blum", "Avrim", ""], ["Haghtalab", "Nika", ""]]}, {"id": "1611.01368", "submitter": "Tal Linzen", "authors": "Tal Linzen, Emmanuel Dupoux and Yoav Goldberg", "title": "Assessing the Ability of LSTMs to Learn Syntax-Sensitive Dependencies", "comments": "15 pages; to appear in Transactions of the Association for\n  Computational Linguistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of long short-term memory (LSTM) neural networks in language\nprocessing is typically attributed to their ability to capture long-distance\nstatistical regularities. Linguistic regularities are often sensitive to\nsyntactic structure; can such dependencies be captured by LSTMs, which do not\nhave explicit structural representations? We begin addressing this question\nusing number agreement in English subject-verb dependencies. We probe the\narchitecture's grammatical competence both using training objectives with an\nexplicit grammatical target (number prediction, grammaticality judgments) and\nusing language models. In the strongly supervised settings, the LSTM achieved\nvery high overall accuracy (less than 1% errors), but errors increased when\nsequential and structural information conflicted. The frequency of such errors\nrose sharply in the language-modeling setting. We conclude that LSTMs can\ncapture a non-trivial amount of grammatical structure given targeted\nsupervision, but stronger architectures may be required to further reduce\nerrors; furthermore, the language modeling signal is insufficient for capturing\nsyntax-sensitive dependencies, and should be supplemented with more direct\nsupervision if such dependencies need to be captured.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 13:36:32 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Linzen", "Tal", ""], ["Dupoux", "Emmanuel", ""], ["Goldberg", "Yoav", ""]]}, {"id": "1611.01400", "submitter": "Jesse Lingeman", "authors": "Jesse M Lingeman, Hong Yu", "title": "Learning to Rank Scientific Documents from the Crowd", "comments": "12 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.DL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding related published articles is an important task in any science, but\nwith the explosion of new work in the biomedical domain it has become\nespecially challenging. Most existing methodologies use text similarity metrics\nto identify whether two articles are related or not. However biomedical\nknowledge discovery is hypothesis-driven. The most related articles may not be\nones with the highest text similarities. In this study, we first develop an\ninnovative crowd-sourcing approach to build an expert-annotated\ndocument-ranking corpus. Using this corpus as the gold standard, we then\nevaluate the approaches of using text similarity to rank the relatedness of\narticles. Finally, we develop and evaluate a new supervised model to\nautomatically rank related scientific articles. Our results show that authors'\nranking differ significantly from rankings by text-similarity-based models. By\ntraining a learning-to-rank model on a subset of the annotated corpus, we found\nthe best supervised learning-to-rank model (SVM-Rank) significantly surpassed\nstate-of-the-art baseline systems.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 14:43:44 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Lingeman", "Jesse M", ""], ["Yu", "Hong", ""]]}, {"id": "1611.01436", "submitter": "Tom Kwiatkowski", "authors": "Kenton Lee, Shimi Salant, Tom Kwiatkowski, Ankur Parikh, Dipanjan Das,\n  Jonathan Berant", "title": "Learning Recurrent Span Representations for Extractive Question\n  Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reading comprehension task, that asks questions about a given evidence\ndocument, is a central problem in natural language understanding. Recent\nformulations of this task have typically focused on answer selection from a set\nof candidates pre-defined manually or through the use of an external NLP\npipeline. However, Rajpurkar et al. (2016) recently released the SQuAD dataset\nin which the answers can be arbitrary strings from the supplied text. In this\npaper, we focus on this answer extraction task, presenting a novel model\narchitecture that efficiently builds fixed length representations of all spans\nin the evidence document with a recurrent network. We show that scoring\nexplicit span representations significantly improves performance over other\napproaches that factor the prediction into separate predictions about words or\nstart and end markers. Our approach improves upon the best published results of\nWang & Jiang (2016) by 5% and decreases the error of Rajpurkar et al.'s\nbaseline by > 50%.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 16:12:46 GMT"}, {"version": "v2", "created": "Fri, 17 Mar 2017 18:11:12 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Lee", "Kenton", ""], ["Salant", "Shimi", ""], ["Kwiatkowski", "Tom", ""], ["Parikh", "Ankur", ""], ["Das", "Dipanjan", ""], ["Berant", "Jonathan", ""]]}, {"id": "1611.01462", "submitter": "Hakan Inan", "authors": "Hakan Inan, Khashayar Khosravi, Richard Socher", "title": "Tying Word Vectors and Word Classifiers: A Loss Framework for Language\n  Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks have been very successful at predicting sequences\nof words in tasks such as language modeling. However, all such models are based\non the conventional classification framework, where the model is trained\nagainst one-hot targets, and each word is represented both as an input and as\nan output in isolation. This causes inefficiencies in learning both in terms of\nutilizing all of the information and in terms of the number of parameters\nneeded to train. We introduce a novel theoretical framework that facilitates\nbetter learning in language modeling, and show that our framework leads to\ntying together the input embedding and the output projection matrices, greatly\nreducing the number of trainable variables. Our framework leads to state of the\nart performance on the Penn Treebank with a variety of network models.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 17:36:20 GMT"}, {"version": "v2", "created": "Sun, 5 Mar 2017 22:30:23 GMT"}, {"version": "v3", "created": "Sat, 11 Mar 2017 19:13:52 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Inan", "Hakan", ""], ["Khosravi", "Khashayar", ""], ["Socher", "Richard", ""]]}, {"id": "1611.01487", "submitter": "Roee Aharoni", "authors": "Roee Aharoni, Yoav Goldberg", "title": "Morphological Inflection Generation with Hard Monotonic Attention", "comments": "Accepted as a long paper in ACL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a neural model for morphological inflection generation which\nemploys a hard attention mechanism, inspired by the nearly-monotonic alignment\ncommonly found between the characters in a word and the characters in its\ninflection. We evaluate the model on three previously studied morphological\ninflection generation datasets and show that it provides state of the art\nresults in various setups compared to previous neural and non-neural\napproaches. Finally we present an analysis of the continuous representations\nlearned by both the hard and soft attention \\cite{bahdanauCB14} models for the\ntask, shedding some light on the features such models extract.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 18:42:47 GMT"}, {"version": "v2", "created": "Thu, 8 Dec 2016 12:33:44 GMT"}, {"version": "v3", "created": "Tue, 11 Apr 2017 08:51:27 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Aharoni", "Roee", ""], ["Goldberg", "Yoav", ""]]}, {"id": "1611.01547", "submitter": "Philip Blair", "authors": "Philip Blair, Yuval Merhav, and Joel Barry", "title": "Automated Generation of Multilingual Clusters for the Evaluation of\n  Distributed Representations", "comments": "Published as a workshop paper at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a language-agnostic way of automatically generating sets of\nsemantically similar clusters of entities along with sets of \"outlier\"\nelements, which may then be used to perform an intrinsic evaluation of word\nembeddings in the outlier detection task. We used our methodology to create a\ngold-standard dataset, which we call WikiSem500, and evaluated multiple\nstate-of-the-art embeddings. The results show a correlation between performance\non this dataset and performance on sentiment analysis.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 21:35:07 GMT"}, {"version": "v2", "created": "Tue, 15 Nov 2016 13:21:17 GMT"}, {"version": "v3", "created": "Fri, 9 Dec 2016 15:58:37 GMT"}, {"version": "v4", "created": "Wed, 21 Dec 2016 17:51:57 GMT"}, {"version": "v5", "created": "Wed, 5 Apr 2017 15:26:51 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["Blair", "Philip", ""], ["Merhav", "Yuval", ""], ["Barry", "Joel", ""]]}, {"id": "1611.01576", "submitter": "James Bradbury", "authors": "James Bradbury, Stephen Merity, Caiming Xiong, Richard Socher", "title": "Quasi-Recurrent Neural Networks", "comments": "Submitted to conference track at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks are a powerful tool for modeling sequential data,\nbut the dependence of each timestep's computation on the previous timestep's\noutput limits parallelism and makes RNNs unwieldy for very long sequences. We\nintroduce quasi-recurrent neural networks (QRNNs), an approach to neural\nsequence modeling that alternates convolutional layers, which apply in parallel\nacross timesteps, and a minimalist recurrent pooling function that applies in\nparallel across channels. Despite lacking trainable recurrent layers, stacked\nQRNNs have better predictive accuracy than stacked LSTMs of the same hidden\nsize. Due to their increased parallelism, they are up to 16 times faster at\ntrain and test time. Experiments on language modeling, sentiment\nclassification, and character-level neural machine translation demonstrate\nthese advantages and underline the viability of QRNNs as a basic building block\nfor a variety of sequence tasks.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2016 00:31:25 GMT"}, {"version": "v2", "created": "Mon, 21 Nov 2016 20:52:34 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Bradbury", "James", ""], ["Merity", "Stephen", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "1611.01587", "submitter": "Kazuma Hashimoto", "authors": "Kazuma Hashimoto, Caiming Xiong, Yoshimasa Tsuruoka, Richard Socher", "title": "A Joint Many-Task Model: Growing a Neural Network for Multiple NLP Tasks", "comments": "Accepted as a full paper at the 2017 Conference on Empirical Methods\n  in Natural Language Processing (EMNLP 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer and multi-task learning have traditionally focused on either a\nsingle source-target pair or very few, similar tasks. Ideally, the linguistic\nlevels of morphology, syntax and semantics would benefit each other by being\ntrained in a single model. We introduce a joint many-task model together with a\nstrategy for successively growing its depth to solve increasingly complex\ntasks. Higher layers include shortcut connections to lower-level task\npredictions to reflect linguistic hierarchies. We use a simple regularization\nterm to allow for optimizing all model weights to improve one task's loss\nwithout exhibiting catastrophic interference of the other tasks. Our single\nend-to-end model obtains state-of-the-art or competitive results on five\ndifferent tasks from tagging, parsing, relatedness, and entailment tasks.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2016 01:59:29 GMT"}, {"version": "v2", "created": "Fri, 11 Nov 2016 01:16:07 GMT"}, {"version": "v3", "created": "Sat, 19 Nov 2016 00:20:12 GMT"}, {"version": "v4", "created": "Sun, 16 Apr 2017 22:38:21 GMT"}, {"version": "v5", "created": "Mon, 24 Jul 2017 14:41:16 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Hashimoto", "Kazuma", ""], ["Xiong", "Caiming", ""], ["Tsuruoka", "Yoshimasa", ""], ["Socher", "Richard", ""]]}, {"id": "1611.01599", "submitter": "Yannis Assael", "authors": "Yannis M. Assael, Brendan Shillingford, Shimon Whiteson, Nando de\n  Freitas", "title": "LipNet: End-to-End Sentence-level Lipreading", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lipreading is the task of decoding text from the movement of a speaker's\nmouth. Traditional approaches separated the problem into two stages: designing\nor learning visual features, and prediction. More recent deep lipreading\napproaches are end-to-end trainable (Wand et al., 2016; Chung & Zisserman,\n2016a). However, existing work on models trained end-to-end perform only word\nclassification, rather than sentence-level sequence prediction. Studies have\nshown that human lipreading performance increases for longer words (Easton &\nBasala, 1982), indicating the importance of features capturing temporal context\nin an ambiguous communication channel. Motivated by this observation, we\npresent LipNet, a model that maps a variable-length sequence of video frames to\ntext, making use of spatiotemporal convolutions, a recurrent network, and the\nconnectionist temporal classification loss, trained entirely end-to-end. To the\nbest of our knowledge, LipNet is the first end-to-end sentence-level lipreading\nmodel that simultaneously learns spatiotemporal visual features and a sequence\nmodel. On the GRID corpus, LipNet achieves 95.2% accuracy in sentence-level,\noverlapped speaker split task, outperforming experienced human lipreaders and\nthe previous 86.4% word-level state-of-the-art accuracy (Gergen et al., 2016).\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2016 04:05:18 GMT"}, {"version": "v2", "created": "Fri, 16 Dec 2016 16:09:34 GMT"}], "update_date": "2016-12-19", "authors_parsed": [["Assael", "Yannis M.", ""], ["Shillingford", "Brendan", ""], ["Whiteson", "Shimon", ""], ["de Freitas", "Nando", ""]]}, {"id": "1611.01603", "submitter": "Minjoon Seo", "authors": "Minjoon Seo, Aniruddha Kembhavi, Ali Farhadi, Hannaneh Hajishirzi", "title": "Bidirectional Attention Flow for Machine Comprehension", "comments": "Published as a conference paper at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine comprehension (MC), answering a query about a given context\nparagraph, requires modeling complex interactions between the context and the\nquery. Recently, attention mechanisms have been successfully extended to MC.\nTypically these methods use attention to focus on a small portion of the\ncontext and summarize it with a fixed-size vector, couple attentions\ntemporally, and/or often form a uni-directional attention. In this paper we\nintroduce the Bi-Directional Attention Flow (BIDAF) network, a multi-stage\nhierarchical process that represents the context at different levels of\ngranularity and uses bi-directional attention flow mechanism to obtain a\nquery-aware context representation without early summarization. Our\nexperimental evaluations show that our model achieves the state-of-the-art\nresults in Stanford Question Answering Dataset (SQuAD) and CNN/DailyMail cloze\ntest.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2016 04:49:00 GMT"}, {"version": "v2", "created": "Mon, 21 Nov 2016 21:34:22 GMT"}, {"version": "v3", "created": "Tue, 29 Nov 2016 18:46:50 GMT"}, {"version": "v4", "created": "Tue, 7 Feb 2017 22:01:42 GMT"}, {"version": "v5", "created": "Fri, 24 Feb 2017 19:57:53 GMT"}, {"version": "v6", "created": "Thu, 21 Jun 2018 10:53:20 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Seo", "Minjoon", ""], ["Kembhavi", "Aniruddha", ""], ["Farhadi", "Ali", ""], ["Hajishirzi", "Hannaneh", ""]]}, {"id": "1611.01604", "submitter": "Victor Zhong", "authors": "Caiming Xiong, Victor Zhong, Richard Socher", "title": "Dynamic Coattention Networks For Question Answering", "comments": "14 pages, 7 figures, International Conference on Learning\n  Representations 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several deep learning models have been proposed for question answering.\nHowever, due to their single-pass nature, they have no way to recover from\nlocal maxima corresponding to incorrect answers. To address this problem, we\nintroduce the Dynamic Coattention Network (DCN) for question answering. The DCN\nfirst fuses co-dependent representations of the question and the document in\norder to focus on relevant parts of both. Then a dynamic pointing decoder\niterates over potential answer spans. This iterative procedure enables the\nmodel to recover from initial local maxima corresponding to incorrect answers.\nOn the Stanford question answering dataset, a single DCN model improves the\nprevious state of the art from 71.0% F1 to 75.9%, while a DCN ensemble obtains\n80.4% F1.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2016 04:53:40 GMT"}, {"version": "v2", "created": "Thu, 17 Nov 2016 19:58:22 GMT"}, {"version": "v3", "created": "Mon, 13 Feb 2017 23:00:32 GMT"}, {"version": "v4", "created": "Tue, 6 Mar 2018 22:45:53 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Xiong", "Caiming", ""], ["Zhong", "Victor", ""], ["Socher", "Richard", ""]]}, {"id": "1611.01628", "submitter": "Zichao Yang", "authors": "Zichao Yang, Phil Blunsom, Chris Dyer, Wang Ling", "title": "Reference-Aware Language Models", "comments": "emnlp camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general class of language models that treat reference as an\nexplicit stochastic latent variable. This architecture allows models to create\nmentions of entities and their attributes by accessing external databases\n(required by, e.g., dialogue generation and recipe generation) and internal\nstate (required by, e.g. language models which are aware of coreference). This\nfacilitates the incorporation of information that can be accessed in\npredictable locations in databases or discourse context, even when the targets\nof the reference may be rare words. Experiments on three tasks shows our model\nvariants based on deterministic attention.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2016 10:55:37 GMT"}, {"version": "v2", "created": "Fri, 11 Nov 2016 22:51:28 GMT"}, {"version": "v3", "created": "Tue, 7 Feb 2017 20:33:12 GMT"}, {"version": "v4", "created": "Tue, 8 Aug 2017 17:05:33 GMT"}, {"version": "v5", "created": "Wed, 9 Aug 2017 00:39:51 GMT"}], "update_date": "2017-08-10", "authors_parsed": [["Yang", "Zichao", ""], ["Blunsom", "Phil", ""], ["Dyer", "Chris", ""], ["Ling", "Wang", ""]]}, {"id": "1611.01702", "submitter": "Adji Bousso Dieng", "authors": "Adji B. Dieng, Chong Wang, Jianfeng Gao, John Paisley", "title": "TopicRNN: A Recurrent Neural Network with Long-Range Semantic Dependency", "comments": "International Conference on Learning Representations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose TopicRNN, a recurrent neural network (RNN)-based\nlanguage model designed to directly capture the global semantic meaning\nrelating words in a document via latent topics. Because of their sequential\nnature, RNNs are good at capturing the local structure of a word sequence -\nboth semantic and syntactic - but might face difficulty remembering long-range\ndependencies. Intuitively, these long-range dependencies are of semantic\nnature. In contrast, latent topic models are able to capture the global\nunderlying semantic structure of a document but do not account for word\nordering. The proposed TopicRNN model integrates the merits of RNNs and latent\ntopic models: it captures local (syntactic) dependencies using an RNN and\nglobal (semantic) dependencies using latent topics. Unlike previous work on\ncontextual RNN language modeling, our model is learned end-to-end. Empirical\nresults on word prediction show that TopicRNN outperforms existing contextual\nRNN baselines. In addition, TopicRNN can be used as an unsupervised feature\nextractor for documents. We do this for sentiment analysis on the IMDB movie\nreview dataset and report an error rate of $6.28\\%$. This is comparable to the\nstate-of-the-art $5.91\\%$ resulting from a semi-supervised approach. Finally,\nTopicRNN also yields sensible topics, making it a useful alternative to\ndocument models such as latent Dirichlet allocation.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2016 21:25:07 GMT"}, {"version": "v2", "created": "Mon, 27 Feb 2017 03:03:38 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Dieng", "Adji B.", ""], ["Wang", "Chong", ""], ["Gao", "Jianfeng", ""], ["Paisley", "John", ""]]}, {"id": "1611.01714", "submitter": "Nathan Hodas", "authors": "Ark Anderson, Kyle Shaffer, Artem Yankov, Court D. Corley, Nathan O.\n  Hodas", "title": "Beyond Fine Tuning: A Modular Approach to Learning on Small Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a technique to train neural network models on small\namounts of data. Current methods for training neural networks on small amounts\nof rich data typically rely on strategies such as fine-tuning a pre-trained\nneural network or the use of domain-specific hand-engineered features. Here we\ntake the approach of treating network layers, or entire networks, as modules\nand combine pre-trained modules with untrained modules, to learn the shift in\ndistributions between data sets. The central impact of using a modular approach\ncomes from adding new representations to a network, as opposed to replacing\nrepresentations via fine-tuning. Using this technique, we are able surpass\nresults using standard fine-tuning transfer learning approaches, and we are\nalso able to significantly increase performance over such approaches when using\nsmaller amounts of data.\n", "versions": [{"version": "v1", "created": "Sun, 6 Nov 2016 01:32:39 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Anderson", "Ark", ""], ["Shaffer", "Kyle", ""], ["Yankov", "Artem", ""], ["Corley", "Court D.", ""], ["Hodas", "Nathan O.", ""]]}, {"id": "1611.01724", "submitter": "Zhilin Yang", "authors": "Zhilin Yang, Bhuwan Dhingra, Ye Yuan, Junjie Hu, William W. Cohen,\n  Ruslan Salakhutdinov", "title": "Words or Characters? Fine-grained Gating for Reading Comprehension", "comments": "Accepted as a conference paper at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work combines word-level and character-level representations using\nconcatenation or scalar weighting, which is suboptimal for high-level tasks\nlike reading comprehension. We present a fine-grained gating mechanism to\ndynamically combine word-level and character-level representations based on\nproperties of the words. We also extend the idea of fine-grained gating to\nmodeling the interaction between questions and paragraphs for reading\ncomprehension. Experiments show that our approach can improve the performance\non reading comprehension tasks, achieving new state-of-the-art results on the\nChildren's Book Test dataset. To demonstrate the generality of our gating\nmechanism, we also show improved results on a social media tag prediction task.\n", "versions": [{"version": "v1", "created": "Sun, 6 Nov 2016 03:17:42 GMT"}, {"version": "v2", "created": "Mon, 11 Sep 2017 21:00:30 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Yang", "Zhilin", ""], ["Dhingra", "Bhuwan", ""], ["Yuan", "Ye", ""], ["Hu", "Junjie", ""], ["Cohen", "William W.", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1611.01734", "submitter": "Timothy Dozat", "authors": "Timothy Dozat and Christopher D. Manning", "title": "Deep Biaffine Attention for Neural Dependency Parsing", "comments": "Accepted to ICLR 2017; updated with new results and comparison to\n  more recent models, including current state-of-the-art", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper builds off recent work from Kiperwasser & Goldberg (2016) using\nneural attention in a simple graph-based dependency parser. We use a larger but\nmore thoroughly regularized parser than other recent BiLSTM-based approaches,\nwith biaffine classifiers to predict arcs and labels. Our parser gets state of\nthe art or near state of the art performance on standard treebanks for six\ndifferent languages, achieving 95.7% UAS and 94.1% LAS on the most popular\nEnglish PTB dataset. This makes it the highest-performing graph-based parser on\nthis benchmark---outperforming Kiperwasser Goldberg (2016) by 1.8% and\n2.2%---and comparable to the highest performing transition-based parser\n(Kuncoro et al., 2016), which achieves 95.8% UAS and 94.6% LAS. We also show\nwhich hyperparameter choices had a significant effect on parsing accuracy,\nallowing us to achieve large gains over other graph-based approaches.\n", "versions": [{"version": "v1", "created": "Sun, 6 Nov 2016 07:26:38 GMT"}, {"version": "v2", "created": "Tue, 22 Nov 2016 02:01:39 GMT"}, {"version": "v3", "created": "Fri, 10 Mar 2017 04:37:03 GMT"}], "update_date": "2017-03-13", "authors_parsed": [["Dozat", "Timothy", ""], ["Manning", "Christopher D.", ""]]}, {"id": "1611.01747", "submitter": "Shuohang Wang", "authors": "Shuohang Wang and Jing Jiang", "title": "A Compare-Aggregate Model for Matching Text Sequences", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many NLP tasks including machine comprehension, answer selection and text\nentailment require the comparison between sequences. Matching the important\nunits between sequences is a key to solve these problems. In this paper, we\npresent a general \"compare-aggregate\" framework that performs word-level\nmatching followed by aggregation using Convolutional Neural Networks. We\nparticularly focus on the different comparison functions we can use to match\ntwo vectors. We use four different datasets to evaluate the model. We find that\nsome simple comparison functions based on element-wise operations can work\nbetter than standard neural network and neural tensor network.\n", "versions": [{"version": "v1", "created": "Sun, 6 Nov 2016 09:50:24 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Wang", "Shuohang", ""], ["Jiang", "Jing", ""]]}, {"id": "1611.01783", "submitter": "Joseph Keshet", "authors": "Yehoshua Dissen, Joseph Keshet, Jacob Goldberger and Cynthia Clopper", "title": "Domain Adaptation For Formant Estimation Using Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a domain adaptation technique for formant estimation\nusing a deep network. We first train a deep learning network on a small read\nspeech dataset. We then freeze the parameters of the trained network and use\nseveral different datasets to train an adaptation layer that makes the obtained\nnetwork universal in the sense that it works well for a variety of speakers and\nspeech domains with very different characteristics. We evaluated our adapted\nnetwork on three datasets, each of which has different speaker characteristics\nand speech styles. The performance of our method compares favorably with\nalternative methods for formant estimation.\n", "versions": [{"version": "v1", "created": "Sun, 6 Nov 2016 14:00:14 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Dissen", "Yehoshua", ""], ["Keshet", "Joseph", ""], ["Goldberger", "Jacob", ""], ["Clopper", "Cynthia", ""]]}, {"id": "1611.01802", "submitter": "Ricardo Usbeck", "authors": "Ricardo Usbeck, Jonathan Huthmann, Nico Duldhardt, Axel-Cyrille Ngonga\n  Ngomo", "title": "Self-Wiring Question Answering Systems", "comments": "6 pages, 1 figure, pre-print in lncs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question answering (QA) has been the subject of a resurgence over the past\nyears. The said resurgence has led to a multitude of question answering (QA)\nsystems being developed both by companies and research facilities. While a few\ncomponents of QA systems get reused across implementations, most systems do not\nleverage the full potential of component reuse. Hence, the development of QA\nsystems is currently still a tedious and time-consuming process. We address the\nchallenge of accelerating the creation of novel or tailored QA systems by\npresenting a concept for a self-wiring approach to composing QA systems. Our\napproach will allow the reuse of existing, web-based QA systems or modules\nwhile developing new QA platforms. To this end, it will rely on QA modules\nbeing described using the Web Ontology Language. Based on these descriptions,\nour approach will be able to automatically compose QA systems using a\ndata-driven approach automatically.\n", "versions": [{"version": "v1", "created": "Sun, 6 Nov 2016 16:08:21 GMT"}, {"version": "v2", "created": "Tue, 8 Nov 2016 17:27:39 GMT"}], "update_date": "2016-11-09", "authors_parsed": [["Usbeck", "Ricardo", ""], ["Huthmann", "Jonathan", ""], ["Duldhardt", "Nico", ""], ["Ngomo", "Axel-Cyrille Ngonga", ""]]}, {"id": "1611.01839", "submitter": "Eunsol Choi", "authors": "Eunsol Choi, Daniel Hewlett, Alexandre Lacoste, Illia Polosukhin,\n  Jakob Uszkoreit, Jonathan Berant", "title": "Hierarchical Question Answering for Long Documents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for question answering that can efficiently scale to\nlonger documents while maintaining or even improving performance of\nstate-of-the-art models. While most successful approaches for reading\ncomprehension rely on recurrent neural networks (RNNs), running them over long\ndocuments is prohibitively slow because it is difficult to parallelize over\nsequences. Inspired by how people first skim the document, identify relevant\nparts, and carefully read these parts to produce an answer, we combine a\ncoarse, fast model for selecting relevant sentences and a more expensive RNN\nfor producing the answer from those sentences. We treat sentence selection as a\nlatent variable trained jointly from the answer only using reinforcement\nlearning. Experiments demonstrate the state of the art performance on a\nchallenging subset of the Wikireading and on a new dataset, while speeding up\nthe model by 3.5x-6.7x.\n", "versions": [{"version": "v1", "created": "Sun, 6 Nov 2016 20:24:40 GMT"}, {"version": "v2", "created": "Wed, 8 Feb 2017 07:42:34 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Choi", "Eunsol", ""], ["Hewlett", "Daniel", ""], ["Lacoste", "Alexandre", ""], ["Polosukhin", "Illia", ""], ["Uszkoreit", "Jakob", ""], ["Berant", "Jonathan", ""]]}, {"id": "1611.01867", "submitter": "Xinyun Chen", "authors": "Xinyun Chen, Chang Liu, Richard Shin, Dawn Song, Mingcheng Chen", "title": "Latent Attention For If-Then Program Synthesis", "comments": "Accepted by NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic translation from natural language descriptions into programs is a\nlongstanding challenging problem. In this work, we consider a simple yet\nimportant sub-problem: translation from textual descriptions to If-Then\nprograms. We devise a novel neural network architecture for this task which we\ntrain end-to-end. Specifically, we introduce Latent Attention, which computes\nmultiplicative weights for the words in the description in a two-stage process\nwith the goal of better leveraging the natural language structures that\nindicate the relevant parts for predicting program elements. Our architecture\nreduces the error rate by 28.57% compared to prior art. We also propose a\none-shot learning scenario of If-Then program synthesis and simulate it with\nour existing dataset. We demonstrate a variation on the training procedure for\nthis scenario that outperforms the original procedure, significantly closing\nthe gap to the model trained with all data.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 00:56:19 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Chen", "Xinyun", ""], ["Liu", "Chang", ""], ["Shin", "Richard", ""], ["Song", "Dawn", ""], ["Chen", "Mingcheng", ""]]}, {"id": "1611.01868", "submitter": "Luyang Li", "authors": "Luyang Li, Bing Qin, Wenjing Ren, Ting Liu", "title": "Truth Discovery with Memory Network", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Truth discovery is to resolve conflicts and find the truth from\nmultiple-source statements. Conventional methods mostly research based on the\nmutual effect between the reliability of sources and the credibility of\nstatements, however, pay no attention to the mutual effect among the\ncredibility of statements about the same object. We propose memory network\nbased models to incorporate these two ideas to do the truth discovery. We use\nfeedforward memory network and feedback memory network to learn the\nrepresentation of the credibility of statements which are about the same\nobject. Specially, we adopt memory mechanism to learn source reliability and\nuse it through truth prediction. During learning models, we use multiple types\nof data (categorical data and continuous data) by assigning different weights\nautomatically in the loss function based on their own effect on truth discovery\nprediction. The experiment results show that the memory network based models\nmuch outperform the state-of-the-art method and other baseline methods.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 01:08:11 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Li", "Luyang", ""], ["Qin", "Bing", ""], ["Ren", "Wenjing", ""], ["Liu", "Ting", ""]]}, {"id": "1611.01874", "submitter": "Zhaopeng Tu", "authors": "Zhaopeng Tu, Yang Liu, Lifeng Shang, Xiaohua Liu, Hang Li", "title": "Neural Machine Translation with Reconstruction", "comments": "Accepted by AAAI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although end-to-end Neural Machine Translation (NMT) has achieved remarkable\nprogress in the past two years, it suffers from a major drawback: translations\ngenerated by NMT systems often lack of adequacy. It has been widely observed\nthat NMT tends to repeatedly translate some source words while mistakenly\nignoring other words. To alleviate this problem, we propose a novel\nencoder-decoder-reconstructor framework for NMT. The reconstructor,\nincorporated into the NMT model, manages to reconstruct the input source\nsentence from the hidden layer of the output target sentence, to ensure that\nthe information in the source side is transformed to the target side as much as\npossible. Experiments show that the proposed framework significantly improves\nthe adequacy of NMT output and achieves superior translation result over\nstate-of-the-art NMT and statistical MT systems.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 02:03:55 GMT"}, {"version": "v2", "created": "Mon, 21 Nov 2016 09:47:22 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Tu", "Zhaopeng", ""], ["Liu", "Yang", ""], ["Shang", "Lifeng", ""], ["Liu", "Xiaohua", ""], ["Li", "Hang", ""]]}, {"id": "1611.01884", "submitter": "Depeng Liang", "authors": "Depeng Liang, Yongdong Zhang", "title": "AC-BLSTM: Asymmetric Convolutional Bidirectional LSTM Networks for Text\n  Classification", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently deeplearning models have been shown to be capable of making\nremarkable performance in sentences and documents classification tasks. In this\nwork, we propose a novel framework called AC-BLSTM for modeling sentences and\ndocuments, which combines the asymmetric convolution neural network (ACNN) with\nthe Bidirectional Long Short-Term Memory network (BLSTM). Experiment results\ndemonstrate that our model achieves state-of-the-art results on five tasks,\nincluding sentiment analysis, question type classification, and subjectivity\nclassification. In order to further improve the performance of AC-BLSTM, we\npropose a semi-supervised learning framework called G-AC-BLSTM for text\nclassification by combining the generative model with AC-BLSTM.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 03:39:52 GMT"}, {"version": "v2", "created": "Thu, 15 Dec 2016 03:22:12 GMT"}, {"version": "v3", "created": "Mon, 5 Jun 2017 03:47:15 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Liang", "Depeng", ""], ["Zhang", "Yongdong", ""]]}, {"id": "1611.02007", "submitter": "Florian Boudin", "authors": "Adrien Bougouin, Florian Boudin, B\\'eatrice Daille", "title": "Keyphrase Annotation with Graph Co-Ranking", "comments": "Accepted at the COLING 2016 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Keyphrase annotation is the task of identifying textual units that represent\nthe main content of a document. Keyphrase annotation is either carried out by\nextracting the most important phrases from a document, keyphrase extraction, or\nby assigning entries from a controlled domain-specific vocabulary, keyphrase\nassignment. Assignment methods are generally more reliable. They provide\nbetter-formed keyphrases, as well as keyphrases that do not occur in the\ndocument. But they are often silent on the contrary of extraction methods that\ndo not depend on manually built resources. This paper proposes a new method to\nperform both keyphrase extraction and keyphrase assignment in an integrated and\nmutual reinforcing manner. Experiments have been carried out on datasets\ncovering different domains of humanities and social sciences. They show\nstatistically significant improvements compared to both keyphrase extraction\nand keyphrase assignment state-of-the art methods.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 12:08:13 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Bougouin", "Adrien", ""], ["Boudin", "Florian", ""], ["Daille", "B\u00e9atrice", ""]]}, {"id": "1611.02025", "submitter": "Xavier Holt", "authors": "Xavier Holt, Will Radford, Ben Hachey", "title": "Presenting a New Dataset for the Timeline Generation Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The timeline generation task summarises an entity's biography by selecting\nstories representing key events from a large pool of relevant documents. This\npaper addresses the lack of a standard dataset and evaluative methodology for\nthe problem. We present and make publicly available a new dataset of 18,793\nnews articles covering 39 entities. For each entity, we provide a gold standard\ntimeline and a set of entity-related articles. We propose ROUGE as an\nevaluation metric and validate our dataset by showing that top Google results\noutperform straw-man baselines.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 12:47:25 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Holt", "Xavier", ""], ["Radford", "Will", ""], ["Hachey", "Ben", ""]]}, {"id": "1611.02027", "submitter": "Will Radford", "authors": "Will Radford and Andrew Chisholm and Ben Hachey and Bo Han", "title": ":telephone::person::sailboat::whale::okhand:; or \"Call me Ishmael\" - How\n  do you translate emoji?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on an exploratory analysis of Emoji Dick, a project that leverages\ncrowdsourcing to translate Melville's Moby Dick into emoji. This distinctive\nuse of emoji removes textual context, and leads to a varying translation\nquality. In this paper, we use statistical word alignment and part-of-speech\ntagging to explore how people use emoji. Despite these simple methods, we\nobserved differences in token and part-of-speech distributions. Experiments\nalso suggest that semantics are preserved in the translation, and repetition is\nmore common in emoji.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 12:51:22 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Radford", "Will", ""], ["Chisholm", "Andrew", ""], ["Hachey", "Ben", ""], ["Han", "Bo", ""]]}, {"id": "1611.02091", "submitter": "Bin He", "authors": "Bin He, Bin Dong, Yi Guan, Jinfeng Yang, Zhipeng Jiang, Qiubin Yu,\n  Jianyi Cheng, Chunyan Qu", "title": "Building a comprehensive syntactic and semantic corpus of Chinese\n  clinical texts", "comments": "27 pages, submitted to Journal of Biomedical Informatics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: To build a comprehensive corpus covering syntactic and semantic\nannotations of Chinese clinical texts with corresponding annotation guidelines\nand methods as well as to develop tools trained on the annotated corpus, which\nsupplies baselines for research on Chinese texts in the clinical domain.\n  Materials and methods: An iterative annotation method was proposed to train\nannotators and to develop annotation guidelines. Then, by using annotation\nquality assurance measures, a comprehensive corpus was built, containing\nannotations of part-of-speech (POS) tags, syntactic tags, entities, assertions,\nand relations. Inter-annotator agreement (IAA) was calculated to evaluate the\nannotation quality and a Chinese clinical text processing and information\nextraction system (CCTPIES) was developed based on our annotated corpus.\n  Results: The syntactic corpus consists of 138 Chinese clinical documents with\n47,424 tokens and 2553 full parsing trees, while the semantic corpus includes\n992 documents that annotated 39,511 entities with their assertions and 7695\nrelations. IAA evaluation shows that this comprehensive corpus is of good\nquality, and the system modules are effective.\n  Discussion: The annotated corpus makes a considerable contribution to natural\nlanguage processing (NLP) research into Chinese texts in the clinical domain.\nHowever, this corpus has a number of limitations. Some additional types of\nclinical text should be introduced to improve corpus coverage and active\nlearning methods should be utilized to promote annotation efficiency.\n  Conclusions: In this study, several annotation guidelines and an annotation\nmethod for Chinese clinical texts were proposed, and a comprehensive corpus\nwith its NLP modules were constructed, providing a foundation for further study\nof applying NLP techniques to Chinese texts in the clinical domain.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 15:05:06 GMT"}, {"version": "v2", "created": "Tue, 8 Nov 2016 08:48:59 GMT"}], "update_date": "2016-11-09", "authors_parsed": [["He", "Bin", ""], ["Dong", "Bin", ""], ["Guan", "Yi", ""], ["Yang", "Jinfeng", ""], ["Jiang", "Zhipeng", ""], ["Yu", "Qiubin", ""], ["Cheng", "Jianyi", ""], ["Qu", "Chunyan", ""]]}, {"id": "1611.02266", "submitter": "Ryota Tomioka", "authors": "Liwen Zhang and John Winn and Ryota Tomioka", "title": "Gaussian Attention Model and Its Application to Knowledge Base Embedding\n  and Question Answering", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the Gaussian attention model for content-based neural memory\naccess. With the proposed attention model, a neural network has the additional\ndegree of freedom to control the focus of its attention from a laser sharp\nattention to a broad attention. It is applicable whenever we can assume that\nthe distance in the latent space reflects some notion of semantics. We use the\nproposed attention model as a scoring function for the embedding of a knowledge\nbase into a continuous vector space and then train a model that performs\nquestion answering about the entities in the knowledge base. The proposed\nattention model can handle both the propagation of uncertainty when following a\nseries of relations and also the conjunction of conditions in a natural way. On\na dataset of soccer players who participated in the FIFA World Cup 2014, we\ndemonstrate that our model can handle both path queries and conjunctive queries\nwell.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 20:57:24 GMT"}, {"version": "v2", "created": "Wed, 30 Nov 2016 16:44:17 GMT"}], "update_date": "2016-12-01", "authors_parsed": [["Zhang", "Liwen", ""], ["Winn", "John", ""], ["Tomioka", "Ryota", ""]]}, {"id": "1611.02337", "submitter": "Jose Texier PhD", "authors": "Daniel Robins, Fernando Emmanuel Frati, Jonatan Alvarez, Jose Texier", "title": "Balotage in Argentina 2015, a sentiment analysis of tweets", "comments": "in Spanish. Jornadas de Cloud Computing, La Plata - Argentina. 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Twitter social network contains a large amount of information generated by\nits users. That information is composed of opinions and comments that may\nreflect trends in social behavior. There is talk of trend when it is possible\nto identify opinions and comments geared towards the same shared by a lot of\npeople direction. To determine if two or more written opinions share the same\naddress, techniques Natural Language Processing (NLP) are used. This paper\nproposes a methodology for predicting reflected in Twitter from the use of\nsentiment analysis functions NLP based on social behaviors. The case study was\nselected the 2015 Presidential in Argentina, and a software architecture Big\nData composed Vertica data base with the component called Pulse was used.\nThrough the analysis it was possible to detect trends in voting intentions with\nregard to the presidential candidates, achieving greater accuracy in predicting\nthat achieved with traditional systems surveys.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 23:05:40 GMT"}], "update_date": "2016-11-09", "authors_parsed": [["Robins", "Daniel", ""], ["Frati", "Fernando Emmanuel", ""], ["Alvarez", "Jonatan", ""], ["Texier", "Jose", ""]]}, {"id": "1611.02344", "submitter": "Michael Auli", "authors": "Jonas Gehring, Michael Auli, David Grangier, Yann N. Dauphin", "title": "A Convolutional Encoder Model for Neural Machine Translation", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prevalent approach to neural machine translation relies on bi-directional\nLSTMs to encode the source sentence. In this paper we present a faster and\nsimpler architecture based on a succession of convolutional layers. This allows\nto encode the entire source sentence simultaneously compared to recurrent\nnetworks for which computation is constrained by temporal dependencies. On\nWMT'16 English-Romanian translation we achieve competitive accuracy to the\nstate-of-the-art and we outperform several recently published results on the\nWMT'15 English-German task. Our models obtain almost the same accuracy as a\nvery deep LSTM setup on WMT'14 English-French translation. Our convolutional\nencoder speeds up CPU decoding by more than two times at the same or higher\naccuracy as a strong bi-directional LSTM baseline.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 23:46:45 GMT"}, {"version": "v2", "created": "Thu, 17 Nov 2016 01:45:37 GMT"}, {"version": "v3", "created": "Tue, 25 Jul 2017 01:36:14 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Gehring", "Jonas", ""], ["Auli", "Michael", ""], ["Grangier", "David", ""], ["Dauphin", "Yann N.", ""]]}, {"id": "1611.02360", "submitter": "Rui Zhang", "authors": "Dragomir Radev, Rui Zhang, Steve Wilson, Derek Van Assche, Henrique\n  Spyra Gubert, Alisa Krivokapic, MeiXing Dong, Chongruo Wu, Spruce Bondera,\n  Luke Brandl, Jeremy Dohmann", "title": "Cruciform: Solving Crosswords with Natural Language Processing", "comments": "based on feedback, we have determined that the paper needs more work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crossword puzzles are popular word games that require not only a large\nvocabulary, but also a broad knowledge of topics. Answering each clue is a\nnatural language task on its own as many clues contain nuances, puns, or\ncounter-intuitive word definitions. Additionally, it can be extremely difficult\nto ascertain definitive answers without the constraints of the crossword grid\nitself. This task is challenging for both humans and computers. We describe\nhere a new crossword solving system, Cruciform. We employ a group of natural\nlanguage components, each of which returns a list of candidate words with\nscores when given a clue. These lists are used in conjunction with the fill\nintersections in the puzzle grid to formulate a constraint satisfaction\nproblem, in a manner similar to the one used in the Dr. Fill system. We\ndescribe the results of several of our experiments with the system.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2016 01:47:41 GMT"}, {"version": "v2", "created": "Wed, 23 Nov 2016 16:14:23 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Radev", "Dragomir", ""], ["Zhang", "Rui", ""], ["Wilson", "Steve", ""], ["Van Assche", "Derek", ""], ["Gubert", "Henrique Spyra", ""], ["Krivokapic", "Alisa", ""], ["Dong", "MeiXing", ""], ["Wu", "Chongruo", ""], ["Bondera", "Spruce", ""], ["Brandl", "Luke", ""], ["Dohmann", "Jeremy", ""]]}, {"id": "1611.02361", "submitter": "Rui Zhang", "authors": "Rui Zhang, Honglak Lee, Dragomir Radev", "title": "Dependency Sensitive Convolutional Neural Networks for Modeling\n  Sentences and Documents", "comments": "NAACL2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of sentence and document modeling is to accurately represent the\nmeaning of sentences and documents for various Natural Language Processing\ntasks. In this work, we present Dependency Sensitive Convolutional Neural\nNetworks (DSCNN) as a general-purpose classification system for both sentences\nand documents. DSCNN hierarchically builds textual representations by\nprocessing pretrained word embeddings via Long Short-Term Memory networks and\nsubsequently extracting features with convolution operators. Compared with\nexisting recursive neural models with tree structures, DSCNN does not rely on\nparsers and expensive phrase labeling, and thus is not restricted to\nsentence-level tasks. Moreover, unlike other CNN-based models that analyze\nsentences locally by sliding windows, our system captures both the dependency\ninformation within each sentence and relationships across sentences in the same\ndocument. Experiment results demonstrate that our approach is achieving\nstate-of-the-art performance on several tasks, including sentiment analysis,\nquestion type classification, and subjectivity classification.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2016 01:48:15 GMT"}], "update_date": "2016-11-09", "authors_parsed": [["Zhang", "Rui", ""], ["Lee", "Honglak", ""], ["Radev", "Dragomir", ""]]}, {"id": "1611.02378", "submitter": "Yufeng Ma", "authors": "Yufeng Ma, Long Xia, Wenqi Shen, Mi Zhou, Weiguo Fan", "title": "A Surrogate-based Generic Classifier for Chinese TV Series Reviews", "comments": "submitted to IDD", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the emerging of various online video platforms like Youtube, Youku and\nLeTV, online TV series' reviews become more and more important both for viewers\nand producers. Customers rely heavily on these reviews before selecting TV\nseries, while producers use them to improve the quality. As a result,\nautomatically classifying reviews according to different requirements evolves\nas a popular research topic and is essential in our daily life. In this paper,\nwe focused on reviews of hot TV series in China and successfully trained\ngeneric classifiers based on eight predefined categories. The experimental\nresults showed promising performance and effectiveness of its generalization to\ndifferent TV series.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2016 03:33:46 GMT"}, {"version": "v2", "created": "Mon, 21 Nov 2016 14:55:40 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Ma", "Yufeng", ""], ["Xia", "Long", ""], ["Shen", "Wenqi", ""], ["Zhou", "Mi", ""], ["Fan", "Weiguo", ""]]}, {"id": "1611.02550", "submitter": "Shane Settle", "authors": "Shane Settle and Karen Livescu", "title": "Discriminative Acoustic Word Embeddings: Recurrent Neural Network-Based\n  Approaches", "comments": "To appear at SLT 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustic word embeddings --- fixed-dimensional vector representations of\nvariable-length spoken word segments --- have begun to be considered for tasks\nsuch as speech recognition and query-by-example search. Such embeddings can be\nlearned discriminatively so that they are similar for speech segments\ncorresponding to the same word, while being dissimilar for segments\ncorresponding to different words. Recent work has found that acoustic word\nembeddings can outperform dynamic time warping on query-by-example search and\nrelated word discrimination tasks. However, the space of embedding models and\ntraining approaches is still relatively unexplored. In this paper we present\nnew discriminative embedding models based on recurrent neural networks (RNNs).\nWe consider training losses that have been successful in prior work, in\nparticular a cross entropy loss for word classification and a contrastive loss\nthat explicitly aims to separate same-word and different-word pairs in a\n\"Siamese network\" training setting. We find that both classifier-based and\nSiamese RNN embeddings improve over previously reported results on a word\ndiscrimination task, with Siamese RNNs outperforming classification models. In\naddition, we present analyses of the learned embeddings and the effects of\nvariables such as dimensionality and network structure.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2016 15:13:19 GMT"}], "update_date": "2016-11-09", "authors_parsed": [["Settle", "Shane", ""], ["Livescu", "Karen", ""]]}, {"id": "1611.02554", "submitter": "Lei Yu", "authors": "Lei Yu, Phil Blunsom, Chris Dyer, Edward Grefenstette, Tomas Kocisky", "title": "The Neural Noisy Channel", "comments": "ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate sequence to sequence transduction as a noisy channel decoding\nproblem and use recurrent neural networks to parameterise the source and\nchannel models. Unlike direct models which can suffer from explaining-away\neffects during training, noisy channel models must produce outputs that explain\ntheir inputs, and their component models can be trained with not only paired\ntraining samples but also unpaired samples from the marginal output\ndistribution. Using a latent variable to control how much of the conditioning\nsequence the channel model needs to read in order to generate a subsequent\nsymbol, we obtain a tractable and effective beam search decoder. Experimental\nresults on abstractive sentence summarisation, morphological inflection, and\nmachine translation show that noisy channel models outperform direct models,\nand that they significantly benefit from increased amounts of unpaired output\ndata that direct models cannot easily use.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2016 15:18:44 GMT"}, {"version": "v2", "created": "Mon, 6 Mar 2017 12:37:12 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Yu", "Lei", ""], ["Blunsom", "Phil", ""], ["Dyer", "Chris", ""], ["Grefenstette", "Edward", ""], ["Kocisky", "Tomas", ""]]}, {"id": "1611.02588", "submitter": "Piroska Lendvai", "authors": "Piroska Lendvai and Uwe D. Reichel", "title": "Contradiction Detection for Rumorous Claims", "comments": "To appear in: Proceedings of Extra-Propositional Aspects of Meaning\n  (ExProM) in Computational Linguistics, Osaka, Japan, 2016", "journal-ref": "Proc. Extra-Propositional Aspects of Meaning (ExProM) in\n  Computational Linguistics, Osaka, Japan, 2016, pp 31-40", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The utilization of social media material in journalistic workflows is\nincreasing, demanding automated methods for the identification of mis- and\ndisinformation. Since textual contradiction across social media posts can be a\nsignal of rumorousness, we seek to model how claims in Twitter posts are being\ntextually contradicted. We identify two different contexts in which\ncontradiction emerges: its broader form can be observed across independently\nposted tweets and its more specific form in threaded conversations. We define\nhow the two scenarios differ in terms of central elements of argumentation:\nclaims and conversation structure. We design and evaluate models for the two\nscenarios uniformly as 3-way Recognizing Textual Entailment tasks in order to\nrepresent claims and conversation structure implicitly in a generic inference\nmodel, while previous studies used explicit or no representation of these\nproperties. To address noisy text, our classifiers use simple similarity\nfeatures derived from the string and part-of-speech level. Corpus statistics\nreveal distribution differences for these features in contradictory as opposed\nto non-contradictory tweet relations, and the classifiers yield state of the\nart performance.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2016 16:19:17 GMT"}, {"version": "v2", "created": "Fri, 11 Nov 2016 10:57:07 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Lendvai", "Piroska", ""], ["Reichel", "Uwe D.", ""]]}, {"id": "1611.02590", "submitter": "Uwe Reichel", "authors": "Uwe D. Reichel and Piroska Lendvai", "title": "Veracity Computing from Lexical Cues and Perceived Certainty Trends", "comments": "to appear in: Proc. 2nd Workshop on Noisy User-generated Text, Osaka,\n  Japan, 2016", "journal-ref": "Proc. 2nd Workshop on Noisy User-generated Text, Osaka, Japan,\n  2016, pp 33--42", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a data-driven method for determining the veracity of a set of\nrumorous claims on social media data. Tweets from different sources pertaining\nto a rumor are processed on three levels: first, factuality values are assigned\nto each tweet based on four textual cue categories relevant for our journalism\nuse case; these amalgamate speaker support in terms of polarity and commitment\nin terms of certainty and speculation. Next, the proportions of these lexical\ncues are utilized as predictors for tweet certainty in a generalized linear\nregression model. Subsequently, lexical cue proportions, predicted certainty,\nas well as their time course characteristics are used to compute veracity for\neach rumor in terms of the identity of the rumor-resolving tweet and its binary\nresolution value judgment. The system operates without access to\nextralinguistic resources. Evaluated on the data portion for which hand-labeled\nexamples were available, it achieves .74 F1-score on identifying rumor\nresolving tweets and .76 F1-score on predicting if a rumor is resolved as true\nor false.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2016 16:21:16 GMT"}, {"version": "v2", "created": "Fri, 11 Nov 2016 01:19:06 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Reichel", "Uwe D.", ""], ["Lendvai", "Piroska", ""]]}, {"id": "1611.02654", "submitter": "Lajanugen Logeswaran", "authors": "Lajanugen Logeswaran, Honglak Lee, Dragomir Radev", "title": "Sentence Ordering and Coherence Modeling using Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling the structure of coherent texts is a key NLP problem. The task of\ncoherently organizing a given set of sentences has been commonly used to build\nand evaluate models that understand such structure. We propose an end-to-end\nunsupervised deep learning approach based on the set-to-sequence framework to\naddress this problem. Our model strongly outperforms prior methods in the order\ndiscrimination task and a novel task of ordering abstracts from scientific\narticles. Furthermore, our work shows that useful text representations can be\nobtained by learning to order sentences. Visualizing the learned sentence\nrepresentations shows that the model captures high-level logical structure in\nparagraphs. Our representations perform comparably to state-of-the-art\npre-training methods on sentence similarity and paraphrase detection tasks.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2016 19:04:09 GMT"}, {"version": "v2", "created": "Fri, 22 Dec 2017 02:36:08 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Logeswaran", "Lajanugen", ""], ["Lee", "Honglak", ""], ["Radev", "Dragomir", ""]]}, {"id": "1611.02683", "submitter": "Prajit Ramachandran", "authors": "Prajit Ramachandran, Peter J. Liu, Quoc V. Le", "title": "Unsupervised Pretraining for Sequence to Sequence Learning", "comments": "Updated to accepted EMNLP 2017 version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a general unsupervised learning method to improve the\naccuracy of sequence to sequence (seq2seq) models. In our method, the weights\nof the encoder and decoder of a seq2seq model are initialized with the\npretrained weights of two language models and then fine-tuned with labeled\ndata. We apply this method to challenging benchmarks in machine translation and\nabstractive summarization and find that it significantly improves the\nsubsequent supervised models. Our main result is that pretraining improves the\ngeneralization of seq2seq models. We achieve state-of-the art results on the\nWMT English$\\rightarrow$German task, surpassing a range of methods using both\nphrase-based machine translation and neural machine translation. Our method\nachieves a significant improvement of 1.3 BLEU from the previous best models on\nboth WMT'14 and WMT'15 English$\\rightarrow$German. We also conduct human\nevaluations on abstractive summarization and find that our method outperforms a\npurely supervised learning baseline in a statistically significant manner.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2016 20:42:26 GMT"}, {"version": "v2", "created": "Thu, 22 Feb 2018 01:57:27 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Ramachandran", "Prajit", ""], ["Liu", "Peter J.", ""], ["Le", "Quoc V.", ""]]}, {"id": "1611.02695", "submitter": "Samuel Fernando", "authors": "Samuel Fernando, Roger K. Moore, David Cameron, Emily C. Collins,\n  Abigail Millings, Amanda J. Sharkey, Tony J. Prescott", "title": "Automatic recognition of child speech for robotic applications in noisy\n  environments", "comments": "Submission to Computer Speech and Language, special issue on\n  Interaction Technologies for Children", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic speech recognition (ASR) allows a natural and intuitive interface\nfor robotic educational applications for children. However there are a number\nof challenges to overcome to allow such an interface to operate robustly in\nrealistic settings, including the intrinsic difficulties of recognising child\nspeech and high levels of background noise often present in classrooms. As part\nof the EU EASEL project we have provided several contributions to address these\nchallenges, implementing our own ASR module for use in robotics applications.\nWe used the latest deep neural network algorithms which provide a leap in\nperformance over the traditional GMM approach, and apply data augmentation\nmethods to improve robustness to noise and speaker variation. We provide a\nclose integration between the ASR module and the rest of the dialogue system,\nallowing the ASR to receive in real-time the language models relevant to the\ncurrent section of the dialogue, greatly improving the accuracy. We integrated\nour ASR module into an interactive, multimodal system using a small humanoid\nrobot to help children learn about exercise and energy. The system was\ninstalled at a public museum event as part of a research study where 320\nchildren (aged 3 to 14) interacted with the robot, with our ASR achieving 90%\naccuracy for fluent and near-fluent speech.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2016 09:50:30 GMT"}], "update_date": "2016-11-10", "authors_parsed": [["Fernando", "Samuel", ""], ["Moore", "Roger K.", ""], ["Cameron", "David", ""], ["Collins", "Emily C.", ""], ["Millings", "Abigail", ""], ["Sharkey", "Amanda J.", ""], ["Prescott", "Tony J.", ""]]}, {"id": "1611.02815", "submitter": "Emad Al-Shalabi Fawzi", "authors": "Emad Fawzi Al-Shalabi", "title": "An Automated System for Essay Scoring of Online Exams in Arabic based on\n  Stemming Techniques and Levenshtein Edit Operations", "comments": "5 pages, 2 figures", "journal-ref": "IJCSI International Journal of Computer Science Issues, Volume 13,\n  Issue 5, September 2016", "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this article, an automated system is proposed for essay scoring in Arabic\nlanguage for online exams based on stemming techniques and Levenshtein edit\noperations. An online exam has been developed on the proposed mechanisms,\nexploiting the capabilities of light and heavy stemming. The implemented online\ngrading system has shown to be an efficient tool for automated scoring of essay\nquestions.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2016 15:25:02 GMT"}], "update_date": "2016-11-10", "authors_parsed": [["Al-Shalabi", "Emad Fawzi", ""]]}, {"id": "1611.02839", "submitter": "Kimmo Kettunen", "authors": "Kimmo Kettunen, Eetu M\\\"akel\\\"a, Teemu Ruokolainen, Juha Kuokkala and\n  Laura L\\\"ofberg", "title": "Old Content and Modern Tools - Searching Named Entities in a Finnish\n  OCRed Historical Newspaper Collection 1771-1910", "comments": "24 pages, 13 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named Entity Recognition (NER), search, classification and tagging of names\nand name like frequent informational elements in texts, has become a standard\ninformation extraction procedure for textual data. NER has been applied to many\ntypes of texts and different types of entities: newspapers, fiction, historical\nrecords, persons, locations, chemical compounds, protein families, animals etc.\nIn general a NER system's performance is genre and domain dependent and also\nused entity categories vary (Nadeau and Sekine, 2007). The most general set of\nnamed entities is usually some version of three partite categorization of\nlocations, persons and organizations. In this paper we report first large scale\ntrials and evaluation of NER with data out of a digitized Finnish historical\nnewspaper collection Digi. Experiments, results and discussion of this research\nserve development of the Web collection of historical Finnish newspapers.\n  Digi collection contains 1,960,921 pages of newspaper material from years\n1771-1910 both in Finnish and Swedish. We use only material of Finnish\ndocuments in our evaluation. The OCRed newspaper collection has lots of OCR\nerrors; its estimated word level correctness is about 70-75 % (Kettunen and\nP\\\"a\\\"akk\\\"onen, 2016). Our principal NER tagger is a rule-based tagger of\nFinnish, FiNER, provided by the FIN-CLARIN consortium. We show also results of\nlimited category semantic tagging with tools of the Semantic Computing Research\nGroup (SeCo) of the Aalto University. Three other tools are also evaluated\nbriefly.\n  This research reports first published large scale results of NER in a\nhistorical Finnish OCRed newspaper collection. Results of the research\nsupplement NER results of other languages with similar noisy data.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 07:37:28 GMT"}], "update_date": "2016-11-10", "authors_parsed": [["Kettunen", "Kimmo", ""], ["M\u00e4kel\u00e4", "Eetu", ""], ["Ruokolainen", "Teemu", ""], ["Kuokkala", "Juha", ""], ["L\u00f6fberg", "Laura", ""]]}, {"id": "1611.02879", "submitter": "Abhinav Thanda", "authors": "Abhinav Thanda, Shankar M Venkatesan", "title": "Audio Visual Speech Recognition using Deep Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a training algorithm for an audio-visual automatic\nspeech recognition (AV-ASR) system using deep recurrent neural network\n(RNN).First, we train a deep RNN acoustic model with a Connectionist Temporal\nClassification (CTC) objective function. The frame labels obtained from the\nacoustic model are then used to perform a non-linear dimensionality reduction\nof the visual features using a deep bottleneck network. Audio and visual\nfeatures are fused and used to train a fusion RNN. The use of bottleneck\nfeatures for visual modality helps the model to converge properly during\ntraining. Our system is evaluated on GRID corpus. Our results show that\npresence of visual modality gives significant improvement in character error\nrate (CER) at various levels of noise even when the model is trained without\nnoisy data. We also provide a comparison of two fusion methods: feature fusion\nand decision fusion.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 10:24:52 GMT"}], "update_date": "2016-11-10", "authors_parsed": [["Thanda", "Abhinav", ""], ["Venkatesan", "Shankar M", ""]]}, {"id": "1611.02944", "submitter": "Jernej Vi\\v{c}i\\v{c}", "authors": "Jernej Vi\\v{c}i\\v{c}, Andrej Brodnik", "title": "Increasing the throughput of machine translation systems using clouds", "comments": "20 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The manuscript presents an experiment at implementation of a Machine\nTranslation system in a MapReduce model. The empirical evaluation was done\nusing fully implemented translation systems embedded into the MapReduce\nprogramming model. Two machine translation paradigms were studied: shallow\ntransfer Rule Based Machine Translation and Statistical Machine Translation.\n  The results show that the MapReduce model can be successfully used to\nincrease the throughput of a machine translation system. Furthermore this\nmethod enhances the throughput of a machine translation system without\ndecreasing the quality of the translation output.\n  Thus, the present manuscript also represents a contribution to the seminal\nwork in natural language processing, specifically Machine Translation. It first\npoints toward the importance of the definition of the metric of throughput of\ntranslation system and, second, the applicability of the machine translation\ntask to the MapReduce paradigm.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 14:27:03 GMT"}], "update_date": "2016-11-10", "authors_parsed": [["Vi\u010di\u010d", "Jernej", ""], ["Brodnik", "Andrej", ""]]}, {"id": "1611.02956", "submitter": "Hong Jin Kang", "authors": "Hong Jin Kang, Tao Chen, Muthu Kumar Chandrasekaran, Min-Yen Kan", "title": "A Comparison of Word Embeddings for English and Cross-Lingual Chinese\n  Word Sense Disambiguation", "comments": "10 pages. Appears in the Proceedings of The 3rd Workshop on Natural\n  Language Processing Techniques for Educational Applications (NLPTEA 2016)", "journal-ref": "Proceedings of the 3rd Workshop on Natural Language Processing\n  Techniques for Educational Applications, pages 30 to 39, Osaka, Japan,\n  December 12 2016", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings are now ubiquitous forms of word representation in natural\nlanguage processing. There have been applications of word embeddings for\nmonolingual word sense disambiguation (WSD) in English, but few comparisons\nhave been done. This paper attempts to bridge that gap by examining popular\nembeddings for the task of monolingual English WSD. Our simplified method leads\nto comparable state-of-the-art performance without expensive retraining.\nCross-Lingual WSD - where the word senses of a word in a source language e come\nfrom a separate target translation language f - can also assist in language\nlearning; for example, when providing translations of target vocabulary for\nlearners. Thus we have also applied word embeddings to the novel task of\ncross-lingual WSD for Chinese and provide a public dataset for further\nbenchmarking. We have also experimented with using word embeddings for LSTM\nnetworks and found surprisingly that a basic LSTM network does not work well.\nWe discuss the ramifications of this outcome.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 14:50:01 GMT"}, {"version": "v2", "created": "Fri, 11 Nov 2016 15:30:36 GMT"}, {"version": "v3", "created": "Sun, 9 Apr 2017 11:54:01 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Kang", "Hong Jin", ""], ["Chen", "Tao", ""], ["Chandrasekaran", "Muthu Kumar", ""], ["Kan", "Min-Yen", ""]]}, {"id": "1611.02988", "submitter": "Malvina Nissim Malvina Nissim", "authors": "Chris Pool and Malvina Nissim", "title": "Distant supervision for emotion detection using Facebook reactions", "comments": "Proceedings of the Workshop on Computational Modeling of People's\n  Opinions, Personality, and Emotions in Social Media (PEOPLES 2016), held in\n  conjunction with COLING 2016, Osaka, Japan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We exploit the Facebook reaction feature in a distant supervised fashion to\ntrain a support vector machine classifier for emotion detection, using several\nfeature combinations and combining different Facebook pages. We test our models\non existing benchmarks for emotion detection and show that employing only\ninformation that is derived completely automatically, thus without relying on\nany handcrafted lexicon as it's usually done, we can achieve competitive\nresults. The results also show that there is large room for improvement,\nespecially by gearing the collection of Facebook pages, with a view to the\ntarget domain.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 15:49:31 GMT"}], "update_date": "2016-11-10", "authors_parsed": [["Pool", "Chris", ""], ["Nissim", "Malvina", ""]]}, {"id": "1611.03057", "submitter": "Malvina Nissim", "authors": "Barbara Plank and Malvina Nissim", "title": "When silver glitters more than gold: Bootstrapping an Italian\n  part-of-speech tagger for Twitter", "comments": "Proceedings of the 5th Evaluation Campaign of Natural Language\n  Processing and Speech Tools for Italian (EVALITA 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We bootstrap a state-of-the-art part-of-speech tagger to tag Italian Twitter\ndata, in the context of the Evalita 2016 PoSTWITA shared task. We show that\ntraining the tagger on native Twitter data enriched with little amounts of\nspecifically selected gold data and additional silver-labelled data scraped\nfrom Facebook, yields better results than using large amounts of manually\nannotated data from a mix of genres.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 19:39:15 GMT"}], "update_date": "2016-11-10", "authors_parsed": [["Plank", "Barbara", ""], ["Nissim", "Malvina", ""]]}, {"id": "1611.03218", "submitter": "Emilio Jorge", "authors": "Emilio Jorge, Mikael K{\\aa}geb\\\"ack, Fredrik D. Johansson, Emil\n  Gustavsson", "title": "Learning to Play Guess Who? and Inventing a Grounded Language as a\n  Consequence", "comments": "Previous version was accepted to Deep Reinforcement Learning Workshop\n  at NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acquiring your first language is an incredible feat and not easily\nduplicated. Learning to communicate using nothing but a few pictureless books,\na corpus, would likely be impossible even for humans. Nevertheless, this is the\ndominating approach in most natural language processing today. As an\nalternative, we propose the use of situated interactions between agents as a\ndriving force for communication, and the framework of Deep Recurrent Q-Networks\nfor evolving a shared language grounded in the provided environment. We task\nthe agents with interactive image search in the form of the game Guess Who?.\nThe images from the game provide a non trivial environment for the agents to\ndiscuss and a natural grounding for the concepts they decide to encode in their\ncommunication. Our experiments show that the agents learn not only to encode\nphysical concepts in their words, i.e. grounding, but also that the agents\nlearn to hold a multi-step dialogue remembering the state of the dialogue from\nstep to step.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 08:44:52 GMT"}, {"version": "v2", "created": "Sun, 27 Nov 2016 14:50:50 GMT"}, {"version": "v3", "created": "Tue, 3 Jan 2017 18:28:43 GMT"}, {"version": "v4", "created": "Wed, 15 Mar 2017 11:24:49 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Jorge", "Emilio", ""], ["K\u00e5geb\u00e4ck", "Mikael", ""], ["Johansson", "Fredrik D.", ""], ["Gustavsson", "Emil", ""]]}, {"id": "1611.03279", "submitter": "Malvina Nissim", "authors": "Marco Del Tredici and Malvina Nissim and Andrea Zaninello", "title": "Tracing metaphors in time through self-distance in vector spaces", "comments": "Proceedings of the Third Italian Conference on Computational\n  Linguistics (CLIC 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  From a diachronic corpus of Italian, we build consecutive vector spaces in\ntime and use them to compare a term's cosine similarity to itself in different\ntime spans. We assume that a drop in similarity might be related to the\nemergence of a metaphorical sense at a given time. Similarity-based\nobservations are matched to the actual year when a figurative meaning was\ndocumented in a reference dictionary and through manual inspection of corpus\noccurrences.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 12:22:43 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["Del Tredici", "Marco", ""], ["Nissim", "Malvina", ""], ["Zaninello", "Andrea", ""]]}, {"id": "1611.03305", "submitter": "Kezban Dilek Onal", "authors": "Kezban Dilek Onal, Ismail Sengor Altingovde, Pinar Karagoz, Maarten de\n  Rijke", "title": "Getting Started with Neural Models for Semantic Matching in Web Search", "comments": "under review for the Information Retrieval Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vocabulary mismatch problem is a long-standing problem in information\nretrieval. Semantic matching holds the promise of solving the problem. Recent\nadvances in language technology have given rise to unsupervised neural models\nfor learning representations of words as well as bigger textual units. Such\nrepresentations enable powerful semantic matching methods. This survey is meant\nas an introduction to the use of neural models for semantic matching. To remain\nfocused we limit ourselves to web search. We detail the required background and\nterminology, a taxonomy grouping the rapidly growing body of work in the area,\nand then survey work on neural models for semantic matching in the context of\nthree tasks: query suggestion, ad retrieval, and document retrieval. We include\na section on resources and best practices that we believe will help readers who\nare new to the area. We conclude with an assessment of the state-of-the-art and\nsuggestions for future work.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2016 14:28:40 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["Onal", "Kezban Dilek", ""], ["Altingovde", "Ismail Sengor", ""], ["Karagoz", "Pinar", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1611.03382", "submitter": "Wenyuan Zeng", "authors": "Wenyuan Zeng, Wenjie Luo, Sanja Fidler, Raquel Urtasun", "title": "Efficient Summarization with Read-Again and Copy Mechanism", "comments": "11 pages, 4 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Encoder-decoder models have been widely used to solve sequence to sequence\nprediction tasks. However current approaches suffer from two shortcomings.\nFirst, the encoders compute a representation of each word taking into account\nonly the history of the words it has read so far, yielding suboptimal\nrepresentations. Second, current decoders utilize large vocabularies in order\nto minimize the problem of unknown words, resulting in slow decoding times. In\nthis paper we address both shortcomings. Towards this goal, we first introduce\na simple mechanism that first reads the input sequence before committing to a\nrepresentation of each word. Furthermore, we propose a simple copy mechanism\nthat is able to exploit very small vocabularies and handle out-of-vocabulary\nwords. We demonstrate the effectiveness of our approach on the Gigaword dataset\nand DUC competition outperforming the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 16:23:04 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["Zeng", "Wenyuan", ""], ["Luo", "Wenjie", ""], ["Fidler", "Sanja", ""], ["Urtasun", "Raquel", ""]]}, {"id": "1611.03466", "submitter": "Vikram Krishnamurthy", "authors": "Vikram Krishnamurthy and Sijia Gao", "title": "Syntactic Enhancement to VSIMM for Roadmap Based Anomalous Trajectory\n  Detection: A Natural Language Processing Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of syntactic tracking is to classify spatio-temporal patterns of a\ntarget's motion using natural language processing models. In this paper, we\ngeneralize earlier work by considering a constrained stochastic context free\ngrammar (CSCFG) for modeling patterns confined to a roadmap. The constrained\ngrammar facilitates modeling specific directions and road names in a roadmap.\nWe present a novel particle filtering algorithm that exploits the CSCFG model\nfor estimating the target's patterns. This meta-level algorithm operates in\nconjunction with a base-level tracking algorithm. Extensive numerical results\nusing simulated ground moving target indicator (GMTI) radar measurements show\nsubstantial improvement in target tracking accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 20:13:36 GMT"}, {"version": "v2", "created": "Fri, 26 Jan 2018 07:37:54 GMT"}, {"version": "v3", "created": "Sat, 4 Aug 2018 10:36:21 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Krishnamurthy", "Vikram", ""], ["Gao", "Sijia", ""]]}, {"id": "1611.03533", "submitter": "Xiang Kong", "authors": "Xiang Kong, Xuesong Yang, Mark Hasegawa-Johnson, Jeung-Yoon Choi,\n  Stefanie Shattuck-Hufnagel", "title": "Landmark-based consonant voicing detection on multilingual corpora", "comments": "ready to submit to JASA-EL", "journal-ref": null, "doi": "10.1121/1.4987203", "report-no": null, "categories": "cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper tests the hypothesis that distinctive feature classifiers anchored\nat phonetic landmarks can be transferred cross-lingually without loss of\naccuracy. Three consonant voicing classifiers were developed: (1) manually\nselected acoustic features anchored at a phonetic landmark, (2) MFCCs (either\naveraged across the segment or anchored at the landmark), and(3) acoustic\nfeatures computed using a convolutional neural network (CNN). All detectors are\ntrained on English data (TIMIT),and tested on English, Turkish, and Spanish\n(performance measured using F1 and accuracy). Experiments demonstrate that\nmanual features outperform all MFCC classifiers, while CNNfeatures outperform\nboth. MFCC-based classifiers suffer an F1reduction of 16% absolute when\ngeneralized from English to other languages. Manual features suffer only a 5%\nF1 reduction,and CNN features actually perform better in Turkish and Span-ish\nthan in the training language, demonstrating that features capable of\nrepresenting long-term spectral dynamics (CNN and landmark-based features) are\nable to generalize cross-lingually with little or no loss of accuracy\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 22:11:16 GMT"}], "update_date": "2017-08-23", "authors_parsed": [["Kong", "Xiang", ""], ["Yang", "Xuesong", ""], ["Hasegawa-Johnson", "Mark", ""], ["Choi", "Jeung-Yoon", ""], ["Shattuck-Hufnagel", "Stefanie", ""]]}, {"id": "1611.03558", "submitter": "ShiLiang Zhang", "authors": "Dan Liu and Wei Lin and Shiliang Zhang and Si Wei and Hui Jiang", "title": "Neural Networks Models for Entity Discovery and Linking", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the USTC_NELSLIP systems submitted to the Trilingual\nEntity Detection and Linking (EDL) track in 2016 TAC Knowledge Base Population\n(KBP) contests. We have built two systems for entity discovery and mention\ndetection (MD): one uses the conditional RNNLM and the other one uses the\nattention-based encoder-decoder framework. The entity linking (EL) system\nconsists of two modules: a rule based candidate generation and a neural\nnetworks probability ranking model. Moreover, some simple string matching rules\nare used for NIL clustering. At the end, our best system has achieved an F1\nscore of 0.624 in the end-to-end typed mention ceaf plus metric.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2016 01:21:20 GMT"}], "update_date": "2016-11-14", "authors_parsed": [["Liu", "Dan", ""], ["Lin", "Wei", ""], ["Zhang", "Shiliang", ""], ["Wei", "Si", ""], ["Jiang", "Hui", ""]]}, {"id": "1611.03596", "submitter": "Eduardo G. Altmann", "authors": "Eduardo G. Altmann, Laercio Dias, and Martin Gerlach", "title": "Generalized Entropies and the Similarity of Texts", "comments": "13 pages, 6 figures; Results presented at the StatPhys-2016 meeting\n  in Lyon", "journal-ref": "J. Stat. Mech. 014002 (2017)", "doi": "10.1088/1742-5468/aa53f5", "report-no": null, "categories": "physics.soc-ph cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how generalized Gibbs-Shannon entropies can provide new insights on\nthe statistical properties of texts. The universal distribution of word\nfrequencies (Zipf's law) implies that the generalized entropies, computed at\nthe word level, are dominated by words in a specific range of frequencies. Here\nwe show that this is the case not only for the generalized entropies but also\nfor the generalized (Jensen-Shannon) divergences, used to compute the\nsimilarity between different texts. This finding allows us to identify the\ncontribution of specific words (and word frequencies) for the different\ngeneralized entropies and also to estimate the size of the databases needed to\nobtain a reliable estimation of the divergences. We test our results in large\ndatabases of books (from the Google n-gram database) and scientific papers\n(indexed by Web of Science).\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2016 06:36:53 GMT"}], "update_date": "2017-02-15", "authors_parsed": [["Altmann", "Eduardo G.", ""], ["Dias", "Laercio", ""], ["Gerlach", "Martin", ""]]}, {"id": "1611.03599", "submitter": "Wei-Fan Chen", "authors": "Wei-Fan Chen and Lun-Wei Ku", "title": "UTCNN: a Deep Learning Model of Stance Classificationon on Social Media\n  Text", "comments": "11 pages, to appear in COLING 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most neural network models for document classification on social media focus\non text infor-mation to the neglect of other information on these platforms. In\nthis paper, we classify post stance on social media channels and develop UTCNN,\na neural network model that incorporates user tastes, topic tastes, and user\ncomments on posts. UTCNN not only works on social media texts, but also\nanalyzes texts in forums and message boards. Experiments performed on Chinese\nFacebook data and English online debate forum data show that UTCNN achieves a\n0.755 macro-average f-score for supportive, neutral, and unsupportive stance\nclasses on Facebook data, which is significantly better than models in which\neither user, topic, or comment information is withheld. This model design\ngreatly mitigates the lack of data for the minor class without the use of\noversampling. In addition, UTCNN yields a 0.842 accuracy on English online\ndebate forum data, which also significantly outperforms results from previous\nwork as well as other deep learning models, showing that UTCNN performs well\nregardless of language or platform.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2016 07:05:49 GMT"}], "update_date": "2016-11-14", "authors_parsed": [["Chen", "Wei-Fan", ""], ["Ku", "Lun-Wei", ""]]}, {"id": "1611.03641", "submitter": "Oded Avraham", "authors": "Oded Avraham and Yoav Goldberg", "title": "Improving Reliability of Word Similarity Evaluation by Redesigning\n  Annotation Task and Performance Measure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We suggest a new method for creating and using gold-standard datasets for\nword similarity evaluation. Our goal is to improve the reliability of the\nevaluation, and we do this by redesigning the annotation task to achieve higher\ninter-rater agreement, and by defining a performance measure which takes the\nreliability of each annotation decision in the dataset into account.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2016 10:06:29 GMT"}, {"version": "v2", "created": "Mon, 27 Feb 2017 18:38:56 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Avraham", "Oded", ""], ["Goldberg", "Yoav", ""]]}, {"id": "1611.03932", "submitter": "Jangho Lee", "authors": "Jangho Lee, Gyuwan Kim, Jaeyoon Yoo, Changwoo Jung, Minseok Kim,\n  Sungroh Yoon", "title": "Training IBM Watson using Automatically Generated Question-Answer Pairs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IBM Watson is a cognitive computing system capable of question answering in\nnatural languages. It is believed that IBM Watson can understand large corpora\nand answer relevant questions more effectively than any other\nquestion-answering system currently available. To unleash the full power of\nWatson, however, we need to train its instance with a large number of\nwell-prepared question-answer pairs. Obviously, manually generating such pairs\nin a large quantity is prohibitively time consuming and significantly limits\nthe efficiency of Watson's training. Recently, a large-scale dataset of over 30\nmillion question-answer pairs was reported. Under the assumption that using\nsuch an automatically generated dataset could relieve the burden of manual\nquestion-answer generation, we tried to use this dataset to train an instance\nof Watson and checked the training efficiency and accuracy. According to our\nexperiments, using this auto-generated dataset was effective for training\nWatson, complementing manually crafted question-answer pairs. To the best of\nthe authors' knowledge, this work is the first attempt to use a large-scale\ndataset of automatically generated question-answer pairs for training IBM\nWatson. We anticipate that the insights and lessons obtained from our\nexperiments will be useful for researchers who want to expedite Watson training\nleveraged by automatically generated question-answer pairs.\n", "versions": [{"version": "v1", "created": "Sat, 12 Nov 2016 01:49:48 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Lee", "Jangho", ""], ["Kim", "Gyuwan", ""], ["Yoo", "Jaeyoon", ""], ["Jung", "Changwoo", ""], ["Kim", "Minseok", ""], ["Yoon", "Sungroh", ""]]}, {"id": "1611.03949", "submitter": "Qiao Qian", "authors": "Qiao Qian, Minlie Huang, Jinhao Lei, Xiaoyan Zhu", "title": "Linguistically Regularized LSTMs for Sentiment Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment understanding has been a long-term goal of AI in the past decades.\nThis paper deals with sentence-level sentiment classification. Though a variety\nof neural network models have been proposed very recently, however, previous\nmodels either depend on expensive phrase-level annotation, whose performance\ndrops substantially when trained with only sentence-level annotation; or do not\nfully employ linguistic resources (e.g., sentiment lexicons, negation words,\nintensity words), thus not being able to produce linguistically coherent\nrepresentations. In this paper, we propose simple models trained with\nsentence-level annotation, but also attempt to generating linguistically\ncoherent representations by employing regularizers that model the linguistic\nrole of sentiment lexicons, negation words, and intensity words. Results show\nthat our models are effective to capture the sentiment shifting effect of\nsentiment, negation, and intensity words, while still obtain competitive\nresults without sacrificing the models' simplicity.\n", "versions": [{"version": "v1", "created": "Sat, 12 Nov 2016 03:55:10 GMT"}, {"version": "v2", "created": "Tue, 25 Apr 2017 18:29:58 GMT"}], "update_date": "2017-04-27", "authors_parsed": [["Qian", "Qiao", ""], ["Huang", "Minlie", ""], ["Lei", "Jinhao", ""], ["Zhu", "Xiaoyan", ""]]}, {"id": "1611.03954", "submitter": "Muhao Chen", "authors": "Muhao Chen, Yingtao Tian, Mohan Yang, Carlo Zaniolo", "title": "Multilingual Knowledge Graph Embeddings for Cross-lingual Knowledge\n  Alignment", "comments": "Extended version of the IJCAI-17 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent works have demonstrated the benefits of knowledge graph\nembeddings in completing monolingual knowledge graphs. Inasmuch as related\nknowledge bases are built in several different languages, achieving\ncross-lingual knowledge alignment will help people in constructing a coherent\nknowledge base, and assist machines in dealing with different expressions of\nentity relationships across diverse human languages. Unfortunately, achieving\nthis highly desirable crosslingual alignment by human labor is very costly and\nerrorprone. Thus, we propose MTransE, a translation-based model for\nmultilingual knowledge graph embeddings, to provide a simple and automated\nsolution. By encoding entities and relations of each language in a separated\nembedding space, MTransE provides transitions for each embedding vector to its\ncross-lingual counterparts in other spaces, while preserving the\nfunctionalities of monolingual embeddings. We deploy three different techniques\nto represent cross-lingual transitions, namely axis calibration, translation\nvectors, and linear transformations, and derive five variants for MTransE using\ndifferent loss functions. Our models can be trained on partially aligned\ngraphs, where just a small portion of triples are aligned with their\ncross-lingual counterparts. The experiments on cross-lingual entity matching\nand triple-wise alignment verification show promising results, with some\nvariants consistently outperforming others on different tasks. We also explore\nhow MTransE preserves the key properties of its monolingual counterpart TransE.\n", "versions": [{"version": "v1", "created": "Sat, 12 Nov 2016 04:28:04 GMT"}, {"version": "v2", "created": "Tue, 21 Feb 2017 01:20:30 GMT"}, {"version": "v3", "created": "Wed, 17 May 2017 19:33:53 GMT"}], "update_date": "2017-05-19", "authors_parsed": [["Chen", "Muhao", ""], ["Tian", "Yingtao", ""], ["Yang", "Mohan", ""], ["Zaniolo", "Carlo", ""]]}, {"id": "1611.04010", "submitter": "Rohan Mahadev", "authors": "Vrishabh Ajay Lakhani and Rohan Mahadev", "title": "Multi-Language Identification Using Convolutional Recurrent Neural\n  Network", "comments": "Further experiments were performed on the model using LibriVox speech\n  dataset and it was found that a Time Distributed CRNN model performed better\n  and represented our initial ideas about the speaker recognition task better.\n  The dataset contains speech in three languages - English, Spanish and Czech.\n  A report on our findings along with experimental results will be published\n  soon", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language Identification, being an important aspect of Automatic Speaker\nRecognition has had many changes and new approaches to ameliorate performance\nover the last decade. We compare the performance of using audio spectrum in the\nlog scale and using Polyphonic sound sequences from raw audio samples to train\nthe neural network and to classify speech as either English or Spanish. To\nachieve this, we use the novel approach of using a Convolutional Recurrent\nNeural Network using Long Short Term Memory (LSTM) or a Gated Recurrent Unit\n(GRU) for forward propagation of the neural network. Our hypothesis is that the\nperformance of using polyphonic sound sequence as features and both LSTM and\nGRU as the gating mechanisms for the neural network outperform the traditional\nMFCC features using a unidirectional Deep Neural Network.\n", "versions": [{"version": "v1", "created": "Sat, 12 Nov 2016 15:59:22 GMT"}, {"version": "v2", "created": "Thu, 18 May 2017 09:15:26 GMT"}], "update_date": "2017-05-19", "authors_parsed": [["Lakhani", "Vrishabh Ajay", ""], ["Mahadev", "Rohan", ""]]}, {"id": "1611.04033", "submitter": "Ibrahim Abu El-Khair", "authors": "Ibrahim Abu El-khair", "title": "1.5 billion words Arabic Corpus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This study is an attempt to build a contemporary linguistic corpus for Arabic\nlanguage. The corpus produced, is a text corpus includes more than five million\nnewspaper articles. It contains over a billion and a half words in total, out\nof which, there is about three million unique words. The data were collected\nfrom newspaper articles in ten major news sources from eight Arabic countries,\nover a period of fourteen years. The corpus was encoded with two types of\nencoding, namely: UTF-8, and Windows CP-1256. Also it was marked with two\nmark-up languages, namely: SGML, and XML.\n", "versions": [{"version": "v1", "created": "Sat, 12 Nov 2016 18:41:58 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["El-khair", "Ibrahim Abu", ""]]}, {"id": "1611.04052", "submitter": "Xiaojun Zhang", "authors": "Xiaojun Zhang", "title": "Semi-automatic Simultaneous Interpreting Quality Evaluation", "comments": null, "journal-ref": "International Journal on Natural Language Computing (IJNLC) Vol.\n  5, No.5, October 2016", "doi": "10.5121/ijnlc.2016.5501", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing interpreting needs a more objective and automatic measurement. We\nhold a basic idea that 'translating means translating meaning' in that we can\nassessment interpretation quality by comparing the meaning of the interpreting\noutput with the source input. That is, a translation unit of a 'chunk' named\nFrame which comes from frame semantics and its components named Frame Elements\n(FEs) which comes from Frame Net are proposed to explore their matching rate\nbetween target and source texts. A case study in this paper verifies the\nusability of semi-automatic graded semantic-scoring measurement for human\nsimultaneous interpreting and shows how to use frame and FE matches to score.\nExperiments results show that the semantic-scoring metrics have a significantly\ncorrelation coefficient with human judgment.\n", "versions": [{"version": "v1", "created": "Sat, 12 Nov 2016 23:24:00 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Zhang", "Xiaojun", ""]]}, {"id": "1611.04122", "submitter": "Yangqiu Song", "authors": "Yangqiu Song and Stephen Mayhew and Dan Roth", "title": "Cross-lingual Dataless Classification for Languages with Small Wikipedia\n  Presence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an approach to classify documents in any language into an\nEnglish topical label space, without any text categorization training data. The\napproach, Cross-Lingual Dataless Document Classification (CLDDC) relies on\nmapping the English labels or short category description into a Wikipedia-based\nsemantic representation, and on the use of the target language Wikipedia.\nConsequently, performance could suffer when Wikipedia in the target language is\nsmall. In this paper, we focus on languages with small Wikipedias,\n(Small-Wikipedia languages, SWLs). We use a word-level dictionary to convert\ndocuments in a SWL to a large-Wikipedia language (LWLs), and then perform CLDDC\nbased on the LWL's Wikipedia. This approach can be applied to thousands of\nlanguages, which can be contrasted with machine translation, which is a\nsupervision heavy approach and can be done for about 100 languages. We also\ndevelop a ranking algorithm that makes use of language similarity metrics to\nautomatically select a good LWL, and show that this significantly improves\nclassification of SWLs' documents, performing comparably to the best bridge\npossible.\n", "versions": [{"version": "v1", "created": "Sun, 13 Nov 2016 12:20:33 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Song", "Yangqiu", ""], ["Mayhew", "Stephen", ""], ["Roth", "Dan", ""]]}, {"id": "1611.04125", "submitter": "Han Xu", "authors": "Xu Han, Zhiyuan Liu, Maosong Sun", "title": "Joint Representation Learning of Text and Knowledge for Knowledge Graph\n  Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Joint representation learning of text and knowledge within a unified semantic\nspace enables us to perform knowledge graph completion more accurately. In this\nwork, we propose a novel framework to embed words, entities and relations into\nthe same continuous vector space. In this model, both entity and relation\nembeddings are learned by taking knowledge graph and plain text into\nconsideration. In experiments, we evaluate the joint learning model on three\ntasks including entity prediction, relation prediction and relation\nclassification from text. The experiment results show that our model can\nsignificantly and consistently improve the performance on the three tasks as\ncompared with other baselines.\n", "versions": [{"version": "v1", "created": "Sun, 13 Nov 2016 12:32:20 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Han", "Xu", ""], ["Liu", "Zhiyuan", ""], ["Sun", "Maosong", ""]]}, {"id": "1611.04230", "submitter": "Ramesh Nallapati", "authors": "Ramesh Nallapati, Feifei Zhai, Bowen Zhou", "title": "SummaRuNNer: A Recurrent Neural Network based Sequence Model for\n  Extractive Summarization of Documents", "comments": "Published at AAAI 2017, The Thirty-First AAAI Conference on\n  Artificial Intelligence (AAAI-2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present SummaRuNNer, a Recurrent Neural Network (RNN) based sequence model\nfor extractive summarization of documents and show that it achieves performance\nbetter than or comparable to state-of-the-art. Our model has the additional\nadvantage of being very interpretable, since it allows visualization of its\npredictions broken up by abstract features such as information content,\nsalience and novelty. Another novel contribution of our work is abstractive\ntraining of our extractive model that can train on human generated reference\nsummaries alone, eliminating the need for sentence-level extractive labels.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 02:44:14 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Nallapati", "Ramesh", ""], ["Zhai", "Feifei", ""], ["Zhou", "Bowen", ""]]}, {"id": "1611.04233", "submitter": "Shuming Ma", "authors": "Shuming Ma, Xu Sun", "title": "A New Recurrent Neural CRF for Learning Non-linear Edge Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional Random Field (CRF) and recurrent neural models have achieved\nsuccess in structured prediction. More recently, there is a marriage of CRF and\nrecurrent neural models, so that we can gain from both non-linear dense\nfeatures and globally normalized CRF objective. These recurrent neural CRF\nmodels mainly focus on encode node features in CRF undirected graphs. However,\nedge features prove important to CRF in structured prediction. In this work, we\nintroduce a new recurrent neural CRF model, which learns non-linear edge\nfeatures, and thus makes non-linear features encoded completely. We compare our\nmodel with different neural models in well-known structured prediction tasks.\nExperiments show that our model outperforms state-of-the-art methods in NP\nchunking, shallow parsing, Chinese word segmentation and POS tagging.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 02:48:46 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Ma", "Shuming", ""], ["Sun", "Xu", ""]]}, {"id": "1611.04234", "submitter": "Hangfeng He", "authors": "Hangfeng He, Xu Sun", "title": "F-Score Driven Max Margin Neural Network for Named Entity Recognition in\n  Chinese Social Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on named entity recognition (NER) for Chinese social media. With\nmassive unlabeled text and quite limited labelled corpus, we propose a\nsemi-supervised learning model based on B-LSTM neural network. To take\nadvantage of traditional methods in NER such as CRF, we combine transition\nprobability with deep learning in our model. To bridge the gap between label\naccuracy and F-score of NER, we construct a model which can be directly trained\non F-score. When considering the instability of F-score driven method and\nmeaningful information provided by label accuracy, we propose an integrated\nmethod to train on both F-score and label accuracy. Our integrated model yields\n7.44\\% improvement over previous state-of-the-art result.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 02:50:33 GMT"}, {"version": "v2", "created": "Tue, 11 Apr 2017 10:57:34 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["He", "Hangfeng", ""], ["Sun", "Xu", ""]]}, {"id": "1611.04244", "submitter": "Ramesh Nallapati", "authors": "Ramesh Nallapati, Bowen Zhou, Mingbo Ma", "title": "Classify or Select: Neural Architectures for Extractive Document\n  Summarization", "comments": "arXiv admin note: text overlap with arXiv:1611.04230", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two novel and contrasting Recurrent Neural Network (RNN) based\narchitectures for extractive summarization of documents. The Classifier based\narchitecture sequentially accepts or rejects each sentence in the original\ndocument order for its membership in the final summary. The Selector\narchitecture, on the other hand, is free to pick one sentence at a time in any\narbitrary order to piece together the summary. Our models under both\narchitectures jointly capture the notions of salience and redundancy of\nsentences. In addition, these models have the advantage of being very\ninterpretable, since they allow visualization of their predictions broken up by\nabstract features such as information content, salience and redundancy. We show\nthat our models reach or outperform state-of-the-art supervised models on two\ndifferent corpora. We also recommend the conditions under which one\narchitecture is superior to the other based on experimental evidence.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 03:54:10 GMT"}], "update_date": "2017-01-05", "authors_parsed": [["Nallapati", "Ramesh", ""], ["Zhou", "Bowen", ""], ["Ma", "Mingbo", ""]]}, {"id": "1611.04326", "submitter": "Aditya Joshi", "authors": "Aditya Joshi, Prayas Jain, Pushpak Bhattacharyya, Mark Carman", "title": "`Who would have thought of that!': A Hierarchical Topic Model for\n  Extraction of Sarcasm-prevalent Topics and Sarcasm Detection", "comments": "This version of the paper contains corrected changes, after the\n  camera -ready submission. These changes were observed based on an issue in\n  the output returned by SVM Perf. This paper will be presented at ExPROM\n  workshop at COLING 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic Models have been reported to be beneficial for aspect-based sentiment\nanalysis. This paper reports a simple topic model for sarcasm detection, a\nfirst, to the best of our knowledge. Designed on the basis of the intuition\nthat sarcastic tweets are likely to have a mixture of words of both sentiments\nas against tweets with literal sentiment (either positive or negative), our\nhierarchical topic model discovers sarcasm-prevalent topics and topic-level\nsentiment. Using a dataset of tweets labeled using hashtags, the model\nestimates topic-level, and sentiment-level distributions. Our evaluation shows\nthat topics such as `work', `gun laws', `weather' are sarcasm-prevalent topics.\nOur model is also able to discover the mixture of sentiment-bearing words that\nexist in a text of a given sentiment-related label. Finally, we apply our model\nto predict sarcasm in tweets. We outperform two prior work based on statistical\nclassifiers with specific features, by around 25\\%.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 10:40:44 GMT"}, {"version": "v2", "created": "Tue, 22 Nov 2016 10:55:56 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["Joshi", "Aditya", ""], ["Jain", "Prayas", ""], ["Bhattacharyya", "Pushpak", ""], ["Carman", "Mark", ""]]}, {"id": "1611.04358", "submitter": "Weijie Huang", "authors": "Weijie Huang, Jun Wang", "title": "Character-level Convolutional Network for Text Classification Applied to\n  Chinese Corpus", "comments": "MSc Thesis, 44 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article provides an interesting exploration of character-level\nconvolutional neural network solving Chinese corpus text classification\nproblem. We constructed a large-scale Chinese language dataset, and the result\nshows that character-level convolutional neural network works better on Chinese\ncorpus than its corresponding pinyin format dataset. This is the first time\nthat character-level convolutional neural network applied to text\nclassification problem.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 12:24:27 GMT"}, {"version": "v2", "created": "Tue, 15 Nov 2016 14:41:23 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Huang", "Weijie", ""], ["Wang", "Jun", ""]]}, {"id": "1611.04361", "submitter": "Marek Rei", "authors": "Marek Rei, Gamal K.O. Crichton, Sampo Pyysalo", "title": "Attending to Characters in Neural Sequence Labeling Models", "comments": "Proceedings of COLING 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence labeling architectures use word embeddings for capturing similarity,\nbut suffer when handling previously unseen or rare words. We investigate\ncharacter-level extensions to such models and propose a novel architecture for\ncombining alternative word representations. By using an attention mechanism,\nthe model is able to dynamically decide how much information to use from a\nword- or character-level component. We evaluated different architectures on a\nrange of sequence labeling datasets, and character-level extensions were found\nto improve performance on every benchmark. In addition, the proposed\nattention-based architecture delivered the best results even with a smaller\nnumber of trainable parameters.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 12:36:07 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Rei", "Marek", ""], ["Crichton", "Gamal K. O.", ""], ["Pyysalo", "Sampo", ""]]}, {"id": "1611.04491", "submitter": "Jinying Chen", "authors": "Jinying Chen, Abhyuday N. Jagannatha, Samah J. Jarad, Hong Yu", "title": "Ranking medical jargon in electronic health record notes by adapted\n  distant supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: Allowing patients to access their own electronic health record\n(EHR) notes through online patient portals has the potential to improve\npatient-centered care. However, medical jargon, which abounds in EHR notes, has\nbeen shown to be a barrier for patient EHR comprehension. Existing knowledge\nbases that link medical jargon to lay terms or definitions play an important\nrole in alleviating this problem but have low coverage of medical jargon in\nEHRs. We developed a data-driven approach that mines EHRs to identify and rank\nmedical jargon based on its importance to patients, to support the building of\nEHR-centric lay language resources.\n  Methods: We developed an innovative adapted distant supervision (ADS) model\nbased on support vector machines to rank medical jargon from EHRs. For distant\nsupervision, we utilized the open-access, collaborative consumer health\nvocabulary, a large, publicly available resource that links lay terms to\nmedical jargon. We explored both knowledge-based features from the Unified\nMedical Language System and distributed word representations learned from\nunlabeled large corpora. We evaluated the ADS model using physician-identified\nimportant medical terms.\n  Results: Our ADS model significantly surpassed two state-of-the-art automatic\nterm recognition methods, TF*IDF and C-Value, yielding 0.810 ROC-AUC versus\n0.710 and 0.667, respectively. Our model identified 10K important medical\njargon terms after ranking over 100K candidate terms mined from over 7,500 EHR\nnarratives.\n  Conclusion: Our work is an important step towards enriching lexical resources\nthat link medical jargon to lay terms/definitions to support patient EHR\ncomprehension. The identified medical jargon terms and their rankings are\navailable upon request.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 17:36:05 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Chen", "Jinying", ""], ["Jagannatha", "Abhyuday N.", ""], ["Jarad", "Samah J.", ""], ["Yu", "Hong", ""]]}, {"id": "1611.04496", "submitter": "Weiran Wang", "authors": "Wanjia He, Weiran Wang, Karen Livescu", "title": "Multi-view Recurrent Neural Acoustic Word Embeddings", "comments": "Appearing in ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has begun exploring neural acoustic word\nembeddings---fixed-dimensional vector representations of arbitrary-length\nspeech segments corresponding to words. Such embeddings are applicable to\nspeech retrieval and recognition tasks, where reasoning about whole words may\nmake it possible to avoid ambiguous sub-word representations. The main idea is\nto map acoustic sequences to fixed-dimensional vectors such that examples of\nthe same word are mapped to similar vectors, while different-word examples are\nmapped to very different vectors. In this work we take a multi-view approach to\nlearning acoustic word embeddings, in which we jointly learn to embed acoustic\nsequences and their corresponding character sequences. We use deep\nbidirectional LSTM embedding models and multi-view contrastive losses. We study\nthe effect of different loss variants, including fixed-margin and\ncost-sensitive losses. Our acoustic word embeddings improve over previous\napproaches for the task of word discrimination. We also present results on\nother tasks that are enabled by the multi-view approach, including cross-view\nword discrimination and word similarity.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 17:47:03 GMT"}, {"version": "v2", "created": "Fri, 10 Mar 2017 23:57:57 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["He", "Wanjia", ""], ["Wang", "Weiran", ""], ["Livescu", "Karen", ""]]}, {"id": "1611.04503", "submitter": "Hideki Nakayama", "authors": "Hideki Nakayama and Noriki Nishida", "title": "Zero-resource Machine Translation by Multimodal Encoder-decoder Network\n  with Multimedia Pivot", "comments": "Some error corrections in Sect.2.2 and Table 5, Machine Translation,\n  2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an approach to build a neural machine translation system with no\nsupervised resources (i.e., no parallel corpora) using multimodal embedded\nrepresentation over texts and images. Based on the assumption that text\ndocuments are often likely to be described with other multimedia information\n(e.g., images) somewhat related to the content, we try to indirectly estimate\nthe relevance between two languages. Using multimedia as the \"pivot\", we\nproject all modalities into one common hidden space where samples belonging to\nsimilar semantic concepts should come close to each other, whatever the\nobserved space of each sample is. This modality-agnostic representation is the\nkey to bridging the gap between different modalities. Putting a decoder on top\nof it, our network can flexibly draw the outputs from any input modality.\nNotably, in the testing phase, we need only source language texts as the input\nfor translation. In experiments, we tested our method on two benchmarks to show\nthat it can achieve reasonable translation performance. We compared and\ninvestigated several possible implementations and found that an end-to-end\nmodel that simultaneously optimized both rank loss in multimodal encoders and\ncross-entropy loss in decoders performed the best.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 18:07:54 GMT"}, {"version": "v2", "created": "Sun, 21 May 2017 17:36:30 GMT"}, {"version": "v3", "created": "Sun, 23 Jul 2017 15:52:08 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Nakayama", "Hideki", ""], ["Nishida", "Noriki", ""]]}, {"id": "1611.04558", "submitter": "Mike Schuster", "authors": "Melvin Johnson, Mike Schuster, Quoc V. Le, Maxim Krikun, Yonghui Wu,\n  Zhifeng Chen, Nikhil Thorat, Fernanda Vi\\'egas, Martin Wattenberg, Greg\n  Corrado, Macduff Hughes, Jeffrey Dean", "title": "Google's Multilingual Neural Machine Translation System: Enabling\n  Zero-Shot Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple solution to use a single Neural Machine Translation (NMT)\nmodel to translate between multiple languages. Our solution requires no change\nin the model architecture from our base system but instead introduces an\nartificial token at the beginning of the input sentence to specify the required\ntarget language. The rest of the model, which includes encoder, decoder and\nattention, remains unchanged and is shared across all languages. Using a shared\nwordpiece vocabulary, our approach enables Multilingual NMT using a single\nmodel without any increase in parameters, which is significantly simpler than\nprevious proposals for Multilingual NMT. Our method often improves the\ntranslation quality of all involved language pairs, even while keeping the\ntotal number of model parameters constant. On the WMT'14 benchmarks, a single\nmultilingual model achieves comparable performance for\nEnglish$\\rightarrow$French and surpasses state-of-the-art results for\nEnglish$\\rightarrow$German. Similarly, a single multilingual model surpasses\nstate-of-the-art results for French$\\rightarrow$English and\nGerman$\\rightarrow$English on WMT'14 and WMT'15 benchmarks respectively. On\nproduction corpora, multilingual models of up to twelve language pairs allow\nfor better translation of many individual pairs. In addition to improving the\ntranslation quality of language pairs that the model was trained with, our\nmodels can also learn to perform implicit bridging between language pairs never\nseen explicitly during training, showing that transfer learning and zero-shot\ntranslation is possible for neural translation. Finally, we show analyses that\nhints at a universal interlingua representation in our models and show some\ninteresting examples when mixing languages.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 20:24:39 GMT"}, {"version": "v2", "created": "Mon, 21 Aug 2017 20:33:43 GMT"}], "update_date": "2017-08-23", "authors_parsed": [["Johnson", "Melvin", ""], ["Schuster", "Mike", ""], ["Le", "Quoc V.", ""], ["Krikun", "Maxim", ""], ["Wu", "Yonghui", ""], ["Chen", "Zhifeng", ""], ["Thorat", "Nikhil", ""], ["Vi\u00e9gas", "Fernanda", ""], ["Wattenberg", "Martin", ""], ["Corrado", "Greg", ""], ["Hughes", "Macduff", ""], ["Dean", "Jeffrey", ""]]}, {"id": "1611.04642", "submitter": "Po-Sen Huang", "authors": "Yelong Shen, Po-Sen Huang, Ming-Wei Chang, Jianfeng Gao", "title": "Link Prediction using Embedded Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since large knowledge bases are typically incomplete, missing facts need to\nbe inferred from observed facts in a task called knowledge base completion. The\nmost successful approaches to this task have typically explored explicit paths\nthrough sequences of triples. These approaches have usually resorted to\nhuman-designed sampling procedures, since large knowledge graphs produce\nprohibitively large numbers of possible paths, most of which are uninformative.\nAs an alternative approach, we propose performing a single, short sequence of\ninteractive lookup operations on an embedded knowledge graph which has been\ntrained through end-to-end backpropagation to be an optimized and compressed\nversion of the initial knowledge base. Our proposed model, called Embedded\nKnowledge Graph Network (EKGN), achieves new state-of-the-art results on\npopular knowledge base completion benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 22:54:45 GMT"}, {"version": "v2", "created": "Sat, 22 Apr 2017 19:46:44 GMT"}, {"version": "v3", "created": "Sat, 28 Oct 2017 03:02:10 GMT"}, {"version": "v4", "created": "Wed, 8 Nov 2017 18:59:19 GMT"}, {"version": "v5", "created": "Sun, 22 Apr 2018 05:22:58 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Shen", "Yelong", ""], ["Huang", "Po-Sen", ""], ["Chang", "Ming-Wei", ""], ["Gao", "Jianfeng", ""]]}, {"id": "1611.04684", "submitter": "Yu Wu", "authors": "Yu Wu, Wei Wu, Zhoujun Li, Ming Zhou", "title": "Knowledge Enhanced Hybrid Neural Network for Text Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long text brings a big challenge to semantic matching due to their\ncomplicated semantic and syntactic structures. To tackle the challenge, we\nconsider using prior knowledge to help identify useful information and filter\nout noise to matching in long text. To this end, we propose a knowledge\nenhanced hybrid neural network (KEHNN). The model fuses prior knowledge into\nword representations by knowledge gates and establishes three matching channels\nwith words, sequential structures of sentences given by Gated Recurrent Units\n(GRU), and knowledge enhanced representations. The three channels are processed\nby a convolutional neural network to generate high level features for matching,\nand the features are synthesized as a matching score by a multilayer\nperceptron. The model extends the existing methods by conducting matching on\nwords, local structures of sentences, and global context of sentences.\nEvaluation results from extensive experiments on public data sets for question\nanswering and conversation show that KEHNN can significantly outperform\nthe-state-of-the-art matching models and particularly improve the performance\non pairs with long text.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 03:11:59 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Wu", "Yu", ""], ["Wu", "Wei", ""], ["Li", "Zhoujun", ""], ["Zhou", "Ming", ""]]}, {"id": "1611.04741", "submitter": "K. M. Annervaz", "authors": "Biswajit Paria, K. M. Annervaz, Ambedkar Dukkipati, Ankush Chatterjee,\n  Sanjay Podder", "title": "A Neural Architecture Mimicking Humans End-to-End for Natural Language\n  Inference", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this work we use the recent advances in representation learning to propose\na neural architecture for the problem of natural language inference. Our\napproach is aligned to mimic how a human does the natural language inference\nprocess given two statements. The model uses variants of Long Short Term Memory\n(LSTM), attention mechanism and composable neural networks, to carry out the\ntask. Each part of our model can be mapped to a clear functionality humans do\nfor carrying out the overall task of natural language inference. The model is\nend-to-end differentiable enabling training by stochastic gradient descent. On\nStanford Natural Language Inference(SNLI) dataset, the proposed model achieves\nbetter accuracy numbers than all published models in literature.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 08:48:22 GMT"}, {"version": "v2", "created": "Fri, 27 Jan 2017 05:36:05 GMT"}], "update_date": "2017-01-30", "authors_parsed": [["Paria", "Biswajit", ""], ["Annervaz", "K. M.", ""], ["Dukkipati", "Ambedkar", ""], ["Chatterjee", "Ankush", ""], ["Podder", "Sanjay", ""]]}, {"id": "1611.04798", "submitter": "Thanh-Le Ha", "authors": "Thanh-Le Ha and Jan Niehues and Alexander Waibel", "title": "Toward Multilingual Neural Machine Translation with Universal Encoder\n  and Decoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present our first attempts in building a multilingual\nNeural Machine Translation framework under a unified approach. We are then able\nto employ attention-based NMT for many-to-many multilingual translation tasks.\nOur approach does not require any special treatment on the network architecture\nand it allows us to learn minimal number of free parameters in a standard way\nof training. Our approach has shown its effectiveness in an under-resourced\ntranslation scenario with considerable improvements up to 2.6 BLEU points. In\naddition, the approach has achieved interesting and promising results when\napplied in the translation task that there is no direct parallel corpus between\nsource and target languages.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 11:47:42 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Ha", "Thanh-Le", ""], ["Niehues", "Jan", ""], ["Waibel", "Alexander", ""]]}, {"id": "1611.04822", "submitter": "Harshita Sahijwani", "authors": "Gaurav Maheshwari, Priyansh Trivedi, Harshita Sahijwani, Kunal Jha,\n  Sourish Dasgupta and Jens Lehmann", "title": "SimDoc: Topic Sequence Alignment based Document Similarity Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document similarity is the problem of estimating the degree to which a given\npair of documents has similar semantic content. An accurate document similarity\nmeasure can improve several enterprise relevant tasks such as document\nclustering, text mining, and question-answering. In this paper, we show that a\ndocument's thematic flow, which is often disregarded by bag-of-word techniques,\nis pivotal in estimating their similarity. To this end, we propose a novel\nsemantic document similarity framework, called SimDoc. We model documents as\ntopic-sequences, where topics represent latent generative clusters of related\nwords. Then, we use a sequence alignment algorithm to estimate their semantic\nsimilarity. We further conceptualize a novel mechanism to compute topic-topic\nsimilarity to fine tune our system. In our experiments, we show that SimDoc\noutperforms many contemporary bag-of-words techniques in accurately computing\ndocument similarity, and on practical applications such as document clustering.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 13:31:28 GMT"}, {"version": "v2", "created": "Sat, 11 Nov 2017 23:07:54 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Maheshwari", "Gaurav", ""], ["Trivedi", "Priyansh", ""], ["Sahijwani", "Harshita", ""], ["Jha", "Kunal", ""], ["Dasgupta", "Sourish", ""], ["Lehmann", "Jens", ""]]}, {"id": "1611.04837", "submitter": "Michael Ward", "authors": "Sophie J. Lee, Howard Liu, and Michael D. Ward", "title": "Lost in Space: Geolocation in Event Data", "comments": null, "journal-ref": "PSRM 7 (2019) 871-888", "doi": "10.1017/psrm.2018.23", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting the \"correct\" location information from text data, i.e.,\ndetermining the place of event, has long been a goal for automated text\nprocessing. To approximate human-like coding schema, we introduce a supervised\nmachine learning algorithm that classifies each location word to be either\ncorrect or incorrect. We use news articles collected from around the world\n(Integrated Crisis Early Warning System [ICEWS] data and Open Event Data\nAlliance [OEDA] data) to test our algorithm that consists of two stages. In the\nfeature selection stage, we extract contextual information from texts, namely,\nthe N-gram patterns for location words, the frequency of mention, and the\ncontext of the sentences containing location words. In the classification\nstage, we use three classifiers to estimate the model parameters in the\ntraining set and then to predict whether a location word in the test set news\narticles is the place of the event. The validation results show that our\nalgorithm improves the accuracy rate of the current geolocation methods of\ndictionary approach by as much as 25%.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 20:50:03 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Lee", "Sophie J.", ""], ["Liu", "Howard", ""], ["Ward", "Michael D.", ""]]}, {"id": "1611.04841", "submitter": "Weibing Deng", "authors": "R.R. Xie, W.B. Deng, D.J. Wang and L.P. Csernai", "title": "Quantitative Entropy Study of Language Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the entropy of Chinese and English texts, based on characters in\ncase of Chinese texts and based on words for both languages. Significant\ndifferences are found between the languages and between different personal\nstyles of debating partners. The entropy analysis points in the direction of\nlower entropy, that is of higher complexity. Such a text analysis would be\napplied for individuals of different styles, a single individual at different\nage, as well as different groups of the population.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 10:53:40 GMT"}, {"version": "v2", "created": "Sun, 15 Jan 2017 03:59:14 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Xie", "R. R.", ""], ["Deng", "W. B.", ""], ["Wang", "D. J.", ""], ["Csernai", "L. P.", ""]]}, {"id": "1611.04842", "submitter": "Francesco Fumarola", "authors": "Francesco Fumarola", "title": "The Role of Word Length in Semantic Topology", "comments": "17 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A topological argument is presented concering the structure of semantic\nspace, based on the negative correlation between polysemy and word length. The\nresulting graph structure is applied to the modeling of free-recall\nexperiments, resulting in predictions on the comparative values of recall\nprobabilities. Associative recall is found to favor longer words whereas\nsequential recall is found to favor shorter words. Data from the PEERS\nexperiments of Lohnas et al. (2015) and Healey and Kahana (2016) confirm both\npredictons, with correlation coefficients $r_{seq}= -0.17$ and $r_{ass}=\n+0.17$. The argument is then applied to predicting global properties of list\nrecall, which leads to a novel explanation for the word-length effect based on\nthe optimization of retrieval strategies.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 14:12:41 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Fumarola", "Francesco", ""]]}, {"id": "1611.04887", "submitter": "Ganesh J", "authors": "J Ganesh, Manish Gupta, Vasudeva Varma", "title": "Interpreting the Syntactic and Social Elements of the Tweet\n  Representations via Elementary Property Prediction Tasks", "comments": "Presented at NIPS 2016 Workshop on Interpretable Machine Learning in\n  Complex Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in social media analysis is experiencing a recent surge with a large\nnumber of works applying representation learning models to solve high-level\nsyntactico-semantic tasks such as sentiment analysis, semantic textual\nsimilarity computation, hashtag prediction and so on. Although the performance\nof the representation learning models are better than the traditional baselines\nfor the tasks, little is known about the core properties of a tweet encoded\nwithin the representations. Understanding these core properties would empower\nus in making generalizable conclusions about the quality of representations.\nOur work presented here constitutes the first step in opening the black-box of\nvector embedding for social media posts, with emphasis on tweets in particular.\n  In order to understand the core properties encoded in a tweet representation,\nwe evaluate the representations to estimate the extent to which it can model\neach of those properties such as tweet length, presence of words, hashtags,\nmentions, capitalization, and so on. This is done with the help of multiple\nclassifiers which take the representation as input. Essentially, each\nclassifier evaluates one of the syntactic or social properties which are\narguably salient for a tweet. This is also the first holistic study on\nextensively analysing the ability to encode these properties for a wide variety\nof tweet representation models including the traditional unsupervised methods\n(BOW, LDA), unsupervised representation learning methods (Siamese CBOW,\nTweet2Vec) as well as supervised methods (CNN, BLSTM).\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 15:34:47 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Ganesh", "J", ""], ["Gupta", "Manish", ""], ["Varma", "Vasudeva", ""]]}, {"id": "1611.04928", "submitter": "Yong Cheng", "authors": "Yong Cheng, Yang Liu, Qian Yang, Maosong Sun and Wei Xu", "title": "Neural Machine Translation with Pivot Languages", "comments": "fix experiments and revise the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While recent neural machine translation approaches have delivered\nstate-of-the-art performance for resource-rich language pairs, they suffer from\nthe data scarcity problem for resource-scarce language pairs. Although this\nproblem can be alleviated by exploiting a pivot language to bridge the source\nand target languages, the source-to-pivot and pivot-to-target translation\nmodels are usually independently trained. In this work, we introduce a joint\ntraining algorithm for pivot-based neural machine translation. We propose three\nmethods to connect the two models and enable them to interact with each other\nduring training. Experiments on Europarl and WMT corpora show that joint\ntraining of source-to-pivot and pivot-to-target models leads to significant\nimprovements over independent training across various languages.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 16:44:54 GMT"}, {"version": "v2", "created": "Tue, 21 Feb 2017 04:13:38 GMT"}], "update_date": "2017-02-22", "authors_parsed": [["Cheng", "Yong", ""], ["Liu", "Yang", ""], ["Yang", "Qian", ""], ["Sun", "Maosong", ""], ["Xu", "Wei", ""]]}, {"id": "1611.04953", "submitter": "Xinchi Chen", "authors": "Jingjing Gong, Xinchi Chen, Xipeng Qiu, Xuanjing Huang", "title": "End-to-End Neural Sentence Ordering Using Pointer Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence ordering is one of important tasks in NLP. Previous works mainly\nfocused on improving its performance by using pair-wise strategy. However, it\nis nontrivial for pair-wise models to incorporate the contextual sentence\ninformation. In addition, error prorogation could be introduced by using the\npipeline strategy in pair-wise models. In this paper, we propose an end-to-end\nneural approach to address the sentence ordering problem, which uses the\npointer network (Ptr-Net) to alleviate the error propagation problem and\nutilize the whole contextual information. Experimental results show the\neffectiveness of the proposed model. Source codes and dataset of this paper are\navailable.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 17:38:10 GMT"}, {"version": "v2", "created": "Fri, 25 Nov 2016 16:38:30 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Gong", "Jingjing", ""], ["Chen", "Xinchi", ""], ["Qiu", "Xipeng", ""], ["Huang", "Xuanjing", ""]]}, {"id": "1611.04989", "submitter": "Raj Nath Patel", "authors": "Raj Nath Patel, Prakash B. Pimpale, M Sasikumar", "title": "Recurrent Neural Network based Part-of-Speech Tagger for Code-Mixed\n  Social Media Text", "comments": "7 pages, Published at the Tool Contest on POS tagging for Indian\n  Social Media Text, ICON 2016", "journal-ref": "In Proceedings of the Tool Contest on POS tagging for Indian\n  Social Media Text, ICON 2016", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes Centre for Development of Advanced Computing's (CDACM)\nsubmission to the shared task-'Tool Contest on POS tagging for Code-Mixed\nIndian Social Media (Facebook, Twitter, and Whatsapp) Text', collocated with\nICON-2016. The shared task was to predict Part of Speech (POS) tag at word\nlevel for a given text. The code-mixed text is generated mostly on social media\nby multilingual users. The presence of the multilingual words,\ntransliterations, and spelling variations make such content linguistically\ncomplex. In this paper, we propose an approach to POS tag code-mixed social\nmedia text using Recurrent Neural Network Language Model (RNN-LM) architecture.\nWe submitted the results for Hindi-English (hi-en), Bengali-English (bn-en),\nand Telugu-English (te-en) code-mixed data.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 19:02:35 GMT"}, {"version": "v2", "created": "Wed, 16 Nov 2016 04:28:06 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Patel", "Raj Nath", ""], ["Pimpale", "Prakash B.", ""], ["Sasikumar", "M", ""]]}, {"id": "1611.05010", "submitter": "Kejun Huang", "authors": "Kejun Huang, Xiao Fu, Nicholas D. Sidiropoulos", "title": "Anchor-Free Correlated Topic Modeling: Identifiability and Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In topic modeling, many algorithms that guarantee identifiability of the\ntopics have been developed under the premise that there exist anchor words --\ni.e., words that only appear (with positive probability) in one topic.\nFollow-up work has resorted to three or higher-order statistics of the data\ncorpus to relax the anchor word assumption. Reliable estimates of higher-order\nstatistics are hard to obtain, however, and the identification of topics under\nthose models hinges on uncorrelatedness of the topics, which can be\nunrealistic. This paper revisits topic modeling based on second-order moments,\nand proposes an anchor-free topic mining framework. The proposed approach\nguarantees the identification of the topics under a much milder condition\ncompared to the anchor-word assumption, thereby exhibiting much better\nrobustness in practice. The associated algorithm only involves one\neigen-decomposition and a few small linear programs. This makes it easy to\nimplement and scale up to very large problem instances. Experiments using the\nTDT2 and Reuters-21578 corpus demonstrate that the proposed anchor-free\napproach exhibits very favorable performance (measured using coherence,\nsimilarity count, and clustering accuracy metrics) compared to the prior art.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 20:06:40 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Huang", "Kejun", ""], ["Fu", "Xiao", ""], ["Sidiropoulos", "Nicholas D.", ""]]}, {"id": "1611.05104", "submitter": "Sabeek Pradhan", "authors": "Shayne Longpre, Sabeek Pradhan, Caiming Xiong, Richard Socher", "title": "A Way out of the Odyssey: Analyzing and Combining Recent Insights for\n  LSTMs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LSTMs have become a basic building block for many deep NLP models. In recent\nyears, many improvements and variations have been proposed for deep sequence\nmodels in general, and LSTMs in particular. We propose and analyze a series of\naugmentations and modifications to LSTM networks resulting in improved\nperformance for text classification datasets. We observe compounding\nimprovements on traditional LSTMs using Monte Carlo test-time model averaging,\naverage pooling, and residual connections, along with four other suggested\nmodifications. Our analysis provides a simple, reliable, and high quality\nbaseline model.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2016 00:53:01 GMT"}, {"version": "v2", "created": "Sat, 17 Dec 2016 06:47:05 GMT"}], "update_date": "2016-12-20", "authors_parsed": [["Longpre", "Shayne", ""], ["Pradhan", "Sabeek", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "1611.05118", "submitter": "Mohit Iyyer", "authors": "Mohit Iyyer, Varun Manjunatha, Anupam Guha, Yogarshi Vyas, Jordan\n  Boyd-Graber, Hal Daum\\'e III, Larry Davis", "title": "The Amazing Mysteries of the Gutter: Drawing Inferences Between Panels\n  in Comic Book Narratives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual narrative is often a combination of explicit information and judicious\nomissions, relying on the viewer to supply missing details. In comics, most\nmovements in time and space are hidden in the \"gutters\" between panels. To\nfollow the story, readers logically connect panels together by inferring unseen\nactions through a process called \"closure\". While computers can now describe\nwhat is explicitly depicted in natural images, in this paper we examine whether\nthey can understand the closure-driven narratives conveyed by stylized artwork\nand dialogue in comic book panels. We construct a dataset, COMICS, that\nconsists of over 1.2 million panels (120 GB) paired with automatic textbox\ntranscriptions. An in-depth analysis of COMICS demonstrates that neither text\nnor image alone can tell a comic book story, so a computer must understand both\nmodalities to keep up with the plot. We introduce three cloze-style tasks that\nask models to predict narrative and character-centric aspects of a panel given\nn preceding panels as context. Various deep neural architectures underperform\nhuman baselines on these tasks, suggesting that COMICS contains fundamental\nchallenges for both vision and language.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2016 02:16:09 GMT"}, {"version": "v2", "created": "Sun, 7 May 2017 20:26:24 GMT"}], "update_date": "2017-05-09", "authors_parsed": [["Iyyer", "Mohit", ""], ["Manjunatha", "Varun", ""], ["Guha", "Anupam", ""], ["Vyas", "Yogarshi", ""], ["Boyd-Graber", "Jordan", ""], ["Daum\u00e9", "Hal", "III"], ["Davis", "Larry", ""]]}, {"id": "1611.05239", "submitter": "Kimmo Kettunen", "authors": "Kimmo Kettunen", "title": "How to do lexical quality estimation of a large OCRed historical Finnish\n  newspaper collection with scarce resources", "comments": "23 pages, 6 tables, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The National Library of Finland has digitized the historical newspapers\npublished in Finland between 1771 and 1910. This collection contains\napproximately 1.95 million pages in Finnish and Swedish. Finnish part of the\ncollection consists of about 2.40 billion words. The National Library's Digital\nCollections are offered via the digi.kansalliskirjasto.fi web service, also\nknown as Digi. Part of the newspaper material (from 1771 to 1874) is also\navailable freely downloadable in The Language Bank of Finland provided by the\nFINCLARIN consortium. The collection can also be accessed through the Korp\nenvironment that has been developed by Spr{\\aa}kbanken at the University of\nGothenburg and extended by FINCLARIN team at the University of Helsinki to\nprovide concordances of text resources. A Cranfield style information retrieval\ntest collection has also been produced out of a small part of the Digi\nnewspaper material at the University of Tampere.\n  Quality of OCRed collections is an important topic in digital humanities, as\nit affects general usability and searchability of collections. There is no\nsingle available method to assess quality of large collections, but different\nmethods can be used to approximate quality. This paper discusses different\ncorpus analysis style methods to approximate overall lexical quality of the\nFinnish part of the Digi collection. Methods include usage of parallel samples\nand word error rates, usage of morphological analyzers, frequency analysis of\nwords and comparisons to comparable edited lexical data. Our aim in the quality\nanalysis is twofold: firstly to analyze the present state of the lexical data\nand secondly, to establish a set of assessment methods that build up a compact\nprocedure for quality assessment after e.g. new OCRing or post correction of\nthe material. In the discussion part of the paper we shall synthesize results\nof our different analyses.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2016 12:04:19 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 12:24:12 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Kettunen", "Kimmo", ""]]}, {"id": "1611.05360", "submitter": "Javier De La Rosa", "authors": "Javier de la Rosa and Juan-Luis Su\\'arez", "title": "The Life of Lazarillo de Tormes and of His Machine Learning Adversities", "comments": "66 pages, 11 figures", "journal-ref": "Lemir: Revista de Literatura Espa\\~nola Medieval y del\n  Renacimiento, 20 (2016)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Summit work of the Spanish Golden Age and forefather of the so-called\npicaresque novel, The Life of Lazarillo de Tormes and of His Fortunes and\nAdversities still remains an anonymous text. Although distinguished scholars\nhave tried to attribute it to different authors based on a variety of criteria,\na consensus has yet to be reached. The list of candidates is long and not all\nof them enjoy the same support within the scholarly community. Analyzing their\nworks from a data-driven perspective and applying machine learning techniques\nfor style and text fingerprinting, we shed light on the authorship of the\nLazarillo. As in a state-of-the-art survey, we discuss the methods used and how\nthey perform in our specific case. According to our methodology, the most\nlikely author seems to be Juan Arce de Ot\\'alora, closely followed by Alfonso\nde Vald\\'es. The method states that not certain attribution can be made with\nthe given corpus.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2016 16:55:42 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["de la Rosa", "Javier", ""], ["Su\u00e1rez", "Juan-Luis", ""]]}, {"id": "1611.05379", "submitter": "Roger Moore", "authors": "Prof. Roger K. Moore", "title": "PCT and Beyond: Towards a Computational Framework for `Intelligent'\n  Communicative Systems", "comments": "To appear in A. McElhone & W. Mansell (Eds.), Living Control Systems\n  IV: Perceptual Control Theory and the Future of the Life and Social Sciences,\n  Benchmark Publications Inc", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.HC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed increasing interest in the potential benefits of\n`intelligent' autonomous machines such as robots. Honda's Asimo humanoid robot,\niRobot's Roomba robot vacuum cleaner and Google's driverless cars have fired\nthe imagination of the general public, and social media buzz with speculation\nabout a utopian world of helpful robot assistants or the coming robot\napocalypse! However, there is a long way to go before autonomous systems reach\nthe level of capabilities required for even the simplest of tasks involving\nhuman-robot interaction - especially if it involves communicative behaviour\nsuch as speech and language. Of course the field of Artificial Intelligence\n(AI) has made great strides in these areas, and has moved on from abstract\nhigh-level rule-based paradigms to embodied architectures whose operations are\ngrounded in real physical environments. What is still missing, however, is an\noverarching theory of intelligent communicative behaviour that informs\nsystem-level design decisions in order to provide a more coherent approach to\nsystem integration. This chapter introduces the beginnings of such a framework\ninspired by the principles of Perceptual Control Theory (PCT). In particular,\nit is observed that PCT has hitherto tended to view perceptual processes as a\nrelatively straightforward series of transformations from sensation to\nperception, and has overlooked the potential of powerful generative model-based\nsolutions that have emerged in practical fields such as visual or auditory\nscene analysis. Starting from first principles, a sequence of arguments is\npresented which not only shows how these ideas might be integrated into PCT,\nbut which also extend PCT towards a remarkably symmetric architecture for a\nneeds-driven communicative agent. It is concluded that, if behaviour is the\ncontrol of perception, then perception is the simulation of behaviour.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2016 17:32:10 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Moore", "Prof. Roger K.", ""]]}, {"id": "1611.05384", "submitter": "Xinchi Chen", "authors": "Xinchi Chen, Xipeng Qiu, Xuanjing Huang", "title": "A Feature-Enriched Neural Model for Joint Chinese Word Segmentation and\n  Part-of-Speech Tagging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, neural network models for natural language processing tasks have\nbeen increasingly focused on for their ability of alleviating the burden of\nmanual feature engineering. However, the previous neural models cannot extract\nthe complicated feature compositions as the traditional methods with discrete\nfeatures. In this work, we propose a feature-enriched neural model for joint\nChinese word segmentation and part-of-speech tagging task. Specifically, to\nsimulate the feature templates of traditional discrete feature based models, we\nuse different filters to model the complex compositional features with\nconvolutional and pooling layer, and then utilize long distance dependency\ninformation with recurrent layer. Experimental results on five different\ndatasets show the effectiveness of our proposed model.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2016 17:47:57 GMT"}, {"version": "v2", "created": "Sun, 2 Jul 2017 08:27:53 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Chen", "Xinchi", ""], ["Qiu", "Xipeng", ""], ["Huang", "Xuanjing", ""]]}, {"id": "1611.05527", "submitter": "Tsubasa Ochiai", "authors": "Tsubasa Ochiai, Shigeki Matsuda, Hideyuki Watanabe, Shigeru Katagiri", "title": "Automatic Node Selection for Deep Neural Networks using Group Lasso\n  Regularization", "comments": "Submitted to ICASSP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the effect of the Group Lasso (gLasso) regularizer in selecting\nthe salient nodes of Deep Neural Network (DNN) hidden layers by applying a\nDNN-HMM hybrid speech recognizer to TED Talks speech data. We test two types of\ngLasso regularization, one for outgoing weight vectors and another for incoming\nweight vectors, as well as two sizes of DNNs: 2048 hidden layer nodes and 4096\nnodes. Furthermore, we compare gLasso and L2 regularizers. Our experiment\nresults demonstrate that our DNN training, in which the gLasso regularizer was\nembedded, successfully selected the hidden layer nodes that are necessary and\nsufficient for achieving high classification power.\n", "versions": [{"version": "v1", "created": "Thu, 17 Nov 2016 01:43:01 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Ochiai", "Tsubasa", ""], ["Matsuda", "Shigeki", ""], ["Watanabe", "Hideyuki", ""], ["Katagiri", "Shigeru", ""]]}, {"id": "1611.05546", "submitter": "Damien Teney", "authors": "Damien Teney, Anton van den Hengel", "title": "Zero-Shot Visual Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Part of the appeal of Visual Question Answering (VQA) is its promise to\nanswer new questions about previously unseen images. Most current methods\ndemand training questions that illustrate every possible concept, and will\ntherefore never achieve this capability, since the volume of required training\ndata would be prohibitive. Answering general questions about images requires\nmethods capable of Zero-Shot VQA, that is, methods able to answer questions\nbeyond the scope of the training questions. We propose a new evaluation\nprotocol for VQA methods which measures their ability to perform Zero-Shot VQA,\nand in doing so highlights significant practical deficiencies of current\napproaches, some of which are masked by the biases in current datasets. We\npropose and evaluate several strategies for achieving Zero-Shot VQA, including\nmethods based on pretrained word embeddings, object classifiers with semantic\nembeddings, and test-time retrieval of example images. Our extensive\nexperiments are intended to serve as baselines for Zero-Shot VQA, and they also\nachieve state-of-the-art performance in the standard VQA evaluation setting.\n", "versions": [{"version": "v1", "created": "Thu, 17 Nov 2016 03:21:00 GMT"}, {"version": "v2", "created": "Sun, 20 Nov 2016 21:51:24 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Teney", "Damien", ""], ["Hengel", "Anton van den", ""]]}, {"id": "1611.05774", "submitter": "Adhiguna Kuncoro", "authors": "Adhiguna Kuncoro and Miguel Ballesteros and Lingpeng Kong and Chris\n  Dyer and Graham Neubig and Noah A. Smith", "title": "What Do Recurrent Neural Network Grammars Learn About Syntax?", "comments": "10 pages. To appear in EACL 2017, Valencia, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural network grammars (RNNG) are a recently proposed\nprobabilistic generative modeling family for natural language. They show\nstate-of-the-art language modeling and parsing performance. We investigate what\ninformation they learn, from a linguistic perspective, through various\nablations to the model and the data, and by augmenting the model with an\nattention mechanism (GA-RNNG) to enable closer inspection. We find that\nexplicit modeling of composition is crucial for achieving the best performance.\nThrough the attention mechanism, we find that headedness plays a central role\nin phrasal representation (with the model's latent attention largely agreeing\nwith predictions made by hand-crafted head rules, albeit with some important\ndifferences). By training grammars without nonterminal labels, we find that\nphrasal representations depend minimally on nonterminals, providing support for\nthe endocentricity hypothesis.\n", "versions": [{"version": "v1", "created": "Thu, 17 Nov 2016 16:41:41 GMT"}, {"version": "v2", "created": "Tue, 10 Jan 2017 19:15:08 GMT"}], "update_date": "2017-01-12", "authors_parsed": [["Kuncoro", "Adhiguna", ""], ["Ballesteros", "Miguel", ""], ["Kong", "Lingpeng", ""], ["Dyer", "Chris", ""], ["Neubig", "Graham", ""], ["Smith", "Noah A.", ""]]}, {"id": "1611.05962", "submitter": "Siwei Lai", "authors": "Siwei Lai", "title": "Word and Document Embeddings based on Neural Network Approaches", "comments": "PhD thesis, in Chinese, Institute of Automation, Chinese Academy of\n  Sciences, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data representation is a fundamental task in machine learning. The\nrepresentation of data affects the performance of the whole machine learning\nsystem. In a long history, the representation of data is done by feature\nengineering, and researchers aim at designing better features for specific\ntasks. Recently, the rapid development of deep learning and representation\nlearning has brought new inspiration to various domains.\n  In natural language processing, the most widely used feature representation\nis the Bag-of-Words model. This model has the data sparsity problem and cannot\nkeep the word order information. Other features such as part-of-speech tagging\nor more complex syntax features can only fit for specific tasks in most cases.\nThis thesis focuses on word representation and document representation. We\ncompare the existing systems and present our new model.\n  First, for generating word embeddings, we make comprehensive comparisons\namong existing word embedding models. In terms of theory, we figure out the\nrelationship between the two most important models, i.e., Skip-gram and GloVe.\nIn our experiments, we analyze three key points in generating word embeddings,\nincluding the model construction, the training corpus and parameter design. We\nevaluate word embeddings with three types of tasks, and we argue that they\ncover the existing use of word embeddings. Through theory and practical\nexperiments, we present some guidelines for how to generate a good word\nembedding.\n  Second, in Chinese character or word representation. We introduce the joint\ntraining of Chinese character and word. ...\n  Third, for document representation, we analyze the existing document\nrepresentation models, including recursive NNs, recurrent NNs and convolutional\nNNs. We point out the drawbacks of these models and present our new model, the\nrecurrent convolutional neural networks. ...\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2016 03:21:28 GMT"}], "update_date": "2016-11-21", "authors_parsed": [["Lai", "Siwei", ""]]}, {"id": "1611.06188", "submitter": "Yacine Jernite", "authors": "Yacine Jernite, Edouard Grave, Armand Joulin, Tomas Mikolov", "title": "Variable Computation in Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) have been used extensively and with\nincreasing success to model various types of sequential data. Much of this\nprogress has been achieved through devising recurrent units and architectures\nwith the flexibility to capture complex statistics in the data, such as long\nrange dependency or localized attention phenomena. However, while many\nsequential data (such as video, speech or language) can have highly variable\ninformation flow, most recurrent models still consume input features at a\nconstant rate and perform a constant number of computations per time step,\nwhich can be detrimental to both speed and model capacity. In this paper, we\nexplore a modification to existing recurrent units which allows them to learn\nto vary the amount of computation they perform at each step, without prior\nknowledge of the sequence's time structure. We show experimentally that not\nonly do our models require fewer operations, they also lead to better\nperformance overall on evaluation tasks.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2016 18:13:46 GMT"}, {"version": "v2", "created": "Thu, 2 Mar 2017 19:47:59 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Jernite", "Yacine", ""], ["Grave", "Edouard", ""], ["Joulin", "Armand", ""], ["Mikolov", "Tomas", ""]]}, {"id": "1611.06204", "submitter": "Volkan Cirik", "authors": "Volkan Cirik, Eduard Hovy, Louis-Philippe Morency", "title": "Visualizing and Understanding Curriculum Learning for Long Short-Term\n  Memory Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Curriculum Learning emphasizes the order of training instances in a\ncomputational learning setup. The core hypothesis is that simpler instances\nshould be learned early as building blocks to learn more complex ones. Despite\nits usefulness, it is still unknown how exactly the internal representation of\nmodels are affected by curriculum learning. In this paper, we study the effect\nof curriculum learning on Long Short-Term Memory (LSTM) networks, which have\nshown strong competency in many Natural Language Processing (NLP) problems. Our\nexperiments on sentiment analysis task and a synthetic task similar to sequence\nprediction tasks in NLP show that curriculum learning has a positive effect on\nthe LSTM's internal states by biasing the model towards building constructive\nrepresentations i.e. the internal representation at the previous timesteps are\nused as building blocks for the final prediction. We also find that smaller\nmodels significantly improves when they are trained with curriculum learning.\nLastly, we show that curriculum learning helps more when the amount of training\ndata is limited.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2016 19:38:59 GMT"}], "update_date": "2016-11-21", "authors_parsed": [["Cirik", "Volkan", ""], ["Hovy", "Eduard", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "1611.06216", "submitter": "Iulian Vlad Serban", "authors": "Iulian Vlad Serban, Ryan Lowe, Laurent Charlin, Joelle Pineau", "title": "Generative Deep Neural Networks for Dialogue: A Short Review", "comments": "6 pages, 1 figure, 3 tables; NIPS 2016 workshop on Learning Methods\n  for Dialogue", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers have recently started investigating deep neural networks for\ndialogue applications. In particular, generative sequence-to-sequence (Seq2Seq)\nmodels have shown promising results for unstructured tasks, such as word-level\ndialogue response generation. The hope is that such models will be able to\nleverage massive amounts of data to learn meaningful natural language\nrepresentations and response generation strategies, while requiring a minimum\namount of domain knowledge and hand-crafting. An important challenge is to\ndevelop models that can effectively incorporate dialogue context and generate\nmeaningful and diverse responses. In support of this goal, we review recently\nproposed models based on generative encoder-decoder neural network\narchitectures, and show that these models have better ability to incorporate\nlong-term dialogue history, to model uncertainty and ambiguity in dialogue, and\nto generate responses with high-level compositional structure.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2016 20:11:51 GMT"}], "update_date": "2016-11-21", "authors_parsed": [["Serban", "Iulian Vlad", ""], ["Lowe", "Ryan", ""], ["Charlin", "Laurent", ""], ["Pineau", "Joelle", ""]]}, {"id": "1611.06320", "submitter": "Chao-Lin Liu", "authors": "Chao-Lin Liu and Kuo-Feng Luo", "title": "Tracking Words in Chinese Poetry of Tang and Song Dynasties with the\n  China Biographical Database", "comments": "9 pages, 3 figures, Workshop on Language Technology Resources and\n  Tools for Digital Humanities (LT4DH), 26th International Conference on\n  Computational Linguistics (COLING)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale comparisons between the poetry of Tang and Song dynasties shed\nlight on how words, collocations, and expressions were used and shared among\nthe poets. That some words were used only in the Tang poetry and some only in\nthe Song poetry could lead to interesting research in linguistics. That the\nmost frequent colors are different in the Tang and Song poetry provides a trace\nof the changing social circumstances in the dynasties. Results of the current\nwork link to research topics of lexicography, semantics, and social\ntransitions. We discuss our findings and present our algorithms for efficient\ncomparisons among the poems, which are crucial for completing billion times of\ncomparisons within acceptable time.\n", "versions": [{"version": "v1", "created": "Sat, 19 Nov 2016 07:14:59 GMT"}, {"version": "v2", "created": "Sun, 29 Oct 2017 09:49:19 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Liu", "Chao-Lin", ""], ["Luo", "Kuo-Feng", ""]]}, {"id": "1611.06322", "submitter": "Dominik Wurzer Dominik Wurzer", "authors": "Yumeng Qin, Dominik Wurzer, Victor Lavrenko, Cunchen Tang", "title": "Spotting Rumors via Novelty Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rumour detection is hard because the most accurate systems operate\nretrospectively, only recognizing rumours once they have collected repeated\nsignals. By then the rumours might have already spread and caused harm. We\nintroduce a new category of features based on novelty, tailored to detect\nrumours early on. To compensate for the absence of repeated signals, we make\nuse of news wire as an additional data source. Unconfirmed (novel) information\nwith respect to the news articles is considered as an indication of rumours.\nAdditionally we introduce pseudo feedback, which assumes that documents that\nare similar to previous rumours, are more likely to also be a rumour.\nComparison with other real-time approaches shows that novelty based features in\nconjunction with pseudo feedback perform significantly better, when detecting\nrumours instantly after their publication.\n", "versions": [{"version": "v1", "created": "Sat, 19 Nov 2016 07:23:10 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Qin", "Yumeng", ""], ["Wurzer", "Dominik", ""], ["Lavrenko", "Victor", ""], ["Tang", "Cunchen", ""]]}, {"id": "1611.06423", "submitter": "Achintya Sarkar", "authors": "A. K. Sarkar, Zheng-Hua Tan", "title": "Incorporating Pass-Phrase Dependent Background Models for Text-Dependent\n  Speaker Verification", "comments": null, "journal-ref": "Computer speech Language: Volume 47,January 2018, pp. 259-271", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose pass-phrase dependent background models (PBMs) for\ntext-dependent (TD) speaker verification (SV) to integrate the pass-phrase\nidentification process into the conventional TD-SV system, where a PBM is\nderived from a text-independent background model through adaptation using the\nutterances of a particular pass-phrase. During training, pass-phrase specific\ntarget speaker models are derived from the particular PBM using the training\ndata for the respective target model. While testing, the best PBM is first\nselected for the test utterance in the maximum likelihood (ML) sense and the\nselected PBM is then used for the log likelihood ratio (LLR) calculation with\nrespect to the claimant model. The proposed method incorporates the pass-phrase\nidentification step in the LLR calculation, which is not considered in\nconventional standalone TD-SV systems. The performance of the proposed method\nis compared to conventional text-independent background model based TD-SV\nsystems using either Gaussian mixture model (GMM)-universal background model\n(UBM) or Hidden Markov model (HMM)-UBM or i-vector paradigms. In addition, we\nconsider two approaches to build PBMs: speaker-independent and\nspeaker-dependent. We show that the proposed method significantly reduces the\nerror rates of text-dependent speaker verification for the non-target types:\ntarget-wrong and imposter-wrong while it maintains comparable TD-SV performance\nwhen imposters speak a correct utterance with respect to the conventional\nsystem. Experiments are conducted on the RedDots challenge and the RSR2015\ndatabases that consist of short utterances.\n", "versions": [{"version": "v1", "created": "Sat, 19 Nov 2016 20:12:19 GMT"}, {"version": "v2", "created": "Mon, 12 Jun 2017 16:42:56 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Sarkar", "A. K.", ""], ["Tan", "Zheng-Hua", ""]]}, {"id": "1611.06459", "submitter": "Giovanni Luca Ciampaglia", "authors": "Supun Nakandala, Giovanni Luca Ciampaglia, Norman Makoto Su, Yong-Yeol\n  Ahn", "title": "Gendered Conversation in a Social Game-Streaming Platform", "comments": "10 pages, 7 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online social media and games are increasingly replacing offline social\nactivities. Social media is now an indispensable mode of communication; online\ngaming is not only a genuine social activity but also a popular spectator\nsport. With support for anonymity and larger audiences, online interaction\nshrinks social and geographical barriers. Despite such benefits, social\ndisparities such as gender inequality persist in online social media. In\nparticular, online gaming communities have been criticized for persistent\ngender disparities and objectification. As gaming evolves into a social\nplatform, persistence of gender disparity is a pressing question. Yet, there\nare few large-scale, systematic studies of gender inequality and\nobjectification in social gaming platforms. Here we analyze more than one\nbillion chat messages from Twitch, a social game-streaming platform, to study\nhow the gender of streamers is associated with the nature of conversation.\nUsing a combination of computational text analysis methods, we show that\ngendered conversation and objectification is prevalent in chats. Female\nstreamers receive significantly more objectifying comments while male streamers\nreceive more game-related comments. This difference is more pronounced for\npopular streamers. There also exists a large number of users who post only on\nfemale or male streams. Employing a neural vector-space embedding (paragraph\nvector) method, we analyze gendered chat messages and create prediction models\nthat (i) identify the gender of streamers based on messages posted in the\nchannel and (ii) identify the gender a viewer prefers to watch based on their\nchat messages. Our findings suggest that disparities in social game-streaming\nplatforms is a nuanced phenomenon that involves the gender of streamers as well\nas those who produce gendered and game-related conversation.\n", "versions": [{"version": "v1", "created": "Sun, 20 Nov 2016 01:21:31 GMT"}, {"version": "v2", "created": "Tue, 22 Nov 2016 21:49:40 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Nakandala", "Supun", ""], ["Ciampaglia", "Giovanni Luca", ""], ["Su", "Norman Makoto", ""], ["Ahn", "Yong-Yeol", ""]]}, {"id": "1611.06468", "submitter": "Rui Liu", "authors": "Rui Liu, Xiaoli Zhang", "title": "Generating machine-executable plans from end-user's natural-language\n  instructions", "comments": "16 pages, 10 figures, article submitted to Robotics and\n  Computer-Integrated Manufacturing, 2016 Aug", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is critical for advanced manufacturing machines to autonomously execute a\ntask by following an end-user's natural language (NL) instructions. However, NL\ninstructions are usually ambiguous and abstract so that the machines may\nmisunderstand and incorrectly execute the task. To address this NL-based\nhuman-machine communication problem and enable the machines to appropriately\nexecute tasks by following the end-user's NL instructions, we developed a\nMachine-Executable-Plan-Generation (exePlan) method. The exePlan method\nconducts task-centered semantic analysis to extract task-related information\nfrom ambiguous NL instructions. In addition, the method specifies machine\nexecution parameters to generate a machine-executable plan by interpreting\nabstract NL instructions. To evaluate the exePlan method, an industrial robot\nBaxter was instructed by NL to perform three types of industrial tasks {'drill\na hole', 'clean a spot', 'install a screw'}. The experiment results proved that\nthe exePlan method was effective in generating machine-executable plans from\nthe end-user's NL instructions. Such a method has the promise to endow a\nmachine with the ability of NL-instructed task execution.\n", "versions": [{"version": "v1", "created": "Sun, 20 Nov 2016 04:06:47 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Liu", "Rui", ""], ["Zhang", "Xiaoli", ""]]}, {"id": "1611.06478", "submitter": "Salman Mahmood", "authors": "Salman Mahmood, Rami Al-Rfou, Klaus Mueller", "title": "Visualizing Linguistic Shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network based models are a very powerful tool for creating word\nembeddings, the objective of these models is to group similar words together.\nThese embeddings have been used as features to improve results in various\napplications such as document classification, named entity recognition, etc.\nNeural language models are able to learn word representations which have been\nused to capture semantic shifts across time and geography. The objective of\nthis paper is to first identify and then visualize how words change meaning in\ndifferent text corpus. We will train a neural language model on texts from a\ndiverse set of disciplines philosophy, religion, fiction etc. Each text will\nalter the embeddings of the words to represent the meaning of the word inside\nthat text. We will present a computational technique to detect words that\nexhibit significant linguistic shift in meaning and usage. We then use enhanced\nscatterplots and storyline visualization to visualize the linguistic shift.\n", "versions": [{"version": "v1", "created": "Sun, 20 Nov 2016 06:50:16 GMT"}], "update_date": "2016-11-27", "authors_parsed": [["Mahmood", "Salman", ""], ["Al-Rfou", "Rami", ""], ["Mueller", "Klaus", ""]]}, {"id": "1611.06492", "submitter": "Abhinav Agarwalla", "authors": "Arnav Kumar Jain, Abhinav Agarwalla, Kumar Krishna Agrawal, Pabitra\n  Mitra", "title": "Recurrent Memory Addressing for describing videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce Key-Value Memory Networks to a multimodal setting\nand a novel key-addressing mechanism to deal with sequence-to-sequence models.\nThe proposed model naturally decomposes the problem of video captioning into\nvision and language segments, dealing with them as key-value pairs. More\nspecifically, we learn a semantic embedding (v) corresponding to each frame (k)\nin the video, thereby creating (k, v) memory slots. We propose to find the next\nstep attention weights conditioned on the previous attention distributions for\nthe key-value memory slots in the memory addressing schema. Exploiting this\nflexibility of the framework, we additionally capture spatial dependencies\nwhile mapping from the visual to semantic embedding. Experiments done on the\nYoutube2Text dataset demonstrate usefulness of recurrent key-addressing, while\nachieving competitive scores on BLEU@4, METEOR metrics against state-of-the-art\nmodels.\n", "versions": [{"version": "v1", "created": "Sun, 20 Nov 2016 10:07:54 GMT"}, {"version": "v2", "created": "Thu, 23 Mar 2017 14:01:20 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Jain", "Arnav Kumar", ""], ["Agarwalla", "Abhinav", ""], ["Agrawal", "Kumar Krishna", ""], ["Mitra", "Pabitra", ""]]}, {"id": "1611.06607", "submitter": "Jonathan Krause", "authors": "Jonathan Krause, Justin Johnson, Ranjay Krishna, Li Fei-Fei", "title": "A Hierarchical Approach for Generating Descriptive Image Paragraphs", "comments": "CVPR 2017 spotlight", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress on image captioning has made it possible to generate novel\nsentences describing images in natural language, but compressing an image into\na single sentence can describe visual content in only coarse detail. While one\nnew captioning approach, dense captioning, can potentially describe images in\nfiner levels of detail by captioning many regions within an image, it in turn\nis unable to produce a coherent story for an image. In this paper we overcome\nthese limitations by generating entire paragraphs for describing images, which\ncan tell detailed, unified stories. We develop a model that decomposes both\nimages and paragraphs into their constituent parts, detecting semantic regions\nin images and using a hierarchical recurrent neural network to reason about\nlanguage. Linguistic analysis confirms the complexity of the paragraph\ngeneration task, and thorough experiments on a new dataset of image and\nparagraph pairs demonstrate the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Sun, 20 Nov 2016 23:10:51 GMT"}, {"version": "v2", "created": "Mon, 10 Apr 2017 17:59:15 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Krause", "Jonathan", ""], ["Johnson", "Justin", ""], ["Krishna", "Ranjay", ""], ["Fei-Fei", "Li", ""]]}, {"id": "1611.06639", "submitter": "Peng Zhou", "authors": "Peng Zhou, Zhenyu Qi, Suncong Zheng, Jiaming Xu, Hongyun Bao, Bo Xu", "title": "Text Classification Improved by Integrating Bidirectional LSTM with\n  Two-dimensional Max Pooling", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Network (RNN) is one of the most popular architectures used\nin Natural Language Processsing (NLP) tasks because its recurrent structure is\nvery suitable to process variable-length text. RNN can utilize distributed\nrepresentations of words by first converting the tokens comprising each text\ninto vectors, which form a matrix. And this matrix includes two dimensions: the\ntime-step dimension and the feature vector dimension. Then most existing models\nusually utilize one-dimensional (1D) max pooling operation or attention-based\noperation only on the time-step dimension to obtain a fixed-length vector.\nHowever, the features on the feature vector dimension are not mutually\nindependent, and simply applying 1D pooling operation over the time-step\ndimension independently may destroy the structure of the feature\nrepresentation. On the other hand, applying two-dimensional (2D) pooling\noperation over the two dimensions may sample more meaningful features for\nsequence modeling tasks. To integrate the features on both dimensions of the\nmatrix, this paper explores applying 2D max pooling operation to obtain a\nfixed-length representation of the text. This paper also utilizes 2D\nconvolution to sample more meaningful information of the matrix. Experiments\nare conducted on six text classification tasks, including sentiment analysis,\nquestion classification, subjectivity classification and newsgroup\nclassification. Compared with the state-of-the-art models, the proposed models\nachieve excellent performance on 4 out of 6 tasks. Specifically, one of the\nproposed models achieves highest accuracy on Stanford Sentiment Treebank binary\nclassification and fine-grained classification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 03:26:29 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Zhou", "Peng", ""], ["Qi", "Zhenyu", ""], ["Zheng", "Suncong", ""], ["Xu", "Jiaming", ""], ["Bao", "Hongyun", ""], ["Xu", "Bo", ""]]}, {"id": "1611.06671", "submitter": "Mark Magumba", "authors": "Mark Abraham Magumba, Peter Nabende", "title": "Ontology Driven Disease Incidence Detection on Twitter", "comments": "19 pages, 7 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we address the issue of generic automated disease incidence\nmonitoring on twitter. We employ an ontology of disease related concepts and\nuse it to obtain a conceptual representation of tweets. Unlike previous key\nword based systems and topic modeling approaches, our ontological approach\nallows us to apply more stringent criteria for determining which messages are\nrelevant such as spatial and temporal characteristics whilst giving a stronger\nguarantee that the resulting models will perform well on new data that may be\nlexically divergent. We achieve this by training learners on concepts rather\nthan individual words. For training we use a dataset containing mentions of\ninfluenza and Listeria and use the learned models to classify datasets\ncontaining mentions of an arbitrary selection of other diseases. We show that\nour ontological approach achieves good performance on this task using a variety\nof Natural Language Processing Techniques. We also show that word vectors can\nbe learned directly from our concepts to achieve even better results.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 07:32:56 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Magumba", "Mark Abraham", ""], ["Nabende", "Peter", ""]]}, {"id": "1611.06722", "submitter": "Yanqing Chen", "authors": "Yanqing Chen, Steven Skiena", "title": "False-Friend Detection and Entity Matching via Unsupervised\n  Transliteration", "comments": "11 Pages, ACL style", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transliterations play an important role in multilingual entity reference\nresolution, because proper names increasingly travel between languages in news\nand social media. Previous work associated with machine translation targets\ntransliteration only single between language pairs, focuses on specific classes\nof entities (such as cities and celebrities) and relies on manual curation,\nwhich limits the expression power of transliteration in multilingual\nenvironment.\n  By contrast, we present an unsupervised transliteration model covering 69\nmajor languages that can generate good transliterations for arbitrary strings\nbetween any language pair. Our model yields top-(1, 20, 100) averages of\n(32.85%, 60.44%, 83.20%) in matching gold standard transliteration compared to\nresults from a recently-published system of (26.71%, 50.27%, 72.79%). We also\nshow the quality of our model in detecting true and false friends from\nWikipedia high frequency lexicons. Our method indicates a strong signal of\npronunciation similarity and boosts the probability of finding true friends in\n68 out of 69 languages.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 11:07:11 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Chen", "Yanqing", ""], ["Skiena", "Steven", ""]]}, {"id": "1611.06788", "submitter": "Zhiyang Teng", "authors": "Zhiyang Teng and Yue Zhang", "title": "Bidirectional Tree-Structured LSTM with Head Lexicalization", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential LSTM has been extended to model tree structures, giving\ncompetitive results for a number of tasks. Existing methods model constituent\ntrees by bottom-up combinations of constituent nodes, making direct use of\ninput word information only for leaf nodes. This is different from sequential\nLSTMs, which contain reference to input words for each node. In this paper, we\npropose a method for automatic head-lexicalization for tree-structure LSTMs,\npropagating head words from leaf nodes to every constituent node. In addition,\nenabled by head lexicalization, we build a tree LSTM in the top-down direction,\nwhich corresponds to bidirectional sequential LSTM structurally. Experiments\nshow that both extensions give better representations of tree structures. Our\nfinal model gives the best results on the Standford Sentiment Treebank and\nhighly competitive results on the TREC question type classification task.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 14:01:53 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Teng", "Zhiyang", ""], ["Zhang", "Yue", ""]]}, {"id": "1611.06933", "submitter": "Jacob Eisenstein", "authors": "Jacob Eisenstein", "title": "Unsupervised Learning for Lexicon-Based Classification", "comments": "to appear in AAAI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In lexicon-based classification, documents are assigned labels by comparing\nthe number of words that appear from two opposed lexicons, such as positive and\nnegative sentiment. Creating such words lists is often easier than labeling\ninstances, and they can be debugged by non-experts if classification\nperformance is unsatisfactory. However, there is little analysis or\njustification of this classification heuristic. This paper describes a set of\nassumptions that can be used to derive a probabilistic justification for\nlexicon-based classification, as well as an analysis of its expected accuracy.\nOne key assumption behind lexicon-based classification is that all words in\neach lexicon are equally predictive. This is rarely true in practice, which is\nwhy lexicon-based approaches are usually outperformed by supervised classifiers\nthat learn distinct weights on each word from labeled instances. This paper\nshows that it is possible to learn such weights without labeled data, by\nleveraging co-occurrence statistics across the lexicons. This offers the best\nof both worlds: light supervision in the form of lexicons, and data-driven\nclassification with higher accuracy than traditional word-counting heuristics.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 18:30:17 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Eisenstein", "Jacob", ""]]}, {"id": "1611.06950", "submitter": "Jie Mei", "authors": "Jie Mei, Aminul Islam, Yajing Wu, Abidalrahman Moh'd, Evangelos E.\n  Milios", "title": "Statistical Learning for OCR Text Correction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The accuracy of Optical Character Recognition (OCR) is crucial to the success\nof subsequent applications used in text analyzing pipeline. Recent models of\nOCR post-processing significantly improve the quality of OCR-generated text,\nbut are still prone to suggest correction candidates from limited observations\nwhile insufficiently accounting for the characteristics of OCR errors. In this\npaper, we show how to enlarge candidate suggestion space by using external\ncorpus and integrating OCR-specific features in a regression approach to\ncorrect OCR-generated errors. The evaluation results show that our model can\ncorrect 61.5% of the OCR-errors (considering the top 1 suggestion) and 71.5% of\nthe OCR-errors (considering the top 3 suggestions), for cases where the\ntheoretical correction upper-bound is 78%.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 19:00:32 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Mei", "Jie", ""], ["Islam", "Aminul", ""], ["Wu", "Yajing", ""], ["Moh'd", "Abidalrahman", ""], ["Milios", "Evangelos E.", ""]]}, {"id": "1611.06986", "submitter": "Ramon Sanabria", "authors": "Ramon Sanabria, Florian Metze and Fernando De La Torre", "title": "Robust end-to-end deep audiovisual speech recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech is one of the most effective ways of communication among humans. Even\nthough audio is the most common way of transmitting speech, very important\ninformation can be found in other modalities, such as vision. Vision is\nparticularly useful when the acoustic signal is corrupted. Multi-modal speech\nrecognition however has not yet found wide-spread use, mostly because the\ntemporal alignment and fusion of the different information sources is\nchallenging.\n  This paper presents an end-to-end audiovisual speech recognizer (AVSR), based\non recurrent neural networks (RNN) with a connectionist temporal classification\n(CTC) loss function. CTC creates sparse \"peaky\" output activations, and we\nanalyze the differences in the alignments of output targets (phonemes or\nvisemes) between audio-only, video-only, and audio-visual feature\nrepresentations. We present the first such experiments on the large vocabulary\nIBM ViaVoice database, which outperform previously published approaches on\nphone accuracy in clean and noisy conditions.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 20:08:51 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Sanabria", "Ramon", ""], ["Metze", "Florian", ""], ["De La Torre", "Fernando", ""]]}, {"id": "1611.06997", "submitter": "Hongyuan Mei", "authors": "Hongyuan Mei and Mohit Bansal and Matthew R. Walter", "title": "Coherent Dialogue with Attention-based Language Models", "comments": "To appear at AAAI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We model coherent conversation continuation via RNN-based dialogue models\nequipped with a dynamic attention mechanism. Our attention-RNN language model\ndynamically increases the scope of attention on the history as the conversation\ncontinues, as opposed to standard attention (or alignment) models with a fixed\ninput scope in a sequence-to-sequence model. This allows each generated word to\nbe associated with the most relevant words in its corresponding conversation\nhistory. We evaluate the model on two popular dialogue datasets, the\nopen-domain MovieTriples dataset and the closed-domain Ubuntu Troubleshoot\ndataset, and achieve significant improvements over the state-of-the-art and\nbaselines on several metrics, including complementary diversity-based metrics,\nhuman evaluation, and qualitative visualizations. We also show that a vanilla\nRNN with dynamic attention outperforms more complex memory models (e.g., LSTM\nand GRU) by allowing for flexible, long-distance memory. We promote further\ncoherence via topic modeling-based reranking.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 20:25:19 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Mei", "Hongyuan", ""], ["Bansal", "Mohit", ""], ["Walter", "Matthew R.", ""]]}, {"id": "1611.07139", "submitter": "Reza Rawassizadeh", "authors": "Reza Rawassizadeh, Chelsea Dobbins, Manouchehr Nourizadeh, Zahra\n  Ghamchili, Michael Pazzani", "title": "A Natural Language Query Interface for Searching Personal Information on\n  Smartwatches", "comments": "6 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, personal assistant systems, run on smartphones and use natural\nlanguage interfaces. However, these systems rely mostly on the web for finding\ninformation. Mobile and wearable devices can collect an enormous amount of\ncontextual personal data such as sleep and physical activities. These\ninformation objects and their applications are known as quantified-self, mobile\nhealth or personal informatics, and they can be used to provide a deeper\ninsight into our behavior. To our knowledge, existing personal assistant\nsystems do not support all types of quantified-self queries. In response to\nthis, we have undertaken a user study to analyze a set of \"textual\nquestions/queries\" that users have used to search their quantified-self or\nmobile health data. Through analyzing these questions, we have constructed a\nlight-weight natural language based query interface, including a text parser\nalgorithm and a user interface, to process the users' queries that have been\nused for searching quantified-self information. This query interface has been\ndesigned to operate on small devices, i.e. smartwatches, as well as augmenting\nthe personal assistant systems by allowing them to process end users' natural\nlanguage queries about their quantified-self data.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 03:42:44 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["Rawassizadeh", "Reza", ""], ["Dobbins", "Chelsea", ""], ["Nourizadeh", "Manouchehr", ""], ["Ghamchili", "Zahra", ""], ["Pazzani", "Michael", ""]]}, {"id": "1611.07174", "submitter": "Zewang Zhang", "authors": "Zewang Zhang, Zheng Sun, Jiaqi Liu, Jingwen Chen, Zhao Huo, Xiao Zhang", "title": "Deep Recurrent Convolutional Neural Network: Improving Performance For\n  Speech Recognition", "comments": "11 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A deep learning approach has been widely applied in sequence modeling\nproblems. In terms of automatic speech recognition (ASR), its performance has\nsignificantly been improved by increasing large speech corpus and deeper neural\nnetwork. Especially, recurrent neural network and deep convolutional neural\nnetwork have been applied in ASR successfully. Given the arising problem of\ntraining speed, we build a novel deep recurrent convolutional network for\nacoustic modeling and then apply deep residual learning to it. Our experiments\nshow that it has not only faster convergence speed but better recognition\naccuracy over traditional deep convolutional recurrent network. In the\nexperiments, we compare the convergence speed of our novel deep recurrent\nconvolutional networks and traditional deep convolutional recurrent networks.\nWith faster convergence speed, our novel deep recurrent convolutional networks\ncan reach the comparable performance. We further show that applying deep\nresidual learning can boost the convergence speed of our novel deep recurret\nconvolutional networks. Finally, we evaluate all our experimental networks by\nphoneme error rate (PER) with our proposed bidirectional statistical n-gram\nlanguage model. Our evaluation results show that our newly proposed deep\nrecurrent convolutional network applied with deep residual learning can reach\nthe best PER of 17.33\\% with the fastest convergence speed on TIMIT database.\nThe outstanding performance of our novel deep recurrent convolutional neural\nnetwork with deep residual learning indicates that it can be potentially\nadopted in other sequential problems.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 07:36:21 GMT"}, {"version": "v2", "created": "Tue, 27 Dec 2016 04:53:56 GMT"}], "update_date": "2016-12-28", "authors_parsed": [["Zhang", "Zewang", ""], ["Sun", "Zheng", ""], ["Liu", "Jiaqi", ""], ["Chen", "Jingwen", ""], ["Huo", "Zhao", ""], ["Zhang", "Xiao", ""]]}, {"id": "1611.07206", "submitter": "Kuan-Yu Chen", "authors": "Kuan-Yu Chen, Shih-Hung Liu, Berlin Chen, and Hsin-Min Wang", "title": "Learning to Distill: The Essence Vector Modeling Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of natural language processing, representation learning has\nemerged as a newly active research subject because of its excellent performance\nin many applications. Learning representations of words is a pioneering study\nin this school of research. However, paragraph (or sentence and document)\nembedding learning is more suitable/reasonable for some tasks, such as\nsentiment classification and document summarization. Nevertheless, as far as we\nare aware, there is relatively less work focusing on the development of\nunsupervised paragraph embedding methods. Classic paragraph embedding methods\ninfer the representation of a given paragraph by considering all of the words\noccurring in the paragraph. Consequently, those stop or function words that\noccur frequently may mislead the embedding learning process to produce a misty\nparagraph representation. Motivated by these observations, our major\ncontributions in this paper are twofold. First, we propose a novel unsupervised\nparagraph embedding method, named the essence vector (EV) model, which aims at\nnot only distilling the most representative information from a paragraph but\nalso excluding the general background information to produce a more informative\nlow-dimensional vector representation for the paragraph. Second, in view of the\nincreasing importance of spoken content processing, an extension of the EV\nmodel, named the denoising essence vector (D-EV) model, is proposed. The D-EV\nmodel not only inherits the advantages of the EV model but also can infer a\nmore robust representation for a given spoken paragraph against imperfect\nspeech recognition.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 09:11:42 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["Chen", "Kuan-Yu", ""], ["Liu", "Shih-Hung", ""], ["Chen", "Berlin", ""], ["Wang", "Hsin-Min", ""]]}, {"id": "1611.07232", "submitter": "Renchu Guan", "authors": "Xixun Lin, Yanchun Liang, Fausto Giunchiglia, Xiaoyue Feng, Renchu\n  Guan", "title": "Compositional Learning of Relation Path Embedding for Knowledge Base\n  Completion", "comments": "7 pages,1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale knowledge bases have currently reached impressive sizes; however,\nthese knowledge bases are still far from complete. In addition, most of the\nexisting methods for knowledge base completion only consider the direct links\nbetween entities, ignoring the vital impact of the consistent semantics of\nrelation paths. In this paper, we study the problem of how to better embed\nentities and relations of knowledge bases into different low-dimensional spaces\nby taking full advantage of the additional semantics of relation paths, and we\npropose a compositional learning model of relation path embedding (RPE).\nSpecifically, with the corresponding relation and path projections, RPE can\nsimultaneously embed each entity into two types of latent spaces. It is also\nproposed that type constraints could be extended from traditional\nrelation-specific constraints to the new proposed path-specific constraints.\nThe results of experiments show that the proposed model achieves significant\nand consistent improvements compared with the state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 10:11:56 GMT"}, {"version": "v2", "created": "Mon, 28 Nov 2016 13:07:30 GMT"}, {"version": "v3", "created": "Tue, 20 Dec 2016 07:11:26 GMT"}, {"version": "v4", "created": "Fri, 24 Feb 2017 04:12:56 GMT"}], "update_date": "2017-02-27", "authors_parsed": [["Lin", "Xixun", ""], ["Liang", "Yanchun", ""], ["Giunchiglia", "Fausto", ""], ["Feng", "Xiaoyue", ""], ["Guan", "Renchu", ""]]}, {"id": "1611.07804", "submitter": "Nikita Astrakhantsev", "authors": "N. Astrakhantsev", "title": "ATR4S: Toolkit with State-of-the-art Automatic Terms Recognition Methods\n  in Scala", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatically recognized terminology is widely used for various\ndomain-specific texts processing tasks, such as machine translation,\ninformation retrieval or sentiment analysis. However, there is still no\nagreement on which methods are best suited for particular settings and,\nmoreover, there is no reliable comparison of already developed methods. We\nbelieve that one of the main reasons is the lack of state-of-the-art methods\nimplementations, which are usually non-trivial to recreate. In order to address\nthese issues, we present ATR4S, an open-source software written in Scala that\ncomprises more than 15 methods for automatic terminology recognition (ATR) and\nimplements the whole pipeline from text document preprocessing, to term\ncandidates collection, term candidates scoring, and finally, term candidates\nranking. It is highly scalable, modular and configurable tool with support of\nautomatic caching. We also compare 10 state-of-the-art methods on 7 open\ndatasets by average precision and processing time. Experimental comparison\nreveals that no single method demonstrates best average precision for all\ndatasets and that other available tools for ATR do not contain the best\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 14:14:52 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Astrakhantsev", "N.", ""]]}, {"id": "1611.07837", "submitter": "Zhe Gan", "authors": "Yunchen Pu, Martin Renqiang Min, Zhe Gan, Lawrence Carin", "title": "Adaptive Feature Abstraction for Translating Video to Text", "comments": "Accepted to AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous models for video captioning often use the output from a specific\nlayer of a Convolutional Neural Network (CNN) as video features. However, the\nvariable context-dependent semantics in the video may make it more appropriate\nto adaptively select features from the multiple CNN layers. We propose a new\napproach for generating adaptive spatiotemporal representations of videos for\nthe captioning task. A novel attention mechanism is developed, that adaptively\nand sequentially focuses on different layers of CNN features (levels of feature\n\"abstraction\"), as well as local spatiotemporal regions of the feature maps at\neach layer. The proposed approach is evaluated on three benchmark datasets:\nYouTube2Text, M-VAD and MSR-VTT. Along with visualizing the results and how the\nmodel works, these experiments quantitatively demonstrate the effectiveness of\nthe proposed adaptive spatiotemporal feature abstraction for translating videos\nto sentences with rich semantics.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 15:21:48 GMT"}, {"version": "v2", "created": "Wed, 15 Nov 2017 03:40:47 GMT"}, {"version": "v3", "created": "Fri, 17 Nov 2017 05:13:16 GMT"}], "update_date": "2017-11-20", "authors_parsed": [["Pu", "Yunchen", ""], ["Min", "Martin Renqiang", ""], ["Gan", "Zhe", ""], ["Carin", "Lawrence", ""]]}, {"id": "1611.07897", "submitter": "Zhe Gan", "authors": "Zhe Gan, Yunchen Pu, Ricardo Henao, Chunyuan Li, Xiaodong He, Lawrence\n  Carin", "title": "Learning Generic Sentence Representations Using Convolutional Neural\n  Networks", "comments": "Accepted by EMNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new encoder-decoder approach to learn distributed sentence\nrepresentations that are applicable to multiple purposes. The model is learned\nby using a convolutional neural network as an encoder to map an input sentence\ninto a continuous vector, and using a long short-term memory recurrent neural\nnetwork as a decoder. Several tasks are considered, including sentence\nreconstruction and future sentence prediction. Further, a hierarchical\nencoder-decoder model is proposed to encode a sentence to predict multiple\nfuture sentences. By training our models on a large collection of novels, we\nobtain a highly generic convolutional sentence encoder that performs well in\npractice. Experimental results on several benchmark datasets, and across a\nbroad range of applications, demonstrate the superiority of the proposed model\nover competing methods.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 17:32:23 GMT"}, {"version": "v2", "created": "Wed, 26 Jul 2017 20:48:52 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Gan", "Zhe", ""], ["Pu", "Yunchen", ""], ["Henao", "Ricardo", ""], ["Li", "Chunyuan", ""], ["He", "Xiaodong", ""], ["Carin", "Lawrence", ""]]}, {"id": "1611.07954", "submitter": "Hai Wang", "authors": "Hai Wang, Takeshi Onishi, Kevin Gimpel, David McAllester", "title": "Emergent Predication Structure in Hidden State Vectors of Neural Readers", "comments": "Accepted for Repl4NLP: 2nd Workshop on Representation Learning for\n  NLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A significant number of neural architectures for reading comprehension have\nrecently been developed and evaluated on large cloze-style datasets. We present\nexperiments supporting the emergence of \"predication structure\" in the hidden\nstate vectors of these readers. More specifically, we provide evidence that the\nhidden state vectors represent atomic formulas $\\Phi[c]$ where $\\Phi$ is a\nsemantic property (predicate) and $c$ is a constant symbol entity identifier.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 19:51:34 GMT"}, {"version": "v2", "created": "Wed, 31 May 2017 01:32:26 GMT"}], "update_date": "2017-06-01", "authors_parsed": [["Wang", "Hai", ""], ["Onishi", "Takeshi", ""], ["Gimpel", "Kevin", ""], ["McAllester", "David", ""]]}, {"id": "1611.08002", "submitter": "Zhe Gan", "authors": "Zhe Gan, Chuang Gan, Xiaodong He, Yunchen Pu, Kenneth Tran, Jianfeng\n  Gao, Lawrence Carin, Li Deng", "title": "Semantic Compositional Networks for Visual Captioning", "comments": "Accepted in CVPR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Semantic Compositional Network (SCN) is developed for image captioning, in\nwhich semantic concepts (i.e., tags) are detected from the image, and the\nprobability of each tag is used to compose the parameters in a long short-term\nmemory (LSTM) network. The SCN extends each weight matrix of the LSTM to an\nensemble of tag-dependent weight matrices. The degree to which each member of\nthe ensemble is used to generate an image caption is tied to the\nimage-dependent probability of the corresponding tag. In addition to captioning\nimages, we also extend the SCN to generate captions for video clips. We\nqualitatively analyze semantic composition in SCNs, and quantitatively evaluate\nthe algorithm on three benchmark datasets: COCO, Flickr30k, and Youtube2Text.\nExperimental results show that the proposed method significantly outperforms\nprior state-of-the-art approaches, across multiple evaluation metrics.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 21:22:22 GMT"}, {"version": "v2", "created": "Tue, 28 Mar 2017 18:33:51 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Gan", "Zhe", ""], ["Gan", "Chuang", ""], ["He", "Xiaodong", ""], ["Pu", "Yunchen", ""], ["Tran", "Kenneth", ""], ["Gao", "Jianfeng", ""], ["Carin", "Lawrence", ""], ["Deng", "Li", ""]]}, {"id": "1611.08034", "submitter": "Zhe Gan", "authors": "Zhe Gan, Chunyuan Li, Changyou Chen, Yunchen Pu, Qinliang Su, Lawrence\n  Carin", "title": "Scalable Bayesian Learning of Recurrent Neural Networks for Language\n  Modeling", "comments": "Accepted to ACL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) have shown promising performance for\nlanguage modeling. However, traditional training of RNNs using back-propagation\nthrough time often suffers from overfitting. One reason for this is that\nstochastic optimization (used for large training sets) does not provide good\nestimates of model uncertainty. This paper leverages recent advances in\nstochastic gradient Markov Chain Monte Carlo (also appropriate for large\ntraining sets) to learn weight uncertainty in RNNs. It yields a principled\nBayesian learning algorithm, adding gradient noise during training (enhancing\nexploration of the model-parameter space) and model averaging when testing.\nExtensive experiments on various RNN models and across a broad range of\napplications demonstrate the superiority of the proposed approach over\nstochastic optimization.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 23:40:50 GMT"}, {"version": "v2", "created": "Mon, 24 Apr 2017 15:32:49 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Gan", "Zhe", ""], ["Li", "Chunyuan", ""], ["Chen", "Changyou", ""], ["Pu", "Yunchen", ""], ["Su", "Qinliang", ""], ["Carin", "Lawrence", ""]]}, {"id": "1611.08096", "submitter": "Zheqian Chen", "authors": "Zheqian Chen and Ben Gao and Huimin Zhang and Zhou Zhao and Deng Cai", "title": "User Personalized Satisfaction Prediction via Multiple Instance Deep\n  Learning", "comments": "draft for www", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community based question answering services have arisen as a popular\nknowledge sharing pattern for netizens. With abundant interactions among users,\nindividuals are capable of obtaining satisfactory information. However, it is\nnot effective for users to attain answers within minutes. Users have to check\nthe progress over time until the satisfying answers submitted. We address this\nproblem as a user personalized satisfaction prediction task. Existing methods\nusually exploit manual feature selection. It is not desirable as it requires\ncareful design and is labor intensive. In this paper, we settle this issue by\ndeveloping a new multiple instance deep learning framework. Specifically, in\nour settings, each question follows a weakly supervised learning multiple\ninstance learning assumption, where its obtained answers can be regarded as\ninstance sets and we define the question resolved with at least one\nsatisfactory answer. We thus design an efficient framework exploiting multiple\ninstance learning property with deep learning to model the question answer\npairs. Extensive experiments on large scale datasets from Stack Exchange\ndemonstrate the feasibility of our proposed framework in predicting askers\npersonalized satisfaction. Our framework can be extended to numerous\napplications such as UI satisfaction Prediction, multi armed bandit problem,\nexpert finding and so on.\n", "versions": [{"version": "v1", "created": "Thu, 24 Nov 2016 08:43:03 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Chen", "Zheqian", ""], ["Gao", "Ben", ""], ["Zhang", "Huimin", ""], ["Zhao", "Zhou", ""], ["Cai", "Deng", ""]]}, {"id": "1611.08135", "submitter": "Zheqian Chen", "authors": "Zheqian Chen and Chi Zhang and Zhou Zhao and Deng Cai", "title": "Question Retrieval for Community-based Question Answering via\n  Heterogeneous Network Integration Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community based question answering platforms have attracted substantial users\nto share knowledge and learn from each other. As the rapid enlargement of CQA\nplatforms, quantities of overlapped questions emerge, which makes users\nconfounded to select a proper reference. It is urgent for us to take effective\nautomated algorithms to reuse historical questions with corresponding answers.\nIn this paper we focus on the problem with question retrieval, which aims to\nmatch historical questions that are relevant or semantically equivalent to\nresolve one s query directly. The challenges in this task are the lexical gaps\nbetween questions for the word ambiguity and word mismatch problem.\nFurthermore, limited words in queried sentences cause sparsity of word\nfeatures. To alleviate these challenges, we propose a novel framework named\nHNIL which encodes not only the question contents but also the askers social\ninteractions to enhance the question embedding performance. More specifically,\nwe apply random walk based learning method with recurrent neural network to\nmatch the similarities between askers question and historical questions\nproposed by other users. Extensive experiments on a large scale dataset from a\nreal world CQA site show that employing the heterogeneous social network\ninformation outperforms the other state of the art solutions in this task.\n", "versions": [{"version": "v1", "created": "Thu, 24 Nov 2016 11:01:32 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Chen", "Zheqian", ""], ["Zhang", "Chi", ""], ["Zhao", "Zhou", ""], ["Cai", "Deng", ""]]}, {"id": "1611.08307", "submitter": "Tim Rockt\\\"aschel", "authors": "Avishkar Bhoopchand, Tim Rockt\\\"aschel, Earl Barr, Sebastian Riedel", "title": "Learning Python Code Suggestion with a Sparse Pointer Network", "comments": "Under review as a conference paper at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To enhance developer productivity, all modern integrated development\nenvironments (IDEs) include code suggestion functionality that proposes likely\nnext tokens at the cursor. While current IDEs work well for statically-typed\nlanguages, their reliance on type annotations means that they do not provide\nthe same level of support for dynamic programming languages as for\nstatically-typed languages. Moreover, suggestion engines in modern IDEs do not\npropose expressions or multi-statement idiomatic code. Recent work has shown\nthat language models can improve code suggestion systems by learning from\nsoftware repositories. This paper introduces a neural language model with a\nsparse pointer network aimed at capturing very long-range dependencies. We\nrelease a large-scale code suggestion corpus of 41M lines of Python code\ncrawled from GitHub. On this corpus, we found standard neural language models\nto perform well at suggesting local phenomena, but struggle to refer to\nidentifiers that are introduced many tokens in the past. By augmenting a neural\nlanguage model with a pointer network specialized in referring to predefined\nclasses of identifiers, we obtain a much lower perplexity and a 5 percentage\npoints increase in accuracy for code suggestion compared to an LSTM baseline.\nIn fact, this increase in code suggestion accuracy is due to a 13 times more\naccurate prediction of identifiers. Furthermore, a qualitative analysis shows\nthis model indeed captures interesting long-range dependencies, like referring\nto a class member defined over 60 tokens in the past.\n", "versions": [{"version": "v1", "created": "Thu, 24 Nov 2016 21:01:46 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Bhoopchand", "Avishkar", ""], ["Rockt\u00e4schel", "Tim", ""], ["Barr", "Earl", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1611.08321", "submitter": "Junhua Mao", "authors": "Junhua Mao, Jiajing Xu, Yushi Jing, Alan Yuille", "title": "Training and Evaluating Multimodal Word Embeddings with Large-scale Web\n  Annotated Images", "comments": "Appears in NIPS 2016. The datasets introduced in this work will be\n  gradually released on the project page", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on training and evaluating effective word embeddings\nwith both text and visual information. More specifically, we introduce a\nlarge-scale dataset with 300 million sentences describing over 40 million\nimages crawled and downloaded from publicly available Pins (i.e. an image with\nsentence descriptions uploaded by users) on Pinterest. This dataset is more\nthan 200 times larger than MS COCO, the standard large-scale image dataset with\nsentence descriptions. In addition, we construct an evaluation dataset to\ndirectly assess the effectiveness of word embeddings in terms of finding\nsemantically similar or related words and phrases. The word/phrase pairs in\nthis evaluation dataset are collected from the click data with millions of\nusers in an image search system, thus contain rich semantic relationships.\nBased on these datasets, we propose and compare several Recurrent Neural\nNetworks (RNNs) based multimodal (text and image) models. Experiments show that\nour model benefits from incorporating the visual information into the word\nembeddings, and a weight sharing strategy is crucial for learning such\nmultimodal embeddings. The project page is:\nhttp://www.stat.ucla.edu/~junhua.mao/multimodal_embedding.html\n", "versions": [{"version": "v1", "created": "Thu, 24 Nov 2016 23:15:56 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Mao", "Junhua", ""], ["Xu", "Jiajing", ""], ["Jing", "Yushi", ""], ["Yuille", "Alan", ""]]}, {"id": "1611.08358", "submitter": "Rajashekara Murthy S", "authors": "A N Akshatha, Chandana G Upadhyaya, Rajashekara S Murthy", "title": "Kannada Spell Checker with Sandhi Splitter", "comments": "7 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spelling errors are introduced in text either during typing, or when the user\ndoes not know the correct phoneme or grapheme. If a language contains complex\nwords like sandhi where two or more morphemes join based on some rules, spell\nchecking becomes very tedious. In such situations, having a spell checker with\nsandhi splitter which alerts the user by flagging the errors and providing\nsuggestions is very useful. A novel algorithm of sandhi splitting is proposed\nin this paper. The sandhi splitter can split about 7000 most common sandhi\nwords in Kannada language used as test samples. The sandhi splitter was\nintegrated with a Kannada spell checker and a mechanism for generating\nsuggestions was added. A comprehensive, platform independent, standalone spell\nchecker with sandhi splitter application software was thus developed and tested\nextensively for its efficiency and correctness. A comparative analysis of this\nspell checker with sandhi splitter was made and results concluded that the\nKannada spell checker with sandhi splitter has an improved performance. It is\ntwice as fast, 200 times more space efficient, and it is 90% accurate in case\nof complex nouns and 50% accurate for complex verbs. Such a spell checker with\nsandhi splitter will be of foremost significance in machine translation\nsystems, voice processing, etc. This is the first sandhi splitter in Kannada\nand the advantage of the novel algorithm is that, it can be extended to all\nIndian languages.\n", "versions": [{"version": "v1", "created": "Fri, 25 Nov 2016 06:18:29 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Akshatha", "A N", ""], ["Upadhyaya", "Chandana G", ""], ["Murthy", "Rajashekara S", ""]]}, {"id": "1611.08373", "submitter": "Raghav Chalapathy", "authors": "Raghavendra Chalapathy, Ehsan Zare Borzeshi, Massimo Piccardi", "title": "Bidirectional LSTM-CRF for Clinical Concept Extraction", "comments": "This paper \"Bidirectional LSTM-CRF for Clinical Concept Extraction\"\n  is accepted for short paper presentation at Clinical Natural Language\n  Processing Workshop at COLING 2016 Osaka, Japan. December 11, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated extraction of concepts from patient clinical records is an\nessential facilitator of clinical research. For this reason, the 2010 i2b2/VA\nNatural Language Processing Challenges for Clinical Records introduced a\nconcept extraction task aimed at identifying and classifying concepts into\npredefined categories (i.e., treatments, tests and problems). State-of-the-art\nconcept extraction approaches heavily rely on handcrafted features and\ndomain-specific resources which are hard to collect and define. For this\nreason, this paper proposes an alternative, streamlined approach: a recurrent\nneural network (the bidirectional LSTM with CRF decoding) initialized with\ngeneral-purpose, off-the-shelf word embeddings. The experimental results\nachieved on the 2010 i2b2/VA reference corpora using the proposed framework\noutperform all recent methods and ranks closely to the best submission from the\noriginal 2010 i2b2/VA challenge.\n", "versions": [{"version": "v1", "created": "Fri, 25 Nov 2016 08:11:23 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Chalapathy", "Raghavendra", ""], ["Borzeshi", "Ehsan Zare", ""], ["Piccardi", "Massimo", ""]]}, {"id": "1611.08459", "submitter": "Joji Toyama", "authors": "Joji Toyama, Masanori Misono, Masahiro Suzuki, Kotaro Nakayama and\n  Yutaka Matsuo", "title": "Neural Machine Translation with Latent Semantic of Image and Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although attention-based Neural Machine Translation have achieved great\nsuccess, attention-mechanism cannot capture the entire meaning of the source\nsentence because the attention mechanism generates a target word depending\nheavily on the relevant parts of the source sentence. The report of earlier\nstudies has introduced a latent variable to capture the entire meaning of\nsentence and achieved improvement on attention-based Neural Machine\nTranslation. We follow this approach and we believe that the capturing meaning\nof sentence benefits from image information because human beings understand the\nmeaning of language not only from textual information but also from perceptual\ninformation such as that gained from vision. As described herein, we propose a\nneural machine translation model that introduces a continuous latent variable\ncontaining an underlying semantic extracted from texts and images. Our model,\nwhich can be trained end-to-end, requires image information only when training.\nExperiments conducted with an English--German translation task show that our\nmodel outperforms over the baseline.\n", "versions": [{"version": "v1", "created": "Fri, 25 Nov 2016 14:10:39 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Toyama", "Joji", ""], ["Misono", "Masanori", ""], ["Suzuki", "Masahiro", ""], ["Nakayama", "Kotaro", ""], ["Matsuo", "Yutaka", ""]]}, {"id": "1611.08562", "submitter": "Jiwei Li", "authors": "Jiwei Li, Will Monroe and Dan Jurafsky", "title": "A Simple, Fast Diverse Decoding Algorithm for Neural Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a simple, fast decoding algorithm that fosters\ndiversity in neural generation. The algorithm modifies the standard beam search\nalgorithm by adding an inter-sibling ranking penalty, favoring choosing\nhypotheses from diverse parents. We evaluate the proposed model on the tasks of\ndialogue response generation, abstractive summarization and machine\ntranslation. We find that diverse decoding helps across all tasks, especially\nthose for which reranking is needed.\n  We further propose a variation that is capable of automatically adjusting its\ndiversity decoding rates for different inputs using reinforcement learning\n(RL). We observe a further performance boost from this RL technique. This paper\nincludes material from the unpublished script \"Mutual Information and Diverse\nDecoding Improve Neural Machine Translation\" (Li and Jurafsky, 2016).\n", "versions": [{"version": "v1", "created": "Fri, 25 Nov 2016 19:18:27 GMT"}, {"version": "v2", "created": "Thu, 22 Dec 2016 16:31:52 GMT"}], "update_date": "2016-12-23", "authors_parsed": [["Li", "Jiwei", ""], ["Monroe", "Will", ""], ["Jurafsky", "Dan", ""]]}, {"id": "1611.08656", "submitter": "Da-Rong Liu", "authors": "Da-Rong Liu, Shun-Po Chuang, Hung-yi Lee", "title": "Attention-based Memory Selection Recurrent Network for Language Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) have achieved great success in language\nmodeling. However, since the RNNs have fixed size of memory, their memory\ncannot store all the information about the words it have seen before in the\nsentence, and thus the useful long-term information may be ignored when\npredicting the next words. In this paper, we propose Attention-based Memory\nSelection Recurrent Network (AMSRN), in which the model can review the\ninformation stored in the memory at each previous time step and select the\nrelevant information to help generate the outputs. In AMSRN, the attention\nmechanism finds the time steps storing the relevant information in the memory,\nand memory selection determines which dimensions of the memory are involved in\ncomputing the attention weights and from which the information is extracted.In\nthe experiments, AMSRN outperformed long short-term memory (LSTM) based\nlanguage models on both English and Chinese corpora. Moreover, we investigate\nusing entropy as a regularizer for attention weights and visualize how the\nattention mechanism helps language modeling.\n", "versions": [{"version": "v1", "created": "Sat, 26 Nov 2016 04:25:00 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Liu", "Da-Rong", ""], ["Chuang", "Shun-Po", ""], ["Lee", "Hung-yi", ""]]}, {"id": "1611.08661", "submitter": "Xipeng Qiu", "authors": "Jiacheng Xu, Kan Chen, Xipeng Qiu and Xuanjing Huang", "title": "Knowledge Graph Representation with Jointly Structural and Textual\n  Encoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of knowledge graph embedding is to encode both entities and\nrelations of knowledge graphs into continuous low-dimensional vector spaces.\nPreviously, most works focused on symbolic representation of knowledge graph\nwith structure information, which can not handle new entities or entities with\nfew facts well. In this paper, we propose a novel deep architecture to utilize\nboth structural and textual information of entities. Specifically, we introduce\nthree neural models to encode the valuable information from text description of\nentity, among which an attentive model can select related information as\nneeded. Then, a gating mechanism is applied to integrate representations of\nstructure and text into a unified architecture. Experiments show that our\nmodels outperform baseline by margin on link prediction and triplet\nclassification tasks. Source codes of this paper will be available on Github.\n", "versions": [{"version": "v1", "created": "Sat, 26 Nov 2016 05:42:20 GMT"}, {"version": "v2", "created": "Tue, 13 Dec 2016 04:40:42 GMT"}], "update_date": "2016-12-14", "authors_parsed": [["Xu", "Jiacheng", ""], ["Chen", "Kan", ""], ["Qiu", "Xipeng", ""], ["Huang", "Xuanjing", ""]]}, {"id": "1611.08669", "submitter": "Satwik Kottur", "authors": "Abhishek Das, Satwik Kottur, Khushi Gupta, Avi Singh, Deshraj Yadav,\n  Jos\\'e M. F. Moura, Devi Parikh, Dhruv Batra", "title": "Visual Dialog", "comments": "23 pages, 18 figures, CVPR 2017 camera-ready, results on VisDial v0.9\n  dataset, Webpage: http://visualdialog.org", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the task of Visual Dialog, which requires an AI agent to hold a\nmeaningful dialog with humans in natural, conversational language about visual\ncontent. Specifically, given an image, a dialog history, and a question about\nthe image, the agent has to ground the question in image, infer context from\nhistory, and answer the question accurately. Visual Dialog is disentangled\nenough from a specific downstream task so as to serve as a general test of\nmachine intelligence, while being grounded in vision enough to allow objective\nevaluation of individual responses and benchmark progress. We develop a novel\ntwo-person chat data-collection protocol to curate a large-scale Visual Dialog\ndataset (VisDial). VisDial v0.9 has been released and contains 1 dialog with 10\nquestion-answer pairs on ~120k images from COCO, with a total of ~1.2M dialog\nquestion-answer pairs.\n  We introduce a family of neural encoder-decoder models for Visual Dialog with\n3 encoders -- Late Fusion, Hierarchical Recurrent Encoder and Memory Network --\nand 2 decoders (generative and discriminative), which outperform a number of\nsophisticated baselines. We propose a retrieval-based evaluation protocol for\nVisual Dialog where the AI agent is asked to sort a set of candidate answers\nand evaluated on metrics such as mean-reciprocal-rank of human response. We\nquantify gap between machine and human performance on the Visual Dialog task\nvia human studies. Putting it all together, we demonstrate the first 'visual\nchatbot'! Our dataset, code, trained models and visual chatbot are available on\nhttps://visualdialog.org\n", "versions": [{"version": "v1", "created": "Sat, 26 Nov 2016 06:39:28 GMT"}, {"version": "v2", "created": "Mon, 5 Dec 2016 02:00:49 GMT"}, {"version": "v3", "created": "Fri, 21 Apr 2017 16:29:55 GMT"}, {"version": "v4", "created": "Mon, 24 Apr 2017 02:10:49 GMT"}, {"version": "v5", "created": "Tue, 1 Aug 2017 22:04:37 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Das", "Abhishek", ""], ["Kottur", "Satwik", ""], ["Gupta", "Khushi", ""], ["Singh", "Avi", ""], ["Yadav", "Deshraj", ""], ["Moura", "Jos\u00e9 M. F.", ""], ["Parikh", "Devi", ""], ["Batra", "Dhruv", ""]]}, {"id": "1611.08675", "submitter": "Heriberto Cuay\\'ahuitl", "authors": "Heriberto Cuay\\'ahuitl, Seunghak Yu, Ashley Williamson, Jacob Carse", "title": "Deep Reinforcement Learning for Multi-Domain Dialogue Systems", "comments": "NIPS Workshop on Deep Reinforcement Learning, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard deep reinforcement learning methods such as Deep Q-Networks (DQN)\nfor multiple tasks (domains) face scalability problems. We propose a method for\nmulti-domain dialogue policy learning---termed NDQN, and apply it to an\ninformation-seeking spoken dialogue system in the domains of restaurants and\nhotels. Experimental results comparing DQN (baseline) versus NDQN (proposed)\nusing simulations report that our proposed method exhibits better scalability\nand is promising for optimising the behaviour of multi-domain dialogue systems.\n", "versions": [{"version": "v1", "created": "Sat, 26 Nov 2016 07:53:22 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Cuay\u00e1huitl", "Heriberto", ""], ["Yu", "Seunghak", ""], ["Williamson", "Ashley", ""], ["Carse", "Jacob", ""]]}, {"id": "1611.08737", "submitter": "Shuangfei Zhai", "authors": "Nana Li, Shuangfei Zhai, Zhongfei Zhang, Boying Liu", "title": "Structural Correspondence Learning for Cross-lingual Sentiment\n  Classification with One-to-many Mappings", "comments": "To appear in AAAI 2017. arXiv admin note: text overlap with\n  arXiv:1008.0716 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structural correspondence learning (SCL) is an effective method for\ncross-lingual sentiment classification. This approach uses unlabeled documents\nalong with a word translation oracle to automatically induce task specific,\ncross-lingual correspondences. It transfers knowledge through identifying\nimportant features, i.e., pivot features. For simplicity, however, it assumes\nthat the word translation oracle maps each pivot feature in source language to\nexactly only one word in target language. This one-to-one mapping between words\nin different languages is too strict. Also the context is not considered at\nall. In this paper, we propose a cross-lingual SCL based on distributed\nrepresentation of words; it can learn meaningful one-to-many mappings for pivot\nwords using large amounts of monolingual data and a small dictionary. We\nconduct experiments on NLP\\&CC 2013 cross-lingual sentiment analysis dataset,\nemploying English as source language, and Chinese as target language. Our\nmethod does not rely on the parallel corpora and the experimental results show\nthat our approach is more competitive than the state-of-the-art methods in\ncross-lingual sentiment classification.\n", "versions": [{"version": "v1", "created": "Sat, 26 Nov 2016 20:11:00 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Li", "Nana", ""], ["Zhai", "Shuangfei", ""], ["Zhang", "Zhongfei", ""], ["Liu", "Boying", ""]]}, {"id": "1611.08765", "submitter": "Jason Mielens", "authors": "Liang Sun, Jason Mielens, Jason Baldridge", "title": "Fill it up: Exploiting partial dependency annotations in a minimum\n  spanning tree parser", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised models of dependency parsing typically require large amounts of\nclean, unlabeled data plus gold-standard part-of-speech tags. Adding indirect\nsupervision (e.g. language universals and rules) can help, but we show that\nobtaining small amounts of direct supervision - here, partial dependency\nannotations - provides a strong balance between zero and full supervision. We\nadapt the unsupervised ConvexMST dependency parser to learn from partial\ndependencies expressed in the Graph Fragment Language. With less than 24 hours\nof total annotation, we obtain 7% and 17% absolute improvement in unlabeled\ndependency scores for English and Spanish, respectively, compared to the same\nparser using only universal grammar constraints.\n", "versions": [{"version": "v1", "created": "Sat, 26 Nov 2016 23:39:41 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Sun", "Liang", ""], ["Mielens", "Jason", ""], ["Baldridge", "Jason", ""]]}, {"id": "1611.08807", "submitter": "Ramon Ferrer i Cancho", "authors": "Bernardino Casas, Neus Catal\\`a, Ramon Ferrer-i-Cancho, Antoni\n  Hern\\'andez-Fern\\'andez and Jaume Baixeries", "title": "The polysemy of the words that children learn over time", "comments": "Substantially revised version based on referee comments from\n  Interaction Studies", "journal-ref": "Interaction Studies 19 (3), 389-426 (2018)", "doi": "10.1075/is.16036.cas", "report-no": null, "categories": "cs.CL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here we study polysemy as a potential learning bias in vocabulary learning in\nchildren. Words of low polysemy could be preferred as they reduce the\ndisambiguation effort for the listener. However, such preference could be a\nside-effect of another bias: the preference of children for nouns in\ncombination with the lower polysemy of nouns with respect to other\npart-of-speech categories. Our results show that mean polysemy in children\nincreases over time in two phases, i.e. a fast growth till the 31st month\nfollowed by a slower tendency towards adult speech. In contrast, this evolution\nis not found in adults interacting with children. This suggests that children\nhave a preference for non-polysemous words in their early stages of vocabulary\nacquisition. Interestingly, the evolutionary pattern described above weakens\nwhen controlling for syntactic category (noun, verb, adjective or adverb) but\nit does not disappear completely, suggesting that it could result from\nacombination of a standalone bias for low polysemy and a preference for nouns.\n", "versions": [{"version": "v1", "created": "Sun, 27 Nov 2016 08:32:19 GMT"}, {"version": "v2", "created": "Tue, 26 Mar 2019 12:57:23 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Casas", "Bernardino", ""], ["Catal\u00e0", "Neus", ""], ["Ferrer-i-Cancho", "Ramon", ""], ["Hern\u00e1ndez-Fern\u00e1ndez", "Antoni", ""], ["Baixeries", "Jaume", ""]]}, {"id": "1611.08813", "submitter": "Hila Gonen", "authors": "Hila Gonen and Yoav Goldberg", "title": "Semi Supervised Preposition-Sense Disambiguation using Multilingual Data", "comments": "12 pages; COLING 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Prepositions are very common and very ambiguous, and understanding their\nsense is critical for understanding the meaning of the sentence. Supervised\ncorpora for the preposition-sense disambiguation task are small, suggesting a\nsemi-supervised approach to the task. We show that signals from unannotated\nmultilingual data can be used to improve supervised preposition-sense\ndisambiguation. Our approach pre-trains an LSTM encoder for predicting the\ntranslation of a preposition, and then incorporates the pre-trained encoder as\na component in a supervised classification system, and fine-tunes it for the\ntask. The multilingual signals consistently improve results on two\npreposition-sense datasets.\n", "versions": [{"version": "v1", "created": "Sun, 27 Nov 2016 09:53:36 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Gonen", "Hila", ""], ["Goldberg", "Yoav", ""]]}, {"id": "1611.08928", "submitter": "Francesco Fumarola", "authors": "Francesco Fumarola", "title": "A theory of interpretive clustering in free recall", "comments": "24 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A stochastic model of short-term verbal memory is proposed, in which the\npsychological state of the subject is encoded as the instantaneous position of\na particle diffusing over a semantic graph with a probabilistic structure. The\nmodel is particularly suitable for studying the dependence of free-recall\nobservables on semantic properties of the words to be recalled. Besides\npredicting some well-known experimental features (contiguity effect, forward\nasymmetry, word-length effect), a novel prediction is obtained on the\nrelationship between the contiguity effect and the syllabic length of words;\nshorter words, by way of their wider semantic range, are predicted to be\ncharacterized by stronger forward contiguity. A fresh analysis of archival data\nallows to confirm this prediction.\n", "versions": [{"version": "v1", "created": "Sun, 27 Nov 2016 22:42:13 GMT"}, {"version": "v2", "created": "Tue, 21 Mar 2017 17:15:23 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Fumarola", "Francesco", ""]]}, {"id": "1611.08945", "submitter": "Arvind Neelakantan", "authors": "Arvind Neelakantan, Quoc V. Le, Martin Abadi, Andrew McCallum, Dario\n  Amodei", "title": "Learning a Natural Language Interface with Neural Programmer", "comments": "Published as a conference paper at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a natural language interface for database tables is a challenging\ntask that involves deep language understanding and multi-step reasoning. The\ntask is often approached by mapping natural language queries to logical forms\nor programs that provide the desired response when executed on the database. To\nour knowledge, this paper presents the first weakly supervised, end-to-end\nneural network model to induce such programs on a real-world dataset. We\nenhance the objective function of Neural Programmer, a neural network with\nbuilt-in discrete operations, and apply it on WikiTableQuestions, a natural\nlanguage question-answering dataset. The model is trained end-to-end with weak\nsupervision of question-answer pairs, and does not require domain-specific\ngrammars, rules, or annotations that are key elements in previous approaches to\nprogram induction. The main experimental result in this paper is that a single\nNeural Programmer model achieves 34.2% accuracy using only 10,000 examples with\nweak supervision. An ensemble of 15 models, with a trivial combination\ntechnique, achieves 37.7% accuracy, which is competitive to the current\nstate-of-the-art accuracy of 37.1% obtained by a traditional natural language\nsemantic parser.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 00:54:34 GMT"}, {"version": "v2", "created": "Mon, 20 Feb 2017 16:18:14 GMT"}, {"version": "v3", "created": "Tue, 21 Feb 2017 14:43:12 GMT"}, {"version": "v4", "created": "Thu, 2 Mar 2017 16:02:00 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Neelakantan", "Arvind", ""], ["Le", "Quoc V.", ""], ["Abadi", "Martin", ""], ["McCallum", "Andrew", ""], ["Amodei", "Dario", ""]]}, {"id": "1611.08987", "submitter": "Zhuoran Liu", "authors": "Zhuoran Liu and Yang Liu", "title": "Exploiting Unlabeled Data for Neural Grammatical Error Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying and correcting grammatical errors in the text written by\nnon-native writers has received increasing attention in recent years. Although\na number of annotated corpora have been established to facilitate data-driven\ngrammatical error detection and correction approaches, they are still limited\nin terms of quantity and coverage because human annotation is labor-intensive,\ntime-consuming, and expensive. In this work, we propose to utilize unlabeled\ndata to train neural network based grammatical error detection models. The\nbasic idea is to cast error detection as a binary classification problem and\nderive positive and negative training examples from unlabeled data. We\nintroduce an attention-based neural network to capture long-distance\ndependencies that influence the word being detected. Experiments show that the\nproposed approach significantly outperforms SVMs and convolutional networks\nwith fixed-size context window.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 05:32:35 GMT"}, {"version": "v2", "created": "Tue, 29 Nov 2016 06:08:59 GMT"}], "update_date": "2016-11-30", "authors_parsed": [["Liu", "Zhuoran", ""], ["Liu", "Yang", ""]]}, {"id": "1611.09020", "submitter": "Jia Su", "authors": "Jia Su, Bin He, Yi Guan, Jingchi Jiang, Jinfeng Yang", "title": "Developing a cardiovascular disease risk factor annotated corpus of\n  Chinese electronic medical records", "comments": "32 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cardiovascular disease (CVD) has become the leading cause of death in China,\nand most of the cases can be prevented by controlling risk factors. The goal of\nthis study was to build a corpus of CVD risk factor annotations based on\nChinese electronic medical records (CEMRs). This corpus is intended to be used\nto develop a risk factor information extraction system that, in turn, can be\napplied as a foundation for the further study of the progress of risk factors\nand CVD. We designed a light annotation task to capture CVD risk factors with\nindicators, temporal attributes and assertions that were explicitly or\nimplicitly displayed in the records. The task included: 1) preparing data; 2)\ncreating guidelines for capturing annotations (these were created with the help\nof clinicians); 3) proposing an annotation method including building the\nguidelines draft, training the annotators and updating the guidelines, and\ncorpus construction. Then, a risk factor annotated corpus based on\nde-identified discharge summaries and progress notes from 600 patients was\ndeveloped. Built with the help of clinicians, this corpus has an\ninter-annotator agreement (IAA) F1-measure of 0.968, indicating a high\nreliability. To the best of our knowledge, this is the first annotated corpus\nconcerning CVD risk factors in CEMRs and the guidelines for capturing CVD risk\nfactor annotations from CEMRs were proposed. The obtained document-level\nannotations can be applied in future studies to monitor risk factors and CVD\nover the long term.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 08:20:54 GMT"}, {"version": "v2", "created": "Fri, 3 Mar 2017 08:52:27 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Su", "Jia", ""], ["He", "Bin", ""], ["Guan", "Yi", ""], ["Jiang", "Jingchi", ""], ["Yang", "Jinfeng", ""]]}, {"id": "1611.09028", "submitter": "Albin Zehe", "authors": "Fotis Jannidis, Isabella Reger, Albin Zehe, Martin Becker, Lena\n  Hettinger, Andreas Hotho", "title": "Analyzing Features for the Detection of Happy Endings in German Novels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With regard to a computational representation of literary plot, this paper\nlooks at the use of sentiment analysis for happy ending detection in German\nnovels. Its focus lies on the investigation of previously proposed sentiment\nfeatures in order to gain insight about the relevance of specific features on\nthe one hand and the implications of their performance on the other hand.\nTherefore, we study various partitionings of novels, considering the highly\nvariable concept of \"ending\". We also show that our approach, even though still\nrather simple, can potentially lead to substantial findings relevant to\nliterary studies.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 08:56:04 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Jannidis", "Fotis", ""], ["Reger", "Isabella", ""], ["Zehe", "Albin", ""], ["Becker", "Martin", ""], ["Hettinger", "Lena", ""], ["Hotho", "Andreas", ""]]}, {"id": "1611.09100", "submitter": "Dani Yogatama", "authors": "Dani Yogatama, Phil Blunsom, Chris Dyer, Edward Grefenstette, Wang\n  Ling", "title": "Learning to Compose Words into Sentences with Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use reinforcement learning to learn tree-structured neural networks for\ncomputing representations of natural language sentences. In contrast with prior\nwork on tree-structured models in which the trees are either provided as input\nor predicted using supervision from explicit treebank annotations, the tree\nstructures in this work are optimized to improve performance on a downstream\ntask. Experiments demonstrate the benefit of learning task-specific composition\norders, outperforming both sequential encoders and recursive encoders based on\ntreebank annotations. We analyze the induced trees and show that while they\ndiscover some linguistically intuitive structures (e.g., noun phrases, simple\nverb phrases), they are different than conventional English syntactic\nstructures.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 12:57:07 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Yogatama", "Dani", ""], ["Blunsom", "Phil", ""], ["Dyer", "Chris", ""], ["Grefenstette", "Edward", ""], ["Ling", "Wang", ""]]}, {"id": "1611.09122", "submitter": "Leonid Borisov", "authors": "Andronik Arutyunov, Leonid Borisov, Sergey Fedorov, Anastasiya\n  Ivchenko, Elizabeth Kirina-Lilinskaya, Yurii Orlov, Konstantin Osminin,\n  Sergey Shilin, Dmitriy Zeniuk", "title": "Statistical Properties of European Languages and Voynich Manuscript\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The statistical properties of letters frequencies in European literature\ntexts are investigated. The determination of logarithmic dependence of letters\nsequence for one-language and two-language texts are examined. The pare of\nlanguages is suggested for Voynich Manuscript. The internal structure of\nManuscript is considered. The spectral portraits of two-letters distribution\nare constructed.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2016 03:48:04 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Arutyunov", "Andronik", ""], ["Borisov", "Leonid", ""], ["Fedorov", "Sergey", ""], ["Ivchenko", "Anastasiya", ""], ["Kirina-Lilinskaya", "Elizabeth", ""], ["Orlov", "Yurii", ""], ["Osminin", "Konstantin", ""], ["Shilin", "Sergey", ""], ["Zeniuk", "Dmitriy", ""]]}, {"id": "1611.09207", "submitter": "Brian Patton", "authors": "Brian Patton, Yannis Agiomyrgiannakis, Michael Terry, Kevin Wilson,\n  Rif A. Saurous, D. Sculley", "title": "AutoMOS: Learning a non-intrusive assessor of naturalness-of-speech", "comments": "4 pages, 2 figures, 2 tables, NIPS 2016 End-to-end Learning for\n  Speech and Audio Processing Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developers of text-to-speech synthesizers (TTS) often make use of human\nraters to assess the quality of synthesized speech. We demonstrate that we can\nmodel human raters' mean opinion scores (MOS) of synthesized speech using a\ndeep recurrent neural network whose inputs consist solely of a raw waveform.\nOur best models provide utterance-level estimates of MOS only moderately\ninferior to sampled human ratings, as shown by Pearson and Spearman\ncorrelations. When multiple utterances are scored and averaged, a scenario\ncommon in synthesizer quality assessment, AutoMOS achieves correlations\napproaching those of human raters. The AutoMOS model has a number of\napplications, such as the ability to explore the parameter space of a speech\nsynthesizer without requiring a human-in-the-loop.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 15:51:25 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Patton", "Brian", ""], ["Agiomyrgiannakis", "Yannis", ""], ["Terry", "Michael", ""], ["Wilson", "Kevin", ""], ["Saurous", "Rif A.", ""], ["Sculley", "D.", ""]]}, {"id": "1611.09235", "submitter": "Ziqiang Cao", "authors": "Ziqiang Cao, Chuwei Luo, Wenjie Li, Sujian Li", "title": "Joint Copying and Restricted Generation for Paraphrase", "comments": "7 pages, 1 figure, AAAI-17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Many natural language generation tasks, such as abstractive summarization and\ntext simplification, are paraphrase-orientated. In these tasks, copying and\nrewriting are two main writing modes. Most previous sequence-to-sequence\n(Seq2Seq) models use a single decoder and neglect this fact. In this paper, we\ndevelop a novel Seq2Seq model to fuse a copying decoder and a restricted\ngenerative decoder. The copying decoder finds the position to be copied based\non a typical attention model. The generative decoder produces words limited in\nthe source-specific vocabulary. To combine the two decoders and determine the\nfinal output, we develop a predictor to predict the mode of copying or\nrewriting. This predictor can be guided by the actual writing mode in the\ntraining data. We conduct extensive experiments on two different paraphrase\ndatasets. The result shows that our model outperforms the state-of-the-art\napproaches in terms of both informativeness and language quality.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 16:49:37 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Cao", "Ziqiang", ""], ["Luo", "Chuwei", ""], ["Li", "Wenjie", ""], ["Li", "Sujian", ""]]}, {"id": "1611.09238", "submitter": "Ziqiang Cao", "authors": "Ziqiang Cao, Wenjie Li, Sujian Li, Furu Wei", "title": "Improving Multi-Document Summarization via Text Classification", "comments": "7 pages, 3 figures, AAAI-17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Developed so far, multi-document summarization has reached its bottleneck due\nto the lack of sufficient training data and diverse categories of documents.\nText classification just makes up for these deficiencies. In this paper, we\npropose a novel summarization system called TCSum, which leverages plentiful\ntext classification data to improve the performance of multi-document\nsummarization. TCSum projects documents onto distributed representations which\nact as a bridge between text classification and summarization. It also utilizes\nthe classification results to produce summaries of different styles. Extensive\nexperiments on DUC generic multi-document summarization datasets show that,\nTCSum can achieve the state-of-the-art performance without using any\nhand-crafted features and has the capability to catch the variations of summary\nstyles with respect to different text categories.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 16:53:06 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Cao", "Ziqiang", ""], ["Li", "Wenjie", ""], ["Li", "Sujian", ""], ["Wei", "Furu", ""]]}, {"id": "1611.09268", "submitter": "Bhaskar Mitra", "authors": "Payal Bajaj, Daniel Campos, Nick Craswell, Li Deng, Jianfeng Gao,\n  Xiaodong Liu, Rangan Majumder, Andrew McNamara, Bhaskar Mitra, Tri Nguyen,\n  Mir Rosenberg, Xia Song, Alina Stoica, Saurabh Tiwary and Tong Wang", "title": "MS MARCO: A Human Generated MAchine Reading COmprehension Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a large scale MAchine Reading COmprehension dataset, which we\nname MS MARCO. The dataset comprises of 1,010,916 anonymized\nquestions---sampled from Bing's search query logs---each with a human generated\nanswer and 182,669 completely human rewritten generated answers. In addition,\nthe dataset contains 8,841,823 passages---extracted from 3,563,535 web\ndocuments retrieved by Bing---that provide the information necessary for\ncurating the natural language answers. A question in the MS MARCO dataset may\nhave multiple answers or no answers at all. Using this dataset, we propose\nthree different tasks with varying levels of difficulty: (i) predict if a\nquestion is answerable given a set of context passages, and extract and\nsynthesize the answer as a human would (ii) generate a well-formed answer (if\npossible) based on the context passages that can be understood with the\nquestion and passage context, and finally (iii) rank a set of retrieved\npassages given a question. The size of the dataset and the fact that the\nquestions are derived from real user search queries distinguishes MS MARCO from\nother well-known publicly available datasets for machine reading comprehension\nand question-answering. We believe that the scale and the real-world nature of\nthis dataset makes it attractive for benchmarking machine reading comprehension\nand question-answering models.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 18:14:11 GMT"}, {"version": "v2", "created": "Tue, 29 Nov 2016 02:39:53 GMT"}, {"version": "v3", "created": "Wed, 31 Oct 2018 14:46:47 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Bajaj", "Payal", ""], ["Campos", "Daniel", ""], ["Craswell", "Nick", ""], ["Deng", "Li", ""], ["Gao", "Jianfeng", ""], ["Liu", "Xiaodong", ""], ["Majumder", "Rangan", ""], ["McNamara", "Andrew", ""], ["Mitra", "Bhaskar", ""], ["Nguyen", "Tri", ""], ["Rosenberg", "Mir", ""], ["Song", "Xia", ""], ["Stoica", "Alina", ""], ["Tiwary", "Saurabh", ""], ["Wang", "Tong", ""]]}, {"id": "1611.09288", "submitter": "Tom Sercu", "authors": "Tom Sercu and Vaibhava Goel", "title": "Dense Prediction on Sequences with Time-Dilated Convolutions for Speech\n  Recognition", "comments": "Appeared at NIPS 2016 End-to-end Learning for Speech and Audio\n  Processing Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In computer vision pixelwise dense prediction is the task of predicting a\nlabel for each pixel in the image. Convolutional neural networks achieve good\nperformance on this task, while being computationally efficient. In this paper\nwe carry these ideas over to the problem of assigning a sequence of labels to a\nset of speech frames, a task commonly known as framewise classification. We\nshow that dense prediction view of framewise classification offers several\nadvantages and insights, including computational efficiency and the ability to\napply batch normalization. When doing dense prediction we pay specific\nattention to strided pooling in time and introduce an asymmetric dilated\nconvolution, called time-dilated convolution, that allows for efficient and\nelegant implementation of pooling in time. We show results using time-dilated\nconvolutions in a very deep VGG-style CNN with batch normalization on the Hub5\nSwitchboard-2000 benchmark task. With a big n-gram language model, we achieve\n7.7% WER which is the best single model single-pass performance reported so\nfar.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 19:09:58 GMT"}, {"version": "v2", "created": "Wed, 14 Dec 2016 08:27:41 GMT"}], "update_date": "2016-12-15", "authors_parsed": [["Sercu", "Tom", ""], ["Goel", "Vaibhava", ""]]}, {"id": "1611.09405", "submitter": "Christopher Lengerich", "authors": "Chris Lengerich, Awni Hannun", "title": "An End-to-End Architecture for Keyword Spotting and Voice Activity\n  Detection", "comments": "NIPS 2016 End-to-End Learning for Speech and Audio Processing\n  Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a single neural network architecture for two tasks: on-line\nkeyword spotting and voice activity detection. We develop novel inference\nalgorithms for an end-to-end Recurrent Neural Network trained with the\nConnectionist Temporal Classification loss function which allow our model to\nachieve high accuracy on both keyword spotting and voice activity detection\nwithout retraining. In contrast to prior voice activity detection models, our\narchitecture does not require aligned training data and uses the same\nparameters as the keyword spotting model. This allows us to deploy a high\nquality voice activity detector with no additional memory or maintenance\nrequirements.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 22:03:22 GMT"}], "update_date": "2016-11-30", "authors_parsed": [["Lengerich", "Chris", ""], ["Hannun", "Awni", ""]]}, {"id": "1611.09434", "submitter": "Jakob Foerster", "authors": "Jakob N. Foerster, Justin Gilmer, Jan Chorowski, Jascha\n  Sohl-Dickstein, David Sussillo", "title": "Input Switched Affine Networks: An RNN Architecture Designed for\n  Interpretability", "comments": "ICLR 2107 submission: https://openreview.net/forum?id=H1MjAnqxg", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There exist many problem domains where the interpretability of neural network\nmodels is essential for deployment. Here we introduce a recurrent architecture\ncomposed of input-switched affine transformations - in other words an RNN\nwithout any explicit nonlinearities, but with input-dependent recurrent\nweights. This simple form allows the RNN to be analyzed via straightforward\nlinear methods: we can exactly characterize the linear contribution of each\ninput to the model predictions; we can use a change-of-basis to disentangle\ninput, output, and computational hidden unit subspaces; we can fully\nreverse-engineer the architecture's solution to a simple task. Despite this\nease of interpretation, the input switched affine network achieves reasonable\nperformance on a text modeling tasks, and allows greater computational\nefficiency than networks with standard nonlinearities.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 23:48:41 GMT"}, {"version": "v2", "created": "Mon, 12 Jun 2017 20:29:48 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Foerster", "Jakob N.", ""], ["Gilmer", "Justin", ""], ["Chorowski", "Jan", ""], ["Sohl-Dickstein", "Jascha", ""], ["Sussillo", "David", ""]]}, {"id": "1611.09441", "submitter": "Lahari Poddar Lahari Poddar", "authors": "Lahari Poddar, Kishaloy Halder, and Xianyan Jia", "title": "Sentiment Analysis for Twitter : Going Beyond Tweet Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysing sentiment of tweets is important as it helps to determine the\nusers' opinion. Knowing people's opinion is crucial for several purposes\nstarting from gathering knowledge about customer base, e-governance,\ncampaigning and many more. In this report, we aim to develop a system to detect\nthe sentiment from tweets. We employ several linguistic features along with\nsome other external sources of information to detect the sentiment of a tweet.\nWe show that augmenting the 140 character-long tweet with information harvested\nfrom external urls shared in the tweet as well as Social Media features\nenhances the sentiment prediction accuracy significantly.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 00:22:13 GMT"}], "update_date": "2016-11-30", "authors_parsed": [["Poddar", "Lahari", ""], ["Halder", "Kishaloy", ""], ["Jia", "Xianyan", ""]]}, {"id": "1611.09534", "submitter": "Tom Zahavy", "authors": "Tom Zahavy and Alessandro Magnani and Abhinandan Krishnan and Shie\n  Mannor", "title": "Is a picture worth a thousand words? A Deep Multi-Modal Fusion\n  Architecture for Product Classification in e-commerce", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifying products into categories precisely and efficiently is a major\nchallenge in modern e-commerce. The high traffic of new products uploaded daily\nand the dynamic nature of the categories raise the need for machine learning\nmodels that can reduce the cost and time of human editors. In this paper, we\npropose a decision level fusion approach for multi-modal product classification\nusing text and image inputs. We train input specific state-of-the-art deep\nneural networks for each input source, show the potential of forging them\ntogether into a multi-modal architecture and train a novel policy network that\nlearns to choose between them. Finally, we demonstrate that our multi-modal\nnetwork improves the top-1 accuracy % over both networks on a real-world\nlarge-scale product classification dataset that we collected fromWalmart.com.\nWhile we focus on image-text fusion that characterizes e-commerce domains, our\nalgorithms can be easily applied to other modalities such as audio, video,\nphysical sensors, etc.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 09:05:11 GMT"}], "update_date": "2016-11-30", "authors_parsed": [["Zahavy", "Tom", ""], ["Magnani", "Alessandro", ""], ["Krishnan", "Abhinandan", ""], ["Mannor", "Shie", ""]]}, {"id": "1611.09573", "submitter": "Anoop V S", "authors": "V. S. Anoop, S. Asharaf and P. Deepak", "title": "Learning Concept Hierarchies through Probabilistic Topic Modeling", "comments": null, "journal-ref": "International Journal of Information Processing (IJIP), Volume 10,\n  Issue 3, 2016", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of semantic web, various tools and techniques have been\nintroduced for presenting and organizing knowledge. Concept hierarchies are one\nsuch technique which gained significant attention due to its usefulness in\ncreating domain ontologies that are considered as an integral part of semantic\nweb. Automated concept hierarchy learning algorithms focus on extracting\nrelevant concepts from unstructured text corpus and connect them together by\nidentifying some potential relations exist between them. In this paper, we\npropose a novel approach for identifying relevant concepts from plain text and\nthen learns hierarchy of concepts by exploiting subsumption relation between\nthem. To start with, we model topics using a probabilistic topic model and then\nmake use of some lightweight linguistic process to extract semantically rich\nconcepts. Then we connect concepts by identifying an \"is-a\" relationship\nbetween pair of concepts. The proposed method is completely unsupervised and\nthere is no need for a domain specific training corpus for concept extraction\nand learning. Experiments on large and real-world text corpora such as BBC News\ndataset and Reuters News corpus shows that the proposed method outperforms some\nof the existing methods for concept extraction and efficient concept hierarchy\nlearning is possible if the overall task is guided by a probabilistic topic\nmodeling algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 11:28:59 GMT"}], "update_date": "2016-11-30", "authors_parsed": [["Anoop", "V. S.", ""], ["Asharaf", "S.", ""], ["Deepak", "P.", ""]]}, {"id": "1611.09703", "submitter": "Ji\\v{r}\\'i Vysko\\v{c}il", "authors": "Cezary Kaliszyk, Josef Urban, Ji\\v{r}\\'i Vysko\\v{c}il", "title": "Semantic Parsing of Mathematics by Context-based Learning from Aligned\n  Corpora and Theorem Proving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study methods for automated parsing of informal mathematical expressions\ninto formal ones, a main prerequisite for deep computer understanding of\ninformal mathematical texts. We propose a context-based parsing approach that\ncombines efficient statistical learning of deep parse trees with their semantic\npruning by type checking and large-theory automated theorem proving. We show\nthat the methods very significantly improve on previous results in parsing\ntheorems from the Flyspeck corpus.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 16:20:24 GMT"}], "update_date": "2016-11-30", "authors_parsed": [["Kaliszyk", "Cezary", ""], ["Urban", "Josef", ""], ["Vysko\u010dil", "Ji\u0159\u00ed", ""]]}, {"id": "1611.09799", "submitter": "Hongyu Gong", "authors": "Hongyu Gong, Suma Bhat, Pramod Viswanath", "title": "Geometry of Compositionality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a simple test for compositionality (i.e., literal usage)\nof a word or phrase in a context-specific way. The test is computationally\nsimple, relying on no external resources and only uses a set of trained word\nvectors. Experiments show that the proposed method is competitive with state of\nthe art and displays high accuracy in context-specific compositionality\ndetection of a variety of natural language phenomena (idiomaticity, sarcasm,\nmetaphor) for different datasets in multiple languages. The key insight is to\nconnect compositionality to a curious geometric property of word embeddings,\nwhich is of independent interest.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 19:23:41 GMT"}], "update_date": "2016-11-30", "authors_parsed": [["Gong", "Hongyu", ""], ["Bhat", "Suma", ""], ["Viswanath", "Pramod", ""]]}, {"id": "1611.09823", "submitter": "Jason  Weston", "authors": "Jiwei Li, Alexander H. Miller, Sumit Chopra, Marc'Aurelio Ranzato,\n  Jason Weston", "title": "Dialogue Learning With Human-In-The-Loop", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important aspect of developing conversational agents is to give a bot the\nability to improve through communicating with humans and to learn from the\nmistakes that it makes. Most research has focused on learning from fixed\ntraining sets of labeled data rather than interacting with a dialogue partner\nin an online fashion. In this paper we explore this direction in a\nreinforcement learning setting where the bot improves its question-answering\nability from feedback a teacher gives following its generated responses. We\nbuild a simulator that tests various aspects of such learning in a synthetic\nenvironment, and introduce models that work in this regime. Finally, real\nexperiments with Mechanical Turk validate the approach.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 20:16:44 GMT"}, {"version": "v2", "created": "Fri, 16 Dec 2016 00:22:53 GMT"}, {"version": "v3", "created": "Fri, 13 Jan 2017 21:12:38 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Li", "Jiwei", ""], ["Miller", "Alexander H.", ""], ["Chopra", "Sumit", ""], ["Ranzato", "Marc'Aurelio", ""], ["Weston", "Jason", ""]]}, {"id": "1611.09830", "submitter": "Tong Wang", "authors": "Adam Trischler, Tong Wang, Xingdi Yuan, Justin Harris, Alessandro\n  Sordoni, Philip Bachman, Kaheer Suleman", "title": "NewsQA: A Machine Comprehension Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present NewsQA, a challenging machine comprehension dataset of over\n100,000 human-generated question-answer pairs. Crowdworkers supply questions\nand answers based on a set of over 10,000 news articles from CNN, with answers\nconsisting of spans of text from the corresponding articles. We collect this\ndataset through a four-stage process designed to solicit exploratory questions\nthat require reasoning. A thorough analysis confirms that NewsQA demands\nabilities beyond simple word matching and recognizing textual entailment. We\nmeasure human performance on the dataset and compare it to several strong\nneural models. The performance gap between humans and machines (0.198 in F1)\nindicates that significant progress can be made on NewsQA through future\nresearch. The dataset is freely available at\nhttps://datasets.maluuba.com/NewsQA.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 20:38:07 GMT"}, {"version": "v2", "created": "Thu, 22 Dec 2016 18:12:57 GMT"}, {"version": "v3", "created": "Tue, 7 Feb 2017 16:27:59 GMT"}], "update_date": "2017-02-08", "authors_parsed": [["Trischler", "Adam", ""], ["Wang", "Tong", ""], ["Yuan", "Xingdi", ""], ["Harris", "Justin", ""], ["Sordoni", "Alessandro", ""], ["Bachman", "Philip", ""], ["Suleman", "Kaheer", ""]]}, {"id": "1611.09878", "submitter": "Jian Tang", "authors": "Jian Tang, Meng Qu, and Qiaozhu Mei", "title": "Identity-sensitive Word Embedding through Heterogeneous Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Most existing word embedding approaches do not distinguish the same words in\ndifferent contexts, therefore ignoring their contextual meanings. As a result,\nthe learned embeddings of these words are usually a mixture of multiple\nmeanings. In this paper, we acknowledge multiple identities of the same word in\ndifferent contexts and learn the \\textbf{identity-sensitive} word embeddings.\nBased on an identity-labeled text corpora, a heterogeneous network of words and\nword identities is constructed to model different-levels of word\nco-occurrences. The heterogeneous network is further embedded into a\nlow-dimensional space through a principled network embedding approach, through\nwhich we are able to obtain the embeddings of words and the embeddings of word\nidentities. We study three different types of word identities including topics,\nsentiments and categories. Experimental results on real-world data sets show\nthat the identity-sensitive word embeddings learned by our approach indeed\ncapture different meanings of words and outperforms competitive methods on\ntasks including text classification and word similarity computation.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 21:12:04 GMT"}], "update_date": "2016-12-04", "authors_parsed": [["Tang", "Jian", ""], ["Qu", "Meng", ""], ["Mei", "Qiaozhu", ""]]}, {"id": "1611.09900", "submitter": "Jian Tang", "authors": "Jian Tang, Yifan Yang, Sam Carton, Ming Zhang, and Qiaozhu Mei", "title": "Context-aware Natural Language Generation with Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper studied generating natural languages at particular contexts or\nsituations. We proposed two novel approaches which encode the contexts into a\ncontinuous semantic representation and then decode the semantic representation\ninto text sequences with recurrent neural networks. During decoding, the\ncontext information are attended through a gating mechanism, addressing the\nproblem of long-range dependency caused by lengthy sequences. We evaluate the\neffectiveness of the proposed approaches on user review data, in which rich\ncontexts are available and two informative contexts, sentiments and products,\nare selected for evaluation. Experiments show that the fake reviews generated\nby our approaches are very natural. Results of fake review detection with human\njudges show that more than 50\\% of the fake reviews are misclassified as the\nreal reviews, and more than 90\\% are misclassified by existing state-of-the-art\nfake review detection algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 21:45:42 GMT"}], "update_date": "2016-12-01", "authors_parsed": [["Tang", "Jian", ""], ["Yang", "Yifan", ""], ["Carton", "Sam", ""], ["Zhang", "Ming", ""], ["Mei", "Qiaozhu", ""]]}, {"id": "1611.09921", "submitter": "Jian Tang", "authors": "Jian Tang, Cheng Li, Ming Zhang, and Qiaozhu Mei", "title": "Less is More: Learning Prominent and Diverse Topics for Data\n  Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Statistical topic models efficiently facilitate the exploration of\nlarge-scale data sets. Many models have been developed and broadly used to\nsummarize the semantic structure in news, science, social media, and digital\nhumanities. However, a common and practical objective in data exploration tasks\nis not to enumerate all existing topics, but to quickly extract representative\nones that broadly cover the content of the corpus, i.e., a few topics that\nserve as a good summary of the data. Most existing topic models fit exactly the\nsame number of topics as a user specifies, which have imposed an unnecessary\nburden to the users who have limited prior knowledge. We instead propose new\nmodels that are able to learn fewer but more representative topics for the\npurpose of data summarization. We propose a reinforced random walk that allows\nprominent topics to absorb tokens from similar and smaller topics, thus\nenhances the diversity among the top topics extracted. With this reinforced\nrandom walk as a general process embedded in classical topic models, we obtain\n\\textit{diverse topic models} that are able to extract the most prominent and\ndiverse topics from data. The inference procedures of these diverse topic\nmodels remain as simple and efficient as the classical models. Experimental\nresults demonstrate that the diverse topic models not only discover topics that\nbetter summarize the data, but also require minimal prior knowledge of the\nusers.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 22:24:30 GMT"}, {"version": "v2", "created": "Thu, 1 Dec 2016 02:45:34 GMT"}], "update_date": "2016-12-02", "authors_parsed": [["Tang", "Jian", ""], ["Li", "Cheng", ""], ["Zhang", "Ming", ""], ["Mei", "Qiaozhu", ""]]}, {"id": "1611.10038", "submitter": "Si Li", "authors": "Si Li and Nianwen Xue", "title": "Towards Accurate Word Segmentation for Chinese Patents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A patent is a property right for an invention granted by the government to\nthe inventor. An invention is a solution to a specific technological problem.\nSo patents often have a high concentration of scientific and technical terms\nthat are rare in everyday language. The Chinese word segmentation model trained\non currently available everyday language data sets performs poorly because it\ncannot effectively recognize these scientific and technical terms. In this\npaper we describe a pragmatic approach to Chinese word segmentation on patents\nwhere we train a character-based semi-supervised sequence labeling model by\nextracting features from a manually segmented corpus of 142 patents, enhanced\nwith information extracted from the Chinese TreeBank. Experiments show that the\naccuracy of our model reached 95.08% (F1 score) on a held-out test set and\n96.59% on development set, compared with an F1 score of 91.48% on development\nset if the model is trained on the Chinese TreeBank. We also experimented with\nsome existing domain adaptation techniques, the results show that the amount of\ntarget domain data and the selected features impact the performance of the\ndomain adaptation techniques.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2016 07:53:34 GMT"}], "update_date": "2016-12-01", "authors_parsed": [["Li", "Si", ""], ["Xue", "Nianwen", ""]]}, {"id": "1611.10122", "submitter": "Laurent Romary", "authors": "Jack Bowers (OEAW), Laurent Romary (CMB, ALPAGE)", "title": "Deep encoding of etymological information in TEI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to provide a comprehensive modeling and representation of\netymological data in digital dictionaries. The purpose is to integrate in one\ncoherent framework both digital representations of legacy dictionaries, and\nalso born-digital lexical databases that are constructed manually or\nsemi-automatically. We want to propose a systematic and coherent set of\nmodeling principles for a variety of etymological phenomena that may contribute\nto the creation of a continuum between existing and future lexical constructs,\nwhere anyone interested in tracing the history of words and their meanings will\nbe able to seamlessly query lexical resources.Instead of designing an ad hoc\nmodel and representation language for digital etymological data, we will focus\non identifying all the possibilities offered by the TEI guidelines for the\nrepresentation of lexical information.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2016 12:30:11 GMT"}], "update_date": "2016-12-01", "authors_parsed": [["Bowers", "Jack", "", "OEAW"], ["Romary", "Laurent", "", "CMB, ALPAGE"]]}, {"id": "1611.10277", "submitter": "Ryan Gallagher", "authors": "Ryan J. Gallagher, Kyle Reing, David Kale, Greg Ver Steeg", "title": "Anchored Correlation Explanation: Topic Modeling with Minimal Domain\n  Knowledge", "comments": "21 pages, 7 figures. 2018/09/03: Updated citation for HA/DR dataset", "journal-ref": "Transactions of the Association for Computational Linguistics\n  (TACL), Vol. 5, 2017", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While generative models such as Latent Dirichlet Allocation (LDA) have proven\nfruitful in topic modeling, they often require detailed assumptions and careful\nspecification of hyperparameters. Such model complexity issues only compound\nwhen trying to generalize generative models to incorporate human input. We\nintroduce Correlation Explanation (CorEx), an alternative approach to topic\nmodeling that does not assume an underlying generative model, and instead\nlearns maximally informative topics through an information-theoretic framework.\nThis framework naturally generalizes to hierarchical and semi-supervised\nextensions with no additional modeling assumptions. In particular, word-level\ndomain knowledge can be flexibly incorporated within CorEx through anchor\nwords, allowing topic separability and representation to be promoted with\nminimal human intervention. Across a variety of datasets, metrics, and\nexperiments, we demonstrate that CorEx produces topics that are comparable in\nquality to those produced by unsupervised and semi-supervised variants of LDA.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2016 17:32:17 GMT"}, {"version": "v2", "created": "Fri, 28 Jul 2017 17:41:04 GMT"}, {"version": "v3", "created": "Mon, 4 Dec 2017 03:53:19 GMT"}, {"version": "v4", "created": "Mon, 3 Sep 2018 15:23:40 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Gallagher", "Ryan J.", ""], ["Reing", "Kyle", ""], ["Kale", "David", ""], ["Steeg", "Greg Ver", ""]]}]