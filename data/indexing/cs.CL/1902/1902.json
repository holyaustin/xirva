[{"id": "1902.00027", "submitter": "Thomas Crossland", "authors": "Tom Crossland, Pontus Stenetorp, Sebastian Riedel, Daisuke Kawata,\n  Thomas D. Kitching, Rupert A. C. Croft", "title": "Towards Machine-assisted Meta-Studies: The Hubble Constant", "comments": "13 pages, 6 figures. Accepted for publication in MNRAS", "journal-ref": null, "doi": "10.1093/mnras/stz3400", "report-no": null, "categories": "astro-ph.IM cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present an approach for automatic extraction of measured values from the\nastrophysical literature, using the Hubble constant for our pilot study. Our\nrules-based model -- a classical technique in natural language processing --\nhas successfully extracted 298 measurements of the Hubble constant, with\nuncertainties, from the 208,541 available arXiv astrophysics papers. We have\nalso created an artificial neural network classifier to identify papers in\narXiv which report novel measurements. From the analysis of our results we find\nthat reporting measurements with uncertainties and the correct units is\ncritical information when distinguishing novel measurements in free text. Our\nresults correctly highlight the current tension for measurements of the Hubble\nconstant and recover the $3.5\\sigma$ discrepancy -- demonstrating that the tool\npresented in this paper is useful for meta-studies of astrophysical\nmeasurements from a large number of publications.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 19:00:07 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 16:02:29 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Crossland", "Tom", ""], ["Stenetorp", "Pontus", ""], ["Riedel", "Sebastian", ""], ["Kawata", "Daisuke", ""], ["Kitching", "Thomas D.", ""], ["Croft", "Rupert A. C.", ""]]}, {"id": "1902.00098", "submitter": "Emily Dinan", "authors": "Emily Dinan, Varvara Logacheva, Valentin Malykh, Alexander Miller,\n  Kurt Shuster, Jack Urbanek, Douwe Kiela, Arthur Szlam, Iulian Serban, Ryan\n  Lowe, Shrimai Prabhumoye, Alan W Black, Alexander Rudnicky, Jason Williams,\n  Joelle Pineau, Mikhail Burtsev, Jason Weston", "title": "The Second Conversational Intelligence Challenge (ConvAI2)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the setting and results of the ConvAI2 NeurIPS competition that\naims to further the state-of-the-art in open-domain chatbots. Some key\ntakeaways from the competition are: (i) pretrained Transformer variants are\ncurrently the best performing models on this task, (ii) but to improve\nperformance on multi-turn conversations with humans, future systems must go\nbeyond single word metrics like perplexity to measure the performance across\nsequences of utterances (conversations) -- in terms of repetition, consistency\nand balance of dialogue acts (e.g. how many questions asked vs. answered).\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 22:14:34 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Dinan", "Emily", ""], ["Logacheva", "Varvara", ""], ["Malykh", "Valentin", ""], ["Miller", "Alexander", ""], ["Shuster", "Kurt", ""], ["Urbanek", "Jack", ""], ["Kiela", "Douwe", ""], ["Szlam", "Arthur", ""], ["Serban", "Iulian", ""], ["Lowe", "Ryan", ""], ["Prabhumoye", "Shrimai", ""], ["Black", "Alan W", ""], ["Rudnicky", "Alexander", ""], ["Williams", "Jason", ""], ["Pineau", "Joelle", ""], ["Burtsev", "Mikhail", ""], ["Weston", "Jason", ""]]}, {"id": "1902.00154", "submitter": "Dinghan Shen", "authors": "Dinghan Shen, Asli Celikyilmaz, Yizhe Zhang, Liqun Chen, Xin Wang,\n  Jianfeng Gao, Lawrence Carin", "title": "Towards Generating Long and Coherent Text with Multi-Level Latent\n  Variable Models", "comments": "To appear at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders (VAEs) have received much attention recently as an\nend-to-end architecture for text generation with latent variables. In this\npaper, we investigate several multi-level structures to learn a VAE model to\ngenerate long, and coherent text. In particular, we use a hierarchy of\nstochastic layers between the encoder and decoder networks to generate more\ninformative latent codes. We also investigate a multi-level decoder structure\nto learn a coherent long-term structure by generating intermediate sentence\nrepresentations as high-level plan vectors. Empirical results demonstrate that\na multi-level VAE model produces more coherent and less repetitive long text\ncompared to the standard VAE models and can further mitigate the\nposterior-collapse issue.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 02:42:55 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 20:22:13 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Shen", "Dinghan", ""], ["Celikyilmaz", "Asli", ""], ["Zhang", "Yizhe", ""], ["Chen", "Liqun", ""], ["Wang", "Xin", ""], ["Gao", "Jianfeng", ""], ["Carin", "Lawrence", ""]]}, {"id": "1902.00164", "submitter": "Kai Sun", "authors": "Kai Sun, Dian Yu, Jianshu Chen, Dong Yu, Yejin Choi, Claire Cardie", "title": "DREAM: A Challenge Dataset and Models for Dialogue-Based Reading\n  Comprehension", "comments": "To appear in TACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present DREAM, the first dialogue-based multiple-choice reading\ncomprehension dataset. Collected from English-as-a-foreign-language\nexaminations designed by human experts to evaluate the comprehension level of\nChinese learners of English, our dataset contains 10,197 multiple-choice\nquestions for 6,444 dialogues. In contrast to existing reading comprehension\ndatasets, DREAM is the first to focus on in-depth multi-turn multi-party\ndialogue understanding. DREAM is likely to present significant challenges for\nexisting reading comprehension systems: 84% of answers are non-extractive, 85%\nof questions require reasoning beyond a single sentence, and 34% of questions\nalso involve commonsense knowledge.\n  We apply several popular neural reading comprehension models that primarily\nexploit surface information within the text and find them to, at best, just\nbarely outperform a rule-based approach. We next investigate the effects of\nincorporating dialogue structure and different kinds of general world knowledge\ninto both rule-based and (neural and non-neural) machine learning-based reading\ncomprehension models. Experimental results on the DREAM dataset show the\neffectiveness of dialogue structure and general world knowledge. DREAM will be\navailable at https://dataset.org/dream/.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 03:43:51 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Sun", "Kai", ""], ["Yu", "Dian", ""], ["Chen", "Jianshu", ""], ["Yu", "Dong", ""], ["Choi", "Yejin", ""], ["Cardie", "Claire", ""]]}, {"id": "1902.00175", "submitter": "Shikhar Vashishth", "authors": "Shikhar Vashishth, Shib Sankar Dasgupta, Swayambhu Nath Ray, Partha\n  Talukdar", "title": "Dating Documents using Graph Convolution Networks", "comments": "Accepted at ACL 2018", "journal-ref": "Proceedings of the 56th Annual Meeting of the Association for\n  Computational Linguistics 2018", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document date is essential for many important tasks, such as document\nretrieval, summarization, event detection, etc. While existing approaches for\nthese tasks assume accurate knowledge of the document date, this is not always\navailable, especially for arbitrary documents from the Web. Document Dating is\na challenging problem which requires inference over the temporal structure of\nthe document. Prior document dating systems have largely relied on handcrafted\nfeatures while ignoring such document internal structures. In this paper, we\npropose NeuralDater, a Graph Convolutional Network (GCN) based document dating\napproach which jointly exploits syntactic and temporal graph structures of\ndocument in a principled way. To the best of our knowledge, this is the first\napplication of deep learning for the problem of document dating. Through\nextensive experiments on real-world datasets, we find that NeuralDater\nsignificantly outperforms state-of-the-art baseline by 19% absolute (45%\nrelative) accuracy points.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 04:30:42 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Vashishth", "Shikhar", ""], ["Dasgupta", "Shib Sankar", ""], ["Ray", "Swayambhu Nath", ""], ["Talukdar", "Partha", ""]]}, {"id": "1902.00184", "submitter": "Wei Yang", "authors": "Wei Yang, Wei Lu, Vincent W. Zheng", "title": "A Simple Regularization-based Algorithm for Learning Cross-Domain Word\n  Embeddings", "comments": "7 pages, accepted by EMNLP 2017", "journal-ref": "D17-1312, 2017, 2898-2904", "doi": "10.18653/v1/D17-1312", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning word embeddings has received a significant amount of attention\nrecently. Often, word embeddings are learned in an unsupervised manner from a\nlarge collection of text. The genre of the text typically plays an important\nrole in the effectiveness of the resulting embeddings. How to effectively train\nword embedding models using data from different domains remains a problem that\nis underexplored. In this paper, we present a simple yet effective method for\nlearning word embeddings based on text from different domains. We demonstrate\nthe effectiveness of our approach through extensive experiments on various\ndown-stream NLP tasks.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 05:02:59 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Yang", "Wei", ""], ["Lu", "Wei", ""], ["Zheng", "Vincent W.", ""]]}, {"id": "1902.00193", "submitter": "Afshin Rahimi", "authors": "Afshin Rahimi, Yuan Li and Trevor Cohn", "title": "Massively Multilingual Transfer for NER", "comments": "The first and the second author have equally contributed to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cross-lingual transfer, NLP models over one or more source languages are\napplied to a low-resource target language. While most prior work has used a\nsingle source model or a few carefully selected models, here we consider a\n`massive' setting with many such models. This setting raises the problem of\npoor transfer, particularly from distant languages. We propose two techniques\nfor modulating the transfer, suitable for zero-shot or few-shot learning,\nrespectively. Evaluating on named entity recognition, we show that our\ntechniques are much more effective than strong baselines, including standard\nensembling, and our unsupervised method rivals oracle selection of the single\nbest individual model.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 05:49:45 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 07:25:18 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 04:40:53 GMT"}, {"version": "v4", "created": "Wed, 5 Jun 2019 01:30:40 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Rahimi", "Afshin", ""], ["Li", "Yuan", ""], ["Cohn", "Trevor", ""]]}, {"id": "1902.00330", "submitter": "Zheng Fang", "authors": "Zheng Fang, Yanan Cao, Dongjie Zhang, Qian Li, Zhenyu Zhang, Yanbing\n  Liu", "title": "Joint Entity Linking with Deep Reinforcement Learning", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity linking is the task of aligning mentions to corresponding entities in\na given knowledge base. Previous studies have highlighted the necessity for\nentity linking systems to capture the global coherence. However, there are two\ncommon weaknesses in previous global models. First, most of them calculate the\npairwise scores between all candidate entities and select the most relevant\ngroup of entities as the final result. In this process, the consistency among\nwrong entities as well as that among right ones are involved, which may\nintroduce noise data and increase the model complexity. Second, the cues of\npreviously disambiguated entities, which could contribute to the disambiguation\nof the subsequent mentions, are usually ignored by previous models. To address\nthese problems, we convert the global linking into a sequence decision problem\nand propose a reinforcement learning model which makes decisions from a global\nperspective. Our model makes full use of the previous referred entities and\nexplores the long-term influence of current selection on subsequent decisions.\nWe conduct experiments on different types of datasets, the results show that\nour model outperforms state-of-the-art systems and has better generalization\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 13:58:37 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Fang", "Zheng", ""], ["Cao", "Yanan", ""], ["Zhang", "Dongjie", ""], ["Li", "Qian", ""], ["Zhang", "Zhenyu", ""], ["Liu", "Yanbing", ""]]}, {"id": "1902.00438", "submitter": "Bla\\v{z} \\v{S}krlj", "authors": "Bla\\v{z} \\v{S}krlj, Matej Martinc, Jan Kralj, Nada Lavra\\v{c}, Senja\n  Pollak", "title": "tax2vec: Constructing Interpretable Features from Taxonomies for Short\n  Text Classification", "comments": "Accepted at CSL journal", "journal-ref": null, "doi": "10.1016/j.csl.2020.101104", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of background knowledge is largely unexploited in text classification\ntasks. This paper explores word taxonomies as means for constructing new\nsemantic features, which may improve the performance and robustness of the\nlearned classifiers. We propose tax2vec, a parallel algorithm for constructing\ntaxonomy-based features, and demonstrate its use on six short text\nclassification problems: prediction of gender, personality type, age, news\ntopics, drug side effects and drug effectiveness. The constructed semantic\nfeatures, in combination with fast linear classifiers, tested against strong\nbaselines such as hierarchical attention neural networks, achieves comparable\nclassification results on short text documents. The algorithm's performance is\nalso tested in a few-shot learning setting, indicating that the inclusion of\nsemantic features can improve the performance in data-scarce situations. The\ntax2vec capability to extract corpus-specific semantic keywords is also\ndemonstrated. Finally, we investigate the semantic space of potential features,\nwhere we observe a similarity with the well known Zipf's law.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 16:23:17 GMT"}, {"version": "v2", "created": "Sun, 7 Apr 2019 19:09:20 GMT"}, {"version": "v3", "created": "Thu, 23 Apr 2020 08:28:24 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["\u0160krlj", "Bla\u017e", ""], ["Martinc", "Matej", ""], ["Kralj", "Jan", ""], ["Lavra\u010d", "Nada", ""], ["Pollak", "Senja", ""]]}, {"id": "1902.00489", "submitter": "Abram Handler", "authors": "Abram Handler, Brian Dillon and Brendan O'Connor", "title": "Human acceptability judgements for extractive sentence compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent approaches to English-language sentence compression rely on parallel\ncorpora consisting of sentence-compression pairs. However, a sentence may be\nshortened in many different ways, which each might be suited to the needs of a\nparticular application. Therefore, in this work, we collect and model\ncrowdsourced judgements of the acceptability of many possible sentence\nshortenings. We then show how a model of such judgements can be used to support\na flexible approach to the compression task. We release our model and dataset\nfor future work.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 18:22:33 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Handler", "Abram", ""], ["Dillon", "Brian", ""], ["O'Connor", "Brendan", ""]]}, {"id": "1902.00496", "submitter": "Shelly Rathee", "authors": "A. Mishra, H. Mishra, S. Rathee", "title": "Examining the Presence of Gender Bias in Customer Reviews Using Word\n  Embedding", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.15426.02240", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans have entered the age of algorithms. Each minute, algorithms shape\ncountless preferences from suggesting a product to a potential life partner. In\nthe marketplace algorithms are trained to learn consumer preferences from\ncustomer reviews because user-generated reviews are considered the voice of\ncustomers and a valuable source of information to firms. Insights mined from\nreviews play an indispensable role in several business activities ranging from\nproduct recommendation, targeted advertising, promotions, segmentation etc. In\nthis research, we question whether reviews might hold stereotypic gender bias\nthat algorithms learn and propagate Utilizing data from millions of\nobservations and a word embedding approach, GloVe, we show that algorithms\ndesigned to learn from human language output also learn gender bias. We also\nexamine why such biases occur: whether the bias is caused because of a negative\nbias against females or a positive bias for males. We examine the impact of\ngender bias in reviews on choice and conclude with policy implications for\nfemale consumers, especially when they are unaware of the bias, and the ethical\nimplications for firms.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 18:36:09 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Mishra", "A.", ""], ["Mishra", "H.", ""], ["Rathee", "S.", ""]]}, {"id": "1902.00508", "submitter": "Goran Glava\\v{s}", "authors": "Goran Glavas, Robert Litschko, Sebastian Ruder, Ivan Vulic", "title": "How to (Properly) Evaluate Cross-Lingual Word Embeddings: On Strong\n  Baselines, Comparative Analyses, and Some Misconceptions", "comments": null, "journal-ref": "ACL 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Cross-lingual word embeddings (CLEs) enable multilingual modeling of meaning\nand facilitate cross-lingual transfer of NLP models. Despite their ubiquitous\nusage in downstream tasks, recent increasingly popular projection-based CLE\nmodels are almost exclusively evaluated on a single task only: bilingual\nlexicon induction (BLI). Even BLI evaluations vary greatly, hindering our\nability to correctly interpret performance and properties of different CLE\nmodels. In this work, we make the first step towards a comprehensive evaluation\nof cross-lingual word embeddings. We thoroughly evaluate both supervised and\nunsupervised CLE models on a large number of language pairs in the BLI task and\nthree downstream tasks, providing new insights concerning the ability of\ncutting-edge CLE models to support cross-lingual NLP. We empirically\ndemonstrate that the performance of CLE models largely depends on the task at\nhand and that optimizing CLE models for BLI can result in deteriorated\ndownstream performance. We indicate the most robust supervised and unsupervised\nCLE models and emphasize the need to reassess existing baselines, which still\ndisplay competitive performance across the board. We hope that our work will\ncatalyze further work on CLE evaluation and model analysis.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 18:59:27 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Glavas", "Goran", ""], ["Litschko", "Robert", ""], ["Ruder", "Sebastian", ""], ["Vulic", "Ivan", ""]]}, {"id": "1902.00551", "submitter": "Koushik Varma K", "authors": "Koushik Varma Kalidindi", "title": "Deconstructing Word Embeddings", "comments": "arXiv admin note: text overlap with arXiv:1705.04416 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A review of Word Embedding Models through a deconstructive approach reveals\ntheir several shortcomings and inconsistencies. These include instability of\nthe vector representations, a distorted analogical reasoning, geometric\nincompatibility with linguistic features, and the inconsistencies in the corpus\ndata. A new theoretical embedding model, Derridian Embedding, is proposed in\nthis paper. Contemporary embedding models are evaluated qualitatively in terms\nof how adequate they are in relation to the capabilities of a Derridian\nEmbedding.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 06:44:40 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Kalidindi", "Koushik Varma", ""]]}, {"id": "1902.00555", "submitter": "Massimiliano Polito Dr", "authors": "Massimiliano Polito", "title": "Riconoscimento ortografico per apostrofo ed espressioni polirematiche", "comments": "in Italian", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The work presents two algorithms of manipulation and comparison between\nstrings whose purpose is the orthographic recognition of the apostrophe and of\nthe compound expressions. The theory supporting general reasoning refers to the\nbasic concept of EditDistance, the improvements that ensure the achievement of\nthe objective are achieved with the aid of tools borrowed from the use of\ntechniques for processing large amounts of data on distributed platforms.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 16:12:14 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Polito", "Massimiliano", ""]]}, {"id": "1902.00570", "submitter": "Atta Norouzian", "authors": "Atta Norouzian, Bogdan Mazoure, Dermot Connolly and Daniel Willett", "title": "Exploring attention mechanism for acoustic-based classification of\n  speech utterances into system-directed and non-system-directed", "comments": "Accpeted for presentation at ICASSP2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice controlled virtual assistants (VAs) are now available in smartphones,\ncars, and standalone devices in homes. In most cases, the user needs to first\n\"wake-up\" the VA by saying a particular word/phrase every time he or she wants\nthe VA to do something. Eliminating the need for saying the wake-up word for\nevery interaction could improve the user experience. This would require the VA\nto have the capability to detect the speech that is being directed at it and\nrespond accordingly. In other words, the challenge is to distinguish between\nsystem-directed and non-system-directed speech utterances. In this paper, we\npresent a number of neural network architectures for tackling this\nclassification problem based on using only acoustic features. These\narchitectures are based on using convolutional, recurrent and feed-forward\nlayers. In addition, we investigate the use of an attention mechanism applied\nto the output of the convolutional and the recurrent layers. It is shown that\nincorporating the proposed attention mechanism into the models always leads to\nsignificant improvement in classification accuracy. The best model achieved\nequal error rates of 16.25 and 15.62 percents on two distinct realistic\ndatasets.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 21:48:45 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Norouzian", "Atta", ""], ["Mazoure", "Bogdan", ""], ["Connolly", "Dermot", ""], ["Willett", "Daniel", ""]]}, {"id": "1902.00579", "submitter": "Zhe Gan", "authors": "Zhe Gan, Yu Cheng, Ahmed El Kholy, Linjie Li, Jingjing Liu, Jianfeng\n  Gao", "title": "Multi-step Reasoning via Recurrent Dual Attention for Visual Dialog", "comments": "Accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new model for visual dialog, Recurrent Dual Attention\nNetwork (ReDAN), using multi-step reasoning to answer a series of questions\nabout an image. In each question-answering turn of a dialog, ReDAN infers the\nanswer progressively through multiple reasoning steps. In each step of the\nreasoning process, the semantic representation of the question is updated based\non the image and the previous dialog history, and the recurrently-refined\nrepresentation is used for further reasoning in the subsequent step. On the\nVisDial v1.0 dataset, the proposed ReDAN model achieves a new state-of-the-art\nof 64.47% NDCG score. Visualization on the reasoning process further\ndemonstrates that ReDAN can locate context-relevant visual and textual clues\nvia iterative refinement, which can lead to the correct answer step-by-step.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 22:48:26 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 05:54:02 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Gan", "Zhe", ""], ["Cheng", "Yu", ""], ["Kholy", "Ahmed El", ""], ["Li", "Linjie", ""], ["Liu", "Jingjing", ""], ["Gao", "Jianfeng", ""]]}, {"id": "1902.00595", "submitter": "Michael Hahn", "authors": "Michael Hahn, Frank Keller, Yonatan Bisk, Yonatan Belinkov", "title": "Character-based Surprisal as a Model of Reading Difficulty in the\n  Presence of Error", "comments": "Published in Proceedings of CogSci 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intuitively, human readers cope easily with errors in text; typos,\nmisspelling, word substitutions, etc. do not unduly disrupt natural reading.\nPrevious work indicates that letter transpositions result in increased reading\ntimes, but it is unclear if this effect generalizes to more natural errors. In\nthis paper, we report an eye-tracking study that compares two error types\n(letter transpositions and naturally occurring misspelling) and two error rates\n(10% or 50% of all words contain errors). We find that human readers show\nunimpaired comprehension in spite of these errors, but error words cause more\nreading difficulty than correct words. Also, transpositions are more difficult\nthan misspellings, and a high error rate increases difficulty for all words,\nincluding correct ones. We then present a computational model that uses\ncharacter-based (rather than traditional word-based) surprisal to account for\nthese results. The model explains that transpositions are harder than\nmisspellings because they contain unexpected letter combinations. It also\nexplains the error rate effect: upcoming words are more difficultto predict\nwhen the context is degraded, leading to increased surprisal.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 00:32:11 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 16:50:58 GMT"}, {"version": "v3", "created": "Mon, 20 May 2019 00:32:49 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Hahn", "Michael", ""], ["Keller", "Frank", ""], ["Bisk", "Yonatan", ""], ["Belinkov", "Yonatan", ""]]}, {"id": "1902.00613", "submitter": "Abraham Frandsen", "authors": "Abraham Frandsen, Rong Ge", "title": "Understanding Composition of Word Embeddings via Tensor Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embedding is a powerful tool in natural language processing. In this\npaper we consider the problem of word embedding composition \\--- given vector\nrepresentations of two words, compute a vector for the entire phrase. We give a\ngenerative model that can capture specific syntactic relations between words.\nUnder our model, we prove that the correlations between three words (measured\nby their PMI) form a tensor that has an approximate low rank Tucker\ndecomposition. The result of the Tucker decomposition gives the word embeddings\nas well as a core tensor, which can be used to produce better compositions of\nthe word embeddings. We also complement our theoretical results with\nexperiments that verify our assumptions, and demonstrate the effectiveness of\nthe new composition method.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 01:34:56 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Frandsen", "Abraham", ""], ["Ge", "Rong", ""]]}, {"id": "1902.00663", "submitter": "Tolgahan Cakaloglu Ph.D", "authors": "Tolgahan Cakaloglu, Xiaowei Xu", "title": "A Multi-Resolution Word Embedding for Document Retrieval from Large\n  Unstructured Knowledge Bases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep language models learning a hierarchical representation proved to be a\npowerful tool for natural language processing, text mining and information\nretrieval. However, representations that perform well for retrieval must\ncapture semantic meaning at different levels of abstraction or context-scopes.\nIn this paper, we propose a new method to generate multi-resolution word\nembeddings that represent documents at multiple resolutions in terms of\ncontext-scopes. In order to investigate its performance,we use the Stanford\nQuestion Answering Dataset (SQuAD) and the Question Answering by Search And\nReading (QUASAR) in an open-domain question-answering setting, where the first\ntask is to find documents useful for answering a given question. To this end,\nwe first compare the quality of various text-embedding methods for retrieval\nperformance and give an extensive empirical comparison with the performance of\nvarious non-augmented base embeddings with and without multi-resolution\nrepresentation. We argue that multi-resolution word embeddings are consistently\nsuperior to the original counterparts and deep residual neural models\nspecifically trained for retrieval purposes can yield further significant gains\nwhen they are used for augmenting those embeddings.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 07:44:41 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 18:01:07 GMT"}, {"version": "v3", "created": "Thu, 21 Feb 2019 19:22:45 GMT"}, {"version": "v4", "created": "Thu, 2 May 2019 17:47:54 GMT"}, {"version": "v5", "created": "Thu, 9 May 2019 06:46:00 GMT"}, {"version": "v6", "created": "Fri, 10 May 2019 20:25:14 GMT"}, {"version": "v7", "created": "Wed, 22 May 2019 23:03:24 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Cakaloglu", "Tolgahan", ""], ["Xu", "Xiaowei", ""]]}, {"id": "1902.00672", "submitter": "Hadrien Van Lierde", "authors": "Hadrien Van Lierde and Tommy W. S. Chow", "title": "Query-oriented text summarization based on hypergraph transversals", "comments": "This is the unrefereed Author's Original Version (or pre-print\n  Version) of the article", "journal-ref": "Information Processing & Management, Volume 56, Issue 4, July\n  2019, Pages 1317-1338", "doi": "10.1016/j.ipm.2019.03.003", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing graph- and hypergraph-based algorithms for document summarization\nrepresent the sentences of a corpus as the nodes of a graph or a hypergraph in\nwhich the edges represent relationships of lexical similarities between\nsentences. Each sentence of the corpus is then scored individually, using\npopular node ranking algorithms, and a summary is produced by extracting highly\nscored sentences. This approach fails to select a subset of jointly relevant\nsentences and it may produce redundant summaries that are missing important\ntopics of the corpus. To alleviate this issue, a new hypergraph-based\nsummarizer is proposed in this paper, in which each node is a sentence and each\nhyperedge is a theme, namely a group of sentences sharing a topic. Themes are\nweighted in terms of their prominence in the corpus and their relevance to a\nuser-defined query. It is further shown that the problem of identifying a\nsubset of sentences covering the relevant themes of the corpus is equivalent to\nthat of finding a hypergraph transversal in our theme-based hypergraph. Two\nextensions of the notion of hypergraph transversal are proposed for the purpose\nof summarization, and polynomial time algorithms building on the theory of\nsubmodular functions are proposed for solving the associated discrete\noptimization problems. The worst-case time complexity of the proposed\nalgorithms is squared in the number of terms, which makes it cheaper than the\nexisting hypergraph-based methods. A thorough comparative analysis with related\nmodels on DUC benchmark datasets demonstrates the effectiveness of our\napproach, which outperforms existing graph- or hypergraph-based methods by at\nleast 6% of ROUGE-SU4 score.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 08:52:44 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Van Lierde", "Hadrien", ""], ["Chow", "Tommy W. S.", ""]]}, {"id": "1902.00679", "submitter": "Adil Rajput", "authors": "Adil Rajput", "title": "Natural Language Processing, Sentiment Analysis and Clinical Analytics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in Big Data has prompted health care practitioners to utilize\nthe data available on social media to discern sentiment and emotions\nexpression. Health Informatics and Clinical Analytics depend heavily on\ninformation gathered from diverse sources. Traditionally, a healthcare\npractitioner will ask a patient to fill out a questionnaire that will form the\nbasis of diagnosing the medical condition. However, medical practitioners have\naccess to many sources of data including the patients writings on various\nmedia. Natural Language Processing (NLP) allows researchers to gather such data\nand analyze it to glean the underlying meaning of such writings. The field of\nsentiment analysis (applied to many other domains) depend heavily on techniques\nutilized by NLP. This work will look into various prevalent theories underlying\nthe NLP field and how they can be leveraged to gather users sentiments on\nsocial media. Such sentiments can be culled over a period of time thus\nminimizing the errors introduced by data input and other stressors.\nFurthermore, we look at some applications of sentiment analysis and application\nof NLP to mental health. The reader will also learn about the NLTK toolkit that\nimplements various NLP theories and how they can make the data scavenging\nprocess a lot easier.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 09:30:26 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Rajput", "Adil", ""]]}, {"id": "1902.00702", "submitter": "Adil Rajput", "authors": "Adil Rajput, Samara Ahmed", "title": "Making a Case for Social Media Corpus for Detecting Depression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The social media platform provides an opportunity to gain valuable insights\ninto user behaviour. Users mimic their internal feelings and emotions in a\ndisinhibited fashion using natural language. Techniques in Natural Language\nProcessing have helped researchers decipher standard documents and cull\ntogether inferences from massive amount of data. A representative corpus is a\nprerequisite for NLP and one of the challenges we face today is the\nnon-standard and noisy language that exists on the internet. Our work focuses\non building a corpus from social media that is focused on detecting mental\nillness. We use depression as a case study and demonstrate the effectiveness of\nusing such a corpus for helping practitioners detect such cases. Our results\nshow a high correlation between our Social Media Corpus and the standard corpus\nfor depression.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 11:59:28 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Rajput", "Adil", ""], ["Ahmed", "Samara", ""]]}, {"id": "1902.00750", "submitter": "Yuting Yang", "authors": "Yuting Yang, Juan Cao, Mingyan Lu, Jintao Li and Chia-Wen Lin", "title": "How to Write High-quality News on Social Network? Predicting News\n  Quality by Mining Writing Style", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid development of Internet technologies promotes traditional newspapers to\nreport news on social networks. However, people on social networks may have\ndifferent needs which naturally arises the question: whether can we analyze the\ninfluence of writing style on news quality automatically and assist writers in\nimproving news quality? It's challenging due to writing style and 'quality' are\nhard to measure. First, we use 'popularity' as the measure of 'quality'. It is\nnatural on social networks but brings new problems: popularity are also\ninfluenced by event and publisher. So we design two methods to alleviate their\ninfluence. Then, we proposed eight types of linguistic features (53 features in\nall) according eight writing guidelines and analyze their relationship with\nnews quality. The experimental results show these linguistic features influence\ngreatly on news quality. Based on it, we design a news quality assessment model\non social network (SNQAM). SNQAM performs excellently on predicting quality,\npresenting interpretable quality score and giving accessible suggestions on how\nto improve it according to writing guidelines we referred to.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 16:29:12 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 03:18:17 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Yang", "Yuting", ""], ["Cao", "Juan", ""], ["Lu", "Mingyan", ""], ["Li", "Jintao", ""], ["Lin", "Chia-Wen", ""]]}, {"id": "1902.00751", "submitter": "Neil Houlsby", "authors": "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone,\n  Quentin de Laroussilhe, Andrea Gesmundo, Mona Attariyan, Sylvain Gelly", "title": "Parameter-Efficient Transfer Learning for NLP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-tuning large pre-trained models is an effective transfer mechanism in\nNLP. However, in the presence of many downstream tasks, fine-tuning is\nparameter inefficient: an entire new model is required for every task. As an\nalternative, we propose transfer with adapter modules. Adapter modules yield a\ncompact and extensible model; they add only a few trainable parameters per\ntask, and new tasks can be added without revisiting previous ones. The\nparameters of the original network remain fixed, yielding a high degree of\nparameter sharing. To demonstrate adapter's effectiveness, we transfer the\nrecently proposed BERT Transformer model to 26 diverse text classification\ntasks, including the GLUE benchmark. Adapters attain near state-of-the-art\nperformance, whilst adding only a few parameters per task. On GLUE, we attain\nwithin 0.4% of the performance of full fine-tuning, adding only 3.6% parameters\nper task. By contrast, fine-tuning trains 100% of the parameters per task.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 16:29:47 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 17:48:30 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Houlsby", "Neil", ""], ["Giurgiu", "Andrei", ""], ["Jastrzebski", "Stanislaw", ""], ["Morrone", "Bruna", ""], ["de Laroussilhe", "Quentin", ""], ["Gesmundo", "Andrea", ""], ["Attariyan", "Mona", ""], ["Gelly", "Sylvain", ""]]}, {"id": "1902.00753", "submitter": "Erion \\c{C}ano", "authors": "Erion \\c{C}ano and Maurizio Morisio", "title": "Word Embeddings for Sentiment Analysis: A Comprehensive Empirical Survey", "comments": "20 pages, 16 figures, 15 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This work investigates the role of factors like training method, training\ncorpus size and thematic relevance of texts in the performance of word\nembedding features on sentiment analysis of tweets, song lyrics, movie reviews\nand item reviews. We also explore specific training or post-processing methods\nthat can be used to enhance the performance of word embeddings in certain tasks\nor domains. Our empirical observations indicate that models trained with\nmultithematic texts that are large and rich in vocabulary are the best in\nanswering syntactic and semantic word analogy questions. We further observe\nthat influence of thematic relevance is stronger on movie and phone reviews,\nbut weaker on tweets and lyrics. These two later domains are more sensitive to\ncorpus size and training method, with Glove outperforming Word2vec. \"Injecting\"\nextra intelligence from lexicons or generating sentiment specific word\nembeddings are two prominent alternatives for increasing performance of word\nembedding features.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 17:04:14 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["\u00c7ano", "Erion", ""], ["Morisio", "Maurizio", ""]]}, {"id": "1902.00756", "submitter": "Hao Zhu", "authors": "Hao Zhu, Yankai Lin, Zhiyuan Liu, Jie Fu, Tat-seng Chua, Maosong Sun", "title": "Graph Neural Networks with Generated Parameters for Relation Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Recently, progress has been made towards improving relational reasoning in\nmachine learning field. Among existing models, graph neural networks (GNNs) is\none of the most effective approaches for multi-hop relational reasoning. In\nfact, multi-hop relational reasoning is indispensable in many natural language\nprocessing tasks such as relation extraction. In this paper, we propose to\ngenerate the parameters of graph neural networks (GP-GNNs) according to natural\nlanguage sentences, which enables GNNs to process relational reasoning on\nunstructured text inputs. We verify GP-GNNs in relation extraction from text.\nExperimental results on a human-annotated dataset and two distantly supervised\ndatasets show that our model achieves significant improvements compared to\nbaselines. We also perform a qualitative analysis to demonstrate that our model\ncould discover more accurate relations by multi-hop relational reasoning.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 17:34:19 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Zhu", "Hao", ""], ["Lin", "Yankai", ""], ["Liu", "Zhiyuan", ""], ["Fu", "Jie", ""], ["Chua", "Tat-seng", ""], ["Sun", "Maosong", ""]]}, {"id": "1902.00821", "submitter": "Hu Xu", "authors": "Hu Xu, Bing Liu, Lei Shu, Philip S. Yu", "title": "Review Conversational Reading Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by conversational reading comprehension (CRC), this paper studies a\nnovel task of leveraging reviews as a source to build an agent that can answer\nmulti-turn questions from potential consumers of online businesses. We first\nbuild a review CRC dataset and then propose a novel task-aware pre-tuning step\nrunning between language model (e.g., BERT) pre-training and domain-specific\nfine-tuning. The proposed pre-tuning requires no data annotation, but can\ngreatly enhance the performance on our end task. Experimental results show that\nthe proposed approach is highly effective and has competitive performance as\nthe supervised approach. The dataset is available at\n\\url{https://github.com/howardhsu/RCRC}\n", "versions": [{"version": "v1", "created": "Sun, 3 Feb 2019 00:32:46 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 17:25:40 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Xu", "Hu", ""], ["Liu", "Bing", ""], ["Shu", "Lei", ""], ["Yu", "Philip S.", ""]]}, {"id": "1902.00863", "submitter": "Jiacheng Xu", "authors": "Jiacheng Xu and Greg Durrett", "title": "Neural Extractive Text Summarization with Syntactic Compression", "comments": "14 pages, EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent neural network approaches to summarization are largely either\nselection-based extraction or generation-based abstraction. In this work, we\npresent a neural model for single-document summarization based on joint\nextraction and syntactic compression. Our model chooses sentences from the\ndocument, identifies possible compressions based on constituency parses, and\nscores those compressions with a neural model to produce the final summary. For\nlearning, we construct oracle extractive-compressive summaries, then learn both\nof our components jointly with this supervision. Experimental results on the\nCNN/Daily Mail and New York Times datasets show that our model achieves strong\nperformance (comparable to state-of-the-art systems) as evaluated by ROUGE.\nMoreover, our approach outperforms an off-the-shelf compression module, and\nhuman and manual evaluation shows that our model's output generally remains\ngrammatical.\n", "versions": [{"version": "v1", "created": "Sun, 3 Feb 2019 08:19:42 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 19:43:46 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Xu", "Jiacheng", ""], ["Durrett", "Greg", ""]]}, {"id": "1902.00913", "submitter": "Maximilian Nickel", "authors": "Matt Le, Stephen Roller, Laetitia Papaxanthos, Douwe Kiela, Maximilian\n  Nickel", "title": "Inferring Concept Hierarchies from Text Corpora via Hyperbolic\n  Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of inferring is-a relationships from large text corpora.\nFor this purpose, we propose a new method combining hyperbolic embeddings and\nHearst patterns. This approach allows us to set appropriate constraints for\ninferring concept hierarchies from distributional contexts while also being\nable to predict missing is-a relationships and to correct wrong extractions.\nMoreover -- and in contrast with other methods -- the hierarchical nature of\nhyperbolic space allows us to learn highly efficient representations and to\nimprove the taxonomic consistency of the inferred hierarchies. Experimentally,\nwe show that our approach achieves state-of-the-art performance on several\ncommonly-used benchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 3 Feb 2019 16:03:29 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Le", "Matt", ""], ["Roller", "Stephen", ""], ["Papaxanthos", "Laetitia", ""], ["Kiela", "Douwe", ""], ["Nickel", "Maximilian", ""]]}, {"id": "1902.00972", "submitter": "Jenna Kanerva", "authors": "Jenna Kanerva, Filip Ginter, and Tapio Salakoski", "title": "Universal Lemmatizer: A Sequence to Sequence Model for Lemmatizing\n  Universal Dependencies Treebanks", "comments": "Accepted to the Journal of Natural Language Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a novel lemmatization method based on a\nsequence-to-sequence neural network architecture and morphosyntactic context\nrepresentation. In the proposed method, our context-sensitive lemmatizer\ngenerates the lemma one character at a time based on the surface form\ncharacters and its morphosyntactic features obtained from a morphological\ntagger. We argue that a sliding window context representation suffers from\nsparseness, while in majority of cases the morphosyntactic features of a word\nbring enough information to resolve lemma ambiguities while keeping the context\nrepresentation dense and more practical for machine learning systems.\nAdditionally, we study two different data augmentation methods utilizing\nautoencoder training and morphological transducers especially beneficial for\nlow resource languages. We evaluate our lemmatizer on 52 different languages\nand 76 different treebanks, showing that our system outperforms all latest\nbaseline systems. Compared to the best overall baseline, UDPipe Future, our\nsystem outperforms it on 62 out of 76 treebanks reducing errors on average by\n19% relative. The lemmatizer together with all trained models is made available\nas a part of the Turku-neural-parsing-pipeline under the Apache 2.0 license.\n", "versions": [{"version": "v1", "created": "Sun, 3 Feb 2019 21:38:29 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 09:16:15 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Kanerva", "Jenna", ""], ["Ginter", "Filip", ""], ["Salakoski", "Tapio", ""]]}, {"id": "1902.00993", "submitter": "Kai Sun", "authors": "Xiaoman Pan, Kai Sun, Dian Yu, Jianshu Chen, Heng Ji, Claire Cardie,\n  Dong Yu", "title": "Improving Question Answering with External Knowledge", "comments": "Accepted to MRQA (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on multiple-choice question answering (QA) tasks in subject areas\nsuch as science, where we require both broad background knowledge and the facts\nfrom the given subject-area reference corpus. In this work, we explore simple\nyet effective methods for exploiting two sources of external knowledge for\nsubject-area QA. The first enriches the original subject-area reference corpus\nwith relevant text snippets extracted from an open-domain resource (i.e.,\nWikipedia) that cover potentially ambiguous concepts in the question and answer\noptions. As in other QA research, the second method simply increases the amount\nof training data by appending additional in-domain subject-area instances.\n  Experiments on three challenging multiple-choice science QA tasks (i.e.,\nARC-Easy, ARC-Challenge, and OpenBookQA) demonstrate the effectiveness of our\nmethods: in comparison to the previous state-of-the-art, we obtain absolute\ngains in accuracy of up to 8.1%, 13.0%, and 12.8%, respectively. While we\nobserve consistent gains when we introduce knowledge from Wikipedia, we find\nthat employing additional QA training instances is not uniformly helpful:\nperformance degrades when the added instances exhibit a higher level of\ndifficulty than the original training data. As one of the first studies on\nexploiting unstructured external knowledge for subject-area QA, we hope our\nmethods, observations, and discussion of the exposed limitations may shed light\non further developments in the area.\n", "versions": [{"version": "v1", "created": "Sun, 3 Feb 2019 23:44:10 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 20:32:42 GMT"}, {"version": "v3", "created": "Tue, 1 Oct 2019 20:25:33 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Pan", "Xiaoman", ""], ["Sun", "Kai", ""], ["Yu", "Dian", ""], ["Chen", "Jianshu", ""], ["Ji", "Heng", ""], ["Cardie", "Claire", ""], ["Yu", "Dong", ""]]}, {"id": "1902.01007", "submitter": "Tom McCoy", "authors": "R. Thomas McCoy and Ellie Pavlick and Tal Linzen", "title": "Right for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural\n  Language Inference", "comments": "Camera-ready for ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A machine learning system can score well on a given test set by relying on\nheuristics that are effective for frequent example types but break down in more\nchallenging cases. We study this issue within natural language inference (NLI),\nthe task of determining whether one sentence entails another. We hypothesize\nthat statistical NLI models may adopt three fallible syntactic heuristics: the\nlexical overlap heuristic, the subsequence heuristic, and the constituent\nheuristic. To determine whether models have adopted these heuristics, we\nintroduce a controlled evaluation set called HANS (Heuristic Analysis for NLI\nSystems), which contains many examples where the heuristics fail. We find that\nmodels trained on MNLI, including BERT, a state-of-the-art model, perform very\npoorly on HANS, suggesting that they have indeed adopted these heuristics. We\nconclude that there is substantial room for improvement in NLI systems, and\nthat the HANS dataset can motivate and measure progress in this area\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 01:54:19 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 13:36:17 GMT"}, {"version": "v3", "created": "Mon, 17 Jun 2019 19:59:59 GMT"}, {"version": "v4", "created": "Mon, 24 Jun 2019 16:02:01 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["McCoy", "R. Thomas", ""], ["Pavlick", "Ellie", ""], ["Linzen", "Tal", ""]]}, {"id": "1902.01030", "submitter": "Haoyu Wang", "authors": "Haoyu Wang, Ming Tan, Mo Yu, Shiyu Chang, Dakuo Wang, Kun Xu, Xiaoxiao\n  Guo, Saloni Potdar", "title": "Extracting Multiple-Relations in One-Pass with Pre-Trained Transformers", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most approaches to extraction multiple relations from a paragraph require\nmultiple passes over the paragraph. In practice, multiple passes are\ncomputationally expensive and this makes difficult to scale to longer\nparagraphs and larger text corpora. In this work, we focus on the task of\nmultiple relation extraction by encoding the paragraph only once (one-pass). We\nbuild our solution on the pre-trained self-attentive (Transformer) models,\nwhere we first add a structured prediction layer to handle extraction between\nmultiple entity pairs, then enhance the paragraph embedding to capture multiple\nrelational information associated with each entity with an entity-aware\nattention technique. We show that our approach is not only scalable but can\nalso perform state-of-the-art on the standard benchmark ACE 2005.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 04:42:08 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 14:43:32 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Wang", "Haoyu", ""], ["Tan", "Ming", ""], ["Yu", "Mo", ""], ["Chang", "Shiyu", ""], ["Wang", "Dakuo", ""], ["Xu", "Kun", ""], ["Guo", "Xiaoxiao", ""], ["Potdar", "Saloni", ""]]}, {"id": "1902.01069", "submitter": "Wonseok Hwang", "authors": "Wonseok Hwang, Jinyeong Yim, Seunghyun Park, Minjoon Seo", "title": "A Comprehensive Exploration on WikiSQL with Table-Aware Word\n  Contextualization", "comments": "KR2ML Workshop at NeurIPS 2019, 11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present SQLova, the first Natural-language-to-SQL (NL2SQL) model to\nachieve human performance in WikiSQL dataset. We revisit and discuss diverse\npopular methods in NL2SQL literature, take a full advantage of BERT {Devlin et\nal., 2018) through an effective table contextualization method, and coherently\ncombine them, outperforming the previous state of the art by 8.2% and 2.5% in\nlogical form and execution accuracy, respectively. We particularly note that\nBERT with a seq2seq decoder leads to a poor performance in the task, indicating\nthe importance of a careful design when using such large pretrained models. We\nalso provide a comprehensive analysis on the dataset and our model, which can\nbe helpful for designing future NL2SQL datsets and models. We especially show\nthat our model's performance is near the upper bound in WikiSQL, where we\nobserve that a large portion of the evaluation errors are due to wrong\nannotations, and our model is already exceeding human performance by 1.3% in\nexecution accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 07:55:47 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 04:48:46 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Hwang", "Wonseok", ""], ["Yim", "Jinyeong", ""], ["Park", "Seunghyun", ""], ["Seo", "Minjoon", ""]]}, {"id": "1902.01109", "submitter": "Angela Fan", "authors": "Angela Fan, Mike Lewis, Yann Dauphin", "title": "Strategies for Structuring Story Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Writers generally rely on plans or sketches to write long stories, but most\ncurrent language models generate word by word from left to right. We explore\ncoarse-to-fine models for creating narrative texts of several hundred words,\nand introduce new models which decompose stories by abstracting over actions\nand entities. The model first generates the predicate-argument structure of the\ntext, where different mentions of the same entity are marked with placeholder\ntokens. It then generates a surface realization of the predicate-argument\nstructure, and finally replaces the entity placeholders with context-sensitive\nnames and references. Human judges prefer the stories from our models to a wide\nrange of previous approaches to hierarchical text generation. Extensive\nanalysis shows that our methods can help improve the diversity and coherence of\nevents and entities in generated stories.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 10:23:39 GMT"}, {"version": "v2", "created": "Sat, 15 Jun 2019 21:25:44 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Fan", "Angela", ""], ["Lewis", "Mike", ""], ["Dauphin", "Yann", ""]]}, {"id": "1902.01119", "submitter": "Guy Tennenholtz", "authors": "Guy Tennenholtz, Shie Mannor", "title": "The Natural Language of Actions", "comments": "Published in the proceedings of the 36th International Conference on\n  Machine Learning (ICML 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Act2Vec, a general framework for learning context-based action\nrepresentation for Reinforcement Learning. Representing actions in a vector\nspace help reinforcement learning algorithms achieve better performance by\ngrouping similar actions and utilizing relations between different actions. We\nshow how prior knowledge of an environment can be extracted from demonstrations\nand injected into action vector representations that encode natural compatible\nbehavior. We then use these for augmenting state representations as well as\nimproving function approximation of Q-values. We visualize and test action\nembeddings in three domains including a drawing task, a high dimensional\nnavigation task, and the large action space domain of StarCraft II.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 10:46:53 GMT"}, {"version": "v2", "created": "Sun, 19 May 2019 07:35:28 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Tennenholtz", "Guy", ""], ["Mannor", "Shie", ""]]}, {"id": "1902.01177", "submitter": "Wei-Hung Weng", "authors": "Wei-Hung Weng, Yu-An Chung, Peter Szolovits", "title": "Unsupervised Clinical Language Translation", "comments": "Accepted to KDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As patients' access to their doctors' clinical notes becomes common,\ntranslating professional, clinical jargon to layperson-understandable language\nis essential to improve patient-clinician communication. Such translation\nyields better clinical outcomes by enhancing patients' understanding of their\nown health conditions, and thus improving patients' involvement in their own\ncare. Existing research has used dictionary-based word replacement or\ndefinition insertion to approach the need. However, these methods are limited\nby expert curation, which is hard to scale and has trouble generalizing to\nunseen datasets that do not share an overlapping vocabulary. In contrast, we\napproach the clinical word and sentence translation problem in a completely\nunsupervised manner. We show that a framework using representation learning,\nbilingual dictionary induction and statistical machine translation yields the\nbest precision at 10 of 0.827 on professional-to-consumer word translation, and\nmean opinion scores of 4.10 and 4.28 out of 5 for clinical correctness and\nlayperson readability, respectively, on sentence translation. Our\nfully-unsupervised strategy overcomes the curation problem, and the clinically\nmeaningful evaluation reduces biases from inappropriate evaluators, which are\ncritical in clinical machine learning.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 13:47:18 GMT"}, {"version": "v2", "created": "Sun, 26 May 2019 08:35:17 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Weng", "Wei-Hung", ""], ["Chung", "Yu-An", ""], ["Szolovits", "Peter", ""]]}, {"id": "1902.01267", "submitter": "Dafydd Gibbon", "authors": "Dafydd Gibbon and Xuewei Lin", "title": "Rhythm Zone Theory: Speech Rhythms are Physical after all", "comments": "15 pages, 9 figures, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech rhythms have been dealt with in three main ways: from the\nintrospective analyses of rhythm as a correlate of syllable and foot timing in\nlinguistics and applied linguistics, through analyses of durations of segments\nof utterances associated with consonantal and vocalic properties, syllables,\nfeet and words, to models of rhythms in speech production and perception as\nphysical oscillations. The present study avoids introspection and\nhuman-filtered annotation methods and extends the signal processing paradigm of\namplitude envelope spectrum analysis by adding an additional analytic step of\nedge detection, and postulating the co-existence of multiple speech rhythms in\nrhythm zones marked by identifiable edges (Rhythm Zone Theory, RZT). An\nexploratory investigation of the utility of RZT is conducted, suggesting that\nnative and non-native readings of the same text are distinct sub-genres of read\nspeech: a reading by a US native speaker and non-native readings by relatively\nlow-performing Cantonese adult learners of English. The study concludes by\nnoting that with the methods used, RZT can distinguish between the speech\nrhythms of well-defined sub-genres of native speaker reading vs. non-native\nlearner reading, but needs further refinement in order to be applied to the\nparadoxically more complex speech of low-performing language learners, whose\nspeech rhythms are co-determined by non-fluency and disfluency factors in\naddition to well-known linguistic factors of grammar, vocabulary and discourse\nconstraints.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 20:49:17 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 19:01:22 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Gibbon", "Dafydd", ""], ["Lin", "Xuewei", ""]]}, {"id": "1902.01313", "submitter": "Mikel Artetxe", "authors": "Mikel Artetxe, Gorka Labaka, Eneko Agirre", "title": "An Effective Approach to Unsupervised Machine Translation", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While machine translation has traditionally relied on large amounts of\nparallel corpora, a recent research line has managed to train both Neural\nMachine Translation (NMT) and Statistical Machine Translation (SMT) systems\nusing monolingual corpora only. In this paper, we identify and address several\ndeficiencies of existing unsupervised SMT approaches by exploiting subword\ninformation, developing a theoretically well founded unsupervised tuning\nmethod, and incorporating a joint refinement procedure. Moreover, we use our\nimproved SMT system to initialize a dual NMT model, which is further fine-tuned\nthrough on-the-fly back-translation. Together, we obtain large improvements\nover the previous state-of-the-art in unsupervised machine translation. For\ninstance, we get 22.5 BLEU points in English-to-German WMT 2014, 5.5 points\nmore than the previous best unsupervised system, and 0.5 points more than the\n(supervised) shared task winner back in 2014.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 17:08:32 GMT"}, {"version": "v2", "created": "Wed, 24 Jul 2019 22:23:38 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Artetxe", "Mikel", ""], ["Labaka", "Gorka", ""], ["Agirre", "Eneko", ""]]}, {"id": "1902.01349", "submitter": "Juri Opitz", "authors": "Juri Opitz, Anette Frank", "title": "An Argument-Marker Model for Syntax-Agnostic Proto-Role Labeling", "comments": "accepted at *SEM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic proto-role labeling (SPRL) is an alternative to semantic role\nlabeling (SRL) that moves beyond a categorical definition of roles, following\nDowty's feature-based view of proto-roles. This theory determines agenthood vs.\npatienthood based on a participant's instantiation of more or less typical\nagent vs. patient properties, such as, for example, volition in an event. To\nperform SPRL, we develop an ensemble of hierarchical models with self-attention\nand concurrently learned predicate-argument-markers. Our method is competitive\nwith the state-of-the art, overall outperforming previous work in two\nformulations of the task (multi-label and multi-variate Likert scale\nprediction). In contrast to previous work, our results do not depend on gold\nargument heads derived from supplementary gold tree banks.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 18:11:36 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2019 07:47:44 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Opitz", "Juri", ""], ["Frank", "Anette", ""]]}, {"id": "1902.01370", "submitter": "Jiatao Gu", "authors": "Jiatao Gu, Qi Liu and Kyunghyun Cho", "title": "Insertion-based Decoding with automatically Inferred Generation Order", "comments": "Camera ready. Accepted by TACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional neural autoregressive decoding commonly assumes a fixed\nleft-to-right generation order, which may be sub-optimal. In this work, we\npropose a novel decoding algorithm -- InDIGO -- which supports flexible\nsequence generation in arbitrary orders through insertion operations. We extend\nTransformer, a state-of-the-art sequence generation model, to efficiently\nimplement the proposed approach, enabling it to be trained with either a\npre-defined generation order or adaptive orders obtained from beam-search.\nExperiments on four real-world tasks, including word order recovery, machine\ntranslation, image caption and code generation, demonstrate that our algorithm\ncan generate sequences following arbitrary orders, while achieving competitive\nor even better performance compared to the conventional left-to-right\ngeneration. The generated sequences show that InDIGO adopts adaptive generation\norders based on input information.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 18:35:59 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 18:56:48 GMT"}, {"version": "v3", "created": "Mon, 28 Oct 2019 07:55:12 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Gu", "Jiatao", ""], ["Liu", "Qi", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1902.01382", "submitter": "Myle Ott", "authors": "Francisco Guzm\\'an, Peng-Jen Chen, Myle Ott, Juan Pino, Guillaume\n  Lample, Philipp Koehn, Vishrav Chaudhary, Marc'Aurelio Ranzato", "title": "The FLoRes Evaluation Datasets for Low-Resource Machine Translation:\n  Nepali-English and Sinhala-English", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For machine translation, a vast majority of language pairs in the world are\nconsidered low-resource because they have little parallel data available.\nBesides the technical challenges of learning with limited supervision, it is\ndifficult to evaluate methods trained on low-resource language pairs because of\nthe lack of freely and publicly available benchmarks. In this work, we\nintroduce the FLoRes evaluation datasets for Nepali-English and\nSinhala-English, based on sentences translated from Wikipedia. Compared to\nEnglish, these are languages with very different morphology and syntax, for\nwhich little out-of-domain parallel data is available and for which relatively\nlarge amounts of monolingual data are freely available. We describe our process\nto collect and cross-check the quality of translations, and we report baseline\nperformance using several learning settings: fully supervised, weakly\nsupervised, semi-supervised, and fully unsupervised. Our experiments\ndemonstrate that current state-of-the-art methods perform rather poorly on this\nbenchmark, posing a challenge to the research community working on low-resource\nMT. Data and code to reproduce our experiments are available at\nhttps://github.com/facebookresearch/flores.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 18:48:45 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2019 20:05:12 GMT"}, {"version": "v3", "created": "Sat, 14 Sep 2019 19:09:55 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Guzm\u00e1n", "Francisco", ""], ["Chen", "Peng-Jen", ""], ["Ott", "Myle", ""], ["Pino", "Juan", ""], ["Lample", "Guillaume", ""], ["Koehn", "Philipp", ""], ["Chaudhary", "Vishrav", ""], ["Ranzato", "Marc'Aurelio", ""]]}, {"id": "1902.01385", "submitter": "Devendra Singh Chaplot", "authors": "Devendra Singh Chaplot, Lisa Lee, Ruslan Salakhutdinov, Devi Parikh,\n  Dhruv Batra", "title": "Embodied Multimodal Multitask Learning", "comments": "See https://devendrachaplot.github.io/projects/EMML for demo videos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent efforts on training visual navigation agents conditioned on language\nusing deep reinforcement learning have been successful in learning policies for\ndifferent multimodal tasks, such as semantic goal navigation and embodied\nquestion answering. In this paper, we propose a multitask model capable of\njointly learning these multimodal tasks, and transferring knowledge of words\nand their grounding in visual objects across the tasks. The proposed model uses\na novel Dual-Attention unit to disentangle the knowledge of words in the\ntextual representations and visual concepts in the visual representations, and\nalign them with each other. This disentangled task-invariant alignment of\nrepresentations facilitates grounding and knowledge transfer across both tasks.\nWe show that the proposed model outperforms a range of baselines on both tasks\nin simulated 3D environments. We also show that this disentanglement of\nrepresentations makes our model modular, interpretable, and allows for transfer\nto instructions containing new words by leveraging object detectors.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 18:53:14 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Chaplot", "Devendra Singh", ""], ["Lee", "Lisa", ""], ["Salakhutdinov", "Ruslan", ""], ["Parikh", "Devi", ""], ["Batra", "Dhruv", ""]]}, {"id": "1902.01390", "submitter": "Siddharth Vashishtha", "authors": "Siddharth Vashishtha, Benjamin Van Durme, Aaron Steven White", "title": "Fine-Grained Temporal Relation Extraction", "comments": "Proceedings of the 57th Annual Meeting of the Association for\n  Computational Linguistics (ACL 2019), Florence, Italy, July 29-31, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel semantic framework for modeling temporal relations and\nevent durations that maps pairs of events to real-valued scales. We use this\nframework to construct the largest temporal relations dataset to date, covering\nthe entirety of the Universal Dependencies English Web Treebank. We use this\ndataset to train models for jointly predicting fine-grained temporal relations\nand event durations. We report strong results on our data and show the efficacy\nof a transfer-learning approach for predicting categorical relations.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 18:58:18 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 21:18:54 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Vashishtha", "Siddharth", ""], ["Van Durme", "Benjamin", ""], ["White", "Aaron Steven", ""]]}, {"id": "1902.01474", "submitter": "Yunong Shi", "authors": "Yunong Shi, Nelson Leung, Pranav Gokhale, Zane Rossi, David I.\n  Schuster, Henry Hoffman, Fred T. Chong", "title": "Optimized Compilation of Aggregated Instructions for Realistic Quantum\n  Computers", "comments": "13 pages, to apper in ASPLOS", "journal-ref": null, "doi": "10.1145/3297858.3304018", "report-no": null, "categories": "quant-ph cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in engineering and algorithms have made real-world\napplications in quantum computing possible in the near future. Existing quantum\nprogramming languages and compilers use a quantum assembly language composed of\n1- and 2-qubit (quantum bit) gates. Quantum compiler frameworks translate this\nquantum assembly to electric signals (called control pulses) that implement the\nspecified computation on specific physical devices. However, there is a\nmismatch between the operations defined by the 1- and 2-qubit logical ISA and\ntheir underlying physical implementation, so the current practice of directly\ntranslating logical instructions into control pulses results in inefficient,\nhigh-latency programs. To address this inefficiency, we propose a universal\nquantum compilation methodology that aggregates multiple logical operations\ninto larger units that manipulate up to 10 qubits at a time. Our methodology\nthen optimizes these aggregates by (1) finding commutative intermediate\noperations that result in more efficient schedules and (2) creating custom\ncontrol pulses optimized for the aggregate (instead of individual 1- and\n2-qubit operations). Compared to the standard gate-based compilation, the\nproposed approach realizes a deeper vertical integration of high-level quantum\nsoftware and low-level, physical quantum hardware. We evaluate our approach on\nimportant near-term quantum applications on simulations of superconducting\nquantum architectures. Our proposed approach provides a mean speedup of\n$5\\times$, with a maximum of $10\\times$. Because latency directly affects the\nfeasibility of quantum computation, our results not only improve performance\nbut also have the potential to enable quantum computation sooner than otherwise\npossible.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 22:05:50 GMT"}, {"version": "v2", "created": "Sun, 17 Feb 2019 19:55:20 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Shi", "Yunong", ""], ["Leung", "Nelson", ""], ["Gokhale", "Pranav", ""], ["Rossi", "Zane", ""], ["Schuster", "David I.", ""], ["Hoffman", "Henry", ""], ["Chong", "Fred T.", ""]]}, {"id": "1902.01509", "submitter": "Omer Levy", "authors": "Vladimir Karpukhin, Omer Levy, Jacob Eisenstein, Marjan Ghazvininejad", "title": "Training on Synthetic Noise Improves Robustness to Natural Noise in\n  Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of making machine translation more robust to\ncharacter-level variation at the source side, such as typos. Existing methods\nachieve greater coverage by applying subword models such as byte-pair encoding\n(BPE) and character-level encoders, but these methods are highly sensitive to\nspelling mistakes. We show how training on a mild amount of random synthetic\nnoise can dramatically improve robustness to these variations, without\ndiminishing performance on clean text. We focus on translation performance on\nnatural noise, as captured by frequent corrections in Wikipedia edit logs, and\nshow that robustness to such noise can be achieved using a balanced diet of\nsimple synthetic noises at training time, without access to the natural noise\ndata or distribution.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 01:17:07 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Karpukhin", "Vladimir", ""], ["Levy", "Omer", ""], ["Eisenstein", "Jacob", ""], ["Ghazvininejad", "Marjan", ""]]}, {"id": "1902.01529", "submitter": "Ryota Tanaka", "authors": "Ryota Tanaka, Akihide Ozeki, Shugo Kato, Akinobu Lee", "title": "An Ensemble Dialogue System for Facts-Based Sentence Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study aims to generate responses based on real-world facts by\nconditioning context and external facts extracted from information websites.\nOur system is an ensemble system that combines three modules: generated-based\nmodule, retrieval-based module, and reranking module. Therefore, this system\ncan return diverse and meaningful responses from various perspectives. The\nexperiments and evaluations are conducted with the sentence generation task in\nDialog System Technology Challenges 7 (DSTC7-Task2). As a result, the proposed\nsystem performed significantly better than sole modules, and worked fine at the\nDSTC7-Task2, specifically on the objective evaluation.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 03:25:24 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Tanaka", "Ryota", ""], ["Ozeki", "Akihide", ""], ["Kato", "Shugo", ""], ["Lee", "Akinobu", ""]]}, {"id": "1902.01541", "submitter": "Fei Liu", "authors": "Fei Liu and Luke Zettlemoyer and Jacob Eisenstein", "title": "The Referential Reader: A Recurrent Entity Network for Anaphora\n  Resolution", "comments": "Published at the 57th Annual Meeting of the Association for\n  Computational Linguistics (ACL) 2019. Source code available at:\n  https://github.com/liufly/refreader", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new architecture for storing and accessing entity mentions\nduring online text processing. While reading the text, entity references are\nidentified, and may be stored by either updating or overwriting a cell in a\nfixed-length memory. The update operation implies coreference with the other\nmentions that are stored in the same cell; the overwrite operation causes these\nmentions to be forgotten. By encoding the memory operations as differentiable\ngates, it is possible to train the model end-to-end, using both a supervised\nanaphora resolution objective as well as a supplementary language modeling\nobjective. Evaluation on a dataset of pronoun-name anaphora demonstrates strong\nperformance with purely incremental text processing.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 04:41:55 GMT"}, {"version": "v2", "created": "Tue, 9 Jul 2019 07:10:21 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Liu", "Fei", ""], ["Zettlemoyer", "Luke", ""], ["Eisenstein", "Jacob", ""]]}, {"id": "1902.01615", "submitter": "Prakhar Ganesh", "authors": "Prakhar Ganesh, Saket Dingliwal", "title": "Restructuring Conversations using Discourse Relations for Zero-shot\n  Abstractive Dialogue Summarization", "comments": "4 pages + supplementary", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dialogue summarization is a challenging problem due to the informal and\nunstructured nature of conversational data. Recent advances in abstractive\nsummarization have been focused on data-hungry neural models and adapting these\nmodels to a new domain requires the availability of domain-specific manually\nannotated corpus created by linguistic experts. We propose a zero-shot\nabstractive dialogue summarization method that uses discourse relations to\nprovide structure to conversations, and then uses an out-of-the-box document\nsummarization model to create final summaries. Experiments on the AMI and ICSI\nmeeting corpus, with document summarization models like PGN and BART, shows\nthat our method improves the ROGUE score by up to 3 points, and even performs\ncompetitively against other state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 09:50:47 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 07:04:22 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Ganesh", "Prakhar", ""], ["Dingliwal", "Saket", ""]]}, {"id": "1902.01718", "submitter": "Jimmy Lin", "authors": "Wei Yang, Yuqing Xie, Aileen Lin, Xingyu Li, Luchen Tan, Kun Xiong,\n  Ming Li, and Jimmy Lin", "title": "End-to-End Open-Domain Question Answering with BERTserini", "comments": "Published in the Proceedings of the 2019 Conference of the North\n  American Chapter of the Association for Computational Linguistics\n  (Demonstrations)", "journal-ref": null, "doi": "10.18653/v1/N19-4013", "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate an end-to-end question answering system that integrates BERT\nwith the open-source Anserini information retrieval toolkit. In contrast to\nmost question answering and reading comprehension models today, which operate\nover small amounts of input text, our system integrates best practices from IR\nwith a BERT-based reader to identify answers from a large corpus of Wikipedia\narticles in an end-to-end fashion. We report large improvements over previous\nresults on a standard benchmark test collection, showing that fine-tuning\npretrained BERT with SQuAD is sufficient to achieve high accuracy in\nidentifying answer spans.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 14:50:48 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 01:31:39 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Yang", "Wei", ""], ["Xie", "Yuqing", ""], ["Lin", "Aileen", ""], ["Li", "Xingyu", ""], ["Tan", "Luchen", ""], ["Xiong", "Kun", ""], ["Li", "Ming", ""], ["Lin", "Jimmy", ""]]}, {"id": "1902.01918", "submitter": "Po-Hsu Chen", "authors": "Michael A. Schwemmer, Po-Hsu Chen, Mithun Balakrishna, Amy Leibrand,\n  Aaron Leonard, Nancy J. McMillan, and Jeffrey J. Geppert", "title": "CMS Sematrix: A Tool to Aid the Development of Clinical Quality Measures\n  (CQMs)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As part of the effort to improve quality and to reduce national healthcare\ncosts, the Centers for Medicare and Medicaid Services (CMS) are responsible for\ncreating and maintaining an array of clinical quality measures (CQMs) for\nassessing healthcare structure, process, outcome, and patient experience across\nvarious conditions, clinical specialties, and settings. The development and\nmaintenance of CQMs involves substantial and ongoing evaluation of the evidence\non the measure's properties: importance, reliability, validity, feasibility,\nand usability. As such, CMS conducts monthly environmental scans of the\npublished clinical and health service literature. Conducting time consuming,\nexhaustive evaluations of the ever-changing healthcare literature presents one\nof the largest challenges to an evidence-based approach to healthcare quality\nimprovement. Thus, it is imperative to leverage automated techniques to aid CMS\nin the identification of clinical and health services literature relevant to\nCQMs. Additionally, the estimated labor hours and related cost savings of using\nCMS Sematrix compared to a traditional literature review are roughly 818 hours\nand 122,000 dollars for a single monthly environmental scan.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 21:26:57 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Schwemmer", "Michael A.", ""], ["Chen", "Po-Hsu", ""], ["Balakrishna", "Mithun", ""], ["Leibrand", "Amy", ""], ["Leonard", "Aaron", ""], ["McMillan", "Nancy J.", ""], ["Geppert", "Jeffrey J.", ""]]}, {"id": "1902.01951", "submitter": "Thai Son Nguyen", "authors": "Thai-Son Nguyen, Sebastian Stueker, Alex Waibel", "title": "Using multi-task learning to improve the performance of acoustic-to-word\n  and conventional hybrid models", "comments": "submitted newer work which includes this paper results", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustic-to-word (A2W) models that allow direct mapping from acoustic signals\nto word sequences are an appealing approach to end-to-end automatic speech\nrecognition due to their simplicity. However, prior works have shown that\nmodelling A2W typically encounters issues of data sparsity that prevent\ntraining such a model directly. So far, pre-training initialization is the only\napproach proposed to deal with this issue. In this work, we propose to build a\nshared neural network and optimize A2W and conventional hybrid models in a\nmulti-task manner. Our results show that training an A2W model is much more\nstable with our multi-task model without pre-training initialization, and\nresults in a significant improvement compared to a baseline model. Experiments\nalso reveal that the performance of a hybrid acoustic model can be further\nimproved when jointly training with a sequence-level optimization criterion\nsuch as acoustic-to-word.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 07:33:48 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 20:29:06 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Nguyen", "Thai-Son", ""], ["Stueker", "Sebastian", ""], ["Waibel", "Alex", ""]]}, {"id": "1902.01955", "submitter": "Kazuki Irie", "authors": "Kazuki Irie, Rohit Prabhavalkar, Anjuli Kannan, Antoine Bruguier,\n  David Rybach, Patrick Nguyen", "title": "On the Choice of Modeling Unit for Sequence-to-Sequence Speech\n  Recognition", "comments": "To appear in the proceedings of INTERSPEECH 2019", "journal-ref": null, "doi": "10.21437/Interspeech.2019-2277", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In conventional speech recognition, phoneme-based models outperform\ngrapheme-based models for non-phonetic languages such as English. The\nperformance gap between the two typically reduces as the amount of training\ndata is increased. In this work, we examine the impact of the choice of\nmodeling unit for attention-based encoder-decoder models. We conduct\nexperiments on the LibriSpeech 100hr, 460hr, and 960hr tasks, using various\ntarget units (phoneme, grapheme, and word-piece); across all tasks, we find\nthat grapheme or word-piece models consistently outperform phoneme-based\nmodels, even though they are evaluated without a lexicon or an external\nlanguage model. We also investigate model complementarity: we find that we can\nimprove WERs by up to 9% relative by rescoring N-best lists generated from a\nstrong word-piece based baseline with either the phoneme or the grapheme model.\nRescoring an N-best list generated by the phonemic system, however, provides\nlimited improvements. Further analysis shows that the word-piece-based models\nproduce more diverse N-best hypotheses, and thus lower oracle WERs, than\nphonemic models.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 22:16:15 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 16:03:31 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Irie", "Kazuki", ""], ["Prabhavalkar", "Rohit", ""], ["Kannan", "Anjuli", ""], ["Bruguier", "Antoine", ""], ["Rybach", "David", ""], ["Nguyen", "Patrick", ""]]}, {"id": "1902.02078", "submitter": "Satya Almasian", "authors": "Satya Almasian, Andreas Spitz, and Michael Gertz", "title": "Word Embeddings for Entity-annotated Texts", "comments": "This paper is accepted in 41st European Conference on Information\n  Retrieval", "journal-ref": null, "doi": "10.1007/978-3-030-15712-8_20", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learned vector representations of words are useful tools for many information\nretrieval and natural language processing tasks due to their ability to capture\nlexical semantics. However, while many such tasks involve or even rely on named\nentities as central components, popular word embedding models have so far\nfailed to include entities as first-class citizens. While it seems intuitive\nthat annotating named entities in the training corpus should result in more\nintelligent word features for downstream tasks, performance issues arise when\npopular embedding approaches are naively applied to entity annotated corpora.\nNot only are the resulting entity embeddings less useful than expected, but one\nalso finds that the performance of the non-entity word embeddings degrades in\ncomparison to those trained on the raw, unannotated corpus. In this paper, we\ninvestigate approaches to jointly train word and entity embeddings on a large\ncorpus with automatically annotated and linked entities. We discuss two\ndistinct approaches to the generation of such embeddings, namely the training\nof state-of-the-art embeddings on raw-text and annotated versions of the\ncorpus, as well as node embeddings of a co-occurrence graph representation of\nthe annotated corpus. We compare the performance of annotated embeddings and\nclassical word embeddings on a variety of word similarity, analogy, and\nclustering evaluation tasks, and investigate their performance in\nentity-specific tasks. Our findings show that it takes more than training\npopular word embedding models on an annotated corpus to create entity\nembeddings with acceptable performance on common test cases. Based on these\nresults, we discuss how and when node embeddings of the co-occurrence graph\nrepresentation of the text can restore the performance.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 09:21:55 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 14:29:14 GMT"}, {"version": "v3", "created": "Wed, 12 Feb 2020 10:22:08 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Almasian", "Satya", ""], ["Spitz", "Andreas", ""], ["Gertz", "Michael", ""]]}, {"id": "1902.02113", "submitter": "Max Frenzel", "authors": "Max F. Frenzel, Bogdan Teleaga, Asahi Ushio", "title": "Latent Space Cartography: Generalised Metric-Inspired Measures and\n  Measure-Based Transformations for Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models are universal tools for learning data distributions on\nhigh dimensional data spaces via a mapping to lower dimensional latent spaces.\nWe provide a study of latent space geometries and extend and build upon\nprevious results on Riemannian metrics. We show how a class of heuristic\nmeasures gives more flexibility in finding meaningful, problem-specific\ndistances, and how it can be applied to diverse generator types such as\nautoregressive generators commonly used in e.g. language and other sequence\nmodeling. We further demonstrate how a diffusion-inspired transformation\npreviously studied in cartography can be used to smooth out latent spaces,\nstretching them according to a chosen measure. In addition to providing more\nmeaningful distances directly in latent space, this also provides a unique tool\nfor novel kinds of data visualizations. We believe that the proposed methods\ncan be a valuable tool for studying the structure of latent spaces and learned\ndata distributions of generative models.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 11:15:08 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Frenzel", "Max F.", ""], ["Teleaga", "Bogdan", ""], ["Ushio", "Asahi", ""]]}, {"id": "1902.02160", "submitter": "Baohua Sun", "authors": "Baohua Sun, Lin Yang, Catherine Chi, Wenhan Zhang, Michael Lin", "title": "Squared English Word: A Method of Generating Glyph to Use Super\n  Characters for Sentiment Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Super Characters method addresses sentiment analysis problems by first\nconverting the input text into images and then applying 2D-CNN models to\nclassify the sentiment. It achieves state of the art performance on many\nbenchmark datasets. However, it is not as straightforward to apply in Latin\nlanguages as in Asian languages. Because the 2D-CNN model is designed to\nrecognize two-dimensional images, it is better if the inputs are in the form of\nglyphs. In this paper, we propose SEW (Squared English Word) method generating\na squared glyph for each English word by drawing Super Characters images of\neach English word at the alphabet level, combining the squared glyph together\ninto a whole Super Characters image at the sentence level, and then applying\nthe CNN model to classify the sentiment within the sentence. We applied the SEW\nmethod to Wikipedia dataset and obtained a 2.1% accuracy gain compared to the\noriginal Super Characters method. For multi-modal data with both structured\ntabular data and unstructured natural language text, the modified SEW method\nintegrates the data into a single image and classifies sentiment with one\nunified CNN model.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 17:10:02 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 21:28:21 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Sun", "Baohua", ""], ["Yang", "Lin", ""], ["Chi", "Catherine", ""], ["Zhang", "Wenhan", ""], ["Lin", "Michael", ""]]}, {"id": "1902.02161", "submitter": "Shib Sankar Dasgupta", "authors": "Swayambhu Nath Ray, Shib Sankar Dasgupta, Partha Talukdar", "title": "AD3: Attentive Deep Document Dater", "comments": null, "journal-ref": "DBLP:conf/emnlp/RayDT18 (2018)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge of the creation date of documents facilitates several tasks such as\nsummarization, event extraction, temporally focused information extraction etc.\nUnfortunately, for most of the documents on the Web, the time-stamp metadata is\neither missing or can't be trusted. Thus, predicting creation time from\ndocument content itself is an important task. In this paper, we propose\nAttentive Deep Document Dater (AD3), an attention-based neural document dating\nsystem which utilizes both context and temporal information in documents in a\nflexible and principled manner. We perform extensive experimentation on\nmultiple real-world datasets to demonstrate the effectiveness of AD3 over\nneural and non-neural baselines.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 07:02:52 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Ray", "Swayambhu Nath", ""], ["Dasgupta", "Shib Sankar", ""], ["Talukdar", "Partha", ""]]}, {"id": "1902.02162", "submitter": "Anupiya Nugaliyadde Mr", "authors": "M.R, Akram, C.P, Singhabahu, M.S.M Saad, P, Deleepa, Anupiya,\n  Nugaliyadde and Yashas, Mallawarachchi", "title": "Adaptive Artificial Intelligent Q&A Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents an approach to build a question and answer system that is\ncapable of processing the information in a large dataset and allows the user to\ngain knowledge from this dataset by asking questions in natural language form.\nKey content of this research covers four dimensions which are; Corpus\nPreprocessing, Question Preprocessing, Deep Neural Network for Answer\nExtraction and Answer Generation. The system is capable of understanding the\nquestion, responds to the user's query in natural language form as well. The\ngoal is to make the user feel as if they were interacting with a person than a\nmachine.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2019 17:40:08 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["R", "M.", ""], ["Akram", "", ""], ["P", "C.", ""], ["Singhabahu", "", ""], ["Saad", "M. S. M", ""], ["P", "", ""], ["Deleepa", "", ""], ["Anupiya", "", ""], ["Nugaliyadde", "", ""], ["Yashas", "", ""], ["Mallawarachchi", "", ""]]}, {"id": "1902.02169", "submitter": "Lukas Schmelzeisen", "authors": "Lukas Schmelzeisen and Steffen Staab", "title": "Learning Taxonomies of Concepts and not Words using Contextualized Word\n  Representations: A Position Paper", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Taxonomies are semantic hierarchies of concepts. One limitation of current\ntaxonomy learning systems is that they define concepts as single words. This\nposition paper argues that contextualized word representations, which recently\nachieved state-of-the-art results on many competitive NLP tasks, are a\npromising method to address this limitation. We outline a novel approach for\ntaxonomy learning that (1) defines concepts as synsets, (2) learns\ndensity-based approximations of contextualized word representations, and (3)\ncan measure similarity and hypernymy among them.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 17:18:42 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Schmelzeisen", "Lukas", ""], ["Staab", "Steffen", ""]]}, {"id": "1902.02173", "submitter": "Igor Barahona Dr", "authors": "Dalina Aidee Villa, Igor Barahona, Luis Javier \\'Alvarez", "title": "Dise\\~no de un espacio sem\\'antico sobre la base de la Wikipedia. Una\n  propuesta de an\\'alisis de la sem\\'antica latente para el idioma espa\\~nol", "comments": "14 pages, in Spanish, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent Semantic Analysis (LSA) was initially conceived by the cognitive\npsychology at the 90s decade. Since its emergence, the LSA has been used to\nmodel cognitive processes, pointing out academic texts, compare literature\nworks and analyse political speeches, among other applications. Taking as\nstarting point multivariate method for dimensionality reduction, this paper\npropose a semantic space for Spanish language. Out results include a document\ntext matrix with dimensions 1.3 x10^6 and 5.9x10^6, which later is decomposed\ninto singular values. Those singular values are used to semantically words or\ntext.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 21:39:23 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Villa", "Dalina Aidee", ""], ["Barahona", "Igor", ""], ["\u00c1lvarez", "Luis Javier", ""]]}, {"id": "1902.02176", "submitter": "Sayyed Ali Hossayni", "authors": "Sayyed-Ali Hossayni, Yousef Alizadeh-Q, Vahid Tavana, Seyed M.\n  Hosseini Nejad, Mohammad-R Akbarzadeh-T, Esteve Del Acebo, Josep Lluis De la\n  Rosa i Esteva, Enrico Grosso, Massimo Tistarelli, Przemyslaw Kudlacik", "title": "A Linear-complexity Multi-biometric Forensic Document Analysis System,\n  by Fusing the Stylome and Signature Modalities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forensic Document Analysis (FDA) addresses the problem of finding the\nauthorship of a given document. Identification of the document writer via a\nnumber of its modalities (e.g. handwriting, signature, linguistic writing style\n(i.e. stylome), etc.) has been studied in the FDA state-of-the-art. But, no\nresearch is conducted on the fusion of stylome and signature modalities. In\nthis paper, we propose such a bimodal FDA system (which has vast applications\nin judicial, police-related, and historical documents analysis) with a focus on\ntime-complexity. The proposed bimodal system can be trained and tested with\nlinear time complexity. For this purpose, we first revisit Multinomial Na\\\"ive\nBayes (MNB), as the best state-of-the-art linear-complexity authorship\nattribution system and, then, prove its superior accuracy to the well-known\nlinear-complexity classifiers in the state-of-the-art. Then, we propose a fuzzy\nversion of MNB for being fused with a state-of-the-art well-known\nlinear-complexity fuzzy signature recognition system. For the evaluation\npurposes, we construct a chimeric dataset, composed of signatures and textual\ncontents of different letters. Despite its linear-complexity, the proposed\nmulti-biometric system is proven to meaningfully improve its state-of-the-art\nunimodal counterparts, regarding the accuracy, F-Score, Detection Error\nTrade-off (DET), Cumulative Match Characteristics (CMC), and Match Score\nHistograms (MSH) evaluation metrics.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 10:26:55 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Hossayni", "Sayyed-Ali", ""], ["Alizadeh-Q", "Yousef", ""], ["Tavana", "Vahid", ""], ["Nejad", "Seyed M. Hosseini", ""], ["Akbarzadeh-T", "Mohammad-R", ""], ["Del Acebo", "Esteve", ""], ["Esteva", "Josep Lluis De la Rosa i", ""], ["Grosso", "Enrico", ""], ["Tistarelli", "Massimo", ""], ["Kudlacik", "Przemyslaw", ""]]}, {"id": "1902.02179", "submitter": "Logan Martel", "authors": "Logan Martel, Edward Newell, Drew Margolin, Derek Ruths", "title": "Assessing Partisan Traits of News Text Attributions", "comments": "Honours Thesis completed for McGill University B.Sc. Software\n  Engineering Supervised under Professor Derek Ruths Network Dynamics Lab", "journal-ref": null, "doi": "10.13140/RG.2.2.11343.12966", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  On the topic of journalistic integrity, the current state of accurate,\nimpartial news reporting has garnered much debate in context to the 2016 US\nPresidential Election. In pursuit of computational evaluation of news text, the\nstatements (attributions) ascribed by media outlets to sources provide a common\ncategory of evidence on which to operate. In this paper, we develop an approach\nto compare partisan traits of news text attributions and apply it to\ncharacterize differences in statements ascribed to candidate, Hilary Clinton,\nand incumbent President, Donald Trump. In doing so, we present a model trained\non over 600 in-house annotated attributions to identify each candidate with\naccuracy > 88%. Finally, we discuss insights from its performance for future\nresearch.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 01:47:13 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Martel", "Logan", ""], ["Newell", "Edward", ""], ["Margolin", "Drew", ""], ["Ruths", "Derek", ""]]}, {"id": "1902.02181", "submitter": "Andrea Galassi", "authors": "Andrea Galassi, Marco Lippi, Paolo Torroni", "title": "Attention in Natural Language Processing", "comments": "18 pages, 8 figures", "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems (2020)", "doi": "10.1109/TNNLS.2020.3019893", "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Attention is an increasingly popular mechanism used in a wide range of neural\narchitectures. The mechanism itself has been realized in a variety of formats.\nHowever, because of the fast-paced advances in this domain, a systematic\noverview of attention is still missing. In this article, we define a unified\nmodel for attention architectures in natural language processing, with a focus\non those designed to work with vector representations of the textual data. We\npropose a taxonomy of attention models according to four dimensions: the\nrepresentation of the input, the compatibility function, the distribution\nfunction, and the multiplicity of the input and/or output. We present the\nexamples of how prior information can be exploited in attention models and\ndiscuss ongoing research efforts and open challenges in the area, providing the\nfirst extensive categorization of the vast body of literature in this exciting\ndomain.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 17:14:13 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 16:09:50 GMT"}, {"version": "v3", "created": "Fri, 11 Sep 2020 10:52:29 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Galassi", "Andrea", ""], ["Lippi", "Marco", ""], ["Torroni", "Paolo", ""]]}, {"id": "1902.02192", "submitter": "Sean Welleck", "authors": "Sean Welleck, Kiant\\'e Brantley, Hal Daum\\'e III, Kyunghyun Cho", "title": "Non-Monotonic Sequential Text Generation", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard sequential generation methods assume a pre-specified generation\norder, such as text generation methods which generate words from left to right.\nIn this work, we propose a framework for training models of text generation\nthat operate in non-monotonic orders; the model directly learns good orders,\nwithout any additional annotation. Our framework operates by generating a word\nat an arbitrary position, and then recursively generating words to its left and\nthen words to its right, yielding a binary tree. Learning is framed as\nimitation learning, including a coaching method which moves from imitating an\noracle to reinforcing the policy's own preferences. Experimental results\ndemonstrate that using the proposed method, it is possible to learn policies\nwhich generate text without pre-specifying a generation order, while achieving\ncompetitive performance with conventional left-to-right generation.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 14:02:45 GMT"}, {"version": "v2", "created": "Sun, 12 May 2019 08:24:04 GMT"}, {"version": "v3", "created": "Wed, 23 Oct 2019 19:48:43 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Welleck", "Sean", ""], ["Brantley", "Kiant\u00e9", ""], ["Daum\u00e9", "Hal", "III"], ["Cho", "Kyunghyun", ""]]}, {"id": "1902.02263", "submitter": "Eliya Nachmani", "authors": "Eliya Nachmani, Lior Wolf", "title": "Unsupervised Polyglot Text To Speech", "comments": "The paper will be presented at ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a TTS neural network that is able to produce speech in multiple\nlanguages. The proposed network is able to transfer a voice, which was\npresented as a sample in a source language, into one of several target\nlanguages. Training is done without using matching or parallel data, i.e.,\nwithout samples of the same speaker in multiple languages, making the method\nmuch more applicable. The conversion is based on learning a polyglot network\nthat has multiple per-language sub-networks and adding loss terms that preserve\nthe speaker's identity in multiple languages. We evaluate the proposed polyglot\nneural network for three languages with a total of more than 400 speakers and\ndemonstrate convincing conversion capabilities.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 16:28:26 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Nachmani", "Eliya", ""], ["Wolf", "Lior", ""]]}, {"id": "1902.02326", "submitter": "Neama Abdulaziz Ms.", "authors": "Neama Abdulaziz Dahan and Fadl Mutaher Ba-Alwi", "title": "Extending a model for ontology-based Arabic-English machine translation", "comments": "13 pages, 3 figures, 3 equations, 4 tables, paper research", "journal-ref": "International Journal of Artificial Intelligence and Applications\n  (IJAIA), Vol.10, No.1, January 2019", "doi": "10.5121/ijaia.2019.10105", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The acceleration in telecommunication needs leads to many groups of research,\nespecially in communication facilitating and Machine Translation fields. While\npeople contact with others having different languages and cultures, they need\nto have instant translations. However, the available instant translators are\nstill providing somewhat bad Arabic-English Translations, for instance when\ntranslating books or articles, the meaning is not totally accurate. Therefore,\nusing the semantic web techniques to deal with the homographs and homonyms\nsemantically, the aim of this research is to extend a model for the\nontology-based Arabic-English Machine Translation, named NAN, which simulate\nthe human way in translation. The experimental results show that NAN\ntranslation is approximately more similar to the Human Translation than the\nother instant translators. The resulted translation will help getting the\ntranslated texts in the target language somewhat correctly and semantically\nmore similar to human translations for the Non-Arabic Natives and the\nNon-English natives.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 18:42:18 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Dahan", "Neama Abdulaziz", ""], ["Ba-Alwi", "Fadl Mutaher", ""]]}, {"id": "1902.02380", "submitter": "Artem Grachev", "authors": "Artem M. Grachev and Dmitry I. Ignatov and Andrey V. Savchenko", "title": "Compression of Recurrent Neural Networks for Efficient Language Modeling", "comments": "25 pages, 3 tables, 4 figures", "journal-ref": null, "doi": "10.1016/j.asoc.2019.03.057", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks have proved to be an effective method for\nstatistical language modeling. However, in practice their memory and run-time\ncomplexity are usually too large to be implemented in real-time offline mobile\napplications. In this paper we consider several compression techniques for\nrecurrent neural networks including Long-Short Term Memory models. We make\nparticular attention to the high-dimensional output problem caused by the very\nlarge vocabulary size. We focus on effective compression methods in the context\nof their exploitation on devices: pruning, quantization, and matrix\ndecomposition approaches (low-rank factorization and tensor train\ndecomposition, in particular). For each model we investigate the trade-off\nbetween its size, suitability for fast inference and perplexity. We propose a\ngeneral pipeline for applying the most suitable methods to compress recurrent\nneural networks for language modeling. It has been shown in the experimental\nstudy with the Penn Treebank (PTB) dataset that the most efficient results in\nterms of speed and compression-perplexity balance are obtained by matrix\ndecomposition techniques.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 19:49:22 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Grachev", "Artem M.", ""], ["Ignatov", "Dmitry I.", ""], ["Savchenko", "Andrey V.", ""]]}, {"id": "1902.02383", "submitter": "Yiming Wang", "authors": "Yiming Wang, Xing Fan, I-Fan Chen, Yuzong Liu, Tongfei Chen, Bj\\\"orn\n  Hoffmeister", "title": "End-to-end Anchored Speech Recognition", "comments": "Accepted by ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice-controlled house-hold devices, like Amazon Echo or Google Home, face\nthe problem of performing speech recognition of device-directed speech in the\npresence of interfering background speech, i.e., background noise and\ninterfering speech from another person or media device in proximity need to be\nignored. We propose two end-to-end models to tackle this problem with\ninformation extracted from the \"anchored segment\". The anchored segment refers\nto the wake-up word part of an audio stream, which contains valuable speaker\ninformation that can be used to suppress interfering speech and background\nnoise. The first method is called \"Multi-source Attention\" where the attention\nmechanism takes both the speaker information and decoder state into\nconsideration. The second method directly learns a frame-level mask on top of\nthe encoder output. We also explore a multi-task learning setup where we use\nthe ground truth of the mask to guide the learner. Given that audio data with\ninterfering speech is rare in our training data set, we also propose a way to\nsynthesize \"noisy\" speech from \"clean\" speech to mitigate the mismatch between\ntraining and test data. Our proposed methods show up to 15% relative reduction\nin WER for Amazon Alexa live data with interfering background speech without\nsignificantly degrading on clean speech.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 19:50:23 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Wang", "Yiming", ""], ["Fan", "Xing", ""], ["Chen", "I-Fan", ""], ["Liu", "Yuzong", ""], ["Chen", "Tongfei", ""], ["Hoffmeister", "Bj\u00f6rn", ""]]}, {"id": "1902.02507", "submitter": "Hoang Tai", "authors": "Tai Hoang, Huy Le, Tho Quan", "title": "Towards Autoencoding Variational Inference for Aspect-based Opinion\n  Summary", "comments": "20 pages, 11 figures", "journal-ref": "Applied Artificial Intelligence, 33 (2019) 796-816", "doi": "10.1080/08839514.2019.1630148", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect-based Opinion Summary (AOS), consisting of aspect discovery and\nsentiment classification steps, has recently been emerging as one of the most\ncrucial data mining tasks in e-commerce systems. Along this direction, the\nLDA-based model is considered as a notably suitable approach, since this model\noffers both topic modeling and sentiment classification. However, unlike\ntraditional topic modeling, in the context of aspect discovery it is often\nrequired some initial seed words, whose prior knowledge is not easy to be\nincorporated into LDA models. Moreover, LDA approaches rely on sampling\nmethods, which need to load the whole corpus into memory, making them hardly\nscalable. In this research, we study an alternative approach for AOS problem,\nbased on Autoencoding Variational Inference (AVI). Firstly, we introduce the\nAutoencoding Variational Inference for Aspect Discovery (AVIAD) model, which\nextends the previous work of Autoencoding Variational Inference for Topic\nModels (AVITM) to embed prior knowledge of seed words. This work includes\nenhancement of the previous AVI architecture and also modification of the loss\nfunction. Ultimately, we present the Autoencoding Variational Inference for\nJoint Sentiment/Topic (AVIJST) model. In this model, we substantially extend\nthe AVI model to support the JST model, which performs topic modeling for\ncorresponding sentiment. The experimental results show that our proposed models\nenjoy higher topic coherent, faster convergence time and better accuracy on\nsentiment classification, as compared to their LDA-based counterparts.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 07:44:03 GMT"}, {"version": "v2", "created": "Sat, 16 Feb 2019 02:59:58 GMT"}, {"version": "v3", "created": "Fri, 7 Jun 2019 02:04:17 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Hoang", "Tai", ""], ["Le", "Huy", ""], ["Quan", "Tho", ""]]}, {"id": "1902.02671", "submitter": "Asa Cooper Stickland", "authors": "Asa Cooper Stickland and Iain Murray", "title": "BERT and PALs: Projected Attention Layers for Efficient Adaptation in\n  Multi-Task Learning", "comments": "Accepted for publication at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning shares information between related tasks, sometimes\nreducing the number of parameters required. State-of-the-art results across\nmultiple natural language understanding tasks in the GLUE benchmark have\npreviously used transfer from a single large task: unsupervised pre-training\nwith BERT, where a separate BERT model was fine-tuned for each task. We explore\nmulti-task approaches that share a single BERT model with a small number of\nadditional task-specific parameters. Using new adaptation modules, PALs or\n`projected attention layers', we match the performance of separately fine-tuned\nmodels on the GLUE benchmark with roughly 7 times fewer parameters, and obtain\nstate-of-the-art results on the Recognizing Textual Entailment dataset.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 15:05:46 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 11:13:54 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Stickland", "Asa Cooper", ""], ["Murray", "Iain", ""]]}, {"id": "1902.02704", "submitter": "Abhishek Laddha", "authors": "Abhishek Laddha, Mohamed Hanoosh, Debdoot Mukherjee, Parth Patwa,\n  Ankur Narang", "title": "Understanding Chat Messages for Sticker Recommendation in Messaging Apps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stickers are popularly used in messaging apps such as Hike to visually\nexpress a nuanced range of thoughts and utterances to convey exaggerated\nemotions. However, discovering the right sticker from a large and ever\nexpanding pool of stickers while chatting can be cumbersome. In this paper, we\ndescribe a system for recommending stickers in real time as the user is typing\nbased on the context of the conversation. We decompose the sticker\nrecommendation (SR) problem into two steps. First, we predict the message that\nthe user is likely to send in the chat. Second, we substitute the predicted\nmessage with an appropriate sticker. Majority of Hike's messages are in the\nform of text which is transliterated from users' native language to the Roman\nscript. This leads to numerous orthographic variations of the same message and\nmakes accurate message prediction challenging. To address this issue, we learn\ndense representations of chat messages employing character level convolution\nnetwork in an unsupervised manner. We use them to cluster the messages that\nhave the same meaning. In the subsequent steps, we predict the message cluster\ninstead of the message. Our approach does not depend on human labelled data\n(except for validation), leading to fully automatic updation and tuning\npipeline for the underlying models. We also propose a novel hybrid message\nprediction model, which can run with low latency on low-end phones that have\nsevere computational limitations. Our described system has been deployed for\nmore than $6$ months and is being used by millions of users along with hundreds\nof thousands of expressive stickers.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 16:01:43 GMT"}, {"version": "v2", "created": "Wed, 17 Jul 2019 15:51:06 GMT"}, {"version": "v3", "created": "Fri, 19 Jul 2019 02:53:18 GMT"}, {"version": "v4", "created": "Sun, 24 Nov 2019 12:30:29 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Laddha", "Abhishek", ""], ["Hanoosh", "Mohamed", ""], ["Mukherjee", "Debdoot", ""], ["Patwa", "Parth", ""], ["Narang", "Ankur", ""]]}, {"id": "1902.02709", "submitter": "Abhishek Laddha", "authors": "Abhishek Laddha, Arjun Mukherjee", "title": "Aspect Specific Opinion Expression Extraction using Attention based\n  LSTM-CRF Network", "comments": "12 pages, Accepted paper in CICLing 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Opinion phrase extraction is one of the key tasks in fine-grained sentiment\nanalysis. While opinion expressions could be generic subjective expressions,\naspect specific opinion expressions contain both the aspect as well as the\nopinion expression within the original sentence context. In this work, we\nformulate the task as an instance of token-level sequence labeling. When\nmultiple aspects are present in a sentence, detection of opinion phrase\nboundary becomes difficult and label of each word depend not only upon the\nsurrounding words but also with the concerned aspect. We propose a neural\nnetwork architecture with bidirectional LSTM (Bi-LSTM) and a novel attention\nmechanism. Bi-LSTM layer learns the various sequential pattern among the words\nwithout requiring any hand-crafted features. The attention mechanism captures\nthe importance of context words on a particular aspect opinion expression when\nmultiple aspects are present in a sentence via location and content based\nmemory. A Conditional Random Field (CRF) model is incorporated in the final\nlayer to explicitly model the dependencies among the output labels.\nExperimental results on Hotel dataset from Tripadvisor.com showed that our\napproach outperformed several state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 16:12:41 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Laddha", "Abhishek", ""], ["Mukherjee", "Arjun", ""]]}, {"id": "1902.02783", "submitter": "Limor Gultchin", "authors": "Limor Gultchin (University of Oxford), Genevieve Patterson (TRASH),\n  Nancy Baym (Microsoft Research), Nathaniel Swinger (Lexington High School),\n  Adam Tauman Kalai (Microsoft Research)", "title": "Humor in Word Embeddings: Cockamamie Gobbledegook for Nincompoops", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While humor is often thought to be beyond the reach of Natural Language\nProcessing, we show that several aspects of single-word humor correlate with\nsimple linear directions in Word Embeddings. In particular: (a) the word\nvectors capture multiple aspects discussed in humor theories from various\ndisciplines; (b) each individual's sense of humor can be represented by a\nvector, which can predict differences in people's senses of humor on new,\nunrated, words; and (c) upon clustering humor ratings of multiple demographic\ngroups, different humor preferences emerge across the different groups. Humor\nratings are taken from the work of Engelthaler and Hills (2017) as well as from\nan original crowdsourcing study of 120,000 words. Our dataset further includes\nannotations for the theoretically-motivated humor features we identify.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 14:36:43 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2019 19:00:59 GMT"}, {"version": "v3", "created": "Fri, 24 May 2019 21:04:59 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Gultchin", "Limor", "", "University of Oxford"], ["Patterson", "Genevieve", "", "TRASH"], ["Baym", "Nancy", "", "Microsoft Research"], ["Swinger", "Nathaniel", "", "Lexington High School"], ["Kalai", "Adam Tauman", "", "Microsoft Research"]]}, {"id": "1902.03052", "submitter": "William Havard", "authors": "William N. Havard, Jean-Pierre Chevrot, Laurent Besacier", "title": "Models of Visually Grounded Speech Signal Pay Attention To Nouns: a\n  Bilingual Experiment on English and Japanese", "comments": "5 pages, 3 figures, accepted at ICASSP2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We investigate the behaviour of attention in neural models of visually\ngrounded speech trained on two languages: English and Japanese. Experimental\nresults show that attention focuses on nouns and this behaviour holds true for\ntwo very typologically different languages. We also draw parallels between\nartificial neural attention and human attention and show that neural attention\nfocuses on word endings as it has been theorised for human attention. Finally,\nwe investigate how two visually grounded monolingual models can be used to\nperform cross-lingual speech-to-speech retrieval. For both languages, the\nenriched bilingual (speech-image) corpora with part-of-speech tags and forced\nalignments are distributed to the community for reproducible research.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 12:27:26 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Havard", "William N.", ""], ["Chevrot", "Jean-Pierre", ""], ["Besacier", "Laurent", ""]]}, {"id": "1902.03089", "submitter": "Sima Sharifirad", "authors": "Sima Sharifirad, Borna Jafarpour, Stan Matwin", "title": "How is Your Mood When Writing Sexist tweets? Detecting the Emotion Type\n  and Intensity of Emotion Using Natural Language Processing Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online social platforms have been the battlefield of users with different\nemotions and attitudes toward each other in recent years. While sexism has been\nconsidered as a category of hateful speech in the literature, there is no\ncomprehensive definition and category of sexism attracting natural language\nprocessing techniques. Categorizing sexism as either benevolent or hostile\nsexism is so broad that it easily ignores the other categories of sexism on\nsocial media. Sharifirad S and Matwin S 2018 proposed a well-defined category\nof sexism including indirect harassment, information threat, sexual harassment\nand physical harassment, inspired from social science for the purpose of\nnatural language processing techniques. In this article, we take advantage of a\nnewly released dataset in SemEval-2018 task1: Affect in tweets, to show the\ntype of emotion and intensity of emotion in each category. We train, test and\nevaluate different classification methods on the SemEval- 2018 dataset and\nchoose the classifier with highest accuracy for testing on each category of\nsexist tweets to know the mental state and the affectual state of the user who\ntweets in each category. It is a nice avenue to explore because not all the\ntweets are directly sexist and they carry different emotions from the users.\nThis is the first work experimenting on affect detection this in depth on\nsexist tweets. Based on our best knowledge they are all new contributions to\nthe field; we are the first to demonstrate the power of such in-depth sentiment\nanalysis on the sexist tweets.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 19:58:14 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Sharifirad", "Sima", ""], ["Jafarpour", "Borna", ""], ["Matwin", "Stan", ""]]}, {"id": "1902.03190", "submitter": "Guangzhi Sun", "authors": "Guangzhi Sun, Chao Zhang and Phil Woodland", "title": "Speaker diarisation using 2D self-attentive combination of embeddings", "comments": "ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker diarisation systems often cluster audio segments using speaker\nembeddings such as i-vectors and d-vectors. Since different types of embeddings\nare often complementary, this paper proposes a generic framework to improve\nperformance by combining them into a single embedding, referred to as a\nc-vector. This combination uses a 2-dimensional (2D) self-attentive structure,\nwhich extends the standard self-attentive layer by averaging not only across\ntime but also across different types of embeddings. Two types of 2D\nself-attentive structure in this paper are the simultaneous combination and the\nconsecutive combination, adopting a single and multiple self-attentive layers\nrespectively. The penalty term in the original self-attentive layer which is\njointly minimised with the objective function to encourage diversity of\nannotation vectors is also modified to obtain not only different local peaks\nbut also the overall trends in the multiple annotation vectors. Experiments on\nthe AMI meeting corpus show that our modified penalty term improves the d-\nvector relative speaker error rate (SER) by 6% and 21% for d-vector systems,\nand a 10% further relative SER reduction can be obtained using the c-vector\nfrom our best 2D self-attentive structure.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 16:54:51 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Sun", "Guangzhi", ""], ["Zhang", "Chao", ""], ["Woodland", "Phil", ""]]}, {"id": "1902.03249", "submitter": "Mitchell Stern", "authors": "Mitchell Stern, William Chan, Jamie Kiros, Jakob Uszkoreit", "title": "Insertion Transformer: Flexible Sequence Generation via Insertion\n  Operations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Insertion Transformer, an iterative, partially autoregressive\nmodel for sequence generation based on insertion operations. Unlike typical\nautoregressive models which rely on a fixed, often left-to-right ordering of\nthe output, our approach accommodates arbitrary orderings by allowing for\ntokens to be inserted anywhere in the sequence during decoding. This\nflexibility confers a number of advantages: for instance, not only can our\nmodel be trained to follow specific orderings such as left-to-right generation\nor a binary tree traversal, but it can also be trained to maximize entropy over\nall valid insertions for robustness. In addition, our model seamlessly\naccommodates both fully autoregressive generation (one insertion at a time) and\npartially autoregressive generation (simultaneous insertions at multiple\nlocations). We validate our approach by analyzing its performance on the WMT\n2014 English-German machine translation task under various settings for\ntraining and decoding. We find that the Insertion Transformer outperforms many\nprior non-autoregressive approaches to translation at comparable or better\nlevels of parallelism, and successfully recovers the performance of the\noriginal Transformer while requiring only logarithmically many iterations\nduring decoding.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 19:00:04 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Stern", "Mitchell", ""], ["Chan", "William", ""], ["Kiros", "Jamie", ""], ["Uszkoreit", "Jakob", ""]]}, {"id": "1902.03455", "submitter": "Sam Wenke", "authors": "Sam Wenke, Jim Fleming", "title": "Contextual Recurrent Neural Networks", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an implicit assumption that by unfolding recurrent neural networks\n(RNN) in finite time, the misspecification of choosing a zero value for the\ninitial hidden state is mitigated by later time steps. This assumption has been\nshown to work in practice and alternative initialization may be suggested but\noften overlooked. In this paper, we propose a method of parameterizing the\ninitial hidden state of an RNN. The resulting architecture, referred to as a\nContextual RNN, can be trained end-to-end. The performance on an associative\nretrieval task is found to improve by conditioning the RNN initial hidden state\non contextual information from the input sequence. Furthermore, we propose a\nnovel method of conditionally generating sequences using the hidden state\nparameterization of Contextual RNN.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 17:41:56 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Wenke", "Sam", ""], ["Fleming", "Jim", ""]]}, {"id": "1902.03499", "submitter": "Xinyi Wang", "authors": "Xinyi Wang, Hieu Pham, Philip Arthur, Graham Neubig", "title": "Multilingual Neural Machine Translation With Soft Decoupled Encoding", "comments": "accepted at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual training of neural machine translation (NMT) systems has led to\nimpressive accuracy improvements on low-resource languages. However, there are\nstill significant challenges in efficiently learning word representations in\nthe face of paucity of data. In this paper, we propose Soft Decoupled Encoding\n(SDE), a multilingual lexicon encoding framework specifically designed to share\nlexical-level information intelligently without requiring heuristic\npreprocessing such as pre-segmenting the data. SDE represents a word by its\nspelling through a character encoding, and its semantic meaning through a\nlatent embedding space shared by all languages. Experiments on a standard\ndataset of four low-resource languages show consistent improvements over strong\nmultilingual NMT baselines, with gains of up to 2 BLEU on one of the tested\nlanguages, achieving the new state-of-the-art on all four language pairs.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 21:47:05 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Wang", "Xinyi", ""], ["Pham", "Hieu", ""], ["Arthur", "Philip", ""], ["Neubig", "Graham", ""]]}, {"id": "1902.03570", "submitter": "Deshraj Yadav", "authors": "Deshraj Yadav, Rishabh Jain, Harsh Agrawal, Prithvijit Chattopadhyay,\n  Taranjeet Singh, Akash Jain, Shiv Baran Singh, Stefan Lee, Dhruv Batra", "title": "EvalAI: Towards Better Evaluation Systems for AI Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce EvalAI, an open source platform for evaluating and comparing\nmachine learning (ML) and artificial intelligence algorithms (AI) at scale.\nEvalAI is built to provide a scalable solution to the research community to\nfulfill the critical need of evaluating machine learning models and agents\nacting in an environment against annotations or with a human-in-the-loop. This\nwill help researchers, students, and data scientists to create, collaborate,\nand participate in AI challenges organized around the globe. By simplifying and\nstandardizing the process of benchmarking these models, EvalAI seeks to lower\nthe barrier to entry for participating in the global scientific effort to push\nthe frontiers of machine learning and artificial intelligence, thereby\nincreasing the rate of measurable progress in this domain.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2019 10:34:54 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Yadav", "Deshraj", ""], ["Jain", "Rishabh", ""], ["Agrawal", "Harsh", ""], ["Chattopadhyay", "Prithvijit", ""], ["Singh", "Taranjeet", ""], ["Jain", "Akash", ""], ["Singh", "Shiv Baran", ""], ["Lee", "Stefan", ""], ["Batra", "Dhruv", ""]]}, {"id": "1902.03658", "submitter": "Konstantinos Perifanos", "authors": "Konstantinos Perifanos, Eirini Florou, Dionysis Goutsos", "title": "Word embeddings for idiolect identification", "comments": "IISA 2018 - The 9th International Conference on Information,\n  Intelligence, Systems and Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The term idiolect refers to the unique and distinctive use of language of an\nindividual and it is the theoretical foundation of Authorship Attribution. In\nthis paper we are focusing on learning distributed representations (embeddings)\nof social media users that reflect their writing style. These representations\ncan be considered as stylistic fingerprints of the authors. We are exploring\nthe performance of the two main flavours of distributed representations, namely\nembeddings produced by Neural Probabilistic Language models (such as word2vec)\nand matrix factorization (such as GloVe).\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2019 19:40:07 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Perifanos", "Konstantinos", ""], ["Florou", "Eirini", ""], ["Goutsos", "Dionysis", ""]]}, {"id": "1902.03659", "submitter": "Konstantinos Perifanos", "authors": "Eirini Florou, Konstantinos Perifanos, Dionysis Goutsos", "title": "Neural embeddings for metaphor detection in a corpus of Greek texts", "comments": "IISA 2018 - The 9th International Conference on Information,\n  Intelligence, Systems and Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major challenges that NLP faces is metaphor detection, especially\nby automatic means, a task that becomes even more difficult for languages\nlacking in linguistic resources and tools. Our purpose is the automatic\ndifferentiation between literal and metaphorical meaning in authentic\nnon-annotated phrases from the Corpus of Greek Texts by means of computational\nmethods of machine learning. For this purpose the theoretical background of\ndistributional semantics is discussed and employed. Distributional Semantics\nTheory develops concepts and methods for the quantification and classification\nof semantic similarities displayed by linguistic elements in large amounts of\nlinguistic data according to their distributional properties. In accordance\nwith this model, the approach followed in the thesis takes into account the\nlinguistic context for the computation of the distributional representation of\nphrases in geometrical space, as well as for their comparison with the\ndistributional representations of other phrases, whose function in speech is\nalready \"known\" with the objective to reach conclusions about their literal or\nmetaphorical function in the specific linguistic context. This procedure aims\nat dealing with the lack of linguistic resources for the Greek language, as the\nalmost impossible up to now semantic comparison between \"phrases\", takes the\nform of an arithmetical comparison of their distributional representations in\ngeometrical space.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2019 19:46:24 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Florou", "Eirini", ""], ["Perifanos", "Konstantinos", ""], ["Goutsos", "Dionysis", ""]]}, {"id": "1902.04094", "submitter": "Alex Wang", "authors": "Alex Wang, Kyunghyun Cho", "title": "BERT has a Mouth, and It Must Speak: BERT as a Markov Random Field\n  Language Model", "comments": "NeuralGen 2019;\n  https://colab.research.google.com/drive/1MxKZGtQ9SSBjTK5ArsZ5LKhkztzg52RV", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that BERT (Devlin et al., 2018) is a Markov random field language\nmodel. This formulation gives way to a natural procedure to sample sentences\nfrom BERT. We generate from BERT and find that it can produce high-quality,\nfluent generations. Compared to the generations of a traditional left-to-right\nlanguage model, BERT generates sentences that are more diverse but of slightly\nworse quality.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 19:02:27 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 18:01:28 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Wang", "Alex", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1902.04187", "submitter": "Jianbo Chen", "authors": "Jianbo Chen, Michael I. Jordan", "title": "LS-Tree: Model Interpretation When the Data Are Linguistic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of interpreting trained classification models in the\nsetting of linguistic data sets. Leveraging a parse tree, we propose to assign\nleast-squares based importance scores to each word of an instance by exploiting\nsyntactic constituency structure. We establish an axiomatic characterization of\nthese importance scores by relating them to the Banzhaf value in coalitional\ngame theory. Based on these importance scores, we develop a principled method\nfor detecting and quantifying interactions between words in a sentence. We\ndemonstrate that the proposed method can aid in interpretability and\ndiagnostics for several widely-used language models.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 23:58:22 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Chen", "Jianbo", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1902.04247", "submitter": "Kento Nozawa", "authors": "Kento Nozawa, Issei Sato", "title": "PAC-Bayes Analysis of Sentence Representation", "comments": "fix styles", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning sentence vectors from an unlabeled corpus has attracted attention\nbecause such vectors can represent sentences in a lower dimensional and\ncontinuous space. Simple heuristics using pre-trained word vectors are widely\napplied to machine learning tasks. However, they are not well understood from a\ntheoretical perspective. We analyze learning sentence vectors from a transfer\nlearning perspective by using a PAC-Bayes bound that enables us to understand\nexisting heuristics. We show that simple heuristics such as averaging and\ninverse document frequency weighted averaging are derived by our formulation.\nMoreover, we propose novel sentence vector learning algorithms on the basis of\nour PAC-Bayes analysis.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 05:49:34 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 11:41:49 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Nozawa", "Kento", ""], ["Sato", "Issei", ""]]}, {"id": "1902.04260", "submitter": "Huilin Gao", "authors": "Tong Guo, Huilin Gao", "title": "Table2answer: Read the database and answer without SQL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic parsing is the task of mapping natural language to logic form. In\nquestion answering, semantic parsing can be used to map the question to logic\nform and execute the logic form to get the answer. One key problem for semantic\nparsing is the hard label work. We study this problem in another way: we do not\nuse the logic form any more. Instead we only use the schema and answer info. We\nthink that the logic form step can be injected into the deep model. The reason\nwhy we think removing the logic form step is possible is that human can do the\ntask without explicit logic form. We use BERT-based model and do the experiment\nin the WikiSQL dataset, which is a large natural language to SQL dataset. Our\nexperimental evaluations that show that our model can achieves the baseline\nresults in WikiSQL dataset.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 07:07:16 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 01:41:47 GMT"}, {"version": "v3", "created": "Mon, 11 Mar 2019 02:16:51 GMT"}, {"version": "v4", "created": "Mon, 8 Jul 2019 03:36:19 GMT"}, {"version": "v5", "created": "Mon, 22 Jul 2019 08:58:37 GMT"}, {"version": "v6", "created": "Fri, 30 Aug 2019 03:42:23 GMT"}, {"version": "v7", "created": "Mon, 2 Sep 2019 01:09:38 GMT"}, {"version": "v8", "created": "Mon, 9 Sep 2019 07:49:44 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Guo", "Tong", ""], ["Gao", "Huilin", ""]]}, {"id": "1902.04574", "submitter": "Momchil Hardalov", "authors": "Momchil Hardalov, Ivan Koychev and Preslav Nakov", "title": "Machine Reading Comprehension for Answer Re-Ranking in Customer Support\n  Chatbots", "comments": "13 pages, 1 figure, 4 tables", "journal-ref": "Information 2019, 10, 82", "doi": "10.3390/info10030082", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advances in deep neural networks, language modeling and language\ngeneration have introduced new ideas to the field of conversational agents. As\na result, deep neural models such as sequence-to-sequence, Memory Networks, and\nthe Transformer have become key ingredients of state-of-the-art dialog systems.\nWhile those models are able to generate meaningful responses even in unseen\nsituation, they need a lot of training data to build a reliable model. Thus,\nmost real-world systems stuck to traditional approaches based on information\nretrieval and even hand-crafted rules, due to their robustness and\neffectiveness, especially for narrow-focused conversations. Here, we present a\nmethod that adapts a deep neural architecture from the domain of machine\nreading comprehension to re-rank the suggested answers from different models\nusing the question as context. We train our model using negative sampling based\non question-answer pairs from the Twitter Customer Support Dataset.The\nexperimental results show that our re-ranking framework can improve the\nperformance in terms of word overlap and semantics both for individual models\nas well as for model combinations.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 15:49:40 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 14:17:59 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Hardalov", "Momchil", ""], ["Koychev", "Ivan", ""], ["Nakov", "Preslav", ""]]}, {"id": "1902.04793", "submitter": "Sebastian Arnold", "authors": "Sebastian Arnold, Rudolf Schneider, Philippe Cudr\\'e-Mauroux, Felix A.\n  Gers, Alexander L\\\"oser", "title": "SECTOR: A Neural Model for Coherent Topic Segmentation and\n  Classification", "comments": "Author's final version, accepted for publication at TACL, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When searching for information, a human reader first glances over a document,\nspots relevant sections and then focuses on a few sentences for resolving her\nintention. However, the high variance of document structure complicates to\nidentify the salient topic of a given section at a glance. To tackle this\nchallenge, we present SECTOR, a model to support machine reading systems by\nsegmenting documents into coherent sections and assigning topic labels to each\nsection. Our deep neural network architecture learns a latent topic embedding\nover the course of a document. This can be leveraged to classify local topics\nfrom plain text and segment a document at topic shifts. In addition, we\ncontribute WikiSection, a publicly available dataset with 242k labeled sections\nin English and German from two distinct domains: diseases and cities. From our\nextensive evaluation of 20 architectures, we report a highest score of 71.6% F1\nfor the segmentation and classification of 30 topics from the English city\ndomain, scored by our SECTOR LSTM model with bloom filter embeddings and\nbidirectional segmentation. This is a significant improvement of 29.5 points F1\ncompared to state-of-the-art CNN classifiers with baseline segmentation.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 09:00:16 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Arnold", "Sebastian", ""], ["Schneider", "Rudolf", ""], ["Cudr\u00e9-Mauroux", "Philippe", ""], ["Gers", "Felix A.", ""], ["L\u00f6ser", "Alexander", ""]]}, {"id": "1902.04911", "submitter": "Min Xie", "authors": "Rongzhong Lian, Min Xie, Fan Wang, Jinhua Peng and Hua Wu", "title": "Learning to Select Knowledge for Response Generation in Dialog Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end neural models for intelligent dialogue systems suffer from the\nproblem of generating uninformative responses. Various methods were proposed to\ngenerate more informative responses by leveraging external knowledge. However,\nfew previous work has focused on selecting appropriate knowledge in the\nlearning process. The inappropriate selection of knowledge could prohibit the\nmodel from learning to make full use of the knowledge. Motivated by this, we\npropose an end-to-end neural model which employs a novel knowledge selection\nmechanism where both prior and posterior distributions over knowledge are used\nto facilitate knowledge selection. Specifically, a posterior distribution over\nknowledge is inferred from both utterances and responses, and it ensures the\nappropriate selection of knowledge during the training process. Meanwhile, a\nprior distribution, which is inferred from utterances only, is used to\napproximate the posterior distribution so that appropriate knowledge can be\nselected even without responses during the inference process. Compared with the\nprevious work, our model can better incorporate appropriate knowledge in\nresponse generation. Experiments on both automatic and human evaluation verify\nthe superiority of our model over previous baselines.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 14:13:21 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 12:30:50 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Lian", "Rongzhong", ""], ["Xie", "Min", ""], ["Wang", "Fan", ""], ["Peng", "Jinhua", ""], ["Wu", "Hua", ""]]}, {"id": "1902.04994", "submitter": "Linyi Yang", "authors": "Linyi Yang, Zheng Zhang, Su Xiong, Lirui Wei, James Ng, Lina Xu,\n  Ruihai Dong", "title": "Explainable Text-Driven Neural Network for Stock Prediction", "comments": "10 pages, Proceedings of CCIS2018", "journal-ref": "2018 5th IEEE International Conference on Cloud Computing and\n  Intelligence Systems", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown that financial news leads to the fluctuation of stock\nprices. However, previous work on news-driven financial market prediction\nfocused only on predicting stock price movement without providing an\nexplanation. In this paper, we propose a dual-layer attention-based neural\nnetwork to address this issue. In the initial stage, we introduce a\nknowledge-based method to adaptively extract relevant financial news. Then, we\nuse input attention to pay more attention to the more influential news and\nconcatenate the day embeddings with the output of the news representation.\nFinally, we use an output attention mechanism to allocate different weights to\ndifferent days in terms of their contribution to stock price movement. Thorough\nempirical studies based upon historical prices of several individual stocks\ndemonstrate the superiority of our proposed method in stock price prediction\ncompared to state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 16:37:32 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Yang", "Linyi", ""], ["Zhang", "Zheng", ""], ["Xiong", "Su", ""], ["Wei", "Lirui", ""], ["Ng", "James", ""], ["Xu", "Lina", ""], ["Dong", "Ruihai", ""]]}, {"id": "1902.05070", "submitter": "Mee Seong Im", "authors": "Mee Seong Im, Venkat R. Dasari, Lubjana Beshaj, Dale Shires", "title": "Optimization problems with low SWaP tactical Computing", "comments": "8 pages, 1 figure. To appear in Proc. SPIE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.CL cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a resource-constrained, contested environment, computing resources need to\nbe aware of possible size, weight, and power (SWaP) restrictions. SWaP-aware\ncomputational efficiency depends upon optimization of computational resources\nand intelligent time versus efficiency tradeoffs in decision making. In this\npaper we address the complexity of various optimization strategies related to\nlow SWaP computing. Due to these restrictions, only a small subset of less\ncomplicated and fast computable algorithms can be used for tactical, adaptive\ncomputing.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 11:17:43 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Im", "Mee Seong", ""], ["Dasari", "Venkat R.", ""], ["Beshaj", "Lubjana", ""], ["Shires", "Dale", ""]]}, {"id": "1902.05085", "submitter": "Irshad Bhat", "authors": "Riyaz Ahmad Bhat, Irshad Ahmad Bhat, Dipti Misra Sharma", "title": "Leveraging Newswire Treebanks for Parsing Conversational Data with\n  Argument Scrambling", "comments": "Proceedings of the 15th International Conference on Parsing\n  Technologies, pages 61-66, Pisa, Italy; September 20-22, 2017. Association\n  for Computational Linguistics", "journal-ref": "Proceedings of the 15th International Conference on Parsing\n  Technologies, pages 61-66, Pisa, Italy; September 20-22, 2017. Association\n  for Computational Linguistics", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of parsing conversational data of\nmorphologically-rich languages such as Hindi where argument scrambling occurs\nfrequently. We evaluate a state-of-the-art non-linear transition-based parsing\nsystem on a new dataset containing 506 dependency trees for sentences from\nBollywood (Hindi) movie scripts and Twitter posts of Hindi monolingual\nspeakers. We show that a dependency parser trained on a newswire treebank is\nstrongly biased towards the canonical structures and degrades when applied to\nconversational data. Inspired by Transformational Generative Grammar, we\nmitigate the sampling bias by generating all theoretically possible alternative\nword orders of a clause from the existing (kernel) structures in the treebank.\nTraining our parser on canonical and transformed structures improves\nperformance on conversational data by around 9% LAS over the baseline newswire\nparser.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 19:01:51 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Bhat", "Riyaz Ahmad", ""], ["Bhat", "Irshad Ahmad", ""], ["Sharma", "Dipti Misra", ""]]}, {"id": "1902.05196", "submitter": "Reinald Kim Amplayo", "authors": "Jihyeok Kim, Reinald Kim Amplayo, Kyungjae Lee, Sua Sung, Minji Seo,\n  Seung-won Hwang", "title": "Categorical Metadata Representation for Customized Text Classification", "comments": "Authors' final version, accepted at TACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of text classification has improved tremendously using\nintelligently engineered neural-based models, especially those injecting\ncategorical metadata as additional information, e.g., using user/product\ninformation for sentiment classification. These information have been used to\nmodify parts of the model (e.g., word embeddings, attention mechanisms) such\nthat results can be customized according to the metadata. We observe that\ncurrent representation methods for categorical metadata, which are devised for\nhuman consumption, are not as effective as claimed in popular classification\nmethods, outperformed even by simple concatenation of categorical features in\nthe final layer of the sentence encoder. We conjecture that categorical\nfeatures are harder to represent for machine use, as available context only\nindirectly describes the category, and even such context is often scarce (for\ntail category). To this end, we propose to use basis vectors to effectively\nincorporate categorical metadata on various parts of a neural-based model. This\nadditionally decreases the number of parameters dramatically, especially when\nthe number of categorical features is large. Extensive experiments on various\ndatasets with different properties are performed and show that through our\nmethod, we can represent categorical metadata more effectively to customize\nparts of the model, including unexplored ones, and increase the performance of\nthe model greatly.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 03:07:53 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Kim", "Jihyeok", ""], ["Amplayo", "Reinald Kim", ""], ["Lee", "Kyungjae", ""], ["Sung", "Sua", ""], ["Seo", "Minji", ""], ["Hwang", "Seung-won", ""]]}, {"id": "1902.05309", "submitter": "Lingzhen Chen", "authors": "Lingzhen Chen, Alessandro Moschitti", "title": "Transfer Learning for Sequence Labeling Using Source Model and Target\n  Data", "comments": "9 pages, 4 figures, 3 tables, accepted paper in the Thirty-Third AAAI\n  Conference on Artificial Intelligence (AAAI-19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an approach for transferring the knowledge of a\nneural model for sequence labeling, learned from the source domain, to a new\nmodel trained on a target domain, where new label categories appear. Our\ntransfer learning (TL) techniques enable to adapt the source model using the\ntarget data and new categories, without accessing to the source data. Our\nsolution consists in adding new neurons in the output layer of the target model\nand transferring parameters from the source model, which are then fine-tuned\nwith the target data. Additionally, we propose a neural adapter to learn the\ndifference between the source and the target label distribution, which provides\nadditional important information to the target model. Our experiments on Named\nEntity Recognition show that (i) the learned knowledge in the source model can\nbe effectively transferred when the target data contains new categories and\n(ii) our neural adapter further improves such transfer.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 11:40:58 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Chen", "Lingzhen", ""], ["Moschitti", "Alessandro", ""]]}, {"id": "1902.05715", "submitter": "Shalini Ghosh", "authors": "Shalini Ghosh, Giedrius Burachas, Arijit Ray, Avi Ziskind", "title": "Generating Natural Language Explanations for Visual Question Answering\n  using Scene Graphs and Visual Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel approach for the task of eXplainable\nQuestion Answering (XQA), i.e., generating natural language (NL) explanations\nfor the Visual Question Answering (VQA) problem. We generate NL explanations\ncomprising of the evidence to support the answer to a question asked to an\nimage using two sources of information: (a) annotations of entities in an image\n(e.g., object labels, region descriptions, relation phrases) generated from the\nscene graph of the image, and (b) the attention map generated by a VQA model\nwhen answering the question. We show how combining the visual attention map\nwith the NL representation of relevant scene graph entities, carefully selected\nusing a language model, can give reasonable textual explanations without the\nneed of any additional collected data (explanation captions, etc). We run our\nalgorithms on the Visual Genome (VG) dataset and conduct internal user-studies\nto demonstrate the efficacy of our approach over a strong baseline. We have\nalso released a live web demo showcasing our VQA and textual explanation\ngeneration using scene graphs and visual attention.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 07:59:11 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Ghosh", "Shalini", ""], ["Burachas", "Giedrius", ""], ["Ray", "Arijit", ""], ["Ziskind", "Avi", ""]]}, {"id": "1902.05766", "submitter": "Zhaopeng Tu", "authors": "Baosong Yang, Jian Li, Derek Wong, Lidia S. Chao, Xing Wang, Zhaopeng\n  Tu", "title": "Context-Aware Self-Attention Networks", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-attention model have shown its flexibility in parallel computation and\nthe effectiveness on modeling both long- and short-term dependencies. However,\nit calculates the dependencies between representations without considering the\ncontextual information, which have proven useful for modeling dependencies\namong neural representations in various natural language tasks. In this work,\nwe focus on improving self-attention networks through capturing the richness of\ncontext. To maintain the simplicity and flexibility of the self-attention\nnetworks, we propose to contextualize the transformations of the query and key\nlayers, which are used to calculates the relevance between elements.\nSpecifically, we leverage the internal representations that embed both global\nand deep contexts, thus avoid relying on external resources. Experimental\nresults on WMT14 English-German and WMT17 Chinese-English translation tasks\ndemonstrate the effectiveness and universality of the proposed methods.\nFurthermore, we conducted extensive analyses to quantity how the context\nvectors participate in the self-attention model.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 11:03:52 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Yang", "Baosong", ""], ["Li", "Jian", ""], ["Wong", "Derek", ""], ["Chao", "Lidia S.", ""], ["Wang", "Xing", ""], ["Tu", "Zhaopeng", ""]]}, {"id": "1902.05770", "submitter": "Zhaopeng Tu", "authors": "Zi-Yi Dou, Zhaopeng Tu, Xing Wang, Longyue Wang, Shuming Shi, Tong\n  Zhang", "title": "Dynamic Layer Aggregation for Neural Machine Translation with\n  Routing-by-Agreement", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the promising progress of deep neural networks, layer aggregation has\nbeen used to fuse information across layers in various fields, such as computer\nvision and machine translation. However, most of the previous methods combine\nlayers in a static fashion in that their aggregation strategy is independent of\nspecific hidden states. Inspired by recent progress on capsule networks, in\nthis paper we propose to use routing-by-agreement strategies to aggregate\nlayers dynamically. Specifically, the algorithm learns the probability of a\npart (individual layer representations) assigned to a whole (aggregated\nrepresentations) in an iterative way and combines parts accordingly. We\nimplement our algorithm on top of the state-of-the-art neural machine\ntranslation model TRANSFORMER and conduct experiments on the widely-used WMT14\nEnglish-German and WMT17 Chinese-English translation datasets. Experimental\nresults across language pairs show that the proposed approach consistently\noutperforms the strong baseline model and a representative static aggregation\nmodel.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 11:14:35 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Dou", "Zi-Yi", ""], ["Tu", "Zhaopeng", ""], ["Wang", "Xing", ""], ["Wang", "Longyue", ""], ["Shi", "Shuming", ""], ["Zhang", "Tong", ""]]}, {"id": "1902.06000", "submitter": "Arash Einolghozati", "authors": "Arash Einolghozati, Panupong Pasupat, Sonal Gupta, Rushin Shah, Mrinal\n  Mohit, Mike Lewis, Luke Zettlemoyer", "title": "Improving Semantic Parsing for Task Oriented Dialog", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic parsing using hierarchical representations has recently been\nproposed for task oriented dialog with promising results [Gupta et al 2018]. In\nthis paper, we present three different improvements to the model:\ncontextualized embeddings, ensembling, and pairwise re-ranking based on a\nlanguage model. We taxonomize the errors possible for the hierarchical\nrepresentation, such as wrong top intent, missing spans or split spans, and\nshow that the three approaches correct different kinds of errors. The best\nmodel combines the three techniques and gives 6.4% better exact match accuracy\nthan the state-of-the-art, with an error reduction of 33%, resulting in a new\nstate-of-the-art result on the Task Oriented Parsing (TOP) dataset.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 22:54:32 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Einolghozati", "Arash", ""], ["Pasupat", "Panupong", ""], ["Gupta", "Sonal", ""], ["Shah", "Rushin", ""], ["Mohit", "Mrinal", ""], ["Lewis", "Mike", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1902.06006", "submitter": "Noah Smith", "authors": "Noah A. Smith", "title": "Contextual Word Representations: A Contextual Introduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This introduction aims to tell the story of how we put words into computers.\nIt is part of the story of the field of natural language processing (NLP), a\nbranch of artificial intelligence. It targets a wide audience with a basic\nunderstanding of computer programming, but avoids a detailed mathematical\ntreatment, and it does not present any algorithms. It also does not focus on\nany particular application of NLP such as translation, question answering, or\ninformation extraction. The ideas presented here were developed by many\nresearchers over many decades, so the citations are not exhaustive but rather\ndirect the reader to a handful of papers that are, in the author's view,\nseminal. After reading this document, you should have a general understanding\nof word vectors (also known as word embeddings): why they exist, what problems\nthey solve, where they come from, how they have changed over time, and what\nsome of the open questions about them are. Readers already familiar with word\nvectors are advised to skip to Section 5 for the discussion of the most recent\nadvance, contextual word vectors.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 23:28:36 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 05:25:19 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2020 17:16:08 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Smith", "Noah A.", ""]]}, {"id": "1902.06022", "submitter": "Ronan Collobert", "authors": "Ronan Collobert, Awni Hannun, Gabriel Synnaeve", "title": "A Fully Differentiable Beam Search Decoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new beam search decoder that is fully differentiable, making\nit possible to optimize at training time through the inference procedure. Our\ndecoder allows us to combine models which operate at different granularities\n(e.g. acoustic and language models). It can be used when target sequences are\nnot aligned to input sequences by considering all possible alignments between\nthe two. We demonstrate our approach scales by applying it to speech\nrecognition, jointly training acoustic and word-level language models. The\nsystem is end-to-end, with gradients flowing through the whole architecture\nfrom the word-level transcriptions. Recent research efforts have shown that\ndeep neural networks with attention-based mechanisms are powerful enough to\nsuccessfully train an acoustic model from the final transcription, while\nimplicitly learning a language model. Instead, we show that it is possible to\ndiscriminatively train an acoustic model jointly with an explicit and possibly\npre-trained language model.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2019 01:28:12 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Collobert", "Ronan", ""], ["Hannun", "Awni", ""], ["Synnaeve", "Gabriel", ""]]}, {"id": "1902.06024", "submitter": "Jiaqi Wu", "authors": "Jiaqi Wu, Ryan Compton, Geetanjali Rakshit, Marilyn Walker, Pranav\n  Anand, and Steve Whittaker", "title": "CruzAffect at AffCon 2019 Shared Task: A feature-rich approach to\n  characterize happiness", "comments": "Workshop on Affective Content Analysis (AffCon) 2019, Workshop of\n  Association for the Advancement of Artificial Intelligence (AAAI) 2019,\n  Hawaii, USA January 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present our system, CruzAffect, for the CL-Aff Shared Task 2019.\nCruzAffect consists of several types of robust and efficient models for\naffective classification tasks. We utilize both traditional classifiers, such\nas XGBoosted Forest, as well as a deep learning Convolutional Neural Networks\n(CNN) classifier. We explore rich feature sets such as syntactic features,\nemotional features, and profile features, and utilize several sentiment\nlexicons, to discover essential indicators of social involvement and control\nthat a subject might exercise in their happy moments, as described in textual\nsnippets from the HappyDB database. The data comes with a labeled set (10K),\nand a larger unlabeled set (70K). We therefore use supervised methods on the\n10K dataset, and a bootstrapped semi-supervised approach for the 70K. We\nevaluate these models for binary classification of agency and social labels\n(Task 1), as well as multi-class prediction for concepts labels (Task 2). We\nobtain promising results on the held-out data, suggesting that the proposed\nfeature sets effectively represent the data for affective classification tasks.\nWe also build concepts models that discover general themes recurring in happy\nmoments. Our results indicate that generic characteristics are shared between\nthe classes of agency, social and concepts, suggesting it should be possible to\nbuild general models for affective classification tasks.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2019 01:54:47 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Wu", "Jiaqi", ""], ["Compton", "Ryan", ""], ["Rakshit", "Geetanjali", ""], ["Walker", "Marilyn", ""], ["Anand", "Pranav", ""], ["Whittaker", "Steve", ""]]}, {"id": "1902.06034", "submitter": "Michihiro Yasunaga", "authors": "Michihiro Yasunaga, John Lafferty", "title": "TopicEq: A Joint Topic and Mathematical Equation Model for Scientific\n  Texts", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific documents rely on both mathematics and text to communicate ideas.\nInspired by the topical correspondence between mathematical equations and word\ncontexts observed in scientific texts, we propose a novel topic model that\njointly generates mathematical equations and their surrounding text (TopicEq).\nUsing an extension of the correlated topic model, the context is generated from\na mixture of latent topics, and the equation is generated by an RNN that\ndepends on the latent topic activations. To experiment with this model, we\ncreate a corpus of 400K equation-context pairs extracted from a range of\nscientific articles from arXiv, and fit the model using a variational\nautoencoder approach. Experimental results show that this joint model\nsignificantly outperforms existing topic models and equation models for\nscientific texts. Moreover, we qualitatively show that the model effectively\ncaptures the relationship between topics and mathematics, enabling novel\napplications such as topic-aware equation generation, equation topic inference,\nand topic-aware alignment of mathematical symbols and words.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2019 03:39:51 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 16:55:23 GMT"}, {"version": "v3", "created": "Thu, 25 Apr 2019 21:24:05 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Yasunaga", "Michihiro", ""], ["Lafferty", "John", ""]]}, {"id": "1902.06050", "submitter": "Khuong Vo", "authors": "Khuong Vo, Tri Nguyen, Dang Pham, Mao Nguyen, Minh Truong, Trung Mai,\n  Tho Quan", "title": "Combination of Domain Knowledge and Deep Learning for Sentiment Analysis\n  of Short and Informal Messages on Social Media", "comments": "A Preprint of an article accepted for publication by Inderscience in\n  IJCVR on September 2018", "journal-ref": "International Journal of Computational Vision and Robotics, 2019\n  Vol.9 No.5, pp.458 - 485", "doi": "10.1504/IJCVR.2019.102286", "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sentiment analysis has been emerging recently as one of the major natural\nlanguage processing (NLP) tasks in many applications. Especially, as social\nmedia channels (e.g. social networks or forums) have become significant sources\nfor brands to observe user opinions about their products, this task is thus\nincreasingly crucial. However, when applied with real data obtained from social\nmedia, we notice that there is a high volume of short and informal messages\nposted by users on those channels. This kind of data makes the existing works\nsuffer from many difficulties to handle, especially ones using deep learning\napproaches. In this paper, we propose an approach to handle this problem. This\nwork is extended from our previous work, in which we proposed to combine the\ntypical deep learning technique of Convolutional Neural Networks with domain\nknowledge. The combination is used for acquiring additional training data\naugmentation and a more reasonable loss function. In this work, we further\nimprove our architecture by various substantial enhancements, including\nnegation-based data augmentation, transfer learning for word embeddings, the\ncombination of word-level embeddings and character-level embeddings, and using\nmultitask learning technique for attaching domain knowledge rules in the\nlearning process. Those enhancements, specifically aiming to handle short and\ninformal messages, help us to enjoy significant improvement in performance once\nexperimenting on real datasets.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2019 06:03:57 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 07:53:04 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Vo", "Khuong", ""], ["Nguyen", "Tri", ""], ["Pham", "Dang", ""], ["Nguyen", "Mao", ""], ["Truong", "Minh", ""], ["Mai", "Trung", ""], ["Quan", "Tho", ""]]}, {"id": "1902.06092", "submitter": "Sangarshanan Veeraraghavan", "authors": "Sangarshanan Veeraraghavan", "title": "Exploring Language Similarities with Dimensionality Reduction Technique", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years several novel models were developed to process natural\nlanguage, development of accurate language translation systems have helped us\novercome geographical barriers and communicate ideas effectively. These models\nare developed mostly for a few languages that are widely used while other\nlanguages are ignored. Most of the languages that are spoken share lexical,\nsyntactic and sematic similarity with several other languages and knowing this\ncan help us leverage the existing model to build more specific and accurate\nmodels that can be used for other languages, so here I have explored the idea\nof representing several known popular languages in a lower dimension such that\ntheir similarities can be visualized using simple 2 dimensional plots. This can\neven help us understand newly discovered languages that may not share its\nvocabulary with any of the existing languages.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2019 11:27:21 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Veeraraghavan", "Sangarshanan", ""]]}, {"id": "1902.06193", "submitter": "Mohammad Amin Alipour", "authors": "Soodeh Atefi, Mohammad Amin Alipour", "title": "An Automated Testing Framework for Conversational Agents", "comments": "work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Conversational agents are systems with a conversational interface that afford\ninteraction in spoken language. These systems are becoming prevalent and are\npreferred in various contexts and for many users. Despite their increasing\nsuccess, the automated testing infrastructure to support the effective and\nefficient development of such systems compared to traditional software systems\nis still limited. Automated testing framework for conversational systems can\nimprove the quality of these systems by assisting developers to write, execute,\nand maintain test cases. In this paper, we introduce our work-in-progress\nautomated testing framework, and its realization in the Python programming\nlanguage. We discuss some research problems in the development of such an\nautomated testing framework for conversational agents. In particular, we point\nout the problems of the specification of the expected behavior, known as test\noracles, and semantic comparison of utterances.\n", "versions": [{"version": "v1", "created": "Sun, 17 Feb 2019 03:17:03 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Atefi", "Soodeh", ""], ["Alipour", "Mohammad Amin", ""]]}, {"id": "1902.06208", "submitter": "Albert Haque", "authors": "Albert Haque", "title": "Twitch Plays Pokemon, Machine Learns Twitch: Unsupervised Context-Aware\n  Anomaly Detection for Identifying Trolls in Streaming Data", "comments": "Haque, A. Twitch Plays Pokemon, Machine Learns Twitch: Unsupervised\n  Context-Aware Anomaly Detection for Identifying Trolls in Streaming Data.\n  University of Texas at Austin. 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing importance of online communities, discussion forums, and\ncustomer reviews, Internet \"trolls\" have proliferated thereby making it\ndifficult for information seekers to find relevant and correct information. In\nthis paper, we consider the problem of detecting and identifying Internet\ntrolls, almost all of which are human agents. Identifying a human agent among a\nhuman population presents significant challenges compared to detecting\nautomated spam or computerized robots. To learn a troll's behavior, we use\ncontextual anomaly detection to profile each chat user. Using clustering and\ndistance-based methods, we use contextual data such as the group's current\ngoal, the current time, and the username to classify each point as an anomaly.\nA user whose features significantly differ from the norm will be classified as\na troll. We collected 38 million data points from the viral Internet fad,\nTwitch Plays Pokemon. Using clustering and distance-based methods, we develop\nheuristics for identifying trolls. Using MapReduce techniques for preprocessing\nand user profiling, we are able to classify trolls based on 10 features\nextracted from a user's lifetime history.\n", "versions": [{"version": "v1", "created": "Sun, 17 Feb 2019 06:09:39 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Haque", "Albert", ""]]}, {"id": "1902.06242", "submitter": "Omar Al-Harbi Mohammad", "authors": "Omar Al-Harbi", "title": "A Comparative Study of Feature Selection Methods for Dialectal Arabic\n  Sentiment Classification Using Support Vector Machine", "comments": "10 pages", "journal-ref": "IJCSNS International Journal of Computer Science and Network\n  Security, VOL.19 No.1, January 2019, 167-176", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unlike other languages, the Arabic language has a morphological complexity\nwhich makes the Arabic sentiment analysis is a challenging task. Moreover, the\npresence of the dialects in the Arabic texts have made the sentiment analysis\ntask is more challenging, due to the absence of specific rules that govern the\nwriting or speaking system. Generally, one of the problems of sentiment\nanalysis is the high dimensionality of the feature vector. To resolve this\nproblem, many feature selection methods have been proposed. In contrast to the\ndialectal Arabic language, these selection methods have been investigated\nwidely for the English language. This work investigated the effect of feature\nselection methods and their combinations on dialectal Arabic sentiment\nclassification. The feature selection methods are Information Gain (IG),\nCorrelation, Support Vector Machine (SVM), Gini Index (GI), and Chi-Square. A\nnumber of experiments were carried out on dialectical Jordanian reviews with\nusing an SVM classifier. Furthermore, the effect of different term weighting\nschemes, stemmers, stop words removal, and feature models on the performance\nwere investigated. The experimental results showed that the best performance of\nthe SVM classifier was obtained after the SVM and correlation feature selection\nmethods had been combined with the uni-gram model.\n", "versions": [{"version": "v1", "created": "Sun, 17 Feb 2019 10:51:15 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Al-Harbi", "Omar", ""]]}, {"id": "1902.06377", "submitter": "Yu Zhao", "authors": "Yu Zhao and Ji Liu", "title": "SCEF: A Support-Confidence-aware Embedding Framework for Knowledge Graph\n  Refinement", "comments": "(1)the model are unreasonable;(2)the experiments are unfair to\n  baselines;", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph (KG) refinement mainly aims at KG completion and correction\n(i.e., error detection). However, most conventional KG embedding models only\nfocus on KG completion with an unreasonable assumption that all facts in KG\nhold without noises, ignoring error detection which also should be significant\nand essential for KG refinement.In this paper, we propose a novel\nsupport-confidence-aware KG embedding framework (SCEF), which implements KG\ncompletion and correction simultaneously by learning knowledge representations\nwith both triple support and triple confidence. Specifically, we build model\nenergy function by incorporating conventional translation-based model with\nsupport and confidence. To make our triple support-confidence more sufficient\nand robust, we not only consider the internal structural information in KG,\nstudying the approximate relation entailment as triple confidence constraints,\nbut also the external textual evidence, proposing two kinds of triple supports\nwith entity types and descriptions respectively.Through extensive experiments\non real-world datasets, we demonstrate SCEF's effectiveness.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 02:00:23 GMT"}, {"version": "v2", "created": "Sat, 27 Jul 2019 02:07:10 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Zhao", "Yu", ""], ["Liu", "Ji", ""]]}, {"id": "1902.06423", "submitter": "Florian Mai", "authors": "Florian Mai, Lukas Galke, Ansgar Scherp", "title": "CBOW Is Not All You Need: Combining CBOW with the Compositional Matrix\n  Space Model", "comments": "Conference paper at ICLR 2019", "journal-ref": "In International Conference on Learning Representations 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous Bag of Words (CBOW) is a powerful text embedding method. Due to\nits strong capabilities to encode word content, CBOW embeddings perform well on\na wide range of downstream tasks while being efficient to compute. However,\nCBOW is not capable of capturing the word order. The reason is that the\ncomputation of CBOW's word embeddings is commutative, i.e., embeddings of XYZ\nand ZYX are the same. In order to address this shortcoming, we propose a\nlearning algorithm for the Continuous Matrix Space Model, which we call\nContinual Multiplication of Words (CMOW). Our algorithm is an adaptation of\nword2vec, so that it can be trained on large quantities of unlabeled text. We\nempirically show that CMOW better captures linguistic properties, but it is\ninferior to CBOW in memorizing word content. Motivated by these findings, we\npropose a hybrid model that combines the strengths of CBOW and CMOW. Our\nresults show that the hybrid CBOW-CMOW-model retains CBOW's strong ability to\nmemorize word content while at the same time substantially improving its\nability to encode other linguistic information by 8%. As a result, the hybrid\nalso performs better on 8 out of 11 supervised downstream tasks with an average\nimprovement of 1.2%.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 06:54:14 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Mai", "Florian", ""], ["Galke", "Lukas", ""], ["Scherp", "Ansgar", ""]]}, {"id": "1902.06428", "submitter": "Robert J\\\"aschke", "authors": "Frank Fischer and Robert J\\\"aschke", "title": "\"The Michael Jordan of Greatness\": Extracting Vossian Antonomasia from\n  Two Decades of the New York Times, 1987-2007", "comments": null, "journal-ref": "Digital Scholarship in the Humanities (January 2019)", "doi": "10.1093/llc/fqy087", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Vossian Antonomasia is a prolific stylistic device, in use since antiquity.\nIt can compress the introduction or description of a person or another named\nentity into a terse, poignant formulation and can best be explained by an\nexample: When Norwegian world champion Magnus Carlsen is described as \"the\nMozart of chess\", it is Vossian Antonomasia we are dealing with. The pattern is\nsimple: A source (Mozart) is used to describe a target (Magnus Carlsen), the\ntransfer of meaning is reached via a modifier (\"of chess\"). This phenomenon has\nbeen discussed before (as 'metaphorical antonomasia' or, with special focus on\nthe source object, as 'paragons'), but no corpus-based approach has been\nundertaken as yet to explore its breadth and variety. We are looking into a\nfull-text newspaper corpus (The New York Times, 1987-2007) and describe a new\nmethod for the automatic extraction of Vossian Antonomasia based on Wikidata\nentities. Our analysis offers new insights into the occurrence of popular\nparagons and their distribution.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 07:21:21 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Fischer", "Frank", ""], ["J\u00e4schke", "Robert", ""]]}, {"id": "1902.06450", "submitter": "Linhao Dong", "authors": "Linhao Dong, Feng Wang, Bo Xu", "title": "Self-Attention Aligner: A Latency-Control End-to-End Model for ASR Using\n  Self-Attention Network and Chunk-Hopping", "comments": "To appear at ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-attention network, an attention-based feedforward neural network, has\nrecently shown the potential to replace recurrent neural networks (RNNs) in a\nvariety of NLP tasks. However, it is not clear if the self-attention network\ncould be a good alternative of RNNs in automatic speech recognition (ASR),\nwhich processes the longer speech sequences and may have online recognition\nrequirements. In this paper, we present a RNN-free end-to-end model:\nself-attention aligner (SAA), which applies the self-attention networks to a\nsimplified recurrent neural aligner (RNA) framework. We also propose a\nchunk-hopping mechanism, which enables the SAA model to encode on segmented\nframe chunks one after another to support online recognition. Experiments on\ntwo Mandarin ASR datasets show the replacement of RNNs by the self-attention\nnetworks yields a 8.4%-10.2% relative character error rate (CER) reduction. In\naddition, the chunk-hopping mechanism allows the SAA to have only a 2.5%\nrelative CER degradation with a 320ms latency. After jointly training with a\nself-attention network language model, our SAA model obtains further error rate\nreduction on multiple datasets. Especially, it achieves 24.12% CER on the\nMandarin ASR benchmark (HKUST), exceeding the best end-to-end model by over 2%\nabsolute CER.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 08:17:24 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Dong", "Linhao", ""], ["Wang", "Feng", ""], ["Xu", "Bo", ""]]}, {"id": "1902.06598", "submitter": "Jose Segovia Martin", "authors": "Jos\\'e Segovia Mart\\'in, Bradley Walker, Nicolas Fay, Monica Tamariz", "title": "Network connectivity dynamics affect the evolution of culturally\n  transmitted variants", "comments": "Electronic supplementary material and simulation code are available\n  at: https://github.com/jsegoviamartin/network_connectivity_dynamics_model", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The distribution of cultural variants in a population is shaped by both\nneutral evolutionary dynamics and by selection pressures, which include several\nindividual cognitive biases, demographic factors and social network structures.\nThe temporal dynamics of social network connectivity, i.e. the order in which\nindividuals in a population interact with each other, has been largely\nunexplored. In this paper we investigate how, in a fully connected social\nnetwork, connectivity dynamics, alone and in interaction with different\ncognitive biases, affect the evolution of cultural variants. Using agent-based\ncomputer simulations, we manipulate population connectivity dynamics (early,\nmiddle and late full-population connectivity); content bias, or a preference\nfor high-quality variants; coordination bias, or whether agents tend to use\nself-produced variants (egocentric bias), or to switch to variants observed in\nothers (allocentric bias); and memory size, or the number of items that agents\ncan store in their memory. We show that connectivity dynamics affect the\ntime-course of variant spread, with lower connectivity slowing down convergence\nof the population onto a single cultural variant. We also show that, compared\nto a neutral evolutionary model, content bias accelerates convergence and\namplifies the effects of connectivity dynamics, whilst larger memory size and\ncoordination bias, especially egocentric bias, slow down convergence.\nFurthermore, connectivity dynamics affect the frequency of high quality\nvariants (adaptiveness), with late connectivity populations showing bursts of\nrapid change in adaptiveness followed by periods of relatively slower change,\nand early connectivity populations following a single-peak evolutionary\ndynamic. In this way, we provide for the first time a direct connection between\nthe order of agents' interactions and punctuational evolution.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 15:53:14 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Mart\u00edn", "Jos\u00e9 Segovia", ""], ["Walker", "Bradley", ""], ["Fay", "Nicolas", ""], ["Tamariz", "Monica", ""]]}, {"id": "1902.06635", "submitter": "Pinar Karagoz", "authors": "Fatih Kurt, Dilek Kisa, Pinar Karagoz", "title": "Investigating the Effect of Segmentation Methods on Neural Model based\n  Sentiment Analysis on Informal Short Texts in Turkish", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates segmentation approaches for sentiment analysis on\ninformal short texts in Turkish. The two building blocks of the proposed work\nare segmentation and deep neural network model. Segmentation focuses on\npreprocessing of text with different methods. These methods are grouped in\nfour: morphological, sub-word, tokenization, and hybrid approaches. We analyzed\nseveral variants for each of these four methods. The second stage focuses on\nevaluation of the neural model for sentiment analysis. The performance of each\nsegmentation method is evaluated under Convolutional Neural Network (CNN) and\nRecurrent Neural Network (RNN) model proposed in the literature for sentiment\nclassification.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 16:26:01 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Kurt", "Fatih", ""], ["Kisa", "Dilek", ""], ["Karagoz", "Pinar", ""]]}, {"id": "1902.06689", "submitter": "Cass Dykeman", "authors": "Mandy M. Greaves and Cass Dykeman", "title": "A Corpus Linguistic Analysis of Public Reddit Blog Posts on Non-Suicidal\n  Self-Injury", "comments": "21 pages, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While non-suicidal self-injury (NSSI) is not a new phenomenon, there is still\na limited yet little is still known about understanding of the behavior, the\nintent behind the behavior and what the individuals themselves say about their\nbehavior. This study collected pro-NSSI public blog posts from Reddit on\npro-NSSI and analyzed the content linguistically using LIWC software, in order\nto examine the use of NSSI specific words, linguistic properties and the\npsychological linguistic properties. were examined. The results inform current\ncounseling practices by dispelling myths and providing insight into the inner\nworld of people who engage in use NSSII to cope. The most frequently appearing\ncategory of For NSSI specific words categories, in the Reddit blogs was the\nreasons in which one engagesfor engaging in NSSI was the most frequently used\nin the Reddit blogs. The linguistic properties found in the analysis reflected\nthe predicted results; authors of pro-NSSI posts used demonstrated expected\nresults of first-person singular pronouns extensively, which indicatesing high\nlevels of mental health distress and isolation. The psychological linguistic\nproperties that could be observed of in these public Reddit posts were\ndominantly in a negative emotional tone which demonstrates youth and\nimpulsivity. The linguistic properties found when these posts were analyzed\nsupports the work of earlier studies that dispelled common myths about NSSI\nthat were circulating in the mental health community. These findings suggest\nthat the language of people who engage in NSSI supports research findings in\ndispelling common myths about NSSI.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 23:42:42 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Greaves", "Mandy M.", ""], ["Dykeman", "Cass", ""]]}, {"id": "1902.06734", "submitter": "Pushkar Mishra", "authors": "Pushkar Mishra, Marco Del Tredici, Helen Yannakoudakis and Ekaterina\n  Shutova", "title": "Author Profiling for Hate Speech Detection", "comments": "Proceedings of the 27th International Conference on Computational\n  Linguistics (COLING) 2018. arXiv admin note: text overlap with\n  arXiv:1809.00378", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid growth of social media in recent years has fed into some highly\nundesirable phenomena such as proliferation of abusive and offensive language\non the Internet. Previous research suggests that such hateful content tends to\ncome from users who share a set of common stereotypes and form communities\naround them. The current state-of-the-art approaches to hate speech detection\nare oblivious to user and community information and rely entirely on textual\n(i.e., lexical and semantic) cues. In this paper, we propose a novel approach\nto this problem that incorporates community-based profiling features of Twitter\nusers. Experimenting with a dataset of 16k tweets, we show that our methods\nsignificantly outperform the current state of the art in hate speech detection.\nFurther, we conduct a qualitative analysis of model characteristics. We release\nour code, pre-trained models and all the resources used in the public domain.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 20:00:30 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Mishra", "Pushkar", ""], ["Del Tredici", "Marco", ""], ["Yannakoudakis", "Helen", ""], ["Shutova", "Ekaterina", ""]]}, {"id": "1902.06833", "submitter": "Shruti Palaskar", "authors": "Shruti Palaskar, Vikas Raunak and Florian Metze", "title": "Learned In Speech Recognition: Contextual Acoustic Word Embeddings", "comments": "Accepted at ICASSP 2019, 5 pages, 1 figure, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end acoustic-to-word speech recognition models have recently gained\npopularity because they are easy to train, scale well to large amounts of\ntraining data, and do not require a lexicon. In addition, word models may also\nbe easier to integrate with downstream tasks such as spoken language\nunderstanding, because inference (search) is much simplified compared to\nphoneme, character or any other sort of sub-word units. In this paper, we\ndescribe methods to construct contextual acoustic word embeddings directly from\na supervised sequence-to-sequence acoustic-to-word speech recognition model\nusing the learned attention distribution. On a suite of 16 standard sentence\nevaluation tasks, our embeddings show competitive performance against a\nword2vec model trained on the speech transcriptions. In addition, we evaluate\nthese embeddings on a spoken language understanding task, and observe that our\nembeddings match the performance of text-based embeddings in a pipeline of\nfirst performing speech recognition and then constructing word embeddings from\ntranscriptions.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 23:06:56 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Palaskar", "Shruti", ""], ["Raunak", "Vikas", ""], ["Metze", "Florian", ""]]}, {"id": "1902.06843", "submitter": "Amir Yazdavar", "authors": "Amir Hossein Yazdavar, Mohammad Saeid Mahdavinejad, Goonmeet Bajaj,\n  William Romine, Amirhassan Monadjemi, Krishnaprasad Thirunarayan, Amit Sheth,\n  Jyotishman Pathak", "title": "Fusing Visual, Textual and Connectivity Clues for Studying Mental Health", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With ubiquity of social media platforms, millions of people are sharing their\nonline persona by expressing their thoughts, moods, emotions, feelings, and\neven their daily struggles with mental health issues voluntarily and publicly\non social media. Unlike the most existing efforts which study depression by\nanalyzing textual content, we examine and exploit multimodal big data to\ndiscern depressive behavior using a wide variety of features including\nindividual-level demographics. By developing a multimodal framework and\nemploying statistical techniques for fusing heterogeneous sets of features\nobtained by processing visual, textual and user interaction data, we\nsignificantly enhance the current state-of-the-art approaches for identifying\ndepressed individuals on Twitter (improving the average F1-Score by 5 percent)\nas well as facilitate demographic inference from social media for broader\napplications. Besides providing insights into the relationship between\ndemographics and mental health, our research assists in the design of a new\nbreed of demographic-aware health interventions.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 00:10:08 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Yazdavar", "Amir Hossein", ""], ["Mahdavinejad", "Mohammad Saeid", ""], ["Bajaj", "Goonmeet", ""], ["Romine", "William", ""], ["Monadjemi", "Amirhassan", ""], ["Thirunarayan", "Krishnaprasad", ""], ["Sheth", "Amit", ""], ["Pathak", "Jyotishman", ""]]}, {"id": "1902.06897", "submitter": "Shubham Gupta", "authors": "Shubham Gupta and Ambedkar Dukkipati", "title": "Winning an Election: On Emergent Strategic Communication in Multi-Agent\n  Networks", "comments": "A shorter version of this paper has been accepted as an extended\n  abstract at AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans use language to collectively execute abstract strategies besides using\nit as a referential tool for identifying physical entities. Recently, multiple\nattempts at replicating the process of emergence of language in artificial\nagents have been made. While existing approaches study emergent languages as\nreferential tools, in this paper, we study their role in discovering and\nimplementing strategies. We formulate the problem using a voting game where two\ncandidate agents contest in an election with the goal of convincing population\nmembers (other agents), that are connected to each other via an underlying\nnetwork, to vote for them. To achieve this goal, agents are only allowed to\nexchange messages in the form of sequences of discrete symbols to spread their\npropaganda. We use neural networks with Gumbel-Softmax relaxation for sampling\ncategorical random variables to parameterize the policies followed by all\nagents. Using our proposed framework, we provide concrete answers to the\nfollowing questions: (i) Do the agents learn to communicate in a meaningful way\nand does the emergent communication play a role in deciding the winner? (ii)\nDoes the system evolve as expected under various reward structures? (iii) How\nis the emergent language affected by the community structure in the network? To\nthe best of our knowledge, we are the first to explore emergence of\ncommunication for discovering and implementing strategies in a setting where\nagents communicate over a network.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 05:14:14 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 05:41:09 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Gupta", "Shubham", ""], ["Dukkipati", "Ambedkar", ""]]}, {"id": "1902.07023", "submitter": "Fenia Christopoulou", "authors": "Fenia Christopoulou, Makoto Miwa and Sophia Ananiadou", "title": "A Walk-based Model on Entity Graphs for Relation Extraction", "comments": "8 pages, 2 figures, 2 tables", "journal-ref": "Proceedings of the 56th Annual Meeting of the Association for\n  Computational Linguistics (Volume 2: Short Papers), 2018, pages 81-88", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel graph-based neural network model for relation extraction.\nOur model treats multiple pairs in a sentence simultaneously and considers\ninteractions among them. All the entities in a sentence are placed as nodes in\na fully-connected graph structure. The edges are represented with\nposition-aware contexts around the entity pairs. In order to consider different\nrelation paths between two entities, we construct up to l-length walks between\neach pair. The resulting walks are merged and iteratively used to update the\nedge representations into longer walks representations. We show that the model\nachieves performance comparable to the state-of-the-art systems on the ACE 2005\ndataset without using any external tools.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 12:34:40 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 11:15:29 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Christopoulou", "Fenia", ""], ["Miwa", "Makoto", ""], ["Ananiadou", "Sophia", ""]]}, {"id": "1902.07068", "submitter": "Laura Anderlucci", "authors": "Laura Anderlucci, Lucia Guastadisegni, Cinzia Viroli", "title": "Classifying textual data: shallow, deep and ensemble methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on a comparative evaluation of the most common and modern\nmethods for text classification, including the recent deep learning strategies\nand ensemble methods. The study is motivated by a challenging real data\nproblem, characterized by high-dimensional and extremely sparse data, deriving\nfrom incoming calls to the customer care of an Italian phone company. We will\nshow that deep learning outperforms many classical (shallow) strategies but the\ncombination of shallow and deep learning methods in a unique ensemble\nclassifier may improve the robustness and the accuracy of \"single\"\nclassification methods.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 15:47:35 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Anderlucci", "Laura", ""], ["Guastadisegni", "Lucia", ""], ["Viroli", "Cinzia", ""]]}, {"id": "1902.07087", "submitter": "Swetava Ganguli", "authors": "Jared Dunnmon, Swetava Ganguli, Darren Hau, Brooke Husic", "title": "Predicting US State-Level Agricultural Sentiment as a Measure of Food\n  Security with Tweets from Farming Communities", "comments": "Second revised version corrects typographical errors and adds a few\n  additional references", "journal-ref": null, "doi": null, "report-no": "Final report for research project conducted as part of the\n  Sustainability and Artificial Intelligence Laboratory (SAIL) at Stanford\n  University and the Winter 2017 offering of CS 224N Natural Language\n  Processing with Deep Learning", "categories": "cs.CL cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The ability to obtain accurate food security metrics in developing areas\nwhere relevant data can be sparse is critically important for policy makers\ntasked with implementing food aid programs. As a result, a great deal of work\nhas been dedicated to predicting important food security metrics such as annual\ncrop yields using a variety of methods including simulation, remote sensing,\nweather models, and human expert input. As a complement to existing techniques\nin crop yield prediction, this work develops neural network models for\npredicting the sentiment of Twitter feeds from farming communities.\nSpecifically, we investigate the potential of both direct learning on a small\ndataset of agriculturally-relevant tweets and transfer learning from larger,\nwell-labeled sentiment datasets from other domains (e.g.~politics) to\naccurately predict agricultural sentiment, which we hope would ultimately serve\nas a useful crop yield predictor. We find that direct learning from small,\nrelevant datasets outperforms transfer learning from large, fully-labeled\ndatasets, that convolutional neural networks broadly outperform recurrent\nneural networks on Twitter sentiment classification, and that these models\nperform substantially less well on ternary sentiment problems characteristic of\npractical settings than on binary problems often found in the literature.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 20:29:00 GMT"}, {"version": "v2", "created": "Thu, 25 Apr 2019 20:00:59 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Dunnmon", "Jared", ""], ["Ganguli", "Swetava", ""], ["Hau", "Darren", ""], ["Husic", "Brooke", ""]]}, {"id": "1902.07110", "submitter": "Peng Xu", "authors": "Peng Xu and Pascale Fung", "title": "A novel repetition normalized adversarial reward for headline generation", "comments": "Accepted by ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While reinforcement learning can effectively improve language generation\nmodels, it often suffers from generating incoherent and repetitive phrases\n\\cite{paulus2017deep}. In this paper, we propose a novel repetition normalized\nadversarial reward to mitigate these problems. Our repetition penalized reward\ncan greatly reduce the repetition rate and adversarial training mitigates\ngenerating incoherent phrases. Our model significantly outperforms the baseline\nmodel on ROUGE-1\\,(+3.24), ROUGE-L\\,(+2.25), and a decreased repetition-rate\n(-4.98\\%).\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 16:00:38 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Xu", "Peng", ""], ["Fung", "Pascale", ""]]}, {"id": "1902.07178", "submitter": "Jinxi Guo", "authors": "Jinxi Guo, Tara N. Sainath, Ron J. Weiss", "title": "A spelling correction model for end-to-end speech recognition", "comments": "Accepted to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based sequence-to-sequence models for speech recognition jointly\ntrain an acoustic model, language model (LM), and alignment mechanism using a\nsingle neural network and require only parallel audio-text pairs. Thus, the\nlanguage model component of the end-to-end model is only trained on transcribed\naudio-text pairs, which leads to performance degradation especially on rare\nwords. While there have been a variety of work that look at incorporating an\nexternal LM trained on text-only data into the end-to-end framework, none of\nthem have taken into account the characteristic error distribution made by the\nmodel. In this paper, we propose a novel approach to utilizing text-only data,\nby training a spelling correction (SC) model to explicitly correct those\nerrors. On the LibriSpeech dataset, we demonstrate that the proposed model\nresults in an 18.6% relative improvement in WER over the baseline model when\ndirectly correcting top ASR hypothesis, and a 29.0% relative improvement when\nfurther rescoring an expanded n-best list using an external LM.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 18:18:59 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Guo", "Jinxi", ""], ["Sainath", "Tara N.", ""], ["Weiss", "Ron J.", ""]]}, {"id": "1902.07181", "submitter": "Jacob Andreas", "authors": "Jacob Andreas", "title": "Measuring Compositionality in Representation Learning", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning algorithms represent input data with vector embeddings\nor discrete codes. When inputs exhibit compositional structure (e.g. objects\nbuilt from parts or procedures from subroutines), it is natural to ask whether\nthis compositional structure is reflected in the the inputs' learned\nrepresentations. While the assessment of compositionality in languages has\nreceived significant attention in linguistics and adjacent fields, the machine\nlearning literature lacks general-purpose tools for producing graded\nmeasurements of compositional structure in more general (e.g. vector-valued)\nrepresentation spaces. We describe a procedure for evaluating compositionality\nby measuring how well the true representation-producing model can be\napproximated by a model that explicitly composes a collection of inferred\nrepresentational primitives. We use the procedure to provide formal and\nempirical characterizations of compositional structure in a variety of\nsettings, exploring the relationship between compositionality and learning\ndynamics, human judgments, representational similarity, and generalization.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 18:27:12 GMT"}, {"version": "v2", "created": "Sat, 6 Apr 2019 21:35:43 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Andreas", "Jacob", ""]]}, {"id": "1902.07198", "submitter": "Rishabh Agarwal", "authors": "Rishabh Agarwal, Chen Liang, Dale Schuurmans, Mohammad Norouzi", "title": "Learning to Generalize from Sparse and Underspecified Rewards", "comments": "ICML 2019", "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning, PMLR 97:130-140, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning from sparse and underspecified rewards,\nwhere an agent receives a complex input, such as a natural language\ninstruction, and needs to generate a complex response, such as an action\nsequence, while only receiving binary success-failure feedback. Such\nsuccess-failure rewards are often underspecified: they do not distinguish\nbetween purposeful and accidental success. Generalization from underspecified\nrewards hinges on discounting spurious trajectories that attain accidental\nsuccess, while learning from sparse feedback requires effective exploration. We\naddress exploration by using a mode covering direction of KL divergence to\ncollect a diverse set of successful trajectories, followed by a mode seeking KL\ndivergence to train a robust policy. We propose Meta Reward Learning (MeRL) to\nconstruct an auxiliary reward function that provides more refined feedback for\nlearning. The parameters of the auxiliary reward function are optimized with\nrespect to the validation performance of a trained policy. The MeRL approach\noutperforms our alternative reward learning technique based on Bayesian\nOptimization, and achieves the state-of-the-art on weakly-supervised semantic\nparsing. It improves previous work by 1.2% and 2.4% on WikiTableQuestions and\nWikiSQL datasets respectively.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 18:51:10 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 07:21:04 GMT"}, {"version": "v3", "created": "Fri, 24 May 2019 18:21:10 GMT"}, {"version": "v4", "created": "Fri, 31 May 2019 20:54:19 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Agarwal", "Rishabh", ""], ["Liang", "Chen", ""], ["Schuurmans", "Dale", ""], ["Norouzi", "Mohammad", ""]]}, {"id": "1902.07248", "submitter": "Yi-Shuai Niu", "authors": "Yi-Shuai Niu, Xi-Wei Hu, Yu You, Faouzi Mohamed Benammour, Hu Zhang", "title": "Sentence Compression via DC Programming Approach", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence compression is an important problem in natural language processing.\nIn this paper, we firstly establish a new sentence compression model based on\nthe probability model and the parse tree model. Our sentence compression model\nis equivalent to an integer linear program (ILP) which can both guarantee the\nsyntax correctness of the compression and save the main meaning. We propose\nusing a DC (Difference of convex) programming approach (DCA) for finding local\noptimal solution of our model. Combing DCA with a parallel-branch-and-bound\nframework, we can find global optimal solution. Numerical results demonstrate\nthe good quality of our sentence compression model and the excellent\nperformance of our proposed solution algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 05:43:00 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Niu", "Yi-Shuai", ""], ["Hu", "Xi-Wei", ""], ["You", "Yu", ""], ["Benammour", "Faouzi Mohamed", ""], ["Zhang", "Hu", ""]]}, {"id": "1902.07249", "submitter": "Seil Na", "authors": "Seil Na, Yo Joong Choe, Dong-Hyun Lee, Gunhee Kim", "title": "Discovery of Natural Language Concepts in Individual Units of CNNs", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep convolutional networks have achieved improved performance in\nmany natural language tasks, they have been treated as black boxes because they\nare difficult to interpret. Especially, little is known about how they\nrepresent language in their intermediate layers. In an attempt to understand\nthe representations of deep convolutional networks trained on language tasks,\nwe show that individual units are selectively responsive to specific morphemes,\nwords, and phrases, rather than responding to arbitrary and uninterpretable\npatterns. In order to quantitatively analyze such an intriguing phenomenon, we\npropose a concept alignment method based on how units respond to the replicated\ntext. We conduct analyses with different architectures on multiple datasets for\nclassification and translation tasks and provide new insights into how deep\nmodels understand natural language.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 06:19:14 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 09:05:10 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Na", "Seil", ""], ["Choe", "Yo Joong", ""], ["Lee", "Dong-Hyun", ""], ["Kim", "Gunhee", ""]]}, {"id": "1902.07250", "submitter": "Kristine Mae Adlaon", "authors": "Kristine Mae M. Adlaon and Nelson Marcos", "title": "Neural Machine Translation for Cebuano to Tagalog with Subword Unit\n  Translation", "comments": "Published in IALP 2018 Conference Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Philippines is an archipelago composed of 7, 641 different islands with\nmore than 150 different languages. This linguistic differences and diversity,\nthough may be seen as a beautiful feature, have contributed to the difficulty\nin the promotion of educational and cultural development of different domains\nin the country. An effective machine translation system solely dedicated to\ncater Philippine languages will surely help bridge this gap. In this research\nwork, a never before applied approach for language translation to a Philippine\nlanguage was used for a Cebuano to Tagalog translator. A Recurrent Neural\nNetwork was used to implement the translator using OpenNMT sequence modeling\ntool in TensorFlow. The performance of the translation was evaluated using the\nBLEU Score metric. For the Cebuano to Tagalog translation, BLEU produced a\nscore of 20.01. A subword unit translation for verbs and copyable approach was\nperformed where commonly seen mistranslated words from the source to the target\nwere corrected. The BLEU score increased to 22.87. Though slightly higher, this\nscore still indicates that the translation is somehow understandable but is not\nyet considered as a good translation.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2019 13:28:25 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Adlaon", "Kristine Mae M.", ""], ["Marcos", "Nelson", ""]]}, {"id": "1902.07282", "submitter": "Linfeng Song", "authors": "Linfeng Song, Daniel Gildea, Yue Zhang, Zhiguo Wang and Jinsong Su", "title": "Semantic Neural Machine Translation using AMR", "comments": "Transaction of ACL 2019", "journal-ref": "Transactions of the Association for Computational Linguistics, 7,\n  pages19-31, 2019", "doi": "10.1162/tacl_a_00252", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is intuitive that semantic representations can be useful for machine\ntranslation, mainly because they can help in enforcing meaning preservation and\nhandling data sparsity (many sentences correspond to one meaning) of machine\ntranslation models. On the other hand, little work has been done on leveraging\nsemantics for neural machine translation (NMT). In this work, we study the\nusefulness of AMR (short for abstract meaning representation) on NMT.\nExperiments on a standard English-to-German dataset show that incorporating AMR\nas additional knowledge can significantly improve a strong attention-based\nsequence-to-sequence neural translation model.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 21:03:35 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Song", "Linfeng", ""], ["Gildea", "Daniel", ""], ["Zhang", "Yue", ""], ["Wang", "Zhiguo", ""], ["Su", "Jinsong", ""]]}, {"id": "1902.07285", "submitter": "Wenqi Wang", "authors": "Wenqi Wang, Run Wang, Lina Wang, Zhibo Wang, Aoshuang Ye", "title": "Towards a Robust Deep Neural Network in Texts: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have achieved remarkable success in various tasks\n(e.g., image classification, speech recognition, and natural language\nprocessing (NLP)). However, researchers have demonstrated that DNN-based models\nare vulnerable to adversarial examples, which cause erroneous predictions by\nadding imperceptible perturbations into legitimate inputs. Recently, studies\nhave revealed adversarial examples in the text domain, which could effectively\nevade various DNN-based text analyzers and further bring the threats of the\nproliferation of disinformation. In this paper, we give a comprehensive survey\non the existing studies of adversarial techniques for generating adversarial\ntexts written by both English and Chinese characters and the corresponding\ndefense methods. More importantly, we hope that our work could inspire future\nstudies to develop more robust DNN-based text analyzers against known and\nunknown adversarial techniques.\n  We classify the existing adversarial techniques for crafting adversarial\ntexts based on the perturbation units, helping to better understand the\ngeneration of adversarial texts and build robust models for defense. In\npresenting the taxonomy of adversarial attacks and defenses in the text domain,\nwe introduce the adversarial techniques from the perspective of different NLP\ntasks. Finally, we discuss the existing challenges of adversarial attacks and\ndefenses in texts and present the future research directions in this emerging\nand challenging field.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 02:42:54 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2019 08:25:47 GMT"}, {"version": "v3", "created": "Sun, 14 Apr 2019 11:26:42 GMT"}, {"version": "v4", "created": "Thu, 17 Oct 2019 09:15:28 GMT"}, {"version": "v5", "created": "Fri, 3 Jan 2020 03:12:31 GMT"}, {"version": "v6", "created": "Wed, 21 Apr 2021 10:14:36 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Wang", "Wenqi", ""], ["Wang", "Run", ""], ["Wang", "Lina", ""], ["Wang", "Zhibo", ""], ["Ye", "Aoshuang", ""]]}, {"id": "1902.07516", "submitter": "Eric DeGiuli", "authors": "E. DeGiuli", "title": "Emergence of order in random languages", "comments": "16 pages + 1 appendix; v2: references added and some explanations\n  expanded. J. Phys. A: Math. Theor 2019", "journal-ref": null, "doi": "10.1088/1751-8121/ab293c", "report-no": null, "categories": "cond-mat.dis-nn cs.CL cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider languages generated by weighted context-free grammars. It is\nshown that the behaviour of large texts is controlled by saddle-point equations\nfor an appropriate generating function. We then consider ensembles of grammars,\nin particular the Random Language Model of E. DeGiuli, Phys. Rev. Lett., 122,\n128301, 2019. This model is solved in the replica-symmetric ansatz, which is\nvalid in the high-temperature, disordered phase. It is shown that in the phase\nin which languages carry information, the replica symmetry must be broken.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 11:30:17 GMT"}, {"version": "v2", "created": "Fri, 28 Jun 2019 08:38:11 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["DeGiuli", "E.", ""]]}, {"id": "1902.07613", "submitter": "Siddharth Dalmia", "authors": "Siddharth Dalmia, Xinjian Li, Alan W Black, Florian Metze", "title": "Phoneme Level Language Models for Sequence Based Low Resource ASR", "comments": "To appear in ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building multilingual and crosslingual models help bring different languages\ntogether in a language universal space. It allows models to share parameters\nand transfer knowledge across languages, enabling faster and better adaptation\nto a new language. These approaches are particularly useful for low resource\nlanguages. In this paper, we propose a phoneme-level language model that can be\nused multilingually and for crosslingual adaptation to a target language. We\nshow that our model performs almost as well as the monolingual models by using\nsix times fewer parameters, and is capable of better adaptation to languages\nnot seen during training in a low resource scenario. We show that these\nphoneme-level language models can be used to decode sequence based\nConnectionist Temporal Classification (CTC) acoustic model outputs to obtain\ncomparable word error rates with Weighted Finite State Transducer (WFST) based\ndecoding in Babel languages. We also show that these phoneme-level language\nmodels outperform WFST decoding in various low-resource conditions like\nadapting to a new language and domain mismatch between training and testing\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 16:00:12 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Dalmia", "Siddharth", ""], ["Li", "Xinjian", ""], ["Black", "Alan W", ""], ["Metze", "Florian", ""]]}, {"id": "1902.07669", "submitter": "Daniel King", "authors": "Mark Neumann, Daniel King, Iz Beltagy, Waleed Ammar", "title": "ScispaCy: Fast and Robust Models for Biomedical Natural Language\n  Processing", "comments": "BioNLP@ACL2019 final version", "journal-ref": "Proceedings of the 18th BioNLP Workshop and Shared Task (2019)\n  319-327", "doi": "10.18653/v1/W19-5034", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite recent advances in natural language processing, many statistical\nmodels for processing text perform extremely poorly under domain shift.\nProcessing biomedical and clinical text is a critically important application\narea of natural language processing, for which there are few robust, practical,\npublicly available models. This paper describes scispaCy, a new tool for\npractical biomedical/scientific text processing, which heavily leverages the\nspaCy library. We detail the performance of two packages of models released in\nscispaCy and demonstrate their robustness on several tasks and datasets. Models\nand code are available at https://allenai.github.io/scispacy/\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 17:28:51 GMT"}, {"version": "v2", "created": "Thu, 21 Feb 2019 17:50:09 GMT"}, {"version": "v3", "created": "Wed, 9 Oct 2019 23:07:18 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Neumann", "Mark", ""], ["King", "Daniel", ""], ["Beltagy", "Iz", ""], ["Ammar", "Waleed", ""]]}, {"id": "1902.07814", "submitter": "Xiang Ren", "authors": "Hongtao Lin, Jun Yan, Meng Qu, Xiang Ren", "title": "Learning Dual Retrieval Module for Semi-supervised Relation Extraction", "comments": "10 pages, 2-page references. Accepted to The Web Conference 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relation extraction is an important task in structuring content of text data,\nand becomes especially challenging when learning with weak supervision---where\nonly a limited number of labeled sentences are given and a large number of\nunlabeled sentences are available. Most existing work exploits unlabeled data\nbased on the ideas of self-training (i.e., bootstrapping a model) and\nmulti-view learning (e.g., ensembling multiple model variants). However, these\nmethods either suffer from the issue of semantic drift, or do not fully capture\nthe problem characteristics of relation extraction. In this paper, we leverage\na key insight that retrieving sentences expressing a relation is a dual task of\npredicting relation label for a given sentence---two tasks are complementary to\neach other and can be optimized jointly for mutual enhancement. To model this\nintuition, we propose DualRE, a principled framework that introduces a\nretrieval module which is jointly trained with the original relation prediction\nmodule. In this way, high-quality samples selected by retrieval module from\nunlabeled data can be used to improve prediction module, and vice versa.\nExperimental results\\footnote{\\small Code and data can be found at\n\\url{https://github.com/INK-USC/DualRE}.} on two public datasets as well as\ncase studies demonstrate the effectiveness of the DualRE approach.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 23:56:21 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2019 20:39:43 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Lin", "Hongtao", ""], ["Yan", "Jun", ""], ["Qu", "Meng", ""], ["Ren", "Xiang", ""]]}, {"id": "1902.07816", "submitter": "Tianxiao Shen", "authors": "Tianxiao Shen, Myle Ott, Michael Auli, Marc'Aurelio Ranzato", "title": "Mixture Models for Diverse Machine Translation: Tricks of the Trade", "comments": "ICML 2019 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixture models trained via EM are among the simplest, most widely used and\nwell understood latent variable models in the machine learning literature.\nSurprisingly, these models have been hardly explored in text generation\napplications such as machine translation. In principle, they provide a latent\nvariable to control generation and produce a diverse set of hypotheses. In\npractice, however, mixture models are prone to degeneracies---often only one\ncomponent gets trained or the latent variable is simply ignored. We find that\ndisabling dropout noise in responsibility computation is critical to successful\ntraining. In addition, the design choices of parameterization, prior\ndistribution, hard versus soft EM and online versus offline assignment can\ndramatically affect model performance. We develop an evaluation protocol to\nassess both quality and diversity of generations against multiple references,\nand provide an extensive empirical study of several mixture model variants. Our\nanalysis shows that certain types of mixture models are more robust and offer\nthe best trade-off between translation quality and diversity compared to\nvariational models and diverse decoding approaches.\\footnote{Code to reproduce\nthe results in this paper is available at\n\\url{https://github.com/pytorch/fairseq}}\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 23:57:35 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 17:37:46 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Shen", "Tianxiao", ""], ["Ott", "Myle", ""], ["Auli", "Michael", ""], ["Ranzato", "Marc'Aurelio", ""]]}, {"id": "1902.07817", "submitter": "Albert Haque", "authors": "Albert Haque, Michelle Guo, Prateek Verma, Li Fei-Fei", "title": "Audio-Linguistic Embeddings for Spoken Sentences", "comments": "International Conference on Acoustics, Speech, and Signal Processing\n  (ICASSP) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose spoken sentence embeddings which capture both acoustic and\nlinguistic content. While existing works operate at the character, phoneme, or\nword level, our method learns long-term dependencies by modeling speech at the\nsentence level. Formulated as an audio-linguistic multitask learning problem,\nour encoder-decoder model simultaneously reconstructs acoustic and natural\nlanguage features from audio. Our results show that spoken sentence embeddings\noutperform phoneme and word-level baselines on speech recognition and emotion\nrecognition tasks. Ablation studies show that our embeddings can better model\nhigh-level acoustic concepts while retaining linguistic content. Overall, our\nwork illustrates the viability of generic, multi-modal sentence embeddings for\nspoken language understanding.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 23:58:29 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Haque", "Albert", ""], ["Guo", "Michelle", ""], ["Verma", "Prateek", ""], ["Fei-Fei", "Li", ""]]}, {"id": "1902.07821", "submitter": "Yun Tang", "authors": "Yun Tang, Guohong Ding, Jing Huang, Xiaodong He, Bowen Zhou", "title": "Deep Speaker Embedding Learning with Multi-Level Pooling for\n  Text-Independent Speaker Verification", "comments": "Accepted by ICASSP2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to improve the widely used deep speaker embedding x-vector\nmodel. We propose the following improvements: (1) a hybrid neural network\nstructure using both time delay neural network (TDNN) and long short-term\nmemory neural networks (LSTM) to generate complementary speaker information at\ndifferent levels; (2) a multi-level pooling strategy to collect speaker\ninformation from both TDNN and LSTM layers; (3) a regularization scheme on the\nspeaker embedding extraction layer to make the extracted embeddings suitable\nfor the following fusion step. The synergy of these improvements are shown on\nthe NIST SRE 2016 eval test (with a 19% EER reduction) and SRE 2018 dev test\n(with a 9% EER reduction), as well as more than 10% DCF scores reduction on\nthese two test sets over the x-vector baseline.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 00:36:24 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Tang", "Yun", ""], ["Ding", "Guohong", ""], ["Huang", "Jing", ""], ["He", "Xiaodong", ""], ["Zhou", "Bowen", ""]]}, {"id": "1902.07831", "submitter": "Yilun Zhou", "authors": "Yilun Zhou, Steven Schockaert, Julie A. Shah", "title": "Predicting ConceptNet Path Quality Using Crowdsourced Assessments of\n  Naturalness", "comments": "In Proceedings of the Web Conference (WWW) 2019", "journal-ref": null, "doi": "10.1145/3308558.3313486", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In many applications, it is important to characterize the way in which two\nconcepts are semantically related. Knowledge graphs such as ConceptNet provide\na rich source of information for such characterizations by encoding relations\nbetween concepts as edges in a graph. When two concepts are not directly\nconnected by an edge, their relationship can still be described in terms of the\npaths that connect them. Unfortunately, many of these paths are uninformative\nand noisy, which means that the success of applications that use such path\nfeatures crucially relies on their ability to select high-quality paths. In\nexisting applications, this path selection process is based on relatively\nsimple heuristics. In this paper we instead propose to learn to predict path\nquality from crowdsourced human assessments. Since we are interested in a\ngeneric task-independent notion of quality, we simply ask human participants to\nrank paths according to their subjective assessment of the paths' naturalness,\nwithout attempting to define naturalness or steering the participants towards\nparticular indicators of quality. We show that a neural network model trained\non these assessments is able to predict human judgments on unseen paths with\nnear optimal performance. Most notably, we find that the resulting path\nselection method is substantially better than the current heuristic approaches\nat identifying meaningful paths.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 01:12:07 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Zhou", "Yilun", ""], ["Schockaert", "Steven", ""], ["Shah", "Julie A.", ""]]}, {"id": "1902.07867", "submitter": "Peixiang Zhong", "authors": "Peixiang Zhong, Chunyan Miao", "title": "ntuer at SemEval-2019 Task 3: Emotion Classification with Word and\n  Sentence Representations in RCNN", "comments": "SemEval 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present our model on the task of emotion detection in\ntextual conversations in SemEval-2019. Our model extends the Recurrent\nConvolutional Neural Network (RCNN) by using external fine-tuned word\nrepresentations and DeepMoji sentence representations. We also explored several\nother competitive pre-trained word and sentence representations including ELMo,\nBERT and InferSent but found inferior performance. In addition, we conducted\nextensive sensitivity analysis, which empirically shows that our model is\nrelatively robust to hyper-parameters. Our model requires no handcrafted\nfeatures or emotion lexicons but achieved good performance with a micro-F1\nscore of 0.7463.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 05:16:45 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 02:29:57 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Zhong", "Peixiang", ""], ["Miao", "Chunyan", ""]]}, {"id": "1902.07938", "submitter": "Rezka Leonandya", "authors": "Rezka Leonandya, Fariz Ikhwantri", "title": "Pretrained language model transfer on neural named entity recognition in\n  Indonesian conversational texts", "comments": "Accepted in CICLing 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named entity recognition (NER) is an important task in NLP, which is all the\nmore challenging in conversational domain with their noisy facets. Moreover,\nconversational texts are often available in limited amount, making supervised\ntasks infeasible. To learn from small data, strong inductive biases are\nrequired. Previous work relied on hand-crafted features to encode these biases\nuntil transfer learning emerges. Here, we explore a transfer learning method,\nnamely language model pretraining, on NER task in Indonesian conversational\ntexts. We utilize large unlabeled data (generic domain) to be transferred to\nconversational texts, enabling supervised training on limited in-domain data.\nWe report two transfer learning variants, namely supervised model fine-tuning\nand unsupervised pretrained LM fine-tuning. Our experiments show that both\nvariants outperform baseline neural models when trained on small data (100\nsentences), yielding an absolute improvement of 32 points of test F1 score.\nFurthermore, we find that the pretrained LM encodes part-of-speech information\nwhich is a strong predictor for NER.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 09:53:04 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Leonandya", "Rezka", ""], ["Ikhwantri", "Fariz", ""]]}, {"id": "1902.08050", "submitter": "Jindong Chen", "authors": "Jindong Chen, Yizhou Hu, Jingping Liu, Yanghua Xiao, Haiyun Jiang", "title": "Deep Short Text Classification with Knowledge Powered Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Short text classification is one of important tasks in Natural Language\nProcessing (NLP). Unlike paragraphs or documents, short texts are more\nambiguous since they have not enough contextual information, which poses a\ngreat challenge for classification. In this paper, we retrieve knowledge from\nexternal knowledge source to enhance the semantic representation of short\ntexts. We take conceptual information as a kind of knowledge and incorporate it\ninto deep neural networks. For the purpose of measuring the importance of\nknowledge, we introduce attention mechanisms and propose deep Short Text\nClassification with Knowledge powered Attention (STCKA). We utilize Concept\ntowards Short Text (C- ST) attention and Concept towards Concept Set (C-CS)\nattention to acquire the weight of concepts from two aspects. And we classify a\nshort text with the help of conceptual information. Unlike traditional\napproaches, our model acts like a human being who has intrinsic ability to make\ndecisions based on observation (i.e., training data for machines) and pays more\nattention to important knowledge. We also conduct extensive experiments on four\npublic datasets for different tasks. The experimental results and case studies\nshow that our model outperforms the state-of-the-art methods, justifying the\neffectiveness of knowledge powered attention.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 13:50:56 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Chen", "Jindong", ""], ["Hu", "Yizhou", ""], ["Liu", "Jingping", ""], ["Xiao", "Yanghua", ""], ["Jiang", "Haiyun", ""]]}, {"id": "1902.08061", "submitter": "Mathieu Mangeot", "authors": "Mutsuko Tomokiyo (GETALP, LIG), Mathieu Mangeot (GETALP, LIG),\n  Christian Boitet (LIG, GETALP)", "title": "Development of a classifiers/quantifiers dictionary towards\n  French-Japanese MT", "comments": null, "journal-ref": "MT Summit 2017, Sep 2017, Nagoya, Japan", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although classifiers/quantifiers (CQs) expressions appear frequently in\neveryday communications or written documents, they are described neither in\nclassical bilingual paper dictionaries , nor in machine-readable dictionaries.\nThe paper describes a CQs dictionary, edited from the corpus we have annotated,\nand its usage in the framework of French-Japanese machine translation (MT). CQs\ntreatment in MT often causes problems of lexical ambiguity, polylexical phrase\nrecognition difficulties in analysis and doubtful output in\ntransfer-generation, in particular for distant languages pairs like French and\nJapanese. Our basic treatment of CQs is to annotate the corpus by UNL-UWs\n(Universal Networking Language-Universal words) 1 , and then to produce a\nbilingual or multilingual dictionary of CQs, based on synonymy through identity\nof UWs.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 14:19:00 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Tomokiyo", "Mutsuko", "", "GETALP, LIG"], ["Mangeot", "Mathieu", "", "GETALP, LIG"], ["Boitet", "Christian", "", "LIG, GETALP"]]}, {"id": "1902.08213", "submitter": "David Harwath", "authors": "David Harwath and James Glass", "title": "Towards Visually Grounded Sub-Word Speech Unit Discovery", "comments": "Accepted to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the manner in which interpretable sub-word\nspeech units emerge within a convolutional neural network model trained to\nassociate raw speech waveforms with semantically related natural image scenes.\nWe show how diphone boundaries can be superficially extracted from the\nactivation patterns of intermediate layers of the model, suggesting that the\nmodel may be leveraging these events for the purpose of word recognition. We\npresent a series of experiments investigating the information encoded by these\nevents.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 19:00:30 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Harwath", "David", ""], ["Glass", "James", ""]]}, {"id": "1902.08327", "submitter": "Ting-Hao Huang", "authors": "Ting-Yao Hsu and Yen-Chia Hsu and Ting-Hao 'Kenneth' Huang", "title": "On How Users Edit Computer-Generated Visual Stories", "comments": "To appear in CHI'19 Late-Breaking Work on Human Factors in Computing\n  Systems (CHI LBW 2019), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A significant body of research in Artificial Intelligence (AI) has focused on\ngenerating stories automatically, either based on prior story plots or input\nimages. However, literature has little to say about how users would receive and\nuse these stories. Given the quality of stories generated by modern AI\nalgorithms, users will nearly inevitably have to edit these stories before\nputting them to real use. In this paper, we present the first analysis of how\nhuman users edit machine-generated stories. We obtained 962 short stories\ngenerated by one of the state-of-the-art visual storytelling models. For each\nstory, we recruited five crowd workers from Amazon Mechanical Turk to edit it.\nOur analysis of these edits shows that, on average, users (i) slightly\nshortened machine-generated stories, (ii) increased lexical diversity in these\nstories, and (iii) often replaced nouns and their determiners/articles with\npronouns. Our study provides a better understanding on how users receive and\nedit machine-generated stories,informing future researchers to create more\nusable and helpful story generation systems.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 01:26:05 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2019 20:28:11 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Hsu", "Ting-Yao", ""], ["Hsu", "Yen-Chia", ""], ["Huang", "Ting-Hao 'Kenneth'", ""]]}, {"id": "1902.08342", "submitter": "Devamanyu Hazarika", "authors": "Rajiv Bajpai, Devamanyu Hazarika, Kunal Singh, Sruthi Gorantla, Erik\n  Cambria, and Roger Zimmerman", "title": "Aspect-Sentiment Embeddings for Company Profiling and Employee Opinion\n  Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the multitude of companies and organizations abound today, ranking them\nand choosing one out of the many is a difficult and cumbersome task. Although\nthere are many available metrics that rank companies, there is an inherent need\nfor a generalized metric that takes into account the different aspects that\nconstitute employee opinions of the companies. In this work, we aim to overcome\nthe aforementioned problem by generating aspect-sentiment based embedding for\nthe companies by looking into reliable employee reviews of them. We created a\ncomprehensive dataset of company reviews from the famous website Glassdoor.com\nand employed a novel ensemble approach to perform aspect-level sentiment\nanalysis. Although a relevant amount of work has been done on reviews centered\non subjects like movies, music, etc., this work is the first of its kind. We\nalso provide several insights from the collated embeddings, thus helping users\ngain a better understanding of their options as well as select companies using\ncustomized preferences.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 02:31:41 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Bajpai", "Rajiv", ""], ["Hazarika", "Devamanyu", ""], ["Singh", "Kunal", ""], ["Gorantla", "Sruthi", ""], ["Cambria", "Erik", ""], ["Zimmerman", "Roger", ""]]}, {"id": "1902.08355", "submitter": "Sang-Woo Lee", "authors": "Sang-Woo Lee, Tong Gao, Sohee Yang, Jaejun Yoo, Jung-Woo Ha", "title": "Large-Scale Answerer in Questioner's Mind for Visual Dialog Question\n  Generation", "comments": "Accepted for ICLR 2019. Camera ready version. Our code is publically\n  available: https://github.com/naver/aqm-plus", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answerer in Questioner's Mind (AQM) is an information-theoretic framework\nthat has been recently proposed for task-oriented dialog systems. AQM benefits\nfrom asking a question that would maximize the information gain when it is\nasked. However, due to its intrinsic nature of explicitly calculating the\ninformation gain, AQM has a limitation when the solution space is very large.\nTo address this, we propose AQM+ that can deal with a large-scale problem and\nask a question that is more coherent to the current context of the dialog. We\nevaluate our method on GuessWhich, a challenging task-oriented visual dialog\nproblem, where the number of candidate classes is near 10K. Our experimental\nresults and ablation studies show that AQM+ outperforms the state-of-the-art\nmodels by a remarkable margin with a reasonable approximation. In particular,\nthe proposed AQM+ reduces more than 60% of error as the dialog proceeds, while\nthe comparative algorithms diminish the error by less than 6%. Based on our\nresults, we argue that AQM+ is a general task-oriented dialog algorithm that\ncan be applied for non-yes-or-no responses.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 03:46:53 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Lee", "Sang-Woo", ""], ["Gao", "Tong", ""], ["Yang", "Sohee", ""], ["Yoo", "Jaejun", ""], ["Ha", "Jung-Woo", ""]]}, {"id": "1902.08373", "submitter": "Bishan Yang", "authors": "Igor Labutov, Bishan Yang, Tom Mitchell", "title": "Learning to Learn Semantic Parsers from Natural Language Supervision", "comments": "published at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As humans, we often rely on language to learn language. For example, when\ncorrected in a conversation, we may learn from that correction, over time\nimproving our language fluency. Inspired by this observation, we propose a\nlearning algorithm for training semantic parsers from supervision (feedback)\nexpressed in natural language. Our algorithm learns a semantic parser from\nusers' corrections such as \"no, what I really meant was before his job, not\nafter\", by also simultaneously learning to parse this natural language feedback\nin order to leverage it as a form of supervision. Unlike supervision with\ngold-standard logical forms, our method does not require the user to be\nfamiliar with the underlying logical formalism, and unlike supervision from\ndenotation, it does not require the user to know the correct answer to their\nquery. This makes our learning algorithm naturally scalable in settings where\nexisting conversational logs are available and can be leveraged as training\ndata. We construct a novel dataset of natural language feedback in a\nconversational setting, and show that our method is effective at learning a\nsemantic parser from such natural language supervision.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 06:28:36 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Labutov", "Igor", ""], ["Yang", "Bishan", ""], ["Mitchell", "Tom", ""]]}, {"id": "1902.08558", "submitter": "Jorge Louc\\~a", "authors": "Jorge Lou\\c{c}\\~a and Ant\\'onio Fonseca", "title": "Topology and dynamics of narratives on Brexit propagated by UK press\n  during 2016 and 2017", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This article identifies and characterises political narratives regarding\nEurope and broadcasted in UK press during 2016 and 2017. A new theoretical and\noperational framework is proposed for typifying discourse narratives propagated\nin the public opinion space, based on the social constructivism and structural\nlinguistics approaches, and the mathematical theory of hypernetworks, where\nelementary units are aggregated into high-level entities. In this line of\nthought, a narrative is understood as a social construct where a related and\ncoherent aggregate of terms within public discourse is repeated and propagated\non media until it can be identified as a communication pattern, embodying\nmeaning in a way that provides individuals some interpretation of their world.\nAn inclusive methodology, with state-of-the-art technologies on natural\nlanguage processing and network theory, implements this concept of narrative. A\ncorpus from the Observatorium database, including articles from six UK\nnewspapers and incorporating far-right, right-wing, and left-wing narratives,\nis analysed. The research revealed clear distinctions between narratives along\nthe political spectrum. In 2016 far-right was particularly focused on\nemigration and refugees. Namely, during the referendum campaign, Europe was\nrelated to attacks on women and children, sexual offences, and terrorism.\nRight-wing was manly focused on internal politics, while left-wing was\nremarkably mentioning a diversity of non-political topics, such as sports, side\nby side with economics. During 2017, in general terrorism was less mentioned,\nand negotiations with EU, namely regarding economics, finance, and Ireland,\nbecame central.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 17:02:18 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Lou\u00e7\u00e3", "Jorge", ""], ["Fonseca", "Ant\u00f3nio", ""]]}, {"id": "1902.08564", "submitter": "Yinfei Yang", "authors": "Yinfei Yang, Gustavo Hernandez Abrego, Steve Yuan, Mandy Guo, Qinlan\n  Shen, Daniel Cer, Yun-hsuan Sung, Brian Strope, Ray Kurzweil", "title": "Improving Multilingual Sentence Embedding using Bi-directional Dual\n  Encoder with Additive Margin Softmax", "comments": "Accepted by IJCAI'19(International Joint Conference on Artificial\n  Intelligence)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an approach to learn multilingual sentence\nembeddings using a bi-directional dual-encoder with additive margin softmax.\nThe embeddings are able to achieve state-of-the-art results on the United\nNations (UN) parallel corpus retrieval task. In all the languages tested, the\nsystem achieves P@1 of 86% or higher. We use pairs retrieved by our approach to\ntrain NMT models that achieve similar performance to models trained on gold\npairs. We explore simple document-level embeddings constructed by averaging our\nsentence embeddings. On the UN document-level retrieval task, document\nembeddings achieve around 97% on P@1 for all experimented language pairs.\nLastly, we evaluate the proposed model on the BUCC mining task. The learned\nembeddings with raw cosine similarity scores achieve competitive results\ncompared to current state-of-the-art models, and with a second-stage scorer we\nachieve a new state-of-the-art level on this task.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 17:11:03 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 23:50:42 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Yang", "Yinfei", ""], ["Abrego", "Gustavo Hernandez", ""], ["Yuan", "Steve", ""], ["Guo", "Mandy", ""], ["Shen", "Qinlan", ""], ["Cer", "Daniel", ""], ["Sung", "Yun-hsuan", ""], ["Strope", "Brian", ""], ["Kurzweil", "Ray", ""]]}, {"id": "1902.08628", "submitter": "Jonathan Chang", "authors": "Jonathan P. Chang and Cristian Danescu-Niculescu-Mizil", "title": "Trajectories of Blocked Community Members: Redemption, Recidivism and\n  Departure", "comments": "To appear in Proceedings of the 2019 World Wide Web Conference (WWW\n  '19), May 13-17, 2019, San Francisco, CA, USA. Code and data available as\n  part of ConvoKit: convokit.cornell.edu", "journal-ref": null, "doi": "10.1145/3308558.3313638", "report-no": null, "categories": "cs.CY cs.CL cs.SI physics.soc-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Community norm violations can impair constructive communication and\ncollaboration online. As a defense mechanism, community moderators often\naddress such transgressions by temporarily blocking the perpetrator. Such\nactions, however, come with the cost of potentially alienating community\nmembers. Given this tradeoff, it is essential to understand to what extent, and\nin which situations, this common moderation practice is effective in\nreinforcing community rules.\n  In this work, we introduce a computational framework for studying the future\nbehavior of blocked users on Wikipedia. After their block expires, they can\ntake several distinct paths: they can reform and adhere to the rules, but they\ncan also recidivate, or straight-out abandon the community. We reveal that\nthese trajectories are tied to factors rooted both in the characteristics of\nthe blocked individual and in whether they perceived the block to be fair and\njustified. Based on these insights, we formulate a series of prediction tasks\naiming to determine which of these paths a user is likely to take after being\nblocked for their first offense, and demonstrate the feasibility of these new\ntasks. Overall, this work builds towards a more nuanced approach to moderation\nby highlighting the tradeoffs that are in play.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 19:00:10 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Chang", "Jonathan P.", ""], ["Danescu-Niculescu-Mizil", "Cristian", ""]]}, {"id": "1902.08646", "submitter": "Fabio Kepler", "authors": "F\\'abio Kepler, Jonay Tr\\'enous, Marcos Treviso, Miguel Vera, Andr\\'e\n  F. T. Martins", "title": "OpenKiwi: An Open Source Framework for Quality Estimation", "comments": "Published at the Annual Meeting of the Association for Computational\n  Linguistics (ACL) 2019: System Demonstrations\n  (https://aclweb.org/anthology/papers/P/P19/P19-3020/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce OpenKiwi, a PyTorch-based open source framework for translation\nquality estimation. OpenKiwi supports training and testing of word-level and\nsentence-level quality estimation systems, implementing the winning systems of\nthe WMT 2015-18 quality estimation campaigns. We benchmark OpenKiwi on two\ndatasets from WMT 2018 (English-German SMT and NMT), yielding state-of-the-art\nperformance on the word-level tasks and near state-of-the-art in the\nsentence-level tasks.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 19:27:45 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2019 15:07:52 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Kepler", "F\u00e1bio", ""], ["Tr\u00e9nous", "Jonay", ""], ["Treviso", "Marcos", ""], ["Vera", "Miguel", ""], ["Martins", "Andr\u00e9 F. T.", ""]]}, {"id": "1902.08649", "submitter": "Reza Ghaeini", "authors": "Reza Ghaeini, Xiaoli Z. Fern, Hamed Shahbazi, Prasad Tadepalli", "title": "Saliency Learning: Teaching the Model Where to Pay Attention", "comments": "Accepted as a short paper at NAACL 2019. 10 pages, 2 figures, 6\n  tables", "journal-ref": "NAACL 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has emerged as a compelling solution to many NLP tasks with\nremarkable performances. However, due to their opacity, such models are hard to\ninterpret and trust. Recent work on explaining deep models has introduced\napproaches to provide insights toward the model's behaviour and predictions,\nwhich are helpful for assessing the reliability of the model's predictions.\nHowever, such methods do not improve the model's reliability. In this paper, we\naim to teach the model to make the right prediction for the right reason by\nproviding explanation training and ensuring the alignment of the model's\nexplanation with the ground truth explanation. Our experimental results on\nmultiple tasks and datasets demonstrate the effectiveness of the proposed\nmethod, which produces more reliable predictions while delivering better\nresults compared to traditionally trained models.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 19:38:36 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 00:01:28 GMT"}, {"version": "v3", "created": "Thu, 4 Apr 2019 04:42:28 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Ghaeini", "Reza", ""], ["Fern", "Xiaoli Z.", ""], ["Shahbazi", "Hamed", ""], ["Tadepalli", "Prasad", ""]]}, {"id": "1902.08654", "submitter": "Abigail See", "authors": "Abigail See, Stephen Roller, Douwe Kiela, Jason Weston", "title": "What makes a good conversation? How controllable attributes affect human\n  judgments", "comments": "Accepted to NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A good conversation requires balance -- between simplicity and detail;\nstaying on topic and changing it; asking questions and answering them. Although\ndialogue agents are commonly evaluated via human judgments of overall quality,\nthe relationship between quality and these individual factors is less\nwell-studied. In this work, we examine two controllable neural text generation\nmethods, conditional training and weighted decoding, in order to control four\nimportant attributes for chitchat dialogue: repetition, specificity,\nresponse-relatedness and question-asking. We conduct a large-scale human\nevaluation to measure the effect of these control parameters on multi-turn\ninteractive conversations on the PersonaChat task. We provide a detailed\nanalysis of their relationship to high-level aspects of conversation, and show\nthat by controlling combinations of these variables our models obtain clear\nimprovements in human quality judgments.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 19:59:47 GMT"}, {"version": "v2", "created": "Wed, 10 Apr 2019 16:50:16 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["See", "Abigail", ""], ["Roller", "Stephen", ""], ["Kiela", "Douwe", ""], ["Weston", "Jason", ""]]}, {"id": "1902.08691", "submitter": "Yuqi Si", "authors": "Yuqi Si, Jingqi Wang, Hua Xu, Kirk Roberts", "title": "Enhancing Clinical Concept Extraction with Contextual Embeddings", "comments": "Journal of the American Medical Informatics Association", "journal-ref": null, "doi": "10.1093/jamia/ocz096", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network-based representations (\"embeddings\") have dramatically\nadvanced natural language processing (NLP) tasks, including clinical NLP tasks\nsuch as concept extraction. Recently, however, more advanced embedding methods\nand representations (e.g., ELMo, BERT) have further pushed the state-of-the-art\nin NLP, yet there are no common best practices for how to integrate these\nrepresentations into clinical tasks. The purpose of this study, then, is to\nexplore the space of possible options in utilizing these new models for\nclinical concept extraction, including comparing these to traditional word\nembedding methods (word2vec, GloVe, fastText). Both off-the-shelf open-domain\nembeddings and pre-trained clinical embeddings from MIMIC-III are evaluated. We\nexplore a battery of embedding methods consisting of traditional word\nembeddings and contextual embeddings, and compare these on four concept\nextraction corpora: i2b2 2010, i2b2 2012, SemEval 2014, and SemEval 2015. We\nalso analyze the impact of the pre-training time of a large language model like\nELMo or BERT on the extraction performance. Last, we present an intuitive way\nto understand the semantic information encoded by contextual embeddings.\nContextual embeddings pre-trained on a large clinical corpus achieves new\nstate-of-the-art performances across all concept extraction tasks. The\nbest-performing model outperforms all state-of-the-art methods with respective\nF1-measures of 90.25, 93.18 (partial), 80.74, and 81.65. We demonstrate the\npotential of contextual embeddings through the state-of-the-art performance\nthese methods achieve on clinical concept extraction. Additionally, we\ndemonstrate contextual embeddings encode valuable semantic information not\naccounted for in traditional word representations.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 22:24:37 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 18:48:23 GMT"}, {"version": "v3", "created": "Fri, 10 May 2019 17:16:50 GMT"}, {"version": "v4", "created": "Wed, 14 Aug 2019 16:20:26 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Si", "Yuqi", ""], ["Wang", "Jingqi", ""], ["Xu", "Hua", ""], ["Roberts", "Kirk", ""]]}, {"id": "1902.08795", "submitter": "Chi Sun", "authors": "Chi Sun, Xipeng Qiu, Xuanjing Huang", "title": "VCWE: Visual Character-Enhanced Word Embeddings", "comments": "Accepted to NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chinese is a logographic writing system, and the shape of Chinese characters\ncontain rich syntactic and semantic information. In this paper, we propose a\nmodel to learn Chinese word embeddings via three-level composition: (1) a\nconvolutional neural network to extract the intra-character compositionality\nfrom the visual shape of a character; (2) a recurrent neural network with\nself-attention to compose character representation into word embeddings; (3)\nthe Skip-Gram framework to capture non-compositionality directly from the\ncontextual information. Evaluations demonstrate the superior performance of our\nmodel on four tasks: word similarity, sentiment analysis, named entity\nrecognition and part-of-speech tagging.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2019 14:25:51 GMT"}, {"version": "v2", "created": "Mon, 25 Mar 2019 10:22:18 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Sun", "Chi", ""], ["Qiu", "Xipeng", ""], ["Huang", "Xuanjing", ""]]}, {"id": "1902.08816", "submitter": "Diego Moussallem", "authors": "Diego Moussallem and Mihael Ar\\v{c}an and Axel-Cyrille Ngonga Ngomo\n  and Paul Buitelaar", "title": "Augmenting Neural Machine Translation with Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural networks have been used extensively to make substantial progress\nin the machine translation task, they are known for being heavily dependent on\nthe availability of large amounts of training data. Recent efforts have tried\nto alleviate the data sparsity problem by augmenting the training data using\ndifferent strategies, such as back-translation. Along with the data scarcity,\nthe out-of-vocabulary words, mostly entities and terminological expressions,\npose a difficult challenge to Neural Machine Translation systems. In this\npaper, we hypothesize that knowledge graphs enhance the semantic feature\nextraction of neural models, thus optimizing the translation of entities and\nterminological expressions in texts and consequently leading to a better\ntranslation quality. We hence investigate two different strategies for\nincorporating knowledge graphs into neural models without modifying the neural\nnetwork architectures. We also examine the effectiveness of our augmentation\nmethod to recurrent and non-recurrent (self-attentional) neural architectures.\nOur knowledge graph augmented neural translation model, dubbed KG-NMT, achieves\nsignificant and consistent improvements of +3 BLEU, METEOR and chrF3 on average\non the newstest datasets between 2014 and 2018 for WMT English-German\ntranslation task.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2019 17:04:54 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Moussallem", "Diego", ""], ["Ar\u010dan", "Mihael", ""], ["Ngomo", "Axel-Cyrille Ngonga", ""], ["Buitelaar", "Paul", ""]]}, {"id": "1902.08830", "submitter": "Lea Frermann", "authors": "Lea Frermann and Mirella Lapata", "title": "Categorization in the Wild: Generalizing Cognitive Models to\n  Naturalistic Data across Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Categories such as animal or furniture are acquired at an early age and play\nan important role in processing, organizing, and communicating world knowledge.\nCategories exist across cultures: they allow to efficiently represent the\ncomplexity of the world, and members of a community strongly agree on their\nnature, revealing a shared mental representation. Models of category learning\nand representation, however, are typically tested on data from small-scale\nexperiments involving small sets of concepts with artificially restricted\nfeatures; and experiments predominantly involve participants of selected\ncultural and socio-economical groups (very often involving western native\nspeakers of English such as U.S. college students) . This work investigates\nwhether models of categorization generalize (a) to rich and noisy data\napproximating the environment humans live in; and (b) across languages and\ncultures. We present a Bayesian cognitive model designed to jointly learn\ncategories and their structured representation from natural language text which\nallows us to (a) evaluate performance on a large scale, and (b) apply our model\nto a diverse set of languages. We show that meaningful categories comprising\nhundreds of concepts and richly structured featural representations emerge\nacross languages. Our work illustrates the potential of recent advances in\ncomputational modeling and large scale naturalistic datasets for cognitive\nscience research.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2019 19:21:08 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Frermann", "Lea", ""], ["Lapata", "Mirella", ""]]}, {"id": "1902.08832", "submitter": "Ananya Sai", "authors": "Ananya B. Sai, Mithun Das Gupta, Mitesh M. Khapra, Mukundhan\n  Srinivasan", "title": "Re-evaluating ADEM: A Deeper Look at Scoring Dialogue Responses", "comments": "Accepted as a long paper in the proceedings of AAAI-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatically evaluating the quality of dialogue responses for unstructured\ndomains is a challenging problem. ADEM(Lowe et al. 2017) formulated the\nautomatic evaluation of dialogue systems as a learning problem and showed that\nsuch a model was able to predict responses which correlate significantly with\nhuman judgements, both at utterance and system level. Their system was shown to\nhave beaten word-overlap metrics such as BLEU with large margins. We start with\nthe question of whether an adversary can game the ADEM model. We design a\nbattery of targeted attacks at the neural network based ADEM evaluation system\nand show that automatic evaluation of dialogue systems still has a long way to\ngo. ADEM can get confused with a variation as simple as reversing the word\norder in the text! We report experiments on several such adversarial scenarios\nthat draw out counterintuitive scores on the dialogue responses. We take a\nsystematic look at the scoring function proposed by ADEM and connect it to\nlinear system theory to predict the shortcomings evident in the system. We also\ndevise an attack that can fool such a system to rate a response generation\nsystem as favorable. Finally, we allude to future research directions of using\nthe adversarial attacks to design a truly automated dialogue evaluation system.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2019 19:21:24 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Sai", "Ananya B.", ""], ["Gupta", "Mithun Das", ""], ["Khapra", "Mitesh M.", ""], ["Srinivasan", "Mukundhan", ""]]}, {"id": "1902.08850", "submitter": "Radu Tudor Ionescu", "authors": "Radu Tudor Ionescu and Andrei M. Butnaru", "title": "Vector of Locally-Aggregated Word Embeddings (VLAWE): A Novel\n  Document-level Representation", "comments": "Accepted at NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel representation for text documents based on\naggregating word embedding vectors into document embeddings. Our approach is\ninspired by the Vector of Locally-Aggregated Descriptors used for image\nrepresentation, and it works as follows. First, the word embeddings gathered\nfrom a collection of documents are clustered by k-means in order to learn a\ncodebook of semnatically-related word embeddings. Each word embedding is then\nassociated to its nearest cluster centroid (codeword). The Vector of\nLocally-Aggregated Word Embeddings (VLAWE) representation of a document is then\ncomputed by accumulating the differences between each codeword vector and each\nword vector (from the document) associated to the respective codeword. We plug\nthe VLAWE representation, which is learned in an unsupervised manner, into a\nclassifier and show that it is useful for a diverse set of text classification\ntasks. We compare our approach with a broad range of recent state-of-the-art\nmethods, demonstrating the effectiveness of our approach. Furthermore, we\nobtain a considerable improvement on the Movie Review data set, reporting an\naccuracy of 93.3%, which represents an absolute gain of 10% over the\nstate-of-the-art approach. Our code is available at\nhttps://github.com/raduionescu/vlawe-boswe/.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2019 21:35:54 GMT"}, {"version": "v2", "created": "Sun, 24 Mar 2019 21:58:36 GMT"}, {"version": "v3", "created": "Mon, 6 May 2019 05:19:39 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Ionescu", "Radu Tudor", ""], ["Butnaru", "Andrei M.", ""]]}, {"id": "1902.08852", "submitter": "Hai Wang", "authors": "Hai Wang and Dian Yu and Kai Sun and Jianshu Chen and Dong Yu and\n  David McAllester and Dan Roth", "title": "Evidence Sentence Extraction for Machine Reading Comprehension", "comments": "CONLL 2019 final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Remarkable success has been achieved in the last few years on some limited\nmachine reading comprehension (MRC) tasks. However, it is still difficult to\ninterpret the predictions of existing MRC models. In this paper, we focus on\nextracting evidence sentences that can explain or support the answers of\nmultiple-choice MRC tasks, where the majority of answer options cannot be\ndirectly extracted from reference documents.\n  Due to the lack of ground truth evidence sentence labels in most cases, we\napply distant supervision to generate imperfect labels and then use them to\ntrain an evidence sentence extractor. To denoise the noisy labels, we apply a\nrecently proposed deep probabilistic logic learning framework to incorporate\nboth sentence-level and cross-sentence linguistic indicators for indirect\nsupervision. We feed the extracted evidence sentences into existing MRC models\nand evaluate the end-to-end performance on three challenging multiple-choice\nMRC datasets: MultiRC, RACE, and DREAM, achieving comparable or better\nperformance than the same models that take as input the full reference\ndocument. To the best of our knowledge, this is the first work extracting\nevidence sentences for multiple-choice MRC.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2019 21:53:48 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 02:22:18 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Wang", "Hai", ""], ["Yu", "Dian", ""], ["Sun", "Kai", ""], ["Chen", "Jianshu", ""], ["Yu", "Dong", ""], ["McAllester", "David", ""], ["Roth", "Dan", ""]]}, {"id": "1902.08856", "submitter": "Dimitar Shterionov", "authors": "Eva Vanmassenhove, Amit Moryossef, Alberto Poncelas, Andy Way, Dimitar\n  Shterionov", "title": "ABI Neural Ensemble Model for Gender Prediction Adapt Bar-Ilan\n  Submission for the CLIN29 Shared Task on Gender Prediction", "comments": "Conference: Computational Linguistics of the Netherlands CLIN29", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present our system for the CLIN29 shared task on cross-genre gender\ndetection for Dutch. We experimented with a multitude of neural models (CNN,\nRNN, LSTM, etc.), more \"traditional\" models (SVM, RF, LogReg, etc.), different\nfeature sets as well as data pre-processing. The final results suggested that\nusing tokenized, non-lowercased data works best for most of the neural models,\nwhile a combination of word clusters, character trigrams and word lists showed\nto be most beneficial for the majority of the more \"traditional\" (that is,\nnon-neural) models, beating features used in previous tasks such as n-grams,\ncharacter n-grams, part-of-speech tags and combinations thereof. In\ncontradiction with the results described in previous comparable shared tasks,\nour neural models performed better than our best traditional approaches with\nour best feature set-up. Our final model consisted of a weighted ensemble model\ncombining the top 25 models. Our final model won both the in-domain gender\nprediction task and the cross-genre challenge, achieving an average accuracy of\n64.93% on the in-domain gender prediction task, and 56.26% on cross-genre\ngender prediction.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2019 22:17:08 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Vanmassenhove", "Eva", ""], ["Moryossef", "Amit", ""], ["Poncelas", "Alberto", ""], ["Way", "Andy", ""], ["Shterionov", "Dimitar", ""]]}, {"id": "1902.08858", "submitter": "Tiancheng Zhao", "authors": "Tiancheng Zhao, Kaige Xie and Maxine Eskenazi", "title": "Rethinking Action Spaces for Reinforcement Learning in End-to-end Dialog\n  Agents with Latent Variable Models", "comments": "Camera ready version for NAACL 2019 long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Defining action spaces for conversational agents and optimizing their\ndecision-making process with reinforcement learning is an enduring challenge.\nCommon practice has been to use handcrafted dialog acts, or the output\nvocabulary, e.g. in neural encoder decoders, as the action spaces. Both have\ntheir own limitations. This paper proposes a novel latent action framework that\ntreats the action spaces of an end-to-end dialog agent as latent variables and\ndevelops unsupervised methods in order to induce its own action space from the\ndata. Comprehensive experiments are conducted examining both continuous and\ndiscrete action types and two different optimization methods based on\nstochastic variational inference. Results show that the proposed latent actions\nachieve superior empirical performance improvement over previous word-level\npolicy gradient methods on both DealOrNoDeal and MultiWoz dialogs. Our detailed\nanalysis also provides insights about various latent variable approaches for\npolicy learning and can serve as a foundation for developing better latent\nactions in future research.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2019 22:27:45 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2019 17:07:43 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Zhao", "Tiancheng", ""], ["Xie", "Kaige", ""], ["Eskenazi", "Maxine", ""]]}, {"id": "1902.08899", "submitter": "Graham Neubig", "authors": "Aditi Chaudhary, Siddharth Dalmia, Junjie Hu, Xinjian Li, Austin\n  Matthews, Aldrian Obaja Muis, Naoki Otani, Shruti Rijhwani, Zaid Sheikh,\n  Nidhi Vyas, Xinyi Wang, Jiateng Xie, Ruochen Xu, Chunting Zhou, Peter J.\n  Jansen, Yiming Yang, Lori Levin, Florian Metze, Teruko Mitamura, David R.\n  Mortensen, Graham Neubig, Eduard Hovy, Alan W Black, Jaime Carbonell, Graham\n  V. Horwood, Shabnam Tafreshi, Mona Diab, Efsun S. Kayi, Noura Farra, Kathleen\n  McKeown", "title": "The ARIEL-CMU Systems for LoReHLT18", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the ARIEL-CMU submissions to the Low Resource Human\nLanguage Technologies (LoReHLT) 2018 evaluations for the tasks Machine\nTranslation (MT), Entity Discovery and Linking (EDL), and detection of\nSituation Frames in Text and Speech (SF Text and Speech).\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2019 06:40:47 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Chaudhary", "Aditi", ""], ["Dalmia", "Siddharth", ""], ["Hu", "Junjie", ""], ["Li", "Xinjian", ""], ["Matthews", "Austin", ""], ["Muis", "Aldrian Obaja", ""], ["Otani", "Naoki", ""], ["Rijhwani", "Shruti", ""], ["Sheikh", "Zaid", ""], ["Vyas", "Nidhi", ""], ["Wang", "Xinyi", ""], ["Xie", "Jiateng", ""], ["Xu", "Ruochen", ""], ["Zhou", "Chunting", ""], ["Jansen", "Peter J.", ""], ["Yang", "Yiming", ""], ["Levin", "Lori", ""], ["Metze", "Florian", ""], ["Mitamura", "Teruko", ""], ["Mortensen", "David R.", ""], ["Neubig", "Graham", ""], ["Hovy", "Eduard", ""], ["Black", "Alan W", ""], ["Carbonell", "Jaime", ""], ["Horwood", "Graham V.", ""], ["Tafreshi", "Shabnam", ""], ["Diab", "Mona", ""], ["Kayi", "Efsun S.", ""], ["Farra", "Noura", ""], ["McKeown", "Kathleen", ""]]}, {"id": "1902.08906", "submitter": "Mahmoud Al-Ayyoub", "authors": "Wegdan Hussien and Mahmoud Al-Ayyoub and Yahya Tashtoush and Mohammed\n  Al-Kabi", "title": "On the Use of Emojis to Train Emotion Classifiers", "comments": "Extended version of a conference paper (DOI:\n  10.1109/CSIT.2016.7549459) being submitted to a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, the automatic detection of emotions is employed by many\napplications in different fields like security informatics, e-learning, humor\ndetection, targeted advertising, etc. Many of these applications focus on\nsocial media and treat this problem as a classification problem, which requires\npreparing training data. The typical method for annotating the training data by\nhuman experts is considered time consuming, labor intensive and sometimes prone\nto error. Moreover, such an approach is not easily extensible to new\ndomains/languages since such extensions require annotating new training data.\nIn this study, we propose a distant supervised learning approach where the\ntraining sentences are automatically annotated based on the emojis they have.\nSuch training data would be very cheap to produce compared with the manually\ncreated training data, thus, much larger training data can be easily obtained.\nOn the other hand, this training data would naturally have lower quality as it\nmay contain some errors in the annotation. Nonetheless, we experimentally show\nthat training classifiers on cheap, large and possibly erroneous data annotated\nusing this approach leads to more accurate results compared with training the\nsame classifiers on the more expensive, much smaller and error-free manually\nannotated training data. Our experiments are conducted on an in-house dataset\nof emotional Arabic tweets and the classifiers we consider are: Support Vector\nMachine (SVM), Multinomial Naive Bayes (MNB) and Random Forest (RF). In\naddition to experimenting with single classifiers, we also consider using an\nensemble of classifiers. The results show that using an automatically annotated\ntraining data (that is only one order of magnitude larger than the manually\nannotated one) gives better results in almost all settings considered.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2019 07:44:00 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 01:52:48 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Hussien", "Wegdan", ""], ["Al-Ayyoub", "Mahmoud", ""], ["Tashtoush", "Yahya", ""], ["Al-Kabi", "Mohammed", ""]]}, {"id": "1902.08912", "submitter": "Maximin Coavoux", "authors": "Maximin Coavoux, Beno\\^it Crabb\\'e, Shay B. Cohen", "title": "Unlexicalized Transition-based Discontinuous Constituency Parsing", "comments": "To appear in Transactions of the Association for Computational\n  Linguistics (TACL); 17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lexicalized parsing models are based on the assumptions that (i) constituents\nare organized around a lexical head (ii) bilexical statistics are crucial to\nsolve ambiguities. In this paper, we introduce an unlexicalized\ntransition-based parser for discontinuous constituency structures, based on a\nstructure-label transition system and a bi-LSTM scoring system. We compare it\nto lexicalized parsing models in order to address the question of\nlexicalization in the context of discontinuous constituency parsing. Our\nexperiments show that unlexicalized models systematically achieve higher\nresults than lexicalized models, and provide additional empirical evidence that\nlexicalization is not necessary to achieve strong parsing results. Our best\nunlexicalized model sets a new state of the art on English and German\ndiscontinuous constituency treebanks. We further provide a per-phenomenon\nanalysis of its errors on discontinuous constituents.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2019 09:59:33 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Coavoux", "Maximin", ""], ["Crabb\u00e9", "Beno\u00eet", ""], ["Cohen", "Shay B.", ""]]}, {"id": "1902.08939", "submitter": "Tommi Gr\\\"ondahl", "authors": "Tommi Gr\\\"ondahl and N. Asokan", "title": "Text Analysis in Adversarial Settings: Does Deception Leave a Stylistic\n  Trace?", "comments": "35 pages To appear in ACM Computing Surveys (CSUR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Textual deception constitutes a major problem for online security. Many\nstudies have argued that deceptiveness leaves traces in writing style, which\ncould be detected using text classification techniques. By conducting an\nextensive literature review of existing empirical work, we demonstrate that\nwhile certain linguistic features have been indicative of deception in certain\ncorpora, they fail to generalize across divergent semantic domains. We suggest\nthat deceptiveness as such leaves no content-invariant stylistic trace, and\ntextual similarity measures provide superior means of classifying texts as\npotentially deceptive. Additionally, we discuss forms of deception beyond\nsemantic content, focusing on hiding author identity by writing style\nobfuscation. Surveying the literature on both author identification and\nobfuscation techniques, we conclude that current style transformation methods\nfail to achieve reliable obfuscation while simultaneously ensuring semantic\nfaithfulness to the original text. We propose that future work in style\ntransformation should pay particular attention to disallowing semantically\ndrastic changes.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2019 13:18:27 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 11:14:57 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Gr\u00f6ndahl", "Tommi", ""], ["Asokan", "N.", ""]]}, {"id": "1902.08955", "submitter": "Jiajun Zhang", "authors": "Jiajun Zhang, Long Zhou, Yang Zhao, Chengqing Zong", "title": "Synchronous Bidirectional Inference for Neural Sequence Generation", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In sequence to sequence generation tasks (e.g. machine translation and\nabstractive summarization), inference is generally performed in a left-to-right\nmanner to produce the result token by token. The neural approaches, such as\nLSTM and self-attention networks, are now able to make full use of all the\npredicted history hypotheses from left side during inference, but cannot\nmeanwhile access any future (right side) information and usually generate\nunbalanced outputs in which left parts are much more accurate than right ones.\nIn this work, we propose a synchronous bidirectional inference model to\ngenerate outputs using both left-to-right and right-to-left decoding\nsimultaneously and interactively. First, we introduce a novel beam search\nalgorithm that facilitates synchronous bidirectional decoding. Then, we present\nthe core approach which enables left-to-right and right-to-left decoding to\ninteract with each other, so as to utilize both the history and future\npredictions simultaneously during inference. We apply the proposed model to\nboth LSTM and self-attention networks. In addition, we propose two strategies\nfor parameter optimization. The extensive experiments on machine translation\nand abstractive summarization demonstrate that our synchronous bidirectional\ninference model can achieve remarkable improvements over the strong baselines.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2019 14:44:07 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Zhang", "Jiajun", ""], ["Zhou", "Long", ""], ["Zhao", "Yang", ""], ["Zong", "Chengqing", ""]]}, {"id": "1902.09006", "submitter": "Catherine Chen", "authors": "Catherine Chen, Qihong Lu, Andre Beukers, Christopher Baldassano, and\n  Kenneth A. Norman", "title": "Learning to Perform Role-Filler Binding with Schematic Knowledge", "comments": null, "journal-ref": "PeerJ 9:e11046 (2021)", "doi": "10.7717/peerj.11046", "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Through specific experiences, humans learn relationships underlying the\nstructure of events in the world. Schema theory suggests that we organize this\ninformation in mental frameworks called \"schemata,\" which represent our\nknowledge of the structure of the world. Generalizing knowledge of structural\nrelationships to new situations requires role-filler binding, the ability to\nassociate specific \"fillers\" with abstract \"roles.\" For instance, when we hear\nthe sentence \"Alice ordered a tea from Bob,\" the role-filler bindings\n\"Alice:customer,\" \"tea:drink,\" and \"Bob:barista\" allow us to understand and\nmake inferences about the sentence. We can perform these bindings for arbitrary\nfillers -- we understand this sentence even if we have never heard the names\n\"Alice,\" \"tea,\" or \"Bob\" before. In this work, we define a model as capable of\nperforming role-filler binding if it can recall arbitrary fillers corresponding\nto a specified role, even when these pairings violate correlations seen during\ntraining. Previous work found that models can learn this ability when\nexplicitly told what the roles and fillers are, or when given fillers seen\nduring training. We show that networks with external memory can learn these\nrelationships with fillers not seen during training and without explicitly\nlabeled role-filler bindings, and show that analyses inspired by neural\ndecoding can provide a means of understanding what the networks have learned.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2019 20:05:07 GMT"}, {"version": "v2", "created": "Sat, 2 Nov 2019 00:21:08 GMT"}, {"version": "v3", "created": "Wed, 13 May 2020 00:48:54 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Chen", "Catherine", ""], ["Lu", "Qihong", ""], ["Beukers", "Andre", ""], ["Baldassano", "Christopher", ""], ["Norman", "Kenneth A.", ""]]}, {"id": "1902.09087", "submitter": "Yuxuan Lai", "authors": "Yuxuan Lai, Yansong Feng, Xiaohan Yu, Zheng Wang, Kun Xu, Dongyan Zhao", "title": "Lattice CNNs for Matching Based Chinese Question Answering", "comments": "AAAI 2019, code: https://github.com/Erutan-pku/LCN-for-Chinese-QA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Short text matching often faces the challenges that there are great word\nmismatch and expression diversity between the two texts, which would be further\naggravated in languages like Chinese where there is no natural space to segment\nwords explicitly. In this paper, we propose a novel lattice based CNN model\n(LCNs) to utilize multi-granularity information inherent in the word lattice\nwhile maintaining strong ability to deal with the introduced noisy information\nfor matching based question answering in Chinese. We conduct extensive\nexperiments on both document based question answering and knowledge based\nquestion answering tasks, and experimental results show that the LCNs models\ncan significantly outperform the state-of-the-art matching models and strong\nbaselines by taking advantages of better ability to distill rich but\ndiscriminative information from the word lattice input.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 04:46:52 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Lai", "Yuxuan", ""], ["Feng", "Yansong", ""], ["Yu", "Xiaohan", ""], ["Wang", "Zheng", ""], ["Xu", "Kun", ""], ["Zhao", "Dongyan", ""]]}, {"id": "1902.09091", "submitter": "Bishan Yang", "authors": "Bishan Yang, Tom Mitchell", "title": "Leveraging Knowledge Bases in LSTMs for Improving Machine Reading", "comments": "published at ACL 2017", "journal-ref": "ACL 2017", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on how to take advantage of external knowledge bases (KBs)\nto improve recurrent neural networks for machine reading. Traditional methods\nthat exploit knowledge from KBs encode knowledge as discrete indicator\nfeatures. Not only do these features generalize poorly, but they require\ntask-specific feature engineering to achieve good performance. We propose\nKBLSTM, a novel neural model that leverages continuous representations of KBs\nto enhance the learning of recurrent neural networks for machine reading. To\neffectively integrate background knowledge with information from the currently\nprocessed text, our model employs an attention mechanism with a sentinel to\nadaptively decide whether to attend to background knowledge and which\ninformation from KBs is useful. Experimental results show that our model\nachieves accuracies that surpass the previous state-of-the-art results for both\nentity extraction and event extraction on the widely used ACE2005 dataset.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 05:04:00 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Yang", "Bishan", ""], ["Mitchell", "Tom", ""]]}, {"id": "1902.09092", "submitter": "Guangyu Zheng", "authors": "Wanyun Cui, Guangyu Zheng, Zhiqiang Shen, Sihang Jiang, Wei Wang", "title": "Transfer Learning for Sequences via Learning to Collocate", "comments": "Published at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning aims to solve the data sparsity for a target domain by\napplying information of the source domain. Given a sequence (e.g. a natural\nlanguage sentence), the transfer learning, usually enabled by recurrent neural\nnetwork (RNN), represents the sequential information transfer. RNN uses a chain\nof repeating cells to model the sequence data. However, previous studies of\nneural network based transfer learning simply represents the whole sentence by\na single vector, which is unfeasible for seq2seq and sequence labeling.\nMeanwhile, such layer-wise transfer learning mechanisms lose the fine-grained\ncell-level information from the source domain.\n  In this paper, we proposed the aligned recurrent transfer, ART, to achieve\ncell-level information transfer. ART is under the pre-training framework. Each\ncell attentively accepts transferred information from a set of positions in the\nsource domain. Therefore, ART learns the cross-domain word collocations in a\nmore flexible way. We conducted extensive experiments on both sequence labeling\ntasks (POS tagging, NER) and sentence classification (sentiment analysis). ART\noutperforms the state-of-the-arts over all experiments.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 05:04:11 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Cui", "Wanyun", ""], ["Zheng", "Guangyu", ""], ["Shen", "Zhiqiang", ""], ["Jiang", "Sihang", ""], ["Wang", "Wei", ""]]}, {"id": "1902.09093", "submitter": "Bishan Yang", "authors": "Igor Labutov, Bishan Yang, Anusha Prakash, Amos Azaria", "title": "Multi-Relational Question Answering from Narratives: Machine Reading and\n  Reasoning in Simulated Worlds", "comments": "published at ACL 2018", "journal-ref": "ACL 2018", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question Answering (QA), as a research field, has primarily focused on either\nknowledge bases (KBs) or free text as a source of knowledge. These two sources\nhave historically shaped the kinds of questions that are asked over these\nsources, and the methods developed to answer them. In this work, we look\ntowards a practical use-case of QA over user-instructed knowledge that uniquely\ncombines elements of both structured QA over knowledge bases, and unstructured\nQA over narrative, introducing the task of multi-relational QA over personal\nnarrative. As a first step towards this goal, we make three key contributions:\n(i) we generate and release TextWorldsQA, a set of five diverse datasets, where\neach dataset contains dynamic narrative that describes entities and relations\nin a simulated world, paired with variably compositional questions over that\nknowledge, (ii) we perform a thorough evaluation and analysis of several\nstate-of-the-art QA models and their variants at this task, and (iii) we\nrelease a lightweight Python-based framework we call TextWorlds for easily\ngenerating arbitrary additional worlds and narrative, with the goal of allowing\nthe community to create and share a growing collection of diverse worlds as a\ntest-bed for this task.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 05:04:26 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Labutov", "Igor", ""], ["Yang", "Bishan", ""], ["Prakash", "Anusha", ""], ["Azaria", "Amos", ""]]}, {"id": "1902.09113", "submitter": "Qipeng Guo", "authors": "Qipeng Guo, Xipeng Qiu, Pengfei Liu, Yunfan Shao, Xiangyang Xue, Zheng\n  Zhang", "title": "Star-Transformer", "comments": "Accepted by NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although Transformer has achieved great successes on many NLP tasks, its\nheavy structure with fully-connected attention connections leads to\ndependencies on large training data. In this paper, we present\nStar-Transformer, a lightweight alternative by careful sparsification. To\nreduce model complexity, we replace the fully-connected structure with a\nstar-shaped topology, in which every two non-adjacent nodes are connected\nthrough a shared relay node. Thus, complexity is reduced from quadratic to\nlinear, while preserving capacity to capture both local composition and\nlong-range dependency. The experiments on four tasks (22 datasets) show that\nStar-Transformer achieved significant improvements against the standard\nTransformer for the modestly sized datasets.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 07:07:38 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 05:55:04 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Guo", "Qipeng", ""], ["Qiu", "Xipeng", ""], ["Liu", "Pengfei", ""], ["Shao", "Yunfan", ""], ["Xue", "Xiangyang", ""], ["Zhang", "Zheng", ""]]}, {"id": "1902.09183", "submitter": "Swarnadeep Saha", "authors": "Swarnadeep Saha, Tejas I. Dhamecha, Smit Marvaniya, Peter Foltz,\n  Renuka Sindhgatta, Bikram Sengupta", "title": "Joint Multi-Domain Learning for Automatic Short Answer Grading", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the fundamental challenges towards building any intelligent tutoring\nsystem is its ability to automatically grade short student answers. A typical\nautomatic short answer grading system (ASAG) grades student answers across\nmultiple domains (or subjects). Grading student answers requires building a\nsupervised machine learning model that evaluates the similarity of the student\nanswer with the reference answer(s). We observe that unlike typical textual\nsimilarity or entailment tasks, the notion of similarity is not universal here.\nOn one hand, para-phrasal constructs of the language can indicate similarity\nindependent of the domain. On the other hand, two words, or phrases, that are\nnot strict synonyms of each other, might mean the same in certain domains.\nBuilding on this observation, we propose JMD-ASAG, the first joint multidomain\ndeep learning architecture for automatic short answer grading that performs\ndomain adaptation by learning generic and domain-specific aspects from the\nlimited domain-wise training data. JMD-ASAG not only learns the domain-specific\ncharacteristics but also overcomes the dependence on a large corpus by learning\nthe generic characteristics from the task-specific data itself. On a\nlarge-scale industry dataset and a benchmarking dataset, we show that our model\nperforms significantly better than existing techniques which either learn\ndomain-specific models or adapt a generic similarity scoring model from a large\ncorpus. Further, on the benchmarking dataset, we report state-of-the-art\nresults against all existing non-neural and neural models.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 10:31:57 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Saha", "Swarnadeep", ""], ["Dhamecha", "Tejas I.", ""], ["Marvaniya", "Smit", ""], ["Foltz", "Peter", ""], ["Sindhgatta", "Renuka", ""], ["Sengupta", "Bikram", ""]]}, {"id": "1902.09191", "submitter": "Shaojie Jiang", "authors": "Shaojie Jiang, Pengjie Ren, Christof Monz, Maarten de Rijke", "title": "Improving Neural Response Diversity with Frequency-Aware Cross-Entropy\n  Loss", "comments": "Will appear at The Web Conference 2019", "journal-ref": null, "doi": "10.1145/3308558.3313415", "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sequence-to-Sequence (Seq2Seq) models have achieved encouraging performance\non the dialogue response generation task. However, existing Seq2Seq-based\nresponse generation methods suffer from a low-diversity problem: they\nfrequently generate generic responses, which make the conversation less\ninteresting. In this paper, we address the low-diversity problem by\ninvestigating its connection with model over-confidence reflected in predicted\ndistributions. Specifically, we first analyze the influence of the commonly\nused Cross-Entropy (CE) loss function, and find that the CE loss function\nprefers high-frequency tokens, which results in low-diversity responses. We\nthen propose a Frequency-Aware Cross-Entropy (FACE) loss function that improves\nover the CE loss function by incorporating a weighting mechanism conditioned on\ntoken frequency. Extensive experiments on benchmark datasets show that the FACE\nloss function is able to substantially improve the diversity of existing\nstate-of-the-art Seq2Seq response generation methods, in terms of both\nautomatic and human evaluations.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 10:53:29 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Jiang", "Shaojie", ""], ["Ren", "Pengjie", ""], ["Monz", "Christof", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1902.09243", "submitter": "Haoyu Zhang", "authors": "Haoyu Zhang, Jianjun Xu, Ji Wang", "title": "Pretraining-Based Natural Language Generation for Text Summarization", "comments": "7 pages", "journal-ref": "CoNLL'2019", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel pretraining-based encoder-decoder\nframework, which can generate the output sequence based on the input sequence\nin a two-stage manner. For the encoder of our model, we encode the input\nsequence into context representations using BERT. For the decoder, there are\ntwo stages in our model, in the first stage, we use a Transformer-based decoder\nto generate a draft output sequence. In the second stage, we mask each word of\nthe draft sequence and feed it to BERT, then by combining the input sequence\nand the draft representation generated by BERT, we use a Transformer-based\ndecoder to predict the refined word for each masked position. To the best of\nour knowledge, our approach is the first method which applies the BERT into\ntext generation tasks. As the first step in this direction, we evaluate our\nproposed method on the text summarization task. Experimental results show that\nour model achieves new state-of-the-art on both CNN/Daily Mail and New York\nTimes datasets.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 13:07:32 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2019 05:00:20 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Zhang", "Haoyu", ""], ["Xu", "Jianjun", ""], ["Wang", "Ji", ""]]}, {"id": "1902.09254", "submitter": "Heinrich Dinkel", "authors": "Mengyue Wu, Heinrich Dinkel and Kai Yu", "title": "Audio Caption: Listen and Tell", "comments": "accepted by ICASSP2019", "journal-ref": null, "doi": "10.1109/ICASSP.2019.8682377", "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing amount of research has shed light on machine perception of audio\nevents, most of which concerns detection and classification tasks. However,\nhuman-like perception of audio scenes involves not only detecting and\nclassifying audio sounds, but also summarizing the relationship between\ndifferent audio events. Comparable research such as image caption has been\nconducted, yet the audio field is still quite barren. This paper introduces a\nmanually-annotated dataset for audio caption. The purpose is to automatically\ngenerate natural sentences for audio scene description and to bridge the gap\nbetween machine perception of audio and image. The whole dataset is labelled in\nMandarin and we also include translated English annotations. A baseline\nencoder-decoder model is provided for both English and Mandarin. Similar BLEU\nscores are derived for both languages: our model can generate understandable\nand data-related captions based on the dataset.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 13:27:13 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2019 15:03:41 GMT"}, {"version": "v3", "created": "Mon, 25 Mar 2019 13:20:11 GMT"}, {"version": "v4", "created": "Fri, 31 May 2019 03:56:46 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Wu", "Mengyue", ""], ["Dinkel", "Heinrich", ""], ["Yu", "Kai", ""]]}, {"id": "1902.09271", "submitter": "Gaurav Singh", "authors": "Gaurav Singh and Parminder Bhatia", "title": "Relation Extraction using Explicit Context Conditioning", "comments": "Accepted for Publication at NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relation Extraction (RE) aims to label relations between groups of marked\nentities in raw text. Most current RE models learn context-aware\nrepresentations of the target entities that are then used to establish relation\nbetween them. This works well for intra-sentence RE and we call them\nfirst-order relations. However, this methodology can sometimes fail to capture\ncomplex and long dependencies. To address this, we hypothesize that at times\ntwo target entities can be explicitly connected via a context token. We refer\nto such indirect relations as second-order relations and describe an efficient\nimplementation for computing them. These second-order relation scores are then\ncombined with first-order relation scores. Our empirical results show that the\nproposed method leads to state-of-the-art performance over two biomedical\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 14:09:03 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Singh", "Gaurav", ""], ["Bhatia", "Parminder", ""]]}, {"id": "1902.09314", "submitter": "Youwei Song", "authors": "Youwei Song, Jiahai Wang, Tao Jiang, Zhiyue Liu, Yanghui Rao", "title": "Attentional Encoder Network for Targeted Sentiment Classification", "comments": "7 pages", "journal-ref": null, "doi": "10.1007/978-3-030-30490-4_9", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Targeted sentiment classification aims at determining the sentimental\ntendency towards specific targets. Most of the previous approaches model\ncontext and target words with RNN and attention. However, RNNs are difficult to\nparallelize and truncated backpropagation through time brings difficulty in\nremembering long-term patterns. To address this issue, this paper proposes an\nAttentional Encoder Network (AEN) which eschews recurrence and employs\nattention based encoders for the modeling between context and target. We raise\nthe label unreliability issue and introduce label smoothing regularization. We\nalso apply pre-trained BERT to this task and obtain new state-of-the-art\nresults. Experiments and analysis demonstrate the effectiveness and lightweight\nof our model.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 14:51:46 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 11:43:32 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Song", "Youwei", ""], ["Wang", "Jiahai", ""], ["Jiang", "Tao", ""], ["Liu", "Zhiyue", ""], ["Rao", "Yanghui", ""]]}, {"id": "1902.09381", "submitter": "Tommi Gr\\\"ondahl", "authors": "Tommi Gr\\\"ondahl", "title": "EAT: a simple and versatile semantic representation format for\n  multi-purpose NLP", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic representations are central in many NLP tasks that require\nhuman-interpretable data. The conjunctivist framework - primarily developed by\nPietroski (2005, 2018) - obtains expressive representations with only a few\nbasic semantic types and relations systematically linked to syntactic\npositions. While representational simplicity is crucial for computational\napplications, such findings have not yet had major influence on NLP. We present\nthe first generic semantic representation format for NLP directly based on\nthese insights. We name the format EAT due to its basis in the Event-, Agent-,\nand Theme arguments in Neo-Davidsonian logical forms. It builds on the idea\nthat similar tripartite argument relations are ubiquitous across categories,\nand can be constructed from grammatical structure without additional lexical\ninformation. We present a detailed exposition of EAT and how it relates to\nother prevalent formats used in prior work, such as Abstract Meaning\nRepresentation (AMR) and Minimal Recursion Semantics (MRS). EAT stands out in\ntwo respects: simplicity and versatility. Uniquely, EAT discards semantic\nmetapredicates, and instead represents semantic roles entirely via positional\nencoding. This is made possible by limiting the number of roles to only three;\na major decrease from the many dozens recognized in e.g. AMR and MRS. EAT's\nsimplicity makes it exceptionally versatile in application. First, we show that\ndrastically reducing semantic roles based on EAT benefits text generation from\nMRS in the test settings of Hajdik et al. (2019). Second, we implement the\nderivation of EAT from a syntactic parse, and apply this for parallel corpus\ngeneration between grammatical classes. Third, we train an encoder-decoder LSTM\nnetwork to map EAT to English. Finally, we use both the encoder-decoder network\nand a rule-based alternative to conduct grammatical transformation from\nEAT-input.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 15:49:10 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2019 14:04:34 GMT"}, {"version": "v3", "created": "Mon, 8 Apr 2019 08:47:04 GMT"}, {"version": "v4", "created": "Fri, 12 Mar 2021 11:03:02 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Gr\u00f6ndahl", "Tommi", ""]]}, {"id": "1902.09393", "submitter": "Serhii Havrylov", "authors": "Serhii Havrylov, Germ\\'an Kruszewski, Armand Joulin", "title": "Cooperative Learning of Disjoint Syntax and Semantics", "comments": "The paper was accepted at NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been considerable attention devoted to models that learn to jointly\ninfer an expression's syntactic structure and its semantics. Yet,\n\\citet{NangiaB18} has recently shown that the current best systems fail to\nlearn the correct parsing strategy on mathematical expressions generated from a\nsimple context-free grammar. In this work, we present a recursive model\ninspired by \\newcite{ChoiYL18} that reaches near perfect accuracy on this task.\nOur model is composed of two separated modules for syntax and semantics. They\nare cooperatively trained with standard continuous and discrete optimization\nschemes. Our model does not require any linguistic structure for supervision\nand its recursive nature allows for out-of-domain generalization with little\nloss in performance. Additionally, our approach performs competitively on\nseveral natural language tasks, such as Natural Language Inference or Sentiment\nAnalysis.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 15:56:34 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 12:42:17 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Havrylov", "Serhii", ""], ["Kruszewski", "Germ\u00e1n", ""], ["Joulin", "Armand", ""]]}, {"id": "1902.09476", "submitter": "Sunil Mohan", "authors": "Sunil Mohan and Donghui Li", "title": "MedMentions: A Large Biomedical Corpus Annotated with UMLS Concepts", "comments": "To appear in AKBC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the formal release of MedMentions, a new manually\nannotated resource for the recognition of biomedical concepts. What\ndistinguishes MedMentions from other annotated biomedical corpora is its size\n(over 4,000 abstracts and over 350,000 linked mentions), as well as the size of\nthe concept ontology (over 3 million concepts from UMLS 2017) and its broad\ncoverage of biomedical disciplines. In addition to the full corpus, a\nsub-corpus of MedMentions is also presented, comprising annotations for a\nsubset of UMLS 2017 targeted towards document retrieval. To encourage research\nin Biomedical Named Entity Recognition and Linking, data splits for training\nand testing are included in the release, and a baseline model and its metrics\nfor entity linking are also described.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 17:53:20 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Mohan", "Sunil", ""], ["Li", "Donghui", ""]]}, {"id": "1902.09487", "submitter": "R\\'emi Cad\\`ene", "authors": "Remi Cadene and Hedi Ben-younes and Matthieu Cord and Nicolas Thome", "title": "MUREL: Multimodal Relational Reasoning for Visual Question Answering", "comments": "CVPR2019 accepted paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multimodal attentional networks are currently state-of-the-art models for\nVisual Question Answering (VQA) tasks involving real images. Although attention\nallows to focus on the visual content relevant to the question, this simple\nmechanism is arguably insufficient to model complex reasoning features required\nfor VQA or other high-level tasks.\n  In this paper, we propose MuRel, a multimodal relational network which is\nlearned end-to-end to reason over real images. Our first contribution is the\nintroduction of the MuRel cell, an atomic reasoning primitive representing\ninteractions between question and image regions by a rich vectorial\nrepresentation, and modeling region relations with pairwise combinations.\nSecondly, we incorporate the cell into a full MuRel network, which\nprogressively refines visual and question interactions, and can be leveraged to\ndefine visualization schemes finer than mere attention maps.\n  We validate the relevance of our approach with various ablation studies, and\nshow its superiority to attention-based methods on three datasets: VQA 2.0,\nVQA-CP v2 and TDIUC. Our final MuRel network is competitive to or outperforms\nstate-of-the-art results in this challenging context.\n  Our code is available: https://github.com/Cadene/murel.bootstrap.pytorch\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 18:04:05 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Cadene", "Remi", ""], ["Ben-younes", "Hedi", ""], ["Cord", "Matthieu", ""], ["Thome", "Nicolas", ""]]}, {"id": "1902.09492", "submitter": "Tal Schuster", "authors": "Tal Schuster, Ori Ram, Regina Barzilay, Amir Globerson", "title": "Cross-Lingual Alignment of Contextual Word Embeddings, with Applications\n  to Zero-shot Dependency Parsing", "comments": "NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel method for multilingual transfer that utilizes deep\ncontextual embeddings, pretrained in an unsupervised fashion. While contextual\nembeddings have been shown to yield richer representations of meaning compared\nto their static counterparts, aligning them poses a challenge due to their\ndynamic nature. To this end, we construct context-independent variants of the\noriginal monolingual spaces and utilize their mapping to derive an alignment\nfor the context-dependent spaces. This mapping readily supports processing of a\ntarget language, improving transfer by context-aware embeddings. Our\nexperimental results demonstrate the effectiveness of this approach for\nzero-shot and few-shot learning of dependency parsing. Specifically, our method\nconsistently outperforms the previous state-of-the-art on 6 tested languages,\nyielding an improvement of 6.8 LAS points on average.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 18:14:11 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 02:53:24 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Schuster", "Tal", ""], ["Ram", "Ori", ""], ["Barzilay", "Regina", ""], ["Globerson", "Amir", ""]]}, {"id": "1902.09506", "submitter": "Drew A. Hudson", "authors": "Drew A. Hudson and Christopher D. Manning", "title": "GQA: A New Dataset for Real-World Visual Reasoning and Compositional\n  Question Answering", "comments": "Published as a conference paper at CVPR 2019 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce GQA, a new dataset for real-world visual reasoning and\ncompositional question answering, seeking to address key shortcomings of\nprevious VQA datasets. We have developed a strong and robust question engine\nthat leverages scene graph structures to create 22M diverse reasoning\nquestions, all come with functional programs that represent their semantics. We\nuse the programs to gain tight control over the answer distribution and present\na new tunable smoothing technique to mitigate question biases. Accompanying the\ndataset is a suite of new metrics that evaluate essential qualities such as\nconsistency, grounding and plausibility. An extensive analysis is performed for\nbaselines as well as state-of-the-art models, providing fine-grained results\nfor different question types and topologies. Whereas a blind LSTM obtains mere\n42.1%, and strong VQA models achieve 54.1%, human performance tops at 89.3%,\noffering ample opportunity for new research to explore. We strongly hope GQA\nwill provide an enabling resource for the next generation of models with\nenhanced robustness, improved consistency, and deeper semantic understanding\nfor images and language.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 18:37:49 GMT"}, {"version": "v2", "created": "Wed, 10 Apr 2019 09:10:11 GMT"}, {"version": "v3", "created": "Fri, 10 May 2019 22:24:55 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Hudson", "Drew A.", ""], ["Manning", "Christopher D.", ""]]}, {"id": "1902.09508", "submitter": "Vaibhav Vaibhav", "authors": "Vaibhav Vaibhav, Sumeet Singh, Craig Stewart, Graham Neubig", "title": "Improving Robustness of Machine Translation with Synthetic Noise", "comments": "Accepted at NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern Machine Translation (MT) systems perform consistently well on clean,\nin-domain text. However most human generated text, particularly in the realm of\nsocial media, is full of typos, slang, dialect, idiolect and other noise which\ncan have a disastrous impact on the accuracy of output translation. In this\npaper we leverage the Machine Translation of Noisy Text (MTNT) dataset to\nenhance the robustness of MT systems by emulating naturally occurring noise in\notherwise clean data. Synthesizing noise in this manner we are ultimately able\nto make a vanilla MT system resilient to naturally occurring noise and\npartially mitigate loss in accuracy resulting therefrom.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 18:39:42 GMT"}, {"version": "v2", "created": "Wed, 10 Apr 2019 20:53:49 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Vaibhav", "Vaibhav", ""], ["Singh", "Sumeet", ""], ["Stewart", "Craig", ""], ["Neubig", "Graham", ""]]}, {"id": "1902.09514", "submitter": "Reuben Cohn-Gordon", "authors": "Reuben Cohn-Gordon, Noah Goodman", "title": "Lost in Machine Translation: A Method to Reduce Meaning Loss", "comments": "NAACL short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A desideratum of high-quality translation systems is that they preserve\nmeaning, in the sense that two sentences with different meanings should not\ntranslate to one and the same sentence in another language. However,\nstate-of-the-art systems often fail in this regard, particularly in cases where\nthe source and target languages partition the \"meaning space\" in different\nways. For instance, \"I cut my finger.\" and \"I cut my finger off.\" describe\ndifferent states of the world but are translated to French (by both Fairseq and\nGoogle Translate) as \"Je me suis coupe le doigt.\", which is ambiguous as to\nwhether the finger is detached. More generally, translation systems are\ntypically many-to-one (non-injective) functions from source to target language,\nwhich in many cases results in important distinctions in meaning being lost in\ntranslation. Building on Bayesian models of informative utterance production,\nwe present a method to define a less ambiguous translation system in terms of\nan underlying pre-trained neural sequence-to-sequence model. This method\nincreases injectivity, resulting in greater preservation of meaning as measured\nby improvement in cycle-consistency, without impeding translation quality\n(measured by BLEU score).\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 18:54:10 GMT"}, {"version": "v2", "created": "Fri, 29 Mar 2019 18:47:52 GMT"}, {"version": "v3", "created": "Fri, 12 Apr 2019 00:28:13 GMT"}, {"version": "v4", "created": "Tue, 23 Apr 2019 03:40:09 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Cohn-Gordon", "Reuben", ""], ["Goodman", "Noah", ""]]}, {"id": "1902.09666", "submitter": "Marcos Zampieri", "authors": "Marcos Zampieri, Shervin Malmasi, Preslav Nakov, Sara Rosenthal, Noura\n  Farra, Ritesh Kumar", "title": "Predicting the Type and Target of Offensive Posts in Social Media", "comments": "Proceedings of the 2019 Annual Conference of the North American\n  Chapter of the Association for Computational Linguistics (NAACL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As offensive content has become pervasive in social media, there has been\nmuch research in identifying potentially offensive messages. However, previous\nwork on this topic did not consider the problem as a whole, but rather focused\non detecting very specific types of offensive content, e.g., hate speech,\ncyberbulling, or cyber-aggression. In contrast, here we target several\ndifferent kinds of offensive content. In particular, we model the task\nhierarchically, identifying the type and the target of offensive messages in\nsocial media. For this purpose, we complied the Offensive Language\nIdentification Dataset (OLID), a new dataset with tweets annotated for\noffensive content using a fine-grained three-layer annotation scheme, which we\nmake publicly available. We discuss the main similarities and differences\nbetween OLID and pre-existing datasets for hate speech identification,\naggression detection, and similar tasks. We further experiment with and we\ncompare the performance of different machine learning models on OLID.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 23:54:40 GMT"}, {"version": "v2", "created": "Tue, 16 Apr 2019 16:30:35 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Zampieri", "Marcos", ""], ["Malmasi", "Shervin", ""], ["Nakov", "Preslav", ""], ["Rosenthal", "Sara", ""], ["Farra", "Noura", ""], ["Kumar", "Ritesh", ""]]}, {"id": "1902.09674", "submitter": "Murthy Devarakonda", "authors": "Samarth Rawal, Ashok Prakash, Soumya Adhya, Sidharth Kulkarni, Saadat\n  Anwar, Chitta Baral, Murthy Devarakonda", "title": "Developing and Using Special-Purpose Lexicons for Cohort Selection from\n  Clinical Notes", "comments": "13 pages, paper describing the NLP system built for N2C2 Task 1 2018\n  shared challenge in biomedical NLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background and Significance: Selecting cohorts for a clinical trial typically\nrequires costly and time-consuming manual chart reviews resulting in poor\nparticipation. To help automate the process, National NLP Clinical Challenges\n(N2C2) conducted a shared challenge by defining 13 criteria for clinical trial\ncohort selection and by providing training and test datasets. This research was\nmotivated by the N2C2 challenge.\n  Methods: We broke down the task into 13 independent subtasks corresponding to\neach criterion and implemented subtasks using rules or a supervised machine\nlearning model. Each task critically depended on knowledge resources in the\nform of task-specific lexicons, for which we developed a novel model-driven\napproach. The approach allowed us to first expand the lexicon from a seed set\nand then remove noise from the list, thus improving the accuracy.\n  Results: Our system achieved an overall F measure of 0.9003 at the challenge,\nand was statistically tied for the first place out of 45 participants. The\nmodel-driven lexicon development and further debugging the rules/code on the\ntraining set improved overall F measure to 0.9140, overtaking the best\nnumerical result at the challenge.\n  Discussion: Cohort selection, like phenotype extraction and classification,\nis amenable to rule-based or simple machine learning methods, however, the\nlexicons involved, such as medication names or medical terms referring to a\nmedical problem, critically determine the overall accuracy. Automated lexicon\ndevelopment has the potential for scalability and accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 00:45:56 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Rawal", "Samarth", ""], ["Prakash", "Ashok", ""], ["Adhya", "Soumya", ""], ["Kulkarni", "Sidharth", ""], ["Anwar", "Saadat", ""], ["Baral", "Chitta", ""], ["Devarakonda", "Murthy", ""]]}, {"id": "1902.09697", "submitter": "Phoebe Mulcaire", "authors": "Phoebe Mulcaire, Jungo Kasai, Noah A. Smith", "title": "Polyglot Contextual Representations Improve Crosslingual Transfer", "comments": "NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Rosita, a method to produce multilingual contextual word\nrepresentations by training a single language model on text from multiple\nlanguages. Our method combines the advantages of contextual word\nrepresentations with those of multilingual representation learning. We produce\nlanguage models from dissimilar language pairs (English/Arabic and\nEnglish/Chinese) and use them in dependency parsing, semantic role labeling,\nand named entity recognition, with comparisons to monolingual and\nnon-contextual variants. Our results provide further evidence for the benefits\nof polyglot learning, in which representations are shared across multiple\nlanguages.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 01:50:09 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2019 21:00:13 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Mulcaire", "Phoebe", ""], ["Kasai", "Jungo", ""], ["Smith", "Noah A.", ""]]}, {"id": "1902.09705", "submitter": "Giovanni Saponaro", "authors": "Giovanni Saponaro, Lorenzo Jamone, Alexandre Bernardino, Giampiero\n  Salvi", "title": "Beyond the Self: Using Grounded Affordances to Interpret and Describe\n  Others' Actions", "comments": "code available at https://github.com/gsaponaro/tcds-gestures, IEEE\n  Transactions on Cognitive and Developmental Systems", "journal-ref": "IEEE Transactions on Cognitive and Developmental Systems, vol. 12,\n  no. 2, pp. 209-221, June 2020", "doi": "10.1109/TCDS.2018.2882140", "report-no": null, "categories": "cs.RO cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a developmental approach that allows a robot to interpret and\ndescribe the actions of human agents by reusing previous experience. The robot\nfirst learns the association between words and object affordances by\nmanipulating the objects in its environment. It then uses this information to\nlearn a mapping between its own actions and those performed by a human in a\nshared environment. It finally fuses the information from these two models to\ninterpret and describe human actions in light of its own experience. In our\nexperiments, we show that the model can be used flexibly to do inference on\ndifferent aspects of the scene. We can predict the effects of an action on the\nbasis of object properties. We can revise the belief that a certain action\noccurred, given the observed effects of the human action. In an early action\nrecognition fashion, we can anticipate the effects when the action has only\nbeen partially observed. By estimating the probability of words given the\nevidence and feeding them into a pre-defined grammar, we can generate relevant\ndescriptions of the scene. We believe that this is a step towards providing\nrobots with the fundamental skills to engage in social collaboration with\nhumans.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 02:14:10 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Saponaro", "Giovanni", ""], ["Jamone", "Lorenzo", ""], ["Bernardino", "Alexandre", ""], ["Salvi", "Giampiero", ""]]}, {"id": "1902.09713", "submitter": "Khalil Mrini", "authors": "Khalil Mrini, Claudiu Musat, Michael Baeriswyl, Martin Jaggi", "title": "Interpretable Structure-aware Document Encoders with Hierarchical\n  Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to create document representations that reflect their\ninternal structure. We modify Tree-LSTMs to hierarchically merge basic elements\nsuch as words and sentences into blocks of increasing complexity. Our Structure\nTree-LSTM implements a hierarchical attention mechanism over individual\ncomponents and combinations thereof. We thus emphasize the usefulness of\nTree-LSTMs for texts larger than a sentence. We show that structure-aware\nencoders can be used to improve the performance of document classification. We\ndemonstrate that our method is resilient to changes to the basic building\nblocks, as it performs well with both sentence and word embeddings. The\nStructure Tree-LSTM outperforms all the baselines on two datasets by leveraging\nstructural clues. We show our model's interpretability by visualizing how our\nmodel distributes attention inside a document. On a third dataset from the\nmedical domain, our model achieves competitive performance with the state of\nthe art. This result shows the Structure Tree-LSTM can leverage dependency\nrelations other than text structure, such as a set of reports on the same\npatient.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 02:54:03 GMT"}, {"version": "v2", "created": "Sat, 5 Oct 2019 05:45:39 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Mrini", "Khalil", ""], ["Musat", "Claudiu", ""], ["Baeriswyl", "Michael", ""], ["Jaggi", "Martin", ""]]}, {"id": "1902.09723", "submitter": "Fereshteh Jafariakinabad", "authors": "Fereshteh Jafariakinabad, Sansiri Tarnpradab, Kien A. Hua", "title": "Syntactic Recurrent Neural Network for Authorship Attribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Writing style is a combination of consistent decisions at different levels of\nlanguage production including lexical, syntactic, and structural associated to\na specific author (or author groups). While lexical-based models have been\nwidely explored in style-based text classification, relying on content makes\nthe model less scalable when dealing with heterogeneous data comprised of\nvarious topics. On the other hand, syntactic models which are\ncontent-independent, are more robust against topic variance. In this paper, we\nintroduce a syntactic recurrent neural network to encode the syntactic patterns\nof a document in a hierarchical structure. The model first learns the syntactic\nrepresentation of sentences from the sequence of part-of-speech tags. For this\npurpose, we exploit both convolutional filters and long short-term memories to\ninvestigate the short-term and long-term dependencies of part-of-speech tags in\nthe sentences. Subsequently, the syntactic representations of sentences are\naggregated into document representation using recurrent neural networks. Our\nexperimental results on PAN 2012 dataset for authorship attribution task shows\nthat syntactic recurrent neural network outperforms the lexical model with the\nidentical architecture by approximately 14% in terms of accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 04:32:42 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 02:54:33 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Jafariakinabad", "Fereshteh", ""], ["Tarnpradab", "Sansiri", ""], ["Hua", "Kien A.", ""]]}, {"id": "1902.09774", "submitter": "Dalu Guo Mr.", "authors": "Dalu Guo, Chang Xu, Dacheng Tao", "title": "Image-Question-Answer Synergistic Network for Visual Dialog", "comments": "Accepted by cvpr2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The image, question (combined with the history for de-referencing), and the\ncorresponding answer are three vital components of visual dialog. Classical\nvisual dialog systems integrate the image, question, and history to search for\nor generate the best matched answer, and so, this approach significantly\nignores the role of the answer. In this paper, we devise a novel\nimage-question-answer synergistic network to value the role of the answer for\nprecise visual dialog. We extend the traditional one-stage solution to a\ntwo-stage solution. In the first stage, candidate answers are coarsely scored\naccording to their relevance to the image and question pair. Afterward, in the\nsecond stage, answers with high probability of being correct are re-ranked by\nsynergizing with image and question. On the Visual Dialog v1.0 dataset, the\nproposed synergistic network boosts the discriminative visual dialog model to\nachieve a new state-of-the-art of 57.88\\% normalized discounted cumulative\ngain. A generative visual dialog model equipped with the proposed technique\nalso shows promising improvements.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 07:30:43 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Guo", "Dalu", ""], ["Xu", "Chang", ""], ["Tao", "Dacheng", ""]]}, {"id": "1902.09781", "submitter": "Miryam de Lhoneux", "authors": "Miryam de Lhoneux, Miguel Ballesteros, Joakim Nivre", "title": "Recursive Subtree Composition in LSTM-Based Dependency Parsing", "comments": "Accepted at NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need for tree structure modelling on top of sequence modelling is an open\nissue in neural dependency parsing. We investigate the impact of adding a tree\nlayer on top of a sequential model by recursively composing subtree\nrepresentations (composition) in a transition-based parser that uses features\nextracted by a BiLSTM. Composition seems superfluous with such a model,\nsuggesting that BiLSTMs capture information about subtrees. We perform model\nablations to tease out the conditions under which composition helps. When\nablating the backward LSTM, performance drops and composition does not recover\nmuch of the gap. When ablating the forward LSTM, performance drops less\ndramatically and composition recovers a substantial part of the gap, indicating\nthat a forward LSTM and composition capture similar information. We take the\nbackward LSTM to be related to lookahead features and the forward LSTM to the\nrich history-based features both crucial for transition-based parsers. To\ncapture history-based information, composition is better than a forward LSTM on\nits own, but it is even better to have a forward LSTM as part of a BiLSTM. We\ncorrelate results with language properties, showing that the improved lookahead\nof a backward LSTM is especially important for head-final languages.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 07:57:22 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["de Lhoneux", "Miryam", ""], ["Ballesteros", "Miguel", ""], ["Nivre", "Joakim", ""]]}, {"id": "1902.09802", "submitter": "Benyou Wang", "authors": "Benyou Wang, Qiuchi Li, Massimo Melucci, Dawei Song", "title": "Semantic Hilbert Space for Text Representation Learning", "comments": "accepted in WWW 2019", "journal-ref": null, "doi": "10.1145/3308558.3313516", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capturing the meaning of sentences has long been a challenging task. Current\nmodels tend to apply linear combinations of word features to conduct semantic\ncomposition for bigger-granularity units e.g. phrases, sentences, and\ndocuments. However, the semantic linearity does not always hold in human\nlanguage. For instance, the meaning of the phrase `ivory tower' can not be\ndeduced by linearly combining the meanings of `ivory' and `tower'. To address\nthis issue, we propose a new framework that models different levels of semantic\nunits (e.g. sememe, word, sentence, and semantic abstraction) on a single\n\\textit{Semantic Hilbert Space}, which naturally admits a non-linear semantic\ncomposition by means of a complex-valued vector word representation. An\nend-to-end neural network~\\footnote{https://github.com/wabyking/qnn} is\nproposed to implement the framework in the text classification task, and\nevaluation results on six benchmarking text classification datasets demonstrate\nthe effectiveness, robustness and self-explanation power of the proposed model.\nFurthermore, intuitive case studies are conducted to help end users to\nunderstand how the framework works.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 08:46:15 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Wang", "Benyou", ""], ["Li", "Qiuchi", ""], ["Melucci", "Massimo", ""], ["Song", "Dawei", ""]]}, {"id": "1902.09859", "submitter": "Zhenisbek Assylbekov", "authors": "Zhenisbek Assylbekov and Rustem Takhanov", "title": "Context Vectors are Reflections of Word Vectors in Half the Dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper takes a step towards theoretical analysis of the relationship\nbetween word embeddings and context embeddings in models such as word2vec. We\nstart from basic probabilistic assumptions on the nature of word vectors,\ncontext vectors, and text generation. These assumptions are well supported\neither empirically or theoretically by the existing literature. Next, we show\nthat under these assumptions the widely-used word-word PMI matrix is\napproximately a random symmetric Gaussian ensemble. This, in turn, implies that\ncontext vectors are reflections of word vectors in approximately half the\ndimensions. As a direct application of our result, we suggest a theoretically\ngrounded way of tying weights in the SGNS model.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 11:09:29 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Assylbekov", "Zhenisbek", ""], ["Takhanov", "Rustem", ""]]}, {"id": "1902.09875", "submitter": "Craig Schmidt", "authors": "Craig W. Schmidt", "title": "Improving a tf-idf weighted document vector embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine a number of methods to compute a dense vector embedding for a\ndocument in a corpus, given a set of word vectors such as those from word2vec\nor GloVe. We describe two methods that can improve upon a simple weighted sum,\nthat are optimal in the sense that they maximizes a particular weighted cosine\nsimilarity measure.\n  We consider several weighting functions, including inverse document frequency\n(idf), smooth inverse frequency (SIF), and the sub-sampling function used in\nword2vec. We find that idf works best for our applications. We also use common\ncomponent removal proposed by Arora et al. as a post-process and find it is\nhelpful in most cases.\n  We compare these embeddings variations to the doc2vec embedding on a new\nevaluation task using TripAdvisor reviews, and also on the CQADupStack\nbenchmark from the literature.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 11:55:35 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Schmidt", "Craig W.", ""]]}, {"id": "1902.09969", "submitter": "Ashutosh Mishra", "authors": "Ashutosh Mishra, Marcus Liwicki", "title": "Using Deep Object Features for Image Descriptions", "comments": "arXiv admin note: text overlap with arXiv:1411.2539, arXiv:1609.06647\n  by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by recent advances in leveraging multiple modalities in machine\ntranslation, we introduce an encoder-decoder pipeline that uses (1) specific\nobjects within an image and their object labels, (2) a language model for\ndecoding joint embedding of object features and the object labels. Our pipeline\nmerges prior detected objects from the image and their object labels and then\nlearns the sequences of captions describing the particular image. The decoder\nmodel learns to extract descriptions for the image from scratch by decoding the\njoint representation of the object visual features and their object classes\nconditioned by the encoder component. The idea of the model is to concentrate\nonly on the specific objects of the image and their labels for generating\ndescriptions of the image rather than visual feature of the entire image. The\nmodel needs to be calibrated more by adjusting the parameters and settings to\nresult in better accuracy and performance.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 18:40:25 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Mishra", "Ashutosh", ""], ["Liwicki", "Marcus", ""]]}, {"id": "1902.10031", "submitter": "Nikola Milo\\v{s}evi\\'c Dr", "authors": "Nikola Milosevic, Cassie Gregson, Robert Hernandez, Goran Nenadic", "title": "A framework for information extraction from tables in biomedical\n  literature", "comments": "24 pages", "journal-ref": "2019, International Journal on Document Analysis and Recognition\n  (IJDAR)", "doi": "10.1007/s10032-019-00317-0", "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The scientific literature is growing exponentially, and professionals are no\nmore able to cope with the current amount of publications. Text mining provided\nin the past methods to retrieve and extract information from text; however,\nmost of these approaches ignored tables and figures. The research done in\nmining table data still does not have an integrated approach for mining that\nwould consider all complexities and challenges of a table. Our research is\nexamining the methods for extracting numerical (number of patients, age, gender\ndistribution) and textual (adverse reactions) information from tables in the\nclinical literature. We present a requirement analysis template and an integral\nmethodology for information extraction from tables in clinical domain that\ncontains 7 steps: (1) table detection, (2) functional processing, (3)\nstructural processing, (4) semantic tagging, (5) pragmatic processing, (6) cell\nselection and (7) syntactic processing and extraction. Our approach performed\nwith the F-measure ranged between 82 and 92%, depending on the variable, task\nand its complexity.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 16:22:15 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Milosevic", "Nikola", ""], ["Gregson", "Cassie", ""], ["Hernandez", "Robert", ""], ["Nenadic", "Goran", ""]]}, {"id": "1902.10068", "submitter": "Nora Hollenstein", "authors": "Nora Hollenstein and Ce Zhang", "title": "Entity Recognition at First Sight: Improving NER with Eye Movement\n  Information", "comments": "Accepted at NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous research shows that eye-tracking data contains information about the\nlexical and syntactic properties of text, which can be used to improve natural\nlanguage processing models. In this work, we leverage eye movement features\nfrom three corpora with recorded gaze information to augment a state-of-the-art\nneural model for named entity recognition (NER) with gaze embeddings. These\ncorpora were manually annotated with named entity labels. Moreover, we show how\ngaze features, generalized on word type level, eliminate the need for recorded\neye-tracking data at test time. The gaze-augmented models for NER using\ntoken-level and type-level features outperform the baselines. We present the\nbenefits of eye-tracking features by evaluating the NER models on both\nindividual datasets as well as in cross-domain settings.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 17:29:43 GMT"}, {"version": "v2", "created": "Thu, 28 Mar 2019 15:07:54 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Hollenstein", "Nora", ""], ["Zhang", "Ce", ""]]}, {"id": "1902.10102", "submitter": "Alexandre Garcia", "authors": "Alexandre Garcia, Slim Essid, Florence d'Alch\\'e-Buc, Chlo\\'e Clavel", "title": "A multimodal movie review corpus for fine-grained opinion mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a set of opinion annotations for the POM movie\nreview dataset, composed of 1000 videos. The annotation campaign is motivated\nby the development of a hierarchical opinion prediction framework allowing one\nto predict the different components of the opinions (e.g. polarity and aspect)\nand to identify the corresponding textual spans. The resulting annotations have\nbeen gathered at two granularity levels: a coarse one (opinionated span) and a\nfiner one (span of opinion components). We introduce specific categories in\norder to make the annotation of opinions easier for movie reviews. For example,\nsome categories allow the discovery of user recommendation and preference in\nmovie reviews. We provide a quantitative analysis of the annotations and report\nthe inter-annotator agreement under the different levels of granularity. We\nprovide thus the first set of ground-truth annotations which can be used for\nthe task of fine-grained multimodal opinion prediction. We provide an analysis\nof the data gathered through an inter-annotator study and show that a linear\nstructured predictor learns meaningful features even for the prediction of\nscarce labels. Both the annotations and the baseline system are made publicly\navailable. https://github.com/eusip/POM/\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 18:30:50 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 09:07:39 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Garcia", "Alexandre", ""], ["Essid", "Slim", ""], ["d'Alch\u00e9-Buc", "Florence", ""], ["Clavel", "Chlo\u00e9", ""]]}, {"id": "1902.10118", "submitter": "Hoang Pham", "authors": "Thai-Hoang Pham, Khai Mai, Nguyen Minh Trung, Nguyen Tuan Duc,\n  Danushka Bolegala, Ryohei Sasano, Satoshi Sekine", "title": "Multi-Task Learning with Contextualized Word Representations for\n  Extented Named Entity Recognition", "comments": "7 pages, 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-Grained Named Entity Recognition (FG-NER) is critical for many NLP\napplications. While classical named entity recognition (NER) has attracted a\nsubstantial amount of research, FG-NER is still an open research domain. The\ncurrent state-of-the-art (SOTA) model for FG-NER relies heavily on manual\nefforts for building a dictionary and designing hand-crafted features. The\nend-to-end framework which achieved the SOTA result for NER did not get the\ncompetitive result compared to SOTA model for FG-NER. In this paper, we\ninvestigate how effective multi-task learning approaches are in an end-to-end\nframework for FG-NER in different aspects. Our experiments show that using\nmulti-task learning approaches with contextualized word representation can help\nan end-to-end neural network model achieve SOTA results without using any\nadditional manual effort for creating data and designing features.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 18:53:22 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Pham", "Thai-Hoang", ""], ["Mai", "Khai", ""], ["Trung", "Nguyen Minh", ""], ["Duc", "Nguyen Tuan", ""], ["Bolegala", "Danushka", ""], ["Sasano", "Ryohei", ""], ["Sekine", "Satoshi", ""]]}, {"id": "1902.10126", "submitter": "Martin Faj\\v{c}\\'ik", "authors": "Martin Fajcik, Luk\\'a\\v{s} Burget, Pavel Smrz", "title": "BUT-FIT at SemEval-2019 Task 7: Determining the Rumour Stance with\n  Pre-Trained Deep Bidirectional Transformers", "comments": "This work has been submitted to NAACL SemEval workshop. Work in\n  progress", "journal-ref": "Proceedings of the 13th International Workshop on Semantic\n  Evaluation 13 (2019) 1097-1104", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes our system submitted to SemEval 2019 Task 7: RumourEval\n2019: Determining Rumour Veracity and Support for Rumours, Subtask A (Gorrell\net al., 2019). The challenge focused on classifying whether posts from Twitter\nand Reddit support, deny, query, or comment a hidden rumour, truthfulness of\nwhich is the topic of an underlying discussion thread. We formulate the problem\nas a stance classification, determining the rumour stance of a post with\nrespect to the previous thread post and the source thread post. The recent BERT\narchitecture was employed to build an end-to-end system which has reached the\nF1 score of 61.67% on the provided test data. It finished at the 2nd place in\nthe competition, without any hand-crafted features, only 0.2% behind the\nwinner.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 19:53:01 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2019 08:43:35 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Fajcik", "Martin", ""], ["Burget", "Luk\u00e1\u0161", ""], ["Smrz", "Pavel", ""]]}, {"id": "1902.10186", "submitter": "Sarthak Jain", "authors": "Sarthak Jain, Byron C. Wallace", "title": "Attention is not Explanation", "comments": "Accepted as NAACL 2019 Long Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention mechanisms have seen wide adoption in neural NLP models. In\naddition to improving predictive performance, these are often touted as\naffording transparency: models equipped with attention provide a distribution\nover attended-to input units, and this is often presented (at least implicitly)\nas communicating the relative importance of inputs. However, it is unclear what\nrelationship exists between attention weights and model outputs. In this work,\nwe perform extensive experiments across a variety of NLP tasks that aim to\nassess the degree to which attention weights provide meaningful `explanations'\nfor predictions. We find that they largely do not. For example, learned\nattention weights are frequently uncorrelated with gradient-based measures of\nfeature importance, and one can identify very different attention distributions\nthat nonetheless yield equivalent predictions. Our findings show that standard\nattention modules do not provide meaningful explanations and should not be\ntreated as though they do. Code for all experiments is available at\nhttps://github.com/successar/AttentionExplanation.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 19:59:15 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 16:55:39 GMT"}, {"version": "v3", "created": "Wed, 8 May 2019 18:05:56 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Jain", "Sarthak", ""], ["Wallace", "Byron C.", ""]]}, {"id": "1902.10193", "submitter": "Shijia Liu", "authors": "Shijia Liu, Hongyuan Mei, Adina Williams, Ryan Cotterell", "title": "On the Idiosyncrasies of the Mandarin Chinese Classifier System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While idiosyncrasies of the Chinese classifier system have been a richly\nstudied topic among linguists (Adams and Conklin, 1973; Erbaugh, 1986; Lakoff,\n1986), not much work has been done to quantify them with statistical methods.\nIn this paper, we introduce an information-theoretic approach to measuring\nidiosyncrasy; we examine how much the uncertainty in Mandarin Chinese\nclassifiers can be reduced by knowing semantic information about the nouns that\nthe classifiers modify. Using the empirical distribution of classifiers from\nthe parsed Chinese Gigaword corpus (Graff et al., 2005), we compute the mutual\ninformation (in bits) between the distribution over classifiers and\ndistributions over other linguistic quantities. We investigate whether semantic\nclasses of nouns and adjectives differ in how much they reduce uncertainty in\nclassifier choice, and find that it is not fully idiosyncratic; while there are\nno obvious trends for the majority of semantic classes, shape nouns reduce\nuncertainty in classifier choice the most.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 20:11:27 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 02:07:54 GMT"}, {"version": "v3", "created": "Sat, 23 May 2020 00:05:56 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Liu", "Shijia", ""], ["Mei", "Hongyuan", ""], ["Williams", "Adina", ""], ["Cotterell", "Ryan", ""]]}, {"id": "1902.10197", "submitter": "Zhiqing Sun", "authors": "Zhiqing Sun, Zhi-Hong Deng, Jian-Yun Nie, Jian Tang", "title": "RotatE: Knowledge Graph Embedding by Relational Rotation in Complex\n  Space", "comments": "Accepted to ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning representations of entities and relations in\nknowledge graphs for predicting missing links. The success of such a task\nheavily relies on the ability of modeling and inferring the patterns of (or\nbetween) the relations. In this paper, we present a new approach for knowledge\ngraph embedding called RotatE, which is able to model and infer various\nrelation patterns including: symmetry/antisymmetry, inversion, and composition.\nSpecifically, the RotatE model defines each relation as a rotation from the\nsource entity to the target entity in the complex vector space. In addition, we\npropose a novel self-adversarial negative sampling technique for efficiently\nand effectively training the RotatE model. Experimental results on multiple\nbenchmark knowledge graphs show that the proposed RotatE model is not only\nscalable, but also able to infer and model various relation patterns and\nsignificantly outperform existing state-of-the-art models for link prediction.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 20:15:09 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Sun", "Zhiqing", ""], ["Deng", "Zhi-Hong", ""], ["Nie", "Jian-Yun", ""], ["Tang", "Jian", ""]]}, {"id": "1902.10236", "submitter": "Fr\\'ederic Godin", "authors": "Fr\\'ederic Godin, Anjishnu Kumar, Arpit Mittal", "title": "Learning When Not to Answer: A Ternary Reward Structure for\n  Reinforcement Learning based Question Answering", "comments": "Accepted at NAACL 2019. Version 1 was presented at NIPS 2018 workshop\n  on Relational Representation Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the challenges of using reinforcement learning\nagents for question-answering over knowledge graphs for real-world\napplications. We examine the performance metrics used by state-of-the-art\nsystems and determine that they are inadequate for such settings. More\nspecifically, they do not evaluate the systems correctly for situations when\nthere is no answer available and thus agents optimized for these metrics are\npoor at modeling confidence. We introduce a simple new performance metric for\nevaluating question-answering agents that is more representative of practical\nusage conditions, and optimize for this metric by extending the binary reward\nstructure used in prior work to a ternary reward structure which also rewards\nan agent for not answering a question rather than giving an incorrect answer.\nWe show that this can drastically improve the precision of answered questions\nwhile only not answering a limited number of previously correctly answered\nquestions. Employing a supervised learning strategy using depth-first-search\npaths to bootstrap the reinforcement learning algorithm further improves\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 21:33:48 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2019 18:58:24 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Godin", "Fr\u00e9deric", ""], ["Kumar", "Anjishnu", ""], ["Mittal", "Arpit", ""]]}, {"id": "1902.10245", "submitter": "Yiren Wang", "authors": "Yiren Wang, Fei Tian, Di He, Tao Qin, ChengXiang Zhai, Tie-Yan Liu", "title": "Non-Autoregressive Machine Translation with Auxiliary Regularization", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a new neural machine translation approach, Non-Autoregressive machine\nTranslation (NAT) has attracted attention recently due to its high efficiency\nin inference. However, the high efficiency has come at the cost of not\ncapturing the sequential dependency on the target side of translation, which\ncauses NAT to suffer from two kinds of translation errors: 1) repeated\ntranslations (due to indistinguishable adjacent decoder hidden states), and 2)\nincomplete translations (due to incomplete transfer of source side information\nvia the decoder hidden states).\n  In this paper, we propose to address these two problems by improving the\nquality of decoder hidden representations via two auxiliary regularization\nterms in the training process of an NAT model. First, to make the hidden states\nmore distinguishable, we regularize the similarity between consecutive hidden\nstates based on the corresponding target tokens. Second, to force the hidden\nstates to contain all the information in the source sentence, we leverage the\ndual nature of translation tasks (e.g., English to German and German to\nEnglish) and minimize a backward reconstruction error to ensure that the hidden\nstates of the NAT decoder are able to recover the source side sentence.\nExtensive experiments conducted on several benchmark datasets show that both\nregularization strategies are effective and can alleviate the issues of\nrepeated translations and incomplete translations in NAT models. The accuracy\nof NAT models is therefore improved significantly over the state-of-the-art NAT\nmodels with even better efficiency for inference.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 02:37:15 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Wang", "Yiren", ""], ["Tian", "Fei", ""], ["He", "Di", ""], ["Qin", "Tao", ""], ["Zhai", "ChengXiang", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1902.10246", "submitter": "Xi Zhu", "authors": "Xi Zhu, Mingbin Xu, Hui Jiang", "title": "Fixed-Size Ordinally Forgetting Encoding Based Word Sense Disambiguation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present our method of using fixed-size ordinally forgetting\nencoding (FOFE) to solve the word sense disambiguation (WSD) problem. FOFE\nenables us to encode variable-length sequence of words into a theoretically\nunique fixed-size representation that can be fed into a feed forward neural\nnetwork (FFNN), while keeping the positional information between words. In our\nmethod, a FOFE-based FFNN is used to train a pseudo language model over\nunlabelled corpus, then the pre-trained language model is capable of\nabstracting the surrounding context of polyseme instances in labelled corpus\ninto context embeddings. Next, we take advantage of these context embeddings\ntowards WSD classification. We conducted experiments on several WSD data sets,\nwhich demonstrates that our proposed method can achieve comparable performance\nto that of the state-of-the-art approach at the expense of much lower\ncomputational cost.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2019 00:22:58 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Zhu", "Xi", ""], ["Xu", "Mingbin", ""], ["Jiang", "Hui", ""]]}, {"id": "1902.10247", "submitter": "Hadi Zare", "authors": "Kayvan Bijari, Hadi Zare, Emad Kebriaei, Hadi Veisi", "title": "Leveraging Deep Graph-Based Text Representation for Sentiment Polarity\n  Applications", "comments": "33 pages, 6 figures, 6 Tables, Accepted for publication in Expert\n  Systems With Applications Journal", "journal-ref": "Expert Systems with Applications Volume 144, 15 April 2020, 113090", "doi": "10.1016/j.eswa.2019.113090", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last few years, machine learning over graph structures has\nmanifested a significant enhancement in text mining applications such as event\ndetection, opinion mining, and news recommendation. One of the primary\nchallenges in this regard is structuring a graph that encodes and encompasses\nthe features of textual data for the effective machine learning algorithm.\nBesides, exploration and exploiting of semantic relations is regarded as a\nprincipal step in text mining applications. However, most of the traditional\ntext mining methods perform somewhat poor in terms of employing such relations.\nIn this paper, we propose a sentence-level graph-based text representation\nwhich includes stop words to consider semantic and term relations. Then, we\nemploy a representation learning approach on the combined graphs of sentences\nto extract the latent and continuous features of the documents. Eventually, the\nlearned features of the documents are fed into a deep neural network for the\nsentiment classification task. The experimental results demonstrate that the\nproposed method substantially outperforms the related sentiment analysis\napproaches based on several benchmark datasets. Furthermore, our method can be\ngeneralized on different datasets without any dependency on pre-trained word\nembeddings.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2019 16:38:35 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 12:25:14 GMT"}, {"version": "v3", "created": "Fri, 15 Nov 2019 07:45:35 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Bijari", "Kayvan", ""], ["Zare", "Hadi", ""], ["Kebriaei", "Emad", ""], ["Veisi", "Hadi", ""]]}, {"id": "1902.10296", "submitter": "Aaron Steven White", "authors": "Shaorong Yan, Aaron Steven White", "title": "A Framework for Decoding Event-Related Potentials from Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel framework for modeling event-related potentials (ERPs)\ncollected during reading that couples pre-trained convolutional decoders with a\nlanguage model. Using this framework, we compare the abilities of a variety of\nexisting and novel sentence processing models to reconstruct ERPs. We find that\nmodern contextual word embeddings underperform surprisal-based models but that,\ncombined, the two outperform either on its own.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 01:43:48 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 17:29:41 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Yan", "Shaorong", ""], ["White", "Aaron Steven", ""]]}, {"id": "1902.10326", "submitter": "Jindong Chen", "authors": "Jindong Chen, Ao Wang, Jiangjie Chen, Yanghua Xiao, Zhendong Chu,\n  Jingping Liu, Jiaqing Liang, Wei Wang", "title": "CN-Probase: A Data-driven Approach for Large-scale Chinese Taxonomy\n  Construction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Taxonomies play an important role in machine intelligence. However, most\nwell-known taxonomies are in English, and non-English taxonomies, especially\nChinese ones, are still very rare. In this paper, we focus on automatic Chinese\ntaxonomy construction and propose an effective generation and verification\nframework to build a large-scale and high-quality Chinese taxonomy. In the\ngeneration module, we extract isA relations from multiple sources of Chinese\nencyclopedia, which ensures the coverage. To further improve the precision of\ntaxonomy, we apply three heuristic approaches in verification module. As a\nresult, we construct the largest Chinese taxonomy with high precision about 95%\ncalled CN-Probase. Our taxonomy has been deployed on Aliyun, with over 82\nmillion API calls in six months.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 04:28:33 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Chen", "Jindong", ""], ["Wang", "Ao", ""], ["Chen", "Jiangjie", ""], ["Xiao", "Yanghua", ""], ["Chu", "Zhendong", ""], ["Liu", "Jingping", ""], ["Liang", "Jiaqing", ""], ["Wang", "Wei", ""]]}, {"id": "1902.10339", "submitter": "Wenhu Chen", "authors": "Wenhu Chen, Yu Su, Yilin Shen, Zhiyu Chen, Xifeng Yan, William Wang", "title": "How Large a Vocabulary Does Text Classification Need? A Variational\n  Approach to Vocabulary Selection", "comments": "Accepted to NAACL 2019, 11 pages, 7 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development in deep learning, deep neural networks have been\nwidely adopted in many real-life natural language applications. Under deep\nneural networks, a pre-defined vocabulary is required to vectorize text inputs.\nThe canonical approach to select pre-defined vocabulary is based on the word\nfrequency, where a threshold is selected to cut off the long tail distribution.\nHowever, we observed that such simple approach could easily lead to under-sized\nvocabulary or over-sized vocabulary issues. Therefore, we are interested in\nunderstanding how the end-task classification accuracy is related to the\nvocabulary size and what is the minimum required vocabulary size to achieve a\nspecific performance. In this paper, we provide a more sophisticated\nvariational vocabulary dropout (VVD) based on variational dropout to perform\nvocabulary selection, which can intelligently select the subset of the\nvocabulary to achieve the required performance. To evaluate different\nalgorithms on the newly proposed vocabulary selection problem, we propose two\nnew metrics: Area Under Accuracy-Vocab Curve and Vocab Size under X\\% Accuracy\nDrop. Through extensive experiments on various NLP classification tasks, our\nvariational framework is shown to significantly outperform the frequency-based\nand other selection baselines on these metrics.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 05:57:13 GMT"}, {"version": "v2", "created": "Mon, 11 Mar 2019 19:42:22 GMT"}, {"version": "v3", "created": "Fri, 15 Mar 2019 19:59:53 GMT"}, {"version": "v4", "created": "Wed, 3 Apr 2019 20:07:26 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Chen", "Wenhu", ""], ["Su", "Yu", ""], ["Shen", "Yilin", ""], ["Chen", "Zhiyu", ""], ["Yan", "Xifeng", ""], ["Wang", "William", ""]]}, {"id": "1902.10360", "submitter": "Haggai Roitman", "authors": "Edward Moroshko, Guy Feigenblat, Haggai Roitman, David Konopnicki", "title": "An Editorial Network for Enhanced Document Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We suggest a new idea of Editorial Network - a mixed extractive-abstractive\nsummarization approach, which is applied as a post-processing step over a given\nsequence of extracted sentences. Our network tries to imitate the decision\nprocess of a human editor during summarization. Within such a process, each\nextracted sentence may be either kept untouched, rephrased or completely\nrejected. We further suggest an effective way for training the \"editor\" based\non a novel soft-labeling approach. Using the CNN/DailyMail dataset we\ndemonstrate the effectiveness of our approach compared to state-of-the-art\nextractive-only or abstractive-only baseline methods.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 07:04:47 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Moroshko", "Edward", ""], ["Feigenblat", "Guy", ""], ["Roitman", "Haggai", ""], ["Konopnicki", "David", ""]]}, {"id": "1902.10374", "submitter": "Hao Zhou", "authors": "Hao Zhou, Minlie Huang, Yishun Mao, Changlei Zhu, Peng Shu, Xiaoyan\n  Zhu", "title": "Domain-Constrained Advertising Keyword Generation", "comments": "Accepted in WWW 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advertising (ad for short) keyword suggestion is important for sponsored\nsearch to improve online advertising and increase search revenue. There are two\ncommon challenges in this task. First, the keyword bidding problem: hot ad\nkeywords are very expensive for most of the advertisers because more\nadvertisers are bidding on more popular keywords, while unpopular keywords are\ndifficult to discover. As a result, most ads have few chances to be presented\nto the users. Second, the inefficient ad impression issue: a large proportion\nof search queries, which are unpopular yet relevant to many ad keywords, have\nno ads presented on their search result pages. Existing retrieval-based or\nmatching-based methods either deteriorate the bidding competition or are unable\nto suggest novel keywords to cover more queries, which leads to inefficient ad\nimpressions. To address the above issues, this work investigates to use\ngenerative neural networks for keyword generation in sponsored search. Given a\npurchased keyword (a word sequence) as input, our model can generate a set of\nkeywords that are not only relevant to the input but also satisfy the domain\nconstraint which enforces that the domain category of a generated keyword is as\nexpected. Furthermore, a reinforcement learning algorithm is proposed to\nadaptively utilize domain-specific information in keyword generation. Offline\nevaluation shows that the proposed model can generate keywords that are\ndiverse, novel, relevant to the source keyword, and accordant with the domain\nconstraint. Online evaluation shows that generative models can improve coverage\n(COV), click-through rate (CTR), and revenue per mille (RPM) substantially in\nsponsored search.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 07:54:54 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Zhou", "Hao", ""], ["Huang", "Minlie", ""], ["Mao", "Yishun", ""], ["Zhu", "Changlei", ""], ["Shu", "Peng", ""], ["Zhu", "Xiaoyan", ""]]}, {"id": "1902.10418", "submitter": "Bang Liu", "authors": "Bang Liu, Mingjun Zhao, Di Niu, Kunfeng Lai, Yancheng He, Haojie Wei,\n  Yu Xu", "title": "Learning to Generate Questions by Learning What not to Generate", "comments": "Accepted by WWW 2019", "journal-ref": null, "doi": "10.1145/3308558.3313737", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic question generation is an important technique that can improve the\ntraining of question answering, help chatbots to start or continue a\nconversation with humans, and provide assessment materials for educational\npurposes. Existing neural question generation models are not sufficient mainly\ndue to their inability to properly model the process of how each word in the\nquestion is selected, i.e., whether repeating the given passage or being\ngenerated from a vocabulary. In this paper, we propose our Clue Guided Copy\nNetwork for Question Generation (CGC-QG), which is a sequence-to-sequence\ngenerative model with copying mechanism, yet employing a variety of novel\ncomponents and techniques to boost the performance of question generation. In\nCGC-QG, we design a multi-task labeling strategy to identify whether a question\nword should be copied from the input passage or be generated instead, guiding\nthe model to learn the accurate boundaries between copying and generation.\nFurthermore, our input passage encoder takes as input, among a diverse range of\nother features, the prediction made by a clue word predictor, which helps\nidentify whether each word in the input passage is a potential clue to be\ncopied into the target question. The clue word predictor is designed based on a\nnovel application of Graph Convolutional Networks onto a syntactic dependency\ntree representation of each passage, thus being able to predict clue words only\nbased on their context in the passage and their relative positions to the\nanswer in the tree. We jointly train the clue prediction as well as question\ngeneration with multi-task learning and a number of practical strategies to\nreduce the complexity. Extensive evaluations show that our model significantly\nimproves the performance of question generation and out-performs all previous\nstate-of-the-art neural question generation models by a substantial margin.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 09:56:19 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Liu", "Bang", ""], ["Zhao", "Mingjun", ""], ["Niu", "Di", ""], ["Lai", "Kunfeng", ""], ["He", "Yancheng", ""], ["Wei", "Haojie", ""], ["Xu", "Yu", ""]]}, {"id": "1902.10461", "submitter": "Yi Ren", "authors": "Xu Tan, Yi Ren, Di He, Tao Qin, Zhou Zhao, Tie-Yan Liu", "title": "Multilingual Neural Machine Translation with Knowledge Distillation", "comments": "Accepted by ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual machine translation, which translates multiple languages with a\nsingle model, has attracted much attention due to its efficiency of offline\ntraining and online serving. However, traditional multilingual translation\nusually yields inferior accuracy compared with the counterpart using individual\nmodels for each language pair, due to language diversity and model capacity\nlimitations. In this paper, we propose a distillation-based approach to boost\nthe accuracy of multilingual machine translation. Specifically, individual\nmodels are first trained and regarded as teachers, and then the multilingual\nmodel is trained to fit the training data and match the outputs of individual\nmodels simultaneously through knowledge distillation. Experiments on IWSLT, WMT\nand Ted talk translation datasets demonstrate the effectiveness of our method.\nParticularly, we show that one model is enough to handle multiple languages (up\nto 44 languages in our experiment), with comparable or even better accuracy\nthan individual models.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 11:14:16 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 06:21:46 GMT"}, {"version": "v3", "created": "Tue, 30 Apr 2019 09:44:45 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Tan", "Xu", ""], ["Ren", "Yi", ""], ["He", "Di", ""], ["Qin", "Tao", ""], ["Zhao", "Zhou", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1902.10482", "submitter": "Ruiying Geng", "authors": "Ruiying Geng, Binhua Li, Yongbin Li, Xiaodan Zhu, Ping Jian and Jian\n  Sun", "title": "Induction Networks for Few-Shot Text Classification", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text classification tends to struggle when data is deficient or when it needs\nto adapt to unseen classes. In such challenging scenarios, recent studies have\nused meta-learning to simulate the few-shot task, in which new queries are\ncompared to a small support set at the sample-wise level. However, this\nsample-wise comparison may be severely disturbed by the various expressions in\nthe same class. Therefore, we should be able to learn a general representation\nof each class in the support set and then compare it to new queries. In this\npaper, we propose a novel Induction Network to learn such a generalized\nclass-wise representation, by innovatively leveraging the dynamic routing\nalgorithm in meta-learning. In this way, we find the model is able to induce\nand generalize better. We evaluate the proposed model on a well-studied\nsentiment classification dataset (English) and a real-world dialogue intent\nclassification dataset (Chinese). Experiment results show that on both\ndatasets, the proposed model significantly outperforms the existing\nstate-of-the-art approaches, proving the effectiveness of class-wise\ngeneralization in few-shot text classification.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 12:16:55 GMT"}, {"version": "v2", "created": "Sun, 29 Sep 2019 09:21:49 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Geng", "Ruiying", ""], ["Li", "Binhua", ""], ["Li", "Yongbin", ""], ["Zhu", "Xiaodan", ""], ["Jian", "Ping", ""], ["Sun", "Jian", ""]]}, {"id": "1902.10505", "submitter": "Carlos G\\'omez-Rodr\\'iguez", "authors": "Michalina Strzyz, David Vilares, Carlos G\\'omez-Rodr\\'iguez", "title": "Viable Dependency Parsing as Sequence Labeling", "comments": "Camera-ready version to appear at NAACL 2019 (final peer-reviewed\n  manuscript). 8 pages (incl. appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We recast dependency parsing as a sequence labeling problem, exploring\nseveral encodings of dependency trees as labels. While dependency parsing by\nmeans of sequence labeling had been attempted in existing work, results\nsuggested that the technique was impractical. We show instead that with a\nconventional BiLSTM-based model it is possible to obtain fast and accurate\nparsers. These parsers are conceptually simple, not needing traditional parsing\nalgorithms or auxiliary structures. However, experiments on the PTB and a\nsample of UD treebanks show that they provide a good speed-accuracy tradeoff,\nwith results competitive with more complex approaches.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 13:08:27 GMT"}, {"version": "v2", "created": "Fri, 29 Mar 2019 17:25:11 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Strzyz", "Michalina", ""], ["Vilares", "David", ""], ["G\u00f3mez-Rodr\u00edguez", "Carlos", ""]]}, {"id": "1902.10525", "submitter": "Thomas Deselaers", "authors": "Victor Carbune and Pedro Gonnet and Thomas Deselaers and Henry A.\n  Rowley and Alexander Daryin and Marcos Calvo and Li-Lun Wang and Daniel\n  Keysers and Sandro Feuz and Philippe Gervais", "title": "Fast Multi-language LSTM-based Online Handwriting Recognition", "comments": "accepted to IJDAR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We describe an online handwriting system that is able to support 102\nlanguages using a deep neural network architecture. This new system has\ncompletely replaced our previous Segment-and-Decode-based system and reduced\nthe error rate by 20%-40% relative for most languages. Further, we report new\nstate-of-the-art results on IAM-OnDB for both the open and closed dataset\nsetting. The system combines methods from sequence recognition with a new input\nencoding using B\\'ezier curves. This leads to up to 10x faster recognition\ntimes compared to our previous system. Through a series of experiments we\ndetermine the optimal configuration of our models and report the results of our\nsetup on a number of additional public datasets.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 12:33:38 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 09:52:41 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Carbune", "Victor", ""], ["Gonnet", "Pedro", ""], ["Deselaers", "Thomas", ""], ["Rowley", "Henry A.", ""], ["Daryin", "Alexander", ""], ["Calvo", "Marcos", ""], ["Wang", "Li-Lun", ""], ["Keysers", "Daniel", ""], ["Feuz", "Sandro", ""], ["Gervais", "Philippe", ""]]}, {"id": "1902.10526", "submitter": "Mor Geva", "authors": "Mor Geva, Eric Malmi, Idan Szpektor, Jonathan Berant", "title": "DiscoFuse: A Large-Scale Dataset for Discourse-Based Sentence Fusion", "comments": "NAACL 2019 (camera ready version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence fusion is the task of joining several independent sentences into a\nsingle coherent text. Current datasets for sentence fusion are small and\ninsufficient for training modern neural models. In this paper, we propose a\nmethod for automatically-generating fusion examples from raw text and present\nDiscoFuse, a large scale dataset for discourse-based sentence fusion. We author\na set of rules for identifying a diverse set of discourse phenomena in raw\ntext, and decomposing the text into two independent sentences. We apply our\napproach on two document collections: Wikipedia and Sports articles, yielding\n60 million fusion examples annotated with discourse information required to\nreconstruct the fused text. We develop a sequence-to-sequence model on\nDiscoFuse and thoroughly analyze its strengths and weaknesses with respect to\nthe various discourse phenomena, using both automatic as well as human\nevaluation. Finally, we conduct transfer learning experiments with WebSplit, a\nrecent dataset for text simplification. We show that pretraining on DiscoFuse\nsubstantially improves performance on WebSplit when viewed as a sentence fusion\ntask.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 13:48:59 GMT"}, {"version": "v2", "created": "Thu, 7 Mar 2019 05:04:34 GMT"}, {"version": "v3", "created": "Mon, 18 Mar 2019 12:27:53 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Geva", "Mor", ""], ["Malmi", "Eric", ""], ["Szpektor", "Idan", ""], ["Berant", "Jonathan", ""]]}, {"id": "1902.10547", "submitter": "Alexandra Chronopoulou", "authors": "Alexandra Chronopoulou, Christos Baziotis, Alexandros Potamianos", "title": "An Embarrassingly Simple Approach for Transfer Learning from Pretrained\n  Language Models", "comments": "NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A growing number of state-of-the-art transfer learning methods employ\nlanguage models pretrained on large generic corpora. In this paper we present a\nconceptually simple and effective transfer learning approach that addresses the\nproblem of catastrophic forgetting. Specifically, we combine the task-specific\noptimization function with an auxiliary language model objective, which is\nadjusted during the training process. This preserves language regularities\ncaptured by language models, while enabling sufficient adaptation for solving\nthe target task. Our method does not require pretraining or finetuning separate\ncomponents of the network and we train our models end-to-end in a single step.\nWe present results on a variety of challenging affective and text\nclassification tasks, surpassing well established transfer learning methods\nwith greater level of complexity.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 14:17:12 GMT"}, {"version": "v2", "created": "Wed, 10 Apr 2019 14:41:05 GMT"}, {"version": "v3", "created": "Fri, 31 May 2019 12:53:15 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Chronopoulou", "Alexandra", ""], ["Baziotis", "Christos", ""], ["Potamianos", "Alexandros", ""]]}, {"id": "1902.10580", "submitter": "Bang Liu", "authors": "Ting Zhang, Bang Liu, Di Niu, Kunfeng Lai, Yu Xu", "title": "Multiresolution Graph Attention Networks for Relevance Matching", "comments": "Accepted by CIKM 2018", "journal-ref": null, "doi": "10.1145/3269206.3271806", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large number of deep learning models have been proposed for the text\nmatching problem, which is at the core of various typical natural language\nprocessing (NLP) tasks. However, existing deep models are mainly designed for\nthe semantic matching between a pair of short texts, such as paraphrase\nidentification and question answering, and do not perform well on the task of\nrelevance matching between short-long text pairs. This is partially due to the\nfact that the essential characteristics of short-long text matching have not\nbeen well considered in these deep models. More specifically, these methods\nfail to handle extreme length discrepancy between text pieces and neither can\nthey fully characterize the underlying structural information in long text\ndocuments. In this paper, we are especially interested in relevance matching\nbetween a piece of short text and a long document, which is critical to\nproblems like query-document matching in information retrieval and web\nsearching. To extract the structural information of documents, an undirected\ngraph is constructed, with each vertex representing a keyword and the weight of\nan edge indicating the degree of interaction between keywords. Based on the\nkeyword graph, we further propose a Multiresolution Graph Attention Network to\nlearn multi-layered representations of vertices through a Graph Convolutional\nNetwork (GCN), and then match the short text snippet with the graphical\nrepresentation of the document with the attention mechanisms applied over each\nlayer of the GCN. Experimental results on two datasets demonstrate that our\ngraph approach outperforms other state-of-the-art deep matching models.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 15:19:36 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Zhang", "Ting", ""], ["Liu", "Bang", ""], ["Niu", "Di", ""], ["Lai", "Kunfeng", ""], ["Xu", "Yu", ""]]}, {"id": "1902.10584", "submitter": "Sima Sharifirad", "authors": "Sima Sharifirad and Stan Matwin", "title": "When a Tweet is Actually Sexist. A more Comprehensive Classification of\n  Different Online Harassment Categories and The Challenges in NLP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sexism is very common in social media and makes the boundaries of freedom\ntighter for feminist and female users. There is still no comprehensive\nclassification of sexism attracting natural language processing techniques.\nCategorizing sexism in social media in the categories of hostile or benevolent\nsexism are so general that simply ignores the other types of sexism happening\nin these media. This paper proposes a more comprehensive and in-depth\ncategories of online harassment in social media e.g. twitter into the following\ncategories, \"Indirect harassment\", \"Information threat\", \"sexual harassment\",\n\"Physical harassment\" and \"Not sexist\" and address the challenge of labeling\nthem along with presenting the classification result of the categories. It is\npreliminary work applying machine learning to learn the concept of sexism and\ndistinguishes itself by looking at more precise categories of sexism in social\nmedia.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 15:26:45 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Sharifirad", "Sima", ""], ["Matwin", "Stan", ""]]}, {"id": "1902.10618", "submitter": "Vered Shwartz", "authors": "Vered Shwartz and Ido Dagan", "title": "Still a Pain in the Neck: Evaluating Text Representations on Lexical\n  Composition", "comments": "TACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building meaningful phrase representations is challenging because phrase\nmeanings are not simply the sum of their constituent meanings. Lexical\ncomposition can shift the meanings of the constituent words and introduce\nimplicit information. We tested a broad range of textual representations for\ntheir capacity to address these issues. We found that as expected,\ncontextualized word representations perform better than static word embeddings,\nmore so on detecting meaning shift than in recovering implicit information, in\nwhich their performance is still far from that of humans. Our evaluation suite,\nincluding 5 tasks related to lexical composition effects, can serve future\nresearch aiming to improve such representations.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 16:16:37 GMT"}, {"version": "v2", "created": "Sun, 19 May 2019 13:47:16 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Shwartz", "Vered", ""], ["Dagan", "Ido", ""]]}, {"id": "1902.10623", "submitter": "Sai Prasanna", "authors": "Sai Prasanna, Sri Ananda Seelan", "title": "Zoho at SemEval-2019 Task 9: Semi-supervised Domain Adaptation using\n  Tri-training for Suggestion Mining", "comments": "NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper describes our submission for the SemEval-2019 Suggestion Mining\ntask. A simple Convolutional Neural Network (CNN) classifier with contextual\nword representations from a pre-trained language model was used for sentence\nclassification. The model is trained using tri-training, a semi-supervised\nbootstrapping mechanism for labelling unseen data. Tri-training proved to be an\neffective technique to accommodate domain shift for cross-domain suggestion\nmining (Subtask B) where there is no hand labelled training data. For in-domain\nevaluation (Subtask A), we use the same technique to augment the training set.\nOur system ranks thirteenth in Subtask A with an $F_1$-score of 68.07 and third\nin Subtask B with an $F_1$-score of 81.94.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 16:33:32 GMT"}, {"version": "v2", "created": "Sat, 6 Apr 2019 21:01:35 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Prasanna", "Sai", ""], ["Seelan", "Sri Ananda", ""]]}, {"id": "1902.10649", "submitter": "Stanislav Peshterliev", "authors": "Stanislav Peshterliev, Alexander Hsieh, Imre Kiss", "title": "F10-SGD: Fast Training of Elastic-net Linear Models for Text\n  Classification and Named-entity Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice-assistants text classification and named-entity recognition (NER)\nmodels are trained on millions of example utterances. Because of the large\ndatasets, long training time is one of the bottlenecks for releasing improved\nmodels. In this work, we develop F10-SGD, a fast optimizer for text\nclassification and NER elastic-net linear models. On internal datasets, F10-SGD\nprovides 4x reduction in training time compared to the OWL-QN optimizer without\nloss of accuracy or increase in model size. Furthermore, we incorporate biased\nsampling that prioritizes harder examples towards the end of the training. As a\nresult, in addition to faster training, we were able to obtain statistically\nsignificant accuracy improvements for NER.\n  On public datasets, F10-SGD obtains 22% faster training time compared to\nFastText for text classification. And, 4x reduction in training time compared\nto CRFSuite OWL-QN for NER.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 17:32:15 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Peshterliev", "Stanislav", ""], ["Hsieh", "Alexander", ""], ["Kiss", "Imre", ""]]}, {"id": "1902.10667", "submitter": "Omid Rohanian", "authors": "Omid Rohanian, Shiva Taslimipoor, Samaneh Kouchaki, Le An Ha, Ruslan\n  Mitkov", "title": "Bridging the Gap: Attending to Discontinuity in Identification of\n  Multiword Expressions", "comments": "Accepted at NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new method to tag Multiword Expressions (MWEs) using a\nlinguistically interpretable language-independent deep learning architecture.\nWe specifically target discontinuity, an under-explored aspect that poses a\nsignificant challenge to computational treatment of MWEs. Two neural\narchitectures are explored: Graph Convolutional Network (GCN) and multi-head\nself-attention. GCN leverages dependency parse information, and self-attention\nattends to long-range relations. We finally propose a combined model that\nintegrates complementary information from both through a gating mechanism. The\nexperiments on a standard multilingual dataset for verbal MWEs show that our\nmodel outperforms the baselines not only in the case of discontinuous MWEs but\nalso in overall F-score.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 18:01:53 GMT"}, {"version": "v2", "created": "Thu, 25 Apr 2019 13:41:57 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Rohanian", "Omid", ""], ["Taslimipoor", "Shiva", ""], ["Kouchaki", "Samaneh", ""], ["Ha", "Le An", ""], ["Mitkov", "Ruslan", ""]]}, {"id": "1902.10680", "submitter": "Shi Zong", "authors": "Shi Zong, Alan Ritter, Graham Mueller, Evan Wright", "title": "Analyzing the Perceived Severity of Cybersecurity Threats Reported on\n  Social Media", "comments": "Accepted at NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Breaking cybersecurity events are shared across a range of websites,\nincluding security blogs (FireEye, Kaspersky, etc.), in addition to social\nmedia platforms such as Facebook and Twitter. In this paper, we investigate\nmethods to analyze the severity of cybersecurity threats based on the language\nthat is used to describe them online. A corpus of 6,000 tweets describing\nsoftware vulnerabilities is annotated with authors' opinions toward their\nseverity. We show that our corpus supports the development of automatic\nclassifiers with high precision for this task. Furthermore, we demonstrate the\nvalue of analyzing users' opinions about the severity of threats reported\nonline as an early indicator of important software vulnerabilities. We present\na simple, yet effective method for linking software vulnerabilities reported in\ntweets to Common Vulnerabilities and Exposures (CVEs) in the National\nVulnerability Database (NVD). Using our predicted severity scores, we show that\nit is possible to achieve a Precision@50 of 0.86 when forecasting high severity\nvulnerabilities, significantly outperforming a baseline that is based on tweet\nvolume. Finally we show how reports of severe vulnerabilities online are\npredictive of real-world exploits.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 18:45:09 GMT"}, {"version": "v2", "created": "Thu, 11 Apr 2019 02:35:43 GMT"}, {"version": "v3", "created": "Fri, 3 May 2019 17:17:29 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Zong", "Shi", ""], ["Ritter", "Alan", ""], ["Mueller", "Graham", ""], ["Wright", "Evan", ""]]}, {"id": "1902.10909", "submitter": "Qian Chen", "authors": "Qian Chen, Zhu Zhuo, Wen Wang", "title": "BERT for Joint Intent Classification and Slot Filling", "comments": "4 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intent classification and slot filling are two essential tasks for natural\nlanguage understanding. They often suffer from small-scale human-labeled\ntraining data, resulting in poor generalization capability, especially for rare\nwords. Recently a new language representation model, BERT (Bidirectional\nEncoder Representations from Transformers), facilitates pre-training deep\nbidirectional representations on large-scale unlabeled corpora, and has created\nstate-of-the-art models for a wide variety of natural language processing tasks\nafter simple fine-tuning. However, there has not been much effort on exploring\nBERT for natural language understanding. In this work, we propose a joint\nintent classification and slot filling model based on BERT. Experimental\nresults demonstrate that our proposed model achieves significant improvement on\nintent classification accuracy, slot filling F1, and sentence-level semantic\nframe accuracy on several public benchmark datasets, compared to the\nattention-based recurrent neural network models and slot-gated models.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 05:54:16 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Chen", "Qian", ""], ["Zhuo", "Zhu", ""], ["Wang", "Wen", ""]]}, {"id": "1902.10985", "submitter": "David Vilares", "authors": "David Vilares and Mostafa Abdou and Anders S{\\o}gaard", "title": "Better, Faster, Stronger Sequence Tagging Constituent Parsers", "comments": "NAACL 2019 (long papers). Contains corrigendum", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence tagging models for constituent parsing are faster, but less accurate\nthan other types of parsers. In this work, we address the following weaknesses\nof such constituent parsers: (a) high error rates around closing brackets of\nlong constituents, (b) large label sets, leading to sparsity, and (c) error\npropagation arising from greedy decoding. To effectively close brackets, we\ntrain a model that learns to switch between tagging schemes. To reduce\nsparsity, we decompose the label set and use multi-task learning to jointly\nlearn to predict sublabels. Finally, we mitigate issues from greedy decoding\nthrough auxiliary losses and sentence-level fine-tuning with policy gradient.\nCombining these techniques, we clearly surpass the performance of sequence\ntagging constituent parsers on the English and Chinese Penn Treebanks, and\nreduce their parsing time even further. On the SPMRL datasets, we observe even\ngreater improvements across the board, including a new state of the art on\nBasque, Hebrew, Polish and Swedish.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 10:06:20 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 08:14:20 GMT"}, {"version": "v3", "created": "Mon, 14 Oct 2019 08:30:54 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Vilares", "David", ""], ["Abdou", "Mostafa", ""], ["S\u00f8gaard", "Anders", ""]]}, {"id": "1902.11004", "submitter": "Adrien Guille", "authors": "Robin Brochier, Adrien Guille, Julien Velcin", "title": "Global Vectors for Node Representations", "comments": "2019 ACM World Wide Web Conference (WWW 19)", "journal-ref": null, "doi": "10.1145/3308558.3313595", "report-no": null, "categories": "cs.CL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most network embedding algorithms consist in measuring co-occurrences of\nnodes via random walks then learning the embeddings using Skip-Gram with\nNegative Sampling. While it has proven to be a relevant choice, there are\nalternatives, such as GloVe, which has not been investigated yet for network\nembedding. Even though SGNS better handles non co-occurrence than GloVe, it has\na worse time-complexity. In this paper, we propose a matrix factorization\napproach for network embedding, inspired by GloVe, that better handles non\nco-occurrence with a competitive time-complexity. We also show how to extend\nthis model to deal with networks where nodes are documents, by simultaneously\nlearning word, node and document representations. Quantitative evaluations show\nthat our model achieves state-of-the-art performance, while not being so\nsensitive to the choice of hyper-parameters. Qualitatively speaking, we show\nhow our model helps exploring a network of documents by generating\ncomplementary network-oriented and content-oriented keywords.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 10:46:54 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Brochier", "Robin", ""], ["Guille", "Adrien", ""], ["Velcin", "Julien", ""]]}, {"id": "1902.11049", "submitter": "Tom Hosking", "authors": "Tom Hosking, Sebastian Riedel", "title": "Evaluating Rewards for Question Generation Models", "comments": "Accepted at NAACL-HLT 2019", "journal-ref": "Proceedings of the 2019 Conference of the North American Chapter\n  of the Association for Computational Linguistics: Human Language\n  Technologies, Volume 1 (Long and Short Papers):2278-2283", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent approaches to question generation have used modifications to a Seq2Seq\narchitecture inspired by advances in machine translation. Models are trained\nusing teacher forcing to optimise only the one-step-ahead prediction. However,\nat test time, the model is asked to generate a whole sequence, causing errors\nto propagate through the generation process (exposure bias). A number of\nauthors have proposed countering this bias by optimising for a reward that is\nless tightly coupled to the training data, using reinforcement learning. We\noptimise directly for quality metrics, including a novel approach using a\ndiscriminator learned directly from the training data. We confirm that policy\ngradient methods can be used to decouple training from the ground truth,\nleading to increases in the metrics used as rewards. We perform a human\nevaluation, and show that although these metrics have previously been assumed\nto be good proxies for question quality, they are poorly aligned with human\njudgement and the model simply learns to exploit the weaknesses of the reward\nsource.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 12:33:17 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 15:03:47 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Hosking", "Tom", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1902.11054", "submitter": "Robin Brochier", "authors": "Robin Brochier and Adrien Guille and Julien Velcin", "title": "Link Prediction with Mutual Attention for Text-Attributed Networks", "comments": "Added missing reference", "journal-ref": null, "doi": "10.1145/3308560.3316587", "report-no": null, "categories": "cs.CL cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this extended abstract, we present an algorithm that learns a similarity\nmeasure between documents from the network topology of a structured corpus. We\nleverage the Scaled Dot-Product Attention, a recently proposed attention\nmechanism, to design a mutual attention mechanism between pairs of documents.\nTo train its parameters, we use the network links as supervision. We provide\npreliminary experiment results with a citation dataset on two prediction tasks,\ndemonstrating the capacity of our model to learn a meaningful textual\nsimilarity.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 12:45:42 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 09:20:53 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Brochier", "Robin", ""], ["Guille", "Adrien", ""], ["Velcin", "Julien", ""]]}, {"id": "1902.11058", "submitter": "Robin Brochier", "authors": "Robin Brochier", "title": "Representation Learning for Recommender Systems with Application to the\n  Scientific Literature", "comments": null, "journal-ref": null, "doi": "10.1145/3308560.3314195", "report-no": null, "categories": "cs.CL cs.DL cs.IR cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The scientific literature is a large information network linking various\nactors (laboratories, companies, institutions, etc.). The vast amount of data\ngenerated by this network constitutes a dynamic heterogeneous attributed\nnetwork (HAN), in which new information is constantly produced and from which\nit is increasingly difficult to extract content of interest. In this article, I\npresent my first thesis works in partnership with an industrial company,\nDigital Scientific Research Technology. This later offers a scientific watch\ntool, Peerus, addressing various issues, such as the real time recommendation\nof newly published papers or the search for active experts to start new\ncollaborations. To tackle this diversity of applications, a common approach\nconsists in learning representations of the nodes and attributes of this HAN\nand use them as features for a variety of recommendation tasks. However, most\nworks on attributed network embedding pay too little attention to textual\nattributes and do not fully take advantage of recent natural language\nprocessing techniques. Moreover, proposed methods that jointly learn node and\ndocument representations do not provide a way to effectively infer\nrepresentations for new documents for which network information is missing,\nwhich happens to be crucial in real time recommender systems. Finally, the\ninterplay between textual and graph data in text-attributed heterogeneous\nnetworks remains an open research direction.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 12:53:38 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Brochier", "Robin", ""]]}, {"id": "1902.11060", "submitter": "Daniel Ortega", "authors": "Daniel Ortega, Chia-Yu Li, Gisela Vallejo, Pavel Denisov, Ngoc Thang\n  Vu", "title": "Context-aware Neural-based Dialog Act Classification on Automatically\n  Generated Transcriptions", "comments": "5 pages, 1 figure, ICASSP 2019, dialog act classification, automatic\n  speech recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents our latest investigations on dialog act (DA)\nclassification on automatically generated transcriptions. We propose a novel\napproach that combines convolutional neural networks (CNNs) and conditional\nrandom fields (CRFs) for context modeling in DA classification. We explore the\nimpact of transcriptions generated from different automatic speech recognition\nsystems such as hybrid TDNN/HMM and End-to-End systems on the final\nperformance. Experimental results on two benchmark datasets (MRDA and SwDA)\nshow that the combination CNN and CRF improves consistently the accuracy.\nFurthermore, they show that although the word error rates are comparable,\nEnd-to-End ASR system seems to be more suitable for DA classification.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 12:55:31 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Ortega", "Daniel", ""], ["Li", "Chia-Yu", ""], ["Vallejo", "Gisela", ""], ["Denisov", "Pavel", ""], ["Vu", "Ngoc Thang", ""]]}, {"id": "1902.11109", "submitter": "Xuan Liang", "authors": "Xuan Liang, Yida Xu", "title": "Actions Generation from Captions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence transduction models have been widely explored in many natural\nlanguage processing tasks. However, the target sequence usually consists of\ndiscrete tokens which represent word indices in a given vocabulary. We barely\nsee the case where target sequence is composed of continuous vectors, where\neach vector is an element of a time series taken successively in a temporal\ndomain. In this work, we introduce a new data set, named Action Generation Data\nSet (AGDS) which is specifically designed to carry out the task of\ncaption-to-action generation. This data set contains caption-action pairs. The\ncaption is comprised of a sequence of words describing the interactive movement\nbetween two people, and the action is a captured sequence of poses representing\nthe movement. This data set is introduced to study the ability of generating\ncontinuous sequences through sequence transduction models. We also propose a\nmodel to innovatively combine Multi-Head Attention (MHA) and Generative\nAdversarial Network (GAN) together. In our model, we have one generator to\ngenerate actions from captions and three discriminators where each of them is\ndesigned to carry out a unique functionality: caption-action consistency\ndiscriminator, pose discriminator and pose transition discriminator. This novel\ndesign allowed us to achieve plausible generation performance which is\ndemonstrated in the experiments.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 04:37:49 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Liang", "Xuan", ""], ["Xu", "Yida", ""]]}, {"id": "1902.11116", "submitter": "Miriam Redi", "authors": "Miriam Redi and Besnik Fetahu and Jonathan Morgan and Dario\n  Taraborelli", "title": "Citation Needed: A Taxonomy and Algorithmic Assessment of Wikipedia's\n  Verifiability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Wikipedia is playing an increasingly central role on the web,and the policies\nits contributors follow when sourcing and fact-checking content affect million\nof readers. Among these core guiding principles, verifiability policies have a\nparticularly important role. Verifiability requires that information included\nin a Wikipedia article be corroborated against reliable secondary sources.\nBecause of the manual labor needed to curate and fact-check Wikipedia at scale,\nhowever, its contents do not always evenly comply with these policies.\nCitations (i.e. reference to external sources) may not conform to verifiability\nrequirements or may be missing altogether, potentially weakening the\nreliability of specific topic areas of the free encyclopedia. In this paper, we\naim to provide an empirical characterization of the reasons why and how\nWikipedia cites external sources to comply with its own verifiability\nguidelines. First, we construct a taxonomy of reasons why inline citations are\nrequired by collecting labeled data from editors of multiple Wikipedia language\neditions. We then collect a large-scale crowdsourced dataset of Wikipedia\nsentences annotated with categories derived from this taxonomy. Finally, we\ndesign and evaluate algorithmic models to determine if a statement requires a\ncitation, and to predict the citation reason based on our taxonomy. We evaluate\nthe robustness of such models across different classes of Wikipedia articles of\nvarying quality, as well as on an additional dataset of claims annotated for\nfact-checking purposes.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 14:50:59 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Redi", "Miriam", ""], ["Fetahu", "Besnik", ""], ["Morgan", "Jonathan", ""], ["Taraborelli", "Dario", ""]]}, {"id": "1902.11145", "submitter": "Roman Klinger", "authors": "Robert McHardy and Heike Adel and Roman Klinger", "title": "Adversarial Training for Satire Detection: Controlling for Confounding\n  Variables", "comments": "Accepted for publication at NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The automatic detection of satire vs. regular news is relevant for downstream\napplications (for instance, knowledge base population) and to improve the\nunderstanding of linguistic characteristics of satire. Recent approaches build\nupon corpora which have been labeled automatically based on article sources. We\nhypothesize that this encourages the models to learn characteristics for\ndifferent publication sources (e.g., \"The Onion\" vs. \"The Guardian\") rather\nthan characteristics of satire, leading to poor generalization performance to\nunseen publication sources. We therefore propose a novel model for satire\ndetection with an adversarial component to control for the confounding variable\nof publication source. On a large novel data set collected from German news\n(which we make available to the research community), we observe comparable\nsatire classification performance and, as desired, a considerable drop in\npublication classification performance with adversarial training. Our analysis\nshows that the adversarial component is crucial for the model to learn to pay\nattention to linguistic properties of satire.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 15:20:41 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 09:50:05 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["McHardy", "Robert", ""], ["Adel", "Heike", ""], ["Klinger", "Roman", ""]]}, {"id": "1902.11205", "submitter": "Xiang Gao", "authors": "Xiang Gao, Sungjin Lee, Yizhe Zhang, Chris Brockett, Michel Galley,\n  Jianfeng Gao, Bill Dolan", "title": "Jointly Optimizing Diversity and Relevance in Neural Response Generation", "comments": "Long paper accepted at NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although recent neural conversation models have shown great potential, they\noften generate bland and generic responses. While various approaches have been\nexplored to diversify the output of the conversation model, the improvement\noften comes at the cost of decreased relevance. In this paper, we propose a\nSpaceFusion model to jointly optimize diversity and relevance that essentially\nfuses the latent space of a sequence-to-sequence model and that of an\nautoencoder model by leveraging novel regularization terms. As a result, our\napproach induces a latent space in which the distance and direction from the\npredicted response vector roughly match the relevance and diversity,\nrespectively. This property also lends itself well to an intuitive\nvisualization of the latent space. Both automatic and human evaluation results\ndemonstrate that the proposed approach brings significant improvement compared\nto strong baselines in both diversity and relevance.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 16:45:19 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 02:29:46 GMT"}, {"version": "v3", "created": "Thu, 4 Apr 2019 18:09:05 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Gao", "Xiang", ""], ["Lee", "Sungjin", ""], ["Zhang", "Yizhe", ""], ["Brockett", "Chris", ""], ["Galley", "Michel", ""], ["Gao", "Jianfeng", ""], ["Dolan", "Bill", ""]]}, {"id": "1902.11245", "submitter": "Egor Lakomkin", "authors": "Egor Lakomkin and Mohammad Ali Zamani and Cornelius Weber and Sven\n  Magg and Stefan Wermter", "title": "Incorporating End-to-End Speech Recognition Models for Sentiment\n  Analysis", "comments": "Accepted at the 2019 International Conference on Robotics and\n  Automation (ICRA) will be held on May 20-24, 2019 in Montreal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work on emotion recognition demonstrated a synergistic effect of\ncombining several modalities such as auditory, visual, and transcribed text to\nestimate the affective state of a speaker. Among these, the linguistic modality\nis crucial for the evaluation of an expressed emotion. However, manually\ntranscribed spoken text cannot be given as input to a system practically. We\nargue that using ground-truth transcriptions during training and evaluation\nphases leads to a significant discrepancy in performance compared to real-world\nconditions, as the spoken text has to be recognized on the fly and can contain\nspeech recognition mistakes. In this paper, we propose a method of integrating\nan automatic speech recognition (ASR) output with a character-level recurrent\nneural network for sentiment recognition. In addition, we conduct several\nexperiments investigating sentiment recognition for human-robot interaction in\na noise-realistic scenario which is challenging for the ASR systems. We\nquantify the improvement compared to using only the acoustic modality in\nsentiment recognition. We demonstrate the effectiveness of this approach on the\nMultimodal Corpus of Sentiment Intensity (MOSI) by achieving 73,6% accuracy in\na binary sentiment classification task, exceeding previously reported results\nthat use only acoustic input. In addition, we set a new state-of-the-art\nperformance on the MOSI dataset (80.4% accuracy, 2% absolute improvement).\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 17:48:20 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Lakomkin", "Egor", ""], ["Zamani", "Mohammad Ali", ""], ["Weber", "Cornelius", ""], ["Magg", "Sven", ""], ["Wermter", "Stefan", ""]]}, {"id": "1902.11269", "submitter": "Liunian Harold Li", "authors": "Liunian Harold Li, Patrick H. Chen, Cho-Jui Hsieh, Kai-Wei Chang", "title": "Efficient Contextual Representation Learning Without Softmax Layer", "comments": "Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual representation models have achieved great success in improving\nvarious downstream tasks. However, these language-model-based encoders are\ndifficult to train due to the large parameter sizes and high computational\ncomplexity. By carefully examining the training procedure, we find that the\nsoftmax layer (the output layer) causes significant inefficiency due to the\nlarge vocabulary size. Therefore, we redesign the learning objective and\npropose an efficient framework for training contextual representation models.\nSpecifically, the proposed approach bypasses the softmax layer by performing\nlanguage modeling with dimension reduction, and allows the models to leverage\npre-trained word embeddings. Our framework reduces the time spent on the output\nlayer to a negligible level, eliminates almost all the trainable parameters of\nthe softmax layer and performs language modeling without truncating the\nvocabulary. When applied to ELMo, our method achieves a 4 times speedup and\neliminates 80% trainable parameters while achieving competitive performance on\ndownstream tasks.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 18:19:14 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Li", "Liunian Harold", ""], ["Chen", "Patrick H.", ""], ["Hsieh", "Cho-Jui", ""], ["Chang", "Kai-Wei", ""]]}, {"id": "1902.11291", "submitter": "Felix Wu", "authors": "Felix Wu, Boyi Li, Lequn Wang, Ni Lao, John Blitzer, Kilian Q.\n  Weinberger", "title": "FastFusionNet: New State-of-the-Art for DAWNBench SQuAD", "comments": "A Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this technical report, we introduce FastFusionNet, an efficient variant of\nFusionNet [12]. FusionNet is a high performing reading comprehension\narchitecture, which was designed primarily for maximum retrieval accuracy with\nless regard towards computational requirements. For FastFusionNets we remove\nthe expensive CoVe layers [21] and substitute the BiLSTMs with far more\nefficient SRU layers [19]. The resulting architecture obtains state-of-the-art\nresults on DAWNBench [5] while achieving the lowest training and inference time\non SQuAD [25] to-date. The code is available at\nhttps://github.com/felixgwu/FastFusionNet.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 18:49:10 GMT"}, {"version": "v2", "created": "Sat, 2 Mar 2019 20:02:22 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Wu", "Felix", ""], ["Li", "Boyi", ""], ["Wang", "Lequn", ""], ["Lao", "Ni", ""], ["Blitzer", "John", ""], ["Weinberger", "Kilian Q.", ""]]}]