[{"id": "2006.00031", "submitter": "Alexander Panchenko", "authors": "Nikolay Arefyev, Boris Sheludko, Alexander Podolskiy, and Alexander\n  Panchenko", "title": "A Comparative Study of Lexical Substitution Approaches based on Neural\n  Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Lexical substitution in context is an extremely powerful technology that can\nbe used as a backbone of various NLP applications, such as word sense\ninduction, lexical relation extraction, data augmentation, etc. In this paper,\nwe present a large-scale comparative study of popular neural language and\nmasked language models (LMs and MLMs), such as context2vec, ELMo, BERT, XLNet,\napplied to the task of lexical substitution. We show that already competitive\nresults achieved by SOTA LMs/MLMs can be further improved if information about\nthe target word is injected properly, and compare several target injection\nmethods. In addition, we provide analysis of the types of semantic relations\nbetween the target and substitutes generated by different models providing\ninsights into what kind of words are really generated or given by annotators as\nsubstitutes.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 18:43:22 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Arefyev", "Nikolay", ""], ["Sheludko", "Boris", ""], ["Podolskiy", "Alexander", ""], ["Panchenko", "Alexander", ""]]}, {"id": "2006.00052", "submitter": "Marjan Hosseinia", "authors": "Marjan Hosseinia, Eduard Dragut and Arjun Mukherjee", "title": "Stance Prediction for Contemporary Issues: Data and Experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate whether pre-trained bidirectional transformers with sentiment\nand emotion information improve stance detection in long discussions of\ncontemporary issues. As a part of this work, we create a novel stance detection\ndataset covering 419 different controversial issues and their related pros and\ncons collected by procon.org in nonpartisan format. Experimental results show\nthat a shallow recurrent neural network with sentiment or emotion information\ncan reach competitive results compared to fine-tuned BERT with 20x fewer\nparameters. We also use a simple approach that explains which input phrases\ncontribute to stance detection.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 19:54:07 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Hosseinia", "Marjan", ""], ["Dragut", "Eduard", ""], ["Mukherjee", "Arjun", ""]]}, {"id": "2006.00075", "submitter": "Zhengyang Wang", "authors": "Zhengyang Wang, Xia Hu, Shuiwang Ji", "title": "iCapsNets: Towards Interpretable Capsule Networks for Text\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many text classification applications require models with satisfying\nperformance as well as good interpretability. Traditional machine learning\nmethods are easy to interpret but have low accuracies. The development of deep\nlearning models boosts the performance significantly. However, deep learning\nmodels are typically hard to interpret. In this work, we propose interpretable\ncapsule networks (iCapsNets) to bridge this gap. iCapsNets use capsules to\nmodel semantic meanings and explore novel methods to increase interpretability.\nThe design of iCapsNets is consistent with human intuition and enables it to\nproduce human-understandable interpretation results. Notably, iCapsNets can be\ninterpreted both locally and globally. In terms of local interpretability,\niCapsNets offer a simple yet effective method to explain the predictions for\neach data sample. On the other hand, iCapsNets explore a novel way to explain\nthe model's general behavior, achieving global interpretability. Experimental\nstudies show that our iCapsNets yield meaningful local and global\ninterpretation results, without suffering from significant performance loss\ncompared to non-interpretable methods.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 04:11:44 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Wang", "Zhengyang", ""], ["Hu", "Xia", ""], ["Ji", "Shuiwang", ""]]}, {"id": "2006.00113", "submitter": "Abdelaziz Lakhfif", "authors": "Abdelaziz Lakhfif and Mohamed Tayeb Laskri", "title": "A frame semantics based approach to comparative study of digitized\n  corpus", "comments": "Proceedings of the 7th International Symposium ISKO-Maghreb Knowledge\n  Organization in the Perspective of Digital Humanities: Research &\n  Applications November 25th & 26th, 2018, pp. 217-223, Bejaia, Algeria", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  in this paper, we present a corpus linguistics based approach applied to\nanalyzing digitized classical multilingual novels and narrative texts, from a\nsemantic point of view. Digitized novels such as \"the hobbit (Tolkien J. R. R.,\n1937)\" and \"the hound of the Baskervilles (Doyle A. C. 1901-1902)\", which were\nwidely translated to dozens of languages, provide rich materials for analyzing\nlanguages differences from several perspectives and within a number of\ndisciplines like linguistics, philosophy and cognitive science. Taking motion\nevents conceptualization as a case study, this paper, focus on the morphologic,\nsyntactic, and semantic annotation process of English-Arabic aligned corpus\ncreated from a digitized novels, in order to re-examine the linguistic\nencodings of motion events in English and Arabic in terms of Frame Semantics.\nThe present study argues that differences in motion events conceptualization\nacross languages can be described with frame structure and frame-to-frame\nrelations.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 22:56:25 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Lakhfif", "Abdelaziz", ""], ["Laskri", "Mohamed Tayeb", ""]]}, {"id": "2006.00114", "submitter": "Abdelaziz Lakhfif", "authors": "Abdelaziz Lakhfif", "title": "Design and Implementation of a Virtual 3D Educational Environment to\n  improve Deaf Education", "comments": "Proceedings of the 7th International Symposium ISKO-Maghreb Knowledge\n  Organization in the Perspective of Digital Humanities: Research &\n  Applications November 25th & 26th, 2018, pp. 201-205, Bejaia, Algeria", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.GR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in NLP, knowledge representation and computer graphic technologies\ncan provide us insights into the development of educational tool for Deaf\npeople. Actual education materials and tools for deaf pupils present several\nproblems, since textbooks are designed to support normal students in the\nclassroom and most of them are not suitable for people with hearing\ndisabilities. Virtual Reality (VR) technologies appear to be a good tool and a\npromising framework in the education of pupils with hearing disabilities. In\nthis paper, we present a current research tasks surrounding the design and\nimplementation of a virtual 3D educational environment based on X3D and H-Anim\nstandards. The system generates and animates automatically Sign language\nsentence from a semantic representation that encode the whole meaning of the\nArabic input text. Some aspects and issues in Sign language generation will be\ndiscussed, including the model of Sign representation that facilitate reuse and\nreduces the time of Sign generation, conversion of semantic components to sign\nfeatures representation with regard to Sign language linguistics\ncharacteristics and how to generate realistic smooth gestural sequences using\nX3D content to performs transition between signs for natural-looking of\nanimated avatar. Sign language sentences were evaluated by Algerian native Deaf\npeople. The goal of the project is the development of a machine translation\nsystem from Arabic to Algerian Sign Language that can be used as educational\ntool for Deaf children in algerian primary schools.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 22:56:43 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Lakhfif", "Abdelaziz", ""]]}, {"id": "2006.00119", "submitter": "Xiaolan Wang", "authors": "Nofar Carmeli and Xiaolan Wang and Yoshihiko Suhara and Stefanos\n  Angelidis and Yuliang Li and Jinfeng Li and Wang-Chiew Tan", "title": "Constructing Explainable Opinion Graphs from Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Web is a major resource of both factual and subjective information. While\nthere are significant efforts to organize factual information into knowledge\nbases, there is much less work on organizing opinions, which are abundant in\nsubjective data, into a structured format.\n  We present ExplainIt, a system that extracts and organizes opinions into an\nopinion graph, which are useful for downstream applications such as generating\nexplainable review summaries and facilitating search over opinion phrases. In\nsuch graphs, a node represents a set of semantically similar opinions extracted\nfrom reviews and an edge between two nodes signifies that one node explains the\nother. ExplainIt mines explanations in a supervised method and groups similar\nopinions together in a weakly supervised way before combining the clusters of\nopinions together with their explanation relationships into an opinion graph.\nWe experimentally demonstrate that the explanation relationships generated in\nthe opinion graph are of good quality and our labeled datasets for explanation\nmining and grouping opinions are publicly available.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 23:11:48 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 23:04:40 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Carmeli", "Nofar", ""], ["Wang", "Xiaolan", ""], ["Suhara", "Yoshihiko", ""], ["Angelidis", "Stefanos", ""], ["Li", "Yuliang", ""], ["Li", "Jinfeng", ""], ["Tan", "Wang-Chiew", ""]]}, {"id": "2006.00148", "submitter": "Pengyuan Li", "authors": "Pengyuan Li, Lei Huang, Guang-jie Ren", "title": "Topic Detection and Summarization of User Reviews", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A massive amount of reviews are generated daily from various platforms. It is\nimpossible for people to read through tons of reviews and to obtain useful\ninformation. Automatic summarizing customer reviews thus is important for\nidentifying and extracting the essential information to help users to obtain\nthe gist of the data. However, as customer reviews are typically short,\ninformal, and multifaceted, it is extremely challenging to generate topic-wise\nsummarization.While there are several studies aims to solve this issue, they\nare heuristic methods that are developed only utilizing customer reviews.\nUnlike existing method, we propose an effective new summarization method by\nanalyzing both reviews and summaries.To do that, we first segment reviews and\nsummaries into individual sentiments. As the sentiments are typically short, we\ncombine sentiments talking about the same aspect into a single document and\napply topic modeling method to identify hidden topics among customer reviews\nand summaries. Sentiment analysis is employed to distinguish positive and\nnegative opinions among each detected topic. A classifier is also introduced to\ndistinguish the writing pattern of summaries and that of customer reviews.\nFinally, sentiments are selected to generate the summarization based on their\ntopic relevance, sentiment analysis score and the writing pattern. To test our\nmethod, a new dataset comprising product reviews and summaries about 1028\nproducts are collected from Amazon and CNET. Experimental results show the\neffectiveness of our method compared with other methods.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 02:19:08 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Li", "Pengyuan", ""], ["Huang", "Lei", ""], ["Ren", "Guang-jie", ""]]}, {"id": "2006.00184", "submitter": "Hu Xu", "authors": "Hu Xu, Seungwhan Moon, Honglei Liu, Bing Liu, Pararth Shah, Bing Liu,\n  Philip S. Yu", "title": "User Memory Reasoning for Conversational Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a conversational recommendation model which dynamically manages\nusers' past (offline) preferences and current (online) requests through a\nstructured and cumulative user memory knowledge graph, to allow for natural\ninteractions and accurate recommendations. For this study, we create a new\nMemory Graph (MG) <--> Conversational Recommendation parallel corpus called\nMGConvRex with 7K+ human-to-human role-playing dialogs, grounded on a\nlarge-scale user memory bootstrapped from real-world user scenarios. MGConvRex\ncaptures human-level reasoning over user memory and has disjoint\ntraining/testing sets of users for zero-shot (cold-start) reasoning for\nrecommendation. We propose a simple yet expandable formulation for constructing\nand updating the MG, and a reasoning model that predicts optimal dialog\npolicies and recommendation items in unconstrained graph space. The prediction\nof our proposed model inherits the graph structure, providing a natural way to\nexplain the model's recommendation. Experiments are conducted for both offline\nmetrics and online simulation, showing competitive results.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 05:29:23 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Xu", "Hu", ""], ["Moon", "Seungwhan", ""], ["Liu", "Honglei", ""], ["Liu", "Bing", ""], ["Shah", "Pararth", ""], ["Liu", "Bing", ""], ["Yu", "Philip S.", ""]]}, {"id": "2006.00206", "submitter": "Bharathi Raja Chakravarthi", "authors": "Bharathi Raja Chakravarthi, Vigneshwaran Muralidaran, Ruba\n  Priyadharshini, John P. McCrae", "title": "Corpus Creation for Sentiment Analysis in Code-Mixed Tamil-English Text", "comments": null, "journal-ref": "Proceedings of the 1st Joint Workshop on Spoken Language\n  Technologies for Under-resourced languages (SLTU) and Collaboration and\n  Computing for Under-Resourced Languages (CCURL) 2020", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the sentiment of a comment from a video or an image is an\nessential task in many applications. Sentiment analysis of a text can be useful\nfor various decision-making processes. One such application is to analyse the\npopular sentiments of videos on social media based on viewer comments. However,\ncomments from social media do not follow strict rules of grammar, and they\ncontain mixing of more than one language, often written in non-native scripts.\nNon-availability of annotated code-mixed data for a low-resourced language like\nTamil also adds difficulty to this problem. To overcome this, we created a gold\nstandard Tamil-English code-switched, sentiment-annotated corpus containing\n15,744 comment posts from YouTube. In this paper, we describe the process of\ncreating the corpus and assigning polarities. We present inter-annotator\nagreement and show the results of sentiment analysis trained on this corpus as\na benchmark.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 07:17:27 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Chakravarthi", "Bharathi Raja", ""], ["Muralidaran", "Vigneshwaran", ""], ["Priyadharshini", "Ruba", ""], ["McCrae", "John P.", ""]]}, {"id": "2006.00210", "submitter": "Bharathi Raja Chakravarthi", "authors": "Bharathi Raja Chakravarthi, Navya Jose, Shardul Suryawanshi, Elizabeth\n  Sherly, John P. McCrae", "title": "A Sentiment Analysis Dataset for Code-Mixed Malayalam-English", "comments": null, "journal-ref": "Proceedings of the 1st Joint Workshop on Spoken Language\n  Technologies for Under-resourced languages (SLTU) and Collaboration and\n  Computing for Under-Resourced Languages (CCURL) 2020", "doi": null, "report-no": "2020.sltu-1.25", "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an increasing demand for sentiment analysis of text from social\nmedia which are mostly code-mixed. Systems trained on monolingual data fail for\ncode-mixed data due to the complexity of mixing at different levels of the\ntext. However, very few resources are available for code-mixed data to create\nmodels specific for this data. Although much research in multilingual and\ncross-lingual sentiment analysis has used semi-supervised or unsupervised\nmethods, supervised methods still performs better. Only a few datasets for\npopular languages such as English-Spanish, English-Hindi, and English-Chinese\nare available. There are no resources available for Malayalam-English\ncode-mixed data. This paper presents a new gold standard corpus for sentiment\nanalysis of code-mixed text in Malayalam-English annotated by voluntary\nannotators. This gold standard corpus obtained a Krippendorff's alpha above 0.8\nfor the dataset. We use this new corpus to provide the benchmark for sentiment\nanalysis in Malayalam-English code-mixed texts.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 07:32:37 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Chakravarthi", "Bharathi Raja", ""], ["Jose", "Navya", ""], ["Suryawanshi", "Shardul", ""], ["Sherly", "Elizabeth", ""], ["McCrae", "John P.", ""]]}, {"id": "2006.00249", "submitter": "Barry Haddow", "authors": "Yuekun Yao and Barry Haddow", "title": "Dynamic Masking for Improved Stability in Spoken Language Translation", "comments": "Presented at AMTA, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For spoken language translation (SLT) in live scenarios such as conferences,\nlectures and meetings, it is desirable to show the translation to the user as\nquickly as possible, avoiding an annoying lag between speaker and translated\ncaptions. In other words, we would like low-latency, online SLT. If we assume a\npipeline of automatic speech recognition (ASR) and machine translation (MT)\nthen a viable approach to online SLT is to pair an online ASR system, with a a\nretranslation strategy, where the MT system re-translates every update received\nfrom ASR. However this can result in annoying \"flicker\" as the MT system\nupdates its translation. A possible solution is to add a fixed delay, or \"mask\"\nto the the output of the MT system, but a fixed global mask introduces\nundesirable latency to the output. We show how this mask can be set\ndynamically, improving the latency-flicker trade-off without sacrificing\ntranslation quality.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 12:23:10 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 22:04:56 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Yao", "Yuekun", ""], ["Haddow", "Barry", ""]]}, {"id": "2006.00262", "submitter": "Sosuke Nishikawa", "authors": "Sosuke Nishikawa, Ryokan Ri and Yoshimasa Tsuruoka", "title": "Data Augmentation with Unsupervised Machine Translation Improves the\n  Structural Similarity of Cross-lingual Word Embeddings", "comments": "Accepted to ACL-IJCNLP 2021 SRW", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised cross-lingual word embedding (CLWE) methods learn a linear\ntransformation matrix that maps two monolingual embedding spaces that are\nseparately trained with monolingual corpora. This method relies on the\nassumption that the two embedding spaces are structurally similar, which does\nnot necessarily hold true in general. In this paper, we argue that using a\npseudo-parallel corpus generated by an unsupervised machine translation model\nfacilitates the structural similarity of the two embedding spaces and improves\nthe quality of CLWEs in the unsupervised mapping method. We show that our\napproach outperforms other alternative approaches given the same amount of\ndata, and, through detailed analysis, we show that data augmentation with the\npseudo data from unsupervised machine translation is especially effective for\nmapping-based CLWEs because (1) the pseudo data makes the source and target\ncorpora (partially) parallel; (2) the pseudo data contains information on the\noriginal language that helps to learn similar embedding spaces between the\nsource and target languages.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 13:28:03 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 08:23:32 GMT"}, {"version": "v3", "created": "Thu, 3 Jun 2021 07:00:44 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Nishikawa", "Sosuke", ""], ["Ri", "Ryokan", ""], ["Tsuruoka", "Yoshimasa", ""]]}, {"id": "2006.00377", "submitter": "Tovly Deutsch", "authors": "Tovly Deutsch, Masoud Jasbi, Stuart Shieber", "title": "Linguistic Features for Readability Assessment", "comments": "To be published in ACL BEA workshop (15th Workshop on Innovative Use\n  of NLP for Building Educational Applications)", "journal-ref": null, "doi": "10.18653/v1/2020.bea-1.1", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Readability assessment aims to automatically classify text by the level\nappropriate for learning readers. Traditional approaches to this task utilize a\nvariety of linguistically motivated features paired with simple machine\nlearning models. More recent methods have improved performance by discarding\nthese features and utilizing deep learning models. However, it is unknown\nwhether augmenting deep learning models with linguistically motivated features\nwould improve performance further. This paper combines these two approaches\nwith the goal of improving overall model performance and addressing this\nquestion. Evaluating on two large readability corpora, we find that, given\nsufficient training data, augmenting deep learning models with linguistically\nmotivated features does not improve state-of-the-art performance. Our results\nprovide preliminary evidence for the hypothesis that the state-of-the-art deep\nlearning models represent linguistic features of the text related to\nreadability. Future research on the nature of representations formed in these\nmodels can shed light on the learned features and their relations to\nlinguistically motivated ones hypothesized in traditional approaches.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 22:14:46 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Deutsch", "Tovly", ""], ["Jasbi", "Masoud", ""], ["Shieber", "Stuart", ""]]}, {"id": "2006.00417", "submitter": "Jeiyoon Park", "authors": "Jeiyoon Park, Chanhee Lee, Kuekyeng Kim, Heuiseok Lim", "title": "Variational Reward Estimator Bottleneck: Learning Robust Reward\n  Estimator for Multi-Domain Task-Oriented Dialog", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its notable success in adversarial learning approaches to\nmulti-domain task-oriented dialog system, training the dialog policy via\nadversarial inverse reinforcement learning often fails to balance the\nperformance of the policy generator and reward estimator. During optimization,\nthe reward estimator often overwhelms the policy generator and produces\nexcessively uninformative gradients. We proposes the Variational Reward\nestimator Bottleneck (VRB), which is an effective regularization method that\naims to constrain unproductive information flows between inputs and the reward\nestimator. The VRB focuses on capturing discriminative features, by exploiting\ninformation bottleneck on mutual information. Empirical results on a\nmulti-domain task-oriented dialog dataset demonstrate that the VRB\nsignificantly outperforms previous methods.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 02:44:36 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Park", "Jeiyoon", ""], ["Lee", "Chanhee", ""], ["Kim", "Kuekyeng", ""], ["Lim", "Heuiseok", ""]]}, {"id": "2006.00418", "submitter": "Julia White", "authors": "Julia White, Jesse Mu, Noah D. Goodman", "title": "Learning to refer informatively by amortizing pragmatic reasoning", "comments": "Accepted to CogSci 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A hallmark of human language is the ability to effectively and efficiently\nconvey contextually relevant information. One theory for how humans reason\nabout language is presented in the Rational Speech Acts (RSA) framework, which\ncaptures pragmatic phenomena via a process of recursive social reasoning\n(Goodman & Frank, 2016). However, RSA represents ideal reasoning in an\nunconstrained setting. We explore the idea that speakers might learn to\namortize the cost of RSA computation over time by directly optimizing for\nsuccessful communication with an internal listener model. In simulations with\ngrounded neural speakers and listeners across two communication game datasets\nrepresenting synthetic and human-generated data, we find that our amortized\nmodel is able to quickly generate language that is effective and concise across\na range of contexts, without the need for explicit pragmatic reasoning.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 02:52:22 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["White", "Julia", ""], ["Mu", "Jesse", ""], ["Goodman", "Noah D.", ""]]}, {"id": "2006.00459", "submitter": "Mahieddine Djoudi", "authors": "Hichem Rahab, Abdelhafid Zitouni, Mahieddine Djoudi", "title": "SANA : Sentiment Analysis on Newspapers comments in Algeria", "comments": "9 pages, 2 figures, 12 tables", "journal-ref": null, "doi": "10.1016/j.jksuci.2019.04.012", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is very current in today life to seek for tracking the people opinion from\ntheir interaction with occurring events. A very common way to do that is\ncomments in articles published in newspapers web sites dealing with\ncontemporary events. Sentiment analysis or opinion mining is an emergent field\nwho is the purpose is finding the behind phenomenon masked in opinionated\ntexts. We are interested in our work by comments in Algerian newspaper\nwebsites. For this end, two corpora were used SANA and OCA. SANA corpus is\ncreated by collection of comments from three Algerian newspapers, and annotated\nby two Algerian Arabic native speakers, while OCA is a freely available corpus\nfor sentiment analysis. For the classification we adopt Supports vector\nmachines, naive Bayes and knearest neighbors. Obtained results are very\npromising and show the different effects of stemming in such domain, also\nknearest neighbors give important improvement comparing to other classifiers\nunlike similar works where SVM is the most dominant. From this study we observe\nthe importance of dedicated resources and methods the newspaper comments\nsentiment analysis which we look forward in future works.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 08:02:23 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Rahab", "Hichem", ""], ["Zitouni", "Abdelhafid", ""], ["Djoudi", "Mahieddine", ""]]}, {"id": "2006.00464", "submitter": "Pin Tang", "authors": "Pin Tang, Pinli Yang, Yuang Shi, Yi Zhou, Feng Lin and Yan Wang", "title": "Recognizing Chinese Judicial Named Entity using BiLSTM-CRF", "comments": null, "journal-ref": null, "doi": "10.1088/1742-6596/1592/1/012040", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named entity recognition (NER) plays an essential role in natural language\nprocessing systems. Judicial NER is a fundamental component of judicial\ninformation retrieval, entity relation extraction, and knowledge map building.\nHowever, Chinese judicial NER remains to be more challenging due to the\ncharacteristics of Chinese and high accuracy requirements in the judicial\nfiled. Thus, in this paper, we propose a deep learning-based method named\nBiLSTM-CRF which consists of bi-directional long short-term memory (BiLSTM) and\nconditional random fields (CRF). For further accuracy promotion, we propose to\nuse Adaptive moment estimation (Adam) for optimization of the model. To\nvalidate our method, we perform experiments on judgment documents including\ncommutation, parole and temporary service outside prison, which is acquired\nfrom China Judgments Online. Experimental results achieve the accuracy of\n0.876, recall of 0.856 and F1 score of 0.855, which suggests the superiority of\nthe proposed BiLSTM-CRF with Adam optimizer.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 08:13:00 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["Tang", "Pin", ""], ["Yang", "Pinli", ""], ["Shi", "Yuang", ""], ["Zhou", "Yi", ""], ["Lin", "Feng", ""], ["Wang", "Yan", ""]]}, {"id": "2006.00490", "submitter": "Brenda Santana", "authors": "Brenda Salenave Santana and Aline Aver Vanin", "title": "Detecting Group Beliefs Related to 2018's Brazilian Elections in Tweets\n  A Combined Study on Modeling Topics and Sentiment Analysis", "comments": null, "journal-ref": "Proceedings of the Workshop on Digital Humanities and Natural\n  Language Processing (DHandNLP 2020) co-located with International Conference\n  on the Computational Processing of Portuguese (PROPOR 2020)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  2018's Brazilian presidential elections highlighted the influence of\nalternative media and social networks, such as Twitter. In this work, we\nperform an analysis covering politically motivated discourses related to the\nsecond round in Brazilian elections. In order to verify whether similar\ndiscourses reinforce group engagement to personal beliefs, we collected a set\nof tweets related to political hashtags at that moment. To this end, we have\nused a combination of topic modeling approach with opinion mining techniques to\nanalyze the motivated political discourses. Using SentiLex-PT, a Portuguese\nsentiment lexicon, we extracted from the dataset the top 5 most frequent group\nof words related to opinions. Applying a bag-of-words model, the cosine\nsimilarity calculation was performed between each opinion and the observed\ngroups. This study allowed us to observe an exacerbated use of passionate\ndiscourses in the digital political scenario as a form of appreciation and\nengagement to the groups which convey similar beliefs.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 10:58:35 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Santana", "Brenda Salenave", ""], ["Vanin", "Aline Aver", ""]]}, {"id": "2006.00492", "submitter": "Wei Li", "authors": "Wei Li, Wei Shao, Shaoxiong Ji and Erik Cambria", "title": "BiERU: Bidirectional Emotional Recurrent Unit for Conversational\n  Sentiment Analysis", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment analysis in conversations has gained increasing attention in recent\nyears for the growing amount of applications it can serve, e.g., sentiment\nanalysis, recommender systems, and human-robot interaction. The main difference\nbetween conversational sentiment analysis and single sentence sentiment\nanalysis is the existence of context information which may influence the\nsentiment of an utterance in a dialogue. How to effectively encode contextual\ninformation in dialogues, however, remains a challenge. Existing approaches\nemploy complicated deep learning structures to distinguish different parties in\na conversation and then model the context information. In this paper, we\npropose a fast, compact and parameter-efficient party-ignorant framework named\nbidirectional emotional recurrent unit for conversational sentiment analysis.\nIn our system, a generalized neural tensor block followed by a two-channel\nclassifier is designed to perform context compositionality and sentiment\nclassification, respectively. Extensive experiments on three standard datasets\ndemonstrate that our model outperforms the state of the art in most cases.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 11:13:13 GMT"}, {"version": "v2", "created": "Sat, 6 Feb 2021 18:30:36 GMT"}, {"version": "v3", "created": "Sun, 4 Jul 2021 14:20:52 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Li", "Wei", ""], ["Shao", "Wei", ""], ["Ji", "Shaoxiong", ""], ["Cambria", "Erik", ""]]}, {"id": "2006.00512", "submitter": "Sebastiaan Scholten", "authors": "Sebastiaan Scholten, Danny Merkx, Odette Scharenborg", "title": "Learning to Recognise Words using Visually Grounded Speech", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigated word recognition in a Visually Grounded Speech model. The\nmodel has been trained on pairs of images and spoken captions to create\nvisually grounded embeddings which can be used for speech to image retrieval\nand vice versa. We investigate whether such a model can be used to recognise\nwords by embedding isolated words and using them to retrieve images of their\nvisual referents. We investigate the time-course of word recognition using a\ngating paradigm and perform a statistical analysis to see whether well known\nword competition effects in human speech processing influence word recognition.\nOur experiments show that the model is able to recognise words, and the gating\nparadigm reveals that words can be recognised from partial input as well and\nthat recognition is negatively influenced by word competition from the word\ninitial cohort.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 12:48:37 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Scholten", "Sebastiaan", ""], ["Merkx", "Danny", ""], ["Scharenborg", "Odette", ""]]}, {"id": "2006.00518", "submitter": "Thomas Drugman", "authors": "Thomas Drugman, John Kane, Christer Gobl", "title": "Data-driven Detection and Analysis of the Patterns of Creaky Voice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the temporal excitation patterns of creaky voice.\nCreaky voice is a voice quality frequently used as a phrase-boundary marker,\nbut also as a means of portraying attitude, affective states and even social\nstatus. Consequently, the automatic detection and modelling of creaky voice may\nhave implications for speech technology applications. The acoustic\ncharacteristics of creaky voice are, however, rather distinct from modal\nphonation. Further, several acoustic patterns can bring about the perception of\ncreaky voice, thereby complicating the strategies used for its automatic\ndetection, analysis and modelling. The present study is carried out using a\nvariety of languages, speakers, and on both read and conversational data and\ninvolves a mutual information-based assessment of the various acoustic features\nproposed in the literature for detecting creaky voice. These features are then\nexploited in classification experiments where we achieve an appreciable\nimprovement in detection accuracy compared to the state of the art. Both\nexperiments clearly highlight the presence of several creaky patterns. A\nsubsequent qualitative and quantitative analysis of the identified patterns is\nprovided, which reveals a considerable speaker-dependent variability in the\nusage of these creaky patterns. We also investigate how creaky voice detection\nsystems perform across creaky patterns.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 13:34:30 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Drugman", "Thomas", ""], ["Kane", "John", ""], ["Gobl", "Christer", ""]]}, {"id": "2006.00521", "submitter": "Thomas Drugman", "authors": "Thomas Drugman, Yannis Stylianou", "title": "Maximum Voiced Frequency Estimation: Exploiting Amplitude and Phase\n  Spectra", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum Voiced Frequency (MVF) is used in various speech models as the\nspectral boundary separating periodic and aperiodic components during the\nproduction of voiced sounds. Recent studies have shown that its proper\nestimation and modeling enhance the quality of statistical parametric speech\nsynthesizers. Contrastingly, these same methods of MVF estimation have been\nreported to degrade the performance of singing voice synthesizers. This paper\nproposes a new approach for MVF estimation which exploits both amplitude and\nphase spectra. It is shown that phase conveys relevant information about the\nharmonicity of the voice signal, and that it can be jointly used with features\nderived from the amplitude spectrum. This information is further integrated\ninto a maximum likelihood criterion which provides a decision about the MVF\nestimate. The proposed technique is compared to two state-of-the-art methods,\nand shows a superior performance in both objective and subjective evaluations.\nPerceptual tests indicate a drastic improvement in high-pitched voices.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 13:40:46 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Drugman", "Thomas", ""], ["Stylianou", "Yannis", ""]]}, {"id": "2006.00525", "submitter": "Thomas Drugman", "authors": "Thomas Drugman", "title": "Residual Excitation Skewness for Automatic Speech Polarity Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting the correct speech polarity is a necessary step prior to several\nspeech processing techniques. An error on its determination could have a\ndramatic detrimental impact on their performance. As current systems have to\ndeal with increasing amounts of data stemming from multiple devices, the\nautomatic detection of speech polarity has become a crucial problem. For this\npurpose, we here propose a very simple algorithm based on the skewness of two\nexcitation signals. The method is shown on 10 speech corpora (8545 files) to\nlead to an error rate of only 0.06% in clean conditions and to clearly\noutperform four state-of-the-art methods. Besides it significantly reduces the\ncomputational load through its simplicity and is observed to exhibit the\nstrongest robustness in both noisy and reverberant environments.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 13:56:07 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Drugman", "Thomas", ""]]}, {"id": "2006.00533", "submitter": "Kaustubh Dhole", "authors": "Abhinav Bhatt, Kaustubh D. Dhole", "title": "Benchmarking BioRelEx for Entity Tagging and Relation Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting relationships and interactions between different biological\nentities is still an extremely challenging problem but has not received much\nattention as much as extraction in other generic domains. In addition to the\nlack of annotated data, low benchmarking is still a major reason for slow\nprogress. In order to fill this gap, we compare multiple existing entity and\nrelation extraction models over a recently introduced public dataset, BioRelEx\nof sentences annotated with biological entities and relations. Our\nstraightforward benchmarking shows that span-based multi-task architectures\nlike DYGIE show 4.9% and 6% absolute improvements in entity tagging and\nrelation extraction respectively over the previous state-of-art and that\nincorporating domain-specific information like embeddings pre-trained over\nrelated domains boosts performance.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 14:45:28 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Bhatt", "Abhinav", ""], ["Dhole", "Kaustubh D.", ""]]}, {"id": "2006.00572", "submitter": "Erfaneh Gharavi", "authors": "Erfaneh Gharavi, Hadi Veisi", "title": "Improve Document Embedding for Text Categorization Through Deep Siamese\n  Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the increasing amount of data on the internet, finding a\nhighly-informative, low-dimensional representation for text is one of the main\nchallenges for efficient natural language processing tasks including text\nclassification. This representation should capture the semantic information of\nthe text while retaining their relevance level for document classification.\nThis approach maps the documents with similar topics to a similar space in\nvector space representation. To obtain representation for large text, we\npropose the utilization of deep Siamese neural networks. To embed document\nrelevance in topics in the distributed representation, we use a Siamese neural\nnetwork to jointly learn document representations. Our Siamese network consists\nof two sub-network of multi-layer perceptron. We examine our representation for\nthe text categorization task on BBC news dataset. The results show that the\nproposed representations outperform the conventional and state-of-the-art\nrepresentations in the text classification task on this dataset.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 17:51:08 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Gharavi", "Erfaneh", ""], ["Veisi", "Hadi", ""]]}, {"id": "2006.00575", "submitter": "Artem Shelmanov", "authors": "Ozge Sevgili, Artem Shelmanov, Mikhail Arkhipov, Alexander Panchenko,\n  Chris Biemann", "title": "Neural Entity Linking: A Survey of Models Based on Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this survey, we provide a comprehensive description of recent neural\nentity linking (EL) systems developed since 2015 as a result of the \"deep\nlearning revolution\" in NLP. Our goal is to systemize design features of neural\nentity linking systems and compare their performances to the best classic\nmethods on the common benchmarks. We distill generic architectural components\nof a neural EL system, like candidate generation and entity ranking summarizing\nthe prominent methods for each of them, such as approaches to mention encoding\nbased on the self-attention architecture. The vast variety of modifications of\nthis general neural entity linking architecture are grouped by several common\nthemes: joint entity recognition and linking, models for global linking,\ndomain-independent techniques including zero-shot and distant supervision\nmethods, and cross-lingual approaches. Since many neural models take advantage\nof pre-trained entity embeddings to improve their generalization capabilities,\nwe provide an overview of popular entity embedding techniques. Finally, we\nbriefly discuss applications of entity linking, focusing on the recently\nemerged use-case of enhancing deep pre-trained masked language models such as\nBERT.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 18:02:26 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 14:07:02 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Sevgili", "Ozge", ""], ["Shelmanov", "Artem", ""], ["Arkhipov", "Mikhail", ""], ["Panchenko", "Alexander", ""], ["Biemann", "Chris", ""]]}, {"id": "2006.00578", "submitter": "Aparna Garimella", "authors": "Aparna Garimella, Carmen Banea, Nabil Hossain, Rada Mihalcea", "title": "\"Judge me by my size (noun), do you?'' YodaLib: A Demographic-Aware\n  Humor Generation Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The subjective nature of humor makes computerized humor generation a\nchallenging task. We propose an automatic humor generation framework for\nfilling the blanks in Mad Libs stories, while accounting for the demographic\nbackgrounds of the desired audience. We collect a dataset consisting of such\nstories, which are filled in and judged by carefully selected workers on Amazon\nMechanical Turk. We build upon the BERT platform to predict location-biased\nword fillings in incomplete sentences, and we fine tune BERT to classify\nlocation-specific humor in a sentence. We leverage these components to produce\nYodaLib, a fully-automated Mad Libs style humor generation framework, which\nselects and ranks appropriate candidate words and sentences in order to\ngenerate a coherent and funny story tailored to certain demographics. Our\nexperimental results indicate that YodaLib outperforms a previous\nsemi-automated approach proposed for this task, while also surpassing human\nannotators in both qualitative and quantitative analyses.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 18:11:52 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Garimella", "Aparna", ""], ["Banea", "Carmen", ""], ["Hossain", "Nabil", ""], ["Mihalcea", "Rada", ""]]}, {"id": "2006.00591", "submitter": "Anthony Colas", "authors": "Anthony Colas, Trung Bui, Franck Dernoncourt, Moumita Sinha, Doo Soon\n  Kim", "title": "Efficient Deployment of Conversational Natural Language Interfaces over\n  Databases", "comments": "Accepted at ACL-NLI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many users communicate with chatbots and AI assistants in order to help them\nwith various tasks. A key component of the assistant is the ability to\nunderstand and answer a user's natural language questions for\nquestion-answering (QA). Because data can be usually stored in a structured\nmanner, an essential step involves turning a natural language question into its\ncorresponding query language. However, in order to train most natural\nlanguage-to-query-language state-of-the-art models, a large amount of training\ndata is needed first. In most domains, this data is not available and\ncollecting such datasets for various domains can be tedious and time-consuming.\nIn this work, we propose a novel method for accelerating the training dataset\ncollection for developing the natural language-to-query-language machine\nlearning models. Our system allows one to generate conversational multi-term\ndata, where multiple turns define a dialogue session, enabling one to better\nutilize chatbot interfaces. We train two current state-of-the-art NL-to-QL\nmodels, on both an SQL and SPARQL-based datasets in order to showcase the\nadaptability and efficacy of our created data.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 19:16:27 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 19:31:14 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Colas", "Anthony", ""], ["Bui", "Trung", ""], ["Dernoncourt", "Franck", ""], ["Sinha", "Moumita", ""], ["Kim", "Doo Soon", ""]]}, {"id": "2006.00593", "submitter": "Rajaswa Patil", "authors": "Rajaswa Patil, Somesh Singh and Swati Agarwal", "title": "BPGC at SemEval-2020 Task 11: Propaganda Detection in News Articles with\n  Multi-Granularity Knowledge Sharing and Linguistic Features based Ensemble\n  Learning", "comments": "Accepted at SemEval-2020 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Propaganda spreads the ideology and beliefs of like-minded people,\nbrainwashing their audiences, and sometimes leading to violence. SemEval 2020\nTask-11 aims to design automated systems for news propaganda detection. Task-11\nconsists of two sub-tasks, namely, Span Identification - given any news\narticle, the system tags those specific fragments which contain at least one\npropaganda technique; and Technique Classification - correctly classify a given\npropagandist statement amongst 14 propaganda techniques. For sub-task 1, we use\ncontextual embeddings extracted from pre-trained transformer models to\nrepresent the text data at various granularities and propose a\nmulti-granularity knowledge sharing approach. For sub-task 2, we use an\nensemble of BERT and logistic regression classifiers with linguistic features.\nOur results reveal that the linguistic features are the strong indicators for\ncovering minority classes in a highly imbalanced dataset.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 19:35:53 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 12:34:38 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Patil", "Rajaswa", ""], ["Singh", "Somesh", ""], ["Agarwal", "Swati", ""]]}, {"id": "2006.00607", "submitter": "Rajaswa Patil", "authors": "Siddhant Mahurkar and Rajaswa Patil", "title": "LRG at SemEval-2020 Task 7: Assessing the Ability of BERT and Derivative\n  Models to Perform Short-Edits based Humor Grading", "comments": "Submitted at SemEval-2020 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we assess the ability of BERT and its derivative models\n(RoBERTa, DistilBERT, and ALBERT) for short-edits based humor grading. We test\nthese models for humor grading and classification tasks on the Humicroedit and\nthe FunLines dataset. We perform extensive experiments with these models to\ntest their language modeling and generalization abilities via zero-shot\ninference and cross-dataset inference based approaches. Further, we also\ninspect the role of self-attention layers in humor-grading by performing a\nqualitative analysis over the self-attention weights from the final layer of\nthe trained BERT model. Our experiments show that all the pre-trained BERT\nderivative models show significant generalization capabilities for\nhumor-grading related tasks.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 20:55:08 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Mahurkar", "Siddhant", ""], ["Patil", "Rajaswa", ""]]}, {"id": "2006.00609", "submitter": "Rajaswa Patil", "authors": "Rajaswa Patil and Veeky Baths", "title": "CNRL at SemEval-2020 Task 5: Modelling Causal Reasoning in Language with\n  Multi-Head Self-Attention Weights based Counterfactual Detection", "comments": "Submitted at SemEval-2020 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe an approach for modelling causal reasoning in\nnatural language by detecting counterfactuals in text using multi-head\nself-attention weights. We use pre-trained transformer models to extract\ncontextual embeddings and self-attention weights from the text. We show the use\nof convolutional layers to extract task-specific features from these\nself-attention weights. Further, we describe a fine-tuning approach with a\ncommon base model for knowledge sharing between the two closely related\nsub-tasks for counterfactual detection. We analyze and compare the performance\nof various transformer models in our experiments. Finally, we perform a\nqualitative analysis with the multi-head self-attention weights to interpret\nour models' dynamics.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 21:02:25 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Patil", "Rajaswa", ""], ["Baths", "Veeky", ""]]}, {"id": "2006.00632", "submitter": "Barbara Plank", "authors": "Alan Ramponi and Barbara Plank", "title": "Neural Unsupervised Domain Adaptation in NLP---A Survey", "comments": "COLING 2020. Accompanying repository:\n  https://github.com/bplank/awesome-neural-adaptation-in-NLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks excel at learning from labeled data and achieve\nstate-of-the-art resultson a wide array of Natural Language Processing tasks.\nIn contrast, learning from unlabeled data, especially under domain shift,\nremains a challenge. Motivated by the latest advances, in this survey we review\nneural unsupervised domain adaptation techniques which do not require labeled\ntarget domain data. This is a more challenging yet a more widely applicable\nsetup. We outline methods, from early traditional non-neural methods to\npre-trained model transfer. We also revisit the notion of domain, and we\nuncover a bias in the type of Natural Language Processing tasks which received\nmost attention. Lastly, we outline future directions, particularly the broader\nneed for out-of-distribution generalization of future NLP.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 22:34:14 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 08:24:14 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Ramponi", "Alan", ""], ["Plank", "Barbara", ""]]}, {"id": "2006.00635", "submitter": "Emily Allaway", "authors": "Emily Allaway and Kathleen McKeown", "title": "A Unified Feature Representation for Lexical Connotations", "comments": "EACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ideological attitudes and stance are often expressed through subtle meanings\nof words and phrases. Understanding these connotations is critical to\nrecognizing the cultural and emotional perspectives of the speaker. In this\npaper, we use distant labeling to create a new lexical resource representing\nconnotation aspects for nouns and adjectives. Our analysis shows that it aligns\nwell with human judgments. Additionally, we present a method for creating\nlexical representations that captures connotations within the embedding space\nand show that using the embeddings provides a statistically significant\nimprovement on the task of stance detection when data is limited.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 23:14:02 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 14:14:21 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Allaway", "Emily", ""], ["McKeown", "Kathleen", ""]]}, {"id": "2006.00671", "submitter": "Somil Gupta", "authors": "Somil Gupta, Bhanu Pratap Singh Rawat, Hong Yu", "title": "Conversational Machine Comprehension: a Literature Review", "comments": "Accepted to COLING 2020", "journal-ref": null, "doi": "10.18653/v1/2020.coling-main.247", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Conversational Machine Comprehension (CMC), a research track in\nconversational AI, expects the machine to understand an open-domain natural\nlanguage text and thereafter engage in a multi-turn conversation to answer\nquestions related to the text. While most of the research in Machine Reading\nComprehension (MRC) revolves around single-turn question answering (QA),\nmulti-turn CMC has recently gained prominence, thanks to the advancement in\nnatural language understanding via neural language models such as BERT and the\nintroduction of large-scale conversational datasets such as CoQA and QuAC. The\nrise in interest has, however, led to a flurry of concurrent publications, each\nwith a different yet structurally similar modeling approach and an inconsistent\nview of the surrounding literature. With the volume of model submissions to\nconversational datasets increasing every year, there exists a need to\nconsolidate the scattered knowledge in this domain to streamline future\nresearch. This literature review attempts at providing a holistic overview of\nCMC with an emphasis on the common trends across recently published models,\nspecifically in their approach to tackling conversational history. The review\nsynthesizes a generic framework for CMC models while highlighting the\ndifferences in recent approaches and intends to serve as a compendium of CMC\nfor future researchers.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 02:20:08 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 06:28:06 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Gupta", "Somil", ""], ["Rawat", "Bhanu Pratap Singh", ""], ["Yu", "Hong", ""]]}, {"id": "2006.00691", "submitter": "Sumeet Kumar", "authors": "Ramon Villa-Cox, Sumeet Kumar, Matthew Babcock, Kathleen M. Carley", "title": "Stance in Replies and Quotes (SRQ): A New Dataset For Learning Stance in\n  Twitter Conversations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated ways to extract stance (denying vs. supporting opinions) from\nconversations on social media are essential to advance opinion mining research.\nRecently, there is a renewed excitement in the field as we see new models\nattempting to improve the state-of-the-art. However, for training and\nevaluating the models, the datasets used are often small. Additionally, these\nsmall datasets have uneven class distributions, i.e., only a tiny fraction of\nthe examples in the dataset have favoring or denying stances, and most other\nexamples have no clear stance. Moreover, the existing datasets do not\ndistinguish between the different types of conversations on social media (e.g.,\nreplying vs. quoting on Twitter). Because of this, models trained on one event\ndo not generalize to other events.\n  In the presented work, we create a new dataset by labeling stance in\nresponses to posts on Twitter (both replies and quotes) on controversial\nissues. To the best of our knowledge, this is currently the largest\nhuman-labeled stance dataset for Twitter conversations with over 5200 stance\nlabels. More importantly, we designed a tweet collection methodology that\nfavors the selection of denial-type responses. This class is expected to be\nmore useful in the identification of rumors and determining antagonistic\nrelationships between users. Moreover, we include many baseline models for\nlearning the stance in conversations and compare the performance of various\nmodels. We show that combining data from replies and quotes decreases the\naccuracy of models indicating that the two modalities behave differently when\nit comes to stance learning.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 03:30:08 GMT"}, {"version": "v2", "created": "Sat, 27 Jun 2020 21:23:20 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Villa-Cox", "Ramon", ""], ["Kumar", "Sumeet", ""], ["Babcock", "Matthew", ""], ["Carley", "Kathleen M.", ""]]}, {"id": "2006.00697", "submitter": "Patricio Cerda-Mardini", "authors": "Patricio Cerda-Mardini, Vladimir Araujo, Alvaro Soto", "title": "Translating Natural Language Instructions for Behavioral Robot\n  Navigation with a Multi-Head Attention Mechanism", "comments": "Accepted at ACL 2020 WiNLP workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a multi-head attention mechanism as a blending layer in a neural\nnetwork model that translates natural language to a high level behavioral\nlanguage for indoor robot navigation. We follow the framework established by\n(Zang et al., 2018a) that proposes the use of a navigation graph as a knowledge\nbase for the task. Our results show significant performance gains when\ntranslating instructions on previously unseen environments, therefore,\nimproving the generalization capabilities of the model.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 03:49:43 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 19:49:53 GMT"}, {"version": "v3", "created": "Sun, 7 Jun 2020 23:00:47 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Cerda-Mardini", "Patricio", ""], ["Araujo", "Vladimir", ""], ["Soto", "Alvaro", ""]]}, {"id": "2006.00703", "submitter": "Chander Chandak", "authors": "Chander Chandak, Zeynab Raeesy, Ariya Rastrow, Yuzong Liu, Xiangyang\n  Huang, Siyu Wang, Dong Kwon Joo, Roland Maas", "title": "Streaming Language Identification using Combination of Acoustic\n  Representations and ASR Hypotheses", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents our modeling and architecture approaches for building a\nhighly accurate low-latency language identification system to support\nmultilingual spoken queries for voice assistants. A common approach to solve\nmultilingual speech recognition is to run multiple monolingual ASR systems in\nparallel and rely on a language identification (LID) component that detects the\ninput language. Conventionally, LID relies on acoustic only information to\ndetect input language. We propose an approach that learns and combines acoustic\nlevel representations with embeddings estimated on ASR hypotheses resulting in\nup to 50% relative reduction of identification error rate, compared to a model\nthat uses acoustic only features. Furthermore, to reduce the processing cost\nand latency, we exploit a streaming architecture to identify the spoken\nlanguage early when the system reaches a predetermined confidence level,\nalleviating the need to run multiple ASR systems until the end of input query.\nThe combined acoustic and text LID, coupled with our proposed streaming runtime\narchitecture, results in an average of 1500ms early identification for more\nthan 50% of utterances, with almost no degradation in accuracy. We also show\nimproved results by adopting a semi-supervised learning (SSL) technique using\nthe newly proposed model architecture as a teacher model.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 04:08:55 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Chandak", "Chander", ""], ["Raeesy", "Zeynab", ""], ["Rastrow", "Ariya", ""], ["Liu", "Yuzong", ""], ["Huang", "Xiangyang", ""], ["Wang", "Siyu", ""], ["Joo", "Dong Kwon", ""], ["Maas", "Roland", ""]]}, {"id": "2006.00707", "submitter": "Emaad Manzoor", "authors": "Emaad Manzoor, George H. Chen, Dokyun Lee, Michael D. Smith", "title": "Influence via Ethos: On the Persuasive Power of Reputation in\n  Deliberation Online", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.CL stat.AP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deliberation among individuals online plays a key role in shaping the\nopinions that drive votes, purchases, donations and other critical offline\nbehavior. Yet, the determinants of opinion-change via persuasion in\ndeliberation online remain largely unexplored. Our research examines the\npersuasive power of $\\textit{ethos}$ -- an individual's \"reputation\" -- using a\n7-year panel of over a million debates from an argumentation platform\ncontaining explicit indicators of successful persuasion. We identify the causal\neffect of reputation on persuasion by constructing an instrument for reputation\nfrom a measure of past debate competition, and by controlling for unstructured\nargument text using neural models of language in the double machine-learning\nframework. We find that an individual's reputation significantly impacts their\npersuasion rate above and beyond the validity, strength and presentation of\ntheir arguments. In our setting, we find that having 10 additional reputation\npoints causes a 31% increase in the probability of successful persuasion over\nthe platform average. We also find that the impact of reputation is moderated\nby characteristics of the argument content, in a manner consistent with a\ntheoretical model that attributes the persuasive power of reputation to\nheuristic information-processing under cognitive overload. We discuss\nmanagerial implications for platforms that facilitate deliberative\ndecision-making for public and private organizations online.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 04:25:40 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Manzoor", "Emaad", ""], ["Chen", "George H.", ""], ["Lee", "Dokyun", ""], ["Smith", "Michael D.", ""]]}, {"id": "2006.00782", "submitter": "Sanket Shah", "authors": "Sanket Shah, Basil Abraham, Gurunath Reddy M, Sunayana Sitaram, Vikas\n  Joshi", "title": "Learning to Recognize Code-switched Speech Without Forgetting\n  Monolingual Speech Recognition", "comments": "5 pages (4 pages + 1 page references), 5 tables, 1 figure, 1\n  algorithm, 16 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been significant progress made in Automatic Speech\nRecognition (ASR) of code-switched speech, leading to gains in accuracy on\ncode-switched datasets in many language pairs. Code-switched speech co-occurs\nwith monolingual speech in one or both languages being mixed. In this work, we\nshow that fine-tuning ASR models on code-switched speech harms performance on\nmonolingual speech. We point out the need to optimize models for code-switching\nwhile also ensuring that monolingual performance is not sacrificed. Monolingual\nmodels may be trained on thousands of hours of speech which may not be\navailable for re-training a new model. We propose using the Learning Without\nForgetting (LWF) framework for code-switched ASR when we only have access to a\nmonolingual model and do not have the data it was trained on. We show that it\nis possible to train models using this framework that perform well on both\ncode-switched and monolingual test sets. In cases where we have access to\nmonolingual training data as well, we propose regularization strategies for\nfine-tuning models for code-switching without sacrificing monolingual accuracy.\nWe report improvements in Word Error Rate (WER) in monolingual and\ncode-switched test sets compared to baselines that use pooled data and simple\nfine-tuning.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 08:16:24 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Shah", "Sanket", ""], ["Abraham", "Basil", ""], ["M", "Gurunath Reddy", ""], ["Sitaram", "Sunayana", ""], ["Joshi", "Vikas", ""]]}, {"id": "2006.00785", "submitter": "Xavier Gir\\'o-i-Nieto", "authors": "Benet Oriol, Jordi Luque, Ferran Diego and Xavier Giro-i-Nieto", "title": "Transcription-Enriched Joint Embeddings for Spoken Descriptions of\n  Images and Videos", "comments": "Accepted for presentation at EPIC@CVPR2020 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.IR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose an effective approach for training unique embedding\nrepresentations by combining three simultaneous modalities: image and spoken\nand textual narratives. The proposed methodology departs from a baseline system\nthat spawns a embedding space trained with only spoken narratives and image\ncues. Our experiments on the EPIC-Kitchen and Places Audio Caption datasets\nshow that introducing the human-generated textual transcriptions of the spoken\nnarratives helps to the training procedure yielding to get better embedding\nrepresentations. The triad speech, image and words allows for a better estimate\nof the point embedding and show an improving of the performance within tasks\nlike image and speech retrieval, even when text third modality, text, is not\npresent in the task.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 08:18:15 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Oriol", "Benet", ""], ["Luque", "Jordi", ""], ["Diego", "Ferran", ""], ["Giro-i-Nieto", "Xavier", ""]]}, {"id": "2006.00804", "submitter": "Mohammed Emtiaz Ahmed", "authors": "Mohammed Emtiaz Ahmed, Md Rafiqul Islam Rabin, Farah Naz Chowdhury", "title": "COVID-19: Social Media Sentiment Analysis on Reopening", "comments": "8 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The novel coronavirus (COVID-19) pandemic is the most talked topic in social\nmedia platforms in 2020. People are using social media such as Twitter to\nexpress their opinion and share information on a number of issues related to\nthe COVID-19 in this stay at home order. In this paper, we investigate the\nsentiment and emotion of peoples in the United States on the subject of\nreopening. We choose the social media platform Twitter for our analysis and\nstudy the Tweets to discover the sentimental perspective, emotional\nperspective, and triggering words towards the reopening. During this COVID-19\npandemic, researchers have made some analysis on various social media dataset\nregarding lockdown and stay at home. However, in our analysis, we are\nparticularly interested to analyse public sentiment on reopening. Our major\nfinding is that when all states resorted to lockdown in March, people showed\ndominant emotion of fear, but as reopening starts people have less fear. While\nthis may be true, due to this reopening phase daily positive cases are rising\ncompared to the lockdown situation. Overall, people have a less negative\nsentiment towards the situation of reopening.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 09:15:02 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Ahmed", "Mohammed Emtiaz", ""], ["Rabin", "Md Rafiqul Islam", ""], ["Chowdhury", "Farah Naz", ""]]}, {"id": "2006.00814", "submitter": "Maha Elbayad", "authors": "Maha Elbayad, Michael Ustaszewski, Emmanuelle Esperan\\c{c}a-Rodier,\n  Francis Brunet Manquat, Jakob Verbeek, Laurent Besacier", "title": "Online Versus Offline NMT Quality: An In-depth Analysis on\n  English-German and German-English", "comments": "Accepted at COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conduct in this work an evaluation study comparing offline and online\nneural machine translation architectures. Two sequence-to-sequence models:\nconvolutional Pervasive Attention (Elbayad et al. 2018) and attention-based\nTransformer (Vaswani et al. 2017) are considered. We investigate, for both\narchitectures, the impact of online decoding constraints on the translation\nquality through a carefully designed human evaluation on English-German and\nGerman-English language pairs, the latter being particularly sensitive to\nlatency constraints. The evaluation results allow us to identify the strengths\nand shortcomings of each model when we shift to the online setup.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 09:43:54 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 13:36:00 GMT"}, {"version": "v3", "created": "Tue, 24 Nov 2020 09:10:30 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Elbayad", "Maha", ""], ["Ustaszewski", "Michael", ""], ["Esperan\u00e7a-Rodier", "Emmanuelle", ""], ["Manquat", "Francis Brunet", ""], ["Verbeek", "Jakob", ""], ["Besacier", "Laurent", ""]]}, {"id": "2006.00838", "submitter": "Mark Anderson", "authors": "Mathieu Dehouck, Mark Anderson and Carlos G\\'omez-Rodr\\'iguez", "title": "Efficient EUD Parsing", "comments": "To published in the proceedings of the IWPT 2020 Shared Task on\n  Parsing into Enhanced Universal Dependencies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the system submission from the FASTPARSE team for the EUD Shared\nTask at IWPT 2020. We engaged with the task by focusing on efficiency. For this\nwe considered training costs and inference efficiency. Our models are a\ncombination of distilled neural dependency parsers and a rule-based system that\nprojects UD trees into EUD graphs. We obtained an average ELAS of 74.04 for our\nofficial submission, ranking 4th overall.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 10:31:56 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Dehouck", "Mathieu", ""], ["Anderson", "Mark", ""], ["G\u00f3mez-Rodr\u00edguez", "Carlos", ""]]}, {"id": "2006.00843", "submitter": "Anne Lauscher", "authors": "Anne Lauscher, Lily Ng, Courtney Napoles, Joel Tetreault", "title": "Rhetoric, Logic, and Dialectic: Advancing Theory-based Argument Quality\n  Assessment in Natural Language Processing", "comments": "accepted for COLING 20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though preceding work in computational argument quality (AQ) mostly focuses\non assessing overall AQ, researchers agree that writers would benefit from\nfeedback targeting individual dimensions of argumentation theory. However, a\nlarge-scale theory-based corpus and corresponding computational models are\nmissing. We fill this gap by conducting an extensive analysis covering three\ndiverse domains of online argumentative writing and presenting GAQCorpus: the\nfirst large-scale English multi-domain (community Q&A forums, debate forums,\nreview forums) corpus annotated with theory-based AQ scores. We then propose\nthe first computational approaches to theory-based assessment, which can serve\nas strong baselines for future work. We demonstrate the feasibility of\nlarge-scale AQ annotation, show that exploiting relations between dimensions\nyields performance improvements, and explore the synergies between theory-based\nprediction and practical AQ assessment.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 10:39:50 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 09:26:07 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Lauscher", "Anne", ""], ["Ng", "Lily", ""], ["Napoles", "Courtney", ""], ["Tetreault", "Joel", ""]]}, {"id": "2006.00844", "submitter": "Mark Anderson", "authors": "Mark Anderson, Carlos G\\'omez-Rodr\\'iguez", "title": "Distilling Neural Networks for Greener and Faster Dependency Parsing", "comments": "To be published in proceedings of the 16th International Conference\n  on Parsing Technologies. Earlier versions were rejected at the 58th Annual\n  Conference of the Association for Computational Linguistics and 8th\n  International Conference on Learning Representations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The carbon footprint of natural language processing research has been\nincreasing in recent years due to its reliance on large and inefficient neural\nnetwork implementations. Distillation is a network compression technique which\nattempts to impart knowledge from a large model to a smaller one. We use\nteacher-student distillation to improve the efficiency of the Biaffine\ndependency parser which obtains state-of-the-art performance with respect to\naccuracy and parsing speed (Dozat and Manning, 2017). When distilling to 20\\%\nof the original model's trainable parameters, we only observe an average\ndecrease of $\\sim$1 point for both UAS and LAS across a number of diverse\nUniversal Dependency treebanks while being 2.30x (1.19x) faster than the\nbaseline model on CPU (GPU) at inference time. We also observe a small increase\nin performance when compressing to 80\\% for some treebanks. Finally, through\ndistillation we attain a parser which is not only faster but also more accurate\nthan the fastest modern parser on the Penn Treebank.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 10:43:53 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Anderson", "Mark", ""], ["G\u00f3mez-Rodr\u00edguez", "Carlos", ""]]}, {"id": "2006.00850", "submitter": "Kartikey Pant", "authors": "Kartikey Pant and Tanvi Dadu", "title": "Sarcasm Detection using Context Separators in Online Discourse", "comments": "Accepted at FigLang 2020 workshop to be held at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sarcasm is an intricate form of speech, where meaning is conveyed implicitly.\nBeing a convoluted form of expression, detecting sarcasm is an assiduous\nproblem. The difficulty in recognition of sarcasm has many pitfalls, including\nmisunderstandings in everyday communications, which leads us to an increasing\nfocus on automated sarcasm detection. In the second edition of the Figurative\nLanguage Processing (FigLang 2020) workshop, the shared task of sarcasm\ndetection released two datasets, containing responses along with their context\nsampled from Twitter and Reddit.\n  In this work, we use RoBERTa_large to detect sarcasm in both the datasets. We\nfurther assert the importance of context in improving the performance of\ncontextual word embedding based models by using three different types of inputs\n- Response-only, Context-Response, and Context-Response (Separated). We show\nthat our proposed architecture performs competitively for both the datasets. We\nalso show that the addition of a separation token between context and target\nresponse results in an improvement of 5.13% in the F1-score in the Reddit\ndataset.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 10:52:35 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Pant", "Kartikey", ""], ["Dadu", "Tanvi", ""]]}, {"id": "2006.00885", "submitter": "Limeng Cui", "authors": "Limeng Cui, Dongwon Lee", "title": "CoAID: COVID-19 Healthcare Misinformation Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the COVID-19 virus quickly spreads around the world, unfortunately,\nmisinformation related to COVID-19 also gets created and spreads like wild\nfire. Such misinformation has caused confusion among people, disruptions in\nsociety, and even deadly consequences in health problems. To be able to\nunderstand, detect, and mitigate such COVID-19 misinformation, therefore, has\nnot only deep intellectual values but also huge societal impacts. To help\nresearchers combat COVID-19 health misinformation, therefore, we present CoAID\n(Covid-19 heAlthcare mIsinformation Dataset), with diverse COVID-19 healthcare\nmisinformation, including fake news on websites and social platforms, along\nwith users' social engagement about such news. CoAID includes 4,251 news,\n296,000 related user engagements, 926 social platform posts about COVID-19, and\nground truth labels. The dataset is available at:\nhttps://github.com/cuilimeng/CoAID.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 19:08:14 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 00:27:59 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2020 20:37:11 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Cui", "Limeng", ""], ["Lee", "Dongwon", ""]]}, {"id": "2006.00987", "submitter": "Aritra Sarkar", "authors": "Aritra Sarkar, Zaid Al-Ars, Koen Bertels", "title": "Quantum Accelerated Estimation of Algorithmic Information", "comments": "31 pages, pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CL cs.ET cs.IT math.IT", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this research we present a quantum circuit for estimating algorithmic\ninformation metrics like the universal prior distribution. This accelerates\ninferring algorithmic structure in data for discovering causal generative\nmodels. The computation model is restricted in time and space resources to make\nit computable in approximating the target metrics. A classical exhaustive\nenumeration is shown for a few examples. The precise quantum circuit design\nthat allows executing a superposition of automata is presented. As a use-case,\nan application framework for experimenting on DNA sequences for meta-biology is\nproposed. To our knowledge, this is the first time approximating algorithmic\ninformation is implemented for quantum computation. Our implementation on the\nOpenQL quantum programming language and the QX Simulator is copy-left and can\nbe found on https://github.com/Advanced-Research-Centre/QuBio.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 14:47:28 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Sarkar", "Aritra", ""], ["Al-Ars", "Zaid", ""], ["Bertels", "Koen", ""]]}, {"id": "2006.00988", "submitter": "Shashank Sonkar", "authors": "Shashank Sonkar, Andrew E. Waters, Richard G. Baraniuk", "title": "Attention Word Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embedding models learn semantically rich vector representations of words\nand are widely used to initialize natural processing language (NLP) models. The\npopular continuous bag-of-words (CBOW) model of word2vec learns a vector\nembedding by masking a given word in a sentence and then using the other words\nas a context to predict it. A limitation of CBOW is that it equally weights the\ncontext words when making a prediction, which is inefficient, since some words\nhave higher predictive value than others. We tackle this inefficiency by\nintroducing the Attention Word Embedding (AWE) model, which integrates the\nattention mechanism into the CBOW model. We also propose AWE-S, which\nincorporates subword information. We demonstrate that AWE and AWE-S outperform\nthe state-of-the-art word embedding models both on a variety of word similarity\ndatasets and when used for initialization of NLP models.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 14:47:48 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Sonkar", "Shashank", ""], ["Waters", "Andrew E.", ""], ["Baraniuk", "Richard G.", ""]]}, {"id": "2006.00995", "submitter": "Yanai Elazar", "authors": "Yanai Elazar, Shauli Ravfogel, Alon Jacovi, Yoav Goldberg", "title": "Amnesic Probing: Behavioral Explanation with Amnesic Counterfactuals", "comments": "TACL journal. Initial title was: \"When Bert Forgets How To POS:\n  Amnesic Probing of Linguistic Properties and MLM Predictions\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A growing body of work makes use of probing to investigate the working of\nneural models, often considered black boxes. Recently, an ongoing debate\nemerged surrounding the limitations of the probing paradigm. In this work, we\npoint out the inability to infer behavioral conclusions from probing results\nand offer an alternative method that focuses on how the information is being\nused, rather than on what information is encoded. Our method, Amnesic Probing,\nfollows the intuition that the utility of a property for a given task can be\nassessed by measuring the influence of a causal intervention that removes it\nfrom the representation. Equipped with this new analysis tool, we can ask\nquestions that were not possible before, e.g. is part-of-speech information\nimportant for word prediction? We perform a series of analyses on BERT to\nanswer these types of questions. Our findings demonstrate that conventional\nprobing performance is not correlated to task importance, and we call for\nincreased scrutiny of claims that draw behavioral or causal conclusions from\nprobing results.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 15:00:11 GMT"}, {"version": "v2", "created": "Sat, 5 Dec 2020 22:21:10 GMT"}, {"version": "v3", "created": "Fri, 19 Feb 2021 09:01:59 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Elazar", "Yanai", ""], ["Ravfogel", "Shauli", ""], ["Jacovi", "Alon", ""], ["Goldberg", "Yoav", ""]]}, {"id": "2006.00998", "submitter": "John Pavlopoulos", "authors": "John Pavlopoulos and Jeffrey Sorensen and Lucas Dixon and Nithum Thain\n  and Ion Androutsopoulos", "title": "Toxicity Detection: Does Context Really Matter?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Moderation is crucial to promoting healthy on-line discussions. Although\nseveral `toxicity' detection datasets and models have been published, most of\nthem ignore the context of the posts, implicitly assuming that comments maybe\njudged independently. We investigate this assumption by focusing on two\nquestions: (a) does context affect the human judgement, and (b) does\nconditioning on context improve performance of toxicity detection systems? We\nexperiment with Wikipedia conversations, limiting the notion of context to the\nprevious post in the thread and the discussion title. We find that context can\nboth amplify or mitigate the perceived toxicity of posts. Moreover, a small but\nsignificant subset of manually labeled posts (5% in one of our experiments) end\nup having the opposite toxicity labels if the annotators are not provided with\ncontext. Surprisingly, we also find no evidence that context actually improves\nthe performance of toxicity classifiers, having tried a range of classifiers\nand mechanisms to make them context aware. This points to the need for larger\ndatasets of comments annotated in context. We make our code and data publicly\navailable.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 15:03:48 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Pavlopoulos", "John", ""], ["Sorensen", "Jeffrey", ""], ["Dixon", "Lucas", ""], ["Thain", "Nithum", ""], ["Androutsopoulos", "Ion", ""]]}, {"id": "2006.00999", "submitter": "Mihaela Duta", "authors": "Mihaela Duta and Kim Plunkett", "title": "A Neural Network Model of Lexical Competition during Infant Spoken Word\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual world studies show that upon hearing a word in a target-absent visual\ncontext containing related and unrelated items, toddlers and adults briefly\ndirect their gaze towards phonologically related items, before shifting towards\nsemantically and visually related ones. We present a neural network model that\nprocesses dynamic unfolding phonological representations and maps them to\nstatic internal semantic and visual representations. The model, trained on\nrepresentations derived from real corpora, simulates this early phonological\nover semantic/visual preference. Our results support the hypothesis that\nincremental unfolding of a spoken word is in itself sufficient to account for\nthe transient preference for phonological competitors over both unrelated and\nsemantically and visually related ones. Phonological representations mapped\ndynamically in a bottom-up fashion to semantic-visual representations capture\nthe early phonological preference effects reported in a visual world task. The\nsemantic-visual preference observed later in such a trial does not require\ntop-down feedback from a semantic or visual system.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 15:04:11 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Duta", "Mihaela", ""], ["Plunkett", "Kim", ""]]}, {"id": "2006.01016", "submitter": "Federico Carnevale", "authors": "Abhishek Das, Federico Carnevale, Hamza Merzic, Laura Rimell, Rosalia\n  Schneider, Josh Abramson, Alden Hung, Arun Ahuja, Stephen Clark, Gregory\n  Wayne, Felix Hill", "title": "Probing Emergent Semantics in Predictive Agents via Question Answering", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown how predictive modeling can endow agents with rich\nknowledge of their surroundings, improving their ability to act in complex\nenvironments. We propose question-answering as a general paradigm to decode and\nunderstand the representations that such agents develop, applying our method to\ntwo recent approaches to predictive modeling -action-conditional CPC (Guo et\nal., 2018) and SimCore (Gregor et al., 2019). After training agents with these\npredictive objectives in a visually-rich, 3D environment with an assortment of\nobjects, colors, shapes, and spatial configurations, we probe their internal\nstate representations with synthetic (English) questions, without\nbackpropagating gradients from the question-answering decoder into the agent.\nThe performance of different agents when probed this way reveals that they\nlearn to encode factual, and seemingly compositional, information about\nobjects, properties and spatial relations from their physical environment. Our\napproach is intuitive, i.e. humans can easily interpret responses of the model\nas opposed to inspecting continuous vectors, and model-agnostic, i.e.\napplicable to any modeling approach. By revealing the implicit knowledge of\nobjects, quantities, properties and relations acquired by agents as they learn,\nquestion-conditional agent probing can stimulate the design and development of\nstronger predictive learning objectives.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 15:27:36 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Das", "Abhishek", ""], ["Carnevale", "Federico", ""], ["Merzic", "Hamza", ""], ["Rimell", "Laura", ""], ["Schneider", "Rosalia", ""], ["Abramson", "Josh", ""], ["Hung", "Alden", ""], ["Ahuja", "Arun", ""], ["Clark", "Stephen", ""], ["Wayne", "Gregory", ""], ["Hill", "Felix", ""]]}, {"id": "2006.01038", "submitter": "Lei Cui", "authors": "Minghao Li, Yiheng Xu, Lei Cui, Shaohan Huang, Furu Wei, Zhoujun Li,\n  Ming Zhou", "title": "DocBank: A Benchmark Dataset for Document Layout Analysis", "comments": "COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Document layout analysis usually relies on computer vision models to\nunderstand documents while ignoring textual information that is vital to\ncapture. Meanwhile, high quality labeled datasets with both visual and textual\ninformation are still insufficient. In this paper, we present \\textbf{DocBank},\na benchmark dataset that contains 500K document pages with fine-grained\ntoken-level annotations for document layout analysis. DocBank is constructed\nusing a simple yet effective way with weak supervision from the \\LaTeX{}\ndocuments available on the arXiv.com. With DocBank, models from different\nmodalities can be compared fairly and multi-modal approaches will be further\ninvestigated and boost the performance of document layout analysis. We build\nseveral strong baselines and manually split train/dev/test sets for evaluation.\nExperiment results show that models trained on DocBank accurately recognize the\nlayout information for a variety of documents. The DocBank dataset is publicly\navailable at \\url{https://github.com/doc-analysis/DocBank}.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 16:04:30 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 08:05:48 GMT"}, {"version": "v3", "created": "Wed, 11 Nov 2020 05:08:05 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Li", "Minghao", ""], ["Xu", "Yiheng", ""], ["Cui", "Lei", ""], ["Huang", "Shaohan", ""], ["Wei", "Furu", ""], ["Li", "Zhoujun", ""], ["Zhou", "Ming", ""]]}, {"id": "2006.01067", "submitter": "Alon Jacovi", "authors": "Alon Jacovi, Yoav Goldberg", "title": "Aligning Faithful Interpretations with their Social Attribution", "comments": "Accepted as a journal paper to TACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We find that the requirement of model interpretations to be faithful is vague\nand incomplete. With interpretation by textual highlights as a case-study, we\npresent several failure cases. Borrowing concepts from social science, we\nidentify that the problem is a misalignment between the causal chain of\ndecisions (causal attribution) and the attribution of human behavior to the\ninterpretation (social attribution). We re-formulate faithfulness as an\naccurate attribution of causality to the model, and introduce the concept of\naligned faithfulness: faithful causal chains that are aligned with their\nexpected social behavior. The two steps of causal attribution and social\nattribution together complete the process of explaining behavior. With this\nformalization, we characterize various failures of misaligned faithful\nhighlight interpretations, and propose an alternative causal chain to remedy\nthe issues. Finally, we implement highlight explanations of the proposed causal\nformat using contrastive explanations.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 16:45:38 GMT"}, {"version": "v2", "created": "Sun, 3 Jan 2021 00:45:44 GMT"}, {"version": "v3", "created": "Thu, 14 Jan 2021 18:54:01 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Jacovi", "Alon", ""], ["Goldberg", "Yoav", ""]]}, {"id": "2006.01080", "submitter": "Alina Karakanta", "authors": "Alina Karakanta, Matteo Negri, Marco Turchi", "title": "Is 42 the Answer to Everything in Subtitling-oriented Speech\n  Translation?", "comments": "Accepted at IWSLT 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subtitling is becoming increasingly important for disseminating information,\ngiven the enormous amounts of audiovisual content becoming available daily.\nAlthough Neural Machine Translation (NMT) can speed up the process of\ntranslating audiovisual content, large manual effort is still required for\ntranscribing the source language, and for spotting and segmenting the text into\nproper subtitles. Creating proper subtitles in terms of timing and segmentation\nhighly depends on information present in the audio (utterance duration, natural\npauses). In this work, we explore two methods for applying Speech Translation\n(ST) to subtitling: a) a direct end-to-end and b) a classical cascade approach.\nWe discuss the benefit of having access to the source language speech for\nimproving the conformity of the generated subtitles to the spatial and temporal\nsubtitling constraints and show that length is not the answer to everything in\nthe case of subtitling-oriented ST.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 17:02:28 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Karakanta", "Alina", ""], ["Negri", "Matteo", ""], ["Turchi", "Marco", ""]]}, {"id": "2006.01095", "submitter": "SueYeon Chung", "authors": "Jonathan Mamou, Hang Le, Miguel Del Rio, Cory Stephenson, Hanlin Tang,\n  Yoon Kim, SueYeon Chung", "title": "Emergence of Separable Manifolds in Deep Language Representations", "comments": "9 pages. 10 figures. Accepted to ICML 2020. Included supplemental\n  materials", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have shown much empirical success in solving\nperceptual tasks across various cognitive modalities. While they are only\nloosely inspired by the biological brain, recent studies report considerable\nsimilarities between representations extracted from task-optimized DNNs and\nneural populations in the brain. DNNs have subsequently become a popular model\nclass to infer computational principles underlying complex cognitive functions,\nand in turn, they have also emerged as a natural testbed for applying methods\noriginally developed to probe information in neural populations. In this work,\nwe utilize mean-field theoretic manifold analysis, a recent technique from\ncomputational neuroscience that connects geometry of feature representations\nwith linear separability of classes, to analyze language representations from\nlarge-scale contextual embedding models. We explore representations from\ndifferent model families (BERT, RoBERTa, GPT, etc.) and find evidence for\nemergence of linguistic manifolds across layer depth (e.g., manifolds for\npart-of-speech tags), especially in ambiguous data (i.e, words with multiple\npart-of-speech tags, or part-of-speech classes including many words). In\naddition, we find that the emergence of linear separability in these manifolds\nis driven by a combined reduction of manifolds' radius, dimensionality and\ninter-manifold correlations.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 17:23:44 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 21:45:07 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2020 20:56:06 GMT"}, {"version": "v4", "created": "Wed, 8 Jul 2020 22:10:19 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Mamou", "Jonathan", ""], ["Le", "Hang", ""], ["Del Rio", "Miguel", ""], ["Stephenson", "Cory", ""], ["Tang", "Hanlin", ""], ["Kim", "Yoon", ""], ["Chung", "SueYeon", ""]]}, {"id": "2006.01110", "submitter": "Yen-Ling Kuo", "authors": "Yen-Ling Kuo, Boris Katz, Andrei Barbu", "title": "Encoding formulas as deep networks: Reinforcement learning for zero-shot\n  execution of LTL formulas", "comments": "Accepted in IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate a reinforcement learning agent which uses a compositional\nrecurrent neural network that takes as input an LTL formula and determines\nsatisfying actions. The input LTL formulas have never been seen before, yet the\nnetwork performs zero-shot generalization to satisfy them. This is a novel form\nof multi-task learning for RL agents where agents learn from one diverse set of\ntasks and generalize to a new set of diverse tasks. The formulation of the\nnetwork enables this capacity to generalize. We demonstrate this ability in two\ndomains. In a symbolic domain, the agent finds a sequence of letters that is\naccepted. In a Minecraft-like environment, the agent finds a sequence of\nactions that conform to the formula. While prior work could learn to execute\none formula reliably given examples of that formula, we demonstrate how to\nencode all formulas reliably. This could form the basis of new multitask agents\nthat discover sub-tasks and execute them without any additional training, as\nwell as the agents which follow more complex linguistic commands. The\nstructures required for this generalization are specific to LTL formulas, which\nopens up an interesting theoretical question: what structures are required in\nneural networks for zero-shot generalization to different logics?\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 17:50:20 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2020 16:32:02 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Kuo", "Yen-Ling", ""], ["Katz", "Boris", ""], ["Barbu", "Andrei", ""]]}, {"id": "2006.01112", "submitter": "Yuntian Deng", "authors": "Yuntian Deng, Alexander M. Rush", "title": "Cascaded Text Generation with Markov Transformers", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The two dominant approaches to neural text generation are fully\nautoregressive models, using serial beam search decoding, and\nnon-autoregressive models, using parallel decoding with no output dependencies.\nThis work proposes an autoregressive model with sub-linear parallel time\ngeneration. Noting that conditional random fields with bounded context can be\ndecoded in parallel, we propose an efficient cascaded decoding approach for\ngenerating high-quality output. To parameterize this cascade, we introduce a\nMarkov transformer, a variant of the popular fully autoregressive model that\nallows us to simultaneously decode with specific autoregressive context\ncutoffs. This approach requires only a small modification from standard\nautoregressive training, while showing competitive accuracy/speed tradeoff\ncompared to existing methods on five machine translation datasets.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 17:52:15 GMT"}, {"version": "v2", "created": "Sat, 5 Dec 2020 05:26:19 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Deng", "Yuntian", ""], ["Rush", "Alexander M.", ""]]}, {"id": "2006.01117", "submitter": "Joshua Bambrick", "authors": "Joshua Bambrick, Minjie Xu, Andy Almonte, Igor Malioutov, Guim\n  Perarnau, Vittorio Selo and Iat Chong Chan", "title": "NSTM: Real-Time Query-Driven News Overview Composition at Bloomberg", "comments": "To be presented at ACL 2020 (System Demonstration track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millions of news articles from hundreds of thousands of sources around the\nglobe appear in news aggregators every day. Consuming such a volume of news\npresents an almost insurmountable challenge. For example, a reader searching on\nBloomberg's system for news about the U.K. would find 10,000 articles on a\ntypical day. Apple Inc., the world's most journalistically covered company,\ngarners around 1,800 news articles a day.\n  We realized that a new kind of summarization engine was needed, one that\nwould condense large volumes of news into short, easy to absorb points. The\nsystem would filter out noise and duplicates to identify and summarize key news\nabout companies, countries or markets.\n  When given a user query, Bloomberg's solution, Key News Themes (or NSTM),\nleverages state-of-the-art semantic clustering techniques and novel\nsummarization methods to produce comprehensive, yet concise, digests to\ndramatically simplify the news consumption process.\n  NSTM is available to hundreds of thousands of readers around the world and\nserves thousands of requests daily with sub-second latency. At ACL 2020, we\nwill present a demo of NSTM.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 17:58:57 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Bambrick", "Joshua", ""], ["Xu", "Minjie", ""], ["Almonte", "Andy", ""], ["Malioutov", "Igor", ""], ["Perarnau", "Guim", ""], ["Selo", "Vittorio", ""], ["Chan", "Iat Chong", ""]]}, {"id": "2006.01131", "submitter": "Saif M. Mohammad Dr.", "authors": "Saif M. Mohammad", "title": "NLP Scholar: An Interactive Visual Explorer for Natural Language\n  Processing Literature", "comments": "arXiv admin note: text overlap with arXiv:2005.00912", "journal-ref": "Proceedings of the 58th Annual Meeting of the Association of\n  Computational Linguistics (ACL-2020), July 2020", "doi": null, "report-no": null, "categories": "cs.DL cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As part of the NLP Scholar project, we created a single unified dataset of\nNLP papers and their meta-information (including citation numbers), by\nextracting and aligning information from the ACL Anthology and Google Scholar.\nIn this paper, we describe several interconnected interactive visualizations\n(dashboards) that present various aspects of the data. Clicking on an item\nwithin a visualization or entering query terms in the search boxes filters the\ndata in all visualizations in the dashboard. This allows users to search for\npapers in the area of their interest, published within specific time periods,\npublished by specified authors, etc. The interactive visualizations presented\nhere, and the associated dataset of papers mapped to citations, have additional\nuses as well including understanding how the field is growing (both overall and\nacross sub-areas), as well as quantifying the impact of different types of\npapers on subsequent publications.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 17:12:37 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Mohammad", "Saif M.", ""]]}, {"id": "2006.01175", "submitter": "Rob van der Goot", "authors": "Rob van der Goot, \\\"Ozlem \\c{C}etino\\u{g}lu", "title": "Lexical Normalization for Code-switched Data and its Effect on\n  POS-tagging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lexical normalization, the translation of non-canonical data to standard\nlanguage, has shown to improve the performance of manynatural language\nprocessing tasks on social media. Yet, using multiple languages in one\nutterance, also called code-switching (CS), is frequently overlooked by these\nnormalization systems, despite its common use in social media. In this paper,\nwe propose three normalization models specifically designed to handle\ncode-switched data which we evaluate for two language pairs: Indonesian-English\n(Id-En) and Turkish-German (Tr-De). For the latter, we introduce novel\nnormalization layers and their corresponding language ID and POS tags for the\ndataset, and evaluate the downstream effect of normalization on POS tagging.\nResults show that our CS-tailored normalization models outperform Id-En state\nof the art and Tr-De monolingual models, and lead to 5.4% relative performance\nincrease for POS tagging as compared to unnormalized input.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 18:07:15 GMT"}, {"version": "v2", "created": "Sun, 31 Jan 2021 20:57:52 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["van der Goot", "Rob", ""], ["\u00c7etino\u011flu", "\u00d6zlem", ""]]}, {"id": "2006.01189", "submitter": "Shi-Yan Weng", "authors": "Shi-Yan Weng, Tien-Hong Lo, Berlin Chen", "title": "An Effective Contextual Language Modeling Framework for Speech\n  Summarization with Augmented Features", "comments": "Accepted by EUSIPCO 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tremendous amounts of multimedia associated with speech information are\ndriving an urgent need to develop efficient and effective automatic\nsummarization methods. To this end, we have seen rapid progress in applying\nsupervised deep neural network-based methods to extractive speech\nsummarization. More recently, the Bidirectional Encoder Representations from\nTransformers (BERT) model was proposed and has achieved record-breaking success\non many natural language processing (NLP) tasks such as question answering and\nlanguage understanding. In view of this, we in this paper contextualize and\nenhance the state-of-the-art BERT-based model for speech summarization, while\nits contributions are at least three-fold. First, we explore the incorporation\nof confidence scores into sentence representations to see if such an attempt\ncould help alleviate the negative effects caused by imperfect automatic speech\nrecognition (ASR). Secondly, we also augment the sentence embeddings obtained\nfrom BERT with extra structural and linguistic features, such as sentence\nposition and inverse document frequency (IDF) statistics. Finally, we validate\nthe effectiveness of our proposed method on a benchmark dataset, in comparison\nto several classic and celebrated speech summarization methods.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 18:27:48 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Weng", "Shi-Yan", ""], ["Lo", "Tien-Hong", ""], ["Chen", "Berlin", ""]]}, {"id": "2006.01203", "submitter": "Satanik Mitra", "authors": "Satanik Mitra and Mamata Jenamani", "title": "Hybrid Improved Document-level Embedding (HIDE)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent times, word embeddings are taking a significant role in sentiment\nanalysis. As the generation of word embeddings needs huge corpora, many\napplications use pretrained embeddings. In spite of the success, word\nembeddings suffers from certain drawbacks such as it does not capture sentiment\ninformation of a word, contextual information in terms of parts of speech tags\nand domain-specific information. In this work we propose HIDE a Hybrid Improved\nDocument level Embedding which incorporates domain information, parts of speech\ninformation and sentiment information into existing word embeddings such as\nGloVe and Word2Vec. It combine improved word embeddings into document level\nembeddings. Further, Latent Semantic Analysis (LSA) has been used to represent\ndocuments as a vectors. HIDE is generated, combining LSA and document level\nembeddings, which is computed from improved word embeddings. We test HIDE with\nsix different datasets and shown considerable improvement over the accuracy of\nexisting pretrained word vectors such as GloVe and Word2Vec. We further compare\nour work with two existing document level sentiment analysis approaches. HIDE\nperforms better than existing systems.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 19:09:13 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Mitra", "Satanik", ""], ["Jenamani", "Mamata", ""]]}, {"id": "2006.01204", "submitter": "Zitao Liu", "authors": "Shiting Xu, Wenbiao Ding, Zitao Liu", "title": "Automatic Dialogic Instruction Detection for K-12 Online One-on-one\n  Classes", "comments": "The 21th International Conference on Artificial Intelligence in\n  Education(AIED), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online one-on-one class is created for highly interactive and immersive\nlearning experience. It demands a large number of qualified online instructors.\nIn this work, we develop six dialogic instructions and help teachers achieve\nthe benefits of one-on-one learning paradigm. Moreover, we utilize neural\nlanguage models, i.e., long short-term memory (LSTM), to detect above six\ninstructions automatically. Experiments demonstrate that the LSTM approach\nachieves AUC scores from 0.840 to 0.979 among all six types of instructions on\nour real-world educational dataset.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 01:55:31 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Xu", "Shiting", ""], ["Ding", "Wenbiao", ""], ["Liu", "Zitao", ""]]}, {"id": "2006.01205", "submitter": "Sirwe Saeedi", "authors": "Sirwe Saeedi, Aliakbar Panahi, Seyran Saeedi, Alvis C Fong", "title": "CS-NLP team at SemEval-2020 Task 4: Evaluation of State-of-the-art NLP\n  Deep Learning Architectures on Commonsense Reasoning Task", "comments": "6 pages, 1 figure, 2 tables, SemEval -2020, Commonsense Reasoning and\n  Natural Language Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate a commonsense inference task that unifies\nnatural language understanding and commonsense reasoning. We describe our\nattempt at SemEval-2020 Task 4 competition: Commonsense Validation and\nExplanation (ComVE) challenge. We discuss several state-of-the-art deep\nlearning architectures for this challenge. Our system uses prepared labeled\ntextual datasets that were manually curated for three different natural\nlanguage inference subtasks. The goal of the first subtask is to test whether a\nmodel can distinguish between natural language statements that make sense and\nthose that do not make sense. We compare the performance of several language\nmodels and fine-tuned classifiers. Then, we propose a method inspired by\nquestion/answering tasks to treat a classification problem as a multiple choice\nquestion task to boost the performance of our experimental results (96.06%),\nwhich is significantly better than the baseline. For the second subtask, which\nis to select the reason why a statement does not make sense, we stand within\nthe first six teams (93.7%) among 27 participants with very competitive\nresults. Our result for last subtask of generating reason against the nonsense\nstatement shows many potentials for future researches as we applied the most\npowerful generative model of language (GPT-2) with 6.1732 BLEU score among\nfirst four teams.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 13:20:10 GMT"}, {"version": "v2", "created": "Sat, 18 Jul 2020 15:19:20 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Saeedi", "Sirwe", ""], ["Panahi", "Aliakbar", ""], ["Saeedi", "Seyran", ""], ["Fong", "Alvis C", ""]]}, {"id": "2006.01206", "submitter": "Or Haim Anidjar", "authors": "O. H. Anidjar, C. Hajaj, A. Dvir, I. Gilad", "title": "A Thousand Words are Worth More Than One Recording: NLP Based Speaker\n  Change Point Detection", "comments": "30 pages, 8 Figures, and 6 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker Diarization (SD) consists of splitting or segmenting an input audio\nburst according to speaker identities. In this paper, we focus on the crucial\ntask of the SD problem which is the audio segmenting process and suggest a\nsolution for the Change Point Detection (CPD) problem. We empirically\ndemonstrate the negative correlation between an increase in the number of\nspeakers and the Recall and F1-Score measurements. This negative correlation is\nshown to be the outcome of a massive experimental evaluation process, which\naccounts its superiority to recently developed voice based solutions. In order\nto overcome the number of speakers issue, we suggest a robust solution based on\na novel Natural Language Processing (NLP) technique, as well as a metadata\nfeatures extraction process, rather than a vocal based alone. To the best of\nour knowledge, we are the first to propose an intelligent NLP based solution\nthat (I) tackles the CPD problem with a dataset in Hebrew, and (II) solves the\nCPD variant of the SD problem. We empirically show, based on two distinct\ndatasets, that our method is abled to accurately identify the CPDs in an audio\nburst with 82.12% and 89.02% of success in the Recall and F1-score\nmeasurements.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 17:47:01 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Anidjar", "O. H.", ""], ["Hajaj", "C.", ""], ["Dvir", "A.", ""], ["Gilad", "I.", ""]]}, {"id": "2006.01207", "submitter": "Jens Helge Reelfs Reelfs", "authors": "Jens Helge Reelfs and Oliver Hohlfeld and Markus Strohmaier and Niklas\n  Henckell", "title": "Word-Emoji Embeddings from large scale Messaging Data reflect real-world\n  Semantic Associations of Expressive Icons", "comments": "10 pages, to appear in 3rd International Workshop on Emoji\n  Understanding and Applications in Social Media", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We train word-emoji embeddings on large scale messaging data obtained from\nthe Jodel online social network. Our data set contains more than 40 million\nsentences, of which 11 million sentences are annotated with a subset of the\nUnicode 13.0 standard Emoji list. We explore semantic emoji associations\ncontained in this embedding by analyzing associations between emojis, between\nemojis and text, and between text and emojis. Our investigations demonstrate\nanecdotally that word-emoji embeddings trained on large scale messaging data\ncan reflect real-world semantic associations. To enable further research we\nrelease the Jodel Emoji Embedding Dataset (JEED1488) containing 1488 emojis and\ntheir embeddings along 300 dimensions.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 19:55:56 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Reelfs", "Jens Helge", ""], ["Hohlfeld", "Oliver", ""], ["Strohmaier", "Markus", ""], ["Henckell", "Niklas", ""]]}, {"id": "2006.01208", "submitter": "Nikhita Vedula", "authors": "Nikhita Vedula, Rahul Gupta, Aman Alok, Mukund Sridhar", "title": "Automatic Discovery of Novel Intents & Domains from Text Utterances", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the primary tasks in Natural Language Understanding (NLU) is to\nrecognize the intents as well as domains of users' spoken and written language\nutterances. Most existing research formulates this as a supervised\nclassification problem with a closed-world assumption, i.e. the domains or\nintents to be identified are pre-defined or known beforehand. Real-world\napplications however increasingly encounter dynamic, rapidly evolving\nenvironments with newly emerging intents and domains, about which no\ninformation is known during model training. We propose a novel framework,\nADVIN, to automatically discover novel domains and intents from large volumes\nof unlabeled data. We first employ an open classification model to identify all\nutterances potentially consisting of a novel intent. Next, we build a knowledge\ntransfer component with a pairwise margin loss function. It learns\ndiscriminative deep features to group together utterances and discover multiple\nlatent intent categories within them in an unsupervised manner. We finally\nhierarchically link mutually related intents into domains, forming an\nintent-domain taxonomy. ADVIN significantly outperforms baselines on three\nbenchmark datasets, and real user utterances from a commercial voice-powered\nagent.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 00:47:10 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Vedula", "Nikhita", ""], ["Gupta", "Rahul", ""], ["Alok", "Aman", ""], ["Sridhar", "Mukund", ""]]}, {"id": "2006.01209", "submitter": "Xingyuan Pan", "authors": "Xingyuan Pan, Maitrey Mehta, Vivek Srikumar", "title": "Learning Constraints for Structured Prediction Using Rectifier Networks", "comments": "to be published in ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Various natural language processing tasks are structured prediction problems\nwhere outputs are constructed with multiple interdependent decisions. Past work\nhas shown that domain knowledge, framed as constraints over the output space,\ncan help improve predictive accuracy. However, designing good constraints often\nrelies on domain expertise. In this paper, we study the problem of learning\nsuch constraints. We frame the problem as that of training a two-layer\nrectifier network to identify valid structures or substructures, and show a\nconstruction for converting a trained network into a system of linear\nconstraints over the inference variables. Our experiments on several NLP tasks\nshow that the learned constraints can improve the prediction accuracy,\nespecially when the number of training examples is small.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 18:31:30 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Pan", "Xingyuan", ""], ["Mehta", "Maitrey", ""], ["Srikumar", "Vivek", ""]]}, {"id": "2006.01210", "submitter": "Qinghua Chen", "authors": "Qinghua Chen, Yan Wang, Mengmeng Wang, Xiaomeng Li", "title": "The 'Letter' Distribution in the Chinese Language", "comments": "17 pages, 8 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Corpus-based statistical analysis plays a significant role in linguistic\nresearch, and ample evidence has shown that different languages exhibit some\ncommon laws. Studies have found that letters in some alphabetic writing\nlanguages have strikingly similar statistical usage frequency distributions.\nDoes this hold for Chinese, which employs ideogram writing? We obtained letter\nfrequency data of some alphabetic writing languages and found the common law of\nthe letter distributions. In addition, we collected Chinese literature corpora\nfor different historical periods from the Tang Dynasty to the present, and we\ndismantled the Chinese written language into three kinds of basic particles:\ncharacters, strokes and constructive parts. The results of the statistical\nanalysis showed that, in different historical periods, the intensity of the use\nof basic particles in Chinese writing varied, but the form of the distribution\nwas consistent. In particular, the distributions of the Chinese constructive\nparts are certainly consistent with those alphabetic writing languages. This\nstudy provides new evidence of the consistency of human languages.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 05:18:56 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Chen", "Qinghua", ""], ["Wang", "Yan", ""], ["Wang", "Mengmeng", ""], ["Li", "Xiaomeng", ""]]}, {"id": "2006.01211", "submitter": "Benjamin Horne", "authors": "Benjamin D. Horne and Maur\\'icio Gruppi and Sibel Adal{\\i}", "title": "Do All Good Actors Look The Same? Exploring News Veracity Detection\n  Across The U.S. and The U.K", "comments": "Published in ICWSM 2020 Data Challenge", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major concern with text-based news veracity detection methods is that they\nmay not generalize across countries and cultures. In this short paper, we\nexplicitly test news veracity models across news data from the United States\nand the United Kingdom, demonstrating there is reason for concern of\ngeneralizabilty. Through a series of testing scenarios, we show that text-based\nclassifiers perform poorly when trained on one country's news data and tested\non another. Furthermore, these same models have trouble classifying unseen,\nunreliable news sources. In conclusion, we discuss implications of these\nresults and avenues for future work.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 22:45:28 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Horne", "Benjamin D.", ""], ["Gruppi", "Maur\u00edcio", ""], ["Adal\u0131", "Sibel", ""]]}, {"id": "2006.01222", "submitter": "Tanvi Dadu Miss", "authors": "Tanvi Dadu, Kartikey Pant and Radhika Mamidi", "title": "BERT-based Ensembles for Modeling Disclosure and Support in\n  Conversational Social Media Text", "comments": "Accepted at the Affective Content workshop held at AAAI 2020 as the\n  Best System Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing interest in understanding how humans initiate and hold\nconversations. The affective understanding of conversations focuses on the\nproblem of how speakers use emotions to react to a situation and to each other.\nIn the CL-Aff Shared Task, the organizers released Get it #OffMyChest dataset,\nwhich contains Reddit comments from casual and confessional conversations,\nlabeled for their disclosure and supportiveness characteristics. In this paper,\nwe introduce a predictive ensemble model exploiting the finetuned\ncontextualized word embeddings, RoBERTa and ALBERT. We show that our model\noutperforms the base models in all considered metrics, achieving an improvement\nof $3\\%$ in the F1 score. We further conduct statistical analysis and outline\ndeeper insights into the given dataset while providing a new characterization\nof impact for the dataset.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 19:52:01 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Dadu", "Tanvi", ""], ["Pant", "Kartikey", ""], ["Mamidi", "Radhika", ""]]}, {"id": "2006.01245", "submitter": "Julio Gonzalo", "authors": "Enrique Amig\\'o, Julio Gonzalo, Stefano Mizzaro, Jorge\n  Carrillo-de-Albornoz", "title": "An Effectiveness Metric for Ordinal Classification: Formal Properties\n  and Experimental Results", "comments": "To appear in Proceedings of ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Ordinal Classification tasks, items have to be assigned to classes that\nhave a relative ordering, such as positive, neutral, negative in sentiment\nanalysis. Remarkably, the most popular evaluation metrics for ordinal\nclassification tasks either ignore relevant information (for instance,\nprecision/recall on each of the classes ignores their relative ordering) or\nassume additional information (for instance, Mean Average Error assumes\nabsolute distances between classes). In this paper we propose a new metric for\nOrdinal Classification, Closeness Evaluation Measure, that is rooted on\nMeasurement Theory and Information Theory. Our theoretical analysis and\nexperimental results over both synthetic data and data from NLP shared tasks\nindicate that the proposed metric captures quality aspects from different\ntraditional tasks simultaneously. In addition, it generalizes some popular\nclassification (nominal scale) and error minimization (interval scale) metrics,\ndepending on the measurement scale in which it is instantiated.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 20:35:46 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Amig\u00f3", "Enrique", ""], ["Gonzalo", "Julio", ""], ["Mizzaro", "Stefano", ""], ["Carrillo-de-Albornoz", "Jorge", ""]]}, {"id": "2006.01266", "submitter": "Abdelrahim Elmadany", "authors": "AbdelRahim Elmadany, Chiyu Zhang, Muhammad Abdul-Mageed, Azadeh\n  Hashemi", "title": "Leveraging Affective Bidirectional Transformers for Offensive Language\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media are pervasive in our life, making it necessary to ensure safe\nonline experiences by detecting and removing offensive and hate speech. In this\nwork, we report our submission to the Offensive Language and hate-speech\nDetection shared task organized with the 4th Workshop on Open-Source Arabic\nCorpora and Processing Tools Arabic (OSACT4). We focus on developing purely\ndeep learning systems, without a need for feature engineering. For that\npurpose, we develop an effective method for automatic data augmentation and\nshow the utility of training both offensive and hate speech models off (i.e.,\nby fine-tuning) previously trained affective models (i.e., sentiment and\nemotion). Our best models are significantly better than a vanilla BERT model,\nwith 89.60% acc (82.31% macro F1) for hate speech and 95.20% acc (70.51% macro\nF1) on official TEST data.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 04:55:35 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Elmadany", "AbdelRahim", ""], ["Zhang", "Chiyu", ""], ["Abdul-Mageed", "Muhammad", ""], ["Hashemi", "Azadeh", ""]]}, {"id": "2006.01285", "submitter": "Ivano Lauriola", "authors": "Ivano Lauriola and Alessandro Moschitti", "title": "Context-based Transformer Models for Answer Sentence Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  An important task for the design of Question Answering systems is the\nselection of the sentence containing (or constituting) the answer from\ndocuments relevant to the asked question. Most previous work has only used the\ntarget sentence to compute its score with the question as the models were not\npowerful enough to also effectively encode additional contextual information.\nIn this paper, we analyze the role of the contextual information in the\nsentence selection task, proposing a Transformer based architecture that\nleverages two types of contexts, local and global. The former describes the\nparagraph containing the sentence, aiming at solving implicit references,\nwhereas the latter describes the entire document containing the candidate\nsentence, providing content-based information. The results on three different\nbenchmarks show that the combination of local and global contexts in a\nTransformer model significantly improves the accuracy in Answer Sentence\nSelection.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 21:52:19 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Lauriola", "Ivano", ""], ["Moschitti", "Alessandro", ""]]}, {"id": "2006.01338", "submitter": "George Cybenko", "authors": "Joshua Ackerman, George Cybenko", "title": "A Survey of Neural Networks and Formal Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report is a survey of the relationships between various state-of-the-art\nneural network architectures and formal languages as, for example, structured\nby the Chomsky Language Hierarchy. Of particular interest are the abilities of\na neural architecture to represent, recognize and generate words from a\nspecific language by learning from samples of the language.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 01:46:04 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Ackerman", "Joshua", ""], ["Cybenko", "George", ""]]}, {"id": "2006.01346", "submitter": "Jie Cai", "authors": "Jie Cai, Zhengzhou Zhu, Ping Nie and Qian Liu", "title": "A Pairwise Probe for Understanding BERT Fine-Tuning on Machine Reading\n  Comprehension", "comments": "e.g.: 4 pages, 1 figure", "journal-ref": null, "doi": "10.1145/3397271.3401195", "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained models have brought significant improvements to many NLP tasks\nand have been extensively analyzed. But little is known about the effect of\nfine-tuning on specific tasks. Intuitively, people may agree that a pre-trained\nmodel already learns semantic representations of words (e.g. synonyms are\ncloser to each other) and fine-tuning further improves its capabilities which\nrequire more complicated reasoning (e.g. coreference resolution, entity\nboundary detection, etc). However, how to verify these arguments analytically\nand quantitatively is a challenging task and there are few works focus on this\ntopic. In this paper, inspired by the observation that most probing tasks\ninvolve identifying matched pairs of phrases (e.g. coreference requires\nmatching an entity and a pronoun), we propose a pairwise probe to understand\nBERT fine-tuning on the machine reading comprehension (MRC) task. Specifically,\nwe identify five phenomena in MRC. According to pairwise probing tasks, we\ncompare the performance of each layer's hidden representation of pre-trained\nand fine-tuned BERT. The proposed pairwise probe alleviates the problem of\ndistraction from inaccurate model training and makes a robust and quantitative\ncomparison. Our experimental analysis leads to highly confident conclusions:\n(1) Fine-tuning has little effect on the fundamental and low-level information\nand general semantic tasks. (2) For specific abilities required for downstream\ntasks, fine-tuned BERT is better than pre-trained BERT and such gaps are\nobvious after the fifth layer.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 02:12:19 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Cai", "Jie", ""], ["Zhu", "Zhengzhou", ""], ["Nie", "Ping", ""], ["Liu", "Qian", ""]]}, {"id": "2006.01372", "submitter": "Takuma Kato", "authors": "Takuma Kato, Kaori Abe, Hiroki Ouchi, Shumpei Miyawaki, Jun Suzuki,\n  Kentaro Inui", "title": "Embeddings of Label Components for Sequence Labeling: A Case Study of\n  Fine-grained Named Entity Recognition", "comments": "Accepted by ACL SRW 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In general, the labels used in sequence labeling consist of different types\nof elements. For example, IOB-format entity labels, such as B-Person and\nI-Person, can be decomposed into span (B and I) and type information (Person).\nHowever, while most sequence labeling models do not consider such label\ncomponents, the shared components across labels, such as Person, can be\nbeneficial for label prediction. In this work, we propose to integrate label\ncomponent information as embeddings into models. Through experiments on English\nand Japanese fine-grained named entity recognition, we demonstrate that the\nproposed method improves performance, especially for instances with\nlow-frequency labels.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 03:47:19 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 14:01:18 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Kato", "Takuma", ""], ["Abe", "Kaori", ""], ["Ouchi", "Hiroki", ""], ["Miyawaki", "Shumpei", ""], ["Suzuki", "Jun", ""], ["Inui", "Kentaro", ""]]}, {"id": "2006.01414", "submitter": "Xinyu Wang", "authors": "Xinyu Wang, Yong Jiang, Kewei Tu", "title": "Enhanced Universal Dependency Parsing with Second-Order Inference and\n  Mixture of Training Data", "comments": "IWPT 2020 shared task. After fixing the bug, our proposed parser\n  performs better than the team that ranked 1st in the official results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents the system used in our submission to the \\textit{IWPT\n2020 Shared Task}. Our system is a graph-based parser with second-order\ninference. For the low-resource Tamil corpus, we specially mixed the training\ndata of Tamil with other languages and significantly improved the performance\nof Tamil. Due to our misunderstanding of the submission requirements, we\nsubmitted graphs that are not connected, which makes our system only rank\n\\textbf{6th} over 10 teams. However, after we fixed this problem, our system is\n0.6 ELAS higher than the team that ranked \\textbf{1st} in the official results.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 06:42:22 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 07:10:28 GMT"}, {"version": "v3", "created": "Wed, 2 Jun 2021 03:07:41 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Wang", "Xinyu", ""], ["Jiang", "Yong", ""], ["Tu", "Kewei", ""]]}, {"id": "2006.01416", "submitter": "Katie Knister", "authors": "Yuan Shangguan, Kate Knister, Yanzhang He, Ian McGraw, Francoise\n  Beaufays", "title": "Analyzing the Quality and Stability of a Streaming End-to-End On-Device\n  Speech Recognizer", "comments": "Accepted at Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The demand for fast and accurate incremental speech recognition increases as\nthe applications of automatic speech recognition (ASR) proliferate. Incremental\nspeech recognizers output chunks of partially recognized words while the user\nis still talking. Partial results can be revised before the ASR finalizes its\nhypothesis, causing instability issues. We analyze the quality and stability of\non-device streaming end-to-end (E2E) ASR models. We first introduce a novel set\nof metrics that quantify the instability at word and segment levels. We study\nthe impact of several model training techniques that improve E2E model\nqualities but degrade model stability. We categorize the causes of instability\nand explore various solutions to mitigate them in a streaming E2E ASR system.\nIndex Terms: ASR, stability, end-to-end, text normalization,on-device, RNN-T\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 06:47:27 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 22:02:24 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Shangguan", "Yuan", ""], ["Knister", "Kate", ""], ["He", "Yanzhang", ""], ["McGraw", "Ian", ""], ["Beaufays", "Francoise", ""]]}, {"id": "2006.01432", "submitter": "Somil Gupta", "authors": "Somil Gupta, Nilesh Khade", "title": "BERT Based Multilingual Machine Comprehension in English and Hindi", "comments": "Submitted for review to the Special Issue on Deep Learning of ACM\n  Transactions on Asian and Low-Resource Language Information Processing\n  (TALLIP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual Machine Comprehension (MMC) is a Question-Answering (QA)\nsub-task that involves quoting the answer for a question from a given snippet,\nwhere the question and the snippet can be in different languages. Recently\nreleased multilingual variant of BERT (m-BERT), pre-trained with 104 languages,\nhas performed well in both zero-shot and fine-tuned settings for multilingual\ntasks; however, it has not been used for English-Hindi MMC yet. We, therefore,\npresent in this article, our experiments with m-BERT for MMC in zero-shot,\nmono-lingual (e.g. Hindi Question-Hindi Snippet) and cross-lingual (e.g.\nEnglish QuestionHindi Snippet) fine-tune setups. These model variants are\nevaluated on all possible multilingual settings and results are compared\nagainst the current state-of-the-art sequential QA system for these languages.\nExperiments show that m-BERT, with fine-tuning, improves performance on all\nevaluation settings across both the datasets used by the prior model, therefore\nestablishing m-BERT based MMC as the new state-of-the-art for English and\nHindi. We also publish our results on an extended version of the recently\nreleased XQuAD dataset, which we propose to use as the evaluation benchmark for\nfuture research.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 07:36:49 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Gupta", "Somil", ""], ["Khade", "Nilesh", ""]]}, {"id": "2006.01439", "submitter": "Maria Janina Sarol", "authors": "M. Janina Sarol, Ly Dinh, Rezvaneh Rezapour, Chieh-Li Chin, Pingjing\n  Yang, Jana Diesner", "title": "An Empirical Methodology for Detecting and Prioritizing Needs during\n  Crisis Events", "comments": null, "journal-ref": null, "doi": "10.18653/v1/2020.findings-emnlp.366", "report-no": null, "categories": "cs.CL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In times of crisis, identifying the essential needs is a crucial step to\nproviding appropriate resources and services to affected entities. Social media\nplatforms such as Twitter contain vast amount of information about the general\npublic's needs. However, the sparsity of the information as well as the amount\nof noisy content present a challenge to practitioners to effectively identify\nshared information on these platforms. In this study, we propose two novel\nmethods for two distinct but related needs detection tasks: the identification\nof 1) a list of resources needed ranked by priority, and 2) sentences that\nspecify who-needs-what resources. We evaluated our methods on a set of tweets\nabout the COVID-19 crisis. For task 1 (detecting top needs), we compared our\nresults against two given lists of resources and achieved 64% precision. For\ntask 2 (detecting who-needs-what), we compared our results on a set of 1,000\nannotated tweets and achieved a 68% F1-score.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 08:02:29 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Sarol", "M. Janina", ""], ["Dinh", "Ly", ""], ["Rezapour", "Rezvaneh", ""], ["Chin", "Chieh-Li", ""], ["Yang", "Pingjing", ""], ["Diesner", "Jana", ""]]}, {"id": "2006.01460", "submitter": "Satwik Kottur", "authors": "Seungwhan Moon, Satwik Kottur, Paul A. Crook, Ankita De, Shivani\n  Poddar, Theodore Levin, David Whitney, Daniel Difranco, Ahmad Beirami,\n  Eunjoon Cho, Rajen Subba, Alborz Geramifard", "title": "Situated and Interactive Multimodal Conversations", "comments": "20 pages, 5 figures, 11 tables, accepted to COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Next generation virtual assistants are envisioned to handle multimodal inputs\n(e.g., vision, memories of previous interactions, in addition to the user's\nutterances), and perform multimodal actions (e.g., displaying a route in\naddition to generating the system's utterance). We introduce Situated\nInteractive MultiModal Conversations (SIMMC) as a new direction aimed at\ntraining agents that take multimodal actions grounded in a co-evolving\nmultimodal input context in addition to the dialog history. We provide two\nSIMMC datasets totalling ~13K human-human dialogs (~169K utterances) using a\nmultimodal Wizard-of-Oz (WoZ) setup, on two shopping domains: (a) furniture\n(grounded in a shared virtual environment) and, (b) fashion (grounded in an\nevolving set of images). We also provide logs of the items appearing in each\nscene, and contextual NLU and coreference annotations, using a novel and\nunified framework of SIMMC conversational acts for both user and assistant\nutterances. Finally, we present several tasks within SIMMC as objective\nevaluation protocols, such as Structural API Prediction and Response\nGeneration. We benchmark a collection of existing models on these SIMMC tasks\nas strong baselines, and demonstrate rich multimodal conversational\ninteractions. Our data, annotations, code, and models are publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 09:02:23 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 20:21:19 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Moon", "Seungwhan", ""], ["Kottur", "Satwik", ""], ["Crook", "Paul A.", ""], ["De", "Ankita", ""], ["Poddar", "Shivani", ""], ["Levin", "Theodore", ""], ["Whitney", "David", ""], ["Difranco", "Daniel", ""], ["Beirami", "Ahmad", ""], ["Cho", "Eunjoon", ""], ["Subba", "Rajen", ""], ["Geramifard", "Alborz", ""]]}, {"id": "2006.01527", "submitter": "Mohamad Yaser Jaradeh", "authors": "Mohamad Yaser Jaradeh, Markus Stocker, S\\\"oren Auer", "title": "Question Answering on Scholarly Knowledge Graphs", "comments": "Pre-print for TPDL2020 accepted full paper, 14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answering questions on scholarly knowledge comprising text and other\nartifacts is a vital part of any research life cycle. Querying scholarly\nknowledge and retrieving suitable answers is currently hardly possible due to\nthe following primary reason: machine inactionable, ambiguous and unstructured\ncontent in publications. We present JarvisQA, a BERT based system to answer\nquestions on tabular views of scholarly knowledge graphs. Such tables can be\nfound in a variety of shapes in the scholarly literature (e.g., surveys,\ncomparisons or results). Our system can retrieve direct answers to a variety of\ndifferent questions asked on tabular data in articles. Furthermore, we present\na preliminary dataset of related tables and a corresponding set of natural\nlanguage questions. This dataset is used as a benchmark for our system and can\nbe reused by others. Additionally, JarvisQA is evaluated on two datasets\nagainst other baselines and shows an improvement of two to three folds in\nperformance compared to related methods.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 11:24:02 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Jaradeh", "Mohamad Yaser", ""], ["Stocker", "Markus", ""], ["Auer", "S\u00f6ren", ""]]}, {"id": "2006.01538", "submitter": "Sampo Pyysalo", "authors": "Sampo Pyysalo, Jenna Kanerva, Antti Virtanen, Filip Ginter", "title": "WikiBERT models: deep transfer learning for many languages", "comments": "7 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural language models such as BERT have enabled substantial recent\nadvances in many natural language processing tasks. Due to the effort and\ncomputational cost involved in their pre-training, language-specific models are\ntypically introduced only for a small number of high-resource languages such as\nEnglish. While multilingual models covering large numbers of languages are\navailable, recent work suggests monolingual training can produce better models,\nand our understanding of the tradeoffs between mono- and multilingual training\nis incomplete. In this paper, we introduce a simple, fully automated pipeline\nfor creating language-specific BERT models from Wikipedia data and introduce 42\nnew such models, most for languages up to now lacking dedicated deep neural\nlanguage models. We assess the merits of these models using the\nstate-of-the-art UDify parser on Universal Dependencies data, contrasting\nperformance with results using the multilingual BERT model. We find that UDify\nusing WikiBERT models outperforms the parser using mBERT on average, with the\nlanguage-specific models showing substantially improved performance for some\nlanguages, yet limited improvement or a decrease in performance for others. We\nalso present preliminary results as first steps toward an understanding of the\nconditions under which language-specific models are most beneficial. All of the\nmethods and models introduced in this work are available under open licenses\nfrom https://github.com/turkunlp/wikibert.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 11:57:53 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Pyysalo", "Sampo", ""], ["Kanerva", "Jenna", ""], ["Virtanen", "Antti", ""], ["Ginter", "Filip", ""]]}, {"id": "2006.01554", "submitter": "Yong Shan", "authors": "Yong Shan, Zekang Li, Jinchao Zhang, Fandong Meng, Yang Feng, Cheng\n  Niu, Jie Zhou", "title": "A Contextual Hierarchical Attention Network with Adaptive Objective for\n  Dialogue State Tracking", "comments": "This paper has been withdrawn from ACL 2020. More modifications are\n  needed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies in dialogue state tracking (DST) leverage historical\ninformation to determine states which are generally represented as slot-value\npairs. However, most of them have limitations to efficiently exploit relevant\ncontext due to the lack of a powerful mechanism for modeling interactions\nbetween the slot and the dialogue history. Besides, existing methods usually\nignore the slot imbalance problem and treat all slots indiscriminately, which\nlimits the learning of hard slots and eventually hurts overall performance. In\nthis paper, we propose to enhance the DST through employing a contextual\nhierarchical attention network to not only discern relevant information at both\nword level and turn level but also learn contextual representations. We further\npropose an adaptive objective to alleviate the slot imbalance problem by\ndynamically adjust weights of different slots during training. Experimental\nresults show that our approach reaches 52.68% and 58.55% joint accuracy on\nMultiWOZ 2.0 and MultiWOZ 2.1 datasets respectively and achieves new\nstate-of-the-art performance with considerable improvements (+1.24% and\n+5.98%).\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 12:25:44 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 02:03:40 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Shan", "Yong", ""], ["Li", "Zekang", ""], ["Zhang", "Jinchao", ""], ["Meng", "Fandong", ""], ["Feng", "Yang", ""], ["Niu", "Cheng", ""], ["Zhou", "Jie", ""]]}, {"id": "2006.01563", "submitter": "Jouni Luoma", "authors": "Jouni Luoma, Sampo Pyysalo", "title": "Exploring Cross-sentence Contexts for Named Entity Recognition with BERT", "comments": null, "journal-ref": "Proceedings of the 28th International Conference on Computational\n  Linguistics, dec,2020, Barcelona, Spain (Online),International Committee on\n  Computational Linguistics, pages 904-914", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Named entity recognition (NER) is frequently addressed as a sequence\nclassification task where each input consists of one sentence of text. It is\nnevertheless clear that useful information for the task can often be found\noutside of the scope of a single-sentence context. Recently proposed\nself-attention models such as BERT can both efficiently capture long-distance\nrelationships in input as well as represent inputs consisting of several\nsentences, creating new opportunitites for approaches that incorporate\ncross-sentence information in natural language processing tasks. In this paper,\nwe present a systematic study exploring the use of cross-sentence information\nfor NER using BERT models in five languages. We find that adding context in the\nform of additional sentences to BERT input systematically increases NER\nperformance on all of the tested languages and models. Including multiple\nsentences in each input also allows us to study the predictions of the same\nsentences in different contexts. We propose a straightforward method,\nContextual Majority Voting (CMV), to combine different predictions for\nsentences and demonstrate this to further increase NER performance with BERT.\nOur approach does not require any changes to the underlying BERT architecture,\nrather relying on restructuring examples for training and prediction.\nEvaluation on established datasets, including the CoNLL'02 and CoNLL'03 NER\nbenchmarks, demonstrates that our proposed approach can improve on the\nstate-of-the-art NER results on English, Dutch, and Finnish, achieves the best\nreported BERT-based results on German, and is on par with performance reported\nwith other BERT-based approaches in Spanish. We release all methods implemented\nin this work under open licenses.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 12:34:52 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 16:32:55 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Luoma", "Jouni", ""], ["Pyysalo", "Sampo", ""]]}, {"id": "2006.01592", "submitter": "Hou Pong Chan", "authors": "Hou Pong Chan, Wang Chen, Irwin King", "title": "A Unified Dual-view Model for Review Summarization and Sentiment\n  Classification with Inconsistency Loss", "comments": "Accepted by SIGIR 2020. Updated the results of balanced accuracy\n  scores in Table 3 since we found a bug in our source code. Nevertheless, our\n  model still achieves higher balanced accuracy scores than the baselines after\n  we fixed this bug", "journal-ref": "SIGIR 2020: 1191-1200", "doi": "10.1145/3397271.3401039", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acquiring accurate summarization and sentiment from user reviews is an\nessential component of modern e-commerce platforms. Review summarization aims\nat generating a concise summary that describes the key opinions and sentiment\nof a review, while sentiment classification aims to predict a sentiment label\nindicating the sentiment attitude of a review. To effectively leverage the\nshared sentiment information in both review summarization and sentiment\nclassification tasks, we propose a novel dual-view model that jointly improves\nthe performance of these two tasks. In our model, an encoder first learns a\ncontext representation for the review, then a summary decoder generates a\nreview summary word by word. After that, a source-view sentiment classifier\nuses the encoded context representation to predict a sentiment label for the\nreview, while a summary-view sentiment classifier uses the decoder hidden\nstates to predict a sentiment label for the generated summary. During training,\nwe introduce an inconsistency loss to penalize the disagreement between these\ntwo classifiers. It helps the decoder to generate a summary to have a\nconsistent sentiment tendency with the review and also helps the two sentiment\nclassifiers learn from each other. Experiment results on four real-world\ndatasets from different domains demonstrate the effectiveness of our model.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 13:34:11 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 08:56:42 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Chan", "Hou Pong", ""], ["Chen", "Wang", ""], ["King", "Irwin", ""]]}, {"id": "2006.01594", "submitter": "Marta R. Costa-juss\\`a", "authors": "Carlos Escolano, Marta R. Costa-juss\\`a, Jos\\'e A. R. Fonollosa and\n  Mikel Artetxe", "title": "Training Multilingual Machine Translation by Alternately Freezing\n  Language-Specific Encoders-Decoders", "comments": "arXiv admin note: text overlap with arXiv:2004.06575", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a modular architecture of language-specific encoder-decoders that\nconstitutes a multilingual machine translation system that can be incrementally\nextended to new languages without the need for retraining the existing system\nwhen adding new languages. Differently from previous works, we simultaneously\ntrain $N$ languages in all translation directions by alternately freezing\nencoder or decoder modules, which indirectly forces the system to train in a\ncommon intermediate representation for all languages. Experimental results from\nmultilingual machine translation show that we can successfully train this\nmodular architecture improving on the initial languages while falling slightly\nbehind when adding new languages or doing zero-shot translation. Additional\ncomparison of the quality of sentence representation in the task of natural\nlanguage inference shows that the alternately freezing training is also\nbeneficial in this direction.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 19:00:59 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Escolano", "Carlos", ""], ["Costa-juss\u00e0", "Marta R.", ""], ["Fonollosa", "Jos\u00e9 A. R.", ""], ["Artetxe", "Mikel", ""]]}, {"id": "2006.01603", "submitter": "Damien Sileo", "authors": "Damien Sileo, Tim Van de Cruys, Camille Pradel, Philippe Muller", "title": "DiscSense: Automated Semantic Analysis of Discourse Markers", "comments": "Accepted at LREC2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Discourse markers ({\\it by contrast}, {\\it happily}, etc.) are words or\nphrases that are used to signal semantic and/or pragmatic relationships between\nclauses or sentences. Recent work has fruitfully explored the prediction of\ndiscourse markers between sentence pairs in order to learn accurate sentence\nrepresentations, that are useful in various classification tasks. In this work,\nwe take another perspective: using a model trained to predict discourse markers\nbetween sentence pairs, we predict plausible markers between sentence pairs\nwith a known semantic relation (provided by existing classification datasets).\nThese predictions allow us to study the link between discourse markers and the\nsemantic relations annotated in classification datasets. Handcrafted mappings\nhave been proposed between markers and discourse relations on a limited set of\nmarkers and a limited set of categories, but there exist hundreds of discourse\nmarkers expressing a wide variety of relations, and there is no consensus on\nthe taxonomy of relations between competing discourse theories (which are\nlargely built in a top-down fashion). By using an automatic rediction method\nover existing semantically annotated datasets, we provide a bottom-up\ncharacterization of discourse markers in English. The resulting dataset, named\nDiscSense, is publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 13:39:53 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Sileo", "Damien", ""], ["Van de Cruys", "Tim", ""], ["Pradel", "Camille", ""], ["Muller", "Philippe", ""]]}, {"id": "2006.01626", "submitter": "Bilal Abu-Salih", "authors": "Bilal Abu-Salih, Marwan Al-Tawil, Ibrahim Aljarah, Hossam Faris,\n  Pornpit Wongthongtham", "title": "Relational Learning Analysis of Social Politics using Knowledge Graph\n  Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Graphs (KGs) have gained considerable attention recently from both\nacademia and industry. In fact, incorporating graph technology and the copious\nof various graph datasets have led the research community to build\nsophisticated graph analytics tools. Therefore, the application of KGs has\nextended to tackle a plethora of real-life problems in dissimilar domains.\nDespite the abundance of the currently proliferated generic KGs, there is a\nvital need to construct domain-specific KGs. Further, quality and credibility\nshould be assimilated in the process of constructing and augmenting KGs,\nparticularly those propagated from mixed-quality resources such as social media\ndata. This paper presents a novel credibility domain-based KG Embedding\nframework. This framework involves capturing a fusion of data obtained from\nheterogeneous resources into a formal KG representation depicted by a domain\nontology. The proposed approach makes use of various knowledge-based\nrepositories to enrich the semantics of the textual contents, thereby\nfacilitating the interoperability of information. The proposed framework also\nembodies a credibility module to ensure data quality and trustworthiness. The\nconstructed KG is then embedded in a low-dimension semantically-continuous\nspace using several embedding techniques. The utility of the constructed KG and\nits embeddings is demonstrated and substantiated on link prediction,\nclustering, and visualisation tasks.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 14:10:28 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Abu-Salih", "Bilal", ""], ["Al-Tawil", "Marwan", ""], ["Aljarah", "Ibrahim", ""], ["Faris", "Hossam", ""], ["Wongthongtham", "Pornpit", ""]]}, {"id": "2006.01715", "submitter": "Mohammad Reza Saleh Sedghpour", "authors": "Alireza Saleh Sedghpour, Mohammad Reza Saleh Sedghpour", "title": "Web Document Categorization Using Naive Bayes Classifier and Latent\n  Semantic Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A rapid growth of web documents due to heavy use of World Wide Web\nnecessitates efficient techniques to efficiently classify the document on the\nweb. It is thus produced High volumes of data per second with high diversity.\nAutomatically classification of these growing amounts of web document is One of\nthe biggest challenges facing us today. Probabilistic classification algorithms\nsuch as Naive Bayes have become commonly used for web document classification.\nThis problem is mainly because of the irrelatively high classification accuracy\non plenty application areas as well as their lack of support to handle high\ndimensional and sparse data which is the exclusive characteristics of textual\ndata representation. also it is common to Lack of attention and support the\nsemantic relation between words using traditional feature selection method When\ndealing with the big data and large-scale web documents. In order to solve the\nproblem, we proposed a method for web document classification that uses LSA to\nincrease similarity of documents under the same class and improve the\nclassification precision. Using this approach, we designed a faster and much\naccurate classifier for Web Documents. Experimental results have shown that\nusing the mentioned preprocessing can improve accuracy and speed of Naive Bayes\navailably, the precision and recall metrics have indicated the improvement.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 15:35:05 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Sedghpour", "Alireza Saleh", ""], ["Sedghpour", "Mohammad Reza Saleh", ""]]}, {"id": "2006.01796", "submitter": "Yusuke Fujita", "authors": "Yusuke Fujita, Shinji Watanabe, Shota Horiguchi, Yawen Xue, Jing Shi,\n  Kenji Nagamatsu", "title": "Neural Speaker Diarization with Speaker-Wise Chain Rule", "comments": "Submitted to Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker diarization is an essential step for processing multi-speaker audio.\nAlthough an end-to-end neural diarization (EEND) method achieved\nstate-of-the-art performance, it is limited to a fixed number of speakers. In\nthis paper, we solve this fixed number of speaker issue by a novel speaker-wise\nconditional inference method based on the probabilistic chain rule. In the\nproposed method, each speaker's speech activity is regarded as a single random\nvariable, and is estimated sequentially conditioned on previously estimated\nother speakers' speech activities. Similar to other sequence-to-sequence\nmodels, the proposed method produces a variable number of speakers with a stop\nsequence condition. We evaluated the proposed method on multi-speaker audio\nrecordings of a variable number of speakers. Experimental results show that the\nproposed method can correctly produce diarization results with a variable\nnumber of speakers and outperforms the state-of-the-art end-to-end speaker\ndiarization methods in terms of diarization error rate.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 17:28:12 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Fujita", "Yusuke", ""], ["Watanabe", "Shinji", ""], ["Horiguchi", "Shota", ""], ["Xue", "Yawen", ""], ["Shi", "Jing", ""], ["Nagamatsu", "Kenji", ""]]}, {"id": "2006.01854", "submitter": "Zhigang Kan", "authors": "Zhigang Kan, Linbo Qiao, Sen Yang, Feng Liu, Feng Huang", "title": "Event Arguments Extraction via Dilate Gated Convolutional Neural Network\n  with Enhanced Local Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event Extraction plays an important role in information-extraction to\nunderstand the world. Event extraction could be split into two subtasks: one is\nevent trigger extraction, the other is event arguments extraction. However, the\nF-Score of event arguments extraction is much lower than that of event trigger\nextraction, i.e. in the most recent work, event trigger extraction achieves\n80.7%, while event arguments extraction achieves only 58%. In pipelined\nstructures, the difficulty of event arguments extraction lies in its lack of\nclassification feature, and the much higher computation consumption. In this\nwork, we proposed a novel Event Extraction approach based on multi-layer Dilate\nGated Convolutional Neural Network (EE-DGCNN) which has fewer parameters. In\naddition, enhanced local information is incorporated into word features, to\nassign event arguments roles for triggers predicted by the first subtask. The\nnumerical experiments demonstrated significant performance improvement beyond\nstate-of-art event extraction approaches on real-world datasets. Further\nanalysis of extraction procedure is presented, as well as experiments are\nconducted to analyze impact factors related to the performance improvement.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 18:05:34 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Kan", "Zhigang", ""], ["Qiao", "Linbo", ""], ["Yang", "Sen", ""], ["Liu", "Feng", ""], ["Huang", "Feng", ""]]}, {"id": "2006.01912", "submitter": "Ethan Wilcox", "authors": "Ethan Gotlieb Wilcox, Jon Gauthier, Jennifer Hu, Peng Qian and Roger\n  Levy", "title": "On the Predictive Power of Neural Language Models for Human Real-Time\n  Comprehension Behavior", "comments": "To Appear at CogSci 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Human reading behavior is tuned to the statistics of natural language: the\ntime it takes human subjects to read a word can be predicted from estimates of\nthe word's probability in context. However, it remains an open question what\ncomputational architecture best characterizes the expectations deployed in real\ntime by humans that determine the behavioral signatures of reading. Here we\ntest over two dozen models, independently manipulating computational\narchitecture and training dataset size, on how well their next-word\nexpectations predict human reading time behavior on naturalistic text corpora.\nWe find that across model architectures and training dataset sizes the\nrelationship between word log-probability and reading time is (near-)linear. We\nnext evaluate how features of these models determine their psychometric\npredictive power, or ability to predict human reading behavior. In general, the\nbetter a model's next-word expectations, the better its psychometric predictive\npower. However, we find nontrivial differences across model architectures. For\nany given perplexity, deep Transformer models and n-gram models generally show\nsuperior psychometric predictive power over LSTM or structurally supervised\nneural models, especially for eye movement data. Finally, we compare models'\npsychometric predictive power to the depth of their syntactic knowledge, as\nmeasured by a battery of syntactic generalization tests developed using methods\nfrom controlled psycholinguistic experiments. Once perplexity is controlled\nfor, we find no significant relationship between syntactic knowledge and\npredictive power. These results suggest that different approaches may be\nrequired to best model human real-time language comprehension behavior in\nnaturalistic reading versus behavior for controlled linguistic materials\ndesigned for targeted probing of syntactic knowledge.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 19:47:01 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Wilcox", "Ethan Gotlieb", ""], ["Gauthier", "Jon", ""], ["Hu", "Jennifer", ""], ["Qian", "Peng", ""], ["Levy", "Roger", ""]]}, {"id": "2006.01938", "submitter": "Tenzin Singhay Bhotia", "authors": "Vaibhav Kumar, Tenzin Singhay Bhotia, Vaibhav Kumar, Tanmoy\n  Chakraborty", "title": "Nurse is Closer to Woman than Surgeon? Mitigating Gender-Biased\n  Proximities in Word Embeddings", "comments": "TACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Word embeddings are the standard model for semantic and syntactic\nrepresentations of words. Unfortunately, these models have been shown to\nexhibit undesirable word associations resulting from gender, racial, and\nreligious biases. Existing post-processing methods for debiasing word\nembeddings are unable to mitigate gender bias hidden in the spatial arrangement\nof word vectors. In this paper, we propose RAN-Debias, a novel gender debiasing\nmethodology which not only eliminates the bias present in a word vector but\nalso alters the spatial distribution of its neighbouring vectors, achieving a\nbias-free setting while maintaining minimal semantic offset. We also propose a\nnew bias evaluation metric - Gender-based Illicit Proximity Estimate (GIPE),\nwhich measures the extent of undue proximity in word vectors resulting from the\npresence of gender-based predilections. Experiments based on a suite of\nevaluation metrics show that RAN-Debias significantly outperforms the\nstate-of-the-art in reducing proximity bias (GIPE) by at least 42.02%. It also\nreduces direct bias, adding minimal semantic disturbance, and achieves the best\nperformance in a downstream application task (coreference resolution).\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 20:50:43 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Kumar", "Vaibhav", ""], ["Bhotia", "Tenzin Singhay", ""], ["Kumar", "Vaibhav", ""], ["Chakraborty", "Tanmoy", ""]]}, {"id": "2006.01966", "submitter": "Ella Rabinovich", "authors": "Ella Rabinovich, Yang Xu, Suzanne Stevenson", "title": "The Typology of Polysemy: A Multilingual Distributional Framework", "comments": "CogSci 2020 (Annual Meeting of the Cognitive Science Society)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lexical semantic typology has identified important cross-linguistic\ngeneralizations about the variation and commonalities in polysemy\npatterns---how languages package up meanings into words. Recent computational\nresearch has enabled investigation of lexical semantics at a much larger scale,\nbut little work has explored lexical typology across semantic domains, nor the\nfactors that influence cross-linguistic similarities. We present a novel\ncomputational framework that quantifies semantic affinity, the cross-linguistic\nsimilarity of lexical semantics for a concept. Our approach defines a common\nmultilingual semantic space that enables a direct comparison of the lexical\nexpression of concepts across languages. We validate our framework against\nempirical findings on lexical semantic typology at both the concept and domain\nlevels. Our results reveal an intricate interaction between semantic domains\nand extra-linguistic factors, beyond language phylogeny, that co-shape the\ntypology of polysemy across languages.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 22:31:40 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Rabinovich", "Ella", ""], ["Xu", "Yang", ""], ["Stevenson", "Suzanne", ""]]}, {"id": "2006.01969", "submitter": "Faegheh Hasibi", "authors": "Johannes M. van Hulst, Faegheh Hasibi, Koen Dercksen, Krisztian Balog,\n  Arjen P. de Vries", "title": "REL: An Entity Linker Standing on the Shoulders of Giants", "comments": null, "journal-ref": null, "doi": "10.1145/3397271.3401416", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity linking is a standard component in modern retrieval system that is\noften performed by third-party toolkits. Despite the plethora of open source\noptions, it is difficult to find a single system that has a modular\narchitecture where certain components may be replaced, does not depend on\nexternal sources, can easily be updated to newer Wikipedia versions, and, most\nimportant of all, has state-of-the-art performance. The REL system presented in\nthis paper aims to fill that gap. Building on state-of-the-art neural\ncomponents from natural language processing research, it is provided as a\nPython package as well as a web API. We also report on an experimental\ncomparison against both well-established systems and the current\nstate-of-the-art on standard entity linking benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 22:51:17 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["van Hulst", "Johannes M.", ""], ["Hasibi", "Faegheh", ""], ["Dercksen", "Koen", ""], ["Balog", "Krisztian", ""], ["de Vries", "Arjen P.", ""]]}, {"id": "2006.01997", "submitter": "Virapat Kieuvongngam", "authors": "Virapat Kieuvongngam, Bowen Tan, Yiming Niu", "title": "Automatic Text Summarization of COVID-19 Medical Research Articles using\n  BERT and GPT-2", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the COVID-19 pandemic, there is a growing urgency for medical community\nto keep up with the accelerating growth in the new coronavirus-related\nliterature. As a result, the COVID-19 Open Research Dataset Challenge has\nreleased a corpus of scholarly articles and is calling for machine learning\napproaches to help bridging the gap between the researchers and the rapidly\ngrowing publications. Here, we take advantage of the recent advances in\npre-trained NLP models, BERT and OpenAI GPT-2, to solve this challenge by\nperforming text summarization on this dataset. We evaluate the results using\nROUGE scores and visual inspection. Our model provides abstractive and\ncomprehensive information based on keywords extracted from the original\narticles. Our work can help the the medical community, by providing succinct\nsummaries of articles for which the abstract are not already available.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 00:54:44 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Kieuvongngam", "Virapat", ""], ["Tan", "Bowen", ""], ["Niu", "Yiming", ""]]}, {"id": "2006.02014", "submitter": "Xuebo Liu", "authors": "Xuebo Liu, Houtim Lai, Derek F. Wong, Lidia S. Chao", "title": "Norm-Based Curriculum Learning for Neural Machine Translation", "comments": "Accepted to ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A neural machine translation (NMT) system is expensive to train, especially\nwith high-resource settings. As the NMT architectures become deeper and wider,\nthis issue gets worse and worse. In this paper, we aim to improve the\nefficiency of training an NMT by introducing a novel norm-based curriculum\nlearning method. We use the norm (aka length or module) of a word embedding as\na measure of 1) the difficulty of the sentence, 2) the competence of the model,\nand 3) the weight of the sentence. The norm-based sentence difficulty takes the\nadvantages of both linguistically motivated and model-based sentence\ndifficulties. It is easy to determine and contains learning-dependent features.\nThe norm-based model competence makes NMT learn the curriculum in a fully\nautomated way, while the norm-based sentence weight further enhances the\nlearning of the vector representation of the NMT. Experimental results for the\nWMT'14 English-German and WMT'17 Chinese-English translation tasks demonstrate\nthat the proposed method outperforms strong baselines in terms of BLEU score\n(+1.17/+1.56) and training speedup (2.22x/3.33x).\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 02:22:00 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Liu", "Xuebo", ""], ["Lai", "Houtim", ""], ["Wong", "Derek F.", ""], ["Chao", "Lidia S.", ""]]}, {"id": "2006.02104", "submitter": "Arkaitz Zubiaga", "authors": "Arkaitz Zubiaga", "title": "Exploiting Class Labels to Boost Performance on Embedding-based Text\n  Classification", "comments": "CIKM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text classification is one of the most frequent tasks for processing textual\ndata, facilitating among others research from large-scale datasets. Embeddings\nof different kinds have recently become the de facto standard as features used\nfor text classification. These embeddings have the capacity to capture meanings\nof words inferred from occurrences in large external collections. While they\nare built out of external collections, they are unaware of the distributional\ncharacteristics of words in the classification dataset at hand, including most\nimportantly the distribution of words across classes in training data. To make\nthe most of these embeddings as features and to boost the performance of\nclassifiers using them, we introduce a weighting scheme, Term\nFrequency-Category Ratio (TF-CR), which can weight high-frequency,\ncategory-exclusive words higher when computing word embeddings. Our experiments\non eight datasets show the effectiveness of TF-CR, leading to improved\nperformance scores over the well-known weighting schemes TF-IDF and KLD as well\nas over the absence of a weighting scheme in most cases.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 08:53:40 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 19:39:36 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Zubiaga", "Arkaitz", ""]]}, {"id": "2006.02120", "submitter": "Boris Mocialov", "authors": "Boris Mocialov, Graham Turner, Helen Hastie", "title": "Towards Large-Scale Data Mining for Data-Driven Analysis of Sign\n  Languages", "comments": "https://colab.research.google.com/drive/118Sx1ua-NXy9kjqWi94vz-RrRVYKmnDl?usp=sharing", "journal-ref": "Proceedings of the 9th Workshop on the Representation and\n  Processing of Sign Languages (LREC 2020)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Access to sign language data is far from adequate. We show that it is\npossible to collect the data from social networking services such as TikTok,\nInstagram, and YouTube by applying data filtering to enforce quality standards\nand by discovering patterns in the filtered data, making it easier to analyse\nand model. Using our data collection pipeline, we collect and examine the\ninterpretation of songs in both the American Sign Language (ASL) and the\nBrazilian Sign Language (Libras). We explore their differences and similarities\nby looking at the co-dependence of the orientation and location phonological\nparameters\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 09:28:17 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Mocialov", "Boris", ""], ["Turner", "Graham", ""], ["Hastie", "Helen", ""]]}, {"id": "2006.02144", "submitter": "Boris Mocialov", "authors": "Boris Mocialov, Graham Turner, Helen Hastie", "title": "Transfer Learning for British Sign Language Modelling", "comments": "10 pages, 3 figures", "journal-ref": "Proceedings of the Sixth Workshop on NLP for Similar Languages,\n  Varieties and Dialects, VarDial (2018)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Automatic speech recognition and spoken dialogue systems have made great\nadvances through the use of deep machine learning methods. This is partly due\nto greater computing power but also through the large amount of data available\nin common languages, such as English. Conversely, research in minority\nlanguages, including sign languages, is hampered by the severe lack of data.\nThis has led to work on transfer learning methods, whereby a model developed\nfor one language is reused as the starting point for a model on a second\nlanguage, which is less resourced. In this paper, we examine two transfer\nlearning techniques of fine-tuning and layer substitution for language\nmodelling of British Sign Language. Our results show improvement in perplexity\nwhen using transfer learning with standard stacked LSTM models, trained\ninitially using a large corpus for standard English from the Penn Treebank\ncorpus\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 10:13:29 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Mocialov", "Boris", ""], ["Turner", "Graham", ""], ["Hastie", "Helen", ""]]}, {"id": "2006.02163", "submitter": "Xuan Phi Nguyen", "authors": "Xuan-Phi Nguyen, Shafiq Joty, Thanh-Tung Nguyen, Wu Kui, Ai Ti Aw", "title": "Cross-model Back-translated Distillation for Unsupervised Machine\n  Translation", "comments": "Accepted to a conference paper at ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent unsupervised machine translation (UMT) systems usually employ three\nmain principles: initialization, language modeling and iterative\nback-translation, though they may apply them differently. Crucially, iterative\nback-translation and denoising auto-encoding for language modeling provide data\ndiversity to train the UMT systems. However, the gains from these\ndiversification processes has seemed to plateau. We introduce a novel component\nto the standard UMT framework called Cross-model Back-translated Distillation\n(CBD), that is aimed to induce another level of data diversification that\nexisting principles lack. CBD is applicable to all previous UMT approaches. In\nour experiments, CBD achieves the state of the art in the WMT'14\nEnglish-French, WMT'16 English-German and English-Romanian bilingual\nunsupervised translation tasks, with 38.2, 30.1, and 36.3 BLEU respectively. It\nalso yields 1.5-3.3 BLEU improvements in IWSLT English-French and\nEnglish-German tasks. Through extensive experimental analyses, we show that CBD\nis effective because it embraces data diversity while other similar variants do\nnot.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 10:57:21 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 14:07:14 GMT"}, {"version": "v3", "created": "Sat, 6 Feb 2021 18:02:41 GMT"}, {"version": "v4", "created": "Mon, 24 May 2021 16:07:26 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Nguyen", "Xuan-Phi", ""], ["Joty", "Shafiq", ""], ["Nguyen", "Thanh-Tung", ""], ["Kui", "Wu", ""], ["Aw", "Ai Ti", ""]]}, {"id": "2006.02174", "submitter": "Alessandro Suglia", "authors": "Alessandro Suglia, Ioannis Konstas, Andrea Vanzo, Emanuele\n  Bastianelli, Desmond Elliott, Stella Frank and Oliver Lemon", "title": "CompGuessWhat?!: A Multi-task Evaluation Framework for Grounded Language\n  Learning", "comments": "Accepted to the Annual Conference of the Association for\n  Computational Linguistics (ACL) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approaches to Grounded Language Learning typically focus on a single\ntask-based final performance measure that may not depend on desirable\nproperties of the learned hidden representations, such as their ability to\npredict salient attributes or to generalise to unseen situations. To remedy\nthis, we present GROLLA, an evaluation framework for Grounded Language Learning\nwith Attributes with three sub-tasks: 1) Goal-oriented evaluation; 2) Object\nattribute prediction evaluation; and 3) Zero-shot evaluation. We also propose a\nnew dataset CompGuessWhat?! as an instance of this framework for evaluating the\nquality of learned neural representations, in particular concerning attribute\ngrounding. To this end, we extend the original GuessWhat?! dataset by including\na semantic layer on top of the perceptual one. Specifically, we enrich the\nVisualGenome scene graphs associated with the GuessWhat?! images with abstract\nand situated attributes. By using diagnostic classifiers, we show that current\nmodels learn representations that are not expressive enough to encode object\nattributes (average F1 of 44.27). In addition, they do not learn strategies nor\nrepresentations that are robust enough to perform well when novel scenes or\nobjects are involved in gameplay (zero-shot best accuracy 50.06%).\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 11:21:42 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Suglia", "Alessandro", ""], ["Konstas", "Ioannis", ""], ["Vanzo", "Andrea", ""], ["Bastianelli", "Emanuele", ""], ["Elliott", "Desmond", ""], ["Frank", "Stella", ""], ["Lemon", "Oliver", ""]]}, {"id": "2006.02295", "submitter": "Herman Kamper", "authors": "Herman Kamper, Yevgen Matusevych, Sharon Goldwater", "title": "Improved acoustic word embeddings for zero-resource languages using\n  multilingual transfer", "comments": "11 pages, 7 figures, 8 tables. arXiv admin note: text overlap with\n  arXiv:2002.02109. Submitted to the IEEE Transactions on Audio, Speech and\n  Language Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustic word embeddings are fixed-dimensional representations of\nvariable-length speech segments. Such embeddings can form the basis for speech\nsearch, indexing and discovery systems when conventional speech recognition is\nnot possible. In zero-resource settings where unlabelled speech is the only\navailable resource, we need a method that gives robust embeddings on an\narbitrary language. Here we explore multilingual transfer: we train a single\nsupervised embedding model on labelled data from multiple well-resourced\nlanguages and then apply it to unseen zero-resource languages. We consider\nthree multilingual recurrent neural network (RNN) models: a classifier trained\non the joint vocabularies of all training languages; a Siamese RNN trained to\ndiscriminate between same and different words from multiple languages; and a\ncorrespondence autoencoder (CAE) RNN trained to reconstruct word pairs. In a\nword discrimination task on six target languages, all of these models\noutperform state-of-the-art unsupervised models trained on the zero-resource\nlanguages themselves, giving relative improvements of more than 30% in average\nprecision. When using only a few training languages, the multilingual CAE\nperforms better, but with more training languages the other multilingual models\nperform similarly. Using more training languages is generally beneficial, but\nimprovements are marginal on some languages. We present probing experiments\nwhich show that the CAE encodes more phonetic, word duration, language identity\nand speaker information than the other multilingual models.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 12:28:34 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 08:03:25 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Kamper", "Herman", ""], ["Matusevych", "Yevgen", ""], ["Goldwater", "Sharon", ""]]}, {"id": "2006.02419", "submitter": "Angeliki  Lazaridou", "authors": "Angeliki Lazaridou, Marco Baroni", "title": "Emergent Multi-Agent Communication in the Deep Learning Era", "comments": "Added some more references and discussion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to cooperate through language is a defining feature of humans. As\nthe perceptual, motory and planning capabilities of deep artificial networks\nincrease, researchers are studying whether they also can develop a shared\nlanguage to interact. From a scientific perspective, understanding the\nconditions under which language evolves in communities of deep agents and its\nemergent features can shed light on human language evolution. From an applied\nperspective, endowing deep networks with the ability to solve problems\ninteractively by communicating with each other and with us should make them\nmore flexible and useful in everyday life.\n  This article surveys representative recent language emergence studies from\n  both of these two angles.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 17:50:16 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 09:21:53 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Lazaridou", "Angeliki", ""], ["Baroni", "Marco", ""]]}, {"id": "2006.02490", "submitter": "Juan Pino", "authors": "Juan Pino and Qiantong Xu and Xutai Ma and Mohammad Javad Dousti and\n  Yun Tang", "title": "Self-Training for End-to-End Speech Translation", "comments": "INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main challenges for end-to-end speech translation is data\nscarcity. We leverage pseudo-labels generated from unlabeled audio by a cascade\nand an end-to-end speech translation model. This provides 8.3 and 5.7 BLEU\ngains over a strong semi-supervised baseline on the MuST-C English-French and\nEnglish-German datasets, reaching state-of-the art performance. The effect of\nthe quality of the pseudo-labels is investigated. Our approach is shown to be\nmore effective than simply pre-training the encoder on the speech recognition\ntask. Finally, we demonstrate the effectiveness of self-training by directly\ngenerating pseudo-labels with an end-to-end model instead of a cascade model.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 19:28:36 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 05:25:01 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Pino", "Juan", ""], ["Xu", "Qiantong", ""], ["Ma", "Xutai", ""], ["Dousti", "Mohammad Javad", ""], ["Tang", "Yun", ""]]}, {"id": "2006.02547", "submitter": "Sameer Khurana", "authors": "Sameer Khurana, Antoine Laurent, Wei-Ning Hsu, Jan Chorowski, Adrian\n  Lancucki, Ricard Marxer, James Glass", "title": "A Convolutional Deep Markov Model for Unsupervised Speech Representation\n  Learning", "comments": "Proceedings of Interspeech, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic Latent Variable Models (LVMs) provide an alternative to\nself-supervised learning approaches for linguistic representation learning from\nspeech. LVMs admit an intuitive probabilistic interpretation where the latent\nstructure shapes the information extracted from the signal. Even though LVMs\nhave recently seen a renewed interest due to the introduction of Variational\nAutoencoders (VAEs), their use for speech representation learning remains\nlargely unexplored. In this work, we propose Convolutional Deep Markov Model\n(ConvDMM), a Gaussian state-space model with non-linear emission and transition\nfunctions modelled by deep neural networks. This unsupervised model is trained\nusing black box variational inference. A deep convolutional neural network is\nused as an inference network for structured variational approximation. When\ntrained on a large scale speech dataset (LibriSpeech), ConvDMM produces\nfeatures that significantly outperform multiple self-supervised feature\nextracting methods on linear phone classification and recognition on the Wall\nStreet Journal dataset. Furthermore, we found that ConvDMM complements\nself-supervised methods like Wav2Vec and PASE, improving on the results\nachieved with any of the methods alone. Lastly, we find that ConvDMM features\nenable learning better phone recognizers than any other features in an extreme\nlow-resource regime with few labeled training examples.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 21:50:20 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 14:09:58 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Khurana", "Sameer", ""], ["Laurent", "Antoine", ""], ["Hsu", "Wei-Ning", ""], ["Chorowski", "Jan", ""], ["Lancucki", "Adrian", ""], ["Marxer", "Ricard", ""], ["Glass", "James", ""]]}, {"id": "2006.02567", "submitter": "Shi Zong", "authors": "Shi Zong, Ashutosh Baheti, Wei Xu, Alan Ritter", "title": "Extracting COVID-19 Events from Twitter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a corpus of 7,500 tweets annotated with COVID-19 events, including\npositive test results, denied access to testing, and more. We show that our\ncorpus enables automatic identification of COVID-19 events mentioned in Twitter\nwith text spans that fill a set of pre-defined slots for each event. We also\npresent analyses on the self-reporting cases and user's demographic\ninformation. We will make our annotated corpus and extraction tools available\nfor the research community to use upon publication at\nhttps://github.com/viczong/extract_COVID19_events_from_Twitter\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 22:39:24 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 16:29:20 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Zong", "Shi", ""], ["Baheti", "Ashutosh", ""], ["Xu", "Wei", ""], ["Ritter", "Alan", ""]]}, {"id": "2006.02588", "submitter": "Yumo Xu", "authors": "Yumo Xu, Chenguang Zhu, Baolin Peng and Michael Zeng", "title": "Meta Dialogue Policy Learning", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialog policy determines the next-step actions for agents and hence is\ncentral to a dialogue system. However, when migrated to novel domains with\nlittle data, a policy model can fail to adapt due to insufficient interactions\nwith the new environment. We propose Deep Transferable Q-Network (DTQN) to\nutilize shareable low-level signals between domains, such as dialogue acts and\nslots. We decompose the state and action representation space into feature\nsubspaces corresponding to these low-level components to facilitate\ncross-domain knowledge transfer. Furthermore, we embed DTQN in a meta-learning\nframework and introduce Meta-DTQN with a dual-replay mechanism to enable\neffective off-policy training and adaptation. In experiments, our model\noutperforms baseline models in terms of both success rate and dialogue\nefficiency on the multi-domain dialogue dataset MultiWOZ 2.0.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 23:53:06 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Xu", "Yumo", ""], ["Zhu", "Chenguang", ""], ["Peng", "Baolin", ""], ["Zeng", "Michael", ""]]}, {"id": "2006.02633", "submitter": "Serhad Sarica", "authors": "Serhad Sarica and Jianxi Luo", "title": "Stopwords in Technical Language Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are increasingly applications of natural language processing techniques\nfor information retrieval, indexing and topic modelling in the engineering\ncontexts. A standard component of such tasks is the removal of stopwords, which\nare uninformative components of the data. While researchers use readily\navailable stopword lists which are derived for general English language, the\ntechnical jargon of engineering fields contains their own highly frequent and\nuninformative words and there exists no standard stopword list for technical\nlanguage processing applications. Here we address this gap by rigorously\nidentifying generic, insignificant, uninformative stopwords in engineering\ntexts beyond the stopwords in general texts, based on the synthesis of\nalternative data-driven approaches, and curating a stopword list ready for\ntechnical language processing applications.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 03:52:59 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Sarica", "Serhad", ""], ["Luo", "Jianxi", ""]]}, {"id": "2006.02635", "submitter": "Haoyang Huang", "authors": "Minheng Ni, Haoyang Huang, Lin Su, Edward Cui, Taroon Bharti, Lijuan\n  Wang, Jianfeng Gao, Dongdong Zhang and Nan Duan", "title": "M3P: Learning Universal Representations via Multitask Multilingual\n  Multimodal Pre-training", "comments": "Accepted to CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present M3P, a Multitask Multilingual Multimodal Pre-trained model that\ncombines multilingual pre-training and multimodal pre-training into a unified\nframework via multitask pre-training. Our goal is to learn universal\nrepresentations that can map objects occurred in different modalities or texts\nexpressed in different languages into a common semantic space. In addition, to\nexplicitly encourage fine-grained alignment between images and non-English\nlanguages, we also propose Multimodal Code-switched Training (MCT) to combine\nmonolingual pre-training and multimodal pre-training via a code-switch\nstrategy. Experiments are performed on the multilingual image retrieval task\nacross two benchmark datasets, including MSCOCO and Multi30K. M3P can achieve\ncomparable results for English and new state-of-the-art results for non-English\nlanguages.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 03:54:29 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 04:58:59 GMT"}, {"version": "v3", "created": "Mon, 22 Mar 2021 07:53:52 GMT"}, {"version": "v4", "created": "Thu, 1 Apr 2021 03:43:53 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Ni", "Minheng", ""], ["Huang", "Haoyang", ""], ["Su", "Lin", ""], ["Cui", "Edward", ""], ["Bharti", "Taroon", ""], ["Wang", "Lijuan", ""], ["Gao", "Jianfeng", ""], ["Zhang", "Dongdong", ""], ["Duan", "Nan", ""]]}, {"id": "2006.02648", "submitter": "Andreas Chandra", "authors": "Andreas Chandra, Ruben Stefanus", "title": "Experiments on Paraphrase Identification Using Quora Question Pairs\n  Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We modeled the Quora question pairs dataset to identify a similar question.\nThe dataset that we use is provided by Quora. The task is a binary\nclassification. We tried several methods and algorithms and different approach\nfrom previous works. For feature extraction, we used Bag of Words including\nCount Vectorizer, and Term Frequency-Inverse Document Frequency with unigram\nfor XGBoost and CatBoost. Furthermore, we also experimented with WordPiece\ntokenizer which improves the model performance significantly. We achieved up to\n97 percent accuracy. Code and Dataset.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 05:43:25 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 03:38:51 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Chandra", "Andreas", ""], ["Stefanus", "Ruben", ""]]}, {"id": "2006.02767", "submitter": "Abonia Sojasingarayar", "authors": "Abonia Sojasingarayar", "title": "Seq2Seq AI Chatbot with Attention Mechanism", "comments": "18 pages 8 Figures 4 Tables 5 Equations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent Conversational Agent development using Artificial Intelligence or\nMachine Learning technique is an interesting problem in the field of Natural\nLanguage Processing. With the rise of deep learning, these models were quickly\nreplaced by end to end trainable neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 10:54:43 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Sojasingarayar", "Abonia", ""]]}, {"id": "2006.02786", "submitter": "Thilo von Neumann", "authors": "Thilo von Neumann, Christoph Boeddeker, Lukas Drude, Keisuke\n  Kinoshita, Marc Delcroix, Tomohiro Nakatani, Reinhold Haeb-Umbach", "title": "Multi-talker ASR for an unknown number of sources: Joint training of\n  source counting, separation and ASR", "comments": "5 pages, INTERSPEECH 2020", "journal-ref": null, "doi": "10.21437/Interspeech.2020-2519", "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most approaches to multi-talker overlapped speech separation and recognition\nassume that the number of simultaneously active speakers is given, but in\nrealistic situations, it is typically unknown. To cope with this, we extend an\niterative speech extraction system with mechanisms to count the number of\nsources and combine it with a single-talker speech recognizer to form the first\nend-to-end multi-talker automatic speech recognition system for an unknown\nnumber of active speakers. Our experiments show very promising performance in\ncounting accuracy, source separation and speech recognition on simulated clean\nmixtures from WSJ0-2mix and WSJ0-3mix. Among others, we set a new\nstate-of-the-art word error rate on the WSJ0-2mix database. Furthermore, our\nsystem generalizes well to a larger number of speakers than it ever saw during\ntraining, as shown in experiments with the WSJ0-4mix database.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 11:25:50 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 11:18:33 GMT"}, {"version": "v3", "created": "Mon, 21 Dec 2020 12:27:40 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["von Neumann", "Thilo", ""], ["Boeddeker", "Christoph", ""], ["Drude", "Lukas", ""], ["Kinoshita", "Keisuke", ""], ["Delcroix", "Marc", ""], ["Nakatani", "Tomohiro", ""], ["Haeb-Umbach", "Reinhold", ""]]}, {"id": "2006.02814", "submitter": "Antoine Laurent", "authors": "Sameer Khurana, Antoine Laurent, James Glass", "title": "CSTNet: Contrastive Speech Translation Network for Self-Supervised\n  Speech Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More than half of the 7,000 languages in the world are in imminent danger of\ngoing extinct. Traditional methods of documenting language proceed by\ncollecting audio data followed by manual annotation by trained linguists at\ndifferent levels of granularity. This time consuming and painstaking process\ncould benefit from machine learning. Many endangered languages do not have any\northographic form but usually have speakers that are bi-lingual and trained in\na high resource language. It is relatively easy to obtain textual translations\ncorresponding to speech. In this work, we provide a multimodal machine learning\nframework for speech representation learning by exploiting the correlations\nbetween the two modalities namely speech and its corresponding text\ntranslation. Here, we construct a convolutional neural network audio encoder\ncapable of extracting linguistic representations from speech. The audio encoder\nis trained to perform a speech-translation retrieval task in a contrastive\nlearning framework. By evaluating the learned representations on a phone\nrecognition task, we demonstrate that linguistic representations emerge in the\naudio encoder's internal representations as a by-product of learning to perform\nthe retrieval task.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 12:21:48 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 07:28:36 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Khurana", "Sameer", ""], ["Laurent", "Antoine", ""], ["Glass", "James", ""]]}, {"id": "2006.02876", "submitter": "Idris Abdulmumin", "authors": "Idris Abdulmumin, Bashir Shehu Galadanci, Abubakar Isa", "title": "Enhanced back-translation for low resource neural machine translation\n  using self-training", "comments": "17 pages, 3 figures, 5 tables; Accepted for publication in the\n  International Conference on Information and Communication Technology and\n  Applications (ICTA 2020)", "journal-ref": null, "doi": "10.1007/978-3-030-69143-1_28", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Improving neural machine translation (NMT) models using the back-translations\nof the monolingual target data (synthetic parallel data) is currently the\nstate-of-the-art approach for training improved translation systems. The\nquality of the backward system - which is trained on the available parallel\ndata and used for the back-translation - has been shown in many studies to\naffect the performance of the final NMT model. In low resource conditions, the\navailable parallel data is usually not enough to train a backward model that\ncan produce the qualitative synthetic data needed to train a standard\ntranslation model. This work proposes a self-training strategy where the output\nof the backward model is used to improve the model itself through the forward\ntranslation technique. The technique was shown to improve baseline low resource\nIWSLT'14 English-German and IWSLT'15 English-Vietnamese backward translation\nmodels by 11.06 and 1.5 BLEUs respectively. The synthetic data generated by the\nimproved English-German backward model was used to train a forward model which\nout-performed another forward model trained using standard back-translation by\n2.7 BLEU.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 14:19:52 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 18:35:33 GMT"}, {"version": "v3", "created": "Thu, 24 Dec 2020 10:35:31 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Abdulmumin", "Idris", ""], ["Galadanci", "Bashir Shehu", ""], ["Isa", "Abubakar", ""]]}, {"id": "2006.02951", "submitter": "Gasper Begus", "authors": "Ga\\v{s}per Begu\\v{s}", "title": "CiwGAN and fiwGAN: Encoding information in acoustic data to model\n  lexical learning with Generative Adversarial Networks", "comments": "Published in Neural Networks", "journal-ref": "Neural Networks 139 (2021), pp. 305-325", "doi": "10.1016/j.neunet.2021.03.017", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  How can deep neural networks encode information that corresponds to words in\nhuman speech into raw acoustic data? This paper proposes two neural network\narchitectures for modeling unsupervised lexical learning from raw acoustic\ninputs, ciwGAN (Categorical InfoWaveGAN) and fiwGAN (Featural InfoWaveGAN),\nthat combine a Deep Convolutional GAN architecture for audio data (WaveGAN;\narXiv:1705.07904) with an information theoretic extension of GAN -- InfoGAN\n(arXiv:1606.03657), and propose a new latent space structure that can model\nfeatural learning simultaneously with a higher level classification and allows\nfor a very low-dimension vector representation of lexical items. Lexical\nlearning is modeled as emergent from an architecture that forces a deep neural\nnetwork to output data such that unique information is retrievable from its\nacoustic outputs. The networks trained on lexical items from TIMIT learn to\nencode unique information corresponding to lexical items in the form of\ncategorical variables in their latent space. By manipulating these variables,\nthe network outputs specific lexical items. The network occasionally outputs\ninnovative lexical items that violate training data, but are linguistically\ninterpretable and highly informative for cognitive modeling and neural network\ninterpretability. Innovative outputs suggest that phonetic and phonological\nrepresentations learned by the network can be productively recombined and\ndirectly paralleled to productivity in human speech: a fiwGAN network trained\non `suit' and `dark' outputs innovative `start', even though it never saw\n`start' or even a [st] sequence in the training data. We also argue that\nsetting latent featural codes to values well beyond training range results in\nalmost categorical generation of prototypical lexical items and reveals\nunderlying values of each latent code.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 15:33:55 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 07:02:03 GMT"}, {"version": "v3", "created": "Wed, 28 Jul 2021 10:31:31 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Begu\u0161", "Ga\u0161per", ""]]}, {"id": "2006.02964", "submitter": "Maria N\\u{a}dejde", "authors": "Maria Nadejde and Joel Tetreault", "title": "Personalizing Grammatical Error Correction: Adaptation to Proficiency\n  Level and L1", "comments": "Proceedings of the 2019 EMNLP Workshop W-NUT: The 5th Workshop on\n  Noisy User-generated Text", "journal-ref": "Proceedings of the 2019 EMNLP Workshop W-NUT: The 5th Workshop on\n  Noisy User-generated Text, pages 27-33, Hong Kong, Nov 4, 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grammar error correction (GEC) systems have become ubiquitous in a variety of\nsoftware applications, and have started to approach human-level performance for\nsome datasets. However, very little is known about how to efficiently\npersonalize these systems to the user's characteristics, such as their\nproficiency level and first language, or to emerging domains of text. We\npresent the first results on adapting a general-purpose neural GEC system to\nboth the proficiency level and the first language of a writer, using only a few\nthousand annotated sentences. Our study is the broadest of its kind, covering\nfive proficiency levels and twelve different languages, and comparing three\ndifferent adaptation scenarios: adapting to the proficiency level only, to the\nfirst language only, or to both aspects simultaneously. We show that tailoring\nto both scenarios achieves the largest performance improvement (3.6 F0.5)\nrelative to a strong baseline.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 15:47:29 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Nadejde", "Maria", ""], ["Tetreault", "Joel", ""]]}, {"id": "2006.02965", "submitter": "Marco Gaido", "authors": "Marco Gaido, Mattia Antonino Di Gangi, Matteo Negri, Marco Turchi", "title": "End-to-End Speech-Translation with Knowledge Distillation: FBK@IWSLT2020", "comments": "Accepted at IWSLT2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes FBK's participation in the IWSLT 2020 offline speech\ntranslation (ST) task. The task evaluates systems' ability to translate English\nTED talks audio into German texts. The test talks are provided in two versions:\none contains the data already segmented with automatic tools and the other is\nthe raw data without any segmentation. Participants can decide whether to work\non custom segmentation or not. We used the provided segmentation. Our system is\nan end-to-end model based on an adaptation of the Transformer for speech data.\nIts training process is the main focus of this paper and it is based on: i)\ntransfer learning (ASR pretraining and knowledge distillation), ii) data\naugmentation (SpecAugment, time stretch and synthetic data), iii) combining\nsynthetic and real data marked as different domains, and iv) multi-task\nlearning using the CTC loss. Finally, after the training with word-level\nknowledge distillation is complete, our ST models are fine-tuned using label\nsmoothed cross entropy. Our best model scored 29 BLEU on the MuST-C En-De test\nset, which is an excellent result compared to recent papers, and 23.7 BLEU on\nthe same data segmented with VAD, showing the need for researching solutions\naddressing this specific data condition.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 15:47:47 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Gaido", "Marco", ""], ["Di Gangi", "Mattia Antonino", ""], ["Negri", "Matteo", ""], ["Turchi", "Marco", ""]]}, {"id": "2006.03002", "submitter": "Guy Edward Toh Emerson", "authors": "Guy Emerson", "title": "Linguists Who Use Probabilistic Models Love Them: Quantification in\n  Functional Distributional Semantics", "comments": "To be published in Proceedings of Probability and Meaning 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional Distributional Semantics provides a computationally tractable\nframework for learning truth-conditional semantics from a corpus. Previous work\nin this framework has provided a probabilistic version of first-order logic,\nrecasting quantification as Bayesian inference. In this paper, I show how the\nprevious formulation gives trivial truth values when a precise quantifier is\nused with vague predicates. I propose an improved account, avoiding this\nproblem by treating a vague predicate as a distribution over precise\npredicates. I connect this account to recent work in the Rational Speech Acts\nframework on modelling generic quantification, and I extend this to modelling\ndonkey sentences. Finally, I explain how the generic quantifier can be both\npragmatically complex and yet computationally simpler than precise quantifiers.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 16:48:45 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Emerson", "Guy", ""]]}, {"id": "2006.03010", "submitter": "Hillel Taub-Tabib", "authors": "Micah Shlain, Hillel Taub-Tabib, Shoval Sadde, Yoav Goldberg", "title": "Syntactic Search by Example", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a system that allows a user to search a large linguistically\nannotated corpus using syntactic patterns over dependency graphs. In contrast\nto previous attempts to this effect, we introduce a light-weight query language\nthat does not require the user to know the details of the underlying syntactic\nrepresentations, and instead to query the corpus by providing an example\nsentence coupled with simple markup. Search is performed at an interactive\nspeed due to an efficient linguistic graph-indexing and retrieval engine. This\nallows for rapid exploration, development and refinement of syntax-based\nqueries. We demonstrate the system using queries over two corpora: the English\nwikipedia, and a collection of English pubmed abstracts. A demo of the\nwikipedia system is available at: https://allenai.github.io/spike\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 16:59:01 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Shlain", "Micah", ""], ["Taub-Tabib", "Hillel", ""], ["Sadde", "Shoval", ""], ["Goldberg", "Yoav", ""]]}, {"id": "2006.03022", "submitter": "Hao Wu", "authors": "Hao Wu, Gareth J. F. Jones, Francois Pitie", "title": "Response to LiveBot: Generating Live Video Comments Based on Visual and\n  Textual Contexts", "comments": "4 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": "06-04", "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Live video commenting systems are an emerging feature of online video sites.\nRecently the Chinese video sharing platform Bilibili, has popularised a novel\ncaptioning system where user comments are displayed as streams of moving\nsubtitles overlaid on the video playback screen and broadcast to all viewers in\nreal-time. LiveBot was recently introduced as a novel Automatic Live Video\nCommenting (ALVC) application. This enables the automatic generation of live\nvideo comments from both the existing video stream and existing viewers\ncomments. In seeking to reproduce the baseline results reported in the original\nLivebot paper, we found differences between the reproduced results using the\nproject codebase and the numbers reported in the paper. Further examination of\nthis situation suggests that this may be caused by a number of small issues in\nthe project code, including a non-obvious overlap between the training and test\nsets. In this paper, we study these discrepancies in detail and propose an\nalternative baseline implementation as a reference for other researchers in\nthis field.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 17:16:22 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Wu", "Hao", ""], ["Jones", "Gareth J. F.", ""], ["Pitie", "Francois", ""]]}, {"id": "2006.03039", "submitter": "Annemarie Friedrich", "authors": "Annemarie Friedrich and Heike Adel and Federico Tomazic and Johannes\n  Hingerl and Renou Benteau and Anika Maruscyk and Lukas Lange", "title": "The SOFC-Exp Corpus and Neural Approaches to Information Extraction in\n  the Materials Science Domain", "comments": "Accepted for publication at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a new challenging information extraction task in the\ndomain of materials science. We develop an annotation scheme for marking\ninformation on experiments related to solid oxide fuel cells in scientific\npublications, such as involved materials and measurement conditions. With this\npaper, we publish our annotation guidelines, as well as our SOFC-Exp corpus\nconsisting of 45 open-access scholarly articles annotated by domain experts. A\ncorpus and an inter-annotator agreement study demonstrate the complexity of the\nsuggested named entity recognition and slot filling tasks as well as high\nannotation quality. We also present strong neural-network based models for a\nvariety of tasks that can be addressed on the basis of our new data set. On all\ntasks, using BERT embeddings leads to large performance gains, but with\nincreasing task complexity, adding a recurrent neural network on top seems\nbeneficial. Our models will serve as competitive baselines in future work, and\nanalysis of their performance highlights difficult cases when modeling the data\nand suggests promising research directions.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 17:49:34 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Friedrich", "Annemarie", ""], ["Adel", "Heike", ""], ["Tomazic", "Federico", ""], ["Hingerl", "Johannes", ""], ["Benteau", "Renou", ""], ["Maruscyk", "Anika", ""], ["Lange", "Lukas", ""]]}, {"id": "2006.03051", "submitter": "Jerry Wei", "authors": "Jerry Wei", "title": "NewB: 200,000+ Sentences for Political Bias Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Newspaper Bias Dataset (NewB), a text corpus of more than\n200,000 sentences from eleven news sources regarding Donald Trump. While\nprevious datasets have labeled sentences as either liberal or conservative,\nNewB covers the political views of eleven popular media sources, capturing more\nnuanced political viewpoints than a traditional binary classification system\ndoes. We train two state-of-the-art deep learning models to predict the news\nsource of a given sentence from eleven newspapers and find that a recurrent\nneural network achieved top-1, top-3, and top-5 accuracies of 33.3%, 61.4%, and\n77.6%, respectively, significantly outperforming a baseline logistic regression\nmodel's accuracies of 18.3%, 42.6%, and 60.8%. Using the news source label of\nsentences, we analyze the top n-grams with our model to gain meaningful insight\ninto the portrayal of Trump by media sources.We hope that the public release of\nour dataset will encourage further research in using natural language\nprocessing to analyze more complex political biases.\n  Our dataset is posted at https://github.com/JerryWei03/NewB .\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 18:21:50 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Wei", "Jerry", ""]]}, {"id": "2006.03096", "submitter": "Svetlana Kiritchenko", "authors": "Svetlana Kiritchenko, Will E. Hipson, Robert J. Coplan, Saif M.\n  Mohammad", "title": "SOLO: A Corpus of Tweets for Examining the State of Being Alone", "comments": "In Proceedings of the 12th edition of the Language Resources and\n  Evaluation Conference (LREC), May 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state of being alone can have a substantial impact on our lives, though\nexperiences with time alone diverge significantly among individuals.\nPsychologists distinguish between the concept of solitude, a positive state of\nvoluntary aloneness, and the concept of loneliness, a negative state of\ndissatisfaction with the quality of one's social interactions. Here, for the\nfirst time, we conduct a large-scale computational analysis to explore how the\nterms associated with the state of being alone are used in online language. We\npresent SOLO (State of Being Alone), a corpus of over 4 million tweets\ncollected with query terms 'solitude', 'lonely', and 'loneliness'. We use SOLO\nto analyze the language and emotions associated with the state of being alone.\nWe show that the term 'solitude' tends to co-occur with more positive,\nhigh-dominance words (e.g., enjoy, bliss) while the terms 'lonely' and\n'loneliness' frequently co-occur with negative, low-dominance words (e.g.,\nscared, depressed), which confirms the conceptual distinctions made in\npsychology. We also show that women are more likely to report on negative\nfeelings of being lonely as compared to men, and there are more teenagers among\nthe tweeters that use the word 'lonely' than among the tweeters that use the\nword 'solitude'.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 18:46:02 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Kiritchenko", "Svetlana", ""], ["Hipson", "Will E.", ""], ["Coplan", "Robert J.", ""], ["Mohammad", "Saif M.", ""]]}, {"id": "2006.03189", "submitter": "Erion \\c{C}ano", "authors": "Erion \\c{C}ano and Ond\\v{r}ej Bojar", "title": "Human or Machine: Automating Human Likeliness Evaluation of NLG Texts", "comments": "9 pages, 5 equations, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic evaluation of various text quality criteria produced by data-driven\nintelligent methods is very common and useful because it is cheap, fast, and\nusually yields repeatable results. In this paper, we present an attempt to\nautomate the human likeliness evaluation of the output text samples coming from\nnatural language generation methods used to solve several tasks. We propose to\nuse a human likeliness score that shows the percentage of the output samples\nfrom a method that look as if they were written by a human. Instead of having\nhuman participants label or rate those samples, we completely automate the\nprocess by using a discrimination procedure based on large pretrained language\nmodels and their probability distributions. As follow up, we plan to perform an\nempirical analysis of human-written and machine-generated texts to find the\noptimal setup of this evaluation approach. A validation procedure involving\nhuman participants will also check how the automatic evaluation correlates with\nhuman judgments.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 00:57:52 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["\u00c7ano", "Erion", ""], ["Bojar", "Ond\u0159ej", ""]]}, {"id": "2006.03202", "submitter": "Sharon Levy", "authors": "Sharon Levy and William Yang Wang", "title": "Cross-lingual Transfer Learning for COVID-19 Outbreak Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spread of COVID-19 has become a significant and troubling aspect of\nsociety in 2020. With millions of cases reported across countries, new\noutbreaks have occurred and followed patterns of previously affected areas.\nMany disease detection models do not incorporate the wealth of social media\ndata that can be utilized for modeling and predicting its spread. In this case,\nit is useful to ask, can we utilize this knowledge in one country to model the\noutbreak in another? To answer this, we propose the task of cross-lingual\ntransfer learning for epidemiological alignment. Utilizing both macro and micro\ntext features, we train on Italy's early COVID-19 outbreak through Twitter and\ntransfer to several other countries. Our experiments show strong results with\nup to 0.85 Spearman correlation in cross-country predictions.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 02:04:25 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 22:37:43 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Levy", "Sharon", ""], ["Wang", "William Yang", ""]]}, {"id": "2006.03210", "submitter": "Minh-Tien Nguyen", "authors": "Minh-Tien Nguyen and Bui Cong Minh and Dung Tien Le and Le Thai Linh", "title": "Sentence Compression as Deletion with Contextual Embeddings", "comments": "12 pages, 3 figures, accepted by ICCCI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence compression is the task of creating a shorter version of an input\nsentence while keeping important information. In this paper, we extend the task\nof compression by deletion with the use of contextual embeddings. Different\nfrom prior work usually using non-contextual embeddings (Glove or Word2Vec), we\nexploit contextual embeddings that enable our model capturing the context of\ninputs. More precisely, we utilize contextual embeddings stacked by\nbidirectional Long-short Term Memory and Conditional Random Fields for dealing\nwith sequence labeling. Experimental results on a benchmark Google dataset show\nthat by utilizing contextual embeddings, our model achieves a new\nstate-of-the-art F-score compared to strong methods reported on the leader\nboard.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 02:40:46 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Nguyen", "Minh-Tien", ""], ["Minh", "Bui Cong", ""], ["Le", "Dung Tien", ""], ["Linh", "Le Thai", ""]]}, {"id": "2006.03221", "submitter": "Shuang Zeng", "authors": "Sennan Liu, Shuang Zeng and Sujian Li", "title": "Evaluating Text Coherence at Sentence and Paragraph Levels", "comments": "Long paper accepted by LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, to evaluate text coherence, we propose the paragraph ordering\ntask as well as conducting sentence ordering. We collected four distinct\ncorpora from different domains on which we investigate the adaptation of\nexisting sentence ordering methods to a paragraph ordering task. We also\ncompare the learnability and robustness of existing models by artificially\ncreating mini datasets and noisy datasets respectively and verifying the\nefficiency of established models under these circumstances. Furthermore, we\ncarry out human evaluation on the rearranged passages from two competitive\nmodels and confirm that WLCS-l is a better metric performing significantly\nhigher correlations with human rating than tau, the most prevalent metric used\nbefore. Results from these evaluations show that except for certain extreme\nconditions, the recurrent graph neural network-based model is an optimal choice\nfor coherence modeling.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 03:31:49 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Liu", "Sennan", ""], ["Zeng", "Shuang", ""], ["Li", "Sujian", ""]]}, {"id": "2006.03236", "submitter": "Zihang Dai", "authors": "Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le", "title": "Funnel-Transformer: Filtering out Sequential Redundancy for Efficient\n  Language Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the success of language pretraining, it is highly desirable to develop\nmore efficient architectures of good scalability that can exploit the abundant\nunlabeled data at a lower cost. To improve the efficiency, we examine the\nmuch-overlooked redundancy in maintaining a full-length token-level\npresentation, especially for tasks that only require a single-vector\npresentation of the sequence. With this intuition, we propose\nFunnel-Transformer which gradually compresses the sequence of hidden states to\na shorter one and hence reduces the computation cost. More importantly, by\nre-investing the saved FLOPs from length reduction in constructing a deeper or\nwider model, we further improve the model capacity. In addition, to perform\ntoken-level predictions as required by common pretraining objectives,\nFunnel-Transformer is able to recover a deep representation for each token from\nthe reduced hidden sequence via a decoder. Empirically, with comparable or\nfewer FLOPs, Funnel-Transformer outperforms the standard Transformer on a wide\nvariety of sequence-level prediction tasks, including text classification,\nlanguage understanding, and reading comprehension. The code and pretrained\ncheckpoints are available at https://github.com/laiguokun/Funnel-Transformer.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 05:16:23 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Dai", "Zihang", ""], ["Lai", "Guokun", ""], ["Yang", "Yiming", ""], ["Le", "Quoc V.", ""]]}, {"id": "2006.03256", "submitter": "Gaurav Verma", "authors": "Gaurav Verma, Niyati Chhaya, Vishwa Vinay", "title": "\"To Target or Not to Target\": Identification and Analysis of Abusive\n  Text Using Ensemble of Classifiers", "comments": "In ICWSM'20 Safety Data Challenge", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With rising concern around abusive and hateful behavior on social media\nplatforms, we present an ensemble learning method to identify and analyze the\nlinguistic properties of such content. Our stacked ensemble comprises of three\nmachine learning models that capture different aspects of language and provide\ndiverse and coherent insights about inappropriate language. The proposed\napproach provides comparable results to the existing state-of-the-art on the\nTwitter Abusive Behavior dataset (Founta et al. 2018) without using any user or\nnetwork-related information; solely relying on textual properties. We believe\nthat the presented insights and discussion of shortcomings of current\napproaches will highlight potential directions for future research.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 06:59:22 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Verma", "Gaurav", ""], ["Chhaya", "Niyati", ""], ["Vinay", "Vishwa", ""]]}, {"id": "2006.03257", "submitter": "Souvic Chakraborty", "authors": "Souvic Chakraborty, Pawan Goyal, Animesh Mukherjee", "title": "Aspect-based Sentiment Analysis of Scientific Reviews", "comments": "Accepted in JCDL'20", "journal-ref": null, "doi": "10.1145/3383583.3398541", "report-no": null, "categories": "cs.CL cs.DL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific papers are complex and understanding the usefulness of these\npapers requires prior knowledge. Peer reviews are comments on a paper provided\nby designated experts on that field and hold a substantial amount of\ninformation, not only for the editors and chairs to make the final decision,\nbut also to judge the potential impact of the paper. In this paper, we propose\nto use aspect-based sentiment analysis of scientific reviews to be able to\nextract useful information, which correlates well with the accept/reject\ndecision.\n  While working on a dataset of close to 8k reviews from ICLR, one of the top\nconferences in the field of machine learning, we use an active learning\nframework to build a training dataset for aspect prediction, which is further\nused to obtain the aspects and sentiments for the entire dataset. We show that\nthe distribution of aspect-based sentiments obtained from a review is\nsignificantly different for accepted and rejected papers. We use the aspect\nsentiments from these reviews to make an intriguing observation, certain\naspects present in a paper and discussed in the review strongly determine the\nfinal recommendation. As a second objective, we quantify the extent of\ndisagreement among the reviewers refereeing a paper. We also investigate the\nextent of disagreement between the reviewers and the chair and find that the\ninter-reviewer disagreement may have a link to the disagreement with the chair.\nOne of the most interesting observations from this study is that reviews, where\nthe reviewer score and the aspect sentiments extracted from the review text\nwritten by the reviewer are consistent, are also more likely to be concurrent\nwith the chair's decision.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 07:06:01 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Chakraborty", "Souvic", ""], ["Goyal", "Pawan", ""], ["Mukherjee", "Animesh", ""]]}, {"id": "2006.03265", "submitter": "Shu-Wen Yang", "authors": "Shu-wen Yang, Andy T. Liu, Hung-yi Lee", "title": "Understanding Self-Attention of Self-Supervised Audio Transformers", "comments": "Accepted by INTERSPEECH 2020, ICML 2020 Workshop on Self-supervision\n  in Audio and Speech", "journal-ref": "INTERSPEECH 2020", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised Audio Transformers (SAT) enable great success in many\ndownstream speech applications like ASR, but how they work has not been widely\nexplored yet. In this work, we present multiple strategies for the analysis of\nattention mechanisms in SAT. We categorize attentions into explainable\ncategories, where we discover each category possesses its own unique\nfunctionality. We provide a visualization tool for understanding multi-head\nself-attention, importance ranking strategies for identifying critical\nattention, and attention refinement techniques to improve model performance.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 07:23:03 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 18:48:41 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Yang", "Shu-wen", ""], ["Liu", "Andy T.", ""], ["Lee", "Hung-yi", ""]]}, {"id": "2006.03274", "submitter": "Ankit Gupta", "authors": "Ankit Gupta, Jonathan Berant", "title": "GMAT: Global Memory Augmentation for Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer-based models have become ubiquitous in natural language\nprocessing thanks to their large capacity, innate parallelism and high\nperformance. The contextualizing component of a Transformer block is the\n$\\textit{pairwise dot-product}$ attention that has a large $\\Omega(L^2)$ memory\nrequirement for length $L$ sequences, limiting its ability to process long\ndocuments. This has been the subject of substantial interest recently, where\nmultiple approximations were proposed to reduce the quadratic memory\nrequirement using sparse attention matrices. In this work, we propose to\naugment sparse Transformer blocks with a dense attention-based $\\textit{global\nmemory}$ of length $M$ ($\\ll L$) which provides an aggregate global view of the\nentire input sequence to each position. Our augmentation has a manageable\n$O(M\\cdot(L+M))$ memory overhead, and can be seamlessly integrated with prior\nsparse solutions. Moreover, global memory can also be used for sequence\ncompression, by representing a long input sequence with the memory\nrepresentations only. We empirically show that our method leads to substantial\nimprovement on a range of tasks, including (a) synthetic tasks that require\nglobal reasoning, (b) masked language modeling, and (c) reading comprehension.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 07:50:40 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Gupta", "Ankit", ""], ["Berant", "Jonathan", ""]]}, {"id": "2006.03292", "submitter": "Ayush Garg", "authors": "Ayush Garg, Sammed Shantinath Kagi, Mayank Singh", "title": "SEAL: Scientific Keyphrase Extraction and Classification", "comments": "Accepted at JCDL 2020", "journal-ref": null, "doi": "10.1145/3383583.3398625", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic scientific keyphrase extraction is a challenging problem\nfacilitating several downstream scholarly tasks like search, recommendation,\nand ranking. In this paper, we introduce SEAL, a scholarly tool for automatic\nkeyphrase extraction and classification. The keyphrase extraction module\ncomprises two-stage neural architecture composed of Bidirectional Long\nShort-Term Memory cells augmented with Conditional Random Fields. The\nclassification module comprises of a Random Forest classifier. We extensively\nexperiment to showcase the robustness of the system. We evaluate multiple\nstate-of-the-art baselines and show a significant improvement. The current\nsystem is hosted at http://lingo.iitgn.ac.in:5000/.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 08:21:26 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Garg", "Ayush", ""], ["Kagi", "Sammed Shantinath", ""], ["Singh", "Mayank", ""]]}, {"id": "2006.03331", "submitter": "Dominik Mach\\'a\\v{c}ek", "authors": "Dominik Mach\\'a\\v{c}ek, Jon\\'a\\v{s} Kratochv\\'il, Sangeet Sagar,\n  Mat\\'u\\v{s} \\v{Z}ilinec, Ond\\v{r}ej Bojar, Thai-Son Nguyen, Felix Schneider,\n  Philip Williams, Yuekun Yao", "title": "ELITR Non-Native Speech Translation at IWSLT 2020", "comments": "IWSLT 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is an ELITR system submission for the non-native speech\ntranslation task at IWSLT 2020. We describe systems for offline ASR, real-time\nASR, and our cascaded approach to offline SLT and real-time SLT. We select our\nprimary candidates from a pool of pre-existing systems, develop a new\nend-to-end general ASR system, and a hybrid ASR trained on non-native speech.\nThe provided small validation set prevents us from carrying out a complex\nvalidation, but we submit all the unselected candidates for contrastive\nevaluation on the test set.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 09:29:57 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Mach\u00e1\u010dek", "Dominik", ""], ["Kratochv\u00edl", "Jon\u00e1\u0161", ""], ["Sagar", "Sangeet", ""], ["\u017dilinec", "Mat\u00fa\u0161", ""], ["Bojar", "Ond\u0159ej", ""], ["Nguyen", "Thai-Son", ""], ["Schneider", "Felix", ""], ["Williams", "Philip", ""], ["Yao", "Yuekun", ""]]}, {"id": "2006.03353", "submitter": "Haider Khalid", "authors": "Haider Khalid, Vincent Wade", "title": "Topic Detection from Conversational Dialogue Corpus with Parallel\n  Dirichlet Allocation Model and Elbow Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A conversational system needs to know how to switch between topics to\ncontinue the conversation for a more extended period. For this topic detection\nfrom dialogue corpus has become an important task for a conversation and\naccurate prediction of conversation topics is important for creating coherent\nand engaging dialogue systems. In this paper, we proposed a topic detection\napproach with Parallel Latent Dirichlet Allocation (PLDA) Model by clustering a\nvocabulary of known similar words based on TF-IDF scores and Bag of Words (BOW)\ntechnique. In the experiment, we use K-mean clustering with Elbow Method for\ninterpretation and validation of consistency within-cluster analysis to select\nthe optimal number of clusters. We evaluate our approach by comparing it with\ntraditional LDA and clustering technique. The experimental results show that\ncombining PLDA with Elbow method selects the optimal number of clusters and\nrefine the topics for the conversation.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 10:24:43 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Khalid", "Haider", ""], ["Wade", "Vincent", ""]]}, {"id": "2006.03354", "submitter": "Xingyi Song", "authors": "Xingyi Song, Johann Petrak, Ye Jiang, Iknoor Singh, Diana Maynard and\n  Kalina Bontcheva", "title": "Classification Aware Neural Topic Model and its Application on a New\n  COVID-19 Disinformation Corpus", "comments": "This is arXiv version of \"Classification Aware Neural Topic Model for\n  COVID-19 Disinformation Categorisation\"", "journal-ref": "PLOS ONE 2021", "doi": "10.1371/journal.pone.0247086", "report-no": null, "categories": "cs.LG cs.CL cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The explosion of disinformation accompanying the COVID-19 pandemic has\noverloaded fact-checkers and media worldwide, and brought a new major challenge\nto government responses worldwide. Not only is disinformation creating\nconfusion about medical science amongst citizens, but it is also amplifying\ndistrust in policy makers and governments. To help tackle this, we developed\ncomputational methods to categorise COVID-19 disinformation. The COVID-19\ndisinformation categories could be used for a) focusing fact-checking efforts\non the most damaging kinds of COVID-19 disinformation; b) guiding policy makers\nwho are trying to deliver effective public health messages and counter\neffectively COVID-19 disinformation. This paper presents: 1) a corpus\ncontaining what is currently the largest available set of manually annotated\nCOVID-19 disinformation categories; 2) a classification-aware neural topic\nmodel (CANTM) designed for COVID-19 disinformation category classification and\ntopic discovery; 3) an extensive analysis of COVID-19 disinformation categories\nwith respect to time, volume, false type, media type and origin source.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 10:32:18 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 12:55:12 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Song", "Xingyi", ""], ["Petrak", "Johann", ""], ["Jiang", "Ye", ""], ["Singh", "Iknoor", ""], ["Maynard", "Diana", ""], ["Bontcheva", "Kalina", ""]]}, {"id": "2006.03388", "submitter": "Rustam Latypov", "authors": "Rustam Latypov and Evgeni Stolov", "title": "A New Method Towards Speech Files Local Features Investigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are a few reasons for the recent increased interest in the study of\nlocal features of speech files. It is stated that many essential features of\nthe speaker language used can appear in the form of the speech signal. The\ntraditional instruments - short Fourier transform, wavelet transform, Hadamard\ntransforms, autocorrelation, and the like can detect not all particular\nproperties of the language. In this paper, we suggest a new approach to the\nexploration of such properties. The source signal is approximated by a new one\nthat has its values taken from a finite set. Then we construct a new sequence\nof vectors of a fixed size on the base of those approximations. Examination of\nthe distribution of the produced vectors provides a new method for a\ndescription of speech files local characteristics. Finally, the developed\ntechnique is applied to the problem of the automatic distinguishing of two\nknown languages used in speech files. For this purpose, a simple neural net is\nconsumed.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 11:53:56 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Latypov", "Rustam", ""], ["Stolov", "Evgeni", ""]]}, {"id": "2006.03411", "submitter": "Mahaveer Jain", "authors": "Mahaveer Jain, Gil Keren, Jay Mahadeokar, Geoffrey Zweig, Florian\n  Metze, Yatharth Saraf", "title": "Contextual RNN-T For Open Domain ASR", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end (E2E) systems for automatic speech recognition (ASR), such as RNN\nTransducer (RNN-T) and Listen-Attend-Spell (LAS) blend the individual\ncomponents of a traditional hybrid ASR system - acoustic model, language model,\npronunciation model - into a single neural network. While this has some nice\nadvantages, it limits the system to be trained using only paired audio and\ntext. Because of this, E2E models tend to have difficulties with correctly\nrecognizing rare words that are not frequently seen during training, such as\nentity names. In this paper, we propose modifications to the RNN-T model that\nallow the model to utilize additional metadata text with the objective of\nimproving performance on these named entity words. We evaluate our approach on\nan in-house dataset sampled from de-identified public social media videos,\nwhich represent an open domain ASR task. By using an attention model and a\nbiasing model to leverage the contextual metadata that accompanies a video, we\nobserve a relative improvement of about 16% in Word Error Rate on Named\nEntities (WER-NE) for videos with related metadata.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 04:37:03 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 23:17:13 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Jain", "Mahaveer", ""], ["Keren", "Gil", ""], ["Mahadeokar", "Jay", ""], ["Zweig", "Geoffrey", ""], ["Metze", "Florian", ""], ["Saraf", "Yatharth", ""]]}, {"id": "2006.03463", "submitter": "Ilia Shumailov", "authors": "Ilia Shumailov, Yiren Zhao, Daniel Bates, Nicolas Papernot, Robert\n  Mullins, Ross Anderson", "title": "Sponge Examples: Energy-Latency Attacks on Neural Networks", "comments": "Accepted at 6th IEEE European Symposium on Security and Privacy\n  (EuroS&P)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The high energy costs of neural network training and inference led to the use\nof acceleration hardware such as GPUs and TPUs. While this enabled us to train\nlarge-scale neural networks in datacenters and deploy them on edge devices, the\nfocus so far is on average-case performance. In this work, we introduce a novel\nthreat vector against neural networks whose energy consumption or decision\nlatency are critical. We show how adversaries can exploit carefully crafted\n$\\boldsymbol{sponge}~\\boldsymbol{examples}$, which are inputs designed to\nmaximise energy consumption and latency.\n  We mount two variants of this attack on established vision and language\nmodels, increasing energy consumption by a factor of 10 to 200. Our attacks can\nalso be used to delay decisions where a network has critical real-time\nperformance, such as in perception for autonomous vehicles. We demonstrate the\nportability of our malicious inputs across CPUs and a variety of hardware\naccelerator chips including GPUs, and an ASIC simulator. We conclude by\nproposing a defense strategy which mitigates our attack by shifting the\nanalysis of energy consumption in hardware from an average-case to a worst-case\nperspective.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 14:10:09 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 14:17:37 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Shumailov", "Ilia", ""], ["Zhao", "Yiren", ""], ["Bates", "Daniel", ""], ["Papernot", "Nicolas", ""], ["Mullins", "Robert", ""], ["Anderson", "Ross", ""]]}, {"id": "2006.03473", "submitter": "Zheng Li", "authors": "Zheng Li, Miao Zhao, Qingyang Hong, Lin Li, Zhiyuan Tang, Dong Wang,\n  Liming Song and Cheng Yang", "title": "AP20-OLR Challenge: Three Tasks and Their Baselines", "comments": "arXiv admin note: substantial text overlap with arXiv:1907.07626,\n  arXiv:1806.00616, arXiv:1706.09742", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the fifth oriental language recognition (OLR) challenge\nAP20-OLR, which intends to improve the performance of language recognition\nsystems, along with APSIPA Annual Summit and Conference (APSIPA ASC). The data\nprofile, three tasks, the corresponding baselines, and the evaluation\nprinciples are introduced in this paper. The AP20-OLR challenge includes more\nlanguages, dialects and real-life data provided by Speechocean and the NSFC\nM2ASR project, and all the data is free for participants. The challenge this\nyear still focuses on practical and challenging problems, with three tasks: (1)\ncross-channel LID, (2) dialect identification and (3) noisy LID. Based on Kaldi\nand Pytorch, recipes for i-vector and x-vector systems are also conducted as\nbaselines for the three tasks. These recipes will be online-published, and\navailable for participants to configure LID systems. The baseline results on\nthe three tasks demonstrate that those tasks in this challenge are worth paying\nmore efforts to achieve better performance.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 16:29:21 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 02:53:38 GMT"}, {"version": "v3", "created": "Fri, 24 Jul 2020 13:28:00 GMT"}, {"version": "v4", "created": "Fri, 9 Oct 2020 09:08:08 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Li", "Zheng", ""], ["Zhao", "Miao", ""], ["Hong", "Qingyang", ""], ["Li", "Lin", ""], ["Tang", "Zhiyuan", ""], ["Wang", "Dong", ""], ["Song", "Liming", ""], ["Yang", "Cheng", ""]]}, {"id": "2006.03511", "submitter": "Baptiste Roziere", "authors": "Marie-Anne Lachaux, Baptiste Roziere, Lowik Chanussot, Guillaume\n  Lample", "title": "Unsupervised Translation of Programming Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A transcompiler, also known as source-to-source translator, is a system that\nconverts source code from a high-level programming language (such as C++ or\nPython) to another. Transcompilers are primarily used for interoperability, and\nto port codebases written in an obsolete or deprecated language (e.g. COBOL,\nPython 2) to a modern one. They typically rely on handcrafted rewrite rules,\napplied to the source code abstract syntax tree. Unfortunately, the resulting\ntranslations often lack readability, fail to respect the target language\nconventions, and require manual modifications in order to work properly. The\noverall translation process is timeconsuming and requires expertise in both the\nsource and target languages, making code-translation projects expensive.\nAlthough neural models significantly outperform their rule-based counterparts\nin the context of natural language translation, their applications to\ntranscompilation have been limited due to the scarcity of parallel data in this\ndomain. In this paper, we propose to leverage recent approaches in unsupervised\nmachine translation to train a fully unsupervised neural transcompiler. We\ntrain our model on source code from open source GitHub projects, and show that\nit can translate functions between C++, Java, and Python with high accuracy.\nOur method relies exclusively on monolingual source code, requires no expertise\nin the source or target languages, and can easily be generalized to other\nprogramming languages. We also build and release a test set composed of 852\nparallel functions, along with unit tests to check the correctness of\ntranslations. We show that our model outperforms rule-based commercial\nbaselines by a significant margin.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 15:28:01 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 10:44:08 GMT"}, {"version": "v3", "created": "Tue, 22 Sep 2020 08:58:24 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Lachaux", "Marie-Anne", ""], ["Roziere", "Baptiste", ""], ["Chanussot", "Lowik", ""], ["Lample", "Guillaume", ""]]}, {"id": "2006.03533", "submitter": "Seokhwan Kim", "authors": "Seokhwan Kim, Mihail Eric, Karthik Gopalakrishnan, Behnam Hedayatnia,\n  Yang Liu, Dilek Hakkani-Tur", "title": "Beyond Domain APIs: Task-oriented Conversational Modeling with\n  Unstructured Knowledge Access", "comments": "To be presented at SIGDIAL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most prior work on task-oriented dialogue systems are restricted to a limited\ncoverage of domain APIs, while users oftentimes have domain related requests\nthat are not covered by the APIs. In this paper, we propose to expand coverage\nof task-oriented dialogue systems by incorporating external unstructured\nknowledge sources. We define three sub-tasks: knowledge-seeking turn detection,\nknowledge selection, and knowledge-grounded response generation, which can be\nmodeled individually or jointly. We introduce an augmented version of MultiWOZ\n2.1, which includes new out-of-API-coverage turns and responses grounded on\nexternal knowledge sources. We present baselines for each sub-task using both\nconventional and neural approaches. Our experimental results demonstrate the\nneed for further research in this direction to enable more informative\nconversational systems.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 16:12:18 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Kim", "Seokhwan", ""], ["Eric", "Mihail", ""], ["Gopalakrishnan", "Karthik", ""], ["Hedayatnia", "Behnam", ""], ["Liu", "Yang", ""], ["Hakkani-Tur", "Dilek", ""]]}, {"id": "2006.03535", "submitter": "Alvin Chan", "authors": "Alvin Chan, Yew-Soon Ong, Bill Pung, Aston Zhang, Jie Fu", "title": "CoCon: A Self-Supervised Approach for Controlled Text Generation", "comments": "ICLR 2021 Camera-Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pretrained Transformer-based language models (LMs) display remarkable natural\nlanguage generation capabilities. With their immense potential, controlling\ntext generation of such LMs is getting attention. While there are studies that\nseek to control high-level attributes (such as sentiment and topic) of\ngenerated text, there is still a lack of more precise control over its content\nat the word- and phrase-level. Here, we propose Content-Conditioner (CoCon) to\ncontrol an LM's output text with a content input, at a fine-grained level. In\nour self-supervised approach, the CoCon block learns to help the LM complete a\npartially-observed text sequence by conditioning with content inputs that are\nwithheld from the LM. Through experiments, we show that CoCon can naturally\nincorporate target content into generated texts and control high-level text\nattributes in a zero-shot manner.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 16:15:46 GMT"}, {"version": "v2", "created": "Tue, 9 Mar 2021 14:23:42 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Chan", "Alvin", ""], ["Ong", "Yew-Soon", ""], ["Pung", "Bill", ""], ["Zhang", "Aston", ""], ["Fu", "Jie", ""]]}, {"id": "2006.03541", "submitter": "Mar\\'ia N. Moreno Garc\\'ia", "authors": "Nhan Cach Dang, Mar\\'ia N. Moreno-Garc\\'ia and Fernando De la Prieta", "title": "Sentiment Analysis Based on Deep Learning: A Comparative Study", "comments": null, "journal-ref": "Electronics, 9 (3), 483, 29 pages, 2020", "doi": "10.3390/electronics9030483", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The study of public opinion can provide us with valuable information. The\nanalysis of sentiment on social networks, such as Twitter or Facebook, has\nbecome a powerful means of learning about the users' opinions and has a wide\nrange of applications. However, the efficiency and accuracy of sentiment\nanalysis is being hindered by the challenges encountered in natural language\nprocessing (NLP). In recent years, it has been demonstrated that deep learning\nmodels are a promising solution to the challenges of NLP. This paper reviews\nthe latest studies that have employed deep learning to solve sentiment analysis\nproblems, such as sentiment polarity. Models using term frequency-inverse\ndocument frequency (TF-IDF) and word embedding have been applied to a series of\ndatasets. Finally, a comparative study has been conducted on the experimental\nresults obtained for the different models and input features\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 16:28:10 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Dang", "Nhan Cach", ""], ["Moreno-Garc\u00eda", "Mar\u00eda N.", ""], ["De la Prieta", "Fernando", ""]]}, {"id": "2006.03555", "submitter": "Xingyou Song", "authors": "Krzysztof Choromanski, Valerii Likhosherstov, David Dohan, Xingyou\n  Song, Andreea Gane, Tamas Sarlos, Peter Hawkins, Jared Davis, David Belanger,\n  Lucy Colwell, Adrian Weller", "title": "Masked Language Modeling for Proteins via Linearly Scalable Long-Context\n  Transformers", "comments": "This arXiv submission has been deprecated. Please see \"Rethinking\n  Attention with Performers\" at arXiv:2009.14794 for the most updated version\n  of the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer models have achieved state-of-the-art results across a diverse\nrange of domains. However, concern over the cost of training the attention\nmechanism to learn complex dependencies between distant inputs continues to\ngrow. In response, solutions that exploit the structure and sparsity of the\nlearned attention matrix have blossomed. However, real-world applications that\ninvolve long sequences, such as biological sequence analysis, may fall short of\nmeeting these assumptions, precluding exploration of these models. To address\nthis challenge, we present a new Transformer architecture, Performer, based on\nFast Attention Via Orthogonal Random features (FAVOR). Our mechanism scales\nlinearly rather than quadratically in the number of tokens in the sequence, is\ncharacterized by sub-quadratic space complexity and does not incorporate any\nsparsity pattern priors. Furthermore, it provides strong theoretical\nguarantees: unbiased estimation of the attention matrix and uniform\nconvergence. It is also backwards-compatible with pre-trained regular\nTransformers. We demonstrate its effectiveness on the challenging task of\nprotein sequence modeling and provide detailed theoretical analysis.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 17:09:16 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 14:33:41 GMT"}, {"version": "v3", "created": "Thu, 1 Oct 2020 00:41:49 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Choromanski", "Krzysztof", ""], ["Likhosherstov", "Valerii", ""], ["Dohan", "David", ""], ["Song", "Xingyou", ""], ["Gane", "Andreea", ""], ["Sarlos", "Tamas", ""], ["Hawkins", "Peter", ""], ["Davis", "Jared", ""], ["Belanger", "David", ""], ["Colwell", "Lucy", ""], ["Weller", "Adrian", ""]]}, {"id": "2006.03564", "submitter": "Mohammadreza Banaei", "authors": "Mohammadreza Banaei, R\\'emi Lebret, Karl Aberer", "title": "Spoken dialect identification in Twitter using a multi-filter\n  architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents our approach for SwissText & KONVENS 2020 shared task 2,\nwhich is a multi-stage neural model for Swiss German (GSW) identification on\nTwitter. Our model outputs either GSW or non-GSW and is not meant to be used as\na generic language identifier. Our architecture consists of two independent\nfilters where the first one favors recall, and the second one filter favors\nprecision (both towards GSW). Moreover, we do not use binary models (GSW vs.\nnot-GSW) in our filters but rather a multi-class classifier with GSW being one\nof the possible labels. Our model reaches F1-score of 0.982 on the test set of\nthe shared task.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 17:19:15 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Banaei", "Mohammadreza", ""], ["Lebret", "R\u00e9mi", ""], ["Aberer", "Karl", ""]]}, {"id": "2006.03644", "submitter": "Abeer AlDayel", "authors": "Abeer AlDayel and Walid Magdy", "title": "Stance Detection on Social Media: State of the Art and Trends", "comments": "This is an early version of the paper. For the final version, please\n  find it published at Elsevier IP&Min the following link:\n  https://doi.org/10.1016/j.ipm.2021.102597", "journal-ref": "Abeer ALDayel, Walid Magdy, Stance detection on social media:\n  State of the art and trends, Information Processing & Management, Volume 58,\n  Issue 4, 2021, 102597, ISSN 0306-4573", "doi": "10.1016/j.ipm.2021.102597", "report-no": null, "categories": "cs.SI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Stance detection on social media is an emerging opinion mining paradigm for\nvarious social and political applications in which sentiment analysis may be\nsub-optimal. There has been a growing research interest for developing\neffective methods for stance detection methods varying among multiple\ncommunities including natural language processing, web science, and social\ncomputing. This paper surveys the work on stance detection within those\ncommunities and situates its usage within current opinion mining techniques in\nsocial media. It presents an exhaustive review of stance detection techniques\non social media, including the task definition, different types of targets in\nstance detection, features set used, and various machine learning approaches\napplied. The survey reports state-of-the-art results on the existing benchmark\ndatasets on stance detection, and discusses the most effective approaches. In\naddition, this study explores the emerging trends and different applications of\nstance detection on social media. The study concludes by discussing the gaps in\nthe current existing research and highlights the possible future directions for\nstance detection on social media.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 19:24:16 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 11:13:46 GMT"}, {"version": "v3", "created": "Sun, 13 Sep 2020 07:04:39 GMT"}, {"version": "v4", "created": "Wed, 24 Feb 2021 07:40:01 GMT"}, {"version": "v5", "created": "Thu, 15 Apr 2021 12:41:20 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["AlDayel", "Abeer", ""], ["Magdy", "Walid", ""]]}, {"id": "2006.03652", "submitter": "Vinayak Sachidananda", "authors": "Vin Sachidananda, Ziyi Yang, Chenguang Zhu", "title": "Filtered Inner Product Projection for Crosslingual Embedding Alignment", "comments": "ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Due to widespread interest in machine translation and transfer learning,\nthere are numerous algorithms for mapping multiple embeddings to a shared\nrepresentation space. Recently, these algorithms have been studied in the\nsetting of bilingual dictionary induction where one seeks to align the\nembeddings of a source and a target language such that translated word pairs\nlie close to one another in a common representation space. In this paper, we\npropose a method, Filtered Inner Product Projection (FIPP), for mapping\nembeddings to a common representation space and evaluate FIPP in the context of\nbilingual dictionary induction. As semantic shifts are pervasive across\nlanguages and domains, FIPP first identifies the common geometric structure in\nboth embeddings and then, only on the common structure, aligns the Gram\nmatrices of these embeddings. Unlike previous approaches, FIPP is applicable\neven when the source and target embeddings are of differing dimensionalities.\nWe show that our approach outperforms existing methods on the MUSE dataset for\nvarious language pairs. Furthermore, FIPP provides computational benefits both\nin ease of implementation and scalability.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 19:53:30 GMT"}, {"version": "v2", "created": "Tue, 23 Mar 2021 22:00:24 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Sachidananda", "Vin", ""], ["Yang", "Ziyi", ""], ["Zhu", "Chenguang", ""]]}, {"id": "2006.03654", "submitter": "Pengcheng He", "authors": "Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen", "title": "DeBERTa: Decoding-enhanced BERT with Disentangled Attention", "comments": "20 pages,5 figures, 13 tables. In v2, we scale up DeBERTa to 1.5B\n  parameters and it surpasses the human performance on SuperGLUE leaderboard\n  for the first time as of December 29, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in pre-trained neural language models has significantly\nimproved the performance of many natural language processing (NLP) tasks. In\nthis paper we propose a new model architecture DeBERTa (Decoding-enhanced BERT\nwith disentangled attention) that improves the BERT and RoBERTa models using\ntwo novel techniques. The first is the disentangled attention mechanism, where\neach word is represented using two vectors that encode its content and\nposition, respectively, and the attention weights among words are computed\nusing disentangled matrices on their contents and relative positions,\nrespectively. Second, an enhanced mask decoder is used to incorporate absolute\npositions in the decoding layer to predict the masked tokens in model\npre-training. In addition, a new virtual adversarial training method is used\nfor fine-tuning to improve models' generalization. We show that these\ntechniques significantly improve the efficiency of model pre-training and the\nperformance of both natural language understanding (NLU) and natural langauge\ngeneration (NLG) downstream tasks. Compared to RoBERTa-Large, a DeBERTa model\ntrained on half of the training data performs consistently better on a wide\nrange of NLP tasks, achieving improvements on MNLI by +0.9% (90.2% vs. 91.1%),\non SQuAD v2.0 by +2.3% (88.4% vs. 90.7%) and RACE by +3.6% (83.2% vs. 86.8%).\nNotably, we scale up DeBERTa by training a larger version that consists of 48\nTransform layers with 1.5 billion parameters. The significant performance boost\nmakes the single DeBERTa model surpass the human performance on the SuperGLUE\nbenchmark (Wang et al., 2019a) for the first time in terms of macro-average\nscore (89.9 versus 89.8), and the ensemble DeBERTa model sits atop the\nSuperGLUE leaderboard as of January 6, 2021, out performing the human baseline\nby a decent margin (90.3 versus 89.8).\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 19:54:34 GMT"}, {"version": "v2", "created": "Sun, 3 Jan 2021 05:36:50 GMT"}, {"version": "v3", "created": "Mon, 11 Jan 2021 22:54:26 GMT"}, {"version": "v4", "created": "Thu, 18 Mar 2021 02:27:00 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["He", "Pengcheng", ""], ["Liu", "Xiaodong", ""], ["Gao", "Jianfeng", ""], ["Chen", "Weizhu", ""]]}, {"id": "2006.03659", "submitter": "John Giorgi", "authors": "John Giorgi, Osvald Nitski, Bo Wang, Gary Bader", "title": "DeCLUTR: Deep Contrastive Learning for Unsupervised Textual\n  Representations", "comments": "ACL2021 Camera Ready V2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Sentence embeddings are an important component of many natural language\nprocessing (NLP) systems. Like word embeddings, sentence embeddings are\ntypically learned on large text corpora and then transferred to various\ndownstream tasks, such as clustering and retrieval. Unlike word embeddings, the\nhighest performing solutions for learning sentence embeddings require labelled\ndata, limiting their usefulness to languages and domains where labelled data is\nabundant. In this paper, we present DeCLUTR: Deep Contrastive Learning for\nUnsupervised Textual Representations. Inspired by recent advances in deep\nmetric learning (DML), we carefully design a self-supervised objective for\nlearning universal sentence embeddings that does not require labelled training\ndata. When used to extend the pretraining of transformer-based language models,\nour approach closes the performance gap between unsupervised and supervised\npretraining for universal sentence encoders. Importantly, our experiments\nsuggest that the quality of the learned embeddings scale with both the number\nof trainable parameters and the amount of unlabelled training data. Our code\nand pretrained models are publicly available and can be easily adapted to new\ndomains or used to embed unseen text.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 20:00:28 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 20:24:17 GMT"}, {"version": "v3", "created": "Thu, 20 May 2021 19:47:53 GMT"}, {"version": "v4", "created": "Thu, 27 May 2021 14:57:02 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Giorgi", "John", ""], ["Nitski", "Osvald", ""], ["Wang", "Bo", ""], ["Bader", "Gary", ""]]}, {"id": "2006.03679", "submitter": "Milan Straka", "authors": "Jan Haji\\v{c}, Eduard Bej\\v{c}ek, Jaroslava Hlav\\'a\\v{c}ov\\'a, Marie\n  Mikulov\\'a, Milan Straka, Jan \\v{S}t\\v{e}p\\'anek, Barbora\n  \\v{S}t\\v{e}p\\'ankov\\'a", "title": "Prague Dependency Treebank -- Consolidated 1.0", "comments": "Accepted at LREC 2020 (Proceedings of Language Resources and\n  Evaluation, Marseille, France)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a richly annotated and genre-diversified language resource, the\nPrague Dependency Treebank-Consolidated 1.0 (PDT-C 1.0), the purpose of which\nis - as it always been the case for the family of the Prague Dependency\nTreebanks - to serve both as a training data for various types of NLP tasks as\nwell as for linguistically-oriented research. PDT-C 1.0 contains four different\ndatasets of Czech, uniformly annotated using the standard PDT scheme (albeit\nnot everything is annotated manually, as we describe in detail here). The texts\ncome from different sources: daily newspaper articles, Czech translation of the\nWall Street Journal, transcribed dialogs and a small amount of user-generated,\nshort, often non-standard language segments typed into a web translator.\nAltogether, the treebank contains around 180,000 sentences with their\nmorphological, surface and deep syntactic annotation. The diversity of the\ntexts and annotations should serve well the NLP applications as well as it is\nan invaluable resource for linguistic research, including comparative studies\nregarding texts of different genres. The corpus is publicly and freely\navailable.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 20:52:55 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Haji\u010d", "Jan", ""], ["Bej\u010dek", "Eduard", ""], ["Hlav\u00e1\u010dov\u00e1", "Jaroslava", ""], ["Mikulov\u00e1", "Marie", ""], ["Straka", "Milan", ""], ["\u0160t\u011bp\u00e1nek", "Jan", ""], ["\u0160t\u011bp\u00e1nkov\u00e1", "Barbora", ""]]}, {"id": "2006.03685", "submitter": "Zachariah Zhang", "authors": "Zachariah Zhang, Jingshu Liu, Narges Razavian", "title": "BERT-XML: Large Scale Automated ICD Coding Using BERT Pretraining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical interactions are initially recorded and documented in free text\nmedical notes. ICD coding is the task of classifying and coding all diagnoses,\nsymptoms and procedures associated with a patient's visit. The process is often\nmanual and extremely time-consuming and expensive for hospitals. In this paper,\nwe propose a machine learning model, BERT-XML, for large scale automated ICD\ncoding from EHR notes, utilizing recently developed unsupervised pretraining\nthat have achieved state of the art performance on a variety of NLP tasks. We\ntrain a BERT model from scratch on EHR notes, learning with vocabulary better\nsuited for EHR tasks and thus outperform off-the-shelf models. We adapt the\nBERT architecture for ICD coding with multi-label attention. While other works\nfocus on small public medical datasets, we have produced the first large scale\nICD-10 classification model using millions of EHR notes to predict thousands of\nunique ICD codes.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 21:12:43 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Zhang", "Zachariah", ""], ["Liu", "Jingshu", ""], ["Razavian", "Narges", ""]]}, {"id": "2006.03687", "submitter": "Milan Straka", "authors": "Milan Straka, Jana Strakov\\'a", "title": "UDPipe at EvaLatin 2020: Contextualized Embeddings and Treebank\n  Embeddings", "comments": "Accepted at EvaLatin 2020, LREC (Proceedings of Language Resources\n  and Evaluation, Marseille, France)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present our contribution to the EvaLatin shared task, which is the first\nevaluation campaign devoted to the evaluation of NLP tools for Latin. We\nsubmitted a system based on UDPipe 2.0, one of the winners of the CoNLL 2018\nShared Task, The 2018 Shared Task on Extrinsic Parser Evaluation and SIGMORPHON\n2019 Shared Task. Our system places first by a wide margin both in\nlemmatization and POS tagging in the open modality, where additional supervised\ndata is allowed, in which case we utilize all Universal Dependency Latin\ntreebanks. In the closed modality, where only the EvaLatin training data is\nallowed, our system achieves the best performance in lemmatization and in\nclassical subtask of POS tagging, while reaching second place in cross-genre\nand cross-time settings. In the ablation experiments, we also evaluate the\ninfluence of BERT and XLM-RoBERTa contextualized embeddings, and the treebank\nencodings of the different flavors of Latin treebanks.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 21:03:35 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Straka", "Milan", ""], ["Strakov\u00e1", "Jana", ""]]}, {"id": "2006.03701", "submitter": "Ojas Ahuja", "authors": "Ojas Ahuja and Shrey Desai", "title": "Accelerating Natural Language Understanding in Task-Oriented Dialog", "comments": "Accepted to ACL 2020 Workshop on NLP for Conversational AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task-oriented dialog models typically leverage complex neural architectures\nand large-scale, pre-trained Transformers to achieve state-of-the-art\nperformance on popular natural language understanding benchmarks. However,\nthese models frequently have in excess of tens of millions of parameters,\nmaking them impossible to deploy on-device where resource-efficiency is a major\nconcern. In this work, we show that a simple convolutional model compressed\nwith structured pruning achieves largely comparable results to BERT on ATIS and\nSnips, with under 100K parameters. Moreover, we perform acceleration\nexperiments on CPUs, where we observe our multi-task model predicts intents and\nslots nearly 63x faster than even DistilBERT.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 21:36:33 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Ahuja", "Ojas", ""], ["Desai", "Shrey", ""]]}, {"id": "2006.03719", "submitter": "Zhijing Jin", "authors": "Zhijing Jin, Yongyi Yang, Xipeng Qiu, Zheng Zhang", "title": "Relation of the Relations: A New Paradigm of the Relation Extraction\n  Problem", "comments": "Passed the reviews of EMNLP; withdrawn for non-technical reasons", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In natural language, often multiple entities appear in the same text.\nHowever, most previous works in Relation Extraction (RE) limit the scope to\nidentifying the relation between two entities at a time. Such an approach\ninduces a quadratic computation time, and also overlooks the interdependency\nbetween multiple relations, namely the relation of relations (RoR). Due to the\nsignificance of RoR in existing datasets, we propose a new paradigm of RE that\nconsiders as a whole the predictions of all relations in the same context.\nAccordingly, we develop a data-driven approach that does not require\nhand-crafted rules but learns by itself the RoR, using Graph Neural Networks\nand a relation matrix transformer. Experiments show that our model outperforms\nthe state-of-the-art approaches by +1.12\\% on the ACE05 dataset and +2.55\\% on\nSemEval 2018 Task 7.2, which is a substantial improvement on the two\ncompetitive benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 22:25:27 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 11:45:16 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Jin", "Zhijing", ""], ["Yang", "Yongyi", ""], ["Qiu", "Xipeng", ""], ["Zhang", "Zheng", ""]]}, {"id": "2006.03744", "submitter": "Mingjie Li", "authors": "Mingjie Li, Fuyu Wang, Xiaojun Chang and Xiaodan Liang", "title": "Auxiliary Signal-Guided Knowledge Encoder-Decoder for Medical Report\n  Generation", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Beyond the common difficulties faced in the natural image captioning, medical\nreport generation specifically requires the model to describe a medical image\nwith a fine-grained and semantic-coherence paragraph that should satisfy both\nmedical commonsense and logic. Previous works generally extract the global\nimage features and attempt to generate a paragraph that is similar to\nreferenced reports; however, this approach has two limitations. Firstly, the\nregions of primary interest to radiologists are usually located in a small area\nof the global image, meaning that the remainder parts of the image could be\nconsidered as irrelevant noise in the training procedure. Secondly, there are\nmany similar sentences used in each medical report to describe the normal\nregions of the image, which causes serious data bias. This deviation is likely\nto teach models to generate these inessential sentences on a regular basis. To\naddress these problems, we propose an Auxiliary Signal-Guided Knowledge\nEncoder-Decoder (ASGK) to mimic radiologists' working patterns. In more detail,\nASGK integrates internal visual feature fusion and external medical linguistic\ninformation to guide medical knowledge transfer and learning. The core\nstructure of ASGK consists of a medical graph encoder and a natural language\ndecoder, inspired by advanced Generative Pre-Training (GPT). Experiments on the\nCX-CHR dataset and our COVID-19 CT Report dataset demonstrate that our proposed\nASGK is able to generate a robust and accurate report, and moreover outperforms\nstate-of-the-art methods on both medical terminology classification and\nparagraph generation metrics.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 01:00:15 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Li", "Mingjie", ""], ["Wang", "Fuyu", ""], ["Chang", "Xiaojun", ""], ["Liang", "Xiaodan", ""]]}, {"id": "2006.03773", "submitter": "Anurag Pallaprolu", "authors": "Anurag Pallaprolu, Radha Vaidya, Aditya Swaroop Attawar", "title": "Challenges and Thrills of Legal Arguments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art attention based models, mostly centered around the\ntransformer architecture, solve the problem of sequence-to-sequence translation\nusing the so-called scaled dot-product attention. While this technique is\nhighly effective for estimating inter-token attention, it does not answer the\nquestion of inter-sequence attention when we deal with conversation-like\nscenarios. We propose an extension, HumBERT, that attempts to perform\ncontinuous contextual argument generation using locally trained transformers.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 03:43:15 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Pallaprolu", "Anurag", ""], ["Vaidya", "Radha", ""], ["Attawar", "Aditya Swaroop", ""]]}, {"id": "2006.03776", "submitter": "Amar Shrestha", "authors": "Amar Shrestha, Krittaphat Pugdeethosapol, Haowen Fang, Qinru Qiu", "title": "MAGNet: Multi-Region Attention-Assisted Grounding of Natural Language\n  Queries at Phrase Level", "comments": "Submitted to The 2020 European Conference on Computer Vision (ECCV\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grounding free-form textual queries necessitates an understanding of these\ntextual phrases and its relation to the visual cues to reliably reason about\nthe described locations. Spatial attention networks are known to learn this\nrelationship and focus its gaze on salient objects in the image. Thus, we\npropose to utilize spatial attention networks for image-level visual-textual\nfusion preserving local (word) and global (phrase) information to refine region\nproposals with an in-network Region Proposal Network (RPN) and detect single or\nmultiple regions for a phrase query. We focus only on the phrase query - ground\ntruth pair (referring expression) for a model independent of the constraints of\nthe datasets i.e. additional attributes, context etc. For such referring\nexpression dataset ReferIt game, our Multi-region Attention-assisted Grounding\nnetwork (MAGNet) achieves over 12\\% improvement over the state-of-the-art.\nWithout the context from image captions and attribute information in Flickr30k\nEntities, we still achieve competitive results compared to the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 04:14:15 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Shrestha", "Amar", ""], ["Pugdeethosapol", "Krittaphat", ""], ["Fang", "Haowen", ""], ["Qiu", "Qinru", ""]]}, {"id": "2006.03866", "submitter": "Shubham Toshniwal", "authors": "Shubham Toshniwal, Haoyue Shi, Bowen Shi, Lingyu Gao, Karen Livescu,\n  Kevin Gimpel", "title": "A Cross-Task Analysis of Text Span Representations", "comments": "RepL4NLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many natural language processing (NLP) tasks involve reasoning with textual\nspans, including question answering, entity recognition, and coreference\nresolution. While extensive research has focused on functional architectures\nfor representing words and sentences, there is less work on representing\narbitrary spans of text within sentences. In this paper, we conduct a\ncomprehensive empirical evaluation of six span representation methods using\neight pretrained language representation models across six tasks, including two\ntasks that we introduce. We find that, although some simple span\nrepresentations are fairly reliable across tasks, in general the optimal span\nrepresentation varies by task, and can also vary within different facets of\nindividual tasks. We also find that the choice of span representation has a\nbigger impact with a fixed pretrained encoder than with a fine-tuned encoder.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 13:37:51 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Toshniwal", "Shubham", ""], ["Shi", "Haoyue", ""], ["Shi", "Bowen", ""], ["Gao", "Lingyu", ""], ["Livescu", "Karen", ""], ["Gimpel", "Kevin", ""]]}, {"id": "2006.03950", "submitter": "Aylin Caliskan", "authors": "Autumn Toney and Aylin Caliskan", "title": "ValNorm Quantifies Semantics to Reveal Consistent Valence Biases Across\n  Languages and Over Centuries", "comments": "15 pages, 3 figures, 12 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Word embeddings, which are numeric dictionaries for machines to process\nlanguage, learn implicit biases from linguistic regularities captured by word\nco-occurrence information. As a result, statistical methods can detect and\nquantify social biases along with widely shared associations present in the\ncorpus the word embeddings are trained on. By extending methods that quantify\nhuman-like biases in word embeddings, we introduce ValNorm, a novel word\nembedding intrinsic evaluation task and a method to measure the affective\nmeaning of valence (pleasantness/unpleasantness) in words, with high accuracy.\nThe correlation between human judgment scores of valence for 399 words\ncollected to establish pleasantness norms in English and ValNorm scores is\nr=0.88. These 399 words, obtained from the social psychology literature, are\nused to measure biases that are non-discriminatory among social groups. We\nhypothesize that the valence associations for this set of words (in various\ntranslations) are widely shared across languages and consistent over time. We\nestimate valence associations of these words using word embeddings from seven\nlanguages representing various language structures and from historical text\ncovering 200 years. Our method achieves consistently high accuracy, suggesting\nthat the valence associations for these words are widely shared. In contrast,\nwe measure gender stereotypes using the same set of word embeddings and find\nthat social biases vary across languages. Our results signal that valence\nassociations of this word set represent widely shared associations of the last\ntwo centuries. Consequently, ValNorm can be used to evaluate valence norms and\nthe accuracy of word embeddings especially when measuring biases.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 19:29:36 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 23:59:07 GMT"}, {"version": "v3", "created": "Wed, 11 Nov 2020 04:16:21 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Toney", "Autumn", ""], ["Caliskan", "Aylin", ""]]}, {"id": "2006.03955", "submitter": "Aylin Caliskan", "authors": "Wei Guo and Aylin Caliskan", "title": "Detecting Emergent Intersectional Biases: Contextualized Word Embeddings\n  Contain a Distribution of Human-like Biases", "comments": "19 pages, 2 figures, 4 tables", "journal-ref": "AAAI/ACM Conference on Artificial Intelligence, Ethics, and\n  Society 2021", "doi": "10.1145/3461702.3462536", "report-no": null, "categories": "cs.CY cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the starting point that implicit human biases are reflected in the\nstatistical regularities of language, it is possible to measure biases in\nEnglish static word embeddings. State-of-the-art neural language models\ngenerate dynamic word embeddings dependent on the context in which the word\nappears. Current methods measure pre-defined social and intersectional biases\nthat appear in particular contexts defined by sentence templates. Dispensing\nwith templates, we introduce the Contextualized Embedding Association Test\n(CEAT), that can summarize the magnitude of overall bias in neural language\nmodels by incorporating a random-effects model. Experiments on social and\nintersectional biases show that CEAT finds evidence of all tested biases and\nprovides comprehensive information on the variance of effect magnitudes of the\nsame bias in different contexts. All the models trained on English corpora that\nwe study contain biased representations.\n  Furthermore, we develop two methods, Intersectional Bias Detection (IBD) and\nEmergent Intersectional Bias Detection (EIBD), to automatically identify the\nintersectional biases and emergent intersectional biases from static word\nembeddings in addition to measuring them in contextualized word embeddings. We\npresent the first algorithmic bias detection findings on how intersectional\ngroup members are strongly associated with unique emergent biases that do not\noverlap with the biases of their constituent minority identities. IBD and EIBD\nachieve high accuracy when detecting the intersectional and emergent biases of\nAfrican American females and Mexican American females. Our results indicate\nthat biases at the intersection of race and gender associated with members of\nmultiple minority groups, such as African American females and Mexican American\nfemales, have the highest magnitude across all neural language models.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 19:49:50 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 20:08:41 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 18:43:34 GMT"}, {"version": "v4", "created": "Fri, 16 Apr 2021 01:45:35 GMT"}, {"version": "v5", "created": "Wed, 19 May 2021 15:06:28 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Guo", "Wei", ""], ["Caliskan", "Aylin", ""]]}, {"id": "2006.03965", "submitter": "Gasper Begus", "authors": "Ga\\v{s}per Begu\\v{s}", "title": "Generative Adversarial Phonology: Modeling unsupervised phonetic and\n  phonological learning with neural networks", "comments": "Provisionally accepted in Frontiers in Artificial Intelligence", "journal-ref": "Frontiers in Artificial Intelligence 2020", "doi": "10.3389/frai.2020.00044", "report-no": null, "categories": "cs.CL cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep neural networks on well-understood dependencies in speech data\ncan provide new insights into how they learn internal representations. This\npaper argues that acquisition of speech can be modeled as a dependency between\nrandom space and generated speech data in the Generative Adversarial Network\narchitecture and proposes a methodology to uncover the network's internal\nrepresentations that correspond to phonetic and phonological properties. The\nGenerative Adversarial architecture is uniquely appropriate for modeling\nphonetic and phonological learning because the network is trained on\nunannotated raw acoustic data and learning is unsupervised without any\nlanguage-specific assumptions or pre-assumed levels of abstraction. A\nGenerative Adversarial Network was trained on an allophonic distribution in\nEnglish. The network successfully learns the allophonic alternation: the\nnetwork's generated speech signal contains the conditional distribution of\naspiration duration. The paper proposes a technique for establishing the\nnetwork's internal representations that identifies latent variables that\ncorrespond to, for example, presence of [s] and its spectral properties. By\nmanipulating these variables, we actively control the presence of [s] and its\nfrication amplitude in the generated outputs. This suggests that the network\nlearns to use latent variables as an approximation of phonetic and phonological\nrepresentations. Crucially, we observe that the dependencies learned in\ntraining extend beyond the training interval, which allows for additional\nexploration of learning representations. The paper also discusses how the\nnetwork's architecture and innovative outputs resemble and differ from\nlinguistic behavior in language acquisition, speech disorders, and speech\nerrors, and how well-understood dependencies in speech data can help us\ninterpret how neural networks learn their representations.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 20:31:23 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Begu\u0161", "Ga\u0161per", ""]]}, {"id": "2006.04014", "submitter": "Katikapalli Subramanyam Kalyan", "authors": "Katikapalli Subramanyam Kalyan, S.Sangeetha", "title": "Medical Concept Normalization in User Generated Texts by Learning Target\n  Concept Embeddings", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical concept normalization helps in discovering standard concepts in\nfree-form text i.e., maps health-related mentions to standard concepts in a\nvocabulary. It is much beyond simple string matching and requires a deep\nsemantic understanding of concept mentions. Recent research approach concept\nnormalization as either text classification or text matching. The main drawback\nin existing a) text classification approaches is ignoring valuable target\nconcepts information in learning input concept mention representation b) text\nmatching approach is the need to separately generate target concept embeddings\nwhich is time and resource consuming. Our proposed model overcomes these\ndrawbacks by jointly learning the representations of input concept mention and\ntarget concepts. First, it learns the input concept mention representation\nusing RoBERTa. Second, it finds cosine similarity between embeddings of input\nconcept mention and all the target concepts. Here, embeddings of target\nconcepts are randomly initialized and then updated during training. Finally,\nthe target concept with maximum cosine similarity is assigned to the input\nconcept mention. Our model surpasses all the existing methods across three\nstandard datasets by improving accuracy up to 2.31%.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 01:17:18 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Kalyan", "Katikapalli Subramanyam", ""], ["Sangeetha", "S.", ""]]}, {"id": "2006.04016", "submitter": "Sawsan Alqahtani", "authors": "Sawsan Alqahtani and Ajay Mishra and Mona Diab", "title": "A Multitask Learning Approach for Diacritic Restoration", "comments": null, "journal-ref": "ACL 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many languages like Arabic, diacritics are used to specify pronunciations\nas well as meanings. Such diacritics are often omitted in written text,\nincreasing the number of possible pronunciations and meanings for a word. This\nresults in a more ambiguous text making computational processing on such text\nmore difficult. Diacritic restoration is the task of restoring missing\ndiacritics in the written text. Most state-of-the-art diacritic restoration\nmodels are built on character level information which helps generalize the\nmodel to unseen data, but presumably lose useful information at the word level.\nThus, to compensate for this loss, we investigate the use of multi-task\nlearning to jointly optimize diacritic restoration with related NLP problems\nnamely word segmentation, part-of-speech tagging, and syntactic diacritization.\nWe use Arabic as a case study since it has sufficient data resources for tasks\nthat we consider in our joint modeling. Our joint models significantly\noutperform the baselines and are comparable to the state-of-the-art models that\nare more complex relying on morphological analyzers and/or a lot more data\n(e.g. dialectal data).\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 01:20:40 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Alqahtani", "Sawsan", ""], ["Mishra", "Ajay", ""], ["Diab", "Mona", ""]]}, {"id": "2006.04031", "submitter": "Venkata Sasank Pagolu", "authors": "Venkata Sasank Pagolu", "title": "Semantic Loss Application to Entity Relation Recognition", "comments": "More rigorous experimentation and vigilant testing are required to\n  establish the results and models used in this paper with higher confidence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Usually, entity relation recognition systems either use a pipe-lined model\nthat treats the entity tagging and relation identification as separate tasks or\na joint model that simultaneously identifies the relation and entities. This\npaper compares these two general approaches for the entity relation\nrecognition. State-of-the-art entity relation recognition systems are built\nusing deep recurrent neural networks which often does not capture the symbolic\nknowledge or the logical constraints in the problem. The main contribution of\nthis paper is an end-to-end neural model for joint entity relation extraction\nwhich incorporates a novel loss function. This novel loss function encodes the\nconstraint information in the problem to guide the model training effectively.\nWe show that addition of this loss function to the existing typical loss\nfunctions has a positive impact over the performance of the models. This model\nis truly end-to-end, requires no feature engineering and easily extensible.\nExtensive experimentation has been conducted to evaluate the significance of\ncapturing symbolic knowledge for natural language understanding. Models using\nthis loss function are observed to be outperforming their counterparts and\nconverging faster. Experimental results in this work suggest the use of this\nmethodology for other language understanding applications.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 03:12:38 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 22:49:32 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Pagolu", "Venkata Sasank", ""]]}, {"id": "2006.04050", "submitter": "El Moatez Billah Nagoudi", "authors": "El Moatez Billah Nagoudi, Muhammad Abdul-Mageed, Hasan Cavusoglu", "title": "Growing Together: Modeling Human Language Learning With n-Best\n  Multi-Checkpoint Machine Translation", "comments": "Accepted to the 4th Workshop on Neural Generation and Translation\n  (Duolingo Shared Task on Simultaneous Translation And Paraphrase for Language\n  Education Mayhew et al., 2020) collocated with ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe our submission to the 2020 Duolingo Shared Task on Simultaneous\nTranslation And Paraphrase for Language Education (STAPLE) (Mayhew et al.,\n2020). We view MT models at various training stages (i.e., checkpoints) as\nhuman learners at different levels. Hence, we employ an ensemble of\nmulti-checkpoints from the same model to generate translation sequences with\nvarious levels of fluency. From each checkpoint, for our best model, we sample\nn-Best sequences (n=10) with a beam width =100. We achieve 37.57 macro F1 with\na 6 checkpoint model ensemble on the official English to Portuguese shared task\ntest data, outperforming a baseline Amazon translation system of 21.30 macro F1\nand ultimately demonstrating the utility of our intuitive method.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 05:46:15 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Nagoudi", "El Moatez Billah", ""], ["Abdul-Mageed", "Muhammad", ""], ["Cavusoglu", "Hasan", ""]]}, {"id": "2006.04102", "submitter": "Nayeon Lee", "authors": "Nayeon Lee, Belinda Z. Li, Sinong Wang, Wen-tau Yih, Hao Ma, Madian\n  Khabsa", "title": "Language Models as Fact Checkers?", "comments": "Accepted in FEVER Workshop (ACL2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has suggested that language models (LMs) store both common-sense\nand factual knowledge learned from pre-training data. In this paper, we\nleverage this implicit knowledge to create an effective end-to-end fact checker\nusing a solely a language model, without any external knowledge or explicit\nretrieval components. While previous work on extracting knowledge from LMs have\nfocused on the task of open-domain question answering, to the best of our\nknowledge, this is the first work to examine the use of language models as fact\ncheckers. In a closed-book setting, we show that our zero-shot LM approach\noutperforms a random baseline on the standard FEVER task, and that our\nfine-tuned LM compares favorably with standard baselines. Though we do not\nultimately outperform methods which use explicit knowledge bases, we believe\nour exploration shows that this method is viable and has much room for\nexploration.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 09:52:05 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 07:15:37 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Lee", "Nayeon", ""], ["Li", "Belinda Z.", ""], ["Wang", "Sinong", ""], ["Yih", "Wen-tau", ""], ["Ma", "Hao", ""], ["Khabsa", "Madian", ""]]}, {"id": "2006.04109", "submitter": "Yipeng Kang", "authors": "Yipeng Kang, Tonghan Wang, Gerard de Melo", "title": "Incorporating Pragmatic Reasoning Communication into Emergent Language", "comments": "9 pages. Accepted as a spotlight paper to NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emergentism and pragmatics are two research fields that study the dynamics of\nlinguistic communication along substantially different timescales and\nintelligence levels. From the perspective of multi-agent reinforcement\nlearning, they correspond to stochastic games with reinforcement training and\nstage games with opponent awareness. Given that their combination has been\nexplored in linguistics, we propose computational models that combine\nshort-term mutual reasoning-based pragmatics with long-term language\nemergentism. We explore this for agent communication referential games as well\nas in Starcraft II, assessing the relative merits of different kinds of mutual\nreasoning pragmatics models both empirically and theoretically. Our results\nshed light on their importance for making inroads towards getting more natural,\naccurate, robust, fine-grained, and succinct utterances.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 10:31:06 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 18:19:21 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Kang", "Yipeng", ""], ["Wang", "Tonghan", ""], ["de Melo", "Gerard", ""]]}, {"id": "2006.04136", "submitter": "Thomas Drugman", "authors": "Benjamin Picart, Thomas Drugman, Thierry Dutoit", "title": "Analysis and Synthesis of Hypo and Hyperarticulated Speech", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the analysis and synthesis of hypo and hyperarticulated\nspeech in the framework of HMM-based speech synthesis. First of all, a new\nFrench database matching our needs was created, which contains three identical\nsets, pronounced with three different degrees of articulation: neutral, hypo\nand hyperarticulated speech. On that basis, acoustic and phonetic analyses were\nperformed. It is shown that the degrees of articulation significantly\ninfluence, on one hand, both vocal tract and glottal characteristics, and on\nthe other hand, speech rate, phone durations, phone variations and the presence\nof glottal stops. Finally, neutral, hypo and hyperarticulated speech are\nsynthesized using HMM-based speech synthesis and both objective and subjective\ntests aiming at assessing the generated speech quality are performed. These\ntests show that synthesized hypoarticulated speech seems to be less naturally\nrendered than neutral and hyperarticulated speech.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 12:21:16 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Picart", "Benjamin", ""], ["Drugman", "Thomas", ""], ["Dutoit", "Thierry", ""]]}, {"id": "2006.04138", "submitter": "Thomas Drugman", "authors": "Thomas Drugman", "title": "Maximum Phase Modeling for Sparse Linear Prediction of Speech", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear prediction (LP) is an ubiquitous analysis method in speech processing.\nVarious studies have focused on sparse LP algorithms by introducing sparsity\nconstraints into the LP framework. Sparse LP has been shown to be effective in\nseveral issues related to speech modeling and coding. However, all existing\napproaches assume the speech signal to be minimum-phase. Because speech is\nknown to be mixed-phase, the resulting residual signal contains a persistent\nmaximum-phase component. The aim of this paper is to propose a novel technique\nwhich incorporates a modeling of the maximum-phase contribution of speech, and\ncan be applied to any filter representation. The proposed method is shown to\nsignificantly increase the sparsity of the LP residual signal and to be\neffective in two illustrative applications: speech polarity detection and\nexcitation modeling.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 12:34:20 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Drugman", "Thomas", ""]]}, {"id": "2006.04142", "submitter": "Thomas Drugman", "authors": "Onur Babacan, Thomas Drugman, Tuomo Raitio, Daniel Erro, Thierry\n  Dutoit", "title": "Parametric Representation for Singing Voice Synthesis: a Comparative\n  Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various parametric representations have been proposed to model the speech\nsignal. While the performance of such vocoders is well-known in the context of\nspeech processing, their extrapolation to singing voice synthesis might not be\nstraightforward. The goal of this paper is twofold. First, a comparative\nsubjective evaluation is performed across four existing techniques suitable for\nstatistical parametric synthesis: traditional pulse vocoder, Deterministic plus\nStochastic Model, Harmonic plus Noise Model and GlottHMM. The behavior of these\ntechniques as a function of the singer type (baritone, counter-tenor and\nsoprano) is studied. Secondly, the artifacts occurring in high-pitched voices\nare discussed and possible approaches to overcome them are suggested.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 13:06:30 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Babacan", "Onur", ""], ["Drugman", "Thomas", ""], ["Raitio", "Tuomo", ""], ["Erro", "Daniel", ""], ["Dutoit", "Thierry", ""]]}, {"id": "2006.04148", "submitter": "Hillel Taub-Tabib", "authors": "Hillel Taub-Tabib, Micah Shlain, Shoval Sadde, Dan Lahav, Matan Eyal,\n  Yaara Cohen, Yoav Goldberg", "title": "Interactive Extractive Search over Biomedical Corpora", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a system that allows life-science researchers to search a\nlinguistically annotated corpus of scientific texts using patterns over\ndependency graphs, as well as using patterns over token sequences and a\npowerful variant of boolean keyword queries. In contrast to previous attempts\nto dependency-based search, we introduce a light-weight query language that\ndoes not require the user to know the details of the underlying linguistic\nrepresentations, and instead to query the corpus by providing an example\nsentence coupled with simple markup. Search is performed at an interactive\nspeed due to efficient linguistic graph-indexing and retrieval engine. This\nallows for rapid exploration, development and refinement of user queries. We\ndemonstrate the system using example workflows over two corpora: the PubMed\ncorpus including 14,446,243 PubMed abstracts and the CORD-19 dataset, a\ncollection of over 45,000 research papers focused on COVID-19 research. The\nsystem is publicly available at https://allenai.github.io/spike\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 13:26:32 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Taub-Tabib", "Hillel", ""], ["Shlain", "Micah", ""], ["Sadde", "Shoval", ""], ["Lahav", "Dan", ""], ["Eyal", "Matan", ""], ["Cohen", "Yaara", ""], ["Goldberg", "Yoav", ""]]}, {"id": "2006.04152", "submitter": "Canwen Xu", "authors": "Wangchunshu Zhou and Canwen Xu and Tao Ge and Julian McAuley and Ke Xu\n  and Furu Wei", "title": "BERT Loses Patience: Fast and Robust Inference with Early Exit", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose Patience-based Early Exit, a straightforward yet\neffective inference method that can be used as a plug-and-play technique to\nsimultaneously improve the efficiency and robustness of a pretrained language\nmodel (PLM). To achieve this, our approach couples an internal-classifier with\neach layer of a PLM and dynamically stops inference when the intermediate\npredictions of the internal classifiers remain unchanged for a pre-defined\nnumber of steps. Our approach improves inference efficiency as it allows the\nmodel to make a prediction with fewer layers. Meanwhile, experimental results\nwith an ALBERT model show that our method can improve the accuracy and\nrobustness of the model by preventing it from overthinking and exploiting\nmultiple classifiers for prediction, yielding a better accuracy-speed trade-off\ncompared to existing early exit methods.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 13:38:32 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 04:46:19 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 06:37:36 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Zhou", "Wangchunshu", ""], ["Xu", "Canwen", ""], ["Ge", "Tao", ""], ["McAuley", "Julian", ""], ["Xu", "Ke", ""], ["Wei", "Furu", ""]]}, {"id": "2006.04229", "submitter": "S{\\l}awomir Dadas", "authors": "S{\\l}awomir Dadas, Micha{\\l} Pere{\\l}kiewicz, Rafa{\\l} Po\\'swiata", "title": "Pre-training Polish Transformer-based Language Models at Scale", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer-based language models are now widely used in Natural Language\nProcessing (NLP). This statement is especially true for English language, in\nwhich many pre-trained models utilizing transformer-based architecture have\nbeen published in recent years. This has driven forward the state of the art\nfor a variety of standard NLP tasks such as classification, regression, and\nsequence labeling, as well as text-to-text tasks, such as machine translation,\nquestion answering, or summarization. The situation have been different for\nlow-resource languages, such as Polish, however. Although some\ntransformer-based language models for Polish are available, none of them have\ncome close to the scale, in terms of corpus size and the number of parameters,\nof the largest English-language models. In this study, we present two language\nmodels for Polish based on the popular BERT architecture. The larger model was\ntrained on a dataset consisting of over 1 billion polish sentences, or 135GB of\nraw text. We describe our methodology for collecting the data, preparing the\ncorpus, and pre-training the model. We then evaluate our models on thirteen\nPolish linguistic tasks, and demonstrate improvements over previous approaches\nin eleven of them.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 18:48:58 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 12:58:43 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Dadas", "S\u0142awomir", ""], ["Pere\u0142kiewicz", "Micha\u0142", ""], ["Po\u015bwiata", "Rafa\u0142", ""]]}, {"id": "2006.04232", "submitter": "Esma Balk{\\i}r", "authors": "Esma Balkir, Daniel Gildea and Shay Cohen", "title": "Tensors over Semirings for Latent-Variable Weighted Logic Programs", "comments": "Accepted to IWPT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semiring parsing is an elegant framework for describing parsers by using\nsemiring weighted logic programs. In this paper we present a generalization of\nthis concept: latent-variable semiring parsing. With our framework, any\nsemiring weighted logic program can be latentified by transforming weights from\nscalar values of a semiring to rank-n arrays, or tensors, of semiring values,\nallowing the modelling of latent variables within the semiring parsing\nframework. Semiring is too strong a notion when dealing with tensors, and we\nhave to resort to a weaker structure: a partial semiring. We prove that this\ngeneralization preserves all the desired properties of the original semiring\nframework while strictly increasing its expressiveness.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 18:52:58 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Balkir", "Esma", ""], ["Gildea", "Daniel", ""], ["Cohen", "Shay", ""]]}, {"id": "2006.04315", "submitter": "Yulei Niu", "authors": "Yulei Niu, Kaihua Tang, Hanwang Zhang, Zhiwu Lu, Xian-Sheng Hua,\n  Ji-Rong Wen", "title": "Counterfactual VQA: A Cause-Effect Look at Language Bias", "comments": "Accepted by CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  VQA models may tend to rely on language bias as a shortcut and thus fail to\nsufficiently learn the multi-modal knowledge from both vision and language.\nRecent debiasing methods proposed to exclude the language prior during\ninference. However, they fail to disentangle the \"good\" language context and\n\"bad\" language bias from the whole. In this paper, we investigate how to\nmitigate language bias in VQA. Motivated by causal effects, we proposed a novel\ncounterfactual inference framework, which enables us to capture the language\nbias as the direct causal effect of questions on answers and reduce the\nlanguage bias by subtracting the direct language effect from the total causal\neffect. Experiments demonstrate that our proposed counterfactual inference\nframework 1) is general to various VQA backbones and fusion strategies, 2)\nachieves competitive performance on the language-bias sensitive VQA-CP dataset\nwhile performs robustly on the balanced VQA v2 dataset without any augmented\ndata. The code is available at https://github.com/yuleiniu/cfvqa.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 01:49:27 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 16:08:46 GMT"}, {"version": "v3", "created": "Mon, 28 Dec 2020 10:35:08 GMT"}, {"version": "v4", "created": "Thu, 1 Apr 2021 16:15:36 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Niu", "Yulei", ""], ["Tang", "Kaihua", ""], ["Zhang", "Hanwang", ""], ["Lu", "Zhiwu", ""], ["Hua", "Xian-Sheng", ""], ["Wen", "Ji-Rong", ""]]}, {"id": "2006.04334", "submitter": "Shahan Ali Memon", "authors": "Shahan Ali Memon, Aman Tyagi, David R. Mortensen, Kathleen M. Carley", "title": "Characterizing Sociolinguistic Variation in the Competing Vaccination\n  Communities", "comments": "11 pages, 4 tables, 1 figure, 1 algorithm, accepted to SBP-BRiMS 2020\n  -- International Conference on Social Computing, Behavioral-Cultural Modeling\n  & Prediction and Behavior Representation in Modeling and Simulation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Public health practitioners and policy makers grapple with the challenge of\ndevising effective message-based interventions for debunking public health\nmisinformation in cyber communities. \"Framing\" and \"personalization\" of the\nmessage is one of the key features for devising a persuasive messaging\nstrategy. For an effective health communication, it is imperative to focus on\n\"preference-based framing\" where the preferences of the target sub-community\nare taken into consideration. To achieve that, it is important to understand\nand hence characterize the target sub-communities in terms of their social\ninteractions. In the context of health-related misinformation, vaccination\nremains to be the most prevalent topic of discord. Hence, in this paper, we\nconduct a sociolinguistic analysis of the two competing vaccination communities\non Twitter: \"pro-vaxxers\" or individuals who believe in the effectiveness of\nvaccinations, and \"anti-vaxxers\" or individuals who are opposed to\nvaccinations. Our data analysis show significant linguistic variation between\nthe two communities in terms of their usage of linguistic intensifiers,\npronouns, and uncertainty words. Our network-level analysis show significant\ndifferences between the two communities in terms of their network density,\necho-chamberness, and the EI index. We hypothesize that these sociolinguistic\ndifferences can be used as proxies to characterize and understand these\ncommunities to devise better message interventions.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 03:05:28 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 09:39:51 GMT"}, {"version": "v3", "created": "Sun, 4 Oct 2020 13:28:50 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Memon", "Shahan Ali", ""], ["Tyagi", "Aman", ""], ["Mortensen", "David R.", ""], ["Carley", "Kathleen M.", ""]]}, {"id": "2006.04469", "submitter": "Muhammed Shifas Pv", "authors": "Muhammed PV Shifas, Nagaraj Adiga, Vassilis Tsiaras, Yannis Stylianou", "title": "A non-causal FFTNet architecture for speech enhancement", "comments": "5 pages", "journal-ref": null, "doi": "10.21437/Interspeech.2019-2622", "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we suggest a new parallel, non-causal and shallow waveform\ndomain architecture for speech enhancement based on FFTNet, a neural network\nfor generating high quality audio waveform. In contrast to other waveform based\napproaches like WaveNet, FFTNet uses an initial wide dilation pattern. Such an\narchitecture better represents the long term correlated structure of speech in\nthe time domain, where noise is usually highly non-correlated, and therefore it\nis suitable for waveform domain based speech enhancement. To further strengthen\nthis feature of FFTNet, we suggest a non-causal FFTNet architecture, where the\npresent sample in each layer is estimated from the past and future samples of\nthe previous layer. By suggesting a shallow network and applying non-causality\nwithin certain limits, the suggested FFTNet for speech enhancement (SE-FFTNet)\nuses much fewer parameters compared to other neural network based approaches\nfor speech enhancement like WaveNet and SEGAN. Specifically, the suggested\nnetwork has considerably reduced model parameters: 32% fewer compared to\nWaveNet and 87% fewer compared to SEGAN. Finally, based on subjective and\nobjective metrics, SE-FFTNet outperforms WaveNet in terms of enhanced signal\nquality, while it provides equally good performance as SEGAN. A Tensorflow\nimplementation of the architecture is provided at 1 .\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 10:49:04 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Shifas", "Muhammed PV", ""], ["Adiga", "Nagaraj", ""], ["Tsiaras", "Vassilis", ""], ["Stylianou", "Yannis", ""]]}, {"id": "2006.04513", "submitter": "Yoan Dimitrov", "authors": "Yoan Dimitrov", "title": "Combining word embeddings and convolutional neural networks to detect\n  duplicated questions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Detecting semantic similarities between sentences is still a challenge today\ndue to the ambiguity of natural languages. In this work, we propose a simple\napproach to identifying semantically similar questions by combining the\nstrengths of word embeddings and Convolutional Neural Networks (CNNs). In\naddition, we demonstrate how the cosine similarity metric can be used to\neffectively compare feature vectors. Our network is trained on the Quora\ndataset, which contains over 400k question pairs. We experiment with different\nembedding approaches such as Word2Vec, Fasttext, and Doc2Vec and investigate\nthe effects these approaches have on model performance. Our model achieves\ncompetitive results on the Quora dataset and complements the well-established\nevidence that CNNs can be utilized for paraphrase detection tasks.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 12:30:25 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Dimitrov", "Yoan", ""]]}, {"id": "2006.04558", "submitter": "Yi Ren", "authors": "Yi Ren, Chenxu Hu, Xu Tan, Tao Qin, Sheng Zhao, Zhou Zhao, Tie-Yan Liu", "title": "FastSpeech 2: Fast and High-Quality End-to-End Text to Speech", "comments": "Accepted by ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-autoregressive text to speech (TTS) models such as FastSpeech can\nsynthesize speech significantly faster than previous autoregressive models with\ncomparable quality. The training of FastSpeech model relies on an\nautoregressive teacher model for duration prediction (to provide more\ninformation as input) and knowledge distillation (to simplify the data\ndistribution in output), which can ease the one-to-many mapping problem (i.e.,\nmultiple speech variations correspond to the same text) in TTS. However,\nFastSpeech has several disadvantages: 1) the teacher-student distillation\npipeline is complicated and time-consuming, 2) the duration extracted from the\nteacher model is not accurate enough, and the target mel-spectrograms distilled\nfrom teacher model suffer from information loss due to data simplification,\nboth of which limit the voice quality. In this paper, we propose FastSpeech 2,\nwhich addresses the issues in FastSpeech and better solves the one-to-many\nmapping problem in TTS by 1) directly training the model with ground-truth\ntarget instead of the simplified output from teacher, and 2) introducing more\nvariation information of speech (e.g., pitch, energy and more accurate\nduration) as conditional inputs. Specifically, we extract duration, pitch and\nenergy from speech waveform and directly take them as conditional inputs in\ntraining and use predicted values in inference. We further design FastSpeech\n2s, which is the first attempt to directly generate speech waveform from text\nin parallel, enjoying the benefit of fully end-to-end inference. Experimental\nresults show that 1) FastSpeech 2 achieves a 3x training speed-up over\nFastSpeech, and FastSpeech 2s enjoys even faster inference speed; 2) FastSpeech\n2 and 2s outperform FastSpeech in voice quality, and FastSpeech 2 can even\nsurpass autoregressive models. Audio samples are available at\nhttps://speechresearch.github.io/fastspeech2/.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 13:05:40 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 09:33:54 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2020 05:30:06 GMT"}, {"version": "v4", "created": "Fri, 16 Oct 2020 14:34:02 GMT"}, {"version": "v5", "created": "Wed, 3 Mar 2021 04:36:43 GMT"}, {"version": "v6", "created": "Thu, 4 Mar 2021 05:52:28 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Ren", "Yi", ""], ["Hu", "Chenxu", ""], ["Tan", "Xu", ""], ["Qin", "Tao", ""], ["Zhao", "Sheng", ""], ["Zhao", "Zhou", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2006.04562", "submitter": "Mirko Lenz", "authors": "Mirko Lenz, Premtim Sahitaj, Sean Kallenberg, Christopher Coors, Lorik\n  Dumani, Ralf Schenkel, Ralph Bergmann", "title": "Towards an Argument Mining Pipeline Transforming Texts to Argument\n  Graphs", "comments": null, "journal-ref": null, "doi": "10.3233/FAIA200510", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper targets the automated extraction of components of argumentative\ninformation and their relations from natural language text. Moreover, we\naddress a current lack of systems to provide complete argumentative structure\nfrom arbitrary natural language text for general usage. We present an argument\nmining pipeline as a universally applicable approach for transforming German\nand English language texts to graph-based argument representations. We also\nintroduce new methods for evaluating the results based on existing benchmark\nargument structures. Our results show that the generated argument graphs can be\nbeneficial to detect new connections between different statements of an\nargumentative text. Our pipeline implementation is publicly available on\nGitHub.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 13:10:19 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 11:07:04 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Lenz", "Mirko", ""], ["Sahitaj", "Premtim", ""], ["Kallenberg", "Sean", ""], ["Coors", "Christopher", ""], ["Dumani", "Lorik", ""], ["Schenkel", "Ralf", ""], ["Bergmann", "Ralph", ""]]}, {"id": "2006.04597", "submitter": "Frances Laureano De Leon", "authors": "Frances Adriana Laureano De Leon and Florimond Gu\\'eniat and Harish\n  Tayyar Madabushi", "title": "CS-Embed at SemEval-2020 Task 9: The effectiveness of code-switched word\n  embeddings for sentiment analysis", "comments": "Accepted at SemEval-2020, COLING", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The growing popularity and applications of sentiment analysis of social media\nposts has naturally led to sentiment analysis of posts written in multiple\nlanguages, a practice known as code-switching. While recent research into\ncode-switched posts has focused on the use of multilingual word embeddings,\nthese embeddings were not trained on code-switched data. In this work, we\npresent word-embeddings trained on code-switched tweets, specifically those\nthat make use of Spanish and English, known as Spanglish. We explore the\nembedding space to discover how they capture the meanings of words in both\nlanguages. We test the effectiveness of these embeddings by participating in\nSemEval 2020 Task 9: ~\\emph{Sentiment Analysis on Code-Mixed Social Media\nText}. We utilised them to train a sentiment classifier that achieves an F-1\nscore of 0.722. This is higher than the baseline for the competition of 0.656,\nwith our team (codalab username \\emph{francesita}) ranking 14 out of 29\nparticipating teams, beating the baseline.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 13:48:17 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 10:39:45 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["De Leon", "Frances Adriana Laureano", ""], ["Gu\u00e9niat", "Florimond", ""], ["Madabushi", "Harish Tayyar", ""]]}, {"id": "2006.04598", "submitter": "Hyeongju Kim", "authors": "Hyeongju Kim, Hyeonseung Lee, Woo Hyun Kang, Sung Jun Cheon, Byoung\n  Jin Choi, Nam Soo Kim", "title": "WaveNODE: A Continuous Normalizing Flow for Speech Synthesis", "comments": "8 pages, 4 figures, Second workshop on Invertible Neural Networks,\n  Normalizing Flows, and Explicit Likelihood Models (ICML 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, various flow-based generative models have been proposed to\ngenerate high-fidelity waveforms in real-time. However, these models require\neither a well-trained teacher network or a number of flow steps making them\nmemory-inefficient. In this paper, we propose a novel generative model called\nWaveNODE which exploits a continuous normalizing flow for speech synthesis.\nUnlike the conventional models, WaveNODE places no constraint on the function\nused for flow operation, thus allowing the usage of more flexible and complex\nfunctions. Moreover, WaveNODE can be optimized to maximize the likelihood\nwithout requiring any teacher network or auxiliary loss terms. We\nexperimentally show that WaveNODE achieves comparable performance with fewer\nparameters compared to the conventional flow-based vocoders.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 13:49:36 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 01:32:06 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 02:28:02 GMT"}, {"version": "v4", "created": "Thu, 2 Jul 2020 23:12:56 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Kim", "Hyeongju", ""], ["Lee", "Hyeonseung", ""], ["Kang", "Woo Hyun", ""], ["Cheon", "Sung Jun", ""], ["Choi", "Byoung Jin", ""], ["Kim", "Nam Soo", ""]]}, {"id": "2006.04611", "submitter": "Kaustubh Yadav", "authors": "Kaustubh Yadav", "title": "A Comprehensive Survey on Aspect Based Sentiment Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect Based Sentiment Analysis (ABSA) is the sub-field of Natural Language\nProcessing that deals with essentially splitting our data into aspects ad\nfinally extracting the sentiment information. ABSA is known to provide more\ninformation about the context than general sentiment analysis. In this study,\nour aim is to explore the various methodologies practiced while performing\nABSA, and providing a comparative study. This survey paper discusses various\nsolutions in-depth and gives a comparison between them. And is conveniently\ndivided into sections to get a holistic view on the process.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 14:07:58 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Yadav", "Kaustubh", ""]]}, {"id": "2006.04643", "submitter": "Jacopo Staiano", "authors": "Thomas Scialom, Paul-Alexis Dray, Sylvain Lamprier, Benjamin\n  Piwowarski, Jacopo Staiano", "title": "ColdGANs: Taming Language GANs with Cautious Sampling Strategies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training regimes based on Maximum Likelihood Estimation (MLE) suffer from\nknown limitations, often leading to poorly generated text sequences. At the\nroot of these limitations is the mismatch between training and inference, i.e.\nthe so-called exposure bias, exacerbated by considering only the reference\ntexts as correct, while in practice several alternative formulations could be\nas good. Generative Adversarial Networks (GANs) can mitigate those limitations\nbut the discrete nature of text has hindered their application to language\ngeneration: the approaches proposed so far, based on Reinforcement Learning,\nhave been shown to underperform MLE. Departing from previous works, we analyze\nthe exploration step in GANs applied to text generation, and show how classical\nsampling results in unstable training. We propose to consider alternative\nexploration strategies in a GAN framework that we name ColdGANs, where we force\nthe sampling to be close to the distribution modes to get smoother learning\ndynamics. For the first time, to the best of our knowledge, the proposed\nlanguage GANs compare favorably to MLE, and obtain improvements over the\nstate-of-the-art on three generative tasks, namely unconditional text\ngeneration, question generation, and abstractive summarization.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 14:48:14 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Scialom", "Thomas", ""], ["Dray", "Paul-Alexis", ""], ["Lamprier", "Sylvain", ""], ["Piwowarski", "Benjamin", ""], ["Staiano", "Jacopo", ""]]}, {"id": "2006.04660", "submitter": "Rajdeep Mukherjee", "authors": "Rajdeep Mukherjee, Hari Chandana Peruri, Uppada Vishnu, Pawan Goyal,\n  Sourangshu Bhattacharya, Niloy Ganguly", "title": "Read what you need: Controllable Aspect-based Opinion Summarization of\n  Tourist Reviews", "comments": "4 pages, accepted in the Proceedings of the 43rd International ACM\n  SIGIR Conference on Research and Development in Information Retrieval\n  (SIGIR), 2020", "journal-ref": null, "doi": "10.1145/3397271.3401269", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manually extracting relevant aspects and opinions from large volumes of\nuser-generated text is a time-consuming process. Summaries, on the other hand,\nhelp readers with limited time budgets to quickly consume the key ideas from\nthe data. State-of-the-art approaches for multi-document summarization,\nhowever, do not consider user preferences while generating summaries. In this\nwork, we argue the need and propose a solution for generating personalized\naspect-based opinion summaries from large collections of online tourist\nreviews. We let our readers decide and control several attributes of the\nsummary such as the length and specific aspects of interest among others.\nSpecifically, we take an unsupervised approach to extract coherent aspects from\ntourist reviews posted on TripAdvisor. We then propose an Integer Linear\nProgramming (ILP) based extractive technique to select an informative subset of\nopinions around the identified aspects while respecting the user-specified\nvalues for various control parameters. Finally, we evaluate and compare our\nsummaries using crowdsourcing and ROUGE-based metrics and obtain competitive\nresults.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 15:03:38 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 07:22:48 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Mukherjee", "Rajdeep", ""], ["Peruri", "Hari Chandana", ""], ["Vishnu", "Uppada", ""], ["Goyal", "Pawan", ""], ["Bhattacharya", "Sourangshu", ""], ["Ganguly", "Niloy", ""]]}, {"id": "2006.04664", "submitter": "Mingjian Chen", "authors": "Mingjian Chen, Xu Tan, Yi Ren, Jin Xu, Hao Sun, Sheng Zhao, Tao Qin,\n  Tie-Yan Liu", "title": "MultiSpeech: Multi-Speaker Text to Speech with Transformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer-based text to speech (TTS) model (e.g., Transformer\nTTS~\\cite{li2019neural}, FastSpeech~\\cite{ren2019fastspeech}) has shown the\nadvantages of training and inference efficiency over RNN-based model (e.g.,\nTacotron~\\cite{shen2018natural}) due to its parallel computation in training\nand/or inference. However, the parallel computation increases the difficulty\nwhile learning the alignment between text and speech in Transformer, which is\nfurther magnified in the multi-speaker scenario with noisy data and diverse\nspeakers, and hinders the applicability of Transformer for multi-speaker TTS.\nIn this paper, we develop a robust and high-quality multi-speaker Transformer\nTTS system called MultiSpeech, with several specially designed\ncomponents/techniques to improve text-to-speech alignment: 1) a diagonal\nconstraint on the weight matrix of encoder-decoder attention in both training\nand inference; 2) layer normalization on phoneme embedding in encoder to better\npreserve position information; 3) a bottleneck in decoder pre-net to prevent\ncopy between consecutive speech frames. Experiments on VCTK and LibriTTS\nmulti-speaker datasets demonstrate the effectiveness of MultiSpeech: 1) it\nsynthesizes more robust and better quality multi-speaker voice than naive\nTransformer based TTS; 2) with a MutiSpeech model as the teacher, we obtain a\nstrong multi-speaker FastSpeech model with almost zero quality degradation\nwhile enjoying extremely fast inference speed.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 15:05:28 GMT"}, {"version": "v2", "created": "Sat, 1 Aug 2020 03:45:03 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Chen", "Mingjian", ""], ["Tan", "Xu", ""], ["Ren", "Yi", ""], ["Xu", "Jin", ""], ["Sun", "Hao", ""], ["Zhao", "Sheng", ""], ["Qin", "Tao", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2006.04666", "submitter": "Nayeon Lee", "authors": "Nayeon Lee, Yejin Bang, Andrea Madotto, Pascale Fung", "title": "Misinformation Has High Perplexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Debunking misinformation is an important and time-critical task as there\ncould be adverse consequences when misinformation is not quashed promptly.\nHowever, the usual supervised approach to debunking via misinformation\nclassification requires human-annotated data and is not suited to the fast\ntime-frame of newly emerging events such as the COVID-19 outbreak. In this\npaper, we postulate that misinformation itself has higher perplexity compared\nto truthful statements, and propose to leverage the perplexity to debunk false\nclaims in an unsupervised manner. First, we extract reliable evidence from\nscientific and news sources according to sentence similarity to the claims.\nSecond, we prime a language model with the extracted evidence and finally\nevaluate the correctness of given claims based on the perplexity scores at\ndebunking time. We construct two new COVID-19-related test sets, one is\nscientific, and another is political in content, and empirically verify that\nour system performs favorably compared to existing systems. We are releasing\nthese datasets publicly to encourage more research in debunking misinformation\non COVID-19 and other topics.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 15:13:44 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 08:49:30 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Lee", "Nayeon", ""], ["Bang", "Yejin", ""], ["Madotto", "Andrea", ""], ["Fung", "Pascale", ""]]}, {"id": "2006.04702", "submitter": "Zhijing Jin", "authors": "Qipeng Guo, Zhijing Jin, Xipeng Qiu, Weinan Zhang, David Wipf, Zheng\n  Zhang", "title": "CycleGT: Unsupervised Graph-to-Text and Text-to-Graph Generation via\n  Cycle Training", "comments": "INLG 2020 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Two important tasks at the intersection of knowledge graphs and natural\nlanguage processing are graph-to-text (G2T) and text-to-graph (T2G) conversion.\nDue to the difficulty and high cost of data collection, the supervised data\navailable in the two fields are usually on the magnitude of tens of thousands,\nfor example, 18K in the WebNLG~2017 dataset after preprocessing, which is far\nfewer than the millions of data for other tasks such as machine translation.\nConsequently, deep learning models for G2T and T2G suffer largely from scarce\ntraining data. We present CycleGT, an unsupervised training method that can\nbootstrap from fully non-parallel graph and text data, and iteratively back\ntranslate between the two forms. Experiments on WebNLG datasets show that our\nunsupervised model trained on the same number of data achieves performance on\npar with several fully supervised models. Further experiments on the\nnon-parallel GenWiki dataset verify that our method performs the best among\nunsupervised baselines. This validates our framework as an effective approach\nto overcome the data scarcity problem in the fields of G2T and T2G. Our code is\navailable at https://github.com/QipengGuo/CycleGT.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 15:59:00 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 17:26:44 GMT"}, {"version": "v3", "created": "Wed, 9 Dec 2020 19:29:27 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Guo", "Qipeng", ""], ["Jin", "Zhijing", ""], ["Qiu", "Xipeng", ""], ["Zhang", "Weinan", ""], ["Wipf", "David", ""], ["Zhang", "Zheng", ""]]}, {"id": "2006.04721", "submitter": "Junxuan Chen", "authors": "Junxuan Chen, Xiang Li, Jiarui Zhang, Chulun Zhou, Jianwei Cui, Bin\n  Wang, Jinsong Su", "title": "Modeling Discourse Structure for Document-level Neural Machine\n  Translation", "comments": null, "journal-ref": "AutoSimTrans2020 camera-ready", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, document-level neural machine translation (NMT) has become a hot\ntopic in the community of machine translation. Despite its success, most of\nexisting studies ignored the discourse structure information of the input\ndocument to be translated, which has shown effective in other tasks. In this\npaper, we propose to improve document-level NMT with the aid of discourse\nstructure information. Our encoder is based on a hierarchical attention network\n(HAN). Specifically, we first parse the input document to obtain its discourse\nstructure. Then, we introduce a Transformer-based path encoder to embed the\ndiscourse structure information of each word. Finally, we combine the discourse\nstructure information with the word embedding before it is fed into the\nencoder. Experimental results on the English-to-German dataset show that our\nmodel can significantly outperform both Transformer and Transformer+HAN.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 16:24:03 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Chen", "Junxuan", ""], ["Li", "Xiang", ""], ["Zhang", "Jiarui", ""], ["Zhou", "Chulun", ""], ["Cui", "Jianwei", ""], ["Wang", "Bin", ""], ["Su", "Jinsong", ""]]}, {"id": "2006.04781", "submitter": "Samuel L\\\"aubli", "authors": "Lukas Fischer and Samuel L\\\"aubli", "title": "What's the Difference Between Professional Human and Machine\n  Translation? A Blind Multi-language Study on Domain-specific MT", "comments": "EAMT 2020 (Research Track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine translation (MT) has been shown to produce a number of errors that\nrequire human post-editing, but the extent to which professional human\ntranslation (HT) contains such errors has not yet been compared to MT. We\ncompile pre-translated documents in which MT and HT are interleaved, and ask\nprofessional translators to flag errors and post-edit these documents in a\nblind evaluation. We find that the post-editing effort for MT segments is only\nhigher in two out of three language pairs, and that the number of segments with\nwrong terminology, omissions, and typographical problems is similar in HT.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 17:55:14 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Fischer", "Lukas", ""], ["L\u00e4ubli", "Samuel", ""]]}, {"id": "2006.05003", "submitter": "Satish Mylapore", "authors": "Satish Mylapore, Ryan Quincy Paul, Joshua Yi, and Robert D. Slater", "title": "Universal Vector Neural Machine Translation With Effective Attention", "comments": "15pages, 3 figures", "journal-ref": "SMU Data Science Review: Vol. 3 : No. 1 , Article 10. Available\n  at: https://scholar.smu.edu/datasciencereview/vol3/iss1/10 Year March 2020", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Neural Machine Translation (NMT) leverages one or more trained neural\nnetworks for the translation of phrases. Sutskever introduced a sequence to\nsequence based encoder-decoder model which became the standard for NMT based\nsystems. Attention mechanisms were later introduced to address the issues with\nthe translation of long sentences and improving overall accuracy. In this\npaper, we propose a singular model for Neural Machine Translation based on\nencoder-decoder models. Most translation models are trained as one model for\none translation. We introduce a neutral/universal model representation that can\nbe used to predict more than one language depending on the source and a\nprovided target. Secondly, we introduce an attention model by adding an overall\nlearning vector to the multiplicative model. With these two changes, by using\nthe novel universal model the number of models needed for multiple language\ntranslation applications are reduced.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 01:13:57 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Mylapore", "Satish", ""], ["Paul", "Ryan Quincy", ""], ["Yi", "Joshua", ""], ["Slater", "Robert D.", ""]]}, {"id": "2006.05014", "submitter": "Adewale Akinfaderin", "authors": "Adewale Akinfaderin", "title": "HausaMT v1.0: Towards English-Hausa Neural Machine Translation", "comments": "Accepted at 4th Widening NLP Workshop, Annual Meeting of the\n  Association for Computational Linguistics, ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural Machine Translation (NMT) for low-resource languages suffers from low\nperformance because of the lack of large amounts of parallel data and language\ndiversity. To contribute to ameliorating this problem, we built a baseline\nmodel for English-Hausa machine translation, which is considered a task for\nlow-resource language. The Hausa language is the second largest Afro-Asiatic\nlanguage in the world after Arabic and it is the third largest language for\ntrading across a larger swath of West Africa countries, after English and\nFrench. In this paper, we curated different datasets containing Hausa-English\nparallel corpus for our translation. We trained baseline models and evaluated\nthe performance of our models using the Recurrent and Transformer\nencoder-decoder architecture with two tokenization approaches: standard\nword-level tokenization and Byte Pair Encoding (BPE) subword tokenization.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 02:08:03 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 04:35:37 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Akinfaderin", "Adewale", ""]]}, {"id": "2006.05113", "submitter": "Lukas Muttenthaler", "authors": "Lukas Muttenthaler, Nora Hollenstein, Maria Barrett", "title": "Human brain activity for machine attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognitively inspired NLP leverages human-derived data to teach machines about\nlanguage processing mechanisms. Recently, neural networks have been augmented\nwith behavioral data to solve a range of NLP tasks spanning syntax and\nsemantics. We are the first to exploit neuroscientific data, namely\nelectroencephalography (EEG), to inform a neural attention model about language\nprocessing of the human brain. The challenge in working with EEG data is that\nfeatures are exceptionally rich and need extensive pre-processing to isolate\nsignals specific to text processing. We devise a method for finding such EEG\nfeatures to supervise machine attention through combining theoretically\nmotivated cropping with random forest tree splits. After this dimensionality\nreduction, the pre-processed EEG features are capable of distinguishing two\nreading tasks retrieved from a publicly available EEG corpus. We apply these\nfeatures to regularise attention on relation classification and show that EEG\nis more informative than strong baselines. This improvement depends on both the\ncognitive load of the task and the EEG frequency domain. Hence, informing\nneural attention models with EEG signals is beneficial but requires further\ninvestigation to understand which dimensions are the most useful across NLP\ntasks.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 08:39:07 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 22:06:31 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Muttenthaler", "Lukas", ""], ["Hollenstein", "Nora", ""], ["Barrett", "Maria", ""]]}, {"id": "2006.05129", "submitter": "Bal\\'azs Tarj\\'an", "authors": "Bal\\'azs Tarj\\'an, Gy\\\"orgy Szasz\\'ak, Tibor Fegy\\'o, P\\'eter Mihajlik", "title": "On the Effectiveness of Neural Text Generation based Data Augmentation\n  for Recognition of Morphologically Rich Speech", "comments": "8 pages, 2 figures, accepted for publication at TSD 2020", "journal-ref": null, "doi": "10.1007/978-3-030-58323-1_47", "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advanced neural network models have penetrated Automatic Speech Recognition\n(ASR) in recent years, however, in language modeling many systems still rely on\ntraditional Back-off N-gram Language Models (BNLM) partly or entirely. The\nreason for this are the high cost and complexity of training and using neural\nlanguage models, mostly possible by adding a second decoding pass (rescoring).\nIn our recent work we have significantly improved the online performance of a\nconversational speech transcription system by transferring knowledge from a\nRecurrent Neural Network Language Model (RNNLM) to the single pass BNLM with\ntext generation based data augmentation. In the present paper we analyze the\namount of transferable knowledge and demonstrate that the neural augmented LM\n(RNN-BNLM) can help to capture almost 50% of the knowledge of the RNNLM yet by\ndropping the second decoding pass and making the system real-time capable. We\nalso systematically compare word and subword LMs and show that subword-based\nneural text augmentation can be especially beneficial in under-resourced\nconditions. In addition, we show that using the RNN-BNLM in the first pass\nfollowed by a neural second pass, offline ASR results can be even significantly\nimproved.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 09:01:04 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Tarj\u00e1n", "Bal\u00e1zs", ""], ["Szasz\u00e1k", "Gy\u00f6rgy", ""], ["Fegy\u00f3", "Tibor", ""], ["Mihajlik", "P\u00e9ter", ""]]}, {"id": "2006.05163", "submitter": "Vaishali Pal", "authors": "Vaishali Pal, Manish Shrivastava and Laurent Besacier", "title": "ConfNet2Seq: Full Length Answer Generation from Spoken Questions", "comments": "Accepted at Text, Speech and Dialogue, 2020", "journal-ref": "ConfNet2Seq, Text, Speech, and Dialogue - 23rd International\n  Conference, {TSD}, Brno, Czech Republic, September 8-11, 2020, Proceedings,\n  12284, 2020, 524-531 (2020)", "doi": "10.1007/978-3-030-58323-1_56", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational and task-oriented dialogue systems aim to interact with the\nuser using natural responses through multi-modal interfaces, such as text or\nspeech. These desired responses are in the form of full-length natural answers\ngenerated over facts retrieved from a knowledge source. While the task of\ngenerating natural answers to questions from an answer span has been widely\nstudied, there has been little research on natural sentence generation over\nspoken content. We propose a novel system to generate full length natural\nlanguage answers from spoken questions and factoid answers. The spoken sequence\nis compactly represented as a confusion network extracted from a pre-trained\nAutomatic Speech Recognizer. This is the first attempt towards generating\nfull-length natural answers from a graph input(confusion network) to the best\nof our knowledge. We release a large-scale dataset of 259,788 samples of spoken\nquestions, their factoid answers and corresponding full-length textual answers.\nFollowing our proposed approach, we achieve comparable performance with best\nASR hypothesis.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 10:04:49 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 08:39:41 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Pal", "Vaishali", ""], ["Shrivastava", "Manish", ""], ["Besacier", "Laurent", ""]]}, {"id": "2006.05165", "submitter": "Peng Li", "authors": "Qiu Ran, Yankai Lin, Peng Li, Jie Zhou", "title": "Learning to Recover from Multi-Modality Errors for Non-Autoregressive\n  Neural Machine Translation", "comments": "This work has been accepted for publication at ACL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-autoregressive neural machine translation (NAT) predicts the entire\ntarget sequence simultaneously and significantly accelerates inference process.\nHowever, NAT discards the dependency information in a sentence, and thus\ninevitably suffers from the multi-modality problem: the target tokens may be\nprovided by different possible translations, often causing token repetitions or\nmissing. To alleviate this problem, we propose a novel semi-autoregressive\nmodel RecoverSAT in this work, which generates a translation as a sequence of\nsegments. The segments are generated simultaneously while each segment is\npredicted token-by-token. By dynamically determining segment length and\ndeleting repetitive segments, RecoverSAT is capable of recovering from\nrepetitive and missing token errors. Experimental results on three widely-used\nbenchmark datasets show that our proposed model achieves more than 4$\\times$\nspeedup while maintaining comparable performance compared with the\ncorresponding autoregressive model.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 10:12:16 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Ran", "Qiu", ""], ["Lin", "Yankai", ""], ["Li", "Peng", ""], ["Zhou", "Jie", ""]]}, {"id": "2006.05174", "submitter": "Tsung-Han Wu", "authors": "Tsung-Han Wu, Chun-Chen Hsieh, Yen-Hao Chen, Po-Han Chi, Hung-yi Lee", "title": "Input-independent Attention Weights Are Expressive Enough: A Study of\n  Attention in Self-supervised Audio Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we seek solutions for reducing the computation complexity of\ntransformer-based models for speech representation learning. We evaluate 10\nattention algorithms; then, we pre-train the transformer-based model with those\nattention algorithms in a self-supervised fashion and treat them as feature\nextractors on downstream tasks, including phoneme classification and speaker\nclassification. With the assistance of t-SNE, PCA and some observation, the\nattention weights in self-supervised audio transformers can be categorized into\nfour general cases. Based on these cases and some analyses, we are able to use\na specific set of attention weights to initialize the model. Our approach shows\ncomparable performance to the typical self-attention yet requires 20% less time\nin both training and inference.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 10:40:52 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 06:32:17 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Wu", "Tsung-Han", ""], ["Hsieh", "Chun-Chen", ""], ["Chen", "Yen-Hao", ""], ["Chi", "Po-Han", ""], ["Lee", "Hung-yi", ""]]}, {"id": "2006.05206", "submitter": "Jayden Macklin-Cordes", "authors": "Jayden L. Macklin-Cordes, Erich R. Round", "title": "Re-evaluating phoneme frequencies", "comments": "29pp (3 figures, 3 tables). This article has been provisionally\n  accepted for publication (Frontiers in Psychology, Language Sciences).\n  Supplementary information, data and code available at\n  http://doi.org/10.5281/zenodo.3886212", "journal-ref": null, "doi": "10.3389/fpsyg.2020.570895", "report-no": null, "categories": "cs.CL physics.soc-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal processes can give rise to distinctive distributions in the linguistic\nvariables that they affect. Consequently, a secure understanding of a\nvariable's distribution can hold a key to understanding the forces that have\ncausally shaped it. A storied distribution in linguistics has been Zipf's law,\na kind of power law. In the wake of a major debate in the sciences around\npower-law hypotheses and the unreliability of earlier methods of evaluating\nthem, here we re-evaluate the distributions claimed to characterize phoneme\nfrequencies. We infer the fit of power laws and three alternative distributions\nto 166 Australian languages, using a maximum likelihood framework. We find\nevidence supporting earlier results, but also nuancing them and increasing our\nunderstanding of them. Most notably, phonemic inventories appear to have a\nZipfian-like frequency structure among their most-frequent members (though\nperhaps also a lognormal structure) but a geometric (or exponential) structure\namong the least-frequent. We compare these new insights the kinds of causal\nprocesses that affect the evolution of phonemic inventories over time, and\nidentify a potential account for why, despite there being an important role for\nphonetic substance in phonemic change, we could still expect inventories with\nhighly diverse phonetic content to share similar distributions of phoneme\nfrequencies. We conclude with priorities for future work in this promising\nprogram of research.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 12:05:10 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 03:56:14 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Macklin-Cordes", "Jayden L.", ""], ["Round", "Erich R.", ""]]}, {"id": "2006.05213", "submitter": "Sanghyun Yoo", "authors": "Sanghyun Yoo, Young-Seok Kim, Kang Hyun Lee, Kuhwan Jeong, Junhwi\n  Choi, Hoshik Lee, Young Sang Choi", "title": "Graph-Aware Transformer: Is Attention All Graphs Need?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs are the natural data structure to represent relational and structural\ninformation in many domains. To cover the broad range of graph-data\napplications including graph classification as well as graph generation, it is\ndesirable to have a general and flexible model consisting of an encoder and a\ndecoder that can handle graph data. Although the representative encoder-decoder\nmodel, Transformer, shows superior performance in various tasks especially of\nnatural language processing, it is not immediately available for graphs due to\ntheir non-sequential characteristics. To tackle this incompatibility, we\npropose GRaph-Aware Transformer (GRAT), the first Transformer-based model which\ncan encode and decode whole graphs in end-to-end fashion. GRAT is featured with\na self-attention mechanism adaptive to the edge information and an\nauto-regressive decoding mechanism based on the two-path approach consisting of\nsub-graph encoding path and node-and-edge generation path for each decoding\nstep. We empirically evaluated GRAT on multiple setups including encoder-based\ntasks such as molecule property predictions on QM9 datasets and\nencoder-decoder-based tasks such as molecule graph generation in the organic\nmolecule synthesis domain. GRAT has shown very promising results including\nstate-of-the-art performance on 4 regression tasks in QM9 benchmark.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 12:13:56 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Yoo", "Sanghyun", ""], ["Kim", "Young-Seok", ""], ["Lee", "Kang Hyun", ""], ["Jeong", "Kuhwan", ""], ["Choi", "Junhwi", ""], ["Lee", "Hoshik", ""], ["Choi", "Young Sang", ""]]}, {"id": "2006.05236", "submitter": "Manraj Singh Grover", "authors": "Manraj Singh Grover, Pakhi Bamdev, Yaman Kumar, Mika Hama, Rajiv Ratn\n  Shah", "title": "audino: A Modern Annotation Tool for Audio and Speech", "comments": "Submitted to 28th ACM International Conference on Multimedia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a collaborative and modern annotation tool for\naudio and speech: audino. The tool allows annotators to define and describe\ntemporal segmentation in audios. These segments can be labelled and transcribed\neasily using a dynamically generated form. An admin can centrally control user\nroles and project assignment through the admin dashboard. The dashboard also\nenables describing labels and their values. The annotations can easily be\nexported in JSON format for further processing. The tool allows audio data to\nbe uploaded and assigned to a user through a key-based API. The flexibility\navailable in the annotation tool enables annotation for Speech Scoring, Voice\nActivity Detection (VAD), Speaker Diarisation, Speaker Identification, Speech\nRecognition, Emotion Recognition tasks and more. The MIT open source license\nallows it to be used for academic and commercial projects.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 13:12:44 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Grover", "Manraj Singh", ""], ["Bamdev", "Pakhi", ""], ["Kumar", "Yaman", ""], ["Hama", "Mika", ""], ["Shah", "Rajiv Ratn", ""]]}, {"id": "2006.05244", "submitter": "Mantong Zhou", "authors": "Mantong Zhou, Zhouxing Shi, Minlie Huang, Xiaoyan Zhu", "title": "Knowledge-Aided Open-Domain Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open-domain question answering (QA) aims to find the answer to a question\nfrom a large collection of documents.Though many models for single-document\nmachine comprehension have achieved strong performance, there is still much\nroom for improving open-domain QA systems since document retrieval and answer\nreranking are still unsatisfactory. Golden documents that contain the correct\nanswers may not be correctly scored by the retrieval component, and the correct\nanswers that have been extracted may be wrongly ranked after other candidate\nanswers by the reranking component. One of the reasons is derived from the\nindependent principle in which each candidate document (or answer) is scored\nindependently without considering its relationship to other documents (or\nanswers). In this work, we propose a knowledge-aided open-domain QA (KAQA)\nmethod which targets at improving relevant document retrieval and candidate\nanswer reranking by considering the relationship between a question and the\ndocuments (termed as question-document graph), and the relationship between\ncandidate documents (termed as document-document graph). The graphs are built\nusing knowledge triples from external knowledge resources. During document\nretrieval, a candidate document is scored by considering its relationship to\nthe question and other documents. During answer reranking, a candidate answer\nis reranked using not only its own context but also the clues from other\ndocuments. The experimental results show that our proposed method improves\ndocument retrieval and answer reranking, and thereby enhances the overall\nperformance of open-domain question answering.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 13:28:57 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Zhou", "Mantong", ""], ["Shi", "Zhouxing", ""], ["Huang", "Minlie", ""], ["Zhu", "Xiaoyan", ""]]}, {"id": "2006.05257", "submitter": "Sanket Shah", "authors": "Gurunath Reddy Madhumani, Sanket Shah, Basil Abraham, Vikas Joshi,\n  Sunayana Sitaram", "title": "Learning not to Discriminate: Task Agnostic Learning for Improving\n  Monolingual and Code-switched Speech Recognition", "comments": "5 pages (4 pages + 1 reference), 3 tables, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing code-switched speech is challenging for Automatic Speech\nRecognition (ASR) for a variety of reasons, including the lack of code-switched\ntraining data. Recently, we showed that monolingual ASR systems fine-tuned on\ncode-switched data deteriorate in performance on monolingual speech\nrecognition, which is not desirable as ASR systems deployed in multilingual\nscenarios should recognize both monolingual and code-switched speech with high\naccuracy. Our experiments indicated that this loss in performance could be\nmitigated by using certain strategies for fine-tuning and regularization,\nleading to improvements in both monolingual and code-switched ASR. In this\nwork, we present further improvements over our previous work by using domain\nadversarial learning to train task agnostic models. We evaluate the\nclassification accuracy of an adversarial discriminator and show that it can\nlearn shared layer parameters that are task agnostic. We train end-to-end ASR\nsystems starting with a pooled model that uses monolingual and code-switched\ndata along with the adversarial discriminator. Our proposed technique leads to\nreductions in Word Error Rates (WER) in monolingual and code-switched test sets\nacross three language pairs.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 13:45:30 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Madhumani", "Gurunath Reddy", ""], ["Shah", "Sanket", ""], ["Abraham", "Basil", ""], ["Joshi", "Vikas", ""], ["Sitaram", "Sunayana", ""]]}, {"id": "2006.05281", "submitter": "Isar Nejadgholi", "authors": "Isar Nejadgholi, Kathleen C. Fraser and Berry De Bruijn", "title": "Extensive Error Analysis and a Learning-Based Evaluation of Medical\n  Entity Recognition Systems to Approximate User Experience", "comments": "to appear at BioNLP2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When comparing entities extracted by a medical entity recognition system with\ngold standard annotations over a test set, two types of mismatches might occur,\nlabel mismatch or span mismatch. Here we focus on span mismatch and show that\nits severity can vary from a serious error to a fully acceptable entity\nextraction due to the subjectivity of span annotations. For a domain-specific\nBERT-based NER system, we showed that 25% of the errors have the same labels\nand overlapping span with gold standard entities. We collected expert judgement\nwhich shows more than 90% of these mismatches are accepted or partially\naccepted by the user. Using the training set of the NER system, we built a fast\nand lightweight entity classifier to approximate the user experience of such\nmismatches through accepting or rejecting them. The decisions made by this\nclassifier are used to calculate a learning-based F-score which is shown to be\na better approximation of a forgiving user's experience than the relaxed\nF-score. We demonstrated the results of applying the proposed evaluation metric\nfor a variety of deep learning medical entity recognition models trained with\ntwo datasets.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 14:15:33 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Nejadgholi", "Isar", ""], ["Fraser", "Kathleen C.", ""], ["De Bruijn", "Berry", ""]]}, {"id": "2006.05354", "submitter": "Vladislav Tretyak", "authors": "Vladislav Tretyak, Denis Stepanov", "title": "Combination of abstractive and extractive approaches for summarization\n  of long scientific texts", "comments": "11 pages, 2 figures, 3 table, submitted to 23rd International\n  Conference on Discovery Science. Fixed authors list", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this research work, we present a method to generate summaries of long\nscientific documents that uses the advantages of both extractive and\nabstractive approaches. Before producing a summary in an abstractive manner, we\nperform the extractive step, which then is used for conditioning the abstractor\nmodule. We used pre-trained transformer-based language models, for both\nextractor and abstractor. Our experiments showed that using extractive and\nabstractive models jointly significantly improves summarization results and\nROUGE scores.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 15:38:21 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 11:25:21 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Tretyak", "Vladislav", ""], ["Stepanov", "Denis", ""]]}, {"id": "2006.05365", "submitter": "Rachid Riad", "authors": "Rachid Riad and Hadrien Titeux and Laurie Lemoine and Justine\n  Montillot and Jennifer Hamet Bagnou and Xuan Nga Cao and Emmanuel Dupoux and\n  Anne-Catherine Bachoud-L\\'evi", "title": "Vocal markers from sustained phonation in Huntington's Disease", "comments": "To appear at INTERSPEECH 2020. 1 pages of supplementary material\n  appear only in the arxiv version. Code to replicate\n  https://github.com/bootphon/sustained-phonation-features", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Disease-modifying treatments are currently assessed in neurodegenerative\ndiseases. Huntington's Disease represents a unique opportunity to design\nautomatic sub-clinical markers, even in premanifest gene carriers. We\ninvestigated phonatory impairments as potential clinical markers and propose\nthem for both diagnosis and gene carriers follow-up. We used two sets of\nfeatures: Phonatory features and Modulation Power Spectrum Features. We found\nthat phonation is not sufficient for the identification of sub-clinical\ndisorders of premanifest gene carriers. According to our regression results,\nPhonatory features are suitable for the predictions of clinical performance in\nHuntington's Disease.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 15:51:28 GMT"}, {"version": "v2", "created": "Sun, 26 Jul 2020 07:29:55 GMT"}, {"version": "v3", "created": "Fri, 31 Jul 2020 13:20:04 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Riad", "Rachid", ""], ["Titeux", "Hadrien", ""], ["Lemoine", "Laurie", ""], ["Montillot", "Justine", ""], ["Bagnou", "Jennifer Hamet", ""], ["Cao", "Xuan Nga", ""], ["Dupoux", "Emmanuel", ""], ["Bachoud-L\u00e9vi", "Anne-Catherine", ""]]}, {"id": "2006.05456", "submitter": "Aishwarya Padmakumar", "authors": "Aishwarya Padmakumar and Raymond J. Mooney", "title": "Dialog Policy Learning for Joint Clarification and Active Learning\n  Queries", "comments": "AAAI 2020 Camera Ready", "journal-ref": "Proceedings of 2021 AAAI Conference on Artificial Intelligence\n  (AAAI-2021)", "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Intelligent systems need to be able to recover from mistakes, resolve\nuncertainty, and adapt to novel concepts not seen during training. Dialog\ninteraction can enable this by the use of clarifications for correction and\nresolving uncertainty, and active learning queries to learn new concepts\nencountered during operation. Prior work on dialog systems has either focused\non exclusively learning how to perform clarification/ information seeking, or\nto perform active learning. In this work, we train a hierarchical dialog policy\nto jointly perform both clarification and active learning in the context of an\ninteractive language-based image retrieval task motivated by an online shopping\napplication, and demonstrate that jointly learning dialog policies for\nclarification and active learning is more effective than the use of static\ndialog policies for one or both of these functions.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 18:53:21 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 18:03:22 GMT"}, {"version": "v3", "created": "Mon, 14 Dec 2020 03:31:36 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Padmakumar", "Aishwarya", ""], ["Mooney", "Raymond J.", ""]]}, {"id": "2006.05469", "submitter": "Liqun Shao", "authors": "Liqun Shao, Sahitya Mantravadi, Tom Manzini, Alejandro Buendia, Manon\n  Knoertzer, Soundar Srinivasan, and Chris Quirk", "title": "Examination and Extension of Strategies for Improving Personalized\n  Language Modeling via Interpolation", "comments": "ACL Natural Language Interface Workshop 2020, short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we detail novel strategies for interpolating personalized\nlanguage models and methods to handle out-of-vocabulary (OOV) tokens to improve\npersonalized language models. Using publicly available data from Reddit, we\ndemonstrate improvements in offline metrics at the user level by interpolating\na global LSTM-based authoring model with a user-personalized n-gram model. By\noptimizing this approach with a back-off to uniform OOV penalty and the\ninterpolation coefficient, we observe that over 80% of users receive a lift in\nperplexity, with an average of 5.2% in perplexity lift per user. In doing this\nresearch we extend previous work in building NLIs and improve the robustness of\nmetrics for downstream tasks.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 19:29:41 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Shao", "Liqun", ""], ["Mantravadi", "Sahitya", ""], ["Manzini", "Tom", ""], ["Buendia", "Alejandro", ""], ["Knoertzer", "Manon", ""], ["Srinivasan", "Soundar", ""], ["Quirk", "Chris", ""]]}, {"id": "2006.05474", "submitter": "Changhan Wang", "authors": "Changhan Wang, Juan Pino, Jiatao Gu", "title": "Improving Cross-Lingual Transfer Learning for End-to-End Speech\n  Recognition with Speech Translation", "comments": "Accepted to INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning from high-resource languages is known to be an efficient\nway to improve end-to-end automatic speech recognition (ASR) for low-resource\nlanguages. Pre-trained or jointly trained encoder-decoder models, however, do\nnot share the language modeling (decoder) for the same language, which is\nlikely to be inefficient for distant target languages. We introduce\nspeech-to-text translation (ST) as an auxiliary task to incorporate additional\nknowledge of the target language and enable transferring from that target\nlanguage. Specifically, we first translate high-resource ASR transcripts into a\ntarget low-resource language, with which a ST model is trained. Both ST and\ntarget ASR share the same attention-based encoder-decoder architecture and\nvocabulary. The former task then provides a fully pre-trained model for the\nlatter, bringing up to 24.6% word error rate (WER) reduction to the baseline\n(direct transfer from high-resource ASR). We show that training ST with human\ntranslations is not necessary. ST trained with machine translation (MT)\npseudo-labels brings consistent gains. It can even outperform those using human\nlabels when transferred to target ASR by leveraging only 500K MT examples. Even\nwith pseudo-labels from low-resource MT (200K examples), ST-enhanced transfer\nbrings up to 8.9% WER reduction to direct transfer.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 19:34:11 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 04:07:38 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Wang", "Changhan", ""], ["Pino", "Juan", ""], ["Gu", "Jiatao", ""]]}, {"id": "2006.05477", "submitter": "Chaitra Vishwanatha Hegde", "authors": "Chaitra Hegde, Shrikumar Patil", "title": "Unsupervised Paraphrase Generation using Pre-trained Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large scale Pre-trained Language Models have proven to be very powerful\napproach in various Natural language tasks. OpenAI's GPT-2\n\\cite{radford2019language} is notable for its capability to generate fluent,\nwell formulated, grammatically consistent text and for phrase completions. In\nthis paper we leverage this generation capability of GPT-2 to generate\nparaphrases without any supervision from labelled data. We examine how the\nresults compare with other supervised and unsupervised approaches and the\neffect of using paraphrases for data augmentation on downstream tasks such as\nclassification. Our experiments show that paraphrases generated with our model\nare of good quality, are diverse and improves the downstream task performance\nwhen used for data augmentation.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 19:40:19 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Hegde", "Chaitra", ""], ["Patil", "Shrikumar", ""]]}, {"id": "2006.05489", "submitter": "Radhika Gaonkar", "authors": "Radhika Gaonkar, Heeyoung Kwon, Mohaddeseh Bastan, Niranjan\n  Balasubramanian, Nathanael Chambers", "title": "Modeling Label Semantics for Predicting Emotional Reactions", "comments": "6 pages, 2 figures, published in Proceedings of the 58th Annual\n  Meeting of the Association for Computational Linguistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting how events induce emotions in the characters of a story is\ntypically seen as a standard multi-label classification task, which usually\ntreats labels as anonymous classes to predict. They ignore information that may\nbe conveyed by the emotion labels themselves. We propose that the semantics of\nemotion labels can guide a model's attention when representing the input story.\nFurther, we observe that the emotions evoked by an event are often related: an\nevent that evokes joy is unlikely to also evoke sadness. In this work, we\nexplicitly model label classes via label embeddings, and add mechanisms that\ntrack label-label correlations both during training and inference. We also\nintroduce a new semi-supervision strategy that regularizes for the correlations\non unlabeled data. Our empirical evaluations show that modeling label semantics\nyields consistent benefits, and we advance the state-of-the-art on an emotion\ninference task.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 20:04:02 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 23:47:04 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Gaonkar", "Radhika", ""], ["Kwon", "Heeyoung", ""], ["Bastan", "Mohaddeseh", ""], ["Balasubramanian", "Niranjan", ""], ["Chambers", "Nathanael", ""]]}, {"id": "2006.05493", "submitter": "Adewale Akinfaderin", "authors": "Oyinlola Babafemi and Adewale Akinfaderin", "title": "Predicting and Analyzing Law-Making in Kenya", "comments": "Accepted at 4th Widening NLP Workshop, Annual Meeting of the\n  Association for Computational Linguistics, ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modelling and analyzing parliamentary legislation, roll-call votes and order\nof proceedings in developed countries has received significant attention in\nrecent years. In this paper, we focused on understanding the bills introduced\nin a developing democracy, the Kenyan bicameral parliament. We developed and\ntrained machine learning models on a combination of features extracted from the\nbills to predict the outcome - if a bill will be enacted or not. We observed\nthat the texts in a bill are not as relevant as the year and month the bill was\nintroduced and the category the bill belongs to.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 20:21:50 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Babafemi", "Oyinlola", ""], ["Akinfaderin", "Adewale", ""]]}, {"id": "2006.05561", "submitter": "Gabriele Bettgenh\\\"auser", "authors": "Gabriele Bettgenh\\\"auser, Michael A. Hedderich, Dietrich Klakow", "title": "Learning Functions to Study the Benefit of Multitask Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study and quantify the generalization patterns of multitask learning (MTL)\nmodels for sequence labeling tasks. MTL models are trained to optimize a set of\nrelated tasks jointly. Although multitask learning has achieved improved\nperformance in some problems, there are also tasks that lose performance when\ntrained together. These mixed results motivate us to study the factors that\nimpact the performance of MTL models. We note that theoretical bounds and\nconvergence rates for MTL models exist, but they rely on strong assumptions\nsuch as task relatedness and the use of balanced datasets. To remedy these\nlimitations, we propose the creation of a task simulator and the use of\nSymbolic Regression to learn expressions relating model performance to possible\nfactors of influence. For MTL, we study the model performance against the\nnumber of tasks (T), the number of samples per task (n) and the task\nrelatedness measured by the adjusted mutual information (AMI). In our\nexperiments, we could empirically find formulas relating model performance with\nfactors of sqrt(n), sqrt(T), which are equivalent to sound mathematical proofs\nin Maurer[2016], and we went beyond by discovering that performance relates to\na factor of sqrt(AMI).\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 23:51:32 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 06:19:12 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Bettgenh\u00e4user", "Gabriele", ""], ["Hedderich", "Michael A.", ""], ["Klakow", "Dietrich", ""]]}, {"id": "2006.05602", "submitter": "Yong Dai", "authors": "Yong Dai, Jian Liu, Xiancong Ren, Zenglin Xu", "title": "Adversarial Training Based Multi-Source Unsupervised Domain Adaptation\n  for Sentiment Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-source unsupervised domain adaptation (MS-UDA) for sentiment analysis\n(SA) aims to leverage useful information in multiple source domains to help do\nSA in an unlabeled target domain that has no supervised information. Existing\nalgorithms of MS-UDA either only exploit the shared features, i.e., the\ndomain-invariant information, or based on some weak assumption in NLP, e.g.,\nsmoothness assumption. To avoid these problems, we propose two transfer\nlearning frameworks based on the multi-source domain adaptation methodology for\nSA by combining the source hypotheses to derive a good target hypothesis. The\nkey feature of the first framework is a novel Weighting Scheme based\nUnsupervised Domain Adaptation framework (WS-UDA), which combine the source\nclassifiers to acquire pseudo labels for target instances directly. While the\nsecond framework is a Two-Stage Training based Unsupervised Domain Adaptation\nframework (2ST-UDA), which further exploits these pseudo labels to train a\ntarget private extractor. Importantly, the weights assigned to each source\nclassifier are based on the relations between target instances and source\ndomains, which measured by a discriminator through the adversarial training.\nFurthermore, through the same discriminator, we also fulfill the separation of\nshared features and private features. Experimental results on two SA datasets\ndemonstrate the promising performance of our frameworks, which outperforms\nunsupervised state-of-the-art competitors.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 01:41:00 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Dai", "Yong", ""], ["Liu", "Jian", ""], ["Ren", "Xiancong", ""], ["Xu", "Zenglin", ""]]}, {"id": "2006.05621", "submitter": "Logan Lebanoff", "authors": "Logan Lebanoff, John Muchovej, Franck Dernoncourt, Doo Soon Kim, Lidan\n  Wang, Walter Chang, Fei Liu", "title": "Understanding Points of Correspondence between Sentences for Abstractive\n  Summarization", "comments": "Camera-ready version for ACL 2020 Student Research Workshop (SRW)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fusing sentences containing disparate content is a remarkable human ability\nthat helps create informative and succinct summaries. Such a simple task for\nhumans has remained challenging for modern abstractive summarizers,\nsubstantially restricting their applicability in real-world scenarios. In this\npaper, we present an investigation into fusing sentences drawn from a document\nby introducing the notion of points of correspondence, which are cohesive\ndevices that tie any two sentences together into a coherent text. The types of\npoints of correspondence are delineated by text cohesion theory, covering\npronominal and nominal referencing, repetition and beyond. We create a dataset\ncontaining the documents, source and fusion sentences, and human annotations of\npoints of correspondence between sentences. Our dataset bridges the gap between\ncoreference resolution and summarization. It is publicly shared to serve as a\nbasis for future work to measure the success of sentence fusion systems.\n(https://github.com/ucfnlp/points-of-correspondence)\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 02:42:38 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Lebanoff", "Logan", ""], ["Muchovej", "John", ""], ["Dernoncourt", "Franck", ""], ["Kim", "Doo Soon", ""], ["Wang", "Lidan", ""], ["Chang", "Walter", ""], ["Liu", "Fei", ""]]}, {"id": "2006.05635", "submitter": "Longshaokan Wang", "authors": "Longshaokan Wang, Maryam Fazel-Zarandi, Aditya Tiwari, Spyros\n  Matsoukas, Lazaros Polymenakos", "title": "Data Augmentation for Training Dialog Models Robust to Speech\n  Recognition Errors", "comments": "To be presented at 2nd Workshop on NLP for ConvAI, ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech-based virtual assistants, such as Amazon Alexa, Google assistant, and\nApple Siri, typically convert users' audio signals to text data through\nautomatic speech recognition (ASR) and feed the text to downstream dialog\nmodels for natural language understanding and response generation. The ASR\noutput is error-prone; however, the downstream dialog models are often trained\non error-free text data, making them sensitive to ASR errors during inference\ntime. To bridge the gap and make dialog models more robust to ASR errors, we\nleverage an ASR error simulator to inject noise into the error-free text data,\nand subsequently train the dialog models with the augmented data. Compared to\nother approaches for handling ASR errors, such as using ASR lattice or\nend-to-end methods, our data augmentation approach does not require any\nmodification to the ASR or downstream dialog models; our approach also does not\nintroduce any additional latency during inference time. We perform extensive\nexperiments on benchmark data and show that our approach improves the\nperformance of downstream dialog models in the presence of ASR errors, and it\nis particularly effective in the low-resource situations where there are\nconstraints on model size or the training data is scarce.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 03:18:15 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Wang", "Longshaokan", ""], ["Fazel-Zarandi", "Maryam", ""], ["Tiwari", "Aditya", ""], ["Matsoukas", "Spyros", ""], ["Polymenakos", "Lazaros", ""]]}, {"id": "2006.05676", "submitter": "Andy Wagner", "authors": "Andy Wagner, Tiyasa Mitra, Mrinal Iyer, Godfrey Da Costa, Marc\n  Tremblay", "title": "Position Masking for Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Masked language modeling (MLM) pre-training models such as BERT corrupt the\ninput by replacing some tokens with [MASK] and then train a model to\nreconstruct the original tokens. This is an effective technique which has led\nto good results on all NLP benchmarks. We propose to expand upon this idea by\nmasking the positions of some tokens along with the masked input token ids. We\nfollow the same standard approach as BERT masking a percentage of the tokens\npositions and then predicting their original values using an additional fully\nconnected classifier stage. This approach has shown good performance gains\n(.3\\% improvement) for the SQUAD additional improvement in convergence times.\nFor the Graphcore IPU the convergence of BERT Base with position masking\nrequires only 50\\% of the tokens from the original BERT paper.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 23:40:41 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Wagner", "Andy", ""], ["Mitra", "Tiyasa", ""], ["Iyer", "Mrinal", ""], ["Da Costa", "Godfrey", ""], ["Tremblay", "Marc", ""]]}, {"id": "2006.05702", "submitter": "Yutai Hou", "authors": "Yutai Hou, Wanxiang Che, Yongkui Lai, Zhihan Zhou, Yijia Liu, Han Liu,\n  Ting Liu", "title": "Few-shot Slot Tagging with Collapsed Dependency Transfer and\n  Label-enhanced Task-adaptive Projection Network", "comments": "Accepted by ACL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore the slot tagging with only a few labeled support\nsentences (a.k.a. few-shot). Few-shot slot tagging faces a unique challenge\ncompared to the other few-shot classification problems as it calls for modeling\nthe dependencies between labels. But it is hard to apply previously learned\nlabel dependencies to an unseen domain, due to the discrepancy of label sets.\nTo tackle this, we introduce a collapsed dependency transfer mechanism into the\nconditional random field (CRF) to transfer abstract label dependency patterns\nas transition scores. In the few-shot setting, the emission score of CRF can be\ncalculated as a word's similarity to the representation of each label. To\ncalculate such similarity, we propose a Label-enhanced Task-Adaptive Projection\nNetwork (L-TapNet) based on the state-of-the-art few-shot classification model\n-- TapNet, by leveraging label name semantics in representing labels.\nExperimental results show that our model significantly outperforms the\nstrongest few-shot learning baseline by 14.64 F1 scores in the one-shot\nsetting.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 07:50:44 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Hou", "Yutai", ""], ["Che", "Wanxiang", ""], ["Lai", "Yongkui", ""], ["Zhou", "Zhihan", ""], ["Liu", "Yijia", ""], ["Liu", "Han", ""], ["Liu", "Ting", ""]]}, {"id": "2006.05726", "submitter": "Corentin Kervadec", "authors": "Corentin Kervadec (imagine), Grigory Antipov, Moez Baccouche,\n  Christian Wolf (imagine)", "title": "Estimating semantic structure for the VQA answer space", "comments": "[WARNING] We want to notice the reader that additional experiments\n  (not in the paper) have shown that using a `random' semantic space performs\n  as much as the proposed semantic loss. This additional result question the\n  effectiveness of our method", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since its appearance, Visual Question Answering (VQA, i.e. answering a\nquestion posed over an image), has always been treated as a classification\nproblem over a set of predefined answers. Despite its convenience, this\nclassification approach poorly reflects the semantics of the problem limiting\nthe answering to a choice between independent proposals, without taking into\naccount the similarity between them (e.g. equally penalizing for answering cat\nor German shepherd instead of dog). We address this issue by proposing (1) two\nmeasures of proximity between VQA classes, and (2) a corresponding loss which\ntakes into account the estimated proximity. This significantly improves the\ngeneralization of VQA models by reducing their language bias. In particular, we\nshow that our approach is completely model-agnostic since it allows consistent\nimprovements with three different VQA models. Finally, by combining our method\nwith a language bias reduction approach, we report SOTA-level performance on\nthe challenging VQAv2-CP dataset.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 08:32:56 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 10:33:21 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Kervadec", "Corentin", "", "imagine"], ["Antipov", "Grigory", "", "imagine"], ["Baccouche", "Moez", "", "imagine"], ["Wolf", "Christian", "", "imagine"]]}, {"id": "2006.05744", "submitter": "Linyuan Gong", "authors": "Zhenhui Xu, Linyuan Gong, Guolin Ke, Di He, Shuxin Zheng, Liwei Wang,\n  Jiang Bian, Tie-Yan Liu", "title": "MC-BERT: Efficient Language Pre-Training via a Meta Controller", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained contextual representations (e.g., BERT) have become the\nfoundation to achieve state-of-the-art results on many NLP tasks. However,\nlarge-scale pre-training is computationally expensive. ELECTRA, an early\nattempt to accelerate pre-training, trains a discriminative model that predicts\nwhether each input token was replaced by a generator. Our studies reveal that\nELECTRA's success is mainly due to its reduced complexity of the pre-training\ntask: the binary classification (replaced token detection) is more efficient to\nlearn than the generation task (masked language modeling). However, such a\nsimplified task is less semantically informative. To achieve better efficiency\nand effectiveness, we propose a novel meta-learning framework, MC-BERT. The\npre-training task is a multi-choice cloze test with a reject option, where a\nmeta controller network provides training input and candidates. Results over\nGLUE natural language understanding benchmark demonstrate that our proposed\nmethod is both efficient and effective: it outperforms baselines on GLUE\nsemantic tasks given the same computational budget.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 09:22:19 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 09:15:08 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Xu", "Zhenhui", ""], ["Gong", "Linyuan", ""], ["Ke", "Guolin", ""], ["He", "Di", ""], ["Zheng", "Shuxin", ""], ["Wang", "Liwei", ""], ["Bian", "Jiang", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2006.05754", "submitter": "Mattia Antonino Di Gangi", "authors": "Luisa Bentivogli and Beatrice Savoldi and Matteo Negri and Mattia\n  Antonino Di Gangi and Roldano Cattoni and Marco Turchi", "title": "Gender in Danger? Evaluating Speech Translation Technology on the\n  MuST-SHE Corpus", "comments": "9 pages of content, accepted at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Translating from languages without productive grammatical gender like English\ninto gender-marked languages is a well-known difficulty for machines. This\ndifficulty is also due to the fact that the training data on which models are\nbuilt typically reflect the asymmetries of natural languages, gender bias\nincluded. Exclusively fed with textual data, machine translation is\nintrinsically constrained by the fact that the input sentence does not always\ncontain clues about the gender identity of the referred human entities. But\nwhat happens with speech translation, where the input is an audio signal? Can\naudio provide additional information to reduce gender bias? We present the\nfirst thorough investigation of gender bias in speech translation, contributing\nwith: i) the release of a benchmark useful for future studies, and ii) the\ncomparison of different technologies (cascade and end-to-end) on two language\ndirections (English-Italian/French).\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 09:55:38 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Bentivogli", "Luisa", ""], ["Savoldi", "Beatrice", ""], ["Negri", "Matteo", ""], ["Di Gangi", "Mattia Antonino", ""], ["Cattoni", "Roldano", ""], ["Turchi", "Marco", ""]]}, {"id": "2006.05908", "submitter": "Hansi Hettiarachchi", "authors": "Hansi Hettiarachchi, Mariam Adedoyin-Olowe, Jagdev Bhogal and Mohamed\n  Medhat Gaber", "title": "Embed2Detect: Temporally Clustered Embedded Words for Event Detection in\n  Social Media", "comments": "This is a preprint of an article published in the Journal of Machine\n  Learning, Springer. The final authenticated version is available online at:\n  https://doi.org/10.1007/s10994-021-05988-7", "journal-ref": null, "doi": "10.1007/s10994-021-05988-7", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media is becoming a primary medium to discuss what is happening around\nthe world. Therefore, the data generated by social media platforms contain rich\ninformation which describes the ongoing events. Further, the timeliness\nassociated with these data is capable of facilitating immediate insights.\nHowever, considering the dynamic nature and high volume of data production in\nsocial media data streams, it is impractical to filter the events manually and\ntherefore, automated event detection mechanisms are invaluable to the\ncommunity. Apart from a few notable exceptions, most previous research on\nautomated event detection have focused only on statistical and syntactical\nfeatures in data and lacked the involvement of underlying semantics which are\nimportant for effective information retrieval from text since they represent\nthe connections between words and their meanings. In this paper, we propose a\nnovel method termed Embed2Detect for event detection in social media by\ncombining the characteristics in word embeddings and hierarchical agglomerative\nclustering. The adoption of word embeddings gives Embed2Detect the capability\nto incorporate powerful semantical features into event detection and overcome a\nmajor limitation inherent in previous approaches. We experimented our method on\ntwo recent real social media data sets which represent the sports and political\ndomain and also compared the results to several state-of-the-art methods. The\nobtained results show that Embed2Detect is capable of effective and efficient\nevent detection and it outperforms the recent event detection methods. For the\nsports data set, Embed2Detect achieved 27% higher F-measure than the\nbest-performed baseline and for the political data set, it was an increase of\n29%.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 15:52:52 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 08:47:29 GMT"}, {"version": "v3", "created": "Tue, 29 Sep 2020 13:48:35 GMT"}, {"version": "v4", "created": "Tue, 25 May 2021 21:49:41 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Hettiarachchi", "Hansi", ""], ["Adedoyin-Olowe", "Mariam", ""], ["Bhogal", "Jagdev", ""], ["Gaber", "Mohamed Medhat", ""]]}, {"id": "2006.05986", "submitter": "Vaibhav Kumar", "authors": "Vaibhav Kumar and Alan W. black", "title": "ClarQ: A large-scale and diverse dataset for Clarification Question\n  Generation", "comments": "Accepted at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question answering and conversational systems are often baffled and need help\nclarifying certain ambiguities. However, limitations of existing datasets\nhinder the development of large-scale models capable of generating and\nutilising clarification questions. In order to overcome these limitations, we\ndevise a novel bootstrapping framework (based on self-supervision) that assists\nin the creation of a diverse, large-scale dataset of clarification questions\nbased on post-comment tuples extracted from stackexchange. The framework\nutilises a neural network based architecture for classifying clarification\nquestions. It is a two-step method where the first aims to increase the\nprecision of the classifier and second aims to increase its recall. We\nquantitatively demonstrate the utility of the newly created dataset by applying\nit to the downstream task of question-answering. The final dataset, ClarQ,\nconsists of ~2M examples distributed across 173 domains of stackexchange. We\nrelease this dataset in order to foster research into the field of\nclarification question generation with the larger goal of enhancing dialog and\nquestion answering systems.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 17:56:50 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 17:18:39 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Kumar", "Vaibhav", ""], ["black", "Alan W.", ""]]}, {"id": "2006.05987", "submitter": "Felix Wu", "authors": "Tianyi Zhang, Felix Wu, Arzoo Katiyar, Kilian Q. Weinberger, Yoav\n  Artzi", "title": "Revisiting Few-sample BERT Fine-tuning", "comments": "Code available at\n  https://github.com/asappresearch/revisit-bert-finetuning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is a study of fine-tuning of BERT contextual representations, with\nfocus on commonly observed instabilities in few-sample scenarios. We identify\nseveral factors that cause this instability: the common use of a non-standard\noptimization method with biased gradient estimation; the limited applicability\nof significant parts of the BERT network for down-stream tasks; and the\nprevalent practice of using a pre-determined, and small number of training\niterations. We empirically test the impact of these factors, and identify\nalternative practices that resolve the commonly observed instability of the\nprocess. In light of these observations, we re-visit recently proposed methods\nto improve few-sample fine-tuning with BERT and re-evaluate their\neffectiveness. Generally, we observe the impact of these methods diminishes\nsignificantly with our modified process.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 17:57:03 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 17:59:03 GMT"}, {"version": "v3", "created": "Thu, 11 Mar 2021 17:22:50 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Zhang", "Tianyi", ""], ["Wu", "Felix", ""], ["Katiyar", "Arzoo", ""], ["Weinberger", "Kilian Q.", ""], ["Artzi", "Yoav", ""]]}, {"id": "2006.06026", "submitter": "Tiancheng Zhao", "authors": "Maxine Eskenazi, Tiancheng Zhao", "title": "Report from the NSF Future Directions Workshop, Toward User-Oriented\n  Agents: Research Directions and Challenges", "comments": "Final report of the NSF Future Directions Workshop, Toward\n  User-Oriented Agents: Research Directions and Challenges", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This USER Workshop was convened with the goal of defining future research\ndirections for the burgeoning intelligent agent research community and to\ncommunicate them to the National Science Foundation. It took place in\nPittsburgh Pennsylvania on October 24 and 25, 2019 and was sponsored by\nNational Science Foundation Grant Number IIS-1934222. Any opinions, findings\nand conclusions or future directions expressed in this document are those of\nthe authors and do not necessarily reflect the views of the National Science\nFoundation. The 27 participants presented their individual research interests\nand their personal research goals. In the breakout sessions that followed, the\nparticipants defined the main research areas within the domain of intelligent\nagents and they discussed the major future directions that the research in each\narea of this domain should take\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 18:32:35 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Eskenazi", "Maxine", ""], ["Zhao", "Tiancheng", ""]]}, {"id": "2006.06105", "submitter": "Jon Saad-Falcon", "authors": "Jon Saad-Falcon, Omar Shaikh, Zijie J. Wang, Austin P. Wright, Sasha\n  Richardson, Duen Horng Chau", "title": "PeopleMap: Visualization Tool for Mapping Out Researchers using Natural\n  Language Processing", "comments": "7 pages, 3 figures, submission to the 29th ACM International\n  Conference on Information and Knowledge Management (CIKM '20), October 19-23,\n  2020, Galway, Ireland", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering research expertise at institutions can be a difficult task.\nManually curated university directories easily become out of date and they\noften lack the information necessary for understanding a researcher's interests\nand past work, making it harder to explore the diversity of research at an\ninstitution and identify research talents. This results in lost opportunities\nfor both internal and external entities to discover new connections and nurture\nresearch collaboration. To solve this problem, we have developed PeopleMap, the\nfirst interactive, open-source, web-based tool that visually \"maps out\"\nresearchers based on their research interests and publications by leveraging\nembeddings generated by natural language processing (NLP) techniques. PeopleMap\nprovides a new engaging way for institutions to summarize their research\ntalents and for people to discover new connections. The platform is developed\nwith ease-of-use and sustainability in mind. Using only researchers' Google\nScholar profiles as input, PeopleMap can be readily adopted by any institution\nusing its publicly-accessible repository and detailed documentation.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 23:06:25 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Saad-Falcon", "Jon", ""], ["Shaikh", "Omar", ""], ["Wang", "Zijie J.", ""], ["Wright", "Austin P.", ""], ["Richardson", "Sasha", ""], ["Chau", "Duen Horng", ""]]}, {"id": "2006.06110", "submitter": "Sarah Finch", "authors": "Sarah E. Finch and Jinho D. Choi", "title": "Towards Unified Dialogue System Evaluation: A Comprehensive Analysis of\n  Current Evaluation Protocols", "comments": "Accepted by SIGDIAL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As conversational AI-based dialogue management has increasingly become a\ntrending topic, the need for a standardized and reliable evaluation procedure\ngrows even more pressing. The current state of affairs suggests various\nevaluation protocols to assess chat-oriented dialogue management systems,\nrendering it difficult to conduct fair comparative studies across different\napproaches and gain an insightful understanding of their values. To foster this\nresearch, a more robust evaluation protocol must be set in place. This paper\npresents a comprehensive synthesis of both automated and human evaluation\nmethods on dialogue systems, identifying their shortcomings while accumulating\nevidence towards the most effective evaluation dimensions. A total of 20 papers\nfrom the last two years are surveyed to analyze three types of evaluation\nprotocols: automated, static, and interactive. Finally, the evaluation\ndimensions used in these papers are compared against our expert evaluation on\nthe system-user dialogue data collected from the Alexa Prize 2020.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 23:29:05 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Finch", "Sarah E.", ""], ["Choi", "Jinho D.", ""]]}, {"id": "2006.06114", "submitter": "Filip Ilievski", "authors": "Filip Ilievski, Pedro Szekely, Jingwei Cheng, Fu Zhang, Ehsan Qasemi", "title": "Consolidating Commonsense Knowledge", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Commonsense reasoning is an important aspect of building robust AI systems\nand is receiving significant attention in the natural language understanding,\ncomputer vision, and knowledge graphs communities. At present, a number of\nvaluable commonsense knowledge sources exist, with different foci, strengths,\nand weaknesses. In this paper, we list representative sources and their\nproperties. Based on this survey, we propose principles and a representation\nmodel in order to consolidate them into a Common Sense Knowledge Graph (CSKG).\nWe apply this approach to consolidate seven separate sources into a first\nintegrated CSKG. We present statistics of CSKG, present initial investigations\nof its utility on four QA datasets, and list learned lessons.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 23:40:11 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 19:38:59 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Ilievski", "Filip", ""], ["Szekely", "Pedro", ""], ["Cheng", "Jingwei", ""], ["Zhang", "Fu", ""], ["Qasemi", "Ehsan", ""]]}, {"id": "2006.06143", "submitter": "James D. Finch", "authors": "James D. Finch and Jinho D. Choi", "title": "Emora STDM: A Versatile Framework for Innovative Dialogue System\n  Development", "comments": "Accepted by SIGDIAL 2020: System Demonstrations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This demo paper presents Emora STDM (State Transition Dialogue Manager), a\ndialogue system development framework that provides novel workflows for rapid\nprototyping of chat-based dialogue managers as well as collaborative\ndevelopment of complex interactions. Our framework caters to a wide range of\nexpertise levels by supporting interoperability between two popular approaches,\nstate machine and information state, to dialogue management. Our Natural\nLanguage Expression package allows seamless integration of pattern matching,\ncustom NLP modules, and database querying, that makes the workflows much more\nefficient. As a user study, we adopt this framework to an interdisciplinary\nundergraduate course where students with both technical and non-technical\nbackgrounds are able to develop creative dialogue managers in a short period of\ntime.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 01:31:17 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Finch", "James D.", ""], ["Choi", "Jinho D.", ""]]}, {"id": "2006.06195", "submitter": "Zhe Gan", "authors": "Zhe Gan, Yen-Chun Chen, Linjie Li, Chen Zhu, Yu Cheng, Jingjing Liu", "title": "Large-Scale Adversarial Training for Vision-and-Language Representation\n  Learning", "comments": "NeurIPS 2020 Spotlight paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present VILLA, the first known effort on large-scale adversarial training\nfor vision-and-language (V+L) representation learning. VILLA consists of two\ntraining stages: (i) task-agnostic adversarial pre-training; followed by (ii)\ntask-specific adversarial finetuning. Instead of adding adversarial\nperturbations on image pixels and textual tokens, we propose to perform\nadversarial training in the embedding space of each modality. To enable\nlarge-scale training, we adopt the \"free\" adversarial training strategy, and\ncombine it with KL-divergence-based regularization to promote higher invariance\nin the embedding space. We apply VILLA to current best-performing V+L models,\nand achieve new state of the art on a wide range of tasks, including Visual\nQuestion Answering, Visual Commonsense Reasoning, Image-Text Retrieval,\nReferring Expression Comprehension, Visual Entailment, and NLVR2.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 05:14:35 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 18:12:53 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Gan", "Zhe", ""], ["Chen", "Yen-Chun", ""], ["Li", "Linjie", ""], ["Zhu", "Chen", ""], ["Cheng", "Yu", ""], ["Liu", "Jingjing", ""]]}, {"id": "2006.06202", "submitter": "Pedro Ortiz Suarez", "authors": "Pedro Javier Ortiz Su\\'arez (ALMAnaCH, SU), Laurent Romary (ALMAnaCH),\n  Beno\\^it Sagot (ALMAnaCH)", "title": "A Monolingual Approach to Contextualized Word Embeddings for\n  Mid-Resource Languages", "comments": null, "journal-ref": "Proceedings of the 58th Annual Meeting of the Association for\n  Computational Linguistics, July 2020, Online", "doi": "10.18653/v1/2020.acl-main.156", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use the multilingual OSCAR corpus, extracted from Common Crawl via\nlanguage classification, filtering and cleaning, to train monolingual\ncontextualized word embeddings (ELMo) for five mid-resource languages. We then\ncompare the performance of OSCAR-based and Wikipedia-based ELMo embeddings for\nthese languages on the part-of-speech tagging and parsing tasks. We show that,\ndespite the noise in the Common-Crawl-based OSCAR data, embeddings trained on\nOSCAR perform much better than monolingual embeddings trained on Wikipedia.\nThey actually equal or improve the current state of the art in tagging and\nparsing for all five languages. In particular, they also improve over\nmultilingual Wikipedia-based contextual embeddings (multilingual BERT), which\nalmost always constitutes the previous state of the art, thereby showing that\nthe benefit of a larger, more diverse corpus surpasses the cross-lingual\nbenefit of multilingual embedding architectures.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 05:25:18 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 16:28:29 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Su\u00e1rez", "Pedro Javier Ortiz", "", "ALMAnaCH, SU"], ["Romary", "Laurent", "", "ALMAnaCH"], ["Sagot", "Beno\u00eet", "", "ALMAnaCH"]]}, {"id": "2006.06226", "submitter": "Shuning Jin", "authors": "Shuning Jin, Sam Wiseman, Karl Stratos, Karen Livescu", "title": "Discrete Latent Variable Representations for Low-Resource Text\n  Classification", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While much work on deep latent variable models of text uses continuous latent\nvariables, discrete latent variables are interesting because they are more\ninterpretable and typically more space efficient. We consider several\napproaches to learning discrete latent variable models for text in the case\nwhere exact marginalization over these variables is intractable. We compare the\nperformance of the learned representations as features for low-resource\ndocument and sentence classification. Our best models outperform the previous\nbest reported results with continuous representations in these low-resource\nsettings, while learning significantly more compressed representations.\nInterestingly, we find that an amortized variant of Hard EM performs\nparticularly well in the lowest-resource regimes.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 06:55:13 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Jin", "Shuning", ""], ["Wiseman", "Sam", ""], ["Stratos", "Karl", ""], ["Livescu", "Karen", ""]]}, {"id": "2006.06251", "submitter": "Rajaa El Hamdani", "authors": "Paul Boniol, George Panagopoulos, Christos Xypolopoulos, Rajaa El\n  Hamdani, David Restrepo Amariles, Michalis Vazirgiannis", "title": "Performance in the Courtroom: Automated Processing and Visualization of\n  Appeal Court Decisions in France", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence techniques are already popular and important in the\nlegal domain. We extract legal indicators from judicial judgment to decrease\nthe asymmetry of information of the legal system and the access-to-justice gap.\nWe use NLP methods to extract interesting entities/data from judgments to\nconstruct networks of lawyers and judgments. We propose metrics to rank lawyers\nbased on their experience, wins/loss ratio and their importance in the network\nof lawyers. We also perform community detection in the network of judgments and\npropose metrics to represent the difficulty of cases capitalising on\ncommunities features.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 08:22:59 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 09:17:36 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2020 19:47:27 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Boniol", "Paul", ""], ["Panagopoulos", "George", ""], ["Xypolopoulos", "Christos", ""], ["Hamdani", "Rajaa El", ""], ["Amariles", "David Restrepo", ""], ["Vazirgiannis", "Michalis", ""]]}, {"id": "2006.06259", "submitter": "Hankyol Lee", "authors": "Hankyol Lee, Youngjae Yu, Gunhee Kim", "title": "Augmenting Data for Sarcasm Detection with Unlabeled Conversation\n  Context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel data augmentation technique, CRA (Contextual Response\nAugmentation), which utilizes conversational context to generate meaningful\nsamples for training. We also mitigate the issues regarding unbalanced context\nlengths by changing the input-output format of the model such that it can deal\nwith varying context lengths effectively. Specifically, our proposed model,\ntrained with the proposed data augmentation technique, participated in the\nsarcasm detection task of FigLang2020, have won and achieves the best\nperformance in both Reddit and Twitter datasets.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 09:00:11 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Lee", "Hankyol", ""], ["Yu", "Youngjae", ""], ["Kim", "Gunhee", ""]]}, {"id": "2006.06261", "submitter": "Peiling Lu", "authors": "Peiling Lu, Jie Wu, Jian Luan, Xu Tan, Li Zhou", "title": "XiaoiceSing: A High-Quality and Integrated Singing Voice Synthesis\n  System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents XiaoiceSing, a high-quality singing voice synthesis\nsystem which employs an integrated network for spectrum, F0 and duration\nmodeling. We follow the main architecture of FastSpeech while proposing some\nsinging-specific design: 1) Besides phoneme ID and position encoding, features\nfrom musical score (e.g.note pitch and length) are also added. 2) To attenuate\noff-key issues, we add a residual connection in F0 prediction. 3) In addition\nto the duration loss of each phoneme, the duration of all the phonemes in a\nmusical note is accumulated to calculate the syllable duration loss for rhythm\nenhancement. Experiment results show that XiaoiceSing outperforms the baseline\nsystem of convolutional neural networks by 1.44 MOS on sound quality, 1.18 on\npronunciation accuracy and 1.38 on naturalness respectively. In two A/B tests,\nthe proposed F0 and duration modeling methods achieve 97.3% and 84.3%\npreference rate over baseline respectively, which demonstrates the overwhelming\nadvantages of XiaoiceSing.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 09:09:59 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Lu", "Peiling", ""], ["Wu", "Jie", ""], ["Luan", "Jian", ""], ["Tan", "Xu", ""], ["Zhou", "Li", ""]]}, {"id": "2006.06264", "submitter": "Nitika Mathur", "authors": "Nitika Mathur, Timothy Baldwin and Trevor Cohn", "title": "Tangled up in BLEU: Reevaluating the Evaluation of Automatic Machine\n  Translation Evaluation Metrics", "comments": "Accepted at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic metrics are fundamental for the development and evaluation of\nmachine translation systems. Judging whether, and to what extent, automatic\nmetrics concur with the gold standard of human evaluation is not a\nstraightforward problem. We show that current methods for judging metrics are\nhighly sensitive to the translations used for assessment, particularly the\npresence of outliers, which often leads to falsely confident conclusions about\na metric's efficacy. Finally, we turn to pairwise system ranking, developing a\nmethod for thresholding performance improvement under an automatic metric\nagainst human judgements, which allows quantification of type I versus type II\nerrors incurred, i.e., insignificant human differences in system quality that\nare accepted, and significant human differences that are rejected. Together,\nthese findings suggest improvements to the protocols for metric evaluation and\nsystem performance evaluation in machine translation.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 09:12:53 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 04:35:41 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Mathur", "Nitika", ""], ["Baldwin", "Timothy", ""], ["Cohn", "Trevor", ""]]}, {"id": "2006.06295", "submitter": "Justin Edwards", "authors": "Justin Edwards and Allison Perrone and Philip R. Doyle", "title": "Transparency in Language Generation: Levels of Automation", "comments": "Accepted for publication at CUI 2020", "journal-ref": null, "doi": "10.1145/3405755.3406136", "report-no": null, "categories": "cs.HC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language models and conversational systems are growing increasingly advanced,\ncreating outputs that may be mistaken for humans. Consumers may thus be misled\nby advertising, media reports, or vagueness regarding the role of automation in\nthe production of language. We propose a taxonomy of language automation, based\non the SAE levels of driving automation, to establish a shared set of terms for\ndescribing automated language. It is our hope that the proposed taxonomy can\nincrease transparency in this rapidly advancing field.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 10:01:59 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Edwards", "Justin", ""], ["Perrone", "Allison", ""], ["Doyle", "Philip R.", ""]]}, {"id": "2006.06328", "submitter": "Justin Edwards", "authors": "Yunhan Wu, Daniel Rough, Anna Bleakley, Justin Edwards, Orla Cooney,\n  Philip R. Doyle, Leigh Clark, and Benjamin R. Cowan", "title": "See what I'm saying? Comparing Intelligent Personal Assistant use for\n  Native and Non-Native Language Speakers", "comments": "Accepted to Mobile HCI 2020", "journal-ref": null, "doi": "10.1145/3379503.3403563", "report-no": null, "categories": "cs.HC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Limited linguistic coverage for Intelligent Personal Assistants (IPAs) means\nthat many interact in a non-native language. Yet we know little about how IPAs\ncurrently support or hinder these users. Through native (L1) and non-native\n(L2) English speakers interacting with Google Assistant on a smartphone and\nsmart speaker, we aim to understand this more deeply. Interviews revealed that\nL2 speakers prioritised utterance planning around perceived linguistic\nlimitations, as opposed to L1 speakers prioritising succinctness because of\nsystem limitations. L2 speakers see IPAs as insensitive to linguistic needs\nresulting in failed interaction. L2 speakers clearly preferred using\nsmartphones, as visual feedback supported diagnoses of communication breakdowns\nwhilst allowing time to process query results. Conversely, L1 speakers\npreferred smart speakers, with audio feedback being seen as sufficient. We\ndiscuss the need to tailor the IPA experience for L2 users, emphasising visual\nfeedback whilst reducing the burden of language production.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 11:03:49 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Wu", "Yunhan", ""], ["Rough", "Daniel", ""], ["Bleakley", "Anna", ""], ["Edwards", "Justin", ""], ["Cooney", "Orla", ""], ["Doyle", "Philip R.", ""], ["Clark", "Leigh", ""], ["Cowan", "Benjamin R.", ""]]}, {"id": "2006.06331", "submitter": "Justin Edwards", "authors": "Yunhan Wu, Justin Edwards, Orla Cooney, Anna Bleakley, Philip R.Doyle,\n  Leigh Clark, Daniel Rough, and Benjamin R. Cowan", "title": "Mental Workload and Language Production in Non-Native Speaker IPA\n  Interaction", "comments": "Accepted at CUI 2020", "journal-ref": null, "doi": "10.1145/3405755.3406118", "report-no": null, "categories": "cs.HC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Through proliferation on smartphones and smart speakers, intelligent personal\nassistants (IPAs) have made speech a common interaction modality. Yet, due to\nlinguistic coverage and varying levels of functionality, many speakers engage\nwith IPAs using a non-native language. This may impact the mental workload and\npattern of language production displayed by non-native speakers. We present a\nmixed-design experiment, wherein native (L1) and non-native (L2) English\nspeakers completed tasks with IPAs through smartphones and smart speakers. We\nfound significantly higher mental workload for L2 speakers during IPA\ninteractions. Contrary to our hypotheses, we found no significant differences\nbetween L1 and L2 speakers in terms of number of turns, lexical complexity,\ndiversity, or lexical adaptation when encountering errors. These findings are\ndiscussed in relation to language production and processing load increases for\nL2 speakers in IPA interaction.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 11:06:42 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Wu", "Yunhan", ""], ["Edwards", "Justin", ""], ["Cooney", "Orla", ""], ["Bleakley", "Anna", ""], ["Doyle", "Philip R.", ""], ["Clark", "Leigh", ""], ["Rough", "Daniel", ""], ["Cowan", "Benjamin R.", ""]]}, {"id": "2006.06336", "submitter": "Vukosi Marivate", "authors": "Vukosi Marivate, Avashlin Moodley, Athandiwe Saba", "title": "Extracting and categorising the reactions to COVID-19 by the South\n  African public -- A social media study", "comments": "Under review for EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Social Media can be used to extract discussion topics during a disaster. With\nthe COVID-19 pandemic impact on South Africa, we need to understand how the law\nand regulation promulgated by the government in response to the pandemic\ncontrasts with discussion topics social media users have been engaging in. In\nthis work, we expand on traditional media analysis by using Social Media\ndiscussions driven by or directed to South African government officials. We\nfind topics that are similar as well as different in some cases. The findings\ncan inform further study into social media during disaster settings in South\nAfrica and beyond.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 11:19:43 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Marivate", "Vukosi", ""], ["Moodley", "Avashlin", ""], ["Saba", "Athandiwe", ""]]}, {"id": "2006.06341", "submitter": "Tobias Kuhn", "authors": "Timo Lek, Anna de Groot, Tobias Kuhn, Roser Morante", "title": "Provenance for Linguistic Corpora Through Nanopublications", "comments": null, "journal-ref": "In Proceedings of the 14th Linguistic Annotation Workshop (LAW),\n  co-located with COLING 2020", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Research in Computational Linguistics is dependent on text corpora for\ntraining and testing new tools and methodologies. While there exists a plethora\nof annotated linguistic information, these corpora are often not interoperable\nwithout significant manual work. Moreover, these annotations might have evolved\ninto different versions, making it challenging for researchers to know the\ndata's provenance. This paper addresses this issue with a case study on event\nannotated corpora and by creating a new, more interoperable representation of\nthis data in the form of nanopublications. We demonstrate how linguistic\nannotations from separate corpora can be reliably linked from the start, and\nthereby be accessed and queried as if they were a single dataset. We describe\nhow such nanopublications can be created and demonstrate how SPARQL queries can\nbe performed to extract interesting content from the new representations. The\nqueries show that information of multiple corpora can be retrieved more easily\nand effectively because the information of different corpora is represented in\na uniform data format.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 11:30:30 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 07:29:09 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Lek", "Timo", ""], ["de Groot", "Anna", ""], ["Kuhn", "Tobias", ""], ["Morante", "Roser", ""]]}, {"id": "2006.06402", "submitter": "Libo Qin", "authors": "Libo Qin, Minheng Ni, Yue Zhang, Wanxiang Che", "title": "CoSDA-ML: Multi-Lingual Code-Switching Data Augmentation for Zero-Shot\n  Cross-Lingual NLP", "comments": "Accepted at IJCAI2020. SOLE copyright holder is IJCAI (international\n  Joint Conferences on Artificial Intelligence), all rights reserved.\n  http://static.ijcai.org/2020-accepted_papers.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-lingual contextualized embeddings, such as multilingual-BERT (mBERT),\nhave shown success in a variety of zero-shot cross-lingual tasks. However,\nthese models are limited by having inconsistent contextualized representations\nof subwords across different languages. Existing work addresses this issue by\nbilingual projection and fine-tuning technique. We propose a data augmentation\nframework to generate multi-lingual code-switching data to fine-tune mBERT,\nwhich encourages model to align representations from source and multiple target\nlanguages once by mixing their context information. Compared with the existing\nwork, our method does not rely on bilingual sentences for training, and\nrequires only one training process for multiple target languages. Experimental\nresults on five tasks with 19 languages show that our method leads to\nsignificantly improved performances for all the tasks compared with mBERT.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 13:15:59 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 04:59:04 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Qin", "Libo", ""], ["Ni", "Minheng", ""], ["Zhang", "Yue", ""], ["Che", "Wanxiang", ""]]}, {"id": "2006.06436", "submitter": "Meng Jiang", "authors": "Yang Zhou, Tong Zhao, Meng Jiang", "title": "A Probabilistic Model with Commonsense Constraints for Pattern-based\n  Temporal Fact Extraction", "comments": "7 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Textual patterns (e.g., Country's president Person) are specified and/or\ngenerated for extracting factual information from unstructured data.\nPattern-based information extraction methods have been recognized for their\nefficiency and transferability. However, not every pattern is reliable: A major\nchallenge is to derive the most complete and accurate facts from diverse and\nsometimes conflicting extractions. In this work, we propose a probabilistic\ngraphical model which formulates fact extraction in a generative process. It\nautomatically infers true facts and pattern reliability without any\nsupervision. It has two novel designs specially for temporal facts: (1) it\nmodels pattern reliability on two types of time signals, including temporal tag\nin text and text generation time; (2) it models commonsense constraints as\nobservable variables. Experimental results demonstrate that our model\nsignificantly outperforms existing methods on extracting true temporal facts\nfrom news data.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 13:48:04 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Zhou", "Yang", ""], ["Zhao", "Tong", ""], ["Jiang", "Meng", ""]]}, {"id": "2006.06462", "submitter": "Fran\\c{c}ois Charton", "authors": "Fran\\c{c}ois Charton, Amaury Hayat, Guillaume Lample", "title": "Learning advanced mathematical computations from examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using transformers over large generated datasets, we train models to learn\nmathematical properties of differential systems, such as local stability,\nbehavior at infinity and controllability. We achieve near perfect prediction of\nqualitative characteristics, and good approximations of numerical features of\nthe system. This demonstrates that neural networks can learn to perform complex\ncomputations, grounded in advanced theory, from examples, without built-in\nmathematical knowledge.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 14:18:35 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 07:02:10 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Charton", "Fran\u00e7ois", ""], ["Hayat", "Amaury", ""], ["Lample", "Guillaume", ""]]}, {"id": "2006.06478", "submitter": "Weiming Lu", "authors": "Zeyun Tang, Yongliang Shen, Xinyin Ma, Wei Xu, Jiale Yu, Weiming Lu", "title": "Multi-hop Reading Comprehension across Documents with Path-based Graph\n  Convolutional Network", "comments": "Accepted by IJCAI 2020 (copyright held by IJCAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-hop reading comprehension across multiple documents attracts much\nattention recently. In this paper, we propose a novel approach to tackle this\nmulti-hop reading comprehension problem. Inspired by human reasoning\nprocessing, we construct a path-based reasoning graph from supporting\ndocuments. This graph can combine both the idea of the graph-based and\npath-based approaches, so it is better for multi-hop reasoning. Meanwhile, we\npropose Gated-RGCN to accumulate evidence on the path-based reasoning graph,\nwhich contains a new question-aware gating mechanism to regulate the usefulness\nof information propagating across documents and add question information during\nreasoning. We evaluate our approach on WikiHop dataset, and our approach\nachieves state-of-the-art accuracy against previously published approaches.\nEspecially, our ensemble model surpasses human performance by 4.2%.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 14:43:34 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 04:04:05 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Tang", "Zeyun", ""], ["Shen", "Yongliang", ""], ["Ma", "Xinyin", ""], ["Xu", "Wei", ""], ["Yu", "Jiale", ""], ["Lu", "Weiming", ""]]}, {"id": "2006.06609", "submitter": "Alon Talmor", "authors": "Alon Talmor, Oyvind Tafjord, Peter Clark, Yoav Goldberg, Jonathan\n  Berant", "title": "Leap-Of-Thought: Teaching Pre-Trained Models to Systematically Reason\n  Over Implicit Knowledge", "comments": "Presented as Spotlight at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To what extent can a neural network systematically reason over symbolic\nfacts? Evidence suggests that large pre-trained language models (LMs) acquire\nsome reasoning capacity, but this ability is difficult to control. Recently, it\nhas been shown that Transformer-based models succeed in consistent reasoning\nover explicit symbolic facts, under a \"closed-world\" assumption. However, in an\nopen-domain setup, it is desirable to tap into the vast reservoir of implicit\nknowledge already encoded in the parameters of pre-trained LMs. In this work,\nwe provide a first demonstration that LMs can be trained to reliably perform\nsystematic reasoning combining both implicit, pre-trained knowledge and\nexplicit natural language statements. To do this, we describe a procedure for\nautomatically generating datasets that teach a model new reasoning skills, and\ndemonstrate that models learn to effectively perform inference which involves\nimplicit taxonomic and world knowledge, chaining and counting. Finally, we show\nthat \"teaching\" models to reason generalizes beyond the training distribution:\nthey successfully compose the usage of multiple reasoning skills in single\nexamples. Our work paves a path towards open-domain systems that constantly\nimprove by interacting with users who can instantly correct a model by adding\nsimple natural language statements.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 17:02:20 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 15:31:59 GMT"}, {"version": "v3", "created": "Sat, 14 Nov 2020 07:47:21 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Talmor", "Alon", ""], ["Tafjord", "Oyvind", ""], ["Clark", "Peter", ""], ["Goldberg", "Yoav", ""], ["Berant", "Jonathan", ""]]}, {"id": "2006.06637", "submitter": "Shaunak Halbe", "authors": "Shaunak Halbe", "title": "Exploring Weaknesses of VQA Models through Attribution Driven Insights", "comments": "Second Grand-Challenge and Workshop on Multimodal Language, ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks have been successfully used for the task of Visual\nQuestion Answering for the past few years owing to the availability of relevant\nlarge scale datasets. However these datasets are created in artificial settings\nand rarely reflect the real world scenario. Recent research effectively applies\nthese VQA models for answering visual questions for the blind. Despite\nachieving high accuracy these models appear to be susceptible to variation in\ninput questions.We analyze popular VQA models through the lens of attribution\n(input's influence on predictions) to gain valuable insights. Further, We use\nthese insights to craft adversarial attacks which inflict significant damage to\nthese systems with negligible change in meaning of the input questions. We\nbelieve this will enhance development of systems more robust to the possible\nvariations in inputs when deployed to assist the visually impaired.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 17:30:07 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 12:01:03 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Halbe", "Shaunak", ""]]}, {"id": "2006.06666", "submitter": "Karan Desai", "authors": "Karan Desai, Justin Johnson", "title": "VirTex: Learning Visual Representations from Textual Annotations", "comments": "Code available at https://github.com/kdexd/virtex", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The de-facto approach to many vision tasks is to start from pretrained visual\nrepresentations, typically learned via supervised training on ImageNet. Recent\nmethods have explored unsupervised pretraining to scale to vast quantities of\nunlabeled images. In contrast, we aim to learn high-quality visual\nrepresentations from fewer images. To this end, we revisit supervised\npretraining, and seek data-efficient alternatives to classification-based\npretraining. We propose VirTex -- a pretraining approach using semantically\ndense captions to learn visual representations. We train convolutional networks\nfrom scratch on COCO Captions, and transfer them to downstream recognition\ntasks including image classification, object detection, and instance\nsegmentation. On all tasks, VirTex yields features that match or exceed those\nlearned on ImageNet -- supervised or unsupervised -- despite using up to ten\ntimes fewer images.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 17:58:48 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 12:03:24 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Desai", "Karan", ""], ["Johnson", "Justin", ""]]}, {"id": "2006.06668", "submitter": "Han Hu", "authors": "Minghao Yin and Zhuliang Yao and Yue Cao and Xiu Li and Zheng Zhang\n  and Stephen Lin and Han Hu", "title": "Disentangled Non-Local Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The non-local block is a popular module for strengthening the context\nmodeling ability of a regular convolutional neural network. This paper first\nstudies the non-local block in depth, where we find that its attention\ncomputation can be split into two terms, a whitened pairwise term accounting\nfor the relationship between two pixels and a unary term representing the\nsaliency of every pixel. We also observe that the two terms trained alone tend\nto model different visual clues, e.g. the whitened pairwise term learns\nwithin-region relationships while the unary term learns salient boundaries.\nHowever, the two terms are tightly coupled in the non-local block, which\nhinders the learning of each. Based on these findings, we present the\ndisentangled non-local block, where the two terms are decoupled to facilitate\nlearning for both terms. We demonstrate the effectiveness of the decoupled\ndesign on various tasks, such as semantic segmentation on Cityscapes, ADE20K\nand PASCAL Context, object detection on COCO, and action recognition on\nKinetics.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 17:59:22 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 14:12:09 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Yin", "Minghao", ""], ["Yao", "Zhuliang", ""], ["Cao", "Yue", ""], ["Li", "Xiu", ""], ["Zhang", "Zheng", ""], ["Lin", "Stephen", ""], ["Hu", "Han", ""]]}, {"id": "2006.06814", "submitter": "Jianhong Wang", "authors": "Jianhong Wang, Yuan Zhang, Tae-Kyun Kim, Yunjie Gu", "title": "Modelling Hierarchical Structure between Dialogue Policy and Natural\n  Language Generator with Option Framework for Task-oriented Dialogue System", "comments": "Published as a conference paper at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing task-oriented dialogue systems is a challenging research topic,\nsince it needs not only to generate utterances fulfilling user requests but\nalso to guarantee the comprehensibility. Many previous works trained end-to-end\n(E2E) models with supervised learning (SL), however, the bias in annotated\nsystem utterances remains as a bottleneck. Reinforcement learning (RL) deals\nwith the problem through using non-differentiable evaluation metrics (e.g., the\nsuccess rate) as rewards. Nonetheless, existing works with RL showed that the\ncomprehensibility of generated system utterances could be corrupted when\nimproving the performance on fulfilling user requests. In our work, we (1)\npropose modelling the hierarchical structure between dialogue policy and\nnatural language generator (NLG) with the option framework, called HDNO, where\nthe latent dialogue act is applied to avoid designing specific dialogue act\nrepresentations; (2) train HDNO via hierarchical reinforcement learning (HRL),\nas well as suggest the asynchronous updates between dialogue policy and NLG\nduring training to theoretically guarantee their convergence to a local\nmaximizer; and (3) propose using a discriminator modelled with language models\nas an additional reward to further improve the comprehensibility. We test HDNO\non MultiWoz 2.0 and MultiWoz 2.1, the datasets on multi-domain dialogues, in\ncomparison with word-level E2E model trained with RL, LaRL and HDSA, showing\nimprovements on the performance evaluated by automatic evaluation metrics and\nhuman evaluation. Finally, we demonstrate the semantic meanings of latent\ndialogue acts to show the explanability for HDNO.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 20:55:28 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 10:26:21 GMT"}, {"version": "v3", "created": "Wed, 30 Sep 2020 21:56:52 GMT"}, {"version": "v4", "created": "Fri, 19 Feb 2021 17:26:40 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Wang", "Jianhong", ""], ["Zhang", "Yuan", ""], ["Kim", "Tae-Kyun", ""], ["Gu", "Yunjie", ""]]}, {"id": "2006.06873", "submitter": "Adrian {\\L}a\\'ncucki", "authors": "Adrian {\\L}a\\'ncucki", "title": "FastPitch: Parallel Text-to-speech with Pitch Prediction", "comments": "Accepted to ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present FastPitch, a fully-parallel text-to-speech model based on\nFastSpeech, conditioned on fundamental frequency contours. The model predicts\npitch contours during inference. By altering these predictions, the generated\nspeech can be more expressive, better match the semantic of the utterance, and\nin the end more engaging to the listener. Uniformly increasing or decreasing\npitch with FastPitch generates speech that resembles the voluntary modulation\nof voice. Conditioning on frequency contours improves the overall quality of\nsynthesized speech, making it comparable to state-of-the-art. It does not\nintroduce an overhead, and FastPitch retains the favorable, fully-parallel\nTransformer architecture, with over 900x real-time factor for mel-spectrogram\nsynthesis of a typical utterance.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 23:23:58 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 14:23:15 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["\u0141a\u0144cucki", "Adrian", ""]]}, {"id": "2006.06877", "submitter": "Daniel King", "authors": "Daniel King, Doug Downey, Daniel S. Weld", "title": "High-Precision Extraction of Emerging Concepts from Scientific\n  Literature", "comments": "Accepted to SIGIR 2020", "journal-ref": "Proceedings of the 43rd International ACM SIGIR Conference on\n  Research and Development in Information Retrieval (2020) 1549-1552", "doi": "10.1145/3397271.3401235", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identification of new concepts in scientific literature can help power\nfaceted search, scientific trend analysis, knowledge-base construction, and\nmore, but current methods are lacking. Manual identification cannot keep up\nwith the torrent of new publications, while the precision of existing automatic\ntechniques is too low for many applications. We present an unsupervised concept\nextraction method for scientific literature that achieves much higher precision\nthan previous work. Our approach relies on a simple but novel intuition: each\nscientific concept is likely to be introduced or popularized by a single paper\nthat is disproportionately cited by subsequent papers mentioning the concept.\nFrom a corpus of computer science papers on arXiv, we find that our method\nachieves a Precision@1000 of 99%, compared to 86% for prior work, and a\nsubstantially better precision-yield trade-off across the top 15,000\nextractions. To stimulate research in this area, we release our code and data\n(https://github.com/allenai/ForeCite).\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 23:48:27 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["King", "Daniel", ""], ["Downey", "Doug", ""], ["Weld", "Daniel S.", ""]]}, {"id": "2006.06900", "submitter": "Yue Wu", "authors": "Yue Wu, Pan Zhou, Andrew Gordon Wilson, Eric P. Xing, Zhiting Hu", "title": "Improving GAN Training with Probability Ratio Clipping and Sample\n  Reweighting", "comments": "NeurIPS 2020 camera ready version (citations updated)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite success on a wide range of problems related to vision, generative\nadversarial networks (GANs) often suffer from inferior performance due to\nunstable training, especially for text generation. To solve this issue, we\npropose a new variational GAN training framework which enjoys superior training\nstability. Our approach is inspired by a connection of GANs and reinforcement\nlearning under a variational perspective. The connection leads to (1)\nprobability ratio clipping that regularizes generator training to prevent\nexcessively large updates, and (2) a sample re-weighting mechanism that\nimproves discriminator training by downplaying bad-quality fake samples.\nMoreover, our variational GAN framework can provably overcome the training\nissue in many GANs that an optimal discriminator cannot provide any informative\ngradient to training generator. By plugging the training approach in diverse\nstate-of-the-art GAN architectures, we obtain significantly improved\nperformance over a range of tasks, including text generation, text style\ntransfer, and image generation.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 01:39:48 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 15:02:27 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 03:24:01 GMT"}, {"version": "v4", "created": "Fri, 30 Oct 2020 16:27:22 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Wu", "Yue", ""], ["Zhou", "Pan", ""], ["Wilson", "Andrew Gordon", ""], ["Xing", "Eric P.", ""], ["Hu", "Zhiting", ""]]}, {"id": "2006.07015", "submitter": "JinYeong Bak", "authors": "JinYeong Bak, Alice Oh", "title": "Speaker Sensitive Response Evaluation Model", "comments": "Accepted at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic evaluation of open-domain dialogue response generation is very\nchallenging because there are many appropriate responses for a given context.\nExisting evaluation models merely compare the generated response with the\nground truth response and rate many of the appropriate responses as\ninappropriate if they deviate from the ground truth. One approach to resolve\nthis problem is to consider the similarity of the generated response with the\nconversational context. In this paper, we propose an automatic evaluation model\nbased on that idea and learn the model parameters from an unlabeled\nconversation corpus. Our approach considers the speakers in defining the\ndifferent levels of similar context. We use a Twitter conversation corpus that\ncontains many speakers and conversations to test our evaluation model.\nExperiments show that our model outperforms the other existing evaluation\nmetrics in terms of high correlation with human annotation scores. We also show\nthat our model trained on Twitter can be applied to movie dialogues without any\nadditional training. We provide our code and the learned parameters so that\nthey can be used for automatic evaluation of dialogue response generation\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 08:59:10 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Bak", "JinYeong", ""], ["Oh", "Alice", ""]]}, {"id": "2006.07017", "submitter": "Wei Wang", "authors": "Junshu Jiang and Songyun Ye and Wei Wang and Jingran Xu and Xiaosheng\n  Luo", "title": "Learning Effective Representations for Person-Job Fit by Feature Fusion", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Person-job fit is to match candidates and job posts on online recruitment\nplatforms using machine learning algorithms. The effectiveness of matching\nalgorithms heavily depends on the learned representations for the candidates\nand job posts. In this paper, we propose to learn comprehensive and effective\nrepresentations of the candidates and job posts via feature fusion. First, in\naddition to applying deep learning models for processing the free text in\nresumes and job posts, which is adopted by existing methods, we extract\nsemantic entities from the whole resume (and job post) and then learn features\nfor them. By fusing the features from the free text and the entities, we get a\ncomprehensive representation for the information explicitly stated in the\nresume and job post. Second, however, some information of a candidate or a job\nmay not be explicitly captured in the resume or job post. Nonetheless, the\nhistorical applications including accepted and rejected cases can reveal some\nimplicit intentions of the candidates or recruiters. Therefore, we propose to\nlearn the representations of implicit intentions by processing the historical\napplications using LSTM. Last, by fusing the representations for the explicit\nand implicit intentions, we get a more comprehensive and effective\nrepresentation for person-job fit. Experiments over 10 months real data show\nthat our solution outperforms existing methods with a large margin. Ablation\nstudies confirm the contribution of each component of the fused representation.\nThe extracted semantic entities help interpret the matching results during the\ncase study.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 09:02:41 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Jiang", "Junshu", ""], ["Ye", "Songyun", ""], ["Wang", "Wei", ""], ["Xu", "Jingran", ""], ["Luo", "Xiaosheng", ""]]}, {"id": "2006.07043", "submitter": "C\\'edric Colas", "authors": "C\\'edric Colas, Ahmed Akakzia, Pierre-Yves Oudeyer, Mohamed Chetouani,\n  Olivier Sigaud", "title": "Language-Conditioned Goal Generation: a New Approach to Language\n  Grounding for RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the real world, linguistic agents are also embodied agents: they perceive\nand act in the physical world. The notion of Language Grounding questions the\ninteractions between language and embodiment: how do learning agents connect or\nground linguistic representations to the physical world ? This question has\nrecently been approached by the Reinforcement Learning community under the\nframework of instruction-following agents. In these agents, behavioral policies\nor reward functions are conditioned on the embedding of an instruction\nexpressed in natural language. This paper proposes another approach: using\nlanguage to condition goal generators. Given any goal-conditioned policy, one\ncould train a language-conditioned goal generator to generate language-agnostic\ngoals for the agent. This method allows to decouple sensorimotor learning from\nlanguage acquisition and enable agents to demonstrate a diversity of behaviors\nfor any given instruction. We propose a particular instantiation of this\napproach and demonstrate its benefits.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 09:54:38 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Colas", "C\u00e9dric", ""], ["Akakzia", "Ahmed", ""], ["Oudeyer", "Pierre-Yves", ""], ["Chetouani", "Mohamed", ""], ["Sigaud", "Olivier", ""]]}, {"id": "2006.07116", "submitter": "Nikita Klyuchnikov", "authors": "Nikita Klyuchnikov, Ilya Trofimov, Ekaterina Artemova, Mikhail\n  Salnikov, Maxim Fedorov, Evgeny Burnaev", "title": "NAS-Bench-NLP: Neural Architecture Search Benchmark for Natural Language\n  Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS) is a promising and rapidly evolving research\narea. Training a large number of neural networks requires an exceptional amount\nof computational power, which makes NAS unreachable for those researchers who\nhave limited or no access to high-performance clusters and supercomputers. A\nfew benchmarks with precomputed neural architectures performances have been\nrecently introduced to overcome this problem and ensure more reproducible\nexperiments. However, these benchmarks are only for the computer vision domain\nand, thus, are built from the image datasets and convolution-derived\narchitectures. In this work, we step outside the computer vision domain by\nleveraging the language modeling task, which is the core of natural language\nprocessing (NLP). Our main contribution is as follows: we have provided search\nspace of recurrent neural networks on the text datasets and trained 14k\narchitectures within it; we have conducted both intrinsic and extrinsic\nevaluation of the trained models using datasets for semantic relatedness and\nlanguage understanding evaluation; finally, we have tested several NAS\nalgorithms to demonstrate how the precomputed results can be utilized. We\nbelieve that our results have high potential of usage for both NAS and NLP\ncommunities.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 12:19:06 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Klyuchnikov", "Nikita", ""], ["Trofimov", "Ilya", ""], ["Artemova", "Ekaterina", ""], ["Salnikov", "Mikhail", ""], ["Fedorov", "Maxim", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "2006.07214", "submitter": "Andre Martins", "authors": "Andr\\'e F. T. Martins, Ant\\'onio Farinhas, Marcos Treviso, Vlad\n  Niculae, Pedro M. Q. Aguiar, M\\'ario A. T. Figueiredo", "title": "Sparse and Continuous Attention Mechanisms", "comments": "Accepted for spotlight presentation at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exponential families are widely used in machine learning; they include many\ndistributions in continuous and discrete domains (e.g., Gaussian, Dirichlet,\nPoisson, and categorical distributions via the softmax transformation).\nDistributions in each of these families have fixed support. In contrast, for\nfinite domains, there has been recent work on sparse alternatives to softmax\n(e.g. sparsemax and alpha-entmax), which have varying support, being able to\nassign zero probability to irrelevant categories. This paper expands that work\nin two directions: first, we extend alpha-entmax to continuous domains,\nrevealing a link with Tsallis statistics and deformed exponential families.\nSecond, we introduce continuous-domain attention mechanisms, deriving efficient\ngradient backpropagation algorithms for alpha in {1,2}. Experiments on\nattention-based text classification, machine translation, and visual question\nanswering illustrate the use of continuous attention in 1D and 2D, showing that\nit allows attending to time intervals and compact regions.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 14:16:48 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 22:22:38 GMT"}, {"version": "v3", "created": "Thu, 29 Oct 2020 08:39:54 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Martins", "Andr\u00e9 F. T.", ""], ["Farinhas", "Ant\u00f3nio", ""], ["Treviso", "Marcos", ""], ["Niculae", "Vlad", ""], ["Aguiar", "Pedro M. Q.", ""], ["Figueiredo", "M\u00e1rio A. T.", ""]]}, {"id": "2006.07235", "submitter": "Marcos Zampieri", "authors": "Marcos Zampieri, Preslav Nakov, Sara Rosenthal, Pepa Atanasova, Georgi\n  Karadzhov, Hamdy Mubarak, Leon Derczynski, Zeses Pitenis, \\c{C}a\\u{g}r{\\i}\n  \\c{C}\\\"oltekin", "title": "SemEval-2020 Task 12: Multilingual Offensive Language Identification in\n  Social Media (OffensEval 2020)", "comments": "Proceedings of the International Workshop on Semantic Evaluation\n  (SemEval-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the results and main findings of SemEval-2020 Task 12 on\nMultilingual Offensive Language Identification in Social Media (OffensEval\n2020). The task involves three subtasks corresponding to the hierarchical\ntaxonomy of the OLID schema (Zampieri et al., 2019a) from OffensEval 2019. The\ntask featured five languages: English, Arabic, Danish, Greek, and Turkish for\nSubtask A. In addition, English also featured Subtasks B and C. OffensEval 2020\nwas one of the most popular tasks at SemEval-2020 attracting a large number of\nparticipants across all subtasks and also across all languages. A total of 528\nteams signed up to participate in the task, 145 teams submitted systems during\nthe evaluation period, and 70 submitted system description papers.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 14:39:40 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 15:46:44 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Zampieri", "Marcos", ""], ["Nakov", "Preslav", ""], ["Rosenthal", "Sara", ""], ["Atanasova", "Pepa", ""], ["Karadzhov", "Georgi", ""], ["Mubarak", "Hamdy", ""], ["Derczynski", "Leon", ""], ["Pitenis", "Zeses", ""], ["\u00c7\u00f6ltekin", "\u00c7a\u011fr\u0131", ""]]}, {"id": "2006.07264", "submitter": "Alexandre Magueresse", "authors": "Alexandre Magueresse, Vincent Carles, Evan Heetderks", "title": "Low-resource Languages: A Review of Past Work and Future Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A current problem in NLP is massaging and processing low-resource languages\nwhich lack useful training attributes such as supervised data, number of native\nspeakers or experts, etc. This review paper concisely summarizes previous\ngroundbreaking achievements made towards resolving this problem, and analyzes\npotential improvements in the context of the overall future research direction.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 15:21:57 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Magueresse", "Alexandre", ""], ["Carles", "Vincent", ""], ["Heetderks", "Evan", ""]]}, {"id": "2006.07283", "submitter": "Erik Tjong Kim Sang", "authors": "Shihan Wang, Marijn Schraagen, Erik Tjong Kim Sang and Mehdi Dastani", "title": "Dutch General Public Reaction on Governmental COVID-19 Measures and\n  Announcements in Twitter Data", "comments": "25 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Public sentiment (the opinions, attitudes or feelings expressed by the\npublic) is a factor of interest for government, as it directly influences the\nimplementation of policies. Given the unprecedented nature of the COVID-19\ncrisis, having an up-to-date representation of public sentiment on governmental\nmeasures and announcements is crucial. While the 'staying-at-home' policy makes\nface-to-face interactions and interviews challenging, analysing real-time\nTwitter data that reflects public opinion toward policy measures is a\ncost-effective way to access public sentiment. In this context, we collect\nstreaming data using the Twitter API starting from the COVID-19 outbreak in the\nNetherlands in February 2020, and track Dutch general public reactions on\ngovernmental measures and announcements. We provide temporal analysis of tweet\nfrequency and public sentiment over the past seven months. We also identify\npublic attitudes towards two Dutch policies in case studies: one regarding\nsocial distancing and one regarding wearing face masks. By presenting those\npreliminary results, we aim to provide visibility into the social media\ndiscussions around COVID-19 to the general public, scientists and policy\nmakers. The data collection and analysis will be updated and expanded over\ntime.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 16:03:58 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 10:10:35 GMT"}, {"version": "v3", "created": "Mon, 21 Dec 2020 19:53:55 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Wang", "Shihan", ""], ["Schraagen", "Marijn", ""], ["Sang", "Erik Tjong Kim", ""], ["Dastani", "Mehdi", ""]]}, {"id": "2006.07296", "submitter": "Yitong Tseo", "authors": "Yitong Tseo, M. I. Salkola, Ahmed Mohamed, Anuj Kumar, Freddy Abnousi", "title": "Information Extraction of Clinical Trial Eligibility Criteria", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical trials predicate subject eligibility on a diversity of criteria\nranging from patient demographics to food allergies. Trials post their\nrequirements as semantically complex, unstructured free-text. Formalizing trial\ncriteria to a computer-interpretable syntax would facilitate eligibility\ndetermination. In this paper, we investigate an information extraction (IE)\napproach for grounding criteria from trials in ClinicalTrials(dot)gov to a\nshared knowledge base. We frame the problem as a novel knowledge base\npopulation task, and implement a solution combining machine learning and\ncontext free grammar. To our knowledge, this work is the first criteria\nextraction system to apply attention-based conditional random field\narchitecture for named entity recognition (NER), and word2vec embedding\nclustering for named entity linking (NEL). We release the resources and core\ncomponents of our system on GitHub at\nhttps://github.com/facebookresearch/Clinical-Trial-Parser. Finally, we report\nour per module and end to end performances; we conclude that our system is\ncompetitive with Criteria2Query, which we view as the current state-of-the-art\nin criteria extraction.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 16:25:45 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 02:37:49 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 01:44:36 GMT"}, {"version": "v4", "created": "Thu, 16 Jul 2020 22:36:50 GMT"}, {"version": "v5", "created": "Fri, 24 Jul 2020 23:48:48 GMT"}, {"version": "v6", "created": "Tue, 28 Jul 2020 17:50:42 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Tseo", "Yitong", ""], ["Salkola", "M. I.", ""], ["Mohamed", "Ahmed", ""], ["Kumar", "Anuj", ""], ["Abnousi", "Freddy", ""]]}, {"id": "2006.07358", "submitter": "Thomas Searle", "authors": "Thomas Searle, Zina Ibrahim, Richard Dobson", "title": "Comparing Natural Language Processing Techniques for Alzheimer's\n  Dementia Prediction in Spontaneous Speech", "comments": "Submitted to INTERSPEECH 2020: Alzheimer's Dementia Recognition\n  through Spontaneous Speech The ADReSS Challenge Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alzheimer's Dementia (AD) is an incurable, debilitating, and progressive\nneurodegenerative condition that affects cognitive function. Early diagnosis is\nimportant as therapeutics can delay progression and give those diagnosed vital\ntime. Developing models that analyse spontaneous speech could eventually\nprovide an efficient diagnostic modality for earlier diagnosis of AD. The\nAlzheimer's Dementia Recognition through Spontaneous Speech task offers\nacoustically pre-processed and balanced datasets for the classification and\nprediction of AD and associated phenotypes through the modelling of spontaneous\nspeech. We exclusively analyse the supplied textual transcripts of the\nspontaneous speech dataset, building and comparing performance across numerous\nmodels for the classification of AD vs controls and the prediction of Mental\nMini State Exam scores. We rigorously train and evaluate Support Vector\nMachines (SVMs), Gradient Boosting Decision Trees (GBDT), and Conditional\nRandom Fields (CRFs) alongside deep learning Transformer based models. We find\nour top performing models to be a simple Term Frequency-Inverse Document\nFrequency (TF-IDF) vectoriser as input into a SVM model and a pre-trained\nTransformer based model `DistilBERT' when used as an embedding layer into\nsimple linear models. We demonstrate test set scores of 0.81-0.82 across\nclassification metrics and a RMSE of 4.58.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 17:51:16 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 14:21:22 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Searle", "Thomas", ""], ["Ibrahim", "Zina", ""], ["Dobson", "Richard", ""]]}, {"id": "2006.07398", "submitter": "Arman Kabiri", "authors": "Arman Kabiri, Paul Cook", "title": "Evaluating a Multi-sense Definition Generation Model for Multiple\n  Languages", "comments": "To be presented orally in 23rd International Conference on Text,\n  Speech and Dialogue (TSD 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most prior work on definition modeling has not accounted for polysemy, or has\ndone so by considering definition modeling for a target word in a given\ncontext. In contrast, in this study, we propose a context-agnostic approach to\ndefinition modeling, based on multi-sense word embeddings, that is capable of\ngenerating multiple definitions for a target word. In further, contrast to most\nprior work, which has primarily focused on English, we evaluate our proposed\napproach on fifteen different datasets covering nine languages from several\nlanguage families. To evaluate our approach we consider several variations of\nBLEU. Our results demonstrate that our proposed multi-sense model outperforms a\nsingle-sense model on all fifteen datasets.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 18:15:59 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Kabiri", "Arman", ""], ["Cook", "Paul", ""]]}, {"id": "2006.07409", "submitter": "Prithviraj Ammanabrolu", "authors": "Prithviraj Ammanabrolu, Ethan Tien, Matthew Hausknecht, Mark O. Riedl", "title": "How to Avoid Being Eaten by a Grue: Structured Exploration Strategies\n  for Textual Worlds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text-based games are long puzzles or quests, characterized by a sequence of\nsparse and potentially deceptive rewards. They provide an ideal platform to\ndevelop agents that perceive and act upon the world using a combinatorially\nsized natural language state-action space. Standard Reinforcement Learning\nagents are poorly equipped to effectively explore such spaces and often\nstruggle to overcome bottlenecks---states that agents are unable to pass\nthrough simply because they do not see the right action sequence enough times\nto be sufficiently reinforced. We introduce Q*BERT, an agent that learns to\nbuild a knowledge graph of the world by answering questions, which leads to\ngreater sample efficiency. To overcome bottlenecks, we further introduce\nMC!Q*BERT an agent that uses an knowledge-graph-based intrinsic motivation to\ndetect bottlenecks and a novel exploration strategy to efficiently learn a\nchain of policy modules to overcome them. We present an ablation study and\nresults demonstrating how our method outperforms the current state-of-the-art\non nine text games, including the popular game, Zork, where, for the first\ntime, a learning agent gets past the bottleneck where the player is eaten by a\nGrue.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 18:24:06 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Ammanabrolu", "Prithviraj", ""], ["Tien", "Ethan", ""], ["Hausknecht", "Matthew", ""], ["Riedl", "Mark O.", ""]]}, {"id": "2006.07425", "submitter": "Shi Zong", "authors": "Shi Zong, Alan Ritter, Eduard Hovy", "title": "Measuring Forecasting Skill from Text", "comments": "Accepted at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People vary in their ability to make accurate predictions about the future.\nPrior studies have shown that some individuals can predict the outcome of\nfuture events with consistently better accuracy. This leads to a natural\nquestion: what makes some forecasters better than others? In this paper we\nexplore connections between the language people use to describe their\npredictions and their forecasting skill. Datasets from two different\nforecasting domains are explored: (1) geopolitical forecasts from Good Judgment\nOpen, an online prediction forum and (2) a corpus of company earnings forecasts\nmade by financial analysts. We present a number of linguistic metrics which are\ncomputed over text associated with people's predictions about the future\nincluding: uncertainty, readability, and emotion. By studying linguistic\nfactors associated with predictions, we are able to shed some light on the\napproach taken by skilled forecasters. Furthermore, we demonstrate that it is\npossible to accurately predict forecasting skill using a model that is based\nsolely on language. This could potentially be useful for identifying accurate\npredictions or potentially skilled forecasters earlier.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 19:04:10 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 16:09:30 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Zong", "Shi", ""], ["Ritter", "Alan", ""], ["Hovy", "Eduard", ""]]}, {"id": "2006.07490", "submitter": "Om Thakkar", "authors": "Om Thakkar, Swaroop Ramaswamy, Rajiv Mathews, Fran\\c{c}oise Beaufays", "title": "Understanding Unintended Memorization in Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent works have shown that generative sequence models (e.g., language\nmodels) have a tendency to memorize rare or unique sequences in the training\ndata. Since useful models are often trained on sensitive data, to ensure the\nprivacy of the training data it is critical to identify and mitigate such\nunintended memorization. Federated Learning (FL) has emerged as a novel\nframework for large-scale distributed learning tasks. However, it differs in\nmany aspects from the well-studied central learning setting where all the data\nis stored at the central server. In this paper, we initiate a formal study to\nunderstand the effect of different components of canonical FL on unintended\nmemorization in trained models, comparing with the central learning setting.\nOur results show that several differing components of FL play an important role\nin reducing unintended memorization. Specifically, we observe that the\nclustering of data according to users---which happens by design in FL---has a\nsignificant effect in reducing such memorization, and using the method of\nFederated Averaging for training causes a further reduction. We also show that\ntraining with a strong user-level differential privacy guarantee results in\nmodels that exhibit the least amount of unintended memorization.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 22:10:16 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Thakkar", "Om", ""], ["Ramaswamy", "Swaroop", ""], ["Mathews", "Rajiv", ""], ["Beaufays", "Fran\u00e7oise", ""]]}, {"id": "2006.07499", "submitter": "Bo-Hsiang (Andy) Tseng", "authors": "Bo-Hsiang Tseng, Jianpeng Cheng, Yimai Fang, David Vandyke", "title": "A Generative Model for Joint Natural Language Understanding and\n  Generation", "comments": "The 58th Annual Meeting of the Association for Computational\n  Linguistics, ACL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language understanding (NLU) and natural language generation (NLG)\nare two fundamental and related tasks in building task-oriented dialogue\nsystems with opposite objectives: NLU tackles the transformation from natural\nlanguage to formal representations, whereas NLG does the reverse. A key to\nsuccess in either task is parallel training data which is expensive to obtain\nat a large scale. In this work, we propose a generative model which couples NLU\nand NLG through a shared latent variable. This approach allows us to explore\nboth spaces of natural language and formal representations, and facilitates\ninformation sharing through the latent space to eventually benefit NLU and NLG.\nOur model achieves state-of-the-art performance on two dialogue datasets with\nboth flat and tree-structured formal representations. We also show that the\nmodel can be trained in a semi-supervised fashion by utilising unlabelled data\nto boost its performance.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 22:38:55 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Tseng", "Bo-Hsiang", ""], ["Cheng", "Jianpeng", ""], ["Fang", "Yimai", ""], ["Vandyke", "David", ""]]}, {"id": "2006.07510", "submitter": "Peter Clark", "authors": "Sumithra Bhakthavatsalam, Kyle Richardson, Niket Tandon, Peter Clark", "title": "Do Dogs have Whiskers? A New Knowledge Base of hasPart Relations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new knowledge-base of hasPart relationships, extracted from a\nlarge corpus of generic statements. Complementary to other resources available,\nit is the first which is all three of: accurate (90% precision), salient\n(covers relationships a person may mention), and has high coverage of common\nterms (approximated as within a 10 year old's vocabulary), as well as having\nseveral times more hasPart entries than in the popular ontologies ConceptNet\nand WordNet. In addition, it contains information about quantifiers, argument\nmodifiers, and links the entities to appropriate concepts in Wikipedia and\nWordNet. The knowledge base is available at https://allenai.org/data/haspartkb\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 23:34:05 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Bhakthavatsalam", "Sumithra", ""], ["Richardson", "Kyle", ""], ["Tandon", "Niket", ""], ["Clark", "Peter", ""]]}, {"id": "2006.07519", "submitter": "Kyle Dent", "authors": "Kyle Dent and Kalai Ramea", "title": "Conversational User Interfaces for Blind Knowledge Workers: A Case Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern trends in interface design for office equipment using controls on\ntouch surfaces create greater obstacles for blind and visually impaired users\nand contribute to an environment of dependency in work settings. We believe\nthat \\textit{conversational user interfaces} (CUIs) offer a reasonable\nalternative to touchscreen interactions enabling more access and most\nimportantly greater independence for blind knowledge workers. We present a case\nstudy of our work to develop a conversational user interface for accessibility\nfor multifunction printers. We also describe our approach to conversational\ninterfaces in general, which emphasizes task-based collaborative interactions\nbetween people and intelligent agents, and we detail the specifics of the\nsolution we created for multifunction printers. To guide our design, we worked\nwith a group of blind and visually impaired individuals starting with focus\ngroup sessions to ascertain the challenges our target users face in their\nprofessional lives. We followed our technology development with a user study to\nassess the solution and direct our future efforts. We present our findings and\nconclusions from the study.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 00:27:14 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 21:06:00 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Dent", "Kyle", ""], ["Ramea", "Kalai", ""]]}, {"id": "2006.07548", "submitter": "Hamed Zamani", "authors": "Helia Hashemi, Hamed Zamani, W. Bruce Croft", "title": "Guided Transformer: Leveraging Multiple External Sources for\n  Representation Learning in Conversational Search", "comments": "To appear in the Proceedings of ACM SIGIR 2020. 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asking clarifying questions in response to ambiguous or faceted queries has\nbeen recognized as a useful technique for various information retrieval\nsystems, especially conversational search systems with limited bandwidth\ninterfaces. Analyzing and generating clarifying questions have been studied\nrecently but the accurate utilization of user responses to clarifying questions\nhas been relatively less explored. In this paper, we enrich the representations\nlearned by Transformer networks using a novel attention mechanism from external\ninformation sources that weights each term in the conversation. We evaluate\nthis Guided Transformer model in a conversational search scenario that includes\nclarifying questions. In our experiments, we use two separate external sources,\nincluding the top retrieved documents and a set of different possible\nclarifying questions for the query. We implement the proposed representation\nlearning model for two downstream tasks in conversational search; document\nretrieval and next clarifying question selection. Our experiments use a public\ndataset for search clarification and demonstrate significant improvements\ncompared to competitive baselines.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 03:24:53 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Hashemi", "Helia", ""], ["Zamani", "Hamed", ""], ["Croft", "W. Bruce", ""]]}, {"id": "2006.07573", "submitter": "Xavier Marjou", "authors": "Xavier Marjou", "title": "GIPFA: Generating IPA Pronunciation from Audio", "comments": "8 pages, 2 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Transcribing spoken audio samples into International Phonetic Alphabet (IPA)\nhas long been reserved for experts. In this study, we instead examined the use\nof an Artificial Neural Network (ANN) model to automatically extract the IPA\npronunciation of a word based on its audio pronunciation, hence its name\nGenerating IPA Pronunciation From Audio (GIPFA). Based on the French Wikimedia\ndictionary, we trained our model which then correctly predicted 75% of the IPA\npronunciations tested. Interestingly, by studying inference errors, the model\nmade it possible to highlight possible errors in the dataset as well as\nidentifying the closest phonemes in French.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 06:14:11 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Marjou", "Xavier", ""]]}, {"id": "2006.07581", "submitter": "Ming Gong", "authors": "Linjun Shou, Shining Bo, Feixiang Cheng, Ming Gong, Jian Pei, Daxin\n  Jiang", "title": "Mining Implicit Relevance Feedback from User Behavior for Web Question\n  Answering", "comments": "Accepted by KDD 2020", "journal-ref": null, "doi": "10.1145/3394486.3403343", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training and refreshing a web-scale Question Answering (QA) system for a\nmulti-lingual commercial search engine often requires a huge amount of training\nexamples. One principled idea is to mine implicit relevance feedback from user\nbehavior recorded in search engine logs. All previous works on mining implicit\nrelevance feedback target at relevance of web documents rather than passages.\nDue to several unique characteristics of QA tasks, the existing user behavior\nmodels for web documents cannot be applied to infer passage relevance. In this\npaper, we make the first study to explore the correlation between user behavior\nand passage relevance, and propose a novel approach for mining training data\nfor Web QA. We conduct extensive experiments on four test datasets and the\nresults show our approach significantly improves the accuracy of passage\nranking without extra human labeled data. In practice, this work has proved\neffective to substantially reduce the human labeling cost for the QA service in\na global commercial search engine, especially for languages with low resources.\nOur techniques have been deployed in multi-language services.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 07:02:08 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 01:10:48 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Shou", "Linjun", ""], ["Bo", "Shining", ""], ["Cheng", "Feixiang", ""], ["Gong", "Ming", ""], ["Pei", "Jian", ""], ["Jiang", "Daxin", ""]]}, {"id": "2006.07637", "submitter": "Luka Chkhetiani", "authors": "Luka Chkhetiani, Levan Bejanidze", "title": "SE-MelGAN -- Speaker Agnostic Rapid Speech Enhancement", "comments": "4 pages, 1 image, 1 table, 1 page for references", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent advancement in Generative Adversarial Networks in speech synthesis\ndomain[3],[2] have shown, that it's possible to train GANs [8] in a reliable\nmanner for high quality coherent waveform generation from mel-spectograms. We\npropose that it is possible to transfer the MelGAN's [3] robustness in learning\nspeech features to speech enhancement and noise reduction domain without any\nmodel modification tasks. Our proposed method generalizes over multi-speaker\nspeech dataset and is able to robustly handle unseen background noises during\nthe inference. Also, we show that by increasing the batch size for this\nparticular approach not only yields better speech results, but generalizes over\nmulti-speaker dataset easily and leads to faster convergence. Additionally, it\noutperforms previous state of the art GAN approach for speech enhancement SEGAN\n[5] in two domains: 1. quality ; 2. speed. Proposed method runs at more than\n100x faster than realtime on GPU and more than 2x faster than real time on CPU\nwithout any hardware optimization tasks, right at the speed of MelGAN [3].\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 13:26:37 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Chkhetiani", "Luka", ""], ["Bejanidze", "Levan", ""]]}, {"id": "2006.07667", "submitter": "Valerio Ficcadenti", "authors": "Valerio Ficcadenti, Roy Cerqueti, Marcel Ausloos, Gurjeet Dhesi", "title": "Words ranking and Hirsch index for identifying the core of the hapaxes\n  in political texts", "comments": null, "journal-ref": null, "doi": "10.1016/j.joi.2020.101054", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with a quantitative analysis of the content of official\npolitical speeches. We study a set of about one thousand talks pronounced by\nthe US Presidents, ranging from Washington to Trump. In particular, we search\nfor the relevance of the rare words, i.e. those said only once in each speech\n-- the so-called hapaxes. We implement a rank-size procedure of Zipf-Mandelbrot\ntype for discussing the hapaxes' frequencies regularity over the overall set of\nspeeches. Starting from the obtained rank-size law, we define and detect the\ncore of the hapaxes set by means of a procedure based on an Hirsch index\nvariant. We discuss the resulting list of words in the light of the overall US\nPresidents' speeches. We further show that this core of hapaxes itself can be\nwell fitted through a Zipf-Mandelbrot law and that contains elements producing\ndeviations at the low ranks between scatter plots and fitted curve -- the\nso-called king and vice-roy effect. Some socio-political insights are derived\nfrom the obtained findings about the US Presidents messages.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 15:48:15 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Ficcadenti", "Valerio", ""], ["Cerqueti", "Roy", ""], ["Ausloos", "Marcel", ""], ["Dhesi", "Gurjeet", ""]]}, {"id": "2006.07698", "submitter": "Abrhalei Frezghi Tela", "authors": "Abrhalei Tela, Abraham Woubie, and Ville Hautamaki", "title": "Transferring Monolingual Model to Low-Resource Language: The Case of\n  Tigrinya", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In recent years, transformer models have achieved great success in natural\nlanguage processing (NLP) tasks. Most of the current state-of-the-art NLP\nresults are achieved by using monolingual transformer models, where the model\nis pre-trained using a single language unlabelled text corpus. Then, the model\nis fine-tuned to the specific downstream task. However, the cost of\npre-training a new transformer model is high for most languages. In this work,\nwe propose a cost-effective transfer learning method to adopt a strong source\nlanguage model, trained from a large monolingual corpus to a low-resource\nlanguage. Thus, using XLNet language model, we demonstrate competitive\nperformance with mBERT and a pre-trained target language model on the\ncross-lingual sentiment (CLS) dataset and on a new sentiment analysis dataset\nfor low-resourced language Tigrinya. With only 10k examples of the given\nTigrinya sentiment analysis dataset, English XLNet has achieved 78.88% F1-Score\noutperforming BERT and mBERT by 10% and 7%, respectively. More interestingly,\nfine-tuning (English) XLNet model on the CLS dataset has promising results\ncompared to mBERT and even outperformed mBERT for one dataset of the Japanese\nlanguage.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 18:53:22 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 15:00:02 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Tela", "Abrhalei", ""], ["Woubie", "Abraham", ""], ["Hautamaki", "Ville", ""]]}, {"id": "2006.07732", "submitter": "Kyle Dent", "authors": "Kyle Dent and Sharoda Paul", "title": "Through the Twitter Glass: Detecting Questions in Micro-Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a separate study, we were interested in understanding people's Q&A habits\non Twitter. Finding questions within Twitter turned out to be a difficult\nchallenge, so we considered applying some traditional NLP approaches to the\nproblem. On the one hand, Twitter is full of idiosyncrasies, which make\nprocessing it difficult. On the other, it is very restricted in length and\ntends to employ simple syntactic constructions, which could help the\nperformance of NLP processing. In order to find out the viability of NLP and\nTwitter, we built a pipeline of tools to work specifically with Twitter input\nfor the task of finding questions in tweets. This work is still preliminary,\nbut in this paper we discuss the techniques we used and the lessons we learned.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 22:34:01 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Dent", "Kyle", ""], ["Paul", "Sharoda", ""]]}, {"id": "2006.07804", "submitter": "Duc-Vu Nguyen", "authors": "Duc-Vu Nguyen, Dang Van Thin, Kiet Van Nguyen, Ngan Luu-Thuy Nguyen", "title": "Vietnamese Word Segmentation with SVM: Ambiguity Reduction and Suffix\n  Capture", "comments": "In Proceedings of the 16th International Conference of the Pacific\n  Association for Computational Linguistics (PACLING 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we approach Vietnamese word segmentation as a binary\nclassification by using the Support Vector Machine classifier. We inherit\nfeatures from prior works such as n-gram of syllables, n-gram of syllable\ntypes, and checking conjunction of adjacent syllables in the dictionary. We\npropose two novel ways to feature extraction, one to reduce the overlap\nambiguity and the other to increase the ability to predict unknown words\ncontaining suffixes. Different from UETsegmenter and RDRsegmenter, two\nstate-of-the-art Vietnamese word segmentation methods, we do not employ the\nlongest matching algorithm as an initial processing step or any post-processing\ntechnique. According to experimental results on benchmark Vietnamese datasets,\nour proposed method obtained a better F1-score than the prior state-of-the-art\nmethods UETsegmenter, and RDRsegmenter.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 05:19:46 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Nguyen", "Duc-Vu", ""], ["Van Thin", "Dang", ""], ["Van Nguyen", "Kiet", ""], ["Nguyen", "Ngan Luu-Thuy", ""]]}, {"id": "2006.07849", "submitter": "Mike Thelwall Prof", "authors": "Mike Thelwall", "title": "Pot, kettle: Nonliteral titles aren't (natural) science", "comments": "Quantitative Science Studies, to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers may be tempted to attract attention through poetic titles for\ntheir publications, but would this be mistaken in some fields? Whilst poetic\ntitles are known to be common in medicine, it is not clear whether the practice\nis widespread elsewhere. This article investigates the prevalence of poetic\nexpressions in journal article titles 1996-2019 in 3.3 million articles from\nall 27 Scopus broad fields. Expressions were identified by manually checking\nall phrases with at least 5 words that occurred at least 25 times, finding 149\nstock phrases, idioms, sayings, literary allusions, film names and song titles\nor lyrics. The expressions found are most common in the social sciences and the\nhumanities. They are also relatively common in medicine, but almost absent from\nengineering and the natural and formal sciences. The differences may reflect\nthe less hierarchical and more varied nature of the social sciences and\nhumanities, where interesting titles may attract an audience. In engineering,\nnatural science and formal science fields, authors should take extra care with\npoetic expressions, in case their choice is judged inappropriate. This includes\ninterdisciplinary research overlapping these areas. Conversely, reviewers of\ninterdisciplinary research involving the social sciences should be more\ntolerant of poetic license.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 09:32:13 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Thelwall", "Mike", ""]]}, {"id": "2006.07853", "submitter": "Danilo Vasconcellos  Vargas", "authors": "Danilo Vasconcellos Vargas and Toshitake Asabuki", "title": "Continual General Chunking Problem and SyncMap", "comments": null, "journal-ref": "AAAI2021", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans possess an inherent ability to chunk sequences into their constituent\nparts. In fact, this ability is thought to bootstrap language skills and\nlearning of image patterns which might be a key to a more animal-like type of\nintelligence. Here, we propose a continual generalization of the chunking\nproblem (an unsupervised problem), encompassing fixed and probabilistic chunks,\ndiscovery of temporal and causal structures and their continual variations.\nAdditionally, we propose an algorithm called SyncMap that can learn and adapt\nto changes in the problem by creating a dynamic map which preserves the\ncorrelation between variables. Results of SyncMap suggest that the proposed\nalgorithm learn near optimal solutions, despite the presence of many types of\nstructures and their continual variation. When compared to Word2vec, PARSER and\nMRIL, SyncMap surpasses or ties with the best algorithm on $66\\%$ of the\nscenarios while being the second best in the remaining $34\\%$. SyncMap's\nmodel-free simple dynamics and the absence of loss functions reveal that,\nperhaps surprisingly, much can be done with self-organization alone. Code\navailable at https://github.com/zweifel/SyncMap.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 09:39:56 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 02:00:10 GMT"}, {"version": "v3", "created": "Wed, 3 Feb 2021 07:17:42 GMT"}, {"version": "v4", "created": "Mon, 5 Apr 2021 09:40:22 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Vargas", "Danilo Vasconcellos", ""], ["Asabuki", "Toshitake", ""]]}, {"id": "2006.07887", "submitter": "Lushi Chen", "authors": "Lucia Lushi Chen, Walid Magdy, Heather Whalley, Maria Wolters", "title": "Examining the Role of Mood Patterns in Predicting Self-Reported\n  Depressive symptoms", "comments": "Accepted at The Web Science Conference 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Depression is the leading cause of disability worldwide. Initial efforts to\ndetect depression signals from social media posts have shown promising results.\nGiven the high internal validity, results from such analyses are potentially\nbeneficial to clinical judgment. The existing models for automatic detection of\ndepressive symptoms learn proxy diagnostic signals from social media data, such\nas help-seeking behavior for mental health or medication names. However, in\nreality, individuals with depression typically experience depressed mood, loss\nof pleasure nearly in all the activities, feeling of worthlessness or guilt,\nand diminished ability to think. Therefore, a lot of the proxy signals used in\nthese models lack the theoretical underpinnings for depressive symptoms. It is\nalso reported that social media posts from many patients in the clinical\nsetting do not contain these signals. Based on this research gap, we propose to\nmonitor a type of signal that is well-established as a class of symptoms in\naffective disorders -- mood. The mood is an experience of feeling that can last\nfor hours, days, or even weeks. In this work, we attempt to enrich current\ntechnology for detecting symptoms of potential depression by constructing a\n'mood profile' for social media users.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 12:48:43 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Chen", "Lucia Lushi", ""], ["Magdy", "Walid", ""], ["Whalley", "Heather", ""], ["Wolters", "Maria", ""]]}, {"id": "2006.07890", "submitter": "Matej Ul\\v{c}ar", "authors": "Matej Ul\\v{c}ar and Marko Robnik-\\v{S}ikonja", "title": "FinEst BERT and CroSloEngual BERT: less is more in multilingual models", "comments": "10 pages, accepted at TSD 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Large pretrained masked language models have become state-of-the-art\nsolutions for many NLP problems. The research has been mostly focused on\nEnglish language, though. While massively multilingual models exist, studies\nhave shown that monolingual models produce much better results. We train two\ntrilingual BERT-like models, one for Finnish, Estonian, and English, the other\nfor Croatian, Slovenian, and English. We evaluate their performance on several\ndownstream tasks, NER, POS-tagging, and dependency parsing, using the\nmultilingual BERT and XLM-R as baselines. The newly created FinEst BERT and\nCroSloEngual BERT improve the results on all tasks in most monolingual and\ncross-lingual situations\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 12:54:01 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Ul\u010dar", "Matej", ""], ["Robnik-\u0160ikonja", "Marko", ""]]}, {"id": "2006.07909", "submitter": "Selvan Sunitha Ravi", "authors": "Anumeha Agrawal, Rosa Anil George, Selvan Sunitha Ravi, Sowmya Kamath\n  S, Anand Kumar M", "title": "Leveraging Multimodal Behavioral Analytics for Automated Job Interview\n  Performance Assessment and Feedback", "comments": "9 pages, ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Behavioral cues play a significant part in human communication and cognitive\nperception. In most professional domains, employee recruitment policies are\nframed such that both professional skills and personality traits are adequately\nassessed. Hiring interviews are structured to evaluate expansively a potential\nemployee's suitability for the position - their professional qualifications,\ninterpersonal skills, ability to perform in critical and stressful situations,\nin the presence of time and resource constraints, etc. Therefore, candidates\nneed to be aware of their positive and negative attributes and be mindful of\nbehavioral cues that might have adverse effects on their success. We propose a\nmultimodal analytical framework that analyzes the candidate in an interview\nscenario and provides feedback for predefined labels such as engagement,\nspeaking rate, eye contact, etc. We perform a comprehensive analysis that\nincludes the interviewee's facial expressions, speech, and prosodic\ninformation, using the video, audio, and text transcripts obtained from the\nrecorded interview. We use these multimodal data sources to construct a\ncomposite representation, which is used for training machine learning\nclassifiers to predict the class labels. Such analysis is then used to provide\nconstructive feedback to the interviewee for their behavioral cues and body\nlanguage. Experimental validation showed that the proposed methodology achieved\npromising results.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 14:20:42 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 14:18:05 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Agrawal", "Anumeha", ""], ["George", "Rosa Anil", ""], ["Ravi", "Selvan Sunitha", ""], ["S", "Sowmya Kamath", ""], ["M", "Anand Kumar", ""]]}, {"id": "2006.07926", "submitter": "Chen Zhang", "authors": "Chen Zhang, Xu Tan, Yi Ren, Tao Qin, Kejun Zhang, Tie-Yan Liu", "title": "UWSpeech: Speech to Speech Translation for Unwritten Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing speech to speech translation systems heavily rely on the text of\ntarget language: they usually translate source language either to target text\nand then synthesize target speech from text, or directly to target speech with\ntarget text for auxiliary training. However, those methods cannot be applied to\nunwritten target languages, which have no written text or phoneme available. In\nthis paper, we develop a translation system for unwritten languages, named as\nUWSpeech, which converts target unwritten speech into discrete tokens with a\nconverter, and then translates source-language speech into target discrete\ntokens with a translator, and finally synthesizes target speech from target\ndiscrete tokens with an inverter. We propose a method called XL-VAE, which\nenhances vector quantized variational autoencoder (VQ-VAE) with cross-lingual\n(XL) speech recognition, to train the converter and inverter of UWSpeech\njointly. Experiments on Fisher Spanish-English conversation translation dataset\nshow that UWSpeech outperforms direct translation and VQ-VAE baseline by about\n16 and 10 BLEU points respectively, which demonstrate the advantages and\npotentials of UWSpeech.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 15:22:12 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 12:39:06 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Zhang", "Chen", ""], ["Tan", "Xu", ""], ["Ren", "Yi", ""], ["Qin", "Tao", ""], ["Zhang", "Kejun", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2006.07968", "submitter": "Christopher Potts", "authors": "Atticus Geiger, Alexandra Carstensen, Michael C. Frank, and\n  Christopher Potts", "title": "Relational reasoning and generalization using non-symbolic neural\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Humans have a remarkable capacity to reason about abstract relational\nstructures, an ability that may support some of the most impressive,\nhuman-unique cognitive feats. Because equality (or identity) is a simple and\nubiquitous relational operator, equality reasoning has been a key case study\nfor the broader question of abstract relational reasoning. This paper revisits\nthe question of whether equality can be learned by neural networks that do not\nencode explicit symbolic structure. Earlier work arrived at a negative answer\nto this question, but that result holds only for a particular class of\nhand-crafted feature representations. In our experiments, we assess\nout-of-sample generalization of equality using both arbitrary representations\nand representations that have been pretrained on separate tasks to imbue them\nwith abstract structure. In this setting, even simple neural networks are able\nto learn basic equality with relatively little training data. In a second case\nstudy, we show that sequential equality problems (learning ABA sequences) can\nbe solved with only positive training instances. Finally, we consider a more\ncomplex, hierarchical equality problem, but this requires vastly more data.\nHowever, using a pretrained equality network as a modular component of this\nlarger task leads to good performance with no task-specific training. Overall,\nthese findings indicate that neural models are able to solve equality-based\nreasoning tasks, suggesting that essential aspects of symbolic reasoning can\nemerge from data-driven, non-symbolic learning processes.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 18:25:42 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 04:34:22 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Geiger", "Atticus", ""], ["Carstensen", "Alexandra", ""], ["Frank", "Michael C.", ""], ["Potts", "Christopher", ""]]}, {"id": "2006.08097", "submitter": "Yi Yang", "authors": "Yi Yang, Mark Christopher Siy UY, Allen Huang", "title": "FinBERT: A Pretrained Language Model for Financial Communications", "comments": "https://github.com/yya518/FinBERT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual pretrained language models, such as BERT (Devlin et al., 2019),\nhave made significant breakthrough in various NLP tasks by training on large\nscale of unlabeled text re-sources.Financial sector also accumulates large\namount of financial communication text.However, there is no pretrained finance\nspecific language models available. In this work,we address the need by\npretraining a financial domain specific BERT models, FinBERT, using a large\nscale of financial communication corpora. Experiments on three financial\nsentiment classification tasks confirm the advantage of FinBERT over generic\ndomain BERT model. The code and pretrained models are available at\nhttps://github.com/yya518/FinBERT. We hope this will be useful for\npractitioners and researchers working on financial NLP tasks.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 02:51:06 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 02:50:04 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Yang", "Yi", ""], ["UY", "Mark Christopher Siy", ""], ["Huang", "Allen", ""]]}, {"id": "2006.08101", "submitter": "Daya Guo", "authors": "Daya Guo, Duyu Tang, Nan Duan, Jian Yin, Daxin Jiang and Ming Zhou", "title": "Evidence-Aware Inferential Text Generation with Vector Quantised\n  Variational AutoEncoder", "comments": "Accepted by ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating inferential texts about an event in different perspectives\nrequires reasoning over different contexts that the event occurs. Existing\nworks usually ignore the context that is not explicitly provided, resulting in\na context-independent semantic representation that struggles to support the\ngeneration. To address this, we propose an approach that automatically finds\nevidence for an event from a large text corpus, and leverages the evidence to\nguide the generation of inferential texts. Our approach works in an\nencoder-decoder manner and is equipped with a Vector Quantised-Variational\nAutoencoder, where the encoder outputs representations from a distribution over\ndiscrete variables. Such discrete representations enable automatically\nselecting relevant evidence, which not only facilitates evidence-aware\ngeneration, but also provides a natural way to uncover rationales behind the\ngeneration. Our approach provides state-of-the-art performance on both\nEvent2Mind and ATOMIC datasets. More importantly, we find that with discrete\nrepresentations, our model selectively uses evidence to generate different\ninferential texts.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 02:59:52 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Guo", "Daya", ""], ["Tang", "Duyu", ""], ["Duan", "Nan", ""], ["Yin", "Jian", ""], ["Jiang", "Daxin", ""], ["Zhou", "Ming", ""]]}, {"id": "2006.08185", "submitter": "Sachin Pawar", "authors": "Sachin Pawar, Pushpak Bhattacharyya, Girish K. Palshikar", "title": "Extracting N-ary Cross-sentence Relations using Constrained Subsequence\n  Kernel", "comments": "Appeared in 20th International Conference on Computational\n  Linguistics and Intelligent Text Processing (CICLing 2019),\n  https://www.cicling.org/2019/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the past work in relation extraction deals with relations occurring\nwithin a sentence and having only two entity arguments. We propose a new\nformulation of the relation extraction task where the relations are more\ngeneral than intra-sentence relations in the sense that they may span multiple\nsentences and may have more than two arguments. Moreover, the relations are\nmore specific than corpus-level relations in the sense that their scope is\nlimited only within a document and not valid globally throughout the corpus. We\npropose a novel sequence representation to characterize instances of such\nrelations. We then explore various classifiers whose features are derived from\nthis sequence representation. For SVM classifier, we design a Constrained\nSubsequence Kernel which is a variant of Generalized Subsequence Kernel. We\nevaluate our approach on three datasets across two domains: biomedical and\ngeneral domain.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 07:23:58 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Pawar", "Sachin", ""], ["Bhattacharyya", "Pushpak", ""], ["Palshikar", "Girish K.", ""]]}, {"id": "2006.08274", "submitter": "Aleksandr Laptev", "authors": "Andrei Andrusenko, Aleksandr Laptev, Ivan Medennikov", "title": "Exploration of End-to-End ASR for OpenSTT -- Russian Open Speech-to-Text\n  Dataset", "comments": "Accepted by SPECOM 2020", "journal-ref": null, "doi": "10.1007/978-3-030-60276-5_4", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an exploration of end-to-end automatic speech recognition\nsystems (ASR) for the largest open-source Russian language data set -- OpenSTT.\nWe evaluate different existing end-to-end approaches such as joint\nCTC/Attention, RNN-Transducer, and Transformer. All of them are compared with\nthe strong hybrid ASR system based on LF-MMI TDNN-F acoustic model. For the\nthree available validation sets (phone calls, YouTube, and books), our best\nend-to-end model achieves word error rate (WER) of 34.8%, 19.1%, and 18.1%,\nrespectively. Under the same conditions, the hybridASR system demonstrates\n33.5%, 20.9%, and 18.6% WER.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 10:35:31 GMT"}, {"version": "v2", "created": "Sun, 26 Jul 2020 20:21:09 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Andrusenko", "Andrei", ""], ["Laptev", "Aleksandr", ""], ["Medennikov", "Ivan", ""]]}, {"id": "2006.08281", "submitter": "Tomasz Dwojak", "authors": "Tomasz Dwojak and Micha{\\l} Pietruszka and {\\L}ukasz Borchmann and\n  Filip Grali\\'nski and Jakub Ch{\\l}\\k{e}dowski", "title": "On the Multi-Property Extraction and Beyond", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the Dual-source Transformer architecture on the\nWikiReading information extraction and machine reading comprehension dataset.\nThe proposed model outperforms the current state-of-the-art by a large margin.\nNext, we introduce WikiReading Recycled - a newly developed public dataset,\nsupporting the task of multiple property extraction. It keeps the spirit of the\noriginal WikiReading but does not inherit the identified disadvantages of its\npredecessor.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 11:07:52 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Dwojak", "Tomasz", ""], ["Pietruszka", "Micha\u0142", ""], ["Borchmann", "\u0141ukasz", ""], ["Grali\u0144ski", "Filip", ""], ["Ch\u0142\u0119dowski", "Jakub", ""]]}, {"id": "2006.08297", "submitter": "Yuying Ye", "authors": "Yuying Ye, Antonio Toral", "title": "Fine-grained Human Evaluation of Transformer and Recurrent Approaches to\n  Neural Machine Translation for English-to-Chinese", "comments": "Accepted at the 22nd Annual Conference of the European Association\n  for Machine Translation (EAMT 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research presents a fine-grained human evaluation to compare the\nTransformer and recurrent approaches to neural machine translation (MT), on the\ntranslation direction English-to-Chinese. To this end, we develop an error\ntaxonomy compliant with the Multidimensional Quality Metrics (MQM) framework\nthat is customised to the relevant phenomena of this translation direction. We\nthen conduct an error annotation using this customised error taxonomy on the\noutput of state-of-the-art recurrent- and Transformer-based MT systems on a\nsubset of WMT2019's news test set. The resulting annotation shows that,\ncompared to the best recurrent system, the best Transformer system results in a\n31% reduction of the total number of errors and it produced significantly less\nerrors in 10 out of 22 error categories. We also note that two of the systems\nevaluated do not produce any error for a category that was relevant for this\ntranslation direction prior to the advent of NMT systems: Chinese classifiers.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 11:47:00 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Ye", "Yuying", ""], ["Toral", "Antonio", ""]]}, {"id": "2006.08328", "submitter": "Ioannis Mollas", "authors": "Ioannis Mollas, Zoe Chrysopoulou, Stamatis Karlos, Grigorios Tsoumakas", "title": "ETHOS: an Online Hate Speech Detection Dataset", "comments": "16 Pages, 3 Figures, 9 Tables, Submitted to the special issue on\n  \"Intelligent Systems for Safer Social Media\" of Complex & Intelligent Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online hate speech is a recent problem in our society that is rising at a\nsteady pace by leveraging the vulnerabilities of the corresponding regimes that\ncharacterise most social media platforms. This phenomenon is primarily fostered\nby offensive comments, either during user interaction or in the form of a\nposted multimedia context. Nowadays, giant corporations own platforms where\nmillions of users log in every day, and protection from exposure to similar\nphenomena appears to be necessary in order to comply with the corresponding\nlegislation and maintain a high level of service quality. A robust and reliable\nsystem for detecting and preventing the uploading of relevant content will have\na significant impact on our digitally interconnected society. Several aspects\nof our daily lives are undeniably linked to our social profiles, making us\nvulnerable to abusive behaviours. As a result, the lack of accurate hate speech\ndetection mechanisms would severely degrade the overall user experience,\nalthough its erroneous operation would pose many ethical concerns. In this\npaper, we present 'ETHOS', a textual dataset with two variants: binary and\nmulti-label, based on YouTube and Reddit comments validated using the\nFigure-Eight crowdsourcing platform. Furthermore, we present the annotation\nprotocol used to create this dataset: an active sampling procedure for\nbalancing our data in relation to the various aspects defined. Our key\nassumption is that, even gaining a small amount of labelled data from such a\ntime-consuming process, we can guarantee hate speech occurrences in the\nexamined material.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 08:59:57 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 07:25:14 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Mollas", "Ioannis", ""], ["Chrysopoulou", "Zoe", ""], ["Karlos", "Stamatis", ""], ["Tsoumakas", "Grigorios", ""]]}, {"id": "2006.08331", "submitter": "Abdelrhman Saleh", "authors": "Abdelrhman Saleh, Tovly Deutsch, Stephen Casper, Yonatan Belinkov,\n  Stuart Shieber", "title": "Probing Neural Dialog Models for Conversational Understanding", "comments": null, "journal-ref": null, "doi": "10.18653/v1/2020.nlp4convai-1.15", "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The predominant approach to open-domain dialog generation relies on\nend-to-end training of neural models on chat datasets. However, this approach\nprovides little insight as to what these models learn (or do not learn) about\nengaging in dialog. In this study, we analyze the internal representations\nlearned by neural open-domain dialog systems and evaluate the quality of these\nrepresentations for learning basic conversational skills. Our results suggest\nthat standard open-domain dialog systems struggle with answering questions,\ninferring contradiction, and determining the topic of conversation, among other\ntasks. We also find that the dyadic, turn-taking nature of dialog is not fully\nleveraged by these models. By exploring these limitations, we highlight the\nneed for additional research into architectures and training methods that can\nbetter capture high-level information about dialog.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 17:32:00 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Saleh", "Abdelrhman", ""], ["Deutsch", "Tovly", ""], ["Casper", "Stephen", ""], ["Belinkov", "Yonatan", ""], ["Shieber", "Stuart", ""]]}, {"id": "2006.08332", "submitter": "Vineet Sahula", "authors": "Rashi Kumar and Piyush Jha and Vineet Sahula", "title": "An Augmented Translation Technique for low Resource language pair:\n  Sanskrit to Hindi translation", "comments": null, "journal-ref": "Proceedings of the 2019 2nd International Conference on\n  Algorithms, Computing and Artificial Intelligence, December 2019, pp 377 to\n  383", "doi": "10.1145/3377713.3377774", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) is an ongoing technique for Machine\nTranslation (MT) using enormous artificial neural network. It has exhibited\npromising outcomes and has shown incredible potential in solving challenging\nmachine translation exercises. One such exercise is the best approach to\nfurnish great MT to language sets with a little preparing information. In this\nwork, Zero Shot Translation (ZST) is inspected for a low resource language\npair. By working on high resource language pairs for which benchmarks are\navailable, namely Spanish to Portuguese, and training on data sets\n(Spanish-English and English-Portuguese) we prepare a state of proof for ZST\nsystem that gives appropriate results on the available data. Subsequently the\nsame architecture is tested for Sanskrit to Hindi translation for which data is\nsparse, by training the model on English-Hindi and Sanskrit-English language\npairs. In order to prepare and decipher with ZST system, we broaden the\npreparation and interpretation pipelines of NMT seq2seq model in tensorflow,\nincorporating ZST features. Dimensionality reduction of word embedding is\nperformed to reduce the memory usage for data storage and to achieve a faster\ntraining and translation cycles. In this work existing helpful technology has\nbeen utilized in an imaginative manner to execute our NLP issue of Sanskrit to\nHindi translation. A Sanskrit-Hindi parallel corpus of 300 is constructed for\ntesting. The data required for the construction of parallel corpus has been\ntaken from the telecasted news, published on Department of Public Information,\nstate government of Madhya Pradesh, India website.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 17:01:55 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Kumar", "Rashi", ""], ["Jha", "Piyush", ""], ["Sahula", "Vineet", ""]]}, {"id": "2006.08334", "submitter": "David Hin", "authors": "David Hin", "title": "StackOverflow vs Kaggle: A Study of Developer Discussions About Data\n  Science", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software developers are increasingly required to understand fundamental Data\nscience (DS) concepts. Recently, the presence of machine learning (ML) and deep\nlearning (DL) has dramatically increased in the development of user\napplications, whether they are leveraged through frameworks or implemented from\nscratch. These topics attract much discussion on online platforms. This paper\nconducts large-scale qualitative and quantitative experiments to study the\ncharacteristics of 197836 posts from StackOverflow and Kaggle. Latent Dirichlet\nAllocation topic modelling is used to extract twenty-four DS discussion topics.\nThe main findings include that TensorFlow-related topics were most prevalent in\nStackOverflow, while meta discussion topics were the prevalent ones on Kaggle.\nStackOverflow tends to include lower-level troubleshooting, while Kaggle\nfocuses on practicality and optimising leaderboard performance. In addition,\nacross both communities, DS discussion is increasing at a dramatic rate. While\nTensorFlow discussion on StackOverflow is slowing, interest in Keras is rising.\nFinally, ensemble algorithms are the most mentioned ML/DL algorithms in Kaggle\nbut are rarely discussed on StackOverflow. These findings can help educators\nand researchers to more effectively tailor and prioritise efforts in\nresearching and communicating DS concepts towards different developer\ncommunities.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 06:51:11 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Hin", "David", ""]]}, {"id": "2006.08335", "submitter": "Bofan Xue", "authors": "Bofan Xue, David Chan, John Canny", "title": "A Dataset and Benchmarks for Multimedia Social Analysis", "comments": "Published as a workshop paper at \"Multimodality Learning\" (CVPR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new publicly available dataset with the goal of advancing\nmulti-modality learning by offering vision and language data within the same\ncontext. This is achieved by obtaining data from a social media website with\nposts containing multiple paired images/videos and text, along with comment\ntrees containing images/videos and/or text. With a total of 677k posts, 2.9\nmillion post images, 488k post videos, 1.4 million comment images, 4.6 million\ncomment videos, and 96.9 million comments, data from different modalities can\nbe jointly used to improve performances for a variety of tasks such as image\ncaptioning, image classification, next frame prediction, sentiment analysis,\nand language modeling. We present a wide range of statistics for our dataset.\nFinally, we provide baseline performance analysis for one of the regression\ntasks using pre-trained models and several fully connected networks.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 11:33:01 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Xue", "Bofan", ""], ["Chan", "David", ""], ["Canny", "John", ""]]}, {"id": "2006.08336", "submitter": "Danai Xezonaki", "authors": "D. Xezonaki, G. Paraskevopoulos, A. Potamianos, S. Narayanan", "title": "Affective Conditioning on Hierarchical Networks applied to Depression\n  Detection from Transcribed Clinical Interviews", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a machine learning model for depression detection\nfrom transcribed clinical interviews. Depression is a mental disorder that\nimpacts not only the subject's mood but also the use of language. To this end\nwe use a Hierarchical Attention Network to classify interviews of depressed\nsubjects. We augment the attention layer of our model with a conditioning\nmechanism on linguistic features, extracted from affective lexica. Our analysis\nshows that individuals diagnosed with depression use affective language to a\ngreater extent than not-depressed. Our experiments show that external affective\ninformation improves the performance of the proposed architecture in the\nGeneral Psychotherapy Corpus and the DAIC-WoZ 2017 depression datasets,\nachieving state-of-the-art 71.6 and 68.6 F1 scores respectively.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 20:55:22 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Xezonaki", "D.", ""], ["Paraskevopoulos", "G.", ""], ["Potamianos", "A.", ""], ["Narayanan", "S.", ""]]}, {"id": "2006.08337", "submitter": "Jinfeng Xiao", "authors": "Jinfeng Xiao, Lidan Wang, Franck Dernoncourt, Trung Bui, Tong Sun,\n  Jiawei Han", "title": "Open-Domain Question Answering with Pre-Constructed Question Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open-domain question answering aims at solving the task of locating the\nanswers to user-generated questions in massive collections of documents. There\nare two families of solutions available: retriever-readers, and\nknowledge-graph-based approaches. A retriever-reader usually first uses\ninformation retrieval methods like TF-IDF to locate some documents or\nparagraphs that are likely to be relevant to the question, and then feeds the\nretrieved text to a neural network reader to extract the answer. Alternatively,\nknowledge graphs can be constructed from the corpus and be queried against to\nanswer user questions. We propose a novel algorithm with a reader-retriever\nstructure that differs from both families. Our reader-retriever first uses an\noffline reader to read the corpus and generate collections of all answerable\nquestions associated with their answers, and then uses an online retriever to\nrespond to user queries by searching the pre-constructed question spaces for\nanswers that are most likely to be asked in the given way. We further combine\nretriever-reader and reader-retriever results into one single answer by\nexamining the consistency between the two components. We claim that our\nalgorithm solves some bottlenecks in existing work, and demonstrate that it\nachieves superior accuracy on real-world datasets.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 04:31:09 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 02:10:07 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Xiao", "Jinfeng", ""], ["Wang", "Lidan", ""], ["Dernoncourt", "Franck", ""], ["Bui", "Trung", ""], ["Sun", "Tong", ""], ["Han", "Jiawei", ""]]}, {"id": "2006.08338", "submitter": "Chaoran Cheng", "authors": "Chaoran Cheng, Fei Tan, Zhi Wei", "title": "DeepVar: An End-to-End Deep Learning Approach for Genomic Variant\n  Recognition in Biomedical Literature", "comments": "accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of Named Entity Recognition (NER) on biomedical\nscientific literature, and more specifically the genomic variants recognition\nin this work. Significant success has been achieved for NER on canonical tasks\nin recent years where large data sets are generally available. However, it\nremains a challenging problem on many domain-specific areas, especially the\ndomains where only small gold annotations can be obtained. In addition, genomic\nvariant entities exhibit diverse linguistic heterogeneity, differing much from\nthose that have been characterized in existing canonical NER tasks. The\nstate-of-the-art machine learning approaches in such tasks heavily rely on\narduous feature engineering to characterize those unique patterns. In this\nwork, we present the first successful end-to-end deep learning approach to\nbridge the gap between generic NER algorithms and low-resource applications\nthrough genomic variants recognition. Our proposed model can result in\npromising performance without any hand-crafted features or post-processing\nrules. Our extensive experiments and results may shed light on other similar\nlow-resource NER applications.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 04:39:34 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Cheng", "Chaoran", ""], ["Tan", "Fei", ""], ["Wei", "Zhi", ""]]}, {"id": "2006.08339", "submitter": "Zhongliang Yang", "authors": "Zhongliang Yang, Baitao Gong, Yamin Li, Jinshuai Yang, Zhiwen Hu,\n  Yongfeng Huang", "title": "Graph-Stega: Semantic Controllable Steganographic Text Generation Guided\n  by Knowledge Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the existing text generative steganographic methods are based on\ncoding the conditional probability distribution of each word during the\ngeneration process, and then selecting specific words according to the secret\ninformation, so as to achieve information hiding. Such methods have their\nlimitations which may bring potential security risks. Firstly, with the\nincrease of embedding rate, these models will choose words with lower\nconditional probability, which will reduce the quality of the generated\nsteganographic texts; secondly, they can not control the semantic expression of\nthe final generated steganographic text. This paper proposes a new text\ngenerative steganography method which is quietly different from the existing\nmodels. We use a Knowledge Graph (KG) to guide the generation of steganographic\nsentences. On the one hand, we hide the secret information by coding the path\nin the knowledge graph, but not the conditional probability of each generated\nword; on the other hand, we can control the semantic expression of the\ngenerated steganographic text to a certain extent. The experimental results\nshow that the proposed model can guarantee both the quality of the generated\ntext and its semantic expression, which is a supplement and improvement to the\ncurrent text generation steganography.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 06:53:21 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Yang", "Zhongliang", ""], ["Gong", "Baitao", ""], ["Li", "Yamin", ""], ["Yang", "Jinshuai", ""], ["Hu", "Zhiwen", ""], ["Huang", "Yongfeng", ""]]}, {"id": "2006.08342", "submitter": "Lukas Muttenthaler", "authors": "Lukas Muttenthaler", "title": "Subjective Question Answering: Deciphering the inner workings of\n  Transformers in the realm of subjectivity", "comments": "80 pages, Master's thesis in Computer Science (CS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding subjectivity demands reasoning skills beyond the realm of\ncommon knowledge. It requires a machine learning model to process sentiment and\nto perform opinion mining. In this work, I've exploited a recently released\ndataset for span-selection Question Answering, namely SubjQA. SubjQA is the\nfirst QA dataset that contains questions that ask for subjective opinions\ncorresponding to review paragraphs from six different domains. Hence, to answer\nthese subjective questions, a learner must extract opinions and process\nsentiment for various domains, and additionally, align the knowledge extracted\nfrom a paragraph with the natural language utterances in the corresponding\nquestion, which together enhance the difficulty of a QA task. The primary goal\nof this thesis was to investigate the inner workings (i.e., latent\nrepresentations) of a Transformer-based architecture to contribute to a better\nunderstanding of these not yet well understood \"black-box\" models.\nTransformer's hidden representations, concerning the true answer span, are\nclustered more closely in vector space than those representations corresponding\nto erroneous predictions. This observation holds across the top three\nTransformer layers for both objective and subjective questions and generally\nincreases as a function of layer dimensions. Moreover, the probability to\nachieve a high cosine similarity among hidden representations in latent space\nconcerning the true answer span tokens is significantly higher for correct\ncompared to incorrect answer span predictions. These results have decisive\nimplications for down-stream applications, where it is crucial to know about\nwhy a neural network made mistakes, and in which point, in space and time the\nmistake has happened (e.g., to automatically predict correctness of an answer\nspan prediction without the necessity of labeled data).\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 13:48:14 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 07:47:52 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Muttenthaler", "Lukas", ""]]}, {"id": "2006.08344", "submitter": "Tim Z. Xiao", "authors": "Tim Z. Xiao, Aidan N. Gomez, Yarin Gal", "title": "Wat zei je? Detecting Out-of-Distribution Translations with Variational\n  Transformers", "comments": "19 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We detect out-of-training-distribution sentences in Neural Machine\nTranslation using the Bayesian Deep Learning equivalent of Transformer models.\nFor this we develop a new measure of uncertainty designed specifically for long\nsequences of discrete random variables -- i.e. words in the output sentence.\nOur new measure of uncertainty solves a major intractability in the naive\napplication of existing approaches on long sentences. We use our new measure on\na Transformer model trained with dropout approximate inference. On the task of\nGerman-English translation using WMT13 and Europarl, we show that with dropout\nuncertainty our measure is able to identify when Dutch source sentences,\nsentences which use the same word types as German, are given to the model\ninstead of German.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 20:00:36 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Xiao", "Tim Z.", ""], ["Gomez", "Aidan N.", ""], ["Gal", "Yarin", ""]]}, {"id": "2006.08367", "submitter": "Muthiah Annamalai", "authors": "Muthiah Annamalai", "title": "Tamil Vowel Recognition With Augmented MNIST-like Data Set", "comments": "8 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We report generation of a MNIST [4] compatible data set [1] for Tamil vowels\nto enable building a classification DNN or other such ML/AI deep learning [2]\nmodels for Tamil OCR/Handwriting applications. We report the capability of the\n60,000 grayscale, 28x28 pixel dataset to build a 92% accuracy (training) and\n82% cross-validation 4-layer CNN, with 100,000+ parameters, in TensorFlow. We\nalso report a top-1 classification accuracy of 70% and top-2 classification\naccuracy of 92% on handwritten vowels showing, for the same network.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 19:17:30 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 19:20:09 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Annamalai", "Muthiah", ""]]}, {"id": "2006.08369", "submitter": "Junhua Liu", "authors": "Junhua Liu, Trisha Singhal, Lucienne T.M. Blessing, Kristin L. Wood\n  and Kwan Hui Lim", "title": "EPIC30M: An Epidemics Corpus Of Over 30 Million Relevant Tweets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the start of COVID-19, several relevant corpora from various sources\nare presented in the literature that contain millions of data points. While\nthese corpora are valuable in supporting many analyses on this specific\npandemic, researchers require additional benchmark corpora that contain other\nepidemics to facilitate cross-epidemic pattern recognition and trend analysis\ntasks. During our other efforts on COVID-19 related work, we discover very\nlittle disease related corpora in the literature that are sizable and rich\nenough to support such cross-epidemic analysis tasks. In this paper, we present\nEPIC30M, a large-scale epidemic corpus that contains 30 millions micro-blog\nposts, i.e., tweets crawled from Twitter, from year 2006 to 2020. EPIC30M\ncontains a subset of 26.2 millions tweets related to three general diseases,\nnamely Ebola, Cholera and Swine Flu, and another subset of 4.7 millions tweets\nof six global epidemic outbreaks, including 2009 H1N1 Swine Flu, 2010 Haiti\nCholera, 2012 Middle-East Respiratory Syndrome (MERS), 2013 West African Ebola,\n2016 Yemen Cholera and 2018 Kivu Ebola. Furthermore, we explore and discuss the\nproperties of the corpus with statistics of key terms and hashtags and trends\nanalysis for each subset. Finally, we demonstrate the value and impact that\nEPIC30M could create through a discussion of multiple use cases of\ncross-epidemic research topics that attract growing interest in recent years.\nThese use cases span multiple research areas, such as epidemiological modeling,\npattern recognition, natural language understanding and economical modeling.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 13:23:00 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 17:08:45 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Liu", "Junhua", ""], ["Singhal", "Trisha", ""], ["Blessing", "Lucienne T. M.", ""], ["Wood", "Kristin L.", ""], ["Lim", "Kwan Hui", ""]]}, {"id": "2006.08387", "submitter": "William Havard", "authors": "William N. Havard, Jean-Pierre Chevrot, Laurent Besacier", "title": "Catplayinginthesnow: Impact of Prior Segmentation on a Model of Visually\n  Grounded Speech", "comments": "Accepted at CoNLL20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The language acquisition literature shows that children do not build their\nlexicon by segmenting the spoken input into phonemes and then building up words\nfrom them, but rather adopt a top-down approach and start by segmenting\nword-like units and then break them down into smaller units. This suggests that\nthe ideal way of learning a language is by starting from full semantic units.\nIn this paper, we investigate if this is also the case for a neural model of\nVisually Grounded Speech trained on a speech-image retrieval task. We evaluated\nhow well such a network is able to learn a reliable speech-to-image mapping\nwhen provided with phone, syllable, or word boundary information. We present a\nsimple way to introduce such information into an RNN-based model and\ninvestigate which type of boundary is the most efficient. We also explore at\nwhich level of the network's architecture such information should be introduced\nso as to maximise its performances. Finally, we show that using multiple\nboundary types at once in a hierarchical structure, by which low-level segments\nare used to recompose high-level segments, is beneficial and yields better\nresults than using low-level or high-level segments in isolation.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 13:20:13 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 13:15:59 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Havard", "William N.", ""], ["Chevrot", "Jean-Pierre", ""], ["Besacier", "Laurent", ""]]}, {"id": "2006.08432", "submitter": "Gencer Sumbul", "authors": "Gencer Sumbul, Sonali Nayak, Beg\\\"um Demir", "title": "SD-RSIC: Summarization Driven Deep Remote Sensing Image Captioning", "comments": "Accepted in the IEEE Transactions on Geoscience and Remote Sensing.\n  For code visit: https://gitlab.tubit.tu-berlin.de/rsim/SD-RSIC", "journal-ref": null, "doi": "10.1109/TGRS.2020.3031111", "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have been recently found popular for image\ncaptioning problems in remote sensing (RS). Existing DNN based approaches rely\non the availability of a training set made up of a high number of RS images\nwith their captions. However, captions of training images may contain redundant\ninformation (they can be repetitive or semantically similar to each other),\nresulting in information deficiency while learning a mapping from the image\ndomain to the language domain. To overcome this limitation, in this paper, we\npresent a novel Summarization Driven Remote Sensing Image Captioning (SD-RSIC)\napproach. The proposed approach consists of three main steps. The first step\nobtains the standard image captions by jointly exploiting convolutional neural\nnetworks (CNNs) with long short-term memory (LSTM) networks. The second step,\nunlike the existing RS image captioning methods, summarizes the ground-truth\ncaptions of each training image into a single caption by exploiting sequence to\nsequence neural networks and eliminates the redundancy present in the training\nset. The third step automatically defines the adaptive weights associated to\neach RS image to combine the standard captions with the summarized captions\nbased on the semantic content of the image. This is achieved by a novel\nadaptive weighting strategy defined in the context of LSTM networks.\nExperimental results obtained on the RSCID, UCM-Captions and Sydney-Captions\ndatasets show the effectiveness of the proposed approach compared to the\nstate-of-the-art RS image captioning approaches. The code of the proposed\napproach is publicly available at\nhttps://gitlab.tubit.tu-berlin.de/rsim/SD-RSIC.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 14:29:12 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 10:09:15 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Sumbul", "Gencer", ""], ["Nayak", "Sonali", ""], ["Demir", "Beg\u00fcm", ""]]}, {"id": "2006.08506", "submitter": "Tobias Watzel", "authors": "Tobias Watzel, Ludwig K\\\"urzinger, Lujun Li, Gerhard Rigoll", "title": "Regularized Forward-Backward Decoder for Attention Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, attention models are one of the popular candidates for speech\nrecognition. So far, many studies mainly focus on the encoder structure or the\nattention module to enhance the performance of these models. However, mostly\nignore the decoder. In this paper, we propose a novel regularization technique\nincorporating a second decoder during the training phase. This decoder is\noptimized on time-reversed target labels beforehand and supports the standard\ndecoder during training by adding knowledge from future context. Since it is\nonly added during training, we are not changing the basic structure of the\nnetwork or adding complexity during decoding. We evaluate our approach on the\nsmaller TEDLIUMv2 and the larger LibriSpeech dataset, achieving consistent\nimprovements on both of them.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 16:04:16 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 14:00:52 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Watzel", "Tobias", ""], ["K\u00fcrzinger", "Ludwig", ""], ["Li", "Lujun", ""], ["Rigoll", "Gerhard", ""]]}, {"id": "2006.08599", "submitter": "Dhruva Sahrawat", "authors": "Dhruva Sahrawat, Yaman Kumar, Shashwat Aggarwal, Yifang Yin, Rajiv\n  Ratn Shah and Roger Zimmermann", "title": "\"Notic My Speech\" -- Blending Speech Patterns With Multimedia", "comments": "Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech as a natural signal is composed of three parts - visemes (visual part\nof speech), phonemes (spoken part of speech), and language (the imposed\nstructure). However, video as a medium for the delivery of speech and a\nmultimedia construct has mostly ignored the cognitive aspects of speech\ndelivery. For example, video applications like transcoding and compression have\ntill now ignored the fact how speech is delivered and heard. To close the gap\nbetween speech understanding and multimedia video applications, in this paper,\nwe show the initial experiments by modelling the perception on visual speech\nand showing its use case on video compression. On the other hand, in the visual\nspeech recognition domain, existing studies have mostly modeled it as a\nclassification problem, while ignoring the correlations between views,\nphonemes, visemes, and speech perception. This results in solutions which are\nfurther away from how human perception works. To bridge this gap, we propose a\nview-temporal attention mechanism to model both the view dependence and the\nvisemic importance in speech recognition and understanding. We conduct\nexperiments on three public visual speech recognition datasets. The\nexperimental results show that our proposed method outperformed the existing\nwork by 4.99% in terms of the viseme error rate. Moreover, we show that there\nis a strong correlation between our model's understanding of multi-view speech\nand the human perception. This characteristic benefits downstream applications\nsuch as video compression and streaming where a significant number of less\nimportant frames can be compressed or eliminated while being able to maximally\npreserve human speech understanding with good user experience.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 06:51:55 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Sahrawat", "Dhruva", ""], ["Kumar", "Yaman", ""], ["Aggarwal", "Shashwat", ""], ["Yin", "Yifang", ""], ["Shah", "Rajiv Ratn", ""], ["Zimmermann", "Roger", ""]]}, {"id": "2006.08671", "submitter": "Sinong Wang", "authors": "Sinong Wang, Madian Khabsa, Hao Ma", "title": "To Pretrain or Not to Pretrain: Examining the Benefits of Pretraining on\n  Resource Rich Tasks", "comments": "Accepted in ACL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pretraining NLP models with variants of Masked Language Model (MLM)\nobjectives has recently led to a significant improvements on many tasks. This\npaper examines the benefits of pretrained models as a function of the number of\ntraining samples used in the downstream task. On several text classification\ntasks, we show that as the number of training examples grow into the millions,\nthe accuracy gap between finetuning BERT-based model and training vanilla LSTM\nfrom scratch narrows to within 1%. Our findings indicate that MLM-based models\nmight reach a diminishing return point as the supervised data size increases\nsignificantly.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 18:18:59 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Wang", "Sinong", ""], ["Khabsa", "Madian", ""], ["Ma", "Hao", ""]]}, {"id": "2006.08748", "submitter": "Chris Hokamp", "authors": "Chris Hokamp, Demian Gholipour Ghalandari, Nghia The Pham, John Glover", "title": "DynE: Dynamic Ensemble Decoding for Multi-Document Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-to-sequence (s2s) models are the basis for extensive work in natural\nlanguage processing. However, some applications, such as multi-document\nsummarization, multi-modal machine translation, and the automatic post-editing\nof machine translation, require mapping a set of multiple distinct inputs into\na single output sequence. Recent work has introduced bespoke architectures for\nthese multi-input settings, and developed models which can handle increasingly\nlonger inputs; however, the performance of special model architectures is\nlimited by the available in-domain training data. In this work we propose a\nsimple decoding methodology which ensembles the output of multiple instances of\nthe same model on different inputs. Our proposed approach allows models trained\nfor vanilla s2s tasks to be directly used in multi-input settings. This works\nparticularly well when each of the inputs has significant overlap with the\nothers, as when compressing a cluster of news articles about the same event\ninto a single coherent summary, and we obtain state-of-the-art results on\nseveral multi-document summarization datasets.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 20:40:06 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Hokamp", "Chris", ""], ["Ghalandari", "Demian Gholipour", ""], ["Pham", "Nghia The", ""], ["Glover", "John", ""]]}, {"id": "2006.08779", "submitter": "Yaqing Wang", "authors": "Yaqing Wang, Yifan Ethan Xu, Xian Li, Xin Luna Dong and Jing Gao", "title": "Automatic Validation of Textual Attribute Values in E-commerce Catalog\n  by Learning with Limited Labeled Data", "comments": "KDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Product catalogs are valuable resources for eCommerce website. In the\ncatalog, a product is associated with multiple attributes whose values are\nshort texts, such as product name, brand, functionality and flavor. Usually\nindividual retailers self-report these key values, and thus the catalog\ninformation unavoidably contains noisy facts. Although existing deep neural\nnetwork models have shown success in conducting cross-checking between two\npieces of texts, their success has to be dependent upon a large set of quality\nlabeled data, which are hard to obtain in this validation task: products span a\nvariety of categories. To address the aforementioned challenges, we propose a\nnovel meta-learning latent variable approach, called MetaBridge, which can\nlearn transferable knowledge from a subset of categories with limited labeled\ndata and capture the uncertainty of never-seen categories with unlabeled data.\nMore specifically, we make the following contributions. (1) We formalize the\nproblem of validating the textual attribute values of products from a variety\nof categories as a natural language inference task in the few-shot learning\nsetting, and propose a meta-learning latent variable model to jointly process\nthe signals obtained from product profiles and textual attribute values. (2) We\npropose to integrate meta learning and latent variable in a unified model to\neffectively capture the uncertainty of various categories. (3) We propose a\nnovel objective function based on latent variable model in the few-shot\nlearning setting, which ensures distribution consistency between unlabeled and\nlabeled data and prevents overfitting by sampling from the learned\ndistribution. Extensive experiments on real eCommerce datasets from hundreds of\ncategories demonstrate the effectiveness of MetaBridge on textual attribute\nvalidation and its outstanding performance compared with state-of-the-art\napproaches.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 21:31:05 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 01:42:13 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2020 03:52:03 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Wang", "Yaqing", ""], ["Xu", "Yifan Ethan", ""], ["Li", "Xian", ""], ["Dong", "Xin Luna", ""], ["Gao", "Jing", ""]]}, {"id": "2006.08792", "submitter": "Emiel Van Miltenburg", "authors": "Emiel van Miltenburg", "title": "On the use of human reference data for evaluating automatic image\n  descriptions", "comments": "Originally presented as a (non-archival) poster at the VizWiz 2020\n  workshop, collocated with CVPR 2020. See:\n  https://vizwiz.org/workshops/2020-workshop/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatic image description systems are commonly trained and evaluated using\ncrowdsourced, human-generated image descriptions. The best-performing system is\nthen determined using some measure of similarity to the reference data (BLEU,\nMeteor, CIDER, etc). Thus, both the quality of the systems as well as the\nquality of the evaluation depends on the quality of the descriptions. As\nSection 2 will show, the quality of current image description datasets is\ninsufficient. I argue that there is a need for more detailed guidelines that\ntake into account the needs of visually impaired users, but also the\nfeasibility of generating suitable descriptions. With high-quality data,\nevaluation of image description systems could use reference descriptions, but\nwe should also look for alternatives.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 21:57:27 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["van Miltenburg", "Emiel", ""]]}, {"id": "2006.08858", "submitter": "Lin Zheng", "authors": "Lin Zheng, Qinliang Su, Dinghan Shen and Changyou Chen", "title": "Generative Semantic Hashing Enhanced via Boltzmann Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative semantic hashing is a promising technique for large-scale\ninformation retrieval thanks to its fast retrieval speed and small memory\nfootprint. For the tractability of training, existing generative-hashing\nmethods mostly assume a factorized form for the posterior distribution,\nenforcing independence among the bits of hash codes. From the perspectives of\nboth model representation and code space size, independence is always not the\nbest assumption. In this paper, to introduce correlations among the bits of\nhash codes, we propose to employ the distribution of Boltzmann machine as the\nvariational posterior. To address the intractability issue of training, we\nfirst develop an approximate method to reparameterize the distribution of a\nBoltzmann machine by augmenting it as a hierarchical concatenation of a\nGaussian-like distribution and a Bernoulli distribution. Based on that, an\nasymptotically-exact lower bound is further derived for the evidence lower\nbound (ELBO). With these novel techniques, the entire model can be optimized\nefficiently. Extensive experimental results demonstrate that by effectively\nmodeling correlations among different bits within a hash code, our model can\nachieve significant performance gains.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 01:23:39 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Zheng", "Lin", ""], ["Su", "Qinliang", ""], ["Shen", "Dinghan", ""], ["Chen", "Changyou", ""]]}, {"id": "2006.08870", "submitter": "Ahan M R", "authors": "Ahan M. R., Shreyas Sunil Kulkarni", "title": "End-to-End Code Switching Language Models for Automatic Speech\n  Recognition", "comments": "5 pages, 2 figures, To appear in the proceedings of First Workshop on\n  Speech Technologies for Code-switching in Multilingual Communities 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we particularly work on the code-switched text, one of the\nmost common occurrences in the bilingual communities across the world. Due to\nthe discrepancies in the extraction of code-switched text from an Automated\nSpeech Recognition(ASR) module, and thereby extracting the monolingual text\nfrom the code-switched text, we propose an approach for extracting monolingual\ntext using Deep Bi-directional Language Models(LM) such as BERT and other\nMachine Translation models, and also explore different ways of extracting\ncode-switched text from the ASR model. We also explain the robustness of the\nmodel by comparing the results of Perplexity and other different metrics like\nWER, to the standard bi-lingual text output without any external information.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 02:11:18 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["R.", "Ahan M.", ""], ["Kulkarni", "Shreyas Sunil", ""]]}, {"id": "2006.08881", "submitter": "Kellie Webster", "authors": "Kellie Webster and Emily Pitler", "title": "Scalable Cross Lingual Pivots to Model Pronoun Gender for Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Machine translation systems with inadequate document understanding can make\nerrors when translating dropped or neutral pronouns into languages with\ngendered pronouns (e.g., English). Predicting the underlying gender of these\npronouns is difficult since it is not marked textually and must instead be\ninferred from coreferent mentions in the context. We propose a novel\ncross-lingual pivoting technique for automatically producing high-quality\ngender labels, and show that this data can be used to fine-tune a BERT\nclassifier with 92% F1 for Spanish dropped feminine pronouns, compared with\n30-51% for neural machine translation models and 54-71% for a non-fine-tuned\nBERT model. We augment a neural machine translation model with labels from our\nclassifier to improve pronoun translation, while still having parallelizable\ntranslation models that translate a sentence at a time.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 02:41:46 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Webster", "Kellie", ""], ["Pitler", "Emily", ""]]}, {"id": "2006.08904", "submitter": "J. Felipe Montano-Campos", "authors": "Victor Zitian Chen, Felipe Montano-Campos and Wlodek Zadrozny", "title": "Causal Knowledge Extraction from Scholarly Papers in Social Sciences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scale and scope of scholarly articles today are overwhelming human\nresearchers who seek to timely digest and synthesize knowledge. In this paper,\nwe seek to develop natural language processing (NLP) models to accelerate the\nspeed of extraction of relationships from scholarly papers in social sciences,\nidentify hypotheses from these papers, and extract the cause-and-effect\nentities. Specifically, we develop models to 1) classify sentences in scholarly\ndocuments in business and management as hypotheses (hypothesis classification),\n2) classify these hypotheses as causal relationships or not (causality\nclassification), and, if they are causal, 3) extract the cause and effect\nentities from these hypotheses (entity extraction). We have achieved high\nperformance for all the three tasks using different modeling techniques. Our\napproach may be generalizable to scholarly documents in a wide range of social\nsciences, as well as other types of textual materials.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 03:37:40 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Chen", "Victor Zitian", ""], ["Montano-Campos", "Felipe", ""], ["Zadrozny", "Wlodek", ""]]}, {"id": "2006.08952", "submitter": "Bennett Kleinberg", "authors": "Bennett Kleinberg", "title": "Manipulating emotions for ground truth emotion analysis", "comments": "preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Text data are being used as a lens through which human cognition can be\nstudied at a large scale. Methods like emotion analysis are now in the standard\ntoolkit of computational social scientists but typically rely on third-person\nannotation with unknown validity. As an alternative, this paper introduces\nonline emotion induction techniques from experimental behavioural research as a\nmethod for text-based emotion analysis. Text data were collected from\nparticipants who were randomly allocated to a happy, neutral or sad condition.\nThe findings support the mood induction procedure. We then examined how well\nlexicon approaches can retrieve the induced emotion. All approaches resulted in\nstatistical differences between the true emotion conditions. Overall, only up\nto one-third of the variance in emotion was captured by text-based\nmeasurements. Pretrained classifiers performed poorly on detecting true\nemotions. The paper concludes with limitations and suggestions for future\nresearch.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 07:03:28 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Kleinberg", "Bennett", ""]]}, {"id": "2006.09035", "submitter": "Miao Li", "authors": "Miao Li, Haoqi Xiong, Yunbo Cao (Smart Platform Product Department,\n  Tencent Inc, China)", "title": "The SPPD System for Schema Guided Dialogue State Tracking Challenge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces one of our group's work on the Dialog System Technology\nChallenges 8 (DSTC8), the SPPD system for Schema Guided dialogue state tracking\nchallenge. This challenge, named as Track 4 in DSTC8, provides a brand new and\nchallenging dataset for developing scalable multi-domain dialogue state\ntracking algorithms for real world dialogue systems. We propose a zero-shot\ndialogue state tracking system for this task. The key components of the system\nis a number of BERT based zero-shot NLU models that can effectively capture\nsemantic relations between natural language descriptions of services' schemas\nand utterances from dialogue turns. We also propose some strategies to make the\nsystem better to exploit information from longer dialogue history and to\novercome the slot carryover problem for multi-domain dialogues. The\nexperimental results show that the proposed system achieves a significant\nimprovement compared with the baseline system.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 09:57:40 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Li", "Miao", "", "Smart Platform Product Department,\n  Tencent Inc, China"], ["Xiong", "Haoqi", "", "Smart Platform Product Department,\n  Tencent Inc, China"], ["Cao", "Yunbo", "", "Smart Platform Product Department,\n  Tencent Inc, China"]]}, {"id": "2006.09073", "submitter": "Zihao Zhu", "authors": "Zihao Zhu, Jing Yu, Yujing Wang, Yajing Sun, Yue Hu, Qi Wu", "title": "Mucko: Multi-Layer Cross-Modal Knowledge Reasoning for Fact-based Visual\n  Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fact-based Visual Question Answering (FVQA) requires external knowledge\nbeyond visible content to answer questions about an image, which is challenging\nbut indispensable to achieve general VQA. One limitation of existing FVQA\nsolutions is that they jointly embed all kinds of information without\nfine-grained selection, which introduces unexpected noises for reasoning the\nfinal answer. How to capture the question-oriented and\ninformation-complementary evidence remains a key challenge to solve the\nproblem. In this paper, we depict an image by a multi-modal heterogeneous\ngraph, which contains multiple layers of information corresponding to the\nvisual, semantic and factual features. On top of the multi-layer graph\nrepresentations, we propose a modality-aware heterogeneous graph convolutional\nnetwork to capture evidence from different layers that is most relevant to the\ngiven question. Specifically, the intra-modal graph convolution selects\nevidence from each modality and cross-modal graph convolution aggregates\nrelevant information across different modalities. By stacking this process\nmultiple times, our model performs iterative reasoning and predicts the optimal\nanswer by analyzing all question-oriented evidence. We achieve a new\nstate-of-the-art performance on the FVQA task and demonstrate the effectiveness\nand interpretability of our model with extensive experiments.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 11:03:37 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 00:49:02 GMT"}, {"version": "v3", "created": "Wed, 4 Nov 2020 01:36:36 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Zhu", "Zihao", ""], ["Yu", "Jing", ""], ["Wang", "Yujing", ""], ["Sun", "Yajing", ""], ["Hu", "Yue", ""], ["Wu", "Qi", ""]]}, {"id": "2006.09075", "submitter": "Eyal Ben-Davd", "authors": "Eyal Ben-David, Carmel Rabinovitz, Roi Reichart", "title": "PERL: Pivot-based Domain Adaptation for Pre-trained Deep Contextualized\n  Embedding Models", "comments": "Accepted to TACL in June 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pivot-based neural representation models have lead to significant progress in\ndomain adaptation for NLP. However, previous works that follow this approach\nutilize only labeled data from the source domain and unlabeled data from the\nsource and target domains, but neglect to incorporate massive unlabeled corpora\nthat are not necessarily drawn from these domains. To alleviate this, we\npropose PERL: A representation learning model that extends contextualized word\nembedding models such as BERT with pivot-based fine-tuning. PERL outperforms\nstrong baselines across 22 sentiment classification domain adaptation setups,\nimproves in-domain model performance, yields effective reduced-size models and\nincreases model stability.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 11:14:06 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Ben-David", "Eyal", ""], ["Rabinovitz", "Carmel", ""], ["Reichart", "Roi", ""]]}, {"id": "2006.09109", "submitter": "Steffen Eger", "authors": "Steffen Eger and Johannes Daxenberger and Iryna Gurevych", "title": "How to Probe Sentence Embeddings in Low-Resource Languages: On\n  Structural Design Choices for Probing Task Evaluation", "comments": "Accepted for Publication at CONLL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence encoders map sentences to real valued vectors for use in downstream\napplications. To peek into these representations - e.g., to increase\ninterpretability of their results - probing tasks have been designed which\nquery them for linguistic knowledge. However, designing probing tasks for\nlesser-resourced languages is tricky, because these often lack large-scale\nannotated data or (high-quality) dependency parsers as a prerequisite of\nprobing task design in English. To investigate how to probe sentence embeddings\nin such cases, we investigate sensitivity of probing task results to structural\ndesign choices, conducting the first such large scale study. We show that\ndesign choices like size of the annotated probing dataset and type of\nclassifier used for evaluation do (sometimes substantially) influence probing\noutcomes. We then probe embeddings in a multilingual setup with design choices\nthat lie in a 'stable region', as we identify for English, and find that\nresults on English do not transfer to other languages. Fairer and more\ncomprehensive sentence-level probing evaluation should thus be carried out on\nmultiple languages in the future.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 12:37:50 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 12:38:37 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Eger", "Steffen", ""], ["Daxenberger", "Johannes", ""], ["Gurevych", "Iryna", ""]]}, {"id": "2006.09161", "submitter": "Hongru Wang", "authors": "Hongru Wang and Xiangru Tang and Sunny Lai and Kwong Sak Leung and Jia\n  Zhu and Gabriel Pui Cheong Fung and Kam-Fai Wong", "title": "CUHK at SemEval-2020 Task 4: CommonSense Explanation, Reasoning and\n  Prediction with Multi-task Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes our system submitted to task 4 of SemEval 2020:\nCommonsense Validation and Explanation (ComVE) which consists of three\nsub-tasks. The task is to directly validate the given sentence whether or not\nit makes sense and require the model to explain it. Based on BERTarchitecture\nwith a multi-task setting, we propose an effective and interpretable \"Explain,\nReason and Predict\" (ERP) system to solve the three sub-tasks about\ncommonsense: (a) Validation, (b)Reasoning, and (c) Explanation. Inspired by\ncognitive studies of common sense, our system first generates a reason or\nunderstanding of the sentences and then chooses which one statement makes\nsense, which is achieved by multi-task learning. During the post-evaluation,\nour system has reached 92.9% accuracy in subtask A (rank 11), 89.7% accuracy in\nsubtask B (rank 9), andBLEU score of 12.9 in subtask C (rank 8)\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 13:51:12 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 00:34:47 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Wang", "Hongru", ""], ["Tang", "Xiangru", ""], ["Lai", "Sunny", ""], ["Leung", "Kwong Sak", ""], ["Zhu", "Jia", ""], ["Fung", "Gabriel Pui Cheong", ""], ["Wong", "Kam-Fai", ""]]}, {"id": "2006.09174", "submitter": "Anastasios Nentidis", "authors": "Anastasios Nentidis, Konstantinos Bougiatiotis, Anastasia Krithara,\n  Georgios Paliouras", "title": "Results of the seventh edition of the BioASQ Challenge", "comments": "17 pages, 2 figures", "journal-ref": "Cellier P., Driessens K. (eds) Machine Learning and Knowledge\n  Discovery in Databases. ECML PKDD 2019. Communications in Computer and\n  Information Science, vol 1168. Springer, Cham", "doi": "10.1007/978-3-030-43887-6_51", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The results of the seventh edition of the BioASQ challenge are presented in\nthis paper. The aim of the BioASQ challenge is the promotion of systems and\nmethodologies through the organization of a challenge on the tasks of\nlarge-scale biomedical semantic indexing and question answering. In total, 30\nteams with more than 100 systems participated in the challenge this year. As in\nprevious years, the best systems were able to outperform the strong baselines.\nThis suggests that state-of-the-art systems are continuously improving, pushing\nthe frontier of research.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 14:23:27 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Nentidis", "Anastasios", ""], ["Bougiatiotis", "Konstantinos", ""], ["Krithara", "Anastasia", ""], ["Paliouras", "Georgios", ""]]}, {"id": "2006.09199", "submitter": "Andrew Rouditchenko", "authors": "Andrew Rouditchenko, Angie Boggust, David Harwath, Brian Chen, Dhiraj\n  Joshi, Samuel Thomas, Kartik Audhkhasi, Hilde Kuehne, Rameswar Panda, Rogerio\n  Feris, Brian Kingsbury, Michael Picheny, Antonio Torralba, James Glass", "title": "AVLnet: Learning Audio-Visual Language Representations from\n  Instructional Videos", "comments": "A version of this work has been accepted to Interspeech 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.MM cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current methods for learning visually grounded language from videos often\nrely on text annotation, such as human generated captions or machine generated\nautomatic speech recognition (ASR) transcripts. In this work, we introduce the\nAudio-Video Language Network (AVLnet), a self-supervised network that learns a\nshared audio-visual embedding space directly from raw video inputs. To\ncircumvent the need for text annotation, we learn audio-visual representations\nfrom randomly segmented video clips and their raw audio waveforms. We train\nAVLnet on HowTo100M, a large corpus of publicly available instructional videos,\nand evaluate on image retrieval and video retrieval tasks, achieving\nstate-of-the-art performance. We perform analysis of AVLnet's learned\nrepresentations, showing our model utilizes speech and natural sounds to learn\naudio-visual concepts. Further, we propose a tri-modal model that jointly\nprocesses raw audio, video, and text captions from videos to learn a\nmulti-modal semantic embedding space useful for text-video retrieval. Our code,\ndata, and trained models will be released at avlnet.csail.mit.edu\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 14:38:03 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 18:44:50 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Rouditchenko", "Andrew", ""], ["Boggust", "Angie", ""], ["Harwath", "David", ""], ["Chen", "Brian", ""], ["Joshi", "Dhiraj", ""], ["Thomas", "Samuel", ""], ["Audhkhasi", "Kartik", ""], ["Kuehne", "Hilde", ""], ["Panda", "Rameswar", ""], ["Feris", "Rogerio", ""], ["Kingsbury", "Brian", ""], ["Picheny", "Michael", ""], ["Torralba", "Antonio", ""], ["Glass", "James", ""]]}, {"id": "2006.09213", "submitter": "Wei Wei", "authors": "Wei Wei, Bei Zhou, Georgios Leontidis", "title": "A Hybrid Natural Language Generation System Integrating Rules and Deep\n  Learning Algorithms", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an enhanced natural language generation system combining\nthe merits of both rule-based approaches and modern deep learning algorithms,\nboosting its performance to the extent where the generated textual content is\ncapable of exhibiting agile human-writing styles and the content logic of which\nis highly controllable. We also come up with a novel approach called HMCU to\nmeasure the performance of the natural language processing comprehensively and\nprecisely.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 00:50:41 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 14:40:38 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Wei", "Wei", ""], ["Zhou", "Bei", ""], ["Leontidis", "Georgios", ""]]}, {"id": "2006.09217", "submitter": "Chris C. Emezue", "authors": "Bonaventure F. P. Dossou and Chris C. Emezue", "title": "FFR v1.1: Fon-French Neural Machine Translation", "comments": "Accepted for publication at the Widening Natural Language Processing\n  (WiNLP) Workshop, The 58th Annual Meeting of the Association for\n  Computational Linguistics, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  All over the world and especially in Africa, researchers are putting efforts\ninto building Neural Machine Translation (NMT) systems to help tackle the\nlanguage barriers in Africa, a continent of over 2000 different languages.\nHowever, the low-resourceness, diacritical, and tonal complexities of African\nlanguages are major issues being faced. The FFR project is a major step towards\ncreating a robust translation model from Fon, a very low-resource and tonal\nlanguage, to French, for research and public use. In this paper, we introduce\nFFR Dataset, a corpus of Fon-to-French translations, describe the diacritical\nencoding process, and introduce our FFR v1.1 model, trained on the dataset. The\ndataset and model are made publicly available at https://github.com/\nbonaventuredossou/ffr-v1, to promote collaboration and reproducibility.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 04:27:12 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Dossou", "Bonaventure F. P.", ""], ["Emezue", "Chris C.", ""]]}, {"id": "2006.09222", "submitter": "Sebastian Bayerl", "authors": "Sebastian P. Bayerl, Florian H\\\"onig, Joelle Reister and Korbinian\n  Riedhammer", "title": "Towards Automated Assessment of Stuttering and Stuttering Therapy", "comments": "10 pages, 3 figures, 1 table Accepted at TSD 2020, 23rd International\n  Conference on Text, Speech and Dialogue", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stuttering is a complex speech disorder that can be identified by\nrepetitions, prolongations of sounds, syllables or words, and blocks while\nspeaking. Severity assessment is usually done by a speech therapist. While\nattempts at automated assessment were made, it is rarely used in therapy.\nCommon methods for the assessment of stuttering severity include percent\nstuttered syllables (% SS), the average of the three longest stuttering\nsymptoms during a speech task, or the recently introduced Speech Efficiency\nScore (SES). This paper introduces the Speech Control Index (SCI), a new method\nto evaluate the severity of stuttering. Unlike SES, it can also be used to\nassess therapy success for fluency shaping. We evaluate both SES and SCI on a\nnew comprehensively labeled dataset containing stuttered German speech of\nclients prior to, during, and after undergoing stuttering therapy. Phone\nalignments of an automatic speech recognition system are statistically\nevaluated in relation to their relative position to labeled stuttering events.\nThe results indicate that phone length distributions differ with respect to\ntheir position in and around labeled stuttering events\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 14:50:56 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Bayerl", "Sebastian P.", ""], ["H\u00f6nig", "Florian", ""], ["Reister", "Joelle", ""], ["Riedhammer", "Korbinian", ""]]}, {"id": "2006.09235", "submitter": "Fengmao Lv", "authors": "Tao Liang, Wenya Wang, Fengmao Lv", "title": "Weakly-supervised Domain Adaption for Aspect Extraction via Multi-level\n  Interaction Transfer", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-grained aspect extraction is an essential sub-task in aspect based\nopinion analysis. It aims to identify the aspect terms (a.k.a. opinion targets)\nof a product or service in each sentence. However, expensive annotation process\nis usually involved to acquire sufficient token-level labels for each domain.\nTo address this limitation, some previous works propose domain adaptation\nstrategies to transfer knowledge from a sufficiently labeled source domain to\nunlabeled target domains. But due to both the difficulty of fine-grained\nprediction problems and the large domain gap between domains, the performance\nremains unsatisfactory. This work conducts a pioneer study on leveraging\nsentence-level aspect category labels that can be usually available in\ncommercial services like review sites to promote token-level transfer for the\nextraction purpose. Specifically, the aspect category information is used to\nconstruct pivot knowledge for transfer with assumption that the interactions\nbetween sentence-level aspect category and token-level aspect terms are\ninvariant across domains. To this end, we propose a novel multi-level\nreconstruction mechanism that aligns both the fine-grained and coarse-grained\ninformation in multiple levels of abstractions. Comprehensive experiments\ndemonstrate that our approach can fully utilize sentence-level aspect category\nlabels to improve cross-domain aspect extraction with a large performance gain.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 15:11:51 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Liang", "Tao", ""], ["Wang", "Wenya", ""], ["Lv", "Fengmao", ""]]}, {"id": "2006.09242", "submitter": "Martin Schmitt", "authors": "Martin Schmitt, Leonardo F. R. Ribeiro, Philipp Dufter, Iryna\n  Gurevych, Hinrich Sch\\\"utze", "title": "Modeling Graph Structure via Relative Position for Text Generation from\n  Knowledge Graphs", "comments": "Accepted as a long paper at TextGraphs 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present Graformer, a novel Transformer-based encoder-decoder architecture\nfor graph-to-text generation. With our novel graph self-attention, the encoding\nof a node relies on all nodes in the input graph - not only direct neighbors -\nfacilitating the detection of global patterns. We represent the relation\nbetween two nodes as the length of the shortest path between them. Graformer\nlearns to weight these node-node relations differently for different attention\nheads, thus virtually learning differently connected views of the input graph.\nWe evaluate Graformer on two popular graph-to-text generation benchmarks,\nAGENDA and WebNLG, where it achieves strong performance while using many fewer\nparameters than other approaches.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 15:20:04 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 12:52:33 GMT"}, {"version": "v3", "created": "Tue, 27 Apr 2021 09:13:08 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Schmitt", "Martin", ""], ["Ribeiro", "Leonardo F. R.", ""], ["Dufter", "Philipp", ""], ["Gurevych", "Iryna", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "2006.09265", "submitter": "Wenda Li", "authors": "Wenda Li and Lei Yu and Yuhuai Wu and Lawrence C. Paulson", "title": "IsarStep: a Benchmark for High-level Mathematical Reasoning", "comments": "9 pages, published at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CL cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A well-defined benchmark is essential for measuring and accelerating research\nprogress of machine learning models. In this paper, we present a benchmark for\nhigh-level mathematical reasoning and study the reasoning capabilities of\nneural sequence-to-sequence models. We build a non-synthetic dataset from the\nlargest repository of proofs written by human experts in a theorem prover. The\ndataset has a broad coverage of undergraduate and research-level mathematical\nand computer science theorems. In our defined task, a model is required to fill\nin a missing intermediate proposition given surrounding proofs. This task\nprovides a starting point for the long-term goal of having machines generate\nhuman-readable proofs automatically. Our experiments and analysis reveal that\nwhile the task is challenging, neural models can capture non-trivial\nmathematical reasoning. We further design a hierarchical transformer that\noutperforms the transformer baseline.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 21:09:23 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 16:45:18 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Li", "Wenda", ""], ["Yu", "Lei", ""], ["Wu", "Yuhuai", ""], ["Paulson", "Lawrence C.", ""]]}, {"id": "2006.09277", "submitter": "Andres Karjus", "authors": "Andres Karjus, Richard A. Blythe, Simon Kirby, Kenny Smith", "title": "Communicative need modulates competition in language change", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  All living languages change over time. The causes for this are many, one\nbeing the emergence and borrowing of new linguistic elements. Competition\nbetween the new elements and older ones with a similar semantic or grammatical\nfunction may lead to speakers preferring one of them, and leaving the other to\ngo out of use. We introduce a general method for quantifying competition\nbetween linguistic elements in diachronic corpora which does not require\nlanguage-specific resources other than a sufficiently large corpus. This\napproach is readily applicable to a wide range of languages and linguistic\nsubsystems. Here, we apply it to lexical data in five corpora differing in\nlanguage, type, genre, and time span. We find that changes in communicative\nneed are consistently predictive of lexical competition dynamics.\nNear-synonymous words are more likely to directly compete if they belong to a\ntopic of conversation whose importance to language users is constant over time,\npossibly leading to the extinction of one of the competing words. By contrast,\nin topics which are increasing in importance for language users,\nnear-synonymous words tend not to compete directly and can coexist. This\nsuggests that, in addition to direct competition between words, language change\ncan be driven by competition between topics or semantic subspaces.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 16:11:04 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Karjus", "Andres", ""], ["Blythe", "Richard A.", ""], ["Kirby", "Simon", ""], ["Smith", "Kenny", ""]]}, {"id": "2006.09286", "submitter": "Satwik Bhattamishra", "authors": "Satwik Bhattamishra, Arkil Patel, Navin Goyal", "title": "On the Computational Power of Transformers and its Implications in\n  Sequence Modeling", "comments": "CoNLL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformers are being used extensively across several sequence modeling\ntasks. Significant research effort has been devoted to experimentally probe the\ninner workings of Transformers. However, our conceptual and theoretical\nunderstanding of their power and inherent limitations is still nascent. In\nparticular, the roles of various components in Transformers such as positional\nencodings, attention heads, residual connections, and feedforward networks, are\nnot clear. In this paper, we take a step towards answering these questions. We\nanalyze the computational power as captured by Turing-completeness. We first\nprovide an alternate and simpler proof to show that vanilla Transformers are\nTuring-complete and then we prove that Transformers with only positional\nmasking and without any positional encoding are also Turing-complete. We\nfurther analyze the necessity of each component for the Turing-completeness of\nthe network; interestingly, we find that a particular type of residual\nconnection is necessary. We demonstrate the practical implications of our\nresults via experiments on machine translation and synthetic tasks.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 16:27:56 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 19:55:21 GMT"}, {"version": "v3", "created": "Sat, 10 Oct 2020 13:34:20 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Bhattamishra", "Satwik", ""], ["Patel", "Arkil", ""], ["Goyal", "Navin", ""]]}, {"id": "2006.09336", "submitter": "Chan Young Park", "authors": "Jimin Sun, Hwijeen Ahn, Chan Young Park, Yulia Tsvetkov, David R.\n  Mortensen", "title": "Cross-Cultural Similarity Features for Cross-Lingual Transfer Learning\n  of Pragmatically Motivated Tasks", "comments": "EACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much work in cross-lingual transfer learning explored how to select better\ntransfer languages for multilingual tasks, primarily focusing on typological\nand genealogical similarities between languages. We hypothesize that these\nmeasures of linguistic proximity are not enough when working with\npragmatically-motivated tasks, such as sentiment analysis. As an alternative,\nwe introduce three linguistic features that capture cross-cultural similarities\nthat manifest in linguistic patterns and quantify distinct aspects of language\npragmatics: language context-level, figurative language, and the lexification\nof emotion concepts. Our analyses show that the proposed pragmatic features do\ncapture cross-cultural similarities and align well with existing work in\nsociolinguistics and linguistic anthropology. We further corroborate the\neffectiveness of pragmatically-driven transfer in the downstream task of\nchoosing transfer languages for cross-lingual sentiment analysis.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 17:20:25 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 08:31:54 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Sun", "Jimin", ""], ["Ahn", "Hwijeen", ""], ["Park", "Chan Young", ""], ["Tsvetkov", "Yulia", ""], ["Mortensen", "David R.", ""]]}, {"id": "2006.09432", "submitter": "Dorottya Demszky", "authors": "Dorottya Demszky and L\\'aszl\\'o K\\'alm\\'an and Dan Jurafsky and Beth\n  Levin", "title": "The Role of Verb Semantics in Hungarian Verb-Object Order", "comments": "Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hungarian is often referred to as a discourse-configurational language, since\nthe structural position of constituents is determined by their logical function\n(topic or comment) rather than their grammatical function (e.g., subject or\nobject). We build on work by Koml\\'osy (1989) and argue that in addition to\ndiscourse context, the lexical semantics of the verb also plays a significant\nrole in determining Hungarian word order. In order to investigate the role of\nlexical semantics in determining Hungarian word order, we conduct a\nlarge-scale, data-driven analysis on the ordering of 380 transitive verbs and\ntheir objects, as observed in hundreds of thousands of examples extracted from\nthe Hungarian Gigaword Corpus. We test the effect of lexical semantics on the\nordering of verbs and their objects by grouping verbs into 11 semantic classes.\nIn addition to the semantic class of the verb, we also include two control\nfeatures related to information structure, object definiteness and object NP\nweight, chosen to allow a comparison of their effect size to that of verb\nsemantics. Our results suggest that all three features have a significant\neffect on verb-object ordering in Hungarian and among these features, the\nsemantic class of the verb has the largest effect. Specifically, we find that\nstative verbs, such as fed \"cover\", jelent \"mean\" and \\\"ovez \"surround\", tend\nto be OV-preferring (with the exception of psych verbs which are strongly\nVO-preferring) and non-stative verbs, such as b\\'ir\\'al \"judge\", cs\\\"okkent\n\"reduce\" and cs\\'okol \"kiss\", verbs tend to be VO-preferring. These findings\nsupport our hypothesis that lexical semantic factors influence word order in\nHungarian.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 18:23:58 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Demszky", "Dorottya", ""], ["K\u00e1lm\u00e1n", "L\u00e1szl\u00f3", ""], ["Jurafsky", "Dan", ""], ["Levin", "Beth", ""]]}, {"id": "2006.09462", "submitter": "Amita Kamath", "authors": "Amita Kamath, Robin Jia, Percy Liang", "title": "Selective Question Answering under Domain Shift", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To avoid giving wrong answers, question answering (QA) models need to know\nwhen to abstain from answering. Moreover, users often ask questions that\ndiverge from the model's training data, making errors more likely and thus\nabstention more critical. In this work, we propose the setting of selective\nquestion answering under domain shift, in which a QA model is tested on a\nmixture of in-domain and out-of-domain data, and must answer (i.e., not abstain\non) as many questions as possible while maintaining high accuracy. Abstention\npolicies based solely on the model's softmax probabilities fare poorly, since\nmodels are overconfident on out-of-domain inputs. Instead, we train a\ncalibrator to identify inputs on which the QA model errs, and abstain when it\npredicts an error is likely. Crucially, the calibrator benefits from observing\nthe model's behavior on out-of-domain data, even if from a different domain\nthan the test data. We combine this method with a SQuAD-trained QA model and\nevaluate on mixtures of SQuAD and five other QA datasets. Our method answers\n56% of questions while maintaining 80% accuracy; in contrast, directly using\nthe model's probabilities only answers 48% at 80% accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 19:13:21 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Kamath", "Amita", ""], ["Jia", "Robin", ""], ["Liang", "Percy", ""]]}, {"id": "2006.09479", "submitter": "Prateek Saxena", "authors": "Prateek Saxena and Soma Paul", "title": "EPIE Dataset: A Corpus For Possible Idiomatic Expressions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Idiomatic expressions have always been a bottleneck for language\ncomprehension and natural language understanding, specifically for tasks like\nMachine Translation(MT). MT systems predominantly produce literal translations\nof idiomatic expressions as they do not exhibit generic and linguistically\ndeterministic patterns which can be exploited for comprehension of the\nnon-compositional meaning of the expressions. These expressions occur in\nparallel corpora used for training, but due to the comparatively high\noccurrences of the constituent words of idiomatic expressions in literal\ncontext, the idiomatic meaning gets overpowered by the compositional meaning of\nthe expression. State of the art Metaphor Detection Systems are able to detect\nnon-compositional usage at word level but miss out on idiosyncratic phrasal\nidiomatic expressions. This creates a dire need for a dataset with a wider\ncoverage and higher occurrence of commonly occurring idiomatic expressions, the\nspans of which can be used for Metaphor Detection. With this in mind, we\npresent our English Possible Idiomatic Expressions(EPIE) corpus containing\n25206 sentences labelled with lexical instances of 717 idiomatic expressions.\nThese spans also cover literal usages for the given set of idiomatic\nexpressions. We also present the utility of our dataset by using it to train a\nsequence labelling module and testing on three independent datasets with high\naccuracy, precision and recall scores.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 19:43:30 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Saxena", "Prateek", ""], ["Paul", "Soma", ""]]}, {"id": "2006.09526", "submitter": "Chau Tran", "authors": "Chau Tran, Yuqing Tang, Xian Li, Jiatao Gu", "title": "Cross-lingual Retrieval for Iterative Self-Supervised Training", "comments": null, "journal-ref": "NeurIPS 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have demonstrated the cross-lingual alignment ability of\nmultilingual pretrained language models. In this work, we found that the\ncross-lingual alignment can be further improved by training seq2seq models on\nsentence pairs mined using their own encoder outputs. We utilized these\nfindings to develop a new approach -- cross-lingual retrieval for iterative\nself-supervised training (CRISS), where mining and training processes are\napplied iteratively, improving cross-lingual alignment and translation ability\nat the same time. Using this method, we achieved state-of-the-art unsupervised\nmachine translation results on 9 language directions with an average\nimprovement of 2.4 BLEU, and on the Tatoeba sentence retrieval task in the\nXTREME benchmark on 16 languages with an average improvement of 21.5% in\nabsolute accuracy. Furthermore, CRISS also brings an additional 1.8 BLEU\nimprovement on average compared to mBART, when finetuned on supervised machine\ntranslation downstream tasks.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 21:30:51 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 23:25:31 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Tran", "Chau", ""], ["Tang", "Yuqing", ""], ["Li", "Xian", ""], ["Gu", "Jiatao", ""]]}, {"id": "2006.09589", "submitter": "Zijian Wang", "authors": "Elisa Kreiss, Zijian Wang, Christopher Potts", "title": "Modeling Subjective Assessments of Guilt in Newspaper Crime Narratives", "comments": "CoNLL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Crime reporting is a prevalent form of journalism with the power to shape\npublic perceptions and social policies. How does the language of these reports\nact on readers? We seek to address this question with the SuspectGuilt Corpus\nof annotated crime stories from English-language newspapers in the U.S. For\nSuspectGuilt, annotators read short crime articles and provided text-level\nratings concerning the guilt of the main suspect as well as span-level\nannotations indicating which parts of the story they felt most influenced their\nratings. SuspectGuilt thus provides a rich picture of how linguistic choices\naffect subjective guilt judgments. In addition, we use SuspectGuilt to train\nand assess predictive models, and show that these models benefit from genre\npretraining and joint supervision from the text-level ratings and span-level\nannotations. Such models might be used as tools for understanding the societal\neffects of crime reporting.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 01:21:19 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 22:38:44 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Kreiss", "Elisa", ""], ["Wang", "Zijian", ""], ["Potts", "Christopher", ""]]}, {"id": "2006.09595", "submitter": "Andre Esteva", "authors": "Andre Esteva, Anuprit Kale, Romain Paulus, Kazuma Hashimoto, Wenpeng\n  Yin, Dragomir Radev, Richard Socher", "title": "CO-Search: COVID-19 Information Retrieval with Semantic Search, Question\n  Answering, and Abstractive Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 global pandemic has resulted in international efforts to\nunderstand, track, and mitigate the disease, yielding a significant corpus of\nCOVID-19 and SARS-CoV-2-related publications across scientific disciplines. As\nof May 2020, 128,000 coronavirus-related publications have been collected\nthrough the COVID-19 Open Research Dataset Challenge. Here we present\nCO-Search, a retriever-ranker semantic search engine designed to handle complex\nqueries over the COVID-19 literature, potentially aiding overburdened health\nworkers in finding scientific answers during a time of crisis. The retriever is\nbuilt from a Siamese-BERT encoder that is linearly composed with a TF-IDF\nvectorizer, and reciprocal-rank fused with a BM25 vectorizer. The ranker is\ncomposed of a multi-hop question-answering module, that together with a\nmulti-paragraph abstractive summarizer adjust retriever scores. To account for\nthe domain-specific and relatively limited dataset, we generate a bipartite\ngraph of document paragraphs and citations, creating 1.3 million (citation\ntitle, paragraph) tuples for training the encoder. We evaluate our system on\nthe data of the TREC-COVID information retrieval challenge. CO-Search obtains\ntop performance on the datasets of the first and second rounds, across several\nkey metrics: normalized discounted cumulative gain, precision, mean average\nprecision, and binary preference.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 01:32:48 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Esteva", "Andre", ""], ["Kale", "Anuprit", ""], ["Paulus", "Romain", ""], ["Hashimoto", "Kazuma", ""], ["Yin", "Wenpeng", ""], ["Radev", "Dragomir", ""], ["Socher", "Richard", ""]]}, {"id": "2006.09610", "submitter": "Tianwen Jiang", "authors": "Tianwen Jiang, Tong Zhao, Bing Qin, Ting Liu, Nitesh V. Chawla, Meng\n  Jiang", "title": "Canonicalizing Open Knowledge Bases with Multi-Layered Meta-Graph Neural\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noun phrases and relational phrases in Open Knowledge Bases are often not\ncanonical, leading to redundant and ambiguous facts. In this work, we integrate\nstructural information (from which tuple, which sentence) and semantic\ninformation (semantic similarity) to do the canonicalization. We represent the\ntwo types of information as a multi-layered graph: the structural information\nforms the links across the sentence, relational phrase, and noun phrase layers;\nthe semantic information forms weighted intra-layer links for each layer. We\npropose a graph neural network model to aggregate the representations of noun\nphrases and relational phrases through the multi-layered meta-graph structure.\nExperiments show that our model outperforms existing approaches on a public\ndatasets in general domain.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 02:32:36 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Jiang", "Tianwen", ""], ["Zhao", "Tong", ""], ["Qin", "Bing", ""], ["Liu", "Ting", ""], ["Chawla", "Nitesh V.", ""], ["Jiang", "Meng", ""]]}, {"id": "2006.09615", "submitter": "Zhen Sun", "authors": "Zhen Sun, Roei Schuster, Vitaly Shmatikov", "title": "De-Anonymizing Text by Fingerprinting Language Generation", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Components of machine learning systems are not (yet) perceived as security\nhotspots. Secure coding practices, such as ensuring that no execution paths\ndepend on confidential inputs, have not yet been adopted by ML developers. We\ninitiate the study of code security of ML systems by investigating how nucleus\nsampling---a popular approach for generating text, used for applications such\nas auto-completion---unwittingly leaks texts typed by users. Our main result is\nthat the series of nucleus sizes for many natural English word sequences is a\nunique fingerprint. We then show how an attacker can infer typed text by\nmeasuring these fingerprints via a suitable side channel (e.g., cache access\ntimes), explain how this attack could help de-anonymize anonymous texts, and\ndiscuss defenses.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 02:49:15 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 04:47:25 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Sun", "Zhen", ""], ["Schuster", "Roei", ""], ["Shmatikov", "Vitaly", ""]]}, {"id": "2006.09627", "submitter": "Stephen Mayhew", "authors": "Tatiana Tsygankova, Francesca Marini, Stephen Mayhew, Dan Roth", "title": "Building Low-Resource NER Models Using Non-Speaker Annotation", "comments": "Accepted to DASH-LA 2021, workshop at NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In low-resource natural language processing (NLP), the key problems are a\nlack of target language training data, and a lack of native speakers to create\nit. Cross-lingual methods have had notable success in addressing these\nconcerns, but in certain common circumstances, such as insufficient\npre-training corpora or languages far from the source language, their\nperformance suffers. In this work we propose a complementary approach to\nbuilding low-resource Named Entity Recognition (NER) models using\n``non-speaker'' (NS) annotations, provided by annotators with no prior\nexperience in the target language. We recruit 30 participants in a carefully\ncontrolled annotation experiment with Indonesian, Russian, and Hindi. We show\nthat use of NS annotators produces results that are consistently on par or\nbetter than cross-lingual methods built on modern contextual representations,\nand have the potential to outperform with additional effort. We conclude with\nobservations of common annotation patterns and recommended implementation\npractices, and motivate how NS annotations can be used in addition to prior\nmethods for improved performance. For more details,\nhttp://cogcomp.org/page/publication_view/941\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 03:24:38 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 16:28:48 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Tsygankova", "Tatiana", ""], ["Marini", "Francesca", ""], ["Mayhew", "Stephen", ""], ["Roth", "Dan", ""]]}, {"id": "2006.09639", "submitter": "Dhruv Kumar", "authors": "Dhruv Kumar, Lili Mou, Lukasz Golab, Olga Vechtomova", "title": "Iterative Edit-Based Unsupervised Sentence Simplification", "comments": "The paper has been accepted to ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel iterative, edit-based approach to unsupervised sentence\nsimplification. Our model is guided by a scoring function involving fluency,\nsimplicity, and meaning preservation. Then, we iteratively perform word and\nphrase-level edits on the complex sentence. Compared with previous approaches,\nour model does not require a parallel training set, but is more controllable\nand interpretable. Experiments on Newsela and WikiLarge datasets show that our\napproach is nearly as effective as state-of-the-art supervised approaches.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 03:53:12 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Kumar", "Dhruv", ""], ["Mou", "Lili", ""], ["Golab", "Lukasz", ""], ["Vechtomova", "Olga", ""]]}, {"id": "2006.09685", "submitter": "Jiahua Du", "authors": "Jiahua Du, Jia Rong, Hua Wang, Yanchun Zhang", "title": "Exploiting Review Neighbors for Contextualized Helpfulness Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Helpfulness prediction techniques have been widely used to identify and\nrecommend high-quality online reviews to customers. Currently, the vast\nmajority of studies assume that a review's helpfulness is self-contained. In\npractice, however, customers hardly process reviews independently given the\nsequential nature. The perceived helpfulness of a review is likely to be\naffected by its sequential neighbors (i.e., context), which has been largely\nignored. This paper proposes a new methodology to capture the missing\ninteraction between reviews and their neighbors. The first end-to-end neural\narchitecture is developed for neighbor-aware helpfulness prediction (NAP). For\neach review, NAP allows for three types of neighbor selection: its preceding,\nfollowing, and surrounding neighbors. Four weighting schemes are designed to\nlearn context clues from the selected neighbors. A review is then\ncontextualized into the learned clues for neighbor-aware helpfulness\nprediction. NAP is evaluated on six domains of real-world online reviews\nagainst a series of state-of-the-art baselines. Extensive experiments confirm\nthe effectiveness of NAP and the influence of sequential neighbors on a current\nreviews. Further hyperparameter analysis reveals three main findings. (1) On\naverage, eight neighbors treated with uneven importance are engaged for context\nconstruction. (2) The benefit of neighbor-aware prediction mainly results from\ncloser neighbors. (3) Equally considering up to five closest neighbors of a\nreview can usually produce a weaker but tolerable prediction result.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 07:02:42 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Du", "Jiahua", ""], ["Rong", "Jia", ""], ["Wang", "Hua", ""], ["Zhang", "Yanchun", ""]]}, {"id": "2006.09719", "submitter": "Vadim Gudkov", "authors": "Vadim Gudkov, Olga Mitrofanova, Elizaveta Filippskikh", "title": "Automatically Ranked Russian Paraphrase Corpus for Text Generation", "comments": "To be published in The 4th Workshop on Neural Generation and\n  Translation @ ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The article is focused on automatic development and ranking of a large corpus\nfor Russian paraphrase generation which proves to be the first corpus of such\ntype in Russian computational linguistics. Existing manually annotated\nparaphrase datasets for Russian are limited to small-sized ParaPhraser corpus\nand ParaPlag which are suitable for a set of NLP tasks, such as paraphrase and\nplagiarism detection, sentence similarity and relatedness estimation, etc. Due\nto size restrictions, these datasets can hardly be applied in end-to-end text\ngeneration solutions. Meanwhile, paraphrase generation requires a large amount\nof training data. In our study we propose a solution to the problem: we\ncollect, rank and evaluate a new publicly available headline paraphrase corpus\n(ParaPhraser Plus), and then perform text generation experiments with manual\nevaluation on automatically ranked corpora using the Universal Transformer\narchitecture.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 08:40:52 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Gudkov", "Vadim", ""], ["Mitrofanova", "Olga", ""], ["Filippskikh", "Elizaveta", ""]]}, {"id": "2006.09723", "submitter": "Pranava Madhyastha", "authors": "Karolina Sowinska and Pranava Madhyastha", "title": "A Tweet-based Dataset for Company-Level Stock Return Prediction", "comments": "Dataset available here:\n  https://github.com/ImperialNLP/stockreturnpred", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI q-fin.ST", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Public opinion influences events, especially related to stock market\nmovement, in which a subtle hint can influence the local outcome of the market.\nIn this paper, we present a dataset that allows for company-level analysis of\ntweet based impact on one-, two-, three-, and seven-day stock returns. Our\ndataset consists of 862, 231 labelled instances from twitter in English, we\nalso release a cleaned subset of 85, 176 labelled instances to the community.\nWe also provide baselines using standard machine learning algorithms and a\nmulti-view learning based approach that makes use of different types of\nfeatures. Our dataset, scripts and models are publicly available at:\nhttps://github.com/ImperialNLP/stockreturnpred.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 08:55:11 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Sowinska", "Karolina", ""], ["Madhyastha", "Pranava", ""]]}, {"id": "2006.09766", "submitter": "Anton Alekseev", "authors": "Anton Alekseev, Elena Tutubalina, Valentin Malykh, Sergey Nikolenko", "title": "Improving unsupervised neural aspect extraction for online discussions\n  using out-of-domain classification", "comments": "Journal of Intelligent & Fuzzy Systems, pre-press,\n  https://content.iospress.com/articles/journal-of-intelligent-and-fuzzy-systems/ifs179908", "journal-ref": null, "doi": "10.3233/JIFS-179908", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning architectures based on self-attention have recently achieved\nand surpassed state of the art results in the task of unsupervised aspect\nextraction and topic modeling. While models such as neural attention-based\naspect extraction (ABAE) have been successfully applied to user-generated\ntexts, they are less coherent when applied to traditional data sources such as\nnews articles and newsgroup documents. In this work, we introduce a simple\napproach based on sentence filtering in order to improve topical aspects\nlearned from newsgroups-based content without modifying the basic mechanism of\nABAE. We train a probabilistic classifier to distinguish between out-of-domain\ntexts (outer dataset) and in-domain texts (target dataset). Then, during data\npreparation we filter out sentences that have a low probability of being\nin-domain and train the neural model on the remaining sentences. The positive\neffect of sentence filtering on topic coherence is demonstrated in comparison\nto aspect extraction models trained on unfiltered texts.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 10:34:16 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Alekseev", "Anton", ""], ["Tutubalina", "Elena", ""], ["Malykh", "Valentin", ""], ["Nikolenko", "Sergey", ""]]}, {"id": "2006.09873", "submitter": "Debanjan Ghosh", "authors": "Debanjan Ghosh, Beata Beigman Klebanov, Yi Song", "title": "An Exploratory Study of Argumentative Writing by Young Students: A\n  Transformer-based Approach", "comments": "15th Workshop on Innovative Use of NLP for Building Educational\n  Applications, ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a computational exploration of argument critique writing by young\nstudents. Middle school students were asked to criticize an argument presented\nin the prompt, focusing on identifying and explaining the reasoning flaws. This\ntask resembles an established college-level argument critique task. Lexical and\ndiscourse features that utilize detailed domain knowledge to identify critiques\nexist for the college task but do not perform well on the young students data.\nInstead, transformer-based architecture (e.g., BERT) fine-tuned on a large\ncorpus of critique essays from the college task performs much better (over 20%\nimprovement in F1 score). Analysis of the performance of various configurations\nof the system suggests that while children's writing does not exhibit the\nstandard discourse structure of an argumentative essay, it does share basic\nlocal sequential structures with the more mature writers.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 13:55:31 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Ghosh", "Debanjan", ""], ["Klebanov", "Beata Beigman", ""], ["Song", "Yi", ""]]}, {"id": "2006.09891", "submitter": "Bidisha Samanta", "authors": "Bidisha Samanta, Mohit Agarwal, Niloy Ganguly", "title": "Fine-grained Sentiment Controlled Text Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Controlled text generation techniques aim to regulate specific attributes\n(e.g. sentiment) while preserving the attribute independent content. The\nstate-of-the-art approaches model the specified attribute as a structured or\ndiscrete representation while making the content representation independent of\nit to achieve a better control. However, disentangling the text representation\ninto separate latent spaces overlooks complex dependencies between content and\nattribute, leading to generation of poorly constructed and not so meaningful\nsentences. Moreover, such an approach fails to provide a finer control on the\ndegree of attribute change. To address these problems of controlled text\ngeneration, in this paper, we propose DE-VAE, a hierarchical framework which\ncaptures both information enriched entangled representation and attribute\nspecific disentangled representation in different hierarchies. DE-VAE achieves\nbetter control of sentiment as an attribute while preserving the content by\nlearning a suitable lossless transformation network from the disentangled\nsentiment space to the desired entangled representation. Through feature\nsupervision on a single dimension of the disentangled representation, DE-VAE\nmaps the variation of sentiment to a continuous space which helps in smoothly\nregulating sentiment from positive to negative and vice versa. Detailed\nexperiments on three publicly available review datasets show the superiority of\nDE-VAE over recent state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 14:17:58 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Samanta", "Bidisha", ""], ["Agarwal", "Mohit", ""], ["Ganguly", "Niloy", ""]]}, {"id": "2006.09896", "submitter": "Adam Sutton", "authors": "Adam Sutton and Nello Cristianini", "title": "On the Learnability of Concepts: With Applications to Comparing Word\n  Embedding Algorithms", "comments": "7 Pages. AIAI 2020. 5 equations 6 tables", "journal-ref": "Artificial Intelligence Applications and Innovations. AIAI 2020.\n  IFIP Advances in Information and Communication Technology, vol 584", "doi": "10.1007/978-3-030-49186-4", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word Embeddings are used widely in multiple Natural Language Processing (NLP)\napplications. They are coordinates associated with each word in a dictionary,\ninferred from statistical properties of these words in a large corpus. In this\npaper we introduce the notion of \"concept\" as a list of words that have shared\nsemantic content. We use this notion to analyse the learnability of certain\nconcepts, defined as the capability of a classifier to recognise unseen members\nof a concept after training on a random subset of it. We first use this method\nto measure the learnability of concepts on pretrained word embeddings. We then\ndevelop a statistical analysis of concept learnability, based on hypothesis\ntesting and ROC curves, in order to compare the relative merits of various\nembedding algorithms using a fixed corpora and hyper parameters. We find that\nall embedding methods capture the semantic content of those word lists, but\nfastText performs better than the others.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 14:25:36 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Sutton", "Adam", ""], ["Cristianini", "Nello", ""]]}, {"id": "2006.09920", "submitter": "Arash Vahdat", "authors": "Tanmay Gupta, Arash Vahdat, Gal Chechik, Xiaodong Yang, Jan Kautz, and\n  Derek Hoiem", "title": "Contrastive Learning for Weakly Supervised Phrase Grounding", "comments": "ECCV 2020 (spotlight paper), Project page:\n  http://tanmaygupta.info/info-ground", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phrase grounding, the problem of associating image regions to caption words,\nis a crucial component of vision-language tasks. We show that phrase grounding\ncan be learned by optimizing word-region attention to maximize a lower bound on\nmutual information between images and caption words. Given pairs of images and\ncaptions, we maximize compatibility of the attention-weighted regions and the\nwords in the corresponding caption, compared to non-corresponding pairs of\nimages and captions. A key idea is to construct effective negative captions for\nlearning through language model guided word substitutions. Training with our\nnegatives yields a $\\sim10\\%$ absolute gain in accuracy over randomly-sampled\nnegatives from the training data. Our weakly supervised phrase grounding model\ntrained on COCO-Captions shows a healthy gain of $5.7\\%$ to achieve $76.7\\%$\naccuracy on Flickr30K Entities benchmark.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 15:00:53 GMT"}, {"version": "v2", "created": "Sat, 25 Jul 2020 04:11:42 GMT"}, {"version": "v3", "created": "Wed, 5 Aug 2020 21:53:38 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Gupta", "Tanmay", ""], ["Vahdat", "Arash", ""], ["Chechik", "Gal", ""], ["Yang", "Xiaodong", ""], ["Kautz", "Jan", ""], ["Hoiem", "Derek", ""]]}, {"id": "2006.09977", "submitter": "Shan Jiang", "authors": "Cong Wan, Shan Jiang, Cuirong Wang, Cong Wang, Changming Xu, Xianxia\n  Chen, Ying Yuan", "title": "A novel sentence embedding based topic detection method for micro-blog", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic detection is a challenging task, especially without knowing the exact\nnumber of topics. In this paper, we present a novel approach based on neural\nnetwork to detect topics in the micro-blogging dataset. We use an unsupervised\nneural sentence embedding model to map the blogs to an embedding space. Our\nmodel is a weighted power mean word embedding model, and the weights are\ncalculated by attention mechanism. Experimental result shows our embedding\nmethod performs better than baselines in sentence clustering. In addition, we\npropose an improved clustering algorithm referred as relationship-aware DBSCAN\n(RADBSCAN). It can discover topics from a micro-blogging dataset, and the topic\nnumber depends on dataset character itself. Moreover, in order to solve the\nproblem of parameters sensitive, we take blog forwarding relationship as a\nbridge of two independent clusters. Finally, we validate our approach on a\ndataset from sina micro-blog. The result shows that we can detect all the\ntopics successfully and extract keywords in each topic.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 09:58:57 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Wan", "Cong", ""], ["Jiang", "Shan", ""], ["Wang", "Cuirong", ""], ["Wang", "Cong", ""], ["Xu", "Changming", ""], ["Chen", "Xianxia", ""], ["Yuan", "Ying", ""]]}, {"id": "2006.10022", "submitter": "Forough Arabshahi", "authors": "Forough Arabshahi, Jennifer Lee, Mikayla Gawarecki, Kathryn Mazaitis,\n  Amos Azaria, Tom Mitchell", "title": "Conversational Neuro-Symbolic Commonsense Reasoning", "comments": "Appearing in the 35th AAAI international Conference on Artificial\n  Intelligence, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order for conversational AI systems to hold more natural and broad-ranging\nconversations, they will require much more commonsense, including the ability\nto identify unstated presumptions of their conversational partners. For\nexample, in the command \"If it snows at night then wake me up early because I\ndon't want to be late for work\" the speaker relies on commonsense reasoning of\nthe listener to infer the implicit presumption that they wish to be woken only\nif it snows enough to cause traffic slowdowns. We consider here the problem of\nunderstanding such imprecisely stated natural language commands given in the\nform of \"if-(state), then-(action), because-(goal)\" statements. More precisely,\nwe consider the problem of identifying the unstated presumptions of the speaker\nthat allow the requested action to achieve the desired goal from the given\nstate (perhaps elaborated by making the implicit presumptions explicit). We\nrelease a benchmark data set for this task, collected from humans and annotated\nwith commonsense presumptions. We present a neuro-symbolic theorem prover that\nextracts multi-hop reasoning chains, and apply it to this problem. Furthermore,\nto accommodate the reality that current AI commonsense systems lack full\ncoverage, we also present an interactive conversational framework built on our\nneuro-symbolic system, that conversationally evokes commonsense knowledge from\nhumans to complete its reasoning chains.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 17:28:38 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 18:24:40 GMT"}, {"version": "v3", "created": "Tue, 2 Feb 2021 07:37:41 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Arabshahi", "Forough", ""], ["Lee", "Jennifer", ""], ["Gawarecki", "Mikayla", ""], ["Mazaitis", "Kathryn", ""], ["Azaria", "Amos", ""], ["Mitchell", "Tom", ""]]}, {"id": "2006.10079", "submitter": "R\\'emi Cad\\`ene", "authors": "Corentin Dancette and Remi Cadene and Xinlei Chen and Matthieu Cord", "title": "Overcoming Statistical Shortcuts for Open-ended Visual Counting", "comments": "17 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models tend to over-rely on statistical shortcuts. These\nspurious correlations between parts of the input and the output labels does not\nhold in real-world settings. We target this issue on the recent open-ended\nvisual counting task which is well suited to study statistical shortcuts. We\naim to develop models that learn a proper mechanism of counting regardless of\nthe output label. First, we propose the Modifying Count Distribution (MCD)\nprotocol, which penalizes models that over-rely on statistical shortcuts. It is\nbased on pairs of training and testing sets that do not follow the same count\nlabel distribution such as the odd-even sets. Intuitively, models that have\nlearned a proper mechanism of counting on odd numbers should perform well on\neven numbers. Secondly, we introduce the Spatial Counting Network (SCN), which\nis dedicated to visual analysis and counting based on natural language\nquestions. Our model selects relevant image regions, scores them with fusion\nand self-attention mechanisms, and provides a final counting score. We apply\nour protocol on the recent dataset, TallyQA, and show superior performances\ncompared to state-of-the-art models. We also demonstrate the ability of our\nmodel to select the correct instances to count in the image. Code and datasets\nare available: https://github.com/cdancette/spatial-counting-network\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 18:02:01 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 11:04:02 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Dancette", "Corentin", ""], ["Cadene", "Remi", ""], ["Chen", "Xinlei", ""], ["Cord", "Matthieu", ""]]}, {"id": "2006.10093", "submitter": "Viet Lai", "authors": "Viet Dac Lai, Franck Dernoncourt, Thien Huu Nguyen", "title": "Extensively Matching for Few-shot Learning Event Detection", "comments": "1st Joint Workshop on Narrative Understanding, Storylines, and Events\n  (NUSE) @ ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Current event detection models under super-vised learning settings fail to\ntransfer to newevent types. Few-shot learning has not beenexplored in event\ndetection even though it al-lows a model to perform well with high\ngener-alization on new event types. In this work, weformulate event detection\nas a few-shot learn-ing problem to enable to extend event detec-tion to new\nevent types. We propose two novelloss factors that matching examples in the\nsup-port set to provide more training signals to themodel. Moreover, these\ntraining signals can beapplied in many metric-based few-shot learn-ing models.\nOur extensive experiments on theACE-2005 dataset (under a few-shot\nlearningsetting) show that the proposed method can im-prove the performance of\nfew-shot learning\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 18:30:30 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Lai", "Viet Dac", ""], ["Dernoncourt", "Franck", ""], ["Nguyen", "Thien Huu", ""]]}, {"id": "2006.10145", "submitter": "\\'Eloi Brassard-Gourdeau", "authors": "\\'Eloi Brassard-Gourdeau, Richard Khoury", "title": "Using Sentiment Information for Preemptive Detection of Toxic Comments\n  in Online Conversations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The challenge of automatic detection of toxic comments online has been the\nsubject of a lot of research recently, but the focus has been mostly on\ndetecting it in individual messages after they have been posted. Some authors\nhave tried to predict if a conversation will derail into toxicity using the\nfeatures of the first few messages. In this paper, we combine that approach\nwith previous work on toxicity detection using sentiment information, and show\nhow the sentiments expressed in the first messages of a conversation can help\npredict upcoming toxicity. Our results show that adding sentiment features does\nhelp improve the accuracy of toxicity prediction, and also allow us to make\nimportant observations on the general task of preemptive toxicity detection.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 20:41:57 GMT"}], "update_date": "2020-06-20", "authors_parsed": [["Brassard-Gourdeau", "\u00c9loi", ""], ["Khoury", "Richard", ""]]}, {"id": "2006.10157", "submitter": "Alessandra Cervone", "authors": "Alessandra Cervone, Giuseppe Riccardi", "title": "Is this Dialogue Coherent? Learning from Dialogue Acts and Entities", "comments": "Accepted at SIGDIAL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigate the human perception of coherence in open-domain\ndialogues. In particular, we address the problem of annotating and modeling the\ncoherence of next-turn candidates while considering the entire history of the\ndialogue. First, we create the Switchboard Coherence (SWBD-Coh) corpus, a\ndataset of human-human spoken dialogues annotated with turn coherence ratings,\nwhere next-turn candidate utterances ratings are provided considering the full\ndialogue context. Our statistical analysis of the corpus indicates how turn\ncoherence perception is affected by patterns of distribution of entities\npreviously introduced and the Dialogue Acts used. Second, we experiment with\ndifferent architectures to model entities, Dialogue Acts and their combination\nand evaluate their performance in predicting human coherence ratings on\nSWBD-Coh. We find that models combining both DA and entity information yield\nthe best performances both for response selection and turn coherence rating.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 21:02:40 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Cervone", "Alessandra", ""], ["Riccardi", "Giuseppe", ""]]}, {"id": "2006.10174", "submitter": "Hamed Zamani", "authors": "Hamed Zamani, Gord Lueck, Everest Chen, Rodolfo Quispe, Flint Luu,\n  Nick Craswell", "title": "MIMICS: A Large-Scale Data Collection for Search Clarification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search clarification has recently attracted much attention due to its\napplications in search engines. It has also been recognized as a major\ncomponent in conversational information seeking systems. Despite its\nimportance, the research community still feels the lack of a large-scale data\nfor studying different aspects of search clarification. In this paper, we\nintroduce MIMICS, a collection of search clarification datasets for real web\nsearch queries sampled from the Bing query logs. Each clarification in MIMICS\nis generated by a Bing production algorithm and consists of a clarifying\nquestion and up to five candidate answers. MIMICS contains three datasets: (1)\nMIMICS-Click includes over 400k unique queries, their associated clarification\npanes, and the corresponding aggregated user interaction signals (i.e.,\nclicks). (2) MIMICS-ClickExplore is an exploration data that includes\naggregated user interaction signals for over 60k unique queries, each with\nmultiple clarification panes. (3) MIMICS-Manual includes over 2k unique real\nsearch queries. Each query-clarification pair in this dataset has been manually\nlabeled by at least three trained annotators. It contains graded quality labels\nfor the clarifying question, the candidate answer set, and the landing result\npage for each candidate answer.\n  MIMICS is publicly available for research purposes, thus enables researchers\nto study a number of tasks related to search clarification, including\nclarification generation and selection, user engagement prediction for\nclarification, click models for clarification, and analyzing user interactions\nwith search clarification.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 21:54:41 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Zamani", "Hamed", ""], ["Lueck", "Gord", ""], ["Chen", "Everest", ""], ["Quispe", "Rodolfo", ""], ["Luu", "Flint", ""], ["Craswell", "Nick", ""]]}, {"id": "2006.10207", "submitter": "Lukasz Augustyniak", "authors": "{\\L}ukasz Augustyniak, Krzysztof Rajda, Tomasz Kajdanowicz, Micha{\\l}\n  Bernaczyk", "title": "Political Advertising Dataset: the use case of the Polish 2020\n  Presidential Elections", "comments": "ACL 2020 WiNLP Workshop - accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CC cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Political campaigns are full of political ads posted by candidates on social\nmedia. Political advertisements constitute a basic form of campaigning,\nsubjected to various social requirements. We present the first publicly open\ndataset for detecting specific text chunks and categories of political\nadvertising in the Polish language. It contains 1,705 human-annotated tweets\ntagged with nine categories, which constitute campaigning under Polish\nelectoral law. We achieved a 0.65 inter-annotator agreement (Cohen's kappa\nscore). An additional annotator resolved the mismatches between the first two\nannotators improving the consistency and complexity of the annotation process.\nWe used the newly created dataset to train a well established neural tagger\n(achieving a 70% percent points F1 score). We also present a possible direction\nof use cases for such datasets and models with an initial analysis of the\nPolish 2020 Presidential Elections on Twitter.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 23:58:01 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Augustyniak", "\u0141ukasz", ""], ["Rajda", "Krzysztof", ""], ["Kajdanowicz", "Tomasz", ""], ["Bernaczyk", "Micha\u0142", ""]]}, {"id": "2006.10213", "submitter": "Yao Zhao", "authors": "Yao Zhao, Mohammad Saleh, Peter J.Liu", "title": "SEAL: Segment-wise Extractive-Abstractive Long-form Text Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most prior work in the sequence-to-sequence paradigm focused on datasets with\ninput sequence lengths in the hundreds of tokens due to the computational\nconstraints of common RNN and Transformer architectures. In this paper, we\nstudy long-form abstractive text summarization, a sequence-to-sequence setting\nwith input sequence lengths up to 100,000 tokens and output sequence lengths up\nto 768 tokens. We propose SEAL, a Transformer-based model, featuring a new\nencoder-decoder attention that dynamically extracts/selects input snippets to\nsparsely attend to for each output segment. Using only the original documents\nand summaries, we derive proxy labels that provide weak supervision for\nextractive layers simultaneously with regular supervision from abstractive\nsummaries. The SEAL model achieves state-of-the-art results on existing\nlong-form summarization tasks, and outperforms strong baseline models on a new\ndataset/task we introduce, Search2Wiki, with much longer input text. Since\ncontent selection is explicit in the SEAL model, a desirable side effect is\nthat the selection can be inspected for enhanced interpretability.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 00:13:21 GMT"}], "update_date": "2020-06-20", "authors_parsed": [["Zhao", "Yao", ""], ["Saleh", "Mohammad", ""], ["Liu", "Peter J.", ""]]}, {"id": "2006.10217", "submitter": "Yue Yu", "authors": "Yue Yu, Yinghao Li, Jiaming Shen, Hao Feng, Jimeng Sun and Chao Zhang", "title": "STEAM: Self-Supervised Taxonomy Expansion with Mini-Paths", "comments": "KDD 2020 Research Track Full Paper", "journal-ref": null, "doi": "10.1145/3394486.3403145", "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Taxonomies are important knowledge ontologies that underpin numerous\napplications on a daily basis, but many taxonomies used in practice suffer from\nthe low coverage issue. We study the taxonomy expansion problem, which aims to\nexpand existing taxonomies with new concept terms. We propose a self-supervised\ntaxonomy expansion model named STEAM, which leverages natural supervision in\nthe existing taxonomy for expansion. To generate natural self-supervision\nsignals, STEAM samples mini-paths from the existing taxonomy, and formulates a\nnode attachment prediction task between anchor mini-paths and query terms. To\nsolve the node attachment task, it learns feature representations for\nquery-anchor pairs from multiple views and performs multi-view co-training for\nprediction. Extensive experiments show that STEAM outperforms state-of-the-art\nmethods for taxonomy expansion by 11.6\\% in accuracy and 7.0\\% in mean\nreciprocal rank on three public benchmarks. The implementation of STEAM can be\nfound at \\url{https://github.com/yueyu1030/STEAM}.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 00:32:53 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Yu", "Yue", ""], ["Li", "Yinghao", ""], ["Shen", "Jiaming", ""], ["Feng", "Hao", ""], ["Sun", "Jimeng", ""], ["Zhang", "Chao", ""]]}, {"id": "2006.10270", "submitter": "Yingce Xia", "authors": "Yang Fan, Shufang Xie, Yingce Xia, Lijun Wu, Tao Qin, Xiang-Yang Li,\n  Tie-Yan Liu", "title": "Multi-branch Attentive Transformer", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the multi-branch architecture is one of the key ingredients to the\nsuccess of computer vision tasks, it has not been well investigated in natural\nlanguage processing, especially sequence learning tasks. In this work, we\npropose a simple yet effective variant of Transformer called multi-branch\nattentive Transformer (briefly, MAT), where the attention layer is the average\nof multiple branches and each branch is an independent multi-head attention\nlayer. We leverage two training techniques to regularize the training:\ndrop-branch, which randomly drops individual branches during training, and\nproximal initialization, which uses a pre-trained Transformer model to\ninitialize multiple branches. Experiments on machine translation, code\ngeneration and natural language understanding demonstrate that such a simple\nvariant of Transformer brings significant improvements. Our code is available\nat \\url{https://github.com/HA-Transformer}.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 04:24:28 GMT"}, {"version": "v2", "created": "Sun, 26 Jul 2020 13:04:49 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Fan", "Yang", ""], ["Xie", "Shufang", ""], ["Xia", "Yingce", ""], ["Wu", "Lijun", ""], ["Qin", "Tao", ""], ["Li", "Xiang-Yang", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2006.10276", "submitter": "Yuning Mao", "authors": "Yuning Mao, Tong Zhao, Andrey Kan, Chenwei Zhang, Xin Luna Dong,\n  Christos Faloutsos, Jiawei Han", "title": "Octet: Online Catalog Taxonomy Enrichment with Self-Supervision", "comments": "KDD 2020", "journal-ref": null, "doi": "10.1145/3394486.3403274", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Taxonomies have found wide applications in various domains, especially online\nfor item categorization, browsing, and search. Despite the prevalent use of\nonline catalog taxonomies, most of them in practice are maintained by humans,\nwhich is labor-intensive and difficult to scale. While taxonomy construction\nfrom scratch is considerably studied in the literature, how to effectively\nenrich existing incomplete taxonomies remains an open yet important research\nquestion. Taxonomy enrichment not only requires the robustness to deal with\nemerging terms but also the consistency between existing taxonomy structure and\nnew term attachment. In this paper, we present a self-supervised end-to-end\nframework, Octet, for Online Catalog Taxonomy EnrichmenT. Octet leverages\nheterogeneous information unique to online catalog taxonomies such as user\nqueries, items, and their relations to the taxonomy nodes while requiring no\nother supervision than the existing taxonomies. We propose to distantly train a\nsequence labeling model for term extraction and employ graph neural networks\n(GNNs) to capture the taxonomy structure as well as the query-item-taxonomy\ninteractions for term attachment. Extensive experiments in different online\ndomains demonstrate the superiority of Octet over state-of-the-art methods via\nboth automatic and human evaluations. Notably, Octet enriches an online catalog\ntaxonomy in production to 2 times larger in the open-world evaluation.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 04:53:07 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Mao", "Yuning", ""], ["Zhao", "Tong", ""], ["Kan", "Andrey", ""], ["Zhang", "Chenwei", ""], ["Dong", "Xin Luna", ""], ["Faloutsos", "Christos", ""], ["Han", "Jiawei", ""]]}, {"id": "2006.10304", "submitter": "Juan Pablo Zuluaga-Gomez", "authors": "Juan Zuluaga-Gomez and Petr Motlicek and Qingran Zhan and Karel Vesely\n  and Rudolf Braun", "title": "Automatic Speech Recognition Benchmark for Air-Traffic Communications", "comments": "Accepted to: 21st INTERSPEECH conference (Shanghai, October 25-29)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in Automatic Speech Recognition (ASR) over the last decade opened\nnew areas of speech-based automation such as in Air-Traffic Control (ATC)\nenvironment. Currently, voice communication and data links communications are\nthe only way of contact between pilots and Air-Traffic Controllers (ATCo),\nwhere the former is the most widely used and the latter is a non-spoken method\nmandatory for oceanic messages and limited for some domestic issues. ASR\nsystems on ATCo environments inherit increasing complexity due to accents from\nnon-English speakers, cockpit noise, speaker-dependent biases, and small\nin-domain ATC databases for training. Hereby, we introduce CleanSky EC-H2020\nATCO2, a project that aims to develop an ASR-based platform to collect,\norganize and automatically pre-process ATCo speech-data from air space. This\npaper conveys an exploratory benchmark of several state-of-the-art ASR models\ntrained on more than 170 hours of ATCo speech-data. We demonstrate that the\ncross-accent flaws due to speakers' accents are minimized due to the amount of\ndata, making the system feasible for ATC environments. The developed ASR system\nachieves an averaged word error rate (WER) of 7.75% across four databases. An\nadditional 35% relative improvement in WER is achieved on one test set when\ntraining a TDNNF system with byte-pair encoding.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 06:49:22 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 06:46:34 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Zuluaga-Gomez", "Juan", ""], ["Motlicek", "Petr", ""], ["Zhan", "Qingran", ""], ["Vesely", "Karel", ""], ["Braun", "Rudolf", ""]]}, {"id": "2006.10334", "submitter": "Kenichi Iwatsuki", "authors": "Kenichi Iwatsuki, Florian Boudin and Akiko Aizawa", "title": "Extraction and Evaluation of Formulaic Expressions Used in Scholarly\n  Papers", "comments": "21 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formulaic expressions, such as 'in this paper we propose', are helpful for\nauthors of scholarly papers because they convey communicative functions; in the\nabove, it is showing the aim of this paper'. Thus, resources of formulaic\nexpressions, such as a dictionary, that could be looked up easily would be\nuseful. However, forms of formulaic expressions can often vary to a great\nextent. For example, 'in this paper we propose', 'in this study we propose' and\n'in this paper we propose a new method to' are all regarded as formulaic\nexpressions. Such a diversity of spans and forms causes problems in both\nextraction and evaluation of formulaic expressions. In this paper, we propose a\nnew approach that is robust to variation of spans and forms of formulaic\nexpressions. Our approach regards a sentence as consisting of a formulaic part\nand non-formulaic part. Then, instead of trying to extract formulaic\nexpressions from a whole corpus, by extracting them from each sentence,\ndifferent forms can be dealt with at once. Based on this formulation, to avoid\nthe diversity problem, we propose evaluating extraction methods by how much\nthey convey specific communicative functions rather than by comparing extracted\nexpressions to an existing lexicon. We also propose a new extraction method\nthat utilises named entities and dependency structures to remove the\nnon-formulaic part from a sentence. Experimental results show that the proposed\nextraction method achieved the best performance compared to other existing\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 07:42:45 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Iwatsuki", "Kenichi", ""], ["Boudin", "Florian", ""], ["Aizawa", "Akiko", ""]]}, {"id": "2006.10369", "submitter": "Jungo Kasai", "authors": "Jungo Kasai, Nikolaos Pappas, Hao Peng, James Cross, Noah A. Smith", "title": "Deep Encoder, Shallow Decoder: Reevaluating Non-autoregressive Machine\n  Translation", "comments": "ICLR 2021 Final Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much recent effort has been invested in non-autoregressive neural machine\ntranslation, which appears to be an efficient alternative to state-of-the-art\nautoregressive machine translation on modern GPUs. In contrast to the latter,\nwhere generation is sequential, the former allows generation to be parallelized\nacross target token positions. Some of the latest non-autoregressive models\nhave achieved impressive translation quality-speed tradeoffs compared to\nautoregressive baselines. In this work, we reexamine this tradeoff and argue\nthat autoregressive baselines can be substantially sped up without loss in\naccuracy. Specifically, we study autoregressive models with encoders and\ndecoders of varied depths. Our extensive experiments show that given a\nsufficiently deep encoder, a single-layer autoregressive decoder can\nsubstantially outperform strong non-autoregressive models with comparable\ninference speed. We show that the speed disadvantage for autoregressive\nbaselines compared to non-autoregressive methods has been overestimated in\nthree aspects: suboptimal layer allocation, insufficient speed measurement, and\nlack of knowledge distillation. Our results establish a new protocol for future\nresearch toward fast, accurate machine translation. Our code is available at\nhttps://github.com/jungokasai/deep-shallow.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 09:06:49 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 09:10:57 GMT"}, {"version": "v3", "created": "Sat, 6 Mar 2021 14:47:10 GMT"}, {"version": "v4", "created": "Thu, 24 Jun 2021 21:46:03 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Kasai", "Jungo", ""], ["Pappas", "Nikolaos", ""], ["Peng", "Hao", ""], ["Cross", "James", ""], ["Smith", "Noah A.", ""]]}, {"id": "2006.10413", "submitter": "Nora Kassner", "authors": "Nora Kassner, Benno Krojer, Hinrich Sch\\\"utze", "title": "Are Pretrained Language Models Symbolic Reasoners Over Knowledge?", "comments": "Accepted to CoNLL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can pretrained language models (PLMs) learn factual knowledge from the\ntraining set? We investigate the two most important mechanisms: reasoning and\nmemorization. Prior work has attempted to quantify the number of facts PLMs\nlearn, but we present, using synthetic data, the first study that investigates\nthe causal relation between facts present in training and facts learned by the\nPLM. For reasoning, we show that PLMs seem to learn to apply some symbolic\nreasoning rules correctly but struggle with others, including two-hop\nreasoning. Further analysis suggests that even the application of learned\nreasoning rules is flawed. For memorization, we identify schema conformity\n(facts systematically supported by other facts) and frequency as key factors\nfor its success.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 10:40:37 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 10:09:46 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Kassner", "Nora", ""], ["Krojer", "Benno", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "2006.10598", "submitter": "Bryan Plummer", "authors": "Bryan A. Plummer, Nikoli Dryden, Julius Frost, Torsten Hoefler, Kate\n  Saenko", "title": "Neural Parameter Allocation Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fitting a model into GPU memory during training is an increasing concern as\nmodels continue to grow. Parameter sharing can reduce memory requirements, but\nexisting methods only share parameters between identical layers, limiting their\nimpact. This paper removes these restrictions with a novel task called Neural\nParameter Allocation Search (NPAS), where the goal is to generate weights for a\nnetwork using a given parameter budget. NPAS requires new techniques to morph\navailable parameters to fit any architecture. To address this new task we\nintroduce Shapeshifter Networks (SSNs), which automatically learns where and\nhow to share parameters between all layers in a network, even between layers of\nvarying sizes and operations. SSNs do not require any loss function or\narchitecture modifications, making them easy to use. We evaluate SSNs in key\nNPAS settings using seven network architectures across diverse tasks including\nimage classification, bidirectional image-sentence retrieval, and phrase\ngrounding, creating high performing models even when using as little as 1% of\nthe parameters.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 15:01:00 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 18:43:30 GMT"}, {"version": "v3", "created": "Tue, 13 Apr 2021 14:08:20 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Plummer", "Bryan A.", ""], ["Dryden", "Nikoli", ""], ["Frost", "Julius", ""], ["Hoefler", "Torsten", ""], ["Saenko", "Kate", ""]]}, {"id": "2006.10627", "submitter": "Qian Liu", "authors": "Qian Liu, Shengnan An, Jian-Guang Lou, Bei Chen, Zeqi Lin, Yan Gao,\n  Bin Zhou, Nanning Zheng, Dongmei Zhang", "title": "Compositional Generalization by Learning Analytical Expressions", "comments": "To appear in NeurIPS 2020 (Spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compositional generalization is a basic and essential intellective capability\nof human beings, which allows us to recombine known parts readily. However,\nexisting neural network based models have been proven to be extremely deficient\nin such a capability. Inspired by work in cognition which argues\ncompositionality can be captured by variable slots with symbolic functions, we\npresent a refreshing view that connects a memory-augmented neural model with\nanalytical expressions, to achieve compositional generalization. Our model\nconsists of two cooperative neural modules, Composer and Solver, fitting well\nwith the cognitive argument while being able to be trained in an end-to-end\nmanner via a hierarchical reinforcement learning algorithm. Experiments on the\nwell-known benchmark SCAN demonstrate that our model seizes a great ability of\ncompositional generalization, solving all challenges addressed by previous\nworks with 100% accuracies.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 15:50:57 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 03:47:49 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Liu", "Qian", ""], ["An", "Shengnan", ""], ["Lou", "Jian-Guang", ""], ["Chen", "Bei", ""], ["Lin", "Zeqi", ""], ["Gao", "Yan", ""], ["Zhou", "Bin", ""], ["Zheng", "Nanning", ""], ["Zhang", "Dongmei", ""]]}, {"id": "2006.10632", "submitter": "Yatin Chaudhary", "authors": "Yatin Chaudhary, Hinrich Sch\\\"utze, Pankaj Gupta", "title": "Explainable and Discourse Topic-aware Neural Language Understanding", "comments": "Accepted at ICML2020 (13 pages, 2 figures), acknowledgements added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Marrying topic models and language models exposes language understanding to a\nbroader source of document-level context beyond sentences via topics. While\nintroducing topical semantics in language models, existing approaches\nincorporate latent document topic proportions and ignore topical discourse in\nsentences of the document. This work extends the line of research by\nadditionally introducing an explainable topic representation in language\nunderstanding, obtained from a set of key terms correspondingly for each latent\ntopic of the proportion. Moreover, we retain sentence-topic associations along\nwith document-topic association by modeling topical discourse for every\nsentence in the document. We present a novel neural composite language model\nthat exploits both the latent and explainable topics along with topical\ndiscourse at sentence-level in a joint learning framework of topic and language\nmodels. Experiments over a range of tasks such as language modeling, word sense\ndisambiguation, document classification, retrieval and text generation\ndemonstrate ability of the proposed model in improving language understanding.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 15:53:58 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 08:50:24 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Chaudhary", "Yatin", ""], ["Sch\u00fctze", "Hinrich", ""], ["Gupta", "Pankaj", ""]]}, {"id": "2006.10677", "submitter": "Luke Gessler", "authors": "Luke Gessler, Siyao Peng, Yang Liu, Yilun Zhu, Shabnam Behzad, Amir\n  Zeldes", "title": "AMALGUM -- A Free, Balanced, Multilayer English Web Corpus", "comments": "Accepted at LREC 2020. See\n  https://www.aclweb.org/anthology/2020.lrec-1.648/ (note: ACL Anthology's\n  title is currently out of date)", "journal-ref": "In Proceedings of The 12th Language Resources and Evaluation\n  Conference (pp. 5267-5275), 2020", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We present a freely available, genre-balanced English web corpus totaling 4M\ntokens and featuring a large number of high-quality automatic annotation\nlayers, including dependency trees, non-named entity annotations, coreference\nresolution, and discourse trees in Rhetorical Structure Theory. By tapping open\nonline data sources the corpus is meant to offer a more sizable alternative to\nsmaller manually created annotated data sets, while avoiding pitfalls such as\nimbalanced or unknown composition, licensing problems, and low-quality natural\nlanguage processing. We harness knowledge from multiple annotation layers in\norder to achieve a \"better than NLP\" benchmark and evaluate the accuracy of the\nresulting resource.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 17:05:45 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Gessler", "Luke", ""], ["Peng", "Siyao", ""], ["Liu", "Yang", ""], ["Zhu", "Yilun", ""], ["Behzad", "Shabnam", ""], ["Zeldes", "Amir", ""]]}, {"id": "2006.10713", "submitter": "Nihal V. Nayak", "authors": "Nihal V. Nayak, Stephen H. Bach", "title": "Zero-Shot Learning with Common Sense Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-shot learning relies on semantic class representations such as\nhand-engineered attributes or learned embeddings to predict classes without any\nlabeled examples. We propose to learn class representations from common sense\nknowledge graphs. Common sense knowledge graphs are an untapped source of\nexplicit high-level knowledge that requires little human effort to apply to a\nrange of tasks. To capture the knowledge in the graph, we introduce ZSL-KG, a\ngeneral-purpose framework with a novel transformer graph convolutional network\n(TrGCN) for generating class representations. Our proposed TrGCN architecture\ncomputes non-linear combinations of the node neighbourhood and shows\nimprovements on zero-shot learning tasks in language and vision. Our results\nshow ZSL-KG outperforms the best performing graph-based zero-shot learning\nframework by an average of 2.1 accuracy points with improvements as high as 3.4\naccuracy points. Our ablation study on ZSL-KG with alternate graph neural\nnetworks shows that our TrGCN adds up to 1.2 accuracy points improvement on\nthese tasks.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 17:46:17 GMT"}, {"version": "v2", "created": "Sun, 7 Feb 2021 20:06:18 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Nayak", "Nihal V.", ""], ["Bach", "Stephen H.", ""]]}, {"id": "2006.10909", "submitter": "Pankaj Gupta", "authors": "Pankaj Gupta and Yatin Chaudhary and Thomas Runkler and Hinrich\n  Sch\\\"utze", "title": "Neural Topic Modeling with Continual Lifelong Learning", "comments": "ICML2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lifelong learning has recently attracted attention in building machine\nlearning systems that continually accumulate and transfer knowledge to help\nfuture learning. Unsupervised topic modeling has been popularly used to\ndiscover topics from document collections. However, the application of topic\nmodeling is challenging due to data sparsity, e.g., in a small collection of\n(short) documents and thus, generate incoherent topics and sub-optimal document\nrepresentations. To address the problem, we propose a lifelong learning\nframework for neural topic modeling that can continuously process streams of\ndocument collections, accumulate topics and guide future topic modeling tasks\nby knowledge transfer from several sources to better deal with the sparse data.\nIn the lifelong process, we particularly investigate jointly: (1) sharing\ngenerative homologies (latent topics) over lifetime to transfer prior\nknowledge, and (2) minimizing catastrophic forgetting to retain the past\nlearning via novel selective data augmentation, co-training and topic\nregularization approaches. Given a stream of document collections, we apply the\nproposed Lifelong Neural Topic Modeling (LNTM) framework in modeling three\nsparse document collections as future tasks and demonstrate improved\nperformance quantified by perplexity, topic coherence and information retrieval\ntask.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 00:43:23 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Gupta", "Pankaj", ""], ["Chaudhary", "Yatin", ""], ["Runkler", "Thomas", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "2006.10930", "submitter": "Naoyuki Kanda", "authors": "Naoyuki Kanda, Yashesh Gaur, Xiaofei Wang, Zhong Meng, Zhuo Chen,\n  Tianyan Zhou, Takuya Yoshioka", "title": "Joint Speaker Counting, Speech Recognition, and Speaker Identification\n  for Overlapped Speech of Any Number of Speakers", "comments": "Accepted to INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an end-to-end speaker-attributed automatic speech recognition\nmodel that unifies speaker counting, speech recognition, and speaker\nidentification on monaural overlapped speech. Our model is built on serialized\noutput training (SOT) with attention-based encoder-decoder, a recently proposed\nmethod for recognizing overlapped speech comprising an arbitrary number of\nspeakers. We extend SOT by introducing a speaker inventory as an auxiliary\ninput to produce speaker labels as well as multi-speaker transcriptions. All\nmodel parameters are optimized by speaker-attributed maximum mutual information\ncriterion, which represents a joint probability for overlapped speech\nrecognition and speaker identification. Experiments on LibriSpeech corpus show\nthat our proposed method achieves significantly better speaker-attributed word\nerror rate than the baseline that separately performs overlapped speech\nrecognition and speaker identification.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 02:05:18 GMT"}, {"version": "v2", "created": "Sat, 8 Aug 2020 20:25:22 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Kanda", "Naoyuki", ""], ["Gaur", "Yashesh", ""], ["Wang", "Xiaofei", ""], ["Meng", "Zhong", ""], ["Chen", "Zhuo", ""], ["Zhou", "Tianyan", ""], ["Yoshioka", "Takuya", ""]]}, {"id": "2006.10964", "submitter": "Yanshan Wang", "authors": "David Oniani, Yanshan Wang", "title": "A Qualitative Evaluation of Language Models on Automatic\n  Question-Answering for COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COVID-19 has resulted in an ongoing pandemic and as of 12 June 2020, has\ncaused more than 7.4 million cases and over 418,000 deaths. The highly dynamic\nand rapidly evolving situation with COVID-19 has made it difficult to access\naccurate, on-demand information regarding the disease. Online communities,\nforums, and social media provide potential venues to search for relevant\nquestions and answers, or post questions and seek answers from other members.\nHowever, due to the nature of such sites, there are always a limited number of\nrelevant questions and responses to search from, and posted questions are\nrarely answered immediately. With the advancements in the field of natural\nlanguage processing, particularly in the domain of language models, it has\nbecome possible to design chatbots that can automatically answer consumer\nquestions. However, such models are rarely applied and evaluated in the\nhealthcare domain, to meet the information needs with accurate and up-to-date\nhealthcare data. In this paper, we propose to apply a language model for\nautomatically answering questions related to COVID-19 and qualitatively\nevaluate the generated responses. We utilized the GPT-2 language model and\napplied transfer learning to retrain it on the COVID-19 Open Research Dataset\n(CORD-19) corpus. In order to improve the quality of the generated responses,\nwe applied 4 different approaches, namely tf-idf, BERT, BioBERT, and USE to\nfilter and retain relevant sentences in the responses. In the performance\nevaluation step, we asked two medical experts to rate the responses. We found\nthat BERT and BioBERT, on average, outperform both tf-idf and USE in\nrelevance-based sentence filtering tasks. Additionally, based on the chatbot,\nwe created a user-friendly interactive web application to be hosted online.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 05:13:57 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 20:23:04 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Oniani", "David", ""], ["Wang", "Yanshan", ""]]}, {"id": "2006.10973", "submitter": "Nicolay Rusnachenko", "authors": "Natalia Loukachevitch, Nicolay Rusnachenko", "title": "Sentiment Frames for Attitude Extraction in Russian", "comments": "12 pages, 1 figure, 6 tables", "journal-ref": "Proceedings of the International Conference on Computational\n  Linguistics and Intellectual Technologies \"Dialogue-2020\", 2020, pp.526-537", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Texts can convey several types of inter-related information concerning\nopinions and attitudes. Such information includes the author's attitude towards\nmentioned entities, attitudes of the entities towards each other, positive and\nnegative effects on the entities in the described situations. In this paper, we\ndescribed the lexicon RuSentiFrames for Russian, where predicate words and\nexpressions are collected and linked to so-called sentiment frames conveying\nseveral types of presupposed information on attitudes and effects. We applied\nthe created frames in the task of extracting attitudes from a large news\ncollection.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 06:07:48 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Loukachevitch", "Natalia", ""], ["Rusnachenko", "Nicolay", ""]]}, {"id": "2006.11056", "submitter": "Meishan Zhang", "authors": "Meishan Zhang", "title": "A Survey of Syntactic-Semantic Parsing Based on Constituent and\n  Dependency Structures", "comments": "SCIENCE CHINA Technological Sciences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Syntactic and semantic parsing has been investigated for decades, which is\none primary topic in the natural language processing community. This article\naims for a brief survey on this topic. The parsing community includes many\ntasks, which are difficult to be covered fully. Here we focus on two of the\nmost popular formalizations of parsing: constituent parsing and dependency\nparsing. Constituent parsing is majorly targeted to syntactic analysis, and\ndependency parsing can handle both syntactic and semantic analysis. This\narticle briefly reviews the representative models of constituent parsing and\ndependency parsing, and also dependency graph parsing with rich semantics.\nBesides, we also review the closely-related topics such as cross-domain,\ncross-lingual and joint parsing models, parser application as well as corpus\ndevelopment of parsing in the article.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 10:21:17 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Zhang", "Meishan", ""]]}, {"id": "2006.11063", "submitter": "Ilya Gusev", "authors": "Ilya Gusev", "title": "Dataset for Automatic Summarization of Russian News", "comments": "Version 3, accepted to AINL 2020", "journal-ref": "In: AINL 2020. Communications in Computer and Information Science,\n  vol 1292. Springer, Cham (2020)", "doi": "10.1007/978-3-030-59082-6_9", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic text summarization has been studied in a variety of domains and\nlanguages. However, this does not hold for the Russian language. To overcome\nthis issue, we present Gazeta, the first dataset for summarization of Russian\nnews. We describe the properties of this dataset and benchmark several\nextractive and abstractive models. We demonstrate that the dataset is a valid\ntask for methods of text summarization for Russian. Additionally, we prove the\npretrained mBART model to be useful for Russian text summarization.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 10:44:06 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 23:42:10 GMT"}, {"version": "v3", "created": "Wed, 22 Jul 2020 17:12:48 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Gusev", "Ilya", ""]]}, {"id": "2006.11098", "submitter": "Yair Lakretz", "authors": "Yair Lakretz, Dieuwke Hupkes, Alessandra Vergallito, Marco Marelli,\n  Marco Baroni, Stanislas Dehaene", "title": "Mechanisms for Handling Nested Dependencies in Neural-Network Language\n  Models and Humans", "comments": null, "journal-ref": "Lakretz et al. (2021), Cognition", "doi": "10.1016/j.cognition.2021.104699", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recursive processing in sentence comprehension is considered a hallmark of\nhuman linguistic abilities. However, its underlying neural mechanisms remain\nlargely unknown. We studied whether a modern artificial neural network trained\nwith \"deep learning\" methods mimics a central aspect of human sentence\nprocessing, namely the storing of grammatical number and gender information in\nworking memory and its use in long-distance agreement (e.g., capturing the\ncorrect number agreement between subject and verb when they are separated by\nother phrases). Although the network, a recurrent architecture with Long\nShort-Term Memory units, was solely trained to predict the next word in a large\ncorpus, analysis showed the emergence of a very sparse set of specialized units\nthat successfully handled local and long-distance syntactic agreement for\ngrammatical number. However, the simulations also showed that this mechanism\ndoes not support full recursion and fails with some long-range embedded\ndependencies. We tested the model's predictions in a behavioral experiment\nwhere humans detected violations in number agreement in sentences with\nsystematic variations in the singular/plural status of multiple nouns, with or\nwithout embedding. Human and model error patterns were remarkably similar,\nshowing that the model echoes various effects observed in human data. However,\na key difference was that, with embedded long-range dependencies, humans\nremained above chance level, while the model's systematic errors brought it\nbelow chance. Overall, our study shows that exploring the ways in which modern\nartificial neural networks process sentences leads to precise and testable\nhypotheses about human linguistic performance.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 12:00:05 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 06:25:20 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Lakretz", "Yair", ""], ["Hupkes", "Dieuwke", ""], ["Vergallito", "Alessandra", ""], ["Marelli", "Marco", ""], ["Baroni", "Marco", ""], ["Dehaene", "Stanislas", ""]]}, {"id": "2006.11138", "submitter": "Kiet Nguyen", "authors": "Kiet Van Nguyen, Tin Van Huynh, Duc-Vu Nguyen, Anh Gia-Tuan Nguyen,\n  Ngan Luu-Thuy Nguyen", "title": "New Vietnamese Corpus for Machine Reading Comprehension of Health News\n  Articles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Large-scale and high-quality corpora are necessary for evaluating machine\nreading comprehension models on a low-resource language like Vietnamese.\nBesides, machine reading comprehension (MRC) for the health domain offers great\npotential for practical applications; however, there is still very little MRC\nresearch in this domain. This paper presents ViNewsQA as a new corpus for the\nVietnamese language to evaluate healthcare reading comprehension models. The\ncorpus comprises 22,057 human-generated question-answer pairs. Crowd-workers\ncreate the questions and their answers based on a collection of over 4,416\nonline Vietnamese healthcare news articles, where the answers comprise spans\nextracted from the corresponding articles. In particular, we develop a process\nof creating a corpus for the Vietnamese machine reading comprehension.\nComprehensive evaluations demonstrate that our corpus requires abilities beyond\nsimple reasoning, such as word matching and demanding difficult reasoning based\non single-or-multiple-sentence information. We conduct experiments using\ndifferent types of machine reading comprehension methods to achieve the first\nbaseline performances, compared with further models' performances. We also\nmeasure human performance on the corpus and compared it with several powerful\nneural network-based and transfer learning-based models. Our experiments show\nthat the best machine model is ALBERT, which achieves an exact match score of\n65.26% and an F1-score of 84.89% on our corpus. The significant differences\nbetween humans and the best-performance model (14.53% of EM and 10.90% of\nF1-score) on the test set of our corpus indicate that improvements in ViNewsQA\ncould be explored in the future study. Our corpus is publicly available on our\nwebsite for the research purpose to encourage the research community to make\nthese improvements.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 13:49:26 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 12:50:41 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Van Nguyen", "Kiet", ""], ["Van Huynh", "Tin", ""], ["Nguyen", "Duc-Vu", ""], ["Nguyen", "Anh Gia-Tuan", ""], ["Nguyen", "Ngan Luu-Thuy", ""]]}, {"id": "2006.11159", "submitter": "Martin Van Harmelen", "authors": "Martin van Harmelen, Jonas Groschwitz", "title": "Graphs with Multiple Sources per Vertex", "comments": "Supervision by Jonas Groschwitz", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several attempts have been made at constructing Abstract Meaning\nRepresentations (AMRs) compositionally, and recently the idea of using s-graphs\nwith the HR-algebra (Koller, 2015) has been simplified to reduce the number of\noptions when parsing (Groschwitz et al., 2017). This apply-modify algebra\n(AM-algebra) is a linguistically plausible graph algebra with two classes of\noperations, both of rank two: the apply operation is used to combine a\npredicate with its argument; the modify operation is used to modify a\npredicate. While the AM-algebra correctly handles relative clauses and complex\ncases of coordination, it cannot parse reflexive sentences like: \"The raven\nwashes herself.\" To facilitate processing of such reflexive sentences, this\npaper proposes to change the definition of s-graphs underlying the AM-algebra\nto allow vertices with multiple sources, and additionally proposes an adaption\nto the type system of the algebra to correctly handle such vertices.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 14:43:12 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["van Harmelen", "Martin", ""], ["Groschwitz", "Jonas", ""]]}, {"id": "2006.11316", "submitter": "Forrest Iandola", "authors": "Forrest N. Iandola, Albert E. Shaw, Ravi Krishna, Kurt W. Keutzer", "title": "SqueezeBERT: What can computer vision teach NLP about efficient neural\n  networks?", "comments": "9 pages + appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans read and write hundreds of billions of messages every day. Further,\ndue to the availability of large datasets, large computing systems, and better\nneural network models, natural language processing (NLP) technology has made\nsignificant strides in understanding, proofreading, and organizing these\nmessages. Thus, there is a significant opportunity to deploy NLP in myriad\napplications to help web users, social networks, and businesses. In particular,\nwe consider smartphones and other mobile devices as crucial platforms for\ndeploying NLP models at scale. However, today's highly-accurate NLP neural\nnetwork models such as BERT and RoBERTa are extremely computationally\nexpensive, with BERT-base taking 1.7 seconds to classify a text snippet on a\nPixel 3 smartphone. In this work, we observe that methods such as grouped\nconvolutions have yielded significant speedups for computer vision networks,\nbut many of these techniques have not been adopted by NLP neural network\ndesigners. We demonstrate how to replace several operations in self-attention\nlayers with grouped convolutions, and we use this technique in a novel network\narchitecture called SqueezeBERT, which runs 4.3x faster than BERT-base on the\nPixel 3 while achieving competitive accuracy on the GLUE test set. The\nSqueezeBERT code will be released.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 18:40:29 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Iandola", "Forrest N.", ""], ["Shaw", "Albert E.", ""], ["Krishna", "Ravi", ""], ["Keutzer", "Kurt W.", ""]]}, {"id": "2006.11405", "submitter": "Chongyang Bai", "authors": "Chongyang Bai, Haipeng Chen, Srijan Kumar, Jure Leskovec, V.S.\n  Subrahmanian", "title": "M2P2: Multimodal Persuasion Prediction using Adaptive Fusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG cs.MM cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Identifying persuasive speakers in an adversarial environment is a critical\ntask. In a national election, politicians would like to have persuasive\nspeakers campaign on their behalf. When a company faces adverse publicity, they\nwould like to engage persuasive advocates for their position in the presence of\nadversaries who are critical of them. Debates represent a common platform for\nthese forms of adversarial persuasion. This paper solves two problems: the\nDebate Outcome Prediction (DOP) problem predicts who wins a debate while the\nIntensity of Persuasion Prediction (IPP) problem predicts the change in the\nnumber of votes before and after a speaker speaks. Though DOP has been\npreviously studied, we are the first to study IPP. Past studies on DOP fail to\nleverage two important aspects of multimodal data: 1) multiple modalities are\noften semantically aligned, and 2) different modalities may provide diverse\ninformation for prediction. Our M2P2 (Multimodal Persuasion Prediction)\nframework is the first to use multimodal (acoustic, visual, language) data to\nsolve the IPP problem. To leverage the alignment of different modalities while\nmaintaining the diversity of the cues they provide, M2P2 devises a novel\nadaptive fusion learning framework which fuses embeddings obtained from two\nmodules -- an alignment module that extracts shared information between\nmodalities and a heterogeneity module that learns the weights of different\nmodalities with guidance from three separately trained unimodal reference\nmodels. We test M2P2 on the popular IQ2US dataset designed for DOP. We also\nintroduce a new dataset called QPS (from Qipashuo, a popular Chinese debate TV\nshow ) for IPP. M2P2 significantly outperforms 3 recent baselines on both\ndatasets. Our code and QPS dataset can be found at\nhttp://snap.stanford.edu/m2p2/.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 18:47:24 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Bai", "Chongyang", ""], ["Chen", "Haipeng", ""], ["Kumar", "Srijan", ""], ["Leskovec", "Jure", ""], ["Subrahmanian", "V. S.", ""]]}, {"id": "2006.11465", "submitter": "Junpei Zhong", "authors": "Junpei Zhong and Angelo Cangelosi and Stefan Wermter", "title": "Towards a self-organizing pre-symbolic neural model representing\n  sensorimotor primitives", "comments": null, "journal-ref": "Frontiers in behavioral neuroscience, 8, 22 (2014)", "doi": "10.3389/fnbeh.2014.00022", "report-no": null, "categories": "cs.NE cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The acquisition of symbolic and linguistic representations of sensorimotor\nbehavior is a cognitive process performed by an agent when it is executing\nand/or observing own and others' actions. According to Piaget's theory of\ncognitive development, these representations develop during the sensorimotor\nstage and the pre-operational stage. We propose a model that relates the\nconceptualization of the higher-level information from visual stimuli to the\ndevelopment of ventral/dorsal visual streams. This model employs neural network\narchitecture incorporating a predictive sensory module based on an RNNPB\n(Recurrent Neural Network with Parametric Biases) and a horizontal product\nmodel. We exemplify this model through a robot passively observing an object to\nlearn its features and movements. During the learning process of observing\nsensorimotor primitives, i.e. observing a set of trajectories of arm movements\nand its oriented object features, the pre-symbolic representation is\nself-organized in the parametric units. These representational units act as\nbifurcation parameters, guiding the robot to recognize and predict various\nlearned sensorimotor primitives. The pre-symbolic representation also accounts\nfor the learning of sensorimotor primitives in a latent learning context.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 01:58:28 GMT"}, {"version": "v2", "created": "Sun, 12 Jul 2020 04:30:56 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Zhong", "Junpei", ""], ["Cangelosi", "Angelo", ""], ["Wermter", "Stefan", ""]]}, {"id": "2006.11477", "submitter": "Michael Auli", "authors": "Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, Michael Auli", "title": "wav2vec 2.0: A Framework for Self-Supervised Learning of Speech\n  Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show for the first time that learning powerful representations from speech\naudio alone followed by fine-tuning on transcribed speech can outperform the\nbest semi-supervised methods while being conceptually simpler. wav2vec 2.0\nmasks the speech input in the latent space and solves a contrastive task\ndefined over a quantization of the latent representations which are jointly\nlearned. Experiments using all labeled data of Librispeech achieve 1.8/3.3 WER\non the clean/other test sets. When lowering the amount of labeled data to one\nhour, wav2vec 2.0 outperforms the previous state of the art on the 100 hour\nsubset while using 100 times less labeled data. Using just ten minutes of\nlabeled data and pre-training on 53k hours of unlabeled data still achieves\n4.8/8.2 WER. This demonstrates the feasibility of speech recognition with\nlimited amounts of labeled data.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 02:35:02 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 04:26:03 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 06:09:10 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Baevski", "Alexei", ""], ["Zhou", "Henry", ""], ["Mohamed", "Abdelrahman", ""], ["Auli", "Michael", ""]]}, {"id": "2006.11511", "submitter": "Abhijit Mahabal", "authors": "Abhijit Mahabal, Yinrui Li, Rajat Raina, Daniel Sun, Revati Mahajan,\n  Jure Leskovec", "title": "Improving Query Safety at Pinterest", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Query recommendations in search engines is a double edged sword, with\nundeniable benefits but potential of harm. Identifying unsafe queries is\nnecessary to protect users from inappropriate query suggestions. However,\nidentifying these is non-trivial because of the linguistic diversity resulting\nfrom large vocabularies, social-group-specific slang and typos, and because the\ninappropriateness of a term depends on the context. Here we formulate the\nproblem as query-set expansion, where we are given a small and potentially\nbiased seed set and the aim is to identify a diverse set of semantically\nrelated queries. We present PinSets, a system for query-set expansion, which\napplies a simple yet powerful mechanism to search user sessions, expanding a\ntiny seed set into thousands of related queries at nearly perfect precision,\ndeep into the tail, along with explanations that are easy to interpret. PinSets\nowes its high quality expansion to using a hybrid of textual and behavioral\ntechniques (i.e., treating queries both as compositional and as black boxes).\nExperiments show that, for the domain of drugs-related queries, PinSets expands\n20 seed queries into 15,670 positive training examples at over 99\\% precision.\nThe generated expansions have diverse vocabulary and correctly handles words\nwith ambiguous safety. PinSets decreased unsafe query suggestions at Pinterest\nby 90\\%.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 07:35:22 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 04:12:09 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Mahabal", "Abhijit", ""], ["Li", "Yinrui", ""], ["Raina", "Rajat", ""], ["Sun", "Daniel", ""], ["Mahajan", "Revati", ""], ["Leskovec", "Jure", ""]]}, {"id": "2006.11512", "submitter": "Akshay Khatri", "authors": "Akshay Khatri, Pranav P and Dr. Anand Kumar M", "title": "Sarcasm Detection in Tweets with BERT and GloVe Embeddings", "comments": "5 pages Submitted to ACL 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sarcasm is a form of communication in whichthe person states opposite of what\nhe actually means. It is ambiguous in nature. In this paper, we propose using\nmachine learning techniques with BERT and GloVe embeddings to detect sarcasm in\ntweets. The dataset is preprocessed before extracting the embeddings. The\nproposed model also uses the context in which the user is reacting to along\nwith his actual response.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 07:36:06 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Khatri", "Akshay", ""], ["P", "Pranav", ""], ["M", "Dr. Anand Kumar", ""]]}, {"id": "2006.11527", "submitter": "Mikhail Burtsev", "authors": "Mikhail S. Burtsev, Yuri Kuratov, Anton Peganov, Grigory V. Sapunov", "title": "Memory Transformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer-based models have achieved state-of-the-art results in many\nnatural language processing tasks. The self-attention architecture allows\ntransformer to combine information from all elements of a sequence into\ncontext-aware representations. However, information about the context is stored\nmostly in the same element-wise representations. This might limit the\nprocessing of properties related to the sequence as a whole more difficult.\nAdding trainable memory to selectively store local as well as global\nrepresentations of a sequence is a promising direction to improve the\nTransformer model. Memory-augmented neural networks (MANNs) extend traditional\nneural architectures with general-purpose memory for representations. MANNs\nhave demonstrated the capability to learn simple algorithms like Copy or\nReverse and can be successfully trained via backpropagation on diverse tasks\nfrom question answering to language modeling outperforming RNNs and LSTMs of\ncomparable complexity. In this work, we propose and study few extensions of the\nTransformer baseline (1) by adding memory tokens to store non-local\nrepresentations, (2) creating memory bottleneck for the global information, (3)\ncontrolling memory update with dedicated layer. We evaluate these memory\naugmented Transformers and demonstrate that presence of memory positively\ncorrelates with the model performance for machine translation and language\nmodelling tasks. Augmentation of pre-trained masked language model with memory\ntokens shows mixed results for tasks from GLUE benchmark. Visualization of\nattention patterns over the memory suggest that it improves the model's ability\nto process a global context.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 09:06:27 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 08:06:47 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Burtsev", "Mikhail S.", ""], ["Kuratov", "Yuri", ""], ["Peganov", "Anton", ""], ["Sapunov", "Grigory V.", ""]]}, {"id": "2006.11534", "submitter": "Hamid Zafar", "authors": "Hamid Zafar, Mohnish Dubey, Jens Lehmann, Elena Demidova", "title": "IQA: Interactive Query Construction in Semantic Question Answering\n  Systems", "comments": null, "journal-ref": "Journal of Web Semantics Volume 64, October 2020, 100586", "doi": "10.1016/j.websem.2020.100586", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic Question Answering (SQA) systems automatically interpret user\nquestions expressed in a natural language in terms of semantic queries. This\nprocess involves uncertainty, such that the resulting queries do not always\naccurately match the user intent, especially for more complex and less common\nquestions. In this article, we aim to empower users in guiding SQA systems\ntowards the intended semantic queries through interaction. We introduce IQA -\nan interaction scheme for SQA pipelines. This scheme facilitates seamless\nintegration of user feedback in the question answering process and relies on\nOption Gain - a novel metric that enables efficient and intuitive user\ninteraction. Our evaluation shows that using the proposed scheme, even a small\nnumber of user interactions can lead to significant improvements in the\nperformance of SQA systems.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 10:02:20 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 07:41:43 GMT"}, {"version": "v3", "created": "Thu, 25 Jun 2020 05:17:03 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Zafar", "Hamid", ""], ["Dubey", "Mohnish", ""], ["Lehmann", "Jens", ""], ["Demidova", "Elena", ""]]}, {"id": "2006.11548", "submitter": "Diego Alexander Huerfano Villalba", "authors": "Diego Alexander Hu\\'erfano Villalba and Elizabeth Le\\'on Guzm\\'an", "title": "Named Entity Extraction with Finite State Transducers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a named entity tagging system that requires minimal linguistic\nknowledge and can be applied to more target languages without substantial\nchanges. The system is based on the ideas of the Brill's tagger which makes it\nreally simple. Using supervised machine learning, we construct a series of\nautomatons (or transducers) in order to tag a given text. The final model is\ncomposed entirely of automatons and it requires a lineal time for tagging. It\nwas tested with the Spanish data set provided in the CoNLL-$2002$ attaining an\noverall $F_{\\beta = 1}$ measure of $60\\%.$ Also, we present an algorithm for\nthe construction of the final transducer used to encode all the learned\ncontextual rules.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 11:09:04 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Villalba", "Diego Alexander Hu\u00e9rfano", ""], ["Guzm\u00e1n", "Elizabeth Le\u00f3n", ""]]}, {"id": "2006.11558", "submitter": "Thoudam Doren Singh", "authors": "Thoudam Doren Singh, Abdullah Faiz Ur Rahman Khilji, Divyansha,\n  Apoorva Vikram Singh, Surmila Thokchom and Sivaji Bandyopadhyay", "title": "Seq2Seq and Joint Learning Based Unix Command Line Prediction System", "comments": "9 pages, 1 Figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite being an open-source operating system pioneered in the early 90s,\nUNIX based platforms have not been able to garner an overwhelming reception\nfrom amateur end users. One of the rationales for under popularity of UNIX\nbased systems is the steep learning curve corresponding to them due to\nextensive use of command line interface instead of usual interactive graphical\nuser interface. In past years, the majority of insights used to explore the\nconcern are eminently centered around the notion of utilizing chronic log\nhistory of the user to make the prediction of successive command. The\napproaches directed at anatomization of this notion are predominantly in\naccordance with Probabilistic inference models. The techniques employed in\npast, however, have not been competent enough to address the predicament as\nlegitimately as anticipated. Instead of deploying usual mechanism of\nrecommendation systems, we have employed a simple yet novel approach of Seq2seq\nmodel by leveraging continuous representations of self-curated exhaustive\nKnowledge Base (KB) to enhance the embedding employed in the model. This work\ndescribes an assistive, adaptive and dynamic way of enhancing UNIX command line\nprediction systems. Experimental methods state that our model has achieved\naccuracy surpassing mixture of other techniques and adaptive command line\ninterface mechanism as acclaimed in the past.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 11:57:01 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Singh", "Thoudam Doren", ""], ["Khilji", "Abdullah Faiz Ur Rahman", ""], ["Divyansha", "", ""], ["Singh", "Apoorva Vikram", ""], ["Thokchom", "Surmila", ""], ["Bandyopadhyay", "Sivaji", ""]]}, {"id": "2006.11572", "submitter": "Ekaterina Vylomova", "authors": "Ekaterina Vylomova, Jennifer White, Elizabeth Salesky, Sabrina J.\n  Mielke, Shijie Wu, Edoardo Ponti, Rowan Hall Maudslay, Ran Zmigrod, Josef\n  Valvoda, Svetlana Toldova, Francis Tyers, Elena Klyachko, Ilya Yegorov,\n  Natalia Krizhanovsky, Paula Czarnowska, Irene Nikkarinen, Andrew\n  Krizhanovsky, Tiago Pimentel, Lucas Torroba Hennigen, Christo Kirov, Garrett\n  Nicolai, Adina Williams, Antonios Anastasopoulos, Hilaria Cruz, Eleanor\n  Chodroff, Ryan Cotterell, Miikka Silfverberg, Mans Hulden", "title": "SIGMORPHON 2020 Shared Task 0: Typologically Diverse Morphological\n  Inflection", "comments": "39 pages, SIGMORPHON", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A broad goal in natural language processing (NLP) is to develop a system that\nhas the capacity to process any natural language. Most systems, however, are\ndeveloped using data from just one language such as English. The SIGMORPHON\n2020 shared task on morphological reinflection aims to investigate systems'\nability to generalize across typologically distinct languages, many of which\nare low resource. Systems were developed using data from 45 languages and just\n5 language families, fine-tuned with data from an additional 45 languages and\n10 language families (13 in total), and evaluated on all 90 languages. A total\nof 22 systems (19 neural) from 10 teams were submitted to the task. All four\nwinning systems were neural (two monolingual transformers and two massively\nmultilingual RNN-based models with gated attention). Most teams demonstrate\nutility of data hallucination and augmentation, ensembles, and multilingual\ntraining for low-resource languages. Non-neural learners and manually designed\ngrammars showed competitive and even superior performance on some languages\n(such as Ingrian, Tajik, Tagalog, Zarma, Lingala), especially with very limited\ndata. Some language families (Afro-Asiatic, Niger-Congo, Turkic) were\nrelatively easy for most systems and achieved over 90% mean accuracy while\nothers were more challenging.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 13:24:14 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 11:17:11 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Vylomova", "Ekaterina", ""], ["White", "Jennifer", ""], ["Salesky", "Elizabeth", ""], ["Mielke", "Sabrina J.", ""], ["Wu", "Shijie", ""], ["Ponti", "Edoardo", ""], ["Maudslay", "Rowan Hall", ""], ["Zmigrod", "Ran", ""], ["Valvoda", "Josef", ""], ["Toldova", "Svetlana", ""], ["Tyers", "Francis", ""], ["Klyachko", "Elena", ""], ["Yegorov", "Ilya", ""], ["Krizhanovsky", "Natalia", ""], ["Czarnowska", "Paula", ""], ["Nikkarinen", "Irene", ""], ["Krizhanovsky", "Andrew", ""], ["Pimentel", "Tiago", ""], ["Hennigen", "Lucas Torroba", ""], ["Kirov", "Christo", ""], ["Nicolai", "Garrett", ""], ["Williams", "Adina", ""], ["Anastasopoulos", "Antonios", ""], ["Cruz", "Hilaria", ""], ["Chodroff", "Eleanor", ""], ["Cotterell", "Ryan", ""], ["Silfverberg", "Miikka", ""], ["Hulden", "Mans", ""]]}, {"id": "2006.11578", "submitter": "Antonio Henrique De Oliveira Fonseca", "authors": "Antonio H. O. Fonseca and David van Dijk", "title": "Learning aligned embeddings for semi-supervised word translation using\n  Maximum Mean Discrepancy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word translation is an integral part of language translation. In machine\ntranslation, each language is considered a domain with its own word embedding.\nThe alignment between word embeddings allows linking semantically equivalent\nwords in multilingual contexts. Moreover, it offers a way to infer\ncross-lingual meaning for words without a direct translation. Current methods\nfor word embedding alignment are either supervised, i.e. they require known\nword pairs, or learn a cross-domain transformation on fixed embeddings in an\nunsupervised way. Here we propose an end-to-end approach for word embedding\nalignment that does not require known word pairs. Our method, termed Word\nAlignment through MMD (WAM), learns embeddings that are aligned during sentence\ntranslation training using a localized Maximum Mean Discrepancy (MMD)\nconstraint between the embeddings. We show that our method not only\nout-performs unsupervised methods, but also supervised methods that train on\nknown word translations.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 13:57:55 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Fonseca", "Antonio H. O.", ""], ["van Dijk", "David", ""]]}, {"id": "2006.11586", "submitter": "Mahmoud Daif", "authors": "Mahmoud Daif, Shunsuke Kitada, Hitoshi Iyatomi", "title": "AraDIC: Arabic Document Classification using Image-Based Character\n  Embeddings and Class-Balanced Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical and some deep learning techniques for Arabic text classification\noften depend on complex morphological analysis, word segmentation, and\nhand-crafted feature engineering. These could be eliminated by using\ncharacter-level features. We propose a novel end-to-end Arabic document\nclassification framework, Arabic document image-based classifier (AraDIC),\ninspired by the work on image-based character embeddings. AraDIC consists of an\nimage-based character encoder and a classifier. They are trained in an\nend-to-end fashion using the class balanced loss to deal with the long-tailed\ndata distribution problem. To evaluate the effectiveness of AraDIC, we created\nand published two datasets, the Arabic Wikipedia title (AWT) dataset and the\nArabic poetry (AraP) dataset. To the best of our knowledge, this is the first\nimage-based character embedding framework addressing the problem of Arabic text\nclassification. We also present the first deep learning-based text classifier\nwidely evaluated on modern standard Arabic, colloquial Arabic and classical\nArabic. AraDIC shows performance improvement over classical and deep learning\nbaselines by 12.29% and 23.05% for the micro and macro F-score, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 14:25:06 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Daif", "Mahmoud", ""], ["Kitada", "Shunsuke", ""], ["Iyatomi", "Hitoshi", ""]]}, {"id": "2006.11605", "submitter": "Nicolay Rusnachenko", "authors": "Nicolay Rusnachenko, Natalia Loukachevitch", "title": "Studying Attention Models in Sentiment Attitude Extraction Task", "comments": "This is a preprint of an article published in the Proceedings of the\n  25th International Conference on Natural Language and Information Systems.\n  The final authenticated publication is available online at\n  https://doi.org/10.1007/978-3-030-51310-8_15", "journal-ref": "M\\'etais E., Meziane F., Horacek H., Cimiano P. (eds) Natural\n  Language Processing and Information Systems. NLDB 2020. Lecture Notes in\n  Computer Science, vol 12089. Springer, Cham", "doi": "10.1007/978-3-030-51310-8_15", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the sentiment attitude extraction task, the aim is to identify\n<<attitudes>> -- sentiment relations between entities mentioned in text. In\nthis paper, we provide a study on attention-based context encoders in the\nsentiment attitude extraction task. For this task, we adapt attentive context\nencoders of two types: (i) feature-based; (ii) self-based. Our experiments with\na corpus of Russian analytical texts RuSentRel illustrate that the models\ntrained with attentive encoders outperform ones that were trained without them\nand achieve 1.5-5.9% increase by F1. We also provide the analysis of attention\nweight distributions in dependence on the term type.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 16:09:24 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Rusnachenko", "Nicolay", ""], ["Loukachevitch", "Natalia", ""]]}, {"id": "2006.11627", "submitter": "Yi Zhou", "authors": "Yi Zhou, Xiaoqing Zheng, Cho-Jui Hsieh, Kai-wei Chang, Xuanjing Huang", "title": "Defense against Adversarial Attacks in NLP via Dirichlet Neighborhood\n  Ensemble", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite neural networks have achieved prominent performance on many natural\nlanguage processing (NLP) tasks, they are vulnerable to adversarial examples.\nIn this paper, we propose Dirichlet Neighborhood Ensemble (DNE), a randomized\nsmoothing method for training a robust model to defense substitution-based\nattacks. During training, DNE forms virtual sentences by sampling embedding\nvectors for each word in an input sentence from a convex hull spanned by the\nword and its synonyms, and it augments them with the training data. In such a\nway, the model is robust to adversarial attacks while maintaining the\nperformance on the original clean data. DNE is agnostic to the network\narchitectures and scales to large models for NLP applications. We demonstrate\nthrough extensive experimentation that our method consistently outperforms\nrecently proposed defense methods by a significant margin across different\nnetwork architectures and multiple data sets.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 18:01:16 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Zhou", "Yi", ""], ["Zheng", "Xiaoqing", ""], ["Hsieh", "Cho-Jui", ""], ["Chang", "Kai-wei", ""], ["Huang", "Xuanjing", ""]]}, {"id": "2006.11642", "submitter": "Yuhao Du", "authors": "Yuhao Du and Kenneth Joseph", "title": "MDR Cluster-Debias: A Nonlinear WordEmbedding Debiasing Pipeline", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing methods for debiasing word embeddings often do so only\nsuperficially, in that words that are stereotypically associated with, e.g., a\nparticular gender in the original embedding space can still be clustered\ntogether in the debiased space. However, there has yet to be a study that\nexplores why this residual clustering exists, and how it might be addressed.\nThe present work fills this gap. We identify two potential reasons for which\nresidual bias exists and develop a new pipeline, MDR Cluster-Debias, to\nmitigate this bias. We explore the strengths and weaknesses of our method,\nfinding that it significantly outperforms other existing debiasing approaches\non a variety of upstream bias tests but achieves limited improvement on\ndecreasing gender bias in a downstream task. This indicates that word\nembeddings encode gender bias in still other ways, not necessarily captured by\nupstream tests.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 20:03:07 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Du", "Yuhao", ""], ["Joseph", "Kenneth", ""]]}, {"id": "2006.11646", "submitter": "Lifeng Jin", "authors": "Lifeng Jin and William Schuler", "title": "The Importance of Category Labels in Grammar Induction with\n  Child-directed Utterances", "comments": "The 16th International Conference on Parsing Technologies (IWPT 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in grammar induction has shown that grammar induction is\npossible without explicit assumptions of language-specific knowledge. However,\nevaluation of induced grammars usually has ignored phrasal labels, an essential\npart of a grammar. Experiments in this work using a labeled evaluation metric,\nRH, show that linguistically motivated predictions about grammar sparsity and\nuse of categories can only be revealed through labeled evaluation. Furthermore,\ndepth-bounding as an implementation of human memory constraints in grammar\ninducers is still effective with labeled evaluation on multilingual transcribed\nchild-directed utterances.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 20:21:17 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Jin", "Lifeng", ""], ["Schuler", "William", ""]]}, {"id": "2006.11719", "submitter": "Liu Yang", "authors": "Zizhen Wang, Yixing Fan, Jiafeng Guo, Liu Yang, Ruqing Zhang, Yanyan\n  Lan, Xueqi Cheng, Hui Jiang, Xiaozhao Wang", "title": "Match$^2$: A Matching over Matching Model for Similar Question\n  Identification", "comments": "Accepted by SIGIR 2020. 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community Question Answering (CQA) has become a primary means for people to\nacquire knowledge, where people are free to ask questions or submit answers. To\nenhance the efficiency of the service, similar question identification becomes\na core task in CQA which aims to find a similar question from the archived\nrepository whenever a new question is asked. However, it has long been a\nchallenge to properly measure the similarity between two questions due to the\ninherent variation of natural language, i.e., there could be different ways to\nask a same question or different questions sharing similar expressions. To\nalleviate this problem, it is natural to involve the existing answers for the\nenrichment of the archived questions. Traditional methods typically take a\none-side usage, which leverages the answer as some expanded representation of\nthe corresponding question. Unfortunately, this may introduce unexpected noises\ninto the similarity computation since answers are often long and diverse,\nleading to inferior performance. In this work, we propose a two-side usage,\nwhich leverages the answer as a bridge of the two questions. The key idea is\nbased on our observation that similar questions could be addressed by similar\nparts of the answer while different questions may not. In other words, we can\ncompare the matching patterns of the two questions over the same answer to\nmeasure their similarity. In this way, we propose a novel matching over\nmatching model, namely Match$^2$, which compares the matching patterns between\ntwo question-answer pairs for similar question identification. Empirical\nexperiments on two benchmark datasets demonstrate that our model can\nsignificantly outperform previous state-of-the-art methods on the similar\nquestion identification task.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2020 05:59:34 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Wang", "Zizhen", ""], ["Fan", "Yixing", ""], ["Guo", "Jiafeng", ""], ["Yang", "Liu", ""], ["Zhang", "Ruqing", ""], ["Lan", "Yanyan", ""], ["Cheng", "Xueqi", ""], ["Jiang", "Hui", ""], ["Wang", "Xiaozhao", ""]]}, {"id": "2006.11807", "submitter": "Zhan Shi", "authors": "Zhan Shi, Xu Zhou, Xipeng Qiu, Xiaodan Zhu", "title": "Improving Image Captioning with Better Use of Captions", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image captioning is a multimodal problem that has drawn extensive attention\nin both the natural language processing and computer vision community. In this\npaper, we present a novel image captioning architecture to better explore\nsemantics available in captions and leverage that to enhance both image\nrepresentation and caption generation. Our models first construct\ncaption-guided visual relationship graphs that introduce beneficial inductive\nbias using weakly supervised multi-instance learning. The representation is\nthen enhanced with neighbouring and contextual nodes with their textual and\nvisual features. During generation, the model further incorporates visual\nrelationships using multi-task learning for jointly predicting word and\nobject/predicate tag sequences. We perform extensive experiments on the MSCOCO\ndataset, showing that the proposed framework significantly outperforms the\nbaselines, resulting in the state-of-the-art performance under a wide range of\nevaluation metrics.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2020 14:10:47 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Shi", "Zhan", ""], ["Zhou", "Xu", ""], ["Qiu", "Xipeng", ""], ["Zhu", "Xiaodan", ""]]}, {"id": "2006.11824", "submitter": "Changlong Yu", "authors": "Changlong Yu, Hongming Zhang, Yangqiu Song, Wilfred Ng, Lifeng Shang", "title": "Enriching Large-Scale Eventuality Knowledge Graph with Entailment\n  Relations", "comments": "Accepted by AKBC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational and cognitive studies suggest that the abstraction of\neventualities (activities, states, and events) is crucial for humans to\nunderstand daily eventualities. In this paper, we propose a scalable approach\nto model the entailment relations between eventualities (\"eat an apple''\nentails ''eat fruit''). As a result, we construct a large-scale eventuality\nentailment graph (EEG), which has 10 million eventuality nodes and 103 million\nentailment edges. Detailed experiments and analysis demonstrate the\neffectiveness of the proposed approach and quality of the resulting knowledge\ngraph. Our datasets and code are available at\nhttps://github.com/HKUST-KnowComp/ASER-EEG.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2020 15:22:03 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Yu", "Changlong", ""], ["Zhang", "Hongming", ""], ["Song", "Yangqiu", ""], ["Ng", "Wilfred", ""], ["Shang", "Lifeng", ""]]}, {"id": "2006.11830", "submitter": "Assaf Singer", "authors": "Assaf Singer and Katharina Kann", "title": "The NYU-CUBoulder Systems for SIGMORPHON 2020 Task 0 and Task 2", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the NYU-CUBoulder systems for the SIGMORPHON 2020 Task 0 on\ntypologically diverse morphological inflection and Task 2 on unsupervised\nmorphological paradigm completion. The former consists of generating\nmorphological inflections from a lemma and a set of morphosyntactic features\ndescribing the target form. The latter requires generating entire paradigms for\na set of given lemmas from raw text alone. We model morphological inflection as\na sequence-to-sequence problem, where the input is the sequence of the lemma's\ncharacters with morphological tags, and the output is the sequence of the\ninflected form's characters. First, we apply a transformer model to the task.\nSecond, as inflected forms share most characters with the lemma, we further\npropose a pointer-generator transformer model to allow easy copying of input\ncharacters. Our best performing system for Task 0 is placed 6th out of 23\nsystems. We further use our inflection systems as subcomponents of approaches\nfor Task 2. Our best performing system for Task 2 is the 2nd best out of 7\nsubmissions.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2020 15:41:58 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Singer", "Assaf", ""], ["Kann", "Katharina", ""]]}, {"id": "2006.11834", "submitter": "Yong Cheng", "authors": "Yong Cheng, Lu Jiang, Wolfgang Macherey, Jacob Eisenstein", "title": "AdvAug: Robust Adversarial Augmentation for Neural Machine Translation", "comments": "published at ACL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new adversarial augmentation method for Neural\nMachine Translation (NMT). The main idea is to minimize the vicinal risk over\nvirtual sentences sampled from two vicinity distributions, of which the crucial\none is a novel vicinity distribution for adversarial sentences that describes a\nsmooth interpolated embedding space centered around observed training sentence\npairs. We then discuss our approach, AdvAug, to train NMT models using the\nembeddings of virtual sentences in sequence-to-sequence learning. Experiments\non Chinese-English, English-French, and English-German translation benchmarks\nshow that AdvAug achieves significant improvements over the Transformer (up to\n4.9 BLEU points), and substantially outperforms other data augmentation\ntechniques (e.g. back-translation) without using extra corpora.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2020 15:51:54 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 10:27:17 GMT"}, {"version": "v3", "created": "Fri, 3 Jul 2020 02:45:27 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Cheng", "Yong", ""], ["Jiang", "Lu", ""], ["Macherey", "Wolfgang", ""], ["Eisenstein", "Jacob", ""]]}, {"id": "2006.11852", "submitter": "Murahtan Kurfal{\\i}", "authors": "Murathan Kurfal{\\i}", "title": "Labeling Explicit Discourse Relations using Pre-trained Language Models", "comments": "To be presented at TSD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Labeling explicit discourse relations is one of the most challenging\nsub-tasks of the shallow discourse parsing where the goal is to identify the\ndiscourse connectives and the boundaries of their arguments. The\nstate-of-the-art models achieve slightly above 45% of F-score by using\nhand-crafted features. The current paper investigates the efficacy of the\npre-trained language models in this task. We find that the pre-trained language\nmodels, when finetuned, are powerful enough to replace the linguistic features.\nWe evaluate our model on PDTB 2.0 and report the state-of-the-art results in\nthe extraction of the full relation. This is the first time when a model\noutperforms the knowledge intensive models without employing any linguistic\nfeatures.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2020 17:18:01 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Kurfal\u0131", "Murathan", ""]]}, {"id": "2006.11880", "submitter": "Jianjun Hu", "authors": "Changchang Zeng, Shaobo Li, Qin Li, Jie Hu, and Jianjun Hu", "title": "A Survey on Machine Reading Comprehension: Tasks, Evaluation Metrics and\n  Benchmark Datasets", "comments": "68 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Reading Comprehension (MRC) is a challenging Natural Language\nProcessing(NLP) research field with wide real-world applications. The great\nprogress of this field in recent years is mainly due to the emergence of\nlarge-scale datasets and deep learning. At present, a lot of MRC models have\nalready surpassed human performance on various benchmark datasets despite the\nobvious giant gap between existing MRC models and genuine human-level reading\ncomprehension. This shows the need for improving existing datasets, evaluation\nmetrics, and models to move current MRC models toward \"real\" understanding. To\naddress the current lack of comprehensive survey of existing MRC tasks,\nevaluation metrics, and datasets, herein, (1) we analyze 57 MRC tasks and\ndatasets and propose a more precise classification method of MRC tasks with 4\ndifferent attributes; (2) we summarized 9 evaluation metrics of MRC tasks, 7\nattributes and 10 characteristics of MRC datasets; (3) We also discuss key open\nissues in MRC research and highlighted future research directions. In addition,\nwe have collected, organized, and published our data on the companion\nwebsite(https://mrc-datasets.github.io/) where MRC researchers could directly\naccess each MRC dataset, papers, baseline projects, and the leaderboard.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2020 19:18:54 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 04:19:14 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Zeng", "Changchang", ""], ["Li", "Shaobo", ""], ["Li", "Qin", ""], ["Hu", "Jie", ""], ["Hu", "Jianjun", ""]]}, {"id": "2006.11991", "submitter": "Shijing Si", "authors": "Shijing Si, Rui Wang, Jedrek Wosik, Hao Zhang, David Dov, Guoyin Wang,\n  Ricardo Henao, and Lawrence Carin", "title": "Students Need More Attention: BERT-based AttentionModel for Small Data\n  with Application to AutomaticPatient Message Triage", "comments": "20 pages, Machine Learning for Healthcare 2020 (To appear)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Small and imbalanced datasets commonly seen in healthcare represent a\nchallenge when training classifiers based on deep learning models. So\nmotivated, we propose a novel framework based on BioBERT (Bidirectional Encoder\nRepresentations from Transformers forBiomedical TextMining). Specifically, (i)\nwe introduce Label Embeddings for Self-Attention in each layer of BERT, which\nwe call LESA-BERT, and (ii) by distilling LESA-BERT to smaller variants, we aim\nto reduce overfitting and model size when working on small datasets. As an\napplication, our framework is utilized to build a model for patient portal\nmessage triage that classifies the urgency of a message into three categories:\nnon-urgent, medium and urgent. Experiments demonstrate that our approach can\noutperform several strong baseline classifiers by a significant margin of 4.3%\nin terms of macro F1 score. The code for this project is publicly available at\n\\url{https://github.com/shijing001/text_classifiers}.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 03:39:00 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Si", "Shijing", ""], ["Wang", "Rui", ""], ["Wosik", "Jedrek", ""], ["Zhang", "Hao", ""], ["Dov", "David", ""], ["Wang", "Guoyin", ""], ["Henao", "Ricardo", ""], ["Carin", "Lawrence", ""]]}, {"id": "2006.12005", "submitter": "Chenhan Yuan", "authors": "Chenhan Yuan, Yi-chin Huang and Cheng-Hung Tsai", "title": "Efficient text generation of user-defined topic using generative\n  adversarial networks", "comments": "Accepted by CC-NLG 2019 (Workshop on Computational Creativity in\n  Natural Language Generation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study focused on efficient text generation using generative adversarial\nnetworks (GAN). Assuming that the goal is to generate a paragraph of a\nuser-defined topic and sentimental tendency, conventionally the whole network\nhas to be re-trained to obtain new results each time when a user changes the\ntopic. This would be time-consuming and impractical. Therefore, we propose a\nUser-Defined GAN (UD-GAN) with two-level discriminators to solve this problem.\nThe first discriminator aims to guide the generator to learn paragraph-level\ninformation and sentence syntactic structure, which is constructed by\nmultiple-LSTMs. The second one copes with higher-level information, such as the\nuser-defined sentiment and topic for text generation. The cosine similarity\nbased on TF-IDF and length penalty are adopted to determine the relevance of\nthe topic. Then, the second discriminator is re-trained with the generator if\nthe topic or sentiment for text generation is modified. The system evaluations\nare conducted to compare the performance of the proposed method with other\nGAN-based ones. The objective results showed that the proposed method is\ncapable of generating texts with less time than others and the generated text\nis related to the user-defined topic and sentiment. We will further investigate\nthe possibility of incorporating more detailed paragraph information such as\nsemantics into text generation to enhance the result.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 04:49:47 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Yuan", "Chenhan", ""], ["Huang", "Yi-chin", ""], ["Tsai", "Cheng-Hung", ""]]}, {"id": "2006.12040", "submitter": "John Pavlopoulos", "authors": "John Pavlopoulos and Panagiotis Papapetrou", "title": "Clinical Predictive Keyboard using Statistical and Neural Language\n  Modeling", "comments": "To appear in CBMS'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A language model can be used to predict the next word during authoring, to\ncorrect spelling or to accelerate writing (e.g., in sms or emails). Language\nmodels, however, have only been applied in a very small scale to assist\nphysicians during authoring (e.g., discharge summaries or radiology reports).\nBut along with the assistance to the physician, computer-based systems which\nexpedite the patient's exit also assist in decreasing the hospital infections.\nWe employed statistical and neural language modeling to predict the next word\nof a clinical text and assess all the models in terms of accuracy and keystroke\ndiscount in two datasets with radiology reports. We show that a neural language\nmodel can achieve as high as 51.3% accuracy in radiology reports (one out of\ntwo words predicted correctly). We also show that even when the models are\nemployed only for frequent words, the physician can save valuable time.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 07:20:20 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Pavlopoulos", "John", ""], ["Papapetrou", "Panagiotis", ""]]}, {"id": "2006.12100", "submitter": "Dai Quoc Nguyen", "authors": "Dai Quoc Nguyen and Tu Dinh Nguyen and Dinh Phung", "title": "A Self-Attention Network based Node Embedding Model", "comments": "Accepted version, ECML-PKDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite several signs of progress have been made recently, limited research\nhas been conducted for an inductive setting where embeddings are required for\nnewly unseen nodes -- a setting encountered commonly in practical applications\nof deep learning for graph networks. This significantly affects the\nperformances of downstream tasks such as node classification, link prediction\nor community extraction. To this end, we propose SANNE -- a novel unsupervised\nembedding model -- whose central idea is to employ a transformer self-attention\nnetwork to iteratively aggregate vector representations of nodes in random\nwalks. Our SANNE aims to produce plausible embeddings not only for present\nnodes, but also for newly unseen nodes. Experimental results show that the\nproposed SANNE obtains state-of-the-art results for the node classification\ntask on well-known benchmark datasets.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 09:46:10 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Nguyen", "Dai Quoc", ""], ["Nguyen", "Tu Dinh", ""], ["Phung", "Dinh", ""]]}, {"id": "2006.12106", "submitter": "Mohanad Al-Mousa", "authors": "Mohannad AlMousa, Rachid Benlamri, Richard Khoury", "title": "Exploiting Non-Taxonomic Relations for Measuring Semantic Similarity and\n  Relatedness in WordNet", "comments": null, "journal-ref": null, "doi": "10.1016/j.knosys.2020.106565", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Various applications in the areas of computational linguistics and artificial\nintelligence employ semantic similarity to solve challenging tasks, such as\nword sense disambiguation, text classification, information retrieval, machine\ntranslation, and document clustering. Previous work on semantic similarity\nfollowed a mono-relational approach using mostly the taxonomic relation \"ISA\".\nThis paper explores the benefits of using all types of non-taxonomic relations\nin large linked data, such as WordNet knowledge graph, to enhance existing\nsemantic similarity and relatedness measures. We propose a holistic\npoly-relational approach based on a new relation-based information content and\nnon-taxonomic-based weighted paths to devise a comprehensive semantic\nsimilarity and relatedness measure. To demonstrate the benefits of exploiting\nnon-taxonomic relations in a knowledge graph, we used three strategies to\ndeploy non-taxonomic relations at different granularity levels. We conducted\nexperiments on four well-known gold standard datasets, and the results\ndemonstrated the robustness and scalability of the proposed semantic similarity\nand relatedness measure, which significantly improves existing similarity\nmeasures.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 09:59:39 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["AlMousa", "Mohannad", ""], ["Benlamri", "Rachid", ""], ["Khoury", "Richard", ""]]}, {"id": "2006.12124", "submitter": "Anne Wu", "authors": "Anne Wu, Changhan Wang, Juan Pino, Jiatao Gu", "title": "Self-Supervised Representations Improve End-to-End Speech Translation", "comments": "Accepted to INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end speech-to-text translation can provide a simpler and smaller\nsystem but is facing the challenge of data scarcity. Pre-training methods can\nleverage unlabeled data and have been shown to be effective on data-scarce\nsettings. In this work, we explore whether self-supervised pre-trained speech\nrepresentations can benefit the speech translation task in both high- and\nlow-resource settings, whether they can transfer well to other languages, and\nwhether they can be effectively combined with other common methods that help\nimprove low-resource end-to-end speech translation such as using a pre-trained\nhigh-resource speech recognition system. We demonstrate that self-supervised\npre-trained features can consistently improve the translation performance, and\ncross-lingual transfer allows to extend to a variety of languages without or\nwith little tuning.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 10:28:38 GMT"}, {"version": "v2", "created": "Sun, 25 Oct 2020 03:31:15 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Wu", "Anne", ""], ["Wang", "Changhan", ""], ["Pino", "Juan", ""], ["Gu", "Jiatao", ""]]}, {"id": "2006.12146", "submitter": "Bingning Wang Dr.", "authors": "BingningWang, Ting Yao, Qi Zhang, Jingfang Xu, Xiaochuan Wang", "title": "ReCO: A Large Scale Chinese Reading Comprehension Dataset on Opinion", "comments": "AAAI-2020 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the ReCO, a human-curated ChineseReading Comprehension\ndataset on Opinion. The questions in ReCO are opinion based queries issued to\nthe commercial search engine. The passages are provided by the crowdworkers who\nextract the support snippet from the retrieved documents. Finally, an\nabstractive yes/no/uncertain answer was given by the crowdworkers. The release\nof ReCO consists of 300k questions that to our knowledge is the largest in\nChinese reading comprehension. A prominent characteristic of ReCO is that in\naddition to the original context paragraph, we also provided the support\nevidence that could be directly used to answer the question. Quality analysis\ndemonstrates the challenge of ReCO that requires various types of reasoning\nskills, such as causal inference, logical reasoning, etc. Current QA models\nthat perform very well on many question answering problems, such as BERT, only\nachieve 77% accuracy on this dataset, a large margin behind humans nearly 92%\nperformance, indicating ReCO presents a good challenge for machine reading\ncomprehension. The codes, datasets are freely available at\nhttps://github.com/benywon/ReCO.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 11:18:26 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["BingningWang", "", ""], ["Yao", "Ting", ""], ["Zhang", "Qi", ""], ["Xu", "Jingfang", ""], ["Wang", "Xiaochuan", ""]]}, {"id": "2006.12185", "submitter": "Shuiqiao Yang", "authors": "Jianlong Zhou, Shuiqiao Yang, Chun Xiao, Fang Chen", "title": "Examination of Community Sentiment Dynamics due to COVID-19 Pandemic: A\n  Case Study from A State in Australia", "comments": "accepted by Springer Nature Computer Science", "journal-ref": null, "doi": "10.1007/s42979-021-00596-7", "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The outbreak of the novel Coronavirus Disease 2019 (COVID-19) has caused\nunprecedented impacts to people's daily life around the world. Various measures\nand policies such as lockdown and social-distancing are implemented by\ngovernments to combat the disease during the pandemic period. These measures\nand policies as well as virus itself may cause different mental health issues\nto people such as depression, anxiety, sadness, etc. In this paper, we exploit\nthe massive text data posted by Twitter users to analyse the sentiment dynamics\nof people living in the state of New South Wales (NSW) in Australia during the\npandemic period. Different from the existing work that mostly focuses the\ncountry-level and static sentiment analysis, we analyse the sentiment dynamics\nat the fine-grained local government areas (LGAs). Based on the analysis of\naround 94 million tweets that posted by around 183 thousand users located at\ndifferent LGAs in NSW in five months, we found that people in NSW showed an\noverall positive sentimental polarity and the COVID-19 pandemic decreased the\noverall positive sentimental polarity during the pandemic period. The\nfine-grained analysis of sentiment in LGAs found that despite the dominant\npositive sentiment most of days during the study period, some LGAs experienced\nsignificant sentiment changes from positive to negative. This study also\nanalysed the sentimental dynamics delivered by the hot topics in Twitter such\nas government policies (e.g. the Australia's JobKeeper program, lockdown,\nsocial-distancing) as well as the focused social events (e.g. the Ruby Princess\nCruise). The results showed that the policies and events did affect people's\noverall sentiment, and they affected people's overall sentiment differently at\ndifferent stages.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 12:30:42 GMT"}, {"version": "v2", "created": "Sat, 17 Apr 2021 04:28:45 GMT"}, {"version": "v3", "created": "Sat, 24 Jul 2021 04:56:13 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Zhou", "Jianlong", ""], ["Yang", "Shuiqiao", ""], ["Xiao", "Chun", ""], ["Chen", "Fang", ""]]}, {"id": "2006.12234", "submitter": "Ehud Reiter", "authors": "Ehud Reiter and Craig Thomson", "title": "Shared Task on Evaluating Accuracy in Natural Language Generation", "comments": "To appear in INLG 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a shared task on methodologies and algorithms for evaluating the\naccuracy of generated texts. Participants will measure the accuracy of\nbasketball game summaries produced by NLG systems from basketball box score\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 13:30:35 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 19:00:30 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Reiter", "Ehud", ""], ["Thomson", "Craig", ""]]}, {"id": "2006.12289", "submitter": "Fabrizio Sebastiani", "authors": "Silvia Corbara, Alejandro Moreo, Fabrizio Sebastiani, Mirko Tavoni", "title": "MedLatin1 and MedLatin2: Two Datasets for the Computational Authorship\n  Analysis of Medieval Latin Texts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present and make available MedLatin1 and MedLatin2, two datasets of\nmedieval Latin texts to be used in research on computational authorship\nanalysis. MedLatin1 and MedLatin2 consist of 294 and 30 curated texts,\nrespectively, labelled by author, with MedLatin1 texts being of an epistolary\nnature and MedLatin2 texts consisting of literary comments and treatises about\nvarious subjects. As such, these two datasets lend themselves to supporting\nresearch in authorship analysis tasks, such as authorship attribution,\nauthorship verification, or same-author verification.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 14:22:47 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Corbara", "Silvia", ""], ["Moreo", "Alejandro", ""], ["Sebastiani", "Fabrizio", ""], ["Tavoni", "Mirko", ""]]}, {"id": "2006.12414", "submitter": "Nora Kassner", "authors": "Jakob Jungmaier, Nora Kassner, Benjamin Roth", "title": "Dirichlet-Smoothed Word Embeddings for Low-Resource Settings", "comments": null, "journal-ref": "LREC 2020", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, classical count-based word embeddings using positive pointwise\nmutual information (PPMI) weighted co-occurrence matrices have been widely\nsuperseded by machine-learning-based methods like word2vec and GloVe. But these\nmethods are usually applied using very large amounts of text data. In many\ncases, however, there is not much text data available, for example for specific\ndomains or low-resource languages. This paper revisits PPMI by adding Dirichlet\nsmoothing to correct its bias towards rare words. We evaluate on standard word\nsimilarity data sets and compare to word2vec and the recent state of the art\nfor low-resource settings: Positive and Unlabeled (PU) Learning for word\nembeddings. The proposed method outperforms PU-Learning for low-resource\nsettings and obtains competitive results for Maltese and Luxembourgish.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 16:43:34 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Jungmaier", "Jakob", ""], ["Kassner", "Nora", ""], ["Roth", "Benjamin", ""]]}, {"id": "2006.12418", "submitter": "Oren Halvani", "authors": "Oren Halvani, Lukas Graner, Roey Regev", "title": "A Step Towards Interpretable Authorship Verification", "comments": "21 pages, 5 figures. Paper has been accepted for publication in: The\n  15th International Conference on Availability, Reliability and Security (ARES\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central problem that has been researched for many years in the field of\ndigital text forensics is the question whether two documents were written by\nthe same author. Authorship verification (AV) is a research branch in this\nfield that deals with this question. Over the years, research activities in the\ncontext of AV have steadily increased, which has led to a variety of approaches\ntrying to solve this problem. Many of these approaches, however, make use of\nfeatures that are related to or influenced by the topic of the documents.\nTherefore, it may accidentally happen that their verification results are based\nnot on the writing style (the actual focus of AV), but on the topic of the\ndocuments. To address this problem, we propose an alternative AV approach that\nconsiders only topic-agnostic features in its classification decision. In\naddition, we present a post-hoc interpretation method that allows to understand\nwhich particular features have contributed to the prediction of the proposed AV\nmethod. To evaluate the performance of our AV method, we compared it with ten\ncompeting baselines (including the current state of the art) on four\nchallenging data sets. The results show that our approach outperforms all\nbaselines in two cases (with a maximum accuracy of 84%), while in the other two\ncases it performs as well as the strongest baseline.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 16:44:26 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 23:30:14 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Halvani", "Oren", ""], ["Graner", "Lukas", ""], ["Regev", "Roey", ""]]}, {"id": "2006.12425", "submitter": "Shan Li", "authors": "Shan Li, Baoxu Shi, Jaewon Yang, Ji Yan, Shuai Wang, Fei Chen, Qi He", "title": "Deep Job Understanding at LinkedIn", "comments": "4 pages, to appear in SIGIR2020", "journal-ref": null, "doi": "10.1145/3397271.3401403", "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the world's largest professional network, LinkedIn wants to create\neconomic opportunity for everyone in the global workforce. One of its most\ncritical missions is matching jobs with processionals. Improving job targeting\naccuracy and hire efficiency align with LinkedIn's Member First Motto. To\nachieve those goals, we need to understand unstructured job postings with noisy\ninformation. We applied deep transfer learning to create domain-specific job\nunderstanding models. After this, jobs are represented by professional\nentities, including titles, skills, companies, and assessment questions. To\ncontinuously improve LinkedIn's job understanding ability, we designed an\nexpert feedback loop where we integrated job understanding models into\nLinkedIn's products to collect job posters' feedback. In this demonstration, we\npresent LinkedIn's job posting flow and demonstrate how the integrated deep job\nunderstanding work improves job posters' satisfaction and provides significant\nmetric lifts in LinkedIn's job recommendation system.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 20:04:59 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Li", "Shan", ""], ["Shi", "Baoxu", ""], ["Yang", "Jaewon", ""], ["Yan", "Ji", ""], ["Wang", "Shuai", ""], ["Chen", "Fei", ""], ["He", "Qi", ""]]}, {"id": "2006.12426", "submitter": "Stefano Giani", "authors": "Jonathan Readshaw and Stefano Giani", "title": "Using Company Specific Headlines and Convolutional Neural Networks to\n  Predict Stock Fluctuations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a Convolutional Neural Network (CNN) for the prediction of\nnext-day stock fluctuations using company-specific news headlines. Experiments\nto evaluate model performance using various configurations of word-embeddings\nand convolutional filter widths are reported. The total number of convolutional\nfilters used is far fewer than is common, reducing the dimensionality of the\ntask without loss of accuracy. Furthermore, multiple hidden layers with\ndecreasing dimensionality are employed. A classification accuracy of 61.7\\% is\nachieved using pre-learned embeddings, that are fine-tuned during training to\nrepresent the specific context of this task. Multiple filter widths are also\nimplemented to detect different length phrases that are key for classification.\nTrading simulations are conducted using the presented classification results.\nInitial investments are more than tripled over a 838 day testing period using\nthe optimal classification configuration and a simple trading strategy. Two\nnovel methods are presented to reduce the risk of the trading simulations.\nAdjustment of the sigmoid class threshold and re-labelling headlines using\nmultiple classes form the basis of these methods. A combination of these\napproaches is found to more than double the Average Trade Profit (ATP) achieved\nduring baseline simulations.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 16:53:26 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Readshaw", "Jonathan", ""], ["Giani", "Stefano", ""]]}, {"id": "2006.12442", "submitter": "Stephen Roller", "authors": "Stephen Roller, Y-Lan Boureau, Jason Weston, Antoine Bordes, Emily\n  Dinan, Angela Fan, David Gunning, Da Ju, Margaret Li, Spencer Poff, Pratik\n  Ringshia, Kurt Shuster, Eric Michael Smith, Arthur Szlam, Jack Urbanek, Mary\n  Williamson", "title": "Open-Domain Conversational Agents: Current Progress, Open Problems, and\n  Future Directions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present our view of what is necessary to build an engaging open-domain\nconversational agent: covering the qualities of such an agent, the pieces of\nthe puzzle that have been built so far, and the gaping holes we have not filled\nyet. We present a biased view, focusing on work done by our own group, while\nciting related work in each area. In particular, we discuss in detail the\nproperties of continual learning, providing engaging content, and being\nwell-behaved -- and how to measure success in providing them. We end with a\ndiscussion of our experience and learnings, and our recommendations to the\ncommunity.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 17:23:47 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 17:35:31 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Roller", "Stephen", ""], ["Boureau", "Y-Lan", ""], ["Weston", "Jason", ""], ["Bordes", "Antoine", ""], ["Dinan", "Emily", ""], ["Fan", "Angela", ""], ["Gunning", "David", ""], ["Ju", "Da", ""], ["Li", "Margaret", ""], ["Poff", "Spencer", ""], ["Ringshia", "Pratik", ""], ["Shuster", "Kurt", ""], ["Smith", "Eric Michael", ""], ["Szlam", "Arthur", ""], ["Urbanek", "Jack", ""], ["Williamson", "Mary", ""]]}, {"id": "2006.12467", "submitter": "Yoav Levine", "authors": "Yoav Levine, Noam Wies, Or Sharir, Hofit Bata and Amnon Shashua", "title": "The Depth-to-Width Interplay in Self-Attention", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Self-attention architectures, which are rapidly pushing the frontier in\nnatural language processing, demonstrate a surprising depth-inefficient\nbehavior: previous works indicate that increasing the internal representation\n(network width) is just as useful as increasing the number of self-attention\nlayers (network depth). We theoretically predict a width-dependent transition\nbetween depth-efficiency and depth-inefficiency in self-attention. We conduct\nsystematic empirical ablations on networks of depths 6 to 48 that clearly\nreveal the theoretically predicted behaviors, and provide explicit quantitative\nsuggestions regarding the optimal depth-to-width allocation for a given\nself-attention network size. The race towards beyond 1-Trillion parameter\nlanguage models renders informed guidelines for increasing self-attention depth\nand width in tandem an essential ingredient. Our guidelines elucidate the\ndepth-to-width trade-off in self-attention networks of sizes up to the scale of\nGPT3 (which we project to be too deep for its size), and beyond, marking an\nunprecedented width of 30K as optimal for a 1-Trillion parameter network.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 17:47:09 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 16:52:28 GMT"}, {"version": "v3", "created": "Sun, 17 Jan 2021 18:17:31 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Levine", "Yoav", ""], ["Wies", "Noam", ""], ["Sharir", "Or", ""], ["Bata", "Hofit", ""], ["Shashua", "Amnon", ""]]}, {"id": "2006.12641", "submitter": "Saurabh Pujar", "authors": "Luca Buratti, Saurabh Pujar, Mihaela Bornea, Scott McCarley, Yunhui\n  Zheng, Gaetano Rossiello, Alessandro Morari, Jim Laredo, Veronika Thost,\n  Yufan Zhuang, Giacomo Domeniconi", "title": "Exploring Software Naturalness through Neural Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Software Naturalness hypothesis argues that programming languages can be\nunderstood through the same techniques used in natural language processing. We\nexplore this hypothesis through the use of a pre-trained transformer-based\nlanguage model to perform code analysis tasks. Present approaches to code\nanalysis depend heavily on features derived from the Abstract Syntax Tree (AST)\nwhile our transformer-based language models work on raw source code. This work\nis the first to investigate whether such language models can discover AST\nfeatures automatically. To achieve this, we introduce a sequence labeling task\nthat directly probes the language models understanding of AST. Our results show\nthat transformer based language models achieve high accuracy in the AST tagging\ntask. Furthermore, we evaluate our model on a software vulnerability\nidentification task. Importantly, we show that our approach obtains\nvulnerability identification results comparable to graph based approaches that\nrely heavily on compilers for feature extraction.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 21:56:14 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 13:55:50 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Buratti", "Luca", ""], ["Pujar", "Saurabh", ""], ["Bornea", "Mihaela", ""], ["McCarley", "Scott", ""], ["Zheng", "Yunhui", ""], ["Rossiello", "Gaetano", ""], ["Morari", "Alessandro", ""], ["Laredo", "Jim", ""], ["Thost", "Veronika", ""], ["Zhuang", "Yufan", ""], ["Domeniconi", "Giacomo", ""]]}, {"id": "2006.12719", "submitter": "Shikib Mehri", "authors": "Shikib Mehri and Maxine Eskenazi", "title": "Unsupervised Evaluation of Interactive Dialog with DialoGPT", "comments": "Published at to SIGdial 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is important to define meaningful and interpretable automatic evaluation\nmetrics for open-domain dialog research. Standard language generation metrics\nhave been shown to be ineffective for dialog. This paper introduces the FED\nmetric (fine-grained evaluation of dialog), an automatic evaluation metric\nwhich uses DialoGPT, without any fine-tuning or supervision. It also introduces\nthe FED dataset which is constructed by annotating a set of human-system and\nhuman-human conversations with eighteen fine-grained dialog qualities. The FED\nmetric (1) does not rely on a ground-truth response, (2) does not require\ntraining data and (3) measures fine-grained dialog qualities at both the turn\nand whole dialog levels. FED attains moderate to strong correlation with human\njudgement at both levels.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 03:36:09 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Mehri", "Shikib", ""], ["Eskenazi", "Maxine", ""]]}, {"id": "2006.12799", "submitter": "Mamoru Komachi", "authors": "Tosho Hirasawa and Zhishen Yang and Mamoru Komachi and Naoaki Okazaki", "title": "Keyframe Segmentation and Positional Encoding for Video-guided Machine\n  Translation Challenge 2020", "comments": "4 pages; First Workshop on Advances in Language and Vision Research\n  (ALVR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Video-guided machine translation as one of multimodal neural machine\ntranslation tasks targeting on generating high-quality text translation by\ntangibly engaging both video and text. In this work, we presented our\nvideo-guided machine translation system in approaching the Video-guided Machine\nTranslation Challenge 2020. This system employs keyframe-based video feature\nextractions along with the video feature positional encoding. In the evaluation\nphase, our system scored 36.60 corpus-level BLEU-4 and achieved the 1st place\non the Video-guided Machine Translation Challenge 2020.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 07:15:11 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Hirasawa", "Tosho", ""], ["Yang", "Zhishen", ""], ["Komachi", "Mamoru", ""], ["Okazaki", "Naoaki", ""]]}, {"id": "2006.12816", "submitter": "Xin Cong", "authors": "Xin Cong, Bowen Yu, Tingwen Liu, Shiyao Cui, Hengzhu Tang, Bin Wang", "title": "Inductive Unsupervised Domain Adaptation for Few-Shot Classification via\n  Clustering", "comments": "Accepted by ECML-PKDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot classification tends to struggle when it needs to adapt to diverse\ndomains. Due to the non-overlapping label space between domains, the\nperformance of conventional domain adaptation is limited. Previous work tackles\nthe problem in a transductive manner, by assuming access to the full set of\ntest data, which is too restrictive for many real-world applications. In this\npaper, we set out to tackle this issue by introducing a inductive framework,\nDaFeC, to improve Domain adaptation performance for Few-shot classification via\nClustering. We first build a representation extractor to derive features for\nunlabeled data from the target domain (no test data is necessary) and then\ngroup them with a cluster miner. The generated pseudo-labeled data and the\nlabeled source-domain data are used as supervision to update the parameters of\nthe few-shot classifier. In order to derive high-quality pseudo labels, we\npropose a Clustering Promotion Mechanism, to learn better features for the\ntarget domain via Similarity Entropy Minimization and Adversarial Distribution\nAlignment, which are combined with a Cosine Annealing Strategy. Experiments are\nperformed on the FewRel 2.0 dataset. Our approach outperforms previous work\nwith absolute gains (in classification accuracy) of 4.95%, 9.55%, 3.99% and\n11.62%, respectively, under four few-shot settings.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 08:17:48 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Cong", "Xin", ""], ["Yu", "Bowen", ""], ["Liu", "Tingwen", ""], ["Cui", "Shiyao", ""], ["Tang", "Hengzhu", ""], ["Wang", "Bin", ""]]}, {"id": "2006.12870", "submitter": "Jennifer D'Souza", "authors": "Jennifer D'Souza and S\\\"oren Auer", "title": "NLPContributions: An Annotation Scheme for Machine Reading of Scholarly\n  Contributions in Natural Language Processing Literature", "comments": "In Proceedings of the 1st Workshop on Extraction and Evaluation of\n  Knowledge Entities from Scientific Documents (EEKE 2020) co-located with the\n  ACM/IEEE Joint Conference on Digital Libraries in 2020 (JCDL 2020), Virtual\n  Event, China, August 1. http://ceur-ws.org/Vol-2658/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL cs.IR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We describe an annotation initiative to capture the scholarly contributions\nin natural language processing (NLP) articles, particularly, for the articles\nthat discuss machine learning (ML) approaches for various information\nextraction tasks. We develop the annotation task based on a pilot annotation\nexercise on 50 NLP-ML scholarly articles presenting contributions to five\ninformation extraction tasks 1. machine translation, 2. named entity\nrecognition, 3. question answering, 4. relation classification, and 5. text\nclassification. In this article, we describe the outcomes of this pilot\nannotation phase. Through the exercise we have obtained an annotation\nmethodology; and found ten core information units that reflect the contribution\nof the NLP-ML scholarly investigations. The resulting annotation scheme we\ndeveloped based on these information units is called NLPContributions.\n  The overarching goal of our endeavor is four-fold: 1) to find a systematic\nset of patterns of subject-predicate-object statements for the semantic\nstructuring of scholarly contributions that are more or less generically\napplicable for NLP-ML research articles; 2) to apply the discovered patterns in\nthe creation of a larger annotated dataset for training machine readers of\nresearch contributions; 3) to ingest the dataset into the Open Research\nKnowledge Graph (ORKG) infrastructure as a showcase for creating user-friendly\nstate-of-the-art overviews; 4) to integrate the machine readers into the ORKG\nto assist users in the manual curation of their respective article\ncontributions. We envision that the NLPContributions methodology engenders a\nwider discussion on the topic toward its further refinement and development.\nOur pilot annotated dataset of 50 NLP-ML scholarly articles according to the\nNLPContributions scheme is openly available to the research community at\nhttps://doi.org/10.25835/0019761.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 10:04:39 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 09:52:38 GMT"}, {"version": "v3", "created": "Thu, 3 Sep 2020 05:23:56 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["D'Souza", "Jennifer", ""], ["Auer", "S\u00f6ren", ""]]}, {"id": "2006.12958", "submitter": "Apostol Vassilev", "authors": "Apostol Vassilev, Munawar Hasan, Honglan Jin", "title": "Can you tell? SSNet -- a Sagittal Stratum-inspired Neural Network\n  Framework for Sentiment Analysis", "comments": "21 pages, 4 figures, 5 tables, 42 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When people try to understand nuanced language they typically process\nmultiple input sensor modalities to complete this cognitive task. It turns out\nthe human brain has even a specialized neuron formation, called sagittal\nstratum, to help us understand sarcasm. We use this biological formation as the\ninspiration for designing a neural network architecture that combines\npredictions of different models on the same text to construct robust, accurate\nand computationally efficient classifiers for sentiment analysis and study\nseveral different realizations. Among them, we propose a systematic new\napproach to combining multiple predictions based on a dedicated neural network\nand develop mathematical analysis of it along with state-of-the-art\nexperimental results. We also propose a heuristic-hybrid technique for\ncombining models and back it up with experimental results on a representative\nbenchmark dataset and comparisons to other methods to show the advantages of\nthe new approaches.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 12:55:02 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 15:02:36 GMT"}, {"version": "v3", "created": "Thu, 4 Mar 2021 15:54:31 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Vassilev", "Apostol", ""], ["Hasan", "Munawar", ""], ["Jin", "Honglan", ""]]}, {"id": "2006.13071", "submitter": "Zechang Li", "authors": "Zechang Li, Yuxuan Lai, Yansong Feng, Dongyan Zhao", "title": "Domain Adaptation for Semantic Parsing", "comments": "Accepted by IJCAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, semantic parsing has attracted much attention in the community.\nAlthough many neural modeling efforts have greatly improved the performance, it\nstill suffers from the data scarcity issue. In this paper, we propose a novel\nsemantic parser for domain adaptation, where we have much fewer annotated data\nin the target domain compared to the source domain. Our semantic parser\nbenefits from a two-stage coarse-to-fine framework, thus can provide different\nand accurate treatments for the two stages, i.e., focusing on domain invariant\nand domain specific information, respectively. In the coarse stage, our novel\ndomain discrimination component and domain relevance attention encourage the\nmodel to learn transferable domain general structures. In the fine stage, the\nmodel is guided to concentrate on domain related details. Experiments on a\nbenchmark dataset show that our method consistently outperforms several popular\ndomain adaptation strategies. Additionally, we show that our model can well\nexploit limited target data to capture the difference between the source and\ntarget domain, even when the target domain has far fewer training instances.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 14:47:41 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Li", "Zechang", ""], ["Lai", "Yuxuan", ""], ["Feng", "Yansong", ""], ["Zhao", "Dongyan", ""]]}, {"id": "2006.13200", "submitter": "Nikolay Arefyev", "authors": "Nikolay Arefyev, Boris Sheludko, and Tatiana Aleksashina", "title": "Combining Neural Language Models for WordSense Induction", "comments": "International Conference on Analysis of Images, Social Networks and\n  Texts AIST 2019: Analysis of Images, Social Networks and Texts, pp 105-121", "journal-ref": "van der Aalst W. et al. (eds) Analysis of Images, Social Networks\n  and Texts. AIST 2019. Lecture Notes in Computer Science, vol 11832. Springer,\n  Cham", "doi": "10.1007/978-3-030-37334-4_10", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word sense induction (WSI) is the problem of grouping occurrences of an\nambiguous word according to the expressed sense of this word. Recently a new\napproach to this task was proposed, which generates possible substitutes for\nthe ambiguous word in a particular context using neural language models, and\nthen clusters sparse bag-of-words vectors built from these substitutes. In this\nwork, we apply this approach to the Russian language and improve it in two\nways. First, we propose methods of combining left and right contexts, resulting\nin better substitutes generated. Second, instead of fixed number of clusters\nfor all ambiguous words we propose a technique for selecting individual number\nof clusters for each word. Our approach established new state-of-the-art level,\nimproving current best results of WSI for the Russian language on two RUSSE\n2018 datasets by a large margin.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 17:57:25 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Arefyev", "Nikolay", ""], ["Sheludko", "Boris", ""], ["Aleksashina", "Tatiana", ""]]}, {"id": "2006.13253", "submitter": "Thao Nguyen", "authors": "Thao Nguyen, Nakul Gopalan, Roma Patel, Matt Corsaro, Ellie Pavlick,\n  Stefanie Tellex", "title": "Robot Object Retrieval with Contextual Natural Language Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language object retrieval is a highly useful yet challenging task for\nrobots in human-centric environments. Previous work has primarily focused on\ncommands specifying the desired object's type such as \"scissors\" and/or visual\nattributes such as \"red,\" thus limiting the robot to only known object classes.\nWe develop a model to retrieve objects based on descriptions of their usage.\nThe model takes in a language command containing a verb, for example \"Hand me\nsomething to cut,\" and RGB images of candidate objects and selects the object\nthat best satisfies the task specified by the verb. Our model directly predicts\nan object's appearance from the object's use specified by a verb phrase. We do\nnot need to explicitly specify an object's class label. Our approach allows us\nto predict high level concepts like an object's utility based on the language\nquery. Based on contextual information present in the language commands, our\nmodel can generalize to unseen object classes and unknown nouns in the\ncommands. Our model correctly selects objects out of sets of five candidates to\nfulfill natural language commands, and achieves an average accuracy of 62.3% on\na held-out test set of unseen ImageNet object classes and 53.0% on unseen\nobject classes and unknown nouns. Our model also achieves an average accuracy\nof 54.7% on unseen YCB object classes, which have a different image\ndistribution from ImageNet objects. We demonstrate our model on a KUKA LBR iiwa\nrobot arm, enabling the robot to retrieve objects based on natural language\ndescriptions of their usage. We also present a new dataset of 655 verb-object\npairs denoting object usage over 50 verbs and 216 object classes.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 18:13:40 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Nguyen", "Thao", ""], ["Gopalan", "Nakul", ""], ["Patel", "Roma", ""], ["Corsaro", "Matt", ""], ["Pavlick", "Ellie", ""], ["Tellex", "Stefanie", ""]]}, {"id": "2006.13268", "submitter": "Erion \\c{C}ano", "authors": "Erion \\c{C}ano and Ond\\v{r}ej Bojar", "title": "Automating Text Naturalness Evaluation of NLG Systems", "comments": "15 pages, 4 equations, 3 tables. arXiv admin note: text overlap with\n  arXiv:2006.03189", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic methods and metrics that assess various quality criteria of\nautomatically generated texts are important for developing NLG systems because\nthey produce repeatable results and allow for a fast development cycle. We\npresent here an attempt to automate the evaluation of text naturalness which is\na very important characteristic of natural language generation methods. Instead\nof relying on human participants for scoring or labeling the text samples, we\npropose to automate the process by using a human likeliness metric we define\nand a discrimination procedure based on large pretrained language models with\ntheir probability distributions. We analyze the text probability fractions and\nobserve how they are influenced by the size of the generative and\ndiscriminative models involved in the process. Based on our results, bigger\ngenerators and larger pretrained discriminators are more appropriate for a\nbetter evaluation of text naturalness. A comprehensive validation procedure\nwith human participants is required as follow up to check how well this\nautomatic evaluation scheme correlates with human judgments.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 18:48:33 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["\u00c7ano", "Erion", ""], ["Bojar", "Ond\u0159ej", ""]]}, {"id": "2006.13299", "submitter": "Halid Ziya Yerebakan", "authors": "Halid Ziya Yerebakan, Parmeet Bhatia, Yoshihisa Shinagawa", "title": "Supervised Understanding of Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Pre-trained word embeddings are widely used for transfer learning in natural\nlanguage processing. The embeddings are continuous and distributed\nrepresentations of the words that preserve their similarities in compact\nEuclidean spaces. However, the dimensions of these spaces do not provide any\nclear interpretation. In this study, we have obtained supervised projections in\nthe form of the linear keyword-level classifiers on word embeddings. We have\nshown that the method creates interpretable projections of original embedding\ndimensions. Activations of the trained classifier nodes correspond to a subset\nof the words in the vocabulary. Thus, they behave similarly to the dictionary\nfeatures while having the merit of continuous value output. Additionally, such\ndictionaries can be grown iteratively with multiple rounds by adding expert\nlabels on top-scoring words to an initial collection of the keywords. Also, the\nsame classifiers can be applied to aligned word embeddings in other languages\nto obtain corresponding dictionaries. In our experiments, we have shown that\ninitializing higher-order networks with these classifier weights gives more\naccurate models for downstream NLP tasks. We further demonstrate the usefulness\nof supervised dimensions in revealing the polysemous nature of a keyword of\ninterest by projecting it's embedding using learned classifiers in different\nsub-spaces.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 20:13:42 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Yerebakan", "Halid Ziya", ""], ["Bhatia", "Parmeet", ""], ["Shinagawa", "Yoshihisa", ""]]}, {"id": "2006.13327", "submitter": "Victoria Yaneva PhD", "authors": "Victoria Yaneva, Le An Ha, Richard Evans, and Ruslan Mitkov", "title": "Classifying Referential and Non-referential It Using Gaze", "comments": "Proceedings of the Empirical Methods in Natural Language Processing\n  (EMNLP) conference (2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When processing a text, humans and machines must disambiguate between\ndifferent uses of the pronoun it, including non-referential, nominal anaphoric\nor clause anaphoric ones. In this paper, we use eye-tracking data to learn how\nhumans perform this disambiguation. We use this knowledge to improve the\nautomatic classification of it. We show that by using gaze data and a\nPOS-tagger we are able to significantly outperform a common baseline and\nclassify between three categories of it with an accuracy comparable to that of\nlinguisticbased approaches. In addition, the discriminatory power of specific\ngaze features informs the way humans process the pronoun, which, to the best of\nour knowledge, has not been explored using data from a natural reading task.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 20:54:25 GMT"}], "update_date": "2020-06-28", "authors_parsed": [["Yaneva", "Victoria", ""], ["Ha", "Le An", ""], ["Evans", "Richard", ""], ["Mitkov", "Ruslan", ""]]}, {"id": "2006.13343", "submitter": "Kaili Vesik", "authors": "Kaili Vesik (1), Muhammad Abdul-Mageed (1), Miikka Silfverberg (1)\n  ((1) The University of British Columbia)", "title": "One Model to Pronounce Them All: Multilingual Grapheme-to-Phoneme\n  Conversion With a Transformer Ensemble", "comments": "7 pages, submitted to SIGMORPHON 2020 Shared Task 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The task of grapheme-to-phoneme (G2P) conversion is important for both speech\nrecognition and synthesis. Similar to other speech and language processing\ntasks, in a scenario where only small-sized training data are available,\nlearning G2P models is challenging. We describe a simple approach of exploiting\nmodel ensembles, based on multilingual Transformers and self-training, to\ndevelop a highly effective G2P solution for 15 languages. Our models are\ndeveloped as part of our participation in the SIGMORPHON 2020 Shared Task 1\nfocused at G2P. Our best models achieve 14.99 word error rate (WER) and 3.30\nphoneme error rate (PER), a sizeable improvement over the shared task\ncompetitive baselines.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 21:28:28 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Vesik", "Kaili", "", "The University of British Columbia"], ["Abdul-Mageed", "Muhammad", "", "The University of British Columbia"], ["Silfverberg", "Miikka", "", "The University of British Columbia"]]}, {"id": "2006.13425", "submitter": "Kazuma Hashimoto", "authors": "Kazuma Hashimoto, Raffaella Buschiazzo, James Bradbury, Teresa\n  Marshall, Richard Socher, Caiming Xiong", "title": "A High-Quality Multilingual Dataset for Structured Documentation\n  Translation", "comments": "Published at WMT2019; the draft has been updated with our dataset's\n  URL: https://github.com/salesforce/localization-xml-mt", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a high-quality multilingual dataset for the documentation\ndomain to advance research on localization of structured text. Unlike\nwidely-used datasets for translation of plain text, we collect XML-structured\nparallel text segments from the online documentation for an enterprise software\nplatform. These Web pages have been professionally translated from English into\n16 languages and maintained by domain experts, and around 100,000 text segments\nare available for each language pair. We build and evaluate translation models\nfor seven target languages from English, with several different copy mechanisms\nand an XML-constrained beam search. We also experiment with a non-English pair\nto show that our dataset has the potential to explicitly enable $17 \\times 16$\ntranslation settings. Our experiments show that learning to translate with the\nXML tags improves translation accuracy, and the beam search accurately\ngenerates XML structures. We also discuss trade-offs of using the copy\nmechanisms by focusing on translation of numerical words and named entities. We\nfurther provide a detailed human analysis of gaps between the model output and\nhuman translations for real-world applications, including suitability for\npost-editing.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 02:08:44 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Hashimoto", "Kazuma", ""], ["Buschiazzo", "Raffaella", ""], ["Bradbury", "James", ""], ["Marshall", "Teresa", ""], ["Socher", "Richard", ""], ["Xiong", "Caiming", ""]]}, {"id": "2006.13484", "submitter": "Shuai Zheng", "authors": "Shuai Zheng and Haibin Lin and Sheng Zha and Mu Li", "title": "Accelerated Large Batch Optimization of BERT Pretraining in 54 minutes", "comments": "Technical Report (not under reviewed in any venue)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BERT has recently attracted a lot of attention in natural language\nunderstanding (NLU) and achieved state-of-the-art results in various NLU tasks.\nHowever, its success requires large deep neural networks and huge amount of\ndata, which result in long training time and impede development progress. Using\nstochastic gradient methods with large mini-batch has been advocated as an\nefficient tool to reduce the training time. Along this line of research, LAMB\nis a prominent example that reduces the training time of BERT from 3 days to 76\nminutes on a TPUv3 Pod. In this paper, we propose an accelerated gradient\nmethod called LANS to improve the efficiency of using large mini-batches for\ntraining. As the learning rate is theoretically upper bounded by the inverse of\nthe Lipschitz constant of the function, one cannot always reduce the number of\noptimization iterations by selecting a larger learning rate. In order to use\nlarger mini-batch size without accuracy loss, we develop a new learning rate\nscheduler that overcomes the difficulty of using large learning rate. Using the\nproposed LANS method and the learning rate scheme, we scaled up the mini-batch\nsizes to 96K and 33K in phases 1 and 2 of BERT pretraining, respectively. It\ntakes 54 minutes on 192 AWS EC2 P3dn.24xlarge instances to achieve a target F1\nscore of 90.5 or higher on SQuAD v1.1, achieving the fastest BERT training time\nin the cloud.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 05:00:41 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 08:46:52 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Zheng", "Shuai", ""], ["Lin", "Haibin", ""], ["Zha", "Sheng", ""], ["Li", "Mu", ""]]}, {"id": "2006.13507", "submitter": "Md Rabiul Awal", "authors": "Md Rabiul Awal, Rui Cao, Roy Ka-Wei Lee, Sandra Mitrovi\\'c", "title": "On Analyzing Annotation Consistency in Online Abusive Behavior Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online abusive behavior is an important issue that breaks the cohesiveness of\nonline social communities and even raises public safety concerns in our\nsocieties. Motivated by this rising issue, researchers have proposed,\ncollected, and annotated online abusive content datasets. These datasets play a\ncritical role in facilitating the research on online hate speech and abusive\nbehaviors. However, the annotation of such datasets is a difficult task; it is\noften contentious on what should be the true label of a given text as the\nsemantic difference of the labels may be blurred (e.g., abusive and hate) and\noften subjective. In this study, we proposed an analytical framework to study\nthe annotation consistency in online hate and abusive content datasets. We\napplied our proposed framework to evaluate the consistency of the annotation in\nthree popular datasets that are widely used in online hate speech and abusive\nbehavior studies. We found that there is still a substantial amount of\nannotation inconsistency in the existing datasets, particularly when the labels\nare semantically similar.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 06:34:25 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Awal", "Md Rabiul", ""], ["Cao", "Rui", ""], ["Lee", "Roy Ka-Wei", ""], ["Mitrovi\u0107", "Sandra", ""]]}, {"id": "2006.13519", "submitter": "Kartik Khandelwal", "authors": "Kartik Khandelwal, Preethi Jyothi, Abhijeet Awasthi, Sunita Sarawagi", "title": "Black-box Adaptation of ASR for Accented Speech", "comments": "A slightly different version submitted to INTERSPEECH 2020 (currently\n  under review)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the problem of adapting a black-box, cloud-based ASR system to\nspeech from a target accent. While leading online ASR services obtain\nimpressive performance on main-stream accents, they perform poorly on\nsub-populations - we observed that the word error rate (WER) achieved by\nGoogle's ASR API on Indian accents is almost twice the WER on US accents.\nExisting adaptation methods either require access to model parameters or\noverlay an error-correcting module on output transcripts. We highlight the need\nfor correlating outputs with the original speech to fix accent errors.\nAccordingly, we propose a novel coupling of an open-source accent-tuned local\nmodel with the black-box service where the output from the service guides\nframe-level inference in the local model. Our fine-grained merging algorithm is\nbetter at fixing accent errors than existing word-level combination strategies.\nExperiments on Indian and Australian accents with three leading ASR models as\nservice, show that we achieve as much as 28% relative reduction in WER over\nboth the local and service models.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 07:07:49 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Khandelwal", "Kartik", ""], ["Jyothi", "Preethi", ""], ["Awasthi", "Abhijeet", ""], ["Sarawagi", "Sunita", ""]]}, {"id": "2006.13546", "submitter": "Stefan Heinrich", "authors": "Stefan Heinrich, Yuan Yao, Tobias Hinz, Zhiyuan Liu, Thomas Hummel,\n  Matthias Kerzel, Cornelius Weber, and Stefan Wermter", "title": "Crossmodal Language Grounding in an Embodied Neurocognitive Model", "comments": null, "journal-ref": "Frontiers in Neurorobotics, vol 14(52), 2020", "doi": "10.3389/fnbot.2020.00052", "report-no": null, "categories": "cs.NE cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Human infants are able to acquire natural language seemingly easily at an\nearly age. Their language learning seems to occur simultaneously with learning\nother cognitive functions as well as with playful interactions with the\nenvironment and caregivers. From a neuroscientific perspective, natural\nlanguage is embodied, grounded in most, if not all, sensory and sensorimotor\nmodalities, and acquired by means of crossmodal integration. However,\ncharacterising the underlying mechanisms in the brain is difficult and\nexplaining the grounding of language in crossmodal perception and action\nremains challenging. In this paper, we present a neurocognitive model for\nlanguage grounding which reflects bio-inspired mechanisms such as an implicit\nadaptation of timescales as well as end-to-end multimodal abstraction. It\naddresses developmental robotic interaction and extends its learning\ncapabilities using larger-scale knowledge-based data. In our scenario, we\nutilise the humanoid robot NICO in obtaining the EMIL data collection, in which\nthe cognitive robot interacts with objects in a children's playground\nenvironment while receiving linguistic labels from a caregiver. The model\nanalysis shows that crossmodally integrated representations are sufficient for\nacquiring language merely from sensory input through interaction with objects\nin an environment. The representations self-organise hierarchically and embed\ntemporal and spatial information through composition and decomposition. This\nmodel can also provide the basis for further crossmodal integration of\nperceptually grounded cognitive representations.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 08:12:09 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 08:27:34 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Heinrich", "Stefan", ""], ["Yao", "Yuan", ""], ["Hinz", "Tobias", ""], ["Liu", "Zhiyuan", ""], ["Hummel", "Thomas", ""], ["Kerzel", "Matthias", ""], ["Weber", "Cornelius", ""], ["Wermter", "Stefan", ""]]}, {"id": "2006.13557", "submitter": "Tung Nguyen Thanh", "authors": "Thanh-Tung Nguyen, Xuan-Phi Nguyen, Shafiq Joty, Xiaoli Li", "title": "Efficient Constituency Parsing by Pointing", "comments": "Accepted at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel constituency parsing model that casts the parsing problem\ninto a series of pointing tasks. Specifically, our model estimates the\nlikelihood of a span being a legitimate tree constituent via the pointing score\ncorresponding to the boundary words of the span. Our parsing model supports\nefficient top-down decoding and our learning objective is able to enforce\nstructural consistency without resorting to the expensive CKY inference. The\nexperiments on the standard English Penn Treebank parsing task show that our\nmethod achieves 92.78 F1 without using pre-trained models, which is higher than\nall the existing methods with similar time complexity. Using pre-trained BERT,\nour model achieves 95.48 F1, which is competitive with the state-of-the-art\nwhile being faster. Our approach also establishes new state-of-the-art in\nBasque and Swedish in the SPMRL shared tasks on multilingual constituency\nparsing.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 08:29:09 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Nguyen", "Thanh-Tung", ""], ["Nguyen", "Xuan-Phi", ""], ["Joty", "Shafiq", ""], ["Li", "Xiaoli", ""]]}, {"id": "2006.13561", "submitter": "Tung Nguyen Thanh", "authors": "Thanh-Tung Nguyen, Xuan-Phi Nguyen, Shafiq Joty, Xiaoli Li", "title": "Differentiable Window for Dynamic Local Attention", "comments": "Accepted at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Differentiable Window, a new neural module and general purpose\ncomponent for dynamic window selection. While universally applicable, we\ndemonstrate a compelling use case of utilizing Differentiable Window to improve\nstandard attention modules by enabling more focused attentions over the input\nregions. We propose two variants of Differentiable Window, and integrate them\nwithin the Transformer architecture in two novel ways. We evaluate our proposed\napproach on a myriad of NLP tasks, including machine translation, sentiment\nanalysis, subject-verb agreement and language modeling. Our experimental\nresults demonstrate consistent and sizable improvements across all tasks.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 08:47:26 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Nguyen", "Thanh-Tung", ""], ["Nguyen", "Xuan-Phi", ""], ["Joty", "Shafiq", ""], ["Li", "Xiaoli", ""]]}, {"id": "2006.13730", "submitter": "Nicolay Rusnachenko", "authors": "Nicolay Rusnachenko, Natalia Loukachevitch", "title": "Attention-Based Neural Networks for Sentiment Attitude Extraction using\n  Distant Supervision", "comments": "10 pages, 9 figures. The preprint of an article published in the\n  proceedings of the 10th International Conference on Web Intelligence, Mining\n  and Semantics (WIMS 2020). The final authenticated publication is available\n  online at https://doi.org/10.1145/3405962.3405985. arXiv admin note:\n  substantial text overlap with arXiv:2006.11605", "journal-ref": "The 10th International Conference on Web Intelligence, Mining and\n  Semantics (WIMS 2020), June 30-July 3, 2020, Biarritz, France", "doi": "10.1145/3405962.3405985", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the sentiment attitude extraction task, the aim is to identify\n<<attitudes>> -- sentiment relations between entities mentioned in text. In\nthis paper, we provide a study on attention-based context encoders in the\nsentiment attitude extraction task. For this task, we adapt attentive context\nencoders of two types: (1) feature-based; (2) self-based. In our study, we\nutilize the corpus of Russian analytical texts RuSentRel and automatically\nconstructed news collection RuAttitudes for enriching the training set. We\nconsider the problem of attitude extraction as two-class (positive, negative)\nand three-class (positive, negative, neutral) classification tasks for whole\ndocuments. Our experiments with the RuSentRel corpus show that the three-class\nclassification models, which employ the RuAttitudes corpus for training, result\nin 10% increase and extra 3% by F1, when model architectures include the\nattention mechanism. We also provide the analysis of attention weight\ndistributions in dependence on the term type.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 13:54:48 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 10:46:18 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Rusnachenko", "Nicolay", ""], ["Loukachevitch", "Natalia", ""]]}, {"id": "2006.13760", "submitter": "Heinrich K\\\"uttler", "authors": "Heinrich K\\\"uttler and Nantas Nardelli and Alexander H. Miller and\n  Roberta Raileanu and Marco Selvatici and Edward Grefenstette and Tim\n  Rockt\\\"aschel", "title": "The NetHack Learning Environment", "comments": "28 pages. Accepted at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Progress in Reinforcement Learning (RL) algorithms goes hand-in-hand with the\ndevelopment of challenging environments that test the limits of current\nmethods. While existing RL environments are either sufficiently complex or\nbased on fast simulation, they are rarely both. Here, we present the NetHack\nLearning Environment (NLE), a scalable, procedurally generated, stochastic,\nrich, and challenging environment for RL research based on the popular\nsingle-player terminal-based roguelike game, NetHack. We argue that NetHack is\nsufficiently complex to drive long-term research on problems such as\nexploration, planning, skill acquisition, and language-conditioned RL, while\ndramatically reducing the computational resources required to gather a large\namount of experience. We compare NLE and its task suite to existing\nalternatives, and discuss why it is an ideal medium for testing the robustness\nand systematic generalization of RL agents. We demonstrate empirical success\nfor early stages of the game using a distributed Deep RL baseline and Random\nNetwork Distillation exploration, alongside qualitative analysis of various\nagents trained in the environment. NLE is open source at\nhttps://github.com/facebookresearch/nle.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 14:12:56 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 11:05:57 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["K\u00fcttler", "Heinrich", ""], ["Nardelli", "Nantas", ""], ["Miller", "Alexander H.", ""], ["Raileanu", "Roberta", ""], ["Selvatici", "Marco", ""], ["Grefenstette", "Edward", ""], ["Rockt\u00e4schel", "Tim", ""]]}, {"id": "2006.13774", "submitter": "David Chang", "authors": "David Chang, Ivana Balazevic, Carl Allen, Daniel Chawla, Cynthia\n  Brandt, Richard Andrew Taylor", "title": "Benchmark and Best Practices for Biomedical Knowledge Graph Embeddings", "comments": "Accepted to BioNLP 2020 at ACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of biomedical and healthcare data is encoded in discrete, symbolic form\nsuch as text and medical codes. There is a wealth of expert-curated biomedical\ndomain knowledge stored in knowledge bases and ontologies, but the lack of\nreliable methods for learning knowledge representation has limited their\nusefulness in machine learning applications. While text-based representation\nlearning has significantly improved in recent years through advances in natural\nlanguage processing, attempts to learn biomedical concept embeddings so far\nhave been lacking. A recent family of models called knowledge graph embeddings\nhave shown promising results on general domain knowledge graphs, and we explore\ntheir capabilities in the biomedical domain. We train several state-of-the-art\nknowledge graph embedding models on the SNOMED-CT knowledge graph, provide a\nbenchmark with comparison to existing methods and in-depth discussion on best\npractices, and make a case for the importance of leveraging the\nmulti-relational nature of knowledge graphs for learning biomedical knowledge\nrepresentation. The embeddings, code, and materials will be made available to\nthe communitY.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 14:47:33 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Chang", "David", ""], ["Balazevic", "Ivana", ""], ["Allen", "Carl", ""], ["Chawla", "Daniel", ""], ["Brandt", "Cynthia", ""], ["Taylor", "Richard Andrew", ""]]}, {"id": "2006.13816", "submitter": "Bernal Jimenez Gutierrez", "authors": "Bernal Jim\\'enez Guti\\'errez, Juncheng Zeng, Dongdong Zhang, Ping\n  Zhang, Yu Su", "title": "Document Classification for COVID-19 Literature", "comments": "8 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The global pandemic has made it more important than ever to quickly and\naccurately retrieve relevant scientific literature for effective consumption by\nresearchers in a wide range of fields. We provide an analysis of several\nmulti-label document classification models on the LitCovid dataset, a growing\ncollection of 23,000 research papers regarding the novel 2019 coronavirus. We\nfind that pre-trained language models fine-tuned on this dataset outperform all\nother baselines and that BioBERT surpasses the others by a small margin with\nmicro-F1 and accuracy scores of around 86% and 75% respectively on the test\nset. We evaluate the data efficiency and generalizability of these models as\nessential features of any system prepared to deal with an urgent situation like\nthe current health crisis. Finally, we explore 50 errors made by the best\nperforming models on LitCovid documents and find that they often (1) correlate\ncertain labels too closely together and (2) fail to focus on discriminative\nsections of the articles; both of which are important issues to address in\nfuture work. Both data and code are available on GitHub.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 20:03:28 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 21:58:17 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Guti\u00e9rrez", "Bernal Jim\u00e9nez", ""], ["Zeng", "Juncheng", ""], ["Zhang", "Dongdong", ""], ["Zhang", "Ping", ""], ["Su", "Yu", ""]]}, {"id": "2006.13979", "submitter": "Alexis Conneau", "authors": "Alexis Conneau, Alexei Baevski, Ronan Collobert, Abdelrahman Mohamed,\n  Michael Auli", "title": "Unsupervised Cross-lingual Representation Learning for Speech\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents XLSR which learns cross-lingual speech representations by\npretraining a single model from the raw waveform of speech in multiple\nlanguages. We build on wav2vec 2.0 which is trained by solving a contrastive\ntask over masked latent speech representations and jointly learns a\nquantization of the latents shared across languages. The resulting model is\nfine-tuned on labeled data and experiments show that cross-lingual pretraining\nsignificantly outperforms monolingual pretraining. On the CommonVoice\nbenchmark, XLSR shows a relative phoneme error rate reduction of 72% compared\nto the best known results. On BABEL, our approach improves word error rate by\n16% relative compared to a comparable system. Our approach enables a single\nmultilingual speech recognition model which is competitive to strong individual\nmodels. Analysis shows that the latent discrete speech representations are\nshared across languages with increased sharing for related languages. We hope\nto catalyze research in low-resource speech understanding by releasing XLSR-53,\na large model pretrained in 53 languages.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 18:25:05 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 23:19:19 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Conneau", "Alexis", ""], ["Baevski", "Alexei", ""], ["Collobert", "Ronan", ""], ["Mohamed", "Abdelrahman", ""], ["Auli", "Michael", ""]]}, {"id": "2006.14007", "submitter": "Yushi Hu", "authors": "Yushi Hu, Shane Settle, Karen Livescu", "title": "Multilingual Jointly Trained Acoustic and Written Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustic word embeddings (AWEs) are vector representations of spoken word\nsegments. AWEs can be learned jointly with embeddings of character sequences,\nto generate phonetically meaningful embeddings of written words, or\nacoustically grounded word embeddings (AGWEs). Such embeddings have been used\nto improve speech retrieval, recognition, and spoken term discovery. In this\nwork, we extend this idea to multiple low-resource languages. We jointly train\nan AWE model and an AGWE model, using phonetically transcribed data from\nmultiple languages. The pre-trained models can then be used for unseen\nzero-resource languages, or fine-tuned on data from low-resource languages. We\nalso investigate distinctive features, as an alternative to phone labels, to\nbetter share cross-lingual information. We test our models on word\ndiscrimination tasks for twelve languages. When trained on eleven languages and\ntested on the remaining unseen language, our model outperforms traditional\nunsupervised approaches like dynamic time warping. After fine-tuning the\npre-trained models on one hour or even ten minutes of data from a new language,\nperformance is typically much better than training on only the target-language\ndata. We also find that phonetic supervision improves performance over\ncharacter sequences, and that distinctive feature supervision is helpful in\nhandling unseen phones in the target language.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 19:16:02 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Hu", "Yushi", ""], ["Settle", "Shane", ""], ["Livescu", "Karen", ""]]}, {"id": "2006.14017", "submitter": "Xinyu Hua", "authors": "Xinyu Hua, Lei Li, Lifeng Hua, Lu Wang", "title": "XREF: Entity Linking for Chinese News Comments with Supplementary\n  Article Reference", "comments": "Accepted to AKBC2020, link to openreview:\n  https://openreview.net/forum?id=1hLH6CKIjN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic identification of mentioned entities in social media posts\nfacilitates quick digestion of trending topics and popular opinions.\nNonetheless, this remains a challenging task due to limited context and diverse\nname variations. In this paper, we study the problem of entity linking for\nChinese news comments given mentions' spans. We hypothesize that comments often\nrefer to entities in the corresponding news article, as well as topics\ninvolving the entities. We therefore propose a novel model, XREF, that\nleverages attention mechanisms to (1) pinpoint relevant context within\ncomments, and (2) detect supporting entities from the news article. To improve\ntraining, we make two contributions: (a) we propose a supervised attention loss\nin addition to the standard cross entropy, and (b) we develop a weakly\nsupervised training scheme to utilize the large-scale unlabeled corpus. Two new\ndatasets in entertainment and product domains are collected and annotated for\nexperiments. Our proposed method outperforms previous methods on both datasets.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 19:42:54 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Hua", "Xinyu", ""], ["Li", "Lei", ""], ["Hua", "Lifeng", ""], ["Wang", "Lu", ""]]}, {"id": "2006.14032", "submitter": "Jesse Mu", "authors": "Jesse Mu, Jacob Andreas", "title": "Compositional Explanations of Neurons", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a procedure for explaining neurons in deep representations by\nidentifying compositional logical concepts that closely approximate neuron\nbehavior. Compared to prior work that uses atomic labels as explanations,\nanalyzing neurons compositionally allows us to more precisely and expressively\ncharacterize their behavior. We use this procedure to answer several questions\non interpretability in models for vision and natural language processing.\nFirst, we examine the kinds of abstractions learned by neurons. In image\nclassification, we find that many neurons learn highly abstract but\nsemantically coherent visual concepts, while other polysemantic neurons detect\nmultiple unrelated features; in natural language inference (NLI), neurons learn\nshallow lexical heuristics from dataset biases. Second, we see whether\ncompositional explanations give us insight into model performance: vision\nneurons that detect human-interpretable concepts are positively correlated with\ntask performance, while NLI neurons that fire for shallow heuristics are\nnegatively correlated with task performance. Finally, we show how compositional\nexplanations provide an accessible way for end users to produce simple\n\"copy-paste\" adversarial examples that change model behavior in predictable\nways.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 20:37:05 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 23:46:51 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Mu", "Jesse", ""], ["Andreas", "Jacob", ""]]}, {"id": "2006.14069", "submitter": "Ramon Ferrer-I-Cancho", "authors": "Ramon Ferrer-i-Cancho, Carlos G\\'omez-Rodr\\'iguez and Juan Luis\n  Esteban", "title": "Bounds of the sum of edge lengths in linear arrangements of trees", "comments": "Title changed at proof stage", "journal-ref": "Journal of Statistical Mechanics: Theory and Experiment, 2021 (2),\n  023403 (2021)", "doi": "10.1088/1742-5468/abd4d7", "report-no": null, "categories": "cs.DM cs.CL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental problem in network science is the normalization of the\ntopological or physical distance between vertices, that requires understanding\nthe range of variation of the unnormalized distances. Here we investigate the\nlimits of the variation of the physical distance in linear arrangements of the\nvertices of trees. In particular, we investigate various problems on the sum of\nedge lengths in trees of a fixed size: the minimum and the maximum value of the\nsum for specific trees, the minimum and the maximum in classes of trees (bistar\ntrees and caterpillar trees) and finally the minimum and the maximum for any\ntree. We establish some foundations for research on optimality scores for\nspatial networks in one dimension.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 21:53:39 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 09:32:17 GMT"}, {"version": "v3", "created": "Sun, 14 Feb 2021 17:39:41 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Ferrer-i-Cancho", "Ramon", ""], ["G\u00f3mez-Rodr\u00edguez", "Carlos", ""], ["Esteban", "Juan Luis", ""]]}, {"id": "2006.14116", "submitter": "Jimit Gandhi", "authors": "Fenil Doshi, Jimit Gandhi, Deep Gosalia and Sudhir Bagul", "title": "Normalizing Text using Language Modelling based on Phonetics and String\n  Similarity", "comments": "Author 1, 2 and 3 are equal contributors; Number of pages: 9; Number\n  of figures: 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media networks and chatting platforms often use an informal version of\nnatural text. Adversarial spelling attacks also tend to alter the input text by\nmodifying the characters in the text. Normalizing these texts is an essential\nstep for various applications like language translation and text to speech\nsynthesis where the models are trained over clean regular English language. We\npropose a new robust model to perform text normalization.\n  Our system uses the BERT language model to predict the masked words that\ncorrespond to the unnormalized words. We propose two unique masking strategies\nthat try to replace the unnormalized words in the text with their root form\nusing a unique score based on phonetic and string similarity metrics.We use\nhuman-centric evaluations where volunteers were asked to rank the normalized\ntext. Our strategies yield an accuracy of 86.7% and 83.2% which indicates the\neffectiveness of our system in dealing with text normalization.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 00:42:39 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Doshi", "Fenil", ""], ["Gandhi", "Jimit", ""], ["Gosalia", "Deep", ""], ["Bagul", "Sudhir", ""]]}, {"id": "2006.14135", "submitter": "Ning Wang", "authors": "Ning Wang, Mingxuan Chen, K.P. Subbalakshmi", "title": "Explainable CNN-attention Networks (C-Attention Network) for Automated\n  Detection of Alzheimer's Disease", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose three explainable deep learning architectures to\nautomatically detect patients with Alzheimer`s disease based on their language\nabilities. The architectures use: (1) only the part-of-speech features; (2)\nonly language embedding features and (3) both of these feature classes via a\nunified architecture. We use self-attention mechanisms and interpretable\n1-dimensional ConvolutionalNeural Network (CNN) to generate two types of\nexplanations of the model`s action: intra-class explanation and inter-class\nexplanation. The inter-class explanation captures the relative importance of\neach of the different features in that class, while the inter-class explanation\ncaptures the relative importance between the classes. Note that although we\nhave considered two classes of features in this paper, the architecture is\neasily expandable to more classes because of its modularity. Extensive\nexperimentation and comparison with several recent models show that our method\noutperforms these methods with an accuracy of 92.2% and F1 score of 0.952on the\nDementiaBank dataset while being able to generate explanations. We show by\nexamples, how to generate these explanations using attention values.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 02:10:38 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 04:43:27 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Wang", "Ning", ""], ["Chen", "Mingxuan", ""], ["Subbalakshmi", "K. P.", ""]]}, {"id": "2006.14170", "submitter": "Lingjuan Lyu", "authors": "Lingjuan Lyu, Yitong Li, Xuanli He, Tong Xiao", "title": "Towards Differentially Private Text Representations", "comments": "Accepted to SIGIR'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most deep learning frameworks require users to pool their local data or model\nupdates to a trusted server to train or maintain a global model. The assumption\nof a trusted server who has access to user information is ill-suited in many\napplications. To tackle this problem, we develop a new deep learning framework\nunder an untrusted server setting, which includes three modules: (1) embedding\nmodule, (2) randomization module, and (3) classifier module. For the\nrandomization module, we propose a novel local differentially private (LDP)\nprotocol to reduce the impact of privacy parameter $\\epsilon$ on accuracy, and\nprovide enhanced flexibility in choosing randomization probabilities for LDP.\nAnalysis and experiments show that our framework delivers comparable or even\nbetter performance than the non-private framework and existing LDP protocols,\ndemonstrating the advantages of our LDP protocol.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 04:42:18 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Lyu", "Lingjuan", ""], ["Li", "Yitong", ""], ["He", "Xuanli", ""], ["Xiao", "Tong", ""]]}, {"id": "2006.14194", "submitter": "Alex Sokolov", "authors": "Alex Sokolov, Tracy Rohlin, Ariya Rastrow", "title": "Neural Machine Translation for Multilingual Grapheme-to-Phoneme\n  Conversion", "comments": "Published in INTERSPEECH (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Grapheme-to-phoneme (G2P) models are a key component in Automatic Speech\nRecognition (ASR) systems, such as the ASR system in Alexa, as they are used to\ngenerate pronunciations for out-of-vocabulary words that do not exist in the\npronunciation lexicons (mappings like \"e c h o\" to \"E k oU\"). Most G2P systems\nare monolingual and based on traditional joint-sequence based n-gram models\n[1,2]. As an alternative, we present a single end-to-end trained neural G2P\nmodel that shares same encoder and decoder across multiple languages. This\nallows the model to utilize a combination of universal symbol inventories of\nLatin-like alphabets and cross-linguistically shared feature representations.\nSuch model is especially useful in the scenarios of low resource languages and\ncode switching/foreign words, where the pronunciations in one language need to\nbe adapted to other locales or accents. We further experiment with word\nlanguage distribution vector as an additional training target in order to\nimprove system performance by helping the model decouple pronunciations across\na variety of languages in the parameter space. We show 7.2% average improvement\nin phoneme error rate over low resource languages and no degradation over high\nresource ones compared to monolingual baselines.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 06:16:29 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 23:36:47 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Sokolov", "Alex", ""], ["Rohlin", "Tracy", ""], ["Rastrow", "Ariya", ""]]}, {"id": "2006.14198", "submitter": "Rajarshi Das", "authors": "Rajarshi Das, Ameya Godbole, Shehzaad Dhuliawala, Manzil Zaheer,\n  Andrew McCallum", "title": "A Simple Approach to Case-Based Reasoning in Knowledge Bases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a surprisingly simple yet accurate approach to reasoning in\nknowledge graphs (KGs) that requires \\emph{no training}, and is reminiscent of\ncase-based reasoning in classical artificial intelligence (AI). Consider the\ntask of finding a target entity given a source entity and a binary relation.\nOur non-parametric approach derives crisp logical rules for each query by\nfinding multiple \\textit{graph path patterns} that connect similar source\nentities through the given relation. Using our method, we obtain new\nstate-of-the-art accuracy, outperforming all previous models, on NELL-995 and\nFB-122. We also demonstrate that our model is robust in low data settings,\noutperforming recently proposed meta-learning approaches\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 06:28:09 GMT"}, {"version": "v2", "created": "Sun, 19 Jul 2020 01:26:35 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Das", "Rajarshi", ""], ["Godbole", "Ameya", ""], ["Dhuliawala", "Shehzaad", ""], ["Zaheer", "Manzil", ""], ["McCallum", "Andrew", ""]]}, {"id": "2006.14209", "submitter": "Marina Sedinkina", "authors": "Marina Sedinkina, Nikolas Breitkopf, Hinrich Sch\\\"utze", "title": "Automatic Domain Adaptation Outperforms Manual Domain Adaptation for\n  Predicting Financial Outcomes", "comments": "Accepted at ACL2019", "journal-ref": null, "doi": "10.18653/v1/P19-1034", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we automatically create sentiment dictionaries for predicting\nfinancial outcomes. We compare three approaches: (I) manual adaptation of the\ndomain-general dictionary H4N, (ii) automatic adaptation of H4N and (iii) a\ncombination consisting of first manual, then automatic adaptation. In our\nexperiments, we demonstrate that the automatically adapted sentiment dictionary\noutperforms the previous state of the art in predicting the financial outcomes\nexcess return and volatility. In particular, automatic adaptation performs\nbetter than manual adaptation. In our analysis, we find that annotation based\non an expert's a priori belief about a word's meaning can be incorrect --\nannotation should be performed based on the word's contexts in the target\ndomain instead.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 07:11:07 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Sedinkina", "Marina", ""], ["Breitkopf", "Nikolas", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "2006.14223", "submitter": "Alex Sokolov", "authors": "Alex Sokolov, Denis Filimonov", "title": "Neural Machine Translation For Paraphrase Generation", "comments": "Published in NIPS 2018: 2nd Conversational AI workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Training a spoken language understanding system, as the one in Alexa,\ntypically requires a large human-annotated corpus of data. Manual annotations\nare expensive and time consuming. In Alexa Skill Kit (ASK) user experience with\nthe skill greatly depends on the amount of data provided by skill developer. In\nthis work, we present an automatic natural language generation system, capable\nof generating both human-like interactions and annotations by the means of\nparaphrasing. Our approach consists of machine translation (MT) inspired\nencoder-decoder deep recurrent neural network. We evaluate our model on the\nimpact it has on ASK skill, intent, named entity classification accuracy and\nsentence level coverage, all of which demonstrate significant improvements for\nunseen skills on natural language understanding (NLU) models, trained on the\ndata augmented with paraphrases.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 07:38:00 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Sokolov", "Alex", ""], ["Filimonov", "Denis", ""]]}, {"id": "2006.14262", "submitter": "Chiranjib Sur", "authors": "Chiranjib Sur", "title": "SACT: Self-Aware Multi-Space Feature Composition Transformer for\n  Multinomial Attention for Video Captioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Video captioning works on the two fundamental concepts, feature detection and\nfeature composition. While modern day transformers are beneficial in composing\nfeatures, they lack the fundamental problems of selecting and understanding of\nthe contents. As the feature length increases, it becomes increasingly\nimportant to include provisions for improved capturing of the pertinent\ncontents. In this work, we have introduced a new concept of Self-Aware\nComposition Transformer (SACT) that is capable of generating Multinomial\nAttention (MultAtt) which is a way of generating distributions of various\ncombinations of frames. Also, multi-head attention transformer works on the\nprinciple of combining all possible contents for attention, which is good for\nnatural language classification, but has limitations for video captioning.\nVideo contents have repetitions and require parsing of important contents for\nbetter content composition. In this work, we have introduced SACT for more\nselective attention and combined them for different attention heads for better\ncapturing of the usable contents for any applications. To address the problem\nof diversification and encourage selective utilization, we propose the\nSelf-Aware Composition Transformer model for dense video captioning and apply\nthe technique on two benchmark datasets like ActivityNet and YouCookII.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 09:11:49 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Sur", "Chiranjib", ""]]}, {"id": "2006.14264", "submitter": "Chiranjib Sur", "authors": "Chiranjib Sur", "title": "Self-Segregating and Coordinated-Segregating Transformer for Focused\n  Deep Multi-Modular Network for Visual Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Attention mechanism has gained huge popularity due to its effectiveness in\nachieving high accuracy in different domains. But attention is opportunistic\nand is not justified by the content or usability of the content. Transformer\nlike structure creates all/any possible attention(s). We define segregating\nstrategies that can prioritize the contents for the applications for\nenhancement of performance. We defined two strategies: Self-Segregating\nTransformer (SST) and Coordinated-Segregating Transformer (CST) and used it to\nsolve visual question answering application. Self-segregation strategy for\nattention contributes in better understanding and filtering the information\nthat can be most helpful for answering the question and create diversity of\nvisual-reasoning for attention. This work can easily be used in many other\napplications that involve repetition and multiple frames of features and would\nreduce the commonality of the attentions to a great extent. Visual Question\nAnswering (VQA) requires understanding and coordination of both images and\ntextual interpretations. Experiments demonstrate that segregation strategies\nfor cascaded multi-head transformer attention outperforms many previous works\nand achieved considerable improvement for VQA-v2 dataset benchmark.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 09:17:03 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Sur", "Chiranjib", ""]]}, {"id": "2006.14320", "submitter": "Santosh Barnwal", "authors": "Santosh Kumar Barnwal, Uma Shanker Tiwary", "title": "Analyzing Effect of Repeated Reading on Oral Fluency and Narrative\n  Production for Computer-Assisted Language Learning", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Repeated reading (RR) helps learners, who have little to no experience with\nreading fluently to gain confidence, speed and process words automatically. The\nbenefits of repeated readings include helping all learners with fact recall,\naiding identification of learners' main ideas and vocabulary, increasing\ncomprehension, leading to faster reading as well as increasing word recognition\naccuracy, and assisting struggling learners as they transition from\nword-by-word reading to more meaningful phrasing. Thus, RR ultimately helps in\nimprovements of learners' oral fluency and narrative production. However, there\nare no open audio datasets available on oral responses of learners based on\ntheir RR practices. Therefore, in this paper, we present our dataset, discuss\nits properties, and propose a method to assess oral fluency and narrative\nproduction for learners of English using acoustic, prosodic, lexical and\nsyntactical characteristics. The results show that a CALL system can be\ndeveloped for assessing the improvements in learners' oral fluency and\nnarrative production.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 11:51:08 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Barnwal", "Santosh Kumar", ""], ["Tiwary", "Uma Shanker", ""]]}, {"id": "2006.14405", "submitter": "Hongfei Xu", "authors": "Hongfei Xu and Josef van Genabith and Deyi Xiong and Qiuhui Liu and\n  Jingyi Zhang", "title": "Learning Source Phrase Representations for Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Transformer translation model (Vaswani et al., 2017) based on a\nmulti-head attention mechanism can be computed effectively in parallel and has\nsignificantly pushed forward the performance of Neural Machine Translation\n(NMT). Though intuitively the attentional network can connect distant words via\nshorter network paths than RNNs, empirical analysis demonstrates that it still\nhas difficulty in fully capturing long-distance dependencies (Tang et al.,\n2018). Considering that modeling phrases instead of words has significantly\nimproved the Statistical Machine Translation (SMT) approach through the use of\nlarger translation blocks (\"phrases\") and its reordering ability, modeling NMT\nat phrase level is an intuitive proposal to help the model capture\nlong-distance relationships. In this paper, we first propose an attentive\nphrase representation generation mechanism which is able to generate phrase\nrepresentations from corresponding token representations. In addition, we\nincorporate the generated phrase representations into the Transformer\ntranslation model to enhance its ability to capture long-distance\nrelationships. In our experiments, we obtain significant improvements on the\nWMT 14 English-German and English-French tasks on top of the strong Transformer\nbaseline, which shows the effectiveness of our approach. Our approach helps\nTransformer Base models perform at the level of Transformer Big models, and\neven significantly better for long sentences, but with substantially fewer\nparameters and training steps. The fact that phrase representations help even\nin the big setting further supports our conjecture that they make a valuable\ncontribution to long-distance relations.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 13:43:11 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Xu", "Hongfei", ""], ["van Genabith", "Josef", ""], ["Xiong", "Deyi", ""], ["Liu", "Qiuhui", ""], ["Zhang", "Jingyi", ""]]}, {"id": "2006.14465", "submitter": "Vivek Srivastava", "authors": "Vivek Srivastava, Mayank Singh", "title": "IIT Gandhinagar at SemEval-2020 Task 9: Code-Mixed Sentiment\n  Classification Using Candidate Sentence Generation and Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Code-mixing is the phenomenon of using multiple languages in the same\nutterance of a text or speech. It is a frequently used pattern of communication\non various platforms such as social media sites, online gaming, product\nreviews, etc. Sentiment analysis of the monolingual text is a well-studied\ntask. Code-mixing adds to the challenge of analyzing the sentiment of the text\ndue to the non-standard writing style. We present a candidate sentence\ngeneration and selection based approach on top of the Bi-LSTM based neural\nclassifier to classify the Hinglish code-mixed text into one of the three\nsentiment classes positive, negative, or neutral. The proposed approach shows\nan improvement in the system performance as compared to the Bi-LSTM based\nneural classifier. The results present an opportunity to understand various\nother nuances of code-mixing in the textual data, such as humor-detection,\nintent classification, etc.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 14:59:47 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 03:55:13 GMT"}, {"version": "v3", "created": "Thu, 23 Jul 2020 05:03:02 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Srivastava", "Vivek", ""], ["Singh", "Mayank", ""]]}, {"id": "2006.14666", "submitter": "Pranav Sharma", "authors": "Pranav Sharma", "title": "LPar -- A Distributed Multi Agent platform for building Polyglot, Omni\n  Channel and Industrial grade Natural Language Interfaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of serving and delighting customers in a personal and near human\nlike manner is very high on automation agendas of most Enterprises. Last few\nyears, have seen huge progress in Natural Language Processing domain which has\nled to deployments of conversational agents in many enterprises. Most of the\ncurrent industrial deployments tend to use Monolithic Single Agent designs that\nmodel the entire knowledge and skill of the Domain. While this approach is one\nof the fastest to market, the monolithic design makes it very hard to scale\nbeyond a point. There are also challenges in seamlessly leveraging many tools\noffered by sub fields of Natural Language Processing and Information Retrieval\nin a single solution. The sub fields that can be leveraged to provide relevant\ninformation are, Question and Answer system, Abstractive Summarization,\nSemantic Search, Knowledge Graph etc. Current deployments also tend to be very\ndependent on the underlying Conversational AI platform (open source or\ncommercial) , which is a challenge as this is a fast evolving space and no one\nplatform can be considered future proof even in medium term of 3-4 years.\nLately,there is also work done to build multi agent solutions that tend to\nleverage a concept of master agent. While this has shown promise, this approach\nstill makes the master agent in itself difficult to scale. To address these\nchallenges, we introduce LPar, a distributed multi agent platform for large\nscale industrial deployment of polyglot, diverse and inter-operable agents. The\nasynchronous design of LPar supports dynamically expandable domain. We also\nintroduce multiple strategies available in the LPar system to elect the most\nsuitable agent to service a customer query.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 19:20:07 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Sharma", "Pranav", ""]]}, {"id": "2006.14668", "submitter": "Rudolf Rosa", "authors": "Rudolf Rosa, Ond\\v{r}ej Du\\v{s}ek, Tom Kocmi, David Mare\\v{c}ek,\n  Tom\\'a\\v{s} Musil, Patr\\'icia Schmidtov\\'a, Dominik Jurko, Ond\\v{r}ej Bojar,\n  Daniel Hrbek, David Ko\\v{s}\\v{t}\\'ak, Martina Kinsk\\'a, Josef Dole\\v{z}al and\n  Kl\\'ara Voseck\\'a", "title": "THEaiTRE: Artificial Intelligence to Write a Theatre Play", "comments": "accepted to AI4Narratives2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present THEaiTRE, a starting project aimed at automatic generation of\ntheatre play scripts. This paper reviews related work and drafts an approach we\nintend to follow. We plan to adopt generative neural language models and\nhierarchical generation approaches, supported by summarization and machine\ntranslation methods, and complemented with a human-in-the-loop approach.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 19:24:57 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Rosa", "Rudolf", ""], ["Du\u0161ek", "Ond\u0159ej", ""], ["Kocmi", "Tom", ""], ["Mare\u010dek", "David", ""], ["Musil", "Tom\u00e1\u0161", ""], ["Schmidtov\u00e1", "Patr\u00edcia", ""], ["Jurko", "Dominik", ""], ["Bojar", "Ond\u0159ej", ""], ["Hrbek", "Daniel", ""], ["Ko\u0161\u0165\u00e1k", "David", ""], ["Kinsk\u00e1", "Martina", ""], ["Dole\u017eal", "Josef", ""], ["Voseck\u00e1", "Kl\u00e1ra", ""]]}, {"id": "2006.14744", "submitter": "Liqun Chen", "authors": "Liqun Chen, Zhe Gan, Yu Cheng, Linjie Li, Lawrence Carin, Jingjing Liu", "title": "Graph Optimal Transport for Cross-Domain Alignment", "comments": null, "journal-ref": "ICML 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-domain alignment between two sets of entities (e.g., objects in an\nimage, words in a sentence) is fundamental to both computer vision and natural\nlanguage processing. Existing methods mainly focus on designing advanced\nattention mechanisms to simulate soft alignment, with no training signals to\nexplicitly encourage alignment. The learned attention matrices are also dense\nand lacks interpretability. We propose Graph Optimal Transport (GOT), a\nprincipled framework that germinates from recent advances in Optimal Transport\n(OT). In GOT, cross-domain alignment is formulated as a graph matching problem,\nby representing entities into a dynamically-constructed graph. Two types of OT\ndistances are considered: (i) Wasserstein distance (WD) for node (entity)\nmatching; and (ii) Gromov-Wasserstein distance (GWD) for edge (structure)\nmatching. Both WD and GWD can be incorporated into existing neural network\nmodels, effectively acting as a drop-in regularizer. The inferred transport\nplan also yields sparse and self-normalized alignment, enhancing the\ninterpretability of the learned model. Experiments show consistent\noutperformance of GOT over baselines across a wide range of tasks, including\nimage-text retrieval, visual question answering, image captioning, machine\ntranslation, and text summarization.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 01:14:23 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 15:58:36 GMT"}, {"version": "v3", "created": "Fri, 24 Jul 2020 20:04:49 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Chen", "Liqun", ""], ["Gan", "Zhe", ""], ["Cheng", "Yu", ""], ["Li", "Linjie", ""], ["Carin", "Lawrence", ""], ["Liu", "Jingjing", ""]]}, {"id": "2006.14767", "submitter": "Aishwarya Padmakumar", "authors": "Aishwarya Padmakumar, Raymond J. Mooney", "title": "Dialog as a Vehicle for Lifelong Learning", "comments": "Position Paper Track at the SIGDIAL Special Session on Physically\n  Situated Dialogue (RoboDial 2.0) - Camera Ready Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialog systems research has primarily been focused around two main types of\napplications - task-oriented dialog systems that learn to use clarification to\naid in understanding a goal, and open-ended dialog systems that are expected to\ncarry out unconstrained \"chit chat\" conversations. However, dialog interactions\ncan also be used to obtain various types of knowledge that can be used to\nimprove an underlying language understanding system, or other machine learning\nsystems that the dialog acts over. In this position paper, we present the\nproblem of designing dialog systems that enable lifelong learning as an\nimportant challenge problem, in particular for applications involving\nphysically situated robots. We include examples of prior work in this\ndirection, and discuss challenges that remain to be addressed.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 03:08:33 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Padmakumar", "Aishwarya", ""], ["Mooney", "Raymond J.", ""]]}, {"id": "2006.14779", "submitter": "Gagan Bansal", "authors": "Gagan Bansal, Tongshuang Wu, Joyce Zhou, Raymond Fok, Besmira Nushi,\n  Ece Kamar, Marco Tulio Ribeiro, Daniel S. Weld", "title": "Does the Whole Exceed its Parts? The Effect of AI Explanations on\n  Complementary Team Performance", "comments": "CHI'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many researchers motivate explainable AI with studies showing that human-AI\nteam performance on decision-making tasks improves when the AI explains its\nrecommendations. However, prior studies observed improvements from explanations\nonly when the AI, alone, outperformed both the human and the best team. Can\nexplanations help lead to complementary performance, where team accuracy is\nhigher than either the human or the AI working solo? We conduct mixed-method\nuser studies on three datasets, where an AI with accuracy comparable to humans\nhelps participants solve a task (explaining itself in some conditions). While\nwe observed complementary improvements from AI augmentation, they were not\nincreased by explanations. Rather, explanations increased the chance that\nhumans will accept the AI's recommendation, regardless of its correctness. Our\nresult poses new challenges for human-centered AI: Can we develop explanatory\napproaches that encourage appropriate trust in AI, and therefore help generate\n(or improve) complementary performance?\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 03:34:04 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 21:23:55 GMT"}, {"version": "v3", "created": "Tue, 12 Jan 2021 22:50:34 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Bansal", "Gagan", ""], ["Wu", "Tongshuang", ""], ["Zhou", "Joyce", ""], ["Fok", "Raymond", ""], ["Nushi", "Besmira", ""], ["Kamar", "Ece", ""], ["Ribeiro", "Marco Tulio", ""], ["Weld", "Daniel S.", ""]]}, {"id": "2006.14799", "submitter": "Asli Celikyilmaz", "authors": "Asli Celikyilmaz, Elizabeth Clark, Jianfeng Gao", "title": "Evaluation of Text Generation: A Survey", "comments": "47 pages (revised version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper surveys evaluation methods of natural language generation (NLG)\nsystems that have been developed in the last few years. We group NLG evaluation\nmethods into three categories: (1) human-centric evaluation metrics, (2)\nautomatic metrics that require no training, and (3) machine-learned metrics.\nFor each category, we discuss the progress that has been made and the\nchallenges still being faced, with a focus on the evaluation of recently\nproposed NLG tasks and neural NLG models. We then present two examples for\ntask-specific NLG evaluations for automatic text summarization and long text\ngeneration, and conclude the paper by proposing future research directions.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 04:52:48 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 07:04:41 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Celikyilmaz", "Asli", ""], ["Clark", "Elizabeth", ""], ["Gao", "Jianfeng", ""]]}, {"id": "2006.14806", "submitter": "Xiang Deng", "authors": "Xiang Deng, Huan Sun, Alyssa Lees, You Wu, Cong Yu", "title": "TURL: Table Understanding through Representation Learning", "comments": "Accepted to VLDB 2021. Extended version with experiments added during\n  revision. Our source code, benchmark, as well as pre-trained models will be\n  available on https://github.com/sunlab-osu/TURL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Relational tables on the Web store a vast amount of knowledge. Owing to the\nwealth of such tables, there has been tremendous progress on a variety of tasks\nin the area of table understanding. However, existing work generally relies on\nheavily-engineered task-specific features and model architectures. In this\npaper, we present TURL, a novel framework that introduces the\npre-training/fine-tuning paradigm to relational Web tables. During\npre-training, our framework learns deep contextualized representations on\nrelational tables in an unsupervised manner. Its universal model design with\npre-trained representations can be applied to a wide range of tasks with\nminimal task-specific fine-tuning. Specifically, we propose a structure-aware\nTransformer encoder to model the row-column structure of relational tables, and\npresent a new Masked Entity Recovery (MER) objective for pre-training to\ncapture the semantics and knowledge in large-scale unlabeled data. We\nsystematically evaluate TURL with a benchmark consisting of 6 different tasks\nfor table understanding (e.g., relation extraction, cell filling). We show that\nTURL generalizes well to all tasks and substantially outperforms existing\nmethods in almost all instances.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 05:44:54 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 02:47:41 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Deng", "Xiang", ""], ["Sun", "Huan", ""], ["Lees", "Alyssa", ""], ["Wu", "You", ""], ["Yu", "Cong", ""]]}, {"id": "2006.14939", "submitter": "Jipeng Qiang J", "authors": "Jipeng Qiang and Yun Li and Yi Zhu and Yunhao Yuan and Xindong Wu", "title": "LSBert: A Simple Framework for Lexical Simplification", "comments": "arXiv admin note: text overlap with arXiv:1907.06226", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lexical simplification (LS) aims to replace complex words in a given sentence\nwith their simpler alternatives of equivalent meaning, to simplify the\nsentence. Recently unsupervised lexical simplification approaches only rely on\nthe complex word itself regardless of the given sentence to generate candidate\nsubstitutions, which will inevitably produce a large number of spurious\ncandidates. In this paper, we propose a lexical simplification framework LSBert\nbased on pretrained representation model Bert, that is capable of (1) making\nuse of the wider context when both detecting the words in need of\nsimplification and generating substitue candidates, and (2) taking five\nhigh-quality features into account for ranking candidates, including Bert\nprediction order, Bert-based language model, and the paraphrase database PPDB,\nin addition to the word frequency and word similarity commonly used in other LS\nmethods. We show that our system outputs lexical simplifications that are\ngrammatically correct and semantically appropriate, and obtains obvious\nimprovement compared with these baselines, outperforming the state-of-the-art\nby 29.8 Accuracy points on three well-known benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 09:15:42 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Qiang", "Jipeng", ""], ["Li", "Yun", ""], ["Zhu", "Yi", ""], ["Yuan", "Yunhao", ""], ["Wu", "Xindong", ""]]}, {"id": "2006.14953", "submitter": "Rahma Chaabouni", "authors": "Eugene Kharitonov and Rahma Chaabouni", "title": "What they do when in doubt: a study of inductive biases in seq2seq\n  learners", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-to-sequence (seq2seq) learners are widely used, but we still have\nonly limited knowledge about what inductive biases shape the way they\ngeneralize. We address that by investigating how popular seq2seq learners\ngeneralize in tasks that have high ambiguity in the training data. We use SCAN\nand three new tasks to study learners' preferences for memorization,\narithmetic, hierarchical, and compositional reasoning. Further, we connect to\nSolomonoff's theory of induction and propose to use description length as a\nprincipled and sensitive measure of inductive biases.\n  In our experimental study, we find that LSTM-based learners can learn to\nperform counting, addition, and multiplication by a constant from a single\ntraining example. Furthermore, Transformer and LSTM-based learners show a bias\ntoward the hierarchical induction over the linear one, while CNN-based learners\nprefer the opposite. On the SCAN dataset, we find that CNN-based, and, to a\nlesser degree, Transformer- and LSTM-based learners have a preference for\ncompositional generalization over memorization. Finally, across all our\nexperiments, description length proved to be a sensitive measure of inductive\nbiases.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 12:43:10 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 09:43:36 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Kharitonov", "Eugene", ""], ["Chaabouni", "Rahma", ""]]}, {"id": "2006.14994", "submitter": "Andrei Damian I", "authors": "Andrei Ionut Damian, Laurentiu Piciu, Cosmin Mihai Marinescu", "title": "ProVe -- Self-supervised pipeline for automated product replacement and\n  cold-starting based on neural language models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In retail vertical industries, businesses are dealing with human limitation\nof quickly understanding and adapting to new purchasing behaviors. Moreover,\nretail businesses need to overcome the human limitation of properly managing a\nmassive selection of products/brands/categories. These limitations lead to\ndeficiencies from both commercial (e.g. loss of sales, decrease in customer\nsatisfaction) and operational perspective (e.g. out-of-stock, over-stock). In\nthis paper, we propose a pipeline approach based on Natural Language\nUnderstanding, for recommending the most suitable replacements for products\nthat are out-of-stock. Moreover, we will propose a solution for managing\nproducts that were newly introduced in a retailer's portfolio with almost no\ntransactional history. This solution will help businesses: automatically assign\nthe new products to the right category; recommend complementary products for\ncross-sell from day 1; perform sales predictions even with almost no\ntransactional history. Finally, the vector space model resulted by applying the\npipeline presented in this paper is directly used as semantic information in\ndeep learning-based demand forecasting solutions, leading to more accurate\npredictions. The whole research and experimentation process have been done\nusing real-life private transactional data, however the source code is\navailable on https://github.com/Lummetry/ProVe\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 14:03:18 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 12:55:40 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Damian", "Andrei Ionut", ""], ["Piciu", "Laurentiu", ""], ["Marinescu", "Cosmin Mihai", ""]]}, {"id": "2006.15020", "submitter": "Marjan Ghazvininejad", "authors": "Mike Lewis, Marjan Ghazvininejad, Gargi Ghosh, Armen Aghajanyan, Sida\n  Wang, Luke Zettlemoyer", "title": "Pre-training via Paraphrasing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce MARGE, a pre-trained sequence-to-sequence model learned with an\nunsupervised multi-lingual multi-document paraphrasing objective. MARGE\nprovides an alternative to the dominant masked language modeling paradigm,\nwhere we self-supervise the reconstruction of target text by retrieving a set\nof related texts (in many languages) and conditioning on them to maximize the\nlikelihood of generating the original. We show it is possible to jointly learn\nto do retrieval and reconstruction, given only a random initialization. The\nobjective noisily captures aspects of paraphrase, translation, multi-document\nsummarization, and information retrieval, allowing for strong zero-shot\nperformance on several tasks. For example, with no additional task-specific\ntraining we achieve BLEU scores of up to 35.8 for document translation. We\nfurther show that fine-tuning gives strong performance on a range of\ndiscriminative and generative tasks in many languages, making MARGE the most\ngenerally applicable pre-training method to date.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 14:43:43 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Lewis", "Mike", ""], ["Ghazvininejad", "Marjan", ""], ["Ghosh", "Gargi", ""], ["Aghajanyan", "Armen", ""], ["Wang", "Sida", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "2006.15222", "submitter": "Jesse Vig", "authors": "Jesse Vig, Ali Madani, Lav R. Varshney, Caiming Xiong, Richard Socher,\n  Nazneen Fatema Rajani", "title": "BERTology Meets Biology: Interpreting Attention in Protein Language\n  Models", "comments": "To appear in ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer architectures have proven to learn useful representations for\nprotein classification and generation tasks. However, these representations\npresent challenges in interpretability. In this work, we demonstrate a set of\nmethods for analyzing protein Transformer models through the lens of attention.\nWe show that attention: (1) captures the folding structure of proteins,\nconnecting amino acids that are far apart in the underlying sequence, but\nspatially close in the three-dimensional structure, (2) targets binding sites,\na key functional component of proteins, and (3) focuses on progressively more\ncomplex biophysical properties with increasing layer depth. We find this\nbehavior to be consistent across three Transformer architectures (BERT, ALBERT,\nXLNet) and two distinct protein datasets. We also present a three-dimensional\nvisualization of the interaction between attention and protein structure. Code\nfor visualization and analysis is available at\nhttps://github.com/salesforce/provis.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 21:50:17 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 23:44:32 GMT"}, {"version": "v3", "created": "Sun, 28 Mar 2021 21:56:26 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Vig", "Jesse", ""], ["Madani", "Ali", ""], ["Varshney", "Lav R.", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""], ["Rajani", "Nazneen Fatema", ""]]}, {"id": "2006.15315", "submitter": "Subhabrata Mukherjee", "authors": "Subhabrata Mukherjee, Ahmed Hassan Awadallah", "title": "Uncertainty-aware Self-training for Text Classification with Few Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent success of large-scale pre-trained language models crucially hinge on\nfine-tuning them on large amounts of labeled data for the downstream task, that\nare typically expensive to acquire. In this work, we study self-training as one\nof the earliest semi-supervised learning approaches to reduce the annotation\nbottleneck by making use of large-scale unlabeled data for the target task.\nStandard self-training mechanism randomly samples instances from the unlabeled\npool to pseudo-label and augment labeled data. In this work, we propose an\napproach to improve self-training by incorporating uncertainty estimates of the\nunderlying neural network leveraging recent advances in Bayesian deep learning.\nSpecifically, we propose (i) acquisition functions to select instances from the\nunlabeled pool leveraging Monte Carlo (MC) Dropout, and (ii) learning mechanism\nleveraging model confidence for self-training. As an application, we focus on\ntext classification on five benchmark datasets. We show our methods leveraging\nonly 20-30 labeled samples per class for each task for training and for\nvalidation can perform within 3% of fully supervised pre-trained language\nmodels fine-tuned on thousands of labeled instances with an aggregate accuracy\nof 91% and improving by upto 12% over baselines.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2020 08:13:58 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Mukherjee", "Subhabrata", ""], ["Awadallah", "Ahmed Hassan", ""]]}, {"id": "2006.15319", "submitter": "Hung Le", "authors": "Hung Le, Steven C.H. Hoi", "title": "Video-Grounded Dialogues with Pretrained Generation Language Models", "comments": "Accepted at ACL 2020 (Short Paper)", "journal-ref": "Association for Computational Linguistics (2020) 5842-5848", "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained language models have shown remarkable success in improving\nvarious downstream NLP tasks due to their ability to capture dependencies in\ntextual data and generate natural responses. In this paper, we leverage the\npower of pre-trained language models for improving video-grounded dialogue,\nwhich is very challenging and involves complex features of different dynamics:\n(1) Video features which can extend across both spatial and temporal\ndimensions; and (2) Dialogue features which involve semantic dependencies over\nmultiple dialogue turns. We propose a framework by extending GPT-2 models to\ntackle these challenges by formulating video-grounded dialogue tasks as a\nsequence-to-sequence task, combining both visual and textual representation\ninto a structured sequence, and fine-tuning a large pre-trained GPT-2 network.\nOur framework allows fine-tuning language models to capture dependencies across\nmultiple modalities over different levels of information: spatio-temporal level\nin video and token-sentence level in dialogue context. We achieve promising\nimprovement on the Audio-Visual Scene-Aware Dialogues (AVSD) benchmark from\nDSTC7, which supports a potential direction in this line of research.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2020 08:24:26 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Le", "Hung", ""], ["Hoi", "Steven C. H.", ""]]}, {"id": "2006.15411", "submitter": "David Sears", "authors": "David R. W. Sears", "title": "String-based methods for tonal harmony: A corpus study of Haydn's string\n  quartets", "comments": "This is an original manuscript / preprint of a book chapter: Sears,\n  David R. W (in press). String-based methods for tonal harmony: A corpus study\n  of Haydn's string quartets.\" In D. Shanahan, A. Burgoyne, & I. Quinn (Eds.),\n  Oxford Handbook of Music and Corpus Studies. New York: Oxford University\n  Press. The manuscript contains 2 musical examples, 3 figures, and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter considers how string-based methods might be adapted to address\nmusic-analytic questions related to the discovery of musical organization, with\nparticular attention devoted to the analysis of tonal harmony. I begin by\napplying the taxonomy of mental organization proposed by Mandler (1979) to the\nconcept of musical organization. Using this taxonomy as a guide, I then present\nevidence for three principles of tonal harmony -- recurrence, syntax, and\nrecursion -- using a corpus of Haydn string quartets.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2020 17:42:15 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Sears", "David R. W.", ""]]}, {"id": "2006.15435", "submitter": "Chenguang Zhu", "authors": "Beliz Gunel, Chenguang Zhu, Michael Zeng, Xuedong Huang", "title": "Mind The Facts: Knowledge-Boosted Coherent Abstractive Text\n  Summarization", "comments": "NeurIPS 2019, Knowledge Representation & Reasoning Meets Machine\n  Learning (KR2ML workshop)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural models have become successful at producing abstractive summaries that\nare human-readable and fluent. However, these models have two critical\nshortcomings: they often don't respect the facts that are either included in\nthe source article or are known to humans as commonsense knowledge, and they\ndon't produce coherent summaries when the source article is long. In this work,\nwe propose a novel architecture that extends Transformer encoder-decoder\narchitecture in order to improve on these shortcomings. First, we incorporate\nentity-level knowledge from the Wikidata knowledge graph into the\nencoder-decoder architecture. Injecting structural world knowledge from\nWikidata helps our abstractive summarization model to be more fact-aware.\nSecond, we utilize the ideas used in Transformer-XL language model in our\nproposed encoder-decoder architecture. This helps our model with producing\ncoherent summaries even when the source article is long. We test our model on\nCNN/Daily Mail summarization dataset and show improvements on ROUGE scores over\nthe baseline Transformer model. We also include model predictions for which our\nmodel accurately conveys the facts, while the baseline Transformer model\ndoesn't.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2020 20:06:15 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Gunel", "Beliz", ""], ["Zhu", "Chenguang", ""], ["Zeng", "Michael", ""], ["Huang", "Xuedong", ""]]}, {"id": "2006.15454", "submitter": "Zi-Yi Dou", "authors": "Zi-Yi Dou, Sachin Kumar, Yulia Tsvetkov", "title": "A Deep Reinforced Model for Zero-Shot Cross-Lingual Summarization with\n  Bilingual Semantic Similarity Rewards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual text summarization aims at generating a document summary in one\nlanguage given input in another language. It is a practically important but\nunder-explored task, primarily due to the dearth of available data. Existing\nmethods resort to machine translation to synthesize training data, but such\npipeline approaches suffer from error propagation. In this work, we propose an\nend-to-end cross-lingual text summarization model. The model uses reinforcement\nlearning to directly optimize a bilingual semantic similarity metric between\nthe summaries generated in a target language and gold summaries in a source\nlanguage. We also introduce techniques to pre-train the model leveraging\nmonolingual summarization and machine translation objectives. Experimental\nresults in both English--Chinese and English--German cross-lingual\nsummarization settings demonstrate the effectiveness of our methods. In\naddition, we find that reinforcement learning models with bilingual semantic\nsimilarity as rewards generate more fluent sentences than strong baselines.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2020 21:51:38 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Dou", "Zi-Yi", ""], ["Kumar", "Sachin", ""], ["Tsvetkov", "Yulia", ""]]}, {"id": "2006.15509", "submitter": "Chen Liang", "authors": "Chen Liang, Yue Yu, Haoming Jiang, Siawpeng Er, Ruijia Wang, Tuo Zhao,\n  Chao Zhang", "title": "BOND: BERT-Assisted Open-Domain Named Entity Recognition with Distant\n  Supervision", "comments": "Proceedings of the 26th ACM SIGKDD Conference on Knowledge Discovery\n  and Data Mining (KDD '20)", "journal-ref": null, "doi": "10.1145/3394486.3403149", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the open-domain named entity recognition (NER) problem under distant\nsupervision. The distant supervision, though does not require large amounts of\nmanual annotations, yields highly incomplete and noisy distant labels via\nexternal knowledge bases. To address this challenge, we propose a new\ncomputational framework -- BOND, which leverages the power of pre-trained\nlanguage models (e.g., BERT and RoBERTa) to improve the prediction performance\nof NER models. Specifically, we propose a two-stage training algorithm: In the\nfirst stage, we adapt the pre-trained language model to the NER tasks using the\ndistant labels, which can significantly improve the recall and precision; In\nthe second stage, we drop the distant labels, and propose a self-training\napproach to further improve the model performance. Thorough experiments on 5\nbenchmark datasets demonstrate the superiority of BOND over existing distantly\nsupervised NER methods. The code and distantly labeled data have been released\nin https://github.com/cliang1453/BOND.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2020 04:55:39 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Liang", "Chen", ""], ["Yu", "Yue", ""], ["Jiang", "Haoming", ""], ["Er", "Siawpeng", ""], ["Wang", "Ruijia", ""], ["Zhao", "Tuo", ""], ["Zhang", "Chao", ""]]}, {"id": "2006.15585", "submitter": "Sevinj Yolchuyeva", "authors": "Sevinj Yolchuyeva, G\\'eza N\\'emeth, B\\'alint Gyires-T\\'oth", "title": "Self-Attention Networks for Intent Detection", "comments": "Proceedings of the International Conference on Recent Advances in\n  Natural Language Processing (RANLP 2019)", "journal-ref": null, "doi": "10.26615/978-954-452-056-4_157", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-attention networks (SAN) have shown promising performance in various\nNatural Language Processing (NLP) scenarios, especially in machine translation.\nOne of the main points of SANs is the strength of capturing long-range and\nmulti-scale dependencies from the data. In this paper, we present a novel\nintent detection system which is based on a self-attention network and a\nBi-LSTM. Our approach shows improvement by using a transformer model and deep\naveraging network-based universal sentence encoder compared to previous\nsolutions. We evaluate the system on Snips, Smart Speaker, Smart Lights, and\nATIS datasets by different evaluation metrics. The performance of the proposed\nmodel is compared with LSTM with the same datasets.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2020 12:19:15 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Yolchuyeva", "Sevinj", ""], ["N\u00e9meth", "G\u00e9za", ""], ["Gyires-T\u00f3th", "B\u00e1lint", ""]]}, {"id": "2006.15595", "submitter": "Guolin Ke", "authors": "Guolin Ke, Di He, Tie-Yan Liu", "title": "Rethinking Positional Encoding in Language Pre-training", "comments": "update to ICLR's version", "journal-ref": "International Conference on Learning Representations (ICLR) 2021,\n  https://openreview.net/forum?id=09-528y2Fgf", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigate the positional encoding methods used in language\npre-training (e.g., BERT) and identify several problems in the existing\nformulations. First, we show that in the absolute positional encoding, the\naddition operation applied on positional embeddings and word embeddings brings\nmixed correlations between the two heterogeneous information resources. It may\nbring unnecessary randomness in the attention and further limit the\nexpressiveness of the model. Second, we question whether treating the position\nof the symbol \\texttt{[CLS]} the same as other words is a reasonable design,\nconsidering its special role (the representation of the entire sentence) in the\ndownstream tasks. Motivated from above analysis, we propose a new positional\nencoding method called \\textbf{T}ransformer with \\textbf{U}ntied\n\\textbf{P}ositional \\textbf{E}ncoding (TUPE). In the self-attention module,\nTUPE computes the word contextual correlation and positional correlation\nseparately with different parameterizations and then adds them together. This\ndesign removes the mixed and noisy correlations over heterogeneous embeddings\nand offers more expressiveness by using different projection matrices.\nFurthermore, TUPE unties the \\texttt{[CLS]} symbol from other positions, making\nit easier to capture information from all positions. Extensive experiments and\nablation studies on GLUE benchmark demonstrate the effectiveness of the\nproposed method. Codes and models are released at\nhttps://github.com/guolinke/TUPE.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2020 13:11:02 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 02:57:50 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2020 02:53:21 GMT"}, {"version": "v4", "created": "Mon, 15 Mar 2021 07:56:22 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Ke", "Guolin", ""], ["He", "Di", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2006.15720", "submitter": "Bowen Tan", "authors": "Bowen Tan, Zichao Yang, Maruan AI-Shedivat, Eric P. Xing, Zhiting Hu", "title": "Progressive Generation of Long Text with Pretrained Language Models", "comments": "NAACL 2021, Code available at\n  https://github.com/tanyuqian/progressive-generation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale language models (LMs) pretrained on massive corpora of text, such\nas GPT-2, are powerful open-domain text generators. However, as our systematic\nexamination reveals, it is still challenging for such models to generate\ncoherent long passages of text (e.g., 1000 tokens), especially when the models\nare fine-tuned to the target domain on a small corpus. Previous\nplanning-then-generation methods also fall short of producing such long text in\nvarious domains. To overcome the limitations, we propose a simple but effective\nmethod of generating text in a progressive manner, inspired by generating\nimages from low to high resolution. Our method first produces domain-specific\ncontent keywords and then progressively refines them into complete passages in\nmultiple stages. The simple design allows our approach to take advantage of\npretrained LMs at each stage and effectively adapt to any target domain given\nonly a small set of examples. We conduct a comprehensive empirical study with a\nbroad set of evaluation metrics, and show that our approach significantly\nimproves upon the fine-tuned large LMs and various planning-then-generation\nmethods in terms of quality and sample efficiency. Human evaluation also\nvalidates that our model generations are more coherent.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2020 21:23:05 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 17:23:57 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Tan", "Bowen", ""], ["Yang", "Zichao", ""], ["AI-Shedivat", "Maruan", ""], ["Xing", "Eric P.", ""], ["Hu", "Zhiting", ""]]}, {"id": "2006.15732", "submitter": "Petr Plechac", "authors": "Petr Plechac, Thomas N. Haider", "title": "Mapping Topic Evolution Across Poetic Traditions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Poetic traditions across languages evolved differently, but we find that\ncertain semantic topics occur in several of them, albeit sometimes with\ntemporal delay, or with diverging trajectories over time. We apply Latent\nDirichlet Allocation (LDA) to poetry corpora of four languages, i.e. German\n(52k poems), English (85k poems), Russian (18k poems), and Czech (80k poems).\nWe align and interpret salient topics, their trend over time (1600--1925 A.D.),\nshowing similarities and disparities across poetic traditions with a few select\ntopics, and use their trajectories over time to pinpoint specific literary\nepochs.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2020 22:23:03 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 12:19:12 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Plechac", "Petr", ""], ["Haider", "Thomas N.", ""]]}, {"id": "2006.15795", "submitter": "Shengfei Lyu", "authors": "Shengfei Lyu, Jiaqi Liu", "title": "Combine Convolution with Recurrent Networks for Text Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural network (CNN) and recurrent neural network (RNN) are two\npopular architectures used in text classification. Traditional methods to\ncombine the strengths of the two networks rely on streamlining them or\nconcatenating features extracted from them. In this paper, we propose a novel\nmethod to keep the strengths of the two networks to a great extent. In the\nproposed model, a convolutional neural network is applied to learn a 2D weight\nmatrix where each row reflects the importance of each word from different\naspects. Meanwhile, we use a bi-directional RNN to process each word and employ\na neural tensor layer that fuses forward and backward hidden states to get word\nrepresentations. In the end, the weight matrix and word representations are\ncombined to obtain the representation in a 2D matrix form for the text. We\ncarry out experiments on a number of datasets for text classification. The\nexperimental results confirm the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 03:36:04 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Lyu", "Shengfei", ""], ["Liu", "Jiaqi", ""]]}, {"id": "2006.15830", "submitter": "Jinhyuk Lee", "authors": "Jinhyuk Lee, Sean S. Yi, Minbyul Jeong, Mujeen Sung, Wonjin Yoon,\n  Yonghwa Choi, Miyoung Ko, Jaewoo Kang", "title": "Answering Questions on COVID-19 in Real-Time", "comments": "10 pages, EMNLP NLP-COVID Workshop 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent outbreak of the novel coronavirus is wreaking havoc on the world\nand researchers are struggling to effectively combat it. One reason why the\nfight is difficult is due to the lack of information and knowledge. In this\nwork, we outline our effort to contribute to shrinking this knowledge vacuum by\ncreating covidAsk, a question answering (QA) system that combines biomedical\ntext mining and QA techniques to provide answers to questions in real-time. Our\nsystem also leverages information retrieval (IR) approaches to provide\nentity-level answers that are complementary to QA models. Evaluation of\ncovidAsk is carried out by using a manually created dataset called COVID-19\nQuestions which is based on information from various sources, including the CDC\nand the WHO. We hope our system will be able to aid researchers in their search\nfor knowledge and information not only for COVID-19, but for future pandemics\nas well.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 06:34:35 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 08:42:30 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Lee", "Jinhyuk", ""], ["Yi", "Sean S.", ""], ["Jeong", "Minbyul", ""], ["Sung", "Mujeen", ""], ["Yoon", "Wonjin", ""], ["Choi", "Yonghwa", ""], ["Ko", "Miyoung", ""], ["Kang", "Jaewoo", ""]]}, {"id": "2006.15854", "submitter": "Taiwo Kolajo", "authors": "Taiwo Kolajo, Olawande Daramola, Ayodele Adebiyi, Seth Aaditeshwar", "title": "A Framework for Pre-processing of Social Media Feeds based on Integrated\n  Local Knowledge Base", "comments": "38 pages, 5 figures, 6 tables", "journal-ref": null, "doi": "10.1016/j.ipm.2020.102348", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the previous studies on the semantic analysis of social media feeds\nhave not considered the issue of ambiguity that is associated with slangs,\nabbreviations, and acronyms that are embedded in social media posts. These\nnoisy terms have implicit meanings and form part of the rich semantic context\nthat must be analysed to gain complete insights from social media feeds. This\npaper proposes an improved framework for pre-processing of social media feeds\nfor better performance. To do this, the use of an integrated knowledge base\n(ikb) which comprises a local knowledge source (Naijalingo), urban dictionary\nand internet slang was combined with the adapted Lesk algorithm to facilitate\nsemantic analysis of social media feeds. Experimental results showed that the\nproposed approach performed better than existing methods when it was tested on\nthree machine learning models, which are support vector machines, multilayer\nperceptron, and convolutional neural networks. The framework had an accuracy of\n94.07% on a standardized dataset, and 99.78% on localised dataset when used to\nextract sentiments from tweets. The improved performance on the localised\ndataset reveals the advantage of integrating the use of local knowledge sources\ninto the process of analysing social media feeds particularly in interpreting\nslangs/acronyms/abbreviations that have contextually rooted meanings.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 07:56:22 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Kolajo", "Taiwo", ""], ["Daramola", "Olawande", ""], ["Adebiyi", "Ayodele", ""], ["Aaditeshwar", "Seth", ""]]}, {"id": "2006.15903", "submitter": "Mohammad Mohammadamini", "authors": "Mohammad Mohammadamini (LIA), Driss Matrouf (LIA)", "title": "Data augmentation versus noise compensation for x- vector speaker\n  recognition systems in noisy environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The explosion of available speech data and new speaker modeling methods based\non deep neural networks (DNN) have given the ability to develop more robust\nspeaker recognition systems. Among DNN speaker modelling techniques, x-vector\nsystem has shown a degree of robustness in noisy environments. Previous studies\nsuggest that by increasing the number of speakers in the training data and\nusing data augmentation more robust speaker recognition systems are achievable\nin noisy environments. In this work, we want to know if explicit noise\ncompensation techniques continue to be effective despite the general noise\nrobustness of these systems. For this study, we will use two different x-vector\nnetworks: the first one is trained on Voxceleb1 (Protocol1), and the second one\nis trained on Voxceleb1+Voxveleb2 (Protocol2). We propose to add a denoising\nx-vector subsystem before scoring. Experimental results show that, the x-vector\nsystem used in Protocol2 is more robust than the other one used Protocol1.\nDespite this observation we will show that explicit noise compensation gives\nalmost the same EER relative gain in both protocols. For example, in the\nProtocol2 we have 21% to 66% improvement of EER with denoising techniques.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 09:50:45 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Mohammadamini", "Mohammad", "", "LIA"], ["Matrouf", "Driss", "", "LIA"]]}, {"id": "2006.15935", "submitter": "Stefano M. Iacus", "authors": "Tiziana Carpi and Stefano Maria Iacus", "title": "Is Japanese gendered language used on Twitter ? A large scale study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study analyzes the usage of Japanese gendered language on Twitter.\nStarting from a collection of 408 million Japanese tweets from 2015 till 2019\nand an additional sample of 2355 manually classified Twitter accounts timelines\ninto gender and categories (politicians, musicians, etc). A large scale textual\nanalysis is performed on this corpus to identify and examine sentence-final\nparticles (SFPs) and first-person pronouns appearing in the texts. It turns out\nthat gendered language is in fact used also on Twitter, in about 6% of the\ntweets, and that the prescriptive classification into \"male\" and \"female\"\nlanguage does not always meet the expectations, with remarkable exceptions.\nFurther, SFPs and pronouns show increasing or decreasing trends, indicating an\nevolution of the language used on Twitter.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 11:07:10 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 08:59:17 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Carpi", "Tiziana", ""], ["Iacus", "Stefano Maria", ""]]}, {"id": "2006.15942", "submitter": "Ritwik Bose", "authors": "Ritwik Bose, Siddharth Vashishtha and James Allen", "title": "Hinting Semantic Parsing with Statistical Word Sense Disambiguation", "comments": "Longer version of AAAI2020 student abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of Semantic Parsing can be approximated as a transformation of an\nutterance into a logical form graph where edges represent semantic roles and\nnodes represent word senses. The resulting representation should be capture the\nmeaning of the utterance and be suitable for reasoning. Word senses and\nsemantic roles are interdependent, meaning errors in assigning word senses can\ncause errors in assigning semantic roles and vice versa. While statistical\napproaches to word sense disambiguation outperform logical, rule-based semantic\nparsers for raw word sense assignment, these statistical word sense\ndisambiguation systems do not produce the rich role structure or detailed\nsemantic representation of the input. In this work, we provide hints from a\nstatistical WSD system to guide a logical semantic parser to produce better\nsemantic type assignments while maintaining the soundness of the resulting\nlogical forms. We observe an improvement of up to 10.5% in F-score, however we\nfind that this improvement comes at a cost to the structural integrity of the\nparse\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 11:20:13 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 11:53:15 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Bose", "Ritwik", ""], ["Vashishtha", "Siddharth", ""], ["Allen", "James", ""]]}, {"id": "2006.15955", "submitter": "Jean-Benoit Delbrouck", "authors": "Jean-Benoit Delbrouck and No\\'e Tits and Mathilde Brousmiche and\n  St\\'ephane Dupont", "title": "A Transformer-based joint-encoding for Emotion Recognition and Sentiment\n  Analysis", "comments": "Winner of the ACL20: Second Grand-Challenge on Multimodal Language", "journal-ref": null, "doi": "10.18653/v1/2020.challengehml-1.1", "report-no": null, "categories": "cs.CL cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding expressed sentiment and emotions are two crucial factors in\nhuman multimodal language. This paper describes a Transformer-based\njoint-encoding (TBJE) for the task of Emotion Recognition and Sentiment\nAnalysis. In addition to use the Transformer architecture, our approach relies\non a modular co-attention and a glimpse layer to jointly encode one or more\nmodalities. The proposed solution has also been submitted to the ACL20: Second\nGrand-Challenge on Multimodal Language to be evaluated on the CMU-MOSEI\ndataset. The code to replicate the presented experiments is open-source:\nhttps://github.com/jbdel/MOSEI_UMONS.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 11:51:46 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Delbrouck", "Jean-Benoit", ""], ["Tits", "No\u00e9", ""], ["Brousmiche", "Mathilde", ""], ["Dupont", "St\u00e9phane", ""]]}, {"id": "2006.15994", "submitter": "Phuong Le-Hong", "authors": "Viet Bui The, Oanh Tran Thi, Phuong Le-Hong", "title": "Improving Sequence Tagging for Vietnamese Text Using Transformer-based\n  Neural Models", "comments": "Accepted at the Conference PACLIC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes our study on using mutilingual BERT embeddings and some\nnew neural models for improving sequence tagging tasks for the Vietnamese\nlanguage. We propose new model architectures and evaluate them extensively on\ntwo named entity recognition datasets of VLSP 2016 and VLSP 2018, and on two\npart-of-speech tagging datasets of VLSP 2010 and VLSP 2013. Our proposed models\noutperform existing methods and achieve new state-of-the-art results. In\nparticular, we have pushed the accuracy of part-of-speech tagging to 95.40% on\nthe VLSP 2010 corpus, to 96.77% on the VLSP 2013 corpus; and the F1 score of\nnamed entity recognition to 94.07% on the VLSP 2016 corpus, to 90.31% on the\nVLSP 2018 corpus. Our code and pre-trained models viBERT and vELECTRA are\nreleased as open source to facilitate adoption and further research.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 12:39:44 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 06:32:02 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2020 11:10:51 GMT"}, {"version": "v4", "created": "Fri, 25 Sep 2020 13:24:18 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["The", "Viet Bui", ""], ["Thi", "Oanh Tran", ""], ["Le-Hong", "Phuong", ""]]}, {"id": "2006.16082", "submitter": "Rudolf Rosa", "authors": "Rudolf Rosa, Tom\\'a\\v{s} Musil, David Mare\\v{c}ek", "title": "Measuring Memorization Effect in Word-Level Neural Networks Probing", "comments": "Accepted to TSD 2020. Will be published in Springer LNCS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple studies have probed representations emerging in neural networks\ntrained for end-to-end NLP tasks and examined what word-level linguistic\ninformation may be encoded in the representations. In classical probing, a\nclassifier is trained on the representations to extract the target linguistic\ninformation. However, there is a threat of the classifier simply memorizing the\nlinguistic labels for individual words, instead of extracting the linguistic\nabstractions from the representations, thus reporting false positive results.\nWhile considerable efforts have been made to minimize the memorization problem,\nthe task of actually measuring the amount of memorization happening in the\nclassifier has been understudied so far. In our work, we propose a simple\ngeneral method for measuring the memorization effect, based on a symmetric\nselection of comparable sets of test words seen versus unseen in training. Our\nmethod can be used to explicitly quantify the amount of memorization happening\nin a probing setup, so that an adequate setup can be chosen and the results of\nthe probing can be interpreted with a reliability estimate. We exemplify this\nby showcasing our method on a case study of probing for part of speech in a\ntrained neural machine translation encoder.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 14:35:42 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Rosa", "Rudolf", ""], ["Musil", "Tom\u00e1\u0161", ""], ["Mare\u010dek", "David", ""]]}, {"id": "2006.16146", "submitter": "Katikapalli Subramanyam Kalyan", "authors": "Katikapalli Subramanyam Kalyan, S.Sangeetha", "title": "Want to Identify, Extract and Normalize Adverse Drug Reactions in\n  Tweets? Use RoBERTa", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents our approach for task 2 and task 3 of Social Media Mining\nfor Health (SMM4H) 2020 shared tasks. In task 2, we have to differentiate\nadverse drug reaction (ADR) tweets from nonADR tweets and is treated as binary\nclassification. Task3 involves extracting ADR mentions and then mapping them to\nMedDRA codes. Extracting ADR mentions is treated as sequence labeling and\nnormalizing ADR mentions is treated as multi-class classification. Our system\nis based on pre-trained language model RoBERTa and it achieves a) F1-score of\n58% in task2 which is 12% more than the average score b) relaxed F1-score of\n70.1% in ADR extraction of task 3 which is 13.7% more than the average score\nand relaxed F1-score of 35% in ADR extraction + normalization of task3 which is\n5.8% more than the average score. Overall, our models achieve promising results\nin both the tasks with significant improvements over average scores.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 16:10:27 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Kalyan", "Katikapalli Subramanyam", ""], ["Sangeetha", "S.", ""]]}, {"id": "2006.16152", "submitter": "David Beauchemin", "authors": "Marouane Yassine, David Beauchemin, Fran\\c{c}ois Laviolette, Luc\n  Lamontagne", "title": "Leveraging Subword Embeddings for Multinational Address Parsing", "comments": "Accepted to IEEE CiSt'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Address parsing consists of identifying the segments that make up an address\nsuch as a street name or a postal code. Because of its importance for tasks\nlike record linkage, address parsing has been approached with many techniques.\nNeural network methods defined a new state-of-the-art for address parsing.\nWhile this approach yielded notable results, previous work has only focused on\napplying neural networks to achieve address parsing of addresses from one\nsource country. We propose an approach in which we employ subword embeddings\nand a Recurrent Neural Network architecture to build a single model capable of\nlearning to parse addresses from multiple countries at the same time while\ntaking into account the difference in languages and address formatting systems.\nWe achieved accuracies around 99 % on the countries used for training with no\npre-processing nor post-processing needed. We explore the possibility of\ntransferring the address parsing knowledge obtained by training on some\ncountries' addresses to others with no further training in a zero-shot transfer\nlearning setting. We achieve good results for 80 % of the countries (33 out of\n41), almost 50 % of which (20 out of 41) is near state-of-the-art performance.\nIn addition, we propose an open-source Python implementation of our trained\nmodels.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 16:14:27 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 16:03:49 GMT"}, {"version": "v3", "created": "Sun, 2 May 2021 14:52:14 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Yassine", "Marouane", ""], ["Beauchemin", "David", ""], ["Laviolette", "Fran\u00e7ois", ""], ["Lamontagne", "Luc", ""]]}, {"id": "2006.16174", "submitter": "Zhenyu Liu", "authors": "Zhenyu Liu, Haiwei Huang, Chaohong Lu, Shengfei Lyu", "title": "Multichannel CNN with Attention for Text Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years, the approaches based on neural networks have shown remarkable\npotential for sentence modeling. There are two main neural network structures:\nrecurrent neural network (RNN) and convolution neural network (CNN). RNN can\ncapture long term dependencies and store the semantics of the previous\ninformation in a fixed-sized vector. However, RNN is a biased model and its\nability to extract global semantics is restricted by the fixed-sized vector.\nAlternatively, CNN is able to capture n-gram features of texts by utilizing\nconvolutional filters. But the width of convolutional filters restricts its\nperformance. In order to combine the strengths of the two kinds of networks and\nalleviate their shortcomings, this paper proposes Attention-based Multichannel\nConvolutional Neural Network (AMCNN) for text classification. AMCNN utilizes a\nbi-directional long short-term memory to encode the history and future\ninformation of words into high dimensional representations, so that the\ninformation of both the front and back of the sentence can be fully expressed.\nThen the scalar attention and vectorial attention are applied to obtain\nmultichannel representations. The scalar attention can calculate the word-level\nimportance and the vectorial attention can calculate the feature-level\nimportance. In the classification task, AMCNN uses a CNN structure to cpture\nword relations on the representations generated by the scalar and vectorial\nattention mechanism instead of calculating the weighted sums. It can\neffectively extract the n-gram features of the text. The experimental results\non the benchmark datasets demonstrate that AMCNN achieves better performance\nthan state-of-the-art methods. In addition, the visualization results verify\nthe semantic richness of multichannel representations.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 16:37:51 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Liu", "Zhenyu", ""], ["Huang", "Haiwei", ""], ["Lu", "Chaohong", ""], ["Lyu", "Shengfei", ""]]}, {"id": "2006.16176", "submitter": "Lichao Sun", "authors": "Lichao Sun", "title": "Natural Backdoor Attack on Text Data", "comments": "under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, advanced NLP models have seen a surge in the usage of various\napplications. This raises the security threats of the released models. In\naddition to the clean models' unintentional weaknesses, {\\em i.e.,} adversarial\nattacks, the poisoned models with malicious intentions are much more dangerous\nin real life. However, most existing works currently focus on the adversarial\nattacks on NLP models instead of positioning attacks, also named\n\\textit{backdoor attacks}. In this paper, we first propose the \\textit{natural\nbackdoor attacks} on NLP models. Moreover, we exploit the various attack\nstrategies to generate trigger on text data and investigate different types of\ntriggers based on modification scope, human recognition, and special cases.\nLast, we evaluate the backdoor attacks, and the results show the excellent\nperformance of with 100\\% backdoor attacks success rate and sacrificing of\n0.83\\% on the text classification task.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 16:40:14 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 19:06:19 GMT"}, {"version": "v3", "created": "Fri, 11 Sep 2020 14:02:48 GMT"}, {"version": "v4", "created": "Fri, 15 Jan 2021 14:07:09 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Sun", "Lichao", ""]]}, {"id": "2006.16212", "submitter": "Thoudam Doren Singh", "authors": "Mirinso Shadang, Navanath Saharia, Thoudam Doren Singh", "title": "Towards the Study of Morphological Processing of the Tangkhul Language", "comments": "In proceeding of Regional International Conference on Natural\n  Language Processing (regICON) 2017, 3rd and 4th November 2017, Imphal, India", "journal-ref": "In proceeding of Regional International Conference on Natural\n  Language Processing (regICON) 2017, 3rd and 4th November 2017, IIIT Senapati,\n  Manipur, India", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is no or little work on natural language processing of Tangkhul\nlanguage. The current work is a humble beginning of morphological processing of\nthis language using an unsupervised approach. We use a small corpus collected\nfrom different sources of text books, short stories and articles of other\ntopics. Based on the experiments carried out, the morpheme identification task\nusing morphessor gives reasonable and interesting output despite using a small\ncorpus.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 17:24:09 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Shadang", "Mirinso", ""], ["Saharia", "Navanath", ""], ["Singh", "Thoudam Doren", ""]]}, {"id": "2006.16324", "submitter": "Tom McCoy", "authors": "R. Thomas McCoy, Erin Grant, Paul Smolensky, Thomas L. Griffiths, Tal\n  Linzen", "title": "Universal linguistic inductive biases via meta-learning", "comments": "To appear in the Proceedings of the 42nd Annual Conference of the\n  Cognitive Science Society", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How do learners acquire languages from the limited data available to them?\nThis process must involve some inductive biases - factors that affect how a\nlearner generalizes - but it is unclear which inductive biases can explain\nobserved patterns in language acquisition. To facilitate computational modeling\naimed at addressing this question, we introduce a framework for giving\nparticular linguistic inductive biases to a neural network model; such a model\ncan then be used to empirically explore the effects of those inductive biases.\nThis framework disentangles universal inductive biases, which are encoded in\nthe initial values of a neural network's parameters, from non-universal\nfactors, which the neural network must learn from data in a given language. The\ninitial state that encodes the inductive biases is found with meta-learning, a\ntechnique through which a model discovers how to acquire new languages more\neasily via exposure to many possible languages. By controlling the properties\nof the languages that are used during meta-learning, we can control the\ninductive biases that meta-learning imparts. We demonstrate this framework with\na case study based on syllable structure. First, we specify the inductive\nbiases that we intend to give our model, and then we translate those inductive\nbiases into a space of languages from which a model can meta-learn. Finally,\nusing existing analysis techniques, we verify that our approach has imparted\nthe linguistic inductive biases that it was intended to impart.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 19:15:10 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["McCoy", "R. Thomas", ""], ["Grant", "Erin", ""], ["Smolensky", "Paul", ""], ["Griffiths", "Thomas L.", ""], ["Linzen", "Tal", ""]]}, {"id": "2006.16336", "submitter": "Junxian He", "authors": "Junxian He, Taylor Berg-Kirkpatrick, Graham Neubig", "title": "Learning Sparse Prototypes for Text Generation", "comments": "NeurIPS 2020 Conference Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prototype-driven text generation uses non-parametric models that first choose\nfrom a library of sentence \"prototypes\" and then modify the prototype to\ngenerate the output text. While effective, these methods are inefficient at\ntest time as a result of needing to store and index the entire training corpus.\nFurther, existing methods often require heuristics to identify which prototypes\nto reference at training time. In this paper, we propose a novel generative\nmodel that automatically learns a sparse prototype support set that,\nnonetheless, achieves strong language modeling performance. This is achieved by\n(1) imposing a sparsity-inducing prior on the prototype selection distribution,\nand (2) utilizing amortized variational inference to learn a prototype\nretrieval function. In experiments, our model outperforms previous\nprototype-driven language models while achieving up to a 1000x memory\nreduction, as well as a 1000x speed-up at test time. More interestingly, we\nshow that the learned prototypes are able to capture semantics and syntax at\ndifferent granularity as we vary the sparsity of prototype selection, and that\ncertain sentence attributes can be controlled by specifying the prototype for\ngeneration.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 19:41:26 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 06:00:40 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["He", "Junxian", ""], ["Berg-Kirkpatrick", "Taylor", ""], ["Neubig", "Graham", ""]]}, {"id": "2006.16362", "submitter": "Jean-Baptiste Cordonnier", "authors": "Jean-Baptiste Cordonnier, Andreas Loukas, Martin Jaggi", "title": "Multi-Head Attention: Collaborate Instead of Concatenate", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention layers are widely used in natural language processing (NLP) and are\nbeginning to influence computer vision architectures. Training very large\ntransformer models allowed significant improvement in both fields, but once\ntrained, these networks show symptoms of over-parameterization. For instance,\nit is known that many attention heads can be pruned without impacting accuracy.\nThis work aims to enhance current understanding on how multiple heads interact.\nMotivated by the observation that attention heads learn redundant key/query\nprojections, we propose a collaborative multi-head attention layer that enables\nheads to learn shared projections. Our scheme decreases the number of\nparameters in an attention layer and can be used as a drop-in replacement in\nany transformer architecture. Our experiments confirm that sharing key/query\ndimensions can be exploited in language understanding, machine translation and\nvision. We also show that it is possible to re-parametrize a pre-trained\nmulti-head attention layer into our collaborative attention layer.\nCollaborative multi-head attention reduces the size of the key and query\nprojections by 4 for same accuracy and speed. Our code is public.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 20:28:52 GMT"}, {"version": "v2", "created": "Thu, 20 May 2021 14:48:30 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Cordonnier", "Jean-Baptiste", ""], ["Loukas", "Andreas", ""], ["Jaggi", "Martin", ""]]}, {"id": "2006.16365", "submitter": "Hung Nghiep Tran", "authors": "Hung Nghiep Tran and Atsuhiro Takasu", "title": "Multi-Partition Embedding Interaction with Block Term Format for\n  Knowledge Graph Completion", "comments": "ECAI 2020. Including state-of-the-art results for very small models\n  in appendix", "journal-ref": "European Conference on Artificial Intelligence (ECAI 2020)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph completion is an important task that aims to predict the\nmissing relational link between entities. Knowledge graph embedding methods\nperform this task by representing entities and relations as embedding vectors\nand modeling their interactions to compute the matching score of each triple.\nPrevious work has usually treated each embedding as a whole and has modeled the\ninteractions between these whole embeddings, potentially making the model\nexcessively expensive or requiring specially designed interaction mechanisms.\nIn this work, we propose the multi-partition embedding interaction (MEI) model\nwith block term format to systematically address this problem. MEI divides each\nembedding into a multi-partition vector to efficiently restrict the\ninteractions. Each local interaction is modeled with the Tucker tensor format\nand the full interaction is modeled with the block term tensor format, enabling\nMEI to control the trade-off between expressiveness and computational cost,\nlearn the interaction mechanisms from data automatically, and achieve\nstate-of-the-art performance on the link prediction task. In addition, we\ntheoretically study the parameter efficiency problem and derive a simple\nempirically verified criterion for optimal parameter trade-off. We also apply\nthe framework of MEI to provide a new generalized explanation for several\nspecially designed interaction mechanisms in previous models.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 20:37:11 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Tran", "Hung Nghiep", ""], ["Takasu", "Atsuhiro", ""]]}, {"id": "2006.16370", "submitter": "Stefano Martina", "authors": "Stefano Martina, Leonardo Ventura, Paolo Frasconi", "title": "Classification of cancer pathology reports: a large-scale comparative\n  study", "comments": "10 pages, 6 figures, 3 tables, accepted for publication in IEEE\n  Journal of Biomedical and Health Informatics (J-BHI)", "journal-ref": "IEEE Journal of Biomedical and Health Informatics 24 (11),\n  3085-3094 (2020)", "doi": "10.1109/JBHI.2020.3005016", "report-no": null, "categories": "cs.LG cs.CL eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We report about the application of state-of-the-art deep learning techniques\nto the automatic and interpretable assignment of ICD-O3 topography and\nmorphology codes to free-text cancer reports. We present results on a large\ndataset (more than 80 000 labeled and 1 500 000 unlabeled anonymized reports\nwritten in Italian and collected from hospitals in Tuscany over more than a\ndecade) and with a large number of classes (134 morphological classes and 61\ntopographical classes). We compare alternative architectures in terms of\nprediction accuracy and interpretability and show that our best model achieves\na multiclass accuracy of 90.3% on topography site assignment and 84.8% on\nmorphology type assignment. We found that in this context hierarchical models\nare not better than flat models and that an element-wise maximum aggregator is\nslightly better than attentive models on site classification. Moreover, the\nmaximum aggregator offers a way to interpret the classification process.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 20:47:33 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Martina", "Stefano", ""], ["Ventura", "Leonardo", ""], ["Frasconi", "Paolo", ""]]}, {"id": "2006.16378", "submitter": "Zhiqing Sun", "authors": "Zhiqing Sun, Yiming Yang", "title": "An EM Approach to Non-autoregressive Conditional Sequence Generation", "comments": "Accepted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoregressive (AR) models have been the dominating approach to conditional\nsequence generation, but are suffering from the issue of high inference\nlatency. Non-autoregressive (NAR) models have been recently proposed to reduce\nthe latency by generating all output tokens in parallel but could only achieve\ninferior accuracy compared to their autoregressive counterparts, primarily due\nto a difficulty in dealing with the multi-modality in sequence generation. This\npaper proposes a new approach that jointly optimizes both AR and NAR models in\na unified Expectation-Maximization (EM) framework. In the E-step, an AR model\nlearns to approximate the regularized posterior of the NAR model. In the\nM-step, the NAR model is updated on the new posterior and selects the training\nexamples for the next AR model. This iterative process can effectively guide\nthe system to remove the multi-modality in the output sequences. To our\nknowledge, this is the first EM approach to NAR sequence generation. We\nevaluate our method on the task of machine translation. Experimental results on\nbenchmark data sets show that the proposed approach achieves competitive, if\nnot better, performance with existing NAR models and significantly reduces the\ninference latency.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 20:58:57 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Sun", "Zhiqing", ""], ["Yang", "Yiming", ""]]}, {"id": "2006.16402", "submitter": "Jasmine Bayrooti", "authors": "Elizabeth Reichert, Helen Qiu, Jasmine Bayrooti", "title": "Reading Between the Demographic Lines: Resolving Sources of Bias in\n  Toxicity Classifiers", "comments": "8 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The censorship of toxic comments is often left to the judgment of imperfect\nmodels. Perspective API, a creation of Google technology incubator Jigsaw, is\nperhaps the most widely used toxicity classifier in industry; the model is\nemployed by several online communities including The New York Times to identify\nand filter out toxic comments with the goal of preserving online safety.\nUnfortunately, Google's model tends to unfairly assign higher toxicity scores\nto comments containing words referring to the identities of commonly targeted\ngroups (e.g., \"woman,'' \"gay,'' etc.) because these identities are frequently\nreferenced in a disrespectful manner in the training data. As a result,\ncomments generated by marginalized groups referencing their identities are\noften mistakenly censored. It is important to be cognizant of this unintended\nbias and strive to mitigate its effects. To address this issue, we have\nconstructed several toxicity classifiers with the intention of reducing\nunintended bias while maintaining strong classification performance.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 21:40:55 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Reichert", "Elizabeth", ""], ["Qiu", "Helen", ""], ["Bayrooti", "Jasmine", ""]]}, {"id": "2006.16403", "submitter": "Chenyang Huang", "authors": "Anandh Perumal, Chenyang Huang, Amine Trabelsi, Osmar R. Za\\\"iane", "title": "ANA at SemEval-2020 Task 4: mUlti-task learNIng for cOmmonsense\n  reasoNing (UNION)", "comments": "7 pages, 1 figure, 3 tables, SemEval 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe our mUlti-task learNIng for cOmmonsense reasoNing\n(UNION) system submitted for Task C of the SemEval2020 Task 4, which is to\ngenerate a reason explaining why a given false statement is non-sensical.\nHowever, we found in the early experiments that simple adaptations such as\nfine-tuning GPT2 often yield dull and non-informative generations (e.g. simple\nnegations). In order to generate more meaningful explanations, we propose\nUNION, a unified end-to-end framework, to utilize several existing commonsense\ndatasets so that it allows a model to learn more dynamics under the scope of\ncommonsense reasoning. In order to perform model selection efficiently,\naccurately and promptly, we also propose a couple of auxiliary automatic\nevaluation metrics so that we can extensively compare the models from different\nperspectives. Our submitted system not only results in a good performance in\nthe proposed metrics but also outperforms its competitors with the highest\nachieved score of 2.10 for human evaluation while remaining a BLEU score of\n15.7. Our code is made publicly available at GitHub.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 21:44:51 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Perumal", "Anandh", ""], ["Huang", "Chenyang", ""], ["Trabelsi", "Amine", ""], ["Za\u00efane", "Osmar R.", ""]]}, {"id": "2006.16470", "submitter": "Ayon Sen", "authors": "Ayon Sen, Christopher R. Cox, Matthew Cooper Borkenhagen, Mark S.\n  Seidenberg and Xiaojin Zhu", "title": "Learning to Read through Machine Teaching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to read words aloud is a major step towards becoming a reader. Many\nchildren struggle with the task because of the inconsistencies of English\nspelling-sound correspondences. Curricula vary enormously in how these patterns\nare taught. Children are nonetheless expected to master the system in limited\ntime (by grade 4). We used a cognitively interesting neural network\narchitecture to examine whether the sequence of learning trials could be\nstructured to facilitate learning. This is a hard combinatorial optimization\nproblem even for a modest number of learning trials (e.g., 10K). We show how\nthis sequence optimization problem can be posed as optimizing over a time\nvarying distribution i.e., defining probability distributions over words at\ndifferent steps in training. We then use stochastic gradient descent to find an\noptimal time-varying distribution and a corresponding optimal training\nsequence. We observed significant improvement on generalization accuracy\ncompared to baseline conditions (random sequences; sequences biased by word\nfrequency). These findings suggest an approach to improving learning outcomes\nin domains where performance depends on ability to generalize beyond limited\ntraining experience.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 02:04:52 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 17:09:35 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Sen", "Ayon", ""], ["Cox", "Christopher R.", ""], ["Borkenhagen", "Matthew Cooper", ""], ["Seidenberg", "Mark S.", ""], ["Zhu", "Xiaojin", ""]]}, {"id": "2006.16642", "submitter": "Erion \\c{C}ano", "authors": "Erion \\c{C}ano and Maurizio Morisio", "title": "A Data-driven Neural Network Architecture for Sentiment Analysis", "comments": "18 pages, 4 tables, 7 figures", "journal-ref": "Data Technologies and Applications, Vol. 53, No. 1, pp. 2-19, 2019", "doi": "10.1108/DTA-03-2018-0017", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fabulous results of convolution neural networks in image-related tasks,\nattracted attention of text mining, sentiment analysis and other text analysis\nresearchers. It is however difficult to find enough data for feeding such\nnetworks, optimize their parameters, and make the right design choices when\nconstructing network architectures. In this paper we present the creation steps\nof two big datasets of song emotions. We also explore usage of convolution and\nmax-pooling neural layers on song lyrics, product and movie review text\ndatasets. Three variants of a simple and flexible neural network architecture\nare also compared. Our intention was to spot any important patterns that can\nserve as guidelines for parameter optimization of similar models. We also\nwanted to identify architecture design choices which lead to high performing\nsentiment analysis models. To this end, we conducted a series of experiments\nwith neural architectures of various configurations. Our results indicate that\nparallel convolutions of filter lengths up to three are usually enough for\ncapturing relevant text features. Also, max-pooling region size should be\nadapted to the length of text documents for producing the best feature maps.\nTop results we got are obtained with feature maps of lengths 6 to 18. An\nimprovement on future neural network models for sentiment analysis, could be\ngenerating sentiment polarity prediction of documents using aggregation of\npredictions on smaller excerpt of the entire text.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 10:08:36 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["\u00c7ano", "Erion", ""], ["Morisio", "Maurizio", ""]]}, {"id": "2006.16668", "submitter": "Orhan Firat", "authors": "Dmitry Lepikhin, HyoukJoong Lee, Yuanzhong Xu, Dehao Chen, Orhan\n  Firat, Yanping Huang, Maxim Krikun, Noam Shazeer, Zhifeng Chen", "title": "GShard: Scaling Giant Models with Conditional Computation and Automatic\n  Sharding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network scaling has been critical for improving the model quality in\nmany real-world machine learning applications with vast amounts of training\ndata and compute. Although this trend of scaling is affirmed to be a sure-fire\napproach for better model quality, there are challenges on the path such as the\ncomputation cost, ease of programming, and efficient implementation on parallel\ndevices. GShard is a module composed of a set of lightweight annotation APIs\nand an extension to the XLA compiler. It provides an elegant way to express a\nwide range of parallel computation patterns with minimal changes to the\nexisting model code. GShard enabled us to scale up multilingual neural machine\ntranslation Transformer model with Sparsely-Gated Mixture-of-Experts beyond 600\nbillion parameters using automatic sharding. We demonstrate that such a giant\nmodel can efficiently be trained on 2048 TPU v3 accelerators in 4 days to\nachieve far superior quality for translation from 100 languages to English\ncompared to the prior art.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 10:42:02 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Lepikhin", "Dmitry", ""], ["Lee", "HyoukJoong", ""], ["Xu", "Yuanzhong", ""], ["Chen", "Dehao", ""], ["Firat", "Orhan", ""], ["Huang", "Yanping", ""], ["Krikun", "Maxim", ""], ["Shazeer", "Noam", ""], ["Chen", "Zhifeng", ""]]}, {"id": "2006.16722", "submitter": "Huanhuan Chen", "authors": "Xinyan Zhao, Xiao Feng, Haoming Zhong, Jun Yao, Huanhuan Chen", "title": "Correction of Faulty Background Knowledge based on Condition Aware and\n  Revise Transformer for Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of question answering has received increasing attention in recent\nyears. This work focuses on providing an answer that compatible with both user\nintent and conditioning information corresponding to the question, such as\ndelivery status and stock information in e-commerce. However, these conditions\nmay be wrong or incomplete in real-world applications. Although existing\nquestion answering systems have considered the external information, such as\ncategorical attributes and triples in knowledge base, they all assume that the\nexternal information is correct and complete. To alleviate the effect of\ndefective condition values, this paper proposes condition aware and revise\nTransformer (CAR-Transformer). CAR-Transformer (1) revises each condition value\nbased on the whole conversation and original conditions values, and (2) it\nencodes the revised conditions and utilizes the conditions embedding to select\nan answer. Experimental results on a real-world customer service dataset\ndemonstrate that the CAR-Transformer can still select an appropriate reply when\nconditions corresponding to the question exist wrong or missing values, and\nsubstantially outperforms baseline models on automatic and human evaluations.\nThe proposed CAR-Transformer can be extended to other NLP tasks which need to\nconsider conditioning information.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 12:24:35 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Zhao", "Xinyan", ""], ["Feng", "Xiao", ""], ["Zhong", "Haoming", ""], ["Yao", "Jun", ""], ["Chen", "Huanhuan", ""]]}, {"id": "2006.16743", "submitter": "Pengyu Nie", "authors": "Pengyu Nie, Karl Palmskog, Junyi Jessy Li, Milos Gligoric", "title": "Learning to Format Coq Code Using Language Models", "comments": "Accepted in the Coq Workshop 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Should the final right bracket in a record declaration be on a separate line?\nShould arguments to the rewrite tactic be separated by a single space? Coq code\ntends to be written in distinct manners by different people and teams. The\nexpressiveness, flexibility, and extensibility of Coq's languages and notations\nmeans that Coq projects have a wide variety of recognizable coding styles,\nsometimes explicitly documented as conventions on naming and formatting. In\nparticular, even inexperienced users can distinguish vernacular using the\nstandard library and plain Ltac from idiomatic vernacular using the\nMathematical Components (MathComp) library and SSReflect.\n  While coding conventions are important for comprehension and maintenance,\nthey are costly to document and enforce. Rule-based formatters, such as Coq's\nbeautifier, have limited flexibility and only capture small fractions of\ndesired conventions in large verification projects. We believe that application\nof language models - a class of Natural Language Processing (NLP) techniques\nfor capturing regularities in corpora - can provide a solution to this\nconundrum. More specifically, we believe that an approach based on\nautomatically learning conventions from existing Coq code, and then suggesting\nidiomatic code to users in the proper context, can be superior to manual\napproaches and static analysis tools - both in terms of effort and results.\n  As a first step, we here outline initial models to learn and suggest space\nformatting in Coq files, with a preliminary implementation for Coq 8.10, and\nevaluated on a corpus based on MathComp 1.9.0 which comprises 164k lines of Coq\ncode from four core projects.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 14:46:15 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Nie", "Pengyu", ""], ["Palmskog", "Karl", ""], ["Li", "Junyi Jessy", ""], ["Gligoric", "Milos", ""]]}, {"id": "2006.16779", "submitter": "Siqi Bao", "authors": "Siqi Bao, Huang He, Fan Wang, Hua Wu, Haifeng Wang, Wenquan Wu, Zhen\n  Guo, Zhibin Liu, Xinchao Xu", "title": "PLATO-2: Towards Building an Open-Domain Chatbot via Curriculum Learning", "comments": "Findings of ACL 2021. First four authors contributed equally to this\n  work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To build a high-quality open-domain chatbot, we introduce the effective\ntraining process of PLATO-2 via curriculum learning. There are two stages\ninvolved in the learning process. In the first stage, a coarse-grained\ngeneration model is trained to learn response generation under the simplified\nframework of one-to-one mapping. In the second stage, a fine-grained generative\nmodel augmented with latent variables and an evaluation model are further\ntrained to generate diverse responses and to select the best response,\nrespectively. PLATO-2 was trained on both Chinese and English data, whose\neffectiveness and superiority are verified through comprehensive evaluations,\nachieving new state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 13:36:10 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 11:39:49 GMT"}, {"version": "v3", "created": "Mon, 13 Jul 2020 11:24:03 GMT"}, {"version": "v4", "created": "Fri, 28 May 2021 11:20:24 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Bao", "Siqi", ""], ["He", "Huang", ""], ["Wang", "Fan", ""], ["Wu", "Hua", ""], ["Wang", "Haifeng", ""], ["Wu", "Wenquan", ""], ["Guo", "Zhen", ""], ["Liu", "Zhibin", ""], ["Xu", "Xinchao", ""]]}, {"id": "2006.16823", "submitter": "Or Sharir", "authors": "Yoel Zeldes, Dan Padnos, Or Sharir, and Barak Peleg", "title": "Technical Report: Auxiliary Tuning and its Application to Conditional\n  Text Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a simple and efficient method, called Auxiliary Tuning, for\nadapting a pre-trained Language Model to a novel task; we demonstrate this\napproach on the task of conditional text generation. Our approach supplements\nthe original pre-trained model with an auxiliary model that shifts the output\ndistribution according to the target task. The auxiliary model is trained by\nadding its logits to the pre-trained model logits and maximizing the likelihood\nof the target task output. Our method imposes no constraints on the auxiliary\narchitecture. In particular, the auxiliary model can ingest additional input\nrelevant to the target task, independently from the pre-trained model's input.\nFurthermore, mixing the models at the logits level provides a natural\nprobabilistic interpretation of the method. Our method achieved similar results\nto training from scratch for several different tasks, while using significantly\nfewer resources for training; we share a specific example of text generation\nconditioned on keywords.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 14:00:48 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Zeldes", "Yoel", ""], ["Padnos", "Dan", ""], ["Sharir", "Or", ""], ["Peleg", "Barak", ""]]}, {"id": "2006.16831", "submitter": "Dalcimar Casanova", "authors": "Eliane M. De Bortoli F\\'avero and Dalcimar Casanova and Andrey Ricardo\n  Pimentel", "title": "SE3M: A Model for Software Effort Estimation Using Pre-trained Embedding\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Estimating effort based on requirement texts presents many challenges,\nespecially in obtaining viable features to infer effort. Aiming to explore a\nmore effective technique for representing textual requirements to infer effort\nestimates by analogy, this paper proposes to evaluate the effectiveness of\npre-trained embeddings models. For this, two embeddings approach, context-less\nand contextualized models are used. Generic pre-trained models for both\napproaches went through a fine-tuning process. The generated models were used\nas input in the applied deep learning architecture, with linear output. The\nresults were very promising, realizing that pre-trained incorporation models\ncan be used to estimate software effort based only on requirements texts. We\nhighlight the results obtained to apply the pre-trained BERT model with\nfine-tuning in a single project repository, whose value is the Mean Absolute\nError (MAE) is 4.25 and the standard deviation of only 0.17, which represents a\nresult very positive when compared to similar works. The main advantages of the\nproposed estimation method are reliability, the possibility of generalization,\nspeed, and low computational cost provided by the fine-tuning process, and the\npossibility to infer new or existing requirements.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 14:15:38 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["F\u00e1vero", "Eliane M. De Bortoli", ""], ["Casanova", "Dalcimar", ""], ["Pimentel", "Andrey Ricardo", ""]]}, {"id": "2006.16926", "submitter": "Yash Raj Shrestha", "authors": "Leopold Franz, Yash Raj Shrestha, Bibek Paudel", "title": "A Deep Learning Pipeline for Patient Diagnosis Prediction Using\n  Electronic Health Records", "comments": null, "journal-ref": "BIOKDD 2020 at the ACM SIGKDD Conference on Knowledge Discovery\n  and Data Mining (KDD) 2020", "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Augmentation of disease diagnosis and decision-making in healthcare with\nmachine learning algorithms is gaining much impetus in recent years. In\nparticular, in the current epidemiological situation caused by COVID-19\npandemic, swift and accurate prediction of disease diagnosis with machine\nlearning algorithms could facilitate identification and care of vulnerable\nclusters of population, such as those having multi-morbidity conditions. In\norder to build a useful disease diagnosis prediction system, advancement in\nboth data representation and development of machine learning architectures are\nimperative. First, with respect to data collection and representation, we face\nsevere problems due to multitude of formats and lack of coherency prevalent in\nElectronic Health Records (EHRs). This causes hindrance in extraction of\nvaluable information contained in EHRs. Currently, no universal global data\nstandard has been established. As a useful solution, we develop and publish a\nPython package to transform public health dataset into an easy to access\nuniversal format. This data transformation to an international health data\nformat facilitates researchers to easily combine EHR datasets with clinical\ndatasets of diverse formats. Second, machine learning algorithms that predict\nmultiple disease diagnosis categories simultaneously remain underdeveloped. We\npropose two novel model architectures in this regard. First, DeepObserver,\nwhich uses structured numerical data to predict the diagnosis categories and\nsecond, ClinicalBERT_Multi, that incorporates rich information available in\nclinical notes via natural language processing methods and also provides\ninterpretable visualizations to medical practitioners. We show that both models\ncan predict multiple diagnoses simultaneously with high accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 14:58:58 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Franz", "Leopold", ""], ["Shrestha", "Yash Raj", ""], ["Paudel", "Bibek", ""]]}, {"id": "2006.16934", "submitter": "Jiji Tang", "authors": "Fei Yu, Jiji Tang, Weichong Yin, Yu Sun, Hao Tian, Hua Wu, Haifeng\n  Wang", "title": "ERNIE-ViL: Knowledge Enhanced Vision-Language Representations Through\n  Scene Graph", "comments": "Paper has been published in the AAAI2021 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a knowledge-enhanced approach, ERNIE-ViL, which incorporates\nstructured knowledge obtained from scene graphs to learn joint representations\nof vision-language. ERNIE-ViL tries to build the detailed semantic connections\n(objects, attributes of objects and relationships between objects) across\nvision and language, which are essential to vision-language cross-modal tasks.\nUtilizing scene graphs of visual scenes, ERNIE-ViL constructs Scene Graph\nPrediction tasks, i.e., Object Prediction, Attribute Prediction and\nRelationship Prediction tasks in the pre-training phase. Specifically, these\nprediction tasks are implemented by predicting nodes of different types in the\nscene graph parsed from the sentence. Thus, ERNIE-ViL can learn the joint\nrepresentations characterizing the alignments of the detailed semantics across\nvision and language. After pre-training on large scale image-text aligned\ndatasets, we validate the effectiveness of ERNIE-ViL on 5 cross-modal\ndownstream tasks. ERNIE-ViL achieves state-of-the-art performances on all these\ntasks and ranks the first place on the VCR leaderboard with an absolute\nimprovement of 3.7%.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 16:03:12 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2020 06:49:34 GMT"}, {"version": "v3", "created": "Fri, 19 Mar 2021 05:17:32 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Yu", "Fei", ""], ["Tang", "Jiji", ""], ["Yin", "Weichong", ""], ["Sun", "Yu", ""], ["Tian", "Hao", ""], ["Wu", "Hua", ""], ["Wang", "Haifeng", ""]]}, {"id": "2006.16967", "submitter": "Alireza Ghasemi", "authors": "Alireza Ghasemi and Amina Chebira", "title": "Lest We Forget: A Dataset of Coronavirus-Related News Headlines in Swiss\n  Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We release our COVID-19 news dataset, containing more than 10,000 links to\nnews articles related to the Coronavirus pandemic published in the Swiss media\nsince early January 2020. This collection can prove beneficial in mining and\nanalysis of the reaction of the Swiss media and the COVID-19 pandemic and\nextracting insightful information for further research. We hope this dataset\nhelps researchers and the public deliver results that will help analyse the\npandemic and potentially lead to a better understanding of the events.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 19:43:13 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Ghasemi", "Alireza", ""], ["Chebira", "Amina", ""]]}]