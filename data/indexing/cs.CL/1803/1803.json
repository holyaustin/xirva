[{"id": "1803.00047", "submitter": "Myle Ott", "authors": "Myle Ott and Michael Auli and David Grangier and Marc'Aurelio Ranzato", "title": "Analyzing Uncertainty in Neural Machine Translation", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine translation is a popular test bed for research in neural\nsequence-to-sequence models but despite much recent research, there is still a\nlack of understanding of these models. Practitioners report performance\ndegradation with large beams, the under-estimation of rare words and a lack of\ndiversity in the final translations. Our study relates some of these issues to\nthe inherent uncertainty of the task, due to the existence of multiple valid\ntranslations for a single source sentence, and to the extrinsic uncertainty\ncaused by noisy training data. We propose tools and metrics to assess how\nuncertainty in the data is captured by the model distribution and how it\naffects search strategies that generate translations. Our results show that\nsearch works remarkably well but that models tend to spread too much\nprobability mass over the hypothesis space. Next, we propose tools to assess\nmodel calibration and show how to easily fix some shortcomings of current\nmodels. As part of this study, we release multiple human reference translations\nfor two popular benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 19:33:24 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 15:10:32 GMT"}, {"version": "v3", "created": "Tue, 12 Jun 2018 11:12:43 GMT"}, {"version": "v4", "created": "Mon, 13 Aug 2018 17:13:23 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Ott", "Myle", ""], ["Auli", "Michael", ""], ["Grangier", "David", ""], ["Ranzato", "Marc'Aurelio", ""]]}, {"id": "1803.00057", "submitter": "Boyang Li", "authors": "Pelin Dogan, Boyang Li, Leonid Sigal, Markus Gross", "title": "A Neural Multi-sequence Alignment TeCHnique (NeuMATCH)", "comments": "Accepted at CVPR 2018 (Spotlight). arXiv file includes the paper and\n  the supplemental material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The alignment of heterogeneous sequential data (video to text) is an\nimportant and challenging problem. Standard techniques for this task, including\nDynamic Time Warping (DTW) and Conditional Random Fields (CRFs), suffer from\ninherent drawbacks. Mainly, the Markov assumption implies that, given the\nimmediate past, future alignment decisions are independent of further history.\nThe separation between similarity computation and alignment decision also\nprevents end-to-end training. In this paper, we propose an end-to-end neural\narchitecture where alignment actions are implemented as moving data between\nstacks of Long Short-term Memory (LSTM) blocks. This flexible architecture\nsupports a large variety of alignment tasks, including one-to-one, one-to-many,\nskipping unmatched elements, and (with extensions) non-monotonic alignment.\nExtensive experiments on semi-synthetic and real datasets show that our\nalgorithm outperforms state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 06:51:01 GMT"}, {"version": "v2", "created": "Mon, 9 Apr 2018 20:51:32 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Dogan", "Pelin", ""], ["Li", "Boyang", ""], ["Sigal", "Leonid", ""], ["Gross", "Markus", ""]]}, {"id": "1803.00124", "submitter": "Abdulaziz Alayba", "authors": "Abdulaziz M. Alayba, Vasile Palade, Matthew England and Rahat Iqbal", "title": "Improving Sentiment Analysis in Arabic Using Word Representation", "comments": "Authors accepted version of submission for ASAR 2018", "journal-ref": "Proc. 2nd International Workshop on Arabic and Derived Script\n  Analysis and Recognition (ASAR '18), pp. 13-18. IEEE, 2018", "doi": "10.1109/ASAR.2018.8480191", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexities of Arabic language in morphology, orthography and dialects\nmakes sentiment analysis for Arabic more challenging. Also, text feature\nextraction from short messages like tweets, in order to gauge the sentiment,\nmakes this task even more difficult. In recent years, deep neural networks were\noften employed and showed very good results in sentiment classification and\nnatural language processing applications. Word embedding, or word distributing\napproach, is a current and powerful tool to capture together the closest words\nfrom a contextual text. In this paper, we describe how we construct Word2Vec\nmodels from a large Arabic corpus obtained from ten newspapers in different\nArab countries. By applying different machine learning algorithms and\nconvolutional neural networks with different text feature selections, we report\nimproved accuracy of sentiment classification (91%-95%) on our publicly\navailable Arabic language health sentiment dataset [1]\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 22:46:19 GMT"}, {"version": "v2", "created": "Fri, 30 Mar 2018 19:17:50 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Alayba", "Abdulaziz M.", ""], ["Palade", "Vasile", ""], ["England", "Matthew", ""], ["Iqbal", "Rahat", ""]]}, {"id": "1803.00179", "submitter": "Bang Liu", "authors": "Bang Liu, Ting Zhang, Fred X. Han, Di Niu, Kunfeng Lai, Yu Xu", "title": "Matching Natural Language Sentences with Hierarchical Sentence\n  Factorization", "comments": "Accepted by WWW 2018, 10 pages", "journal-ref": null, "doi": "10.1145/3178876.3186022", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic matching of natural language sentences or identifying the\nrelationship between two sentences is a core research problem underlying many\nnatural language tasks. Depending on whether training data is available, prior\nresearch has proposed both unsupervised distance-based schemes and supervised\ndeep learning schemes for sentence matching. However, previous approaches\neither omit or fail to fully utilize the ordered, hierarchical, and flexible\nstructures of language objects, as well as the interactions between them. In\nthis paper, we propose Hierarchical Sentence Factorization---a technique to\nfactorize a sentence into a hierarchical representation, with the components at\neach different scale reordered into a \"predicate-argument\" form. The proposed\nsentence factorization technique leads to the invention of: 1) a new\nunsupervised distance metric which calculates the semantic distance between a\npair of text snippets by solving a penalized optimal transport problem while\npreserving the logical relationship of words in the reordered sentences, and 2)\nnew multi-scale deep learning models for supervised semantic training, based on\nfactorized sentence hierarchies. We apply our techniques to text-pair\nsimilarity estimation and text-pair relationship classification tasks, based on\nmultiple datasets such as STSbenchmark, the Microsoft Research paraphrase\nidentification (MSRP) dataset, the SICK dataset, etc. Extensive experiments\nshow that the proposed hierarchical sentence factorization can be used to\nsignificantly improve the performance of existing unsupervised distance-based\nmetrics as well as multiple supervised deep learning models based on the\nconvolutional neural network (CNN) and long short-term memory (LSTM).\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 02:48:47 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Liu", "Bang", ""], ["Zhang", "Ting", ""], ["Han", "Fred X.", ""], ["Niu", "Di", ""], ["Lai", "Kunfeng", ""], ["Xu", "Yu", ""]]}, {"id": "1803.00188", "submitter": "Graham Neubig", "authors": "Graham Neubig, Matthias Sperber, Xinyi Wang, Matthieu Felix, Austin\n  Matthews, Sarguna Padmanabhan, Ye Qi, Devendra Singh Sachan, Philip Arthur,\n  Pierre Godard, John Hewitt, Rachid Riad, Liming Wang", "title": "XNMT: The eXtensible Neural Machine Translation Toolkit", "comments": "To be presented at AMTA 2018 Open Source Software Showcase", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes XNMT, the eXtensible Neural Machine Translation toolkit.\nXNMT distin- guishes itself from other open-source NMT toolkits by its focus on\nmodular code design, with the purpose of enabling fast iteration in research\nand replicable, reliable results. In this paper we describe the design of XNMT\nand its experiment configuration system, and demonstrate its utility on the\ntasks of machine translation, speech recognition, and multi-tasked machine\ntranslation/parsing. XNMT is available open-source at\nhttps://github.com/neulab/xnmt\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 03:14:54 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Neubig", "Graham", ""], ["Sperber", "Matthias", ""], ["Wang", "Xinyi", ""], ["Felix", "Matthieu", ""], ["Matthews", "Austin", ""], ["Padmanabhan", "Sarguna", ""], ["Qi", "Ye", ""], ["Sachan", "Devendra Singh", ""], ["Arthur", "Philip", ""], ["Godard", "Pierre", ""], ["Hewitt", "John", ""], ["Riad", "Rachid", ""], ["Wang", "Liming", ""]]}, {"id": "1803.00189", "submitter": "Bang Liu", "authors": "Bang Liu, Di Niu, Kunfeng Lai, Linglong Kong, Yu Xu", "title": "Growing Story Forest Online from Massive Breaking News", "comments": "Accepted by CIKM 2017, 9 pages", "journal-ref": null, "doi": "10.1145/3132847.3132852", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe our experience of implementing a news content organization system\nat Tencent that discovers events from vast streams of breaking news and evolves\nnews story structures in an online fashion. Our real-world system has distinct\nrequirements in contrast to previous studies on topic detection and tracking\n(TDT) and event timeline or graph generation, in that we 1) need to accurately\nand quickly extract distinguishable events from massive streams of long text\ndocuments that cover diverse topics and contain highly redundant information,\nand 2) must develop the structures of event stories in an online manner,\nwithout repeatedly restructuring previously formed stories, in order to\nguarantee a consistent user viewing experience. In solving these challenges, we\npropose Story Forest, a set of online schemes that automatically clusters\nstreaming documents into events, while connecting related events in growing\ntrees to tell evolving stories. We conducted extensive evaluation based on 60\nGB of real-world Chinese news data, although our ideas are not\nlanguage-dependent and can easily be extended to other languages, through\ndetailed pilot user experience studies. The results demonstrate the superior\ncapability of Story Forest to accurately identify events and organize news text\ninto a logical structure that is appealing to human readers, compared to\nmultiple existing algorithm frameworks.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 03:15:10 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Liu", "Bang", ""], ["Niu", "Di", ""], ["Lai", "Kunfeng", ""], ["Kong", "Linglong", ""], ["Xu", "Yu", ""]]}, {"id": "1803.00191", "submitter": "Liang Wang", "authors": "Liang Wang, Meng Sun, Wei Zhao, Kewei Shen, Jingming Liu", "title": "Yuanfudao at SemEval-2018 Task 11: Three-way Attention and Relational\n  Knowledge for Commonsense Machine Comprehension", "comments": "5 pages, 1 figure, Accepted to International Workshop on Semantic\n  Evaluation 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes our system for SemEval-2018 Task 11: Machine\nComprehension using Commonsense Knowledge. We use Three-way Attentive Networks\n(TriAN) to model interactions between the passage, question and answers. To\nincorporate commonsense knowledge, we augment the input with relation embedding\nfrom the graph of general knowledge ConceptNet (Speer et al., 2017). As a\nresult, our system achieves state-of-the-art performance with 83.95% accuracy\non the official test data. Code is publicly available at\nhttps://github.com/intfloat/commonsense-rc\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 03:23:55 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 04:38:11 GMT"}, {"version": "v3", "created": "Sat, 7 Apr 2018 06:15:49 GMT"}, {"version": "v4", "created": "Wed, 11 Apr 2018 10:47:52 GMT"}, {"version": "v5", "created": "Tue, 15 May 2018 06:21:02 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Wang", "Liang", ""], ["Sun", "Meng", ""], ["Zhao", "Wei", ""], ["Shen", "Kewei", ""], ["Liu", "Jingming", ""]]}, {"id": "1803.00202", "submitter": "Miguel Campo PhD", "authors": "Miguel Campo, JJ Espinoza, Julie Rieger, Abhinav Taliyan", "title": "Collaborative Metric Learning Recommendation System: Application to\n  Theatrical Movie Releases", "comments": "6 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Product recommendation systems are important for major movie studios during\nthe movie greenlight process and as part of machine learning personalization\npipelines. Collaborative Filtering (CF) models have proved to be effective at\npowering recommender systems for online streaming services with explicit\ncustomer feedback data. CF models do not perform well in scenarios in which\nfeedback data is not available, in cold start situations like new product\nlaunches, and situations with markedly different customer tiers (e.g., high\nfrequency customers vs. casual customers). Generative natural language models\nthat create useful theme-based representations of an underlying corpus of\ndocuments can be used to represent new product descriptions, like new movie\nplots. When combined with CF, they have shown to increase the performance in\ncold start situations. Outside of those cases though in which explicit customer\nfeedback is available, recommender engines must rely on binary purchase data,\nwhich materially degrades performance. Fortunately, purchase data can be\ncombined with product descriptions to generate meaningful representations of\nproducts and customer trajectories in a convenient product space in which\nproximity represents similarity. Learning to measure the distance between\npoints in this space can be accomplished with a deep neural network that trains\non customer histories and on dense vectorizations of product descriptions. We\ndeveloped a system based on Collaborative (Deep) Metric Learning (CML) to\npredict the purchase probabilities of new theatrical releases. We trained and\nevaluated the model using a large dataset of customer histories, and tested the\nmodel for a set of movies that were released outside of the training window.\nInitial experiments show gains relative to models that do not train on\ncollaborative preferences.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 04:04:35 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Campo", "Miguel", ""], ["Espinoza", "JJ", ""], ["Rieger", "Julie", ""], ["Taliyan", "Abhinav", ""]]}, {"id": "1803.00344", "submitter": "Gangeshwar Krishnamurthy", "authors": "Gangeshwar Krishnamurthy, Navonil Majumder, Soujanya Poria, Erik\n  Cambria", "title": "A Deep Learning Approach for Multimodal Deception Detection", "comments": "Accepted at the 19th International Conference on Computational\n  Linguistics and Intelligent Text Processing (CICLing), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic deception detection is an important task that has gained momentum\nin computational linguistics due to its potential applications. In this paper,\nwe propose a simple yet tough to beat multi-modal neural model for deception\ndetection. By combining features from different modalities such as video,\naudio, and text along with Micro-Expression features, we show that detecting\ndeception in real life videos can be more accurate. Experimental results on a\ndataset of real-life deception videos show that our model outperforms existing\ntechniques for deception detection with an accuracy of 96.14% and ROC-AUC of\n0.9799.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 12:38:13 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Krishnamurthy", "Gangeshwar", ""], ["Majumder", "Navonil", ""], ["Poria", "Soujanya", ""], ["Cambria", "Erik", ""]]}, {"id": "1803.00353", "submitter": "Zhirui Zhang", "authors": "Zhirui Zhang, Shujie Liu, Mu Li, Ming Zhou, Enhong Chen", "title": "Joint Training for Neural Machine Translation Models with Monolingual\n  Data", "comments": "Accepted by AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monolingual data have been demonstrated to be helpful in improving\ntranslation quality of both statistical machine translation (SMT) systems and\nneural machine translation (NMT) systems, especially in resource-poor or domain\nadaptation tasks where parallel data are not rich enough. In this paper, we\npropose a novel approach to better leveraging monolingual data for neural\nmachine translation by jointly learning source-to-target and target-to-source\nNMT models for a language pair with a joint EM optimization method. The\ntraining process starts with two initial NMT models pre-trained on parallel\ndata for each direction, and these two models are iteratively updated by\nincrementally decreasing translation losses on training data. In each iteration\nstep, both NMT models are first used to translate monolingual data from one\nlanguage to the other, forming pseudo-training data of the other NMT model.\nThen two new NMT models are learnt from parallel data together with the pseudo\ntraining data. Both NMT models are expected to be improved and better\npseudo-training data can be generated in next step. Experiment results on\nChinese-English and English-German translation tasks show that our approach can\nsimultaneously improve translation quality of source-to-target and\ntarget-to-source models, significantly outperforming strong baseline systems\nwhich are enhanced with monolingual data for model training including\nback-translation.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 13:14:35 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Zhang", "Zhirui", ""], ["Liu", "Shujie", ""], ["Li", "Mu", ""], ["Zhou", "Ming", ""], ["Chen", "Enhong", ""]]}, {"id": "1803.00357", "submitter": "Michael Neumann", "authors": "Michael Neumann, Ngoc Thang Vu", "title": "Cross-lingual and Multilingual Speech Emotion Recognition on English and\n  French", "comments": "ICASSP 2018, Calgary", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on multilingual speech emotion recognition faces the problem that\nmost available speech corpora differ from each other in important ways, such as\nannotation methods or interaction scenarios. These inconsistencies complicate\nbuilding a multilingual system. We present results for cross-lingual and\nmultilingual emotion recognition on English and French speech data with similar\ncharacteristics in terms of interaction (human-human conversations). Further,\nwe explore the possibility of fine-tuning a pre-trained cross-lingual model\nwith only a small number of samples from the target language, which is of great\ninterest for low-resource languages. To gain more insights in what is learned\nby the deployed convolutional neural network, we perform an analysis on the\nattention mechanism inside the network.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 13:40:04 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Neumann", "Michael", ""], ["Vu", "Ngoc Thang", ""]]}, {"id": "1803.00712", "submitter": "Phuong Le-Hong", "authors": "Phuong Le-Hong, Duc-Thien Bui", "title": "A Factoid Question Answering System for Vietnamese", "comments": "In the proceedings of the HQA'18 workshop, The Web Conference\n  Companion, Lyon, France", "journal-ref": null, "doi": "10.1145/3184558.3191535", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe the development of an end-to-end factoid question\nanswering system for the Vietnamese language. This system combines both\nstatistical models and ontology-based methods in a chain of processing modules\nto provide high-quality mappings from natural language text to entities. We\npresent the challenges in the development of such an intelligent user interface\nfor an isolating language like Vietnamese and show that techniques developed\nfor inflectional languages cannot be applied \"as is\". Our question answering\nsystem can answer a wide range of general knowledge questions with promising\naccuracy on a test set.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 04:10:24 GMT"}, {"version": "v2", "created": "Tue, 13 Mar 2018 03:32:39 GMT"}, {"version": "v3", "created": "Wed, 28 Mar 2018 09:28:56 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Le-Hong", "Phuong", ""], ["Bui", "Duc-Thien", ""]]}, {"id": "1803.00721", "submitter": "Denys Katerenchuk", "authors": "Denys Katerenchuk", "title": "Age Group Classification with Speech and Metadata Multimodality Fusion", "comments": null, "journal-ref": "Proceedings of the 15th Conference of the European Chapter of the\n  Association for Computational Linguistics: Volume 2, Short Papers, 2017", "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Children comprise a significant proportion of TV viewers and it is worthwhile\nto customize the experience for them. However, identifying who is a child in\nthe audience can be a challenging task. Identifying gender and age from audio\ncommands is a well-studied problem but is still very challenging to get good\naccuracy when the utterances are typically only a couple of seconds long. We\npresent initial studies of a novel method which combines utterances with user\nmetadata. In particular, we develop an ensemble of different machine learning\ntechniques on different subsets of data to improve child detection. Our initial\nresults show a 9.2\\% absolute improvement over the baseline, leading to a\nstate-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 05:07:33 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Katerenchuk", "Denys", ""]]}, {"id": "1803.00729", "submitter": "Yu Gong", "authors": "Yu Gong, Kaiqi Zhao, Kenny Q. Zhu", "title": "Representing Verbs as Argument Concepts", "comments": "7 pages, 2 figures, AAAI 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Verbs play an important role in the understanding of natural language text.\nThis paper studies the problem of abstracting the subject and object arguments\nof a verb into a set of noun concepts, known as the \"argument concepts\". This\nset of concepts, whose size is parameterized, represents the fine-grained\nsemantics of a verb. For example, the object of \"enjoy\" can be abstracted into\ntime, hobby and event, etc. We present a novel framework to automatically infer\nhuman readable and machine computable action concepts with high accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 06:18:40 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Gong", "Yu", ""], ["Zhao", "Kaiqi", ""], ["Zhu", "Kenny Q.", ""]]}, {"id": "1803.00831", "submitter": "Daniel Ortega", "authors": "Daniel Ortega and Ngoc Thang Vu", "title": "Lexico-acoustic Neural-based Models for Dialog Act Classification", "comments": "5 pages, 1 figure, 2018 International Conference on Acoustics,\n  Speech, and Signal Processing (ICASSP 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works have proposed neural models for dialog act classification in\nspoken dialogs. However, they have not explored the role and the usefulness of\nacoustic information. We propose a neural model that processes both lexical and\nacoustic features for classification. Our results on two benchmark datasets\nreveal that acoustic features are helpful in improving the overall accuracy.\nFinally, a deeper analysis shows that acoustic features are valuable in three\ncases: when a dialog act has sufficient data, when lexical information is\nlimited and when strong lexical cues are not present.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 12:59:32 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Ortega", "Daniel", ""], ["Vu", "Ngoc Thang", ""]]}, {"id": "1803.00832", "submitter": "Dennis Diefenbach", "authors": "Dennis Diefenbach and Andreas Both and Kamal Singh and Pierre Maret", "title": "Towards a Question Answering System over the Semantic Web", "comments": "There is a Patent Pending for the presented approach. It was\n  submitted the 18 January 2018 at the EPO and has the number EP18305035.0", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thanks to the development of the Semantic Web, a lot of new structured data\nhas become available on the Web in the form of knowledge bases (KBs). Making\nthis valuable data accessible and usable for end-users is one of the main goals\nof Question Answering (QA) over KBs. Most current QA systems query one KB, in\none language (namely English). The existing approaches are not designed to be\neasily adaptable to new KBs and languages. We first introduce a new approach\nfor translating natural language questions to SPARQL queries. It is able to\nquery several KBs simultaneously, in different languages, and can easily be\nported to other KBs and languages. In our evaluation, the impact of our\napproach is proven using 5 different well-known and large KBs: Wikidata,\nDBpedia, MusicBrainz, DBLP and Freebase as well as 5 different languages namely\nEnglish, German, French, Italian and Spanish. Second, we show how we integrated\nour approach, to make it easily accessible by the research community and by\nend-users. To summarize, we provided a conceptional solution for multilingual,\nKB-agnostic Question Answering over the Semantic Web. The provided first\napproximation validates this concept.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 12:59:50 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Diefenbach", "Dennis", ""], ["Both", "Andreas", ""], ["Singh", "Kamal", ""], ["Maret", "Pierre", ""]]}, {"id": "1803.00860", "submitter": "Xin Wang", "authors": "Jaime Lorenzo-Trueba, Fuming Fang, Xin Wang, Isao Echizen, Junichi\n  Yamagishi, Tomi Kinnunen", "title": "Can we steal your vocal identity from the Internet?: Initial\n  investigation of cloning Obama's voice using GAN, WaveNet and low-quality\n  found data", "comments": "conference manuscript submitted to Speaker Odyssey 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Thanks to the growing availability of spoofing databases and rapid advances\nin using them, systems for detecting voice spoofing attacks are becoming more\nand more capable, and error rates close to zero are being reached for the\nASVspoof2015 database. However, speech synthesis and voice conversion paradigms\nthat are not considered in the ASVspoof2015 database are appearing. Such\nexamples include direct waveform modelling and generative adversarial networks.\nWe also need to investigate the feasibility of training spoofing systems using\nonly low-quality found data. For that purpose, we developed a generative\nadversarial network-based speech enhancement system that improves the quality\nof speech data found in publicly available sources. Using the enhanced data, we\ntrained state-of-the-art text-to-speech and voice conversion models and\nevaluated them in terms of perceptual speech quality and speaker similarity.\nThe results show that the enhancement models significantly improved the SNR of\nlow-quality degraded data found in publicly available sources and that they\nsignificantly improved the perceptual cleanliness of the source speech without\nsignificantly degrading the naturalness of the voice. However, the results also\nshow limitations when generating speech with the low-quality found data.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 14:21:16 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Lorenzo-Trueba", "Jaime", ""], ["Fang", "Fuming", ""], ["Wang", "Xin", ""], ["Echizen", "Isao", ""], ["Yamagishi", "Junichi", ""], ["Kinnunen", "Tomi", ""]]}, {"id": "1803.00886", "submitter": "Lantian Li Mr.", "authors": "Lantian Li, Dong Wang, Yixiang Chen, Ying Shi, Zhiyuan Tang and Thomas\n  Fang Zheng", "title": "Deep factorization for speech signal", "comments": "Accepted by ICASSP 2018. arXiv admin note: substantial text overlap\n  with arXiv:1706.01777", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various informative factors mixed in speech signals, leading to great\ndifficulty when decoding any of the factors. An intuitive idea is to factorize\neach speech frame into individual informative factors, though it turns out to\nbe highly difficult. Recently, we found that speaker traits, which were assumed\nto be long-term distributional properties, are actually short-time patterns,\nand can be learned by a carefully designed deep neural network (DNN). This\ndiscovery motivated a cascade deep factorization (CDF) framework that will be\npresented in this paper. The proposed framework infers speech factors in a\nsequential way, where factors previously inferred are used as conditional\nvariables when inferring other factors. We will show that this approach can\neffectively factorize speech signals, and using these factors, the original\nspeech spectrum can be recovered with a high accuracy. This factorization and\nreconstruction approach provides potential values for many speech processing\ntasks, e.g., speaker recognition and emotion recognition, as will be\ndemonstrated in the paper.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 12:45:16 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Li", "Lantian", ""], ["Wang", "Dong", ""], ["Chen", "Yixiang", ""], ["Shi", "Ying", ""], ["Tang", "Zhiyuan", ""], ["Zheng", "Thomas Fang", ""]]}, {"id": "1803.00902", "submitter": "Duygu Altinok", "authors": "Duygu Altinok", "title": "DEMorphy, German Language Morphological Analyzer", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  DEMorphy is a morphological analyzer for German. It is built onto large,\ncompactified lexicons from German Morphological Dictionary. A guesser based on\nGerman declension suffixed is also provided. For German, we provided a\nstate-of-art morphological analyzer. DEMorphy is implemented in Python with\nease of usability and accompanying documentation. The package is suitable for\nboth academic and commercial purposes wit a permissive licence.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 15:41:33 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Altinok", "Duygu", ""]]}, {"id": "1803.00985", "submitter": "Guilherme Wachs-Lopes", "authors": "Henrique X. Goulart, Mauro D. L. Tosi, Daniel Soares Gon\\c{c}alves,\n  Rodrigo F. Maia, Guilherme A. Wachs-Lopes", "title": "Hybrid Model For Word Prediction Using Naive Bayes and Latent\n  Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Historically, the Natural Language Processing area has been given too much\nattention by many researchers. One of the main motivation beyond this interest\nis related to the word prediction problem, which states that given a set words\nin a sentence, one can recommend the next word. In literature, this problem is\nsolved by methods based on syntactic or semantic analysis. Solely, each of\nthese analysis cannot achieve practical results for end-user applications. For\ninstance, the Latent Semantic Analysis can handle semantic features of text,\nbut cannot suggest words considering syntactical rules. On the other hand,\nthere are models that treat both methods together and achieve state-of-the-art\nresults, e.g. Deep Learning. These models can demand high computational effort,\nwhich can make the model infeasible for certain types of applications. With the\nadvance of the technology and mathematical models, it is possible to develop\nfaster systems with more accuracy. This work proposes a hybrid word suggestion\nmodel, based on Naive Bayes and Latent Semantic Analysis, considering\nneighbouring words around unfilled gaps. Results show that this model could\nachieve 44.2% of accuracy in the MSR Sentence Completion Challenge.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 18:34:08 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Goulart", "Henrique X.", ""], ["Tosi", "Mauro D. L.", ""], ["Gon\u00e7alves", "Daniel Soares", ""], ["Maia", "Rodrigo F.", ""], ["Wachs-Lopes", "Guilherme A.", ""]]}, {"id": "1803.01090", "submitter": "Zhehuai Chen", "authors": "Zhehuai Chen, Qi Liu, Hao Li, Kai Yu", "title": "On Modular Training of Neural Acoustics-to-Word Model for LVCSR", "comments": "accepted by ICASSP2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end (E2E) automatic speech recognition (ASR) systems directly map\nacoustics to words using a unified model. Previous works mostly focus on E2E\ntraining a single model which integrates acoustic and language model into a\nwhole. Although E2E training benefits from sequence modeling and simplified\ndecoding pipelines, large amount of transcribed acoustic data is usually\nrequired, and traditional acoustic and language modelling techniques cannot be\nutilized. In this paper, a novel modular training framework of E2E ASR is\nproposed to separately train neural acoustic and language models during\ntraining stage, while still performing end-to-end inference in decoding stage.\nHere, an acoustics-to-phoneme model (A2P) and a phoneme-to-word model (P2W) are\ntrained using acoustic data and text data respectively. A phone synchronous\ndecoding (PSD) module is inserted between A2P and P2W to reduce sequence\nlengths without precision loss. Finally, modules are integrated into an\nacousticsto-word model (A2W) and jointly optimized using acoustic data to\nretain the advantage of sequence modeling. Experiments on a 300- hour\nSwitchboard task show significant improvement over the direct A2W model. The\nefficiency in both training and decoding also benefits from the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Sat, 3 Mar 2018 02:08:46 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Chen", "Zhehuai", ""], ["Liu", "Qi", ""], ["Li", "Hao", ""], ["Yu", "Kai", ""]]}, {"id": "1803.01165", "submitter": "Yizhong Wang", "authors": "Yizhong Wang, Sujian Li, Jingfeng Yang, Xu Sun, Houfeng Wang", "title": "Tag-Enhanced Tree-Structured Neural Networks for Implicit Discourse\n  Relation Classification", "comments": "Accepted by IJCNLP 2017, 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying implicit discourse relations between text spans is a challenging\ntask because it requires understanding the meaning of the text. To tackle this\ntask, recent studies have tried several deep learning methods but few of them\nexploited the syntactic information. In this work, we explore the idea of\nincorporating syntactic parse tree into neural networks. Specifically, we\nemploy the Tree-LSTM model and Tree-GRU model, which are based on the tree\nstructure, to encode the arguments in a relation. Moreover, we further leverage\nthe constituent tags to control the semantic composition process in these\ntree-structured neural networks. Experimental results show that our method\nachieves state-of-the-art performance on PDTB corpus.\n", "versions": [{"version": "v1", "created": "Sat, 3 Mar 2018 13:57:37 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Wang", "Yizhong", ""], ["Li", "Sujian", ""], ["Yang", "Jingfeng", ""], ["Sun", "Xu", ""], ["Wang", "Houfeng", ""]]}, {"id": "1803.01255", "submitter": "Haoyue Shi", "authors": "Haoyue Shi, Yuqi Sun, Junfeng Hu", "title": "Understanding and Improving Multi-Sense Word Embeddings via Extended\n  Robust Principal Component Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised learned representations of polysemous words generate a large of\npseudo multi senses since unsupervised methods are overly sensitive to\ncontextual variations. In this paper, we address the pseudo multi-sense\ndetection for word embeddings by dimensionality reduction of sense pairs. We\npropose a novel principal analysis method, termed Ex-RPCA, designed to detect\nboth pseudo multi senses and real multi senses. With Ex-RPCA, we empirically\nshow that pseudo multi senses are generated systematically in unsupervised\nmethod. Moreover, the multi-sense word embeddings can by improved by a simple\nlinear transformation based on Ex-RPCA. Our improved word embedding outperform\nthe original one by 5.6 points on Stanford contextual word similarity (SCWS)\ndataset. We hope our simple yet effective approach will help the linguistic\nanalysis of multi-sense word embeddings in the future.\n", "versions": [{"version": "v1", "created": "Sat, 3 Mar 2018 22:39:02 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Shi", "Haoyue", ""], ["Sun", "Yuqi", ""], ["Hu", "Junfeng", ""]]}, {"id": "1803.01271", "submitter": "Shaojie Bai", "authors": "Shaojie Bai, J. Zico Kolter, Vladlen Koltun", "title": "An Empirical Evaluation of Generic Convolutional and Recurrent Networks\n  for Sequence Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For most deep learning practitioners, sequence modeling is synonymous with\nrecurrent networks. Yet recent results indicate that convolutional\narchitectures can outperform recurrent networks on tasks such as audio\nsynthesis and machine translation. Given a new sequence modeling task or\ndataset, which architecture should one use? We conduct a systematic evaluation\nof generic convolutional and recurrent architectures for sequence modeling. The\nmodels are evaluated across a broad range of standard tasks that are commonly\nused to benchmark recurrent networks. Our results indicate that a simple\nconvolutional architecture outperforms canonical recurrent networks such as\nLSTMs across a diverse range of tasks and datasets, while demonstrating longer\neffective memory. We conclude that the common association between sequence\nmodeling and recurrent networks should be reconsidered, and convolutional\nnetworks should be regarded as a natural starting point for sequence modeling\ntasks. To assist related work, we have made code available at\nhttp://github.com/locuslab/TCN .\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 00:20:29 GMT"}, {"version": "v2", "created": "Thu, 19 Apr 2018 14:32:38 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Bai", "Shaojie", ""], ["Kolter", "J. Zico", ""], ["Koltun", "Vladlen", ""]]}, {"id": "1803.01335", "submitter": "Long-Huei Chen", "authors": "Long-Huei Chen and Kshitiz Tripathi", "title": "CAESAR: Context Awareness Enabled Summary-Attentive Reader", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comprehending meaning from natural language is a primary objective of Natural\nLanguage Processing (NLP), and text comprehension is the cornerstone for\nachieving this objective upon which all other problems like chat bots, language\ntranslation and others can be achieved. We report a Summary-Attentive Reader we\ndesigned to better emulate the human reading process, along with a\ndictiontary-based solution regarding out-of-vocabulary (OOV) words in the data,\nto generate answer based on machine comprehension of reading passages and\nquestion from the SQuAD benchmark. Our implementation of these features with\ntwo popular models (Match LSTM and Dynamic Coattention) was able to reach close\nto matching the results obtained from humans.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 11:07:55 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Chen", "Long-Huei", ""], ["Tripathi", "Kshitiz", ""]]}, {"id": "1803.01400", "submitter": "Andreas R\\\"uckl\\'e", "authors": "Andreas R\\\"uckl\\'e, Steffen Eger, Maxime Peyrard, Iryna Gurevych", "title": "Concatenated Power Mean Word Embeddings as Universal Cross-Lingual\n  Sentence Representations", "comments": "Experiments/plots added: Normalization + Figure 1 (dimensionality vs.\n  performance)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Average word embeddings are a common baseline for more sophisticated sentence\nembedding techniques. However, they typically fall short of the performances of\nmore complex models such as InferSent. Here, we generalize the concept of\naverage word embeddings to power mean word embeddings. We show that the\nconcatenation of different types of power mean word embeddings considerably\ncloses the gap to state-of-the-art methods monolingually and substantially\noutperforms these more complex techniques cross-lingually. In addition, our\nproposed method outperforms different recently proposed baselines such as SIF\nand Sent2Vec by a solid margin, thus constituting a much harder-to-beat\nmonolingual baseline. Our data and code are publicly available.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 18:42:05 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2018 14:08:34 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["R\u00fcckl\u00e9", "Andreas", ""], ["Eger", "Steffen", ""], ["Peyrard", "Maxime", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1803.01465", "submitter": "Shuming Ma", "authors": "Shuming Ma, Xu Sun, Wei Li, Sujian Li, Wenjie Li, Xuancheng Ren", "title": "Query and Output: Generating Words by Querying Distributed Word\n  Representations for Paraphrase Generation", "comments": "arXiv admin note: text overlap with arXiv:1710.02318", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most recent approaches use the sequence-to-sequence model for paraphrase\ngeneration. The existing sequence-to-sequence model tends to memorize the words\nand the patterns in the training dataset instead of learning the meaning of the\nwords. Therefore, the generated sentences are often grammatically correct but\nsemantically improper. In this work, we introduce a novel model based on the\nencoder-decoder framework, called Word Embedding Attention Network (WEAN). Our\nproposed model generates the words by querying distributed word representations\n(i.e. neural word embeddings), hoping to capturing the meaning of the according\nwords. Following previous work, we evaluate our model on two\nparaphrase-oriented tasks, namely text simplification and short text\nabstractive summarization. Experimental results show that our model outperforms\nthe sequence-to-sequence baseline by the BLEU score of 6.3 and 5.5 on two\nEnglish text simplification datasets, and the ROUGE-2 F1 score of 5.7 on a\nChinese summarization dataset. Moreover, our model achieves state-of-the-art\nperformances on these three benchmark datasets.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 02:44:42 GMT"}, {"version": "v2", "created": "Tue, 20 Mar 2018 08:44:47 GMT"}, {"version": "v3", "created": "Fri, 30 Mar 2018 05:58:59 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Ma", "Shuming", ""], ["Sun", "Xu", ""], ["Li", "Wei", ""], ["Li", "Sujian", ""], ["Li", "Wenjie", ""], ["Ren", "Xuancheng", ""]]}, {"id": "1803.01557", "submitter": "Zhiyuan Zhang", "authors": "Zhiyuan Zhang, Wei Li, Qi Su", "title": "Automatic Translating Between Ancient Chinese and Contemporary Chinese\n  with Limited Aligned Corpora", "comments": "Acceptted by NLPCC 2019", "journal-ref": null, "doi": "10.1007/978-3-030-32236-6_13", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Chinese language has evolved a lot during the long-term development.\nTherefore, native speakers now have trouble in reading sentences written in\nancient Chinese. In this paper, we propose to build an end-to-end neural model\nto automatically translate between ancient and contemporary Chinese. However,\nthe existing ancient-contemporary Chinese parallel corpora are not aligned at\nthe sentence level and sentence-aligned corpora are limited, which makes it\ndifficult to train the model. To build the sentence level parallel training\ndata for the model, we propose an unsupervised algorithm that constructs\nsentence-aligned ancient-contemporary pairs by using the fact that the aligned\nsentence pair shares many of the tokens. Based on the aligned corpus, we\npropose an end-to-end neural model with copying mechanism and local attention\nto translate between ancient and contemporary Chinese. Experiments show that\nthe proposed unsupervised algorithm achieves 99.4% F1 score for sentence\nalignment, and the translation model achieves 26.95 BLEU from ancient to\ncontemporary, and 36.34 BLEU from contemporary to ancient.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 08:37:47 GMT"}, {"version": "v2", "created": "Tue, 14 Aug 2018 12:50:32 GMT"}, {"version": "v3", "created": "Wed, 10 Jun 2020 03:55:28 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Zhang", "Zhiyuan", ""], ["Li", "Wei", ""], ["Su", "Qi", ""]]}, {"id": "1803.01580", "submitter": "Andrew Krizhanovsky A", "authors": "Andrew Krizhanovsky, Alexander Kirillov", "title": "Calculated attributes of synonym sets", "comments": "6 pages, 2 tables, 2 figures, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The goal of formalization, proposed in this paper, is to bring together, as\nnear as possible, the theoretic linguistic problem of synonym conception and\nthe computer linguistic methods based generally on empirical intuitive\nunjustified factors. Using the word vector representation we have proposed the\ngeometric approach to mathematical modeling of synonym set (synset). The word\nembedding is based on the neural networks (Skip-gram, CBOW), developed and\nrealized as word2vec program by T. Mikolov. The standard cosine similarity is\nused as the distance between word-vectors. Several geometric characteristics of\nthe synset words are introduced: the interior of synset, the synset word rank\nand centrality. These notions are intended to select the most significant\nsynset words, i.e. the words which senses are the nearest to the sense of a\nsynset. Some experiments with proposed notions, based on RusVectores resources,\nare represented. A brief description of this work can be viewed in slides\nhttps://goo.gl/K82Fei\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 10:09:32 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Krizhanovsky", "Andrew", ""], ["Kirillov", "Alexander", ""]]}, {"id": "1803.01686", "submitter": "Yuanhang Su", "authors": "Yuanhang Su, C.-C. Jay Kuo", "title": "On Extended Long Short-term Memory and Dependent Bidirectional Recurrent\n  Neural Network", "comments": "github repo: https://github.com/yuanhangsu/ELSTM-DBRNN", "journal-ref": "Neurocomputing 356 (2019): 151-161", "doi": "10.1016/j.neucom.2019.04.044", "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we first analyze the memory behavior in three recurrent neural\nnetworks (RNN) cells; namely, the simple RNN (SRN), the long short-term memory\n(LSTM) and the gated recurrent unit (GRU), where the memory is defined as a\nfunction that maps previous elements in a sequence to the current output. Our\nstudy shows that all three of them suffer rapid memory decay. Then, to\nalleviate this effect, we introduce trainable scaling factors that act like an\nattention mechanism to adjust memory decay adaptively. The new design is called\nthe extended LSTM (ELSTM). Finally, to design a system that is robust to\nprevious erroneous predictions, we propose a dependent bidirectional recurrent\nneural network (DBRNN). Extensive experiments are conducted on different\nlanguage tasks to demonstrate the superiority of the proposed ELSTM and DBRNN\nsolutions. The ELTSM has achieved up to 30% increase in the labeled attachment\nscore (LAS) as compared to LSTM and GRU in the dependency parsing (DP) task.\nOur models also outperform other state-of-the-art models such as bi-attention\nand convolutional sequence to sequence (convseq2seq) by close to 10% in the\nLAS. The code is released as an open source\n(https://github.com/yuanhangsu/ELSTM-DBRNN)\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 02:47:13 GMT"}, {"version": "v2", "created": "Sun, 16 Sep 2018 05:43:49 GMT"}, {"version": "v3", "created": "Sun, 3 Mar 2019 04:30:02 GMT"}, {"version": "v4", "created": "Tue, 14 May 2019 23:26:31 GMT"}, {"version": "v5", "created": "Sun, 17 Nov 2019 21:39:02 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Su", "Yuanhang", ""], ["Kuo", "C. -C. Jay", ""]]}, {"id": "1803.01707", "submitter": "Benjamin Roth", "authors": "Benjamin Roth, Costanza Conforti, Nina Poerner, Sanjeev Karn and\n  Hinrich Sch\\\"utze", "title": "Neural Architectures for Open-Type Relation Argument Extraction", "comments": null, "journal-ref": "Nat. Lang. Eng. 25 (2019) 219-238", "doi": "10.1017/S1351324918000451", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we introduce the task of Open-Type Relation Argument Extraction\n(ORAE): Given a corpus, a query entity Q and a knowledge base relation (e.g.,\"Q\nauthored notable work with title X\"), the model has to extract an argument of\nnon-standard entity type (entities that cannot be extracted by a standard named\nentity tagger, e.g. X: the title of a book or a work of art) from the corpus. A\ndistantly supervised dataset based on WikiData relations is obtained and\nreleased to address the task.\n  We develop and compare a wide range of neural models for this task yielding\nlarge improvements over a strong baseline obtained with a neural question\nanswering system. The impact of different sentence encoding architectures and\nanswer extraction methods is systematically compared. An encoder based on gated\nrecurrent units combined with a conditional random fields tagger gives the best\nresults.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 15:09:49 GMT"}, {"version": "v2", "created": "Sun, 30 Sep 2018 17:04:29 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Roth", "Benjamin", ""], ["Conforti", "Costanza", ""], ["Poerner", "Nina", ""], ["Karn", "Sanjeev", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1803.01934", "submitter": "Luis Seoane Luis F", "authors": "Lu\\'is F Seoane and Ricard Sol\\'e", "title": "The morphospace of language networks", "comments": "Research paper preprint, 18 pages, 11 figures, 2 appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language can be described as a network of interacting objects with different\nqualitative properties and complexity. These networks include semantic,\nsyntactic, or phonological levels and have been found to provide a new picture\nof language complexity and its evolution. A general approach considers language\nfrom an information theory perspective that incorporates a speaker, a hearer,\nand a noisy channel. The later is often encoded in a matrix connecting the\nsignals used for communication with meanings to be found in the real world.\nMost studies of language evolution deal in a way or another with such\ntheoretical contraption and explore the outcome of diverse forms of selection\non the communication matrix that somewhat optimizes communication. This\nframework naturally introduces networks mediating the communicating agents, but\nno systematic analysis of the underlying landscape of possible language graphs\nhas been developed. Here we present a detailed analysis of network properties\non a generic model of a communication code, which reveals a rather complex and\nheterogeneous morphospace of language networks. Additionally, we use curated\ndata of English words to locate and evaluate real languages within this\nlanguage morphospace. Our findings indicate a surprisingly simple structure in\nhuman language unless particles are introduced in the vocabulary, with the\nability of naming any other concept. These results refine and for the first\ntime complement with empirical data a lasting theoretical tradition around the\nframework of \\emph{least effort language}.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 21:29:50 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Seoane", "Lu\u00eds F", ""], ["Sol\u00e9", "Ricard", ""]]}, {"id": "1803.01937", "submitter": "Kavita Ganesan", "authors": "Kavita Ganesan", "title": "ROUGE 2.0: Updated and Improved Measures for Evaluation of Summarization\n  Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluation of summarization tasks is extremely crucial to determining the\nquality of machine generated summaries. Over the last decade, ROUGE has become\nthe standard automatic evaluation measure for evaluating summarization tasks.\nWhile ROUGE has been shown to be effective in capturing n-gram overlap between\nsystem and human composed summaries, there are several limitations with the\nexisting ROUGE measures in terms of capturing synonymous concepts and coverage\nof topics. Thus, often times ROUGE scores do not reflect the true quality of\nsummaries and prevents multi-faceted evaluation of summaries (i.e. by topics,\nby overall content coverage and etc). In this paper, we introduce ROUGE 2.0,\nwhich has several updated measures of ROUGE: ROUGE-N+Synonyms, ROUGE-Topic,\nROUGE-Topic+Synonyms, ROUGE-TopicUniq and ROUGE-TopicUniq+Synonyms; all of\nwhich are improvements over the core ROUGE measures.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 21:35:04 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Ganesan", "Kavita", ""]]}, {"id": "1803.02088", "submitter": "David Robb", "authors": "Francisco J. Chiyah Garcia, David A. Robb, Xingkun Liu, Atanas Laskov,\n  Pedro Patron and Helen Hastie", "title": "Explain Yourself: A Natural Language Interface for Scrutable Autonomous\n  Robots", "comments": "2 pages. Peer reviewed position paper accepted in the Explainable\n  Robotic Systems Workshop, ACM Human-Robot Interaction conference, March 2018,\n  Chicago, IL USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous systems in remote locations have a high degree of autonomy and\nthere is a need to explain what they are doing and why in order to increase\ntransparency and maintain trust. Here, we describe a natural language chat\ninterface that enables vehicle behaviour to be queried by the user. We obtain\nan interpretable model of autonomy through having an expert 'speak out-loud'\nand provide explanations during a mission. This approach is agnostic to the\ntype of autonomy model and as expert and operator are from the same user-group,\nwe predict that these explanations will align well with the operator's mental\nmodel, increase transparency and assist with operator training.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 10:13:29 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Garcia", "Francisco J. Chiyah", ""], ["Robb", "David A.", ""], ["Liu", "Xingkun", ""], ["Laskov", "Atanas", ""], ["Patron", "Pedro", ""], ["Hastie", "Helen", ""]]}, {"id": "1803.02155", "submitter": "Peter Shaw", "authors": "Peter Shaw, Jakob Uszkoreit, Ashish Vaswani", "title": "Self-Attention with Relative Position Representations", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relying entirely on an attention mechanism, the Transformer introduced by\nVaswani et al. (2017) achieves state-of-the-art results for machine\ntranslation. In contrast to recurrent and convolutional neural networks, it\ndoes not explicitly model relative or absolute position information in its\nstructure. Instead, it requires adding representations of absolute positions to\nits inputs. In this work we present an alternative approach, extending the\nself-attention mechanism to efficiently consider representations of the\nrelative positions, or distances between sequence elements. On the WMT 2014\nEnglish-to-German and English-to-French translation tasks, this approach yields\nimprovements of 1.3 BLEU and 0.3 BLEU over absolute position representations,\nrespectively. Notably, we observe that combining relative and absolute position\nrepresentations yields no further improvement in translation quality. We\ndescribe an efficient implementation of our method and cast it as an instance\nof relation-aware self-attention mechanisms that can generalize to arbitrary\ngraph-labeled inputs.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 13:13:11 GMT"}, {"version": "v2", "created": "Thu, 12 Apr 2018 18:51:33 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Shaw", "Peter", ""], ["Uszkoreit", "Jakob", ""], ["Vaswani", "Ashish", ""]]}, {"id": "1803.02205", "submitter": "Vasiliki Efstathiou", "authors": "Vasiliki Efstathiou and Diomidis Spinellis", "title": "Code Review Comments: Language Matters", "comments": null, "journal-ref": null, "doi": "10.1145/3183399.3183411", "report-no": null, "categories": "cs.SE cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research provides evidence that effective communication in\ncollaborative software development has significant impact on the software\ndevelopment lifecycle. Although related qualitative and quantitative studies\npoint out textual characteristics of well-formed messages, the underlying\nsemantics of the intertwined linguistic structures still remain largely\nmisinterpreted or ignored. Especially, regarding quality of code reviews the\nimportance of thorough feedback, and explicit rationale is often mentioned but\nrarely linked with related linguistic features. As a first step towards\naddressing this shortcoming, we propose grounding these studies on theories of\nlinguistics. We particularly focus on linguistic structures of coherent speech\nand explain how they can be exploited in practice. We reflect on related\napproaches and examine through a preliminary study on four open source\nprojects, possible links between existing findings and the directions we\nsuggest for detecting textual features of useful code reviews.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 14:21:15 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Efstathiou", "Vasiliki", ""], ["Spinellis", "Diomidis", ""]]}, {"id": "1803.02238", "submitter": "Ivan Gavran", "authors": "Ivan Gavran, Brendon Boldt, Eva Darulova, Rupak Majumdar", "title": "Precise but Natural Specification for Robot Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CL cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Flipper, a natural language interface for describing high-level\ntask specifications for robots that are compiled into robot actions. Flipper\nstarts with a formal core language for task planning that allows expressing\nrich temporal specifications and uses a semantic parser to provide a natural\nlanguage interface. Flipper provides immediate visual feedback by executing an\nautomatically constructed plan of the task in a graphical user interface. This\nallows the user to resolve potentially ambiguous interpretations. Flipper\nextends itself via naturalization: its users can add definitions for\nutterances, from which Flipper induces new rules and adds them to the core\nlanguage, gradually growing a more and more natural task specification\nlanguage. Flipper improves the naturalization by generalizing the definition\nprovided by users. Unlike other task-specification systems, Flipper enables\nnatural language interactions while maintaining the expressive power and formal\nprecision of a programming language. We show through an initial user study that\nnatural language interactions and generalization can considerably ease the\ndescription of tasks. Moreover, over time, users employ more and more concepts\noutside of the initial core language. Such extensions are available to the\nFlipper community, and users can use concepts that others have defined.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 15:07:40 GMT"}, {"version": "v2", "created": "Thu, 20 Sep 2018 07:12:42 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Gavran", "Ivan", ""], ["Boldt", "Brendon", ""], ["Darulova", "Eva", ""], ["Majumdar", "Rupak", ""]]}, {"id": "1803.02245", "submitter": "Willie Boag", "authors": "Willie Boag, Elena Sergeeva, Saurabh Kulshreshtha, Peter Szolovits,\n  Anna Rumshisky, Tristan Naumann", "title": "CliNER 2.0: Accessible and Accurate Clinical Concept Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical notes often describe important aspects of a patient's stay and are\ntherefore critical to medical research. Clinical concept extraction (CCE) of\nnamed entities - such as problems, tests, and treatments - aids in forming an\nunderstanding of notes and provides a foundation for many downstream clinical\ndecision-making tasks. Historically, this task has been posed as a standard\nnamed entity recognition (NER) sequence tagging problem, and solved with\nfeature-based methods using handengineered domain knowledge. Recent advances,\nhowever, have demonstrated the efficacy of LSTM-based models for NER tasks,\nincluding CCE. This work presents CliNER 2.0, a simple-to-install, open-source\ntool for extracting concepts from clinical text. CliNER 2.0 uses a word- and\ncharacter- level LSTM model, and achieves state-of-the-art performance. For\nease of use, the tool also includes pre-trained models available for public\nuse.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 15:17:40 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Boag", "Willie", ""], ["Sergeeva", "Elena", ""], ["Kulshreshtha", "Saurabh", ""], ["Szolovits", "Peter", ""], ["Rumshisky", "Anna", ""], ["Naumann", "Tristan", ""]]}, {"id": "1803.02279", "submitter": "Stefan Constantin", "authors": "Stefan Constantin, Jan Niehues, and Alex Waibel", "title": "An End-to-End Goal-Oriented Dialog System with a Generative Natural\n  Language Response Generation", "comments": "11 pages, 4 figures, forthcoming in IWSDS 2018; added quantitative\n  analysis of sensitivity to modified user utterances and minor improvements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently advancements in deep learning allowed the development of end-to-end\ntrained goal-oriented dialog systems. Although these systems already achieve\ngood performance, some simplifications limit their usage in real-life\nscenarios.\n  In this work, we address two of these limitations: ignoring positional\ninformation and a fixed number of possible response candidates. We propose to\nuse positional encodings in the input to model the word order of the user\nutterances. Furthermore, by using a feedforward neural network, we are able to\ngenerate the output word by word and are no longer restricted to a fixed number\nof possible response candidates. Using the positional encoding, we were able to\nachieve better accuracies in the Dialog bAbI Tasks and using the feedforward\nneural network for generating the response, we were able to save computation\ntime and space consumption.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 16:17:18 GMT"}, {"version": "v2", "created": "Thu, 15 Mar 2018 15:22:11 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Constantin", "Stefan", ""], ["Niehues", "Jan", ""], ["Waibel", "Alex", ""]]}, {"id": "1803.02324", "submitter": "Suchin Gururangan", "authors": "Suchin Gururangan, Swabha Swayamdipta, Omer Levy, Roy Schwartz, Samuel\n  R. Bowman, Noah A. Smith", "title": "Annotation Artifacts in Natural Language Inference Data", "comments": "6 pages, 1 figure, NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Large-scale datasets for natural language inference are created by presenting\ncrowd workers with a sentence (premise), and asking them to generate three new\nsentences (hypotheses) that it entails, contradicts, or is logically neutral\nwith respect to. We show that, in a significant portion of such data, this\nprotocol leaves clues that make it possible to identify the label by looking\nonly at the hypothesis, without observing the premise. Specifically, we show\nthat a simple text categorization model can correctly classify the hypothesis\nalone in about 67% of SNLI (Bowman et. al, 2015) and 53% of MultiNLI (Williams\net. al, 2017). Our analysis reveals that specific linguistic phenomena such as\nnegation and vagueness are highly correlated with certain inference classes.\nOur findings suggest that the success of natural language inference models to\ndate has been overestimated, and that the task remains a hard open problem.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 18:23:08 GMT"}, {"version": "v2", "created": "Mon, 16 Apr 2018 22:14:06 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Gururangan", "Suchin", ""], ["Swayamdipta", "Swabha", ""], ["Levy", "Omer", ""], ["Schwartz", "Roy", ""], ["Bowman", "Samuel R.", ""], ["Smith", "Noah A.", ""]]}, {"id": "1803.02392", "submitter": "Francesco Barbieri", "authors": "Francesco Barbieri, Miguel Ballesteros, Francesco Ronzano, Horacio\n  Saggion", "title": "Multimodal Emoji Prediction", "comments": "NAACL 2018 (short)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emojis are small images that are commonly included in social media text\nmessages. The combination of visual and textual content in the same message\nbuilds up a modern way of communication, that automatic systems are not used to\ndeal with. In this paper we extend recent advances in emoji prediction by\nputting forward a multimodal approach that is able to predict emojis in\nInstagram posts. Instagram posts are composed of pictures together with texts\nwhich sometimes include emojis. We show that these emojis can be predicted by\nusing the text, but also using the picture. Our main finding is that\nincorporating the two synergistic modalities, in a combined model, improves\naccuracy in an emoji prediction task. This result demonstrates that these two\nmodalities (text and images) encode different information on the use of emojis\nand therefore can complement each other.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 19:23:24 GMT"}, {"version": "v2", "created": "Tue, 17 Apr 2018 14:02:19 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Barbieri", "Francesco", ""], ["Ballesteros", "Miguel", ""], ["Ronzano", "Francesco", ""], ["Saggion", "Horacio", ""]]}, {"id": "1803.02400", "submitter": "Po-Sen Huang", "authors": "Po-Sen Huang, Chenglong Wang, Rishabh Singh, Wen-tau Yih, Xiaodong He", "title": "Natural Language to Structured Query Generation via Meta-Learning", "comments": "in NAACL HLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In conventional supervised training, a model is trained to fit all the\ntraining examples. However, having a monolithic model may not always be the\nbest strategy, as examples could vary widely. In this work, we explore a\ndifferent learning protocol that treats each example as a unique pseudo-task,\nby reducing the original learning problem to a few-shot meta-learning scenario\nwith the help of a domain-dependent relevance function. When evaluated on the\nWikiSQL dataset, our approach leads to faster convergence and achieves\n1.1%-5.4% absolute accuracy gains over the non-meta-learning counterparts.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 05:26:28 GMT"}, {"version": "v2", "created": "Wed, 18 Apr 2018 22:27:18 GMT"}, {"version": "v3", "created": "Wed, 13 Jun 2018 22:32:38 GMT"}, {"version": "v4", "created": "Wed, 18 Jul 2018 21:40:45 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Huang", "Po-Sen", ""], ["Wang", "Chenglong", ""], ["Singh", "Rishabh", ""], ["Yih", "Wen-tau", ""], ["He", "Xiaodong", ""]]}, {"id": "1803.02551", "submitter": "Wei-Ning Hsu", "authors": "Wei-Ning Hsu and James Glass", "title": "Extracting Domain Invariant Features by Unsupervised Learning for Robust\n  Automatic Speech Recognition", "comments": "accepted by 2018 International Conference on Acoustics, Speech, and\n  Signal Processing (ICASSP 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of automatic speech recognition (ASR) systems can be\nsignificantly compromised by previously unseen conditions, which is typically\ndue to a mismatch between training and testing distributions. In this paper, we\naddress robustness by studying domain invariant features, such that domain\ninformation becomes transparent to ASR systems, resolving the mismatch problem.\nSpecifically, we investigate a recent model, called the Factorized Hierarchical\nVariational Autoencoder (FHVAE). FHVAEs learn to factorize sequence-level and\nsegment-level attributes into different latent variables without supervision.\nWe argue that the set of latent variables that contain segment-level\ninformation is our desired domain invariant feature for ASR. Experiments are\nconducted on Aurora-4 and CHiME-4, which demonstrate 41% and 27% absolute word\nerror rate reductions respectively on mismatched domains.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 07:30:36 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Hsu", "Wei-Ning", ""], ["Glass", "James", ""]]}, {"id": "1803.02632", "submitter": "Wenfeng Feng", "authors": "Wenfeng Feng, Hankz Hankui Zhuo, Subbarao Kambhampati", "title": "Extracting Action Sequences from Texts Based on Deep Reinforcement\n  Learning", "comments": "7pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Extracting action sequences from natural language texts is challenging, as it\nrequires commonsense inferences based on world knowledge. Although there has\nbeen work on extracting action scripts, instructions, navigation actions, etc.,\nthey require that either the set of candidate actions be provided in advance,\nor that action descriptions are restricted to a specific form, e.g.,\ndescription templates. In this paper, we aim to extract action sequences from\ntexts in free natural language, i.e., without any restricted templates,\nprovided the candidate set of actions is unknown. We propose to extract action\nsequences from texts based on the deep reinforcement learning framework.\nSpecifically, we view \"selecting\" or \"eliminating\" words from texts as\n\"actions\", and the texts associated with actions as \"states\". We then build\nQ-networks to learn the policy of extracting actions and extract plans from the\nlabeled texts. We demonstrate the effectiveness of our approach on several\ndatasets with comparison to state-of-the-art approaches, including online\nexperiments interacting with humans.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 13:13:16 GMT"}, {"version": "v2", "created": "Fri, 11 May 2018 15:57:08 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Feng", "Wenfeng", ""], ["Zhuo", "Hankz Hankui", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "1803.02710", "submitter": "Yikang Shen", "authors": "Yikang Shen, Shawn Tan, Chin-Wei Huang, Aaron Courville", "title": "Generating Contradictory, Neutral, and Entailing Sentences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning distributed sentence representations remains an interesting problem\nin the field of Natural Language Processing (NLP). We want to learn a model\nthat approximates the conditional latent space over the representations of a\nlogical antecedent of the given statement. In our paper, we propose an approach\nto generating sentences, conditioned on an input sentence and a logical\ninference label. We do this by modeling the different possibilities for the\noutput sentence as a distribution over the latent representation, which we\ntrain using an adversarial objective. We evaluate the model using two\nstate-of-the-art models for the Recognizing Textual Entailment (RTE) task, and\nmeasure the BLEU scores against the actual sentences as a probe for the\ndiversity of sentences produced by our model. The experiment results show that,\ngiven our framework, we have clear ways to improve the quality and diversity of\ngenerated sentences.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 15:18:03 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Shen", "Yikang", ""], ["Tan", "Shawn", ""], ["Huang", "Chin-Wei", ""], ["Courville", "Aaron", ""]]}, {"id": "1803.02728", "submitter": "Willie Boag", "authors": "Willie Boag, Tristan Naumann, Peter Szolovits", "title": "Towards the Creation of a Large Corpus of Synthetically-Identified\n  Clinical Notes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical notes often describe the most important aspects of a patient's\nphysiology and are therefore critical to medical research. However, these notes\nare typically inaccessible to researchers without prior removal of sensitive\nprotected health information (PHI), a natural language processing (NLP) task\nreferred to as deidentification. Tools to automatically de-identify clinical\nnotes are needed but are difficult to create without access to those very same\nnotes containing PHI. This work presents a first step toward creating a large\nsynthetically-identified corpus of clinical notes and corresponding PHI\nannotations in order to facilitate the development de-identification tools.\nFurther, one such tool is evaluated against this corpus in order to understand\nthe advantages and shortcomings of this approach.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 15:51:11 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Boag", "Willie", ""], ["Naumann", "Tristan", ""], ["Szolovits", "Peter", ""]]}, {"id": "1803.02839", "submitter": "Sean Cantrell", "authors": "Sean A. Cantrell", "title": "The emergent algebraic structure of RNNs and embeddings in NLP", "comments": "24 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the algebraic and geometric properties of a uni-directional GRU\nand word embeddings trained end-to-end on a text classification task. A\nhyperparameter search over word embedding dimension, GRU hidden dimension, and\na linear combination of the GRU outputs is performed. We conclude that words\nnaturally embed themselves in a Lie group and that RNNs form a nonlinear\nrepresentation of the group. Appealing to these results, we propose a novel\nclass of recurrent-like neural networks and a word embedding scheme.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 19:06:08 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Cantrell", "Sean A.", ""]]}, {"id": "1803.02893", "submitter": "Lajanugen Logeswaran", "authors": "Lajanugen Logeswaran, Honglak Lee", "title": "An efficient framework for learning sentence representations", "comments": "ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a simple and efficient framework for learning\nsentence representations from unlabelled data. Drawing inspiration from the\ndistributional hypothesis and recent work on learning sentence representations,\nwe reformulate the problem of predicting the context in which a sentence\nappears as a classification problem. Given a sentence and its context, a\nclassifier distinguishes context sentences from other contrastive sentences\nbased on their vector representations. This allows us to efficiently learn\ndifferent types of encoding functions, and we show that the model learns\nhigh-quality sentence representations. We demonstrate that our sentence\nrepresentations outperform state-of-the-art unsupervised and supervised\nrepresentation learning methods on several downstream NLP tasks that involve\nunderstanding sentence semantics while achieving an order of magnitude speedup\nin training time.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 22:02:10 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Logeswaran", "Lajanugen", ""], ["Lee", "Honglak", ""]]}, {"id": "1803.02914", "submitter": "Mihael Arcan", "authors": "Mihael Arcan", "title": "Translating Questions into Answers using DBPedia n-triples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper we present a question answering system using a neural network\nto interpret questions learned from the DBpedia repository. We train a\nsequence-to-sequence neural network model with n-triples extracted from the\nDBpedia Infobox Properties. Since these properties do not represent the natural\nlanguage, we further used question-answer dialogues from movie subtitles.\nAlthough the automatic evaluation shows a low overlap of the generated answers\ncompared to the gold standard set, a manual inspection of the showed promising\noutcomes from the experiment for further work.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 23:29:31 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Arcan", "Mihael", ""]]}, {"id": "1803.02994", "submitter": "Liang Jiang", "authors": "Linli Xu, Liang Jiang, Chuan Qin, Zhe Wang, Dongfang Du", "title": "How Images Inspire Poems: Generating Classical Chinese Poetry from\n  Images with Memory Networks", "comments": "Accepted by AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent advances of neural models and natural language processing,\nautomatic generation of classical Chinese poetry has drawn significant\nattention due to its artistic and cultural value. Previous works mainly focus\non generating poetry given keywords or other text information, while visual\ninspirations for poetry have been rarely explored. Generating poetry from\nimages is much more challenging than generating poetry from text, since images\ncontain very rich visual information which cannot be described completely using\nseveral keywords, and a good poem should convey the image accurately. In this\npaper, we propose a memory based neural model which exploits images to generate\npoems. Specifically, an Encoder-Decoder model with a topic memory network is\nproposed to generate classical Chinese poetry from images. To the best of our\nknowledge, this is the first work attempting to generate classical Chinese\npoetry from images with neural networks. A comprehensive experimental\ninvestigation with both human evaluation and quantitative analysis demonstrates\nthat the proposed model can generate poems which convey images accurately.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 08:07:31 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Xu", "Linli", ""], ["Jiang", "Liang", ""], ["Qin", "Chuan", ""], ["Wang", "Zhe", ""], ["Du", "Dongfang", ""]]}, {"id": "1803.03018", "submitter": "Heishiro Kanagawa", "authors": "Heishiro Kanagawa, Hayato Kobayashi, Nobuyuki Shimizu, Yukihiro Tagami\n  and Taiji Suzuki", "title": "Cross-domain Recommendation via Deep Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The behavior of users in certain services could be a clue that can be used to\ninfer their preferences and may be used to make recommendations for other\nservices they have never used. However, the cross-domain relationships between\nitems and user consumption patterns are not simple, especially when there are\nfew or no common users and items across domains. To address this problem, we\npropose a content-based cross-domain recommendation method for cold-start users\nthat does not require user- and item- overlap. We formulate recommendation as\nextreme multi-class classification where labels (items) corresponding to the\nusers are predicted. With this formulation, the problem is reduced to a domain\nadaptation setting, in which a classifier trained in the source domain is\nadapted to the target domain. For this, we construct a neural network that\ncombines an architecture for domain adaptation, Domain Separation Network, with\na denoising autoencoder for item representation. We assess the performance of\nour approach in experiments on a pair of data sets collected from movie and\nnews services of Yahoo! JAPAN and show that our approach outperforms several\nbaseline methods including a cross-domain collaborative filtering method.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 09:43:04 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Kanagawa", "Heishiro", ""], ["Kobayashi", "Hayato", ""], ["Shimizu", "Nobuyuki", ""], ["Tagami", "Yukihiro", ""], ["Suzuki", "Taiji", ""]]}, {"id": "1803.03178", "submitter": "Preslav Nakov", "authors": "Tsvetomila Mihaylova, Preslav Nakov, Lluis Marquez, Alberto\n  Barron-Cedeno, Mitra Mohtarami, Georgi Karadzhov, James Glass", "title": "Fact Checking in Community Forums", "comments": "AAAI-2018; Fact-Checking; Veracity; Community-Question Answering;\n  Neural Networks; Distributed Representations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community Question Answering (cQA) forums are very popular nowadays, as they\nrepresent effective means for communities around particular topics to share\ninformation. Unfortunately, this information is not always factual. Thus, here\nwe explore a new dimension in the context of cQA, which has been ignored so\nfar: checking the veracity of answers to particular questions in cQA forums. As\nthis is a new problem, we create a specialized dataset for it. We further\npropose a novel multi-faceted model, which captures information from the answer\ncontent (what is said and how), from the author profile (who says it), from the\nrest of the community forum (where it is said), and from external authoritative\nsources of information (external support). Evaluation results show a MAP value\nof 86.54, which is 21 points absolute above the baseline.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 16:06:54 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Mihaylova", "Tsvetomila", ""], ["Nakov", "Preslav", ""], ["Marquez", "Lluis", ""], ["Barron-Cedeno", "Alberto", ""], ["Mohtarami", "Mitra", ""], ["Karadzhov", "Georgi", ""], ["Glass", "James", ""]]}, {"id": "1803.03232", "submitter": "Inigo Casanueva", "authors": "I\\~nigo Casanueva, Pawe{\\l} Budzianowski, Pei-Hao Su, Stefan Ultes,\n  Lina Rojas-Barahona, Bo-Hsiang Tseng and Milica Ga\\v{s}i\\'c", "title": "Feudal Reinforcement Learning for Dialogue Management in Large Domains", "comments": "Accepted as a short paper in NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) is a promising approach to solve dialogue policy\noptimisation. Traditional RL algorithms, however, fail to scale to large\ndomains due to the curse of dimensionality. We propose a novel Dialogue\nManagement architecture, based on Feudal RL, which decomposes the decision into\ntwo steps; a first step where a master policy selects a subset of primitive\nactions, and a second step where a primitive action is chosen from the selected\nsubset. The structural information included in the domain ontology is used to\nabstract the dialogue state space, taking the decisions at each step using\ndifferent parts of the abstracted state. This, combined with an information\nsharing mechanism between slots, increases the scalability to large domains. We\nshow that an implementation of this approach, based on Deep-Q Networks,\nsignificantly outperforms previous state of the art in several dialogue domains\nand environments, without the need of any additional reward signal.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 18:05:18 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Casanueva", "I\u00f1igo", ""], ["Budzianowski", "Pawe\u0142", ""], ["Su", "Pei-Hao", ""], ["Ultes", "Stefan", ""], ["Rojas-Barahona", "Lina", ""], ["Tseng", "Bo-Hsiang", ""], ["Ga\u0161i\u0107", "Milica", ""]]}, {"id": "1803.03370", "submitter": "Qi Zhu", "authors": "Huan Gui, Qi Zhu, Liyuan Liu, Aston Zhang, Jiawei Han", "title": "Expert Finding in Heterogeneous Bibliographic Networks with\n  Locally-trained Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expert finding is an important task in both industry and academia. It is\nchallenging to rank candidates with appropriate expertise for various queries.\nIn addition, different types of objects interact with one another, which\nnaturally forms heterogeneous information networks. We study the task of expert\nfinding in heterogeneous bibliographical networks based on two aspects: textual\ncontent analysis and authority ranking. Regarding the textual content analysis,\nwe propose a new method for query expansion via locally-trained embedding\nlearning with concept hierarchy as guidance, which is particularly tailored for\nspecific queries with narrow semantic meanings. Compared with global embedding\nlearning, locally-trained embedding learning projects the terms into a latent\nsemantic space constrained on relevant topics, therefore it preserves more\nprecise and subtle information for specific queries. Considering the candidate\nranking, the heterogeneous information network structure, while being largely\nignored in the previous studies of expert finding, provides additional\ninformation. Specifically, different types of interactions among objects play\ndifferent roles. We propose a ranking algorithm to estimate the authority of\nobjects in the network, treating each strongly-typed edge type individually. To\ndemonstrate the effectiveness of the proposed framework, we apply the proposed\nmethod to a large-scale bibliographical dataset with over two million entries\nand one million researcher candidates. The experiment results show that the\nproposed framework outperforms existing methods for both general and specific\nqueries.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 03:28:36 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Gui", "Huan", ""], ["Zhu", "Qi", ""], ["Liu", "Liyuan", ""], ["Zhang", "Aston", ""], ["Han", "Jiawei", ""]]}, {"id": "1803.03376", "submitter": "Lifu Tu", "authors": "Lifu Tu, Kevin Gimpel", "title": "Learning Approximate Inference Networks for Structured Prediction", "comments": "accepted by ICLR2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Structured prediction energy networks (SPENs; Belanger & McCallum 2016) use\nneural network architectures to define energy functions that can capture\narbitrary dependencies among parts of structured outputs. Prior work used\ngradient descent for inference, relaxing the structured output to a set of\ncontinuous variables and then optimizing the energy with respect to them. We\nreplace this use of gradient descent with a neural network trained to\napproximate structured argmax inference. This \"inference network\" outputs\ncontinuous values that we treat as the output structure. We develop\nlarge-margin training criteria for joint training of the structured energy\nfunction and inference network. On multi-label classification we report\nspeed-ups of 10-60x compared to (Belanger et al, 2017) while also improving\naccuracy. For sequence labeling with simple structured energies, our approach\nperforms comparably to exact inference while being much faster at test time. We\nthen demonstrate improved accuracy by augmenting the energy with a \"label\nlanguage model\" that scores entire output label sequences, showing it can\nimprove handling of long-distance dependencies in part-of-speech tagging.\nFinally, we show how inference networks can replace dynamic programming for\ntest-time inference in conditional random fields, suggestive for their general\nuse for fast inference in structured settings.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 03:50:24 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Tu", "Lifu", ""], ["Gimpel", "Kevin", ""]]}, {"id": "1803.03378", "submitter": "Peng Xu", "authors": "Peng Xu and Denilson Barbosa", "title": "Neural Fine-Grained Entity Type Classification with Hierarchy-Aware Loss", "comments": "Camera-ready for NAACL HLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of Fine-grained Entity Type Classification (FETC) consists of\nassigning types from a hierarchy to entity mentions in text. Existing methods\nrely on distant supervision and are thus susceptible to noisy labels that can\nbe out-of-context or overly-specific for the training sentence. Previous\nmethods that attempt to address these issues do so with heuristics or with the\nhelp of hand-crafted features. Instead, we propose an end-to-end solution with\na neural network model that uses a variant of cross- entropy loss function to\nhandle out-of-context labels, and hierarchical loss normalization to cope with\noverly-specific ones. Also, previous work solve FETC a multi-label\nclassification followed by ad-hoc post-processing. In contrast, our solution is\nmore elegant: we use public word embeddings to train a single-label that\njointly learns representations for entity mentions and their context. We show\nexperimentally that our approach is robust against noise and consistently\noutperforms the state-of-the-art on established benchmarks for the task.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 04:15:22 GMT"}, {"version": "v2", "created": "Sat, 14 Apr 2018 03:33:53 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Xu", "Peng", ""], ["Barbosa", "Denilson", ""]]}, {"id": "1803.03476", "submitter": "Minghua Zhang", "authors": "Minghua Zhang, Yunfang Wu", "title": "An Unsupervised Model with Attention Autoencoders for Question Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question retrieval is a crucial subtask for community question answering.\nPrevious research focus on supervised models which depend heavily on training\ndata and manual feature engineering. In this paper, we propose a novel\nunsupervised framework, namely reduced attentive matching network (RAMN), to\ncompute semantic matching between two questions. Our RAMN integrates together\nthe deep semantic representations, the shallow lexical mismatching information\nand the initial rank produced by an external search engine. For the first time,\nwe propose attention autoencoders to generate semantic representations of\nquestions. In addition, we employ lexical mismatching to capture surface\nmatching between two questions, which is derived from the importance of each\nword in a question. We conduct experiments on the open CQA datasets of\nSemEval-2016 and SemEval-2017. The experimental results show that our\nunsupervised model obtains comparable performance with the state-of-the-art\nsupervised methods in SemEval-2016 Task 3, and outperforms the best system in\nSemEval-2017 Task 3 by a wide margin.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 11:44:39 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Zhang", "Minghua", ""], ["Wu", "Yunfang", ""]]}, {"id": "1803.03481", "submitter": "Akira Taniguchi", "authors": "Akira Taniguchi, Yoshinobu Hagiwara, Tadahiro Taniguchi, and Tetsunari\n  Inamura", "title": "Improved and Scalable Online Learning of Spatial Concepts and Language\n  Models with Mapping", "comments": "Accepted to Autonomous Robots (24 January 2020)", "journal-ref": null, "doi": "10.1007/s10514-020-09905-0", "report-no": null, "categories": "cs.RO cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel online learning algorithm, called SpCoSLAM 2.0, for\nspatial concepts and lexical acquisition with high accuracy and scalability.\nPreviously, we proposed SpCoSLAM as an online learning algorithm based on\nunsupervised Bayesian probabilistic model that integrates multimodal place\ncategorization, lexical acquisition, and SLAM. However, our original algorithm\nhad limited estimation accuracy owing to the influence of the early stages of\nlearning, and increased computational complexity with added training data.\nTherefore, we introduce techniques such as fixed-lag rejuvenation to reduce the\ncalculation time while maintaining an accuracy higher than that of the original\nalgorithm. The results show that, in terms of estimation accuracy, the proposed\nalgorithm exceeds the original algorithm and is comparable to batch learning.\nIn addition, the calculation time of the proposed algorithm does not depend on\nthe amount of training data and becomes constant for each step of the scalable\nalgorithm. Our approach will contribute to the realization of long-term spatial\nlanguage interactions between humans and robots.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 12:06:04 GMT"}, {"version": "v2", "created": "Fri, 4 Jan 2019 07:36:32 GMT"}, {"version": "v3", "created": "Mon, 10 Feb 2020 12:17:54 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Taniguchi", "Akira", ""], ["Hagiwara", "Yoshinobu", ""], ["Taniguchi", "Tadahiro", ""], ["Inamura", "Tetsunari", ""]]}, {"id": "1803.03585", "submitter": "Ke Tran", "authors": "Ke Tran and Arianna Bisazza and Christof Monz", "title": "The Importance of Being Recurrent for Modeling Hierarchical Structure", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that recurrent neural networks (RNNs) can implicitly\ncapture and exploit hierarchical information when trained to solve common\nnatural language processing tasks such as language modeling (Linzen et al.,\n2016) and neural machine translation (Shi et al., 2016). In contrast, the\nability to model structured data with non-recurrent neural networks has\nreceived little attention despite their success in many NLP tasks (Gehring et\nal., 2017; Vaswani et al., 2017). In this work, we compare the two\narchitectures---recurrent versus non-recurrent---with respect to their ability\nto model hierarchical structure and find that recurrency is indeed important\nfor this purpose.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 16:13:02 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 04:40:49 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Tran", "Ke", ""], ["Bisazza", "Arianna", ""], ["Monz", "Christof", ""]]}, {"id": "1803.03662", "submitter": "Ziqi Zhang", "authors": "Ziqi Zhang and Lei Luo", "title": "Hate Speech Detection: A Solved Problem? The Challenging Case of Long\n  Tail on Twitter", "comments": "Accepted @ the Semantic Web Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the increasing propagation of hate speech on social media\nand the urgent need for effective counter-measures have drawn significant\ninvestment from governments, companies, and researchers. A large number of\nmethods have been developed for automated hate speech detection online. This\naims to classify textual content into non-hate or hate speech, in which case\nthe method may also identify the targeting characteristics (i.e., types of\nhate, such as race, and religion) in the hate speech. However, we notice\nsignificant difference between the performance of the two (i.e., non-hate v.s.\nhate). In this work, we argue for a focus on the latter problem for practical\nreasons. We show that it is a much more challenging task, as our analysis of\nthe language in the typical datasets shows that hate speech lacks unique,\ndiscriminative features and therefore is found in the 'long tail' in a dataset\nthat is difficult to discover. We then propose Deep Neural Network structures\nserving as feature extractors that are particularly effective for capturing the\nsemantics of hate speech. Our methods are evaluated on the largest collection\nof hate speech datasets based on Twitter, and are shown to be able to\noutperform the best performing method by up to 5 percentage points in\nmacro-average F1, or 8 percentage points in the more challenging case of\nidentifying hateful content.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 20:49:51 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2018 12:48:11 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Zhang", "Ziqi", ""], ["Luo", "Lei", ""]]}, {"id": "1803.03664", "submitter": "Vishwajeet Kumar", "authors": "Vishwajeet Kumar, Kireeti Boorla, Yogesh Meena, Ganesh Ramakrishnan\n  and Yuan-Fang Li", "title": "Automating Reading Comprehension by Generating Question and Answer Pairs", "comments": "12 pages, 3 figures, 2 tables, Accepted for publication at 22nd\n  Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network-based methods represent the state-of-the-art in question\ngeneration from text. Existing work focuses on generating only questions from\ntext without concerning itself with answer generation. Moreover, our analysis\nshows that handling rare words and generating the most appropriate question\ngiven a candidate answer are still challenges facing existing approaches. We\npresent a novel two-stage process to generate question-answer pairs from the\ntext. For the first stage, we present alternatives for encoding the span of the\npivotal answer in the sentence using Pointer Networks. In our second stage, we\nemploy sequence to sequence models for question generation, enhanced with rich\nlinguistic features. Finally, global attention and answer encoding are used for\ngenerating the question most relevant to the answer. We motivate and\nlinguistically analyze the role of each component in our framework and consider\ncompositions of these. This analysis is supported by extensive experimental\nevaluations. Using standard evaluation metrics as well as human evaluations,\nour experimental results validate the significant improvement in the quality of\nquestions generated by our framework over the state-of-the-art. The technique\npresented here represents another step towards more automated reading\ncomprehension assessment. We also present a live system \\footnote{Demo of the\nsystem is available at\n\\url{https://www.cse.iitb.ac.in/~vishwajeet/autoqg.html}.} to demonstrate the\neffectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 07:55:11 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Kumar", "Vishwajeet", ""], ["Boorla", "Kireeti", ""], ["Meena", "Yogesh", ""], ["Ramakrishnan", "Ganesh", ""], ["Li", "Yuan-Fang", ""]]}, {"id": "1803.03665", "submitter": "Duncan Blythe", "authors": "Duncan Blythe and Alan Akbik and Roland Vollgraf", "title": "Syntax-Aware Language Modeling with Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural language models (LMs) are typically trained using only lexical\nfeatures, such as surface forms of words. In this paper, we argue this deprives\nthe LM of crucial syntactic signals that can be detected at high confidence\nusing existing parsers. We present a simple but highly effective approach for\ntraining neural LMs using both lexical and syntactic information, and a novel\napproach for applying such LMs to unparsed text using sequential Monte Carlo\nsampling. In experiments on a range of corpora and corpus sizes, we show our\napproach consistently outperforms standard lexical LMs in character-level\nlanguage modeling; on the other hand, for word-level models the models are on a\npar with standard language models. These results indicate potential for\nexpanding LMs beyond lexical surface features to higher-level NLP features for\ncharacter-level models.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 14:47:24 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Blythe", "Duncan", ""], ["Akbik", "Alan", ""], ["Vollgraf", "Roland", ""]]}, {"id": "1803.03667", "submitter": "Irina Legchenkova", "authors": "Evgeny Shulzinger, Irina Legchenkova and Edward Bormashenko", "title": "Co-occurrence of the Benford-like and Zipf Laws Arising from the Texts\n  Representing Human and Artificial Languages", "comments": "23 pages, 8 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL physics.soc-ph stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that large texts, representing human (English, Russian,\nUkrainian) and artificial (C++, Java) languages, display quantitative patterns\ncharacterized by the Benford-like and Zipf laws. The frequency of a word\nfollowing the Zipf law is inversely proportional to its rank, whereas the total\nnumbers of a certain word appearing in the text generate the uneven\nBenford-like distribution of leading numbers. Excluding the most popular words\nessentially improves the correlation of actual textual data with the Zipfian\ndistribution, whereas the Benford distribution of leading numbers (arising from\nthe overall amount of a certain word) is insensitive to the same elimination\nprocedure. The calculated values of the moduli of slopes of double\nlogarithmical plots for artificial languages (C++, Java) are markedly larger\nthan those for human ones.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 12:24:42 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Shulzinger", "Evgeny", ""], ["Legchenkova", "Irina", ""], ["Bormashenko", "Edward", ""]]}, {"id": "1803.03670", "submitter": "Jiwei Li", "authors": "Shuqing Bian, Zhenpeng Deng, Fei Li, Will Monroe, Peng Shi, Zijun Sun,\n  Wei Wu, Sikuang Wang, William Yang Wang, Arianna Yuan, Tianwei Zhang and\n  Jiwei Li", "title": "IcoRating: A Deep-Learning System for Scam ICO Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Cryptocurrencies (or digital tokens, digital currencies, e.g., BTC, ETH, XRP,\nNEO) have been rapidly gaining ground in use, value, and understanding among\nthe public, bringing astonishing profits to investors. Unlike other money and\nbanking systems, most digital tokens do not require central authorities. Being\ndecentralized poses significant challenges for credit rating. Most ICOs are\ncurrently not subject to government regulations, which makes a reliable credit\nrating system for ICO projects necessary and urgent.\n  In this paper, we introduce IcoRating, the first learning--based\ncryptocurrency rating system. We exploit natural-language processing techniques\nto analyze various aspects of 2,251 digital currencies to date, such as white\npaper content, founding teams, Github repositories, websites, etc. Supervised\nlearning models are used to correlate the life span and the price change of\ncryptocurrencies with these features. For the best setting, the proposed system\nis able to identify scam ICO projects with 0.83 precision.\n  We hope this work will help investors identify scam ICOs and attract more\nefforts in automatically evaluating and analyzing ICO projects.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 09:14:37 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Bian", "Shuqing", ""], ["Deng", "Zhenpeng", ""], ["Li", "Fei", ""], ["Monroe", "Will", ""], ["Shi", "Peng", ""], ["Sun", "Zijun", ""], ["Wu", "Wei", ""], ["Wang", "Sikuang", ""], ["Wang", "William Yang", ""], ["Yuan", "Arianna", ""], ["Zhang", "Tianwei", ""], ["Li", "Jiwei", ""]]}, {"id": "1803.03697", "submitter": "Srijan Kumar", "authors": "Srijan Kumar, William L. Hamilton, Jure Leskovec, Dan Jurafsky", "title": "Community Interaction and Conflict on the Web", "comments": "In WWW 2018: The Web Conference. Project website with data and code\n  is https://snap.stanford.edu/conflict/", "journal-ref": null, "doi": "10.1145/3178876.3186141", "report-no": null, "categories": "cs.SI cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Users organize themselves into communities on web platforms. These\ncommunities can interact with one another, often leading to conflicts and toxic\ninteractions. However, little is known about the mechanisms of interactions\nbetween communities and how they impact users.\n  Here we study intercommunity interactions across 36,000 communities on\nReddit, examining cases where users of one community are mobilized by negative\nsentiment to comment in another community. We show that such conflicts tend to\nbe initiated by a handful of communities---less than 1% of communities start\n74% of conflicts. While conflicts tend to be initiated by highly active\ncommunity members, they are carried out by significantly less active members.\nWe find that conflicts are marked by formation of echo chambers, where users\nprimarily talk to other users from their own community. In the long-term,\nconflicts have adverse effects and reduce the overall activity of users in the\ntargeted communities.\n  Our analysis of user interactions also suggests strategies for mitigating the\nnegative impact of conflicts---such as increasing direct engagement between\nattackers and defenders. Further, we accurately predict whether a conflict will\noccur by creating a novel LSTM model that combines graph embeddings, user,\ncommunity, and text features. This model can be used toreate early-warning\nsystems for community moderators to prevent conflicts. Altogether, this work\npresents a data-driven view of community interactions and conflict, and paves\nthe way towards healthier online communities.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 21:26:13 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Kumar", "Srijan", ""], ["Hamilton", "William L.", ""], ["Leskovec", "Jure", ""], ["Jurafsky", "Dan", ""]]}, {"id": "1803.03786", "submitter": "Georgi Karadzhov", "authors": "Georgi Karadzhov, Pepa Gencheva, Preslav Nakov, Ivan Koychev", "title": "We Built a Fake News & Click-bait Filter: What Happened Next Will Blow\n  Your Mind!", "comments": "RANLP'2017, 7 pages, 1 figure", "journal-ref": null, "doi": "10.26615/978-954-452-049-6_045", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is completely amazing! Fake news and click-baits have totally invaded the\ncyber space. Let us face it: everybody hates them for three simple reasons.\nReason #2 will absolutely amaze you. What these can achieve at the time of\nelection will completely blow your mind! Now, we all agree, this cannot go on,\nyou know, somebody has to stop it. So, we did this research on fake\nnews/click-bait detection and trust us, it is totally great research, it really\nis! Make no mistake. This is the best research ever! Seriously, come have a\nlook, we have it all: neural networks, attention mechanism, sentiment lexicons,\nauthor profiling, you name it. Lexical features, semantic features, we\nabsolutely have it all. And we have totally tested it, trust us! We have\nresults, and numbers, really big numbers. The best numbers ever! Oh, and\nanalysis, absolutely top notch analysis. Interested? Come read the shocking\ntruth about fake news and click-bait in the Bulgarian cyber space. You won't\nbelieve what we have found!\n", "versions": [{"version": "v1", "created": "Sat, 10 Mar 2018 10:09:13 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Karadzhov", "Georgi", ""], ["Gencheva", "Pepa", ""], ["Nakov", "Preslav", ""], ["Koychev", "Ivan", ""]]}, {"id": "1803.03827", "submitter": "Albert Gatt", "authors": "Albert Gatt, Marc Tanti, Adrian Muscat, Patrizia Paggio, Reuben A.\n  Farrugia, Claudia Borg, Kenneth P. Camilleri, Mike Rosner, Lonneke van der\n  Plas", "title": "Face2Text: Collecting an Annotated Image Description Corpus for the\n  Generation of Rich Face Descriptions", "comments": "Proceedings of the 11th edition of the Language Resources and\n  Evaluation Conference (LREC'18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The past few years have witnessed renewed interest in NLP tasks at the\ninterface between vision and language. One intensively-studied problem is that\nof automatically generating text from images. In this paper, we extend this\nproblem to the more specific domain of face description. Unlike scene\ndescriptions, face descriptions are more fine-grained and rely on attributes\nextracted from the image, rather than objects and relations. Given that no data\nexists for this task, we present an ongoing crowdsourcing study to collect a\ncorpus of descriptions of face images taken `in the wild'. To gain a better\nunderstanding of the variation we find in face description and the possible\nissues that this may raise, we also conducted an annotation study on a subset\nof the corpus. Primarily, we found descriptions to refer to a mixture of\nattributes, not only physical, but also emotional and inferential, which is\nbound to create further challenges for current image-to-text methods.\n", "versions": [{"version": "v1", "created": "Sat, 10 Mar 2018 15:52:08 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 07:32:51 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Gatt", "Albert", ""], ["Tanti", "Marc", ""], ["Muscat", "Adrian", ""], ["Paggio", "Patrizia", ""], ["Farrugia", "Reuben A.", ""], ["Borg", "Claudia", ""], ["Camilleri", "Kenneth P.", ""], ["Rosner", "Mike", ""], ["van der Plas", "Lonneke", ""]]}, {"id": "1803.03859", "submitter": "Soumil Mandal", "authors": "Soumil Mandal, Sourya Dipta Das, Dipankar Das", "title": "Language Identification of Bengali-English Code-Mixed data using\n  Character & Phonetic based LSTM Models", "comments": "6 pages, 5 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Language identification of social media text still remains a challenging task\ndue to properties like code-mixing and inconsistent phonetic transliterations.\nIn this paper, we present a supervised learning approach for language\nidentification at the word level of low resource Bengali-English code-mixed\ndata taken from social media. We employ two methods of word encoding, namely\ncharacter based and root phone based to train our deep LSTM models. Utilizing\nthese two models we created two ensemble models using stacking and threshold\ntechnique which gave 91.78% and 92.35% accuracies respectively on our testing\ndata.\n", "versions": [{"version": "v1", "created": "Sat, 10 Mar 2018 20:38:55 GMT"}, {"version": "v2", "created": "Wed, 27 Jun 2018 16:26:55 GMT"}], "update_date": "2018-06-28", "authors_parsed": [["Mandal", "Soumil", ""], ["Das", "Sourya Dipta", ""], ["Das", "Dipankar", ""]]}, {"id": "1803.03887", "submitter": "Hai Hu", "authors": "Hai Hu, Yiwen Zhang", "title": "Path of Vowel Raising in Chengdu Dialect of Mandarin", "comments": "to appear in the Proceedings of 29th North America Conference on\n  Chinese Linguistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  He and Rao (2013) reported a raising phenomenon of /a/ in /Xan/ (X being a\nconsonant or a vowel) in Chengdu dialect of Mandarin, i.e. /a/ is realized as\n[epsilon] for young speakers but [ae] for older speakers, but they offered no\nacoustic analysis. We designed an acoustic study that examined the realization\nof /Xan/ in speakers of different age (old vs. young) and gender (male vs.\nfemale) groups, where X represents three conditions: 1) unaspirated consonants:\nC ([p], [t], [k]), 2) aspirated consonants: Ch ([ph], [th], [kh]), and 3) high\nvowels: V ([i], [y], [u]). 17 native speakers were asked to read /Xan/\ncharacters and the F1 values are extracted for comparison. Our results\nconfirmed the raising effect in He and Rao (2013), i.e., young speakers realize\n/a/ as [epsilon] in /an/, whereas older speakers in the most part realize it as\n[ae]. Also, female speakers raise more than male speakers within the same age\ngroup. Interestingly, within the /Van/ condition, older speakers do raise /a/\nin /ian/ and /yan/. We interpret this as /a/ first assimilates to its preceding\nfront high vowels /i/ and /y/ for older speakers, which then becomes\nphonologized in younger speakers in all conditions, including /Chan/ and /Can/.\nThis shows a possible trajectory of the ongoing sound change in the Chengdu\ndialect.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2018 02:58:40 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Hu", "Hai", ""], ["Zhang", "Yiwen", ""]]}, {"id": "1803.03917", "submitter": "Will Monroe", "authors": "Will Monroe, Jennifer Hu, Andrew Jong, Christopher Potts", "title": "Generating Bilingual Pragmatic Color References", "comments": "11 pages including appendices, 7 figures, 3 tables. NAACL-HLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Contextual influences on language often exhibit substantial cross-lingual\nregularities; for example, we are more verbose in situations that require finer\ndistinctions. However, these regularities are sometimes obscured by semantic\nand syntactic differences. Using a newly-collected dataset of color reference\ngames in Mandarin Chinese (which we release to the public), we confirm that a\nvariety of constructions display the same sensitivity to contextual difficulty\nin Chinese and English. We then show that a neural speaker agent trained on\nbilingual data with a simple multitask learning approach displays more\nhuman-like patterns of context dependence and is more pragmatically informative\nthan its monolingual Chinese counterpart. Moreover, this is not at the expense\nof language-specific semantic understanding: the resulting speaker model learns\nthe different basic color term systems of English and Chinese (with noteworthy\ncross-lingual influences), and it can identify synonyms between the two\nlanguages using vector analogy operations on its output layer, despite having\nno exposure to parallel data.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2018 07:05:50 GMT"}, {"version": "v2", "created": "Sat, 19 May 2018 00:56:23 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Monroe", "Will", ""], ["Hu", "Jennifer", ""], ["Jong", "Andrew", ""], ["Potts", "Christopher", ""]]}, {"id": "1803.04000", "submitter": "Soumil Mandal", "authors": "Soumil Mandal, Sainik Kumar Mahata, Dipankar Das", "title": "Preparing Bengali-English Code-Mixed Corpus for Sentiment Analysis of\n  Indian Languages", "comments": "The 13th Workshop on Asian Language Resources (ALR), collocated with\n  LREC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Analysis of informative contents and sentiments of social users has been\nattempted quite intensively in the recent past. Most of the systems are usable\nonly for monolingual data and fails or gives poor results when used on data\nwith code-mixing property. To gather attention and encourage researchers to\nwork on this crisis, we prepared gold standard Bengali-English code-mixed data\nwith language and polarity tag for sentiment analysis purposes. In this paper,\nwe discuss the systems we prepared to collect and filter raw Twitter data. In\norder to reduce manual work while annotation, hybrid systems combining rule\nbased and supervised models were developed for both language and sentiment\ntagging. The final corpus was annotated by a group of annotators following a\nfew guidelines. The gold standard corpus thus obtained has impressive\ninter-annotator agreement obtained in terms of Kappa values. Various metrics\nlike Code-Mixed Index (CMI), Code-Mixed Factor (CF) along with various aspects\n(language and emotion) also qualitatively polled the code-mixed and sentiment\nproperties of the corpus.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2018 18:13:01 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Mandal", "Soumil", ""], ["Mahata", "Sainik Kumar", ""], ["Das", "Dipankar", ""]]}, {"id": "1803.04291", "submitter": "Mohammad Sadegh Rasooli", "authors": "Mohammad Sadegh Rasooli, Sarangarajan Parthasarathy", "title": "Entity-Aware Language Model as an Unsupervised Reranker", "comments": null, "journal-ref": "Interspeech 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In language modeling, it is difficult to incorporate entity relationships\nfrom a knowledge-base. One solution is to use a reranker trained with global\nfeatures, in which global features are derived from n-best lists. However,\ntraining such a reranker requires manually annotated n-best lists, which is\nexpensive to obtain. We propose a method based on the contrastive estimation\nmethod that alleviates the need for such data. Experiments in the music domain\ndemonstrate that global features, as well as features extracted from an\nexternal knowledge-base, can be incorporated into our reranker. Our final\nmodel, a simple ensemble of a language model and reranker, achieves a 0.44\\%\nabsolute word error rate improvement over an LSTM language model on the blind\ntest data.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 14:47:43 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2018 02:33:00 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Rasooli", "Mohammad Sadegh", ""], ["Parthasarathy", "Sarangarajan", ""]]}, {"id": "1803.04329", "submitter": "Fabiano Ferreira Luz", "authors": "Fabiano Ferreira Luz and Marcelo Finger", "title": "Semantic Parsing Natural Language into SPARQL: Improving Target Language\n  Representation with Neural Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic parsing is the process of mapping a natural language sentence into a\nformal representation of its meaning. In this work we use the neural network\napproach to transform natural language sentence into a query to an ontology\ndatabase in the SPARQL language. This method does not rely on handcraft-rules,\nhigh-quality lexicons, manually-built templates or other handmade complex\nstructures. Our approach is based on vector space model and neural networks.\nThe proposed model is based in two learning steps. The first step generates a\nvector representation for the sentence in natural language and SPARQL query.\nThe second step uses this vector representation as input to a neural network\n(LSTM with attention mechanism) to generate a model able to encode natural\nlanguage and decode SPARQL.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 15:59:10 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Luz", "Fabiano Ferreira", ""], ["Finger", "Marcelo", ""]]}, {"id": "1803.04349", "submitter": "Finn {\\AA}rup Nielsen", "authors": "Finn {\\AA}rup Nielsen", "title": "Linking ImageNet WordNet Synsets with Wikidata", "comments": "6 pages, Wiki Workshop 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The linkage of ImageNet WordNet synsets to Wikidata items will leverage deep\nlearning algorithm with access to a rich multilingual knowledge graph. Here I\nwill describe our on-going efforts in linking the two resources and issues\nfaced in matching the Wikidata and WordNet knowledge graphs. I show an example\non how the linkage can be used in a deep learning setting with real-time image\nclassification and labeling in a non-English language and discuss what\nopportunities lies ahead.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 17:07:44 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Nielsen", "Finn \u00c5rup", ""]]}, {"id": "1803.04375", "submitter": "Quang Nhat Minh Pham Mr", "authors": "Pham Quang Nhat Minh", "title": "A Feature-Rich Vietnamese Named-Entity Recognition Model", "comments": "12 pages, pre-print version of CICLing 2018 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a feature-based named-entity recognition (NER)\nmodel that achieves the start-of-the-art accuracy for Vietnamese language. We\ncombine word, word-shape features, PoS, chunk, Brown-cluster-based features,\nand word-embedding-based features in the Conditional Random Fields (CRF) model.\nWe also explore the effects of word segmentation, PoS tagging, and chunking\nresults of many popular Vietnamese NLP toolkits on the accuracy of the proposed\nfeature-based NER model. Up to now, our work is the first work that\nsystematically performs an extrinsic evaluation of basic Vietnamese NLP\ntoolkits on the downstream NER task. Experimental results show that while\nautomatically-generated word segmentation is useful, PoS and chunking\ninformation generated by Vietnamese NLP tools does not show their benefits for\nthe proposed feature-based NER model.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 17:07:40 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Minh", "Pham Quang Nhat", ""]]}, {"id": "1803.04488", "submitter": "Tommaso Soru", "authors": "Faisal Alshargi, Saeedeh Shekarpour, Tommaso Soru, Amit Sheth", "title": "Concept2vec: Metrics for Evaluating Quality of Embeddings for\n  Ontological Concepts", "comments": "Spring Symposium on Combining Machine Learning with Knowledge\n  Engineering (AAAI-MAKE 2019)", "journal-ref": "CEUR-WS 2350 (2019) 26", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although there is an emerging trend towards generating embeddings for\nprimarily unstructured data and, recently, for structured data, no systematic\nsuite for measuring the quality of embeddings has been proposed yet. This\ndeficiency is further sensed with respect to embeddings generated for\nstructured data because there are no concrete evaluation metrics measuring the\nquality of the encoded structure as well as semantic patterns in the embedding\nspace. In this paper, we introduce a framework containing three distinct tasks\nconcerned with the individual aspects of ontological concepts: (i) the\ncategorization aspect, (ii) the hierarchical aspect, and (iii) the relational\naspect. Then, in the scope of each task, a number of intrinsic metrics are\nproposed for evaluating the quality of the embeddings. Furthermore, w.r.t. this\nframework, multiple experimental studies were run to compare the quality of the\navailable embedding models. Employing this framework in future research can\nreduce misjudgment and provide greater insight about quality comparisons of\nembeddings for ontological concepts. We positioned our sampled data and code at\nhttps://github.com/alshargi/Concept2vec under GNU General Public License v3.0.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 19:46:10 GMT"}, {"version": "v2", "created": "Thu, 26 Jul 2018 09:16:45 GMT"}, {"version": "v3", "created": "Fri, 8 May 2020 09:15:17 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Alshargi", "Faisal", ""], ["Shekarpour", "Saeedeh", ""], ["Soru", "Tommaso", ""], ["Sheth", "Amit", ""]]}, {"id": "1803.04579", "submitter": "Ankur Taly", "authors": "Pramod Kaushik Mudrakarta, Ankur Taly, Mukund Sundararajan, Kedar\n  Dhamdhere", "title": "It was the training data pruning too!", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the current best model (KDG) for question answering on tabular data\nevaluated over the WikiTableQuestions dataset. Previous ablation studies\nperformed against this model attributed the model's performance to certain\naspects of its architecture. In this paper, we find that the model's\nperformance also crucially depends on a certain pruning of the data used to\ntrain the model. Disabling the pruning step drops the accuracy of the model\nfrom 43.3% to 36.3%. The large impact on the performance of the KDG model\nsuggests that the pruning may be a useful pre-processing step in training other\nsemantic parsers as well.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 23:59:37 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Mudrakarta", "Pramod Kaushik", ""], ["Taly", "Ankur", ""], ["Sundararajan", "Mukund", ""], ["Dhamdhere", "Kedar", ""]]}, {"id": "1803.04596", "submitter": "Tom De Smedt", "authors": "Tom De Smedt, Guy De Pauw, Pieter Van Ostaeyen", "title": "Automatic Detection of Online Jihadist Hate Speech", "comments": "31 pages", "journal-ref": "CLiPS Technical Report Series 7 (2018) 1-31", "doi": null, "report-no": "CTRS-007", "categories": "cs.CL cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have developed a system that automatically detects online jihadist hate\nspeech with over 80% accuracy, by using techniques from Natural Language\nProcessing and Machine Learning. The system is trained on a corpus of 45,000\nsubversive Twitter messages collected from October 2014 to December 2016. We\npresent a qualitative and quantitative analysis of the jihadist rhetoric in the\ncorpus, examine the network of Twitter users, outline the technical procedure\nused to train the system, and discuss examples of use.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 02:09:06 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["De Smedt", "Tom", ""], ["De Pauw", "Guy", ""], ["Van Ostaeyen", "Pieter", ""]]}, {"id": "1803.04715", "submitter": "Nghi Bui", "authors": "Nghi D. Q. Bui, Lingxiao Jiang", "title": "Hierarchical Learning of Cross-Language Mappings through Distributed\n  Vector Representations for Code", "comments": "Accepted at ICSE'18", "journal-ref": null, "doi": "10.1145/3183399.3183427", "report-no": null, "categories": "cs.LG cs.CL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Translating a program written in one programming language to another can be\nuseful for software development tasks that need functionality implementations\nin different languages. Although past studies have considered this problem,\nthey may be either specific to the language grammars, or specific to certain\nkinds of code elements (e.g., tokens, phrases, API uses). This paper proposes a\nnew approach to automatically learn cross-language representations for various\nkinds of structural code elements that may be used for program translation. Our\nkey idea is two folded: First, we normalize and enrich code token streams with\nadditional structural and semantic information, and train cross-language vector\nrepresentations for the tokens (a.k.a. shared embeddings based on word2vec, a\nneural-network-based technique for producing word embeddings; Second,\nhierarchically from bottom up, we construct shared embeddings for code elements\nof higher levels of granularity (e.g., expressions, statements, methods) from\nthe embeddings for their constituents, and then build mappings among code\nelements across languages based on similarities among embeddings.\n  Our preliminary evaluations on about 40,000 Java and C# source files from 9\nsoftware projects show that our approach can automatically learn shared\nembeddings for various code elements in different languages and identify their\ncross-language mappings with reasonable Mean Average Precision scores. When\ncompared with an existing tool for mapping library API methods, our approach\nidentifies many more mappings accurately. The mapping results and code can be\naccessed at\nhttps://github.com/bdqnghi/hierarchical-programming-language-mapping. We\nbelieve that our idea for learning cross-language vector representations with\ncode structural information can be a useful step towards automated program\ntranslation.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 10:30:55 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Bui", "Nghi D. Q.", ""], ["Jiang", "Lingxiao", ""]]}, {"id": "1803.04757", "submitter": "Magnus Sahlgren", "authors": "Tim Isbister, Magnus Sahlgren, Lisa Kaati, Milan Obaidi, Nazar Akrami", "title": "Monitoring Targeted Hate in Online Environments", "comments": "Accepted for publication at the second workshop on Text Analytics for\n  Cybersecurity and Online Safety (TA-COS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hateful comments, swearwords and sometimes even death threats are becoming a\nreality for many people today in online environments. This is especially true\nfor journalists, politicians, artists, and other public figures. This paper\ndescribes how hate directed towards individuals can be measured in online\nenvironments using a simple dictionary-based approach. We present a case study\non Swedish politicians, and use examples from this study to discuss\nshortcomings of the proposed dictionary-based approach. We also outline\npossibilities for potential refinements of the proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 12:56:27 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Isbister", "Tim", ""], ["Sahlgren", "Magnus", ""], ["Kaati", "Lisa", ""], ["Obaidi", "Milan", ""], ["Akrami", "Nazar", ""]]}, {"id": "1803.04790", "submitter": "Yufang Hou", "authors": "Yufang Hou", "title": "Enhanced Word Representations for Bridging Anaphora Resolution", "comments": "To appear in NAACL2018 (the final version will be forthcoming)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most current models of word representations(e.g.,GloVe) have successfully\ncaptured fine-grained semantics. However, semantic similarity exhibited in\nthese word embeddings is not suitable for resolving bridging anaphora, which\nrequires the knowledge of associative similarity (i.e., relatedness) instead of\nsemantic similarity information between synonyms or hypernyms. We create word\nembeddings (embeddings_PP) to capture such relatedness by exploring the\nsyntactic structure of noun phrases. We demonstrate that using embeddings_PP\nalone achieves around 30% of accuracy for bridging anaphora resolution on the\nISNotes corpus. Furthermore, we achieve a substantial gain over the\nstate-of-the-art system (Hou et al., 2013) for bridging antecedent selection.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 13:33:06 GMT"}, {"version": "v2", "created": "Fri, 13 Apr 2018 16:10:18 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Hou", "Yufang", ""]]}, {"id": "1803.04884", "submitter": "Torsten Kilias", "authors": "Torsten Kilias, Alexander L\\\"oser, Felix A. Gers, Richard\n  Koopmanschap, Ying Zhang, Martin Kersten", "title": "IDEL: In-Database Entity Linking with Neural Embeddings", "comments": "This manuscript is a preprint for a paper submitted to VLDB2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CL cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a novel architecture, In-Database Entity Linking (IDEL), in which\nwe integrate the analytics-optimized RDBMS MonetDB with neural text mining\nabilities. Our system design abstracts core tasks of most neural entity linking\nsystems for MonetDB. To the best of our knowledge, this is the first defacto\nimplemented system integrating entity-linking in a database. We leverage the\nability of MonetDB to support in-database-analytics with user defined functions\n(UDFs) implemented in Python. These functions call machine learning libraries\nfor neural text mining, such as TensorFlow. The system achieves zero cost for\ndata shipping and transformation by utilizing MonetDB's ability to embed Python\nprocesses in the database kernel and exchange data in NumPy arrays. IDEL\nrepresents text and relational data in a joint vector space with neural\nembeddings and can compensate errors with ambiguous entity representations. For\ndetecting matching entities, we propose a novel similarity function based on\njoint neural embeddings which are learned via minimizing pairwise contrastive\nranking loss. This function utilizes a high dimensional index structures for\nfast retrieval of matching entities. Our first implementation and experiments\nusing the WebNLG corpus show the effectiveness and the potentials of IDEL.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 15:35:42 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Kilias", "Torsten", ""], ["L\u00f6ser", "Alexander", ""], ["Gers", "Felix A.", ""], ["Koopmanschap", "Richard", ""], ["Zhang", "Ying", ""], ["Kersten", "Martin", ""]]}, {"id": "1803.05030", "submitter": "ShiLiang Zhang", "authors": "Shiliang Zhang, Ming Lei, Zhijie Yan, Lirong Dai", "title": "Deep-FSMN for Large Vocabulary Continuous Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an improved feedforward sequential memory networks\n(FSMN) architecture, namely Deep-FSMN (DFSMN), by introducing skip connections\nbetween memory blocks in adjacent layers. These skip connections enable the\ninformation flow across different layers and thus alleviate the gradient\nvanishing problem when building very deep structure. As a result, DFSMN\nsignificantly benefits from these skip connections and deep structure. We have\ncompared the performance of DFSMN to BLSTM both with and without lower frame\nrate (LFR) on several large speech recognition tasks, including English and\nMandarin. Experimental results shown that DFSMN can consistently outperform\nBLSTM with dramatic gain, especially trained with LFR using CD-Phone as\nmodeling units. In the 2000 hours Fisher (FSH) task, the proposed DFSMN can\nachieve a word error rate of 9.4% by purely using the cross-entropy criterion\nand decoding with a 3-gram language model, which achieves a 1.5% absolute\nimprovement compared to the BLSTM. In a 20000 hours Mandarin recognition task,\nthe LFR trained DFSMN can achieve more than 20% relative improvement compared\nto the LFR trained BLSTM. Moreover, we can easily design the lookahead filter\norder of the memory blocks in DFSMN to control the latency for real-time\napplications.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 11:08:16 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Zhang", "Shiliang", ""], ["Lei", "Ming", ""], ["Yan", "Zhijie", ""], ["Dai", "Lirong", ""]]}, {"id": "1803.05058", "submitter": "Martha Larson", "authors": "Odette Scharenborg and Martha Larson", "title": "Investigating the Effect of Music and Lyrics on Spoken-Word Recognition", "comments": "Preliminary study", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background music in social interaction settings can hinder conversation. Yet,\nlittle is known of how specific properties of music impact speech processing.\nThis paper addresses this knowledge gap by investigating 1) whether the masking\neffect of background music with lyrics is larger than that of music without\nlyrics, and 2) whether the masking effect is larger for more complex music. To\nanswer these questions, a word identification experiment was run in which Dutch\nparticipants listened to Dutch CVC words embedded in stretches of background\nmusic in two conditions, with and without lyrics, and at three SNRs. Three\nsongs were used of different genres and complexities. Music stretches with and\nwithout lyrics were sampled from the same song in order to control for factors\nbeyond the presence of lyrics. The results showed a clear negative impact of\nthe presence of lyrics in background music on spoken-word recognition. This\nimpact is independent of complexity. The results suggest that social spaces\n(e.g., restaurants, caf\\'es and bars) should make careful choices of music to\npromote conversation, and open a path for future work.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 21:40:59 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Scharenborg", "Odette", ""], ["Larson", "Martha", ""]]}, {"id": "1803.05071", "submitter": "Jacob Buckman", "authors": "Jacob Buckman, Graham Neubig", "title": "Neural Lattice Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a new language modeling paradigm that has the\nability to perform both prediction and moderation of information flow at\nmultiple granularities: neural lattice language models. These models construct\na lattice of possible paths through a sentence and marginalize across this\nlattice to calculate sequence probabilities or optimize parameters. This\napproach allows us to seamlessly incorporate linguistic intuitions - including\npolysemy and existence of multi-word lexical items - into our language model.\nExperiments on multiple language modeling tasks show that English neural\nlattice language models that utilize polysemous embeddings are able to improve\nperplexity by 9.95% relative to a word-level baseline, and that a Chinese model\nthat handles multi-character tokens is able to improve perplexity by 20.94%\nrelative to a character-level baseline.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 23:13:58 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Buckman", "Jacob", ""], ["Neubig", "Graham", ""]]}, {"id": "1803.05160", "submitter": "Igor Mozeti\\v{c}", "authors": "Igor Mozeti\\v{c}, Luis Torgo, Vitor Cerqueira, Jasmina Smailovi\\'c", "title": "How to evaluate sentiment classifiers for Twitter time-ordered data?", "comments": null, "journal-ref": "PLoS ONE 13(3): e0194317, 2018", "doi": "10.1371/journal.pone.0194317", "report-no": null, "categories": "cs.CL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media are becoming an increasingly important source of information\nabout the public mood regarding issues such as elections, Brexit, stock market,\netc. In this paper we focus on sentiment classification of Twitter data.\nConstruction of sentiment classifiers is a standard text mining task, but here\nwe address the question of how to properly evaluate them as there is no settled\nway to do so. Sentiment classes are ordered and unbalanced, and Twitter\nproduces a stream of time-ordered data. The problem we address concerns the\nprocedures used to obtain reliable estimates of performance measures, and\nwhether the temporal ordering of the training and test data matters. We\ncollected a large set of 1.5 million tweets in 13 European languages. We\ncreated 138 sentiment models and out-of-sample datasets, which are used as a\ngold standard for evaluations. The corresponding 138 in-sample datasets are\nused to empirically compare six different estimation procedures: three variants\nof cross-validation, and three variants of sequential validation (where test\nset always follows the training set). We find no significant difference between\nthe best cross-validation and sequential validation. However, we observe that\nall cross-validation variants tend to overestimate the performance, while the\nsequential methods tend to underestimate it. Standard cross-validation with\nrandom selection of examples is significantly worse than the blocked\ncross-validation, and should not be used to evaluate classifiers in\ntime-ordered data scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 08:16:48 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Mozeti\u010d", "Igor", ""], ["Torgo", "Luis", ""], ["Cerqueira", "Vitor", ""], ["Smailovi\u0107", "Jasmina", ""]]}, {"id": "1803.05223", "submitter": "Simon Ostermann", "authors": "Simon Ostermann, Ashutosh Modi, Michael Roth, Stefan Thater, Manfred\n  Pinkal", "title": "MCScript: A Novel Dataset for Assessing Machine Comprehension Using\n  Script Knowledge", "comments": "Accepted at LREC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a large dataset of narrative texts and questions about these\ntexts, intended to be used in a machine comprehension task that requires\nreasoning using commonsense knowledge. Our dataset complements similar datasets\nin that we focus on stories about everyday activities, such as going to the\nmovies or working in the garden, and that the questions require commonsense\nknowledge, or more specifically, script knowledge, to be answered. We show that\nour mode of data collection via crowdsourcing results in a substantial amount\nof such inference questions. The dataset forms the basis of a shared task on\ncommonsense and script knowledge organized at SemEval 2018 and provides\nchallenging test cases for the broader natural language understanding\ncommunity.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 11:59:13 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Ostermann", "Simon", ""], ["Modi", "Ashutosh", ""], ["Roth", "Michael", ""], ["Thater", "Stefan", ""], ["Pinkal", "Manfred", ""]]}, {"id": "1803.05307", "submitter": "Sergey Novoselov", "authors": "Sergey Novoselov, Oleg Kudashev, Vadim Schemelinin, Ivan Kremnev and\n  Galina Lavrentyeva", "title": "Deep CNN based feature extractor for text-prompted speaker recognition", "comments": "Submitted to ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is still not a very common tool in speaker verification field.\nWe study deep convolutional neural network performance in the text-prompted\nspeaker verification task. The prompted passphrase is segmented into word\nstates - i.e. digits -to test each digit utterance separately. We train a\nsingle high-level feature extractor for all states and use cosine similarity\nmetric for scoring. The key feature of our network is the Max-Feature-Map\nactivation function, which acts as an embedded feature selector. By using\nmultitask learning scheme to train the high-level feature extractor we were\nable to surpass the classic baseline systems in terms of quality and achieved\nimpressive results for such a novice approach, getting 2.85% EER on the RSR2015\nevaluation set. Fusion of the proposed and the baseline systems improves this\nresult.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 10:59:24 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Novoselov", "Sergey", ""], ["Kudashev", "Oleg", ""], ["Schemelinin", "Vadim", ""], ["Kremnev", "Ivan", ""], ["Lavrentyeva", "Galina", ""]]}, {"id": "1803.05355", "submitter": "James Thorne", "authors": "James Thorne, Andreas Vlachos, Christos Christodoulopoulos and Arpit\n  Mittal", "title": "FEVER: a large-scale dataset for Fact Extraction and VERification", "comments": "Updated version of NAACL2018 paper. Data is released on\n  http://fever.ai", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a new publicly available dataset for verification\nagainst textual sources, FEVER: Fact Extraction and VERification. It consists\nof 185,445 claims generated by altering sentences extracted from Wikipedia and\nsubsequently verified without knowledge of the sentence they were derived from.\nThe claims are classified as Supported, Refuted or NotEnoughInfo by annotators\nachieving 0.6841 in Fleiss $\\kappa$. For the first two classes, the annotators\nalso recorded the sentence(s) forming the necessary evidence for their\njudgment. To characterize the challenge of the dataset presented, we develop a\npipeline approach and compare it to suitably designed oracles. The best\naccuracy we achieve on labeling a claim accompanied by the correct evidence is\n31.87%, while if we ignore the evidence we achieve 50.91%. Thus we believe that\nFEVER is a challenging testbed that will help stimulate progress on claim\nverification against textual sources.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 15:30:37 GMT"}, {"version": "v2", "created": "Mon, 16 Apr 2018 23:08:25 GMT"}, {"version": "v3", "created": "Tue, 18 Dec 2018 10:58:20 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Thorne", "James", ""], ["Vlachos", "Andreas", ""], ["Christodoulopoulos", "Christos", ""], ["Mittal", "Arpit", ""]]}, {"id": "1803.05449", "submitter": "Alexis Conneau", "authors": "Alexis Conneau and Douwe Kiela", "title": "SentEval: An Evaluation Toolkit for Universal Sentence Representations", "comments": "LREC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce SentEval, a toolkit for evaluating the quality of universal\nsentence representations. SentEval encompasses a variety of tasks, including\nbinary and multi-class classification, natural language inference and sentence\nsimilarity. The set of tasks was selected based on what appears to be the\ncommunity consensus regarding the appropriate evaluations for universal\nsentence representations. The toolkit comes with scripts to download and\npreprocess datasets, and an easy interface to evaluate sentence encoders. The\naim is to provide a fairer, less cumbersome and more centralized way for\nevaluating sentence representations.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 18:01:15 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Conneau", "Alexis", ""], ["Kiela", "Douwe", ""]]}, {"id": "1803.05457", "submitter": "Carissa Schoenick", "authors": "Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish\n  Sabharwal, Carissa Schoenick, Oyvind Tafjord", "title": "Think you have Solved Question Answering? Try ARC, the AI2 Reasoning\n  Challenge", "comments": "10 pages, 7 tables, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new question set, text corpus, and baselines assembled to\nencourage AI research in advanced question answering. Together, these\nconstitute the AI2 Reasoning Challenge (ARC), which requires far more powerful\nknowledge and reasoning than previous challenges such as SQuAD or SNLI. The ARC\nquestion set is partitioned into a Challenge Set and an Easy Set, where the\nChallenge Set contains only questions answered incorrectly by both a\nretrieval-based algorithm and a word co-occurence algorithm. The dataset\ncontains only natural, grade-school science questions (authored for human\ntests), and is the largest public-domain set of this kind (7,787 questions). We\ntest several baselines on the Challenge Set, including leading neural models\nfrom the SQuAD and SNLI tasks, and find that none are able to significantly\noutperform a random baseline, reflecting the difficult nature of this task. We\nare also releasing the ARC Corpus, a corpus of 14M science sentences relevant\nto the task, and implementations of the three neural baseline models tested.\nCan your model perform better? We pose ARC as a challenge to the community.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 18:04:21 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Clark", "Peter", ""], ["Cowhey", "Isaac", ""], ["Etzioni", "Oren", ""], ["Khot", "Tushar", ""], ["Sabharwal", "Ashish", ""], ["Schoenick", "Carissa", ""], ["Tafjord", "Oyvind", ""]]}, {"id": "1803.05495", "submitter": "Marcos Zampieri", "authors": "Shervin Malmasi, Marcos Zampieri", "title": "Challenges in Discriminating Profanity from Hate Speech", "comments": null, "journal-ref": "Shervin Malmasi, Marcos Zampieri (2018) Challenges in\n  Discriminating Profanity from Hate Speech. Journal of Experimental &\n  Theoretical Artificial Intelligence. Volume 30, Issue 2, pp. 187-202. Taylor\n  & Francis", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study we approach the problem of distinguishing general profanity\nfrom hate speech in social media, something which has not been widely\nconsidered. Using a new dataset annotated specifically for this task, we employ\nsupervised classification along with a set of features that includes n-grams,\nskip-grams and clustering-based word representations. We apply approaches based\non single classifiers as well as more advanced ensemble classifiers and stacked\ngeneralization, achieving the best result of 80% accuracy for this 3-class\nclassification task. Analysis of the results reveals that discriminating hate\nspeech and profanity is not a simple task, which may require features that\ncapture a deeper understanding of the text not always possible with surface\nn-grams. The variability of gold labels in the annotated data, due to\ndifferences in the subjective adjudications of the annotators, is also an\nissue. Other directions for future work are discussed.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 20:00:08 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Malmasi", "Shervin", ""], ["Zampieri", "Marcos", ""]]}, {"id": "1803.05547", "submitter": "Siddarth Srinivasan", "authors": "Siddarth Srinivasan, Richa Arora, Mark Riedl", "title": "A Simple and Effective Approach to the Story Cloze Test", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Story Cloze Test, a system is presented with a 4-sentence prompt to a\nstory, and must determine which one of two potential endings is the 'right'\nending to the story. Previous work has shown that ignoring the training set and\ntraining a model on the validation set can achieve high accuracy on this task\ndue to stylistic differences between the story endings in the training set and\nvalidation and test sets. Following this approach, we present a simpler\nfully-neural approach to the Story Cloze Test using skip-thought embeddings of\nthe stories in a feed-forward network that achieves close to state-of-the-art\nperformance on this task without any feature engineering. We also find that\nconsidering just the last sentence of the prompt instead of the whole prompt\nyields higher accuracy with our approach.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 00:16:43 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Srinivasan", "Siddarth", ""], ["Arora", "Richa", ""], ["Riedl", "Mark", ""]]}, {"id": "1803.05563", "submitter": "Jinyu Li", "authors": "Amit Das, Jinyu Li, Rui Zhao, Yifan Gong", "title": "Advancing Connectionist Temporal Classification With Attention Modeling", "comments": "Accepted at ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we propose advancing all-neural speech recognition by directly\nincorporating attention modeling within the Connectionist Temporal\nClassification (CTC) framework. In particular, we derive new context vectors\nusing time convolution features to model attention as part of the CTC network.\nTo further improve attention modeling, we utilize content information extracted\nfrom a network representing an implicit language model. Finally, we introduce\nvector based attention weights that are applied on context vectors across both\ntime and their individual components. We evaluate our system on a 3400 hours\nMicrosoft Cortana voice assistant task and demonstrate that our proposed model\nconsistently outperforms the baseline model achieving about 20% relative\nreduction in word error rates.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 01:19:21 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Das", "Amit", ""], ["Li", "Jinyu", ""], ["Zhao", "Rui", ""], ["Gong", "Yifan", ""]]}, {"id": "1803.05566", "submitter": "Jinyu Li", "authors": "Jinyu Li, Guoli Ye, Amit Das, Rui Zhao, Yifan Gong", "title": "Advancing Acoustic-to-Word CTC Model", "comments": "Accepted at ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The acoustic-to-word model based on the connectionist temporal classification\n(CTC) criterion was shown as a natural end-to-end (E2E) model directly\ntargeting words as output units. However, the word-based CTC model suffers from\nthe out-of-vocabulary (OOV) issue as it can only model limited number of words\nin the output layer and maps all the remaining words into an OOV output node.\nHence, such a word-based CTC model can only recognize the frequent words\nmodeled by the network output nodes. Our first attempt to improve the\nacoustic-to-word model is a hybrid CTC model which consults a letter-based CTC\nwhen the word-based CTC model emits OOV tokens during testing time. Then, we\npropose a much better solution by training a mixed-unit CTC model which\ndecomposes all the OOV words into sequences of frequent words and multi-letter\nunits. Evaluated on a 3400 hours Microsoft Cortana voice assistant task, the\nfinal acoustic-to-word solution improves the baseline word-based CTC by\nrelative 12.09% word error rate (WER) reduction when combined with our proposed\nattention CTC. Such an E2E model without using any language model (LM) or\ncomplex decoder outperforms the traditional context-dependent phoneme CTC which\nhas strong LM and decoder by relative 6.79%.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 01:25:17 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Li", "Jinyu", ""], ["Ye", "Guoli", ""], ["Das", "Amit", ""], ["Zhao", "Rui", ""], ["Gong", "Yifan", ""]]}, {"id": "1803.05567", "submitter": "Hany Hassan Awadalla", "authors": "Hany Hassan, Anthony Aue, Chang Chen, Vishal Chowdhary, Jonathan\n  Clark, Christian Federmann, Xuedong Huang, Marcin Junczys-Dowmunt, William\n  Lewis, Mu Li, Shujie Liu, Tie-Yan Liu, Renqian Luo, Arul Menezes, Tao Qin,\n  Frank Seide, Xu Tan, Fei Tian, Lijun Wu, Shuangzhi Wu, Yingce Xia, Dongdong\n  Zhang, Zhirui Zhang, Ming Zhou", "title": "Achieving Human Parity on Automatic Chinese to English News Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine translation has made rapid advances in recent years. Millions of\npeople are using it today in online translation systems and mobile applications\nin order to communicate across language barriers. The question naturally arises\nwhether such systems can approach or achieve parity with human translations. In\nthis paper, we first address the problem of how to define and accurately\nmeasure human parity in translation. We then describe Microsoft's machine\ntranslation system and measure the quality of its translations on the widely\nused WMT 2017 news translation task from Chinese to English. We find that our\nlatest neural machine translation system has reached a new state-of-the-art,\nand that the translation quality is at human parity when compared to\nprofessional human translations. We also find that it significantly exceeds the\nquality of crowd-sourced non-professional translations.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 01:30:58 GMT"}, {"version": "v2", "created": "Fri, 29 Jun 2018 19:16:39 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Hassan", "Hany", ""], ["Aue", "Anthony", ""], ["Chen", "Chang", ""], ["Chowdhary", "Vishal", ""], ["Clark", "Jonathan", ""], ["Federmann", "Christian", ""], ["Huang", "Xuedong", ""], ["Junczys-Dowmunt", "Marcin", ""], ["Lewis", "William", ""], ["Li", "Mu", ""], ["Liu", "Shujie", ""], ["Liu", "Tie-Yan", ""], ["Luo", "Renqian", ""], ["Menezes", "Arul", ""], ["Qin", "Tao", ""], ["Seide", "Frank", ""], ["Tan", "Xu", ""], ["Tian", "Fei", ""], ["Wu", "Lijun", ""], ["Wu", "Shuangzhi", ""], ["Xia", "Yingce", ""], ["Zhang", "Dongdong", ""], ["Zhang", "Zhirui", ""], ["Zhou", "Ming", ""]]}, {"id": "1803.05651", "submitter": "Maximilian Lam C", "authors": "Maximilian Lam", "title": "Word2Bits - Quantized Word Vectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Word vectors require significant amounts of memory and storage, posing issues\nto resource limited devices like mobile phones and GPUs. We show that high\nquality quantized word vectors using 1-2 bits per parameter can be learned by\nintroducing a quantization function into Word2Vec. We furthermore show that\ntraining with the quantization function acts as a regularizer. We train word\nvectors on English Wikipedia (2017) and evaluate them on standard word\nsimilarity and analogy tasks and on question answering (SQuAD). Our quantized\nword vectors not only take 8-16x less space than full precision (32 bit) word\nvectors but also outperform them on word similarity tasks and question\nanswering.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 09:21:34 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 23:50:06 GMT"}, {"version": "v3", "created": "Sat, 31 Mar 2018 08:45:59 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Lam", "Maximilian", ""]]}, {"id": "1803.05655", "submitter": "Yiming Cui", "authors": "Zhipeng Chen, Yiming Cui, Wentao Ma, Shijin Wang, Ting Liu and Guoping\n  Hu", "title": "HFL-RC System at SemEval-2018 Task 11: Hybrid Multi-Aspects Model for\n  Commonsense Reading Comprehension", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes the system which got the state-of-the-art results at\nSemEval-2018 Task 11: Machine Comprehension using Commonsense Knowledge. In\nthis paper, we present a neural network called Hybrid Multi-Aspects (HMA)\nmodel, which mimic the human's intuitions on dealing with the multiple-choice\nreading comprehension. In this model, we aim to produce the predictions in\nmultiple aspects by calculating attention among the text, question and choices,\nand combine these results for final predictions. Experimental results show that\nour HMA model could give substantial improvements over the baseline system and\ngot the first place on the final test set leaderboard with the accuracy of\n84.13%.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 09:30:12 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Chen", "Zhipeng", ""], ["Cui", "Yiming", ""], ["Ma", "Wentao", ""], ["Wang", "Shijin", ""], ["Liu", "Ting", ""], ["Hu", "Guoping", ""]]}, {"id": "1803.05662", "submitter": "Ji Wen", "authors": "Ji Wen, Xu Sun, Xuancheng Ren, Qi Su", "title": "Structure Regularized Neural Network for Entity Relation Classification\n  for Chinese Literature Text", "comments": "Accepted at NAACL HLT 2018. arXiv admin note: substantial text\n  overlap with arXiv:1711.02509", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relation classification is an important semantic processing task in the field\nof natural language processing. In this paper, we propose the task of relation\nclassification for Chinese literature text. A new dataset of Chinese literature\ntext is constructed to facilitate the study in this task. We present a novel\nmodel, named Structure Regularized Bidirectional Recurrent Convolutional Neural\nNetwork (SR-BRCNN), to identify the relation between entities. The proposed\nmodel learns relation representations along the shortest dependency path (SDP)\nextracted from the structure regularized dependency tree, which has the\nbenefits of reducing the complexity of the whole model. Experimental results\nshow that the proposed method significantly improves the F1 score by 10.3, and\noutperforms the state-of-the-art approaches on Chinese literature text.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 09:45:58 GMT"}], "update_date": "2018-03-18", "authors_parsed": [["Wen", "Ji", ""], ["Sun", "Xu", ""], ["Ren", "Xuancheng", ""], ["Su", "Qi", ""]]}, {"id": "1803.05667", "submitter": "HosseinAli Rahmani Dashti", "authors": "Parisa Naderi Golshan, HosseinAli Rahmani Dashti, Shahrzad Azizi and\n  Leila Safari", "title": "A Study of Recent Contributions on Information Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reports on modern approaches in Information Extraction (IE) and\nits two main sub-tasks of Named Entity Recognition (NER) and Relation\nExtraction (RE). Basic concepts and the most recent approaches in this area are\nreviewed, which mainly include Machine Learning (ML) based approaches and the\nmore recent trend to Deep Learning (DL) based methods.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 10:04:27 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Golshan", "Parisa Naderi", ""], ["Dashti", "HosseinAli Rahmani", ""], ["Azizi", "Shahrzad", ""], ["Safari", "Leila", ""]]}, {"id": "1803.05795", "submitter": "Alexander Panchenko", "authors": "Alexander Panchenko, Anastasiya Lopukhina, Dmitry Ustalov, Konstantin\n  Lopukhin, Nikolay Arefyev, Alexey Leontyev, Natalia Loukachevitch", "title": "RUSSE'2018: A Shared Task on Word Sense Induction for the Russian\n  Language", "comments": "In the Proceedings of the 24rd International Conference on\n  Computational Linguistics and Intellectual Technologies (Dialogue'2018),\n  Moscow, Russia. RGGU", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The paper describes the results of the first shared task on word sense\ninduction (WSI) for the Russian language. While similar shared tasks were\nconducted in the past for some Romance and Germanic languages, we explore the\nperformance of sense induction and disambiguation methods for a Slavic language\nthat shares many features with other Slavic languages, such as rich morphology\nand virtually free word order. The participants were asked to group contexts of\na given word in accordance with its senses that were not provided beforehand.\nFor instance, given a word \"bank\" and a set of contexts for this word, e.g.\n\"bank is a financial institution that accepts deposits\" and \"river bank is a\nslope beside a body of water\", a participant was asked to cluster such contexts\nin the unknown in advance number of clusters corresponding to, in this case,\nthe \"company\" and the \"area\" senses of the word \"bank\". For the purpose of this\nevaluation campaign, we developed three new evaluation datasets based on sense\ninventories that have different sense granularity. The contexts in these\ndatasets were sampled from texts of Wikipedia, the academic corpus of Russian,\nand an explanatory dictionary of Russian. Overall, 18 teams participated in the\ncompetition submitting 383 models. Multiple teams managed to substantially\noutperform competitive state-of-the-art baselines from the previous years based\non sense embeddings.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 15:08:36 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 14:49:44 GMT"}, {"version": "v3", "created": "Sat, 9 Jun 2018 16:07:38 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Panchenko", "Alexander", ""], ["Lopukhina", "Anastasiya", ""], ["Ustalov", "Dmitry", ""], ["Lopukhin", "Konstantin", ""], ["Arefyev", "Nikolay", ""], ["Leontyev", "Alexey", ""], ["Loukachevitch", "Natalia", ""]]}, {"id": "1803.05820", "submitter": "Alexander Panchenko", "authors": "Alexander Panchenko, Natalia Loukachevitch, Dmitry Ustalov, Denis\n  Paperno, Christian Meyer, Natalia Konstantinova", "title": "RUSSE: The First Workshop on Russian Semantic Similarity", "comments": "In Proceedings of the 21st International Conference on Computational\n  Linguistics and Intellectual Technologies (Dialogue'2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The paper gives an overview of the Russian Semantic Similarity Evaluation\n(RUSSE) shared task held in conjunction with the Dialogue 2015 conference.\nThere exist a lot of comparative studies on semantic similarity, yet no\nanalysis of such measures was ever performed for the Russian language.\nExploring this problem for the Russian language is even more interesting,\nbecause this language has features, such as rich morphology and free word\norder, which make it significantly different from English, German, and other\nwell-studied languages. We attempt to bridge this gap by proposing a shared\ntask on the semantic similarity of Russian nouns. Our key contribution is an\nevaluation methodology based on four novel benchmark datasets for the Russian\nlanguage. Our analysis of the 105 submissions from 19 teams reveals that\nsuccessful approaches for English, such as distributional and skip-gram models,\nare directly applicable to Russian as well. On the one hand, the best results\nin the contest were obtained by sophisticated supervised models that combine\nevidence from different sources. On the other hand, completely unsupervised\napproaches, such as a skip-gram model estimated on a large-scale corpus, were\nable score among the top 5 systems.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 15:50:58 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Panchenko", "Alexander", ""], ["Loukachevitch", "Natalia", ""], ["Ustalov", "Dmitry", ""], ["Paperno", "Denis", ""], ["Meyer", "Christian", ""], ["Konstantinova", "Natalia", ""]]}, {"id": "1803.05829", "submitter": "Alexander Panchenko", "authors": "Stefano Faralli, Alexander Panchenko, Chris Biemann, Simone Paolo\n  Ponzetto", "title": "Enriching Frame Representations with Distributionally Induced Senses", "comments": "In Proceedings of the 11th Conference on Language Resources and\n  Evaluation (LREC 2018). Miyazaki, Japan. ELRA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a new lexical resource that enriches the Framester knowledge\ngraph, which links Framnet, WordNet, VerbNet and other resources, with semantic\nfeatures from text corpora. These features are extracted from distributionally\ninduced sense inventories and subsequently linked to the manually-constructed\nframe representations to boost the performance of frame disambiguation in\ncontext. Since Framester is a frame-based knowledge graph, which enables\nfull-fledged OWL querying and reasoning, our resource paves the way for the\ndevelopment of novel, deeper semantic-aware applications that could benefit\nfrom the combination of knowledge from text and complex symbolic\nrepresentations of events and participants. Together with the resource we also\nprovide the software we developed for the evaluation in the task of Word Frame\nDisambiguation (WFD).\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 16:06:33 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Faralli", "Stefano", ""], ["Panchenko", "Alexander", ""], ["Biemann", "Chris", ""], ["Ponzetto", "Simone Paolo", ""]]}, {"id": "1803.05928", "submitter": "Jekaterina Novikova Dr.", "authors": "Jekaterina Novikova, Ond\\v{r}ej Du\\v{s}ek and Verena Rieser", "title": "RankME: Reliable Human Ratings for Natural Language Generation", "comments": "Accepted to NAACL 2018 (The 2018 Conference of the North American\n  Chapter of the Association for Computational Linguistics)", "journal-ref": "Proceedings of NAACL-HLT 2018, pages 72-78, New Orleans,\n  Louisiana, June 1-6, 2018", "doi": "10.18653/v1/N18-2012", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Human evaluation for natural language generation (NLG) often suffers from\ninconsistent user ratings. While previous research tends to attribute this\nproblem to individual user preferences, we show that the quality of human\njudgements can also be improved by experimental design. We present a novel\nrank-based magnitude estimation method (RankME), which combines the use of\ncontinuous scales and relative assessments. We show that RankME significantly\nimproves the reliability and consistency of human ratings compared to\ntraditional evaluation methods. In addition, we show that it is possible to\nevaluate NLG systems according to multiple, distinct criteria, which is\nimportant for error analysis. Finally, we demonstrate that RankME, in\ncombination with Bayesian estimation of system quality, is a cost-effective\nalternative for ranking multiple NLG systems.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 18:10:45 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Novikova", "Jekaterina", ""], ["Du\u0161ek", "Ond\u0159ej", ""], ["Rieser", "Verena", ""]]}, {"id": "1803.06064", "submitter": "Chao-Chun Liang", "authors": "Chao-Chun Liang, Yu-Shiang Wong, Yi-Chung Lin and Keh-Yih Su", "title": "A Meaning-based Statistical English Math Word Problem Solver", "comments": "Accepted as a long paper at NAACL HLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce MeSys, a meaning-based approach, for solving English math word\nproblems (MWPs) via understanding and reasoning in this paper. It first\nanalyzes the text, transforms both body and question parts into their\ncorresponding logic forms, and then performs inference on them. The associated\ncontext of each quantity is represented with proposed role-tags (e.g., nsubj,\nverb, etc.), which provides the flexibility for annotating an extracted math\nquantity with its associated context information (i.e., the physical meaning of\nthis quantity). Statistical models are proposed to select the operator and\noperands. A noisy dataset is designed to assess if a solver solves MWPs mainly\nvia understanding or mechanical pattern matching. Experimental results show\nthat our approach outperforms existing systems on both benchmark datasets and\nthe noisy dataset, which demonstrates that the proposed approach understands\nthe meaning of each quantity in the text more.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 03:07:06 GMT"}, {"version": "v2", "created": "Fri, 6 Jul 2018 00:37:36 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Liang", "Chao-Chun", ""], ["Wong", "Yu-Shiang", ""], ["Lin", "Yi-Chung", ""], ["Su", "Keh-Yih", ""]]}, {"id": "1803.06252", "submitter": "Manuel Carbonell", "authors": "Manuel Carbonell, Mauricio Villegas, Alicia Forn\\'es, Josep Llad\\'os", "title": "Joint Recognition of Handwritten Text and Named Entities with a Neural\n  End-to-end Model", "comments": "To appear in IAPR International Workshop on Document Analysis Systems\n  2018 (DAS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When extracting information from handwritten documents, text transcription\nand named entity recognition are usually faced as separate subsequent tasks.\nThis has the disadvantage that errors in the first module affect heavily the\nperformance of the second module. In this work we propose to do both tasks\njointly, using a single neural network with a common architecture used for\nplain text recognition. Experimentally, the work has been tested on a\ncollection of historical marriage records. Results of experiments are presented\nto show the effect on the performance for different configurations: different\nways of encoding the information, doing or not transfer learning and processing\nat text line or multi-line region level. The results are comparable to state of\nthe art reported in the ICDAR 2017 Information Extraction competition, even\nthough the proposed technique does not use any dictionaries, language modeling\nor post processing.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 14:47:58 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2018 12:27:08 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Carbonell", "Manuel", ""], ["Villegas", "Mauricio", ""], ["Forn\u00e9s", "Alicia", ""], ["Llad\u00f3s", "Josep", ""]]}, {"id": "1803.06390", "submitter": "Marina Sokolova", "authors": "Marina Sokolova, Victoria Bobicev", "title": "Corpus Statistics in Text Classification of Online Data", "comments": "12 pages, 6 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformation of Machine Learning (ML) from a boutique science to a\ngenerally accepted technology has increased importance of reproduction and\ntransportability of ML studies. In the current work, we investigate how corpus\ncharacteristics of textual data sets correspond to text classification results.\nWe work with two data sets gathered from sub-forums of an online health-related\nforum. Our empirical results are obtained for a multi-class sentiment analysis\napplication.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 20:19:56 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Sokolova", "Marina", ""], ["Bobicev", "Victoria", ""]]}, {"id": "1803.06397", "submitter": "Bernhard Kratzwald", "authors": "Bernhard Kratzwald, Suzana Ilic, Mathias Kraus, Stefan Feuerriegel,\n  Helmut Prendinger", "title": "Deep learning for affective computing: text-based emotion recognition in\n  decision support", "comments": "Accepted by Decision Support Systems (DSS)", "journal-ref": null, "doi": "10.1016/j.dss.2018.09.002", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotions widely affect human decision-making. This fact is taken into account\nby affective computing with the goal of tailoring decision support to the\nemotional states of individuals. However, the accurate recognition of emotions\nwithin narrative documents presents a challenging undertaking due to the\ncomplexity and ambiguity of language. Performance improvements can be achieved\nthrough deep learning; yet, as demonstrated in this paper, the specific nature\nof this task requires the customization of recurrent neural networks with\nregard to bidirectional processing, dropout layers as a means of\nregularization, and weighted loss functions. In addition, we propose\nsent2affect, a tailored form of transfer learning for affective computing: here\nthe network is pre-trained for a different task (i.e. sentiment analysis),\nwhile the output layer is subsequently tuned to the task of emotion\nrecognition. The resulting performance is evaluated in a holistic setting\nacross 6 benchmark datasets, where we find that both recurrent neural networks\nand transfer learning consistently outperform traditional machine learning.\nAltogether, the findings have considerable implications for the use of\naffective computing.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 21:05:13 GMT"}, {"version": "v2", "created": "Fri, 23 Mar 2018 15:37:32 GMT"}, {"version": "v3", "created": "Mon, 26 Mar 2018 15:42:57 GMT"}, {"version": "v4", "created": "Tue, 10 Apr 2018 09:41:12 GMT"}, {"version": "v5", "created": "Mon, 20 Aug 2018 17:10:52 GMT"}, {"version": "v6", "created": "Mon, 10 Sep 2018 09:07:30 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Kratzwald", "Bernhard", ""], ["Ilic", "Suzana", ""], ["Kraus", "Mathias", ""], ["Feuerriegel", "Stefan", ""], ["Prendinger", "Helmut", ""]]}, {"id": "1803.06456", "submitter": "Marjan Hosseinia", "authors": "Marjan Hosseinia and Arjun Mukherjee", "title": "Experiments with Neural Networks for Small and Large Scale Authorship\n  Verification", "comments": "Accepted in CICLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose two models for a special case of authorship verification problem.\nThe task is to investigate whether the two documents of a given pair are\nwritten by the same author. We consider the authorship verification problem for\nboth small and large scale datasets. The underlying small-scale problem has two\nmain challenges: First, the authors of the documents are unknown to us because\nno previous writing samples are available. Second, the two documents are short\n(a few hundred to a few thousand words) and may differ considerably in the\ngenre and/or topic. To solve it we propose transformation encoder to transform\none document of the pair into the other. This document transformation generates\na loss which is used as a recognizable feature to verify if the authors of the\npair are identical. For the large scale problem where various authors are\nengaged and more examples are available with larger length, a parallel\nrecurrent neural network is proposed. It compares the language models of the\ntwo documents. We evaluate our methods on various types of datasets including\nAuthorship Identification datasets of PAN competition, Amazon reviews, and\nmachine learning articles. Experiments show that both methods achieve stable\nand competitive performance compared to the baselines.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 04:11:22 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Hosseinia", "Marjan", ""], ["Mukherjee", "Arjun", ""]]}, {"id": "1803.06500", "submitter": "Joseph Corneli", "authors": "Joseph Corneli, Ursula Martin, Dave Murray-Rust, Gabriela Rino Nesin,\n  and Alison Pease", "title": "Argumentation theory for mathematical argument", "comments": "44 pages; to appear in Argumentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To adequately model mathematical arguments the analyst must be able to\nrepresent the mathematical objects under discussion and the relationships\nbetween them, as well as inferences drawn about these objects and relationships\nas the discourse unfolds. We introduce a framework with these properties, which\nhas been used to analyse mathematical dialogues and expository texts. The\nframework can recover salient elements of discourse at, and within, the\nsentence level, as well as the way mathematical content connects to form larger\nargumentative structures. We show how the framework might be used to support\ncomputational reasoning, and argue that it provides a more natural way to\nexamine the process of proving theorems than do Lamport's structured proofs.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 13:20:37 GMT"}, {"version": "v2", "created": "Sun, 15 Jul 2018 14:16:51 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Corneli", "Joseph", ""], ["Martin", "Ursula", ""], ["Murray-Rust", "Dave", ""], ["Nesin", "Gabriela Rino", ""], ["Pease", "Alison", ""]]}, {"id": "1803.06535", "submitter": "Sudha Rao", "authors": "Sudha Rao and Joel Tetreault", "title": "Dear Sir or Madam, May I introduce the GYAFC Dataset: Corpus, Benchmarks\n  and Metrics for Formality Style Transfer", "comments": "To appear in the proceedings of North American Chapter of the\n  Association for Computational Linguistics: Human Language Technologies 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Style transfer is the task of automatically transforming a piece of text in\none particular style into another. A major barrier to progress in this field\nhas been a lack of training and evaluation datasets, as well as benchmarks and\nautomatic metrics. In this work, we create the largest corpus for a particular\nstylistic transfer (formality) and show that techniques from the machine\ntranslation community can serve as strong baselines for future work. We also\ndiscuss challenges of using automatic metrics.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 16:35:04 GMT"}, {"version": "v2", "created": "Mon, 16 Apr 2018 17:23:03 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Rao", "Sudha", ""], ["Tetreault", "Joel", ""]]}, {"id": "1803.06581", "submitter": "Wenhu Chen", "authors": "Wenhu Chen, Wenhan Xiong, Xifeng Yan, William Wang", "title": "Variational Knowledge Graph Reasoning", "comments": "Accepted to NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring missing links in knowledge graphs (KG) has attracted a lot of\nattention from the research community. In this paper, we tackle a practical\nquery answering task involving predicting the relation of a given entity pair.\nWe frame this prediction problem as an inference problem in a probabilistic\ngraphical model and aim at resolving it from a variational inference\nperspective. In order to model the relation between the query entity pair, we\nassume that there exists an underlying latent variable (paths connecting two\nnodes) in the KG, which carries the equivalent semantics of their relations.\nHowever, due to the intractability of connections in large KGs, we propose to\nuse variation inference to maximize the evidence lower bound. More\nspecifically, our framework (\\textsc{Diva}) is composed of three modules, i.e.\na posterior approximator, a prior (path finder), and a likelihood (path\nreasoner). By using variational inference, we are able to incorporate them\nclosely into a unified architecture and jointly optimize them to perform KG\nreasoning. With active interactions among these sub-modules, \\textsc{Diva} is\nbetter at handling noise and coping with more complex reasoning scenarios. In\norder to evaluate our method, we conduct the experiment of the link prediction\ntask on multiple datasets and achieve state-of-the-art performances on both\ndatasets.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 22:08:10 GMT"}, {"version": "v2", "created": "Thu, 5 Apr 2018 19:57:05 GMT"}, {"version": "v3", "created": "Tue, 23 Oct 2018 04:51:29 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Chen", "Wenhu", ""], ["Xiong", "Wenhan", ""], ["Yan", "Xifeng", ""], ["Wang", "William", ""]]}, {"id": "1803.06643", "submitter": "Alon Talmor", "authors": "Alon Talmor, Jonathan Berant", "title": "The Web as a Knowledge-base for Answering Complex Questions", "comments": "accepted as a long paper at NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answering complex questions is a time-consuming activity for humans that\nrequires reasoning and integration of information. Recent work on reading\ncomprehension made headway in answering simple questions, but tackling complex\nquestions is still an ongoing research challenge. Conversely, semantic parsers\nhave been successful at handling compositionality, but only when the\ninformation resides in a target knowledge-base. In this paper, we present a\nnovel framework for answering broad and complex questions, assuming answering\nsimple questions is possible using a search engine and a reading comprehension\nmodel. We propose to decompose complex questions into a sequence of simple\nquestions, and compute the final answer from the sequence of answers. To\nillustrate the viability of our approach, we create a new dataset of complex\nquestions, ComplexWebQuestions, and present a model that decomposes questions\nand interacts with the web to compute an answer. We empirically demonstrate\nthat question decomposition improves performance from 20.8 precision@1 to 27.5\nprecision@1 on this new dataset.\n", "versions": [{"version": "v1", "created": "Sun, 18 Mar 2018 11:28:12 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Talmor", "Alon", ""], ["Berant", "Jonathan", ""]]}, {"id": "1803.06745", "submitter": "Braja Gopal Patra", "authors": "Braja Gopal Patra, Dipankar Das, and Amitava Das", "title": "Sentiment Analysis of Code-Mixed Indian Languages: An Overview of\n  SAIL_Code-Mixed Shared Task @ICON-2017", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment analysis is essential in many real-world applications such as\nstance detection, review analysis, recommendation system, and so on. Sentiment\nanalysis becomes more difficult when the data is noisy and collected from\nsocial media. India is a multilingual country; people use more than one\nlanguages to communicate within themselves. The switching in between the\nlanguages is called code-switching or code-mixing, depending upon the type of\nmixing. This paper presents overview of the shared task on sentiment analysis\nof code-mixed data pairs of Hindi-English and Bengali-English collected from\nthe different social media platform. The paper describes the task, dataset,\nevaluation, baseline and participant's systems.\n", "versions": [{"version": "v1", "created": "Sun, 18 Mar 2018 21:32:07 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Patra", "Braja Gopal", ""], ["Das", "Dipankar", ""], ["Das", "Amitava", ""]]}, {"id": "1803.06805", "submitter": "Qingming Tang", "authors": "Qingming Tang, Weiran Wang and Karen Livescu", "title": "Acoustic feature learning using cross-domain articulatory measurements", "comments": "ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work has shown that it is possible to improve speech recognition by\nlearning acoustic features from paired acoustic-articulatory data, for example\nby using canonical correlation analysis (CCA) or its deep extensions. One\nlimitation of this prior work is that the learned feature models are difficult\nto port to new datasets or domains, and articulatory data is not available for\nmost speech corpora. In this work we study the problem of acoustic feature\nlearning in the setting where we have access to an external, domain-mismatched\ndataset of paired speech and articulatory measurements, either with or without\nlabels. We develop methods for acoustic feature learning in these settings,\nbased on deep variational CCA and extensions that use both source and target\ndomain data and labels. Using this approach, we improve phonetic recognition\naccuracies on both TIMIT and Wall Street Journal and analyze a number of design\nchoices.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 05:13:09 GMT"}, {"version": "v2", "created": "Tue, 20 Mar 2018 01:54:20 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Tang", "Qingming", ""], ["Wang", "Weiran", ""], ["Livescu", "Karen", ""]]}, {"id": "1803.06966", "submitter": "Kyle Richardson", "authors": "Kyle Richardson and Jonathan Berant and Jonas Kuhn", "title": "Polyglot Semantic Parsing in APIs", "comments": "accepted for NAACL-2018 (camera ready version)", "journal-ref": null, "doi": "10.18653/v1/N18-1066", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traditional approaches to semantic parsing (SP) work by training individual\nmodels for each available parallel dataset of text-meaning pairs. In this\npaper, we explore the idea of polyglot semantic translation, or learning\nsemantic parsing models that are trained on multiple datasets and natural\nlanguages. In particular, we focus on translating text to code signature\nrepresentations using the software component datasets of Richardson and Kuhn\n(2017a,b). The advantage of such models is that they can be used for parsing a\nwide variety of input natural languages and output programming languages, or\nmixed input languages, using a single unified model. To facilitate modeling of\nthis type, we develop a novel graph-based decoding framework that achieves\nstate-of-the-art performance on the above datasets, and apply this method to\ntwo other benchmark SP tasks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 14:55:12 GMT"}, {"version": "v2", "created": "Wed, 18 Apr 2018 06:36:14 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Richardson", "Kyle", ""], ["Berant", "Jonathan", ""], ["Kuhn", "Jonas", ""]]}, {"id": "1803.07038", "submitter": "Leena Shekhar", "authors": "Noah Weber, Leena Shekhar, Niranjan Balasubramanian, Kyunghyun Cho", "title": "Controlling Decoding for More Abstractive Summaries with Copy-Based\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based neural abstractive summarization systems equipped with copy\nmechanisms have shown promising results. Despite this success, it has been\nnoticed that such a system generates a summary by mostly, if not entirely,\ncopying over phrases, sentences, and sometimes multiple consecutive sentences\nfrom an input paragraph, effectively performing extractive summarization. In\nthis paper, we verify this behavior using the latest neural abstractive\nsummarization system - a pointer-generator network. We propose a simple\nbaseline method that allows us to control the amount of copying without\nretraining. Experiments indicate that the method provides a strong baseline for\nabstractive systems looking to obtain high ROUGE scores while minimizing\noverlap with the source article, substantially reducing the n-gram overlap with\nthe original article while keeping within 2 points of the original model's\nROUGE score.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 17:02:23 GMT"}, {"version": "v2", "created": "Tue, 20 Mar 2018 03:32:35 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Weber", "Noah", ""], ["Shekhar", "Leena", ""], ["Balasubramanian", "Niranjan", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1803.07116", "submitter": "Lucie-Aim\\'ee Kaffee", "authors": "Lucie-Aim\\'ee Kaffee, Hady Elsahar, Pavlos Vougiouklis, Christophe\n  Gravier, Fr\\'ed\\'erique Laforest, Jonathon Hare, Elena Simperl", "title": "Learning to Generate Wikipedia Summaries for Underserved Languages from\n  Wikidata", "comments": "NAACL HTL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While Wikipedia exists in 287 languages, its content is unevenly distributed\namong them. In this work, we investigate the generation of open domain\nWikipedia summaries in underserved languages using structured data from\nWikidata. To this end, we propose a neural network architecture equipped with\ncopy actions that learns to generate single-sentence and comprehensible textual\nsummaries from Wikidata triples. We demonstrate the effectiveness of the\nproposed approach by evaluating it against a set of baselines on two languages\nof different natures: Arabic, a morphological rich language with a larger\nvocabulary than English, and Esperanto, a constructed language known for its\neasy acquisition.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 18:53:17 GMT"}, {"version": "v2", "created": "Sun, 29 Apr 2018 18:13:17 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Kaffee", "Lucie-Aim\u00e9e", ""], ["Elsahar", "Hady", ""], ["Vougiouklis", "Pavlos", ""], ["Gravier", "Christophe", ""], ["Laforest", "Fr\u00e9d\u00e9rique", ""], ["Hare", "Jonathon", ""], ["Simperl", "Elena", ""]]}, {"id": "1803.07133", "submitter": "Sidi Lu", "authors": "Sidi Lu, Yaoming Zhu, Weinan Zhang, Jun Wang, Yong Yu", "title": "Neural Text Generation: Past, Present and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a systematic survey on recent development of neural text\ngeneration models. Specifically, we start from recurrent neural network\nlanguage models with the traditional maximum likelihood estimation training\nscheme and point out its shortcoming for text generation. We thus introduce the\nrecently proposed methods for text generation based on reinforcement learning,\nre-parametrization tricks and generative adversarial nets (GAN) techniques. We\ncompare different properties of these models and the corresponding techniques\nto handle their common problems such as gradient vanishing and generation\ndiversity. Finally, we conduct a benchmarking experiment with different types\nof neural text generation models on two well-known datasets and discuss the\nempirical results along with the aforementioned model properties.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 07:54:30 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Lu", "Sidi", ""], ["Zhu", "Yaoming", ""], ["Zhang", "Weinan", ""], ["Wang", "Jun", ""], ["Yu", "Yong", ""]]}, {"id": "1803.07136", "submitter": "Rick Dale", "authors": "Rick Dale, Nicholas D. Duran, and Moreno Coco", "title": "Dynamic Natural Language Processing with Recurrence Quantification\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Writing and reading are dynamic processes. As an author composes a text, a\nsequence of words is produced. This sequence is one that, the author hopes,\ncauses a revisitation of certain thoughts and ideas in others. These processes\nof composition and revisitation by readers are ordered in time. This means that\ntext itself can be investigated under the lens of dynamical systems. A common\ntechnique for analyzing the behavior of dynamical systems, known as recurrence\nquantification analysis (RQA), can be used as a method for analyzing sequential\nstructure of text. RQA treats text as a sequential measurement, much like a\ntime series, and can thus be seen as a kind of dynamic natural language\nprocessing (NLP). The extension has several benefits. Because it is part of a\nsuite of time series analysis tools, many measures can be extracted in one\ncommon framework. Secondly, the measures have a close relationship with some\ncommonly used measures from natural language processing. Finally, using\nrecurrence analysis offers an opportunity expand analysis of text by developing\ntheoretical descriptions derived from complex dynamic systems. We showcase an\nexample analysis on 8,000 texts from the Gutenberg Project, compare it to\nwell-known NLP approaches, and describe an R package (crqanlp) that can be used\nin conjunction with R library crqa.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 19:45:38 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Dale", "Rick", ""], ["Duran", "Nicholas D.", ""], ["Coco", "Moreno", ""]]}, {"id": "1803.07139", "submitter": "No\\'e Casas", "authors": "Marta R. Costa-juss\\`a, Noe Casas, Maite Melero", "title": "English-Catalan Neural Machine Translation in the Biomedical Domain\n  through the cascade approach", "comments": "Full workshop proceedings can be found at\n  https://multilingualbio.bsc.es/wp-content/uploads/2018/03/LREC-2018-PROCEEDINGS-MultilingualBIO.pdf", "journal-ref": "Proceedings of workshop \"MultilingualBIO: Multilingual Biomedical\n  Text Processing\" of the 11th Edition of the Language Resources and Evaluation\n  Conference, 2018", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the methodology followed to build a neural machine\ntranslation system in the biomedical domain for the English-Catalan language\npair. This task can be considered a low-resourced task from the point of view\nof the domain and the language pair. To face this task, this paper reports\nexperiments on a cascade pivot strategy through Spanish for the neural machine\ntranslation using the English-Spanish SCIELO and Spanish-Catalan El Peri\\'odico\ndatabase. To test the final performance of the system, we have created a new\ntest data set for English-Catalan in the biomedical domain which is freely\navailable on request.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 19:48:48 GMT"}, {"version": "v2", "created": "Thu, 26 Apr 2018 15:22:04 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Costa-juss\u00e0", "Marta R.", ""], ["Casas", "Noe", ""], ["Melero", "Maite", ""]]}, {"id": "1803.07204", "submitter": "Felix Stahlberg", "authors": "Felix Stahlberg, Danielle Saunders, Gonzalo Iglesias, Bill Byrne", "title": "Why not be Versatile? Applications of the SGNMT Decoder for Machine\n  Translation", "comments": "Presented at AMTA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SGNMT is a decoding platform for machine translation which allows paring\nvarious modern neural models of translation with different kinds of constraints\nand symbolic models. In this paper, we describe three use cases in which SGNMT\nis currently playing an active role: (1) teaching as SGNMT is being used for\ncourse work and student theses in the MPhil in Machine Learning, Speech and\nLanguage Technology at the University of Cambridge, (2) research as most of the\nresearch work of the Cambridge MT group is based on SGNMT, and (3) technology\ntransfer as we show how SGNMT is helping to transfer research findings from the\nlaboratory to the industry, eg. into a product of SDL plc.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 00:44:18 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Stahlberg", "Felix", ""], ["Saunders", "Danielle", ""], ["Iglesias", "Gonzalo", ""], ["Byrne", "Bill", ""]]}, {"id": "1803.07274", "submitter": "Rajen Chatterjee", "authors": "Matteo Negri, Marco Turchi, Rajen Chatterjee, Nicola Bertoldi", "title": "eSCAPE: a Large-scale Synthetic Corpus for Automatic Post-Editing", "comments": "Accepted at LREC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training models for the automatic correction of machine-translated text\nusually relies on data consisting of (source, MT, human post- edit) triplets\nproviding, for each source sentence, examples of translation errors with the\ncorresponding corrections made by a human post-editor. Ideally, a large amount\nof data of this kind should allow the model to learn reliable correction\npatterns and effectively apply them at test stage on unseen (source, MT) pairs.\nIn practice, however, their limited availability calls for solutions that also\nintegrate in the training process other sources of knowledge. Along this\ndirection, state-of-the-art results have been recently achieved by systems\nthat, in addition to a limited amount of available training data, exploit\nartificial corpora that approximate elements of the \"gold\" training instances\nwith automatic translations. Following this idea, we present eSCAPE, the\nlargest freely-available Synthetic Corpus for Automatic Post-Editing released\nso far. eSCAPE consists of millions of entries in which the MT element of the\ntraining triplets has been obtained by translating the source side of\npublicly-available parallel corpora, and using the target side as an artificial\nhuman post-edit. Translations are obtained both with phrase-based and neural\nmodels. For each MT paradigm, eSCAPE contains 7.2 million triplets for\nEnglish-German and 3.3 millions for English-Italian, resulting in a total of\n14,4 and 6,6 million instances respectively. The usefulness of eSCAPE is proved\nthrough experiments in a general-domain scenario, the most challenging one for\nautomatic post-editing. For both language directions, the models trained on our\nartificial data always improve MT quality with statistically significant gains.\nThe current version of eSCAPE can be freely downloaded from:\nhttp://hltshare.fbk.eu/QT21/eSCAPE.html.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 06:59:27 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Negri", "Matteo", ""], ["Turchi", "Marco", ""], ["Chatterjee", "Rajen", ""], ["Bertoldi", "Nicola", ""]]}, {"id": "1803.07295", "submitter": "Rodolfo Delmonte", "authors": "Rodolfo Delmonte", "title": "Expressivity in TTS from Semantics and Pragmatics", "comments": "Presented at AISV 2015 - Now appearing in Studi AISV, n.1", "journal-ref": null, "doi": "10.17469/O2101AISV000026", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper we present ongoing work to produce an expressive TTS reader\nthat can be used both in text and dialogue applications. The system called\nSPARSAR has been used to read (English) poetry so far but it can now be applied\nto any text. The text is fully analyzed both at phonetic and phonological\nlevel, and at syntactic and semantic level. In addition, the system has access\nto a restricted list of typical pragmatically marked phrases and expressions\nthat are used to convey specific discourse function and speech acts and need\nspecialized intonational contours. The text is transformed into a poem-like\nstructures, where each line corresponds to a Breath Group, semantically and\nsyntactically consistent. Stanzas correspond to paragraph boundaries.\nAnalogical parameters are related to ToBI theoretical indices but their number\nis doubled. In this paper, we concentrate on short stories and fables.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 08:35:16 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Delmonte", "Rodolfo", ""]]}, {"id": "1803.07416", "submitter": "Ryan Sepassi", "authors": "Ashish Vaswani, Samy Bengio, Eugene Brevdo, Francois Chollet, Aidan N.\n  Gomez, Stephan Gouws, Llion Jones, {\\L}ukasz Kaiser, Nal Kalchbrenner, Niki\n  Parmar, Ryan Sepassi, Noam Shazeer, Jakob Uszkoreit", "title": "Tensor2Tensor for Neural Machine Translation", "comments": "arXiv admin note: text overlap with arXiv:1706.03762", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Tensor2Tensor is a library for deep learning models that is well-suited for\nneural machine translation and includes the reference implementation of the\nstate-of-the-art Transformer model.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 18:49:22 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Vaswani", "Ashish", ""], ["Bengio", "Samy", ""], ["Brevdo", "Eugene", ""], ["Chollet", "Francois", ""], ["Gomez", "Aidan N.", ""], ["Gouws", "Stephan", ""], ["Jones", "Llion", ""], ["Kaiser", "\u0141ukasz", ""], ["Kalchbrenner", "Nal", ""], ["Parmar", "Niki", ""], ["Sepassi", "Ryan", ""], ["Shazeer", "Noam", ""], ["Uszkoreit", "Jakob", ""]]}, {"id": "1803.07427", "submitter": "Soujanya Poria", "authors": "Soujanya Poria, Navonil Majumder, Devamanyu Hazarika, Erik Cambria,\n  Alexander Gelbukh, Amir Hussain", "title": "Multimodal Sentiment Analysis: Addressing Key Issues and Setting up the\n  Baselines", "comments": "IEEE Intelligence Systems. arXiv admin note: substantial text overlap\n  with arXiv:1707.09538", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.IR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We compile baselines, along with dataset split, for multimodal sentiment\nanalysis. In this paper, we explore three different deep-learning based\narchitectures for multimodal sentiment classification, each improving upon the\nprevious. Further, we evaluate these architectures with multiple datasets with\nfixed train/test partition. We also discuss some major issues, frequently\nignored in multimodal sentiment analysis research, e.g., role of\nspeaker-exclusive models, importance of different modalities, and\ngeneralizability. This framework illustrates the different facets of analysis\nto be considered while performing multimodal sentiment analysis and, hence,\nserves as a new benchmark for future research in this emerging field.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 02:23:30 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 02:42:19 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Poria", "Soujanya", ""], ["Majumder", "Navonil", ""], ["Hazarika", "Devamanyu", ""], ["Cambria", "Erik", ""], ["Gelbukh", "Alexander", ""], ["Hussain", "Amir", ""]]}, {"id": "1803.07602", "submitter": "Radu Tudor Ionescu", "authors": "Andrei M. Butnaru and Radu Tudor Ionescu", "title": "UnibucKernel: A kernel-based learning method for complex word\n  identification", "comments": "This paper presents the system developed by the UnibucKernel team for\n  the 2018 CWI Shared Task. Accepted at the BEA13 Workshop of NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a kernel-based learning approach for the 2018\nComplex Word Identification (CWI) Shared Task. Our approach is based on\ncombining multiple low-level features, such as character n-grams, with\nhigh-level semantic features that are either automatically learned using word\nembeddings or extracted from a lexical knowledge base, namely WordNet. After\nfeature extraction, we employ a kernel method for the learning phase. The\nfeature matrix is first transformed into a normalized kernel matrix. For the\nbinary classification task (simple versus complex), we employ Support Vector\nMachines. For the regression task, in which we have to predict the complexity\nlevel of a word (a word is more complex if it is labeled as complex by more\nannotators), we employ v-Support Vector Regression. We applied our approach\nonly on the three English data sets containing documents from Wikipedia,\nWikiNews and News domains. Our best result during the competition was the third\nplace on the English Wikipedia data set. However, in this paper, we also report\nbetter post-competition results.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 18:47:54 GMT"}, {"version": "v2", "created": "Fri, 6 Apr 2018 09:24:55 GMT"}, {"version": "v3", "created": "Tue, 10 Apr 2018 15:27:52 GMT"}, {"version": "v4", "created": "Tue, 22 May 2018 17:03:19 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Butnaru", "Andrei M.", ""], ["Ionescu", "Radu Tudor", ""]]}, {"id": "1803.07640", "submitter": "Matt Gardner", "authors": "Matt Gardner, Joel Grus, Mark Neumann, Oyvind Tafjord, Pradeep Dasigi,\n  Nelson Liu, Matthew Peters, Michael Schmitz, Luke Zettlemoyer", "title": "AllenNLP: A Deep Semantic Natural Language Processing Platform", "comments": "Describes the initial version of AllenNLP. Many features and models\n  have been added since the first release. This is the paper to cite if you use\n  AllenNLP in your research. Updated 5/31/2018 with version accepted to the NLP\n  OSS workshop help at ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes AllenNLP, a platform for research on deep learning\nmethods in natural language understanding. AllenNLP is designed to support\nresearchers who want to build novel language understanding models quickly and\neasily. It is built on top of PyTorch, allowing for dynamic computation graphs,\nand provides (1) a flexible data API that handles intelligent batching and\npadding, (2) high-level abstractions for common operations in working with\ntext, and (3) a modular and extensible experiment framework that makes doing\ngood science easy. It also includes reference implementations of high quality\napproaches for both core semantic problems (e.g. semantic role labeling (Palmer\net al., 2005)) and language understanding applications (e.g. machine\ncomprehension (Rajpurkar et al., 2016)). AllenNLP is an ongoing open-source\neffort maintained by engineers and researchers at the Allen Institute for\nArtificial Intelligence.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 20:32:07 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 17:56:14 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Gardner", "Matt", ""], ["Grus", "Joel", ""], ["Neumann", "Mark", ""], ["Tafjord", "Oyvind", ""], ["Dasigi", "Pradeep", ""], ["Liu", "Nelson", ""], ["Peters", "Matthew", ""], ["Schmitz", "Michael", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1803.07679", "submitter": "Fabio Daolio", "authors": "\\^Angelo Cardoso, Fabio Daolio and Sa\\'ul Vargas", "title": "Product Characterisation towards Personalisation: Learning Attributes\n  from Unstructured Data to Recommend Fashion Products", "comments": "Under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe a solution to tackle a common set of challenges in\ne-commerce, which arise from the fact that new products are continually being\nadded to the catalogue. The challenges involve properly personalising the\ncustomer experience, forecasting demand and planning the product range. We\nargue that the foundational piece to solve all of these problems is having\nconsistent and detailed information about each product, information that is\nrarely available or consistent given the multitude of suppliers and types of\nproducts. We describe in detail the architecture and methodology implemented at\nASOS, one of the world's largest fashion e-commerce retailers, to tackle this\nproblem. We then show how this quantitative understanding of the products can\nbe leveraged to improve recommendations in a hybrid recommender system\napproach.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 22:25:29 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Cardoso", "\u00c2ngelo", ""], ["Daolio", "Fabio", ""], ["Vargas", "Sa\u00fal", ""]]}, {"id": "1803.07718", "submitter": "Debanjan Mahata", "authors": "Jasper Friedrichs, Debanjan Mahata, Shubham Gupta", "title": "InfyNLP at SMM4H Task 2: Stacked Ensemble of Shallow Convolutional\n  Neural Networks for Identifying Personal Medication Intake from Twitter", "comments": "2nd Workshop on Social Media Mining for Health", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes Infosys's participation in the \"2nd Social Media Mining\nfor Health Applications Shared Task at AMIA, 2017, Task 2\". Mining social media\nmessages for health and drug related information has received significant\ninterest in pharmacovigilance research. This task targets at developing\nautomated classification models for identifying tweets containing descriptions\nof personal intake of medicines. Towards this objective we train a stacked\nensemble of shallow convolutional neural network (CNN) models on an annotated\ndataset provided by the organizers. We use random search for tuning the\nhyper-parameters of the CNN and submit an ensemble of best models for the\nprediction task. Our system secured first place among 9 teams, with a\nmicro-averaged F-score of 0.693.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 02:14:16 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Friedrichs", "Jasper", ""], ["Mahata", "Debanjan", ""], ["Gupta", "Shubham", ""]]}, {"id": "1803.07724", "submitter": "Jasdeep Singh", "authors": "Jasdeep Singh, Vincent Ying, Alex Nutkiewicz", "title": "Attention on Attention: Architectures for Visual Question Answering\n  (VQA)", "comments": "Visual Question Answering Project", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual Question Answering (VQA) is an increasingly popular topic in deep\nlearning research, requiring coordination of natural language processing and\ncomputer vision modules into a single architecture. We build upon the model\nwhich placed first in the VQA Challenge by developing thirteen new attention\nmechanisms and introducing a simplified classifier. We performed 300 GPU hours\nof extensive hyperparameter and architecture searches and were able to achieve\nan evaluation score of 64.78%, outperforming the existing state-of-the-art\nsingle model's validation score of 63.15%.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 03:05:58 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Singh", "Jasdeep", ""], ["Ying", "Vincent", ""], ["Nutkiewicz", "Alex", ""]]}, {"id": "1803.07729", "submitter": "Xin Wang", "authors": "Xin Wang, Wenhan Xiong, Hongmin Wang, William Yang Wang", "title": "Look Before You Leap: Bridging Model-Free and Model-Based Reinforcement\n  Learning for Planned-Ahead Vision-and-Language Navigation", "comments": "21 pages, 7 figures, with supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing research studies on vision and language grounding for robot\nnavigation focus on improving model-free deep reinforcement learning (DRL)\nmodels in synthetic environments. However, model-free DRL models do not\nconsider the dynamics in the real-world environments, and they often fail to\ngeneralize to new scenes. In this paper, we take a radical approach to bridge\nthe gap between synthetic studies and real-world practices---We propose a\nnovel, planned-ahead hybrid reinforcement learning model that combines\nmodel-free and model-based reinforcement learning to solve a real-world\nvision-language navigation task. Our look-ahead module tightly integrates a\nlook-ahead policy model with an environment model that predicts the next state\nand the reward. Experimental results suggest that our proposed method\nsignificantly outperforms the baselines and achieves the best on the real-world\nRoom-to-Room dataset. Moreover, our scalable method is more generalizable when\ntransferring to unseen environments.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 03:21:38 GMT"}, {"version": "v2", "created": "Thu, 26 Jul 2018 06:10:27 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Wang", "Xin", ""], ["Xiong", "Wenhan", ""], ["Wang", "Hongmin", ""], ["Wang", "William Yang", ""]]}, {"id": "1803.07738", "submitter": "Zhilei Liu", "authors": "Haotian Guan, Zhilei Liu, Longbiao Wang, Jianwu Dang, Ruiguo Yu", "title": "Speech Emotion Recognition Considering Local Dynamic Features", "comments": "10 pages, 3 figures, accepted by ISSP 2017", "journal-ref": null, "doi": "10.1007/978-3-030-00126-1_2", "report-no": null, "categories": "cs.HC cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, increasing attention has been directed to the study of the speech\nemotion recognition, in which global acoustic features of an utterance are\nmostly used to eliminate the content differences. However, the expression of\nspeech emotion is a dynamic process, which is reflected through dynamic\ndurations, energies, and some other prosodic information when one speaks. In\nthis paper, a novel local dynamic pitch probability distribution feature, which\nis obtained by drawing the histogram, is proposed to improve the accuracy of\nspeech emotion recognition. Compared with most of the previous works using\nglobal features, the proposed method takes advantage of the local dynamic\ninformation conveyed by the emotional speech. Several experiments on Berlin\nDatabase of Emotional Speech are conducted to verify the effectiveness of the\nproposed method. The experimental results demonstrate that the local dynamic\ninformation obtained with the proposed method is more effective for speech\nemotion recognition than the traditional global features.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 03:52:26 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Guan", "Haotian", ""], ["Liu", "Zhilei", ""], ["Wang", "Longbiao", ""], ["Dang", "Jianwu", ""], ["Yu", "Ruiguo", ""]]}, {"id": "1803.07771", "submitter": "Ou Wu", "authors": "Ou Wu, Tao Yang, Mengyang Li, Ming Li", "title": "$\\rho$-hot Lexicon Embedding-based Two-level LSTM for Sentiment Analysis", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment analysis is a key component in various text mining applications.\nNumerous sentiment classification techniques, including conventional and deep\nlearning-based methods, have been proposed in the literature. In most existing\nmethods, a high-quality training set is assumed to be given. Nevertheless,\nconstructing a high-quality training set that consists of highly accurate\nlabels is challenging in real applications. This difficulty stems from the fact\nthat text samples usually contain complex sentiment representations, and their\nannotation is subjective. We address this challenge in this study by leveraging\na new labeling strategy and utilizing a two-level long short-term memory\nnetwork to construct a sentiment classifier. Lexical cues are useful for\nsentiment analysis, and they have been utilized in conventional studies. For\nexample, polar and privative words play important roles in sentiment analysis.\nA new encoding strategy, that is, $\\rho$-hot encoding, is proposed to alleviate\nthe drawbacks of one-hot encoding and thus effectively incorporate useful\nlexical cues. We compile three Chinese data sets on the basis of our label\nstrategy and proposed methodology. Experiments on the three data sets\ndemonstrate that the proposed method outperforms state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 07:13:16 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Wu", "Ou", ""], ["Yang", "Tao", ""], ["Li", "Mengyang", ""], ["Li", "Ming", ""]]}, {"id": "1803.07828", "submitter": "Tommaso Soru", "authors": "Tommaso Soru, Stefano Ruberto, Diego Moussallem, Andr\\'e Valdestilhas,\n  Alexander Bigerl, Edgard Marx, Diego Esteves", "title": "Expeditious Generation of Knowledge Graph Embeddings", "comments": "Submitted to the Archives of Data Science, Series A; 14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Graph Embedding methods aim at representing entities and relations\nin a knowledge base as points or vectors in a continuous vector space. Several\napproaches using embeddings have shown promising results on tasks such as link\nprediction, entity recommendation, question answering, and triplet\nclassification. However, only a few methods can compute low-dimensional\nembeddings of very large knowledge bases without needing state-of-the-art\ncomputational resources. In this paper, we propose KG2Vec, a simple and fast\napproach to Knowledge Graph Embedding based on the skip-gram model. Instead of\nusing a predefined scoring function, we learn it relying on Long Short-Term\nMemories. We show that our embeddings achieve results comparable with the most\nscalable approaches on knowledge graph completion as well as on a new metric.\nYet, KG2Vec can embed large graphs in lesser time by processing more than 250\nmillion triples in less than 7 hours on common hardware.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 10:06:28 GMT"}, {"version": "v2", "created": "Fri, 9 Nov 2018 14:26:16 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Soru", "Tommaso", ""], ["Ruberto", "Stefano", ""], ["Moussallem", "Diego", ""], ["Valdestilhas", "Andr\u00e9", ""], ["Bigerl", "Alexander", ""], ["Marx", "Edgard", ""], ["Esteves", "Diego", ""]]}, {"id": "1803.08035", "submitter": "Xiaolong Wang", "authors": "Xiaolong Wang, Yufei Ye, Abhinav Gupta", "title": "Zero-shot Recognition via Semantic Embeddings and Knowledge Graphs", "comments": "CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of zero-shot recognition: learning a visual\nclassifier for a category with zero training examples, just using the word\nembedding of the category and its relationship to other categories, which\nvisual data are provided. The key to dealing with the unfamiliar or novel\ncategory is to transfer knowledge obtained from familiar classes to describe\nthe unfamiliar class. In this paper, we build upon the recently introduced\nGraph Convolutional Network (GCN) and propose an approach that uses both\nsemantic embeddings and the categorical relationships to predict the\nclassifiers. Given a learned knowledge graph (KG), our approach takes as input\nsemantic embeddings for each node (representing visual category). After a\nseries of graph convolutions, we predict the visual classifier for each\ncategory. During training, the visual classifiers for a few categories are\ngiven to learn the GCN parameters. At test time, these filters are used to\npredict the visual classifiers of unseen categories. We show that our approach\nis robust to noise in the KG. More importantly, our approach provides\nsignificant improvement in performance compared to the current state-of-the-art\nresults (from 2 ~ 3% on some metrics to whopping 20% on a few).\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 17:52:42 GMT"}, {"version": "v2", "created": "Sun, 8 Apr 2018 18:53:39 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Wang", "Xiaolong", ""], ["Ye", "Yufei", ""], ["Gupta", "Abhinav", ""]]}, {"id": "1803.08073", "submitter": "Vered Shwartz", "authors": "Vered Shwartz and Chris Waterson", "title": "Olive Oil is Made of Olives, Baby Oil is Made for Babies: Interpreting\n  Noun Compounds using Paraphrases in a Neural Model", "comments": "7 pages, short paper at NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic interpretation of the relation between the constituents of a noun\ncompound, e.g. olive oil (source) and baby oil (purpose) is an important task\nfor many NLP applications. Recent approaches are typically based on either\nnoun-compound representations or paraphrases. While the former has initially\nshown promising results, recent work suggests that the success stems from\nmemorizing single prototypical words for each relation. We explore a neural\nparaphrasing approach that demonstrates superior performance when such\nmemorization is not possible.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 18:16:23 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Shwartz", "Vered", ""], ["Waterson", "Chris", ""]]}, {"id": "1803.08240", "submitter": "Stephen Merity", "authors": "Stephen Merity, Nitish Shirish Keskar, Richard Socher", "title": "An Analysis of Neural Language Modeling at Multiple Scales", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many of the leading approaches in language modeling introduce novel, complex\nand specialized architectures. We take existing state-of-the-art word level\nlanguage models based on LSTMs and QRNNs and extend them to both larger\nvocabularies as well as character-level granularity. When properly tuned, LSTMs\nand QRNNs achieve state-of-the-art results on character-level (Penn Treebank,\nenwik8) and word-level (WikiText-103) datasets, respectively. Results are\nobtained in only 12 hours (WikiText-103) to 2 days (enwik8) using a single\nmodern GPU.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 06:25:47 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Merity", "Stephen", ""], ["Keskar", "Nitish Shirish", ""], ["Socher", "Richard", ""]]}, {"id": "1803.08312", "submitter": "Antonio Pertusa", "authors": "Aurelia Bustos and Antonio Pertusa", "title": "Learning Eligibility in Cancer Clinical Trials using Deep Neural\n  Networks", "comments": null, "journal-ref": "Applied Sciences, 8(7), 2018", "doi": "10.3390/app8071206", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interventional cancer clinical trials are generally too restrictive, and some\npatients are often excluded on the basis of comorbidity, past or concomitant\ntreatments, or the fact that they are over a certain age. The efficacy and\nsafety of new treatments for patients with these characteristics are,\ntherefore, not defined. In this work, we built a model to automatically predict\nwhether short clinical statements were considered inclusion or exclusion\ncriteria. We used protocols from cancer clinical trials that were available in\npublic registries from the last 18 years to train word-embeddings, and we\nconstructed a~dataset of 6M short free-texts labeled as eligible or not\neligible. A text classifier was trained using deep neural networks, with\npre-trained word-embeddings as inputs, to predict whether or not short\nfree-text statements describing clinical information were considered eligible.\nWe additionally analyzed the semantic reasoning of the word-embedding\nrepresentations obtained and were able to identify equivalent treatments for a\ntype of tumor analogous with the drugs used to treat other tumors. We show that\nrepresentation learning using {deep} neural networks can be successfully\nleveraged to extract the medical knowledge from clinical trial protocols for\npotentially assisting practitioners when prescribing treatments.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 11:38:53 GMT"}, {"version": "v2", "created": "Fri, 23 Mar 2018 14:45:57 GMT"}, {"version": "v3", "created": "Wed, 25 Jul 2018 10:06:35 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Bustos", "Aurelia", ""], ["Pertusa", "Antonio", ""]]}, {"id": "1803.08409", "submitter": "Andy Way", "authors": "Andy Way", "title": "Quality expectations of machine translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Translation (MT) is being deployed for a range of use-cases by\nmillions of people on a daily basis. There should, therefore, be no doubt as to\nthe utility of MT. However, not everyone is convinced that MT can be useful,\nespecially as a productivity enhancer for human translators. In this chapter, I\naddress this issue, describing how MT is currently deployed, how its output is\nevaluated and how this could be enhanced, especially as MT quality itself\nimproves. Central to these issues is the acceptance that there is no longer a\nsingle 'gold standard' measure of quality, such that the situation in which MT\nis deployed needs to be borne in mind, especially with respect to the expected\n'shelf-life' of the translation itself.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 15:31:39 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Way", "Andy", ""]]}, {"id": "1803.08419", "submitter": "Vinayak Mathur", "authors": "Vinayak Mathur and Arpit Singh", "title": "The Rapidly Changing Landscape of Conversational Agents", "comments": "14 pages, 7 figures. arXiv admin note: text overlap with\n  arXiv:1704.07130, arXiv:1507.04808, arXiv:1603.06155, arXiv:1611.06997,\n  arXiv:1704.08966 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational agents have become ubiquitous, ranging from goal-oriented\nsystems for helping with reservations to chit-chat models found in modern\nvirtual assistants. In this survey paper, we explore this fascinating field. We\nlook at some of the pioneering work that defined the field and gradually move\nto the current state-of-the-art models. We look at statistical, neural,\ngenerative adversarial network based and reinforcement learning based\napproaches and how they evolved. Along the way we discuss various challenges\nthat the field faces, lack of context in utterances, not having a good\nquantitative metric to compare models, lack of trust in agents because they do\nnot have a consistent persona etc. We structure this paper in a way that\nanswers these pertinent questions and discusses competing approaches to solve\nthem.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 15:53:59 GMT"}, {"version": "v2", "created": "Sat, 24 Mar 2018 16:52:27 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Mathur", "Vinayak", ""], ["Singh", "Arpit", ""]]}, {"id": "1803.08463", "submitter": "Pham Quang Nhat Minh Mr", "authors": "Pham Quang Nhat Minh", "title": "A Feature-Based Model for Nested Named-Entity Recognition at VLSP-2018\n  NER Evaluation Campaign", "comments": "5 pages, VLSP 2018 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this report, we describe our participant named-entity recognition system\nat VLSP 2018 evaluation campaign. We formalized the task as a sequence labeling\nproblem using BIO encoding scheme. We applied a feature-based model which\ncombines word, word-shape features, Brown-cluster-based features, and\nword-embedding-based features. We compare several methods to deal with nested\nentities in the dataset. We showed that combining tags of entities at all\nlevels for training a sequence labeling model (joint-tag model) improved the\naccuracy of nested named-entity recognition.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 17:04:32 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Minh", "Pham Quang Nhat", ""]]}, {"id": "1803.08471", "submitter": "Hanna Wallach", "authors": "Aaron Schein, Zhiwei Steven Wu, Alexandra Schofield, Mingyuan Zhou,\n  Hanna Wallach", "title": "Locally Private Bayesian Inference for Count Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.CR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general method for privacy-preserving Bayesian inference in\nPoisson factorization, a broad class of models that includes some of the most\nwidely used models in the social sciences. Our method satisfies limited\nprecision local privacy, a generalization of local differential privacy, which\nwe introduce to formulate privacy guarantees appropriate for sparse count data.\nWe develop an MCMC algorithm that approximates the locally private posterior\nover model parameters given data that has been locally privatized by the\ngeometric mechanism (Ghosh et al., 2012). Our solution is based on two\ninsights: 1) a novel reinterpretation of the geometric mechanism in terms of\nthe Skellam distribution (Skellam, 1946) and 2) a general theorem that relates\nthe Skellam to the Bessel distribution (Yuan & Kalbfleisch, 2000). We\ndemonstrate our method in two case studies on real-world email data in which we\nshow that our method consistently outperforms the commonly-used naive approach,\nobtaining higher quality topics in text and more accurate link prediction in\nnetworks. On some tasks, our privacy-preserving method even outperforms\nnon-private inference which conditions on the true data.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 17:14:29 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 01:20:02 GMT"}, {"version": "v3", "created": "Thu, 21 Feb 2019 21:44:51 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Schein", "Aaron", ""], ["Wu", "Zhiwei Steven", ""], ["Schofield", "Alexandra", ""], ["Zhou", "Mingyuan", ""], ["Wallach", "Hanna", ""]]}, {"id": "1803.08476", "submitter": "Diego Amancio Dr.", "authors": "Edilson A. Corr\\^ea Jr. and Diego R. Amancio", "title": "Word sense induction using word embeddings and community detection in\n  complex networks", "comments": null, "journal-ref": "Physica A, v. 523, p. 180-190, 2019", "doi": "10.1016/j.physa.2019.02.032", "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word Sense Induction (WSI) is the ability to automatically induce word senses\nfrom corpora. The WSI task was first proposed to overcome the limitations of\nmanually annotated corpus that are required in word sense disambiguation\nsystems. Even though several works have been proposed to induce word senses,\nexisting systems are still very limited in the sense that they make use of\nstructured, domain-specific knowledge sources. In this paper, we devise a\nmethod that leverages recent findings in word embeddings research to generate\ncontext embeddings, which are embeddings containing information about the\nsemantical context of a word. In order to induce senses, we modeled the set of\nambiguous words as a complex network. In the generated network, two instances\n(nodes) are connected if the respective context embeddings are similar. Upon\nusing well-established community detection methods to cluster the obtained\ncontext embeddings, we found that the proposed method yields excellent\nperformance for the WSI task. Our method outperformed competing algorithms and\nbaselines, in a completely unsupervised manner and without the need of any\nadditional structured knowledge source.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 17:22:42 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Corr\u00eaa", "Edilson A.", "Jr."], ["Amancio", "Diego R.", ""]]}, {"id": "1803.08493", "submitter": "Eric Zelikman", "authors": "Eric Zelikman, Richard Socher", "title": "Contextual Salience for Fast and Accurate Sentence Vectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised vector representations of sentences or documents are a major\nbuilding block for many language tasks such as sentiment classification.\nHowever, current methods are uninterpretable and slow or require large training\ndatasets. Recent word vector-based proposals implicitly assume that distances\nin a word embedding space are equally important, regardless of context. We\nintroduce contextual salience (CoSal), a measure of word importance that uses\nthe distribution of context vectors to normalize distances and weights. CoSal\nrelies on the insight that unusual word vectors disproportionately affect\nphrase vectors. A bag-of-words model with CoSal-based weights produces accurate\nunsupervised sentence or document representations for classification, requiring\nlittle computation to evaluate and only a single covariance calculation to\n``train.\" CoSal supports small contexts, out-of context words and outperforms\nSkipThought on most benchmarks, beats tf-idf on all benchmarks, and is\ncompetitive with the unsupervised state-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 17:54:21 GMT"}, {"version": "v2", "created": "Thu, 5 Apr 2018 12:03:51 GMT"}, {"version": "v3", "created": "Mon, 9 Apr 2018 16:15:54 GMT"}, {"version": "v4", "created": "Wed, 11 Apr 2018 01:03:53 GMT"}, {"version": "v5", "created": "Thu, 12 Apr 2018 17:04:27 GMT"}, {"version": "v6", "created": "Mon, 2 Nov 2020 15:13:20 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Zelikman", "Eric", ""], ["Socher", "Richard", ""]]}, {"id": "1803.08614", "submitter": "Jeremy Barnes", "authors": "Jeremy Barnes, Patrik Lambert, Toni Badia", "title": "MultiBooked: A Corpus of Basque and Catalan Hotel Reviews Annotated for\n  Aspect-level Sentiment Classification", "comments": "Accepted at LREC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  While sentiment analysis has become an established field in the NLP\ncommunity, research into languages other than English has been hindered by the\nlack of resources. Although much research in multi-lingual and cross-lingual\nsentiment analysis has focused on unsupervised or semi-supervised approaches,\nthese still require a large number of resources and do not reach the\nperformance of supervised approaches. With this in mind, we introduce two\ndatasets for supervised aspect-level sentiment analysis in Basque and Catalan,\nboth of which are under-resourced languages. We provide high-quality\nannotations and benchmarks with the hope that they will be useful to the\ngrowing community of researchers working on these languages.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 23:46:22 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Barnes", "Jeremy", ""], ["Lambert", "Patrik", ""], ["Badia", "Toni", ""]]}, {"id": "1803.08652", "submitter": "Ikuya Yamada", "authors": "Ikuya Yamada, Ryuji Tamaki, Hiroyuki Shindo, Yoshiyasu Takefuji", "title": "Studio Ousia's Quiz Bowl Question Answering System", "comments": "This is a preprint of a springer book chapter from NIPS 2017\n  Competitions proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this chapter, we describe our question answering system, which was the\nwinning system at the Human-Computer Question Answering (HCQA) Competition at\nthe Thirty-first Annual Conference on Neural Information Processing Systems\n(NIPS). The competition requires participants to address a factoid question\nanswering task referred to as quiz bowl. To address this task, we use two novel\nneural network models and combine these models with conventional information\nretrieval models using a supervised machine learning model. Our system achieved\nthe best performance among the systems submitted in the competition and won a\nmatch against six top human quiz experts by a wide margin.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 04:15:07 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Yamada", "Ikuya", ""], ["Tamaki", "Ryuji", ""], ["Shindo", "Hiroyuki", ""], ["Takefuji", "Yoshiyasu", ""]]}, {"id": "1803.08721", "submitter": "Florian Boudin", "authors": "Florian Boudin", "title": "Unsupervised Keyphrase Extraction with Multipartite Graphs", "comments": "Accepted at NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose an unsupervised keyphrase extraction model that encodes topical\ninformation within a multipartite graph structure. Our model represents\nkeyphrase candidates and topics in a single graph and exploits their mutually\nreinforcing relationship to improve candidate ranking. We further introduce a\nnovel mechanism to incorporate keyphrase selection preferences into the model.\nExperiments conducted on three widely used datasets show significant\nimprovements over state-of-the-art graph-based models.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 10:35:42 GMT"}, {"version": "v2", "created": "Mon, 16 Apr 2018 08:49:00 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Boudin", "Florian", ""]]}, {"id": "1803.08790", "submitter": "Md Saiful Islam", "authors": "Hemayet Ahmed Chowdhury, Tanvir Alam Nibir and Md. Saiful Islam", "title": "Sentiment Analysis of Comments on Rohingya Movement with Support Vector\n  Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Rohingya Movement and Crisis caused a huge uproar in the political and\neconomic state of Bangladesh. Refugee movement is a recurring event and a large\namount of data in the form of opinions remains on social media such as\nFacebook, with very little analysis done on them.To analyse the comments based\non all Rohingya related posts, we had to create and modify a classifier based\non the Support Vector Machine algorithm. The code is implemented in python and\nuses scikit-learn library. A dataset on Rohingya analysis is not currently\navailable so we had to use our own data set of 2500 positive and 2500 negative\ncomments. We specifically used a support vector machine with linear kernel. A\nprevious experiment was performed by us on the same dataset using the naive\nbayes algorithm, but that did not yield impressive results.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 15:30:03 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Chowdhury", "Hemayet Ahmed", ""], ["Nibir", "Tanvir Alam", ""], ["Islam", "Md. Saiful", ""]]}, {"id": "1803.08793", "submitter": "Jack Lanchantin", "authors": "Jack Lanchantin, Ji Gao", "title": "Exploring the Naturalness of Buggy Code with Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical language models are powerful tools which have been used for many\ntasks within natural language processing. Recently, they have been used for\nother sequential data such as source code.(Ray et al., 2015) showed that it is\npossible train an n-gram source code language mode, and use it to predict buggy\nlines in code by determining \"unnatural\" lines via entropy with respect to the\nlanguage model. In this work, we propose using a more advanced language\nmodeling technique, Long Short-term Memory recurrent neural networks, to model\nsource code and classify buggy lines based on entropy. We show that our method\nslightly outperforms an n-gram model in the buggy line classification task\nusing AUC.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 16:14:22 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Lanchantin", "Jack", ""], ["Gao", "Ji", ""]]}, {"id": "1803.08863", "submitter": "Enno Hermann", "authors": "Enno Hermann, Sharon Goldwater", "title": "Multilingual bottleneck features for subword modeling in zero-resource\n  languages", "comments": "5 pages, 2 figures, 4 tables; accepted at Interspeech 2018", "journal-ref": "Proc. Interspeech 2018, 2668-2672", "doi": "10.21437/Interspeech.2018-2334", "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we effectively develop speech technology for languages where no\ntranscribed data is available? Many existing approaches use no annotated\nresources at all, yet it makes sense to leverage information from large\nannotated corpora in other languages, for example in the form of multilingual\nbottleneck features (BNFs) obtained from a supervised speech recognition\nsystem. In this work, we evaluate the benefits of BNFs for subword modeling\n(feature extraction) in six unseen languages on a word discrimination task.\nFirst we establish a strong unsupervised baseline by combining two existing\nmethods: vocal tract length normalisation (VTLN) and the correspondence\nautoencoder (cAE). We then show that BNFs trained on a single language already\nbeat this baseline; including up to 10 languages results in additional\nimprovements which cannot be matched by just adding more data from a single\nlanguage. Finally, we show that the cAE can improve further on the BNFs if\nhigh-quality same-word pairs are available.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 16:18:27 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2018 11:23:55 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Hermann", "Enno", ""], ["Goldwater", "Sharon", ""]]}, {"id": "1803.08869", "submitter": "Grzegorz Chrupa{\\l}a", "authors": "Grzegorz Chrupa{\\l}a, Lieke Gelderloos, \\'Akos K\\'ad\\'ar, Afra\n  Alishahi", "title": "On the difficulty of a distributional semantics of spoken language", "comments": "Proceedings of the Society for Computation in Linguistics 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the domain of unsupervised learning most work on speech has focused on\ndiscovering low-level constructs such as phoneme inventories or word-like\nunits. In contrast, for written language, where there is a large body of work\non unsupervised induction of semantic representations of words, whole sentences\nand longer texts. In this study we examine the challenges of adapting these\napproaches from written to spoken language. We conjecture that unsupervised\nlearning of the semantics of spoken language becomes feasible if we abstract\nfrom the surface variability. We simulate this setting with a dataset of\nutterances spoken by a realistic but uniform synthetic voice. We evaluate two\nsimple unsupervised models which, to varying degrees of success, learn semantic\nrepresentations of speech fragments. Finally we present inconclusive results on\nhuman speech, and discuss the challenges inherent in learning distributional\nsemantic representations on unrestricted natural spoken language.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 16:30:06 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 13:52:41 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Chrupa\u0142a", "Grzegorz", ""], ["Gelderloos", "Lieke", ""], ["K\u00e1d\u00e1r", "\u00c1kos", ""], ["Alishahi", "Afra", ""]]}, {"id": "1803.08896", "submitter": "Somak Aditya", "authors": "Somak Aditya, Yezhou Yang, Chitta Baral", "title": "Explicit Reasoning over End-to-End Neural Architectures for Visual\n  Question Answering", "comments": "9 pages, 3 figures, AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many vision and language tasks require commonsense reasoning beyond\ndata-driven image and natural language processing. Here we adopt Visual\nQuestion Answering (VQA) as an example task, where a system is expected to\nanswer a question in natural language about an image. Current state-of-the-art\nsystems attempted to solve the task using deep neural architectures and\nachieved promising performance. However, the resulting systems are generally\nopaque and they struggle in understanding questions for which extra knowledge\nis required. In this paper, we present an explicit reasoning layer on top of a\nset of penultimate neural network based systems. The reasoning layer enables\nreasoning and answering questions where additional knowledge is required, and\nat the same time provides an interpretable interface to the end users.\nSpecifically, the reasoning layer adopts a Probabilistic Soft Logic (PSL) based\nengine to reason over a basket of inputs: visual relations, the semantic parse\nof the question, and background ontological knowledge from word2vec and\nConceptNet. Experimental analysis of the answers and the key evidential\npredicates generated on the VQA dataset validate our approach.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 17:17:16 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Aditya", "Somak", ""], ["Yang", "Yezhou", ""], ["Baral", "Chitta", ""]]}, {"id": "1803.08910", "submitter": "Dilek K\\\"u\\c{c}\\\"uk", "authors": "Dilek K\\\"u\\c{c}\\\"uk and Fazli Can", "title": "Stance Detection on Tweets: An SVM-based Approach", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stance detection is a subproblem of sentiment analysis where the stance of\nthe author of a piece of natural language text for a particular target (either\nexplicitly stated in the text or not) is explored. The stance output is usually\ngiven as Favor, Against, or Neither. In this paper, we target at stance\ndetection on sports-related tweets and present the performance results of our\nSVM-based stance classifiers on such tweets. First, we describe three versions\nof our proprietary tweet data set annotated with stance information, all of\nwhich are made publicly available for research purposes. Next, we evaluate SVM\nclassifiers using different feature sets for stance detection on this data set.\nThe employed features are based on unigrams, bigrams, hashtags, external links,\nemoticons, and lastly, named entities. The results indicate that joint use of\nthe features based on unigrams, hashtags, and named entities by SVM classifiers\nis a plausible approach for stance detection problem on sports-related tweets.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 17:49:04 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["K\u00fc\u00e7\u00fck", "Dilek", ""], ["Can", "Fazli", ""]]}, {"id": "1803.08966", "submitter": "Mahsa Ghasemi", "authors": "Lu Feng, Mahsa Ghasemi, Kai-Wei Chang, Ufuk Topcu", "title": "Counterexamples for Robotic Planning Explained in Structured Language", "comments": "Accepted for publication in International Conference on Robotics and\n  Automation (ICRA) Proceedings, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CL cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated techniques such as model checking have been used to verify models\nof robotic mission plans based on Markov decision processes (MDPs) and generate\ncounterexamples that may help diagnose requirement violations. However, such\nartifacts may be too complex for humans to understand, because existing\nrepresentations of counterexamples typically include a large number of paths or\na complex automaton. To help improve the interpretability of counterexamples,\nwe define a notion of explainable counterexample, which includes a set of\nstructured natural language sentences to describe the robotic behavior that\nlead to a requirement violation in an MDP model of robotic mission plan. We\npropose an approach based on mixed-integer linear programming for generating\nexplainable counterexamples that are minimal, sound and complete. We\ndemonstrate the usefulness of the proposed approach via a case study of\nwarehouse robots planning.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 20:14:51 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Feng", "Lu", ""], ["Ghasemi", "Mahsa", ""], ["Chang", "Kai-Wei", ""], ["Topcu", "Ufuk", ""]]}, {"id": "1803.08976", "submitter": "Yu-An Chung", "authors": "Yu-An Chung, James Glass", "title": "Speech2Vec: A Sequence-to-Sequence Framework for Learning Word\n  Embeddings from Speech", "comments": "Accepted to Interspeech 2018; camera-ready version. arXiv admin note:\n  text overlap with arXiv:1711.01515", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel deep neural network architecture,\nSpeech2Vec, for learning fixed-length vector representations of audio segments\nexcised from a speech corpus, where the vectors contain semantic information\npertaining to the underlying spoken words, and are close to other vectors in\nthe embedding space if their corresponding underlying spoken words are\nsemantically similar. The proposed model can be viewed as a speech version of\nWord2Vec. Its design is based on a RNN Encoder-Decoder framework, and borrows\nthe methodology of skipgrams or continuous bag-of-words for training. Learning\nword embeddings directly from speech enables Speech2Vec to make use of the\nsemantic information carried by speech that does not exist in plain text. The\nlearned word embeddings are evaluated and analyzed on 13 widely used word\nsimilarity benchmarks, and outperform word embeddings learned by Word2Vec from\nthe transcriptions.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 20:59:09 GMT"}, {"version": "v2", "created": "Sat, 9 Jun 2018 07:37:52 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Chung", "Yu-An", ""], ["Glass", "James", ""]]}, {"id": "1803.08983", "submitter": "Patrick Huber", "authors": "Patrick Huber and Jan Niehues and Alex Waibel", "title": "Automated Evaluation of Out-of-Context Errors", "comments": "LREC 2018, 5 pages, Out-of-Context Error Recognition, Automatic\n  Evaluation Dataset, Text Understanding, TEDTalk", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach to evaluate computational models for the task of\ntext understanding by the means of out-of-context error detection. Through the\nnovel design of our automated modification process, existing large-scale data\nsources can be adopted for a vast number of text understanding tasks. The data\nis thereby altered on a semantic level, allowing models to be tested against a\nchallenging set of modified text passages that require to comprise a broader\nnarrative discourse. Our newly introduced task targets actual real-world\nproblems of transcription and translation systems by inserting authentic\nout-of-context errors. The automated modification process is applied to the\n2016 TEDTalk corpus. Entirely automating the process allows the adoption of\ncomplete datasets at low cost, facilitating supervised learning procedures and\ndeeper networks to be trained and tested. To evaluate the quality of the\nmodification algorithm a language model and a supervised binary classification\nmodel are trained and tested on the altered dataset. A human baseline\nevaluation is examined to compare the results with human performance. The\noutcome of the evaluation task indicates the difficulty to detect semantic\nerrors for machine-learning algorithms and humans, showing that the errors\ncannot be identified when limited to a single sentence.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 21:20:00 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Huber", "Patrick", ""], ["Niehues", "Jan", ""], ["Waibel", "Alex", ""]]}, {"id": "1803.08991", "submitter": "Antonios Anastasopoulos", "authors": "Antonis Anastasopoulos and David Chiang", "title": "Leveraging translations for speech transcription in low-resource\n  settings", "comments": "to be presented at Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently proposed data collection frameworks for endangered language\ndocumentation aim not only to collect speech in the language of interest, but\nalso to collect translations into a high-resource language that will render the\ncollected resource interpretable. We focus on this scenario and explore whether\nwe can improve transcription quality under these extremely low-resource\nsettings with the assistance of text translations. We present a neural\nmulti-source model and evaluate several variations of it on three low-resource\ndatasets. We find that our multi-source model with shared attention outperforms\nthe baselines, reducing transcription character error rate by up to 12.3%.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 21:56:54 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 01:11:39 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Anastasopoulos", "Antonis", ""], ["Chiang", "David", ""]]}, {"id": "1803.09000", "submitter": "Yang Yu", "authors": "Yang Yu, Vincent Ng", "title": "WikiRank: Improving Keyphrase Extraction Based on Background Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keyphrase is an efficient representation of the main idea of documents. While\nbackground knowledge can provide valuable information about documents, they are\nrarely incorporated in keyphrase extraction methods. In this paper, we propose\nWikiRank, an unsupervised method for keyphrase extraction based on the\nbackground knowledge from Wikipedia. Firstly, we construct a semantic graph for\nthe document. Then we transform the keyphrase extraction problem into an\noptimization problem on the graph. Finally, we get the optimal keyphrase set to\nbe the output. Our method obtains improvements over other state-of-art models\nby more than 2% in F1-score.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 22:30:58 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Yu", "Yang", ""], ["Ng", "Vincent", ""]]}, {"id": "1803.09017", "submitter": "Yuxuan Wang", "authors": "Yuxuan Wang, Daisy Stanton, Yu Zhang, RJ Skerry-Ryan, Eric Battenberg,\n  Joel Shor, Ying Xiao, Fei Ren, Ye Jia, Rif A. Saurous", "title": "Style Tokens: Unsupervised Style Modeling, Control and Transfer in\n  End-to-End Speech Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose \"global style tokens\" (GSTs), a bank of embeddings\nthat are jointly trained within Tacotron, a state-of-the-art end-to-end speech\nsynthesis system. The embeddings are trained with no explicit labels, yet learn\nto model a large range of acoustic expressiveness. GSTs lead to a rich set of\nsignificant results. The soft interpretable \"labels\" they generate can be used\nto control synthesis in novel ways, such as varying speed and speaking style -\nindependently of the text content. They can also be used for style transfer,\nreplicating the speaking style of a single audio clip across an entire\nlong-form text corpus. When trained on noisy, unlabeled found data, GSTs learn\nto factorize noise and speaker identity, providing a path towards highly\nscalable but robust speech synthesis.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 23:56:49 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Wang", "Yuxuan", ""], ["Stanton", "Daisy", ""], ["Zhang", "Yu", ""], ["Skerry-Ryan", "RJ", ""], ["Battenberg", "Eric", ""], ["Shor", "Joel", ""], ["Xiao", "Ying", ""], ["Ren", "Fei", ""], ["Jia", "Ye", ""], ["Saurous", "Rif A.", ""]]}, {"id": "1803.09047", "submitter": "R J Skerry-Ryan", "authors": "RJ Skerry-Ryan, Eric Battenberg, Ying Xiao, Yuxuan Wang, Daisy\n  Stanton, Joel Shor, Ron J. Weiss, Rob Clark, Rif A. Saurous", "title": "Towards End-to-End Prosody Transfer for Expressive Speech Synthesis with\n  Tacotron", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an extension to the Tacotron speech synthesis architecture that\nlearns a latent embedding space of prosody, derived from a reference acoustic\nrepresentation containing the desired prosody. We show that conditioning\nTacotron on this learned embedding space results in synthesized audio that\nmatches the prosody of the reference signal with fine time detail even when the\nreference and synthesis speakers are different. Additionally, we show that a\nreference prosody embedding can be used to synthesize text that is different\nfrom that of the reference utterance. We define several quantitative and\nsubjective metrics for evaluating prosody transfer, and report results with\naccompanying audio samples from single-speaker and 44-speaker Tacotron models\non a prosody transfer task.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 02:52:58 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Skerry-Ryan", "RJ", ""], ["Battenberg", "Eric", ""], ["Xiao", "Ying", ""], ["Wang", "Yuxuan", ""], ["Stanton", "Daisy", ""], ["Shor", "Joel", ""], ["Weiss", "Ron J.", ""], ["Clark", "Rob", ""], ["Saurous", "Rif A.", ""]]}, {"id": "1803.09065", "submitter": "Julien Tissier", "authors": "Julien Tissier, Christophe Gravier, Amaury Habrard", "title": "Near-lossless Binarization of Word Embeddings", "comments": "Accepted as a long paper at AAAI 2019", "journal-ref": null, "doi": "10.1609/aaai.v33i01.33017104", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings are commonly used as a starting point in many NLP models to\nachieve state-of-the-art performances. However, with a large vocabulary and\nmany dimensions, these floating-point representations are expensive both in\nterms of memory and calculations which makes them unsuitable for use on\nlow-resource devices. The method proposed in this paper transforms real-valued\nembeddings into binary embeddings while preserving semantic information,\nrequiring only 128 or 256 bits for each vector. This leads to a small memory\nfootprint and fast vector operations. The model is based on an autoencoder\narchitecture, which also allows to reconstruct original vectors from the binary\nones. Experimental results on semantic similarity, text classification and\nsentiment analysis tasks show that the binarization of word embeddings only\nleads to a loss of ~2% in accuracy while vector size is reduced by 97%.\nFurthermore, a top-k benchmark demonstrates that using these binary vectors is\n30 times faster than using real-valued vectors.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 06:21:56 GMT"}, {"version": "v2", "created": "Mon, 28 May 2018 15:28:10 GMT"}, {"version": "v3", "created": "Thu, 15 Nov 2018 11:30:08 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Tissier", "Julien", ""], ["Gravier", "Christophe", ""], ["Habrard", "Amaury", ""]]}, {"id": "1803.09074", "submitter": "Yi Tay", "authors": "Yi Tay, Luu Anh Tuan, Siu Cheung Hui", "title": "Multi-range Reasoning for Machine Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose MRU (Multi-Range Reasoning Units), a new fast compositional\nencoder for machine comprehension (MC). Our proposed MRU encoders are\ncharacterized by multi-ranged gating, executing a series of parameterized\ncontract-and-expand layers for learning gating vectors that benefit from long\nand short-term dependencies. The aims of our approach are as follows: (1)\nlearning representations that are concurrently aware of long and short-term\ncontext, (2) modeling relationships between intra-document blocks and (3) fast\nand efficient sequence encoding. We show that our proposed encoder demonstrates\npromising results both as a standalone encoder and as well as a complementary\nbuilding block. We conduct extensive experiments on three challenging MC\ndatasets, namely RACE, SearchQA and NarrativeQA, achieving highly competitive\nperformance on all. On the RACE benchmark, our model outperforms DFN (Dynamic\nFusion Networks) by 1.5%-6% without using any recurrent or convolution layers.\nSimilarly, we achieve competitive performance relative to AMANDA on the\nSearchQA benchmark and BiDAF on the NarrativeQA benchmark without using any\nLSTM/GRU layers. Finally, incorporating MRU encoders with standard BiLSTM\narchitectures further improves performance, achieving state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 08:10:04 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Tay", "Yi", ""], ["Tuan", "Luu Anh", ""], ["Hui", "Siu Cheung", ""]]}, {"id": "1803.09091", "submitter": "Christos Christodoulopoulos", "authors": "Christos Christodoulopoulos, Arpit Mittal", "title": "Simple Large-scale Relation Extraction from Unstructured Text", "comments": "To be published in LREC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge-based question answering relies on the availability of facts, the\nmajority of which cannot be found in structured sources (e.g. Wikipedia\ninfo-boxes, Wikidata). One of the major components of extracting facts from\nunstructured text is Relation Extraction (RE). In this paper we propose a novel\nmethod for creating distant (weak) supervision labels for training a\nlarge-scale RE system. We also provide new evidence about the effectiveness of\nneural network approaches by decoupling the model architecture from the feature\ndesign of a state-of-the-art neural network system. Surprisingly, a much\nsimpler classifier trained on similar features performs on par with the highly\ncomplex neural network system (at 75x reduction to the training time),\nsuggesting that the features are a bigger contributor to the final performance.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 10:57:41 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Christodoulopoulos", "Christos", ""], ["Mittal", "Arpit", ""]]}, {"id": "1803.09103", "submitter": "Sowmya Vajjala", "authors": "Sowmya Vajjala", "title": "Machine Learning and Applied Linguistics", "comments": "Pre-print version of the article that is accepted for publication in\n  \"Encyclopedia of Applied Linguistics\"", "journal-ref": null, "doi": "10.1002/9781405198431.wbeal1486", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This entry introduces the topic of machine learning and provides an overview\nof its relevance for applied linguistics and language learning. The discussion\nwill focus on giving an introduction to the methods and applications of machine\nlearning in applied linguistics, and will provide references for further study.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 13:08:56 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Vajjala", "Sowmya", ""]]}, {"id": "1803.09123", "submitter": "Kriste Krstovski", "authors": "Kriste Krstovski and David M. Blei", "title": "Equation Embeddings", "comments": "12 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an unsupervised approach for discovering semantic representations\nof mathematical equations. Equations are challenging to analyze because each is\nunique, or nearly unique. Our method, which we call equation embeddings, finds\ngood representations of equations by using the representations of their\nsurrounding words. We used equation embeddings to analyze four collections of\nscientific articles from the arXiv, covering four computer science domains\n(NLP, IR, AI, and ML) and $\\sim$98.5k equations. Quantitatively, we found that\nequation embeddings provide better models when compared to existing word\nembedding approaches. Qualitatively, we found that equation embeddings provide\ncoherent semantic representations of equations and can capture semantic\nsimilarity to other equations and to words.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 15:04:17 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Krstovski", "Kriste", ""], ["Blei", "David M.", ""]]}, {"id": "1803.09164", "submitter": "Sameer Bansal", "authors": "Sameer Bansal, Herman Kamper, Karen Livescu, Adam Lopez, Sharon\n  Goldwater", "title": "Low-Resource Speech-to-Text Translation", "comments": "Added references; results remain unchanged. Accepted to Interspeech\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech-to-text translation has many potential applications for low-resource\nlanguages, but the typical approach of cascading speech recognition with\nmachine translation is often impossible, since the transcripts needed to train\na speech recognizer are usually not available for low-resource languages.\nRecent work has found that neural encoder-decoder models can learn to directly\ntranslate foreign speech in high-resource scenarios, without the need for\nintermediate transcription. We investigate whether this approach also works in\nsettings where both data and computation are limited. To make the approach\nefficient, we make several architectural changes, including a change from\ncharacter-level to word-level decoding. We find that this choice yields crucial\nspeed improvements that allow us to train with fewer computational resources,\nyet still performs well on frequent words. We explore models trained on between\n20 and 160 hours of data, and find that although models trained on less data\nhave considerably lower BLEU scores, they can still predict words with\nrelatively high precision and recall---around 50% for a model trained on 50\nhours of data, versus around 60% for the full 160 hour model. Thus, they may\nstill be useful for some low-resource scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 21:17:52 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2018 10:42:11 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Bansal", "Sameer", ""], ["Kamper", "Herman", ""], ["Livescu", "Karen", ""], ["Lopez", "Adam", ""], ["Goldwater", "Sharon", ""]]}, {"id": "1803.09189", "submitter": "Chenxi Liu", "authors": "Yu-Siang Wang, Chenxi Liu, Xiaohui Zeng, Alan Yuille", "title": "Scene Graph Parsing as Dependency Parsing", "comments": "To appear in NAACL 2018 as oral. Code is available at\n  https://github.com/Yusics/bist-parser/tree/sgparser", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of parsing structured knowledge graphs\nfrom textual descriptions. In particular, we consider the scene graph\nrepresentation that considers objects together with their attributes and\nrelations: this representation has been proved useful across a variety of\nvision and language applications. We begin by introducing an alternative but\nequivalent edge-centric view of scene graphs that connect to dependency parses.\nTogether with a careful redesign of label and action space, we combine the\ntwo-stage pipeline used in prior work (generic dependency parsing followed by\nsimple post-processing) into one, enabling end-to-end training. The scene\ngraphs generated by our learned neural dependency parser achieve an F-score\nsimilarity of 49.67% to ground truth graphs on our evaluation set, surpassing\nbest previous approaches by 5%. We further demonstrate the effectiveness of our\nlearned parser on image retrieval applications.\n", "versions": [{"version": "v1", "created": "Sun, 25 Mar 2018 01:53:29 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Wang", "Yu-Siang", ""], ["Liu", "Chenxi", ""], ["Zeng", "Xiaohui", ""], ["Yuille", "Alan", ""]]}, {"id": "1803.09230", "submitter": "Ziaul Hasan", "authors": "Zia Hasan, Sebastian Fischer", "title": "Pay More Attention - Neural Architectures for Question-Answering", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine comprehension is a representative task of natural language\nunderstanding. Typically, we are given context paragraph and the objective is\nto answer a question that depends on the context. Such a problem requires to\nmodel the complex interactions between the context paragraph and the question.\nLately, attention mechanisms have been found to be quite successful at these\ntasks and in particular, attention mechanisms with attention flow from both\ncontext-to-question and question-to-context have been proven to be quite\nuseful. In this paper, we study two state-of-the-art attention mechanisms\ncalled Bi-Directional Attention Flow (BiDAF) and Dynamic Co-Attention Network\n(DCN) and propose a hybrid scheme combining these two architectures that gives\nbetter overall performance. Moreover, we also suggest a new simpler attention\nmechanism that we call Double Cross Attention (DCA) that provides better\nresults compared to both BiDAF and Co-Attention mechanisms while providing\nsimilar performance as the hybrid scheme. The objective of our paper is to\nfocus particularly on the attention layer and to suggest improvements on that.\nOur experimental evaluations show that both our proposed models achieve\nsuperior results on the Stanford Question Answering Dataset (SQuAD) compared to\nBiDAF and DCN attention mechanisms.\n", "versions": [{"version": "v1", "created": "Sun, 25 Mar 2018 10:58:42 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Hasan", "Zia", ""], ["Fischer", "Sebastian", ""]]}, {"id": "1803.09288", "submitter": "Austin Kozlowski", "authors": "Austin C. Kozlowski, Matt Taddy, James A. Evans", "title": "The Geometry of Culture: Analyzing Meaning through Word Embeddings", "comments": null, "journal-ref": "American Sociological Review 2019, Vol. 84(5) 905-949", "doi": "10.1177/0003122419877135", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate the utility of a new methodological tool, neural-network word\nembedding models, for large-scale text analysis, revealing how these models\nproduce richer insights into cultural associations and categories than possible\nwith prior methods. Word embeddings represent semantic relations between words\nas geometric relationships between vectors in a high-dimensional space,\noperationalizing a relational model of meaning consistent with contemporary\ntheories of identity and culture. We show that dimensions induced by word\ndifferences (e.g. man - woman, rich - poor, black - white, liberal -\nconservative) in these vector spaces closely correspond to dimensions of\ncultural meaning, and the projection of words onto these dimensions reflects\nwidely shared cultural connotations when compared to surveyed responses and\nlabeled historical data. We pilot a method for testing the stability of these\nassociations, then demonstrate applications of word embeddings for\nmacro-cultural investigation with a longitudinal analysis of the coevolution of\ngender and class associations in the United States over the 20th century and a\ncomparative analysis of historic distinctions between markers of gender and\nclass in the U.S. and Britain. We argue that the success of these\nhigh-dimensional models motivates a move towards \"high-dimensional theorizing\"\nof meanings, identities and cultural processes.\n", "versions": [{"version": "v1", "created": "Sun, 25 Mar 2018 16:08:06 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Kozlowski", "Austin C.", ""], ["Taddy", "Matt", ""], ["Evans", "James A.", ""]]}, {"id": "1803.09337", "submitter": "Omri Koshorek", "authors": "Omri Koshorek, Adir Cohen, Noam Mor, Michael Rotman, Jonathan Berant", "title": "Text Segmentation as a Supervised Learning Task", "comments": "5 pages, 1 figure, NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text segmentation, the task of dividing a document into contiguous segments\nbased on its semantic structure, is a longstanding challenge in language\nunderstanding. Previous work on text segmentation focused on unsupervised\nmethods such as clustering or graph search, due to the paucity in labeled data.\nIn this work, we formulate text segmentation as a supervised learning problem,\nand present a large new dataset for text segmentation that is automatically\nextracted and labeled from Wikipedia. Moreover, we develop a segmentation model\nbased on this dataset and show that it generalizes well to unseen natural text.\n", "versions": [{"version": "v1", "created": "Sun, 25 Mar 2018 20:53:40 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Koshorek", "Omri", ""], ["Cohen", "Adir", ""], ["Mor", "Noam", ""], ["Rotman", "Michael", ""], ["Berant", "Jonathan", ""]]}, {"id": "1803.09371", "submitter": "Huan Sun", "authors": "Ziyu Yao, Daniel S. Weld, Wei-Peng Chen, Huan Sun", "title": "StaQC: A Systematically Mined Question-Code Dataset from Stack Overflow", "comments": "Accepted to the Web Conference 2018 (former WWW 2018), 11 pages, 6\n  figures", "journal-ref": null, "doi": "10.1145/3178876.3186081", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Stack Overflow (SO) has been a great source of natural language questions and\ntheir code solutions (i.e., question-code pairs), which are critical for many\ntasks including code retrieval and annotation. In most existing research,\nquestion-code pairs were collected heuristically and tend to have low quality.\nIn this paper, we investigate a new problem of systematically mining\nquestion-code pairs from Stack Overflow (in contrast to heuristically\ncollecting them). It is formulated as predicting whether or not a code snippet\nis a standalone solution to a question. We propose a novel Bi-View Hierarchical\nNeural Network which can capture both the programming content and the textual\ncontext of a code snippet (i.e., two views) to make a prediction. On two\nmanually annotated datasets in Python and SQL domain, our framework\nsubstantially outperforms heuristic methods with at least 15% higher F1 and\naccuracy. Furthermore, we present StaQC (Stack Overflow Question-Code pairs),\nthe largest dataset to date of ~148K Python and ~120K SQL question-code pairs,\nautomatically mined from SO using our framework. Under various case studies, we\ndemonstrate that StaQC can greatly help develop data-hungry models for\nassociating natural language with programming language.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 00:06:57 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Yao", "Ziyu", ""], ["Weld", "Daniel S.", ""], ["Chen", "Wei-Peng", ""], ["Sun", "Huan", ""]]}, {"id": "1803.09401", "submitter": "Anik Islam", "authors": "Anik Islam, Arifa Akter and Bayzid Ashik Hossain", "title": "HomeGuard: A Smart System to Deal with the Emergency Response of\n  Domestic Violence Victims", "comments": "10 pages, 5 figures, 2016 International Journal of Computer Science\n  Issues", "journal-ref": null, "doi": "10.20943/01201606.103112", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domestic violence is a silent crisis in the developing and underdeveloped\ncountries, though developed countries also remain drowned in the curse of it.\nIn developed countries, victims can easily report and ask help on the contrary\nin developing and underdeveloped countries victims hardly report the crimes and\nwhen it's noticed by the authority it's become too late to save or support the\nvictim. If this kind of problems can be identified at the very beginning of the\nevent and proper actions can be taken, it'll not only help the victim but also\nreduce the domestic violence crimes. This paper proposed a smart system which\ncan extract victim's situation and provide help according to it. Among of the\ndeveloping and underdeveloped countries Bangladesh has been chosen though the\nrate of reporting of domestic violence is low, the extreme report collected by\nauthorities is too high. Case studies collected by different NGO's relating to\ndomestic violence have been studied and applied to extract possible condition\nfor the victims.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 03:45:56 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Islam", "Anik", ""], ["Akter", "Arifa", ""], ["Hossain", "Bayzid Ashik", ""]]}, {"id": "1803.09402", "submitter": "Ritesh Kumar", "authors": "Ritesh Kumar, Aishwarya N. Reganti, Akshit Bhatia, Tushar Maheshwari", "title": "Aggression-annotated Corpus of Hindi-English Code-mixed Data", "comments": "Pre-print version of paper accepted for presentation at 11th edition\n  of the Language Resources and Evaluation Conference (LREC - 2018), 7-12 May\n  2018, Miyazaki (Japan)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the interaction over the web has increased, incidents of aggression and\nrelated events like trolling, cyberbullying, flaming, hate speech, etc. too\nhave increased manifold across the globe. While most of these behaviour like\nbullying or hate speech have predated the Internet, the reach and extent of the\nInternet has given these an unprecedented power and influence to affect the\nlives of billions of people. So it is of utmost significance and importance\nthat some preventive measures be taken to provide safeguard to the people using\nthe web such that the web remains a viable medium of communication and\nconnection, in general. In this paper, we discuss the development of an\naggression tagset and an annotated corpus of Hindi-English code-mixed data from\ntwo of the most popular social networking and social media platforms in India,\nTwitter and Facebook. The corpus is annotated using a hierarchical tagset of 3\ntop-level tags and 10 level 2 tags. The final dataset contains approximately\n18k tweets and 21k facebook comments and is being released for further research\nin the field.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 03:54:34 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Kumar", "Ritesh", ""], ["Reganti", "Aishwarya N.", ""], ["Bhatia", "Akshit", ""], ["Maheshwari", "Tushar", ""]]}, {"id": "1803.09405", "submitter": "Ritesh Kumar", "authors": "Ritesh Kumar, Bornini Lahiri, Deepak Alok, Atul Kr. Ojha, Mayank Jain,\n  Abdul Basit, Yogesh Dawer", "title": "Automatic Identification of Closely-related Indian Languages: Resources\n  and Experiments", "comments": "Paper accepted at the 4th Workshop in Indian Languages Data and\n  Resources (WILDRE - 4), 11th edition of the Language Resources and Evaluation\n  Conference (LREC - 2018), 7-12 May 2018, Miyazaki (Japan)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we discuss an attempt to develop an automatic language\nidentification system for 5 closely-related Indo-Aryan languages of India,\nAwadhi, Bhojpuri, Braj, Hindi and Magahi. We have compiled a comparable corpora\nof varying length for these languages from various resources. We discuss the\nmethod of creation of these corpora in detail. Using these corpora, a language\nidentification system was developed, which currently gives state of the art\naccuracy of 96.48\\%. We also used these corpora to study the similarity between\nthe 5 languages at the lexical level, which is the first data-based study of\nthe extent of closeness of these languages.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 04:02:00 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Kumar", "Ritesh", ""], ["Lahiri", "Bornini", ""], ["Alok", "Deepak", ""], ["Ojha", "Atul Kr.", ""], ["Jain", "Mayank", ""], ["Basit", "Abdul", ""], ["Dawer", "Yogesh", ""]]}, {"id": "1803.09519", "submitter": "Matthias Sperber", "authors": "Matthias Sperber, Jan Niehues, Graham Neubig, Sebastian St\\\"uker, Alex\n  Waibel", "title": "Self-Attentional Acoustic Models", "comments": "Published at Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-attention is a method of encoding sequences of vectors by relating these\nvectors to each-other based on pairwise similarities. These models have\nrecently shown promising results for modeling discrete sequences, but they are\nnon-trivial to apply to acoustic modeling due to computational and modeling\nissues. In this paper, we apply self-attention to acoustic modeling, proposing\nseveral improvements to mitigate these issues: First, self-attention memory\ngrows quadratically in the sequence length, which we address through a\ndownsampling technique. Second, we find that previous approaches to incorporate\nposition information into the model are unsuitable and explore other\nrepresentations and hybrid models to this end. Third, to stress the importance\nof local context in the acoustic signal, we propose a Gaussian biasing approach\nthat allows explicit control over the context range. Experiments find that our\nmodel approaches a strong baseline based on LSTMs with network-in-network\nconnections while being much faster to compute. Besides speed, we find that\ninterpretability is a strength of self-attentional acoustic models, and\ndemonstrate that self-attention heads learn a linguistically plausible division\nof labor.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 11:36:36 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2018 11:37:18 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Sperber", "Matthias", ""], ["Niehues", "Jan", ""], ["Neubig", "Graham", ""], ["St\u00fcker", "Sebastian", ""], ["Waibel", "Alex", ""]]}, {"id": "1803.09551", "submitter": "Guang-Neng Hu", "authors": "Guang-Neng Hu, Xin-Yu Dai, Feng-Yu Qiu, Rui Xia, Tao Li, Shu-Jian\n  Huang, Jia-Jun Chen", "title": "Collaborative Filtering with Topic and Social Latent Factors\n  Incorporating Implicit Feedback", "comments": "27 pages, 11 figures, 6 tables, ACM TKDD 2018", "journal-ref": null, "doi": "10.1145/3127873", "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems (RSs) provide an effective way of alleviating the\ninformation overload problem by selecting personalized items for different\nusers. Latent factors based collaborative filtering (CF) has become the popular\napproaches for RSs due to its accuracy and scalability. Recently, online social\nnetworks and user-generated content provide diverse sources for recommendation\nbeyond ratings. Although {\\em social matrix factorization} (Social MF) and {\\em\ntopic matrix factorization} (Topic MF) successfully exploit social relations\nand item reviews, respectively, both of them ignore some useful information. In\nthis paper, we investigate the effective data fusion by combining the\naforementioned approaches. First, we propose a novel model {\\em \\mbox{MR3}} to\njointly model three sources of information (i.e., ratings, item reviews, and\nsocial relations) effectively for rating prediction by aligning the latent\nfactors and hidden topics. Second, we incorporate the implicit feedback from\nratings into the proposed model to enhance its capability and to demonstrate\nits flexibility. We achieve more accurate rating prediction on real-life\ndatasets over various state-of-the-art methods. Furthermore, we measure the\ncontribution from each of the three data sources and the impact of implicit\nfeedback from ratings, followed by the sensitivity analysis of hyperparameters.\nEmpirical studies demonstrate the effectiveness and efficacy of our proposed\nmodel and its extension.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 12:46:13 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Hu", "Guang-Neng", ""], ["Dai", "Xin-Yu", ""], ["Qiu", "Feng-Yu", ""], ["Xia", "Rui", ""], ["Li", "Tao", ""], ["Huang", "Shu-Jian", ""], ["Chen", "Jia-Jun", ""]]}, {"id": "1803.09578", "submitter": "Nils Reimers", "authors": "Nils Reimers, Iryna Gurevych", "title": "Why Comparing Single Performance Scores Does Not Allow to Draw\n  Conclusions About Machine Learning Approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Developing state-of-the-art approaches for specific tasks is a major driving\nforce in our research community. Depending on the prestige of the task,\npublishing it can come along with a lot of visibility. The question arises how\nreliable are our evaluation methodologies to compare approaches?\n  One common methodology to identify the state-of-the-art is to partition data\ninto a train, a development and a test set. Researchers can train and tune\ntheir approach on some part of the dataset and then select the model that\nworked best on the development set for a final evaluation on unseen test data.\nTest scores from different approaches are compared, and performance differences\nare tested for statistical significance.\n  In this publication, we show that there is a high risk that a statistical\nsignificance in this type of evaluation is not due to a superior learning\napproach. Instead, there is a high risk that the difference is due to chance.\nFor example for the CoNLL 2003 NER dataset we observed in up to 26% of the\ncases type I errors (false positives) with a threshold of p < 0.05, i.e.,\nfalsely concluding a statistically significant difference between two identical\napproaches.\n  We prove that this evaluation setup is unsuitable to compare learning\napproaches. We formalize alternative evaluation setups based on score\ndistributions.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 13:35:14 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Reimers", "Nils", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1803.09641", "submitter": "Deepak P", "authors": "Deepak P", "title": "Unsupervised Separation of Transliterable and Native Words for Malayalam", "comments": "10 pages, Proceedings of 14th International Conference on Natural\n  Language Processing, Kolkata, India. 18-21 December, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentiating intrinsic language words from transliterable words is a key\nstep aiding text processing tasks involving different natural languages. We\nconsider the problem of unsupervised separation of transliterable words from\nnative words for text in Malayalam language. Outlining a key observation on the\ndiversity of characters beyond the word stem, we develop an optimization method\nto score words based on their nativeness. Our method relies on the usage of\nprobability distributions over character n-grams that are refined in step with\nthe nativeness scorings in an iterative optimization formulation. Using an\nempirical evaluation, we illustrate that our method, DTIM, provides significant\nimprovements in nativeness scoring for Malayalam, establishing DTIM as the\npreferred method for the task.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 15:01:52 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["P", "Deepak", ""]]}, {"id": "1803.09720", "submitter": "Simon \\v{S}uster", "authors": "Simon \\v{S}uster and Walter Daelemans", "title": "CliCR: A Dataset of Clinical Case Reports for Machine Reading\n  Comprehension", "comments": "Accepted at NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new dataset for machine comprehension in the medical domain. Our\ndataset uses clinical case reports with around 100,000 gap-filling queries\nabout these cases. We apply several baselines and state-of-the-art neural\nreaders to the dataset, and observe a considerable gap in performance (20% F1)\nbetween the best human and machine readers. We analyze the skills required for\nsuccessful answering and show how reader performance varies depending on the\napplicable skills. We find that inferences using domain knowledge and object\ntracking are the most frequently required skills, and that recognizing omitted\ninformation and spatio-temporal reasoning are the most difficult for the\nmachines.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 17:20:23 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["\u0160uster", "Simon", ""], ["Daelemans", "Walter", ""]]}, {"id": "1803.09745", "submitter": "Tyler Gray", "authors": "Tyler J. Gray, Andrew J. Reagan, Peter Sheridan Dodds, and Christopher\n  M. Danforth", "title": "English verb regularization in books and tweets", "comments": "16 pages, 10 figures, and 4 tables. Online appendices at\n  https://www.uvm.edu/storylab/share/papers/gray2018a/ ; Updated to journal\n  version with minor differences from first version", "journal-ref": "PLOS ONE 13(12): e0209651, 2018", "doi": "10.1371/journal.pone.0209651", "report-no": null, "categories": "cs.CL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The English language has evolved dramatically throughout its lifespan, to the\nextent that a modern speaker of Old English would be incomprehensible without\ntranslation. One concrete indicator of this process is the movement from\nirregular to regular (-ed) forms for the past tense of verbs. In this study we\nquantify the extent of verb regularization using two vastly disparate datasets:\n(1) Six years of published books scanned by Google (2003--2008), and (2) A\ndecade of social media messages posted to Twitter (2008--2017). We find that\nthe extent of verb regularization is greater on Twitter, taken as a whole, than\nin English Fiction books. Regularization is also greater for tweets geotagged\nin the United States relative to American English books, but the opposite is\ntrue for tweets geotagged in the United Kingdom relative to British English\nbooks. We also find interesting regional variations in regularization across\ncounties in the United States. However, once differences in population are\naccounted for, we do not identify strong correlations with socio-demographic\nvariables such as education or income.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 18:00:00 GMT"}, {"version": "v2", "created": "Fri, 4 Jan 2019 00:26:27 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Gray", "Tyler J.", ""], ["Reagan", "Andrew J.", ""], ["Dodds", "Peter Sheridan", ""], ["Danforth", "Christopher M.", ""]]}, {"id": "1803.09816", "submitter": "Deblin Bagchi", "authors": "Deblin Bagchi, Peter Plantinga, Adam Stiff and Eric Fosler-Lussier", "title": "Spectral feature mapping with mimic loss for robust speech recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the task of speech enhancement, local learning objectives are agnostic to\nphonetic structures helpful for speech recognition. We propose to add a global\ncriterion to ensure de-noised speech is useful for downstream tasks like ASR.\nWe first train a spectral classifier on clean speech to predict senone labels.\nThen, the spectral classifier is joined with our speech enhancer as a noisy\nspeech recognizer. This model is taught to imitate the output of the spectral\nclassifier alone on clean speech. This \\textit{mimic loss} is combined with the\ntraditional local criterion to train the speech enhancer to produce de-noised\nspeech. Feeding the de-noised speech to an off-the-shelf Kaldi training recipe\nfor the CHiME-2 corpus shows significant improvements in WER.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 19:56:21 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Bagchi", "Deblin", ""], ["Plantinga", "Peter", ""], ["Stiff", "Adam", ""], ["Fosler-Lussier", "Eric", ""]]}, {"id": "1803.09832", "submitter": "Matilde Marcolli", "authors": "Andrew Ortegaray, Robert C. Berwick, Matilde Marcolli", "title": "Heat Kernel analysis of Syntactic Structures", "comments": "20 pages, LaTeX, png figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider two different data sets of syntactic parameters and we discuss\nhow to detect relations between parameters through a heat kernel method\ndeveloped by Belkin-Niyogi, which produces low dimensional representations of\nthe data, based on Laplace eigenfunctions, that preserve neighborhood\ninformation. We analyze the different connectivity and clustering structures\nthat arise in the two datasets, and the regions of maximal variance in the\ntwo-parameter space of the Belkin-Niyogi construction, which identify\npreferable choices of independent variables. We compute clustering coefficients\nand their variance.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 20:38:31 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Ortegaray", "Andrew", ""], ["Berwick", "Robert C.", ""], ["Marcolli", "Matilde", ""]]}, {"id": "1803.09840", "submitter": "Valentina Presutti", "authors": "Luigi Asprino, Valerio Basile, Paolo Ciancarini, Valentina Presutti", "title": "Empirical Analysis of Foundational Distinctions in Linked Open Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Web and its Semantic extension (i.e. Linked Open Data) contain open\nglobal-scale knowledge and make it available to potentially intelligent\nmachines that want to benefit from it. Nevertheless, most of Linked Open Data\nlack ontological distinctions and have sparse axiomatisation. For example,\ndistinctions such as whether an entity is inherently a class or an individual,\nor whether it is a physical object or not, are hardly expressed in the data,\nalthough they have been largely studied and formalised by foundational\nontologies (e.g. DOLCE, SUMO). These distinctions belong to common sense too,\nwhich is relevant for many artificial intelligence tasks such as natural\nlanguage understanding, scene recognition, and the like. There is a gap between\nfoundational ontologies, that often formalise or are inspired by pre-existing\nphilosophical theories and are developed with a top-down approach, and Linked\nOpen Data that mostly derive from existing databases or crowd-based effort\n(e.g. DBpedia, Wikidata). We investigate whether machines can learn\nfoundational distinctions over Linked Open Data entities, and if they match\ncommon sense. We want to answer questions such as \"does the DBpedia entity for\ndog refer to a class or to an instance?\". We report on a set of experiments\nbased on machine learning and crowdsourcing that show promising results.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 20:56:30 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 09:54:38 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Asprino", "Luigi", ""], ["Basile", "Valerio", ""], ["Ciancarini", "Paolo", ""], ["Presutti", "Valentina", ""]]}, {"id": "1803.09845", "submitter": "Jiasen Lu", "authors": "Jiasen Lu, Jianwei Yang, Dhruv Batra, Devi Parikh", "title": "Neural Baby Talk", "comments": "12 pages, 7 figures, CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel framework for image captioning that can produce natural\nlanguage explicitly grounded in entities that object detectors find in the\nimage. Our approach reconciles classical slot filling approaches (that are\ngenerally better grounded in images) with modern neural captioning approaches\n(that are generally more natural sounding and accurate). Our approach first\ngenerates a sentence `template' with slot locations explicitly tied to specific\nimage regions. These slots are then filled in by visual concepts identified in\nthe regions by object detectors. The entire architecture (sentence template\ngeneration and slot filling with object detectors) is end-to-end\ndifferentiable. We verify the effectiveness of our proposed model on different\nimage captioning tasks. On standard image captioning and novel object\ncaptioning, our model reaches state-of-the-art on both COCO and Flickr30k\ndatasets. We also demonstrate that our model has unique advantages when the\ntrain and test distributions of scene compositions -- and hence language priors\nof associated captions -- are different. Code has been made available at:\nhttps://github.com/jiasenlu/NeuralBabyTalk\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 01:59:56 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Lu", "Jiasen", ""], ["Yang", "Jianwei", ""], ["Batra", "Dhruv", ""], ["Parikh", "Devi", ""]]}, {"id": "1803.09901", "submitter": "Nick Dingwall", "authors": "Nicholas Dingwall and Christopher Potts", "title": "Mittens: An Extension of GloVe for Learning Domain-Specialized\n  Representations", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We present a simple extension of the GloVe representation learning model that\nbegins with general-purpose representations and updates them based on data from\na specialized domain. We show that the resulting representations can lead to\nfaster learning and better results on a variety of tasks.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 05:23:01 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Dingwall", "Nicholas", ""], ["Potts", "Christopher", ""]]}, {"id": "1803.10132", "submitter": "Ke Wang", "authors": "Ke Wang, Junbo Zhang, Sining Sun, Yujun Wang, Fei Xiang, Lei Xie", "title": "Investigating Generative Adversarial Networks based Speech\n  Dereverberation for Robust Speech Recognition", "comments": "Interspeech 2018", "journal-ref": "Proceedings of Interspeech, 2018, pp. 1581-1585", "doi": "10.21437/Interspeech.2018-1780", "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the use of generative adversarial networks (GANs) in speech\ndereverberation for robust speech recognition. GANs have been recently studied\nfor speech enhancement to remove additive noises, but there still lacks of a\nwork to examine their ability in speech dereverberation and the advantages of\nusing GANs have not been fully established. In this paper, we provide deep\ninvestigations in the use of GAN-based dereverberation front-end in ASR. First,\nwe study the effectiveness of different dereverberation networks (the generator\nin GAN) and find that LSTM leads a significant improvement as compared with\nfeed-forward DNN and CNN in our dataset. Second, further adding residual\nconnections in the deep LSTMs can boost the performance as well. Finally, we\nfind that, for the success of GAN, it is important to update the generator and\nthe discriminator using the same mini-batch data during training. Moreover,\nusing reverberant spectrogram as a condition to discriminator, as suggested in\nprevious studies, may degrade the performance. In summary, our GAN-based\ndereverberation front-end achieves 14%-19% relative CER reduction as compared\nto the baseline DNN dereverberation network when tested on a strong\nmulti-condition training acoustic model.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 15:23:12 GMT"}, {"version": "v2", "created": "Sun, 17 Jun 2018 08:15:04 GMT"}, {"version": "v3", "created": "Thu, 25 Oct 2018 07:01:25 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Wang", "Ke", ""], ["Zhang", "Junbo", ""], ["Sun", "Sining", ""], ["Wang", "Yujun", ""], ["Xiang", "Fei", ""], ["Xie", "Lei", ""]]}, {"id": "1803.10146", "submitter": "Ke Wang", "authors": "Ke Wang, Junbo Zhang, Yujun Wang, Lei Xie", "title": "Empirical Evaluation of Speaker Adaptation on DNN based Acoustic Model", "comments": "Interspeech 2018", "journal-ref": "Proceedings of Interspeech, 2018, pp. 2429-2433", "doi": "10.21437/Interspeech.2018-1897", "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker adaptation aims to estimate a speaker specific acoustic model from a\nspeaker independent one to minimize the mismatch between the training and\ntesting conditions arisen from speaker variabilities. A variety of neural\nnetwork adaptation methods have been proposed since deep learning models have\nbecome the main stream. But there still lacks an experimental comparison\nbetween different methods, especially when DNN-based acoustic models have been\nadvanced greatly. In this paper, we aim to close this gap by providing an\nempirical evaluation of three typical speaker adaptation methods: LIN, LHUC and\nKLD. Adaptation experiments, with different size of adaptation data, are\nconducted on a strong TDNN-LSTM acoustic model. More challengingly, here, the\nsource and target we are concerned with are standard Mandarin speaker model and\naccented Mandarin speaker model. We compare the performances of different\nmethods and their combinations. Speaker adaptation performance is also examined\nby speaker's accent degree.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 15:39:46 GMT"}, {"version": "v2", "created": "Sun, 17 Jun 2018 08:14:42 GMT"}, {"version": "v3", "created": "Thu, 25 Oct 2018 07:11:54 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Wang", "Ke", ""], ["Zhang", "Junbo", ""], ["Wang", "Yujun", ""], ["Xie", "Lei", ""]]}, {"id": "1803.10299", "submitter": "Adithya Renduchintala", "authors": "Adithya Renduchintala, Shuoyang Ding, Matthew Wiesner and Shinji\n  Watanabe", "title": "Multi-Modal Data Augmentation for End-to-End ASR", "comments": "5 Pages, 1 Figure, accepted at INTERSPEECH 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We present a new end-to-end architecture for automatic speech recognition\n(ASR) that can be trained using \\emph{symbolic} input in addition to the\ntraditional acoustic input. This architecture utilizes two separate encoders:\none for acoustic input and another for symbolic input, both sharing the\nattention and decoder parameters. We call this architecture a multi-modal data\naugmentation network (MMDA), as it can support multi-modal (acoustic and\nsymbolic) input and enables seamless mixing of large text datasets with\nsignificantly smaller transcribed speech corpora during training. We study\ndifferent ways of transforming large text corpora into a symbolic form suitable\nfor training our MMDA network. Our best MMDA setup obtains small improvements\non character error rate (CER), and as much as 7-10\\% relative word error rate\n(WER) improvement over a baseline both with and without an external language\nmodel.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 20:12:39 GMT"}, {"version": "v2", "created": "Fri, 30 Mar 2018 00:39:23 GMT"}, {"version": "v3", "created": "Mon, 18 Jun 2018 05:53:10 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Renduchintala", "Adithya", ""], ["Ding", "Shuoyang", ""], ["Wiesner", "Matthew", ""], ["Watanabe", "Shinji", ""]]}, {"id": "1803.10357", "submitter": "Antoine Bosselut", "authors": "Asli Celikyilmaz, Antoine Bosselut, Xiaodong He, Yejin Choi", "title": "Deep Communicating Agents for Abstractive Summarization", "comments": "Accepted for publication at NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present deep communicating agents in an encoder-decoder architecture to\naddress the challenges of representing a long document for abstractive\nsummarization. With deep communicating agents, the task of encoding a long text\nis divided across multiple collaborating agents, each in charge of a subsection\nof the input text. These encoders are connected to a single decoder, trained\nend-to-end using reinforcement learning to generate a focused and coherent\nsummary. Empirical results demonstrate that multiple communicating encoders\nlead to a higher quality summary compared to several strong baselines,\nincluding those based on a single encoder or multiple non-communicating\nencoders.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 23:29:23 GMT"}, {"version": "v2", "created": "Fri, 4 May 2018 23:15:42 GMT"}, {"version": "v3", "created": "Wed, 15 Aug 2018 18:54:22 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Celikyilmaz", "Asli", ""], ["Bosselut", "Antoine", ""], ["He", "Xiaodong", ""], ["Choi", "Yejin", ""]]}, {"id": "1803.10384", "submitter": "Yuan Gong", "authors": "Yuan Gong and Christian Poellabauer", "title": "Topic Modeling Based Multi-modal Depression Detection", "comments": "Proceedings of the 7th Audio/Visual Emotion Challenge and Workshop\n  (AVEC). (Official Depression Challenge Winner)", "journal-ref": null, "doi": "10.1145/3133944.3133945", "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Major depressive disorder is a common mental disorder that affects almost 7%\nof the adult U.S. population. The 2017 Audio/Visual Emotion Challenge (AVEC)\nasks participants to build a model to predict depression levels based on the\naudio, video, and text of an interview ranging between 7-33 minutes. Since\naveraging features over the entire interview will lose most temporal\ninformation, how to discover, capture, and preserve useful temporal details for\nsuch a long interview are significant challenges. Therefore, we propose a novel\ntopic modeling based approach to perform context-aware analysis of the\nrecording. Our experiments show that the proposed approach outperforms\ncontext-unaware methods and the challenge baselines for all metrics.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 02:12:48 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Gong", "Yuan", ""], ["Poellabauer", "Christian", ""]]}, {"id": "1803.10421", "submitter": "Daniyar Itegulov", "authors": "Daniyar Itegulov and Ekaterina Lebedeva", "title": "Handling Verb Phrase Anaphora with Dependent Types and Events", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper studies how dependent typed events can be used to treat verb\nphrase anaphora. We introduce a framework that extends Dependent Type Semantics\n(DTS) with a new atomic type for neo-Davidsonian events and an extended\n@-operator that can return new events that share properties of events\nreferenced by verb phrase anaphora. The proposed framework, along with\nillustrative examples of its use, are presented after a brief overview of the\nnecessary background and of the major challenges posed by verb phrase anaphora.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 05:47:31 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Itegulov", "Daniyar", ""], ["Lebedeva", "Ekaterina", ""]]}, {"id": "1803.10525", "submitter": "Andros Tjandra", "authors": "Andros Tjandra, Sakriani Sakti, Satoshi Nakamura", "title": "Machine Speech Chain with One-shot Speaker Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In previous work, we developed a closed-loop speech chain model based on deep\nlearning, in which the architecture enabled the automatic speech recognition\n(ASR) and text-to-speech synthesis (TTS) components to mutually improve their\nperformance. This was accomplished by the two parts teaching each other using\nboth labeled and unlabeled data. This approach could significantly improve\nmodel performance within a single-speaker speech dataset, but only a slight\nincrease could be gained in multi-speaker tasks. Furthermore, the model is\nstill unable to handle unseen speakers. In this paper, we present a new speech\nchain mechanism by integrating a speaker recognition model inside the loop. We\nalso propose extending the capability of TTS to handle unseen speakers by\nimplementing one-shot speaker adaptation. This enables TTS to mimic voice\ncharacteristics from one speaker to another with only a one-shot speaker\nsample, even from a text without any speaker information. In the speech chain\nloop mechanism, ASR also benefits from the ability to further learn an\narbitrary speaker's characteristics from the generated speech waveform,\nresulting in a significant improvement in the recognition rate.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 11:06:15 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Tjandra", "Andros", ""], ["Sakti", "Sakriani", ""], ["Nakamura", "Satoshi", ""]]}, {"id": "1803.10547", "submitter": "Nurendra Choudhary", "authors": "Nurendra Choudhary, Rajat Singh, Ishita Bindlish and Manish\n  Shrivastava", "title": "Neural Network Architecture for Credibility Assessment of Textual Claims", "comments": "Best Paper Award at 19th International Conference on Computational\n  Linguistics and Intelligent Text Processing, March 2018, Hanoi, Vietnam", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text articles with false claims, especially news, have recently become\naggravating for the Internet users. These articles are in wide circulation and\nreaders face difficulty discerning fact from fiction. Previous work on\ncredibility assessment has focused on factual analysis and linguistic features.\nThe task's main challenge is the distinction between the features of true and\nfalse articles. In this paper, we propose a novel approach called Credibility\nOutcome (CREDO) which aims at scoring the credibility of an article in an open\ndomain setting.\n  CREDO consists of different modules for capturing various features\nresponsible for the credibility of an article. These features includes\ncredibility of the article's source and author, semantic similarity between the\narticle and related credible articles retrieved from a knowledge base, and\nsentiments conveyed by the article. A neural network architecture learns the\ncontribution of each of these modules to the overall credibility of an article.\nExperiments on Snopes dataset reveals that CREDO outperforms the\nstate-of-the-art approaches based on linguistic features.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 11:50:32 GMT"}, {"version": "v2", "created": "Fri, 30 Mar 2018 10:42:04 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 21:30:25 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Choudhary", "Nurendra", ""], ["Singh", "Rajat", ""], ["Bindlish", "Ishita", ""], ["Shrivastava", "Manish", ""]]}, {"id": "1803.10631", "submitter": "Thomas Wolf", "authors": "Thomas Wolf, Julien Chaumond, Clement Delangue", "title": "Meta-Learning a Dynamical Language Model", "comments": "5 pages, 2 figures, accepted at ICLR 2018 workshop track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of word-level language modeling and study the\npossibility of combining hidden-states-based short-term representations with\nmedium-term representations encoded in dynamical weights of a language model.\nOur work extends recent experiments on language models with dynamically\nevolving weights by casting the language modeling problem into an online\nlearning-to-learn framework in which a meta-learner is trained by\ngradient-descent to continuously update a language model weights.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 14:08:12 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Wolf", "Thomas", ""], ["Chaumond", "Julien", ""], ["Delangue", "Clement", ""]]}, {"id": "1803.10916", "submitter": "Lei Xie", "authors": "Changhao Shan, Junbo Zhang, Yujun Wang, Lei Xie", "title": "Attention-based End-to-End Models for Small-Footprint Keyword Spotting", "comments": "attention-based model, end-to-end keyword spotting, convolutional\n  neural networks, recurrent neural networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an attention-based end-to-end neural approach for\nsmall-footprint keyword spotting (KWS), which aims to simplify the pipelines of\nbuilding a production-quality KWS system. Our model consists of an encoder and\nan attention mechanism. The encoder transforms the input signal into a high\nlevel representation using RNNs. Then the attention mechanism weights the\nencoder features and generates a fixed-length vector. Finally, by linear\ntransformation and softmax function, the vector becomes a score used for\nkeyword detection. We also evaluate the performance of different encoder\narchitectures, including LSTM, GRU and CRNN. Experiments on real-world wake-up\ndata show that our approach outperforms the recent Deep KWS approach by a large\nmargin and the best performance is achieved by CRNN. To be more specific, with\n~84K parameters, our attention-based model achieves 1.02% false rejection rate\n(FRR) at 1.0 false alarm (FA) per hour.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 03:32:59 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Shan", "Changhao", ""], ["Zhang", "Junbo", ""], ["Wang", "Yujun", ""], ["Xie", "Lei", ""]]}, {"id": "1803.10952", "submitter": "Yi-Chen Chen", "authors": "Yi-Chen Chen, Chia-Hao Shen, Sung-Feng Huang, Hung-yi Lee", "title": "Towards Unsupervised Automatic Speech Recognition Trained by Unaligned\n  Speech and Text only", "comments": "Code is released:\n  https://github.com/grtzsohalf/Towards-Unsupervised-ASR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic speech recognition (ASR) has been widely researched with supervised\napproaches, while many low-resourced languages lack audio-text aligned data,\nand supervised methods cannot be applied on them.\n  In this work, we propose a framework to achieve unsupervised ASR on a read\nEnglish speech dataset, where audio and text are unaligned. In the first stage,\neach word-level audio segment in the utterances is represented by a vector\nrepresentation extracted by a sequence-of-sequence autoencoder, in which\nphonetic information and speaker information are disentangled.\n  Secondly, semantic embeddings of audio segments are trained from the vector\nrepresentations using a skip-gram model. Last but not the least, an\nunsupervised method is utilized to transform semantic embeddings of audio\nsegments to text embedding space, and finally the transformed embeddings are\nmapped to words.\n  With the above framework, we are towards unsupervised ASR trained by\nunaligned text and speech only.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 08:03:45 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 14:45:22 GMT"}, {"version": "v3", "created": "Sat, 11 Aug 2018 08:54:40 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Chen", "Yi-Chen", ""], ["Shen", "Chia-Hao", ""], ["Huang", "Sung-Feng", ""], ["Lee", "Hung-yi", ""]]}, {"id": "1803.11045", "submitter": "Ryan Wesslen", "authors": "Ryan Wesslen", "title": "Computer-Assisted Text Analysis for Social Science: Topic Models and\n  Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic models are a family of statistical-based algorithms to summarize,\nexplore and index large collections of text documents. After a decade of\nresearch led by computer scientists, topic models have spread to social science\nas a new generation of data-driven social scientists have searched for tools to\nexplore large collections of unstructured text. Recently, social scientists\nhave contributed to topic model literature with developments in causal\ninference and tools for handling the problem of multi-modality. In this paper,\nI provide a literature review on the evolution of topic modeling including\nextensions for document covariates, methods for evaluation and interpretation,\nand advances in interactive visualizations along with each aspect's relevance\nand application for social science research.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 13:11:32 GMT"}, {"version": "v2", "created": "Tue, 3 Apr 2018 14:33:39 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Wesslen", "Ryan", ""]]}, {"id": "1803.11070", "submitter": "Piji Li", "authors": "Piji Li, Lidong Bing, Wai Lam", "title": "Actor-Critic based Training Framework for Abstractive Summarization", "comments": "10 pages. arXiv admin note: text overlap with arXiv:1708.00625", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a training framework for neural abstractive summarization based on\nactor-critic approaches from reinforcement learning. In the traditional neural\nnetwork based methods, the objective is only to maximize the likelihood of the\npredicted summaries, no other assessment constraints are considered, which may\ngenerate low-quality summaries or even incorrect sentences. To alleviate this\nproblem, we employ an actor-critic framework to enhance the training procedure.\nFor the actor, we employ the typical attention based sequence-to-sequence\n(seq2seq) framework as the policy network for summary generation. For the\ncritic, we combine the maximum likelihood estimator with a well designed global\nsummary quality estimator which is a neural network based binary classifier\naiming to make the generated summaries indistinguishable from the human-written\nones. Policy gradient method is used to conduct the parameter learning. An\nalternating training strategy is proposed to conduct the joint training of the\nactor and critic models. Extensive experiments on some benchmark datasets in\ndifferent languages show that our framework achieves improvements over the\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 02:47:51 GMT"}, {"version": "v2", "created": "Wed, 15 Aug 2018 15:59:46 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Li", "Piji", ""], ["Bing", "Lidong", ""], ["Lam", "Wai", ""]]}, {"id": "1803.11112", "submitter": "Yogarshi Vyas", "authors": "Yogarshi Vyas, Xing Niu, Marine Carpuat", "title": "Identifying Semantic Divergences in Parallel Text without Annotations", "comments": "Accepted as a full paper to NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing that even correct translations are not always semantically\nequivalent, we automatically detect meaning divergences in parallel sentence\npairs with a deep neural model of bilingual semantic similarity which can be\ntrained for any parallel corpus without any manual annotation. We show that our\nsemantic model detects divergences more accurately than models based on surface\nfeatures derived from word alignments, and that these divergences matter for\nneural machine translation.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 15:18:09 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Vyas", "Yogarshi", ""], ["Niu", "Xing", ""], ["Carpuat", "Marine", ""]]}, {"id": "1803.11138", "submitter": "Kristina Gulordava", "authors": "Kristina Gulordava, Piotr Bojanowski, Edouard Grave, Tal Linzen, Marco\n  Baroni", "title": "Colorless green recurrent networks dream hierarchically", "comments": "Accepted to NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) have achieved impressive results in a\nvariety of linguistic processing tasks, suggesting that they can induce\nnon-trivial properties of language. We investigate here to what extent RNNs\nlearn to track abstract hierarchical syntactic structure. We test whether RNNs\ntrained with a generic language modeling objective in four languages (Italian,\nEnglish, Hebrew, Russian) can predict long-distance number agreement in various\nconstructions. We include in our evaluation nonsensical sentences where RNNs\ncannot rely on semantic or lexical cues (\"The colorless green ideas I ate with\nthe chair sleep furiously\"), and, for Italian, we compare model performance to\nhuman intuitions. Our language-model-trained RNNs make reliable predictions\nabout long-distance agreement, and do not lag much behind human performance. We\nthus bring support to the hypothesis that RNNs are not just shallow-pattern\nextractors, but they also acquire deeper grammatical competence.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 16:27:36 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Gulordava", "Kristina", ""], ["Bojanowski", "Piotr", ""], ["Grave", "Edouard", ""], ["Linzen", "Tal", ""], ["Baroni", "Marco", ""]]}, {"id": "1803.11175", "submitter": "Daniel Cer", "authors": "Daniel Cer, Yinfei Yang, Sheng-yi Kong, Nan Hua, Nicole Limtiaco,\n  Rhomni St. John, Noah Constant, Mario Guajardo-Cespedes, Steve Yuan, Chris\n  Tar, Yun-Hsuan Sung, Brian Strope, Ray Kurzweil", "title": "Universal Sentence Encoder", "comments": "7 pages; fixed module URL in Listing 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present models for encoding sentences into embedding vectors that\nspecifically target transfer learning to other NLP tasks. The models are\nefficient and result in accurate performance on diverse transfer tasks. Two\nvariants of the encoding models allow for trade-offs between accuracy and\ncompute resources. For both variants, we investigate and report the\nrelationship between model complexity, resource consumption, the availability\nof transfer task training data, and task performance. Comparisons are made with\nbaselines that use word level transfer learning via pretrained word embeddings\nas well as baselines do not use any transfer learning. We find that transfer\nlearning using sentence embeddings tends to outperform word level transfer.\nWith transfer learning via sentence embeddings, we observe surprisingly good\nperformance with minimal amounts of supervised training data for a transfer\ntask. We obtain encouraging results on Word Embedding Association Tests (WEAT)\ntargeted at detecting model bias. Our pre-trained sentence encoding models are\nmade freely available for download and on TF Hub.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 17:43:03 GMT"}, {"version": "v2", "created": "Thu, 12 Apr 2018 17:03:44 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Cer", "Daniel", ""], ["Yang", "Yinfei", ""], ["Kong", "Sheng-yi", ""], ["Hua", "Nan", ""], ["Limtiaco", "Nicole", ""], ["John", "Rhomni St.", ""], ["Constant", "Noah", ""], ["Guajardo-Cespedes", "Mario", ""], ["Yuan", "Steve", ""], ["Tar", "Chris", ""], ["Sung", "Yun-Hsuan", ""], ["Strope", "Brian", ""], ["Kurzweil", "Ray", ""]]}, {"id": "1803.11186", "submitter": "Unnat Jain", "authors": "Unnat Jain, Svetlana Lazebnik, Alexander Schwing", "title": "Two can play this Game: Visual Dialog with Discriminative Question\n  Generation and Answering", "comments": "Accepted to CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human conversation is a complex mechanism with subtle nuances. It is hence an\nambitious goal to develop artificial intelligence agents that can participate\nfluently in a conversation. While we are still far from achieving this goal,\nrecent progress in visual question answering, image captioning, and visual\nquestion generation shows that dialog systems may be realizable in the not too\ndistant future. To this end, a novel dataset was introduced recently and\nencouraging results were demonstrated, particularly for question answering. In\nthis paper, we demonstrate a simple symmetric discriminative baseline, that can\nbe applied to both predicting an answer as well as predicting a question. We\nshow that this method performs on par with the state of the art, even memory\nnet based methods. In addition, for the first time on the visual dialog\ndataset, we assess the performance of a system asking questions, and\ndemonstrate how visual dialog can be generated from discriminative question\ngeneration and question answering.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 17:58:43 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Jain", "Unnat", ""], ["Lazebnik", "Svetlana", ""], ["Schwing", "Alexander", ""]]}, {"id": "1803.11284", "submitter": "Bodhisattwa Prasad Majumder", "authors": "Bodhisattwa Prasad Majumder, Aditya Subramanian, Abhinandan Krishnan,\n  Shreyansh Gandhi, Ajinkya More", "title": "Deep Recurrent Neural Networks for Product Attribute Extraction in\n  eCommerce", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting accurate attribute qualities from product titles is a vital\ncomponent in delivering eCommerce customers with a rewarding online shopping\nexperience via an enriched faceted search. We demonstrate the potential of Deep\nRecurrent Networks in this domain, primarily models such as Bidirectional LSTMs\nand Bidirectional LSTM-CRF with or without an attention mechanism. These have\nimproved overall F1 scores, as compared to the previous benchmarks (More et\nal.) by at least 0.0391, showcasing an overall precision of 97.94%, recall of\n94.12% and the F1 score of 0.9599. This has made us achieve a significant\ncoverage of important facets or attributes of products which not only shows the\nefficacy of deep recurrent models over previous machine learning benchmarks but\nalso greatly enhances the overall customer experience while shopping online.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 23:21:11 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Majumder", "Bodhisattwa Prasad", ""], ["Subramanian", "Aditya", ""], ["Krishnan", "Abhinandan", ""], ["Gandhi", "Shreyansh", ""], ["More", "Ajinkya", ""]]}, {"id": "1803.11291", "submitter": "Shyam Upadhyay", "authors": "Shyam Upadhyay, Yogarshi Vyas, Marine Carpuat, Dan Roth", "title": "Robust Cross-lingual Hypernymy Detection using Dependency Context", "comments": "NAACL 2018. SU and YV contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual Hypernymy Detection involves determining if a word in one\nlanguage (\"fruit\") is a hypernym of a word in another language (\"pomme\" i.e.\napple in French). The ability to detect hypernymy cross-lingually can aid in\nsolving cross-lingual versions of tasks such as textual entailment and event\ncoreference. We propose BISPARSE-DEP, a family of unsupervised approaches for\ncross-lingual hypernymy detection, which learns sparse, bilingual word\nembeddings based on dependency contexts. We show that BISPARSE-DEP can\nsignificantly improve performance on this task, compared to approaches based\nonly on lexical context. Our approach is also robust, showing promise for\nlow-resource settings: our dependency-based embeddings can be learned using a\nparser trained on related languages, with negligible loss in performance. We\nalso crowd-source a challenging dataset for this task on four languages --\nRussian, French, Arabic, and Chinese. Our embeddings and datasets are publicly\navailable.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 00:01:08 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Upadhyay", "Shyam", ""], ["Vyas", "Yogarshi", ""], ["Carpuat", "Marine", ""], ["Roth", "Dan", ""]]}, {"id": "1803.11326", "submitter": "Yu Gong", "authors": "Yu Gong, Xusheng Luo, Yu Zhu, Wenwu Ou, Zhao Li, Muhua Zhu, Kenny Q.\n  Zhu, Lu Duan, Xi Chen", "title": "Deep Cascade Multi-task Learning for Slot Filling in Online Shopping\n  Assistant", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Slot filling is a critical task in natural language understanding (NLU) for\ndialog systems. State-of-the-art approaches treat it as a sequence labeling\nproblem and adopt such models as BiLSTM-CRF. While these models work relatively\nwell on standard benchmark datasets, they face challenges in the context of\nE-commerce where the slot labels are more informative and carry richer\nexpressions. In this work, inspired by the unique structure of E-commerce\nknowledge base, we propose a novel multi-task model with cascade and residual\nconnections, which jointly learns segment tagging, named entity tagging and\nslot filling. Experiments show the effectiveness of the proposed cascade and\nresidual structures. Our model has a 14.6% advantage in F1 score over the\nstrong baseline methods on a new Chinese E-commerce shopping assistant dataset,\nwhile achieving competitive accuracies on a standard dataset. Furthermore,\nonline test deployed on such dominant E-commerce platform shows 130%\nimprovement on accuracy of understanding user utterances. Our model has already\ngone into production in the E-commerce platform.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 03:49:18 GMT"}, {"version": "v2", "created": "Wed, 4 Apr 2018 09:12:02 GMT"}, {"version": "v3", "created": "Fri, 14 Dec 2018 03:16:20 GMT"}, {"version": "v4", "created": "Mon, 6 May 2019 11:50:54 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Gong", "Yu", ""], ["Luo", "Xusheng", ""], ["Zhu", "Yu", ""], ["Ou", "Wenwu", ""], ["Li", "Zhao", ""], ["Zhu", "Muhua", ""], ["Zhu", "Kenny Q.", ""], ["Duan", "Lu", ""], ["Chen", "Xi", ""]]}, {"id": "1803.11359", "submitter": "Yu Gong", "authors": "Yu Gong, Xusheng Luo, Kenny Q. Zhu, Wenwu Ou, Zhao Li, Lu Duan", "title": "Automatic Generation of Chinese Short Product Titles for Mobile Display", "comments": "IAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of automatically extracting a short title from\na manually written longer description of E-commerce products for display on\nmobile devices. It is a new extractive summarization problem on short text\ninputs, for which we propose a feature-enriched network model, combining three\ndifferent categories of features in parallel. Experimental results show that\nour framework significantly outperforms several baselines by a substantial gain\nof 4.5%. Moreover, we produce an extractive summarization dataset for\nE-commerce short texts and will release it to the research community.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 06:34:17 GMT"}, {"version": "v2", "created": "Tue, 11 Sep 2018 11:47:39 GMT"}, {"version": "v3", "created": "Mon, 5 Nov 2018 14:13:43 GMT"}, {"version": "v4", "created": "Mon, 6 May 2019 12:05:49 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Gong", "Yu", ""], ["Luo", "Xusheng", ""], ["Zhu", "Kenny Q.", ""], ["Ou", "Wenwu", ""], ["Li", "Zhao", ""], ["Duan", "Lu", ""]]}, {"id": "1803.11407", "submitter": "Heeyoul Choi", "authors": "Heeyoul Choi, Kyunghyun Cho and Yoshua Bengio", "title": "Fine-Grained Attention Mechanism for Neural Machine Translation", "comments": "9 pages, 4 figures", "journal-ref": "Neurocomputing 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT) has been a new paradigm in machine\ntranslation, and the attention mechanism has become the dominant approach with\nthe state-of-the-art records in many language pairs. While there are variants\nof the attention mechanism, all of them use only temporal attention where one\nscalar value is assigned to one context vector corresponding to a source word.\nIn this paper, we propose a fine-grained (or 2D) attention mechanism where each\ndimension of a context vector will receive a separate attention score. In\nexperiments with the task of En-De and En-Fi translation, the fine-grained\nattention method improves the translation quality in terms of BLEU score. In\naddition, our alignment analysis reveals how the fine-grained attention\nmechanism exploits the internal structure of context vectors.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 10:38:33 GMT"}, {"version": "v2", "created": "Tue, 3 Apr 2018 07:07:32 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Choi", "Heeyoul", ""], ["Cho", "Kyunghyun", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1803.11506", "submitter": "Egor Lakomkin", "authors": "Egor Lakomkin, Cornelius Weber, Stefan Wermter", "title": "Automatically augmenting an emotion dataset improves classification\n  using audio", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we tackle a problem of speech emotion classification. One of\nthe issues in the area of affective computation is that the amount of annotated\ndata is very limited. On the other hand, the number of ways that the same\nemotion can be expressed verbally is enormous due to variability between\nspeakers. This is one of the factors that limits performance and\ngeneralization. We propose a simple method that extracts audio samples from\nmovies using textual sentiment analysis. As a result, it is possible to\nautomatically construct a larger dataset of audio samples with positive,\nnegative emotional and neutral speech. We show that pretraining recurrent\nneural network on such a dataset yields better results on the challenging\nEmotiW corpus. This experiment shows a potential benefit of combining textual\nsentiment analysis with vocal information.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 15:14:51 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Lakomkin", "Egor", ""], ["Weber", "Cornelius", ""], ["Wermter", "Stefan", ""]]}, {"id": "1803.11508", "submitter": "Egor Lakomkin", "authors": "Egor Lakomkin, Cornelius Weber, Sven Magg, Stefan Wermter", "title": "Reusing Neural Speech Representations for Auditory Emotion Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustic emotion recognition aims to categorize the affective state of the\nspeaker and is still a difficult task for machine learning models. The\ndifficulties come from the scarcity of training data, general subjectivity in\nemotion perception resulting in low annotator agreement, and the uncertainty\nabout which features are the most relevant and robust ones for classification.\nIn this paper, we will tackle the latter problem. Inspired by the recent\nsuccess of transfer learning methods we propose a set of architectures which\nutilize neural representations inferred by training on large speech databases\nfor the acoustic emotion recognition task. Our experiments on the IEMOCAP\ndataset show ~10% relative improvements in the accuracy and F1-score over the\nbaseline recurrent neural network which is trained end-to-end for emotion\nrecognition.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 15:18:20 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Lakomkin", "Egor", ""], ["Weber", "Cornelius", ""], ["Magg", "Sven", ""], ["Wermter", "Stefan", ""]]}, {"id": "1803.11509", "submitter": "Egor Lakomkin", "authors": "Egor Lakomkin, Chandrakant Bothe, Stefan Wermter", "title": "GradAscent at EmoInt-2017: Character- and Word-Level Recurrent Neural\n  Network Models for Tweet Emotion Intensity Detection", "comments": null, "journal-ref": null, "doi": "10.18653/v1/W17-5222", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The WASSA 2017 EmoInt shared task has the goal to predict emotion intensity\nvalues of tweet messages. Given the text of a tweet and its emotion category\n(anger, joy, fear, and sadness), the participants were asked to build a system\nthat assigns emotion intensity values. Emotion intensity estimation is a\nchallenging problem given the short length of the tweets, the noisy structure\nof the text and the lack of annotated data. To solve this problem, we developed\nan ensemble of two neural models, processing input on the character. and\nword-level with a lexicon-driven system. The correlation scores across all four\nemotions are averaged to determine the bottom-line competition metric, and our\nsystem ranks place forth in full intensity range and third in 0.5-1 range of\nintensity among 23 systems at the time of writing (June 2017).\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 15:21:00 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Lakomkin", "Egor", ""], ["Bothe", "Chandrakant", ""], ["Wermter", "Stefan", ""]]}]