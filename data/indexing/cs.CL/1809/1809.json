[{"id": "1809.00013", "submitter": "David Alvarez-Melis", "authors": "David Alvarez-Melis and Tommi S. Jaakkola", "title": "Gromov-Wasserstein Alignment of Word Embedding Spaces", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual or cross-domain correspondences play key roles in tasks ranging\nfrom machine translation to transfer learning. Recently, purely unsupervised\nmethods operating on monolingual embeddings have become effective alignment\ntools. Current state-of-the-art methods, however, involve multiple steps,\nincluding heuristic post-hoc refinement strategies. In this paper, we cast the\ncorrespondence problem directly as an optimal transport (OT) problem, building\non the idea that word embeddings arise from metric recovery algorithms. Indeed,\nwe exploit the Gromov-Wasserstein distance that measures how similarities\nbetween pairs of words relate across languages. We show that our OT objective\ncan be estimated efficiently, requires little or no tuning, and results in\nperformance comparable with the state-of-the-art in various unsupervised word\ntranslation tasks.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 18:00:27 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Alvarez-Melis", "David", ""], ["Jaakkola", "Tommi S.", ""]]}, {"id": "1809.00042", "submitter": "Ethan Wilcox", "authors": "Ethan Wilcox, Roger Levy, Takashi Morita and Richard Futrell", "title": "What do RNN Language Models Learn about Filler-Gap Dependencies?", "comments": "9 pages, to appear in Proceedings of BlackboxNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RNN language models have achieved state-of-the-art perplexity results and\nhave proven useful in a suite of NLP tasks, but it is as yet unclear what\nsyntactic generalizations they learn. Here we investigate whether\nstate-of-the-art RNN language models represent long-distance filler-gap\ndependencies and constraints on them. Examining RNN behavior on experimentally\ncontrolled sentences designed to expose filler-gap dependencies, we show that\nRNNs can represent the relationship in multiple syntactic positions and over\nlarge spans of text. Furthermore, we show that RNNs learn a subset of the known\nrestrictions on filler-gap dependencies, known as island constraints: RNNs show\nevidence for wh-islands, adjunct islands, and complex NP islands. These studies\ndemonstrates that state-of-the-art RNN models are able to learn and generalize\nabout empty syntactic positions.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 20:04:42 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Wilcox", "Ethan", ""], ["Levy", "Roger", ""], ["Morita", "Takashi", ""], ["Futrell", "Richard", ""]]}, {"id": "1809.00064", "submitter": "Yova Kementchedjhieva", "authors": "Yova Kementchedjhieva, Sebastian Ruder, Ryan Cotterell, Anders\n  S{\\o}gaard", "title": "Generalizing Procrustes Analysis for Better Bilingual Dictionary\n  Induction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most recent approaches to bilingual dictionary induction find a linear\nalignment between the word vector spaces of two languages. We show that\nprojecting the two languages onto a third, latent space, rather than directly\nonto each other, while equivalent in terms of expressivity, makes it easier to\nlearn approximate alignments. Our modified approach also allows for supporting\nlanguages to be included in the alignment process, to obtain an even better\nperformance in low resource settings.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 21:20:00 GMT"}, {"version": "v2", "created": "Fri, 14 Sep 2018 14:27:33 GMT"}, {"version": "v3", "created": "Wed, 8 Jan 2020 10:34:19 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Kementchedjhieva", "Yova", ""], ["Ruder", "Sebastian", ""], ["Cotterell", "Ryan", ""], ["S\u00f8gaard", "Anders", ""]]}, {"id": "1809.00066", "submitter": "Yova Kementchedjhieva", "authors": "Yova Kementchedjhieva and Adam Lopez", "title": "Indicatements that character language models learn English\n  morpho-syntactic units and regularities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Character language models have access to surface morphological patterns, but\nit is not clear whether or how they learn abstract morphological regularities.\nWe instrument a character language model with several probes, finding that it\ncan develop a specific unit to identify word boundaries and, by extension,\nmorpheme boundaries, which allows it to capture linguistic properties and\nregularities of these units. Our language model proves surprisingly good at\nidentifying the selectional restrictions of English derivational morphemes, a\ntask that requires both morphological and syntactic awareness. Thus we conclude\nthat, when morphemes overlap extensively with the words of a language, a\ncharacter language model can perform morphological abstraction.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 21:27:54 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Kementchedjhieva", "Yova", ""], ["Lopez", "Adam", ""]]}, {"id": "1809.00068", "submitter": "Wei Wang", "authors": "Wei Wang and Taro Watanabe and Macduff Hughes and Tetsuji Nakagawa and\n  Ciprian Chelba", "title": "Denoising Neural Machine Translation Training with Trusted Data and\n  Online Data Selection", "comments": "11 pages, 2018 Third Conference on Machine Translation (WMT18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring domain relevance of data and identifying or selecting well-fit\ndomain data for machine translation (MT) is a well-studied topic, but denoising\nis not yet. Denoising is concerned with a different type of data quality and\ntries to reduce the negative impact of data noise on MT training, in\nparticular, neural MT (NMT) training. This paper generalizes methods for\nmeasuring and selecting data for domain MT and applies them to denoising NMT\ntraining. The proposed approach uses trusted data and a denoising curriculum\nrealized by online data selection. Intrinsic and extrinsic evaluations of the\napproach show its significant effectiveness for NMT to train on data with\nsevere noise.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 22:01:45 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Wang", "Wei", ""], ["Watanabe", "Taro", ""], ["Hughes", "Macduff", ""], ["Nakagawa", "Tetsuji", ""], ["Chelba", "Ciprian", ""]]}, {"id": "1809.00069", "submitter": "Mingbo Ma", "authors": "Liang Huang and Kai Zhao and Mingbo Ma", "title": "When to Finish? Optimal Beam Search for Neural Text Generation (modulo\n  beam size)", "comments": "accepted by EMNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In neural text generation such as neural machine translation, summarization,\nand image captioning, beam search is widely used to improve the output text\nquality. However, in the neural generation setting, hypotheses can finish in\ndifferent steps, which makes it difficult to decide when to end beam search to\nensure optimality. We propose a provably optimal beam search algorithm that\nwill always return the optimal-score complete hypothesis (modulo beam size),\nand finish as soon as the optimality is established (finishing no later than\nthe baseline). To counter neural generation's tendency for shorter hypotheses,\nwe also introduce a bounded length reward mechanism which allows a modified\nversion of our beam search algorithm to remain optimal. Experiments on neural\nmachine translation demonstrate that our principled beam search algorithm leads\nto improvement in BLEU score over previously proposed alternatives.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 22:01:48 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Huang", "Liang", ""], ["Zhao", "Kai", ""], ["Ma", "Mingbo", ""]]}, {"id": "1809.00070", "submitter": "Miryam de Lhoneux", "authors": "Anders S{\\o}gaard, Miryam de Lhoneux and Isabelle Augenstein", "title": "Nightmare at test time: How punctuation prevents parsers from\n  generalizing", "comments": "Analyzing and interpreting neural networks for NLP, EMNLP 2018\n  workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Punctuation is a strong indicator of syntactic structure, and parsers trained\non text with punctuation often rely heavily on this signal. Punctuation is a\ndiversion, however, since human language processing does not rely on\npunctuation to the same extent, and in informal texts, we therefore often leave\nout punctuation. We also use punctuation ungrammatically for emphatic or\ncreative purposes, or simply by mistake. We show that (a) dependency parsers\nare sensitive to both absence of punctuation and to alternative uses; (b)\nneural parsers tend to be more sensitive than vintage parsers; (c) training\nneural parsers without punctuation outperforms all out-of-the-box parsers\nacross all scenarios where punctuation departs from standard punctuation. Our\nmain experiments are on synthetically corrupted data to study the effect of\npunctuation in isolation and avoid potential confounds, but we also show\neffects on out-of-domain data.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 22:07:19 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["S\u00f8gaard", "Anders", ""], ["de Lhoneux", "Miryam", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "1809.00088", "submitter": "Jing Qian", "authors": "Jing Qian, Mai ElSherief, Elizabeth Belding, William Yang Wang", "title": "Hierarchical CVAE for Fine-Grained Hate Speech Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing work on automated hate speech detection typically focuses on binary\nclassification or on differentiating among a small set of categories. In this\npaper, we propose a novel method on a fine-grained hate speech classification\ntask, which focuses on differentiating among 40 hate groups of 13 different\nhate group categories. We first explore the Conditional Variational Autoencoder\n(CVAE) as a discriminative model and then extend it to a hierarchical\narchitecture to utilize the additional hate category information for more\naccurate prediction. Experimentally, we show that incorporating the hate\ncategory information for training can significantly improve the classification\nperformance and our proposed model outperforms commonly-used discriminative\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 23:53:18 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Qian", "Jing", ""], ["ElSherief", "Mai", ""], ["Belding", "Elizabeth", ""], ["Wang", "William Yang", ""]]}, {"id": "1809.00107", "submitter": "Zhanming Jie", "authors": "Zhanming Jie and Wei Lu", "title": "Dependency-based Hybrid Trees for Semantic Parsing", "comments": "Accepted by EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel dependency-based hybrid tree model for semantic parsing,\nwhich converts natural language utterance into machine interpretable meaning\nrepresentations. Unlike previous state-of-the-art models, the semantic\ninformation is interpreted as the latent dependency between the natural\nlanguage words in our joint representation. Such dependency information can\ncapture the interactions between the semantics and natural language words. We\nintegrate a neural component into our model and propose an efficient\ndynamic-programming algorithm to perform tractable inference. Through extensive\nexperiments on the standard multilingual GeoQuery dataset with eight languages,\nwe demonstrate that our proposed approach is able to achieve state-of-the-art\nperformance across several languages. Analysis also justifies the effectiveness\nof using our new dependency-based representation.\n", "versions": [{"version": "v1", "created": "Sat, 1 Sep 2018 03:07:17 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Jie", "Zhanming", ""], ["Lu", "Wei", ""]]}, {"id": "1809.00120", "submitter": "Lijun Wu", "authors": "Lijun Wu, Xu Tan, Di He, Fei Tian, Tao Qin, Jianhuang Lai and Tie-Yan\n  Liu", "title": "Beyond Error Propagation in Neural Machine Translation: Characteristics\n  of Language Also Matter", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation usually adopts autoregressive models and suffers\nfrom exposure bias as well as the consequent error propagation problem. Many\nprevious works have discussed the relationship between error propagation and\nthe \\emph{accuracy drop} (i.e., the left part of the translated sentence is\noften better than its right part in left-to-right decoding models) problem. In\nthis paper, we conduct a series of analyses to deeply understand this problem\nand get several interesting findings. (1) The role of error propagation on\naccuracy drop is overstated in the literature, although it indeed contributes\nto the accuracy drop problem. (2) Characteristics of a language play a more\nimportant role in causing the accuracy drop: the left part of the translation\nresult in a right-branching language (e.g., English) is more likely to be more\naccurate than its right part, while the right part is more accurate for a\nleft-branching language (e.g., Japanese). Our discoveries are confirmed on\ndifferent model structures including Transformer and RNN, and in other sequence\ngeneration tasks such as text summarization.\n", "versions": [{"version": "v1", "created": "Sat, 1 Sep 2018 06:06:20 GMT"}, {"version": "v2", "created": "Tue, 11 Sep 2018 08:42:42 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Wu", "Lijun", ""], ["Tan", "Xu", ""], ["He", "Di", ""], ["Tian", "Fei", ""], ["Qin", "Tao", ""], ["Lai", "Jianhuang", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1809.00125", "submitter": "Felix Stahlberg", "authors": "Felix Stahlberg, James Cross, Veselin Stoyanov", "title": "Simple Fusion: Return of the Language Model", "comments": "WMT18 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) typically leverages monolingual data in\ntraining through backtranslation. We investigate an alternative simple method\nto use monolingual data for NMT training: We combine the scores of a\npre-trained and fixed language model (LM) with the scores of a translation\nmodel (TM) while the TM is trained from scratch. To achieve that, we train the\ntranslation model to predict the residual probability of the training data\nadded to the prediction of the LM. This enables the TM to focus its capacity on\nmodeling the source sentence since it can rely on the LM for fluency. We show\nthat our method outperforms previous approaches to integrate LMs into NMT while\nthe architecture is simpler as it does not require gating networks to balance\nTM and LM. We observe gains of between +0.24 and +2.36 BLEU on all four test\nsets (English-Turkish, Turkish-English, Estonian-English, Xhosa-English) on top\nof ensembles without LM. We compare our method with alternative ways to utilize\nmonolingual data such as backtranslation, shallow fusion, and cold fusion.\n", "versions": [{"version": "v1", "created": "Sat, 1 Sep 2018 06:39:56 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 18:00:25 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Stahlberg", "Felix", ""], ["Cross", "James", ""], ["Stoyanov", "Veselin", ""]]}, {"id": "1809.00129", "submitter": "Junjie Hu", "authors": "Junjie Hu, Wei-Cheng Chang, Yuexin Wu, Graham Neubig", "title": "Contextual Encoding for Translation Quality Estimation", "comments": "6 pages, 2018 Third Conference on Machine Translation (WMT18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of word-level quality estimation (QE) consists of taking a source\nsentence and machine-generated translation, and predicting which words in the\noutput are correct and which are wrong.\n  In this paper, propose a method to effectively encode the local and global\ncontextual information for each target word using a three-part neural network\napproach.\n  The first part uses an embedding layer to represent words and their\npart-of-speech tags in both languages. The second part leverages a\none-dimensional convolution layer to integrate local context information for\neach target word. The third part applies a stack of feed-forward and recurrent\nneural networks to further encode the global context in the sentence before\nmaking the predictions. This model was submitted as the CMU entry to the\nWMT2018 shared task on QE, and achieves strong results, ranking first in three\nof the six tracks.\n", "versions": [{"version": "v1", "created": "Sat, 1 Sep 2018 08:01:29 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Hu", "Junjie", ""], ["Chang", "Wei-Cheng", ""], ["Wu", "Yuexin", ""], ["Neubig", "Graham", ""]]}, {"id": "1809.00150", "submitter": "Mareike Hartmann", "authors": "Mareike Hartmann and Yova Kementchedjhieva and Anders S{\\o}gaard", "title": "Why is unsupervised alignment of English embeddings from different\n  algorithms so hard?", "comments": "Accepted at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a challenge to the community: Generative adversarial\nnetworks (GANs) can perfectly align independent English word embeddings induced\nusing the same algorithm, based on distributional information alone; but fails\nto do so, for two different embeddings algorithms. Why is that? We believe\nunderstanding why, is key to understand both modern word embedding algorithms\nand the limitations and instability dynamics of GANs. This paper shows that (a)\nin all these cases, where alignment fails, there exists a linear transform\nbetween the two embeddings (so algorithm biases do not lead to non-linear\ndifferences), and (b) similar effects can not easily be obtained by varying\nhyper-parameters. One plausible suggestion based on our initial experiments is\nthat the differences in the inductive biases of the embedding algorithms lead\nto an optimization landscape that is riddled with local optima, leading to a\nvery small basin of convergence, but we present this more as a challenge paper\nthan a technical contribution.\n", "versions": [{"version": "v1", "created": "Sat, 1 Sep 2018 10:31:57 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Hartmann", "Mareike", ""], ["Kementchedjhieva", "Yova", ""], ["S\u00f8gaard", "Anders", ""]]}, {"id": "1809.00151", "submitter": "Ozan Caglayan", "authors": "Ozan Caglayan, Adrien Bardet, Fethi Bougares, Lo\\\"ic Barrault, Kai\n  Wang, Marc Masana, Luis Herranz, Joost van de Weijer", "title": "LIUM-CVC Submissions for WMT18 Multimodal Translation Task", "comments": "WMT2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the multimodal Neural Machine Translation systems\ndeveloped by LIUM and CVC for WMT18 Shared Task on Multimodal Translation. This\nyear we propose several modifications to our previous multimodal attention\narchitecture in order to better integrate convolutional features and refine\nthem using encoder-side information. Our final constrained submissions ranked\nfirst for English-French and second for English-German language pairs among the\nconstrained submissions according to the automatic evaluation metric METEOR.\n", "versions": [{"version": "v1", "created": "Sat, 1 Sep 2018 10:54:33 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Caglayan", "Ozan", ""], ["Bardet", "Adrien", ""], ["Bougares", "Fethi", ""], ["Barrault", "Lo\u00efc", ""], ["Wang", "Kai", ""], ["Masana", "Marc", ""], ["Herranz", "Luis", ""], ["van de Weijer", "Joost", ""]]}, {"id": "1809.00188", "submitter": "Marcin Junczys-Dowmunt", "authors": "Marcin Junczys-Dowmunt and Roman Grundkiewicz", "title": "MS-UEdin Submission to the WMT2018 APE Shared Task: Dual-Source\n  Transformer for Automatic Post-Editing", "comments": "Winning submissions for WMT2018 APE shared task", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the Microsoft and University of Edinburgh submission to\nthe Automatic Post-editing shared task at WMT2018. Based on training data and\nsystems from the WMT2017 shared task, we re-implement our own models from the\nlast shared task and introduce improvements based on extensive parameter\nsharing. Next we experiment with our implementation of dual-source transformer\nmodels and data selection for the IT domain. Our submissions decisively wins\nthe SMT post-editing sub-task establishing the new state-of-the-art and is a\nvery close second (or equal, 16.46 vs 16.50 TER) in the NMT sub-task. Based on\nthe rather weak results in the NMT sub-task, we hypothesize that\nneural-on-neural APE might not be actually useful.\n", "versions": [{"version": "v1", "created": "Sat, 1 Sep 2018 14:10:50 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Junczys-Dowmunt", "Marcin", ""], ["Grundkiewicz", "Roman", ""]]}, {"id": "1809.00196", "submitter": "Marcin Junczys-Dowmunt", "authors": "Marcin Junczys-Dowmunt", "title": "Microsoft's Submission to the WMT2018 News Translation Task: How I\n  Learned to Stop Worrying and Love the Data", "comments": "Winning shared task submission to WMT2018 news translation task\n  English-German", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the Microsoft submission to the WMT2018 news translation\nshared task. We participated in one language direction -- English-German. Our\nsystem follows current best-practice and combines state-of-the-art models with\nnew data filtering (dual conditional cross-entropy filtering) and sentence\nweighting methods. We trained fairly standard Transformer-big models with an\nupdated version of Edinburgh's training scheme for WMT2017 and experimented\nwith different filtering schemes for Paracrawl. According to automatic metrics\n(BLEU) we reached the highest score for this subtask with a nearly 2 BLEU point\nmargin over the next strongest system. Based on human evaluation we ranked\nfirst among constrained systems. We believe this is mostly caused by our data\nfiltering/weighting regime.\n", "versions": [{"version": "v1", "created": "Sat, 1 Sep 2018 14:33:11 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Junczys-Dowmunt", "Marcin", ""]]}, {"id": "1809.00197", "submitter": "Marcin Junczys-Dowmunt", "authors": "Marcin Junczys-Dowmunt", "title": "Dual Conditional Cross-Entropy Filtering of Noisy Parallel Corpora", "comments": "Winning submission to WMT2018 shared task on Parallel Corpus\n  Filtering; Corrected math and typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we introduce dual conditional cross-entropy filtering for noisy\nparallel data. For each sentence pair of the noisy parallel corpus we compute\ncross-entropy scores according to two inverse translation models trained on\nclean data. We penalize divergent cross-entropies and weigh the penalty by the\ncross-entropy average of both models. Sorting or thresholding according to\nthese scores results in better subsets of parallel data. We achieve higher BLEU\nscores with models trained on parallel data filtered only from Paracrawl than\nwith models trained on clean WMT data. We further evaluate our method in the\ncontext of the WMT2018 shared task on parallel corpus filtering and achieve the\noverall highest ranking scores of the shared task, scoring top in three out of\nfour subtasks.\n", "versions": [{"version": "v1", "created": "Sat, 1 Sep 2018 14:38:16 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2019 05:32:09 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Junczys-Dowmunt", "Marcin", ""]]}, {"id": "1809.00204", "submitter": "Stephan Baier", "authors": "Stephan Baier, Yunpu Ma, Volker Tresp", "title": "Improving Visual Relationship Detection using Semantic Modeling of Scene\n  Descriptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured scene descriptions of images are useful for the automatic\nprocessing and querying of large image databases. We show how the combination\nof a semantic and a visual statistical model can improve on the task of mapping\nimages to their associated scene description. In this paper we consider scene\ndescriptions which are represented as a set of triples (subject, predicate,\nobject), where each triple consists of a pair of visual objects, which appear\nin the image, and the relationship between them (e.g. man-riding-elephant,\nman-wearing-hat). We combine a standard visual model for object detection,\nbased on convolutional neural networks, with a latent variable model for link\nprediction. We apply multiple state-of-the-art link prediction methods and\ncompare their capability for visual relationship detection. One of the main\nadvantages of link prediction methods is that they can also generalize to\ntriples, which have never been observed in the training data. Our experimental\nresults on the recently published Stanford Visual Relationship dataset, a\nchallenging real world dataset, show that the integration of a semantic model\nusing link prediction methods can significantly improve the results for visual\nrelationship detection. Our combined approach achieves superior performance\ncompared to the state-of-the-art method from the Stanford computer vision\ngroup.\n", "versions": [{"version": "v1", "created": "Sat, 1 Sep 2018 15:11:12 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Baier", "Stephan", ""], ["Ma", "Yunpu", ""], ["Tresp", "Volker", ""]]}, {"id": "1809.00221", "submitter": "Seid Muhie Yimam", "authors": "Gregor Wiedemann and Seid Muhie Yimam and Chris Biemann", "title": "A Multilingual Information Extraction Pipeline for Investigative\n  Journalism", "comments": "EMNLP 2018 Demo. arXiv admin note: text overlap with arXiv:1807.05151", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce an advanced information extraction pipeline to automatically\nprocess very large collections of unstructured textual data for the purpose of\ninvestigative journalism. The pipeline serves as a new input processor for the\nupcoming major release of our New/s/leak 2.0 software, which we develop in\ncooperation with a large German news organization. The use case is that\njournalists receive a large collection of files up to several Gigabytes\ncontaining unknown contents. Collections may originate either from official\ndisclosures of documents, e.g. Freedom of Information Act requests, or\nunofficial data leaks. Our software prepares a visually-aided exploration of\nthe collection to quickly learn about potential stories contained in the data.\nIt is based on the automatic extraction of entities and their co-occurrence in\ndocuments. In contrast to comparable projects, we focus on the following three\nmajor requirements particularly serving the use case of investigative\njournalism in cross-border collaborations: 1) composition of multiple\nstate-of-the-art NLP tools for entity extraction, 2) support of multi-lingual\ndocument sets up to 40 languages, 3) fast and easy-to-use extraction of\nfull-text, metadata and entities from various file formats.\n", "versions": [{"version": "v1", "created": "Sat, 1 Sep 2018 16:54:15 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Wiedemann", "Gregor", ""], ["Yimam", "Seid Muhie", ""], ["Biemann", "Chris", ""]]}, {"id": "1809.00224", "submitter": "Jack Parry", "authors": "Jack Parry", "title": "Finding the Answers with Definition Models", "comments": "MSc Dissertation, University of Edinburgh, <10,000 words", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by a previous attempt to answer crossword questions using neural\nnetworks (Hill, Cho, Korhonen, & Bengio, 2015), this dissertation implements\nextensions to improve the performance of this existing definition model on the\ntask of answering crossword questions. A discussion and evaluation of the\noriginal implementation finds that there are some ways in which the recurrent\nneural model could be extended. Insights from related fields neural language\nmodeling and neural machine translation provide the justification and means\nrequired for these extensions. Two extensions are applied to the LSTM encoder,\nfirst taking the average of LSTM states across the sequence and secondly using\na bidirectional LSTM, both implementations serve to improve model performance\non a definitions and crossword test set. In order to improve performance on\ncrossword questions, the training data is increased to include crossword\nquestions and answers, and this serves to improve results on definitions as\nwell as crossword questions. The final experiments are conducted using sub-word\nunit segmentation, first on the source side and then later preliminary\nexperimentation is conducted to facilitate character-level output. Initially,\nan exact reproduction of the baseline results proves unsuccessful. Despite\nthis, the extensions improve performance, allowing the definition model to\nsurpass the performance of the recurrent neural network variants of the\nprevious work (Hill, et al., 2015).\n", "versions": [{"version": "v1", "created": "Sat, 1 Sep 2018 17:21:01 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Parry", "Jack", ""]]}, {"id": "1809.00252", "submitter": "Devendra Singh Sachan", "authors": "Devendra Singh Sachan and Graham Neubig", "title": "Parameter Sharing Methods for Multilingual Self-Attentional Translation\n  Models", "comments": "Third Conference on Machine Translation (WMT 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multilingual neural machine translation, it has been shown that sharing a\nsingle translation model between multiple languages can achieve competitive\nperformance, sometimes even leading to performance gains over bilingually\ntrained models. However, these improvements are not uniform; often multilingual\nparameter sharing results in a decrease in accuracy due to translation models\nnot being able to accommodate different languages in their limited parameter\nspace. In this work, we examine parameter sharing techniques that strike a\nhappy medium between full sharing and individual training, specifically\nfocusing on the self-attentional Transformer model. We find that the full\nparameter sharing approach leads to increases in BLEU scores mainly when the\ntarget languages are from a similar language family. However, even in the case\nwhere target languages are from different families where full parameter sharing\nleads to a noticeable drop in BLEU scores, our proposed methods for partial\nsharing of parameters can lead to substantial improvements in translation\naccuracy.\n", "versions": [{"version": "v1", "created": "Sat, 1 Sep 2018 21:12:09 GMT"}, {"version": "v2", "created": "Thu, 13 Sep 2018 08:34:40 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Sachan", "Devendra Singh", ""], ["Neubig", "Graham", ""]]}, {"id": "1809.00303", "submitter": "Momchil Hardalov", "authors": "Momchil Hardalov, Ivan Koychev and Preslav Nakov", "title": "Towards Automated Customer Support", "comments": "Accepted as regular paper at AIMSA 2018", "journal-ref": null, "doi": "10.1007/978-3-319-99344-7_5", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent years have seen growing interest in conversational agents, such as\nchatbots, which are a very good fit for automated customer support because the\ndomain in which they need to operate is narrow. This interest was in part\ninspired by recent advances in neural machine translation, esp. the rise of\nsequence-to-sequence (seq2seq) and attention-based models such as the\nTransformer, which have been applied to various other tasks and have opened new\nresearch directions in question answering, chatbots, and conversational\nsystems. Still, in many cases, it might be feasible and even preferable to use\nsimple information retrieval techniques. Thus, here we compare three different\nmodels:(i) a retrieval model, (ii) a sequence-to-sequence model with attention,\nand (iii) Transformer. Our experiments with the Twitter Customer Support\nDataset, which contains over two million posts from customer support services\nof twenty major brands, show that the seq2seq model outperforms the other two\nin terms of semantics and word overlap.\n", "versions": [{"version": "v1", "created": "Sun, 2 Sep 2018 06:22:39 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Hardalov", "Momchil", ""], ["Koychev", "Ivan", ""], ["Nakov", "Preslav", ""]]}, {"id": "1809.00315", "submitter": "Mikel Forcada Dr.", "authors": "Mikel L. Forcada, Carolina Scarton, Lucia Specia, Barry Haddow,\n  Alexandra Birch", "title": "Exploring Gap Filling as a Cheaper Alternative to Reading Comprehension\n  Questionnaires when Evaluating Machine Translation for Gisting", "comments": "12 pages, 3 figures, 2 tables, Proceedings of the Third Conference on\n  Machine Translation (WMT18), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A popular application of machine translation (MT) is gisting: MT is consumed\nas is to make sense of text in a foreign language. Evaluation of the usefulness\nof MT for gisting is surprisingly uncommon. The classical method uses reading\ncomprehension questionnaires (RCQ), in which informants are asked to answer\nprofessionally-written questions in their language about a foreign text that\nhas been machine-translated into their language. Recently, gap-filling (GF), a\nform of cloze testing, has been proposed as a cheaper alternative to RCQ. In\nGF, certain words are removed from reference translations and readers are asked\nto fill the gaps left using the machine-translated text as a hint. This paper\nreports, for thefirst time, a comparative evaluation, using both RCQ and GF, of\ntranslations from multiple MT systems for the same foreign texts, and a\nsystematic study on the effect of variables such as gap density, gap-selection\nstrategies, and document context in GF. The main findings of the study are: (a)\nboth RCQ and GF clearly identify MT to be useful, (b) global RCQ and GF\nrankings for the MT systems are mostly in agreement, (c) GF scores vary very\nwidely across informants, making comparisons among MT systems hard, and (d)\nunlike RCQ, which is framed around documents, GF evaluation can be framed at\nthe sentence level. These findings support the use of GF as a cheaper\nalternative to RCQ.\n", "versions": [{"version": "v1", "created": "Sun, 2 Sep 2018 09:16:18 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Forcada", "Mikel L.", ""], ["Scarton", "Carolina", ""], ["Specia", "Lucia", ""], ["Haddow", "Barry", ""], ["Birch", "Alexandra", ""]]}, {"id": "1809.00329", "submitter": "Yvonne Huang", "authors": "Yafang Huang and Hai Zhao", "title": "Chinese Pinyin Aided IME, Input What You Have Not Keystroked Yet", "comments": "7 pages, accepted by EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chinese pinyin input method engine (IME) converts pinyin into character so\nthat Chinese characters can be conveniently inputted into computer through\ncommon keyboard. IMEs work relying on its core component, pinyin-to-character\nconversion (P2C). Usually Chinese IMEs simply predict a list of character\nsequences for user choice only according to user pinyin input at each turn.\nHowever, Chinese inputting is a multi-turn online procedure, which can be\nsupposed to be exploited for further user experience promoting. This paper thus\nfor the first time introduces a sequence-to-sequence model with gated-attention\nmechanism for the core task in IMEs. The proposed neural P2C model is learned\nby encoding previous input utterance as extra context to enable our IME capable\nof predicting character sequence with incomplete pinyin input. Our model is\nevaluated in different benchmark datasets showing great user experience\nimprovement compared to traditional models, which demonstrates the first\nengineering practice of building Chinese aided IME.\n", "versions": [{"version": "v1", "created": "Sun, 2 Sep 2018 12:01:27 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Huang", "Yafang", ""], ["Zhao", "Hai", ""]]}, {"id": "1809.00336", "submitter": "Bingzhen Wei", "authors": "Bingzhen Wei, Junyang Lin", "title": "Future-Prediction-Based Model for Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel model for Neural Machine Translation (NMT). Different from\nthe conventional method, our model can predict the future text length and words\nat each decoding time step so that the generation can be helped with the\ninformation from the future prediction. With such information, the model does\nnot stop generation without having translated enough content. Experimental\nresults demonstrate that our model can significantly outperform the baseline\nmodels. Besides, our analysis reflects that our model is effective in the\nprediction of the length and words of the untranslated content.\n", "versions": [{"version": "v1", "created": "Sun, 2 Sep 2018 13:47:03 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Wei", "Bingzhen", ""], ["Lin", "Junyang", ""]]}, {"id": "1809.00339", "submitter": "Nabeel Mohammed", "authors": "Motiur Rahman, Nabeel Mohammed, Nafees Mansoor, Sifat Momen", "title": "Chittron: An Automatic Bangla Image Captioning System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic image caption generation aims to produce an accurate description of\nan image in natural language automatically. However, Bangla, the fifth most\nwidely spoken language in the world, is lagging considerably in the research\nand development of such domain. Besides, while there are many established data\nsets to related to image annotation in English, no such resource exists for\nBangla yet. Hence, this paper outlines the development of \"Chittron\", an\nautomatic image captioning system in Bangla. Moreover, to address the data set\navailability issue, a collection of 16,000 Bangladeshi contextual images has\nbeen accumulated and manually annotated in Bangla. This data set is then used\nto train a model which integrates a pre-trained VGG16 image embedding model\nwith stacked LSTM layers. The model is trained to predict the caption when the\ninput is an image, one word at a time. The results show that the model has\nsuccessfully been able to learn a working language model and to generate\ncaptions of images quite accurately in many cases. The results are evaluated\nmainly qualitatively. However, BLEU scores are also reported. It is expected\nthat a better result can be obtained with a bigger and more varied data set.\n", "versions": [{"version": "v1", "created": "Sun, 2 Sep 2018 14:03:30 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Rahman", "Motiur", ""], ["Mohammed", "Nabeel", ""], ["Mansoor", "Nafees", ""], ["Momen", "Sifat", ""]]}, {"id": "1809.00344", "submitter": "Sameen Maruf", "authors": "Sameen Maruf, Andr\\'e F. T. Martins and Gholamreza Haffari", "title": "Contextual Neural Model for Translating Bilingual Multi-Speaker\n  Conversations", "comments": "WMT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works in neural machine translation have begun to explore document\ntranslation. However, translating online multi-speaker conversations is still\nan open problem. In this work, we propose the task of translating Bilingual\nMulti-Speaker Conversations, and explore neural architectures which exploit\nboth source and target-side conversation histories for this task. To initiate\nan evaluation for this task, we introduce datasets extracted from Europarl v7\nand OpenSubtitles2016. Our experiments on four language-pairs confirm the\nsignificance of leveraging conversation history, both in terms of BLEU and\nmanual evaluation.\n", "versions": [{"version": "v1", "created": "Sun, 2 Sep 2018 14:26:44 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Maruf", "Sameen", ""], ["Martins", "Andr\u00e9 F. T.", ""], ["Haffari", "Gholamreza", ""]]}, {"id": "1809.00345", "submitter": "Dar\\'io Garigliotti", "authors": "Dar\\'io Garigliotti and Krisztian Balog", "title": "IntentsKB: A Knowledge Base of Entity-Oriented Search Intents", "comments": "Proceedings of the 27th ACM International Conference on Information\n  and Knowledge Management (CIKM'18), 2018. 4 pages. 2 figures", "journal-ref": null, "doi": "10.1145/3269206.3269257", "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of constructing a knowledge base of entity-oriented\nsearch intents. Search intents are defined on the level of entity types, each\ncomprising of a high-level intent category (property, website, service, or\nother), along with a cluster of query terms used to express that intent. These\nmachine-readable statements can be leveraged in various applications, e.g., for\ngenerating entity cards or query recommendations. By structuring\nservice-oriented search intents, we take one step towards making entities\nactionable. The main contribution of this paper is a pipeline of components we\ndevelop to construct a knowledge base of entity intents. We evaluate\nperformance both component-wise and end-to-end, and demonstrate that our\napproach is able to generate high-quality data.\n", "versions": [{"version": "v1", "created": "Sun, 2 Sep 2018 14:29:05 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Garigliotti", "Dar\u00edo", ""], ["Balog", "Krisztian", ""]]}, {"id": "1809.00357", "submitter": "Tom Kocmi", "authors": "Tom Kocmi and Ond\\v{r}ej Bojar", "title": "Trivial Transfer Learning for Low-Resource Neural Machine Translation", "comments": "Accepted to WMT18 reseach paper, Proceedings of the 3rd Conference on\n  Machine Translation 2018", "journal-ref": "Proceedings of the Third Conference on Machine Translation:\n  Research Papers 2018", "doi": "10.18653/v1/W18-6325", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning has been proven as an effective technique for neural\nmachine translation under low-resource conditions. Existing methods require a\ncommon target language, language relatedness, or specific training tricks and\nregimes. We present a simple transfer learning method, where we first train a\n\"parent\" model for a high-resource language pair and then continue the training\non a lowresource pair only by replacing the training corpus. This \"child\" model\nperforms significantly better than the baseline trained for lowresource pair\nonly. We are the first to show this for targeting different languages, and we\nobserve the improvements even for unrelated languages with different alphabets.\n", "versions": [{"version": "v1", "created": "Sun, 2 Sep 2018 15:24:15 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Kocmi", "Tom", ""], ["Bojar", "Ond\u0159ej", ""]]}, {"id": "1809.00370", "submitter": "Yuchen Zhang", "authors": "Yuchen Zhang and Nianwen Xue", "title": "Neural Ranking Models for Temporal Dependency Structure Parsing", "comments": "11 pages, 2 figures, 7 tables, to appear at EMNLP 2018, Proceedings\n  of the 2018 Conference on Empirical Methods in Natural Language Processing\n  (EMNLP). 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design and build the first neural temporal dependency parser. It utilizes\na neural ranking model with minimal feature engineering, and parses time\nexpressions and events in a text into a temporal dependency tree structure. We\nevaluate our parser on two domains: news reports and narrative stories. In a\nparsing-only evaluation setup where gold time expressions and events are\nprovided, our parser reaches 0.81 and 0.70 f-score on unlabeled and labeled\nparsing respectively, a result that is very competitive against alternative\napproaches. In an end-to-end evaluation setup where time expressions and events\nare automatically recognized, our parser beats two strong baselines on both\ndata domains. Our experimental results and discussions shed light on the nature\nof temporal dependency structures in different domains and provide insights\nthat we believe will be valuable to future research in this area.\n", "versions": [{"version": "v1", "created": "Sun, 2 Sep 2018 17:36:51 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Zhang", "Yuchen", ""], ["Xue", "Nianwen", ""]]}, {"id": "1809.00378", "submitter": "Pushkar Mishra", "authors": "Pushkar Mishra, Helen Yannakoudakis and Ekaterina Shutova", "title": "Neural Character-based Composition Models for Abuse Detection", "comments": "In Proceedings of the EMNLP Workshop on Abusive Language Online 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of social media in recent years has fed into some highly\nundesirable phenomena such as proliferation of offensive language, hate speech,\nsexist remarks, etc. on the Internet. In light of this, there have been several\nefforts to automate the detection and moderation of such abusive content.\nHowever, deliberate obfuscation of words by users to evade detection poses a\nserious challenge to the effectiveness of these efforts. The current state of\nthe art approaches to abusive language detection, based on recurrent neural\nnetworks, do not explicitly address this problem and resort to a generic OOV\n(out of vocabulary) embedding for unseen words. However, in using a single\nembedding for all unseen words we lose the ability to distinguish between\nobfuscated and non-obfuscated or rare words. In this paper, we address this\nproblem by designing a model that can compose embeddings for unseen words. We\nexperimentally demonstrate that our approach significantly advances the current\nstate of the art in abuse detection on datasets from two different domains,\nnamely Twitter and Wikipedia talk page.\n", "versions": [{"version": "v1", "created": "Sun, 2 Sep 2018 19:36:03 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Mishra", "Pushkar", ""], ["Yannakoudakis", "Helen", ""], ["Shutova", "Ekaterina", ""]]}, {"id": "1809.00385", "submitter": "Chenwei Zhang", "authors": "Congying Xia, Chenwei Zhang, Xiaohui Yan, Yi Chang, Philip S. Yu", "title": "Zero-shot User Intent Detection via Capsule Neural Networks", "comments": "In EMNLP 2018 as a long paper. Previously available on\n  http://doi.org/10.13140/RG.2.2.11739.46889", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User intent detection plays a critical role in question-answering and dialog\nsystems. Most previous works treat intent detection as a classification problem\nwhere utterances are labeled with predefined intents. However, it is\nlabor-intensive and time-consuming to label users' utterances as intents are\ndiversely expressed and novel intents will continually be involved. Instead, we\nstudy the zero-shot intent detection problem, which aims to detect emerging\nuser intents where no labeled utterances are currently available. We propose\ntwo capsule-based architectures: INTENT-CAPSNET that extracts semantic features\nfrom utterances and aggregates them to discriminate existing intents, and\nINTENTCAPSNET-ZSL which gives INTENTCAPSNET the zero-shot learning ability to\ndiscriminate emerging intents via knowledge transfer from existing intents.\nExperiments on two real-world datasets show that our model not only can better\ndiscriminate diversely expressed existing intents, but is also able to\ndiscriminate emerging intents when no labeled utterances are available.\n", "versions": [{"version": "v1", "created": "Sun, 2 Sep 2018 20:22:48 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Xia", "Congying", ""], ["Zhang", "Chenwei", ""], ["Yan", "Xiaohui", ""], ["Chang", "Yi", ""], ["Yu", "Philip S.", ""]]}, {"id": "1809.00388", "submitter": "Paul Michel", "authors": "Paul Michel and Graham Neubig", "title": "MTNT: A Testbed for Machine Translation of Noisy Text", "comments": "EMNLP 2018 Long Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noisy or non-standard input text can cause disastrous mistranslations in most\nmodern Machine Translation (MT) systems, and there has been growing research\ninterest in creating noise-robust MT systems. However, as of yet there are no\npublicly available parallel corpora of with naturally occurring noisy inputs\nand translations, and thus previous work has resorted to evaluating on\nsynthetically created datasets. In this paper, we propose a benchmark dataset\nfor Machine Translation of Noisy Text (MTNT), consisting of noisy comments on\nReddit (www.reddit.com) and professionally sourced translations. We\ncommissioned translations of English comments into French and Japanese, as well\nas French and Japanese comments into English, on the order of 7k-37k sentences\nper language pair. We qualitatively and quantitatively examine the types of\nnoise included in this dataset, then demonstrate that existing MT models fail\nbadly on a number of noise-related phenomena, even after performing adaptation\non a small training set of in-domain data. This indicates that this dataset can\nprovide an attractive testbed for methods tailored to handling noisy text in\nMT. The data is publicly available at www.cs.cmu.edu/~pmichel1/mtnt/.\n", "versions": [{"version": "v1", "created": "Sun, 2 Sep 2018 20:43:09 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Michel", "Paul", ""], ["Neubig", "Graham", ""]]}, {"id": "1809.00410", "submitter": "Disha Shrivastava", "authors": "Disha Shrivastava, Abhijit Mishra, Karthik Sankaranarayanan", "title": "Modeling Topical Coherence in Discourse without Supervision", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coherence of text is an important attribute to be measured for both manually\nand automatically generated discourse; but well-defined quantitative metrics\nfor it are still elusive. In this paper, we present a metric for scoring\ntopical coherence of an input paragraph on a real-valued scale by analyzing its\nunderlying topical structure. We first extract all possible topics that the\nsentences of a paragraph of text are related to. Coherence of this text is then\nmeasured by computing: (a) the degree of uncertainty of the topics with respect\nto the paragraph, and (b) the relatedness between these topics. All components\nof our modular framework rely only on unlabeled data and WordNet, thus making\nit completely unsupervised, which is an important feature for general-purpose\nusage of any metric. Experiments are conducted on two datasets - a publicly\navailable dataset for essay grading (representing human discourse), and a\nsynthetic dataset constructed by mixing content from multiple paragraphs\ncovering diverse topics. Our evaluation shows that the measured coherence\nscores are positively correlated with the ground truth for both the datasets.\nFurther validation to our coherence scores is provided by conducting human\nevaluation on the synthetic data, showing a significant agreement of 79.3%\n", "versions": [{"version": "v1", "created": "Sun, 2 Sep 2018 23:49:31 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Shrivastava", "Disha", ""], ["Mishra", "Abhijit", ""], ["Sankaranarayanan", "Karthik", ""]]}, {"id": "1809.00414", "submitter": "Disha Shrivastava", "authors": "Disha Shrivastava, Sreyash Kenkre, Santosh Penubothula", "title": "Hypernyms Through Intra-Article Organization in Wikipedia", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new measure for unsupervised hypernym detection and\ndirectionality. The motivation is to keep the measure computationally light and\nportatable across languages. We show that the relative physical location of\nwords in explanatory articles captures the directionality property. Further,\nthe phrases in section titles of articles about the word, capture the semantic\nsimilarity needed for hypernym detection task. We experimentally show that the\ncombination of features coming from these two simple measures suffices to\nproduce results comparable with the best unsupervised measures in terms of the\naverage precision.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 00:04:49 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Shrivastava", "Disha", ""], ["Kenkre", "Sreyash", ""], ["Penubothula", "Santosh", ""]]}, {"id": "1809.00428", "submitter": "Wenchao Du", "authors": "Wenchao Du, Alan W Black", "title": "Data Augmentation for Neural Online Chat Response Selection", "comments": "EMNLP 2018 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation seeks to manipulate the available data for training to\nimprove the generalization ability of models. We investigate two data\naugmentation proxies, permutation and flipping, for neural dialog response\nselection task on various models over multiple datasets, including both Chinese\nand English languages. Different from standard data augmentation techniques,\nour method combines the original and synthesized data for prediction. Empirical\nresults show that our approach can gain 1 to 3 recall-at-1 points over baseline\nmodels in both full-scale and small-scale settings.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 02:12:56 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Du", "Wenchao", ""], ["Black", "Alan W", ""]]}, {"id": "1809.00494", "submitter": "Diego Esteves", "authors": "Diego Esteves, Aniketh Janardhan Reddy, Piyush Chawla and Jens Lehmann", "title": "Belittling the Source: Trustworthiness Indicators to Obfuscate Fake News\n  on the Web", "comments": null, "journal-ref": "EMNLP 2018: Conference on Empirical Methods in Natural Language\n  Processing (The First Workshop on Fact Extraction and Verification)", "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growth of the internet, the number of fake-news online has been\nproliferating every year. The consequences of such phenomena are manifold,\nranging from lousy decision-making process to bullying and violence episodes.\nTherefore, fact-checking algorithms became a valuable asset. To this aim, an\nimportant step to detect fake-news is to have access to a credibility score for\na given information source. However, most of the widely used Web indicators\nhave either been shut-down to the public (e.g., Google PageRank) or are not\nfree for use (Alexa Rank). Further existing databases are short-manually\ncurated lists of online sources, which do not scale. Finally, most of the\nresearch on the topic is theoretical-based or explore confidential data in a\nrestricted simulation environment. In this paper we explore current research,\nhighlight the challenges and propose solutions to tackle the problem of\nclassifying websites into a credibility scale. The proposed model automatically\nextracts source reputation cues and computes a credibility factor, providing\nvaluable insights which can help in belittling dubious and confirming trustful\nunknown websites. Experimental results outperform state of the art in the\n2-classes and 5-classes setting.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 08:37:33 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Esteves", "Diego", ""], ["Reddy", "Aniketh Janardhan", ""], ["Chawla", "Piyush", ""], ["Lehmann", "Jens", ""]]}, {"id": "1809.00509", "submitter": "Diego Esteves", "authors": "Aniketh Janardhan Reddy and Gil Rocha and Diego Esteves", "title": "DeFactoNLP: Fact Verification using Entity Recognition, TFIDF Vector\n  Comparison and Decomposable Attention", "comments": null, "journal-ref": "EMNLP 2018: Conference on Empirical Methods in Natural Language\n  Processing (The First Workshop on Fact Extraction and Verification)", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe DeFactoNLP, the system we designed for the FEVER\n2018 Shared Task. The aim of this task was to conceive a system that can not\nonly automatically assess the veracity of a claim but also retrieve evidence\nsupporting this assessment from Wikipedia. In our approach, the Wikipedia\ndocuments whose Term Frequency-Inverse Document Frequency (TFIDF) vectors are\nmost similar to the vector of the claim and those documents whose names are\nsimilar to those of the named entities (NEs) mentioned in the claim are\nidentified as the documents which might contain evidence. The sentences in\nthese documents are then supplied to a textual entailment recognition module.\nThis module calculates the probability of each sentence supporting the claim,\ncontradicting the claim or not providing any relevant information to assess the\nveracity of the claim. Various features computed using these probabilities are\nfinally used by a Random Forest classifier to determine the overall\ntruthfulness of the claim. The sentences which support this classification are\nreturned as evidence. Our approach achieved a 0.4277 evidence F1-score, a\n0.5136 label accuracy and a 0.3833 FEVER score.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 09:07:17 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Reddy", "Aniketh Janardhan", ""], ["Rocha", "Gil", ""], ["Esteves", "Diego", ""]]}, {"id": "1809.00530", "submitter": "Ruidan He", "authors": "Ruidan He, Wee Sun Lee, Hwee Tou Ng, Daniel Dahlmeier", "title": "Adaptive Semi-supervised Learning for Cross-domain Sentiment\n  Classification", "comments": "Accepted to EMNLP2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the cross-domain sentiment classification problem, where a\nsentiment classifier is to be learned from a source domain and to be\ngeneralized to a target domain. Our approach explicitly minimizes the distance\nbetween the source and the target instances in an embedded feature space. With\nthe difference between source and target minimized, we then exploit additional\ninformation from the target domain by consolidating the idea of semi-supervised\nlearning, for which, we jointly employ two regularizations -- entropy\nminimization and self-ensemble bootstrapping -- to incorporate the unlabeled\ntarget data for classifier refinement. Our experimental results demonstrate\nthat the proposed approach can better leverage unlabeled data from the target\ndomain and achieve substantial improvements over baseline methods in various\nexperimental settings.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 10:15:04 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["He", "Ruidan", ""], ["Lee", "Wee Sun", ""], ["Ng", "Hwee Tou", ""], ["Dahlmeier", "Daniel", ""]]}, {"id": "1809.00537", "submitter": "Anca Dumitrache", "authors": "Anca Dumitrache, Lora Aroyo, Chris Welty", "title": "Crowdsourcing Semantic Label Propagation in Relation Classification", "comments": "In publication at the First Workshop on Fact Extraction and\n  Verification (FeVer) at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Distant supervision is a popular method for performing relation extraction\nfrom text that is known to produce noisy labels. Most progress in relation\nextraction and classification has been made with crowdsourced corrections to\ndistant-supervised labels, and there is evidence that indicates still more\nwould be better. In this paper, we explore the problem of propagating human\nannotation signals gathered for open-domain relation classification through the\nCrowdTruth methodology for crowdsourcing, that captures ambiguity in\nannotations by measuring inter-annotator disagreement. Our approach propagates\nannotations to sentences that are similar in a low dimensional embedding space,\nexpanding the number of labels by two orders of magnitude. Our experiments show\nsignificant improvement in a sentence-level multi-class relation classifier.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 10:29:09 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Dumitrache", "Anca", ""], ["Aroyo", "Lora", ""], ["Welty", "Chris", ""]]}, {"id": "1809.00540", "submitter": "Sebasti\\~ao Miranda", "authors": "Sebasti\\~ao Miranda, Art\\=urs Znoti\\c{n}\\v{s}, Shay B. Cohen, Guntis\n  Barzdins", "title": "Multilingual Clustering of Streaming News", "comments": "Accepted at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering news across languages enables efficient media monitoring by\naggregating articles from multilingual sources into coherent stories. Doing so\nin an online setting allows scalable processing of massive news streams. To\nthis end, we describe a novel method for clustering an incoming stream of\nmultilingual documents into monolingual and crosslingual story clusters. Unlike\ntypical clustering approaches that consider a small and known number of labels,\nwe tackle the problem of discovering an ever growing number of cluster labels\nin an online fashion, using real news datasets in multiple languages. Our\nmethod is simple to implement, computationally efficient and produces\nstate-of-the-art results on datasets in German, English and Spanish.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 10:40:26 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Miranda", "Sebasti\u00e3o", ""], ["Znoti\u0146\u0161", "Art\u016brs", ""], ["Cohen", "Shay B.", ""], ["Barzdins", "Guntis", ""]]}, {"id": "1809.00549", "submitter": "Ben Bogin", "authors": "Ben Bogin, Mor Geva, Jonathan Berant", "title": "Emergence of Communication in an Interactive World with Consistent\n  Speakers", "comments": "Emergent Communication Workshop @ NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training agents to communicate with one another given task-based supervision\nonly has attracted considerable attention recently, due to the growing interest\nin developing models for human-agent interaction. Prior work on the topic\nfocused on simple environments, where training using policy gradient was\nfeasible despite the non-stationarity of the agents during training. In this\npaper, we present a more challenging environment for testing the emergence of\ncommunication from raw pixels, where training using policy gradient fails. We\npropose a new model and training algorithm, that utilizes the structure of a\nlearned representation space to produce more consistent speakers at the initial\nphases of training, which stabilizes learning. We empirically show that our\nalgorithm substantially improves performance compared to policy gradient. We\nalso propose a new alignment-based metric for measuring context-independence in\nemerged communication and find our method increases context-independence\ncompared to policy gradient and other competitive baselines.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 11:05:00 GMT"}, {"version": "v2", "created": "Sun, 24 Mar 2019 09:23:31 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Bogin", "Ben", ""], ["Geva", "Mor", ""], ["Berant", "Jonathan", ""]]}, {"id": "1809.00563", "submitter": "Gaku Morio", "authors": "Gaku Morio, Katsuhide Fujita", "title": "End-to-End Argument Mining for Discussion Threads Based on Parallel\n  Constrained Pointer Architecture", "comments": "accepted at the 5th Workshop on Argument Mining at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Argument Mining (AM) is a relatively recent discipline, which concentrates on\nextracting claims or premises from discourses, and inferring their structures.\nHowever, many existing works do not consider micro-level AM studies on\ndiscussion threads sufficiently. In this paper, we tackle AM for discussion\nthreads. Our main contributions are follows: (1) A novel combination scheme\nfocusing on micro-level inner- and inter- post schemes for a discussion thread.\n(2) Annotation of large-scale civic discussion threads with the scheme. (3)\nParallel constrained pointer architecture (PCPA), a novel end-to-end technique\nto discriminate sentence types, inner-post relations, and inter-post\ninteractions simultaneously. The experimental results demonstrate that our\nproposed model shows better accuracy in terms of relations extraction, in\ncomparison to existing state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 11:48:28 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Morio", "Gaku", ""], ["Fujita", "Katsuhide", ""]]}, {"id": "1809.00582", "submitter": "Ratish Puduppully", "authors": "Ratish Puduppully, Li Dong, Mirella Lapata", "title": "Data-to-Text Generation with Content Selection and Planning", "comments": "Added link to code", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in data-to-text generation have led to the use of large-scale\ndatasets and neural network models which are trained end-to-end, without\nexplicitly modeling what to say and in what order. In this work, we present a\nneural network architecture which incorporates content selection and planning\nwithout sacrificing end-to-end training. We decompose the generation task into\ntwo stages. Given a corpus of data records (paired with descriptive documents),\nwe first generate a content plan highlighting which information should be\nmentioned and in which order and then generate the document while taking the\ncontent plan into account. Automatic and human-based evaluation experiments\nshow that our model outperforms strong baselines improving the state-of-the-art\non the recently released RotoWire dataset.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 12:41:44 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2019 10:17:44 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Puduppully", "Ratish", ""], ["Dong", "Li", ""], ["Lapata", "Mirella", ""]]}, {"id": "1809.00589", "submitter": "Daniel Loureiro", "authors": "Daniel Loureiro and Al\\'ipio M\\'ario Jorge", "title": "Affordance Extraction and Inference based on Semantic Role Labeling", "comments": "Accepted at FEVER - EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Common-sense reasoning is becoming increasingly important for the advancement\nof Natural Language Processing. While word embeddings have been very\nsuccessful, they cannot explain which aspects of 'coffee' and 'tea' make them\nsimilar, or how they could be related to 'shop'. In this paper, we propose an\nexplicit word representation that builds upon the Distributional Hypothesis to\nrepresent meaning from semantic roles, and allow inference of relations from\ntheir meshing, as supported by the affordance-based Indexical Hypothesis. We\nfind that our model improves the state-of-the-art on unsupervised word\nsimilarity tasks while allowing for direct inference of new relations from the\nsame vector space.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 13:11:07 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Loureiro", "Daniel", ""], ["Jorge", "Al\u00edpio M\u00e1rio", ""]]}, {"id": "1809.00640", "submitter": "Milica Gasic", "authors": "Lina Rojas-Barahona, Bo-Hsiang Tseng, Yinpei Dai, Clare Mansfield,\n  Osman Ramadan, Stefan Ultes, Michael Crawford and Milica Gasic", "title": "Deep learning for language understanding of mental health concepts\n  derived from Cognitive Behavioural Therapy", "comments": "Accepted for publication at LOUHI 2018: The Ninth International\n  Workshop on Health Text Mining and Information Analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, we have seen deep learning and distributed representations\nof words and sentences make impact on a number of natural language processing\ntasks, such as similarity, entailment and sentiment analysis. Here we introduce\na new task: understanding of mental health concepts derived from Cognitive\nBehavioural Therapy (CBT). We define a mental health ontology based on the CBT\nprinciples, annotate a large corpus where this phenomena is exhibited and\nperform understanding using deep learning and distributed representations. Our\nresults show that the performance of deep learning models combined with word\nembeddings or sentence embeddings significantly outperform non-deep-learning\nmodels in this difficult task. This understanding module will be an essential\ncomponent of a statistical dialogue system delivering therapy.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 16:17:11 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Rojas-Barahona", "Lina", ""], ["Tseng", "Bo-Hsiang", ""], ["Dai", "Yinpei", ""], ["Mansfield", "Clare", ""], ["Ramadan", "Osman", ""], ["Ultes", "Stefan", ""], ["Crawford", "Michael", ""], ["Gasic", "Milica", ""]]}, {"id": "1809.00647", "submitter": "Zhengzhong Liu", "authors": "Zhengzhong Liu, Chenyan Xiong, Teruko Mitamura, Eduard Hovy", "title": "Automatic Event Salience Identification", "comments": "EMNLP 2018, 11 pages. Datasets, models and codes:\n  https://github.com/hunterhector/EventSalience", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying the salience (i.e. importance) of discourse units is an important\ntask in language understanding. While events play important roles in text\ndocuments, little research exists on analyzing their saliency status. This\npaper empirically studies the Event Salience task and proposes two salience\ndetection models based on content similarities and discourse relations. The\nfirst is a feature based salience model that incorporates similarities among\ndiscourse units. The second is a neural model that captures more complex\nrelations between discourse units. Tested on our new large-scale event salience\ncorpus, both methods significantly outperform the strong frequency baseline,\nwhile our neural model further improves the feature based one by a large\nmargin. Our analyses demonstrate that our neural model captures interesting\nconnections between salience and discourse unit relations (e.g., scripts and\nframe structures).\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 16:35:07 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Liu", "Zhengzhong", ""], ["Xiong", "Chenyan", ""], ["Mitamura", "Teruko", ""], ["Hovy", "Eduard", ""]]}, {"id": "1809.00653", "submitter": "Vlad Niculae", "authors": "Vlad Niculae, Andr\\'e F. T. Martins, Claire Cardie", "title": "Towards Dynamic Computation Graphs via Sparse Latent Structure", "comments": "EMNLP 2018; 9 pages (incl. appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep NLP models benefit from underlying structures in the data---e.g., parse\ntrees---typically extracted using off-the-shelf parsers. Recent attempts to\njointly learn the latent structure encounter a tradeoff: either make\nfactorization assumptions that limit expressiveness, or sacrifice end-to-end\ndifferentiability. Using the recently proposed SparseMAP inference, which\nretrieves a sparse distribution over latent structures, we propose a novel\napproach for end-to-end learning of latent structure predictors jointly with a\ndownstream predictor. To the best of our knowledge, our method is the first to\nenable unrestricted dynamic computation graph construction from the global\nlatent structure, while maintaining differentiability.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 16:52:19 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Niculae", "Vlad", ""], ["Martins", "Andr\u00e9 F. T.", ""], ["Cardie", "Claire", ""]]}, {"id": "1809.00656", "submitter": "Larry Moss", "authors": "Alex Kruckman and Lawrence S. Moss", "title": "Exploring the Landscape of Relational Syllogistic Logics", "comments": null, "journal-ref": null, "doi": "10.1017/S1755020320000386", "report-no": null, "categories": "math.LO cs.CL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores relational syllogistic logics, a family of logical\nsystems related to reasoning about relations in extensions of the classical\nsyllogistic. These are all decidable logical systems. We prove completeness\ntheorems and complexity results for a natural subfamily of relational\nsyllogistic logics, parametrized by constructors for terms and for sentences.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 16:57:54 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Kruckman", "Alex", ""], ["Moss", "Lawrence S.", ""]]}, {"id": "1809.00676", "submitter": "Jiuniu Wang", "authors": "Jiuniu Wang, Xingyu Fu, Guangluan Xu, Yirong Wu, Ziyan Chen, Yang Wei\n  and Li Jin", "title": "A3Net: Adversarial-and-Attention Network for Machine Reading\n  Comprehension", "comments": "NLPCC2018, 12 pages", "journal-ref": "NLPCC 2018: Natural Language Processing and Chinese Computing pp\n  64-75", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce Adversarial-and-attention Network (A3Net) for\nMachine Reading Comprehension. This model extends existing approaches from two\nperspectives. First, adversarial training is applied to several target\nvariables within the model, rather than only to the inputs or embeddings. We\ncontrol the norm of adversarial perturbations according to the norm of original\ntarget variables, so that we can jointly add perturbations to several target\nvariables during training. As an effective regularization method, adversarial\ntraining improves robustness and generalization of our model. Second, we\npropose a multi-layer attention network utilizing three kinds of\nhigh-efficiency attention mechanisms. Multi-layer attention conducts\ninteraction between question and passage within each layer, which contributes\nto reasonable representation and understanding of the model. Combining these\ntwo contributions, we enhance the diversity of dataset and the information\nextracting ability of the model at the same time. Meanwhile, we construct A3Net\nfor the WebQA dataset. Results show that our model outperforms the\nstate-of-the-art models (improving Fuzzy Score from 73.50% to 77.0%).\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 18:03:46 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Wang", "Jiuniu", ""], ["Fu", "Xingyu", ""], ["Xu", "Guangluan", ""], ["Wu", "Yirong", ""], ["Chen", "Ziyan", ""], ["Wei", "Yang", ""], ["Jin", "Li", ""]]}, {"id": "1809.00699", "submitter": "Jinhua Du", "authors": "Jinhua Du, Jingguang Han, Andy Way, Dadong Wan", "title": "Multi-Level Structured Self-Attentions for Distantly Supervised Relation\n  Extraction", "comments": "Accepted by EMNLP2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention mechanisms are often used in deep neural networks for distantly\nsupervised relation extraction (DS-RE) to distinguish valid from noisy\ninstances. However, traditional 1-D vector attention models are insufficient\nfor the learning of different contexts in the selection of valid instances to\npredict the relationship for an entity pair. To alleviate this issue, we\npropose a novel multi-level structured (2-D matrix) self-attention mechanism\nfor DS-RE in a multi-instance learning (MIL) framework using bidirectional\nrecurrent neural networks. In the proposed method, a structured word-level\nself-attention mechanism learns a 2-D matrix where each row vector represents a\nweight distribution for different aspects of an instance regarding two\nentities. Targeting the MIL issue, the structured sentence-level attention\nlearns a 2-D matrix where each row vector represents a weight distribution on\nselection of different valid in-stances. Experiments conducted on two publicly\navailable DS-RE datasets show that the proposed framework with a multi-level\nstructured self-attention mechanism significantly outperform state-of-the-art\nbaselines in terms of PR curves, P@N and F1 measures.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 19:39:20 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Du", "Jinhua", ""], ["Han", "Jingguang", ""], ["Way", "Andy", ""], ["Wan", "Dadong", ""]]}, {"id": "1809.00717", "submitter": "Alexandra Chronopoulou", "authors": "Alexandra Chronopoulou, Aikaterini Margatina, Christos Baziotis,\n  Alexandros Potamianos", "title": "NTUA-SLP at IEST 2018: Ensemble of Neural Transfer Methods for Implicit\n  Emotion Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present our approach to tackle the Implicit Emotion Shared\nTask (IEST) organized as part of WASSA 2018 at EMNLP 2018. Given a tweet, from\nwhich a certain word has been removed, we are asked to predict the emotion of\nthe missing word. In this work, we experiment with neural Transfer Learning\n(TL) methods. Our models are based on LSTM networks, augmented with a\nself-attention mechanism. We use the weights of various pretrained models, for\ninitializing specific layers of our networks. We leverage a big collection of\nunlabeled Twitter messages, for pretraining word2vec word embeddings and a set\nof diverse language models. Moreover, we utilize a sentiment analysis dataset\nfor pretraining a model, which encodes emotion related information. The\nsubmitted model consists of an ensemble of the aforementioned TL models. Our\nteam ranked 3rd out of 30 participants, achieving an F1 score of 0.703.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 21:00:10 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Chronopoulou", "Alexandra", ""], ["Margatina", "Aikaterini", ""], ["Baziotis", "Christos", ""], ["Potamianos", "Alexandros", ""]]}, {"id": "1809.00732", "submitter": "Anusri Pampari", "authors": "Anusri Pampari, Preethi Raghavan, Jennifer Liang and Jian Peng", "title": "emrQA: A Large Corpus for Question Answering on Electronic Medical\n  Records", "comments": "Accepted at Conference on Empirical Methods in Natural Language\n  Processing (EMNLP) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel methodology to generate domain-specific large-scale\nquestion answering (QA) datasets by re-purposing existing annotations for other\nNLP tasks. We demonstrate an instance of this methodology in generating a\nlarge-scale QA dataset for electronic medical records by leveraging existing\nexpert annotations on clinical notes for various NLP tasks from the community\nshared i2b2 datasets. The resulting corpus (emrQA) has 1 million\nquestion-logical form and 400,000+ question-answer evidence pairs. We\ncharacterize the dataset and explore its learning potential by training\nbaseline models for question to logical form and question to answer mapping.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 21:56:47 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Pampari", "Anusri", ""], ["Raghavan", "Preethi", ""], ["Liang", "Jennifer", ""], ["Peng", "Jian", ""]]}, {"id": "1809.00741", "submitter": "Eitan Sapiro-Gheiler", "authors": "Eitan Sapiro-Gheiler", "title": "\"Read My Lips\": Using Automatic Text Analysis to Classify Politicians by\n  Party and Ideology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.CL q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing digitization of political speech has opened the door to\nstudying a new dimension of political behavior using text analysis. This work\ninvestigates the value of word-level statistical data from the US Congressional\nRecord--which contains the full text of all speeches made in the US\nCongress--for studying the ideological positions and behavior of senators.\nApplying machine learning techniques, we use this data to automatically\nclassify senators according to party, obtaining accuracy in the 70-95% range\ndepending on the specific method used. We also show that using text to predict\nDW-NOMINATE scores, a common proxy for ideology, does not improve upon these\nalready-successful results. This classification deteriorates when applied to\ntext from sessions of Congress that are four or more years removed from the\ntraining set, pointing to a need on the part of voters to dynamically update\nthe heuristics they use to evaluate party based on political speech. Text-based\npredictions are less accurate than those based on voting behavior, supporting\nthe theory that roll-call votes represent greater commitment on the part of\npoliticians and are thus a more accurate reflection of their ideological\npreferences. However, the overall success of the machine learning approaches\nstudied here demonstrates that political speeches are highly predictive of\npartisan affiliation. In addition to these findings, this work also introduces\nthe computational tools and methods relevant to the use of political speech\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 23:13:00 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Sapiro-Gheiler", "Eitan", ""]]}, {"id": "1809.00773", "submitter": "Bo Chen", "authors": "Bo Chen, Le Sun, Xianpei Han", "title": "Sequence-to-Action: End-to-End Semantic Graph Generation for Semantic\n  Parsing", "comments": "Accepted as ACL 2018 long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a neural semantic parsing approach -- Sequence-to-Action,\nwhich models semantic parsing as an end-to-end semantic graph generation\nprocess. Our method simultaneously leverages the advantages from two recent\npromising directions of semantic parsing. Firstly, our model uses a semantic\ngraph to represent the meaning of a sentence, which has a tight-coupling with\nknowledge bases. Secondly, by leveraging the powerful representation learning\nand prediction ability of neural network models, we propose a RNN model which\ncan effectively map sentences to action sequences for semantic graph\ngeneration. Experiments show that our method achieves state-of-the-art\nperformance on OVERNIGHT dataset and gets competitive performance on GEO and\nATIS datasets.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 02:30:57 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Chen", "Bo", ""], ["Sun", "Le", ""], ["Han", "Xianpei", ""]]}, {"id": "1809.00782", "submitter": "Bhuwan Dhingra", "authors": "Haitian Sun, Bhuwan Dhingra, Manzil Zaheer, Kathryn Mazaitis, Ruslan\n  Salakhutdinov and William W. Cohen", "title": "Open Domain Question Answering Using Early Fusion of Knowledge Bases and\n  Text", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open Domain Question Answering (QA) is evolving from complex pipelined\nsystems to end-to-end deep neural networks. Specialized neural models have been\ndeveloped for extracting answers from either text alone or Knowledge Bases\n(KBs) alone. In this paper we look at a more practical setting, namely QA over\nthe combination of a KB and entity-linked text, which is appropriate when an\nincomplete KB is available with a large text corpus. Building on recent\nadvances in graph representation learning we propose a novel model, GRAFT-Net,\nfor extracting answers from a question-specific subgraph containing text and KB\nentities and relations. We construct a suite of benchmark tasks for this\nproblem, varying the difficulty of questions, the amount of training data, and\nKB completeness. We show that GRAFT-Net is competitive with the\nstate-of-the-art when tested using either KBs or text alone, and vastly\noutperforms existing methods in the combined setting. Source code is available\nat https://github.com/OceanskySun/GraftNet .\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 03:15:56 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Sun", "Haitian", ""], ["Dhingra", "Bhuwan", ""], ["Zaheer", "Manzil", ""], ["Mazaitis", "Kathryn", ""], ["Salakhutdinov", "Ruslan", ""], ["Cohen", "William W.", ""]]}, {"id": "1809.00786", "submitter": "Dipendra Misra", "authors": "Dipendra Misra, Andrew Bennett, Valts Blukis, Eyvind Niklasson, Max\n  Shatkhin and Yoav Artzi", "title": "Mapping Instructions to Actions in 3D Environments with Visual Goal\n  Prediction", "comments": "Accepted at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to decompose instruction execution to goal prediction and action\ngeneration. We design a model that maps raw visual observations to goals using\nLINGUNET, a language-conditioned image generation network, and then generates\nthe actions required to complete them. Our model is trained from demonstration\nonly without external resources. To evaluate our approach, we introduce two\nbenchmarks for instruction following: LANI, a navigation task; and CHAI, where\nan agent executes household instructions. Our evaluation demonstrates the\nadvantages of our model decomposition, and illustrates the challenges posed by\nour new benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 03:36:21 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2019 17:04:24 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Misra", "Dipendra", ""], ["Bennett", "Andrew", ""], ["Blukis", "Valts", ""], ["Niklasson", "Eyvind", ""], ["Shatkhin", "Max", ""], ["Artzi", "Yoav", ""]]}, {"id": "1809.00794", "submitter": "Zhiting Hu", "authors": "Zhiting Hu, Haoran Shi, Bowen Tan, Wentao Wang, Zichao Yang, Tiancheng\n  Zhao, Junxian He, Lianhui Qin, Di Wang, Xuezhe Ma, Zhengzhong Liu, Xiaodan\n  Liang, Wangrong Zhu, Devendra Singh Sachan, Eric P. Xing", "title": "Texar: A Modularized, Versatile, and Extensible Toolkit for Text\n  Generation", "comments": "ACL 2019 demo, expanded version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Texar, an open-source toolkit aiming to support the broad set of\ntext generation tasks that transform any inputs into natural language, such as\nmachine translation, summarization, dialog, content manipulation, and so forth.\nWith the design goals of modularity, versatility, and extensibility in mind,\nTexar extracts common patterns underlying the diverse tasks and methodologies,\ncreates a library of highly reusable modules, and allows arbitrary model\narchitectures and algorithmic paradigms. In Texar, model architecture,\ninference, and learning processes are properly decomposed. Modules at a high\nconcept level can be freely assembled and plugged in/swapped out. The toolkit\nalso supports a rich set of large-scale pretrained models. Texar is thus\nparticularly suitable for researchers and practitioners to do fast prototyping\nand experimentation. The versatile toolkit also fosters technique sharing\nacross different text generation tasks. Texar supports both TensorFlow and\nPyTorch, and is released under Apache License 2.0 at https://www.texar.io.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 04:40:34 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 00:12:39 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Hu", "Zhiting", ""], ["Shi", "Haoran", ""], ["Tan", "Bowen", ""], ["Wang", "Wentao", ""], ["Yang", "Zichao", ""], ["Zhao", "Tiancheng", ""], ["He", "Junxian", ""], ["Qin", "Lianhui", ""], ["Wang", "Di", ""], ["Ma", "Xuezhe", ""], ["Liu", "Zhengzhong", ""], ["Liang", "Xiaodan", ""], ["Zhu", "Wangrong", ""], ["Sachan", "Devendra Singh", ""], ["Xing", "Eric P.", ""]]}, {"id": "1809.00800", "submitter": "Sho Yokoi", "authors": "Sho Yokoi, Sosuke Kobayashi, Kenji Fukumizu, Jun Suzuki, Kentaro Inui", "title": "Pointwise HSIC: A Linear-Time Kernelized Co-occurrence Norm for Sparse\n  Linguistic Expressions", "comments": "Accepted by EMNLP 2018", "journal-ref": "EMNLP 2018", "doi": "10.18653/v1/D18-1203", "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new kernel-based co-occurrence measure that can\nbe applied to sparse linguistic expressions (e.g., sentences) with a very short\nlearning time, as an alternative to pointwise mutual information (PMI). As well\nas deriving PMI from mutual information, we derive this new measure from the\nHilbert--Schmidt independence criterion (HSIC); thus, we call the new measure\nthe pointwise HSIC (PHSIC). PHSIC can be interpreted as a smoothed variant of\nPMI that allows various similarity metrics (e.g., sentence embeddings) to be\nplugged in as kernels. Moreover, PHSIC can be estimated by simple and fast\n(linear in the size of the data) matrix calculations regardless of whether we\nuse linear or nonlinear kernels. Empirically, in a dialogue response selection\ntask, PHSIC is learned thousands of times faster than an RNN-based PMI while\noutperforming PMI in accuracy. In addition, we also demonstrate that PHSIC is\nbeneficial as a criterion of a data selection task for machine translation\nowing to its ability to give high (low) scores to a consistent (inconsistent)\npair with other pairs.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 05:33:00 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Yokoi", "Sho", ""], ["Kobayashi", "Sosuke", ""], ["Fukumizu", "Kenji", ""], ["Suzuki", "Jun", ""], ["Inui", "Kentaro", ""]]}, {"id": "1809.00812", "submitter": "Aykut Erdem", "authors": "Semih Yagcioglu, Aykut Erdem, Erkut Erdem, Nazli Ikizler-Cinbis", "title": "RecipeQA: A Challenge Dataset for Multimodal Comprehension of Cooking\n  Recipes", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding and reasoning about cooking recipes is a fruitful research\ndirection towards enabling machines to interpret procedural text. In this work,\nwe introduce RecipeQA, a dataset for multimodal comprehension of cooking\nrecipes. It comprises of approximately 20K instructional recipes with multiple\nmodalities such as titles, descriptions and aligned set of images. With over\n36K automatically generated question-answer pairs, we design a set of\ncomprehension and reasoning tasks that require joint understanding of images\nand text, capturing the temporal flow of events and making sense of procedural\nknowledge. Our preliminary results indicate that RecipeQA will serve as a\nchallenging test bed and an ideal benchmark for evaluating machine\ncomprehension systems. The data and leaderboard are available at\nhttp://hucvl.github.io/recipeqa.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 07:04:55 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Yagcioglu", "Semih", ""], ["Erdem", "Aykut", ""], ["Erdem", "Erkut", ""], ["Ikizler-Cinbis", "Nazli", ""]]}, {"id": "1809.00832", "submitter": "Eunji Jeong", "authors": "Eunji Jeong, Joo Seong Jeong, Soojeong Kim, Gyeong-In Yu, Byung-Gon\n  Chun", "title": "Improving the Expressiveness of Deep Learning Frameworks with Recursion", "comments": "Appeared in EuroSys 2018. 13 pages, 11 figures", "journal-ref": "EuroSys 2018: Thirteenth EuroSys Conference, April 23-26, 2018,\n  Porto, Portugal", "doi": "10.1145/3190508.3190530", "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recursive neural networks have widely been used by researchers to handle\napplications with recursively or hierarchically structured data. However,\nembedded control flow deep learning frameworks such as TensorFlow, Theano,\nCaffe2, and MXNet fail to efficiently represent and execute such neural\nnetworks, due to lack of support for recursion. In this paper, we add recursion\nto the programming model of existing frameworks by complementing their design\nwith recursive execution of dataflow graphs as well as additional APIs for\nrecursive definitions. Unlike iterative implementations, which can only\nunderstand the topological index of each node in recursive data structures, our\nrecursive implementation is able to exploit the recursive relationships between\nnodes for efficient execution based on parallel computation. We present an\nimplementation on TensorFlow and evaluation results with various recursive\nneural network models, showing that our recursive implementation not only\nconveys the recursive nature of recursive neural networks better than other\nimplementations, but also uses given resources more effectively to reduce\ntraining and inference time.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 08:31:21 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Jeong", "Eunji", ""], ["Jeong", "Joo Seong", ""], ["Kim", "Soojeong", ""], ["Yu", "Gyeong-In", ""], ["Chun", "Byung-Gon", ""]]}, {"id": "1809.00836", "submitter": "Andrea Esuli", "authors": "Andrea Esuli, Alejandro Moreo Fern\\'andez, Fabrizio Sebastiani", "title": "A Recurrent Neural Network for Sentiment Quantification", "comments": "Accepted for publication at CIKM 2018", "journal-ref": null, "doi": "10.1145/3269206.3269287", "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantification is a supervised learning task that consists in predicting,\ngiven a set of classes C and a set D of unlabelled items, the prevalence (or\nrelative frequency) p(c|D) of each class c in C. Quantification can in\nprinciple be solved by classifying all the unlabelled items and counting how\nmany of them have been attributed to each class. However, this \"classify and\ncount\" approach has been shown to yield suboptimal quantification accuracy;\nthis has established quantification as a task of its own, and given rise to a\nnumber of methods specifically devised for it. We propose a recurrent neural\nnetwork architecture for quantification (that we call QuaNet) that observes the\nclassification predictions to learn higher-order \"quantification embeddings\",\nwhich are then refined by incorporating quantification predictions of simple\nclassify-and-count-like methods. We test {QuaNet on sentiment quantification on\ntext, showing that it substantially outperforms several state-of-the-art\nbaselines.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 08:41:53 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Esuli", "Andrea", ""], ["Fern\u00e1ndez", "Alejandro Moreo", ""], ["Sebastiani", "Fabrizio", ""]]}, {"id": "1809.00918", "submitter": "Geewook Kim", "authors": "Geewook Kim and Kazuki Fukui and Hidetoshi Shimodaira", "title": "Segmentation-free Compositional $n$-gram Embedding", "comments": "NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new type of representation learning method that models words,\nphrases and sentences seamlessly. Our method does not depend on word\nsegmentation and any human-annotated resources (e.g., word dictionaries), yet\nit is very effective for noisy corpora written in unsegmented languages such as\nChinese and Japanese. The main idea of our method is to ignore word boundaries\ncompletely (i.e., segmentation-free), and construct representations for all\ncharacter $n$-grams in a raw corpus with embeddings of compositional\nsub-$n$-grams. Although the idea is simple, our experiments on various\nbenchmarks and real-world datasets show the efficacy of our proposal.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 12:32:54 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 16:10:31 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Kim", "Geewook", ""], ["Fukui", "Kazuki", ""], ["Shimodaira", "Hidetoshi", ""]]}, {"id": "1809.00934", "submitter": "Xingyi Song", "authors": "Xingyi Song, Johann Petrak, Angus Roberts", "title": "A Deep Neural Network Sentence Level Classification Method with Context\n  Information", "comments": "Accepted at EMNLP2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the sentence classification task, context formed from sentences adjacent\nto the sentence being classified can provide important information for\nclassification. This context is, however, often ignored. Where methods do make\nuse of context, only small amounts are considered, making it difficult to\nscale. We present a new method for sentence classification, Context-LSTM-CNN,\nthat makes use of potentially large contexts. The method also utilizes\nlong-range dependencies within the sentence being classified, using an LSTM,\nand short-span features, using a stacked CNN. Our experiments demonstrate that\nthis approach consistently improves over previous methods on two different\ndatasets.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 14:45:33 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Song", "Xingyi", ""], ["Petrak", "Johann", ""], ["Roberts", "Angus", ""]]}, {"id": "1809.00938", "submitter": "Rosanna Turrisi", "authors": "Rosanna Turrisi, Raffaele Tavarone, Leonardo Badino", "title": "Improving generalization of vocal tract feature reconstruction: from\n  augmented acoustic inversion to articulatory feature reconstruction without\n  articulatory data", "comments": "IEEE Workshop on Spoken Language Technology (SLT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of reconstructing articulatory movements, given audio\nand/or phonetic labels. The scarce availability of multi-speaker articulatory\ndata makes it difficult to learn a reconstruction that generalizes to new\nspeakers and across datasets. We first consider the XRMB dataset where audio,\narticulatory measurements and phonetic transcriptions are available. We show\nthat phonetic labels, used as input to deep recurrent neural networks that\nreconstruct articulatory features, are in general more helpful than acoustic\nfeatures in both matched and mismatched training-testing conditions. In a\nsecond experiment, we test a novel approach that attempts to build articulatory\nfeatures from prior articulatory information extracted from phonetic labels.\nSuch approach recovers vocal tract movements directly from an acoustic-only\ndataset without using any articulatory measurement. Results show that\narticulatory features generated by this approach can correlate up to 0.59\nPearson product-moment correlation with measured articulatory features.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 13:19:16 GMT"}, {"version": "v2", "created": "Mon, 3 Dec 2018 11:10:59 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Turrisi", "Rosanna", ""], ["Tavarone", "Raffaele", ""], ["Badino", "Leonardo", ""]]}, {"id": "1809.00994", "submitter": "Carlos-Emiliano Gonz\\'alez-Gallardo", "authors": "Carlos-Emiliano Gonz\\'alez-Gallardo and Malek Hajjem and Eric SanJuan\n  and Juan-Manuel Torres-Moreno", "title": "\\'Etude de l'informativit\\'e des transcriptions : une approche bas\\'ee\n  sur le r\\'esum\\'e automatique", "comments": "in French, 15e Conf\\'erence en Recherche d'Information et\n  Applications (CORIA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a new approach to evaluate the informativeness of\ntranscriptions coming from Automatic Speech Recognition systems. This approach,\nbased in the notion of informativeness, is focused on the framework of\nAutomatic Text Summarization performed over these transcriptions. At a first\nglance we estimate the informative content of the various automatic\ntranscriptions, then we explore the capacity of Automatic Text Summarization to\novercome the informative loss. To do this we use an automatic summary\nevaluation protocol without reference (based on the informative content), which\ncomputes the divergence between probability distributions of different textual\nrepresentations: manual and automatic transcriptions and their summaries. After\na set of evaluations this analysis allowed us to judge both the quality of the\ntranscriptions in terms of informativeness and to assess the ability of\nautomatic text summarization to compensate the problems raised during the\ntranscription phase.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 14:07:40 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Gonz\u00e1lez-Gallardo", "Carlos-Emiliano", ""], ["Hajjem", "Malek", ""], ["SanJuan", "Eric", ""], ["Torres-Moreno", "Juan-Manuel", ""]]}, {"id": "1809.01060", "submitter": "Yuri Bizzoni", "authors": "Yuri Bizzoni and Shalom Lappin", "title": "The Effect of Context on Metaphor Paraphrase Aptness Judgments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conduct two experiments to study the effect of context on metaphor\nparaphrase aptness judgments. The first is an AMT crowd source task in which\nspeakers rank metaphor paraphrase candidate sentence pairs in short document\ncontexts for paraphrase aptness. In the second we train a composite DNN to\npredict these human judgments, first in binary classifier mode, and then as\ngradient ratings. We found that for both mean human judgments and our DNN's\npredictions, adding document context compresses the aptness scores towards the\ncenter of the scale, raising low out of context ratings and decreasing high out\nof context scores. We offer a provisional explanation for this compression\neffect.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 16:03:06 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Bizzoni", "Yuri", ""], ["Lappin", "Shalom", ""]]}, {"id": "1809.01074", "submitter": "Mahtab Ahmed", "authors": "Mahtab Ahmed, Muhammad Rifayat Samee, Robert E. Mercer", "title": "A Novel Neural Sequence Model with Multiple Attentions for Word Sense\n  Disambiguation", "comments": "9 pages, 3 Figures, Accepted as a conference paper in ICMLA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Word sense disambiguation (WSD) is a well researched problem in computational\nlinguistics. Different research works have approached this problem in different\nways. Some state of the art results that have been achieved for this problem\nare by supervised models in terms of accuracy, but they often fall behind\nflexible knowledge-based solutions which use engineered features as well as\nhuman annotators to disambiguate every target word. This work focuses on\nbridging this gap using neural sequence models incorporating the well-known\nattention mechanism. The main gist of our work is to combine multiple\nattentions on different linguistic features through weights and to provide a\nunified framework for doing this. This weighted attention allows the model to\neasily disambiguate the sense of an ambiguous word by attending over a suitable\nportion of a sentence. Our extensive experiments show that multiple attention\nenables a more versatile encoder-decoder model leading to state of the art\nresults.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 16:28:36 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Ahmed", "Mahtab", ""], ["Samee", "Muhammad Rifayat", ""], ["Mercer", "Robert E.", ""]]}, {"id": "1809.01083", "submitter": "Roman Klinger", "authors": "Roman Klinger and Orph\\'ee De Clercq and Saif M. Mohammad and\n  Alexandra Balahur", "title": "IEST: WASSA-2018 Implicit Emotions Shared Task", "comments": "Accepted at Proceedings of the 9th Workshop on Computational\n  Approaches to Subjectivity, Sentiment and Social Media Analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Past shared tasks on emotions use data with both overt expressions of\nemotions (I am so happy to see you!) as well as subtle expressions where the\nemotions have to be inferred, for instance from event descriptions. Further,\nmost datasets do not focus on the cause or the stimulus of the emotion. Here,\nfor the first time, we propose a shared task where systems have to predict the\nemotions in a large automatically labeled dataset of tweets without access to\nwords denoting emotions. Based on this intention, we call this the Implicit\nEmotion Shared Task (IEST) because the systems have to infer the emotion mostly\nfrom the context. Every tweet has an occurrence of an explicit emotion word\nthat is masked. The tweets are collected in a manner such that they are likely\nto include a description of the cause of the emotion - the stimulus.\nAltogether, 30 teams submitted results which range from macro F1 scores of 21 %\nto 71 %. The baseline (MaxEnt bag of words and bigrams) obtains an F1 score of\n60 % which was available to the participants during the development phase. A\nstudy with human annotators suggests that automatic methods outperform human\npredictions, possibly by honing into subtle textual clues not used by humans.\nCorpora, resources, and results are available at the shared task website at\nhttp://implicitemotions.wassa2018.com.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 16:44:16 GMT"}, {"version": "v2", "created": "Wed, 5 Sep 2018 12:21:45 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Klinger", "Roman", ""], ["De Clercq", "Orph\u00e9e", ""], ["Mohammad", "Saif M.", ""], ["Balahur", "Alexandra", ""]]}, {"id": "1809.01110", "submitter": "Fuwen Tan", "authors": "Fuwen Tan, Song Feng, Vicente Ordonez", "title": "Text2Scene: Generating Compositional Scenes from Textual Descriptions", "comments": "CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we propose Text2Scene, a model that generates various forms of\ncompositional scene representations from natural language descriptions. Unlike\nrecent works, our method does NOT use Generative Adversarial Networks (GANs).\nText2Scene instead learns to sequentially generate objects and their attributes\n(location, size, appearance, etc) at every time step by attending to different\nparts of the input text and the current status of the generated scene. We show\nthat under minor modifications, the proposed framework can handle the\ngeneration of different forms of scene representations, including cartoon-like\nscenes, object layouts corresponding to real images, and synthetic images. Our\nmethod is not only competitive when compared with state-of-the-art GAN-based\nmethods using automatic metrics and superior based on human judgments but also\nhas the advantage of producing interpretable results.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 17:31:13 GMT"}, {"version": "v2", "created": "Sat, 5 Jan 2019 06:20:36 GMT"}, {"version": "v3", "created": "Sun, 9 Jun 2019 16:22:47 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Tan", "Fuwen", ""], ["Feng", "Song", ""], ["Ordonez", "Vicente", ""]]}, {"id": "1809.01201", "submitter": "Eric DeGiuli", "authors": "E. DeGiuli", "title": "Random Language Model", "comments": "5 pages + 3 pages SI", "journal-ref": "Phys. Rev. Lett. 122, 128301 (2019)", "doi": "10.1103/PhysRevLett.122.128301", "report-no": null, "categories": "cond-mat.dis-nn cs.CL cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many complex generative systems use languages to create structured objects.\nWe consider a model of random languages, defined by weighted context-free\ngrammars. As the distribution of grammar weights broadens, a transition is\nfound from a random phase, in which sentences are indistinguishable from noise,\nto an organized phase in which nontrivial information is carried. This marks\nthe emergence of deep structure in the language, and can be understood by a\ncompetition between energy and entropy.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 19:06:18 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 17:24:10 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["DeGiuli", "E.", ""]]}, {"id": "1809.01202", "submitter": "Youngseo Son", "authors": "Youngseo Son, Nipun Bayas, H. Andrew Schwartz", "title": "Causal Explanation Analysis on Social Media", "comments": "To appear in EMNLP 2018; 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding causal explanations - reasons given for happenings in one's\nlife - has been found to be an important psychological factor linked to\nphysical and mental health. Causal explanations are often studied through\nmanual identification of phrases over limited samples of personal writing.\nAutomatic identification of causal explanations in social media, while\nchallenging in relying on contextual and sequential cues, offers a larger-scale\nalternative to expensive manual ratings and opens the door for new applications\n(e.g. studying prevailing beliefs about causes, such as climate change). Here,\nwe explore automating causal explanation analysis, building on discourse\nparsing, and presenting two novel subtasks: causality detection (determining\nwhether a causal explanation exists at all) and causal explanation\nidentification (identifying the specific phrase that is the explanation). We\nachieve strong accuracies for both tasks but find different approaches best: an\nSVM for causality prediction (F1 = 0.791) and a hierarchy of Bidirectional\nLSTMs for causal explanation identification (F1 = 0.853). Finally, we explore\napplications of our complete pipeline (F1 = 0.868), showing demographic\ndifferences in mentions of causal explanation and that the association between\na word and sentiment can change when it is used within a causal explanation.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 19:06:34 GMT"}, {"version": "v2", "created": "Thu, 18 Oct 2018 16:40:26 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Son", "Youngseo", ""], ["Bayas", "Nipun", ""], ["Schwartz", "H. Andrew", ""]]}, {"id": "1809.01215", "submitter": "Ashutosh Baheti", "authors": "Ashutosh Baheti, Alan Ritter, Jiwei Li and Bill Dolan", "title": "Generating More Interesting Responses in Neural Conversation Models with\n  Distributional Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural conversation models tend to generate safe, generic responses for most\ninputs. This is due to the limitations of likelihood-based decoding objectives\nin generation tasks with diverse outputs, such as conversation. To address this\nchallenge, we propose a simple yet effective approach for incorporating side\ninformation in the form of distributional constraints over the generated\nresponses. We propose two constraints that help generate more content rich\nresponses that are based on a model of syntax and topics (Griffiths et al.,\n2005) and semantic similarity (Arora et al., 2016). We evaluate our approach\nagainst a variety of competitive baselines, using both automatic metrics and\nhuman judgments, showing that our proposed approach generates responses that\nare much less generic without sacrificing plausibility. A working demo of our\ncode can be found at https://github.com/abaheti95/DC-NeuralConversation.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 19:29:03 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Baheti", "Ashutosh", ""], ["Ritter", "Alan", ""], ["Li", "Jiwei", ""], ["Dolan", "Bill", ""]]}, {"id": "1809.01219", "submitter": "Fenxiao Chen", "authors": "Fenxiao Chen, Bin Wang and C.-C. Jay Kuo", "title": "Graph-based Deep-Tree Recursive Neural Network (DTRNN) for Text\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel graph-to-tree conversion mechanism called the deep-tree generation\n(DTG) algorithm is first proposed to predict text data represented by graphs.\nThe DTG method can generate a richer and more accurate representation for nodes\n(or vertices) in graphs. It adds flexibility in exploring the vertex\nneighborhood information to better reflect the second order proximity and\nhomophily equivalence in a graph. Then, a Deep-Tree Recursive Neural Network\n(DTRNN) method is presented and used to classify vertices that contains text\ndata in graphs. To demonstrate the effectiveness of the DTRNN method, we apply\nit to three real-world graph datasets and show that the DTRNN method\noutperforms several state-of-the-art benchmarking methods.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 19:39:24 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Chen", "Fenxiao", ""], ["Wang", "Bin", ""], ["Kuo", "C. -C. Jay", ""]]}, {"id": "1809.01229", "submitter": "Sotirios Chatzis", "authors": "Kyriakos Tolias and Sotirios Chatzis", "title": "t-Exponential Memory Networks for Question-Answering Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent advances in deep learning have brought to the fore models that can\nmake multiple computational steps in the service of completing a task; these\nare capable of describ- ing long-term dependencies in sequential data. Novel\nrecurrent attention models over possibly large external memory modules\nconstitute the core mechanisms that enable these capabilities. Our work\naddresses learning subtler and more complex underlying temporal dynamics in\nlanguage modeling tasks that deal with sparse sequential data. To this end, we\nimprove upon these recent advances, by adopting concepts from the field of\nBayesian statistics, namely variational inference. Our proposed approach\nconsists in treating the network parameters as latent variables with a prior\ndistribution imposed over them. Our statistical assumptions go beyond the\nstandard practice of postulating Gaussian priors. Indeed, to allow for handling\noutliers, which are prevalent in long observed sequences of multivariate data,\nmultivariate t-exponential distributions are imposed. On this basis, we proceed\nto infer corresponding posteriors; these can be used for inference and\nprediction at test time, in a way that accounts for the uncertainty in the\navailable sparse training data. Specifically, to allow for our approach to best\nexploit the merits of the t-exponential family, our method considers a new\nt-divergence measure, which generalizes the concept of the Kullback-Leibler\ndivergence. We perform an extensive experimental evaluation of our approach,\nusing challenging language modeling benchmarks, and illustrate its superiority\nover existing state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 20:09:01 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Tolias", "Kyriakos", ""], ["Chatzis", "Sotirios", ""]]}, {"id": "1809.01272", "submitter": "Mikel Artetxe", "authors": "Mikel Artetxe, Gorka Labaka, Eneko Agirre", "title": "Unsupervised Statistical Machine Translation", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While modern machine translation has relied on large parallel corpora, a\nrecent line of work has managed to train Neural Machine Translation (NMT)\nsystems from monolingual corpora only (Artetxe et al., 2018c; Lample et al.,\n2018). Despite the potential of this approach for low-resource settings,\nexisting systems are far behind their supervised counterparts, limiting their\npractical interest. In this paper, we propose an alternative approach based on\nphrase-based Statistical Machine Translation (SMT) that significantly closes\nthe gap with supervised systems. Our method profits from the modular\narchitecture of SMT: we first induce a phrase table from monolingual corpora\nthrough cross-lingual embedding mappings, combine it with an n-gram language\nmodel, and fine-tune hyperparameters through an unsupervised MERT variant. In\naddition, iterative backtranslation improves results further, yielding, for\ninstance, 14.08 and 26.22 BLEU points in WMT 2014 English-German and\nEnglish-French, respectively, an improvement of more than 7-10 BLEU points over\nprevious unsupervised systems, and closing the gap with supervised SMT (Moses\ntrained on Europarl) down to 2-5 BLEU points. Our implementation is available\nat https://github.com/artetxem/monoses\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 23:22:28 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Artetxe", "Mikel", ""], ["Labaka", "Gorka", ""], ["Agirre", "Eneko", ""]]}, {"id": "1809.01285", "submitter": "Ella Rabinovich", "authors": "Ella Rabinovich, Benjamin Sznajder, Artem Spector, Ilya Shnayderman,\n  Ranit Aharonov, David Konopnicki, Noam Slonim", "title": "Learning Concept Abstractness Using Weak Supervision", "comments": "6 pages, EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a weakly supervised approach for inferring the property of\nabstractness of words and expressions in the complete absence of labeled data.\nExploiting only minimal linguistic clues and the contextual usage of a concept\nas manifested in textual data, we train sufficiently powerful classifiers,\nobtaining high correlation with human labels. The results imply the\napplicability of this approach to additional properties of concepts, additional\nlanguages, and resource-scarce scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 01:08:23 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Rabinovich", "Ella", ""], ["Sznajder", "Benjamin", ""], ["Spector", "Artem", ""], ["Shnayderman", "Ilya", ""], ["Aharonov", "Ranit", ""], ["Konopnicki", "David", ""], ["Slonim", "Noam", ""]]}, {"id": "1809.01299", "submitter": "Dipendra Misra", "authors": "Dipendra Misra, Ming-Wei Chang, Xiaodong He and Wen-tau Yih", "title": "Policy Shaping and Generalized Update Equations for Semantic Parsing\n  from Denotations", "comments": "Accepted at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic parsing from denotations faces two key challenges in model training:\n(1) given only the denotations (e.g., answers), search for good candidate\nsemantic parses, and (2) choose the best model update algorithm. We propose\neffective and general solutions to each of them. Using policy shaping, we bias\nthe search procedure towards semantic parses that are more compatible to the\ntext, which provide better supervision signals for training. In addition, we\npropose an update equation that generalizes three different families of\nlearning algorithms, which enables fast model exploration. When experimented on\na recently proposed sequential question answering dataset, our framework leads\nto a new state-of-the-art model that outperforms previous work by 5.0% absolute\non exact match accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 02:15:02 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Misra", "Dipendra", ""], ["Chang", "Ming-Wei", ""], ["He", "Xiaodong", ""], ["Yih", "Wen-tau", ""]]}, {"id": "1809.01301", "submitter": "Pamela Shapiro", "authors": "Pamela Shapiro and Kevin Duh", "title": "BPE and CharCNNs for Translation of Morphology: A Cross-Lingual\n  Comparison and Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) in low-resource settings and of\nmorphologically rich languages is made difficult in part by data sparsity of\nvocabulary words. Several methods have been used to help reduce this sparsity,\nnotably Byte-Pair Encoding (BPE) and a character-based CNN layer (charCNN).\nHowever, the charCNN has largely been neglected, possibly because it has only\nbeen compared to BPE rather than combined with it. We argue for a\nreconsideration of the charCNN, based on cross-lingual improvements on\nlow-resource data. We translate from 8 languages into English, using a\nmulti-way parallel collection of TED transcripts. We find that in most cases,\nusing both BPE and a charCNN performs best, while in Hebrew, using a charCNN\nover words is best.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 02:26:09 GMT"}, {"version": "v2", "created": "Sat, 8 Sep 2018 23:36:53 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Shapiro", "Pamela", ""], ["Duh", "Kevin", ""]]}, {"id": "1809.01316", "submitter": "Donghyeon Kim", "authors": "Donghyeon Kim, Jinhyuk Lee, Donghee Choi, Jaehoon Choi, Jaewoo Kang", "title": "Learning User Preferences and Understanding Calendar Contexts for Event\n  Scheduling", "comments": "CIKM 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With online calendar services gaining popularity worldwide, calendar data has\nbecome one of the richest context sources for understanding human behavior.\nHowever, event scheduling is still time-consuming even with the development of\nonline calendars. Although machine learning based event scheduling models have\nautomated scheduling processes to some extent, they often fail to understand\nsubtle user preferences and complex calendar contexts with event titles written\nin natural language. In this paper, we propose Neural Event Scheduling\nAssistant (NESA) which learns user preferences and understands calendar\ncontexts, directly from raw online calendars for fully automated and highly\neffective event scheduling. We leverage over 593K calendar events for NESA to\nlearn scheduling personal events, and we further utilize NESA for\nmulti-attendee event scheduling. NESA successfully incorporates deep neural\nnetworks such as Bidirectional Long Short-Term Memory, Convolutional Neural\nNetwork, and Highway Network for learning the preferences of each user and\nunderstanding calendar context based on natural languages. The experimental\nresults show that NESA significantly outperforms previous baseline models in\nterms of various evaluation metrics on both personal and multi-attendee event\nscheduling tasks. Our qualitative analysis demonstrates the effectiveness of\neach layer in NESA and learned user preferences.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 04:15:13 GMT"}, {"version": "v2", "created": "Wed, 17 Oct 2018 15:52:06 GMT"}, {"version": "v3", "created": "Sat, 18 Jul 2020 10:58:03 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Kim", "Donghyeon", ""], ["Lee", "Jinhyuk", ""], ["Choi", "Donghee", ""], ["Choi", "Jaehoon", ""], ["Kang", "Jaewoo", ""]]}, {"id": "1809.01329", "submitter": "Richard Futrell", "authors": "Richard Futrell, Ethan Wilcox, Takashi Morita, Roger Levy", "title": "RNNs as psycholinguistic subjects: Syntactic state and grammatical\n  dependency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are the state of the art in sequence\nmodeling for natural language. However, it remains poorly understood what\ngrammatical characteristics of natural language they implicitly learn and\nrepresent as a consequence of optimizing the language modeling objective. Here\nwe deploy the methods of controlled psycholinguistic experimentation to shed\nlight on to what extent RNN behavior reflects incremental syntactic state and\ngrammatical dependency representations known to characterize human linguistic\nbehavior. We broadly test two publicly available long short-term memory (LSTM)\nEnglish sequence models, and learn and test a new Japanese LSTM. We demonstrate\nthat these models represent and maintain incremental syntactic state, but that\nthey do not always generalize in the same way as humans. Furthermore, none of\nour models learn the appropriate grammatical dependency configurations\nlicensing reflexive pronouns or negative polarity items.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 05:12:34 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Futrell", "Richard", ""], ["Wilcox", "Ethan", ""], ["Morita", "Takashi", ""], ["Levy", "Roger", ""]]}, {"id": "1809.01331", "submitter": "Shereen Oraby", "authors": "Shereen Oraby, Lena Reed, Sharath TS, Shubhangi Tandon, Marilyn Walker", "title": "Neural MultiVoice Models for Expressing Novel Personalities in Dialog", "comments": "Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language generators for task-oriented dialog should be able to vary\nthe style of the output utterance while still effectively realizing the system\ndialog actions and their associated semantics. While the use of neural\ngeneration for training the response generation component of conversational\nagents promises to simplify the process of producing high quality responses in\nnew domains, to our knowledge, there has been very little investigation of\nneural generators for task-oriented dialog that can vary their response style,\nand we know of no experiments on models that can generate responses that are\ndifferent in style from those seen during training, while still maintain- ing\nsemantic fidelity to the input meaning representation. Here, we show that a\nmodel that is trained to achieve a single stylis- tic personality target can\nproduce outputs that combine stylistic targets. We carefully evaluate the\nmultivoice outputs for both semantic fidelity and for similarities to and\ndifferences from the linguistic features that characterize the original\ntraining style. We show that contrary to our predictions, the learned models do\nnot always simply interpolate model parameters, but rather produce styles that\nare distinct, and novel from the personalities they were trained on.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 05:24:00 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Oraby", "Shereen", ""], ["Reed", "Lena", ""], ["TS", "Sharath", ""], ["Tandon", "Shubhangi", ""], ["Walker", "Marilyn", ""]]}, {"id": "1809.01337", "submitter": "Lisa Anne Hendricks", "authors": "Lisa Anne Hendricks, Oliver Wang, Eli Shechtman, Josef Sivic, Trevor\n  Darrell, Bryan Russell", "title": "Localizing Moments in Video with Temporal Language", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Localizing moments in a longer video via natural language queries is a new,\nchallenging task at the intersection of language and video understanding.\nThough moment localization with natural language is similar to other language\nand vision tasks like natural language object retrieval in images, moment\nlocalization offers an interesting opportunity to model temporal dependencies\nand reasoning in text. We propose a new model that explicitly reasons about\ndifferent temporal segments in a video, and shows that temporal context is\nimportant for localizing phrases which include temporal language. To benchmark\nwhether our model, and other recent video localization models, can effectively\nreason about temporal language, we collect the novel TEMPOral reasoning in\nvideo and language (TEMPO) dataset. Our dataset consists of two parts: a\ndataset with real videos and template sentences (TEMPO - Template Language)\nwhich allows for controlled studies on temporal language, and a human language\ndataset which consists of temporal sentences annotated by humans (TEMPO - Human\nLanguage).\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 05:58:47 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Hendricks", "Lisa Anne", ""], ["Wang", "Oliver", ""], ["Shechtman", "Eli", ""], ["Sivic", "Josef", ""], ["Darrell", "Trevor", ""], ["Russell", "Bryan", ""]]}, {"id": "1809.01341", "submitter": "Pouya Pezeshkpour", "authors": "Pouya Pezeshkpour, Liyan Chen and Sameer Singh", "title": "Embedding Multimodal Relational Data for Knowledge Base Completion", "comments": "Published at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representing entities and relations in an embedding space is a well-studied\napproach for machine learning on relational data. Existing approaches, however,\nprimarily focus on simple link structure between a finite set of entities,\nignoring the variety of data types that are often used in knowledge bases, such\nas text, images, and numerical values. In this paper, we propose multimodal\nknowledge base embeddings (MKBE) that use different neural encoders for this\nvariety of observed data, and combine them with existing relational models to\nlearn embeddings of the entities and multimodal data. Further, using these\nlearned embedings and different neural decoders, we introduce a novel\nmultimodal imputation model to generate missing multimodal values, like text\nand images, from information in the knowledge base. We enrich existing\nrelational datasets to create two novel benchmarks that contain additional\ninformation such as textual descriptions and images of the original entities.\nWe demonstrate that our models utilize this additional information effectively\nto provide more accurate link prediction, achieving state-of-the-art results\nwith a considerable gap of 5-7% over existing methods. Further, we evaluate the\nquality of our generated multimodal values via a user study. We have release\nthe datasets and the open-source implementation of our models at\nhttps://github.com/pouyapez/mkbe\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 06:07:31 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 18:13:10 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Pezeshkpour", "Pouya", ""], ["Chen", "Liyan", ""], ["Singh", "Sameer", ""]]}, {"id": "1809.01375", "submitter": "Pia Sommerauer", "authors": "Pia Sommerauer and Antske Fokkens", "title": "Firearms and Tigers are Dangerous, Kitchen Knives and Zebras are Not:\n  Testing whether Word Embeddings Can Tell", "comments": "Accepted to the EMNLP workshop \"Analyzing and interpreting neural\n  networks for NLP\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an approach for investigating the nature of semantic\ninformation captured by word embeddings. We propose a method that extends an\nexisting human-elicited semantic property dataset with gold negative examples\nusing crowd judgments. Our experimental approach tests the ability of\nsupervised classifiers to identify semantic features in word embedding vectors\nand com- pares this to a feature-identification method based on full vector\ncosine similarity. The idea behind this method is that properties identified by\nclassifiers, but not through full vector comparison are captured by embeddings.\nProperties that cannot be identified by either method are not. Our results\nprovide an initial indication that semantic properties relevant for the way\nentities interact (e.g. dangerous) are captured, while perceptual information\n(e.g. colors) is not represented. We conclude that, though preliminary, these\nresults show that our method is suitable for identifying which properties are\ncaptured by embeddings.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 08:14:16 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Sommerauer", "Pia", ""], ["Fokkens", "Antske", ""]]}, {"id": "1809.01431", "submitter": "Sameer Bansal", "authors": "Sameer Bansal, Herman Kamper, Karen Livescu, Adam Lopez, Sharon\n  Goldwater", "title": "Pre-training on high-resource speech recognition improves low-resource\n  speech-to-text translation", "comments": "Accepted for publication in NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple approach to improve direct speech-to-text translation\n(ST) when the source language is low-resource: we pre-train the model on a\nhigh-resource automatic speech recognition (ASR) task, and then fine-tune its\nparameters for ST. We demonstrate that our approach is effective by\npre-training on 300 hours of English ASR data to improve Spanish-English ST\nfrom 10.8 to 20.2 BLEU when only 20 hours of Spanish-English ST training data\nare available. Through an ablation study, we find that the pre-trained encoder\n(acoustic model) accounts for most of the improvement, despite the fact that\nthe shared language in these tasks is the target language text, not the source\nlanguage audio. Applying this insight, we show that pre-training on ASR helps\nST even when the ASR language differs from both source and target ST languages:\npre-training on French ASR also improves Spanish-English ST. Finally, we show\nthat the approach improves performance on a true low-resource task:\npre-training on a combination of English ASR and French ASR improves\nMboshi-French ST, where only 4 hours of data are available, from 3.5 to 7.1\nBLEU.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 10:56:30 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 23:47:26 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Bansal", "Sameer", ""], ["Kamper", "Herman", ""], ["Livescu", "Karen", ""], ["Lopez", "Adam", ""], ["Goldwater", "Sharon", ""]]}, {"id": "1809.01446", "submitter": "Bishal Santra", "authors": "Amrith Krishna, Bishal Santra, Sasi Prasanth Bandaru, Gaurav Sahu,\n  Vishnu Dutt Sharma, Pavankumar Satuluri and Pawan Goyal", "title": "Free as in Free Word Order: An Energy Based Model for Word Segmentation\n  and Morphological Tagging in Sanskrit", "comments": "version 2: Corrected typo in Table1, page7 | Accepted in EMNLP 2018.\n  Supplementary material can be found at -\n  http://cse.iitkgp.ac.in/~amrithk/1080_supp.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The configurational information in sentences of a free word order language\nsuch as Sanskrit is of limited use. Thus, the context of the entire sentence\nwill be desirable even for basic processing tasks such as word segmentation. We\npropose a structured prediction framework that jointly solves the word\nsegmentation and morphological tagging tasks in Sanskrit. We build an energy\nbased model where we adopt approaches generally employed in graph based parsing\ntechniques (McDonald et al., 2005a; Carreras, 2007). Our model outperforms the\nstate of the art with an F-Score of 96.92 (percentage improvement of 7.06%)\nwhile using less than one-tenth of the task-specific training data. We find\nthat the use of a graph based ap- proach instead of a traditional lattice-based\nsequential labelling approach leads to a percentage gain of 12.6% in F-Score\nfor the segmentation task.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 11:44:13 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2018 09:24:52 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Krishna", "Amrith", ""], ["Santra", "Bishal", ""], ["Bandaru", "Sasi Prasanth", ""], ["Sahu", "Gaurav", ""], ["Sharma", "Vishnu Dutt", ""], ["Satuluri", "Pavankumar", ""], ["Goyal", "Pawan", ""]]}, {"id": "1809.01448", "submitter": "Rotem Dror", "authors": "Rotem Dror and Roi Reichart", "title": "Appendix - Recommended Statistical Significance Tests for NLP Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical significance testing plays an important role when drawing\nconclusions from experimental results in NLP papers. Particularly, it is a\nvaluable tool when one would like to establish the superiority of one algorithm\nover another. This appendix complements the guide for testing statistical\nsignificance in NLP presented in \\cite{dror2018hitchhiker} by proposing valid\nstatistical tests for the common tasks and evaluation measures in the field.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 11:55:05 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Dror", "Rotem", ""], ["Reichart", "Roi", ""]]}, {"id": "1809.01452", "submitter": "Prabod Rathnayaka", "authors": "Prabod Rathnayaka, Supun Abeysinghe, Chamod Samarajeewa, Isura\n  Manchanayake, Malaka Walpola", "title": "Sentylic at IEST 2018: Gated Recurrent Neural Network and Capsule\n  Network Based Approach for Implicit Emotion Detection", "comments": "accepted to the 9th Workshop on Computational Approaches to\n  Subjectivity, Sentiment & Social Media Analysis, part of the EMNLP 2018\n  Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we present the system we have used for the Implicit WASSA 2018\nImplicit Emotion Shared Task. The task is to predict the emotion of a tweet of\nwhich the explicit mentions of emotion terms have been removed. The idea is to\ncome up with a model which has the ability to implicitly identify the emotion\nexpressed given the context words. We have used a Gated Recurrent Neural\nNetwork (GRU) and a Capsule Network based model for the task. Pre-trained word\nembeddings have been utilized to incorporate contextual knowledge about words\ninto the model. GRU layer learns latent representations using the input word\nembeddings. Subsequent Capsule Network layer learns high-level features from\nthat hidden representation. The proposed model managed to achieve a macro-F1\nscore of 0.692.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 12:04:35 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Rathnayaka", "Prabod", ""], ["Abeysinghe", "Supun", ""], ["Samarajeewa", "Chamod", ""], ["Manchanayake", "Isura", ""], ["Walpola", "Malaka", ""]]}, {"id": "1809.01477", "submitter": "Sahib Singh Budhiraja", "authors": "Sahib Singh Budhiraja, Vijay Mago", "title": "A Supervised Learning Approach For Heading Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  As the Portable Document Format (PDF) file format increases in popularity,\nresearch in analysing its structure for text extraction and analysis is\nnecessary. Detecting headings can be a crucial component of classifying and\nextracting meaningful data. This research involves training a supervised\nlearning model to detect headings with features carefully selected through\nrecursive feature elimination. The best performing classifier had an accuracy\nof 96.95%, sensitivity of 0.986 and a specificity of 0.953. This research into\nheading detection contributes to the field of PDF based text extraction and can\nbe applied to the automation of large scale PDF text analysis in a variety of\nprofessional and policy based contexts.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 19:31:05 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Budhiraja", "Sahib Singh", ""], ["Mago", "Vijay", ""]]}, {"id": "1809.01478", "submitter": "Yu Meng", "authors": "Yu Meng, Jiaming Shen, Chao Zhang, Jiawei Han", "title": "Weakly-Supervised Neural Text Classification", "comments": "CIKM 2018 Full Paper", "journal-ref": null, "doi": "10.1145/3269206.3271737", "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are gaining increasing popularity for the classic text\nclassification task, due to their strong expressive power and less requirement\nfor feature engineering. Despite such attractiveness, neural text\nclassification models suffer from the lack of training data in many real-world\napplications. Although many semi-supervised and weakly-supervised text\nclassification models exist, they cannot be easily applied to deep neural\nmodels and meanwhile support limited supervision types. In this paper, we\npropose a weakly-supervised method that addresses the lack of training data in\nneural text classification. Our method consists of two modules: (1) a\npseudo-document generator that leverages seed information to generate\npseudo-labeled documents for model pre-training, and (2) a self-training module\nthat bootstraps on real unlabeled data for model refinement. Our method has the\nflexibility to handle different types of weak supervision and can be easily\nintegrated into existing deep neural models for text classification. We have\nperformed extensive experiments on three real-world datasets from different\ndomains. The results demonstrate that our proposed method achieves inspiring\nperformance without requiring excessive training data and outperforms baseline\nmethods significantly.\n", "versions": [{"version": "v1", "created": "Sun, 2 Sep 2018 02:56:25 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2018 04:34:59 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Meng", "Yu", ""], ["Shen", "Jiaming", ""], ["Zhang", "Chao", ""], ["Han", "Jiawei", ""]]}, {"id": "1809.01479", "submitter": "Andreas Hanselowski Dr.", "authors": "Andreas Hanselowski, Hao Zhang, Zile Li, Daniil Sorokin, Benjamin\n  Schiller, Claudia Schulz, Iryna Gurevych", "title": "UKP-Athene: Multi-Sentence Textual Entailment for Claim Verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Fact Extraction and VERification (FEVER) shared task was launched to\nsupport the development of systems able to verify claims by extracting\nsupporting or refuting facts from raw text. The shared task organizers provide\na large-scale dataset for the consecutive steps involved in claim verification,\nin particular, document retrieval, fact extraction, and claim classification.\nIn this paper, we present our claim verification pipeline approach, which,\naccording to the preliminary results, scored third in the shared task, out of\n23 competing systems. For the document retrieval, we implemented a new entity\nlinking approach. In order to be able to rank candidate facts and classify a\nclaim on the basis of several selected facts, we introduce two extensions to\nthe Enhanced LSTM (ESIM).\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 14:06:11 GMT"}, {"version": "v2", "created": "Mon, 10 Sep 2018 10:45:21 GMT"}, {"version": "v3", "created": "Wed, 13 Feb 2019 13:42:34 GMT"}, {"version": "v4", "created": "Wed, 8 May 2019 15:35:47 GMT"}, {"version": "v5", "created": "Thu, 9 May 2019 08:00:19 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Hanselowski", "Andreas", ""], ["Zhang", "Hao", ""], ["Li", "Zile", ""], ["Sorokin", "Daniil", ""], ["Schiller", "Benjamin", ""], ["Schulz", "Claudia", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1809.01494", "submitter": "Marzieh Saeidi", "authors": "Marzieh Saeidi, Max Bartolo, Patrick Lewis, Sameer Singh, Tim\n  Rockt\\\"aschel, Mike Sheldon, Guillaume Bouchard, Sebastian Riedel", "title": "Interpretation of Natural Language Rules in Conversational Machine\n  Reading", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most work in machine reading focuses on question answering problems where the\nanswer is directly expressed in the text to read. However, many real-world\nquestion answering problems require the reading of text not because it contains\nthe literal answer, but because it contains a recipe to derive an answer\ntogether with the reader's background knowledge. One example is the task of\ninterpreting regulations to answer \"Can I...?\" or \"Do I have to...?\" questions\nsuch as \"I am working in Canada. Do I have to carry on paying UK National\nInsurance?\" after reading a UK government website about this topic. This task\nrequires both the interpretation of rules and the application of background\nknowledge. It is further complicated due to the fact that, in practice, most\nquestions are underspecified, and a human assistant will regularly have to ask\nclarification questions such as \"How long have you been working abroad?\" when\nthe answer cannot be directly derived from the question and text. In this\npaper, we formalise this task and develop a crowd-sourcing strategy to collect\n32k task instances based on real-world rules and crowd-generated questions and\nscenarios. We analyse the challenges of this task and assess its difficulty by\nevaluating the performance of rule-based and machine-learning baselines. We\nobserve promising results when no background knowledge is necessary, and\nsubstantial room for improvement whenever background knowledge is needed.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 19:44:51 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Saeidi", "Marzieh", ""], ["Bartolo", "Max", ""], ["Lewis", "Patrick", ""], ["Singh", "Sameer", ""], ["Rockt\u00e4schel", "Tim", ""], ["Sheldon", "Mike", ""], ["Bouchard", "Guillaume", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1809.01495", "submitter": "Laure Soulier", "authors": "Wafa Aissa, Laure Soulier, Ludovic Denoyer", "title": "A Reinforcement Learning-driven Translation Model for Search-Oriented\n  Conversational Systems", "comments": "This is the author's pre-print version of the work. It is posted here\n  for your personal use, not for redistribution. Please cite the definitive\n  version which will be published in Proceedings of the 2018 EMNLP Workshop\n  SCAI: The 2nd International Workshop on Search-Oriented Conversational AI -\n  ISBN: 978-1-948087-75-9", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search-oriented conversational systems rely on information needs expressed in\nnatural language (NL). We focus here on the understanding of NL expressions for\nbuilding keyword-based queries. We propose a reinforcement-learning-driven\ntranslation model framework able to 1) learn the translation from NL\nexpressions to queries in a supervised way, and, 2) to overcome the lack of\nlarge-scale dataset by framing the translation model as a word selection\napproach and injecting relevance feedback in the learning process. Experiments\nare carried out on two TREC datasets and outline the effectiveness of our\napproach.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 15:11:49 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Aissa", "Wafa", ""], ["Soulier", "Laure", ""], ["Denoyer", "Ludovic", ""]]}, {"id": "1809.01496", "submitter": "Jieyu Zhao", "authors": "Jieyu Zhao, Yichao Zhou, Zeyu Li, Wei Wang and Kai-Wei Chang", "title": "Learning Gender-Neutral Word Embeddings", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embedding models have become a fundamental component in a wide range of\nNatural Language Processing (NLP) applications. However, embeddings trained on\nhuman-generated corpora have been demonstrated to inherit strong gender\nstereotypes that reflect social constructs. To address this concern, in this\npaper, we propose a novel training procedure for learning gender-neutral word\nembeddings. Our approach aims to preserve gender information in certain\ndimensions of word vectors while compelling other dimensions to be free of\ngender influence. Based on the proposed method, we generate a Gender-Neutral\nvariant of GloVe (GN-GloVe). Quantitative and qualitative experiments\ndemonstrate that GN-GloVe successfully isolates gender information without\nsacrificing the functionality of the embedding model.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 21:11:09 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Zhao", "Jieyu", ""], ["Zhou", "Yichao", ""], ["Li", "Zeyu", ""], ["Wang", "Wei", ""], ["Chang", "Kai-Wei", ""]]}, {"id": "1809.01497", "submitter": "Jingfeng Yang", "authors": "Jingfeng Yang and Sujian Li", "title": "Chinese Discourse Segmentation Using Bilingual Discourse Commonality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discourse segmentation aims to segment Elementary Discourse Units (EDUs) and\nis a fundamental task in discourse analysis. For Chinese, previous researches\nidentify EDUs just through discriminating the functions of punctuations. In\nthis paper, we argue that Chinese EDUs may not end at the punctuation positions\nand should follow the definition of EDU in RST-DT. With this definition, we\nconduct Chinese discourse segmentation with the help of English labeled\ndata.Using discourse commonality between English and Chinese, we design an\nadversarial neural network framework to extract common language-independent\nfeatures and language-specific features which are useful for discourse\nsegmentation, when there is no or only a small scale of Chinese labeled data\navailable. Experiments on discourse segmentation demonstrate that our models\ncan leverage common features from bilingual data, and learn efficient\nChinese-specific features from a small amount of Chinese labeled data,\noutperforming the baseline models.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 00:57:09 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Yang", "Jingfeng", ""], ["Li", "Sujian", ""]]}, {"id": "1809.01498", "submitter": "Benjamin Wilson", "authors": "Matthias Leimeister, Benjamin J. Wilson", "title": "Skip-gram word embeddings in hyperbolic space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has demonstrated that embeddings of tree-like graphs in\nhyperbolic space surpass their Euclidean counterparts in performance by a large\nmargin. Inspired by these results and scale-free structure in the word\nco-occurrence graph, we present an algorithm for learning word embeddings in\nhyperbolic space from free text. An objective function based on the hyperbolic\ndistance is derived and included in the skip-gram negative-sampling\narchitecture of word2vec. The hyperbolic word embeddings are then evaluated on\nword similarity and analogy benchmarks. The results demonstrate the potential\nof hyperbolic word embeddings, particularly in low dimensions, though without\nclear superiority over their Euclidean counterparts. We further discuss\nsubtleties in the formulation of the analogy task in curved spaces.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 13:54:45 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 12:36:58 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Leimeister", "Matthias", ""], ["Wilson", "Benjamin J.", ""]]}, {"id": "1809.01499", "submitter": "Samuel Carton", "authors": "Samuel Carton, Qiaozhu Mei, Paul Resnick", "title": "Extractive Adversarial Networks: High-Recall Explanations for\n  Identifying Personal Attacks in Social Media Posts", "comments": "Accepted to EMNLP 2018 Code and data available at\n  https://github.com/shcarton/rcnn", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an adversarial method for producing high-recall explanations of\nneural text classifier decisions. Building on an existing architecture for\nextractive explanations via hard attention, we add an adversarial layer which\nscans the residual of the attention for remaining predictive signal. Motivated\nby the important domain of detecting personal attacks in social media comments,\nwe additionally demonstrate the importance of manually setting a semantically\nappropriate `default' behavior for the model by explicitly manipulating its\nbias term. We develop a validation set of human-annotated personal attacks to\nevaluate the impact of these changes.\n", "versions": [{"version": "v1", "created": "Sat, 1 Sep 2018 00:15:30 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 20:59:09 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Carton", "Samuel", ""], ["Mei", "Qiaozhu", ""], ["Resnick", "Paul", ""]]}, {"id": "1809.01500", "submitter": "Nishant Nikhil", "authors": "Nishant Nikhil and Shivansh Mundra", "title": "Neural DrugNet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe the system submitted for the shared task on Social\nMedia Mining for Health Applications by the team Light. Previous works\ndemonstrate that LSTMs have achieved remarkable performance in natural language\nprocessing tasks. We deploy an ensemble of two LSTM models. The first one is a\npretrained language model appended with a classifier and takes words as input,\nwhile the second one is a LSTM model with an attention unit over it which takes\ncharacter tri-gram as input. We call the ensemble of these two models:\nNeural-DrugNet. Our system ranks 2nd in the second shared task: Automatic\nclassification of posts describing medication intake.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 10:16:19 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Nikhil", "Nishant", ""], ["Mundra", "Shivansh", ""]]}, {"id": "1809.01534", "submitter": "Daniel Watson", "authors": "Daniel Watson, Nasser Zalmout, Nizar Habash", "title": "Utilizing Character and Word Embeddings for Text Normalization with\n  Sequence-to-Sequence Models", "comments": "Accepted in EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text normalization is an important enabling technology for several NLP tasks.\nRecently, neural-network-based approaches have outperformed well-established\nmodels in this task. However, in languages other than English, there has been\nlittle exploration in this direction. Both the scarcity of annotated data and\nthe complexity of the language increase the difficulty of the problem. To\naddress these challenges, we use a sequence-to-sequence model with\ncharacter-based attention, which in addition to its self-learned character\nembeddings, uses word embeddings pre-trained with an approach that also models\nsubword information. This provides the neural model with access to more\nlinguistic information especially suitable for text normalization, without\nlarge parallel corpora. We show that providing the model with word-level\nfeatures bridges the gap for the neural network approach to achieve a\nstate-of-the-art F1 score on a standard Arabic language correction shared task\ndataset.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 16:44:04 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Watson", "Daniel", ""], ["Zalmout", "Nasser", ""], ["Habash", "Nizar", ""]]}, {"id": "1809.01541", "submitter": "Yova Kementchedjhieva", "authors": "Yova Kementchedjhieva, Johannes Bjerva, Isabelle Augenstein", "title": "Copenhagen at CoNLL--SIGMORPHON 2018: Multilingual Inflection in Context\n  with Explicit Morphosyntactic Decoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper documents the Team Copenhagen system which placed first in the\nCoNLL--SIGMORPHON 2018 shared task on universal morphological reinflection,\nTask 2 with an overall accuracy of 49.87. Task 2 focuses on morphological\ninflection in context: generating an inflected word form, given the lemma of\nthe word and the context it occurs in. Previous SIGMORPHON shared tasks have\nfocused on context-agnostic inflection---the \"inflection in context\" task was\nintroduced this year. We approach this with an encoder-decoder architecture\nover character sequences with three core innovations, all contributing to an\nimprovement in performance: (1) a wide context window; (2) a multi-task\nlearning approach with the auxiliary task of MSD prediction; (3) training\nmodels in a multilingual fashion.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 14:31:04 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Kementchedjhieva", "Yova", ""], ["Bjerva", "Johannes", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "1809.01557", "submitter": "Shang-Yu Su", "authors": "Shang-Yu Su, Pei-Chieh Yuan, Yun-Nung Chen", "title": "Dynamically Context-Sensitive Time-Decay Attention for Dialogue Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spoken language understanding (SLU) is an essential component in\nconversational systems. Considering that contexts provide informative cues for\nbetter understanding, history can be leveraged for contextual SLU. However,\nmost prior work only paid attention to the related content in history\nutterances and ignored the temporal information. In dialogues, it is intuitive\nthat the most recent utterances are more important than the least recent ones,\nand time-aware attention should be in a decaying manner. Therefore, this paper\nallows the model to automatically learn a time-decay attention function where\nthe attentional weights can be dynamically decided based on the content of each\nrole's contexts, which effectively integrates both content-aware and time-aware\nperspectives and demonstrates remarkable flexibility to complex dialogue\ncontexts. The experiments on the benchmark Dialogue State Tracking Challenge\n(DSTC4) dataset show that the proposed dynamically context-sensitive time-decay\nattention mechanisms significantly improve the state-of-the-art model for\ncontextual understanding performance.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 14:53:14 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 00:06:50 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Su", "Shang-Yu", ""], ["Yuan", "Pei-Chieh", ""], ["Chen", "Yun-Nung", ""]]}, {"id": "1809.01574", "submitter": "Nikita Lozhnikov", "authors": "Nikita Lozhnikov and Leon Derczynski and Manuel Mazzara", "title": "Stance Prediction for Russian: Data and Analysis", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.15252.76161/1", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Stance detection is a critical component of rumour and fake news\nidentification. It involves the extraction of the stance a particular author\ntakes related to a given claim, both expressed in text. This paper investigates\nstance classification for Russian. It introduces a new dataset, RuStance, of\nRussian tweets and news comments from multiple sources, covering multiple\nstories, as well as text classification approaches to stance detection as\nbenchmarks over this data in this language. As well as presenting this\nopenly-available dataset, the first of its kind for Russian, the paper presents\na baseline for stance prediction in the language.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 15:20:41 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 12:44:14 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Lozhnikov", "Nikita", ""], ["Derczynski", "Leon", ""], ["Mazzara", "Manuel", ""]]}, {"id": "1809.01576", "submitter": "Lesly Miculicich Werlen", "authors": "Lesly Miculicich, Dhananjay Ram, Nikolaos Pappas, James Henderson", "title": "Document-Level Neural Machine Translation with Hierarchical Attention\n  Networks", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) can be improved by including document-level\ncontextual information. For this purpose, we propose a hierarchical attention\nmodel to capture the context in a structured and dynamic manner. The model is\nintegrated in the original NMT architecture as another level of abstraction,\nconditioning on the NMT model's own previous hidden states. Experiments show\nthat hierarchical attention significantly improves the BLEU score over a strong\nNMT baseline with the state-of-the-art in context-aware methods, and that both\nthe encoder and decoder benefit from context in complementary ways.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 15:27:16 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 09:03:59 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Miculicich", "Lesly", ""], ["Ram", "Dhananjay", ""], ["Pappas", "Nikolaos", ""], ["Henderson", "James", ""]]}, {"id": "1809.01610", "submitter": "Mehdi Moradi", "authors": "Mehdi Moradi, Ali Madani, Yaniv Gur, Yufan Guo, Tanveer Syeda-Mahmood", "title": "Bimodal network architectures for automatic generation of image\n  annotation from text", "comments": "Accepted to MICCAI 2018, LNCS 11070", "journal-ref": "Lecture Notes in Computer Science (LNCS 11070), Proceedings of\n  Medical Image Computing & Computer Assisted Intervention (MICCAI 2018)", "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical image analysis practitioners have embraced big data methodologies.\nThis has created a need for large annotated datasets. The source of big data is\ntypically large image collections and clinical reports recorded for these\nimages. In many cases, however, building algorithms aimed at segmentation and\ndetection of disease requires a training dataset with markings of the areas of\ninterest on the image that match with the described anomalies. This process of\nannotation is expensive and needs the involvement of clinicians. In this work\nwe propose two separate deep neural network architectures for automatic marking\nof a region of interest (ROI) on the image best representing a finding\nlocation, given a textual report or a set of keywords. One architecture\nconsists of LSTM and CNN components and is trained end to end with images,\nmatching text, and markings of ROIs for those images. The output layer\nestimates the coordinates of the vertices of a polygonal region. The second\narchitecture uses a network pre-trained on a large dataset of the same image\ntypes for learning feature representations of the findings of interest. We show\nthat for a variety of findings from chest X-ray images, both proposed\narchitectures learn to estimate the ROI, as validated by clinical annotations.\nThere is a clear advantage obtained from the architecture with pre-trained\nimaging network. The centroids of the ROIs marked by this network were on\naverage at a distance equivalent to 5.1% of the image width from the centroids\nof the ground truth ROIs.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 16:30:08 GMT"}], "update_date": "2018-09-09", "authors_parsed": [["Moradi", "Mehdi", ""], ["Madani", "Ali", ""], ["Gur", "Yaniv", ""], ["Guo", "Yufan", ""], ["Syeda-Mahmood", "Tanveer", ""]]}, {"id": "1809.01682", "submitter": "Georgios-Ioannis Brokos", "authors": "Ryan McDonald, Georgios-Ioannis Brokos, Ion Androutsopoulos", "title": "Deep Relevance Ranking Using Enhanced Document-Query Interactions", "comments": "In Proceedings of the Conference on Empirical Methods in Natural\n  Language Processing (EMNLP 2018), Brussels, Belgium, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore several new models for document relevance ranking, building upon\nthe Deep Relevance Matching Model (DRMM) of Guo et al. (2016). Unlike DRMM,\nwhich uses context-insensitive encodings of terms and query-document term\ninteractions, we inject rich context-sensitive encodings throughout our models,\ninspired by PACRR's (Hui et al., 2017) convolutional n-gram matching features,\nbut extended in several ways including multiple views of query and document\ninputs. We test our models on datasets from the BIOASQ question answering\nchallenge (Tsatsaronis et al., 2015) and TREC ROBUST 2004 (Voorhees, 2005),\nshowing they outperform BM25-based baselines, DRMM, and PACRR.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 18:18:34 GMT"}, {"version": "v2", "created": "Tue, 11 Sep 2018 11:12:58 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["McDonald", "Ryan", ""], ["Brokos", "Georgios-Ioannis", ""], ["Androutsopoulos", "Ion", ""]]}, {"id": "1809.01694", "submitter": "Kazuma Hashimoto", "authors": "Kazuma Hashimoto and Yoshimasa Tsuruoka", "title": "Accelerated Reinforcement Learning for Sentence Generation by Vocabulary\n  Prediction", "comments": "NAACL2019 camera ready (mini-batch splitting is added)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major obstacle in reinforcement learning-based sentence generation is the\nlarge action space whose size is equal to the vocabulary size of the\ntarget-side language. To improve the efficiency of reinforcement learning, we\npresent a novel approach for reducing the action space based on dynamic\nvocabulary prediction. Our method first predicts a fixed-size small vocabulary\nfor each input to generate its target sentence. The input-specific vocabularies\nare then used at supervised and reinforcement learning steps, and also at test\ntime. In our experiments on six machine translation and two image captioning\ndatasets, our method achieves faster reinforcement learning ($\\sim$2.7x faster)\nwith less GPU memory ($\\sim$2.3x less) than the full-vocabulary counterpart.\nThe reinforcement learning with our method consistently leads to significant\nimprovement of BLEU scores, and the scores are equal to or better than those of\nbaselines using the full vocabularies, with faster decoding time ($\\sim$3x\nfaster) on CPUs.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 19:11:14 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 20:51:38 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Hashimoto", "Kazuma", ""], ["Tsuruoka", "Yoshimasa", ""]]}, {"id": "1809.01696", "submitter": "Jie Lei", "authors": "Jie Lei, Licheng Yu, Mohit Bansal, Tamara L. Berg", "title": "TVQA: Localized, Compositional Video Question Answering", "comments": "EMNLP 2018 (13 pages; Data and Leaderboard at:\n  http://tvqa.cs.unc.edu). Updated with test-public results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed an increasing interest in image-based\nquestion-answering (QA) tasks. However, due to data limitations, there has been\nmuch less work on video-based QA. In this paper, we present TVQA, a large-scale\nvideo QA dataset based on 6 popular TV shows. TVQA consists of 152,545 QA pairs\nfrom 21,793 clips, spanning over 460 hours of video. Questions are designed to\nbe compositional in nature, requiring systems to jointly localize relevant\nmoments within a clip, comprehend subtitle-based dialogue, and recognize\nrelevant visual concepts. We provide analyses of this new dataset as well as\nseveral baselines and a multi-stream end-to-end trainable neural network\nframework for the TVQA task. The dataset is publicly available at\nhttp://tvqa.cs.unc.edu.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 19:14:11 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 21:34:05 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Lei", "Jie", ""], ["Yu", "Licheng", ""], ["Bansal", "Mohit", ""], ["Berg", "Tamara L.", ""]]}, {"id": "1809.01771", "submitter": "Roger Stein", "authors": "Roger A. Stein, Patricia A. Jaques, Joao F. Valiati", "title": "An Analysis of Hierarchical Text Classification Using Word Embeddings", "comments": "Article accepted for publication in Information Sciences on Sep 1st,\n  2018", "journal-ref": null, "doi": "10.1016/j.ins.2018.09.001", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient distributed numerical word representation models (word embeddings)\ncombined with modern machine learning algorithms have recently yielded\nconsiderable improvement on automatic document classification tasks. However,\nthe effectiveness of such techniques has not been assessed for the hierarchical\ntext classification (HTC) yet. This study investigates the application of those\nmodels and algorithms on this specific problem by means of experimentation and\nanalysis. We trained classification models with prominent machine learning\nalgorithm implementations---fastText, XGBoost, SVM, and Keras' CNN---and\nnoticeable word embeddings generation methods---GloVe, word2vec, and\nfastText---with publicly available data and evaluated them with measures\nspecifically appropriate for the hierarchical context. FastText achieved an\n${}_{LCA}F_1$ of 0.893 on a single-labeled version of the RCV1 dataset. An\nanalysis indicates that using word embeddings and its flavors is a very\npromising approach for HTC.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 00:31:51 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Stein", "Roger A.", ""], ["Jaques", "Patricia A.", ""], ["Valiati", "Joao F.", ""]]}, {"id": "1809.01797", "submitter": "Qingyun Wang", "authors": "Qingyun Wang, Xiaoman Pan, Lifu Huang, Boliang Zhang, Zhiying Jiang,\n  Heng Ji, Kevin Knight", "title": "Describing a Knowledge Base", "comments": "12 pages. Accepted by The 11th International Conference on Natural\n  Language Generation (INLG 2018) Code at\n  https://github.com/EagleW/Describing_a_Knowledge_Base", "journal-ref": null, "doi": "10.18653/v1/W18-6502", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to automatically generate natural language descriptions about an input\nstructured knowledge base (KB). We build our generation framework based on a\npointer network which can copy facts from the input KB, and add two attention\nmechanisms: (i) slot-aware attention to capture the association between a slot\ntype and its corresponding slot value; and (ii) a new \\emph{table position\nself-attention} to capture the inter-dependencies among related slots. For\nevaluation, besides standard metrics including BLEU, METEOR, and ROUGE, we\npropose a KB reconstruction based metric by extracting a KB from the generation\noutput and comparing it with the input KB. We also create a new data set which\nincludes 106,216 pairs of structured KBs and their corresponding natural\nlanguage descriptions for two distinct entity types. Experiments show that our\napproach significantly outperforms state-of-the-art methods. The reconstructed\nKB achieves 68.8% - 72.6% F-score.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 02:56:58 GMT"}, {"version": "v2", "created": "Sun, 30 Sep 2018 04:36:18 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Wang", "Qingyun", ""], ["Pan", "Xiaoman", ""], ["Huang", "Lifu", ""], ["Zhang", "Boliang", ""], ["Jiang", "Zhiying", ""], ["Ji", "Heng", ""], ["Knight", "Kevin", ""]]}, {"id": "1809.01812", "submitter": "Zhuang Ma", "authors": "Zhuang Ma, Michael Collins", "title": "Noise Contrastive Estimation and Negative Sampling for Conditional\n  Models: Consistency and Statistical Efficiency", "comments": "To appear in EMNLP2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noise Contrastive Estimation (NCE) is a powerful parameter estimation method\nfor log-linear models, which avoids calculation of the partition function or\nits derivatives at each training step, a computationally demanding step in many\ncases. It is closely related to negative sampling methods, now widely used in\nNLP. This paper considers NCE-based estimation of conditional models.\nConditional models are frequently encountered in practice; however there has\nnot been a rigorous theoretical analysis of NCE in this setting, and we will\nargue there are subtle but important questions when generalizing NCE to the\nconditional case. In particular, we analyze two variants of NCE for conditional\nmodels: one based on a classification objective, the other based on a ranking\nobjective. We show that the ranking-based variant of NCE gives consistent\nparameter estimates under weaker assumptions than the classification-based\nmethod; we analyze the statistical efficiency of the ranking-based and\nclassification-based variants of NCE; finally we describe experiments on\nsynthetic data and language modeling showing the effectiveness and trade-offs\nof both methods.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 04:11:46 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Ma", "Zhuang", ""], ["Collins", "Michael", ""]]}, {"id": "1809.01816", "submitter": "Marcus Rohrbach", "authors": "Satwik Kottur, Jos\\'e M. F. Moura, Devi Parikh, Dhruv Batra, Marcus\n  Rohrbach", "title": "Visual Coreference Resolution in Visual Dialog using Neural Module\n  Networks", "comments": "ECCV 2018 + results on VisDial v1.0 dataset", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual dialog entails answering a series of questions grounded in an image,\nusing dialog history as context. In addition to the challenges found in visual\nquestion answering (VQA), which can be seen as one-round dialog, visual dialog\nencompasses several more. We focus on one such problem called visual\ncoreference resolution that involves determining which words, typically noun\nphrases and pronouns, co-refer to the same entity/object instance in an image.\nThis is crucial, especially for pronouns (e.g., `it'), as the dialog agent must\nfirst link it to a previous coreference (e.g., `boat'), and only then can rely\non the visual grounding of the coreference `boat' to reason about the pronoun\n`it'. Prior work (in visual dialog) models visual coreference resolution either\n(a) implicitly via a memory network over history, or (b) at a coarse level for\nthe entire question; and not explicitly at a phrase level of granularity. In\nthis work, we propose a neural module network architecture for visual dialog by\nintroducing two novel modules - Refer and Exclude - that perform explicit,\ngrounded, coreference resolution at a finer word level. We demonstrate the\neffectiveness of our model on MNIST Dialog, a visually simple yet\ncoreference-wise complex dataset, by achieving near perfect accuracy, and on\nVisDial, a large and challenging visual dialog dataset on real images, where\nour model outperforms other approaches, and is more interpretable, grounded,\nand consistent qualitatively.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 04:36:22 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Kottur", "Satwik", ""], ["Moura", "Jos\u00e9 M. F.", ""], ["Parikh", "Devi", ""], ["Batra", "Dhruv", ""], ["Rohrbach", "Marcus", ""]]}, {"id": "1809.01854", "submitter": "Jetic Gu", "authors": "Jetic G\\=u and Hassan S. Shavarani and Anoop Sarkar", "title": "Top-down Tree Structured Decoding with Syntactic Connections for Neural\n  Machine Translation and Parsing", "comments": "Accepted as an EMNLP 2018 Long Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The addition of syntax-aware decoding in Neural Machine Translation (NMT)\nsystems requires an effective tree-structured neural network, a syntax-aware\nattention model and a language generation model that is sensitive to sentence\nstructure. We exploit a top-down tree-structured model called DRNN\n(Doubly-Recurrent Neural Networks) first proposed by Alvarez-Melis and Jaakola\n(2017) to create an NMT model called Seq2DRNN that combines a sequential\nencoder with tree-structured decoding augmented with a syntax-aware attention\nmodel. Unlike previous approaches to syntax-based NMT which use dependency\nparsing models our method uses constituency parsing which we argue provides\nuseful information for translation. In addition, we use the syntactic structure\nof the sentence to add new connections to the tree-structured decoder neural\nnetwork (Seq2DRNN+SynC). We compare our NMT model with sequential and state of\nthe art syntax-based NMT models and show that our model produces more fluent\ntranslations with better reordering. Since our model is capable of doing\ntranslation and constituency parsing at the same time we also compare our\nparsing accuracy against other neural parsing models.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 07:33:48 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["G\u016b", "Jetic", ""], ["Shavarani", "Hassan S.", ""], ["Sarkar", "Anoop", ""]]}, {"id": "1809.01941", "submitter": "Shaojie Jiang", "authors": "Shaojie Jiang, Maarten de Rijke", "title": "Why are Sequence-to-Sequence Models So Dull? Understanding the\n  Low-Diversity Problem of Chatbots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diversity is a long-studied topic in information retrieval that usually\nrefers to the requirement that retrieved results should be non-repetitive and\ncover different aspects. In a conversational setting, an additional dimension\nof diversity matters: an engaging response generation system should be able to\noutput responses that are diverse and interesting. Sequence-to-sequence\n(Seq2Seq) models have been shown to be very effective for response generation.\nHowever, dialogue responses generated by Seq2Seq models tend to have low\ndiversity. In this paper, we review known sources and existing approaches to\nthis low-diversity problem. We also identify a source of low diversity that has\nbeen little studied so far, namely model over-confidence. We sketch several\ndirections for tackling model over-confidence and, hence, the low-diversity\nproblem, including confidence penalties and label smoothing.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 12:24:04 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Jiang", "Shaojie", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1809.01943", "submitter": "Jiaming Xu", "authors": "Yiqun Yao, Jiaming Xu, Feng Wang, Bo Xu", "title": "Cascaded Mutual Modulation for Visual Reasoning", "comments": "to appear in EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Visual reasoning is a special visual question answering problem that is\nmulti-step and compositional by nature, and also requires intensive text-vision\ninteractions. We propose CMM: Cascaded Mutual Modulation as a novel end-to-end\nvisual reasoning model. CMM includes a multi-step comprehension process for\nboth question and image. In each step, we use a Feature-wise Linear Modulation\n(FiLM) technique to enable textual/visual pipeline to mutually control each\nother. Experiments show that CMM significantly outperforms most related models,\nand reach state-of-the-arts on two visual reasoning benchmarks: CLEVR and NLVR,\ncollected from both synthetic and natural languages. Ablation studies confirm\nthat both our multistep framework and our visual-guided language modulation are\ncritical to the task. Our code is available at\nhttps://github.com/FlamingHorizon/CMM-VR.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 12:26:24 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Yao", "Yiqun", ""], ["Xu", "Jiaming", ""], ["Wang", "Feng", ""], ["Xu", "Bo", ""]]}, {"id": "1809.01962", "submitter": "Saurabh Garg", "authors": "Saurabh Garg, Tanmay Parekh, Preethi Jyothi", "title": "Code-switched Language Models Using Dual RNNs and Same-Source\n  Pretraining", "comments": "Accepted at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work focuses on building language models (LMs) for code-switched text.\nWe propose two techniques that significantly improve these LMs: 1) A novel\nrecurrent neural network unit with dual components that focus on each language\nin the code-switched text separately 2) Pretraining the LM using synthetic text\nfrom a generative model estimated using the training data. We demonstrate the\neffectiveness of our proposed techniques by reporting perplexities on a\nMandarin-English task and derive significant reductions in perplexity.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 13:12:27 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Garg", "Saurabh", ""], ["Parekh", "Tanmay", ""], ["Jyothi", "Preethi", ""]]}, {"id": "1809.01984", "submitter": "Pierre-Emmanuel Mazar\\'e", "authors": "Pierre-Emmanuel Mazar\\'e, Samuel Humeau, Martin Raison, Antoine Bordes", "title": "Training Millions of Personalized Dialogue Agents", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current dialogue systems are not very engaging for users, especially when\ntrained end-to-end without relying on proactive reengaging scripted strategies.\nZhang et al. (2018) showed that the engagement level of end-to-end dialogue\nmodels increases when conditioning them on text personas providing some\npersonalized back-story to the model. However, the dataset used in Zhang et al.\n(2018) is synthetic and of limited size as it contains around 1k different\npersonas. In this paper we introduce a new dataset providing 5 million personas\nand 700 million persona-based dialogues. Our experiments show that, at this\nscale, training using personas still improves the performance of end-to-end\nsystems. In addition, we show that other tasks benefit from the wide coverage\nof our dataset by fine-tuning our model on the data from Zhang et al. (2018)\nand achieving state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 13:36:40 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Mazar\u00e9", "Pierre-Emmanuel", ""], ["Humeau", "Samuel", ""], ["Raison", "Martin", ""], ["Bordes", "Antoine", ""]]}, {"id": "1809.01997", "submitter": "Han Xiao", "authors": "Han Xiao, Feng Wang, Jianfeng Yan, Jingyao Zheng", "title": "Dual Ask-Answer Network for Machine Reading Comprehension", "comments": "8 pages, 5 figures, 4 tables. Code is available at\n  https://github.com/hanxiao/daanet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are three modalities in the reading comprehension setting: question,\nanswer and context. The task of question answering or question generation aims\nto infer an answer or a question when given the counterpart based on context.\nWe present a novel two-way neural sequence transduction model that connects\nthree modalities, allowing it to learn two tasks simultaneously and mutually\nbenefit one another. During training, the model receives\nquestion-context-answer triplets as input and captures the cross-modal\ninteraction via a hierarchical attention process. Unlike previous joint\nlearning paradigms that leverage the duality of question generation and\nquestion answering at data level, we solve such dual tasks at the architecture\nlevel by mirroring the network structure and partially sharing components at\ndifferent layers. This enables the knowledge to be transferred from one task to\nanother, helping the model to find a general representation for each modality.\nThe evaluation on four public datasets shows that our dual-learning model\noutperforms the mono-learning counterpart as well as the state-of-the-art joint\nmodels on both question answering and question generation tasks.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 13:57:03 GMT"}, {"version": "v2", "created": "Mon, 10 Sep 2018 10:55:43 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Xiao", "Han", ""], ["Wang", "Feng", ""], ["Yan", "Jianfeng", ""], ["Zheng", "Jingyao", ""]]}, {"id": "1809.02035", "submitter": "Johnny Wei", "authors": "Johnny Tian-Zheng Wei, Khiem Pham, Brian Dillon, Brendan O'Connor", "title": "Evaluating Syntactic Properties of Seq2seq Output with a Broad Coverage\n  HPSG: A Case Study on Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence to sequence (seq2seq) models are often employed in settings where\nthe target output is natural language. However, the syntactic properties of the\nlanguage generated from these models are not well understood. We explore\nwhether such output belongs to a formal and realistic grammar, by employing the\nEnglish Resource Grammar (ERG), a broad coverage, linguistically precise\nHPSG-based grammar of English. From a French to English parallel corpus, we\nanalyze the parseability and grammatical constructions occurring in output from\na seq2seq translation model. Over 93\\% of the model translations are parseable,\nsuggesting that it learns to generate conforming to a grammar. The model has\ntrouble learning the distribution of rarer syntactic rules, and we pinpoint\nseveral constructions that differentiate translations between the references\nand our model.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 15:09:46 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Wei", "Johnny Tian-Zheng", ""], ["Pham", "Khiem", ""], ["Dillon", "Brian", ""], ["O'Connor", "Brendan", ""]]}, {"id": "1809.02040", "submitter": "Linfeng Song", "authors": "Linfeng Song, Zhiguo Wang, Mo Yu, Yue Zhang, Radu Florian and Daniel\n  Gildea", "title": "Exploring Graph-structured Passage Representation for Multi-hop Reading\n  Comprehension with Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-hop reading comprehension focuses on one type of factoid question,\nwhere a system needs to properly integrate multiple pieces of evidence to\ncorrectly answer a question. Previous work approximates global evidence with\nlocal coreference information, encoding coreference chains with DAG-styled GRU\nlayers within a gated-attention reader. However, coreference is limited in\nproviding information for rich inference. We introduce a new method for better\nconnecting global evidence, which forms more complex graphs compared to DAGs.\nTo perform evidence integration on our graphs, we investigate two recent graph\nneural networks, namely graph convolutional network (GCN) and graph recurrent\nnetwork (GRN). Experiments on two standard datasets show that richer global\ninformation leads to better answers. Our method performs better than all\npublished results on these datasets.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 15:18:14 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Song", "Linfeng", ""], ["Wang", "Zhiguo", ""], ["Yu", "Mo", ""], ["Zhang", "Yue", ""], ["Florian", "Radu", ""], ["Gildea", "Daniel", ""]]}, {"id": "1809.02079", "submitter": "Tong Niu", "authors": "Tong Niu and Mohit Bansal", "title": "Adversarial Over-Sensitivity and Over-Stability Strategies for Dialogue\n  Models", "comments": "CoNLL 2018 (15 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two categories of model-agnostic adversarial strategies that\nreveal the weaknesses of several generative, task-oriented dialogue models:\nShould-Not-Change strategies that evaluate over-sensitivity to small and\nsemantics-preserving edits, as well as Should-Change strategies that test if a\nmodel is over-stable against subtle yet semantics-changing modifications. We\nnext perform adversarial training with each strategy, employing a max-margin\napproach for negative generative examples. This not only makes the target\ndialogue model more robust to the adversarial inputs, but also helps it perform\nsignificantly better on the original inputs. Moreover, training on all\nstrategies combined achieves further improvements, achieving a new\nstate-of-the-art performance on the original task (also verified via human\nevaluation). In addition to adversarial training, we also address the\nrobustness task at the model-level, by feeding it subword units as both inputs\nand outputs, and show that the resulting model is equally competitive, requires\nonly 1/4 of the original vocabulary size, and is robust to one of the\nadversarial strategies (to which the original model is vulnerable) even without\nadversarial training.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 16:27:32 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Niu", "Tong", ""], ["Bansal", "Mohit", ""]]}, {"id": "1809.02094", "submitter": "Mikel Artetxe", "authors": "Mikel Artetxe, Gorka Labaka, I\\~nigo Lopez-Gazpio, Eneko Agirre", "title": "Uncovering divergent linguistic information in word embeddings with\n  lessons for intrinsic and extrinsic evaluation", "comments": "CoNLL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following the recent success of word embeddings, it has been argued that\nthere is no such thing as an ideal representation for words, as different\nmodels tend to capture divergent and often mutually incompatible aspects like\nsemantics/syntax and similarity/relatedness. In this paper, we show that each\nembedding model captures more information than directly apparent. A linear\ntransformation that adjusts the similarity order of the model without any\nexternal resource can tailor it to achieve better results in those aspects,\nproviding a new perspective on how embeddings encode divergent linguistic\ninformation. In addition, we explore the relation between intrinsic and\nextrinsic evaluation, as the effect of our transformations in downstream tasks\nis higher for unsupervised systems than for supervised ones.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 17:08:21 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Artetxe", "Mikel", ""], ["Labaka", "Gorka", ""], ["Lopez-Gazpio", "I\u00f1igo", ""], ["Agirre", "Eneko", ""]]}, {"id": "1809.02147", "submitter": "Bodhisattwa Prasad Majumder", "authors": "Amrith Krishna, Bodhisattwa Prasad Majumder, Rajesh Shreedhar Bhat and\n  Pawan Goyal", "title": "Upcycle Your OCR: Reusing OCRs for Post-OCR Text Correction in Romanised\n  Sanskrit", "comments": "This paper has been accepted as a full paper in the SIGNLL Conference\n  on Computational Natural Language Learning (CoNLL), 2018. The code, data and\n  the supplementary material is available at\n  https://github.com/majumderb/sanskrit-ocr", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a post-OCR text correction approach for digitising texts in\nRomanised Sanskrit. Owing to the lack of resources our approach uses OCR models\ntrained for other languages written in Roman. Currently, there exists no\ndataset available for Romanised Sanskrit OCR. So, we bootstrap a dataset of 430\nimages, scanned in two different settings and their corresponding ground truth.\nFor training, we synthetically generate training images for both the settings.\nWe find that the use of copying mechanism (Gu et al., 2016) yields a percentage\nincrease of 7.69 in Character Recognition Rate (CRR) than the current state of\nthe art model in solving monotone sequence-to-sequence tasks (Schnober et al.,\n2016). We find that our system is robust in combating OCR-prone errors, as it\nobtains a CRR of 87.01% from an OCR output with CRR of 35.76% for one of the\ndataset settings. A human judgment survey performed on the models shows that\nour proposed model results in predictions which are faster to comprehend and\nfaster to improve for a human than the other systems.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 18:02:55 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Krishna", "Amrith", ""], ["Majumder", "Bodhisattwa Prasad", ""], ["Bhat", "Rajesh Shreedhar", ""], ["Goyal", "Pawan", ""]]}, {"id": "1809.02156", "submitter": "Lisa Anne Hendricks", "authors": "Anna Rohrbach, Lisa Anne Hendricks, Kaylee Burns, Trevor Darrell, Kate\n  Saenko", "title": "Object Hallucination in Image Captioning", "comments": "Rohrbach and Hendricks contributed equally; accepted to EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite continuously improving performance, contemporary image captioning\nmodels are prone to \"hallucinating\" objects that are not actually in a scene.\nOne problem is that standard metrics only measure similarity to ground truth\ncaptions and may not fully capture image relevance. In this work, we propose a\nnew image relevance metric to evaluate current models with veridical visual\nlabels and assess their rate of object hallucination. We analyze how captioning\nmodel architectures and learning objectives contribute to object hallucination,\nexplore when hallucination is likely due to image misclassification or language\npriors, and assess how well current sentence metrics capture object\nhallucination. We investigate these questions on the standard image captioning\nbenchmark, MSCOCO, using a diverse set of models. Our analysis yields several\ninteresting findings, including that models which score best on standard\nsentence metrics do not always have lower hallucination and that models which\nhallucinate more tend to make errors driven by language priors.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 18:25:18 GMT"}, {"version": "v2", "created": "Fri, 29 Mar 2019 23:48:52 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Rohrbach", "Anna", ""], ["Hendricks", "Lisa Anne", ""], ["Burns", "Kaylee", ""], ["Darrell", "Trevor", ""], ["Saenko", "Kate", ""]]}, {"id": "1809.02208", "submitter": "Marcelo Prates", "authors": "Marcelo O. R. Prates, Pedro H. C. Avelar, Luis Lamb", "title": "Assessing Gender Bias in Machine Translation -- A Case Study with Google\n  Translate", "comments": "Accepted for publication on Neural Computing and Applications; 33\n  pages, 14 figures, 12 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently there has been a growing concern about machine bias, where trained\nstatistical models grow to reflect controversial societal asymmetries, such as\ngender or racial bias. A significant number of AI tools have recently been\nsuggested to be harmfully biased towards some minority, with reports of racist\ncriminal behavior predictors, Iphone X failing to differentiate between two\nAsian people and Google photos' mistakenly classifying black people as\ngorillas. Although a systematic study of such biases can be difficult, we\nbelieve that automated translation tools can be exploited through gender\nneutral languages to yield a window into the phenomenon of gender bias in AI.\n  In this paper, we start with a comprehensive list of job positions from the\nU.S. Bureau of Labor Statistics (BLS) and used it to build sentences in\nconstructions like \"He/She is an Engineer\" in 12 different gender neutral\nlanguages such as Hungarian, Chinese, Yoruba, and several others. We translate\nthese sentences into English using the Google Translate API, and collect\nstatistics about the frequency of female, male and gender-neutral pronouns in\nthe translated output. We show that GT exhibits a strong tendency towards male\ndefaults, in particular for fields linked to unbalanced gender distribution\nsuch as STEM jobs. We ran these statistics against BLS' data for the frequency\nof female participation in each job position, showing that GT fails to\nreproduce a real-world distribution of female workers. We provide experimental\nevidence that even if one does not expect in principle a 50:50 pronominal\ngender distribution, GT yields male defaults much more frequently than what\nwould be expected from demographic data alone.\n  We are hopeful that this work will ignite a debate about the need to augment\ncurrent statistical translation tools with debiasing techniques which can\nalready be found in the scientific literature.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 20:39:23 GMT"}, {"version": "v2", "created": "Thu, 13 Sep 2018 14:01:10 GMT"}, {"version": "v3", "created": "Mon, 5 Nov 2018 13:40:06 GMT"}, {"version": "v4", "created": "Mon, 11 Mar 2019 14:30:20 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Prates", "Marcelo O. R.", ""], ["Avelar", "Pedro H. C.", ""], ["Lamb", "Luis", ""]]}, {"id": "1809.02223", "submitter": "Adithya Renduchintala", "authors": "Adithya Renduchintala, Pamela Shapiro, Kevin Duh and Philipp Koehn", "title": "Character-Aware Decoder for Translation into Morphologically Rich\n  Languages", "comments": "9 pages (12 including Appendix), 5 figures, Accepted at MT Summit\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural machine translation (NMT) systems operate primarily on words (or\nsub-words), ignoring lower-level patterns of morphology. We present a\ncharacter-aware decoder designed to capture such patterns when translating into\nmorphologically rich languages. We achieve character-awareness by augmenting\nboth the softmax and embedding layers of an attention-based encoder-decoder\nmodel with convolutional neural networks that operate on the spelling of a\nword. To investigate performance on a wide variety of morphological phenomena,\nwe translate English into 14 typologically diverse target languages using the\nTED multi-target dataset. In this low-resource setting, the character-aware\ndecoder provides consistent improvements with BLEU score gains of up to\n$+3.05$. In addition, we analyze the relationship between the gains obtained\nand properties of the target language and find evidence that our model does\nindeed exploit morphological patterns.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 21:26:31 GMT"}, {"version": "v2", "created": "Mon, 10 Sep 2018 01:01:24 GMT"}, {"version": "v3", "created": "Tue, 11 Sep 2018 15:50:22 GMT"}, {"version": "v4", "created": "Thu, 28 Mar 2019 23:24:31 GMT"}, {"version": "v5", "created": "Tue, 18 Jun 2019 18:10:49 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Renduchintala", "Adithya", ""], ["Shapiro", "Pamela", ""], ["Duh", "Kevin", ""], ["Koehn", "Philipp", ""]]}, {"id": "1809.02237", "submitter": "Miryam de Lhoneux", "authors": "Aaron Smith, Bernd Bohnet, Miryam de Lhoneux, Joakim Nivre, Yan Shao,\n  Sara Stymne", "title": "82 Treebanks, 34 Models: Universal Dependency Parsing with\n  Multi-Treebank Models", "comments": "Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from\n  Raw Text to Universal Dependencies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Uppsala system for the CoNLL 2018 Shared Task on universal\ndependency parsing. Our system is a pipeline consisting of three components:\nthe first performs joint word and sentence segmentation; the second predicts\npart-of- speech tags and morphological features; the third predicts dependency\ntrees from words and tags. Instead of training a single parsing model for each\ntreebank, we trained models with multiple treebanks for one language or closely\nrelated languages, greatly reducing the number of models. On the official test\nrun, we ranked 7th of 27 teams for the LAS and MLAS metrics. Our system\nobtained the best scores overall for word segmentation, universal POS tagging,\nand morphological features.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 22:10:38 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Smith", "Aaron", ""], ["Bohnet", "Bernd", ""], ["de Lhoneux", "Miryam", ""], ["Nivre", "Joakim", ""], ["Shao", "Yan", ""], ["Stymne", "Sara", ""]]}, {"id": "1809.02251", "submitter": "Zhong Meng", "authors": "Zhong Meng, Jinyu Li, Yifan Gong and Biing-Hwang (Fred) Juang", "title": "Adversarial Feature-Mapping for Speech Enhancement", "comments": "5 pages, 2 figures, Interspeech 2018", "journal-ref": "Interspeech 2018", "doi": "10.21437/Interspeech.2018-2461", "report-no": null, "categories": "eess.AS cs.AI cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature-mapping with deep neural networks is commonly used for single-channel\nspeech enhancement, in which a feature-mapping network directly transforms the\nnoisy features to the corresponding enhanced ones and is trained to minimize\nthe mean square errors between the enhanced and clean features. In this paper,\nwe propose an adversarial feature-mapping (AFM) method for speech enhancement\nwhich advances the feature-mapping approach with adversarial learning. An\nadditional discriminator network is introduced to distinguish the enhanced\nfeatures from the real clean ones. The two networks are jointly optimized to\nminimize the feature-mapping loss and simultaneously mini-maximize the\ndiscrimination loss. The distribution of the enhanced features is further\npushed towards that of the clean features through this adversarial multi-task\ntraining. To achieve better performance on ASR task, senone-aware (SA) AFM is\nfurther proposed in which an acoustic model network is jointly trained with the\nfeature-mapping and discriminator networks to optimize the senone\nclassification loss in addition to the AFM losses. Evaluated on the CHiME-3\ndataset, the proposed AFM achieves 16.95% and 5.27% relative word error rate\n(WER) improvements over the real noisy data and the feature-mapping baseline\nrespectively and the SA-AFM achieves 9.85% relative WER improvement over the\nmulti-conditional acoustic model.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 23:42:21 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2019 15:53:15 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Meng", "Zhong", "", "Fred"], ["Li", "Jinyu", "", "Fred"], ["Gong", "Yifan", "", "Fred"], ["Biing-Hwang", "", "", "Fred"], ["Juang", "", ""]]}, {"id": "1809.02253", "submitter": "Zhong Meng", "authors": "Zhong Meng, Jinyu Li, Yifan Gong, Biing-Hwang (Fred) Juang", "title": "Cycle-Consistent Speech Enhancement", "comments": "5 pages, 2 figures. Interspeech 2018. arXiv admin note: text overlap\n  with arXiv:1809.02251", "journal-ref": "Interspeech 2018", "doi": "10.21437/Interspeech.2018-2409", "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature mapping using deep neural networks is an effective approach for\nsingle-channel speech enhancement. Noisy features are transformed to the\nenhanced ones through a mapping network and the mean square errors between the\nenhanced and clean features are minimized. In this paper, we propose a\ncycle-consistent speech enhancement (CSE) in which an additional inverse\nmapping network is introduced to reconstruct the noisy features from the\nenhanced ones. A cycle-consistent constraint is enforced to minimize the\nreconstruction loss. Similarly, a backward cycle of mappings is performed in\nthe opposite direction with the same networks and losses. With\ncycle-consistency, the speech structure is well preserved in the enhanced\nfeatures while noise is effectively reduced such that the feature-mapping\nnetwork generalizes better to unseen data. In cases where only unparalleled\nnoisy and clean data is available for training, two discriminator networks are\nused to distinguish the enhanced and noised features from the clean and noisy\nones. The discrimination losses are jointly optimized with reconstruction\nlosses through adversarial multi-task learning. Evaluated on the CHiME-3\ndataset, the proposed CSE achieves 19.60% and 6.69% relative word error rate\nimprovements respectively when using or without using parallel clean and noisy\nspeech data.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 23:55:49 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2019 15:48:14 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Meng", "Zhong", "", "Fred"], ["Li", "Jinyu", "", "Fred"], ["Gong", "Yifan", "", "Fred"], ["Biing-Hwang", "", "", "Fred"], ["Juang", "", ""]]}, {"id": "1809.02255", "submitter": "Darsh Shah", "authors": "Darsh J Shah, Tao Lei, Alessandro Moschitti, Salvatore Romeo, Preslav\n  Nakov", "title": "Adversarial Domain Adaptation for Duplicate Question Detection", "comments": "EMNLP 2018 short paper - camera ready. 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of detecting duplicate questions in forums, which is\nan important step towards automating the process of answering new questions. As\nfinding and annotating such potential duplicates manually is very tedious and\ncostly, automatic methods based on machine learning are a viable alternative.\nHowever, many forums do not have annotated data, i.e., questions labeled by\nexperts as duplicates, and thus a promising solution is to use domain\nadaptation from another forum that has such annotations. Here we focus on\nadversarial domain adaptation, deriving important findings about when it\nperforms well and what properties of the domains are important in this regard.\nOur experiments with StackExchange data show an average improvement of 5.6%\nover the best baseline across multiple pairs of domains.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 00:00:39 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Shah", "Darsh J", ""], ["Lei", "Tao", ""], ["Moschitti", "Alessandro", ""], ["Romeo", "Salvatore", ""], ["Nakov", "Preslav", ""]]}, {"id": "1809.02256", "submitter": "Jiang Guo", "authors": "Jiang Guo, Darsh J Shah and Regina Barzilay", "title": "Multi-Source Domain Adaptation with Mixture of Experts", "comments": "11 pages, EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a mixture-of-experts approach for unsupervised domain adaptation\nfrom multiple sources. The key idea is to explicitly capture the relationship\nbetween a target example and different source domains. This relationship,\nexpressed by a point-to-set metric, determines how to combine predictors\ntrained on various domains. The metric is learned in an unsupervised fashion\nusing meta-training. Experimental results on sentiment analysis and\npart-of-speech tagging demonstrate that our approach consistently outperforms\nmultiple baselines and can robustly handle negative transfer.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 00:01:42 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2018 16:11:00 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Guo", "Jiang", ""], ["Shah", "Darsh J", ""], ["Barzilay", "Regina", ""]]}, {"id": "1809.02279", "submitter": "Jihun Choi", "authors": "Jihun Choi, Taeuk Kim, Sang-goo Lee", "title": "Cell-aware Stacked LSTMs for Modeling Sentences", "comments": "ACML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method of stacking multiple long short-term memory (LSTM) layers\nfor modeling sentences. In contrast to the conventional stacked LSTMs where\nonly hidden states are fed as input to the next layer, the suggested\narchitecture accepts both hidden and memory cell states of the preceding layer\nand fuses information from the left and the lower context using the soft gating\nmechanism of LSTMs. Thus the architecture modulates the amount of information\nto be delivered not only in horizontal recurrence but also in vertical\nconnections, from which useful features extracted from lower layers are\neffectively conveyed to upper layers. We dub this architecture Cell-aware\nStacked LSTM (CAS-LSTM) and show from experiments that our models bring\nsignificant performance gain over the standard LSTMs on benchmark datasets for\nnatural language inference, paraphrase detection, sentiment classification, and\nmachine translation. We also conduct extensive qualitative analysis to\nunderstand the internal behavior of the suggested approach.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 02:17:23 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 07:23:42 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Choi", "Jihun", ""], ["Kim", "Taeuk", ""], ["Lee", "Sang-goo", ""]]}, {"id": "1809.02286", "submitter": "Taeuk Kim", "authors": "Taeuk Kim, Jihun Choi, Daniel Edmiston, Sanghwan Bae, Sang-goo Lee", "title": "Dynamic Compositionality in Recursive Neural Networks with\n  Structure-aware Tag Representations", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing recursive neural network (RvNN) architectures utilize only the\nstructure of parse trees, ignoring syntactic tags which are provided as\nby-products of parsing. We present a novel RvNN architecture that can provide\ndynamic compositionality by considering comprehensive syntactic information\nderived from both the structure and linguistic tags. Specifically, we introduce\na structure-aware tag representation constructed by a separate tag-level\ntree-LSTM. With this, we can control the composition function of the existing\nword-level tree-LSTM by augmenting the representation as a supplementary input\nto the gate functions of the tree-LSTM. In extensive experiments, we show that\nmodels built upon the proposed architecture obtain superior or competitive\nperformance on several sentence-level tasks such as sentiment analysis and\nnatural language inference when compared against previous tree-structured\nmodels and other sophisticated neural models.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 02:59:42 GMT"}, {"version": "v2", "created": "Mon, 26 Nov 2018 13:10:58 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Kim", "Taeuk", ""], ["Choi", "Jihun", ""], ["Edmiston", "Daniel", ""], ["Bae", "Sanghwan", ""], ["Lee", "Sang-goo", ""]]}, {"id": "1809.02305", "submitter": "Kang Min Yoo", "authors": "Kang Min Yoo, Youhyun Shin, Sang-goo Lee", "title": "Data Augmentation for Spoken Language Understanding via Joint\n  Variational Generation", "comments": "8 pages, 3 figures, 4 tables, Accepted in AAAI2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data scarcity is one of the main obstacles of domain adaptation in spoken\nlanguage understanding (SLU) due to the high cost of creating manually tagged\nSLU datasets. Recent works in neural text generative models, particularly\nlatent variable models such as variational autoencoder (VAE), have shown\npromising results in regards to generating plausible and natural sentences. In\nthis paper, we propose a novel generative architecture which leverages the\ngenerative power of latent variable models to jointly synthesize fully\nannotated utterances. Our experiments show that existing SLU models trained on\nthe additional synthetic examples achieve performance gains. Our approach not\nonly helps alleviate the data scarcity issue in the SLU task for many datasets\nbut also indiscriminately improves language understanding performances for\nvarious SLU models, supported by extensive experiments and rigorous statistical\ntesting.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 04:17:06 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 01:40:16 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Yoo", "Kang Min", ""], ["Shin", "Youhyun", ""], ["Lee", "Sang-goo", ""]]}, {"id": "1809.02306", "submitter": "Takashi Wada", "authors": "Takashi Wada, Tomoharu Iwata", "title": "Unsupervised Cross-lingual Word Embedding by Multilingual Neural\n  Language Models", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an unsupervised method to obtain cross-lingual embeddings without\nany parallel data or pre-trained word embeddings. The proposed model, which we\ncall multilingual neural language models, takes sentences of multiple languages\nas an input. The proposed model contains bidirectional LSTMs that perform as\nforward and backward language models, and these networks are shared among all\nthe languages. The other parameters, i.e. word embeddings and linear\ntransformation between hidden states and outputs, are specific to each\nlanguage. The shared LSTMs can capture the common sentence structure among all\nlanguages. Accordingly, word embeddings of each language are mapped into a\ncommon latent space, making it possible to measure the similarity of words\nacross multiple languages. We evaluate the quality of the cross-lingual word\nembeddings on a word alignment task. Our experiments demonstrate that our model\ncan obtain cross-lingual embeddings of much higher quality than existing\nunsupervised models when only a small amount of monolingual data (i.e. 50k\nsentences) are available, or the domains of monolingual data are different\nacross languages.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 04:17:40 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Wada", "Takashi", ""], ["Iwata", "Tomoharu", ""]]}, {"id": "1809.02343", "submitter": "Parth Mehta", "authors": "Parth Mehta, Prasenjit Majumder", "title": "Exploiting local and global performance of candidate systems for\n  aggregation of summarization techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With an ever growing number of extractive summarization techniques being\nproposed, there is less clarity then ever about how good each system is\ncompared to the rest. Several studies highlight the variance in performance of\nthese systems with change in datasets or even across documents within the same\ncorpus. An effective way to counter this variance and to make the systems more\nrobust could be to use inputs from multiple systems when generating a summary.\nIn the present work, we define a novel way of creating such ensemble by\nexploiting similarity between the content of candidate summaries to estimate\ntheir reliability. We define GlobalRank which captures the performance of a\ncandidate system on an overall corpus and LocalRank which estimates its\nperformance on a given document cluster. We then use these two scores to assign\na weight to each individual systems, which is then used to generate the new\naggregate ranking. Experiments on DUC2003 and DUC 2004 datasets show a\nsignificant improvement in terms of ROUGE score, over existing sate-of-art\ntechniques.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 08:18:01 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Mehta", "Parth", ""], ["Majumder", "Prasenjit", ""]]}, {"id": "1809.02393", "submitter": "Yanghoon Kim", "authors": "Yanghoon Kim and Hwanhee Lee and Joongbo Shin and Kyomin Jung", "title": "Improving Neural Question Generation using Answer Separation", "comments": "The paper is accepted to AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural question generation (NQG) is the task of generating a question from a\ngiven passage with deep neural networks. Previous NQG models suffer from a\nproblem that a significant proportion of the generated questions include words\nin the question target, resulting in the generation of unintended questions. In\nthis paper, we propose answer-separated seq2seq, which better utilizes the\ninformation from both the passage and the target answer. By replacing the\ntarget answer in the original passage with a special token, our model learns to\nidentify which interrogative word should be used. We also propose a new module\ntermed keyword-net, which helps the model better capture the key information in\nthe target answer and generate an appropriate question. Experimental results\ndemonstrate that our answer separation method significantly reduces the number\nof improper questions which include answers. Consequently, our model\nsignificantly outperforms previous state-of-the-art NQG models.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 10:35:42 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2018 01:43:12 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Kim", "Yanghoon", ""], ["Lee", "Hwanhee", ""], ["Shin", "Joongbo", ""], ["Jung", "Kyomin", ""]]}, {"id": "1809.02428", "submitter": "Johannes Bjerva", "authors": "Johannes Bjerva", "title": "Multitask and Multilingual Modelling for Lexical Analysis", "comments": "Thesis summary. This is a pre-print of an article published in KI -\n  K\\\"unstliche Intelligenz. The final authenticated version is available online\n  at: https://doi.org/10.1007/s13218-018-0557-5", "journal-ref": null, "doi": "10.1007/s13218-018-0557-5", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In Natural Language Processing (NLP), one traditionally considers a single\ntask (e.g. part-of-speech tagging) for a single language (e.g. English) at a\ntime. However, recent work has shown that it can be beneficial to take\nadvantage of relatedness between tasks, as well as between languages. In this\nwork I examine the concept of relatedness and explore how it can be utilised to\nbuild NLP models that require less manually annotated data. A large selection\nof NLP tasks is investigated for a substantial language sample comprising 60\nlanguages. The results show potential for joint multitask and multilingual\nmodelling, and hints at linguistic insights which can be gained from such\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 12:07:59 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Bjerva", "Johannes", ""]]}, {"id": "1809.02494", "submitter": "Alejandro Ramos Soto", "authors": "Alejandro Ramos-Soto and Ehud Reiter and Kees van Deemter and Jose M.\n  Alonso and Albert Gatt", "title": "Meteorologists and Students: A resource for language grounding of\n  geographical descriptors", "comments": "Resource paper, 5 pages, 6 figures, 1 table. Conference: INLG 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a data resource which can be useful for research purposes on\nlanguage grounding tasks in the context of geographical referring expression\ngeneration. The resource is composed of two data sets that encompass 25\ndifferent geographical descriptors and a set of associated graphical\nrepresentations, drawn as polygons on a map by two groups of human subjects:\nteenage students and expert meteorologists.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 14:20:32 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Ramos-Soto", "Alejandro", ""], ["Reiter", "Ehud", ""], ["van Deemter", "Kees", ""], ["Alonso", "Jose M.", ""], ["Gatt", "Albert", ""]]}, {"id": "1809.02534", "submitter": "Barry Devereux", "authors": "Steven Derby and Paul Miller and Brian Murphy and Barry Devereux", "title": "Using Sparse Semantic Embeddings Learned from Multimodal Text and Image\n  Data to Model Human Conceptual Knowledge", "comments": "Proceedings of the 22nd Conference on Computational Natural Language\n  Learning (CoNLL 2018), pages 260-270. Brussels, Belgium, October 31 -\n  November 1, 2018. Association for Computational Linguistics", "journal-ref": "Proceedings of the 22nd Conference on Computational Natural\n  Language Learning (CoNLL 2018), pages 260-270. Brussels, Belgium, October 31\n  - November 1, 2018. Association for Computational Linguistics", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributional models provide a convenient way to model semantics using dense\nembedding spaces derived from unsupervised learning algorithms. However, the\ndimensions of dense embedding spaces are not designed to resemble human\nsemantic knowledge. Moreover, embeddings are often built from a single source\nof information (typically text data), even though neurocognitive research\nsuggests that semantics is deeply linked to both language and perception. In\nthis paper, we combine multimodal information from both text and image-based\nrepresentations derived from state-of-the-art distributional models to produce\nsparse, interpretable vectors using Joint Non-Negative Sparse Embedding.\nThrough in-depth analyses comparing these sparse models to human-derived\nbehavioural and neuroimaging data, we demonstrate their ability to predict\ninterpretable linguistic descriptions of human ground-truth semantic knowledge.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 15:22:04 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2018 13:43:50 GMT"}, {"version": "v3", "created": "Wed, 14 Nov 2018 15:25:30 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Derby", "Steven", ""], ["Miller", "Paul", ""], ["Murphy", "Brian", ""], ["Devereux", "Barry", ""]]}, {"id": "1809.02592", "submitter": "Yihao Fang", "authors": "Yihao Fang, Rong Zheng, and Xiaodan Zhu", "title": "Logographic Subword Model for Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel logographic subword model is proposed to reinterpret logograms as\nabstract subwords for neural machine translation. Our approach drastically\nreduces the size of an artificial neural network, while maintaining comparable\nBLEU scores as those attained with the baseline RNN and CNN seq2seq models. The\nsmaller model size also leads to shorter training and inference time.\nExperiments demonstrate that in the tasks of English-Chinese/Chinese-English\ntranslation, the reduction of those aspects can be from $11\\%$ to as high as\n$77\\%$. Compared to previous subword models, abstract subwords can be applied\nto various logographic languages. Considering most of the logographic languages\nare ancient and very low resource languages, these advantages are very\ndesirable for archaeological computational linguistic applications such as a\nresource-limited offline hand-held Demotic-English translator.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 17:34:34 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Fang", "Yihao", ""], ["Zheng", "Rong", ""], ["Zhu", "Xiaodan", ""]]}, {"id": "1809.02637", "submitter": "Vrindavan Harrison", "authors": "Vrindavan Harrison and Marilyn Walker", "title": "Neural Generation of Diverse Questions using Answer Focus, Contextual\n  and Linguistic Features", "comments": "Accepted to appear at INLG 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question Generation is the task of automatically creating questions from\ntextual input. In this work we present a new Attentional Encoder--Decoder\nRecurrent Neural Network model for automatic question generation. Our model\nincorporates linguistic features and an additional sentence embedding to\ncapture meaning at both sentence and word levels. The linguistic features are\ndesigned to capture information related to named entity recognition, word case,\nand entity coreference resolution. In addition our model uses a copying\nmechanism and a special answer signal that enables generation of numerous\ndiverse questions on a given sentence. Our model achieves state of the art\nresults of 19.98 Bleu_4 on a benchmark Question Generation dataset,\noutperforming all previously published results by a significant margin. A human\nevaluation also shows that these added features improve the quality of the\ngenerated questions.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 18:47:20 GMT"}, {"version": "v2", "created": "Fri, 5 Oct 2018 21:50:26 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Harrison", "Vrindavan", ""], ["Walker", "Marilyn", ""]]}, {"id": "1809.02649", "submitter": "Wenlu Wang", "authors": "Wenlu Wang, Yingtao Tian, Hongyu Xiong, Haixun Wang, Wei-Shinn Ku", "title": "A Transfer-Learnable Natural Language Interface for Databases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relational database management systems (RDBMSs) are powerful because they are\nable to optimize and answer queries against any relational database. A natural\nlanguage interface (NLI) for a database, on the other hand, is tailored to\nsupport that specific database. In this work, we introduce a general purpose\ntransfer-learnable NLI with the goal of learning one model that can be used as\nNLI for any relational database. We adopt the data management principle of\nseparating data and its schema, but with the additional support for the\nidiosyncrasy and complexity of natural languages. Specifically, we introduce an\nautomatic annotation mechanism that separates the schema and the data, where\nthe schema also covers knowledge about natural language. Furthermore, we\npropose a customized sequence model that translates annotated natural language\nqueries to SQL statements. We show in experiments that our approach outperforms\nprevious NLI methods on the WikiSQL dataset and the model we learned can be\napplied to another benchmark dataset OVERNIGHT without retraining.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 19:38:51 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Wang", "Wenlu", ""], ["Tian", "Yingtao", ""], ["Xiong", "Hongyu", ""], ["Wang", "Haixun", ""], ["Ku", "Wei-Shinn", ""]]}, {"id": "1809.02669", "submitter": "Thibault F\\'evry", "authors": "Thibault F\\'evry, Jason Phang", "title": "Unsupervised Sentence Compression using Denoising Auto-Encoders", "comments": "CoNLL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In sentence compression, the task of shortening sentences while retaining the\noriginal meaning, models tend to be trained on large corpora containing pairs\nof verbose and compressed sentences. To remove the need for paired corpora, we\nemulate a summarization task and add noise to extend sentences and train a\ndenoising auto-encoder to recover the original, constructing an end-to-end\ntraining regime without the need for any examples of compressed sentences. We\nconduct a human evaluation of our model on a standard text summarization\ndataset and show that it performs comparably to a supervised baseline based on\ngrammatical correctness and retention of meaning. Despite being exposed to no\ntarget data, our unsupervised models learn to generate imperfect but reasonably\nreadable sentence summaries. Although we underperform supervised models based\non ROUGE scores, our models are competitive with a supervised baseline based on\nhuman evaluation for grammatical correctness and retention of meaning.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 20:56:33 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["F\u00e9vry", "Thibault", ""], ["Phang", "Jason", ""]]}, {"id": "1809.02687", "submitter": "Ran Ding", "authors": "Ran Ding, Ramesh Nallapati, Bing Xiang", "title": "Coherence-Aware Neural Topic Modeling", "comments": "Accepted at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic models are evaluated based on their ability to describe documents well\n(i.e. low perplexity) and to produce topics that carry coherent semantic\nmeaning. In topic modeling so far, perplexity is a direct optimization target.\nHowever, topic coherence, owing to its challenging computation, is not\noptimized for and is only evaluated after training. In this work, under a\nneural variational inference framework, we propose methods to incorporate a\ntopic coherence objective into the training process. We demonstrate that such a\ncoherence-aware topic model exhibits a similar level of perplexity as baseline\nmodels but achieves substantially higher topic coherence.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 21:43:30 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Ding", "Ran", ""], ["Nallapati", "Ramesh", ""], ["Xiang", "Bing", ""]]}, {"id": "1809.02694", "submitter": "Mamoru Komachi", "authors": "Longtu Zhang and Mamoru Komachi", "title": "Neural Machine Translation of Logographic Languages Using Sub-character\n  Level Information", "comments": "WMT 2018 (regular paper); 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Recent neural machine translation (NMT) systems have been greatly improved by\nencoder-decoder models with attention mechanisms and sub-word units. However,\nimportant differences between languages with logographic and alphabetic writing\nsystems have long been overlooked. This study focuses on these differences and\nuses a simple approach to improve the performance of NMT systems utilizing\ndecomposed sub-character level information for logographic languages. Our\nresults indicate that our approach not only improves the translation\ncapabilities of NMT systems between Chinese and English, but also further\nimproves NMT systems between Chinese and Japanese, because it utilizes the\nshared information brought by similar sub-character units.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 22:02:43 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Zhang", "Longtu", ""], ["Komachi", "Mamoru", ""]]}, {"id": "1809.02700", "submitter": "Matthew Lamm", "authors": "Matthew Lamm, Arun Tejasvi Chaganty, Christopher D. Manning, Dan\n  Jurafsky, Percy Liang", "title": "Textual Analogy Parsing: What's Shared and What's Compared among\n  Analogous Facts", "comments": "12 pages including appendix and references. To be presented at EMNLP\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To understand a sentence like \"whereas only 10% of White Americans live at or\nbelow the poverty line, 28% of African Americans do\" it is important not only\nto identify individual facts, e.g., poverty rates of distinct demographic\ngroups, but also the higher-order relations between them, e.g., the disparity\nbetween them. In this paper, we propose the task of Textual Analogy Parsing\n(TAP) to model this higher-order meaning. The output of TAP is a frame-style\nmeaning representation which explicitly specifies what is shared (e.g., poverty\nrates) and what is compared (e.g., White Americans vs. African Americans, 10%\nvs. 28%) between its component facts. Such a meaning representation can enable\nnew applications that rely on discourse understanding such as automated chart\ngeneration from quantitative text. We present a new dataset for TAP, baselines,\nand a model that successfully uses an ILP to enforce the structural constraints\nof the problem.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 22:22:26 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Lamm", "Matthew", ""], ["Chaganty", "Arun Tejasvi", ""], ["Manning", "Christopher D.", ""], ["Jurafsky", "Dan", ""], ["Liang", "Percy", ""]]}, {"id": "1809.02701", "submitter": "Eric Wallace", "authors": "Eric Wallace, Pedro Rodriguez, Shi Feng, Ikuya Yamada, Jordan\n  Boyd-Graber", "title": "Trick Me If You Can: Human-in-the-loop Generation of Adversarial\n  Examples for Question Answering", "comments": "Author final version of article accepted for publication in TACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial evaluation stress tests a model's understanding of natural\nlanguage. While past approaches expose superficial patterns, the resulting\nadversarial examples are limited in complexity and diversity. We propose\nhuman-in-the-loop adversarial generation, where human authors are guided to\nbreak models. We aid the authors with interpretations of model predictions\nthrough an interactive user interface. We apply this generation framework to a\nquestion answering task called Quizbowl, where trivia enthusiasts craft\nadversarial questions. The resulting questions are validated via live\nhuman--computer matches: although the questions appear ordinary to humans, they\nsystematically stump neural and information retrieval models. The adversarial\nquestions cover diverse phenomena from multi-hop reasoning to entity type\ndistractors, exposing open challenges in robust question answering.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 22:39:33 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 19:18:44 GMT"}, {"version": "v3", "created": "Fri, 17 May 2019 16:43:24 GMT"}, {"version": "v4", "created": "Tue, 16 Jul 2019 05:26:13 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Wallace", "Eric", ""], ["Rodriguez", "Pedro", ""], ["Feng", "Shi", ""], ["Yamada", "Ikuya", ""], ["Boyd-Graber", "Jordan", ""]]}, {"id": "1809.02719", "submitter": "Haohan Wang", "authors": "Haohan Wang, Da Sun, Eric P. Xing", "title": "What If We Simply Swap the Two Text Fragments? A Straightforward yet\n  Effective Way to Test the Robustness of Methods to Confounding Signals in\n  Nature Language Inference Tasks", "comments": "8 pages, to appear at AAAI 19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nature language inference (NLI) task is a predictive task of determining the\ninference relationship of a pair of natural language sentences. With the\nincreasing popularity of NLI, many state-of-the-art predictive models have been\nproposed with impressive performances. However, several works have noticed the\nstatistical irregularities in the collected NLI data set that may result in an\nover-estimated performance of these models and proposed remedies. In this\npaper, we further investigate the statistical irregularities, what we refer as\nconfounding factors, of the NLI data sets. With the belief that some NLI labels\nshould preserve under swapping operations, we propose a simple yet effective\nway (swapping the two text fragments) of evaluating the NLI predictive models\nthat naturally mitigate the observed problems. Further, we continue to train\nthe predictive models with our swapping manner and propose to use the deviation\nof the model's evaluation performances under different percentages of training\ntext fragments to be swapped to describe the robustness of a predictive model.\nOur evaluation metrics leads to some interesting understandings of recent\npublished NLI methods. Finally, we also apply the swapping operation on NLI\nmodels to see the effectiveness of this straightforward method in mitigating\nthe confounding factor problems in training generic sentence embeddings for\nother NLP transfer tasks.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 23:59:22 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 01:28:11 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Wang", "Haohan", ""], ["Sun", "Da", ""], ["Xing", "Eric P.", ""]]}, {"id": "1809.02731", "submitter": "Shuai Tang", "authors": "Shuai Tang, Virginia R. de Sa", "title": "Exploiting Invertible Decoders for Unsupervised Sentence Representation\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The encoder-decoder models for unsupervised sentence representation learning\ntend to discard the decoder after being trained on a large unlabelled corpus,\nsince only the encoder is needed to map the input sentence into a vector\nrepresentation. However, parameters learnt in the decoder also contain useful\ninformation about language. In order to utilise the decoder after learning, we\npresent two types of decoding functions whose inverse can be easily derived\nwithout expensive inverse calculation. Therefore, the inverse of the decoding\nfunction serves as another encoder that produces sentence representations. We\nshow that, with careful design of the decoding functions, the model learns good\nsentence representations, and the ensemble of the representations produced from\nthe encoder and the inverse of the decoder demonstrate even better\ngeneralisation ability and solid transferability.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 01:20:45 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 00:35:49 GMT"}, {"version": "v3", "created": "Fri, 31 May 2019 04:53:58 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Tang", "Shuai", ""], ["de Sa", "Virginia R.", ""]]}, {"id": "1809.02735", "submitter": "Jinpeng Wang", "authors": "Feng Nie, Jinpeng Wang, Jin-Ge Yao, Rong Pan, Chin-Yew Lin", "title": "Operations Guided Neural Networks for High Fidelity Data-To-Text\n  Generation", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent neural models for data-to-text generation are mostly based on\ndata-driven end-to-end training over encoder-decoder networks. Even though the\ngenerated texts are mostly fluent and informative, they often generate\ndescriptions that are not consistent with the input structured data. This is a\ncritical issue especially in domains that require inference or calculations\nover raw data. In this paper, we attempt to improve the fidelity of neural\ndata-to-text generation by utilizing pre-executed symbolic operations. We\npropose a framework called Operation-guided Attention-based\nsequence-to-sequence network (OpAtt), with a specifically designed gating\nmechanism as well as a quantization module for operation results to utilize\ninformation from pre-executed operations. Experiments on two sports datasets\nshow our proposed method clearly improves the fidelity of the generated texts\nto the input structured data.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 01:49:03 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Nie", "Feng", ""], ["Wang", "Jinpeng", ""], ["Yao", "Jin-Ge", ""], ["Pan", "Rong", ""], ["Lin", "Chin-Yew", ""]]}, {"id": "1809.02765", "submitter": "Ruixuan Luo", "authors": "Ruixuan Luo", "title": "Exploration on Grounded Word Embedding: Matching Words and Images with\n  Image-Enhanced Skip-Gram Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embedding is designed to represent the semantic meaning of a word with\nlow dimensional vectors. The state-of-the-art methods of learning word\nembeddings (word2vec and GloVe) only use the word co-occurrence information.\nThe learned embeddings are real number vectors, which are obscure to human. In\nthis paper, we propose an Image-Enhanced Skip-Gram Model to learn grounded word\nembeddings by representing the word vectors in the same hyper-plane with image\nvectors. Experiments show that the image vectors and word embeddings learned by\nour model are highly correlated, which indicates that our model is able to\nprovide a vivid image-based explanation to the word embeddings.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 06:43:01 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Luo", "Ruixuan", ""]]}, {"id": "1809.02768", "submitter": "Yifan Gao", "authors": "Yifan Gao, Lidong Bing, Piji Li, Irwin King, Michael R. Lyu", "title": "Generating Distractors for Reading Comprehension Questions from Real\n  Examinations", "comments": "AAAI2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the task of distractor generation for multiple choice reading\ncomprehension questions from examinations. In contrast to all previous works,\nwe do not aim at preparing words or short phrases distractors, instead, we\nendeavor to generate longer and semantic-rich distractors which are closer to\ndistractors in real reading comprehension from examinations. Taking a reading\ncomprehension article, a pair of question and its correct option as input, our\ngoal is to generate several distractors which are somehow related to the\nanswer, consistent with the semantic context of the question and have some\ntrace in the article. We propose a hierarchical encoder-decoder framework with\nstatic and dynamic attention mechanisms to tackle this task. Specifically, the\ndynamic attention can combine sentence-level and word-level attention varying\nat each recurrent time step to generate a more readable sequence. The static\nattention is to modulate the dynamic attention not to focus on question\nirrelevant sentences or sentences which contribute to the correct option. Our\nproposed framework outperforms several strong baselines on the first prepared\ndistractor generation dataset of real reading comprehension questions. For\nhuman evaluation, compared with those distractors generated by baselines, our\ngenerated distractors are more functional to confuse the annotators.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 07:11:15 GMT"}, {"version": "v2", "created": "Tue, 18 Dec 2018 07:04:50 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Gao", "Yifan", ""], ["Bing", "Lidong", ""], ["Li", "Piji", ""], ["King", "Irwin", ""], ["Lyu", "Michael R.", ""]]}, {"id": "1809.02782", "submitter": "Ibrahim Aljarah", "authors": "Mo'ath Alrefai and Hossam Faris and Ibrahim Aljarah", "title": "Sentiment analysis for Arabic language: A brief survey of approaches and\n  techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the emergence of Web 2.0 technology and the expansion of on-line social\nnetworks, current Internet users have the ability to add their reviews, ratings\nand opinions on social media and on commercial and news web sites. Sentiment\nanalysis aims to classify these reviews reviews in an automatic way. In the\nliterature, there are numerous approaches proposed for automatic sentiment\nanalysis for different language contexts. Each language has its own properties\nthat makes the sentiment analysis more challenging. In this regard, this work\npresents a comprehensive survey of existing Arabic sentiment analysis studies,\nand covers the various approaches and techniques proposed in the literature.\nMoreover, we highlight the main difficulties and challenges of Arabic sentiment\nanalysis, and the proposed techniques in literature to overcome these barriers.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 09:47:01 GMT"}, {"version": "v2", "created": "Sat, 15 Sep 2018 13:38:31 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Alrefai", "Mo'ath", ""], ["Faris", "Hossam", ""], ["Aljarah", "Ibrahim", ""]]}, {"id": "1809.02789", "submitter": "Todor Mihaylov", "authors": "Todor Mihaylov, Peter Clark, Tushar Khot, Ashish Sabharwal", "title": "Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book\n  Question Answering", "comments": "Published as conference long paper at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new kind of question answering dataset, OpenBookQA, modeled\nafter open book exams for assessing human understanding of a subject. The open\nbook that comes with our questions is a set of 1329 elementary level science\nfacts. Roughly 6000 questions probe an understanding of these facts and their\napplication to novel situations. This requires combining an open book fact\n(e.g., metals conduct electricity) with broad common knowledge (e.g., a suit of\narmor is made of metal) obtained from other sources. While existing QA datasets\nover documents or knowledge bases, being generally self-contained, focus on\nlinguistic understanding, OpenBookQA probes a deeper understanding of both the\ntopic---in the context of common knowledge---and the language it is expressed\nin. Human performance on OpenBookQA is close to 92%, but many state-of-the-art\npre-trained QA methods perform surprisingly poorly, worse than several simple\nneural baselines we develop. Our oracle experiments designed to circumvent the\nknowledge retrieval bottleneck demonstrate the value of both the open book and\nadditional facts. We leave it as a challenge to solve the retrieval problem in\nthis multi-hop setting and to close the large gap to human performance.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 11:47:16 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Mihaylov", "Todor", ""], ["Clark", "Peter", ""], ["Khot", "Tushar", ""], ["Sabharwal", "Ashish", ""]]}, {"id": "1809.02790", "submitter": "Chao Wang", "authors": "Chao Wang and Hui Jiang", "title": "The Lower The Simpler: Simplifying Hierarchical Recurrent Models", "comments": "NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To improve the training efficiency of hierarchical recurrent models without\ncompromising their performance, we propose a strategy named as `the lower the\nsimpler', which is to simplify the baseline models by making the lower layers\nsimpler than the upper layers. We carry out this strategy to simplify two\ntypical hierarchical recurrent models, namely Hierarchical Recurrent\nEncoder-Decoder (HRED) and R-NET, whose basic building block is GRU.\nSpecifically, we propose Scalar Gated Unit (SGU), which is a simplified variant\nof GRU, and use it to replace the GRUs at the middle layers of HRED and R-NET.\nBesides, we also use Fixed-size Ordinally-Forgetting Encoding (FOFE), which is\nan efficient encoding method without any trainable parameter, to replace the\nGRUs at the bottom layers of HRED and R-NET. The experimental results show that\nthe simplified HRED and the simplified R-NET contain significantly less\ntrainable parameters, consume significantly less training time, and achieve\nslightly better performance than their baseline models.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 11:54:09 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 16:14:36 GMT"}, {"version": "v3", "created": "Wed, 15 May 2019 02:01:14 GMT"}, {"version": "v4", "created": "Mon, 20 May 2019 19:26:07 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Wang", "Chao", ""], ["Jiang", "Hui", ""]]}, {"id": "1809.02794", "submitter": "Zhuosheng Zhang", "authors": "Zhuosheng Zhang, Yuwei Wu, Zuchao Li, Hai Zhao", "title": "Explicit Contextual Semantics for Text Comprehension", "comments": "Proceedings of the 33nd Pacific Asia Conference on Language,\n  Information and Computation (PACLIC 33)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Who did what to whom is a major focus in natural language understanding,\nwhich is right the aim of semantic role labeling (SRL) task. Despite of sharing\na lot of processing characteristics and even task purpose, it is surprisingly\nthat jointly considering these two related tasks was never formally reported in\nprevious work. Thus this paper makes the first attempt to let SRL enhance text\ncomprehension and inference through specifying verbal predicates and their\ncorresponding semantic roles. In terms of deep learning models, our embeddings\nare enhanced by explicit contextual semantic role labels for more fine-grained\nsemantics. We show that the salient labels can be conveniently added to\nexisting models and significantly improve deep learning models in challenging\ntext comprehension tasks. Extensive experiments on benchmark machine reading\ncomprehension and inference datasets verify that the proposed semantic learning\nhelps our system reach new state-of-the-art over strong baselines which have\nbeen enhanced by well pretrained language models from the latest progress.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 12:34:59 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 07:41:09 GMT"}, {"version": "v3", "created": "Sun, 17 Nov 2019 05:40:48 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Zhang", "Zhuosheng", ""], ["Wu", "Yuwei", ""], ["Li", "Zuchao", ""], ["Zhao", "Hai", ""]]}, {"id": "1809.02796", "submitter": "Zhuosheng Zhang", "authors": "Zhuosheng Zhang, Shexia He, Zuchao Li, Hai Zhao", "title": "Attentive Semantic Role Labeling with Boundary Indicator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of semantic role labeling (SRL) is to discover the\npredicate-argument structure of a sentence, which plays a critical role in deep\nprocessing of natural language. This paper introduces simple yet effective\nauxiliary tags for dependency-based SRL to enhance a syntax-agnostic model with\nmulti-hop self-attention. Our syntax-agnostic model achieves competitive\nperformance with state-of-the-art models on the CoNLL-2009 benchmarks both for\nEnglish and Chinese.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 12:49:18 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Zhang", "Zhuosheng", ""], ["He", "Shexia", ""], ["Li", "Zuchao", ""], ["Zhao", "Hai", ""]]}, {"id": "1809.02805", "submitter": "Jialin Wu", "authors": "Jialin Wu and Raymond J. Mooney", "title": "Faithful Multimodal Explanation for Visual Question Answering", "comments": "In ACL 2019 BlackboxNLP workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI systems' ability to explain their reasoning is critical to their utility\nand trustworthiness. Deep neural networks have enabled significant progress on\nmany challenging problems such as visual question answering (VQA). However,\nmost of them are opaque black boxes with limited explanatory capability. This\npaper presents a novel approach to developing a high-performing VQA system that\ncan elucidate its answers with integrated textual and visual explanations that\nfaithfully reflect important aspects of its underlying reasoning while\ncapturing the style of comprehensible human explanations. Extensive\nexperimental evaluation demonstrates the advantages of this approach compared\nto competing methods with both automatic evaluation metrics and human\nevaluation metrics.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 14:14:03 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 19:54:15 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Wu", "Jialin", ""], ["Mooney", "Raymond J.", ""]]}, {"id": "1809.02823", "submitter": "Yingjie Hu", "authors": "Yingjie Hu, Xinyue Ye, Shih-Lung Shaw", "title": "Extracting and Analyzing Semantic Relatedness between Cities Using News\n  Articles", "comments": "International Journal of Geographical Information Science, 2017", "journal-ref": null, "doi": "10.1080/13658816.2017.1367797", "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  News articles capture a variety of topics about our society. They reflect not\nonly the socioeconomic activities that happened in our physical world, but also\nsome of the cultures, human interests, and public concerns that exist only in\nthe perceptions of people. Cities are frequently mentioned in news articles,\nand two or more cities may co-occur in the same article. Such co-occurrence\noften suggests certain relatedness between the mentioned cities, and the\nrelatedness may be under different topics depending on the contents of the news\narticles. We consider the relatedness under different topics as semantic\nrelatedness. By reading news articles, one can grasp the general semantic\nrelatedness between cities, yet, given hundreds of thousands of news articles,\nit is very difficult, if not impossible, for anyone to manually read them. This\npaper proposes a computational framework which can \"read\" a large number of\nnews articles and extract the semantic relatedness between cities. This\nframework is based on a natural language processing model and employs a machine\nlearning process to identify the main topics of news articles. We describe the\noverall structure of this framework and its individual modules, and then apply\nit to an experimental dataset with more than 500,000 news articles covering the\ntop 100 U.S. cities spanning a 10-year period. We perform exploratory\nvisualization of the extracted semantic relatedness under different topics and\nover multiple years. We also analyze the impact of geographic distance on\nsemantic relatedness and find varied distance decay effects. The proposed\nframework can be used to support large-scale content analysis in city network\nresearch.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 15:29:47 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Hu", "Yingjie", ""], ["Ye", "Xinyue", ""], ["Shaw", "Shih-Lung", ""]]}, {"id": "1809.02836", "submitter": "Yiding Hao", "authors": "Yiding Hao, William Merrill, Dana Angluin, Robert Frank, Noah Amsel,\n  Andrew Benz, and Simon Mendelsohn", "title": "Context-Free Transductions with Neural Stacks", "comments": "To appear in the proceedings of the Analyzing and Interpreting Neural\n  Networks for NLP workshop at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyzes the behavior of stack-augmented recurrent neural network\n(RNN) models. Due to the architectural similarity between stack RNNs and\npushdown transducers, we train stack RNN models on a number of tasks, including\nstring reversal, context-free language modelling, and cumulative XOR\nevaluation. Examining the behavior of our networks, we show that\nstack-augmented RNNs can discover intuitive stack-based strategies for solving\nour tasks. However, stack RNNs are more difficult to train than classical\narchitectures such as LSTMs. Rather than employ stack-based strategies, more\ncomplex networks often find approximate solutions by using the stack as\nunstructured memory.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 17:04:53 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Hao", "Yiding", ""], ["Merrill", "William", ""], ["Angluin", "Dana", ""], ["Frank", "Robert", ""], ["Amsel", "Noah", ""], ["Benz", "Andrew", ""], ["Mendelsohn", "Simon", ""]]}, {"id": "1809.02847", "submitter": "Eric Wallace", "authors": "Eric Wallace, Shi Feng, Jordan Boyd-Graber", "title": "Interpreting Neural Networks With Nearest Neighbors", "comments": "EMNLP 2018 BlackboxNLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local model interpretation methods explain individual predictions by\nassigning an importance value to each input feature. This value is often\ndetermined by measuring the change in confidence when a feature is removed.\nHowever, the confidence of neural networks is not a robust measure of model\nuncertainty. This issue makes reliably judging the importance of the input\nfeatures difficult. We address this by changing the test-time behavior of\nneural networks using Deep k-Nearest Neighbors. Without harming text\nclassification accuracy, this algorithm provides a more robust uncertainty\nmetric which we use to generate feature importance values. The resulting\ninterpretations better align with human perception than baseline methods.\nFinally, we use our interpretation method to analyze model predictions on\ndataset annotation artifacts.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 18:03:56 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 13:05:39 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Wallace", "Eric", ""], ["Feng", "Shi", ""], ["Boyd-Graber", "Jordan", ""]]}, {"id": "1809.02922", "submitter": "Dorottya Demszky", "authors": "Dorottya Demszky, Kelvin Guu, Percy Liang", "title": "Transforming Question Answering Datasets Into Natural Language Inference\n  Datasets", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing datasets for natural language inference (NLI) have propelled\nresearch on language understanding. We propose a new method for automatically\nderiving NLI datasets from the growing abundance of large-scale question\nanswering datasets. Our approach hinges on learning a sentence transformation\nmodel which converts question-answer pairs into their declarative forms.\nDespite being primarily trained on a single QA dataset, we show that it can be\nsuccessfully applied to a variety of other QA resources. Using this system, we\nautomatically derive a new freely available dataset of over 500k NLI examples\n(QA-NLI), and show that it exhibits a wide range of inference phenomena rarely\nseen in previous NLI datasets.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 05:03:34 GMT"}, {"version": "v2", "created": "Tue, 11 Sep 2018 00:38:25 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Demszky", "Dorottya", ""], ["Guu", "Kelvin", ""], ["Liang", "Percy", ""]]}, {"id": "1809.02992", "submitter": "Wen Zhang", "authors": "Wen Zhang, Liang Huang, Yang Feng, Lei Shen and Qun Liu", "title": "Speeding Up Neural Machine Translation Decoding by Cube Pruning", "comments": "11pages, 11 figures, EMNLP-2018 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although neural machine translation has achieved promising results, it\nsuffers from slow translation speed. The direct consequence is that a trade-off\nhas to be made between translation quality and speed, thus its performance can\nnot come into full play. We apply cube pruning, a popular technique to speed up\ndynamic programming, into neural machine translation to speed up the\ntranslation. To construct the equivalence class, similar target hidden states\nare combined, leading to less RNN expansion operations on the target side and\nless \\$\\mathrm{softmax}\\$ operations over the large target vocabulary. The\nexperiments show that, at the same or even better translation quality, our\nmethod can translate faster compared with naive beam search by \\$3.3\\times\\$ on\nGPUs and \\$3.5\\times\\$ on CPUs.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 15:45:25 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Zhang", "Wen", ""], ["Huang", "Liang", ""], ["Feng", "Yang", ""], ["Shen", "Lei", ""], ["Liu", "Qun", ""]]}, {"id": "1809.03015", "submitter": "Lena Reed", "authors": "Lena Reed, Shereen Oraby and Marilyn Walker", "title": "Can Neural Generators for Dialogue Learn Sentence Planning and Discourse\n  Structuring?", "comments": "12 pages, 12 tables, 3 figures, iNLG 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Responses in task-oriented dialogue systems often realize multiple\npropositions whose ultimate form depends on the use of sentence planning and\ndiscourse structuring operations. For example a recommendation may consist of\nan explicitly evaluative utterance e.g. Chanpen Thai is the best option, along\nwith content related by the justification discourse relation, e.g. It has great\nfood and service, that combines multiple propositions into a single phrase.\nWhile neural generation methods integrate sentence planning and surface\nrealization in one end-to-end learning framework, previous work has not shown\nthat neural generators can: (1) perform common sentence planning and discourse\nstructuring operations; (2) make decisions as to whether to realize content in\na single sentence or over multiple sentences; (3) generalize sentence planning\nand discourse relation operations beyond what was seen in training. We\nsystematically create large training corpora that exhibit particular sentence\nplanning operations and then test neural models to see what they learn. We\ncompare models without explicit latent variables for sentence planning with\nones that provide explicit supervision during training. We show that only the\nmodels with additional supervision can reproduce sentence planing and discourse\noperations and generalize to situations unseen in training.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 18:01:33 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 20:43:00 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Reed", "Lena", ""], ["Oraby", "Shereen", ""], ["Walker", "Marilyn", ""]]}, {"id": "1809.03044", "submitter": "Alexander Kuhnle", "authors": "Alexander Kuhnle, Huiyuan Xie, Ann Copestake", "title": "How clever is the FiLM model, and how clever can it be?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The FiLM model achieves close-to-perfect performance on the diagnostic CLEVR\ndataset and is distinguished from other such models by having a comparatively\nsimple and easily transferable architecture. In this paper, we investigate in\nmore detail the ability of FiLM to learn various linguistic constructions. Our\nmain results show that (a) FiLM is not able to learn relational statements\nstraight away except for very simple instances, (b) training on a broader set\nof instances as well as pretraining on simpler instance types can help\nalleviate these learning difficulties, (c) mixing is less robust than\npretraining and very sensitive to the compositional structure of the dataset.\nOverall, our results suggest that the approach of big all-encompassing datasets\nand the paradigm of \"the effectiveness of data\" may have fundamental\nlimitations.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 21:08:57 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Kuhnle", "Alexander", ""], ["Xie", "Huiyuan", ""], ["Copestake", "Ann", ""]]}, {"id": "1809.03051", "submitter": "Reza Ghaeini", "authors": "Reza Ghaeini, Xiaoli Z. Fern, Prasad Tadepalli", "title": "Attentional Multi-Reading Sarcasm Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing sarcasm often requires a deep understanding of multiple sources\nof information, including the utterance, the conversational context, and real\nworld facts. Most of the current sarcasm detection systems consider only the\nutterance in isolation. There are some limited attempts toward taking into\naccount the conversational context. In this paper, we propose an interpretable\nend-to-end model that combines information from both the utterance and the\nconversational context to detect sarcasm, and demonstrate its effectiveness\nthrough empirical evaluations. We also study the behavior of the proposed model\nto provide explanations for the model's decisions. Importantly, our model is\ncapable of determining the impact of utterance and conversational context on\nthe model's decisions. Finally, we provide an ablation study to illustrate the\nimpact of different components of the proposed model.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 22:33:20 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Ghaeini", "Reza", ""], ["Fern", "Xiaoli Z.", ""], ["Tadepalli", "Prasad", ""]]}, {"id": "1809.03056", "submitter": "Shiva Taslimipoor", "authors": "Shiva Taslimipoor and Omid Rohanian", "title": "SHOMA at Parseme Shared Task on Automatic Identification of VMWEs:\n  Neural Multiword Expression Tagging with High Generalisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a language-independent deep learning architecture adapted\nto the task of multiword expression (MWE) identification. We employ a neural\narchitecture comprising of convolutional and recurrent layers with the addition\nof an optional CRF layer at the top. This system participated in the open track\nof the Parseme shared task on automatic identification of verbal MWEs due to\nthe use of pre-trained wikipedia word embeddings. It outperformed all\nparticipating systems in both open and closed tracks with the overall\nmacro-average MWE-based F1 score of 58.09 averaged among all languages. A\nparticular strength of the system is its superior performance on unseen data\nentries.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 22:46:51 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Taslimipoor", "Shiva", ""], ["Rohanian", "Omid", ""]]}, {"id": "1809.03068", "submitter": "Christopher Potts", "authors": "Christopher Potts", "title": "A case for deep learning in semantics", "comments": "Commentary on Pater 2018, 'Generative linguistics and neural networks\n  at 60: foundation, friction, and fusion', to appear in Language", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pater's target article builds a persuasive case for establishing stronger\nties between theoretical linguistics and connectionism (deep learning). This\ncommentary extends his arguments to semantics, focusing in particular on issues\nof learning, compositionality, and lexical meaning.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 00:34:34 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Potts", "Christopher", ""]]}, {"id": "1809.03112", "submitter": "Lifeng Jin", "authors": "Lifeng Jin, Finale Doshi-Velez, Timothy Miller, William Schuler, Lane\n  Schwartz", "title": "Depth-bounding is effective: Improvements and evaluation of unsupervised\n  PCFG induction", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There have been several recent attempts to improve the accuracy of grammar\ninduction systems by bounding the recursive complexity of the induction model\n(Ponvert et al., 2011; Noji and Johnson, 2016; Shain et al., 2016; Jin et al.,\n2018). Modern depth-bounded grammar inducers have been shown to be more\naccurate than early unbounded PCFG inducers, but this technique has never been\ncompared against unbounded induction within the same system, in part because\nmost previous depth-bounding models are built around sequence models, the\ncomplexity of which grows exponentially with the maximum allowed depth. The\npresent work instead applies depth bounds within a chart-based Bayesian PCFG\ninducer (Johnson et al., 2007b), where bounding can be switched on and off, and\nthen samples trees with and without bounding. Results show that depth-bounding\nis indeed significantly effective in limiting the search space of the inducer\nand thereby increasing the accuracy of the resulting parsing model. Moreover,\nparsing results on English, Chinese and German show that this bounded model\nwith a new inference technique is able to produce parse trees more accurately\nthan or competitively with state-of-the-art constituency-based grammar\ninduction models.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 03:02:46 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Jin", "Lifeng", ""], ["Doshi-Velez", "Finale", ""], ["Miller", "Timothy", ""], ["Schuler", "William", ""], ["Schwartz", "Lane", ""]]}, {"id": "1809.03118", "submitter": "Pengcheng Yang", "authors": "Pengcheng Yang and Shuming Ma and Yi Zhang and Junyang Lin and Qi Su\n  and Xu Sun", "title": "A Deep Reinforced Sequence-to-Set Model for Multi-Label Text\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label text classification (MLTC) aims to assign multiple labels to each\nsample in the dataset. The labels usually have internal correlations. However,\ntraditional methods tend to ignore the correlations between labels. In order to\ncapture the correlations between labels, the sequence-to-sequence (Seq2Seq)\nmodel views the MLTC task as a sequence generation problem, which achieves\nexcellent performance on this task. However, the Seq2Seq model is not suitable\nfor the MLTC task in essence. The reason is that it requires humans to\npredefine the order of the output labels, while some of the output labels in\nthe MLTC task are essentially an unordered set rather than an ordered sequence.\nThis conflicts with the strict requirement of the Seq2Seq model for the label\norder. In this paper, we propose a novel sequence-to-set framework utilizing\ndeep reinforcement learning, which not only captures the correlations between\nlabels, but also reduces the dependence on the label order. Extensive\nexperimental results show that our proposed method outperforms the competitive\nbaselines by a large margin.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 03:33:48 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Yang", "Pengcheng", ""], ["Ma", "Shuming", ""], ["Zhang", "Yi", ""], ["Lin", "Junyang", ""], ["Su", "Qi", ""], ["Sun", "Xu", ""]]}, {"id": "1809.03132", "submitter": "Chenze Shao", "authors": "Chenze Shao, Yang Feng, Xilin Chen", "title": "Greedy Search with Probabilistic N-gram Matching for Neural Machine\n  Translation", "comments": "7 pages, accepted by emnlp 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT) models are usually trained with the\nword-level loss using the teacher forcing algorithm, which not only evaluates\nthe translation improperly but also suffers from exposure bias. Sequence-level\ntraining under the reinforcement framework can mitigate the problems of the\nword-level loss, but its performance is unstable due to the high variance of\nthe gradient estimation. On these grounds, we present a method with a\ndifferentiable sequence-level training objective based on probabilistic n-gram\nmatching which can avoid the reinforcement framework. In addition, this method\nperforms greedy search in the training which uses the predicted words as\ncontext just as at inference to alleviate the problem of exposure bias.\nExperiment results on the NIST Chinese-to-English translation tasks show that\nour method significantly outperforms the reinforcement-based algorithms and\nachieves an improvement of 1.5 BLEU points on average over a strong baseline\nsystem.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 04:41:44 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Shao", "Chenze", ""], ["Feng", "Yang", ""], ["Chen", "Xilin", ""]]}, {"id": "1809.03169", "submitter": "Marco Del Tredici", "authors": "Marco Del Tredici, Raquel Fern\\'andez, Gemma Boleda", "title": "Short-Term Meaning Shift: A Distributional Exploration", "comments": "Accepted at NAACL2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present the first exploration of meaning shift over short periods of time\nin online communities using distributional representations. We create a small\nannotated dataset and use it to assess the performance of a standard model for\nmeaning shift detection on short-term meaning shift. We find that the model has\nproblems distinguishing meaning shift from referential phenomena, and propose a\nmeasure of contextual variability to remedy this.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 08:05:56 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2019 08:09:19 GMT"}, {"version": "v3", "created": "Tue, 30 Apr 2019 12:10:57 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Del Tredici", "Marco", ""], ["Fern\u00e1ndez", "Raquel", ""], ["Boleda", "Gemma", ""]]}, {"id": "1809.03182", "submitter": "Ngoc Quan Pham", "authors": "Ngoc-Quan Pham and Jan Niehues and Alex Waibel", "title": "Towards one-shot learning for rare-word translation with external\n  experts", "comments": "2nd Workshop on Neural Machine Translation and Generation, ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT) has significantly improved the quality of\nautomatic translation models. One of the main challenges in current systems is\nthe translation of rare words. We present a generic approach to address this\nweakness by having external models annotate the training data as Experts, and\ncontrol the model-expert interaction with a pointer network and reinforcement\nlearning. Our experiments using phrase-based models to simulate Experts to\ncomplement neural machine translation models show that the model can be trained\nto copy the annotations into the output consistently. We demonstrate the\nbenefit of our proposed framework in outof-domain translation scenarios with\nonly lexical resources, improving more than 1.0 BLEU point in both translation\ndirections English to Spanish and German to English\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 08:40:04 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Pham", "Ngoc-Quan", ""], ["Niehues", "Jan", ""], ["Waibel", "Alex", ""]]}, {"id": "1809.03194", "submitter": "Agustinus Kristiadi", "authors": "Debanjan Chaudhuri, Agustinus Kristiadi, Jens Lehmann, and Asja\n  Fischer", "title": "Improving Response Selection in Multi-Turn Dialogue Systems by\n  Incorporating Domain Knowledge", "comments": "Published as conference paper at CoNLL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building systems that can communicate with humans is a core problem in\nArtificial Intelligence. This work proposes a novel neural network architecture\nfor response selection in an end-to-end multi-turn conversational dialogue\nsetting. The architecture applies context level attention and incorporates\nadditional external knowledge provided by descriptions of domain-specific\nwords. It uses a bi-directional Gated Recurrent Unit (GRU) for encoding context\nand responses and learns to attend over the context words given the latent\nresponse representation and vice versa.In addition, it incorporates external\ndomain specific information using another GRU for encoding the domain keyword\ndescriptions. This allows better representation of domain-specific keywords in\nresponses and hence improves the overall performance. Experimental results show\nthat our model outperforms all other state-of-the-art methods for response\nselection in multi-turn conversations.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 09:10:25 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2018 17:34:42 GMT"}, {"version": "v3", "created": "Mon, 5 Nov 2018 10:11:29 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Chaudhuri", "Debanjan", ""], ["Kristiadi", "Agustinus", ""], ["Lehmann", "Jens", ""], ["Fischer", "Asja", ""]]}, {"id": "1809.03195", "submitter": "Ziwei Bai", "authors": "Ziwei Bai and Bo Yu and Bowen Wu and Zhuoran Wang and Baoxun Wang", "title": "Learning to Generate Structured Queries from Natural Language with\n  Indirect Supervision", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating structured query language (SQL) from natural language is an\nemerging research topic. This paper presents a new learning paradigm from\nindirect supervision of the answers to natural language questions, instead of\nSQL queries. This paradigm facilitates the acquisition of training data due to\nthe abundant resources of question-answer pairs for various domains in the\nInternet, and expels the difficult SQL annotation job. An end-to-end neural\nmodel integrating with reinforcement learning is proposed to learn SQL\ngeneration policy within the answer-driven learning paradigm. The model is\nevaluated on datasets of different domains, including movie and academic\npublication. Experimental results show that our model outperforms the baseline\nmodels.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 09:10:49 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Bai", "Ziwei", ""], ["Yu", "Bo", ""], ["Wu", "Bowen", ""], ["Wang", "Zhuoran", ""], ["Wang", "Baoxun", ""]]}, {"id": "1809.03202", "submitter": "Alberto Garcia-Duran", "authors": "Alberto Garc\\'ia-Dur\\'an, Sebastijan Duman\\v{c}i\\'c, Mathias Niepert", "title": "Learning Sequence Encoders for Temporal Knowledge Graph Completion", "comments": "EMNLP'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on link prediction in knowledge graphs has mainly focused on static\nmulti-relational data. In this work we consider temporal knowledge graphs where\nrelations between entities may only hold for a time interval or a specific\npoint in time. In line with previous work on static knowledge graphs, we\npropose to address this problem by learning latent entity and relation type\nrepresentations. To incorporate temporal information, we utilize recurrent\nneural networks to learn time-aware representations of relation types which can\nbe used in conjunction with existing latent factorization methods. The proposed\napproach is shown to be robust to common challenges in real-world KGs: the\nsparsity and heterogeneity of temporal expressions. Experiments show the\nbenefits of our approach on four temporal KGs. The data sets are available\nunder a permissive BSD-3 license 1.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 09:17:04 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Garc\u00eda-Dur\u00e1n", "Alberto", ""], ["Duman\u010di\u0107", "Sebastijan", ""], ["Niepert", "Mathias", ""]]}, {"id": "1809.03211", "submitter": "Hrant Khachatrian", "authors": "Gor Arakelyan, Karen Hambardzumyan, Hrant Khachatrian", "title": "Towards JointUD: Part-of-speech Tagging and Lemmatization using\n  Recurrent Neural Networks", "comments": "System description paper of our system for the CoNLL 2018 shared task\n  on Universal Dependency parsing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes our submission to CoNLL 2018 UD Shared Task. We have\nextended an LSTM-based neural network designed for sequence tagging to\nadditionally generate character-level sequences. The network was jointly\ntrained to produce lemmas, part-of-speech tags and morphological features.\nSentence segmentation, tokenization and dependency parsing were handled by\nUDPipe 1.2 baseline. The results demonstrate the viability of the proposed\nmultitask architecture, although its performance still remains far from\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 09:31:24 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Arakelyan", "Gor", ""], ["Hambardzumyan", "Karen", ""], ["Khachatrian", "Hrant", ""]]}, {"id": "1809.03275", "submitter": "Akari Asai Ms", "authors": "Akari Asai, Akiko Eriguchi, Kazuma Hashimoto, Yoshimasa Tsuruoka", "title": "Multilingual Extractive Reading Comprehension by Runtime Machine\n  Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite recent work in Reading Comprehension (RC), progress has been mostly\nlimited to English due to the lack of large-scale datasets in other languages.\nIn this work, we introduce the first RC system for languages without RC\ntraining data. Given a target language without RC training data and a pivot\nlanguage with RC training data (e.g. English), our method leverages existing RC\nresources in the pivot language by combining a competitive RC model in the\npivot language with an attentive Neural Machine Translation (NMT) model. We\nfirst translate the data from the target to the pivot language, and then obtain\nan answer using the RC model in the pivot language. Finally, we recover the\ncorresponding answer in the original language using soft-alignment attention\nscores from the NMT model. We create evaluation sets of RC data in two\nnon-English languages, namely Japanese and French, to evaluate our method.\nExperimental results on these datasets show that our method significantly\noutperforms a back-translation baseline of a state-of-the-art product-level\nmachine translation system.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 12:41:21 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2018 21:41:06 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Asai", "Akari", ""], ["Eriguchi", "Akiko", ""], ["Hashimoto", "Kazuma", ""], ["Tsuruoka", "Yoshimasa", ""]]}, {"id": "1809.03348", "submitter": "Shang-Chi Tsai", "authors": "Ting-Yun Chang, Ta-Chung Chi, Shang-Chi Tsai, Yun-Nung Chen", "title": "xSense: Learning Sense-Separated Sparse Representations and Textual\n  Definitions for Explainable Word Sense Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the success achieved on various natural language processing tasks,\nword embeddings are difficult to interpret due to the dense vector\nrepresentations. This paper focuses on interpreting the embeddings for various\naspects, including sense separation in the vector dimensions and definition\ngeneration. Specifically, given a context together with a target word, our\nalgorithm first projects the target word embedding to a high-dimensional sparse\nvector and picks the specific dimensions that can best explain the semantic\nmeaning of the target word by the encoded contextual information, where the\nsense of the target word can be indirectly inferred. Finally, our algorithm\napplies an RNN to generate the textual definition of the target word in the\nhuman readable form, which enables direct interpretation of the corresponding\nword embedding. This paper also introduces a large and high-quality\ncontext-definition dataset that consists of sense definitions together with\nmultiple example sentences per polysemous word, which is a valuable resource\nfor definition modeling and word sense disambiguation. The conducted\nexperiments show the superior performance in BLEU score and the human\nevaluation test.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 14:27:08 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Chang", "Ting-Yun", ""], ["Chi", "Ta-Chung", ""], ["Tsai", "Shang-Chi", ""], ["Chen", "Yun-Nung", ""]]}, {"id": "1809.03391", "submitter": "Kemal Kurniawan", "authors": "Kemal Kurniawan and Alham Fikri Aji", "title": "Toward a Standardized and More Accurate Indonesian Part-of-Speech\n  Tagging", "comments": "Accepted in IALP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work in Indonesian part-of-speech (POS) tagging are hard to compare\nas they are not evaluated on a common dataset. Furthermore, in spite of the\nsuccess of neural network models for English POS tagging, they are rarely\nexplored for Indonesian. In this paper, we explored various techniques for\nIndonesian POS tagging, including rule-based, CRF, and neural network-based\nmodels. We evaluated our models on the IDN Tagged Corpus. A new\nstate-of-the-art of 97.47 F1 score is achieved with a recurrent neural network.\nTo provide a standard for future work, we release the dataset split that we\nused publicly.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 15:23:48 GMT"}, {"version": "v2", "created": "Fri, 21 Sep 2018 03:57:35 GMT"}, {"version": "v3", "created": "Tue, 26 Feb 2019 06:36:26 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Kurniawan", "Kemal", ""], ["Aji", "Alham Fikri", ""]]}, {"id": "1809.03401", "submitter": "Koki Washio", "authors": "Koki Washio and Tsuneaki Kato", "title": "Neural Latent Relational Analysis to Capture Lexical Semantic Relations\n  in a Vector Space", "comments": "7 pages, accepted at EMNLP2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capturing the semantic relations of words in a vector space contributes to\nmany natural language processing tasks. One promising approach exploits\nlexico-syntactic patterns as features of word pairs. In this paper, we propose\na novel model of this pattern-based approach, neural latent relational analysis\n(NLRA). NLRA can generalize co-occurrences of word pairs and lexico-syntactic\npatterns, and obtain embeddings of the word pairs that do not co-occur. This\novercomes the critical data sparseness problem encountered in previous\npattern-based models. Our experimental results on measuring relational\nsimilarity demonstrate that NLRA outperforms the previous pattern-based models.\nIn addition, when combined with a vector offset model, NLRA achieves a\nperformance comparable to that of the state-of-the-art model that exploits\nadditional semantic relational data.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 15:37:30 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Washio", "Koki", ""], ["Kato", "Tsuneaki", ""]]}, {"id": "1809.03408", "submitter": "Ravi Shekhar", "authors": "Ravi Shekhar, Aashish Venkatesh, Tim Baumg\\\"artner, Elia Bruni,\n  Barbara Plank, Raffaella Bernardi and Raquel Fern\\'andez", "title": "Beyond task success: A closer look at jointly learning to see, ask, and\n  GuessWhat", "comments": "Accepted to NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose a grounded dialogue state encoder which addresses a foundational\nissue on how to integrate visual grounding with dialogue system components. As\na test-bed, we focus on the GuessWhat?! game, a two-player game where the goal\nis to identify an object in a complex visual scene by asking a sequence of\nyes/no questions. Our visually-grounded encoder leverages synergies between\nguessing and asking questions, as it is trained jointly using multi-task\nlearning. We further enrich our model via a cooperative learning regime. We\nshow that the introduction of both the joint architecture and cooperative\nlearning lead to accuracy improvements over the baseline system. We compare our\napproach to an alternative system which extends the baseline with reinforcement\nlearning. Our in-depth analysis shows that the linguistic skills of the two\nmodels differ dramatically, despite approaching comparable performance levels.\nThis points at the importance of analyzing the linguistic output of competing\nsystems beyond numeric comparison solely based on task success.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 15:46:58 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2019 08:01:14 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Shekhar", "Ravi", ""], ["Venkatesh", "Aashish", ""], ["Baumg\u00e4rtner", "Tim", ""], ["Bruni", "Elia", ""], ["Plank", "Barbara", ""], ["Bernardi", "Raffaella", ""], ["Fern\u00e1ndez", "Raquel", ""]]}, {"id": "1809.03411", "submitter": "Koki Washio", "authors": "Koki Washio and Tsuneaki Kato", "title": "Filling Missing Paths: Modeling Co-occurrences of Word Pairs and\n  Dependency Paths for Recognizing Lexical Semantic Relations", "comments": "11 pages, NAACL2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing lexical semantic relations between word pairs is an important\ntask for many applications of natural language processing. One of the\nmainstream approaches to this task is to exploit the lexico-syntactic paths\nconnecting two target words, which reflect the semantic relations of word\npairs. However, this method requires that the considered words co-occur in a\nsentence. This requirement is hardly satisfied because of Zipf's law, which\nstates that most content words occur very rarely. In this paper, we propose\nnovel methods with a neural model of $P(path|w_1, w_2)$ to solve this problem.\nOur proposed model of $P(path|w_1, w_2)$ can be learned in an unsupervised\nmanner and can generalize the co-occurrences of word pairs and dependency\npaths. This model can be used to augment the path data of word pairs that do\nnot co-occur in the corpus, and extract features capturing relational\ninformation from word pairs. Our experimental results demonstrate that our\nmethods improve on previous neural approaches based on dependency paths and\nsuccessfully solve the focused problem.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 15:47:37 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Washio", "Koki", ""], ["Kato", "Tsuneaki", ""]]}, {"id": "1809.03416", "submitter": "Nisansa de Silva", "authors": "Gathika Ratnayaka, Thejan Rupasinghe, Nisansa de Silva, Menuka\n  Warushavithana, Viraj Gamage, Amal Shehan Perera", "title": "Identifying Relationships Among Sentences in Court Case Transcripts\n  Using Discourse Relations", "comments": "Conference: 2018 International Conference on Advances in ICT for\n  Emerging Regions (ICTer)", "journal-ref": null, "doi": "10.1109/ICTER.2018.8615485", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Case Law has a significant impact on the proceedings of legal cases.\nTherefore, the information that can be obtained from previous court cases is\nvaluable to lawyers and other legal officials when performing their duties.\nThis paper describes a methodology of applying discourse relations between\nsentences when processing text documents related to the legal domain. In this\nstudy, we developed a mechanism to classify the relationships that can be\nobserved among sentences in transcripts of United States court cases. First, we\ndefined relationship types that can be observed between sentences in court case\ntranscripts. Then we classified pairs of sentences according to the\nrelationship type by combining a machine learning model and a rule-based\napproach. The results obtained through our system were evaluated using human\njudges. To the best of our knowledge, this is the first study where discourse\nrelationships between sentences have been used to determine relationships among\nsentences in legal court case transcripts.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 15:55:15 GMT"}, {"version": "v2", "created": "Sat, 15 Sep 2018 02:36:07 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Ratnayaka", "Gathika", ""], ["Rupasinghe", "Thejan", ""], ["de Silva", "Nisansa", ""], ["Warushavithana", "Menuka", ""], ["Gamage", "Viraj", ""], ["Perera", "Amal Shehan", ""]]}, {"id": "1809.03449", "submitter": "Chao Wang", "authors": "Chao Wang and Hui Jiang", "title": "Explicit Utilization of General Knowledge in Machine Reading\n  Comprehension", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To bridge the gap between Machine Reading Comprehension (MRC) models and\nhuman beings, which is mainly reflected in the hunger for data and the\nrobustness to noise, in this paper, we explore how to integrate the neural\nnetworks of MRC models with the general knowledge of human beings. On the one\nhand, we propose a data enrichment method, which uses WordNet to extract\ninter-word semantic connections as general knowledge from each given\npassage-question pair. On the other hand, we propose an end-to-end MRC model\nnamed as Knowledge Aided Reader (KAR), which explicitly uses the above\nextracted general knowledge to assist its attention mechanisms. Based on the\ndata enrichment method, KAR is comparable in performance with the\nstate-of-the-art MRC models, and significantly more robust to noise than them.\nWhen only a subset (20%-80%) of the training examples are available, KAR\noutperforms the state-of-the-art MRC models by a large margin, and is still\nreasonably robust to noise.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 16:42:22 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 02:06:58 GMT"}, {"version": "v3", "created": "Mon, 20 May 2019 19:30:35 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Wang", "Chao", ""], ["Jiang", "Hui", ""]]}, {"id": "1809.03485", "submitter": "Vivek Kulkarni", "authors": "Vivek Kulkarni, Junting Ye, Steven Skiena, William Yang Wang", "title": "Multi-view Models for Political Ideology Detection of News Articles", "comments": "10 pages. EMNLP 2018. Added copyright statement stating this is\n  authors draft (also noticed and fixed issue with citation (spacing and\n  readability))", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A news article's title, content and link structure often reveal its political\nideology. However, most existing works on automatic political ideology\ndetection only leverage textual cues. Drawing inspiration from recent advances\nin neural inference, we propose a novel attention based multi-view model to\nleverage cues from all of the above views to identify the ideology evinced by a\nnews article. Our model draws on advances in representation learning in natural\nlanguage processing and network science to capture cues from both textual\ncontent and the network structure of news articles. We empirically evaluate our\nmodel against a battery of baselines and show that our model outperforms state\nof the art by 10 percentage points F1 score.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 17:57:10 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Kulkarni", "Vivek", ""], ["Ye", "Junting", ""], ["Skiena", "Steven", ""], ["Wang", "William Yang", ""]]}, {"id": "1809.03568", "submitter": "Wanjun Zhong", "authors": "Wanjun Zhong, Duyu Tang, Nan Duan, Ming Zhou, Jiahai Wang, Jian Yin", "title": "Improving Question Answering by Commonsense-Based Pre-Training", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although neural network approaches achieve remarkable success on a variety of\nNLP tasks, many of them struggle to answer questions that require commonsense\nknowledge. We believe the main reason is the lack of commonsense\n\\mbox{connections} between concepts. To remedy this, we provide a simple and\neffective method that leverages external commonsense knowledge base such as\nConceptNet. We pre-train direct and indirect relational functions between\nconcepts, and show that these pre-trained functions could be easily added to\nexisting neural network models. Results show that incorporating\ncommonsense-based function improves the baseline on three question answering\ntasks that require commonsense reasoning. Further analysis shows that our\nsystem \\mbox{discovers} and leverages useful evidence from an external\ncommonsense knowledge base, which is missing in existing neural network models\nand help derive the correct answer.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 13:04:56 GMT"}, {"version": "v2", "created": "Fri, 5 Oct 2018 09:01:15 GMT"}, {"version": "v3", "created": "Fri, 1 Mar 2019 15:43:00 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Zhong", "Wanjun", ""], ["Tang", "Duyu", ""], ["Duan", "Nan", ""], ["Zhou", "Ming", ""], ["Wang", "Jiahai", ""], ["Yin", "Jian", ""]]}, {"id": "1809.03599", "submitter": "Jingbo Shang", "authors": "Jingbo Shang, Liyuan Liu, Xiang Ren, Xiaotao Gu, Teng Ren, Jiawei Han", "title": "Learning Named Entity Tagger using Domain-Specific Dictionary", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep neural models allow us to build reliable named entity\nrecognition (NER) systems without handcrafting features. However, such methods\nrequire large amounts of manually-labeled training data. There have been\nefforts on replacing human annotations with distant supervision (in conjunction\nwith external dictionaries), but the generated noisy labels pose significant\nchallenges on learning effective neural models. Here we propose two neural\nmodels to suit noisy distant supervision from the dictionary. First, under the\ntraditional sequence labeling framework, we propose a revised fuzzy CRF layer\nto handle tokens with multiple possible labels. After identifying the nature of\nnoisy labels in distant supervision, we go beyond the traditional framework and\npropose a novel, more effective neural model AutoNER with a new Tie or Break\nscheme. In addition, we discuss how to refine distant supervision for better\nNER performance. Extensive experiments on three benchmark datasets demonstrate\nthat AutoNER achieves the best performance when only using dictionaries with no\nadditional human effort, and delivers competitive results with state-of-the-art\nsupervised benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 21:15:30 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Shang", "Jingbo", ""], ["Liu", "Liyuan", ""], ["Ren", "Xiang", ""], ["Gu", "Xiaotao", ""], ["Ren", "Teng", ""], ["Han", "Jiawei", ""]]}, {"id": "1809.03632", "submitter": "Serina Chang", "authors": "Serina Chang, Ruiqi Zhong, Ethan Adams, Fei-Tzin Lee, Siddharth Varia,\n  Desmond Patton, William Frey, Chris Kedzie, and Kathleen McKeown", "title": "Detecting Gang-Involved Escalation on Social Media Using Context", "comments": "12 pages", "journal-ref": "EMNLP 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gang-involved youth in cities such as Chicago have increasingly turned to\nsocial media to post about their experiences and intents online. In some\nsituations, when they experience the loss of a loved one, their online\nexpression of emotion may evolve into aggression towards rival gangs and\nultimately into real-world violence. In this paper, we present a novel system\nfor detecting Aggression and Loss in social media. Our system features the use\nof domain-specific resources automatically derived from a large unlabeled\ncorpus, and contextual representations of the emotional and semantic content of\nthe user's recent tweets as well as their interactions with other users.\nIncorporating context in our Convolutional Neural Network (CNN) leads to a\nsignificant improvement.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 23:20:00 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Chang", "Serina", ""], ["Zhong", "Ruiqi", ""], ["Adams", "Ethan", ""], ["Lee", "Fei-Tzin", ""], ["Varia", "Siddharth", ""], ["Patton", "Desmond", ""], ["Frey", "William", ""], ["Kedzie", "Chris", ""], ["McKeown", "Kathleen", ""]]}, {"id": "1809.03633", "submitter": "Ruochen Xu", "authors": "Ruochen Xu, Yiming Yang, Naoki Otani and Yuexin Wu", "title": "Unsupervised Cross-lingual Transfer of Word Embedding Spaces", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual transfer of word embeddings aims to establish the semantic\nmappings among words in different languages by learning the transformation\nfunctions over the corresponding word embedding spaces. Successfully solving\nthis problem would benefit many downstream tasks such as to translate text\nclassification models from resource-rich languages (e.g. English) to\nlow-resource languages. Supervised methods for this problem rely on the\navailability of cross-lingual supervision, either using parallel corpora or\nbilingual lexicons as the labeled data for training, which may not be available\nfor many low resource languages. This paper proposes an unsupervised learning\napproach that does not require any cross-lingual labeled data. Given two\nmonolingual word embedding spaces for any language pair, our algorithm\noptimizes the transformation functions in both directions simultaneously based\non distributional matching as well as minimizing the back-translation losses.\nWe use a neural network implementation to calculate the Sinkhorn distance, a\nwell-defined distributional similarity measure, and optimize our objective\nthrough back-propagation. Our evaluation on benchmark datasets for bilingual\nlexicon induction and cross-lingual word similarity prediction shows stronger\nor competitive performance of the proposed method compared to other\nstate-of-the-art supervised and unsupervised baseline methods over many\nlanguage pairs.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 23:22:43 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Xu", "Ruochen", ""], ["Yang", "Yiming", ""], ["Otani", "Naoki", ""], ["Wu", "Yuexin", ""]]}, {"id": "1809.03664", "submitter": "Jing Li", "authors": "Jichuan Zeng, Jing Li, Yan Song, Cuiyun Gao, Michael R. Lyu, Irwin\n  King", "title": "Topic Memory Networks for Short Text Classification", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many classification models work poorly on short texts due to data sparsity.\nTo address this issue, we propose topic memory networks for short text\nclassification with a novel topic memory mechanism to encode latent topic\nrepresentations indicative of class labels. Different from most prior work that\nfocuses on extending features with external knowledge or pre-trained topics,\nour model jointly explores topic inference and text classification with memory\nnetworks in an end-to-end manner. Experimental results on four benchmark\ndatasets show that our model outperforms state-of-the-art models on short text\nclassification, meanwhile generates coherent topics.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 03:03:37 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Zeng", "Jichuan", ""], ["Li", "Jing", ""], ["Song", "Yan", ""], ["Gao", "Cuiyun", ""], ["Lyu", "Michael R.", ""], ["King", "Irwin", ""]]}, {"id": "1809.03680", "submitter": "J. Walker Orr", "authors": "J. Walker Orr, Prasad Tadepalli, Janardhan Rao Doppa, Xiaoli Fern,\n  Thomas G. Dietterich", "title": "Learning Scripts as Hidden Markov Models", "comments": "7 pages, AAAI 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scripts have been proposed to model the stereotypical event sequences found\nin narratives. They can be applied to make a variety of inferences including\nfilling gaps in the narratives and resolving ambiguous references. This paper\nproposes the first formal framework for scripts based on Hidden Markov Models\n(HMMs). Our framework supports robust inference and learning algorithms, which\nare lacking in previous clustering models. We develop an algorithm for\nstructure and parameter learning based on Expectation Maximization and evaluate\nit on a number of natural datasets. The results show that our algorithm is\nsuperior to several informed baselines for predicting missing events in partial\nobservation sequences.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 05:02:28 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Orr", "J. Walker", ""], ["Tadepalli", "Prasad", ""], ["Doppa", "Janardhan Rao", ""], ["Fern", "Xiaoli", ""], ["Dietterich", "Thomas G.", ""]]}, {"id": "1809.03690", "submitter": "Jing Li", "authors": "Jing Li, Yan Song, Zhongyu Wei, Kam-Fai Wong", "title": "A Joint Model of Conversational Discourse and Latent Topics on\n  Microblogs", "comments": "Accepted in Special Issue of the journal Computational Linguistics\n  on: Language in Social Media: Exploiting discourse and other contextual\n  information", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional topic models are ineffective for topic extraction from microblog\nmessages, because the data sparseness exhibited in short messages lacking\nstructure and contexts results in poor message-level word co-occurrence\npatterns. To address this issue, we organize microblog messages as conversation\ntrees based on their reposting and replying relations, and propose an\nunsupervised model that jointly learns word distributions to represent: 1)\ndifferent roles of conversational discourse, 2) various latent topics in\nreflecting content information. By explicitly distinguishing the probabilities\nof messages with varying discourse roles in containing topical words, our model\nis able to discover clusters of discourse words that are indicative of topical\ncontent. In an automatic evaluation on large-scale microblog corpora, our joint\nmodel yields topics with better coherence scores than competitive topic models\nfrom previous studies. Qualitative analysis on model outputs indicates that our\nmodel induces meaningful representations for both discourse and topics. We\nfurther present an empirical study on microblog summarization based on the\noutputs of our joint model. The results show that the jointly modeled discourse\nand topic representations can effectively indicate summary-worthy content in\nmicroblog conversations.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 06:13:37 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Li", "Jing", ""], ["Song", "Yan", ""], ["Wei", "Zhongyu", ""], ["Wong", "Kam-Fai", ""]]}, {"id": "1809.03695", "submitter": "Aitor Soroa Dr.", "authors": "Oier Lopez de Lacalle, Aitor Soroa, Eneko Agirre", "title": "Evaluating Multimodal Representations on Sentence Similarity: vSTS,\n  Visual Semantic Textual Similarity Dataset", "comments": null, "journal-ref": "ICCV17: second workshop on Closing the Loop Between Vision and\n  Language. Venice, Italy. 2017", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce vSTS, a new dataset for measuring textual\nsimilarity of sentences using multimodal information. The dataset is comprised\nby images along with its respectively textual captions. We describe the dataset\nboth quantitatively and qualitatively, and claim that it is a valid gold\nstandard for measuring automatic multimodal textual similarity systems. We also\ndescribe the initial experiments combining the multimodal information.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 06:40:36 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["de Lacalle", "Oier Lopez", ""], ["Soroa", "Aitor", ""], ["Agirre", "Eneko", ""]]}, {"id": "1809.03707", "submitter": "Hector Basevi", "authors": "M. Wagner, H. Basevi, R. Shetty, W. Li, M. Malinowski, M. Fritz, A.\n  Leonardis", "title": "Answering Visual What-If Questions: From Actions to Predicted Scene\n  Descriptions", "comments": "Paper: 18 pages, 5 figures, 5 tables. Supplementary material: 3\n  pages, 1 figure, 1 table. To be published in VLEASE ECCV 2018 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In-depth scene descriptions and question answering tasks have greatly\nincreased the scope of today's definition of scene understanding. While such\ntasks are in principle open ended, current formulations primarily focus on\ndescribing only the current state of the scenes under consideration. In\ncontrast, in this paper, we focus on the future states of the scenes which are\nalso conditioned on actions. We posit this as a question answering task, where\nan answer has to be given about a future scene state, given observations of the\ncurrent scene, and a question that includes a hypothetical action. Our solution\nis a hybrid model which integrates a physics engine into a question answering\narchitecture in order to anticipate future scene states resulting from\nobject-object interactions caused by an action. We demonstrate first results on\nthis challenging new problem and compare to baselines, where we outperform\nfully data-driven end-to-end learning approaches.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 07:22:28 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 16:39:39 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Wagner", "M.", ""], ["Basevi", "H.", ""], ["Shetty", "R.", ""], ["Li", "W.", ""], ["Malinowski", "M.", ""], ["Fritz", "M.", ""], ["Leonardis", "A.", ""]]}, {"id": "1809.03734", "submitter": "Dominika Basaj", "authors": "Dominika Basaj, Barbara Rychalska, Przemyslaw Biecek, Anna Wroblewska", "title": "How much should you ask? On the question structure in QA systems", "comments": "Accepted to Analyzing and interpreting neural networks for NLP\n  workshop at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Datasets that boosted state-of-the-art solutions for Question Answering (QA)\nsystems prove that it is possible to ask questions in natural language manner.\nHowever, users are still used to query-like systems where they type in keywords\nto search for answer. In this study we validate which parts of questions are\nessential for obtaining valid answer. In order to conclude that, we take\nadvantage of LIME - a framework that explains prediction by local\napproximation. We find that grammar and natural language is disregarded by QA.\nState-of-the-art model can answer properly even if 'asked' only with a few\nwords with high coefficients calculated with LIME. According to our knowledge,\nit is the first time that QA model is being explained by LIME.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 08:26:36 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Basaj", "Dominika", ""], ["Rychalska", "Barbara", ""], ["Biecek", "Przemyslaw", ""], ["Wroblewska", "Anna", ""]]}, {"id": "1809.03740", "submitter": "Dominika Basaj", "authors": "Barbara Rychalska, Dominika Basaj, Przemyslaw Biecek, Anna Wroblewska", "title": "Does it care what you asked? Understanding Importance of Verbs in Deep\n  Learning QA System", "comments": "Accepted to Analyzing and interpreting neural networks for NLP\n  workshop at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper we present the results of an investigation of the importance of\nverbs in a deep learning QA system trained on SQuAD dataset. We show that main\nverbs in questions carry little influence on the decisions made by the system -\nin over 90% of researched cases swapping verbs for their antonyms did not\nchange system decision. We track this phenomenon down to the insides of the\nnet, analyzing the mechanism of self-attention and values contained in hidden\nlayers of RNN. Finally, we recognize the characteristics of the SQuAD dataset\nas the source of the problem. Our work refers to the recently popular topic of\nadversarial examples in NLP, combined with investigating deep net structure.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 08:37:07 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Rychalska", "Barbara", ""], ["Basaj", "Dominika", ""], ["Biecek", "Przemyslaw", ""], ["Wroblewska", "Anna", ""]]}, {"id": "1809.03891", "submitter": "Yonatan Belinkov", "authors": "Yonatan Belinkov, Alexander Magidow, Alberto Barr\\'on-Cede\\~no, Avi\n  Shmidman, Maxim Romanov", "title": "Studying the History of the Arabic Language: Language Technology and a\n  Large-Scale Historical Corpus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arabic is a widely-spoken language with a long and rich history, but existing\ncorpora and language technology focus mostly on modern Arabic and its\nvarieties. Therefore, studying the history of the language has so far been\nmostly limited to manual analyses on a small scale. In this work, we present a\nlarge-scale historical corpus of the written Arabic language, spanning 1400\nyears. We describe our efforts to clean and process this corpus using Arabic\nNLP tools, including the identification of reused text. We study the history of\nthe Arabic language using a novel automatic periodization algorithm, as well as\nother techniques. Our findings confirm the established division of written\nArabic into Modern Standard and Classical Arabic, and confirm other established\nperiodizations, while suggesting that written Arabic may be divisible into\nstill further periods of development.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 13:44:48 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Belinkov", "Yonatan", ""], ["Magidow", "Alexander", ""], ["Barr\u00f3n-Cede\u00f1o", "Alberto", ""], ["Shmidman", "Avi", ""], ["Romanov", "Maxim", ""]]}, {"id": "1809.03944", "submitter": "Tom De Smedt", "authors": "Tom De Smedt, Sylvia Jaki, Eduan Kotz\\'e, Le\\\"ila Saoud, Maja\n  Gw\\'o\\'zd\\'z, Guy De Pauw, Walter Daelemans", "title": "Multilingual Cross-domain Perspectives on Online Hate Speech", "comments": "24 pages", "journal-ref": "CLiPS Technical Report Series 8 (2018) 1-24", "doi": null, "report-no": "CTRS-008", "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report, we present a study of eight corpora of online hate speech, by\ndemonstrating the NLP techniques that we used to collect and analyze the\njihadist, extremist, racist, and sexist content. Analysis of the multilingual\ncorpora shows that the different contexts share certain characteristics in\ntheir hateful rhetoric. To expose the main features, we have focused on text\nclassification, text profiling, keyword and collocation extraction, along with\nmanual annotation and qualitative study.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 14:49:05 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["De Smedt", "Tom", ""], ["Jaki", "Sylvia", ""], ["Kotz\u00e9", "Eduan", ""], ["Saoud", "Le\u00efla", ""], ["Gw\u00f3\u017ad\u017a", "Maja", ""], ["De Pauw", "Guy", ""], ["Daelemans", "Walter", ""]]}, {"id": "1809.03985", "submitter": "Gabriel Bretschner", "authors": "Tamer Alkhouli, Gabriel Bretschner, and Hermann Ney", "title": "On The Alignment Problem In Multi-Head Attention-Based Neural Machine\n  Translation", "comments": null, "journal-ref": "WMT 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates the alignment problem in state-of-the-art multi-head\nattention models based on the transformer architecture. We demonstrate that\nalignment extraction in transformer models can be improved by augmenting an\nadditional alignment head to the multi-head source-to-target attention\ncomponent. This is used to compute sharper attention weights. We describe how\nto use the alignment head to achieve competitive performance. To study the\neffect of adding the alignment head, we simulate a dictionary-guided\ntranslation task, where the user wants to guide translation using pre-defined\ndictionary entries. Using the proposed approach, we achieve up to $3.8$ % BLEU\nimprovement when using the dictionary, in comparison to $2.4$ % BLEU in the\nbaseline case. We also propose alignment pruning to speed up decoding in\nalignment-based neural machine translation (ANMT), which speeds up translation\nby a factor of $1.8$ without loss in translation performance. We carry out\nexperiments on the shared WMT 2016 English$\\to$Romanian news task and the BOLT\nChinese$\\to$English discussion forum task.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 15:41:12 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Alkhouli", "Tamer", ""], ["Bretschner", "Gabriel", ""], ["Ney", "Hermann", ""]]}, {"id": "1809.03992", "submitter": "Allyson Ettinger", "authors": "Allyson Ettinger, Ahmed Elgohary, Colin Phillips, Philip Resnik", "title": "Assessing Composition in Sentence Vector Representations", "comments": "COLING 2018", "journal-ref": "In Proceedings of the 27th International Conference on\n  Computational Linguistics (pp. 1790-1801)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important component of achieving language understanding is mastering the\ncomposition of sentence meaning, but an immediate challenge to solving this\nproblem is the opacity of sentence vector representations produced by current\nneural sentence composition models. We present a method to address this\nchallenge, developing tasks that directly target compositional meaning\ninformation in sentence vector representations with a high degree of precision\nand control. To enable the creation of these controlled tasks, we introduce a\nspecialized sentence generation system that produces large, annotated sentence\nsets meeting specified syntactic, semantic and lexical constraints. We describe\nthe details of the method and generation system, and then present results of\nexperiments applying our method to probe for compositional information in\nembeddings from a number of existing sentence composition models. We find that\nthe method is able to extract useful information about the differing capacities\nof these models, and we discuss the implications of our results with respect to\nthese systems' capturing of sentence information. We make available for public\nuse the datasets used for these experiments, as well as the generation system.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 15:56:46 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Ettinger", "Allyson", ""], ["Elgohary", "Ahmed", ""], ["Phillips", "Colin", ""], ["Resnik", "Philip", ""]]}, {"id": "1809.03999", "submitter": "Shu Liu", "authors": "Shu Liu, Jingjing Xu, Xuancheng Ren, Xu Sun", "title": "Evaluating Semantic Rationality of a Sentence: A Sememe-Word-Matching\n  Neural Network based on HowNet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic evaluation of semantic rationality is an important yet challenging\ntask, and current automatic techniques cannot well identify whether a sentence\nis semantically rational. The methods based on the language model do not\nmeasure the sentence by rationality but by commonness. The methods based on the\nsimilarity with human written sentences will fail if human-written references\nare not available. In this paper, we propose a novel model called\nSememe-Word-Matching Neural Network (SWM-NN) to tackle semantic rationality\nevaluation by taking advantage of sememe knowledge base HowNet. The advantage\nis that our model can utilize a proper combination of sememes to represent the\nfine-grained semantic meanings of a word within the specific contexts. We use\nthe fine-grained semantic representation to help the model learn the semantic\ndependency among words. To evaluate the effectiveness of the proposed model, we\nbuild a large-scale rationality evaluation dataset. Experimental results on\nthis dataset show that the proposed model outperforms the competitive baselines\nwith a 5.4\\% improvement in accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 16:09:53 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Liu", "Shu", ""], ["Xu", "Jingjing", ""], ["Ren", "Xuancheng", ""], ["Sun", "Xu", ""]]}, {"id": "1809.04019", "submitter": "Emilia Apostolova PhD", "authors": "Emilia Apostolova and R. Andrew Kreek", "title": "Training and Prediction Data Discrepancies: Challenges of Text\n  Classification with Noisy, Historical Data", "comments": "2018 The 4th Workshop on Noisy User-generated Text (W-NUT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industry datasets used for text classification are rarely created for that\npurpose. In most cases, the data and target predictions are a by-product of\naccumulated historical data, typically fraught with noise, present in both the\ntext-based document, as well as in the targeted labels. In this work, we\naddress the question of how well performance metrics computed on noisy,\nhistorical data reflect the performance on the intended future machine learning\nmodel input. The results demonstrate the utility of dirty training datasets\nused to build prediction models for cleaner (and different) prediction inputs.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 16:43:52 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Apostolova", "Emilia", ""], ["Kreek", "R. Andrew", ""]]}, {"id": "1809.04022", "submitter": "Shauli Ravfogel", "authors": "Shauli Ravfogel, Francis M. Tyers, Yoav Goldberg", "title": "Can LSTM Learn to Capture Agreement? The Case of Basque", "comments": "Accepted to \"Analyzing and interpreting neural networks for NLP\"\n  workshop at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sequential neural networks models are powerful tools in a variety of Natural\nLanguage Processing (NLP) tasks. The sequential nature of these models raises\nthe questions: to what extent can these models implicitly learn hierarchical\nstructures typical to human language, and what kind of grammatical phenomena\ncan they acquire?\n  We focus on the task of agreement prediction in Basque, as a case study for a\ntask that requires implicit understanding of sentence structure and the\nacquisition of a complex but consistent morphological system. Analyzing\nexperimental results from two syntactic prediction tasks -- verb number\nprediction and suffix recovery -- we find that sequential models perform worse\non agreement prediction in Basque than one might expect on the basis of a\nprevious agreement prediction work in English. Tentative findings based on\ndiagnostic classifiers suggest the network makes use of local heuristics as a\nproxy for the hierarchical structure of the sentence. We propose the Basque\nagreement prediction task as challenging benchmark for models that attempt to\nlearn regularities in human language.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 16:44:02 GMT"}, {"version": "v2", "created": "Thu, 13 Sep 2018 12:48:35 GMT"}, {"version": "v3", "created": "Fri, 21 Sep 2018 06:30:11 GMT"}, {"version": "v4", "created": "Mon, 26 Nov 2018 13:16:56 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Ravfogel", "Shauli", ""], ["Tyers", "Francis M.", ""], ["Goldberg", "Yoav", ""]]}, {"id": "1809.04047", "submitter": "Tengfei Ma", "authors": "Tengfei Ma, Chiamin Wu, Cao Xiao, Jimeng Sun", "title": "AWE: Asymmetric Word Embedding for Textual Entailment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Textual entailment is a fundamental task in natural language processing. It\nrefers to the directional relation between text fragments such that the\n\"premise\" can infer \"hypothesis\". In recent years deep learning methods have\nachieved great success in this task. Many of them have considered the\ninter-sentence word-word interactions between the premise-hypothesis pairs,\nhowever, few of them considered the \"asymmetry\" of these interactions.\nDifferent from paraphrase identification or sentence similarity evaluation,\ntextual entailment is essentially determining a directional (asymmetric)\nrelation between the premise and the hypothesis. In this paper, we propose a\nsimple but effective way to enhance existing textual entailment algorithms by\nusing asymmetric word embeddings. Experimental results on SciTail and SNLI\ndatasets show that the learned asymmetric word embeddings could significantly\nimprove the word-word interaction based textual entailment models. It is\nnoteworthy that the proposed AWE-DeIsTe model can get 2.1% accuracy improvement\nover prior state-of-the-art on SciTail.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 17:30:12 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2018 14:58:36 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Ma", "Tengfei", ""], ["Wu", "Chiamin", ""], ["Xiao", "Cao", ""], ["Sun", "Jimeng", ""]]}, {"id": "1809.04128", "submitter": "Denis Paperno", "authors": "Denis Paperno", "title": "Limitations in learning an interpreted language with recurrent models", "comments": "Paper to be presented at the EMNLP2018 workshop \"Analyzing and\n  interpreting neural networks for NLP\", https://blackboxnlp.github.io/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this submission I report work in progress on learning simplified\ninterpreted languages by means of recurrent models. The data is constructed to\nreflect core properties of natural language as modeled in formal syntax and\nsemantics: recursive syntactic structure and compositionality. Preliminary\nresults suggest that LSTM networks do generalise to compositional\ninterpretation, albeit only in the most favorable learning setting, with a\nwell-paced curriculum, extensive training data, and left-to-right (but not\nright-to-left) composition.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 19:52:44 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Paperno", "Denis", ""]]}, {"id": "1809.04163", "submitter": "Edoardo Maria Ponti", "authors": "Edoardo Maria Ponti, Ivan Vuli\\'c, Goran Glava\\v{s}, Nikola\n  Mrk\\v{s}i\\'c and Anna Korhonen", "title": "Adversarial Propagation and Zero-Shot Cross-Lingual Transfer of Word\n  Vector Specialization", "comments": "Accepted at EMNLP 2018", "journal-ref": null, "doi": "10.18653/v1/D18-1026", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic specialization is the process of fine-tuning pre-trained\ndistributional word vectors using external lexical knowledge (e.g., WordNet) to\naccentuate a particular semantic relation in the specialized vector space.\nWhile post-processing specialization methods are applicable to arbitrary\ndistributional vectors, they are limited to updating only the vectors of words\noccurring in external lexicons (i.e., seen words), leaving the vectors of all\nother words unchanged. We propose a novel approach to specializing the full\ndistributional vocabulary. Our adversarial post-specialization method\npropagates the external lexical knowledge to the full distributional space. We\nexploit words seen in the resources as training examples for learning a global\nspecialization function. This function is learned by combining a standard\nL2-distance loss with an adversarial loss: the adversarial component produces\nmore realistic output vectors. We show the effectiveness and robustness of the\nproposed method across three languages and on three tasks: word similarity,\ndialog state tracking, and lexical simplification. We report consistent\nimprovements over distributional word vectors and vectors specialized by other\nstate-of-the-art specialization frameworks. Finally, we also propose a\ncross-lingual transfer method for zero-shot specialization which successfully\nspecializes a full target distributional space without any lexical knowledge in\nthe target language and without any bilingual data.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 21:08:00 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Ponti", "Edoardo Maria", ""], ["Vuli\u0107", "Ivan", ""], ["Glava\u0161", "Goran", ""], ["Mrk\u0161i\u0107", "Nikola", ""], ["Korhonen", "Anna", ""]]}, {"id": "1809.04179", "submitter": "Tal Linzen", "authors": "Tal Linzen", "title": "What can linguistics and deep learning contribute to each other?", "comments": "Response to Joe Pater, \"Generative linguistics and neural networks at\n  60: foundation, friction, and fusion\". To appear in Language", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Joe Pater's target article calls for greater interaction between neural\nnetwork research and linguistics. I expand on this call and show how such\ninteraction can benefit both fields. Linguists can contribute to research on\nneural networks for language technologies by clearly delineating the linguistic\ncapabilities that can be expected of such systems, and by constructing\ncontrolled experimental paradigms that can determine whether those desiderata\nhave been met. In the other direction, neural networks can benefit the\nscientific study of language by providing infrastructure for modeling human\nsentence processing and for evaluating the necessity of particular innate\nconstraints on language acquisition.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 21:55:11 GMT"}, {"version": "v2", "created": "Fri, 14 Sep 2018 13:59:20 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Linzen", "Tal", ""]]}, {"id": "1809.04203", "submitter": "Minh Nguyen", "authors": "Minh Nguyen, Gia H. Ngo, Nancy F. Chen", "title": "Multimodal neural pronunciation modeling for spoken languages with\n  logographic origin", "comments": "Accepted to EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphemes of most languages encode pronunciation, though some are more\nexplicit than others. Languages like Spanish have a straightforward mapping\nbetween its graphemes and phonemes, while this mapping is more convoluted for\nlanguages like English. Spoken languages such as Cantonese present even more\nchallenges in pronunciation modeling: (1) they do not have a standard written\nform, (2) the closest graphemic origins are logographic Han characters, of\nwhich only a subset of these logographic characters implicitly encodes\npronunciation. In this work, we propose a multimodal approach to predict the\npronunciation of Cantonese logographic characters, using neural networks with a\ngeometric representation of logographs and pronunciation of cognates in\nhistorically related languages. The proposed framework improves performance by\n18.1% and 25.0% respective to unimodal and multimodal baselines.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 00:09:20 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Nguyen", "Minh", ""], ["Ngo", "Gia H.", ""], ["Chen", "Nancy F.", ""]]}, {"id": "1809.04206", "submitter": "Fan-Keng Sun", "authors": "Shun-Yao Shih, Fan-Keng Sun, Hung-yi Lee", "title": "Temporal Pattern Attention for Multivariate Time Series Forecasting", "comments": "Journal track of ECML/PKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forecasting multivariate time series data, such as prediction of electricity\nconsumption, solar power production, and polyphonic piano pieces, has numerous\nvaluable applications. However, complex and non-linear interdependencies\nbetween time steps and series complicate the task. To obtain accurate\nprediction, it is crucial to model long-term dependency in time series data,\nwhich can be achieved to some good extent by recurrent neural network (RNN)\nwith attention mechanism. Typical attention mechanism reviews the information\nat each previous time step and selects the relevant information to help\ngenerate the outputs, but it fails to capture the temporal patterns across\nmultiple time steps. In this paper, we propose to use a set of filters to\nextract time-invariant temporal patterns, which is similar to transforming time\nseries data into its \"frequency domain\". Then we proposed a novel attention\nmechanism to select relevant time series, and use its \"frequency domain\"\ninformation for forecasting. We applied the proposed model on several\nreal-world tasks and achieved state-of-the-art performance in all of them with\nonly one exception.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 00:40:40 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 06:09:10 GMT"}, {"version": "v3", "created": "Wed, 18 Sep 2019 23:17:57 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Shih", "Shun-Yao", ""], ["Sun", "Fan-Keng", ""], ["Lee", "Hung-yi", ""]]}, {"id": "1809.04214", "submitter": "Shun-Yao Shih", "authors": "Shun-Yao Shih, Heng-Yu Chi", "title": "Automatic, Personalized, and Flexible Playlist Generation using\n  Reinforcement Learning", "comments": "7 pages, 4 figures, ISMIR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Songs can be well arranged by professional music curators to form a riveting\nplaylist that creates engaging listening experiences. However, it is\ntime-consuming for curators to timely rearrange these playlists for fitting\ntrends in future. By exploiting the techniques of deep learning and\nreinforcement learning, in this paper, we consider music playlist generation as\na language modeling problem and solve it by the proposed attention language\nmodel with policy gradient. We develop a systematic and interactive approach so\nthat the resulting playlists can be tuned flexibly according to user\npreferences. Considering a playlist as a sequence of words, we first train our\nattention RNN language model on baseline recommended playlists. By optimizing\nsuitable imposed reward functions, the model is thus refined for corresponding\npreferences. The experimental results demonstrate that our approach not only\ngenerates coherent playlists automatically but is also able to flexibly\nrecommend personalized playlists for diversity, novelty and freshness.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 01:32:11 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Shih", "Shun-Yao", ""], ["Chi", "Heng-Yu", ""]]}, {"id": "1809.04259", "submitter": "Jinman Zhao", "authors": "Jinman Zhao, Sidharth Mudgal, Yingyu Liang", "title": "Generalizing Word Embeddings using Bag of Subwords", "comments": "Accepted to EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We approach the problem of generalizing pre-trained word embeddings beyond\nfixed-size vocabularies without using additional contextual information. We\npropose a subword-level word vector generation model that views words as bags\nof character $n$-grams. The model is simple, fast to train and provides good\nvectors for rare or unseen words. Experiments show that our model achieves\nstate-of-the-art performances in English word similarity task and in joint\nprediction of part-of-speech tag and morphosyntactic attributes in 23\nlanguages, suggesting our model's ability in capturing the relationship between\nwords' textual representations and their embeddings.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 05:15:32 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Zhao", "Jinman", ""], ["Mudgal", "Sidharth", ""], ["Liang", "Yingyu", ""]]}, {"id": "1809.04267", "submitter": "Yibo Sun", "authors": "Yibo Sun and Daya Guo and Duyu Tang and Nan Duan and Zhao Yan and\n  Xiaocheng Feng and Bing Qin", "title": "Knowledge Based Machine Reading Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine reading comprehension (MRC) requires reasoning about both the\nknowledge involved in a document and knowledge about the world. However,\nexisting datasets are typically dominated by questions that can be well solved\nby context matching, which fail to test this capability. To encourage the\nprogress on knowledge-based reasoning in MRC, we present knowledge-based MRC in\nthis paper, and build a new dataset consisting of 40,047 question-answer pairs.\nThe annotation of this dataset is designed so that successfully answering the\nquestions requires understanding and the knowledge involved in a document. We\nimplement a framework consisting of both a question answering model and a\nquestion generation model, both of which take the knowledge extracted from the\ndocument as well as relevant facts from an external knowledge base such as\nFreebase/ProBase/Reverb/NELL. Results show that incorporating side information\nfrom external KB improves the accuracy of the baseline question answer system.\nWe compare it with a standard MRC model BiDAF, and also provide the difficulty\nof the dataset and lay out remaining challenges.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 06:21:32 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Sun", "Yibo", ""], ["Guo", "Daya", ""], ["Tang", "Duyu", ""], ["Duan", "Nan", ""], ["Yan", "Zhao", ""], ["Feng", "Xiaocheng", ""], ["Qin", "Bing", ""]]}, {"id": "1809.04271", "submitter": "Yibo Sun", "authors": "Yibo Sun, Duyu Tang, Nan Duan, Jingjing Xu, Xiaocheng Feng, Bing Qin", "title": "Knowledge-Aware Conversational Semantic Parsing Over Web Tables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational semantic parsing over tables requires knowledge acquiring and\nreasoning abilities, which have not been well explored by current\nstate-of-the-art approaches. Motivated by this fact, we propose a\nknowledge-aware semantic parser to improve parsing performance by integrating\nvarious types of knowledge. In this paper, we consider three types of\nknowledge, including grammar knowledge, expert knowledge, and external resource\nknowledge. First, grammar knowledge empowers the model to effectively replicate\npreviously generated logical form, which effectively handles the co-reference\nand ellipsis phenomena in conversation Second, based on expert knowledge, we\npropose a decomposable model, which is more controllable compared with\ntraditional end-to-end models that put all the burdens of learning on\ntrial-and-error in an end-to-end way. Third, external resource knowledge, i.e.,\nprovided by a pre-trained language model or an entity typing model, is used to\nimprove the representation of question and table for a better semantic\nunderstanding. We conduct experiments on the SequentialQA dataset. Results show\nthat our knowledge-aware model outperforms the state-of-the-art approaches.\nIncremental experimental results also prove the usefulness of various\nknowledge. Further analysis shows that our approach has the ability to derive\nthe meaning representation of a context-dependent utterance by leveraging\npreviously generated outcomes.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 06:37:51 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Sun", "Yibo", ""], ["Tang", "Duyu", ""], ["Duan", "Nan", ""], ["Xu", "Jingjing", ""], ["Feng", "Xiaocheng", ""], ["Qin", "Bing", ""]]}, {"id": "1809.04276", "submitter": "Qingfu Zhu", "authors": "Qingfu Zhu, Lei Cui, Weinan Zhang, Furu Wei, Ting Liu", "title": "Retrieval-Enhanced Adversarial Training for Neural Response Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue systems are usually built on either generation-based or\nretrieval-based approaches, yet they do not benefit from the advantages of\ndifferent models. In this paper, we propose a Retrieval-Enhanced Adversarial\nTraining (REAT) method for neural response generation. Distinct from existing\napproaches, the REAT method leverages an encoder-decoder framework in terms of\nan adversarial training paradigm, while taking advantage of N-best response\ncandidates from a retrieval-based system to construct the discriminator. An\nempirical study on a large scale public available benchmark dataset shows that\nthe REAT method significantly outperforms the vanilla Seq2Seq model as well as\nthe conventional adversarial training approach.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 06:47:21 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 00:48:54 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Zhu", "Qingfu", ""], ["Cui", "Lei", ""], ["Zhang", "Weinan", ""], ["Wei", "Furu", ""], ["Liu", "Ting", ""]]}, {"id": "1809.04283", "submitter": "Shikhar Vashishth", "authors": "Shikhar Vashishth, Manik Bhandari, Prateek Yadav, Piyush Rai,\n  Chiranjib Bhattacharyya, Partha Talukdar", "title": "Incorporating Syntactic and Semantic Information in Word Embeddings\n  using Graph Convolutional Networks", "comments": "11 pages, 2 figures", "journal-ref": "57th Annual Meeting of the Association for Computational\n  Linguistics (ACL 2019)", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings have been widely adopted across several NLP applications.\nMost existing word embedding methods utilize sequential context of a word to\nlearn its embedding. While there have been some attempts at utilizing syntactic\ncontext of a word, such methods result in an explosion of the vocabulary size.\nIn this paper, we overcome this problem by proposing SynGCN, a flexible Graph\nConvolution based method for learning word embeddings. SynGCN utilizes the\ndependency context of a word without increasing the vocabulary size. Word\nembeddings learned by SynGCN outperform existing methods on various intrinsic\nand extrinsic tasks and provide an advantage when used with ELMo. We also\npropose SemGCN, an effective framework for incorporating diverse semantic\nknowledge for further enhancing learned word representations. We make the\nsource code of both models available to encourage reproducible research.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 07:31:06 GMT"}, {"version": "v2", "created": "Wed, 22 May 2019 12:10:15 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 21:54:13 GMT"}, {"version": "v4", "created": "Sat, 20 Jul 2019 13:14:37 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Vashishth", "Shikhar", ""], ["Bhandari", "Manik", ""], ["Yadav", "Prateek", ""], ["Rai", "Piyush", ""], ["Bhattacharyya", "Chiranjib", ""], ["Talukdar", "Partha", ""]]}, {"id": "1809.04306", "submitter": "Xiaoyuan Yi", "authors": "Xiaoyuan Yi, Maosong Sun, Ruoyu Li, Zonghan Yang", "title": "Chinese Poetry Generation with a Working Memory Model", "comments": "7 pages, 3 figures, 4 tables, published in proceedings of IJCAI 2018", "journal-ref": "In Proceedings of the Twenty-Seventh International Joint\n  Conference on Artificial Intelligence, pages 4553-4559, Stockholm, Sweden,\n  2018", "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an exquisite and concise literary form, poetry is a gem of human culture.\nAutomatic poetry generation is an essential step towards computer creativity.\nIn recent years, several neural models have been designed for this task.\nHowever, among lines of a whole poem, the coherence in meaning and topics still\nremains a big challenge. In this paper, inspired by the theoretical concept in\ncognitive psychology, we propose a novel Working Memory model for poetry\ngeneration. Different from previous methods, our model explicitly maintains\ntopics and informative limited history in a neural memory. During the\ngeneration process, our model reads the most relevant parts from memory slots\nto generate the current line. After each line is generated, it writes the most\nsalient parts of the previous line into memory slots. By dynamic manipulation\nof the memory, our model keeps a coherent information flow and learns to\nexpress each topic flexibly and naturally. We experiment on three different\ngenres of Chinese poetry: quatrain, iambic and chinoiserie lyric. Both\nautomatic and human evaluation results show that our model outperforms current\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 08:31:20 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Yi", "Xiaoyuan", ""], ["Sun", "Maosong", ""], ["Li", "Ruoyu", ""], ["Yang", "Zonghan", ""]]}, {"id": "1809.04313", "submitter": "Xiaoyuan Yi", "authors": "Xiaoyuan Yi, Ruoyu Li, Maosong Sun", "title": "Chinese Poetry Generation with a Salient-Clue Mechanism", "comments": "10pages, 1.5 page for references, 6 figures, 3 tables, will be\n  published in CoNLL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a precious part of the human cultural heritage, Chinese poetry has\ninfluenced people for generations. Automatic poetry composition is a challenge\nfor AI. In recent years, significant progress has been made in this area\nbenefiting from the development of neural networks. However, the coherence in\nmeaning, theme or even artistic conception for a generated poem as a whole\nstill remains a big problem. In this paper, we propose a novel Salient-Clue\nmechanism for Chinese poetry generation. Different from previous work which\ntried to exploit all the context information, our model selects the most\nsalient characters automatically from each so-far generated line to gradually\nform a salient clue, which is utilized to guide successive poem generation\nprocess so as to eliminate interruptions and improve coherence. Besides, our\nmodel can be flexibly extended to control the generated poem in different\naspects, for example, poetry style, which further enhances the coherence.\nExperimental results show that our model is very effective, outperforming three\nstrong baselines.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 08:50:30 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Yi", "Xiaoyuan", ""], ["Li", "Ruoyu", ""], ["Sun", "Maosong", ""]]}, {"id": "1809.04318", "submitter": "Hangbo Bao", "authors": "Hangbo Bao, Shaohan Huang, Furu Wei, Lei Cui, Yu Wu, Chuanqi Tan,\n  Songhao Piao, Ming Zhou", "title": "Neural Melody Composition from Lyrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a novel task that learns to compose music from\nnatural language. Given the lyrics as input, we propose a melody composition\nmodel that generates lyrics-conditional melody as well as the exact alignment\nbetween the generated melody and the given lyrics simultaneously. More\nspecifically, we develop the melody composition model based on the\nsequence-to-sequence framework. It consists of two neural encoders to encode\nthe current lyrics and the context melody respectively, and a hierarchical\ndecoder to jointly produce musical notes and the corresponding alignment.\nExperimental results on lyrics-melody pairs of 18,451 pop songs demonstrate the\neffectiveness of our proposed methods. In addition, we apply a singing voice\nsynthesizer software to synthesize the \"singing\" of the lyrics and melodies for\nhuman evaluation. Results indicate that our generated melodies are more\nmelodious and tuneful compared with the baseline method.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 09:03:20 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Bao", "Hangbo", ""], ["Huang", "Shaohan", ""], ["Wei", "Furu", ""], ["Cui", "Lei", ""], ["Wu", "Yu", ""], ["Tan", "Chuanqi", ""], ["Piao", "Songhao", ""], ["Zhou", "Ming", ""]]}, {"id": "1809.04344", "submitter": "Sandro Pezzelle", "authors": "Shailza Jolly and Sandro Pezzelle and Tassilo Klein and Andreas Dengel\n  and Moin Nabi", "title": "The Wisdom of MaSSeS: Majority, Subjectivity, and Semantic Similarity in\n  the Evaluation of VQA", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce MASSES, a simple evaluation metric for the task of Visual\nQuestion Answering (VQA). In its standard form, the VQA task is operationalized\nas follows: Given an image and an open-ended question in natural language,\nsystems are required to provide a suitable answer. Currently, model performance\nis evaluated by means of a somehow simplistic metric: If the predicted answer\nis chosen by at least 3 human annotators out of 10, then it is 100% correct.\nThough intuitively valuable, this metric has some important limitations. First,\nit ignores whether the predicted answer is the one selected by the Majority\n(MA) of annotators. Second, it does not account for the quantitative\nSubjectivity (S) of the answers in the sample (and dataset). Third, information\nabout the Semantic Similarity (SES) of the responses is completely neglected.\nBased on such limitations, we propose a multi-component metric that accounts\nfor all these issues. We show that our metric is effective in providing a more\nfine-grained evaluation both on the quantitative and qualitative level.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 10:11:39 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Jolly", "Shailza", ""], ["Pezzelle", "Sandro", ""], ["Klein", "Tassilo", ""], ["Dengel", "Andreas", ""], ["Nabi", "Moin", ""]]}, {"id": "1809.04397", "submitter": "Krishan Rajaratnam", "authors": "Krishan Rajaratnam and Kunal Shah and Jugal Kalita", "title": "Isolated and Ensemble Audio Preprocessing Methods for Detecting\n  Adversarial Examples against Automatic Speech Recognition", "comments": "Accepted for oral presentation at the 30th Conference on\n  Computational Linguistics and Speech Processing (ROCLING 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.CR cs.LG cs.NE eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An adversarial attack is an exploitative process in which minute alterations\nare made to natural inputs, causing the inputs to be misclassified by neural\nmodels. In the field of speech recognition, this has become an issue of\nincreasing significance. Although adversarial attacks were originally\nintroduced in computer vision, they have since infiltrated the realm of speech\nrecognition. In 2017, a genetic attack was shown to be quite potent against the\nSpeech Commands Model. Limited-vocabulary speech classifiers, such as the\nSpeech Commands Model, are used in a variety of applications, particularly in\ntelephony; as such, adversarial examples produced by this attack pose as a\nmajor security threat. This paper explores various methods of detecting these\nadversarial examples with combinations of audio preprocessing. One particular\ncombined defense incorporating compressions, speech coding, filtering, and\naudio panning was shown to be quite effective against the attack on the Speech\nCommands Model, detecting audio adversarial examples with 93.5% precision and\n91.2% recall.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 05:12:15 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Rajaratnam", "Krishan", ""], ["Shah", "Kunal", ""], ["Kalita", "Jugal", ""]]}, {"id": "1809.04444", "submitter": "Aitor Garc\\'ia-Pablos", "authors": "Ona de Gibert, Naiara Perez, Aitor Garc\\'ia-Pablos, Montse Cuadros", "title": "Hate Speech Dataset from a White Supremacy Forum", "comments": "Accepted at 2nd Workshop on Abusive Language Online", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hate speech is commonly defined as any communication that disparages a target\ngroup of people based on some characteristic such as race, colour, ethnicity,\ngender, sexual orientation, nationality, religion, or other characteristic. Due\nto the massive rise of user-generated web content on social media, the amount\nof hate speech is also steadily increasing. Over the past years, interest in\nonline hate speech detection and, particularly, the automation of this task has\ncontinuously grown, along with the societal impact of the phenomenon. This\npaper describes a hate speech dataset composed of thousands of sentences\nmanually labelled as containing hate speech or not. The sentences have been\nextracted from Stormfront, a white supremacist forum. A custom annotation tool\nhas been developed to carry out the manual labelling task which, among other\nthings, allows the annotators to choose whether to read the context of a\nsentence before labelling it. The paper also provides a thoughtful qualitative\nand quantitative study of the resulting dataset and several baseline\nexperiments with different classification models. The dataset is publicly\navailable.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 13:51:02 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["de Gibert", "Ona", ""], ["Perez", "Naiara", ""], ["Garc\u00eda-Pablos", "Aitor", ""], ["Cuadros", "Montse", ""]]}, {"id": "1809.04458", "submitter": "Suwon Shon", "authors": "Suwon Shon, Wei-Ning Hsu, James Glass", "title": "Unsupervised Representation Learning of Speech for Dialect\n  Identification", "comments": "Accepted at SLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore the use of a factorized hierarchical variational\nautoencoder (FHVAE) model to learn an unsupervised latent representation for\ndialect identification (DID). An FHVAE can learn a latent space that separates\nthe more static attributes within an utterance from the more dynamic attributes\nby encoding them into two different sets of latent variables. Useful factors\nfor dialect identification, such as phonetic or linguistic content, are encoded\nby a segmental latent variable, while irrelevant factors that are relatively\nconstant within a sequence, such as a channel or a speaker information, are\nencoded by a sequential latent variable. The disentanglement property makes the\nsegmental latent variable less susceptible to channel and speaker variation,\nand thus reduces degradation from channel domain mismatch. We demonstrate that\non fully-supervised DID tasks, an end-to-end model trained on the features\nextracted from the FHVAE model achieves the best performance, compared to the\nsame model trained on conventional acoustic features and an i-vector based\nsystem. Moreover, we also show that the proposed approach can leverage a large\namount of unlabeled data for FHVAE training to learn domain-invariant features\nfor DID, and significantly improve the performance in a low-resource condition,\nwhere the labels for the in-domain data are not available.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 13:57:06 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Shon", "Suwon", ""], ["Hsu", "Wei-Ning", ""], ["Glass", "James", ""]]}, {"id": "1809.04482", "submitter": "Mateusz Malinowski", "authors": "Mateusz Malinowski and Carl Doersch", "title": "The Visual QA Devil in the Details: The Impact of Early Fusion and Batch\n  Norm on CLEVR", "comments": "Presented at ECCV'18 Workshop on Shortcomings in Vision and Language", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual QA is a pivotal challenge for higher-level reasoning, requiring\nunderstanding language, vision, and relationships between many objects in a\nscene. Although datasets like CLEVR are designed to be unsolvable without such\ncomplex relational reasoning, some surprisingly simple feed-forward, \"holistic\"\nmodels have recently shown strong performance on this dataset. These models\nlack any kind of explicit iterative, symbolic reasoning procedure, which are\nhypothesized to be necessary for counting objects, narrowing down the set of\nrelevant objects based on several attributes, etc. The reason for this strong\nperformance is poorly understood. Hence, our work analyzes such models, and\nfinds that minor architectural elements are crucial to performance. In\nparticular, we find that \\textit{early fusion} of language and vision provides\nlarge performance improvements. This contrasts with the late fusion approaches\npopular at the dawn of Visual QA. We propose a simple module we call Multimodal\nCore, which we hypothesize performs the fundamental operations for multimodal\ntasks. We believe that understanding why these elements are so important to\ncomplex question answering will aid the design of better-performing algorithms\nfor Visual QA while minimizing hand-engineering effort.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 07:14:30 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Malinowski", "Mateusz", ""], ["Doersch", "Carl", ""]]}, {"id": "1809.04505", "submitter": "Peng Xu", "authors": "Peng Xu, Andrea Madotto, Chien-Sheng Wu, Ji Ho Park and Pascale Fung", "title": "Emo2Vec: Learning Generalized Emotion Representation by Multi-task\n  Training", "comments": "Accepted by 9th Workshop on Computational Approaches to Subjectivity,\n  Sentiment & Social Media Analysis(WASSA) in EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose Emo2Vec which encodes emotional semantics into\nvectors. We train Emo2Vec by multi-task learning six different emotion-related\ntasks, including emotion/sentiment analysis, sarcasm classification, stress\ndetection, abusive language classification, insult detection, and personality\nrecognition. Our evaluation of Emo2Vec shows that it outperforms existing\naffect-related representations, such as Sentiment-Specific Word Embedding and\nDeepMoji embeddings with much smaller training corpora. When concatenated with\nGloVe, Emo2Vec achieves competitive performances to state-of-the-art results on\nseveral tasks using a simple logistic regression classifier.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 15:08:00 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Xu", "Peng", ""], ["Madotto", "Andrea", ""], ["Wu", "Chien-Sheng", ""], ["Park", "Ji Ho", ""], ["Fung", "Pascale", ""]]}, {"id": "1809.04553", "submitter": "Carlos Busso", "authors": "Fei Tao and Carlos Busso", "title": "End-to-end Audiovisual Speech Activity Detection with Bimodal Recurrent\n  Neural Models", "comments": "Submitted to Speech Communication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech activity detection (SAD) plays an important role in current speech\nprocessing systems, including automatic speech recognition (ASR). SAD is\nparticularly difficult in environments with acoustic noise. A practical\nsolution is to incorporate visual information, increasing the robustness of the\nSAD approach. An audiovisual system has the advantage of being robust to\ndifferent speech modes (e.g., whisper speech) or background noise. Recent\nadvances in audiovisual speech processing using deep learning have opened\nopportunities to capture in a principled way the temporal relationships between\nacoustic and visual features. This study explores this idea proposing a\n\\emph{bimodal recurrent neural network} (BRNN) framework for SAD. The approach\nmodels the temporal dynamic of the sequential audiovisual data, improving the\naccuracy and robustness of the proposed SAD system. Instead of estimating\nhand-crafted features, the study investigates an end-to-end training approach,\nwhere acoustic and visual features are directly learned from the raw data\nduring training. The experimental evaluation considers a large audiovisual\ncorpus with over 60.8 hours of recordings, collected from 105 speakers. The\nresults demonstrate that the proposed framework leads to absolute improvements\nup to 1.2% under practical scenarios over a VAD baseline using only audio\nimplemented with deep neural network (DNN). The proposed approach achieves\n92.7% F1-score when it is evaluated using the sensors from a portable tablet\nunder noisy acoustic environment, which is only 1.0% lower than the performance\nobtained under ideal conditions (e.g., clean speech obtained with a high\ndefinition camera and a close-talking microphone).\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 16:44:46 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Tao", "Fei", ""], ["Busso", "Carlos", ""]]}, {"id": "1809.04556", "submitter": "Parag Jain", "authors": "Parag Jain, Abhijit Mishra, Amar Prakash Azad, Karthik\n  Sankaranarayanan", "title": "Unsupervised Controllable Text Formalization", "comments": "AAAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel framework for controllable natural language\ntransformation. Realizing that the requirement of parallel corpus is\npractically unsustainable for controllable generation tasks, an unsupervised\ntraining scheme is introduced. The crux of the framework is a deep neural\nencoder-decoder that is reinforced with text-transformation knowledge through\nauxiliary modules (called scorers). The scorers, based on off-the-shelf\nlanguage processing tools, decide the learning scheme of the encoder-decoder\nbased on its actions. We apply this framework for the text-transformation task\nof formalizing an input text by improving its readability grade; the degree of\nrequired formalization can be controlled by the user at run-time. Experiments\non public datasets demonstrate the efficacy of our model towards: (a)\ntransforming a given text to a more formal style, and (b) introducing\nappropriate amount of formalness in the output text pertaining to the input\ncontrol. Our code and datasets are released for academic use.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 17:25:46 GMT"}, {"version": "v2", "created": "Fri, 16 Nov 2018 04:01:25 GMT"}, {"version": "v3", "created": "Mon, 19 Nov 2018 05:31:32 GMT"}, {"version": "v4", "created": "Tue, 20 Nov 2018 18:36:38 GMT"}, {"version": "v5", "created": "Sun, 3 Feb 2019 18:58:18 GMT"}, {"version": "v6", "created": "Wed, 20 Feb 2019 15:33:03 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Jain", "Parag", ""], ["Mishra", "Abhijit", ""], ["Azad", "Amar Prakash", ""], ["Sankaranarayanan", "Karthik", ""]]}, {"id": "1809.04557", "submitter": "Anupiya Nugaliyadde Mr", "authors": "W.M.T Chathurika, K.C.E De Silva, A.M. Raddella, E.M.R.S. Ekanayake,\n  A. Nugaliyadde, Y. Mallawarachchi", "title": "Solving Sinhala Language Arithmetic Problems using Neural Networks", "comments": "34th National Information Technology Conference (NITC 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A methodology is presented to solve Arithmetic problems in Sinhala Language\nusing a Neural Network. The system comprises of (a) keyword identification, (b)\nquestion identification, (c) mathematical operation identification and is\ncombined using a neural network. Naive Bayes Classification is used in order to\nidentify keywords and Conditional Random Field to identify the question and the\noperation which should be performed on the identified keywords to achieve the\nexpected result. \"One vs. all Classification\" is done using a neural network\nfor sentences. All functions are combined through the neural network which\nbuilds an equation to solve the problem. The paper compares each methodology in\nARIS and Mahoshadha to the method presented in the paper. Mahoshadha2 learns to\nsolve arithmetic problems with the accuracy of 76%.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 13:29:08 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Chathurika", "W. M. T", ""], ["De Silva", "K. C. E", ""], ["Raddella", "A. M.", ""], ["Ekanayake", "E. M. R. S.", ""], ["Nugaliyadde", "A.", ""], ["Mallawarachchi", "Y.", ""]]}, {"id": "1809.04560", "submitter": "Ramakanth Pasunuru", "authors": "Ramakanth Pasunuru, Mohit Bansal", "title": "Game-Based Video-Context Dialogue", "comments": "EMNLP 2018 (14 pages) (fixed Table5 typo in v2)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current dialogue systems focus more on textual and speech context knowledge\nand are usually based on two speakers. Some recent work has investigated static\nimage-based dialogue. However, several real-world human interactions also\ninvolve dynamic visual context (similar to videos) as well as dialogue\nexchanges among multiple speakers. To move closer towards such multimodal\nconversational skills and visually-situated applications, we introduce a new\nvideo-context, many-speaker dialogue dataset based on live-broadcast soccer\ngame videos and chats from Twitch.tv. This challenging testbed allows us to\ndevelop visually-grounded dialogue models that should generate relevant\ntemporal and spatial event language from the live video, while also being\nrelevant to the chat history. For strong baselines, we also present several\ndiscriminative and generative models, e.g., based on tridirectional attention\nflow (TriDAF). We evaluate these models via retrieval ranking-recall, automatic\nphrase-matching metrics, as well as human evaluation studies. We also present\ndataset analyses, model ablations, and visualizations to understand the\ncontribution of different modalities and model components.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 16:53:13 GMT"}, {"version": "v2", "created": "Wed, 17 Oct 2018 15:26:48 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Pasunuru", "Ramakanth", ""], ["Bansal", "Mohit", ""]]}, {"id": "1809.04585", "submitter": "Yichen Jiang", "authors": "Yichen Jiang, Mohit Bansal", "title": "Closed-Book Training to Improve Summarization Encoder Memory", "comments": "EMNLP 2018 (16 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A good neural sequence-to-sequence summarization model should have a strong\nencoder that can distill and memorize the important information from long input\ntexts so that the decoder can generate salient summaries based on the encoder's\nmemory. In this paper, we aim to improve the memorization capabilities of the\nencoder of a pointer-generator model by adding an additional 'closed-book'\ndecoder without attention and pointer mechanisms. Such a decoder forces the\nencoder to be more selective in the information encoded in its memory state\nbecause the decoder can't rely on the extra information provided by the\nattention and possibly copy modules, and hence improves the entire model. On\nthe CNN/Daily Mail dataset, our 2-decoder model outperforms the baseline\nsignificantly in terms of ROUGE and METEOR metrics, for both cross-entropy and\nreinforced setups (and on human evaluation). Moreover, our model also achieves\nhigher scores in a test-only DUC-2002 generalizability setup. We further\npresent a memory ability test, two saliency metrics, as well as several\nsanity-check ablations (based on fixed-encoder, gradient-flow cut, and model\ncapacity) to prove that the encoder of our 2-decoder model does in fact learn\nstronger memory representations than the baseline encoder.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 17:50:07 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Jiang", "Yichen", ""], ["Bansal", "Mohit", ""]]}, {"id": "1809.04640", "submitter": "Jasmijn Bastings", "authors": "Jasmijn Bastings, Marco Baroni, Jason Weston, Kyunghyun Cho, Douwe\n  Kiela", "title": "Jump to better conclusions: SCAN both left and right", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lake and Baroni (2018) recently introduced the SCAN data set, which consists\nof simple commands paired with action sequences and is intended to test the\nstrong generalization abilities of recurrent sequence-to-sequence models. Their\ninitial experiments suggested that such models may fail because they lack the\nability to extract systematic rules. Here, we take a closer look at SCAN and\nshow that it does not always capture the kind of generalization that it was\ndesigned for. To mitigate this we propose a complementary dataset, which\nrequires mapping actions back to the original commands, called NACS. We show\nthat models that do well on SCAN do not necessarily do well on NACS, and that\nNACS exhibits properties more closely aligned with realistic use-cases for\nsequence-to-sequence models.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 19:18:16 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 19:53:20 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Bastings", "Jasmijn", ""], ["Baroni", "Marco", ""], ["Weston", "Jason", ""], ["Cho", "Kyunghyun", ""], ["Kiela", "Douwe", ""]]}, {"id": "1809.04649", "submitter": "Hao Zhang", "authors": "Hao Zhang and Jie Wang", "title": "Semantic WordRank: Generating Finer Single-Document Summarizations", "comments": "12 pages, accepted by IDEAL2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Semantic WordRank (SWR), an unsupervised method for generating an\nextractive summary of a single document. Built on a weighted word graph with\nsemantic and co-occurrence edges, SWR scores sentences using an\narticle-structure-biased PageRank algorithm with a Softplus function\nadjustment, and promotes topic diversity using spectral subtopic clustering\nunder the Word-Movers-Distance metric. We evaluate SWR on the DUC-02 and\nSummBank datasets and show that SWR produces better summaries than the\nstate-of-the-art algorithms over DUC-02 under common ROUGE measures. We then\nshow that, under the same measures over SummBank, SWR outperforms each of the\nthree human annotators (aka. judges) and compares favorably with the combined\nperformance of all judges.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 19:53:56 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Zhang", "Hao", ""], ["Wang", "Jie", ""]]}, {"id": "1809.04686", "submitter": "Orhan Firat", "authors": "Akiko Eriguchi, Melvin Johnson, Orhan Firat, Hideto Kazawa, Wolfgang\n  Macherey", "title": "Zero-Shot Cross-lingual Classification Using Multilingual Neural Machine\n  Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transferring representations from large supervised tasks to downstream tasks\nhas shown promising results in AI fields such as Computer Vision and Natural\nLanguage Processing (NLP). In parallel, the recent progress in Machine\nTranslation (MT) has enabled one to train multilingual Neural MT (NMT) systems\nthat can translate between multiple languages and are also capable of\nperforming zero-shot translation. However, little attention has been paid to\nleveraging representations learned by a multilingual NMT system to enable\nzero-shot multilinguality in other NLP tasks. In this paper, we demonstrate a\nsimple framework, a multilingual Encoder-Classifier, for cross-lingual transfer\nlearning by reusing the encoder from a multilingual NMT system and stitching it\nwith a task-specific classifier component. Our proposed model achieves\nsignificant improvements in the English setup on three benchmark tasks - Amazon\nReviews, SST and SNLI. Further, our system can perform classification in a new\nlanguage for which no classification data was seen during training, showing\nthat zero-shot classification is possible and remarkably competitive. In order\nto understand the underlying factors contributing to this finding, we conducted\na series of analyses on the effect of the shared vocabulary, the training data\ntype for NMT, classifier complexity, encoder representation power, and model\ngeneralization on zero-shot performance. Our results provide strong evidence\nthat the representations learned from multilingual NMT systems are widely\napplicable across languages and tasks.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 21:34:03 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Eriguchi", "Akiko", ""], ["Johnson", "Melvin", ""], ["Firat", "Orhan", ""], ["Kazawa", "Hideto", ""], ["Macherey", "Wolfgang", ""]]}, {"id": "1809.04698", "submitter": "Yuhao Zhang", "authors": "Yuhao Zhang, Daisy Yi Ding, Tianpei Qian, Christopher D. Manning,\n  Curtis P. Langlotz", "title": "Learning to Summarize Radiology Findings", "comments": "EMNLP 2018 Workshop on Health Text Mining and Information Analysis\n  (EMNLP-LOUHI). Code and pretrained model available at:\n  https://github.com/yuhaozhang/summarize-radiology-findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Impression section of a radiology report summarizes crucial radiology\nfindings in natural language and plays a central role in communicating these\nfindings to physicians. However, the process of generating impressions by\nsummarizing findings is time-consuming for radiologists and prone to errors. We\npropose to automate the generation of radiology impressions with neural\nsequence-to-sequence learning. We further propose a customized neural model for\nthis task which learns to encode the study background information and use this\ninformation to guide the decoding process. On a large dataset of radiology\nreports collected from actual hospital studies, our model outperforms existing\nnon-neural and neural baselines under the ROUGE metrics. In a blind experiment,\na board-certified radiologist indicated that 67% of sampled system summaries\nare at least as good as the corresponding human-written summaries, suggesting\nsignificant clinical validity. To our knowledge our work represents the first\nattempt in this direction.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 22:41:47 GMT"}, {"version": "v2", "created": "Mon, 8 Oct 2018 20:30:20 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Zhang", "Yuhao", ""], ["Ding", "Daisy Yi", ""], ["Qian", "Tianpei", ""], ["Manning", "Christopher D.", ""], ["Langlotz", "Curtis P.", ""]]}, {"id": "1809.04705", "submitter": "Hongteng Xu", "authors": "Hongteng Xu, Wenlin Wang, Wei Liu, Lawrence Carin", "title": "Distilled Wasserstein Learning for Word Embedding and Topic Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel Wasserstein method with a distillation mechanism, yielding\njoint learning of word embeddings and topics. The proposed method is based on\nthe fact that the Euclidean distance between word embeddings may be employed as\nthe underlying distance in the Wasserstein topic model. The word distributions\nof topics, their optimal transports to the word distributions of documents, and\nthe embeddings of words are learned in a unified framework. When learning the\ntopic model, we leverage a distilled underlying distance matrix to update the\ntopic distributions and smoothly calculate the corresponding optimal\ntransports. Such a strategy provides the updating of word embeddings with\nrobust guidance, improving the algorithmic convergence. As an application, we\nfocus on patient admission records, in which the proposed method embeds the\ncodes of diseases and procedures and learns the topics of admissions, obtaining\nsuperior performance on clinically-meaningful disease network construction,\nmortality prediction as a function of admission codes, and procedure\nrecommendation.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 23:10:23 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Xu", "Hongteng", ""], ["Wang", "Wenlin", ""], ["Liu", "Wei", ""], ["Carin", "Lawrence", ""]]}, {"id": "1809.04708", "submitter": "Ikhlas Alhussien", "authors": "Ikhlas Alhussien, Erik Cambria, Zhang NengSheng", "title": "Semantically Enhanced Models for Commonsense Knowledge Acquisition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commonsense knowledge is paramount to enable intelligent systems. Typically,\nit is characterized as being implicit and ambiguous, hindering thereby the\nautomation of its acquisition. To address these challenges, this paper presents\nsemantically enhanced models to enable reasoning through resolving part of\ncommonsense ambiguity. The proposed models enhance in a knowledge graph\nembedding (KGE) framework for knowledge base completion. Experimental results\nshow the effectiveness of the new semantic models in commonsense reasoning.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 23:23:46 GMT"}, {"version": "v2", "created": "Thu, 27 Sep 2018 00:06:53 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Alhussien", "Ikhlas", ""], ["Cambria", "Erik", ""], ["NengSheng", "Zhang", ""]]}, {"id": "1809.04739", "submitter": "Sweta Karlekar", "authors": "Sweta Karlekar, Mohit Bansal", "title": "SafeCity: Understanding Diverse Forms of Sexual Harassment Personal\n  Stories", "comments": "EMNLP 2018 (7 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent rise of #MeToo, an increasing number of personal stories\nabout sexual harassment and sexual abuse have been shared online. In order to\npush forward the fight against such harassment and abuse, we present the task\nof automatically categorizing and analyzing various forms of sexual harassment,\nbased on stories shared on the online forum SafeCity. For the labels of\ngroping, ogling, and commenting, our single-label CNN-RNN model achieves an\naccuracy of 86.5%, and our multi-label model achieves a Hamming score of 82.5%.\nFurthermore, we present analysis using LIME, first-derivative saliency\nheatmaps, activation clustering, and embedding visualization to interpret\nneural model predictions and demonstrate how this extracts features that can\nhelp automatically fill out incident reports, identify unsafe areas, avoid\nunsafe practices, and 'pin the creeps'.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 02:00:23 GMT"}, {"version": "v2", "created": "Fri, 14 Sep 2018 02:01:22 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Karlekar", "Sweta", ""], ["Bansal", "Mohit", ""]]}, {"id": "1809.04838", "submitter": "Taraka Rama Kasicheyanula", "authors": "\\c{C}a\\u{g}r{\\i} \\c{C}\\\"oltekin, Taraka Rama", "title": "T\\\"ubingen-Oslo system: Linear regression works the best at Predicting\n  Current and Future Psychological Health from Childhood Essays in the CLPsych\n  2018 Shared Task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes our efforts in predicting current and future\npsychological health from childhood essays within the scope of the CLPsych-2018\nShared Task. We experimented with a number of different models, including\nrecurrent and convolutional networks, Poisson regression, support vector\nregression, and L1 and L2 regularized linear regression. We obtained the best\nresults on the training/development data with L2 regularized linear regression\n(ridge regression) which also got the best scores on main metrics in the\nofficial testing for task A (predicting psychological health from essays\nwritten at the age of 11 years) and task B (predicting later psychological\nhealth from essays written at the age of 11).\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 08:53:14 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["\u00c7\u00f6ltekin", "\u00c7a\u011fr\u0131", ""], ["Rama", "Taraka", ""]]}, {"id": "1809.04938", "submitter": "Shuming Ma", "authors": "Shuming Ma, Lei Cui, Damai Dai, Furu Wei, Xu Sun", "title": "LiveBot: Generating Live Video Comments Based on Visual and Textual\n  Contexts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the task of automatic live commenting. Live commenting, which is\nalso called `video barrage', is an emerging feature on online video sites that\nallows real-time comments from viewers to fly across the screen like bullets or\nroll at the right side of the screen. The live comments are a mixture of\nopinions for the video and the chit chats with other comments. Automatic live\ncommenting requires AI agents to comprehend the videos and interact with human\nviewers who also make the comments, so it is a good testbed of an AI agent's\nability of dealing with both dynamic vision and language. In this work, we\nconstruct a large-scale live comment dataset with 2,361 videos and 895,929 live\ncomments. Then, we introduce two neural models to generate live comments based\non the visual and textual contexts, which achieve better performance than\nprevious neural baselines such as the sequence-to-sequence model. Finally, we\nprovide a retrieval-based evaluation protocol for automatic live commenting\nwhere the model is asked to sort a set of candidate comments based on the\nlog-likelihood score, and evaluated on metrics such as mean-reciprocal-rank.\nPutting it all together, we demonstrate the first `LiveBot'.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 13:27:52 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 13:08:53 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Ma", "Shuming", ""], ["Cui", "Lei", ""], ["Dai", "Damai", ""], ["Wei", "Furu", ""], ["Sun", "Xu", ""]]}, {"id": "1809.04960", "submitter": "Shuming Ma", "authors": "Shuming Ma, Lei Cui, Furu Wei, Xu Sun", "title": "Unsupervised Machine Commenting with Neural Variational Topic Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Article comments can provide supplementary opinions and facts for readers,\nthereby increase the attraction and engagement of articles. Therefore,\nautomatically commenting is helpful in improving the activeness of the\ncommunity, such as online forums and news websites. Previous work shows that\ntraining an automatic commenting system requires large parallel corpora.\nAlthough part of articles are naturally paired with the comments on some\nwebsites, most articles and comments are unpaired on the Internet. To fully\nexploit the unpaired data, we completely remove the need for parallel data and\npropose a novel unsupervised approach to train an automatic article commenting\nmodel, relying on nothing but unpaired articles and comments. Our model is\nbased on a retrieval-based commenting framework, which uses news to retrieve\ncomments based on the similarity of their topics. The topic representation is\nobtained from a neural variational topic model, which is trained in an\nunsupervised manner. We evaluate our model on a news comment dataset.\nExperiments show that our proposed topic-based approach significantly\noutperforms previous lexicon-based models. The model also profits from paired\ncorpora and achieves state-of-the-art performance under semi-supervised\nscenarios.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 13:48:42 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Ma", "Shuming", ""], ["Cui", "Lei", ""], ["Wei", "Furu", ""], ["Sun", "Xu", ""]]}, {"id": "1809.05053", "submitter": "Alexis Conneau", "authors": "Alexis Conneau, Guillaume Lample, Ruty Rinott, Adina Williams, Samuel\n  R. Bowman, Holger Schwenk, Veselin Stoyanov", "title": "XNLI: Evaluating Cross-lingual Sentence Representations", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art natural language processing systems rely on supervision in\nthe form of annotated data to learn competent models. These models are\ngenerally trained on data in a single language (usually English), and cannot be\ndirectly used beyond that language. Since collecting data in every language is\nnot realistic, there has been a growing interest in cross-lingual language\nunderstanding (XLU) and low-resource cross-language transfer. In this work, we\nconstruct an evaluation set for XLU by extending the development and test sets\nof the Multi-Genre Natural Language Inference Corpus (MultiNLI) to 15\nlanguages, including low-resource languages such as Swahili and Urdu. We hope\nthat our dataset, dubbed XNLI, will catalyze research in cross-lingual sentence\nunderstanding by providing an informative standard evaluation task. In\naddition, we provide several baselines for multilingual sentence understanding,\nincluding two based on machine translation systems, and two that use parallel\ndata to train aligned multilingual bag-of-words and LSTM encoders. We find that\nXNLI represents a practical and challenging evaluation suite, and that directly\ntranslating the test data yields the best performance among available\nbaselines.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 16:39:53 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Conneau", "Alexis", ""], ["Lample", "Guillaume", ""], ["Rinott", "Ruty", ""], ["Williams", "Adina", ""], ["Bowman", "Samuel R.", ""], ["Schwenk", "Holger", ""], ["Stoyanov", "Veselin", ""]]}, {"id": "1809.05054", "submitter": "Tianze Shi", "authors": "Tianze Shi, Kedar Tatwawadi, Kaushik Chakrabarti, Yi Mao, Oleksandr\n  Polozov, Weizhu Chen", "title": "IncSQL: Training Incremental Text-to-SQL Parsers with Non-Deterministic\n  Oracles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a sequence-to-action parsing approach for the natural language to\nSQL task that incrementally fills the slots of a SQL query with feasible\nactions from a pre-defined inventory. To account for the fact that typically\nthere are multiple correct SQL queries with the same or very similar semantics,\nwe draw inspiration from syntactic parsing techniques and propose to train our\nsequence-to-action models with non-deterministic oracles. We evaluate our\nmodels on the WikiSQL dataset and achieve an execution accuracy of 83.7% on the\ntest set, a 2.1% absolute improvement over the models trained with traditional\nstatic oracles assuming a single correct target SQL query. When further\ncombined with the execution-guided decoding strategy, our model sets a new\nstate-of-the-art performance at an execution accuracy of 87.1%.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 16:42:21 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 17:55:37 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Shi", "Tianze", ""], ["Tatwawadi", "Kedar", ""], ["Chakrabarti", "Kaushik", ""], ["Mao", "Yi", ""], ["Polozov", "Oleksandr", ""], ["Chen", "Weizhu", ""]]}, {"id": "1809.05157", "submitter": "Xiaodong Yu", "authors": "Xiaodong Yu, Stephen Mayhew, Mark Sammons, Dan Roth", "title": "On the Strength of Character Language Models for Multilingual Named\n  Entity Recognition", "comments": "5 pages, EMNLP 2018 short paper", "journal-ref": "EMNLP 2018", "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Character-level patterns have been widely used as features in English Named\nEntity Recognition (NER) systems. However, to date there has been no direct\ninvestigation of the inherent differences between name and non-name tokens in\ntext, nor whether this property holds across multiple languages. This paper\nanalyzes the capabilities of corpus-agnostic Character-level Language Models\n(CLMs) in the binary task of distinguishing name tokens from non-name tokens.\nWe demonstrate that CLMs provide a simple and powerful model for capturing\nthese differences, identifying named entity tokens in a diverse set of\nlanguages at close to the performance of full NER systems. Moreover, by adding\nvery simple CLM-based features we can significantly improve the performance of\nan off-the-shelf NER system for multiple languages.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 20:01:20 GMT"}, {"version": "v2", "created": "Thu, 20 Sep 2018 17:10:03 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Yu", "Xiaodong", ""], ["Mayhew", "Stephen", ""], ["Sammons", "Mark", ""], ["Roth", "Dan", ""]]}, {"id": "1809.05218", "submitter": "Arya McCarthy", "authors": "Brian Thompson, Huda Khayrallah, Antonios Anastasopoulos, Arya D.\n  McCarthy, Kevin Duh, Rebecca Marvin, Paul McNamee, Jeremy Gwinnup, Tim\n  Anderson, and Philipp Koehn", "title": "Freezing Subnetworks to Analyze Domain Adaptation in Neural Machine\n  Translation", "comments": "presented at WMT 2018. Please cite using the bib entry from here:\n  http://www.statmt.org/wmt18/bib/WMT013.bib", "journal-ref": "Proceedings of the Third Conference on Machine Translation:\n  Research Papers (2018) 124-132", "doi": "10.18653/v1/W18-6313", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To better understand the effectiveness of continued training, we analyze the\nmajor components of a neural machine translation system (the encoder, decoder,\nand each embedding space) and consider each component's contribution to, and\ncapacity for, domain adaptation. We find that freezing any single component\nduring continued training has minimal impact on performance, and that\nperformance is surprisingly good when a single component is adapted while\nholding the rest of the model fixed. We also find that continued training does\nnot move the model very far from the out-of-domain model, compared to a\nsensitivity analysis metric, suggesting that the out-of-domain model can\nprovide a good generic initialization for the new domain.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 01:42:21 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 14:36:04 GMT"}, {"version": "v3", "created": "Thu, 20 Dec 2018 18:48:52 GMT"}, {"version": "v4", "created": "Tue, 15 Jan 2019 19:38:47 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Thompson", "Brian", ""], ["Khayrallah", "Huda", ""], ["Anastasopoulos", "Antonios", ""], ["McCarthy", "Arya D.", ""], ["Duh", "Kevin", ""], ["Marvin", "Rebecca", ""], ["McNamee", "Paul", ""], ["Gwinnup", "Jeremy", ""], ["Anderson", "Tim", ""], ["Koehn", "Philipp", ""]]}, {"id": "1809.05219", "submitter": "Vu Tran", "authors": "Vu Tran and Minh Le Nguyen and Ken Satoh", "title": "Automatic Catchphrase Extraction from Legal Case Documents via Scoring\n  using Deep Neural Networks", "comments": "MIning and REasoning with Legal text, MIREL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a method of automatic catchphrase extracting from\nlegal case documents. We utilize deep neural networks for constructing scoring\nmodel of our extraction system. We achieve comparable performance with systems\nusing corpus-wide and citation information which we do not use in our system.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 01:48:46 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Tran", "Vu", ""], ["Nguyen", "Minh Le", ""], ["Satoh", "Ken", ""]]}, {"id": "1809.05233", "submitter": "Raphael Schumann", "authors": "Raphael Schumann", "title": "Unsupervised Abstractive Sentence Summarization using Length Controlled\n  Variational Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present an unsupervised approach to summarize sentences in\nabstractive way using Variational Autoencoder (VAE). VAE are known to learn a\nsemantically rich latent variable, representing high dimensional input. VAEs\nare trained by learning to reconstruct the input from the probabilistic latent\nvariable. Explicitly providing the information about output length during\ntraining influences the VAE to not encode this information and thus can be\nmanipulated during inference. Instructing the decoder to produce a shorter\noutput sequence leads to expressing the input sentence with fewer words. We\nshow on different summarization data sets, that these shorter sentences can not\nbeat a simple baseline but yield higher ROUGE scores than trying to reconstruct\nthe whole sentence.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 02:52:02 GMT"}, {"version": "v2", "created": "Fri, 21 Sep 2018 02:29:30 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Schumann", "Raphael", ""]]}, {"id": "1809.05255", "submitter": "Lingfei Wu", "authors": "Kun Xu, Lingfei Wu, Zhiguo Wang, Yansong Feng, Vadim Sheinin", "title": "SQL-to-Text Generation with Graph-to-Sequence Model", "comments": "EMNLP18, Accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work approaches the SQL-to-text generation task using vanilla\nSeq2Seq models, which may not fully capture the inherent graph-structured\ninformation in SQL query. In this paper, we first introduce a strategy to\nrepresent the SQL query as a directed graph and then employ a graph-to-sequence\nmodel to encode the global structure information into node embeddings. This\nmodel can effectively learn the correlation between the SQL query pattern and\nits interpretation. Experimental results on the WikiSQL dataset and\nStackoverflow dataset show that our model significantly outperforms the Seq2Seq\nand Tree2Seq baselines, achieving the state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 05:00:40 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 22:32:16 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Xu", "Kun", ""], ["Wu", "Lingfei", ""], ["Wang", "Zhiguo", ""], ["Feng", "Yansong", ""], ["Sheinin", "Vadim", ""]]}, {"id": "1809.05268", "submitter": "Diego Molla-Aliod", "authors": "Mandeep Kaur and Diego Moll\\'a", "title": "Supervised Machine Learning for Extractive Query Based Summarisation of\n  Biomedical Data", "comments": "9 pages, 7 figures, published at Louhi 2018 with acknowledgments\n  section", "journal-ref": "Proceedings of the Ninth International Workshop on Health Text\n  Mining and Information Analysis, Louhi 2018", "doi": null, "report-no": "W18-5604", "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automation of text summarisation of biomedical publications is a pressing\nneed due to the plethora of information available on-line. This paper explores\nthe impact of several supervised machine learning approaches for extracting\nmulti-document summaries for given queries. In particular, we compare\nclassification and regression approaches for query-based extractive\nsummarisation using data provided by the BioASQ Challenge. We tackled the\nproblem of annotating sentences for training classification systems and show\nthat a simple annotation approach outperforms regression-based summarisation.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 06:27:38 GMT"}, {"version": "v2", "created": "Thu, 6 Dec 2018 06:38:57 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Kaur", "Mandeep", ""], ["Moll\u00e1", "Diego", ""]]}, {"id": "1809.05275", "submitter": "Ravindra Guntur", "authors": "Kumar Mrityunjay and Guntur Ravindra", "title": "Learning to Fingerprint the Latent Structure in Question Articulation", "comments": "Pre-Print, ACCEPTED FOR PRESENTATION AT the 17th IEEE INTERNATIONAL\n  CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA2018)", "journal-ref": null, "doi": "10.1109/ICMLA.2018.00019", "report-no": null, "categories": "cs.AI cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstract Machine understanding of questions is tightly related to recognition\nof articulation in the context of the computational capabilities of an\nunderlying processing algorithm. In this paper a mathematical model to capture\nand distinguish the latent structure in the articulation of questions is\npresented. We propose an objective-driven approach to represent this latent\nstructure and show that such an approach is beneficial when examples of\ncomplementary objectives are not available. We show that the latent structure\ncan be represented as a system that maximizes a cost function related to the\nunderlying objective. Further, we show that the optimization formulation can be\napproximated to building a memory of patterns represented as a trained neural\nauto-encoder. Experimental evaluation using many clusters of questions, each\nrelated to an objective, shows 80% recognition accuracy and negligible false\npositive across these clusters of questions. We then extend the same memory to\na related task where the goal is to iteratively refine a dataset of questions\nbased on the latent articulation. We also demonstrate a refinement scheme\ncalled K-fingerprints, that achieves nearly 100% recognition with negligible\nfalse positive across the different clusters of questions.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 06:51:01 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Mrityunjay", "Kumar", ""], ["Ravindra", "Guntur", ""]]}, {"id": "1809.05283", "submitter": "Diego Molla-Aliod", "authors": "Diego Moll\\'a", "title": "Macquarie University at BioASQ 6b: Deep learning and deep reinforcement\n  learning for query-based multi-document summarisation", "comments": "8 pages, 8 figures, 3 tables. Published in BioASQ workshop, EMNLP\n  2018. Typos fixed and acknowledgments added", "journal-ref": "Proceedings of the 6th BioASQ Workshop A challenge on large-scale\n  biomedical semantic indexing and question answering, EMNLP 2018", "doi": null, "report-no": "W18-5303", "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes Macquarie University's contribution to the BioASQ\nChallenge (BioASQ 6b, Phase B). We focused on the extraction of the ideal\nanswers, and the task was approached as an instance of query-based\nmulti-document summarisation. In particular, this paper focuses on the\nexperiments related to the deep learning and reinforcement learning approaches\nused in the submitted runs. The best run used a deep learning model under a\nregression-based framework. The deep learning architecture used features\nderived from the output of LSTM chains on word embeddings, plus features based\non similarity with the query, and sentence position. The reinforcement learning\napproach was a proof-of-concept prototype that trained a global policy using\nREINFORCE. The global policy was implemented as a neural network that used\n$tf.idf$ features encoding the candidate sentence, question, and context.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 07:26:31 GMT"}, {"version": "v2", "created": "Thu, 6 Dec 2018 07:00:23 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Moll\u00e1", "Diego", ""]]}, {"id": "1809.05288", "submitter": "Juraj Juraska", "authors": "Juraj Juraska and Marilyn Walker", "title": "Characterizing Variation in Crowd-Sourced Data for Training Neural\n  Language Generators to Produce Stylistically Varied Outputs", "comments": "Accepted to INLG 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the biggest challenges of end-to-end language generation from meaning\nrepresentations in dialogue systems is making the outputs more natural and\nvaried. Here we take a large corpus of 50K crowd-sourced utterances in the\nrestaurant domain and develop text analysis methods that systematically\ncharacterize types of sentences in the training data. We then automatically\nlabel the training data to allow us to conduct two kinds of experiments with a\nneural generator. First, we test the effect of training the system with\ndifferent stylistic partitions and quantify the effect of smaller, but more\nstylistically controlled training data. Second, we propose a method of labeling\nthe style variants during training, and show that we can modify the style of\nthe generated utterances using our stylistic labels. We contrast and compare\nthese methods that can be used with any existing large corpus, showing how they\nvary in terms of semantic quality and stylistic control.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 07:51:19 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Juraska", "Juraj", ""], ["Walker", "Marilyn", ""]]}, {"id": "1809.05296", "submitter": "Deng Cai", "authors": "Deng Cai, Yan Wang, Victoria Bi, Zhaopeng Tu, Xiaojiang Liu, Wai Lam,\n  Shuming Shi", "title": "Skeleton-to-Response: Dialogue Generation Guided by Retrieval Memory", "comments": "accepted to NAACL2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For dialogue response generation, traditional generative models generate\nresponses solely from input queries. Such models rely on insufficient\ninformation for generating a specific response since a certain query could be\nanswered in multiple ways. Consequentially, those models tend to output generic\nand dull responses, impeding the generation of informative utterances.\nRecently, researchers have attempted to fill the information gap by exploiting\ninformation retrieval techniques. When generating a response for a current\nquery, similar dialogues retrieved from the entire training data are considered\nas an additional knowledge source. While this may harvest massive information,\nthe generative models could be overwhelmed, leading to undesirable performance.\nIn this paper, we propose a new framework which exploits retrieval results via\na skeleton-then-response paradigm. At first, a skeleton is generated by\nrevising the retrieved responses. Then, a novel generative model uses both the\ngenerated skeleton and the original query for response generation. Experimental\nresults show that our approaches significantly improve the diversity and\ninformativeness of the generated responses.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 08:07:54 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2018 03:12:57 GMT"}, {"version": "v3", "created": "Fri, 1 Mar 2019 07:14:04 GMT"}, {"version": "v4", "created": "Mon, 4 Mar 2019 02:42:23 GMT"}, {"version": "v5", "created": "Fri, 28 Feb 2020 14:00:58 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Cai", "Deng", ""], ["Wang", "Yan", ""], ["Bi", "Victoria", ""], ["Tu", "Zhaopeng", ""], ["Liu", "Xiaojiang", ""], ["Lam", "Wai", ""], ["Shi", "Shuming", ""]]}, {"id": "1809.05356", "submitter": "Chung-Chi Chen", "authors": "Chung-Chi Chen, Hen-Hsen Huang, Yow-Ting Shiue, Hsin-Hsi Chen", "title": "Numeral Understanding in Financial Tweets for Fine-grained Crowd-based\n  Forecasting", "comments": "Accepted by the 2018 IEEE/WIC/ACM International Conference on Web\n  Intelligence (WI 2018), Santiago, Chile", "journal-ref": null, "doi": "10.1109/WI.2018.00-97", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerals that contain much information in financial documents are crucial for\nfinancial decision making. They play different roles in financial analysis\nprocesses. This paper is aimed at understanding the meanings of numerals in\nfinancial tweets for fine-grained crowd-based forecasting. We propose a\ntaxonomy that classifies the numerals in financial tweets into 7 categories,\nand further extend some of these categories into several subcategories. Neural\nnetwork-based models with word and character-level encoders are proposed for\n7-way classification and 17-way classification. We perform backtest to confirm\nthe effectiveness of the numeric opinions made by the crowd. This work is the\nfirst attempt to understand numerals in financial social media data, and we\nprovide the first comparison of fine-grained opinion of individual investors\nand analysts based on their forecast price. The numeral corpus used in our\nexperiments, called FinNum 1.0 , is available for research purposes.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 11:11:37 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2018 18:32:41 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Chen", "Chung-Chi", ""], ["Huang", "Hen-Hsen", ""], ["Shiue", "Yow-Ting", ""], ["Chen", "Hsin-Hsi", ""]]}, {"id": "1809.05501", "submitter": "Uwe Springmann", "authors": "Uwe Springmann, Christian Reul, Stefanie Dipper, Johannes Baiter", "title": "Ground Truth for training OCR engines on historical documents in German\n  Fraktur and Early Modern Latin", "comments": "Submitted to JLCL Volume 33 (2018), Issue 1: Special Issue on\n  Automatic Text and Layout Recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper we describe a dataset of German and Latin \\textit{ground truth}\n(GT) for historical OCR in the form of printed text line images paired with\ntheir transcription. This dataset, called \\textit{GT4HistOCR}, consists of\n313,173 line pairs covering a wide period of printing dates from incunabula\nfrom the 15th century to 19th century books printed in Fraktur types and is\nopenly available under a CC-BY 4.0 license. The special form of GT as line\nimage/transcription pairs makes it directly usable to train state-of-the-art\nrecognition models for OCR software employing recurring neural networks in LSTM\narchitecture such as Tesseract 4 or OCRopus. We also provide some pretrained\nOCRopus models for subcorpora of our dataset yielding between 95\\% (early\nprintings) and 98\\% (19th century Fraktur printings) character accuracy rates\non unseen test cases, a Perl script to harmonize GT produced by different\ntranscription rules, and give hints on how to construct GT for OCR purposes\nwhich has requirements that may differ from linguistically motivated\ntranscriptions.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 16:52:12 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Springmann", "Uwe", ""], ["Reul", "Christian", ""], ["Dipper", "Stefanie", ""], ["Baiter", "Johannes", ""]]}, {"id": "1809.05524", "submitter": "Prasanna Parthasarathi", "authors": "Prasanna Parthasarathi and Joelle Pineau", "title": "Extending Neural Generative Conversational Model using External\n  Knowledge Sources", "comments": "Accepted in EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of connectionist approaches in conversational agents has been\nprogressing rapidly due to the availability of large corpora. However current\ngenerative dialogue models often lack coherence and are content poor. This work\nproposes an architecture to incorporate unstructured knowledge sources to\nenhance the next utterance prediction in chit-chat type of generative dialogue\nmodels. We focus on Sequence-to-Sequence (Seq2Seq) conversational agents\ntrained with the Reddit News dataset, and consider incorporating external\nknowledge from Wikipedia summaries as well as from the NELL knowledge base. Our\nexperiments show faster training time and improved perplexity when leveraging\nexternal knowledge.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 17:53:53 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Parthasarathi", "Prasanna", ""], ["Pineau", "Joelle", ""]]}, {"id": "1809.05576", "submitter": "Ryan Gabbard", "authors": "Ryan Gabbard, Jay DeYoung, and Marjorie Freedman", "title": "Events Beyond ACE: Curated Training for Events", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We explore a human-driven approach to annotation, curated training (CT), in\nwhich annotation is framed as teaching the system by using interactive search\nto identify informative snippets of text to annotate, unlike traditional\napproaches which either annotate preselected text or use active learning. A\ntrained annotator performed 80 hours of CT for the thirty event types of the\nNIST TAC KBP Event Argument Extraction evaluation. Combining this annotation\nwith ACE results in a 6% reduction in error and the learning curve of CT\nplateaus more slowly than for full-document annotation. 3 NLP researchers\nperformed CT for one event type and showed much sharper learning curves with\nall three exceeding ACE performance in less than ninety minutes, suggesting\nthat CT can provide further benefits when the annotator deeply understands the\nsystem.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 20:37:38 GMT"}, {"version": "v2", "created": "Mon, 24 Sep 2018 13:24:38 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Gabbard", "Ryan", ""], ["DeYoung", "Jay", ""], ["Freedman", "Marjorie", ""]]}, {"id": "1809.05636", "submitter": "Yingjie Hu", "authors": "Yingjie Hu", "title": "Geo-Text Data and Data-Driven Geospatial Semantics", "comments": "Geography Compass, 2018", "journal-ref": null, "doi": "10.1111/gec3.12404", "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many datasets nowadays contain links between geographic locations and natural\nlanguage texts. These links can be geotags, such as geotagged tweets or\ngeotagged Wikipedia pages, in which location coordinates are explicitly\nattached to texts. These links can also be place mentions, such as those in\nnews articles, travel blogs, or historical archives, in which texts are\nimplicitly connected to the mentioned places. This kind of data is referred to\nas geo-text data. The availability of large amounts of geo-text data brings\nboth challenges and opportunities. On the one hand, it is challenging to\nautomatically process this kind of data due to the unstructured texts and the\ncomplex spatial footprints of some places. On the other hand, geo-text data\noffers unique research opportunities through the rich information contained in\ntexts and the special links between texts and geography. As a result, geo-text\ndata facilitates various studies especially those in data-driven geospatial\nsemantics. This paper discusses geo-text data and related concepts. With a\nfocus on data-driven research, this paper systematically reviews a large number\nof studies that have discovered multiple types of knowledge from geo-text data.\nBased on the literature review, a generalized workflow is extracted and key\nchallenges for future work are discussed.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 02:54:34 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Hu", "Yingjie", ""]]}, {"id": "1809.05679", "submitter": "Liang Yao", "authors": "Liang Yao, Chengsheng Mao, Yuan Luo", "title": "Graph Convolutional Networks for Text Classification", "comments": "Accepted by 33rd AAAI Conference on Artificial Intelligence (AAAI\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text classification is an important and classical problem in natural language\nprocessing. There have been a number of studies that applied convolutional\nneural networks (convolution on regular grid, e.g., sequence) to\nclassification. However, only a limited number of studies have explored the\nmore flexible graph convolutional neural networks (convolution on non-grid,\ne.g., arbitrary graph) for the task. In this work, we propose to use graph\nconvolutional networks for text classification. We build a single text graph\nfor a corpus based on word co-occurrence and document word relations, then\nlearn a Text Graph Convolutional Network (Text GCN) for the corpus. Our Text\nGCN is initialized with one-hot representation for word and document, it then\njointly learns the embeddings for both words and documents, as supervised by\nthe known class labels for documents. Our experimental results on multiple\nbenchmark datasets demonstrate that a vanilla Text GCN without any external\nword embeddings or knowledge outperforms state-of-the-art methods for text\nclassification. On the other hand, Text GCN also learns predictive word and\ndocument embeddings. In addition, experimental results show that the\nimprovement of Text GCN over state-of-the-art comparison methods become more\nprominent as we lower the percentage of training data, suggesting the\nrobustness of Text GCN to less training data in text classification.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 09:13:12 GMT"}, {"version": "v2", "created": "Wed, 17 Oct 2018 10:06:08 GMT"}, {"version": "v3", "created": "Tue, 13 Nov 2018 05:23:40 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Yao", "Liang", ""], ["Mao", "Chengsheng", ""], ["Luo", "Yuan", ""]]}, {"id": "1809.05694", "submitter": "Ta-Chung Chi", "authors": "Ta-Chung Chi and Yun-Nung Chen", "title": "CLUSE: Cross-Lingual Unsupervised Sense Embeddings", "comments": "11 pages, accepted by EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a modularized sense induction and representation learning\nmodel that jointly learns bilingual sense embeddings that align well in the\nvector space, where the cross-lingual signal in the English-Chinese parallel\ncorpus is exploited to capture the collocation and distributed characteristics\nin the language pair. The model is evaluated on the Stanford Contextual Word\nSimilarity (SCWS) dataset to ensure the quality of monolingual sense\nembeddings. In addition, we introduce Bilingual Contextual Word Similarity\n(BCWS), a large and high-quality dataset for evaluating cross-lingual sense\nembeddings, which is the first attempt of measuring whether the learned\nembeddings are indeed aligned well in the vector space. The proposed approach\nshows the superior quality of sense embeddings evaluated in both monolingual\nand bilingual spaces.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 10:42:41 GMT"}, {"version": "v2", "created": "Sun, 21 Oct 2018 14:05:54 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Chi", "Ta-Chung", ""], ["Chen", "Yun-Nung", ""]]}, {"id": "1809.05715", "submitter": "Chih-Wen Goo", "authors": "Chih-Wen Goo and Yun-Nung Chen", "title": "Abstractive Dialogue Summarization with Sentence-Gated Modeling\n  Optimized by Dialogue Acts", "comments": "8 pages, accepted by SLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural abstractive summarization has been increasingly studied, where the\nprior work mainly focused on summarizing single-speaker documents (news,\nscientific publications, etc). In dialogues, there are different interactions\nbetween speakers, which are usually defined as dialogue acts. The interactive\nsignals may provide informative cues for better summarizing dialogues. This\npaper proposes to explicitly leverage dialogue acts in a neural summarization\nmodel, where a sentence-gated mechanism is designed for modeling the\nrelationship between dialogue acts and the summary. The experiments show that\nour proposed model significantly improves the abstractive summarization\nperformance compared to the state-of-the-art baselines on AMI meeting corpus,\ndemonstrating the usefulness of the interactive signal provided by dialogue\nacts.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 13:30:03 GMT"}, {"version": "v2", "created": "Sat, 29 Sep 2018 13:40:59 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Goo", "Chih-Wen", ""], ["Chen", "Yun-Nung", ""]]}, {"id": "1809.05724", "submitter": "Pavan Kapanipathi", "authors": "Xiaoyan Wang, Pavan Kapanipathi, Ryan Musa, Mo Yu, Kartik\n  Talamadupula, Ibrahim Abdelaziz, Maria Chang, Achille Fokoue, Bassem Makni,\n  Nicholas Mattei, Michael Witbrock", "title": "Improving Natural Language Inference Using External Knowledge in the\n  Science Questions Domain", "comments": "9 pages, 3 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural Language Inference (NLI) is fundamental to many Natural Language\nProcessing (NLP) applications including semantic search and question answering.\nThe NLI problem has gained significant attention thanks to the release of large\nscale, challenging datasets. Present approaches to the problem largely focus on\nlearning-based methods that use only textual information in order to classify\nwhether a given premise entails, contradicts, or is neutral with respect to a\ngiven hypothesis. Surprisingly, the use of methods based on structured\nknowledge -- a central topic in artificial intelligence -- has not received\nmuch attention vis-a-vis the NLI problem. While there are many open knowledge\nbases that contain various types of reasoning information, their use for NLI\nhas not been well explored. To address this, we present a combination of\ntechniques that harness knowledge graphs to improve performance on the NLI\nproblem in the science questions domain. We present the results of applying our\ntechniques on text, graph, and text-to-graph based models, and discuss\nimplications for the use of external knowledge in solving the NLI problem. Our\nmodel achieves the new state-of-the-art performance on the NLI problem over the\nSciTail science questions dataset.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 14:37:46 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 15:50:33 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Wang", "Xiaoyan", ""], ["Kapanipathi", "Pavan", ""], ["Musa", "Ryan", ""], ["Yu", "Mo", ""], ["Talamadupula", "Kartik", ""], ["Abdelaziz", "Ibrahim", ""], ["Chang", "Maria", ""], ["Fokoue", "Achille", ""], ["Makni", "Bassem", ""], ["Mattei", "Nicholas", ""], ["Witbrock", "Michael", ""]]}, {"id": "1809.05726", "submitter": "Nicholas Mattei", "authors": "Ryan Musa, Xiaoyan Wang, Achille Fokoue, Nicholas Mattei, Maria Chang,\n  Pavan Kapanipathi, Bassem Makni, Kartik Talamadupula, Michael Witbrock", "title": "Answering Science Exam Questions Using Query Rewriting with Background\n  Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open-domain question answering (QA) is an important problem in AI and NLP\nthat is emerging as a bellwether for progress on the generalizability of AI\nmethods and techniques. Much of the progress in open-domain QA systems has been\nrealized through advances in information retrieval methods and corpus\nconstruction. In this paper, we focus on the recently introduced ARC Challenge\ndataset, which contains 2,590 multiple choice questions authored for\ngrade-school science exams. These questions are selected to be the most\nchallenging for current QA systems, and current state of the art performance is\nonly slightly better than random chance. We present a system that rewrites a\ngiven question into queries that are used to retrieve supporting text from a\nlarge corpus of science-related text. Our rewriter is able to incorporate\nbackground knowledge from ConceptNet and -- in tandem with a generic textual\nentailment system trained on SciTail that identifies support in the retrieved\nresults -- outperforms several strong baselines on the end-to-end QA task\ndespite only being trained to identify essential terms in the original source\nquestion. We use a generalizable decision methodology over the retrieved\nevidence and answer candidates to select the best answer. By combining query\nrewriting, background knowledge, and textual entailment our system is able to\noutperform several strong baselines on the ARC dataset.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 14:49:23 GMT"}, {"version": "v2", "created": "Sat, 6 Apr 2019 02:03:14 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Musa", "Ryan", ""], ["Wang", "Xiaoyan", ""], ["Fokoue", "Achille", ""], ["Mattei", "Nicholas", ""], ["Chang", "Maria", ""], ["Kapanipathi", "Pavan", ""], ["Makni", "Bassem", ""], ["Talamadupula", "Kartik", ""], ["Witbrock", "Michael", ""]]}, {"id": "1809.05733", "submitter": "Melanie Tosik", "authors": "Vishwali Mhasawade and Ildik\\'o Emese Szab\\'o and Melanie Tosik and\n  Sheng-Fu Wang", "title": "Neural Networks and Quantifier Conservativity: Does Data Distribution\n  Affect Learnability?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  All known natural language determiners are conservative. Psycholinguistic\nexperiments indicate that children exhibit a corresponding learnability bias\nwhen faced with the task of learning new determiners. However, recent work\nindicates that this bias towards conservativity is not observed during the\ntraining stage of artificial neural networks. In this work, we investigate\nwhether the learnability bias exhibited by children is in part due to the\ndistribution of quantifiers in natural language. We share results of five\nexperiments, contrasted by the distribution of conservative vs.\nnon-conservative determiners in the training data. We demonstrate that the\naquisitional issues with non-conservative quantifiers can not be explained by\nthe distribution of natural language data, which favors conservative\nquantifiers. This finding indicates that the bias in language acquisition data\nmight be innate or representational.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 15:44:54 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Mhasawade", "Vishwali", ""], ["Szab\u00f3", "Ildik\u00f3 Emese", ""], ["Tosik", "Melanie", ""], ["Wang", "Sheng-Fu", ""]]}, {"id": "1809.05742", "submitter": "Arne K\\\"ohn", "authors": "Fynn Schr\\\"oder and Marcel Kamlot and Gregor Billing and Arne K\\\"ohn", "title": "Finding the way from \\\"a to a: Sub-character morphological inflection\n  for the SIGMORPHON 2018 Shared Task", "comments": "CoNLL--SIGMORPHON 2018 Shared Task system description paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we describe the system submitted by UHH to the\nCoNLL--SIGMORPHON 2018 Shared Task: Universal Morphological Reinflection. We\npropose a neural architecture based on the concepts of UZH (Makarov et al.,\n2017), adding new ideas and techniques to their key concept and evaluating\ndifferent combinations of parameters. The resulting system is a\nlanguage-agnostic network model that aims to reduce the number of learned edit\noperations by introducing equivalence classes over graphical features of\nindividual characters. We try to pinpoint advantages and drawbacks of this\napproach by comparing different network configurations and evaluating our\nresults over a wide range of languages.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 16:42:24 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Schr\u00f6der", "Fynn", ""], ["Kamlot", "Marcel", ""], ["Billing", "Gregor", ""], ["K\u00f6hn", "Arne", ""]]}, {"id": "1809.05752", "submitter": "Eben Holderness", "authors": "Eben Holderness, Nicholas Miller, Philip Cawkwell, Kirsten Bolton,\n  James Pustejovsky, Marie Meteer and Mei-Hua Hall", "title": "Analysis of Risk Factor Domains in Psychosis Patient Health Records", "comments": "Accepted at EMNLP-LOUHI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Readmission after discharge from a hospital is disruptive and costly,\nregardless of the reason. However, it can be particularly problematic for\npsychiatric patients, so predicting which patients may be readmitted is\ncritically important but also very difficult. Clinical narratives in\npsychiatric electronic health records (EHRs) span a wide range of topics and\nvocabulary; therefore, a psychiatric readmission prediction model must begin\nwith a robust and interpretable topic extraction component. We created a data\npipeline for using document vector similarity metrics to perform topic\nextraction on psychiatric EHR data in service of our long-term goal of creating\na readmission risk classifier. We show initial results for our topic extraction\nmodel and identify additional features we will be incorporating in the future.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 18:27:59 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Holderness", "Eben", ""], ["Miller", "Nicholas", ""], ["Cawkwell", "Philip", ""], ["Bolton", "Kirsten", ""], ["Pustejovsky", "James", ""], ["Meteer", "Marie", ""], ["Hall", "Mei-Hua", ""]]}, {"id": "1809.05807", "submitter": "Mingyu Ma", "authors": "Yunfei Long, Mingyu Ma, Qin Lu, Rong Xiang and Chu-Ren Huang", "title": "Dual Memory Network Model for Biased Product Review Classification", "comments": "To appear in 2018 EMNLP 9th Workshop on Computational Approaches to\n  Subjectivity, Sentiment and Social Media Analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In sentiment analysis (SA) of product reviews, both user and product\ninformation are proven to be useful. Current tasks handle user profile and\nproduct information in a unified model which may not be able to learn salient\nfeatures of users and products effectively. In this work, we propose a dual\nuser and product memory network (DUPMN) model to learn user profiles and\nproduct reviews using separate memory networks. Then, the two representations\nare used jointly for sentiment prediction. The use of separate models aims to\ncapture user profiles and product information more effectively. Compared to\nstate-of-the-art unified prediction models, the evaluations on three benchmark\ndatasets, IMDB, Yelp13, and Yelp14, show that our dual learning model gives\nperformance gain of 0.6%, 1.2%, and 0.9%, respectively. The improvements are\nalso deemed very significant measured by p-values.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 03:56:21 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Long", "Yunfei", ""], ["Ma", "Mingyu", ""], ["Lu", "Qin", ""], ["Xiang", "Rong", ""], ["Huang", "Chu-Ren", ""]]}, {"id": "1809.05814", "submitter": "Boyi Yang", "authors": "Boyi Yang, Adam Wright", "title": "Development of deep learning algorithms to categorize free-text notes\n  pertaining to diabetes: convolution neural networks achieve higher accuracy\n  than support vector machines", "comments": "9 pages, 4 figures, submitted to Journal of the American Medical\n  Informatics Association (JAMIA) on September 15th, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Health professionals can use natural language processing (NLP) technologies\nwhen reviewing electronic health records (EHR). Machine learning free-text\nclassifiers can help them identify problems and make critical decisions. We aim\nto develop deep learning neural network algorithms that identify EHR progress\nnotes pertaining to diabetes and validate the algorithms at two institutions.\nThe data used are 2,000 EHR progress notes retrieved from patients with\ndiabetes and all notes were annotated manually as diabetic or non-diabetic.\nSeveral deep learning classifiers were developed, and their performances were\nevaluated with the area under the ROC curve (AUC). The convolutional neural\nnetwork (CNN) model with a separable convolution layer accurately identified\ndiabetes-related notes in the Brigham and Womens Hospital testing set with the\nhighest AUC of 0.975. Deep learning classifiers can be used to identify EHR\nprogress notes pertaining to diabetes. In particular, the CNN-based classifier\ncan achieve a higher AUC than an SVM-based classifier.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 04:21:38 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Yang", "Boyi", ""], ["Wright", "Adam", ""]]}, {"id": "1809.05820", "submitter": "Baoyu Jing", "authors": "Baoyu Jing, Chenwei Lu, Deqing Wang, Fuzhen Zhuang, Cheng Niu", "title": "Cross-Domain Labeled LDA for Cross-Domain Text Classification", "comments": "ICDM 2018", "journal-ref": null, "doi": "10.1109/ICDM.2018.00034", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-domain text classification aims at building a classifier for a target\ndomain which leverages data from both source and target domain. One promising\nidea is to minimize the feature distribution differences of the two domains.\nMost existing studies explicitly minimize such differences by an exact\nalignment mechanism (aligning features by one-to-one feature alignment,\nprojection matrix etc.). Such exact alignment, however, will restrict models'\nlearning ability and will further impair models' performance on classification\ntasks when the semantic distributions of different domains are very different.\nTo address this problem, we propose a novel group alignment which aligns the\nsemantics at group level. In addition, to help the model learn better semantic\ngroups and semantics within these groups, we also propose a partial supervision\nfor model's learning in source domain. To this end, we embed the group\nalignment and a partial supervision into a cross-domain topic model, and\npropose a Cross-Domain Labeled LDA (CDL-LDA). On the standard 20Newsgroup and\nReuters dataset, extensive quantitative (classification, perplexity etc.) and\nqualitative (topic detection) experiments are conducted to show the\neffectiveness of the proposed group alignment and partial supervision.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 06:02:37 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Jing", "Baoyu", ""], ["Lu", "Chenwei", ""], ["Wang", "Deqing", ""], ["Zhuang", "Fuzhen", ""], ["Niu", "Cheng", ""]]}, {"id": "1809.05886", "submitter": "James O' Neill", "authors": "James O' Neill and Danushka Bollegala", "title": "Meta-Embedding as Auxiliary Task Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Word embeddings have been shown to benefit from ensambling several word\nembedding sources, often carried out using straightforward mathematical\noperations over the set of word vectors. More recently, self-supervised\nlearning has been used to find a lower-dimensional representation, similar in\nsize to the individual word embeddings within the ensemble. However, these\nmethods do not use the available manually labeled datasets that are often used\nsolely for the purpose of evaluation. We propose to reconstruct an ensemble of\nword embeddings as an auxiliary task that regularises a main task while both\ntasks share the learned meta-embedding layer. We carry out intrinsic evaluation\n(6 word similarity datasets and 3 analogy datasets) and extrinsic evaluation (4\ndownstream tasks). For intrinsic task evaluation, supervision comes from\nvarious labeled word similarity datasets. Our experimental results show that\nthe performance is improved for all word similarity datasets when compared to\nself-supervised learning methods with a mean increase of $11.33$ in Spearman\ncorrelation. Specifically, the proposed method shows the best performance in 4\nout of 6 of word similarity datasets when using a cosine reconstruction loss\nand Brier's word similarity loss. Moreover, improvements are also made when\nperforming word meta-embedding reconstruction in sequence tagging and sentence\nmeta-embedding for sentence classification.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 14:36:54 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 18:57:14 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Neill", "James O'", ""], ["Bollegala", "Danushka", ""]]}, {"id": "1809.05916", "submitter": "James O' Neill", "authors": "James O' Neill and Danushka Bollegala", "title": "Curriculum-Based Neighborhood Sampling For Sequence Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The task of multi-step ahead prediction in language models is challenging\nconsidering the discrepancy between training and testing. At test time, a\nlanguage model is required to make predictions given past predictions as input,\ninstead of the past targets that are provided during training. This difference,\nknown as exposure bias, can lead to the compounding of errors along a generated\nsequence at test time.\n  In order to improve generalization in neural language models and address\ncompounding errors, we propose a curriculum learning based method that\ngradually changes an initially deterministic teacher policy to a gradually more\nstochastic policy, which we refer to as \\textit{Nearest-Neighbor Replacement\nSampling}. A chosen input at a given timestep is replaced with a sampled\nnearest neighbor of the past target with a truncated probability proportional\nto the cosine similarity between the original word and its top $k$ most similar\nwords. This allows the teacher to explore alternatives when the teacher\nprovides a sub-optimal policy or when the initial policy is difficult for the\nlearner to model. The proposed strategy is straightforward, online and requires\nlittle additional memory requirements. We report our main findings on two\nlanguage modelling benchmarks and find that the proposed approach performs\nparticularly well when used in conjunction with scheduled sampling, that too\nattempts to mitigate compounding errors in language models.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 17:17:56 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Neill", "James O'", ""], ["Bollegala", "Danushka", ""]]}, {"id": "1809.05972", "submitter": "Yizhe Zhang", "authors": "Yizhe Zhang, Michel Galley, Jianfeng Gao, Zhe Gan, Xiujun Li, Chris\n  Brockett, Bill Dolan", "title": "Generating Informative and Diverse Conversational Responses via\n  Adversarial Information Maximization", "comments": "NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Responses generated by neural conversational models tend to lack\ninformativeness and diversity. We present Adversarial Information Maximization\n(AIM), an adversarial learning strategy that addresses these two related but\ndistinct problems. To foster response diversity, we leverage adversarial\ntraining that allows distributional matching of synthetic and real responses.\nTo improve informativeness, our framework explicitly optimizes a variational\nlower bound on pairwise mutual information between query and response.\nEmpirical results from automatic and human evaluations demonstrate that our\nmethods significantly boost informativeness and diversity.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 22:45:51 GMT"}, {"version": "v2", "created": "Tue, 25 Sep 2018 03:01:19 GMT"}, {"version": "v3", "created": "Fri, 26 Oct 2018 21:13:43 GMT"}, {"version": "v4", "created": "Sat, 3 Nov 2018 22:23:24 GMT"}, {"version": "v5", "created": "Tue, 6 Nov 2018 19:53:52 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Zhang", "Yizhe", ""], ["Galley", "Michel", ""], ["Gao", "Jianfeng", ""], ["Gan", "Zhe", ""], ["Li", "Xiujun", ""], ["Brockett", "Chris", ""], ["Dolan", "Bill", ""]]}, {"id": "1809.06004", "submitter": "Hu Xu", "authors": "Hu Xu, Bing Liu, Lei Shu, P. Yu", "title": "Open-world Learning and Application to Product Classification", "comments": "accepted by The Web Conference (WWW 2019) Previous title: Learning to\n  Accept New Classes without Training", "journal-ref": null, "doi": "10.1145/3308558.3313644", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classic supervised learning makes the closed-world assumption, meaning that\nclasses seen in testing must have been seen in training. However, in the\ndynamic world, new or unseen class examples may appear constantly. A model\nworking in such an environment must be able to reject unseen classes (not seen\nor used in training). If enough data is collected for the unseen classes, the\nsystem should incrementally learn to accept/classify them. This learning\nparadigm is called open-world learning (OWL). Existing OWL methods all need\nsome form of re-training to accept or include the new classes in the overall\nmodel. In this paper, we propose a meta-learning approach to the problem. Its\nkey novelty is that it only needs to train a meta-classifier, which can then\ncontinually accept new classes when they have enough labeled data for the\nmeta-classifier to use, and also detect/reject future unseen classes. No\nre-training of the meta-classifier or a new overall classifier covering all old\nand new classes is needed. In testing, the method only uses the examples of the\nseen classes (including the newly added classes) on-the-fly for classification\nand rejection. Experimental results demonstrate the effectiveness of the new\napproach.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 03:08:58 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 23:25:46 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Xu", "Hu", ""], ["Liu", "Bing", ""], ["Shu", "Lei", ""], ["Yu", "P.", ""]]}, {"id": "1809.06083", "submitter": "Andreas St\\\"ockl", "authors": "Andreas St\\\"ockl", "title": "Similarity measure for Public Persons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the webportal \"Who is in the News!\" with statistics about the appearence\nof persons in written news we developed an extension, which measures the\nrelationship of public persons depending on a time parameter, as the\nrelationship may vary over time. On a training corpus of English and German\nnews articles we built a measure by extracting the persons occurrence in the\ntext via pretrained named entity extraction and then construct time series of\ncounts for each person. Pearson correlation over a sliding window is then used\nto measure the relation of two persons.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 09:09:48 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["St\u00f6ckl", "Andreas", ""]]}, {"id": "1809.06142", "submitter": "Mathias Creutz", "authors": "Mathias Creutz", "title": "Open Subtitles Paraphrase Corpus for Six Languages", "comments": null, "journal-ref": "Proceedings of the Eleventh International Conference on Language\n  Resources and Evaluation (LREC 2018), pp. 1364-1369, Miyazaki, Japan, 10 May\n  2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper accompanies the release of Opusparcus, a new paraphrase corpus for\nsix European languages: German, English, Finnish, French, Russian, and Swedish.\nThe corpus consists of paraphrases, that is, pairs of sentences in the same\nlanguage that mean approximately the same thing. The paraphrases are extracted\nfrom the OpenSubtitles2016 corpus, which contains subtitles from movies and TV\nshows. The informal and colloquial genre that occurs in subtitles makes such\ndata a very interesting language resource, for instance, from the perspective\nof computer assisted language learning. For each target language, the\nOpusparcus data have been partitioned into three types of data sets: training,\ndevelopment and test sets. The training sets are large, consisting of millions\nof sentence pairs, and have been compiled automatically, with the help of\nprobabilistic ranking functions. The development and test sets consist of\nsentence pairs that have been checked manually; each set contains approximately\n1000 sentence pairs that have been verified to be acceptable paraphrases by two\nannotators.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 11:49:19 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Creutz", "Mathias", ""]]}, {"id": "1809.06152", "submitter": "Alexander Panchenko", "authors": "Alexander Panchenko, Alexander Bondarenko, Mirco Franzek, Matthias\n  Hagen, Chris Biemann", "title": "Categorizing Comparative Sentences", "comments": "In Proceedings of the the 6th Workshop on Argument Mining\n  (ArgMining'2019) August 1st, collocated with ACL 2019 in Florence, Italy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We tackle the tasks of automatically identifying comparative sentences and\ncategorizing the intended preference (e.g., \"Python has better NLP libraries\nthan MATLAB\" => (Python, better, MATLAB). To this end, we manually annotate\n7,199 sentences for 217 distinct target item pairs from several domains (27% of\nthe sentences contain an oriented comparison in the sense of \"better\" or\n\"worse\"). A gradient boosting model based on pre-trained sentence embeddings\nreaches an F1 score of 85% in our experimental evaluation. The model can be\nused to extract comparative sentences for pro/con argumentation in comparative\n/ argument search engines or debating technologies.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 12:04:24 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2019 14:38:47 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Panchenko", "Alexander", ""], ["Bondarenko", "Alexander", ""], ["Franzek", "Mirco", ""], ["Hagen", "Matthias", ""], ["Biemann", "Chris", ""]]}, {"id": "1809.06194", "submitter": "Germ\\'an Kruszewski", "authors": "Rezka Leonandya, Elia Bruni, Dieuwke Hupkes, Germ\\'an Kruszewski", "title": "The Fast and the Flexible: training neural networks to learn to follow\n  instructions from small data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to follow human instructions is a long-pursued goal in artificial\nintelligence. The task becomes particularly challenging if no prior knowledge\nof the employed language is assumed while relying only on a handful of examples\nto learn from. Work in the past has relied on hand-coded components or manually\nengineered features to provide strong inductive biases that make learning in\nsuch situations possible. In contrast, here we seek to establish whether this\nknowledge can be acquired automatically by a neural network system through a\ntwo phase training procedure: A (slow) offline learning stage where the network\nlearns about the general structure of the task and a (fast) online adaptation\nphase where the network learns the language of a new given speaker. Controlled\nexperiments show that when the network is exposed to familiar instructions but\ncontaining novel words, the model adapts very efficiently to the new\nvocabulary. Moreover, even for human speakers whose language usage can depart\nsignificantly from our artificial training language, our network can still make\nuse of its automatically acquired inductive bias to learn to follow\ninstructions more effectively.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 13:34:49 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 13:34:51 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Leonandya", "Rezka", ""], ["Bruni", "Elia", ""], ["Hupkes", "Dieuwke", ""], ["Kruszewski", "Germ\u00e1n", ""]]}, {"id": "1809.06213", "submitter": "Zhen Cui", "authors": "Zhen Cui, Chunyan Xu, Wenming Zheng and Jian Yang", "title": "Context-Dependent Diffusion Network for Visual Relationship Detection", "comments": "8 pages, 3 figures, 2018 ACM Multimedia Conference (MM'18)", "journal-ref": null, "doi": "10.1145/3240508.3240668", "report-no": null, "categories": "cs.CV cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual relationship detection can bridge the gap between computer vision and\nnatural language for scene understanding of images. Different from pure object\nrecognition tasks, the relation triplets of subject-predicate-object lie on an\nextreme diversity space, such as \\textit{person-behind-person} and\n\\textit{car-behind-building}, while suffering from the problem of combinatorial\nexplosion. In this paper, we propose a context-dependent diffusion network\n(CDDN) framework to deal with visual relationship detection. To capture the\ninteractions of different object instances, two types of graphs, word semantic\ngraph and visual scene graph, are constructed to encode global context\ninterdependency. The semantic graph is built through language priors to model\nsemantic correlations across objects, whilst the visual scene graph defines the\nconnections of scene objects so as to utilize the surrounding scene\ninformation. For the graph-structured data, we design a diffusion network to\nadaptively aggregate information from contexts, which can effectively learn\nlatent representations of visual relationships and well cater to visual\nrelationship detection in view of its isomorphic invariance to graphs.\nExperiments on two widely-used datasets demonstrate that our proposed method is\nmore effective and achieves the state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 02:13:45 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Cui", "Zhen", ""], ["Xu", "Chunyan", ""], ["Zheng", "Wenming", ""], ["Yang", "Jian", ""]]}, {"id": "1809.06214", "submitter": "ChengKuan Chen", "authors": "Cheng Kuan Chen, Zhu Feng Pan, Min Sun, Ming-Yu Liu", "title": "Unsupervised Stylish Image Description Generation via Domain Layer Norm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the existing works on image description focus on generating\nexpressive descriptions. The only few works that are dedicated to generating\nstylish (e.g., romantic, lyric, etc.) descriptions suffer from limited style\nvariation and content digression. To address these limitations, we propose a\ncontrollable stylish image description generation model. It can learn to\ngenerate stylish image descriptions that are more related to image content and\ncan be trained with the arbitrary monolingual corpus without collecting new\npaired image and stylish descriptions. Moreover, it enables users to generate\nvarious stylish descriptions by plugging in style-specific parameters to\ninclude new styles into the existing model. We achieve this capability via a\nnovel layer normalization layer design, which we will refer to as the Domain\nLayer Norm (DLN). Extensive experimental validation and user study on various\nstylish image description generation tasks are conducted to show the\ncompetitive advantages of the proposed model.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 11:07:26 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Chen", "Cheng Kuan", ""], ["Pan", "Zhu Feng", ""], ["Sun", "Min", ""], ["Liu", "Ming-Yu", ""]]}, {"id": "1809.06223", "submitter": "Alexander Panchenko", "authors": "Dmitry Ustalov, Alexander Panchenko, Chris Biemann, Simone Paolo\n  Ponzetto", "title": "Unsupervised Sense-Aware Hypernymy Extraction", "comments": "In Proceedings of the 14th Conference on Natural Language Processing\n  (KONVENS 2018). Vienna, Austria", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we show how unsupervised sense representations can be used to\nimprove hypernymy extraction. We present a method for extracting disambiguated\nhypernymy relationships that propagates hypernyms to sets of synonyms\n(synsets), constructs embeddings for these sets, and establishes sense-aware\nrelationships between matching synsets. Evaluation on two gold standard\ndatasets for English and Russian shows that the method successfully recognizes\nhypernymy relationships that cannot be found with standard Hearst patterns and\nWiktionary datasets for the respective languages.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 14:16:49 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Ustalov", "Dmitry", ""], ["Panchenko", "Alexander", ""], ["Biemann", "Chris", ""], ["Ponzetto", "Simone Paolo", ""]]}, {"id": "1809.06284", "submitter": "Shrimai Prabhumoye", "authors": "Shrimai Prabhumoye, Yulia Tsvetkov, Alan W Black, Ruslan Salakhutdinov", "title": "Style Transfer Through Multilingual and Feedback-Based Back-Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Style transfer is the task of transferring an attribute of a sentence (e.g.,\nformality) while maintaining its semantic content. The key challenge in style\ntransfer is to strike a balance between the competing goals, one to preserve\nmeaning and the other to improve the style transfer accuracy. Prior research\nhas identified that the task of meaning preservation is generally harder to\nattain and evaluate. This paper proposes two extensions of the state-of-the-art\nstyle transfer models aiming at improving the meaning preservation in style\ntransfer. Our evaluation shows that these extensions help to ground meaning\nbetter while improving the transfer accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 15:47:06 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Prabhumoye", "Shrimai", ""], ["Tsvetkov", "Yulia", ""], ["Black", "Alan W", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1809.06297", "submitter": "Liqun Chen", "authors": "Liqun Chen, Shuyang Dai, Chenyang Tao, Dinghan Shen, Zhe Gan, Haichao\n  Zhang, Yizhe Zhang, Lawrence Carin", "title": "Adversarial Text Generation via Feature-Mover's Distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) have achieved significant success in\ngenerating real-valued data. However, the discrete nature of text hinders the\napplication of GAN to text-generation tasks. Instead of using the standard GAN\nobjective, we propose to improve text-generation GAN via a novel approach\ninspired by optimal transport. Specifically, we consider matching the latent\nfeature distributions of real and synthetic sentences using a novel metric,\ntermed the feature-mover's distance (FMD). This formulation leads to a highly\ndiscriminative critic and easy-to-optimize objective, overcoming the\nmode-collapsing and brittle-training problems in existing methods. Extensive\nexperiments are conducted on a variety of tasks to evaluate the proposed model\nempirically, including unconditional text generation, style transfer from\nnon-parallel text, and unsupervised cipher cracking. The proposed model yields\nsuperior performance, demonstrating wide applicability and effectiveness.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 16:03:13 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 17:31:30 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Chen", "Liqun", ""], ["Dai", "Shuyang", ""], ["Tao", "Chenyang", ""], ["Shen", "Dinghan", ""], ["Gan", "Zhe", ""], ["Zhang", "Haichao", ""], ["Zhang", "Yizhe", ""], ["Carin", "Lawrence", ""]]}, {"id": "1809.06309", "submitter": "Yicheng Wang", "authors": "Lisa Bauer, Yicheng Wang, Mohit Bansal", "title": "Commonsense for Generative Multi-Hop Question Answering Tasks", "comments": "EMNLP 2018 (22 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reading comprehension QA tasks have seen a recent surge in popularity, yet\nmost works have focused on fact-finding extractive QA. We instead focus on a\nmore challenging multi-hop generative task (NarrativeQA), which requires the\nmodel to reason, gather, and synthesize disjoint pieces of information within\nthe context to generate an answer. This type of multi-step reasoning also often\nrequires understanding implicit relations, which humans resolve via external,\nbackground commonsense knowledge. We first present a strong generative baseline\nthat uses a multi-attention mechanism to perform multiple hops of reasoning and\na pointer-generator decoder to synthesize the answer. This model performs\nsubstantially better than previous generative models, and is competitive with\ncurrent state-of-the-art span prediction models. We next introduce a novel\nsystem for selecting grounded multi-hop relational commonsense information from\nConceptNet via a pointwise mutual information and term-frequency based scoring\nfunction. Finally, we effectively use this extracted commonsense information to\nfill in gaps of reasoning between context hops, using a selectively-gated\nattention mechanism. This boosts the model's performance significantly (also\nverified via human evaluation), establishing a new state-of-the-art for the\ntask. We also show promising initial results of the generalizability of our\nbackground knowledge enhancements by demonstrating some improvement on\nQAngaroo-WikiHop, another multi-hop reasoning dataset.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 16:24:00 GMT"}, {"version": "v2", "created": "Fri, 11 Jan 2019 17:08:37 GMT"}, {"version": "v3", "created": "Sat, 1 Jun 2019 03:50:14 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Bauer", "Lisa", ""], ["Wang", "Yicheng", ""], ["Bansal", "Mohit", ""]]}, {"id": "1809.06366", "submitter": "Georgios-Ioannis Brokos", "authors": "Georgios-Ioannis Brokos, Polyvios Liosis, Ryan McDonald, Dimitris\n  Pappas, Ion Androutsopoulos", "title": "AUEB at BioASQ 6: Document and Snippet Retrieval", "comments": "In Proceedings of the workshop BioASQ: Large-scale Biomedical\n  Semantic Indexing and Question Answering, at the Conference on Empirical\n  Methods in Natural Language Processing (EMNLP 2018), Brussels, Belgium, 2018.\n  arXiv admin note: text overlap with arXiv:1809.01682", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present AUEB's submissions to the BioASQ 6 document and snippet retrieval\ntasks (parts of Task 6b, Phase A). Our models use novel extensions to deep\nlearning architectures that operate solely over the text of the query and\ncandidate document/snippets. Our systems scored at the top or near the top for\nall batches of the challenge, highlighting the effectiveness of deep learning\nfor these tasks.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 22:11:03 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Brokos", "Georgios-Ioannis", ""], ["Liosis", "Polyvios", ""], ["McDonald", "Ryan", ""], ["Pappas", "Dimitris", ""], ["Androutsopoulos", "Ion", ""]]}, {"id": "1809.06416", "submitter": "Kashyap Popat", "authors": "Kashyap Popat, Subhabrata Mukherjee, Andrew Yates, Gerhard Weikum", "title": "DeClarE: Debunking Fake News and False Claims using Evidence-Aware Deep\n  Learning", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Misinformation such as fake news is one of the big challenges of our society.\nResearch on automated fact-checking has proposed methods based on supervised\nlearning, but these approaches do not consider external evidence apart from\nlabeled training instances. Recent approaches counter this deficit by\nconsidering external sources related to a claim. However, these methods require\nsubstantial feature modeling and rich lexicons. This paper overcomes these\nlimitations of prior work with an end-to-end model for evidence-aware\ncredibility assessment of arbitrary textual claims, without any human\nintervention. It presents a neural network model that judiciously aggregates\nsignals from external evidence articles, the language of these articles and the\ntrustworthiness of their sources. It also derives informative features for\ngenerating user-comprehensible explanations that makes the neural network\npredictions transparent to the end-user. Experiments with four datasets and\nablation studies show the strength of our method.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 19:51:18 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Popat", "Kashyap", ""], ["Mukherjee", "Subhabrata", ""], ["Yates", "Andrew", ""], ["Weikum", "Gerhard", ""]]}, {"id": "1809.06444", "submitter": "Avik Ray", "authors": "Avik Ray, Yilin Shen, Hongxia Jin", "title": "Robust Spoken Language Understanding via Paraphrasing", "comments": "Published in Proceedings of INTERSPEECH 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning intents and slot labels from user utterances is a fundamental step\nin all spoken language understanding (SLU) and dialog systems. State-of-the-art\nneural network based methods, after deployment, often suffer from performance\ndegradation on encountering paraphrased utterances, and out-of-vocabulary\nwords, rarely observed in their training set. We address this challenging\nproblem by introducing a novel paraphrasing based SLU model which can be\nintegrated with any existing SLU model in order to improve their overall\nperformance. We propose two new paraphrase generators using RNN and\nsequence-to-sequence based neural networks, which are suitable for our\napplication. Our experiments on existing benchmark and in house datasets\ndemonstrate the robustness of our models to rare and complex paraphrased\nutterances, even under adversarial test distributions.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 21:01:35 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Ray", "Avik", ""], ["Shen", "Yilin", ""], ["Jin", "Hongxia", ""]]}, {"id": "1809.06491", "submitter": "Yuanliang Meng", "authors": "Yuanliang Meng and Anna Rumshisky", "title": "Triad-based Neural Network for Coreference Resolution", "comments": null, "journal-ref": "Proceedings of 27th International Conference on Computational\n  Linguistics (2018) 35-43", "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a triad-based neural network system that generates affinity scores\nbetween entity mentions for coreference resolution. The system simultaneously\naccepts three mentions as input, taking mutual dependency and logical\nconstraints of all three mentions into account, and thus makes more accurate\npredictions than the traditional pairwise approach. Depending on system\nchoices, the affinity scores can be further used in clustering or mention\nranking. Our experiments show that a standard hierarchical clustering using the\nscores produces state-of-art results with gold mentions on the English portion\nof CoNLL 2012 Shared Task. The model does not rely on many handcrafted features\nand is easy to train and use. The triads can also be easily extended to polyads\nof higher orders. To our knowledge, this is the first neural network system to\nmodel mutual dependency of more than two members at mention level.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 00:38:30 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Meng", "Yuanliang", ""], ["Rumshisky", "Anna", ""]]}, {"id": "1809.06502", "submitter": "Zijie Lu", "authors": "Qi Huang and Zhanghao Chen and Zijie Lu and Yuan Ye", "title": "Analysis of Bag-of-n-grams Representation's Properties Based on Textual\n  Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its simplicity, bag-of-n-grams sen- tence representation has been\nfound to excel in some NLP tasks. However, it has not re- ceived much attention\nin recent years and fur- ther analysis on its properties is necessary. We\npropose a framework to investigate the amount and type of information captured\nin a general- purposed bag-of-n-grams sentence represen- tation. We first use\nsentence reconstruction as a tool to obtain bag-of-n-grams representa- tion\nthat contains general information of the sentence. We then run prediction tasks\n(sen- tence length, word content, phrase content and word order) using the\nobtained representation to look into the specific type of information captured\nin the representation. Our analysis demonstrates that bag-of-n-grams\nrepresenta- tion does contain sentence structure level in- formation. However,\nincorporating n-grams with higher order n empirically helps little with\nencoding more information in general, except for phrase content information.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 02:09:56 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Huang", "Qi", ""], ["Chen", "Zhanghao", ""], ["Lu", "Zijie", ""], ["Ye", "Yuan", ""]]}, {"id": "1809.06537", "submitter": "Cunchao Tu", "authors": "Shangbang Long, Cunchao Tu, Zhiyuan Liu, Maosong Sun", "title": "Automatic Judgment Prediction via Legal Reading Comprehension", "comments": "10 pages, 4 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic judgment prediction aims to predict the judicial results based on\ncase materials. It has been studied for several decades mainly by lawyers and\njudges, considered as a novel and prospective application of artificial\nintelligence techniques in the legal field. Most existing methods follow the\ntext classification framework, which fails to model the complex interactions\namong complementary case materials. To address this issue, we formalize the\ntask as Legal Reading Comprehension according to the legal scenario. Following\nthe working protocol of human judges, LRC predicts the final judgment results\nbased on three types of information, including fact description, plaintiffs'\npleas, and law articles. Moreover, we propose a novel LRC model, AutoJudge,\nwhich captures the complex semantic interactions among facts, pleas, and laws.\nIn experiments, we construct a real-world civil case dataset for LRC.\nExperimental results on this dataset demonstrate that our model achieves\nsignificant improvement over state-of-the-art models. We will publish all\nsource codes and datasets of this work on \\urlgithub.com for further research.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 05:26:40 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Long", "Shangbang", ""], ["Tu", "Cunchao", ""], ["Liu", "Zhiyuan", ""], ["Sun", "Maosong", ""]]}, {"id": "1809.06559", "submitter": "Yilin Shen", "authors": "Yilin Shen and Xiangyu Zeng and Yu Wang and Hongxia Jin", "title": "User Information Augmented Semantic Frame Parsing using Coarse-to-Fine\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic frame parsing is a crucial component in spoken language\nunderstanding (SLU) to build spoken dialog systems. It has two main tasks:\nintent detection and slot filling. Although state-of-the-art approaches showed\ngood results, they require large annotated training data and long training\ntime. In this paper, we aim to alleviate these drawbacks for semantic frame\nparsing by utilizing the ubiquitous user information. We design a novel\ncoarse-to-fine deep neural network model to incorporate prior knowledge of user\ninformation intermediately to better and quickly train a semantic frame parser.\nDue to the lack of benchmark dataset with real user information, we synthesize\nthe simplest type of user information (location and time) on ATIS benchmark\ndata. The results show that our approach leverages such simple user information\nto outperform state-of-the-art approaches by 0.25% for intent detection and\n0.31% for slot filling using standard training data. When using smaller\ntraining data, the performance improvement on intent detection and slot filling\nreaches up to 1.35% and 1.20% respectively. We also show that our approach can\nachieve similar performance as state-of-the-art approaches by using less than\n80% annotated training data. Moreover, the training time to achieve the similar\nperformance is also reduced by over 60%.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 07:08:59 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Shen", "Yilin", ""], ["Zeng", "Xiangyu", ""], ["Wang", "Yu", ""], ["Jin", "Hongxia", ""]]}, {"id": "1809.06590", "submitter": "Minghua Zhang", "authors": "Minghua Zhang, Yunfang Wu, Weikang Li and Wei Li", "title": "Learning Universal Sentence Representations with Mean-Max Attention\n  Autoencoder", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to learn universal sentence representations, previous methods focus\non complex recurrent neural networks or supervised learning. In this paper, we\npropose a mean-max attention autoencoder (mean-max AAE) within the\nencoder-decoder framework. Our autoencoder rely entirely on the MultiHead\nself-attention mechanism to reconstruct the input sequence. In the encoding we\npropose a mean-max strategy that applies both mean and max pooling operations\nover the hidden vectors to capture diverse information of the input. To enable\nthe information to steer the reconstruction process dynamically, the decoder\nperforms attention over the mean-max representation. By training our model on a\nlarge collection of unlabelled data, we obtain high-quality representations of\nsentences. Experimental results on a broad range of 10 transfer tasks\ndemonstrate that our model outperforms the state-of-the-art unsupervised single\nmethods, including the classical skip-thoughts and the advanced\nskip-thoughts+LN model. Furthermore, compared with the traditional recurrent\nneural network, our mean-max AAE greatly reduce the training time.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 08:34:12 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Zhang", "Minghua", ""], ["Wu", "Yunfang", ""], ["Li", "Weikang", ""], ["Li", "Wei", ""]]}, {"id": "1809.06639", "submitter": "Alejandro Rodr\\'iguez-Gonz\\'alez", "authors": "Marjan Najafabadipour, Juan Manuel Tu\\~nas, Alejandro\n  Rodr\\'iguez-Gonz\\'alez, Ernestina Menasalvas", "title": "Lung Cancer Concept Annotation from Spanish Clinical Narratives", "comments": "10 pages, 6 figures", "journal-ref": "Data Integration in the Life Sciences (DILS 2018)", "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent rapid increase in the generation of clinical data and rapid\ndevelopment of computational science make us able to extract new insights from\nmassive datasets in healthcare industry. Oncological clinical notes are\ncreating rich databases for documenting patients history and they potentially\ncontain lots of patterns that could help in better management of the disease.\nHowever, these patterns are locked within free text (unstructured) portions of\nclinical documents and consequence in limiting health professionals to extract\nuseful information from them and to finally perform Query and Answering (QA)\nprocess in an accurate way. The Information Extraction (IE) process requires\nNatural Language Processing (NLP) techniques to assign semantics to these\npatterns. Therefore, in this paper, we analyze the design of annotators for\nspecific lung cancer concepts that can be integrated over Apache Unstructured\nInformation Management Architecture (UIMA) framework. In addition, we explain\nthe details of generation and storage of annotation outcomes.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 10:55:03 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Najafabadipour", "Marjan", ""], ["Tu\u00f1as", "Juan Manuel", ""], ["Rodr\u00edguez-Gonz\u00e1lez", "Alejandro", ""], ["Menasalvas", "Ernestina", ""]]}, {"id": "1809.06641", "submitter": "Joachim Fainberg", "authors": "Joachim Fainberg, Ben Krause, Mihai Dobre, Marco Damonte, Emmanuel\n  Kahembwe, Daniel Duma, Bonnie Webber, Federico Fancellu", "title": "Talking to myself: self-dialogues as data for conversational agents", "comments": "5 pages, 5 pages appendix, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational agents are gaining popularity with the increasing ubiquity of\nsmart devices. However, training agents in a data driven manner is challenging\ndue to a lack of suitable corpora. This paper presents a novel method for\ngathering topical, unstructured conversational data in an efficient way:\nself-dialogues through crowd-sourcing. Alongside this paper, we include a\ncorpus of 3.6 million words across 23 topics. We argue the utility of the\ncorpus by comparing self-dialogues with standard two-party conversations as\nwell as data from other corpora.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 11:09:49 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2018 10:16:52 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Fainberg", "Joachim", ""], ["Krause", "Ben", ""], ["Dobre", "Mihai", ""], ["Damonte", "Marco", ""], ["Kahembwe", "Emmanuel", ""], ["Duma", "Daniel", ""], ["Webber", "Bonnie", ""], ["Fancellu", "Federico", ""]]}, {"id": "1809.06662", "submitter": "Kamal Al-Sabahi Ph.D.", "authors": "Kamal Al-Sabahi, Zhang Zuping, Yang Kang", "title": "Bidirectional Attentional Encoder-Decoder Model and Bidirectional Beam\n  Search for Abstractive Summarization", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence generative models with RNN variants, such as LSTM, GRU, show\npromising performance on abstractive document summarization. However, they\nstill have some issues that limit their performance, especially while deal-ing\nwith long sequences. One of the issues is that, to the best of our knowledge,\nall current models employ a unidirectional decoder, which reasons only about\nthe past and still limited to retain future context while giving a prediction.\nThis makes these models suffer on their own by generating unbalanced outputs.\nMoreover, unidirec-tional attention-based document summarization can only\ncapture partial aspects of attentional regularities due to the inherited\nchallenges in document summarization. To this end, we propose an end-to-end\ntrainable bidirectional RNN model to tackle the aforementioned issues. The\nmodel has a bidirectional encoder-decoder architecture; in which the encoder\nand the decoder are bidirectional LSTMs. The forward decoder is initialized\nwith the last hidden state of the backward encoder while the backward decoder\nis initialized with the last hidden state of the for-ward encoder. In addition,\na bidirectional beam search mechanism is proposed as an approximate inference\nalgo-rithm for generating the output summaries from the bidi-rectional model.\nThis enables the model to reason about the past and future and to generate\nbalanced outputs as a result. Experimental results on CNN / Daily Mail dataset\nshow that the proposed model outperforms the current abstractive\nstate-of-the-art models by a considerable mar-gin.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 12:18:22 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Al-Sabahi", "Kamal", ""], ["Zuping", "Zhang", ""], ["Kang", "Yang", ""]]}, {"id": "1809.06683", "submitter": "Leon Derczynski", "authors": "Genevieve Gorrell, Kalina Bontcheva, Leon Derczynski, Elena Kochkina,\n  Maria Liakata, Arkaitz Zubiaga", "title": "RumourEval 2019: Determining Rumour Veracity and Support for Rumours", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This is the proposal for RumourEval-2019, which will run in early 2019 as\npart of that year's SemEval event. Since the first RumourEval shared task in\n2017, interest in automated claim validation has greatly increased, as the\ndangers of \"fake news\" have become a mainstream concern. Yet automated support\nfor rumour checking remains in its infancy. For this reason, it is important\nthat a shared task in this area continues to provide a focus for effort, which\nis likely to increase. We therefore propose a continuation in which the\nveracity of further rumours is determined, and as previously, supportive of\nthis goal, tweets discussing them are classified according to the stance they\ntake regarding the rumour. Scope is extended compared with the first\nRumourEval, in that the dataset is substantially expanded to include Reddit as\nwell as Twitter data, and additional languages are also included.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 13:12:21 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Gorrell", "Genevieve", ""], ["Bontcheva", "Kalina", ""], ["Derczynski", "Leon", ""], ["Kochkina", "Elena", ""], ["Liakata", "Maria", ""], ["Zubiaga", "Arkaitz", ""]]}, {"id": "1809.06709", "submitter": "Pankaj Gupta", "authors": "Pankaj Gupta and Yatin Chaudhary and Florian Buettner and Hinrich\n  Sch\\\"utze", "title": "Document Informed Neural Autoregressive Topic Models with Distributional\n  Prior", "comments": "AAAI2019. arXiv admin note: substantial text overlap with\n  arXiv:1808.03793", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address two challenges in topic models: (1) Context information around\nwords helps in determining their actual meaning, e.g., \"networks\" used in the\ncontexts \"artificial neural networks\" vs. \"biological neuron networks\".\nGenerative topic models infer topic-word distributions, taking no or only\nlittle context into account. Here, we extend a neural autoregressive topic\nmodel to exploit the full context information around words in a document in a\nlanguage modeling fashion. The proposed model is named as iDocNADE. (2) Due to\nthe small number of word occurrences (i.e., lack of context) in short text and\ndata sparsity in a corpus of few documents, the application of topic models is\nchallenging on such texts. Therefore, we propose a simple and efficient way of\nincorporating external knowledge into neural autoregressive topic models: we\nuse embeddings as a distributional prior. The proposed variants are named as\nDocNADEe and iDocNADEe.\n  We present novel neural autoregressive topic model variants that consistently\noutperform state-of-the-art generative topic models in terms of generalization,\ninterpretability (topic coherence) and applicability (retrieval and\nclassification) over 7 long-text and 8 short-text datasets from diverse\ndomains.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 12:48:16 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 16:25:06 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Gupta", "Pankaj", ""], ["Chaudhary", "Yatin", ""], ["Buettner", "Florian", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1809.06748", "submitter": "Murhaf Fares", "authors": "Murhaf Fares, Stephan Oepen and Erik Velldal", "title": "Transfer and Multi-Task Learning for Noun-Noun Compound Interpretation", "comments": "EMNLP 2018: Conference on Empirical Methods in Natural Language\n  Processing (EMNLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we empirically evaluate the utility of transfer and multi-task\nlearning on a challenging semantic classification task: semantic interpretation\nof noun--noun compounds. Through a comprehensive series of experiments and\nin-depth error analysis, we show that transfer learning via parameter\ninitialization and multi-task learning via parameter sharing can help a neural\nclassification model generalize over a highly skewed distribution of relations.\nFurther, we demonstrate how dual annotation with two distinct sets of relations\nover the same set of compounds can be exploited to improve the overall accuracy\nof a neural classifier and its F1 scores on the less frequent, but more\ndifficult relations.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 14:01:22 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Fares", "Murhaf", ""], ["Oepen", "Stephan", ""], ["Velldal", "Erik", ""]]}, {"id": "1809.06858", "submitter": "Di He", "authors": "Chengyue Gong, Di He, Xu Tan, Tao Qin, Liwei Wang, Tie-Yan Liu", "title": "FRAGE: Frequency-Agnostic Word Representation", "comments": "To appear in NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous word representation (aka word embedding) is a basic building block\nin many neural network-based models used in natural language processing tasks.\nAlthough it is widely accepted that words with similar semantics should be\nclose to each other in the embedding space, we find that word embeddings\nlearned in several tasks are biased towards word frequency: the embeddings of\nhigh-frequency and low-frequency words lie in different subregions of the\nembedding space, and the embedding of a rare word and a popular word can be far\nfrom each other even if they are semantically similar. This makes learned word\nembeddings ineffective, especially for rare words, and consequently limits the\nperformance of these neural network models. In this paper, we develop a neat,\nsimple yet effective way to learn \\emph{FRequency-AGnostic word Embedding}\n(FRAGE) using adversarial training. We conducted comprehensive studies on ten\ndatasets across four natural language processing tasks, including word\nsimilarity, language modeling, machine translation and text classification.\nResults show that with FRAGE, we achieve higher performance than the baselines\nin all tasks.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 13:31:22 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 04:28:27 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Gong", "Chengyue", ""], ["He", "Di", ""], ["Tan", "Xu", ""], ["Qin", "Tao", ""], ["Wang", "Liwei", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1809.06873", "submitter": "Xinnuo Xu", "authors": "Xinnuo Xu, Ond\\v{r}ej Du\\v{s}ek, Ioannis Konstas and Verena Rieser", "title": "Better Conversations by Modeling,Filtering,and Optimizing for Coherence\n  and Diversity", "comments": null, "journal-ref": "Proceedings of the 2018 Conference on Empirical Methods in Natural\n  Language Processing, pages 3981-3991, Brussels, Belgium, November 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present three enhancements to existing encoder-decoder models for\nopen-domain conversational agents, aimed at effectively modeling coherence and\npromoting output diversity: (1) We introduce a measure of coherence as the\nGloVe embedding similarity between the dialogue context and the generated\nresponse, (2) we filter our training corpora based on the measure of coherence\nto obtain topically coherent and lexically diverse context-response pairs, (3)\nwe then train a response generator using a conditional variational autoencoder\nmodel that incorporates the measure of coherence as a latent variable and uses\na context gate to guarantee topical consistency with the context and promote\nlexical diversity. Experiments on the OpenSubtitles corpus show a substantial\nimprovement over competitive neural models in terms of BLEU score as well as\nmetrics of coherence and diversity.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 18:08:19 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Xu", "Xinnuo", ""], ["Du\u0161ek", "Ond\u0159ej", ""], ["Konstas", "Ioannis", ""], ["Rieser", "Verena", ""]]}, {"id": "1809.06906", "submitter": "Andrej \\v{S}vec", "authors": "Andrej \\v{S}vec, Mat\\'u\\v{s} Pikuliak, Mari\\'an \\v{S}imko, M\\'aria\n  Bielikov\\'a (Slovak University of Technology in Bratislava, Bratislava,\n  Slovakia)", "title": "Improving Moderation of Online Discussions via Interpretable Neural\n  Models", "comments": "ALW2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Growing amount of comments make online discussions difficult to moderate by\nhuman moderators only. Antisocial behavior is a common occurrence that often\ndiscourages other users from participating in discussion. We propose a neural\nnetwork based method that partially automates the moderation process. It\nconsists of two steps. First, we detect inappropriate comments for moderators\nto see. Second, we highlight inappropriate parts within these comments to make\nthe moderation faster. We evaluated our method on data from a major Slovak news\ndiscussion platform.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 19:45:25 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["\u0160vec", "Andrej", "", "Slovak University of Technology in Bratislava, Bratislava,\n  Slovakia"], ["Pikuliak", "Mat\u00fa\u0161", "", "Slovak University of Technology in Bratislava, Bratislava,\n  Slovakia"], ["\u0160imko", "Mari\u00e1n", "", "Slovak University of Technology in Bratislava, Bratislava,\n  Slovakia"], ["Bielikov\u00e1", "M\u00e1ria", "", "Slovak University of Technology in Bratislava, Bratislava,\n  Slovakia"]]}, {"id": "1809.06951", "submitter": "Umashanthi Pavalanathan", "authors": "Umashanthi Pavalanathan, Xiaochuang Han, Jacob Eisenstein", "title": "Mind Your POV: Convergence of Articles and Editors Towards Wikipedia's\n  Neutrality Norm", "comments": "ACM Conference on Computer-Supported Cooperative Work and Social\n  Computing (CSCW), 2018", "journal-ref": "Umashanthi Pavalanathan, Xiaochuang Han, and Jacob Eisenstein.\n  2018. Mind Your POV: Convergence of Articles and Editors Towards Wikipedia's\n  Neutrality Norm. Proc. ACM Hum.-Comput. Interact. 2, CSCW, Article 137\n  (November 2018)", "doi": "10.1145/3274406", "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wikipedia has a strong norm of writing in a 'neutral point of view' (NPOV).\nArticles that violate this norm are tagged, and editors are encouraged to make\ncorrections. But the impact of this tagging system has not been quantitatively\nmeasured. Does NPOV tagging help articles to converge to the desired style? Do\nNPOV corrections encourage editors to adopt this style? We study these\nquestions using a corpus of NPOV-tagged articles and a set of lexicons\nassociated with biased language. An interrupted time series analysis shows that\nafter an article is tagged for NPOV, there is a significant decrease in biased\nlanguage in the article, as measured by several lexicons. However, for\nindividual editors, NPOV corrections and talk page discussions yield no\nsignificant change in the usage of words in most of these lexicons, including\nWikipedia's own list of 'words to watch.' This suggests that NPOV tagging and\ndiscussion does improve content, but has less success enculturating editors to\nthe site's linguistic norms.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 22:03:48 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Pavalanathan", "Umashanthi", ""], ["Han", "Xiaochuang", ""], ["Eisenstein", "Jacob", ""]]}, {"id": "1809.06963", "submitter": "Yichong Xu", "authors": "Yichong Xu, Xiaodong Liu, Yelong Shen, Jingjing Liu and Jianfeng Gao", "title": "Multi-task Learning with Sample Re-weighting for Machine Reading\n  Comprehension", "comments": "North American Chapter of the Association for Computational\n  Linguistics (NAACL) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a multi-task learning framework to learn a joint Machine Reading\nComprehension (MRC) model that can be applied to a wide range of MRC tasks in\ndifferent domains. Inspired by recent ideas of data selection in machine\ntranslation, we develop a novel sample re-weighting scheme to assign\nsample-specific weights to the loss. Empirical study shows that our approach\ncan be applied to many existing MRC models. Combined with contextual\nrepresentations from pre-trained language models (such as ELMo), we achieve new\nstate-of-the-art results on a set of MRC benchmark datasets. We release our\ncode at https://github.com/xycforgithub/MultiTask-MRC.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 23:44:03 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2019 06:42:32 GMT"}, {"version": "v3", "created": "Sun, 31 Mar 2019 20:51:34 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Xu", "Yichong", ""], ["Liu", "Xiaodong", ""], ["Shen", "Yelong", ""], ["Liu", "Jingjing", ""], ["Gao", "Jianfeng", ""]]}, {"id": "1809.07037", "submitter": "Rui Wang", "authors": "Benjamin Marie, Rui Wang, Atsushi Fujita, Masao Utiyama, and Eiichiro\n  Sumita", "title": "NICT's Neural and Statistical Machine Translation Systems for the WMT18\n  News Translation Task", "comments": "Due to the policy of our institue, with the agreement of all of the\n  author, we decide to withdraw this paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the NICT's participation to the WMT18 shared news\ntranslation task. We participated in the eight translation directions of four\nlanguage pairs: Estonian-English, Finnish-English, Turkish-English and\nChinese-English. For each translation direction, we prepared state-of-the-art\nstatistical (SMT) and neural (NMT) machine translation systems. Our NMT systems\nwere trained with the transformer architecture using the provided parallel data\nenlarged with a large quantity of back-translated monolingual data that we\ngenerated with a new incremental training framework. Our primary submissions to\nthe task are the result of a simple combination of our SMT and NMT systems. Our\nsystems are ranked first for the Estonian-English and Finnish-English language\npairs (constraint) according to BLEU-cased.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 07:41:55 GMT"}, {"version": "v2", "created": "Fri, 12 Oct 2018 02:48:42 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Marie", "Benjamin", ""], ["Wang", "Rui", ""], ["Fujita", "Atsushi", ""], ["Utiyama", "Masao", ""], ["Sumita", "Eiichiro", ""]]}, {"id": "1809.07043", "submitter": "Rui Wang", "authors": "Rui Wang, Benjamin Marie, Masao Utiyama, and Eiichiro Sumita", "title": "NICT's Corpus Filtering Systems for the WMT18 Parallel Corpus Filtering\n  Task", "comments": "Due to the policy of our institute, with the agreement of all of the\n  author, we decide to withdraw this paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the NICT's participation in the WMT18 shared parallel\ncorpus filtering task. The organizers provided 1 billion words German-English\ncorpus crawled from the web as part of the Paracrawl project. This corpus is\ntoo noisy to build an acceptable neural machine translation (NMT) system. Using\nthe clean data of the WMT18 shared news translation task, we designed several\nfeatures and trained a classifier to score each sentence pairs in the noisy\ndata. Finally, we sampled 100 million and 10 million words and built\ncorresponding NMT systems. Empirical results show that our NMT systems trained\non sampled data achieve promising performance.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 07:52:16 GMT"}, {"version": "v2", "created": "Fri, 12 Oct 2018 02:49:05 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Wang", "Rui", ""], ["Marie", "Benjamin", ""], ["Utiyama", "Masao", ""], ["Sumita", "Eiichiro", ""]]}, {"id": "1809.07070", "submitter": "Tsung-Hsien Wen", "authors": "Tsung-Hsien Wen and Minh-Thang Luong", "title": "Latent Topic Conversational Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent variable models have been a preferred choice in conversational\nmodeling compared to sequence-to-sequence (seq2seq) models which tend to\ngenerate generic and repetitive responses. Despite so, training latent variable\nmodels remains to be difficult. In this paper, we propose Latent Topic\nConversational Model (LTCM) which augments seq2seq with a neural latent topic\ncomponent to better guide response generation and make training easier. The\nneural topic component encodes information from the source sentence to build a\nglobal \"topic\" distribution over words, which is then consulted by the seq2seq\nmodel at each generation step. We study in details how the latent\nrepresentation is learnt in both the vanilla model and LTCM. Our extensive\nexperiments contribute to better understanding and training of conditional\nlatent models for languages. Our results show that by sampling from the learnt\nlatent representations, LTCM can generate diverse and interesting responses. In\na subjective human evaluation, the judges also confirm that LTCM is the overall\npreferred option.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 08:58:23 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Wen", "Tsung-Hsien", ""], ["Luong", "Minh-Thang", ""]]}, {"id": "1809.07182", "submitter": "Garrett Nicolai", "authors": "Garrett Nicolai, Saeed Najafi, and Grzegorz Kondrak", "title": "String Transduction with Target Language Models and Insertion Handling", "comments": "8 pages + 1 page Appendix, 4 figures and 8 tables, plus an additional\n  1 figure and 2 tables in appendix; to appear at SIGMORPHON 2018, October,\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many character-level tasks can be framed as sequence-to-sequence\ntransduction, where the target is a word from a natural language. We show that\nleveraging target language models derived from unannotated target corpora,\ncombined with a precise alignment of the training data, yields state-of-the art\nresults on cognate projection, inflection generation, and phoneme-to-grapheme\nconversion.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 13:39:40 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Nicolai", "Garrett", ""], ["Najafi", "Saeed", ""], ["Kondrak", "Grzegorz", ""]]}, {"id": "1809.07234", "submitter": "Denis Gordeev", "authors": "Denis Gordeev, Alexey Rey, Dmitry Shagarov", "title": "Unsupervised cross-lingual matching of product classifications", "comments": "6 pages, sent to 23rd IEEE FRUCT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised cross-lingual embeddings mapping has provided a unique tool for\ncompletely unsupervised translation even for languages with different scripts.\nIn this work we use this method for the task of unsupervised cross-lingual\nmatching of product classifications. Our work also investigates limitations of\nunsupervised vector alignment and we also suggest two other techniques for\naligning product classifications based on their descriptions: using\nhierarchical information and translations.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 15:07:45 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Gordeev", "Denis", ""], ["Rey", "Alexey", ""], ["Shagarov", "Dmitry", ""]]}, {"id": "1809.07257", "submitter": "Oliver Nina", "authors": "Oliver Nina and Washington Garcia and Scott Clouse and Alper Yilmaz", "title": "MTLE: A Multitask Learning Encoder of Visual Feature Representations for\n  Video and Movie Description", "comments": "This is a pre-print version of our soon to be released paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Learning visual feature representations for video analysis is a daunting task\nthat requires a large amount of training samples and a proper generalization\nframework. Many of the current state of the art methods for video captioning\nand movie description rely on simple encoding mechanisms through recurrent\nneural networks to encode temporal visual information extracted from video\ndata. In this paper, we introduce a novel multitask encoder-decoder framework\nfor automatic semantic description and captioning of video sequences. In\ncontrast to current approaches, our method relies on distinct decoders that\ntrain a visual encoder in a multitask fashion. Our system does not depend\nsolely on multiple labels and allows for a lack of training data working even\nwith datasets where only one single annotation is viable per video. Our method\nshows improved performance over current state of the art methods in several\nmetrics on multi-caption and single-caption datasets. To the best of our\nknowledge, our method is the first method to use a multitask approach for\nencoding video features. Our method demonstrates its robustness on the Large\nScale Movie Description Challenge (LSMDC) 2017 where our method won the movie\ndescription task and its results were ranked among other competitors as the\nmost helpful for the visually impaired.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 15:50:18 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Nina", "Oliver", ""], ["Garcia", "Washington", ""], ["Clouse", "Scott", ""], ["Yilmaz", "Alper", ""]]}, {"id": "1809.07269", "submitter": "Chandrakant Bothe", "authors": "Chandrakant Bothe, Fernando Garcia, Arturo Cruz Maya, Amit Kumar\n  Pandey, Stefan Wermter", "title": "Towards Dialogue-based Navigation with Multivariate Adaptation driven by\n  Intention and Politeness for Social Robots", "comments": "Proceedings of ICSR 2018", "journal-ref": null, "doi": "10.1007/978-3-030-05204-1_23", "report-no": null, "categories": "cs.RO cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Service robots need to show appropriate social behaviour in order to be\ndeployed in social environments such as healthcare, education, retail, etc.\nSome of the main capabilities that robots should have are navigation and\nconversational skills. If the person is impatient, the person might want a\nrobot to navigate faster and vice versa. Linguistic features that indicate\npoliteness can provide social cues about a person's patient and impatient\nbehaviour. The novelty presented in this paper is to dynamically incorporate\npoliteness in robotic dialogue systems for navigation. Understanding the\npoliteness in users' speech can be used to modulate the robot behaviour and\nresponses. Therefore, we developed a dialogue system to navigate in an indoor\nenvironment, which produces different robot behaviours and responses based on\nusers' intention and degree of politeness. We deploy and test our system with\nthe Pepper robot that adapts to the changes in user's politeness.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 16:08:50 GMT"}, {"version": "v2", "created": "Wed, 14 Nov 2018 12:49:17 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Bothe", "Chandrakant", ""], ["Garcia", "Fernando", ""], ["Maya", "Arturo Cruz", ""], ["Pandey", "Amit Kumar", ""], ["Wermter", "Stefan", ""]]}, {"id": "1809.07282", "submitter": "Nikita Srivatsan", "authors": "Nikita Srivatsan, Zachary Wojtowicz, Taylor Berg-Kirkpatrick", "title": "Modeling Online Discourse with Coupled Distributed Topics", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a deep, globally normalized topic model that\nincorporates structural relationships connecting documents in socially\ngenerated corpora, such as online forums. Our model (1) captures discursive\ninteractions along observed reply links in addition to traditional topic\ninformation, and (2) incorporates latent distributed representations arranged\nin a deep architecture, which enables a GPU-based mean-field inference\nprocedure that scales efficiently to large data. We apply our model to a new\nsocial media dataset consisting of 13M comments mined from the popular internet\nforum Reddit, a domain that poses significant challenges to models that do not\naccount for relationships connecting user comments. We evaluate against\nexisting methods across multiple metrics including perplexity and metadata\nprediction, and qualitatively analyze the learned interaction patterns.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 16:21:12 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 17:47:25 GMT"}, {"version": "v3", "created": "Fri, 8 May 2020 05:21:13 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Srivatsan", "Nikita", ""], ["Wojtowicz", "Zachary", ""], ["Berg-Kirkpatrick", "Taylor", ""]]}, {"id": "1809.07291", "submitter": "Nina Poerner", "authors": "Nina Poerner, Benjamin Roth and Hinrich Sch\\\"utze", "title": "Interpretable Textual Neuron Representations for NLP", "comments": "BlackboxNLP Workshop at EMNLP 2018 (Extended Abstract)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Input optimization methods, such as Google Deep Dream, create interpretable\nrepresentations of neurons for computer vision DNNs. We propose and evaluate\nways of transferring this technology to NLP. Our results suggest that gradient\nascent with a gumbel softmax layer produces n-gram representations that\noutperform naive corpus search in terms of target neuron activation. The\nrepresentations highlight differences in syntax awareness between the language\nand visual models of the Imaginet architecture.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 16:32:47 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Poerner", "Nina", ""], ["Roth", "Benjamin", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1809.07358", "submitter": "Shrimai Prabhumoye", "authors": "Kangyan Zhou, Shrimai Prabhumoye, Alan W Black", "title": "A Dataset for Document Grounded Conversations", "comments": null, "journal-ref": "Conference on Empirical Methods in Natural Language Processing\n  (EMNLP), 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a document grounded dataset for text conversations. We\ndefine \"Document Grounded Conversations\" as conversations that are about the\ncontents of a specified document. In this dataset the specified documents were\nWikipedia articles about popular movies. The dataset contains 4112\nconversations with an average of 21.43 turns per conversation. This positions\nthis dataset to not only provide a relevant chat history while generating\nresponses but also provide a source of information that the models could use.\nWe describe two neural architectures that provide benchmark performance on the\ntask of generating the next response. We also evaluate our models for\nengagement and fluency, and find that the information from the document helps\nin generating more engaging and fluent responses.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 18:22:44 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Zhou", "Kangyan", ""], ["Prabhumoye", "Shrimai", ""], ["Black", "Alan W", ""]]}, {"id": "1809.07483", "submitter": "Zeyu Dai", "authors": "Zeyu Dai, Ruihong Huang", "title": "Building Context-aware Clause Representations for Situation Entity Type\n  Classification", "comments": "Accepted by EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Capabilities to categorize a clause based on the type of situation entity\n(e.g., events, states and generic statements) the clause introduces to the\ndiscourse can benefit many NLP applications. Observing that the situation\nentity type of a clause depends on discourse functions the clause plays in a\nparagraph and the interpretation of discourse functions depends heavily on\nparagraph-wide contexts, we propose to build context-aware clause\nrepresentations for predicting situation entity types of clauses. Specifically,\nwe propose a hierarchical recurrent neural network model to read a whole\nparagraph at a time and jointly learn representations for all the clauses in\nthe paragraph by extensively modeling context influences and inter-dependencies\nof clauses. Experimental results show that our model achieves the\nstate-of-the-art performance for clause-level situation entity classification\non the genre-rich MASC+Wiki corpus, which approaches human-level performance.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 05:40:46 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Dai", "Zeyu", ""], ["Huang", "Ruihong", ""]]}, {"id": "1809.07485", "submitter": "Takuto Asakura", "authors": "Takuto Asakura, Jin-Dong Kim, Yasunori Yamamoto, Yuka Tateisi and\n  Toshihisa Takagi", "title": "A Quantitative Evaluation of Natural Language Question Interpretation\n  for Question Answering Systems", "comments": "16 pages, 6 figures, JIST 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systematic benchmark evaluation plays an important role in the process of\nimproving technologies for Question Answering (QA) systems. While currently\nthere are a number of existing evaluation methods for natural language (NL) QA\nsystems, most of them consider only the final answers, limiting their utility\nwithin a black box style evaluation. Herein, we propose a subdivided evaluation\napproach to enable finer-grained evaluation of QA systems, and present an\nevaluation tool which targets the NL question (NLQ) interpretation step, an\ninitial step of a QA pipeline. The results of experiments using two public\nbenchmark datasets suggest that we can get a deeper insight about the\nperformance of a QA system using the proposed approach, which should provide a\nbetter guidance for improving the systems, than using black box style\napproaches.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 05:49:40 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Asakura", "Takuto", ""], ["Kim", "Jin-Dong", ""], ["Yamamoto", "Yasunori", ""], ["Tateisi", "Yuka", ""], ["Takagi", "Toshihisa", ""]]}, {"id": "1809.07559", "submitter": "Sanjaye Ramgoolam", "authors": "Sanjaye Ramgoolam", "title": "Permutation Invariant Gaussian Matrix Models", "comments": "47 pages. Revision-small changes in presentation to align with NPB\n  published version, typos corrected", "journal-ref": null, "doi": "10.1016/j.nuclphysb.2019.114682", "report-no": "QMUL-PH-18-17", "categories": "hep-th cs.CL math-ph math.MP math.RT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Permutation invariant Gaussian matrix models were recently developed for\napplications in computational linguistics. A 5-parameter family of models was\nsolved. In this paper, we use a representation theoretic approach to solve the\ngeneral 13-parameter Gaussian model, which can be viewed as a zero-dimensional\nquantum field theory. We express the two linear and eleven quadratic terms in\nthe action in terms of representation theoretic parameters. These parameters\nare coefficients of simple quadratic expressions in terms of appropriate linear\ncombinations of the matrix variables transforming in specific irreducible\nrepresentations of the symmetric group $S_D$ where $D$ is the size of the\nmatrices. They allow the identification of constraints which ensure a\nconvergent Gaussian measure and well-defined expectation values for polynomial\nfunctions of the random matrix at all orders. A graph-theoretic interpretation\nis known to allow the enumeration of permutation invariants of matrices at\nlinear, quadratic and higher orders. We express the expectation values of all\nthe quadratic graph-basis invariants and a selection of cubic and quartic\ninvariants in terms of the representation theoretic parameters of the model.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 10:32:22 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 15:24:40 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Ramgoolam", "Sanjaye", ""]]}, {"id": "1809.07572", "submitter": "Betty Van Aken", "authors": "Betty van Aken, Julian Risch, Ralf Krestel and Alexander L\\\"oser", "title": "Challenges for Toxic Comment Classification: An In-Depth Error Analysis", "comments": "ALW2: 2nd Workshop on Abusive Language Online to be held at EMNLP\n  2018 (Brussels, Belgium), October 31st, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Toxic comment classification has become an active research field with many\nrecently proposed approaches. However, while these approaches address some of\nthe task's challenges others still remain unsolved and directions for further\nresearch are needed. To this end, we compare different deep learning and\nshallow approaches on a new, large comment dataset and propose an ensemble that\noutperforms all individual models. Further, we validate our findings on a\nsecond dataset. The results of the ensemble enable us to perform an extensive\nerror analysis, which reveals open challenges for state-of-the-art methods and\ndirections towards pending future research. These challenges include missing\nparadigmatic context and inconsistent dataset labels.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 11:11:42 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["van Aken", "Betty", ""], ["Risch", "Julian", ""], ["Krestel", "Ralf", ""], ["L\u00f6ser", "Alexander", ""]]}, {"id": "1809.07607", "submitter": "Shrinivasan Patnaikuni", "authors": "Shrinivasan R Patnaik Patnaikuni, Dr. Sachin R Gengaje", "title": "Syntactico-Semantic Reasoning using PCFG, MEBN & PP Attachment Ambiguity", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic context free grammars (PCFG) have been the core of the\nprobabilistic reasoning based parsers for several years especially in the\ncontext of the NLP. Multi entity bayesian networks (MEBN) a First Order Logic\nprobabilistic reasoning methodology is widely adopted and used method for\nuncertainty reasoning. Further upper ontology like Probabilistic Ontology Web\nLanguage (PR-OWL) built using MEBN takes care of probabilistic ontologies which\nmodel and capture the uncertainties inherent in the domain's semantic\ninformation. The paper attempts to establish a link between probabilistic\nreasoning in PCFG and MEBN by proposing a formal description of PCFG driven by\nMEBN leading to usage of PR-OWL modeled ontologies in PCFG parsers.\nFurthermore, the paper outlines an approach to resolve prepositional phrase\n(PP) attachment ambiguity using the proposed mapping between PCFG and MEBN.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 13:20:58 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2019 05:04:28 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Patnaikuni", "Shrinivasan R Patnaik", ""], ["Gengaje", "Dr. Sachin R", ""]]}, {"id": "1809.07615", "submitter": "Desmond Elliott", "authors": "\\'Akos K\\'ad\\'ar, Desmond Elliott, Marc-Alexandre C\\^ot\\'e, Grzegorz\n  Chrupa{\\l}a, Afra Alishahi", "title": "Lessons learned in multilingual grounded language learning", "comments": "CoNLL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown how to learn better visual-semantic embeddings by\nleveraging image descriptions in more than one language. Here, we investigate\nin detail which conditions affect the performance of this type of grounded\nlanguage learning model. We show that multilingual training improves over\nbilingual training, and that low-resource languages benefit from training with\nhigher-resource languages. We demonstrate that a multilingual model can be\ntrained equally well on either translations or comparable sentence pairs, and\nthat annotating the same set of images in multiple language enables further\nimprovements via an additional caption-caption ranking objective.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 13:39:10 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["K\u00e1d\u00e1r", "\u00c1kos", ""], ["Elliott", "Desmond", ""], ["C\u00f4t\u00e9", "Marc-Alexandre", ""], ["Chrupa\u0142a", "Grzegorz", ""], ["Alishahi", "Afra", ""]]}, {"id": "1809.07629", "submitter": "Shang-Yu Su", "authors": "Shang-Yu Su, Yun-Nung Chen", "title": "Investigating Linguistic Pattern Ordering in Hierarchical Natural\n  Language Generation", "comments": "accepted by the 7th IEEE Workshop on Spoken Language Technology (SLT\n  2018). arXiv admin note: text overlap with arXiv:1808.02747", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language generation (NLG) is a critical component in spoken dialogue\nsystem, which can be divided into two phases: (1) sentence planning: deciding\nthe overall sentence structure, (2) surface realization: determining specific\nword forms and flattening the sentence structure into a string. With the rise\nof deep learning, most modern NLG models are based on a sequence-to-sequence\n(seq2seq) model, which basically contains an encoder-decoder structure; these\nNLG models generate sentences from scratch by jointly optimizing sentence\nplanning and surface realization. However, such simple encoder-decoder\narchitecture usually fail to generate complex and long sentences, because the\ndecoder has difficulty learning all grammar and diction knowledge well. This\npaper introduces an NLG model with a hierarchical attentional decoder, where\nthe hierarchy focuses on leveraging linguistic knowledge in a specific order.\nThe experiments show that the proposed method significantly outperforms the\ntraditional seq2seq model with a smaller model size, and the design of the\nhierarchical attentional decoder can be applied to various NLG systems.\nFurthermore, different generation strategies based on linguistic patterns are\ninvestigated and analyzed in order to guide future NLG research work.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 05:40:35 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Su", "Shang-Yu", ""], ["Chen", "Yun-Nung", ""]]}, {"id": "1809.07657", "submitter": "Shyam Upadhyay", "authors": "Shyam Upadhyay and Nitish Gupta and Dan Roth", "title": "Joint Multilingual Supervision for Cross-lingual Entity Linking", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual Entity Linking (XEL) aims to ground entity mentions written in\nany language to an English Knowledge Base (KB), such as Wikipedia. XEL for most\nlanguages is challenging, owing to limited availability of resources as\nsupervision. We address this challenge by developing the first XEL approach\nthat combines supervision from multiple languages jointly. This enables our\napproach to: (a) augment the limited supervision in the target language with\nadditional supervision from a high-resource language (like English), and (b)\ntrain a single entity linking model for multiple languages, improving upon\nindividually trained models for each language. Extensive evaluation on three\nbenchmark datasets across 8 languages shows that our approach significantly\nimproves over the current state-of-the-art. We also provide analyses in two\nlimited resource settings: (a) zero-shot setting, when no supervision in the\ntarget language is available, and in (b) low-resource setting, when some\nsupervision in the target language is available. Our analysis provides insights\ninto the limitations of zero-shot XEL approaches in realistic scenarios, and\nshows the value of joint supervision in low-resource settings.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 14:53:47 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Upadhyay", "Shyam", ""], ["Gupta", "Nitish", ""], ["Roth", "Dan", ""]]}, {"id": "1809.07721", "submitter": "Chunyang Xiao", "authors": "Chunyang Xiao, Marc Dymetman, Claire Gardent", "title": "Symbolic Priors for RNN-based Semantic Parsing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Seq2seq models based on Recurrent Neural Networks (RNNs) have recently\nreceived a lot of attention in the domain of Semantic Parsing for Question\nAnswering. While in principle they can be trained directly on pairs (natural\nlanguage utterances, logical forms), their performance is limited by the amount\nof available data. To alleviate this problem, we propose to exploit various\nsources of prior knowledge: the well-formedness of the logical forms is modeled\nby a weighted context-free grammar; the likelihood that certain entities\npresent in the input utterance are also present in the logical form is modeled\nby weighted finite-state automata. The grammar and automata are combined\ntogether through an efficient intersection algorithm to form a soft guide\n(\"background\") to the RNN. We test our method on an extension of the Overnight\ndataset and show that it not only strongly improves over an RNN baseline, but\nalso outperforms non-RNN models based on rich sets of hand-crafted features.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 16:21:29 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Xiao", "Chunyang", ""], ["Dymetman", "Marc", ""], ["Gardent", "Claire", ""]]}, {"id": "1809.07783", "submitter": "Yee Seng Chan", "authors": "Yee Seng Chan, Joshua Fasching, Haoling Qiu, Bonan Min", "title": "Rapid Customization for Event Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a system for rapidly customizing event extraction capability to\nfind new event types and their arguments. The system allows a user to find,\nexpand and filter event triggers for a new event type by exploring an\nunannotated corpus. The system will then automatically generate mention-level\nevent annotation automatically, and train a Neural Network model for finding\nthe corresponding event. Additionally, the system uses the ACE corpus to train\nan argument model for extracting Actor, Place, and Time arguments for any event\ntypes, including ones not seen in its training data. Experiments show that with\nless than 10 minutes of human effort per event type, the system achieves good\nperformance for 67 novel event types. The code, documentation, and a\ndemonstration video will be released as open source on github.com.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 18:02:49 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Chan", "Yee Seng", ""], ["Fasching", "Joshua", ""], ["Qiu", "Haoling", ""], ["Min", "Bonan", ""]]}, {"id": "1809.07807", "submitter": "Shyam Upadhyay", "authors": "Shyam Upadhyay and Jordan Kodner and Dan Roth", "title": "Bootstrapping Transliteration with Constrained Discovery for\n  Low-Resource Languages", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating the English transliteration of a name written in a foreign script\nis an important and challenging step in multilingual knowledge acquisition and\ninformation extraction. Existing approaches to transliteration generation\nrequire a large (>5000) number of training examples. This difficulty contrasts\nwith transliteration discovery, a somewhat easier task that involves picking a\nplausible transliteration from a given list. In this work, we present a\nbootstrapping algorithm that uses constrained discovery to improve generation,\nand can be used with as few as 500 training examples, which we show can be\nsourced from annotators in a matter of hours. This opens the task to languages\nfor which large number of training examples are unavailable. We evaluate\ntransliteration generation performance itself, as well the improvement it\nbrings to cross-lingual candidate generation for entity linking, a typical\ndownstream task. We present a comprehensive evaluation of our approach on nine\nlanguages, each written in a unique script.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 19:05:29 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Upadhyay", "Shyam", ""], ["Kodner", "Jordan", ""], ["Roth", "Dan", ""]]}, {"id": "1809.07832", "submitter": "Zeynab Raeesy", "authors": "Zeynab Raeesy, Kellen Gillespie, Zhenpei Yang, Chengyuan Ma, Thomas\n  Drugman, Jiacheng Gu, Roland Maas, Ariya Rastrow, Bj\\\"orn Hoffmeister", "title": "LSTM-based Whisper Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents a whisper speech detector in the far-field domain. The\nproposed system consists of a long-short term memory (LSTM) neural network\ntrained on log-filterbank energy (LFBE) acoustic features. This model is\ntrained and evaluated on recordings of human interactions with\nvoice-controlled, far-field devices in whisper and normal phonation modes. We\ncompare multiple inference approaches for utterance-level classification by\nexamining trajectories of the LSTM posteriors. In addition, we engineer a set\nof features based on the signal characteristics inherent to whisper speech, and\nevaluate their effectiveness in further separating whisper from normal speech.\nA benchmarking of these features using multilayer perceptrons (MLP) and LSTMs\nsuggests that the proposed features, in combination with LFBE features, can\nhelp us further improve our classifiers. We prove that, with enough data, the\nLSTM model is indeed as capable of learning whisper characteristics from LFBE\nfeatures alone compared to a simpler MLP model that uses both LFBE and features\nengineered for separating whisper and normal speech. In addition, we prove that\nthe LSTM classifiers accuracy can be further improved with the incorporation of\nthe proposed engineered features.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 20:04:07 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 03:07:01 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Raeesy", "Zeynab", ""], ["Gillespie", "Kellen", ""], ["Yang", "Zhenpei", ""], ["Ma", "Chengyuan", ""], ["Drugman", "Thomas", ""], ["Gu", "Jiacheng", ""], ["Maas", "Roland", ""], ["Rastrow", "Ariya", ""], ["Hoffmeister", "Bj\u00f6rn", ""]]}, {"id": "1809.07853", "submitter": "Diego Krivochen", "authors": "Diego Gabriel Krivochen", "title": "On Folding and Twisting (and whatknot): towards a characterization of\n  workspaces in syntax", "comments": "Manuscript. Do not cite without permission. Comments welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CG cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Syntactic theory has traditionally adopted a constructivist approach, in\nwhich a set of atomic elements are manipulated by combinatory operations to\nyield derived, complex elements. Syntactic structure is thus seen as the result\nor discrete recursive combinatorics over lexical items which get assembled into\nphrases, which are themselves combined to form sentences. This view is common\nto European and American structuralism (e.g., Benveniste, 1971; Hockett, 1958)\nand different incarnations of generative grammar, transformational and\nnon-transformational (Chomsky, 1956, 1995; and Kaplan & Bresnan, 1982; Gazdar,\n1982). Since at least Uriagereka (2002), there has been some attention paid to\nthe fact that syntactic operations must apply somewhere, particularly when\ncopying and movement operations are considered. Contemporary syntactic theory\nhas thus somewhat acknowledged the importance of formalizing aspects of the\nspaces in which elements are manipulated, but it is still a vastly\nunderexplored area. In this paper we explore the consequences of\nconceptualizing syntax as a set of topological operations applying over spaces\nrather than over discrete elements. We argue that there are empirical\nadvantages in such a view for the treatment of long-distance dependencies and\ncross-derivational dependencies: constraints on possible configurations emerge\nfrom the dynamics of the system.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 20:57:43 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 13:41:36 GMT"}, {"version": "v3", "created": "Sun, 30 Dec 2018 22:04:26 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Krivochen", "Diego Gabriel", ""]]}, {"id": "1809.07889", "submitter": "Najoung Kim", "authors": "Najoung Kim, Kyle Rawlins, Benjamin Van Durme, Paul Smolensky", "title": "Predicting the Argumenthood of English Prepositional Phrases", "comments": "AAAI-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distinguishing between arguments and adjuncts of a verb is a longstanding,\nnontrivial problem. In natural language processing, argumenthood information is\nimportant in tasks such as semantic role labeling (SRL) and prepositional\nphrase (PP) attachment disambiguation. In theoretical linguistics, many\ndiagnostic tests for argumenthood exist but they often yield conflicting and\npotentially gradient results. This is especially the case for syntactically\noblique items such as PPs. We propose two PP argumenthood prediction tasks\nbranching from these two motivations: (1) binary argument-adjunct\nclassification of PPs in VerbNet, and (2) gradient argumenthood prediction\nusing human judgments as gold standard, and report results from prediction\nmodels that use pretrained word embeddings and other linguistically informed\nfeatures. Our best results on each task are (1) $acc.=0.955$, $F_1=0.954$\n(ELMo+BiLSTM) and (2) Pearson's $r=0.624$ (word2vec+MLP). Furthermore, we\ndemonstrate the utility of argumenthood prediction in improving sentence\nrepresentations via performance gains on SRL when a sentence encoder is\npretrained with our tasks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 23:21:39 GMT"}, {"version": "v2", "created": "Mon, 24 Sep 2018 19:16:44 GMT"}, {"version": "v3", "created": "Fri, 16 Nov 2018 01:37:51 GMT"}, {"version": "v4", "created": "Sun, 14 Apr 2019 05:34:26 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Kim", "Najoung", ""], ["Rawlins", "Kyle", ""], ["Van Durme", "Benjamin", ""], ["Smolensky", "Paul", ""]]}, {"id": "1809.07950", "submitter": "Wonjin Yoon", "authors": "Wonjin Yoon, Chan Ho So, Jinhyuk Lee, Jaewoo Kang", "title": "CollaboNet: collaboration of deep neural networks for biomedical named\n  entity recognition", "comments": "From DTMBio workshop at CIKM 2018, Turin, Italy. 22-26 October 2018", "journal-ref": "BMC Bioinformatics 2019, 20(Suppl 10):249", "doi": "10.1186/s12859-019-2813-6", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Finding biomedical named entities is one of the most essential\ntasks in biomedical text mining. Recently, deep learning-based approaches have\nbeen applied to biomedical named entity recognition (BioNER) and showed\npromising results. However, as deep learning approaches need an abundant amount\nof training data, a lack of data can hinder performance. BioNER datasets are\nscarce resources and each dataset covers only a small subset of entity types.\nFurthermore, many bio entities are polysemous, which is one of the major\nobstacles in named entity recognition. Results: To address the lack of data and\nthe entity type misclassification problem, we propose CollaboNet which utilizes\na combination of multiple NER models. In CollaboNet, models trained on a\ndifferent dataset are connected to each other so that a target model obtains\ninformation from other collaborator models to reduce false positives. Every\nmodel is an expert on their target entity type and takes turns serving as a\ntarget and a collaborator model during training time. The experimental results\nshow that CollaboNet can be used to greatly reduce the number of false\npositives and misclassified entities including polysemous words. CollaboNet\nachieved state-of-the-art performance in terms of precision, recall and F1\nscore. Conclusions: We demonstrated the benefits of combining multiple models\nfor BioNER. Our model has successfully reduced the number of misclassified\nentities and improved the performance by leveraging multiple datasets annotated\nfor different entity types. Given the state-of-the-art performance of our\nmodel, we believe that CollaboNet can improve the accuracy of downstream\nbiomedical text mining applications such as bio-entity relation extraction.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 05:48:54 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 16:34:50 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Yoon", "Wonjin", ""], ["So", "Chan Ho", ""], ["Lee", "Jinhyuk", ""], ["Kang", "Jaewoo", ""]]}, {"id": "1809.07978", "submitter": "Mathias Creutz", "authors": "Eetu Sj\\\"oblom and Mathias Creutz and Mikko Aulamo", "title": "Paraphrase Detection on Noisy Subtitles in Six Languages", "comments": "To appear in Proceedings of W-NUT at EMNLP 2018, Brussels, Belgium, 1\n  November 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We perform automatic paraphrase detection on subtitle data from the\nOpusparcus corpus comprising six European languages: German, English, Finnish,\nFrench, Russian, and Swedish. We train two types of supervised sentence\nembedding models: a word-averaging (WA) model and a gated recurrent averaging\nnetwork (GRAN) model. We find out that GRAN outperforms WA and is more robust\nto noisy training data. Better results are obtained with more and noisier data\nthan less and cleaner data. Additionally, we experiment on other datasets,\nwithout reaching the same level of performance, because of domain mismatch\nbetween training and test data.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 08:18:12 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Sj\u00f6blom", "Eetu", ""], ["Creutz", "Mathias", ""], ["Aulamo", "Mikko", ""]]}, {"id": "1809.07999", "submitter": "Kyungmin Kim", "authors": "Kyung-Min Kim, Seong-Ho Choi, Jin-Hwa Kim, Byoung-Tak Zhang", "title": "Multimodal Dual Attention Memory for Video Story Question Answering", "comments": "Accepted for ECCV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a video story question-answering (QA) architecture, Multimodal\nDual Attention Memory (MDAM). The key idea is to use a dual attention mechanism\nwith late fusion. MDAM uses self-attention to learn the latent concepts in\nscene frames and captions. Given a question, MDAM uses the second attention\nover these latent concepts. Multimodal fusion is performed after the dual\nattention processes (late fusion). Using this processing pipeline, MDAM learns\nto infer a high-level vision-language joint representation from an abstraction\nof the full video content. We evaluate MDAM on PororoQA and MovieQA datasets\nwhich have large-scale QA annotations on cartoon videos and movies,\nrespectively. For both datasets, MDAM achieves new state-of-the-art results\nwith significant margins compared to the runner-up models. We confirm the best\nperformance of the dual attention mechanism combined with late fusion by\nablation studies. We also perform qualitative analysis by visualizing the\ninference mechanisms of MDAM.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 09:19:12 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Kim", "Kyung-Min", ""], ["Choi", "Seong-Ho", ""], ["Kim", "Jin-Hwa", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "1809.08037", "submitter": "Alon Jacovi", "authors": "Alon Jacovi, Oren Sar Shalom, Yoav Goldberg", "title": "Understanding Convolutional Neural Networks for Text Classification", "comments": "Accepted to \"Analyzing and interpreting neural networks for NLP\"\n  workshop in EMNLP 2018. v2: Added link to online github implementation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an analysis into the inner workings of Convolutional Neural\nNetworks (CNNs) for processing text. CNNs used for computer vision can be\ninterpreted by projecting filters into image space, but for discrete sequence\ninputs CNNs remain a mystery. We aim to understand the method by which the\nnetworks process and classify text. We examine common hypotheses to this\nproblem: that filters, accompanied by global max-pooling, serve as ngram\ndetectors. We show that filters may capture several different semantic classes\nof ngrams by using different activation patterns, and that global max-pooling\ninduces behavior which separates important ngrams from the rest. Finally, we\nshow practical use cases derived from our findings in the form of model\ninterpretability (explaining a trained model by deriving a concrete identity\nfor each filter, bridging the gap between visualization tools in vision tasks\nand NLP) and prediction interpretability (explaining predictions). Code\nimplementation is available online at\ngithub.com/sayaendo/interpreting-cnn-for-text.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 11:03:48 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 10:37:41 GMT"}, {"version": "v3", "created": "Mon, 27 Apr 2020 20:54:08 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Jacovi", "Alon", ""], ["Shalom", "Oren Sar", ""], ["Goldberg", "Yoav", ""]]}, {"id": "1809.08145", "submitter": "Marco Passon", "authors": "Marco Passon and Marco Lippi and Giuseppe Serra and Carlo Tasso", "title": "Predicting the Usefulness of Amazon Reviews Using Off-The-Shelf\n  Argumentation Mining", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet users generate content at unprecedented rates. Building intelligent\nsystems capable of discriminating useful content within this ocean of\ninformation is thus becoming a urgent need. In this paper, we aim to predict\nthe usefulness of Amazon reviews, and to do this we exploit features coming\nfrom an off-the-shelf argumentation mining system. We argue that the usefulness\nof a review, in fact, is strictly related to its argumentative content, whereas\nthe use of an already trained system avoids the costly need of relabeling a\nnovel dataset. Results obtained on a large publicly available corpus support\nthis hypothesis.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 14:31:57 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Passon", "Marco", ""], ["Lippi", "Marco", ""], ["Serra", "Giuseppe", ""], ["Tasso", "Carlo", ""]]}, {"id": "1809.08193", "submitter": "Arkaitz Zubiaga", "authors": "Lev Konstantinovskiy, Oliver Price, Mevan Babakar, Arkaitz Zubiaga", "title": "Towards Automated Factchecking: Developing an Annotation Schema and\n  Benchmark for Consistent Automated Claim Detection", "comments": "Accepted for ACM Digital Threats: Research and Practice (DTRAP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an effort to assist factcheckers in the process of factchecking, we tackle\nthe claim detection task, one of the necessary stages prior to determining the\nveracity of a claim. It consists of identifying the set of sentences, out of a\nlong text, deemed capable of being factchecked. This paper is a collaborative\nwork between Full Fact, an independent factchecking charity, and academic\npartners. Leveraging the expertise of professional factcheckers, we develop an\nannotation schema and a benchmark for automated claim detection that is more\nconsistent across time, topics and annotators than previous approaches. Our\nannotation schema has been used to crowdsource the annotation of a dataset with\nsentences from UK political TV shows. We introduce an approach based on\nuniversal sentence representations to perform the classification, achieving an\nF1 score of 0.83, with over 5% relative improvement over the state-of-the-art\nmethods ClaimBuster and ClaimRank. The system was deployed in production and\nreceived positive user feedback.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 16:24:37 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 08:48:06 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Konstantinovskiy", "Lev", ""], ["Price", "Oliver", ""], ["Babakar", "Mevan", ""], ["Zubiaga", "Arkaitz", ""]]}, {"id": "1809.08205", "submitter": "Nikita Moghe", "authors": "Nikita Moghe, Siddhartha Arora, Suman Banerjee and Mitesh M. Khapra", "title": "Towards Exploiting Background Knowledge for Building Conversation\n  Systems", "comments": "Camera Ready EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing dialog datasets contain a sequence of utterances and responses\nwithout any explicit background knowledge associated with them. This has\nresulted in the development of models which treat conversation as a\nsequence-to-sequence generation task i.e, given a sequence of utterances\ngenerate the response sequence). This is not only an overly simplistic view of\nconversation but it is also emphatically different from the way humans converse\nby heavily relying on their background knowledge about the topic (as opposed to\nsimply relying on the previous sequence of utterances). For example, it is\ncommon for humans to (involuntarily) produce utterances which are copied or\nsuitably modified from background articles they have read about the topic. To\nfacilitate the development of such natural conversation models which mimic the\nhuman process of conversing, we create a new dataset containing movie chats\nwherein each response is explicitly generated by copying and/or modifying\nsentences from unstructured background knowledge such as plots, comments and\nreviews about the movie. We establish baseline results on this dataset (90K\nutterances from 9K conversations) using three different models: (i) pure\ngeneration based models which ignore the background knowledge (ii) generation\nbased models which learn to copy information from the background knowledge when\nrequired and (iii) span prediction based models which predict the appropriate\nresponse span in the background knowledge.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 16:50:17 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Moghe", "Nikita", ""], ["Arora", "Siddhartha", ""], ["Banerjee", "Suman", ""], ["Khapra", "Mitesh M.", ""]]}, {"id": "1809.08267", "submitter": "Michel Galley", "authors": "Jianfeng Gao, Michel Galley, Lihong Li", "title": "Neural Approaches to Conversational AI", "comments": "Foundations and Trends in Information Retrieval (95 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present paper surveys neural approaches to conversational AI that have\nbeen developed in the last few years. We group conversational systems into\nthree categories: (1) question answering agents, (2) task-oriented dialogue\nagents, and (3) chatbots. For each category, we present a review of\nstate-of-the-art neural approaches, draw the connection between them and\ntraditional approaches, and discuss the progress that has been made and\nchallenges still being faced, using specific systems and models as case\nstudies.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 18:42:24 GMT"}, {"version": "v2", "created": "Thu, 13 Dec 2018 18:57:44 GMT"}, {"version": "v3", "created": "Tue, 10 Sep 2019 04:56:51 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Gao", "Jianfeng", ""], ["Galley", "Michel", ""], ["Li", "Lihong", ""]]}, {"id": "1809.08291", "submitter": "Simon DeDeo", "authors": "Christina Boyce-Jacino and Simon DeDeo", "title": "Opacity, Obscurity, and the Geometry of Question-Asking", "comments": "24 pages, 7 tables, 4 figures. Comments welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI physics.soc-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asking questions is a pervasive human activity, but little is understood\nabout what makes them difficult to answer. An analysis of a pair of large\ndatabases, of New York Times crosswords and questions from the quiz-show\nJeopardy, establishes two orthogonal dimensions of question difficulty:\nobscurity (the rarity of the answer) and opacity (the indirectness of question\ncues, operationalized with word2vec). The importance of opacity, and the role\nof synergistic information in resolving it, suggests that accounts of\ndifficulty in terms of prior expectations captures only a part of the\nquestion-asking process. A further regression analysis shows the presence of\nadditional dimensions to question-asking: question complexity, the answer's\nlocal network density, cue intersection, and the presence of signal words. Our\nwork shows how question-askers can help their interlocutors by using contextual\ncues, or, conversely, how a particular kind of unfamiliarity with the domain in\nquestion can make it harder for individuals to learn from others. Taken\ntogether, these results suggest how Bayesian models of question difficulty can\nbe supplemented by process models and accounts of the heuristics individuals\nuse to navigate conceptual spaces.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 20:01:30 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Boyce-Jacino", "Christina", ""], ["DeDeo", "Simon", ""]]}, {"id": "1809.08298", "submitter": "Courtney Napoles", "authors": "Junchao Zheng, Courtney Napoles, Joel Tetreault, and Kostiantyn\n  Omelianchuk", "title": "How do you correct run-on sentences it's not as easy as it seems", "comments": "To appear in W-NUT 2018: Workshop on Noisy User-generated Text (at\n  EMNLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Run-on sentences are common grammatical mistakes but little research has\ntackled this problem to date. This work introduces two machine learning models\nto correct run-on sentences that outperform leading methods for related tasks,\npunctuation restoration and whole-sentence grammatical error correction. Due to\nthe limited annotated data for this error, we experiment with artificially\ngenerating training data from clean newswire text. Our findings suggest\nartificial training data is viable for this task. We discuss implications for\ncorrecting run-ons and other types of mistakes that have low coverage in\nerror-annotated corpora.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 20:13:41 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Zheng", "Junchao", ""], ["Napoles", "Courtney", ""], ["Tetreault", "Joel", ""], ["Omelianchuk", "Kostiantyn", ""]]}, {"id": "1809.08370", "submitter": "Kevin Clark", "authors": "Kevin Clark, Minh-Thang Luong, Christopher D. Manning, Quoc V. Le", "title": "Semi-Supervised Sequence Modeling with Cross-View Training", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised representation learning algorithms such as word2vec and ELMo\nimprove the accuracy of many supervised NLP models, mainly because they can\ntake advantage of large amounts of unlabeled text. However, the supervised\nmodels only learn from task-specific labeled data during the main training\nphase. We therefore propose Cross-View Training (CVT), a semi-supervised\nlearning algorithm that improves the representations of a Bi-LSTM sentence\nencoder using a mix of labeled and unlabeled data. On labeled examples,\nstandard supervised learning is used. On unlabeled examples, CVT teaches\nauxiliary prediction modules that see restricted views of the input (e.g., only\npart of a sentence) to match the predictions of the full model seeing the whole\ninput. Since the auxiliary modules and the full model share intermediate\nrepresentations, this in turn improves the full model. Moreover, we show that\nCVT is particularly effective when combined with multi-task learning. We\nevaluate CVT on five sequence tagging tasks, machine translation, and\ndependency parsing, achieving state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Sat, 22 Sep 2018 02:39:32 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Clark", "Kevin", ""], ["Luong", "Minh-Thang", ""], ["Manning", "Christopher D.", ""], ["Le", "Quoc V.", ""]]}, {"id": "1809.08386", "submitter": "Emily Sheng", "authors": "Emily Sheng and Prem Natarajan", "title": "A Byte-sized Approach to Named Entity Recognition", "comments": "6 pages, 5 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In biomedical literature, it is common for entity boundaries to not align\nwith word boundaries. Therefore, effective identification of entity spans\nrequires approaches capable of considering tokens that are smaller than words.\nWe introduce a novel, subword approach for named entity recognition (NER) that\nuses byte-pair encodings (BPE) in combination with convolutional and recurrent\nneural networks to produce byte-level tags of entities. We present experimental\nresults on several standard biomedical datasets, namely the BioCreative VI\nBio-ID, JNLPBA, and GENETAG datasets. We demonstrate competitive performance\nwhile bypassing the specialized domain expertise needed to create biomedical\ntext tokenization rules.\n", "versions": [{"version": "v1", "created": "Sat, 22 Sep 2018 06:03:29 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Sheng", "Emily", ""], ["Natarajan", "Prem", ""]]}, {"id": "1809.08390", "submitter": "Jiahao Li", "authors": "Junfeng Jiang, Jiahao Li", "title": "Constructing Financial Sentimental Factors in Chinese Market Using\n  Natural Language Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we design an integrated algorithm to evaluate the sentiment of\nChinese market. Firstly, with the help of the web browser automation, we crawl\na lot of news and comments from several influential financial websites\nautomatically. Secondly, we use techniques of Natural Language Processing(NLP)\nunder Chinese context, including tokenization, Word2vec word embedding and\nsemantic database WordNet, to compute Senti-scores of these news and comments,\nand then construct the sentimental factor. Here, we build a finance-specific\nsentimental lexicon so that the sentimental factor can reflect the sentiment of\nfinancial market but not the general sentiments as happiness, sadness, etc.\nThirdly, we also implement an adjustment of the standard sentimental factor.\nOur experimental performance shows that there is a significant correlation\nbetween our standard sentimental factor and the Chinese market, and the\nadjusted factor is even more informative, having a stronger correlation with\nthe Chinese market. Therefore, our sentimental factors can be important\nreferences when making investment decisions. Especially during the Chinese\nmarket crash in 2015, the Pearson correlation coefficient of adjusted\nsentimental factor with SSE is 0.5844, which suggests that our model can\nprovide a solid guidance, especially in the special period when the market is\ninfluenced greatly by public sentiment.\n", "versions": [{"version": "v1", "created": "Sat, 22 Sep 2018 06:35:07 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Jiang", "Junfeng", ""], ["Li", "Jiahao", ""]]}, {"id": "1809.08396", "submitter": "Hamza Harkous", "authors": "Thomas Linden, Rishabh Khandelwal, Hamza Harkous, Kassem Fawaz", "title": "The Privacy Policy Landscape After the GDPR", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The EU General Data Protection Regulation (GDPR) is one of the most demanding\nand comprehensive privacy regulations of all time. A year after it went into\neffect, we study its impact on the landscape of privacy policies online. We\nconduct the first longitudinal, in-depth, and at-scale assessment of privacy\npolicies before and after the GDPR. We gauge the complete consumption cycle of\nthese policies, from the first user impressions until the compliance\nassessment. We create a diverse corpus of two sets of 6,278 unique\nEnglish-language privacy policies from inside and outside the EU, covering\ntheir pre-GDPR and the post-GDPR versions. The results of our tests and\nanalyses suggest that the GDPR has been a catalyst for a major overhaul of the\nprivacy policies inside and outside the EU. This overhaul of the policies,\nmanifesting in extensive textual changes, especially for the EU-based websites,\ncomes at mixed benefits to the users. While the privacy policies have become\nconsiderably longer, our user study with 470 participants on Amazon MTurk\nindicates a significant improvement in the visual representation of privacy\npolicies from the users' perspective for the EU websites. We further develop a\nnew workflow for the automated assessment of requirements in privacy policies.\nUsing this workflow, we show that privacy policies cover more data practices\nand are more consistent with seven compliance requirements post the GDPR. We\nalso assess how transparent the organizations are with their privacy practices\nby performing specificity analysis. In this analysis, we find evidence for\npositive changes triggered by the GDPR, with the specificity level improving on\naverage. Still, we find the landscape of privacy policies to be in a\ntransitional phase; many policies still do not meet several key GDPR\nrequirements or their improved coverage comes with reduced specificity.\n", "versions": [{"version": "v1", "created": "Sat, 22 Sep 2018 07:08:20 GMT"}, {"version": "v2", "created": "Sun, 10 Mar 2019 16:08:06 GMT"}, {"version": "v3", "created": "Mon, 24 Jun 2019 19:49:19 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Linden", "Thomas", ""], ["Khandelwal", "Rishabh", ""], ["Harkous", "Hamza", ""], ["Fawaz", "Kassem", ""]]}, {"id": "1809.08399", "submitter": "Armen Allahverdyan", "authors": "Weibing Deng and Armen E. Allahverdyan", "title": "Relating Zipf's law to textual information", "comments": "14 pages + tables and appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL nlin.AO physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zipf's law is the main regularity of quantitative linguistics. Despite of\nmany works devoted to foundations of this law, it is still unclear whether it\nis only a statistical regularity, or it has deeper relations with\ninformation-carrying structures of the text. This question relates to that of\ndistinguishing a meaningful text (written in an unknown system) from a\nmeaningless set of symbols that mimics statistical features of a text. Here we\ncontribute to resolving these questions by comparing features of the first half\nof a text (from the beginning to the middle) to its second half. This\ncomparison can uncover hidden effects, because the halves have the same values\nof many parameters (style, genre, author's vocabulary {\\it etc}). In all\nstudied texts we saw that for the first half Zipf's law applies from smaller\nranks than in the second half, i.e. the law applies better to the first half.\nAlso, words that hold Zipf's law in the first half are distributed more\nhomogeneously over the text. These features do allow to distinguish a\nmeaningful text from a random sequence of words. Our findings correlate with a\nnumber of textual characteristics that hold in most cases we studied: the first\nhalf is lexically richer, has longer and less repetitive words, more and\nshorter sentences, more punctuation signs and more paragraphs. These\ndifferences between the halves indicate on a higher hierarchic level of text\norganization that so far went unnoticed in text linguistics. They relate the\nvalidity of Zipf's law to textual information. A complete description of this\neffect requires new models, though one existing model can account for some of\nits aspects.\n", "versions": [{"version": "v1", "created": "Sat, 22 Sep 2018 07:37:39 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Deng", "Weibing", ""], ["Allahverdyan", "Armen E.", ""]]}, {"id": "1809.08510", "submitter": "Armen Aghajanyan", "authors": "Armen Aghajanyan, Xia Song, Saurabh Tiwary", "title": "Towards Language Agnostic Universal Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When a bilingual student learns to solve word problems in math, we expect the\nstudent to be able to solve these problem in both languages the student is\nfluent in,even if the math lessons were only taught in one language. However,\ncurrent representations in machine learning are language dependent. In this\nwork, we present a method to decouple the language from the problem by learning\nlanguage agnostic representations and therefore allowing training a model in\none language and applying to a different one in a zero shot fashion. We learn\nthese representations by taking inspiration from linguistics and formalizing\nUniversal Grammar as an optimization process (Chomsky, 2014; Montague, 1970).\nWe demonstrate the capabilities of these representations by showing that the\nmodels trained on a single language using language agnostic representations\nachieve very similar accuracies in other languages.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 01:55:46 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Aghajanyan", "Armen", ""], ["Song", "Xia", ""], ["Tiwary", "Saurabh", ""]]}, {"id": "1809.08621", "submitter": "Valentin Trifonov", "authors": "Valentin Trifonov, Octavian-Eugen Ganea, Anna Potapenko, Thomas\n  Hofmann", "title": "Learning and Evaluating Sparse Interpretable Sentence Embeddings", "comments": "Will be presented at the workshop \"Analyzing and interpreting neural\n  networks for NLP\", collocated with the EMNLP 2018 conference in Brussels", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Previous research on word embeddings has shown that sparse representations,\nwhich can be either learned on top of existing dense embeddings or obtained\nthrough model constraints during training time, have the benefit of increased\ninterpretability properties: to some degree, each dimension can be understood\nby a human and associated with a recognizable feature in the data. In this\npaper, we transfer this idea to sentence embeddings and explore several\napproaches to obtain a sparse representation. We further introduce a novel,\nquantitative and automated evaluation metric for sentence embedding\ninterpretability, based on topic coherence methods. We observe an increase in\ninterpretability compared to dense models, on a dataset of movie dialogs and on\nthe scene descriptions from the MS COCO dataset.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 16:02:03 GMT"}, {"version": "v2", "created": "Tue, 25 Sep 2018 09:17:45 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Trifonov", "Valentin", ""], ["Ganea", "Octavian-Eugen", ""], ["Potapenko", "Anna", ""], ["Hofmann", "Thomas", ""]]}, {"id": "1809.08651", "submitter": "Aditya Gaydhani", "authors": "Aditya Gaydhani, Vikrant Doma, Shrikant Kendre and Laxmi Bhagwat", "title": "Detecting Hate Speech and Offensive Language on Twitter using Machine\n  Learning: An N-gram and TFIDF based Approach", "comments": "To be presented at IEEE International Advance Computing Conference\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Toxic online content has become a major issue in today's world due to an\nexponential increase in the use of internet by people of different cultures and\neducational background. Differentiating hate speech and offensive language is a\nkey challenge in automatic detection of toxic text content. In this paper, we\npropose an approach to automatically classify tweets on Twitter into three\nclasses: hateful, offensive and clean. Using Twitter dataset, we perform\nexperiments considering n-grams as features and passing their term\nfrequency-inverse document frequency (TFIDF) values to multiple machine\nlearning models. We perform comparative analysis of the models considering\nseveral values of n in n-grams and TFIDF normalization methods. After tuning\nthe model giving the best results, we achieve 95.6% accuracy upon evaluating it\non test data. We also create a module which serves as an intermediate between\nuser and Twitter.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 18:19:03 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Gaydhani", "Aditya", ""], ["Doma", "Vikrant", ""], ["Kendre", "Shrikant", ""], ["Bhagwat", "Laxmi", ""]]}, {"id": "1809.08652", "submitter": "Yaman Kumar", "authors": "Raghav Kapoor, Yaman Kumar, Kshitij Rajput, Rajiv Ratn Shah,\n  Ponnurangam Kumaraguru, Roger Zimmermann", "title": "Mind Your Language: Abuse and Offense Detection for Code-Switched\n  Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multilingual societies like the Indian subcontinent, use of code-switched\nlanguages is much popular and convenient for the users. In this paper, we study\noffense and abuse detection in the code-switched pair of Hindi and English\n(i.e. Hinglish), the pair that is the most spoken. The task is made difficult\ndue to non-fixed grammar, vocabulary, semantics and spellings of Hinglish\nlanguage. We apply transfer learning and make a LSTM based model for hate\nspeech classification. This model surpasses the performance shown by the\ncurrent best models to establish itself as the state-of-the-art in the\nunexplored domain of Hinglish offensive text classification.We also release our\nmodel and the embeddings trained for research purposes\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 18:19:46 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Kapoor", "Raghav", ""], ["Kumar", "Yaman", ""], ["Rajput", "Kshitij", ""], ["Shah", "Rajiv Ratn", ""], ["Kumaraguru", "Ponnurangam", ""], ["Zimmermann", "Roger", ""]]}, {"id": "1809.08697", "submitter": "Khyathi Raghavi Chandu", "authors": "Khyathi Raghavi Chandu, Mary Arpita Pyreddy, Matthieu Felix, Narendra\n  Nath Joshi", "title": "Textually Enriched Neural Module Networks for Visual Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Problems at the intersection of language and vision, like visual question\nanswering, have recently been gaining a lot of attention in the field of\nmulti-modal machine learning as computer vision research moves beyond\ntraditional recognition tasks. There has been recent success in visual question\nanswering using deep neural network models which use the linguistic structure\nof the questions to dynamically instantiate network layouts. In the process of\nconverting the question to a network layout, the question is simplified, which\nresults in loss of information in the model. In this paper, we enrich the image\ninformation with textual data using image captions and external knowledge bases\nto generate more coherent answers. We achieve 57.1% overall accuracy on the\ntest-dev open-ended questions from the visual question answering (VQA 1.0) real\nimage dataset.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 23:45:54 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Chandu", "Khyathi Raghavi", ""], ["Pyreddy", "Mary Arpita", ""], ["Felix", "Matthieu", ""], ["Joshi", "Narendra Nath", ""]]}, {"id": "1809.08703", "submitter": "Yi Luan", "authors": "Yonghui Huang, Yunhui Li, Yi Luan", "title": "Monolingual sentence matching for text simplification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work improves monolingual sentence alignment for text simplification,\nspecifically for text in standard and simple Wikipedia. We introduce a\nconvolutional neural network structure to model similarity between two\nsentences. Due to the limitation of available parallel corpora, the model is\ntrained in a semi-supervised way, by using the output of a knowledge-based high\nperformance aligning system. We apply the resulting similarity score to rescore\nthe knowledge-based output, and adapt the model by a small hand-aligned\ndataset. Experiments show that both rescoring and adaptation improve the\nperformance of knowledge-based method.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 04:15:36 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Huang", "Yonghui", ""], ["Li", "Yunhui", ""], ["Luan", "Yi", ""]]}, {"id": "1809.08711", "submitter": "Ahmet Salih Gundogdu", "authors": "Ahmet Salih Gundogdu, Arjun Sanghvi, Keith Harrigian", "title": "Recognizing Film Entities in Podcasts", "comments": "4 pages, 1 figure. To appear in Proceedings of 2018 KDD Workshop on\n  Machine Learning and Data Mining for Podcasts, August 2018, London, UK", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a Named Entity Recognition (NER) system to identify\nfilm titles in podcast audio. Taking inspiration from NER systems for noisy\ntext in social media, we implement a two-stage approach that is robust to\ncomputer transcription errors and does not require significant computational\nexpense to accommodate new film titles/releases. Evaluating on a diverse set of\npodcasts, we demonstrate more than a 20% increase in F1 score across three\nbaseline approaches when combining fuzzy-matching with a linear model aware of\nfilm-specific metadata.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 01:06:46 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Gundogdu", "Ahmet Salih", ""], ["Sanghvi", "Arjun", ""], ["Harrigian", "Keith", ""]]}, {"id": "1809.08718", "submitter": "Ancil Crayton", "authors": "Ancil Crayton", "title": "Central Bank Communication and the Yield Curve: A Semi-Automatic\n  Approach using Non-Negative Matrix Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.CL q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication is now a standard tool in the central bank's monetary policy\ntoolkit. Theoretically, communication provides the central bank an opportunity\nto guide public expectations, and it has been shown empirically that central\nbank communication can lead to financial market fluctuations. However, there\nhas been little research into which dimensions or topics of information are\nmost important in causing these fluctuations. We develop a semi-automatic\nmethodology that summarizes the FOMC statements into its main themes,\nautomatically selects the best model based on coherency, and assesses whether\nthere is a significant impact of these themes on the shape of the U.S Treasury\nyield curve using topic modeling methods from the machine learning literature.\nOur findings suggest that the FOMC statements can be decomposed into three\ntopics: (i) information related to the economic conditions and the mandates,\n(ii) information related to monetary policy tools and intermediate targets, and\n(iii) information related to financial markets and the financial crisis. We\nfind that statements are most influential during the financial crisis and the\neffects are mostly present in the curvature of the yield curve through\ninformation related to the financial theme.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 01:46:05 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Crayton", "Ancil", ""]]}, {"id": "1809.08726", "submitter": "Kilol Gupta", "authors": "Tuhin Chakrabarty and Kilol Gupta", "title": "Context-Aware Attention for Understanding Twitter Abuse", "comments": "The full published version of this work is available at:\n  \\url{https://www.aclweb.org/anthology/W19-3508/}. Please use the version\n  published in the ACL anthology for citation purposes", "journal-ref": "Proc. 3rd Workshop on Abusive Language Online, pp. 70-79, 2019", "doi": "10.18653/v1/W19-3508", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The original goal of any social media platform is to facilitate users to\nindulge in healthy and meaningful conversations. But more often than not, it\nhas been found that it becomes an avenue for wanton attacks. We want to\nalleviate this issue and hence we try to provide a detailed analysis of how\nabusive behavior can be monitored in Twitter. The complexity of the natural\nlanguage constructs makes this task challenging. We show how applying\ncontextual attention to Long Short Term Memory networks help us give near state\nof art results on multiple benchmarks abuse detection data sets from Twitter.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 02:18:01 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 22:34:49 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Chakrabarty", "Tuhin", ""], ["Gupta", "Kilol", ""]]}, {"id": "1809.08730", "submitter": "Shuyang Cao", "authors": "Shuyang Cao, Xipeng Qiu, Xuanjing Huang", "title": "Deformable Stacked Structure for Named Entity Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture for named entity recognition has achieved great success\nin the field of natural language processing. Currently, the dominating\narchitecture consists of a bi-directional recurrent neural network (RNN) as the\nencoder and a conditional random field (CRF) as the decoder. In this paper, we\npropose a deformable stacked structure for named entity recognition, in which\nthe connections between two adjacent layers are dynamically established. We\nevaluate the deformable stacked structure by adapting it to different layers.\nOur model achieves the state-of-the-art performances on the OntoNotes dataset.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 02:42:40 GMT"}, {"version": "v2", "created": "Fri, 28 Sep 2018 07:37:12 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Cao", "Shuyang", ""], ["Qiu", "Xipeng", ""], ["Huang", "Xuanjing", ""]]}, {"id": "1809.08731", "submitter": "Katharina Kann", "authors": "Katharina Kann, Sascha Rothe and Katja Filippova", "title": "Sentence-Level Fluency Evaluation: References Help, But Can Be Spared!", "comments": "Accepted to CoNLL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by recent findings on the probabilistic modeling of acceptability\njudgments, we propose syntactic log-odds ratio (SLOR), a normalized language\nmodel score, as a metric for referenceless fluency evaluation of natural\nlanguage generation output at the sentence level. We further introduce WPSLOR,\na novel WordPiece-based version, which harnesses a more compact language model.\nEven though word-overlap metrics like ROUGE are computed with the help of\nhand-written references, our referenceless methods obtain a significantly\nhigher correlation with human fluency scores on a benchmark dataset of\ncompressed sentences. Finally, we present ROUGE-LM, a reference-based metric\nwhich is a natural extension of WPSLOR to the case of available references. We\nshow that ROUGE-LM yields a significantly higher correlation with human\njudgments than all baseline metrics, including WPSLOR on its own.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 02:42:42 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Kann", "Katharina", ""], ["Rothe", "Sascha", ""], ["Filippova", "Katja", ""]]}, {"id": "1809.08733", "submitter": "Katharina Kann", "authors": "Katharina Kann and Hinrich Sch\\\"utze", "title": "Neural Transductive Learning and Beyond: Morphological Generation in the\n  Minimal-Resource Setting", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural state-of-the-art sequence-to-sequence (seq2seq) models often do not\nperform well for small training sets. We address paradigm completion, the\nmorphological task of, given a partial paradigm, generating all missing forms.\nWe propose two new methods for the minimal-resource setting: (i) Paradigm\ntransduction: Since we assume only few paradigms available for training, neural\nseq2seq models are able to capture relationships between paradigm cells, but\nare tied to the idiosyncracies of the training set. Paradigm transduction\nmitigates this problem by exploiting the input subset of inflected forms at\ntest time. (ii) Source selection with high precision (SHIP): Multi-source\nmodels which learn to automatically select one or multiple sources to predict a\ntarget inflection do not perform well in the minimal-resource setting. SHIP is\nan alternative to identify a reliable source if training data is limited. On a\n52-language benchmark dataset, we outperform the previous state of the art by\nup to 9.71% absolute accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 02:56:31 GMT"}, {"version": "v2", "created": "Thu, 9 May 2019 13:30:35 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Kann", "Katharina", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1809.08738", "submitter": "Mikhail Yurochkin", "authors": "Mikhail Yurochkin, Zhiwei Fan, Aritra Guha, Paraschos Koutris and\n  XuanLong Nguyen", "title": "Scalable inference of topic evolution via models for latent geometric\n  structures", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop new models and algorithms for learning the temporal dynamics of\nthe topic polytopes and related geometric objects that arise in topic model\nbased inference. Our model is nonparametric Bayesian and the corresponding\ninference algorithm is able to discover new topics as the time progresses. By\nexploiting the connection between the modeling of topic polytope evolution,\nBeta-Bernoulli process and the Hungarian matching algorithm, our method is\nshown to be several orders of magnitude faster than existing topic modeling\napproaches, as demonstrated by experiments working with several million\ndocuments in under two dozens of minutes.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 03:23:07 GMT"}, {"version": "v2", "created": "Sun, 28 Apr 2019 23:59:08 GMT"}, {"version": "v3", "created": "Sat, 2 Nov 2019 03:49:37 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Yurochkin", "Mikhail", ""], ["Fan", "Zhiwei", ""], ["Guha", "Aritra", ""], ["Koutris", "Paraschos", ""], ["Nguyen", "XuanLong", ""]]}, {"id": "1809.08761", "submitter": "Mahmoud Azab", "authors": "Mahmoud Azab, Mingzhe Wang, Max Smith, Noriyuki Kojima, Jia Deng, Rada\n  Mihalcea", "title": "Speaker Naming in Movies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new model for speaker naming in movies that leverages visual,\ntextual, and acoustic modalities in an unified optimization framework. To\nevaluate the performance of our model, we introduce a new dataset consisting of\nsix episodes of the Big Bang Theory TV show and eighteen full movies covering\ndifferent genres. Our experiments show that our multimodal model significantly\noutperforms several competitive baselines on the average weighted F-score\nmetric. To demonstrate the effectiveness of our framework, we design an\nend-to-end memory network model that leverages our speaker naming model and\nachieves state-of-the-art results on the subtitles task of the MovieQA 2017\nChallenge.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 05:00:05 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Azab", "Mahmoud", ""], ["Wang", "Mingzhe", ""], ["Smith", "Max", ""], ["Kojima", "Noriyuki", ""], ["Deng", "Jia", ""], ["Mihalcea", "Rada", ""]]}, {"id": "1809.08799", "submitter": "Christian Reisswig", "authors": "Anoop Raveendra Katti, Christian Reisswig, Cordula Guder, Sebastian\n  Brarda, Steffen Bickel, Johannes H\\\"ohne, Jean Baptiste Faddoul", "title": "Chargrid: Towards Understanding 2D Documents", "comments": "To be published at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel type of text representation that preserves the 2D layout\nof a document. This is achieved by encoding each document page as a\ntwo-dimensional grid of characters. Based on this representation, we present a\ngeneric document understanding pipeline for structured documents. This pipeline\nmakes use of a fully convolutional encoder-decoder network that predicts a\nsegmentation mask and bounding boxes. We demonstrate its capabilities on an\ninformation extraction task from invoices and show that it significantly\noutperforms approaches based on sequential text or document images.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 08:37:02 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Katti", "Anoop Raveendra", ""], ["Reisswig", "Christian", ""], ["Guder", "Cordula", ""], ["Brarda", "Sebastian", ""], ["Bickel", "Steffen", ""], ["H\u00f6hne", "Johannes", ""], ["Faddoul", "Jean Baptiste", ""]]}, {"id": "1809.08826", "submitter": "Lyan Verwimp", "authors": "Lyan Verwimp, Joris Pelemans, Hugo Van hamme, Patrick Wambacq", "title": "Information-Weighted Neural Cache Language Models for ASR", "comments": "Accepted for publication at SLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural cache language models (LMs) extend the idea of regular cache language\nmodels by making the cache probability dependent on the similarity between the\ncurrent context and the context of the words in the cache. We make an extensive\ncomparison of 'regular' cache models with neural cache models, both in terms of\nperplexity and WER after rescoring first-pass ASR results. Furthermore, we\npropose two extensions to this neural cache model that make use of the content\nvalue/information weight of the word: firstly, combining the cache probability\nand LM probability with an information-weighted interpolation and secondly,\nselectively adding only content words to the cache. We obtain a 29.9%/32.1%\n(validation/test set) relative improvement in perplexity with respect to a\nbaseline LSTM LM on the WikiText-2 dataset, outperforming previous work on\nneural cache LMs. Additionally, we observe significant WER reductions with\nrespect to the baseline model on the WSJ ASR task.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 10:07:27 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Verwimp", "Lyan", ""], ["Pelemans", "Joris", ""], ["Van hamme", "Hugo", ""], ["Wambacq", "Patrick", ""]]}, {"id": "1809.08887", "submitter": "Tao Yu", "authors": "Tao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga, Dongxu Wang, Zifan\n  Li, James Ma, Irene Li, Qingning Yao, Shanelle Roman, Zilin Zhang, Dragomir\n  Radev", "title": "Spider: A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain\n  Semantic Parsing and Text-to-SQL Task", "comments": "EMNLP 2018, Long Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Spider, a large-scale, complex and cross-domain semantic parsing\nand text-to-SQL dataset annotated by 11 college students. It consists of 10,181\nquestions and 5,693 unique complex SQL queries on 200 databases with multiple\ntables, covering 138 different domains. We define a new complex and\ncross-domain semantic parsing and text-to-SQL task where different complex SQL\nqueries and databases appear in train and test sets. In this way, the task\nrequires the model to generalize well to both new SQL queries and new database\nschemas. Spider is distinct from most of the previous semantic parsing tasks\nbecause they all use a single database and the exact same programs in the train\nset and the test set. We experiment with various state-of-the-art models and\nthe best model achieves only 12.4% exact matching accuracy on a database split\nsetting. This shows that Spider presents a strong challenge for future\nresearch. Our dataset and task are publicly available at\nhttps://yale-lily.github.io/spider\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 13:03:13 GMT"}, {"version": "v2", "created": "Tue, 25 Sep 2018 05:47:19 GMT"}, {"version": "v3", "created": "Mon, 8 Oct 2018 08:14:41 GMT"}, {"version": "v4", "created": "Thu, 25 Oct 2018 20:36:13 GMT"}, {"version": "v5", "created": "Sat, 2 Feb 2019 23:53:18 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Yu", "Tao", ""], ["Zhang", "Rui", ""], ["Yang", "Kai", ""], ["Yasunaga", "Michihiro", ""], ["Wang", "Dongxu", ""], ["Li", "Zifan", ""], ["Ma", "James", ""], ["Li", "Irene", ""], ["Yao", "Qingning", ""], ["Roman", "Shanelle", ""], ["Zhang", "Zilin", ""], ["Radev", "Dragomir", ""]]}, {"id": "1809.08895", "submitter": "Naihan Li", "authors": "Naihan Li, Shujie Liu, Yanqing Liu, Sheng Zhao, Ming Liu, Ming Zhou", "title": "Neural Speech Synthesis with Transformer Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although end-to-end neural text-to-speech (TTS) methods (such as Tacotron2)\nare proposed and achieve state-of-the-art performance, they still suffer from\ntwo problems: 1) low efficiency during training and inference; 2) hard to model\nlong dependency using current recurrent neural networks (RNNs). Inspired by the\nsuccess of Transformer network in neural machine translation (NMT), in this\npaper, we introduce and adapt the multi-head attention mechanism to replace the\nRNN structures and also the original attention mechanism in Tacotron2. With the\nhelp of multi-head self-attention, the hidden states in the encoder and decoder\nare constructed in parallel, which improves the training efficiency. Meanwhile,\nany two inputs at different times are connected directly by self-attention\nmechanism, which solves the long range dependency problem effectively. Using\nphoneme sequences as input, our Transformer TTS network generates mel\nspectrograms, followed by a WaveNet vocoder to output the final audio results.\nExperiments are conducted to test the efficiency and performance of our new\nnetwork. For the efficiency, our Transformer TTS network can speed up the\ntraining about 4.25 times faster compared with Tacotron2. For the performance,\nrigorous human tests show that our proposed model achieves state-of-the-art\nperformance (outperforms Tacotron2 with a gap of 0.048) and is very close to\nhuman quality (4.39 vs 4.44 in MOS).\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 07:41:17 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 08:57:52 GMT"}, {"version": "v3", "created": "Wed, 30 Jan 2019 12:40:57 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Li", "Naihan", ""], ["Liu", "Shujie", ""], ["Liu", "Yanqing", ""], ["Zhao", "Sheng", ""], ["Liu", "Ming", ""], ["Zhou", "Ming", ""]]}, {"id": "1809.08899", "submitter": "Christopher Ormerod", "authors": "Christopher M. Ormerod and Amy E. Harris", "title": "Neural network approach to classifying alarming student responses to\n  online assessment", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated scoring engines are increasingly being used to score the free-form\ntext responses that students give to questions. Such engines are not designed\nto appropriately deal with responses that a human reader would find alarming\nsuch as those that indicate an intention to self-harm or harm others, responses\nthat allude to drug abuse or sexual abuse or any response that would elicit\nconcern for the student writing the response. Our neural network models have\nbeen designed to help identify these anomalous responses from a large\ncollection of typical responses that students give. The responses identified by\nthe neural network can be assessed for urgency, severity, and validity more\nquickly by a team of reviewers than otherwise possible. Given the anomalous\nnature of these types of responses, our goal is to maximize the chance of\nflagging these responses for review given the constraint that only a fixed\npercentage of responses can viably be assessed by a team of reviewers.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 14:29:22 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Ormerod", "Christopher M.", ""], ["Harris", "Amy E.", ""]]}, {"id": "1809.08909", "submitter": "Zhanyu Ma", "authors": "Zhanyu Ma and Hong Yu", "title": "Language Identification with Deep Bottleneck Features", "comments": "Preliminary work report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we proposed an end-to-end short utterances speech language\nidentification(SLD) approach based on a Long Short Term Memory (LSTM) neural\nnetwork which is special suitable for SLD application in intelligent vehicles.\nFeatures used for LSTM learning are generated by a transfer learning method.\nBottle-neck features of a deep neural network (DNN) which are trained for\nmandarin acoustic-phonetic classification are used for LSTM training. In order\nto improve the SLD accuracy of short utterances a phase vocoder based\ntime-scale modification(TSM) method is used to reduce and increase speech rated\nof the test utterance. By splicing the normal, speech rate reduced and\nincreased utterances, we can extend length of test utterances so as to improved\nimproved the performance of the SLD system. The experimental results on\nAP17-OLR database shows that the proposed methods can improve the performance\nof SLD, especially on short utterance with 1s and 3s durations.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 19:34:54 GMT"}, {"version": "v2", "created": "Sun, 2 Feb 2020 09:57:14 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Ma", "Zhanyu", ""], ["Yu", "Hong", ""]]}, {"id": "1809.08927", "submitter": "Zixing Zhang", "authors": "Jing Han, Zixing Zhang, Nicholas Cummins, and Bj\\\"orn Schuller", "title": "Adversarial Training in Affective Computing and Sentiment Analysis:\n  Recent Advances and Perspectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past few years, adversarial training has become an extremely active\nresearch topic and has been successfully applied to various Artificial\nIntelligence (AI) domains. As a potentially crucial technique for the\ndevelopment of the next generation of emotional AI systems, we herein provide a\ncomprehensive overview of the application of adversarial training to affective\ncomputing and sentiment analysis. Various representative adversarial training\nalgorithms are explained and discussed accordingly, aimed at tackling diverse\nchallenges associated with emotional AI systems. Further, we highlight a range\nof potential future research directions. We expect that this overview will help\nfacilitate the development of adversarial training for affective computing and\nsentiment analysis in both the academic and industrial communities.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 08:27:01 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Han", "Jing", ""], ["Zhang", "Zixing", ""], ["Cummins", "Nicholas", ""], ["Schuller", "Bj\u00f6rn", ""]]}, {"id": "1809.08928", "submitter": "Preslav Nakov", "authors": "Shafiq Joty, Lluis Marquez, Preslav Nakov", "title": "Joint Multitask Learning for Community Question Answering Using\n  Task-Specific Embeddings", "comments": "community question answering, task-specific embeddings, multi-task\n  learning, EMNLP-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address jointly two important tasks for Question Answering in community\nforums: given a new question, (i) find related existing questions, and (ii)\nfind relevant answers to this new question. We further use an auxiliary task to\ncomplement the previous two, i.e., (iii) find good answers with respect to the\nthread question in a question-comment thread. We use deep neural networks\n(DNNs) to learn meaningful task-specific embeddings, which we then incorporate\ninto a conditional random field (CRF) model for the multitask setting,\nperforming joint learning over a complex graph structure. While DNNs alone\nachieve competitive results when trained to produce the embeddings, the CRF,\nwhich makes use of the embeddings and the dependencies between the tasks,\nimproves the results significantly and consistently across a variety of\nevaluation metrics, thus showing the complementarity of DNNs and structured\nlearning.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 13:49:14 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Joty", "Shafiq", ""], ["Marquez", "Lluis", ""], ["Nakov", "Preslav", ""]]}, {"id": "1809.08935", "submitter": "Georgios Balikas", "authors": "Georgios Balikas", "title": "Lexical Bias In Essay Level Prediction", "comments": "CAp 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatically predicting the level of non-native English speakers given their\nwritten essays is an interesting machine learning problem. In this work I\npresent the system \"balikasg\" that achieved the state-of-the-art performance in\nthe CAp 2018 data science challenge among 14 systems. I detail the feature\nextraction, feature engineering and model selection steps and I evaluate how\nthese decisions impact the system's performance. The paper concludes with\nremarks for future work.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 12:04:44 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Balikas", "Georgios", ""]]}, {"id": "1809.08962", "submitter": "William L\\'echelle", "authors": "William L\\'echelle, Fabrizio Gotti, Philippe Langlais", "title": "WiRe57 : A Fine-Grained Benchmark for Open Information Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We build a reference for the task of Open Information Extraction, on five\ndocuments. We tentatively resolve a number of issues that arise, including\ninference and granularity. We seek to better pinpoint the requirements for the\ntask. We produce our annotation guidelines specifying what is correct to\nextract and what is not. In turn, we use this reference to score existing Open\nIE systems. We address the non-trivial problem of evaluating the extractions\nproduced by systems against the reference tuples, and share our evaluation\nscript. Among seven compared extractors, we find the MinIE system to perform\nbest.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 14:19:59 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2019 04:53:05 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["L\u00e9chelle", "William", ""], ["Gotti", "Fabrizio", ""], ["Langlais", "Philippe", ""]]}, {"id": "1809.09078", "submitter": "Xiao Liu", "authors": "Xiao Liu and Zhunchen Luo and Heyan Huang", "title": "Jointly Multiple Events Extraction via Attention-based Graph Information\n  Aggregation", "comments": "accepted by EMNLP 2018", "journal-ref": "EMNLP. 1 (2018) 1247-1256", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event extraction is of practical utility in natural language processing. In\nthe real world, it is a common phenomenon that multiple events existing in the\nsame sentence, where extracting them are more difficult than extracting a\nsingle event. Previous works on modeling the associations between events by\nsequential modeling methods suffer a lot from the low efficiency in capturing\nvery long-range dependencies. In this paper, we propose a novel Jointly\nMultiple Events Extraction (JMEE) framework to jointly extract multiple event\ntriggers and arguments by introducing syntactic shortcut arcs to enhance\ninformation flow and attention-based graph convolution networks to model graph\ninformation. The experiment results demonstrate that our proposed framework\nachieves competitive results compared with state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 17:46:27 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 10:22:06 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Liu", "Xiao", ""], ["Luo", "Zhunchen", ""], ["Huang", "Heyan", ""]]}, {"id": "1809.09190", "submitter": "Parisa Hagahni", "authors": "Parisa Haghani, Arun Narayanan, Michiel Bacchiani, Galen Chuang,\n  Neeraj Gaur, Pedro Moreno, Rohit Prabhavalkar, Zhongdi Qu, Austin Waters", "title": "From Audio to Semantics: Approaches to end-to-end spoken language\n  understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional spoken language understanding systems consist of two main\ncomponents: an automatic speech recognition module that converts audio to a\ntranscript, and a natural language understanding module that transforms the\nresulting text (or top N hypotheses) into a set of domains, intents, and\narguments. These modules are typically optimized independently. In this paper,\nwe formulate audio to semantic understanding as a sequence-to-sequence problem\n[1]. We propose and compare various encoder-decoder based approaches that\noptimize both modules jointly, in an end-to-end manner. Evaluations on a\nreal-world task show that 1) having an intermediate text representation is\ncrucial for the quality of the predicted semantics, especially the intent\narguments and 2) jointly optimizing the full system improves overall accuracy\nof prediction. Compared to independently trained models, our best jointly\ntrained model achieves similar domain and intent prediction F1 scores, but\nimproves argument word error rate by 18% relative.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 19:46:24 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Haghani", "Parisa", ""], ["Narayanan", "Arun", ""], ["Bacchiani", "Michiel", ""], ["Chuang", "Galen", ""], ["Gaur", "Neeraj", ""], ["Moreno", "Pedro", ""], ["Prabhavalkar", "Rohit", ""], ["Qu", "Zhongdi", ""], ["Waters", "Austin", ""]]}, {"id": "1809.09194", "submitter": "Xiaodong Liu", "authors": "Xiaodong Liu, Wei Li, Yuwei Fang, Aerin Kim, Kevin Duh and Jianfeng\n  Gao", "title": "Stochastic Answer Networks for SQuAD 2.0", "comments": "6 pages, 2 figures and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an extension of the Stochastic Answer Network (SAN), one\nof the state-of-the-art machine reading comprehension models, to be able to\njudge whether a question is unanswerable or not. The extended SAN contains two\ncomponents: a span detector and a binary classifier for judging whether the\nquestion is unanswerable, and both components are jointly optimized.\nExperiments show that SAN achieves the results competitive to the\nstate-of-the-art on Stanford Question Answering Dataset (SQuAD) 2.0. To\nfacilitate the research on this field, we release our code:\nhttps://github.com/kevinduh/san_mrc.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 19:58:07 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Liu", "Xiaodong", ""], ["Li", "Wei", ""], ["Fang", "Yuwei", ""], ["Kim", "Aerin", ""], ["Duh", "Kevin", ""], ["Gao", "Jianfeng", ""]]}, {"id": "1809.09296", "submitter": "Xiang Kong", "authors": "Xiang Kong, Qizhe Xie, Zihang Dai, Eduard Hovy", "title": "Fast and Simple Mixture of Softmaxes with BPE and Hybrid-LightRNN for\n  Language Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixture of Softmaxes (MoS) has been shown to be effective at addressing the\nexpressiveness limitation of Softmax-based models. Despite the known advantage,\nMoS is practically sealed by its large consumption of memory and computational\ntime due to the need of computing multiple Softmaxes. In this work, we set out\nto unleash the power of MoS in practical applications by investigating improved\nword coding schemes, which could effectively reduce the vocabulary size and\nhence relieve the memory and computation burden. We show both BPE and our\nproposed Hybrid-LightRNN lead to improved encoding mechanisms that can halve\nthe time and memory consumption of MoS without performance losses. With MoS, we\nachieve an improvement of 1.5 BLEU scores on IWSLT 2014 German-to-English\ncorpus and an improvement of 0.76 CIDEr score on image captioning. Moreover, on\nthe larger WMT 2014 machine translation dataset, our MoS-boosted Transformer\nyields 29.5 BLEU score for English-to-German and 42.1 BLEU score for\nEnglish-to-French, outperforming the single-Softmax Transformer by 0.8 and 0.4\nBLEU scores respectively and achieving the state-of-the-art result on WMT 2014\nEnglish-to-German task.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 03:02:38 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 19:15:22 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Kong", "Xiang", ""], ["Xie", "Qizhe", ""], ["Dai", "Zihang", ""], ["Hovy", "Eduard", ""]]}, {"id": "1809.09408", "submitter": "Shengbin Jia", "authors": "Shengbin Jia and Yang Xiang", "title": "Chinese User Service Intention Classification Based on Hybrid Neural\n  Network", "comments": "CMVIT2019", "journal-ref": null, "doi": "10.1088/1742-6596/1229/1/012054", "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to satisfy the consumers' increasing personalized service demand,\nthe Intelligent service has arisen. User service intention recognition is an\nimportant challenge for intelligent service system to provide precise service.\nIt is difficult for the intelligent system to understand the semantics of user\ndemand which leads to poor recognition effect, because of the noise in user\nrequirement descriptions. Therefore, a hybrid neural network classification\nmodel based on BiLSTM and CNN is proposed to recognize users service\nintentions. The model can fuse the temporal semantics and spatial semantics of\nthe user descriptions. The experimental results show that our model achieves a\nbetter effect compared with other models, reaching 0.94 on the F1 score.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 10:56:20 GMT"}, {"version": "v2", "created": "Sat, 25 May 2019 08:53:05 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Jia", "Shengbin", ""], ["Xiang", "Yang", ""]]}, {"id": "1809.09528", "submitter": "Abdalghani Abujabal", "authors": "Abdalghani Abujabal, Rishiraj Saha Roy, Mohamed Yahya, Gerhard Weikum", "title": "ComQA: A Community-sourced Dataset for Complex Factoid Question\n  Answering with Paraphrase Clusters", "comments": "11 pages, NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To bridge the gap between the capabilities of the state-of-the-art in factoid\nquestion answering (QA) and what users ask, we need large datasets of real user\nquestions that capture the various question phenomena users are interested in,\nand the diverse ways in which these questions are formulated. We introduce\nComQA, a large dataset of real user questions that exhibit different\nchallenging aspects such as compositionality, temporal reasoning, and\ncomparisons. ComQA questions come from the WikiAnswers community QA platform,\nwhich typically contains questions that are not satisfactorily answerable by\nexisting search engine technology. Through a large crowdsourcing effort, we\nclean the question dataset, group questions into paraphrase clusters, and\nannotate clusters with their answers. ComQA contains 11,214 questions grouped\ninto 4,834 paraphrase clusters. We detail the process of constructing ComQA,\nincluding the measures taken to ensure its high quality while making effective\nuse of crowdsourcing. We also present an extensive analysis of the dataset and\nthe results achieved by state-of-the-art systems on ComQA, demonstrating that\nour dataset can be a driver of future research on QA.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 14:54:26 GMT"}, {"version": "v2", "created": "Wed, 10 Apr 2019 09:05:16 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Abujabal", "Abdalghani", ""], ["Roy", "Rishiraj Saha", ""], ["Yahya", "Mohamed", ""], ["Weikum", "Gerhard", ""]]}, {"id": "1809.09548", "submitter": "Robert B. Allen", "authors": "Robert B. Allen, Jaihyun Park", "title": "Coordinating and Integrating Faceted Classification with Rich Semantic\n  Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Faceted classifications define dimensions for the types of entities included.\nIn effect, the facets provide an \"ontological commitment\". We compare a faceted\nthesaurus, the Art and Architecture Thesaurus (AAT), with ontologies derived\nfrom the Basic Formal Ontology (BFO2), which is an upper (or formal) ontology\nwidely used to describe entities in biomedicine. We consider how the AAT and\nBFO2-based ontologies could be coordinated and integrated into a Human Activity\nand Infrastructure Foundry (HAIF). To extend the AAT to enable this\ncoordination and integration, we describe how a wider range of relationships\namong its terms could be introduced. Using these extensions, we explore richer\nmodeling of topics from AAT that deal with Technology. Finally, we consider how\nontology-based frames and semantic role frames can be integrated to make rich\nsemantic statements about changes in the world.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 15:29:11 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Allen", "Robert B.", ""], ["Park", "Jaihyun", ""]]}, {"id": "1809.09600", "submitter": "Zhilin Yang", "authors": "Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William W. Cohen,\n  Ruslan Salakhutdinov, Christopher D. Manning", "title": "HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question\n  Answering", "comments": "EMNLP 2018 long paper. The first three authors contribute equally.\n  Data, code, and blog posts available at https://hotpotqa.github.io/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing question answering (QA) datasets fail to train QA systems to perform\ncomplex reasoning and provide explanations for answers. We introduce HotpotQA,\na new dataset with 113k Wikipedia-based question-answer pairs with four key\nfeatures: (1) the questions require finding and reasoning over multiple\nsupporting documents to answer; (2) the questions are diverse and not\nconstrained to any pre-existing knowledge bases or knowledge schemas; (3) we\nprovide sentence-level supporting facts required for reasoning, allowing QA\nsystems to reason with strong supervision and explain the predictions; (4) we\noffer a new type of factoid comparison questions to test QA systems' ability to\nextract relevant facts and perform necessary comparison. We show that HotpotQA\nis challenging for the latest QA systems, and the supporting facts enable\nmodels to improve performance and make explainable predictions.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 17:28:20 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Yang", "Zhilin", ""], ["Qi", "Peng", ""], ["Zhang", "Saizheng", ""], ["Bengio", "Yoshua", ""], ["Cohen", "William W.", ""], ["Salakhutdinov", "Ruslan", ""], ["Manning", "Christopher D.", ""]]}, {"id": "1809.09605", "submitter": "Rahul Gupta", "authors": "Chengwei Su, Rahul Gupta, Shankar Ananthakrishnan, Spyros Matsoukas", "title": "A Re-ranker Scheme for Integrating Large Scale NLU models", "comments": "7 pages, Accepted to IEEE SLT-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large scale Natural Language Understanding (NLU) systems are typically\ntrained on large quantities of data, requiring a fast and scalable training\nstrategy. A typical design for NLU systems consists of domain-level NLU modules\n(domain classifier, intent classifier and named entity recognizer). Hypotheses\n(NLU interpretations consisting of various intent+slot combinations) from these\ndomain specific modules are typically aggregated with another downstream\ncomponent. The re-ranker integrates outputs from domain-level recognizers,\nreturning a scored list of cross domain hypotheses. An ideal re-ranker will\nexhibit the following two properties: (a) it should prefer the most relevant\nhypothesis for the given input as the top hypothesis and, (b) the\ninterpretation scores corresponding to each hypothesis produced by the\nre-ranker should be calibrated. Calibration allows the final NLU interpretation\nscore to be comparable across domains. We propose a novel re-ranker strategy\nthat addresses these aspects, while also maintaining domain specific\nmodularity. We design optimization loss functions for such a modularized\nre-ranker and present results on decreasing the top hypothesis error rate as\nwell as maintaining the model calibration. We also experiment with an extension\ninvolving training the domain specific re-rankers on datasets curated\nindependently by each domain to allow further asynchronization. %The proposed\nre-ranker design showcases the following: (i) improved NLU performance over an\nunweighted aggregation strategy, (ii) cross-domain calibrated performance and,\n(iii) support for use cases involving training each re-ranker on datasets\ncurated by each domain independently.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 17:35:57 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Su", "Chengwei", ""], ["Gupta", "Rahul", ""], ["Ananthakrishnan", "Shankar", ""], ["Matsoukas", "Spyros", ""]]}, {"id": "1809.09658", "submitter": "Daniele Falavigna", "authors": "Marco Matassoni, Roberto Gretter, Daniele Falavigna, Diego Giuliani", "title": "Non-native children speech recognition through transfer learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work deals with non-native children's speech and investigates both\nmulti-task and transfer learning approaches to adapt a multi-language Deep\nNeural Network (DNN) to speakers, specifically children, learning a foreign\nlanguage. The application scenario is characterized by young students learning\nEnglish and German and reading sentences in these second-languages, as well as\nin their mother language. The paper analyzes and discusses techniques for\ntraining effective DNN-based acoustic models starting from children native\nspeech and performing adaptation with limited non-native audio material. A\nmulti-lingual model is adopted as baseline, where a common phonetic lexicon,\ndefined in terms of the units of the International Phonetic Alphabet (IPA), is\nshared across the three languages at hand (Italian, German and English); DNN\nadaptation methods based on transfer learning are evaluated on significant\nnon-native evaluation sets. Results show that the resulting non-native models\nallow a significant improvement with respect to a mono-lingual system adapted\nto speakers of the target language.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 18:50:39 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Matassoni", "Marco", ""], ["Gretter", "Roberto", ""], ["Falavigna", "Daniele", ""], ["Giuliani", "Diego", ""]]}, {"id": "1809.09672", "submitter": "Yue Dong", "authors": "Yue Dong, Yikang Shen, Eric Crawford, Herke van Hoof and Jackie Chi\n  Kit Cheung", "title": "BanditSum: Extractive Summarization as a Contextual Bandit", "comments": "12 pages, 2 figures, EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a novel method for training neural networks to\nperform single-document extractive summarization without\nheuristically-generated extractive labels. We call our approach BanditSum as it\ntreats extractive summarization as a contextual bandit (CB) problem, where the\nmodel receives a document to summarize (the context), and chooses a sequence of\nsentences to include in the summary (the action). A policy gradient\nreinforcement learning algorithm is used to train the model to select sequences\nof sentences that maximize ROUGE score. We perform a series of experiments\ndemonstrating that BanditSum is able to achieve ROUGE scores that are better\nthan or comparable to the state-of-the-art for extractive summarization, and\nconverges using significantly fewer update steps than competing approaches. In\naddition, we show empirically that BanditSum performs significantly better than\ncompeting approaches when good summary sentences appear late in the source\ndocument.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 19:18:52 GMT"}, {"version": "v2", "created": "Sun, 16 Dec 2018 21:59:30 GMT"}, {"version": "v3", "created": "Tue, 7 May 2019 18:19:56 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Dong", "Yue", ""], ["Shen", "Yikang", ""], ["Crawford", "Eric", ""], ["van Hoof", "Herke", ""], ["Cheung", "Jackie Chi Kit", ""]]}, {"id": "1809.09795", "submitter": "Edison Marrese-Taylor", "authors": "Suzana Ili\\'c, Edison Marrese-Taylor, Jorge A. Balazs, Yutaka Matsuo", "title": "Deep contextualized word representations for detecting sarcasm and irony", "comments": "To appear in WASSA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting context-dependent and non-literal utterances like sarcastic and\nironic expressions still remains a challenging task in NLP, as it goes beyond\nlinguistic patterns, encompassing common sense and shared knowledge as crucial\ncomponents. To capture complex morpho-syntactic features that can usually serve\nas indicators for irony or sarcasm across dynamic contexts, we propose a model\nthat uses character-level vector representations of words, based on ELMo. We\ntest our model on 7 different datasets derived from 3 different data sources,\nproviding state-of-the-art performance in 6 of them, and otherwise offering\ncompetitive results.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 03:54:22 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Ili\u0107", "Suzana", ""], ["Marrese-Taylor", "Edison", ""], ["Balazs", "Jorge A.", ""], ["Matsuo", "Yutaka", ""]]}, {"id": "1809.10040", "submitter": "Kelly Zhang", "authors": "Kelly W. Zhang and Samuel R. Bowman", "title": "Language Modeling Teaches You More Syntax than Translation Does: Lessons\n  Learned Through Auxiliary Task Analysis", "comments": null, "journal-ref": "Blackbox NLP Workshop, EMNLP 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work using auxiliary prediction task classifiers to investigate the\nproperties of LSTM representations has begun to shed light on why pretrained\nrepresentations, like ELMo (Peters et al., 2018) and CoVe (McCann et al.,\n2017), are so beneficial for neural language understanding models. We still,\nthough, do not yet have a clear understanding of how the choice of pretraining\nobjective affects the type of linguistic information that models learn. With\nthis in mind, we compare four objectives---language modeling, translation,\nskip-thought, and autoencoding---on their ability to induce syntactic and\npart-of-speech information. We make a fair comparison between the tasks by\nholding constant the quantity and genre of the training data, as well as the\nLSTM architecture. We find that representations from language models\nconsistently perform best on our syntactic auxiliary prediction tasks, even\nwhen trained on relatively small amounts of data. These results suggest that\nlanguage modeling may be the best data-rich pretraining task for transfer\nlearning applications requiring syntactic information. We also find that the\nrepresentations from randomly-initialized, frozen LSTMs perform strikingly well\non our syntactic auxiliary tasks, but this effect disappears when the amount of\ntraining data for the auxiliary tasks is reduced.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 14:58:59 GMT"}, {"version": "v2", "created": "Mon, 7 Jan 2019 18:38:13 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Zhang", "Kelly W.", ""], ["Bowman", "Samuel R.", ""]]}, {"id": "1809.10044", "submitter": "Kuldeep Singh", "authors": "Kuldeep Singh and Ioanna Lytra and Arun Sethupat Radhakrishna and\n  Saeedeh Shekarpour and Maria-Esther Vidal and Jens Lehmann", "title": "No One is Perfect: Analysing the Performance of Question Answering\n  Components over the DBpedia Knowledge Graph", "comments": "Evaluation of State of the art Question Answering components\n  performing entity linking, relation linking etc", "journal-ref": "Journal of Web Semantics (JWS 2020)", "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question answering (QA) over knowledge graphs has gained significant momentum\nover the past five years due to the increasing availability of large knowledge\ngraphs and the rising importance of question answering for user interaction.\nDBpedia has been the most prominently used knowledge graph in this setting and\nmost approaches currently use a pipeline of processing steps connecting a\nsequence of components. In this article, we analyse and micro evaluate the\nbehaviour of 29 available QA components for DBpedia knowledge graph that were\nreleased by the research community since 2010. As a result, we provide a\nperspective on collective failure cases, suggest characteristics of QA\ncomponents that prevent them from performing better and provide future\nchallenges and research directions for the field.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 15:01:28 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 12:22:36 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Singh", "Kuldeep", ""], ["Lytra", "Ioanna", ""], ["Radhakrishna", "Arun Sethupat", ""], ["Shekarpour", "Saeedeh", ""], ["Vidal", "Maria-Esther", ""], ["Lehmann", "Jens", ""]]}, {"id": "1809.10185", "submitter": "Yuhao Zhang", "authors": "Yuhao Zhang, Peng Qi, Christopher D. Manning", "title": "Graph Convolution over Pruned Dependency Trees Improves Relation\n  Extraction", "comments": "EMNLP 2018. Code available at:\n  https://github.com/qipeng/gcn-over-pruned-trees", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dependency trees help relation extraction models capture long-range relations\nbetween words. However, existing dependency-based models either neglect crucial\ninformation (e.g., negation) by pruning the dependency trees too aggressively,\nor are computationally inefficient because it is difficult to parallelize over\ndifferent tree structures. We propose an extension of graph convolutional\nnetworks that is tailored for relation extraction, which pools information over\narbitrary dependency structures efficiently in parallel. To incorporate\nrelevant information while maximally removing irrelevant content, we further\napply a novel pruning strategy to the input trees by keeping words immediately\naround the shortest path between the two entities among which a relation might\nhold. The resulting model achieves state-of-the-art performance on the\nlarge-scale TACRED dataset, outperforming existing sequence and\ndependency-based neural models. We also show through detailed analysis that\nthis model has complementary strengths to sequence models, and combining them\nfurther improves the state of the art.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 18:49:07 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Zhang", "Yuhao", ""], ["Qi", "Peng", ""], ["Manning", "Christopher D.", ""]]}, {"id": "1809.10236", "submitter": "Burak Uzkent", "authors": "Evan Sheehan, Burak Uzkent, Chenlin Meng, Zhongyi Tang, Marshall\n  Burke, David Lobell, Stefano Ermon", "title": "Learning to Interpret Satellite Images Using Wikipedia", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite recent progress in computer vision, fine-grained interpretation of\nsatellite images remains challenging because of a lack of labeled training\ndata. To overcome this limitation, we propose using Wikipedia as a previously\nuntapped source of rich, georeferenced textual information with global\ncoverage. We construct a novel large-scale, multi-modal dataset by pairing\ngeo-referenced Wikipedia articles with satellite imagery of their corresponding\nlocations. To prove the efficacy of this dataset, we focus on the African\ncontinent and train a deep network to classify images based on labels extracted\nfrom articles. We then fine-tune the model on a human annotated dataset and\ndemonstrate that this weak form of supervision can drastically reduce the\nquantity of human annotated labels and time required for downstream tasks.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 21:58:14 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Sheehan", "Evan", ""], ["Uzkent", "Burak", ""], ["Meng", "Chenlin", ""], ["Tang", "Zhongyi", ""], ["Burke", "Marshall", ""], ["Lobell", "David", ""], ["Ermon", "Stefano", ""]]}, {"id": "1809.10267", "submitter": "Chi Zhang", "authors": "Chi Zhang, Shagan Sah, Thang Nguyen, Dheeraj Peri, Alexander Loui,\n  Carl Salvaggio, Raymond Ptucha", "title": "Semantic Sentence Embeddings for Paraphrasing and Text Summarization", "comments": "5 pages, 4 figures, IEEE GlobalSIP 2017 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces a sentence to vector encoding framework suitable for\nadvanced natural language processing. Our latent representation is shown to\nencode sentences with common semantic information with similar vector\nrepresentations. The vector representation is extracted from an encoder-decoder\nmodel which is trained on sentence paraphrase pairs. We demonstrate the\napplication of the sentence representations for two different tasks -- sentence\nparaphrasing and paragraph summarization, making it attractive for commonly\nused recurrent frameworks that process text. Experimental results help gain\ninsight how vector representations are suitable for advanced language\nembedding.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 23:38:19 GMT"}], "update_date": "2018-09-30", "authors_parsed": [["Zhang", "Chi", ""], ["Sah", "Shagan", ""], ["Nguyen", "Thang", ""], ["Peri", "Dheeraj", ""], ["Loui", "Alexander", ""], ["Salvaggio", "Carl", ""], ["Ptucha", "Raymond", ""]]}, {"id": "1809.10274", "submitter": "Chi Zhang", "authors": "Shagan Sah, Dheeraj Peri, Ameya Shringi, Chi Zhang, Miguel Dominguez,\n  Andreas Savakis, Ray Ptucha", "title": "Semantically Invariant Text-to-Image Generation", "comments": "5 papers, 5 figures, Published in 2018 25th IEEE International\n  Conference on Image Processing (ICIP)", "journal-ref": null, "doi": "10.1109/ICIP.2018.8451656", "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Image captioning has demonstrated models that are capable of generating\nplausible text given input images or videos. Further, recent work in image\ngeneration has shown significant improvements in image quality when text is\nused as a prior. Our work ties these concepts together by creating an\narchitecture that can enable bidirectional generation of images and text. We\ncall this network Multi-Modal Vector Representation (MMVR). Along with MMVR, we\npropose two improvements to the text conditioned image generation. Firstly, a\nn-gram metric based cost function is introduced that generalizes the caption\nwith respect to the image. Secondly, multiple semantically similar sentences\nare shown to help in generating better images. Qualitative and quantitative\nevaluations demonstrate that MMVR improves upon existing text conditioned image\ngeneration results by over 20%, while integrating visual and text modalities.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 00:11:25 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Sah", "Shagan", ""], ["Peri", "Dheeraj", ""], ["Shringi", "Ameya", ""], ["Zhang", "Chi", ""], ["Dominguez", "Miguel", ""], ["Savakis", "Andreas", ""], ["Ptucha", "Ray", ""]]}, {"id": "1809.10282", "submitter": "Raphael Tang", "authors": "Raphael Tang, Jimmy Lin", "title": "Adaptive Pruning of Neural Language Models for Mobile Devices", "comments": "10 pages, 3 figures, 2 tables, submitted to ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural language models (NLMs) exist in an accuracy-efficiency tradeoff space\nwhere better perplexity typically comes at the cost of greater computation\ncomplexity. In a software keyboard application on mobile devices, this\ntranslates into higher power consumption and shorter battery life. This paper\nrepresents the first attempt, to our knowledge, in exploring\naccuracy-efficiency tradeoffs for NLMs. Building on quasi-recurrent neural\nnetworks (QRNNs), we apply pruning techniques to provide a \"knob\" to select\ndifferent operating points. In addition, we propose a simple technique to\nrecover some perplexity using a negligible amount of memory. Our empirical\nevaluations consider both perplexity as well as energy consumption on a\nRaspberry Pi, where we demonstrate which methods provide the best\nperplexity-power consumption operating point. At one operating point, one of\nthe techniques is able to provide energy savings of 40% over the state of the\nart with only a 17% relative increase in perplexity.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 00:41:16 GMT"}], "update_date": "2018-09-30", "authors_parsed": [["Tang", "Raphael", ""], ["Lin", "Jimmy", ""]]}, {"id": "1809.10324", "submitter": "Chongyang Tao", "authors": "Xiuying Chen, Shen Gao, Chongyang Tao, Yan Song, Dongyan Zhao, Rui Yan", "title": "Iterative Document Representation Learning Towards Summarization with\n  Polishing", "comments": "10 pages, 4 figures. emnlp 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce Iterative Text Summarization (ITS), an\niteration-based model for supervised extractive text summarization, inspired by\nthe observation that it is often necessary for a human to read an article\nmultiple times in order to fully understand and summarize its contents. Current\nsummarization approaches read through a document only once to generate a\ndocument representation, resulting in a sub-optimal representation. To address\nthis issue we introduce a model which iteratively polishes the document\nrepresentation on many passes through the document. As part of our model, we\nalso introduce a selective reading mechanism that decides more accurately the\nextent to which each sentence in the model should be updated. Experimental\nresults on the CNN/DailyMail and DUC2002 datasets demonstrate that our model\nsignificantly outperforms state-of-the-art extractive systems when evaluated by\nmachines and by humans.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 03:11:35 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 06:34:45 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Chen", "Xiuying", ""], ["Gao", "Shen", ""], ["Tao", "Chongyang", ""], ["Song", "Yan", ""], ["Zhao", "Dongyan", ""], ["Yan", "Rui", ""]]}, {"id": "1809.10522", "submitter": "Narendra Nath Joshi", "authors": "Mary Arpita Pyreddy, Varshini Ramaseshan, Narendra Nath Joshi, Zhuyun\n  Dai, Chenyan Xiong, Jamie Callan, Zhiyuan Liu", "title": "Consistency and Variation in Kernel Neural Ranking Model", "comments": "4 pages, 4 figures, 2 tables", "journal-ref": "Mary Arpita Pyreddy et al. 2018. Consistency and Variation in\n  Kernel Neural Ranking Model. In The 41st International ACM SIGIR Conference\n  on Research & Development in Information Retrieval (SIGIR '18). ACM, New\n  York, NY, USA, 961-964", "doi": "10.1145/3209978.3210107", "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the consistency of the kernel-based neural ranking model\nK-NRM, a recent state-of-the-art neural IR model, which is important for\nreproducible research and deployment in the industry. We find that K-NRM has\nlow variance on relevance-based metrics across experimental trials. In spite of\nthis low variance in overall performance, different trials produce different\ndocument rankings for individual queries. The main source of variance in our\nexperiments was found to be different latent matching patterns captured by\nK-NRM. In the IR-customized word embeddings learned by K-NRM, the\nquery-document word pairs follow two different matching patterns that are\nequally effective, but align word pairs differently in the embedding space. The\ndifferent latent matching patterns enable a simple yet effective approach to\nconstruct ensemble rankers, which improve K-NRM's effectiveness and\ngeneralization abilities.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 14:01:19 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Pyreddy", "Mary Arpita", ""], ["Ramaseshan", "Varshini", ""], ["Joshi", "Narendra Nath", ""], ["Dai", "Zhuyun", ""], ["Xiong", "Chenyan", ""], ["Callan", "Jamie", ""], ["Liu", "Zhiyuan", ""]]}, {"id": "1809.10542", "submitter": "Diego Krivochen", "authors": "Diego Krivochen and Douglas Saddy", "title": "Towards a classification of Lindenmayer systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CL cs.GL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we will attempt to classify Lindenmayer systems based on\nproperties of sets of rules and the kind of strings those rules generate. This\nclassification will be referred to as a parametrization of the L-space: the\nL-space is the phase space in which all possible L-developments are\nrepresented. This space is infinite, because there is no halting algorithm for\nL-grammars; but it is also subjected to hard conditions, because there are\ngrammars and developments which are not possible states of an L-system: a very\nwell-known example is the space of normal grammars. Just as the space of normal\ngrammars is parametrized into Regular, Context-Free, Context-Sensitive, and\nUnrestricted (with proper containment relations holding among them; see\nChomsky, 1959: Theorem 1), we contend here that the L-space is a very rich\nlandscape of grammars which cluster into kinds that are not mutually\ntranslatable.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 14:36:00 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Krivochen", "Diego", ""], ["Saddy", "Douglas", ""]]}, {"id": "1809.10617", "submitter": "Jose Manuel Gomez Perez", "authors": "Andres Garcia-Silva, Jose Manuel Gomez-Perez, Raul Palma, Marcin\n  Krystek, Simone Mantovani, Federica Foglini, Valentina Grande, Francesco De\n  Leo, Stefano Salvi, Elisa Trasati, Vito Romaniello, Mirko Albani, Cristiano\n  Silvagni, Rosemarie Leone, Fulvio Marelli, Sergio Albani, Michele Lazzarini,\n  Hazel J. Napier, Helen M. Glaves, Timothy Aldridge, Charles Meertens, Fran\n  Boler, Henry W. Loescher, Christine Laney, Melissa A Genazzio, Daniel Crawl,\n  Ilkay Altintas", "title": "Enabling FAIR Research in Earth Science through Research Objects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-intensive science communities are progressively adopting FAIR practices\nthat enhance the visibility of scientific breakthroughs and enable reuse. At\nthe core of this movement, research objects contain and describe scientific\ninformation and resources in a way compliant with the FAIR principles and\nsustain the development of key infrastructure and tools. This paper provides an\naccount of the challenges, experiences and solutions involved in the adoption\nof FAIR around research objects over several Earth Science disciplines. During\nthis journey, our work has been comprehensive, with outcomes including: an\nextended research object model adapted to the needs of earth scientists; the\nprovisioning of digital object identifiers (DOI) to enable persistent\nidentification and to give due credit to authors; the generation of\ncontent-based, semantically rich, research object metadata through natural\nlanguage processing, enhancing visibility and reuse through recommendation\nsystems and third-party search engines; and various types of checklists that\nprovide a compact representation of research object quality as a key enabler of\nscientific reuse. All these results have been integrated in ROHub, a platform\nthat provides research object management functionality to a wealth of\napplications and interfaces across different scientific communities. To monitor\nand quantify the community uptake of research objects, we have defined\nindicators and obtained measures via ROHub that are also discussed herein.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 16:28:18 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Garcia-Silva", "Andres", ""], ["Gomez-Perez", "Jose Manuel", ""], ["Palma", "Raul", ""], ["Krystek", "Marcin", ""], ["Mantovani", "Simone", ""], ["Foglini", "Federica", ""], ["Grande", "Valentina", ""], ["De Leo", "Francesco", ""], ["Salvi", "Stefano", ""], ["Trasati", "Elisa", ""], ["Romaniello", "Vito", ""], ["Albani", "Mirko", ""], ["Silvagni", "Cristiano", ""], ["Leone", "Rosemarie", ""], ["Marelli", "Fulvio", ""], ["Albani", "Sergio", ""], ["Lazzarini", "Michele", ""], ["Napier", "Hazel J.", ""], ["Glaves", "Helen M.", ""], ["Aldridge", "Timothy", ""], ["Meertens", "Charles", ""], ["Boler", "Fran", ""], ["Loescher", "Henry W.", ""], ["Laney", "Christine", ""], ["Genazzio", "Melissa A", ""], ["Crawl", "Daniel", ""], ["Altintas", "Ilkay", ""]]}, {"id": "1809.10644", "submitter": "Rohan Kshirsagar", "authors": "Rohan Kshirsagar, Tyus Cukuvac, Kathleen McKeown, Susan McGregor", "title": "Predictive Embeddings for Hate Speech Detection on Twitter", "comments": "Accepted at Abusive Language Online Workshop, EMNLP 2018; 7 pages 7\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a neural-network based approach to classifying online hate speech\nin general, as well as racist and sexist speech in particular. Using\npre-trained word embeddings and max/mean pooling from simple, fully-connected\ntransformations of these embeddings, we are able to predict the occurrence of\nhate speech on three commonly used publicly available datasets. Our models\nmatch or outperform state of the art F1 performance on all three datasets using\nsignificantly fewer parameters and minimal feature preprocessing compared to\nprevious methods.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 17:12:24 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Kshirsagar", "Rohan", ""], ["Cukuvac", "Tyus", ""], ["McKeown", "Kathleen", ""], ["McGregor", "Susan", ""]]}, {"id": "1809.10735", "submitter": "Mark Yatskar", "authors": "Mark Yatskar", "title": "A Qualitative Comparison of CoQA, SQuAD 2.0 and QuAC", "comments": "Camera Ready Presented at NAACL '19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare three new datasets for question answering: SQuAD 2.0, QuAC, and\nCoQA, along several of their new features: (1) unanswerable questions, (2)\nmulti-turn interactions, and (3) abstractive answers. We show that the datasets\nprovide complementary coverage of the first two aspects, but weak coverage of\nthe third. Because of the datasets' structural similarity, a single extractive\nmodel can be easily adapted to any of the datasets and we show improved\nbaseline results on both SQuAD 2.0 and CoQA. Despite the similarity, models\ntrained on one dataset are ineffective on another dataset, but we find moderate\nperformance improvement through pretraining. To encourage cross-evaluation, we\nrelease code for conversion between datasets at\nhttps://github.com/my89/co-squac .\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 19:33:03 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2019 00:34:44 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Yatskar", "Mark", ""]]}, {"id": "1809.10736", "submitter": "Lara Martin", "authors": "Pradyumna Tambwekar, Murtaza Dhuliawala, Lara J. Martin, Animesh\n  Mehta, Brent Harrison, and Mark O. Riedl", "title": "Controllable Neural Story Plot Generation via Reinforcement Learning", "comments": "Published in IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language-modeling--based approaches to story plot generation attempt to\nconstruct a plot by sampling from a language model (LM) to predict the next\ncharacter, word, or sentence to add to the story. LM techniques lack the\nability to receive guidance from the user to achieve a specific goal, resulting\nin stories that don't have a clear sense of progression and lack coherence. We\npresent a reward-shaping technique that analyzes a story corpus and produces\nintermediate rewards that are backpropagated into a pre-trained LM in order to\nguide the model towards a given goal. Automated evaluations show our technique\ncan create a model that generates story plots which consistently achieve a\nspecified goal. Human-subject studies show that the generated stories have more\nplausible event ordering than baseline plot generation techniques.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 19:33:54 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 19:54:32 GMT"}, {"version": "v3", "created": "Mon, 3 Jun 2019 16:19:22 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Tambwekar", "Pradyumna", ""], ["Dhuliawala", "Murtaza", ""], ["Martin", "Lara J.", ""], ["Mehta", "Animesh", ""], ["Harrison", "Brent", ""], ["Riedl", "Mark O.", ""]]}, {"id": "1809.10763", "submitter": "Sina Ahmadi", "authors": "Shahin Salavati and Sina Ahmadi", "title": "Building a Lemmatizer and a Spell-checker for Sorani Kurdish", "comments": "6 pages article, published in LTC'17 The 8th Language & Technology\n  Conference, Poznan, Poland", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present paper aims at presenting a lemmatization and a word-level error\ncorrection system for Sorani Kurdish. We propose a hybrid approach based on the\nmorphological rules and a n-gram language model. We have called our\nlemmatization and error correction systems Peyv and R\\^en\\^us respectively,\nwhich are the first tools presented for Sorani Kurdish to the best of our\nknowledge. The Peyv lemmatizer has shown 86.7% accuracy. As for R\\^en\\^us,\nusing a lexicon, we have obtained 96.4% accuracy while without a lexicon, the\ncorrection system has 87% accuracy. As two fundamental text processing tools,\nthese tools can pave the way for further researches on more natural language\nprocessing applications for Sorani Kurdish.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 21:00:36 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Salavati", "Shahin", ""], ["Ahmadi", "Sina", ""]]}, {"id": "1809.10804", "submitter": "Ivan Girardi", "authors": "Ivan Girardi, Pengfei Ji, An-phi Nguyen, Nora Hollenstein, Adam\n  Ivankay, Lorenz Kuhn, Chiara Marchiori and Ce Zhang", "title": "Patient Risk Assessment and Warning Symptom Detection Using Deep\n  Attention-Based Neural Networks", "comments": "10 pages, 2 figures, EMNLP workshop LOUHI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an operational component of a real-world patient triage system.\nGiven a specific patient presentation, the system is able to assess the level\nof medical urgency and issue the most appropriate recommendation in terms of\nbest point of care and time to treat. We use an attention-based convolutional\nneural network architecture trained on 600,000 doctor notes in German. We\ncompare two approaches, one that uses the full text of the medical notes and\none that uses only a selected list of medical entities extracted from the text.\nThese approaches achieve 79% and 66% precision, respectively, but on a\nconfidence threshold of 0.6, precision increases to 85% and 75%, respectively.\nIn addition, a method to detect warning symptoms is implemented to render the\nclassification task transparent from a medical perspective. The method is based\non the learning of attention scores and a method of automatic validation using\nthe same data.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 00:14:10 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Girardi", "Ivan", ""], ["Ji", "Pengfei", ""], ["Nguyen", "An-phi", ""], ["Hollenstein", "Nora", ""], ["Ivankay", "Adam", ""], ["Kuhn", "Lorenz", ""], ["Marchiori", "Chiara", ""], ["Zhang", "Ce", ""]]}, {"id": "1809.10835", "submitter": "Dung Thai", "authors": "Dung Thai, Sree Harsha Ramesh, Shikhar Murty, Luke Vilnis, Andrew\n  McCallum", "title": "Embedded-State Latent Conditional Random Fields for Sequence Labeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex textual information extraction tasks are often posed as sequence\nlabeling or \\emph{shallow parsing}, where fields are extracted using local\nlabels made consistent through probabilistic inference in a graphical model\nwith constrained transitions. Recently, it has become common to locally\nparametrize these models using rich features extracted by recurrent neural\nnetworks (such as LSTM), while enforcing consistent outputs through a simple\nlinear-chain model, representing Markovian dependencies between successive\nlabels. However, the simple graphical model structure belies the often complex\nnon-local constraints between output labels. For example, many fields, such as\na first name, can only occur a fixed number of times, or in the presence of\nother fields. While RNNs have provided increasingly powerful context-aware\nlocal features for sequence tagging, they have yet to be integrated with a\nglobal graphical model of similar expressivity in the output distribution. Our\nmodel goes beyond the linear chain CRF to incorporate multiple hidden states\nper output label, but parametrizes their transitions parsimoniously with\nlow-rank log-potential scoring matrices, effectively learning an embedding\nspace for hidden states. This augmented latent space of inference variables\ncomplements the rich feature representation of the RNN, and allows exact global\ninference obeying complex, learned non-local output constraints. We experiment\nwith several datasets and show that the model outperforms baseline CRF+RNN\nmodels when global output constraints are necessary at inference-time, and\nexplore the interpretable latent structure.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 03:06:31 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Thai", "Dung", ""], ["Ramesh", "Sree Harsha", ""], ["Murty", "Shikhar", ""], ["Vilnis", "Luke", ""], ["McCallum", "Andrew", ""]]}, {"id": "1809.10853", "submitter": "Michael Auli", "authors": "Alexei Baevski and Michael Auli", "title": "Adaptive Input Representations for Neural Language Modeling", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce adaptive input representations for neural language modeling\nwhich extend the adaptive softmax of Grave et al. (2017) to input\nrepresentations of variable capacity. There are several choices on how to\nfactorize the input and output layers, and whether to model words, characters\nor sub-word units. We perform a systematic comparison of popular choices for a\nself-attentional architecture. Our experiments show that models equipped with\nadaptive embeddings are more than twice as fast to train than the popular\ncharacter input CNN while having a lower number of parameters. On the\nWikiText-103 benchmark we achieve 18.7 perplexity, an improvement of 10.5\nperplexity compared to the previously best published result and on the Billion\nWord benchmark, we achieve 23.02 perplexity.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 04:30:11 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 02:01:50 GMT"}, {"version": "v3", "created": "Fri, 22 Feb 2019 23:41:46 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Baevski", "Alexei", ""], ["Auli", "Michael", ""]]}, {"id": "1809.10867", "submitter": "Mamoru Komachi", "authors": "Tomonori Kodaira and Mamoru Komachi", "title": "The Rule of Three: Abstractive Text Summarization in Three Bullet Points", "comments": "9 pages; PACLIC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Neural network-based approaches have become widespread for abstractive text\nsummarization. Though previously proposed models for abstractive text\nsummarization addressed the problem of repetition of the same contents in the\nsummary, they did not explicitly consider its information structure. One of the\nreasons these previous models failed to account for information structure in\nthe generated summary is that standard datasets include summaries of variable\nlengths, resulting in problems in analyzing information flow, specifically, the\nmanner in which the first sentence is related to the following sentences.\nTherefore, we use a dataset containing summaries with only three bullet points,\nand propose a neural network-based abstractive summarization model that\nconsiders the information structures of the generated summaries. Our\nexperimental results show that the information structure of a summary can be\ncontrolled, thus improving the performance of the overall summarization.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 06:04:32 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Kodaira", "Tomonori", ""], ["Komachi", "Mamoru", ""]]}, {"id": "1809.11047", "submitter": "Richard A. Blythe", "authors": "James Holehouse and Richard A. Blythe", "title": "Cross-situational learning of large lexicons with finite memory", "comments": "39 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-situational word learning, wherein a learner combines information about\npossible meanings of a word across multiple exposures, has previously been\nshown to be a very powerful strategy to acquire a large lexicon in a short\ntime. However, this success may derive from idealizations that are made when\nmodeling the word-learning process. In particular, an earlier model assumed\nthat a learner could perfectly recall all previous instances of a word's use\nand the inferences that were drawn about its meaning. In this work, we relax\nthis assumption and determine the performance of a model cross-situational\nlearner who forgets word-meaning associations over time. Our main finding is\nthat it is possible for this learner to acquire a human-scale lexicon by\nadulthood with word-exposure and memory-decay rates that are consistent with\nempirical research on childhood word learning, as long as the degree of\nreferential uncertainty is not too high or the learner employs a mutual\nexclusivity constraint. Our findings therefore suggest that successful word\nlearning does not necessarily demand either highly accurate long-term tracking\nof word and meaning statistics or hypothesis-testing strategies.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 14:11:26 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Holehouse", "James", ""], ["Blythe", "Richard A.", ""]]}, {"id": "1809.11068", "submitter": "Hossein Zeinali", "authors": "Hossein Zeinali, Lukas Burget, Hossein Sameti and Jan Cernocky", "title": "Spoken Pass-Phrase Verification in the i-vector Space", "comments": null, "journal-ref": "Proc. Odyssey 2018 The Speaker and Language Recognition Workshop", "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of spoken pass-phrase verification is to decide whether a test\nutterance contains the same phrase as given enrollment utterances. Beside other\napplications, pass-phrase verification can complement an independent speaker\nverification subsystem in text-dependent speaker verification. It can also be\nused for liveness detection by verifying that the user is able to correctly\nrespond to a randomly prompted phrase. In this paper, we build on our previous\nwork on i-vector based text-dependent speaker verification, where we have shown\nthat i-vectors extracted using phrase specific Hidden Markov Models (HMMs) or\nusing Deep Neural Network (DNN) based bottle-neck (BN) features help to reject\nutterances with wrong pass-phrases. We apply the same i-vector extraction\ntechniques to the stand-alone task of speaker-independent spoken pass-phrase\nclassification and verification. The experiments on RSR2015 and RedDots\ndatabases show that very simple scoring techniques (e.g. cosine distance\nscoring) applied to such i-vectors can provide results superior to those\npreviously published on the same data.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 14:49:27 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Zeinali", "Hossein", ""], ["Burget", "Lukas", ""], ["Sameti", "Hossein", ""], ["Cernocky", "Jan", ""]]}, {"id": "1809.11155", "submitter": "Hamed Sadeghi", "authors": "Jules Gagnon-Marchand, Hamed Sadeghi, Md. Akmal Haidar and Mehdi\n  Rezagholizadeh", "title": "SALSA-TEXT : self attentive latent space based adversarial text\n  generation", "comments": "10 pages, 3 figures, under review at ICLR 2019", "journal-ref": "Canadian AI 2019", "doi": "10.1007/978-3-030-18305-9_10", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the success of self attention mechanism and Transformer\narchitecture in sequence transduction and image generation applications, we\npropose novel self attention-based architectures to improve the performance of\nadversarial latent code- based schemes in text generation. Adversarial latent\ncode-based text generation has recently gained a lot of attention due to their\npromising results. In this paper, we take a step to fortify the architectures\nused in these setups, specifically AAE and ARAE. We benchmark two latent\ncode-based methods (AAE and ARAE) designed based on adversarial setups. In our\nexperiments, the Google sentence compression dataset is utilized to compare our\nmethod with these methods using various objective and subjective measures. The\nexperiments demonstrate the proposed (self) attention-based models outperform\nthe state-of-the-art in adversarial code-based text generation.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 17:38:36 GMT"}, {"version": "v2", "created": "Mon, 8 Oct 2018 16:42:59 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Gagnon-Marchand", "Jules", ""], ["Sadeghi", "Hamed", ""], ["Haidar", "Md. Akmal", ""], ["Rezagholizadeh", "Mehdi", ""]]}]