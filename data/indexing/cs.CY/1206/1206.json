[{"id": "1206.0604", "submitter": "Adrian Glaubitz", "authors": "John Paul Adrian Glaubitz", "title": "Modern consumerism and the waste problem", "comments": "8 pages, 4 images", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advance of industrial mass production, modern micro-electronics and\ncomputers, the intervals between the release of new generations of consumer\nproducts have been dramatically reduced and so have their lifetime cycles.\nWhile it was very natural in the post-war era, that sophisticated consumer\nproducts like television sets and stereo equipment would not be replaced with a\nnew product until they break, and usually beyond that point since it was very\ncommon to have a broken television set serviced, the habits of consumers have\nchanged during the last quarter of the 20th century.\n  A modern consumer product, like Apple's famous iPhone has a market life of\napproximately one year until a successor is announced and subsequently pushed\ninto the market. Usually these new generations bring a bunch of new features,\nhave a higher performance while maintaining the price or becoming even cheaper,\nthus the consumer greatly benefits from the reduced lifetime cycle of these\nproducts.\n  However, electronic devices not only require a lot of of Earth's limited\nresources for their production, but their production processes are a major\nsource for harmful climate gases like carbon dioxide and toxic waste like heavy\nmetal alloys, acids and alkalis. And last but not least is every obsoleted\niPhone a candidate for waste facilities unless consumers are going to sell them\non the second hand market.\n  While we can not expect consumers and manufacturers to go back to the early\ndays of consumer products where lifetime cycles reached up to 20 years, the\nworld record being the famous \"Centennial Lightbulb\" in Livermore, CA in the\nUS, which has been lit for over 100 years, it is certainly about time to\nrethink modern consumerism with regard to responsibility to future generations.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2012 13:01:09 GMT"}], "update_date": "2012-06-05", "authors_parsed": [["Glaubitz", "John Paul Adrian", ""]]}, {"id": "1206.2517", "submitter": "Xiangju Qin", "authors": "Xiangju Qin, P\\'adraig Cunningham", "title": "Assessing the Quality of Wikipedia Pages Using Edit Longevity and\n  Contributor Centrality", "comments": "9 pages", "journal-ref": "The 23rd Irish Conference on Artificial Intelligence and Cognitive\n  Science (AICS 2012), p.p. 3--11", "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address the challenge of assessing the quality of Wikipedia\npages using scores derived from edit contribution and contributor\nauthoritativeness measures. The hypothesis is that pages with significant\ncontributions from authoritative contributors are likely to be high-quality\npages. Contributions are quantified using edit longevity measures and\ncontributor authoritativeness is scored using centrality metrics in either the\nWikipedia talk or co-author networks. The results suggest that it is useful to\ntake into account the contributor authoritativeness when assessing the\ninformation quality of Wikipedia content. The percentile visualization of the\nquality scores provides some insights about the anomalous articles, and can be\nused to help Wikipedia editors to identify Start and Stub articles that are of\nrelatively good quality.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2012 13:15:40 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2013 11:15:33 GMT"}], "update_date": "2013-10-25", "authors_parsed": [["Qin", "Xiangju", ""], ["Cunningham", "P\u00e1draig", ""]]}, {"id": "1206.2544", "submitter": "Shah Mahmood Mr.", "authors": "Shah Mahmood and Ismatullah Nazar", "title": "Education in Conflict Zones: a Web and Mobility Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new framework for education in conflict zones, considering the\nexplosive growth of social media, web services, and mobile Internet over the\npast decade. Moreover, we focus on one conflict zone, Afghanistan, as a case\nstudy, because of its alarmingly high illiteracy rate, lack of qualified\nteachers, rough terrain, and relatively high mobile penetration of over 50%. In\nseveral of Afghanistan's provinces, it is hard to currently sustain the\ntraditional bricks-and-mortar school model, due to numerous incidents of\nschools, teachers, and students being attacked because of the ongoing\ninsurgency and political instability. Our model improves the virtual school\nmodel, by addressing most of its disadvantages, to provide students in\nAfghanistan with an opportunity to achieve standardised education, even when\nthe security situation does not allow them to attend traditional schools. One\nof the biggest advantages of this model is that it is sufficiently robust to\ndeal with gender discrimination, imposed by culture or politics of the region.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2012 14:32:55 GMT"}], "update_date": "2012-06-13", "authors_parsed": [["Mahmood", "Shah", ""], ["Nazar", "Ismatullah", ""]]}, {"id": "1206.3027", "submitter": "J\\\"org Pohle", "authors": "J\\\"org Pohle", "title": "Social Networks, Functional Differentiation of Society, and Data\n  Protection", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI physics.soc-ph", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Most scholars, politicians, and activists are following individualistic\ntheories of privacy and data protection. In contrast, some of the pioneers of\nthe data protection legislation in Germany like Adalbert Podlech, Paul J.\nM\\\"uller, and Ulrich Dammann used a systems theory approach. Following Niklas\nLuhmann, the aim of data protection is (1) maintaining the functional\ndifferentiation of society against the threats posed by the possibilities of\nmodern information processing, and (2) countering undue information power by\norganized social players. It could be, therefore, no surprise that the first\ndata protection law in the German state of Hesse contained rules to protect the\nindividual as well as the balance of power between the legislative and the\nexecutive body of the state. Social networks like Facebook or Google+ do not\nonly endanger their users by exposing them to other users or the public. They\nconstitute, first and foremost, a threat to society as a whole by collecting\ninformation about individuals, groups, and organizations from different social\nsystems and combining them in a centralized data bank. They transgress the\nboundaries between social systems that act as a shield against total visibility\nand transparency of the individual and protect the freedom and the autonomy of\nthe people. Without enforcing structural limitations on the organizational use\nof collected data by the social network itself or the company behind it, social\nnetworks pose the worst totalitarian peril for western societies since the fall\nof the Soviet Union.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2012 07:59:05 GMT"}], "update_date": "2012-06-15", "authors_parsed": [["Pohle", "J\u00f6rg", ""]]}, {"id": "1206.3722", "submitter": "Saurabh  Pal", "authors": "Umesh Kumar Pandey, Surjeet Kumar Yadav, Saurabh Pal", "title": "Data Mining Application to Attract Students in HEI", "comments": "6 pages", "journal-ref": "International Journal on Computer Science and Engineering\n  (IJCSE)Vol. 4 No. 06 June 2012", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last two decades, number of Higher Education Institutions (HEI) grows\nin leaps and bounds. This causes a cut throat competition among these\ninstitutions while attracting the student get admission in these institutions.\nTo make reach up to the students institution makes effort of advertisement.\nSimilarly developing and developed both type of institution launch several\nservices also to attract students. Most of the institutions are opened in self\nfinance mode. So all time they feel short hand in expenditure. Now a day a\nnumber of advertisement methods are available. So it is difficult for an\ninstitution to make advertisement through all modes and launch all services at\nthe same time due to different constraints. In this paper we use support and\nconfidence method to find out the best way of advertisement.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jun 2012 05:04:16 GMT"}], "update_date": "2012-06-19", "authors_parsed": [["Pandey", "Umesh Kumar", ""], ["Yadav", "Surjeet Kumar", ""], ["Pal", "Saurabh", ""]]}, {"id": "1206.3746", "submitter": "Loet Leydesdorff", "authors": "Loet Leydesdorff", "title": "Science Visualization and Discursive Knowledge", "comments": "forthcoming: Pp. 167-185 in: Blaise Cronin and Cassidy R. Sugimoto\n  (Eds.), Beyond Bibliometrics: Harnessing Multidimensional Indicators of\n  Scholarly Impact. Cambridge MA/ London, UK: the MIT Press, 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Positional and relational perspectives on network data have led to two\ndifferent research traditions in textual analysis and social network analysis,\nrespectively. Latent Semantic Analysis (LSA) focuses on the latent dimensions\nin textual data; social network analysis (SNA) on the observable networks. The\ntwo coupled topographies of information-processing in the network space and\nmeaning-processing in the vector space operate with different (nonlinear)\ndynamics. The historical dynamics of information processing in observable\nnetworks organizes the system into instantiations; the systems dynamics,\nhowever, can be considered as self-organizing in terms of fluxes of\ncommunication along the various dimensions that operate with different codes.\nThe development over time adds evolutionary differentiation to the historical\nintegration; a richer structure can process more complexity.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jun 2012 11:47:31 GMT"}, {"version": "v2", "created": "Sun, 24 Jun 2012 09:31:55 GMT"}, {"version": "v3", "created": "Tue, 4 Sep 2012 08:55:47 GMT"}, {"version": "v4", "created": "Sat, 13 Aug 2016 12:44:44 GMT"}], "update_date": "2016-08-16", "authors_parsed": [["Leydesdorff", "Loet", ""]]}, {"id": "1206.4166", "submitter": "Rapha\\\"el Fournier", "authors": "Matthieu Latapy, Cl\\'emence Magnien, Rapha\\\"el Fournier", "title": "Quantifying Paedophile Activity in a Large P2P System", "comments": "In press Information Processing and Management, 2012", "journal-ref": null, "doi": "10.1016/j.ipm.2012.02.008", "report-no": null, "categories": "cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing knowledge of paedophile activity in P2P systems is a crucial\nsocietal concern, with important consequences on child protection, policy\nmaking, and internet regulation. Because of a lack of traces of P2P exchanges\nand rigorous analysis methodology, however, current knowledge of this activity\nremains very limited. We consider here a widely used P2P system, eDonkey, and\nfocus on two key statistics: the fraction of paedophile queries entered in the\nsystem and the fraction of users who entered such queries. We collect hundreds\nof millions of keyword-based queries; we design a paedophile query detection\ntool for which we establish false positive and false negative rates using\nassessment by experts; with this tool and these rates, we then estimate the\nfraction of paedophile queries in our data; finally, we design and apply\nmethods for quantifying users who entered such queries. We conclude that\napproximately 0.25% of queries are paedophile, and that more than 0.2% of users\nenter such queries. These statistics are by far the most precise and reliable\never obtained in this domain.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2012 10:23:14 GMT"}], "update_date": "2012-06-20", "authors_parsed": [["Latapy", "Matthieu", ""], ["Magnien", "Cl\u00e9mence", ""], ["Fournier", "Rapha\u00ebl", ""]]}, {"id": "1206.4167", "submitter": "Rapha\\\"el Fournier", "authors": "Rapha\\\"el Fournier, Thibault Cholez, Matthieu Latapy, Cl\\'emence\n  Magnien, Isabelle Chrisment, Ivan Daniloff, Olivier Festor", "title": "Comparing paedophile activity in different P2P systems", "comments": "Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Peer-to-peer (P2P) systems are widely used to exchange content over the\nInternet. Knowledge on paedophile activity in such networks remains limited\nwhile it has important social consequences. Moreover, though there are\ndifferent P2P systems in use, previous academic works on this topic focused on\none system at a time and their results are not directly comparable.\n  We design a methodology for comparing \\kad and \\edonkey, two P2P systems\namong the most prominent ones and with different anonymity levels. We monitor\ntwo \\edonkey servers and the \\kad network during several days and record\nhundreds of thousands of keyword-based queries. We detect paedophile-related\nqueries with a previously validated tool and we propose, for the first time, a\nlarge-scale comparison of paedophile activity in two different P2P systems. We\nconclude that there are significantly fewer paedophile queries in \\kad than in\n\\edonkey (approximately 0.09% \\vs 0.25%).\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2012 10:23:33 GMT"}], "update_date": "2012-06-20", "authors_parsed": [["Fournier", "Rapha\u00ebl", ""], ["Cholez", "Thibault", ""], ["Latapy", "Matthieu", ""], ["Magnien", "Cl\u00e9mence", ""], ["Chrisment", "Isabelle", ""], ["Daniloff", "Ivan", ""], ["Festor", "Olivier", ""]]}, {"id": "1206.5451", "submitter": "Christopher Lamb", "authors": "Christopher C. Lamb, Gregory L. Heileman, and Pramod A. Jamkhedkar", "title": "Usage Management of Personal Health Records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personal health record (PHR) management is under new scrutiny as private\ncompanies move into the market and government agencies actively address\nperceived health care distribution inequalities and inefficiencies. Current\nsystems are coarse-grained and provide consumers very little actual control\nover their data. Herein, we propose an alternative system for managing the use\nof healthcare information. This novel system is finer grained, allows for data\nmining and repackaging, and gives users more control over their data, allowing\nit to be distributed to their specifications. In this paper, we outline the\ncharacteristics of such a system in different contexts, present relevant\nbackground information and research leading to the system design, and cover\nspecific usage scenarios supported by this system that are difficult to control\nusing simpler access control strategies.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jun 2012 23:40:01 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Lamb", "Christopher C.", ""], ["Heileman", "Gregory L.", ""], ["Jamkhedkar", "Pramod A.", ""]]}, {"id": "1206.5851", "submitter": "Daniel Gayo Avello", "authors": "Daniel Gayo-Avello", "title": "A meta-analysis of state-of-the-art electoral prediction from Twitter\n  data", "comments": "19 pages, 3 tables", "journal-ref": "Social Science Computer Review, August 23, 2013, 0894439313493979", "doi": "10.1177/0894439313493979", "report-no": null, "categories": "cs.SI cs.CL cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electoral prediction from Twitter data is an appealing research topic. It\nseems relatively straightforward and the prevailing view is overly optimistic.\nThis is problematic because while simple approaches are assumed to be good\nenough, core problems are not addressed. Thus, this paper aims to (1) provide a\nbalanced and critical review of the state of the art; (2) cast light on the\npresume predictive power of Twitter data; and (3) depict a roadmap to push\nforward the field. Hence, a scheme to characterize Twitter prediction methods\nis proposed. It covers every aspect from data collection to performance\nevaluation, through data processing and vote inference. Using that scheme,\nprior research is analyzed and organized to explain the main approaches taken\nup to date but also their weaknesses. This is the first meta-analysis of the\nwhole body of research regarding electoral prediction from Twitter data. It\nreveals that its presumed predictive power regarding electoral prediction has\nbeen rather exaggerated: although social media may provide a glimpse on\nelectoral outcomes current research does not provide strong evidence to support\nit can replace traditional polls. Finally, future lines of research along with\na set of requirements they must fulfill are provided.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2012 21:59:58 GMT"}], "update_date": "2013-09-04", "authors_parsed": [["Gayo-Avello", "Daniel", ""]]}, {"id": "1206.6404", "submitter": "Dotan Di Castro", "authors": "Dotan Di Castro (Technion), Aviv Tamar (Technion), Shie Mannor\n  (Technion)", "title": "Policy Gradients with Variance Related Risk Criteria", "comments": "Appears in Proceedings of the 29th International Conference on\n  Machine Learning (ICML 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Managing risk in dynamic decision problems is of cardinal importance in many\nfields such as finance and process control. The most common approach to\ndefining risk is through various variance related criteria such as the Sharpe\nRatio or the standard deviation adjusted reward. It is known that optimizing\nmany of the variance related risk criteria is NP-hard. In this paper we devise\na framework for local policy gradient style algorithms for reinforcement\nlearning for variance related criteria. Our starting point is a new formula for\nthe variance of the cost-to-go in episodic tasks. Using this formula we develop\npolicy gradient algorithms for criteria that involve both the expected cost and\nthe variance of the cost. We prove the convergence of these algorithms to local\nminima and demonstrate their applicability in a portfolio planning problem.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 19:59:59 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Di Castro", "Dotan", "", "Technion"], ["Tamar", "Aviv", "", "Technion"], ["Mannor", "Shie", "", "Technion"]]}, {"id": "1206.6606", "submitter": "Tuomo Kakkonen", "authors": "T. Kakkonen, N. Myller", "title": "A Sampling-based Tool for Plagiarism Detection in Student Texts", "comments": "Proceedings of the 8th European Conference on e-Learning, Bari,\n  Italy, 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces AntiPlag, an advanced plagiarism detection tool\nintended for use on student texts. It is capable of both hermetic detection\nthat scrutinizes only local collections of documents (other students' texts and\nlecture materials, for example) and web plagiarism detection, in which the aim\nis at identifying instances of plagiarism that have been sourced from the\nInternet. The main feature of the system is the sampling-based web plagiarism\ndetection, a novel approach to plagiarism detection that is based on combining\nweb and hermetic search technologies. The system uses standard web search\nengines to locate documents on the Internet that might have been used as\nsources of plagiarism by the writer of a text. During this sampling phase, the\nsuspected sources are downloaded, converted to ASCII text and saved to the\nlocal database so that they can be later processed by using the hermetic\ndetection methods. We evaluated the system by using a test set that contained\ninstances of verbatim copying as well as texts in which plagiarism was\nconcealed by minor editing, replacing words with synonyms and by paraphrasing.\nWe compared the results achieved by AntiPlag to an earlier evaluation study of\nfour web plagiarism detection systems, SafeAssignment, TurnitIn, EVE2 and\nPlagiarism-Finder. AntiPlag performed better than any of these systems,\nachieving the accuracy 95.8% over all the test items.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2012 09:47:47 GMT"}], "update_date": "2012-06-29", "authors_parsed": [["Kakkonen", "T.", ""], ["Myller", "N.", ""]]}, {"id": "1206.6612", "submitter": "Tuomo Kakkonen", "authors": "T. Kakkonen", "title": "TexComp - A Text Complexity Analyzer for Student Texts", "comments": "Proceedings of the 12th International Conference on Interactive\n  Computer-aided Learning, Villach, Austria, 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a method for providing feedback about the degree of\ncomplexity that is present in particular texts. Both the method and the\nsoftware tool called TexComp are designed for use during the assessment of\nstudent compositions (such as essays and theses). The method is based on a\ncautious approach to the application of readability and lexical diversity\nformulas for reasons that are analyzed in detail in this paper. We evaluated\nthe tool by using USE and BAWE, two corpora of texts that originate from\nstudents who use English as a medium of instruction.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2012 09:58:01 GMT"}], "update_date": "2012-06-29", "authors_parsed": [["Kakkonen", "T.", ""]]}, {"id": "1206.6613", "submitter": "Tuomo Kakkonen", "authors": "T. Kakkonen, E. Sutinen", "title": "Semi-automatic Assessment Model of Student Texts - Pedagogical\n  Foundations", "comments": "Proceedings of the 12th International Conference on Interactive\n  Computer-aided Learning, Villach, Austria, 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the concept of the semi-automatic assessment of student\ntexts that aims at offering the twin benefits of fully automatic grading and\nfeedback together with the advantages that can be provided by human assessors.\nThis paper concentrates on the pedagogical foundations of the model by\ndemonstrating how the relevant findings in research into written composition\nand writing education have been taken into account in the model design.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2012 10:03:11 GMT"}], "update_date": "2012-06-29", "authors_parsed": [["Kakkonen", "T.", ""], ["Sutinen", "E.", ""]]}, {"id": "1206.7050", "submitter": "Derek O'Callaghan", "authors": "Derek O'Callaghan, Derek Greene, Maura Conway, Joe Carthy, P\\'adraig\n  Cunningham", "title": "An Analysis of Interactions Within and Between Extreme Right Communities\n  in Social Media", "comments": "20 pages, 6 figures. Additional topic analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many extreme right groups have had an online presence for some time through\nthe use of dedicated websites. This has been accompanied by increased activity\nin social media platforms in recent years, enabling the dissemination of\nextreme right content to a wider audience. In this paper, we present an\nanalysis of the activity of a selection of such groups on Twitter, using\nnetwork representations based on reciprocal follower and interaction\nrelationships, while also analyzing topics found in their corresponding tweets.\nInternational relationships between certain extreme right groups across\ngeopolitical boundaries are initially identified. Furthermore, we also discover\nstable communities of accounts within local interaction networks, in addition\nto associated topics, where the underlying extreme right ideology of these\ncommunities is often identifiable.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2012 15:21:11 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2014 14:42:43 GMT"}], "update_date": "2014-01-28", "authors_parsed": [["O'Callaghan", "Derek", ""], ["Greene", "Derek", ""], ["Conway", "Maura", ""], ["Carthy", "Joe", ""], ["Cunningham", "P\u00e1draig", ""]]}]