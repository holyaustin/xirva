[{"id": "1808.00023", "submitter": "Sam Corbett-Davies", "authors": "Sam Corbett-Davies and Sharad Goel", "title": "The Measure and Mismeasure of Fairness: A Critical Review of Fair\n  Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The nascent field of fair machine learning aims to ensure that decisions\nguided by algorithms are equitable. Over the last several years, three formal\ndefinitions of fairness have gained prominence: (1) anti-classification,\nmeaning that protected attributes---like race, gender, and their proxies---are\nnot explicitly used to make decisions; (2) classification parity, meaning that\ncommon measures of predictive performance (e.g., false positive and false\nnegative rates) are equal across groups defined by the protected attributes;\nand (3) calibration, meaning that conditional on risk estimates, outcomes are\nindependent of protected attributes. Here we show that all three of these\nfairness definitions suffer from significant statistical limitations. Requiring\nanti-classification or classification parity can, perversely, harm the very\ngroups they were designed to protect; and calibration, though generally\ndesirable, provides little guarantee that decisions are equitable. In contrast\nto these formal fairness criteria, we argue that it is often preferable to\ntreat similarly risky people similarly, based on the most statistically\naccurate estimates of risk that one can produce. Such a strategy, while not\nuniversally applicable, often aligns well with policy objectives; notably, this\nstrategy will typically violate both anti-classification and classification\nparity. In practice, it requires significant effort to construct suitable risk\nestimates. One must carefully define and measure the targets of prediction to\navoid retrenching biases in the data. But, importantly, one cannot generally\naddress these difficulties by requiring that algorithms satisfy popular\nmathematical formalizations of fairness. By highlighting these challenges in\nthe foundation of fair machine learning, we hope to help researchers and\npractitioners productively advance the area.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 18:38:04 GMT"}, {"version": "v2", "created": "Tue, 14 Aug 2018 17:09:32 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Corbett-Davies", "Sam", ""], ["Goel", "Sharad", ""]]}, {"id": "1808.00039", "submitter": "Rawiphon Charunphankasem", "authors": "Rawiphon Charunphankaseam", "title": "Develop the application for learning place value", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.MM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The objectives of this research were 1) to develop the application for\nlearning place value, 2) to determine the efficiency of developed application,\n3) to compare academic achievement to compare academic achievement between\npre-lesson and post-lesson of students who learned with the developed\napplication about place value, 4) to compare academic achievement between\nstudents who learned place value by the developed application and through\ntraditional method during post-lesson, 5) to compare retention of academic\nachievement of application for learning place value after 2 weeks, and 6) to\nfind satisfactory of student who learned the application for learning place\nvalue. The sample group selected through purposive sampling was 5 content\nspecialists and 400 pratomsuksa 1 students.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 05:32:29 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Charunphankaseam", "Rawiphon", ""]]}, {"id": "1808.00048", "submitter": "Christos Rodosthenous", "authors": "Christos Rodosthenous and Loizos Michael", "title": "Web-STAR: A Visual Web-Based IDE for a Story Comprehension System", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Web-STAR, an online platform for story understanding built on top\nof the STAR reasoning engine for STory comprehension through ARgumentation. The\nplatform includes a web-based IDE, integration with the STAR system, and a web\nservice infrastructure to support integration with other systems that rely on\nstory understanding functionality to complete their tasks. The platform also\ndelivers a number of \"social\" features, including a community repository for\npublic story sharing with a built-in commenting system, and tools for\ncollaborative story editing that can be used for team development projects and\nfor educational purposes.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jul 2018 05:09:27 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Rodosthenous", "Christos", ""], ["Michael", "Loizos", ""]]}, {"id": "1808.00151", "submitter": "Yehezkel Resheff", "authors": "Noa Haas, Yair Horesh, Shimon Shahar, Yehezkel S. Resheff", "title": "Identifying Financial Institutions by Transaction Signatures", "comments": "FinTech@KDD'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial data aggregators and Personal Financial Management (PFM) services\nare software products that help individuals manage personal finances by\ncollecting information from multiple accounts at various Financial Institutes\n(FIs), presenting data in a coherent and concentrated way, and highlighting\ninsights and suggestions. Money transfers consist of two sides and a direction.\nFrom the perspective of a financial data aggregator, an incoming transaction\nconsists of a date, an amount, and a description string, but not the explicit\nidentity of the sending FI. In this paper we investigate supervised learning\nbased methods to infer the identity of the sending FI from the description\nstring of a money transfer transaction, using a blend of traditional and RNN\nbased NLP methods. Our approach is based on the observation that the textual\ndescription field associated with a transactions is subjected to various types\nof normalizations and standardizations, resulting in unique patterns that\nidentify the issuer. We compare multiple methods using a large real-word\ndataset of over $10$ million transactions.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 18:20:27 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Haas", "Noa", ""], ["Horesh", "Yair", ""], ["Shahar", "Shimon", ""], ["Resheff", "Yehezkel S.", ""]]}, {"id": "1808.00160", "submitter": "Alejandro Noriega-Campero", "authors": "Alejandro Noriega-Campero, Alex Rutherford, Oren Lederman, Yves A. de\n  Montjoye, and Alex Pentland", "title": "Mapping the Privacy-Utility Tradeoff in Mobile Phone Data for\n  Development", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's age of data holds high potential to enhance the way we pursue and\nmonitor progress in the fields of development and humanitarian action. We study\nthe relation between data utility and privacy risk in large-scale behavioral\ndata, focusing on mobile phone metadata as paradigmatic domain. To measure\nutility, we survey experts about the value of mobile phone metadata at various\nspatial and temporal granularity levels. To measure privacy, we propose a\nformal and intuitive measure of reidentification risk$\\unicode{x2014}$the\ninformation ratio$\\unicode{x2014}$and compute it at each granularity level. Our\nresults confirm the existence of a stark tradeoff between data utility and\nreidentifiability, where the most valuable datasets are also most prone to\nreidentification. When data is specified at ZIP-code and hourly levels, outside\nknowledge of only 7% of a person's data suffices for reidentification and\nretrieval of the remaining 93%. In contrast, in the least valuable dataset,\nspecified at municipality and daily levels, reidentification requires on\naverage outside knowledge of 51%, or 31 data points, of a person's data to\nretrieve the remaining 49%. Overall, our findings show that coarsening data\ndirectly erodes its value, and highlight the need for using data-coarsening,\nnot as stand-alone mechanism, but in combination with data-sharing models that\nprovide adjustable degrees of accountability and security.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 04:19:50 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Noriega-Campero", "Alejandro", ""], ["Rutherford", "Alex", ""], ["Lederman", "Oren", ""], ["de Montjoye", "Yves A.", ""], ["Pentland", "Alex", ""]]}, {"id": "1808.00320", "submitter": "Megan Strait", "authors": "Megan Strait and Ana S\\'anchez Ramos and Virginia Contreras and Noemi\n  Garcia", "title": "Robots Racialized in the Likeness of Marginalized Social Identities are\n  Subject to Greater Dehumanization than those racialized as White", "comments": "Accepted to IEEE RO-MAN 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence and spread of humanlike robots into increasingly public domains\nhas revealed a concerning phenomenon: people's unabashed dehumanization of\nrobots, particularly those gendered as female. Here we examined this phenomenon\nfurther towards understanding whether other socially marginalized cues\n(racialization in the likeness of Asian and Black identities), like\nfemale-gendering, are associated with the manifestation of dehumanization\n(e.g., objectification, stereotyping) in human-robot interactions. To that end,\nwe analyzed free-form comments (N=535) on three videos, each depicting a gynoid\n- Bina48, Nadine, or Yangyang - racialized as Black, White, and Asian\nrespectively. As a preliminary control, we additionally analyzed commentary\n(N=674) on three videos depicting women embodying similar identity cues. The\nanalyses indicate that people more frequently dehumanize robots racialized as\nAsian and Black, than they do of robots racialized as White. Additional,\npreliminary evaluation of how people's responding towards the gynoids compares\nto that towards other people suggests that the gynoids' ontology (as robots)\nfurther facilitates the dehumanization.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 13:57:00 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Strait", "Megan", ""], ["Ramos", "Ana S\u00e1nchez", ""], ["Contreras", "Virginia", ""], ["Garcia", "Noemi", ""]]}, {"id": "1808.00334", "submitter": "Mansaf Alam Dr", "authors": "Samiya Khan, Kashish Ara Shakil, Mansaf Alam", "title": "PABED A Tool for Big Education Data Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing and big data have risen to become the most popular\ntechnologies of the modern world. Apparently, the reason behind their immense\npopularity is their wide range of applicability as far as the areas of interest\nare concerned. Education and research remain one of the most obvious and\nbefitting application areas. This research paper introduces a big data\nanalytics tool, PABED Project Analyzing Big Education Data, for the education\nsector that makes use of cloud-based technologies. This tool is implemented\nusing Google BigQuery and R programming language and allows comparison of\nundergraduate enrollment data for different academic years. Although, there are\nmany proposed applications of big data in education, there is a lack of tools\nthat can actualize the concept into practice. PABED is an effort in this\ndirection. The implementation and testing details of the project have been\ndescribed in this paper. This tool validates the use of cloud computing and big\ndata technologies in education and shall head start development of more\nsophisticated educational intelligence tools.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 09:30:05 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Khan", "Samiya", ""], ["Shakil", "Kashish Ara", ""], ["Alam", "Mansaf", ""]]}, {"id": "1808.00398", "submitter": "Yevhenii Modlo", "authors": "Yevhenii O. Modlo", "title": "Competence of bachelor in electromechanics in simulation", "comments": "8 pages, 3 figures, 1 table, in Ukrainian", "journal-ref": "Bulletin of Alfred Nobel University. Series \"Pedagogy and\n  Psychology\" 1 (2015) 17-24", "doi": null, "report-no": null, "categories": "physics.ed-ph cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The article is devoted to communication competence in modeling with other\ncompetences of Bachelor in Electromechanics, its structure and the contribution\nof components in the formation of competence. The approaches to defining\ncompetence of bachelor-electrician are determined. A system of competencies is\nsuggested. In order to determine the inclusion of each of the selected\ncompetencies in the formation of competence of Bachelor in Electromechanics,\nexperts' opinions were surveyed. The goals were to determine the structure and\ncontent of the bachelor's in Electromechanics competence in modeling. The\nresearch focus was to research the relationship of competence in modeling with\nother competencies of Bachelor of Electromechanics, its structure and the\ncontribution of components in the formation of competence. The object of the\nresearch was Bachelor's in Electromechanics learning process. The subject of\nthe research was the theoretical base of expertise of Bachelors in\nElectromechanics in modeling. The results of the research were the connection\nof competence in modeling with other competencies of Bachelor in\nElectromechanics, its structure and the contribution of components in the\nformation of competence. The structure and content of the electrician's\ncompetence in modeling were defined. The principal conclusions and\nrecommendations were: the system of competence in electromechanics in modeling\ninvolves three groups of competencies: the general scientific, common\nprofessional, and specific professional ones. The formation of competence of\nBachelor in Electromechanics in simulation cycle starts in mathematical and\nnatural-scientific training (the leading one is general scientific competence)\nand continues in the cycle of professional and practical training (the leading\nones are common professional and specific professional competencies).\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 12:07:23 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Modlo", "Yevhenii O.", ""]]}, {"id": "1808.00527", "submitter": "Carlos Sarraute", "authors": "Jorge Brea, Javier Burroni, Carlos Sarraute", "title": "Inference of Users Demographic Attributes based on Homophily in\n  Communication Networks", "comments": "Published in Fourth Conference on the Scientific Analysis of Mobile\n  Phone Datasets (NetMob), MIT Media Lab, Cambridge, USA, 8 April 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Over the past decade, mobile phones have become prevalent in all parts of the\nworld, across all demographic backgrounds. Mobile phones are used by men and\nwomen across a wide age range in both developed and developing countries.\nConsequently, they have become one of the most important mechanisms for social\ninteraction within a population, making them an increasingly important source\nof information to understand human demographics and human behaviour.\n  In this work we combine two sources of information: communication logs from a\nmajor mobile operator in a Latin American country, and information on the\ndemographics of a subset of the users population. This allows us to perform an\nobservational study of mobile phone usage, differentiated by age groups\ncategories. This study is interesting in its own right, since it provides\nknowledge on the structure and demographics of the mobile phone market in the\nstudied country.\n  We then tackle the problem of inferring the age group for all users in the\nnetwork. We present here an exclusively graph-based inference method relying\nsolely on the topological structure of the mobile network, together with a\ntopological analysis of the performance of the algorithm. The equations for our\nalgorithm can be described as a diffusion process with two added properties:\n(i) memory of its initial state, and (ii) the information is propagated as a\nprobability vector for each node attribute (instead of the value of the\nattribute itself). Our algorithm can successfully infer different age groups\nwithin the network population given known values for a subset of nodes (seed\nnodes). Most interestingly, we show that by carefully analysing the topological\nrelationships between correctly predicted nodes and the seed nodes, we can\ncharacterize particular subsets of nodes for which our inference method has\nsignificantly higher accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 19:32:31 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Brea", "Jorge", ""], ["Burroni", "Javier", ""], ["Sarraute", "Carlos", ""]]}, {"id": "1808.01027", "submitter": "Fang-Jing Wu", "authors": "Fang-Jing Wu and G\\\"urkan Solmaz", "title": "We Hear Your Activities through Wi-Fi Signals", "comments": "This work has received funding from the European Union's Horizon 2020\n  research and innovation programme within the project \"Worldwide\n  Interoperability for SEmantics IoT\" under grant agreement Number 723156", "journal-ref": null, "doi": "10.1109/WF-IoT.2016.7845478", "report-no": null, "categories": "cs.NI cs.CY eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we focus on the problem of human activity recognition without\nidentification of the individuals in a scene. We consider using Wi-Fi signals\nto detect certain human mobility behaviors such as stationary, walking, or\nrunning. The main objective is to successfully detect these behaviors for the\nindividuals and based on that enable detection of the crowd's overall mobility\nbehavior. We propose a method which infers mobility behaviors in two stages:\nfrom Wi-Fi signals to trajectories and from trajectories to the mobility\nbehaviors. We evaluate the applicability of the proposed approach using the\nStudentLife dataset which contains Wi-Fi, GPS, and accelerometer measurements\ncollected from smartphones of 49 students within a three-month period. The\nexperimental results indicate that there is high correlation between stability\nof Wi-Fi signals and mobility activity. This unique characteristic provides\nsufficient evidences to extend the proposed idea to mobility analytics of\ngroups of people in the future.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2018 21:05:30 GMT"}], "update_date": "2018-08-06", "authors_parsed": [["Wu", "Fang-Jing", ""], ["Solmaz", "G\u00fcrkan", ""]]}, {"id": "1808.01076", "submitter": "Megan Strait", "authors": "Megan Strait, Virginia Contreras, Christian Duarte Vela", "title": "Verbal Disinhibition towards Robots is Associated with General\n  Antisociality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of agentic technologies (e.g., robots) in increasingly public\nrealms (e.g., social media) has revealed surprising antisocial tendencies in\nhuman-agent interactions. In particular, there is growing indication of\npeople's propensity to act aggressively towards such systems - without\nprovocation and unabashedly so.\n  Towards understanding whether this aggressive behavior is anomalous or\nwhether it is associated with general antisocial tendencies in people's broader\ninteractions, we examined people's verbal disinhibition towards two artificial\nagents. Using Twitter as a corpus of free-form, unsupervised interactions, we\nidentified 40 independent Twitter users who tweeted abusively or non-abusively\nat one of two high-profile robots with Twitter accounts (TMI's Bina48 and\nHanson Robotics' Sophia). Analysis of 50 of each user's tweets most proximate\nto their tweet at the respective robot (N=2,000) shows people's aggression\ntowards the robots to be associated with more frequent abuse in their general\ntweeting. The findings thus suggest that disinhibition towards robots is not\nnecessarily a pervasive tendency, but rather one driven by individual\ndifferences in antisociality. Nevertheless, such unprovoked abuse highlights a\nneed for attention to the reception of agentic technologies in society, as well\nas the necessity of corresponding capacities to recognize and respond to\nantisocial dynamics.\n", "versions": [{"version": "v1", "created": "Fri, 3 Aug 2018 03:19:02 GMT"}], "update_date": "2018-08-06", "authors_parsed": [["Strait", "Megan", ""], ["Contreras", "Virginia", ""], ["Vela", "Christian Duarte", ""]]}, {"id": "1808.01100", "submitter": "Jamie Nunez", "authors": "Ludwik Trammer and Jamie Nunez", "title": "Code Shrew: Software platform for teaching programming through drawings\n  and animations", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present Code Shrew, a new software platform accompanied by\nan interactive programming course. Its aim is to teach the fundamentals of\ncomputer programming by enabling users to create their own drawings and\nanimations. The programming language has a straightforward syntax based on\nPython, with additions that enable easy drawing and animating using\nobject-oriented code. The editor reacts seamlessly and instantly, providing an\nengaging and interactive environment for experimenting and testing ideas. The\nprogramming course consists of lessons that cover essential programming\nprinciples, as well as challenges to test users' skills as they progress\nthrough the course. Both the lessons and challenges take advantage of the\neditor's instant feedback, allowing for a focus on learning-by-doing. We\ndescribe the software and the content, the motivation behind them, and their\nconnection to constructionism.\n", "versions": [{"version": "v1", "created": "Fri, 3 Aug 2018 07:27:26 GMT"}, {"version": "v2", "created": "Wed, 8 Aug 2018 15:38:03 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["Trammer", "Ludwik", ""], ["Nunez", "Jamie", ""]]}, {"id": "1808.01479", "submitter": "Nalin Asanka Gamagedara Arachchilage", "authors": "Awanthika Senarath and Nalin Asanka Gamagedara Arachchilage", "title": "Understanding Software Developers' Approach towards Implementing Data\n  Minimization", "comments": "4, USENIX Symposium on Usable Privacy and Security (SOUPS), August 12\n  14 Baltimore, MD, USA,2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data Minimization (DM) is a privacy practice that requires minimizing the use\nof user data in software systems. However, continuous privacy incidents that\ncompromise user data suggest that the requirements of DM are not adequately\nimplemented in software systems. Therefore, it is important that we understand\nthe problems faced by software developers when they attempt to implement DM in\nsoftware systems. In this study, we investigate how 24 software developers\nimplement DM in a software system design when they are asked to. Our findings\nrevealed that developers find it difficult to implement DM when they are not\naware of the potential of data they could collect at the design phase of\nsystems. Furthermore, developers were inconsistent in how they implemented DM\nin their software designs.\n", "versions": [{"version": "v1", "created": "Sat, 4 Aug 2018 12:59:25 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Senarath", "Awanthika", ""], ["Arachchilage", "Nalin Asanka Gamagedara", ""]]}, {"id": "1808.01481", "submitter": "Nalin Asanka Gamagedara Arachchilage", "authors": "Chamila Wijayarathna and Nalin Asanka Gamagedara Arachchilage", "title": "Am I Responsible for End-User's Security? A Programmer's Perspective", "comments": "4, USENIX Symposium on Usable Privacy and Security (SOUPS), August 12\n  14 Baltimore, MD, USA,2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous research has pointed that software applications should not depend on\nprogrammers to provide security for end-users as majority of programmers are\nnot experts of computer security. On the other hand, some studies have revealed\nthat security experts believe programmers have a major role to play in ensuring\nthe end-users' security. However, there has been no investigation on what\nprogrammers perceive about their responsibility for the end-users' security of\napplications they develop. In this work, by conducting a qualitative\nexperimental study with 40 software developers, we attempted to understand the\nprogrammer's perception on who is responsible for ensuring end-users' security\nof the applications they develop. Results revealed majority of programmers\nperceive that they are responsible for the end-users' security of applications\nthey develop. Furthermore, results showed that even though programmers aware of\nthings they need to do to ensure end-users' security, they do not often follow\nthem. We believe these results would change the current view on the role that\ndifferent stakeholders of the software development process (i.e. researchers,\nsecurity experts, programmers and Application Programming Interface (API)\ndevelopers) have to play in order to ensure the security of software\napplications.\n", "versions": [{"version": "v1", "created": "Sat, 4 Aug 2018 13:07:30 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Wijayarathna", "Chamila", ""], ["Arachchilage", "Nalin Asanka Gamagedara", ""]]}, {"id": "1808.01616", "submitter": "Hongzhi Wang", "authors": "Zhemin Liu and Feng Xiong and Kaifa Zou and Hongzhi Wang", "title": "Predicting Learning Status in MOOCs using LSTM", "comments": "arXiv admin note: text overlap with arXiv:1402.1128 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time and open online course resources of MOOCs have attracted a large\nnumber of learners in recent years. However, many new questions were emerging\nabout the high dropout rate of learners. For MOOCs platform, predicting the\nlearning status of MOOCs learners in real time with high accuracy is the\ncrucial task, and it also help improve the quality of MOOCs teaching. The\nprediction task in this paper is inherently a time series prediction problem,\nand can be treated as time series classification problem, hence this paper\nproposed a prediction model based on RNNLSTMs and optimization techniques which\ncan be used to predict learners' learning status. Using datasets provided by\nChinese University MOOCs as the inputs of model, the average accuracy of\nmodel's outputs was about 90%.\n", "versions": [{"version": "v1", "created": "Sun, 5 Aug 2018 14:06:18 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Liu", "Zhemin", ""], ["Xiong", "Feng", ""], ["Zou", "Kaifa", ""], ["Wang", "Hongzhi", ""]]}, {"id": "1808.01666", "submitter": "Tshilidzi Marwala", "authors": "Tshilidzi Marwala", "title": "On Robot Revolution and Taxation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in artificial intelligence are resulting in the rapid automation of\nthe work force. The tools that are used to automate are called robots. Bill\nGates proposed that in order to deal with the problem of the loss of jobs and\nreduction of the tax revenue we ought to tax the robots. The problem with\ntaxing the robots is that it is not easy to know what a robot is. This article\nstudies the definition of a robot and the implication of advances in robotics\non taxation. It is evident from this article that it is a difficult task to\nestablish what a robot is and what is not a robot. It concludes that taxing\nrobots is the same as increasing corporate tax.\n", "versions": [{"version": "v1", "created": "Sun, 5 Aug 2018 18:26:34 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Marwala", "Tshilidzi", ""]]}, {"id": "1808.01708", "submitter": "Devashish Gosain", "authors": "Tarun Kumar Yadav, Akshat Sinha, Devashish Gosain, Piyush Sharma,\n  Sambuddho Chakravarty", "title": "Where The Light Gets In: Analyzing Web Censorship Mechanisms in India", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a detailed study of the Internet censorship in India. We\nconsolidated a list of potentially blocked websites from various public sources\nto assess censorship mechanisms used by nine major ISPs. To begin with, we\ndemonstrate that existing censorship detection tools like OONI are grossly\ninaccurate. We thus developed various techniques and heuristics to correctly\nassess censorship and study the underlying mechanism involved in these ISPs. At\nevery step we corroborated our finding manually to test the efficacy of our\napproach, a step largely ignored by others. We fortify our findings by\nadjudging the coverage and consistency of censorship infrastructure, broadly in\nterms of average number of network paths and requested domains the\ninfrastructure surveils. Our results indicate a clear disparity among the ISPs,\non how they install censorship infrastructure. For instance, in Idea network we\nobserved the censorious middleboxes on over 90% of our tested intra-AS paths\nwhereas for Vodafone, it is as low as 2.5%. We conclude our research by\ndevising our own novel anti-censorship strategies, that does not depend on\nthird party tools (like proxies, Tor and VPNs etc.). We managed to anti-censor\nall blocked websites in all ISPs under test.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 02:11:51 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Yadav", "Tarun Kumar", ""], ["Sinha", "Akshat", ""], ["Gosain", "Devashish", ""], ["Sharma", "Piyush", ""], ["Chakravarty", "Sambuddho", ""]]}, {"id": "1808.01883", "submitter": "Gaurav Sood", "authors": "Ken Cor, Gaurav Sood", "title": "Pwned: How Often Are Americans' Online Accounts Breached?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  News about massive online breaches is increasingly common. But there has been\nlittle good data on how exposed people are because of these breaches. We\ncombine data from a large, representative sample of adult Americans (n = 5,000)\nwith data from \\textit{Have I Been Pwned} to estimate the lower bound of the\naverage number of breached online accounts per person. We find that at least\n82.84% of Americans have had their accounts breached. And that on average\nAmericans' accounts have been breached at least three times. Better educated,\nthe middle-aged, women, and Whites are more likely to have had their accounts\nbreached than the complementary groups.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 00:55:49 GMT"}, {"version": "v2", "created": "Tue, 7 Aug 2018 21:44:35 GMT"}, {"version": "v3", "created": "Mon, 18 Feb 2019 05:50:22 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Cor", "Ken", ""], ["Sood", "Gaurav", ""]]}, {"id": "1808.01884", "submitter": "Zeeshan Bhatti Dr.", "authors": "Rida Sara Khan, Asad Ali Zardar, Zeeshan Bhatti", "title": "Artificial Intelligence based Smart Doctor using Decision Tree Algorithm", "comments": "5 pages, 13 figures, 3 tables", "journal-ref": "Journal of Information & Communication Technology - JICT Vol. 11\n  Issue. 2, 2017", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial Intelligence (AI) has already made a huge impact on our current\ntechnological trends. Through AI developments, machines are now given power and\nintelligence to behave and work like human mind. In this research project, we\npropose and implement an AI based health physician system that would be able to\ninteract with the patient, do the diagnosis and suggest quick remedy or\ntreatment of their problem. A decision tree algorithm is implemented in order\nto follow a top down searching approach to identify and diagnose the problem\nand suggest a possible solution. The system uses a questionnaire based approach\nto query the user (patient) about various Symptoms, based on which a decision\nis made and a medicine is recommended\n", "versions": [{"version": "v1", "created": "Sun, 29 Jul 2018 07:45:33 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Khan", "Rida Sara", ""], ["Zardar", "Asad Ali", ""], ["Bhatti", "Zeeshan", ""]]}, {"id": "1808.01886", "submitter": "Andrii Striuk", "authors": "Andrii Striuk", "title": "Designing a blended learning of system programming for software\n  engineering bachelors", "comments": "in Ukrainian", "journal-ref": "Theory and methodology of mathematics, physics, computer science\n  10 (2012) 157-163", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The research objective is to design a blended learning of system programming\nfor software engineering bachelors. Under blended learning we understand the\nway of implementing the content of the training, which integrates classroom and\nnon-auditing learning activities provided that a pedagogically balanced\ncombination of traditional, distance and mobile learning technologies. Modern\napproaches to the design and implementation of training systems are considered.\nThe studying purposes of system programming for software engineering bachelors\nare determined. The complex of practical tasks from the course is developed.\nThe methods of training that will be used when studying individual thematic\nsections of system programming are determined. A plan for studying each\nthematic section has been developed: The organizational model of the student's\nwork during the study of the discipline \"System programming\" with the use of\nthe blended learning management system is proposed.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 19:56:39 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Striuk", "Andrii", ""]]}, {"id": "1808.01895", "submitter": "Andreas Kamilaris", "authors": "Andreas Kamilaris and Frank Ostermann", "title": "Geospatial Analysis and Internet of Things in Environmental Informatics", "comments": "Applying Internet of Things Technologies in Environmental Research\n  Workshop, Proc. of EnviroInfo 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Geospatial analysis offers large potential for better understanding,\nmodelling and visualizing our natural and artificial ecosystems, using Internet\nof Things as a pervasive sensing infrastructure. This paper performs a review\nof research work based on the IoT, in which geospatial analysis has been\nemployed in environmental informatics. Six different geospatial analysis\nmethods have been identified, presented together with 26 relevant IoT\ninitiatives adopting some of these techniques. Analysis is performed in\nrelation to the type of IoT devices used, their deployment status and data\ntransmission standards, data types employed, and reliability of measurements.\nThis paper scratches the surface of this combination of technologies and\ntechniques, providing indications of how IoT, together with geospatial\nanalysis, are currently being used in the domain of environmental research.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 10:46:24 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Kamilaris", "Andreas", ""], ["Ostermann", "Frank", ""]]}, {"id": "1808.01989", "submitter": "Viktoriia Tkachuk", "authors": "Natalya Rashevs`ka, Viktoriia Tkachuk", "title": "Technological conditions of mobile learning in high school", "comments": "6 pages, In English", "journal-ref": "Metallurgical and Mining Industry, 3(2015) 161-164", "doi": null, "report-no": null, "categories": "physics.ed-ph cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reviews the history of mobile learning, provides a definition of\nmobile learning. The properties, advantages and disadvantages of mobile\nlearning, areas of its implementation at the Technical University and mobile\nlearning tools were specified. The aim of the article is the analysis of the\nmodern state of mobile learning and the determination of the conditions of its\nimplementation at the high technical educational institutions. The process of\nthe mobile learning in the national education system is in its formation stage.\nNowadays the following stages of its development are formed, which are based on\nthe availability of the technical means for the mobile learning and the mobile\naccess implementation to educational resources. The mobile learning is the\nlogical and innovation process in the education system, which is defined as a\nlearning technology which uses the mobile devices, communication technology and\nintelligent user interfaces.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 12:09:08 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Rashevs`ka", "Natalya", ""], ["Tkachuk", "Viktoriia", ""]]}, {"id": "1808.02017", "submitter": "Daniele Ramazzotti", "authors": "Daniele Ramazzotti and Peter Clardy and Leo Anthony Celi and David J.\n  Stone and Robert S. Rudin", "title": "Withholding or withdrawing invasive interventions may not accelerate\n  time to death among dying ICU patients", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0212439", "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We considered observational data available from the MIMIC-III open-access ICU\ndatabase and collected within a study period between year 2002 up to 2011. If a\npatient had multiple admissions to the ICU during the 30 days before death,\nonly the first stay was analyzed, leading to a final set of 6,436 unique ICU\nadmissions during the study period. We tested two hypotheses: (i)\nadministration of invasive intervention during the ICU stay immediately\npreceding end-of-life would decrease over the study time period and (ii)\ntime-to-death from ICU admission would also decrease, due to the decrease in\ninvasive intervention administration. To investigate the latter hypothesis, we\nperformed a subgroups analysis by considering patients with lowest and highest\nseverity. To do so, we stratified the patients based on their SAPS I scores,\nand we considered patients within the first and the third tertiles of the\nscore. We then assessed differences in trends within these groups between years\n2002-05 vs. 2008-11.\n  Comparing the period 2002-2005 vs. 2008-2011, we found a reduction in\nendotracheal ventilation among patients who died within 30 days of ICU\nadmission (120.8 vs. 68.5 hours for the lowest severity patients, p<0.001; 47.7\nvs. 46.0 hours for the highest severity patients, p=0.004). This is explained\nin part by an increase in the use of non-invasive ventilation. Comparing the\nperiod 2002-2005 vs. 2008-2011, we found a reduction in the use of vasopressors\nand inotropes among patients with the lowest severity who died within 30 days\nof ICU admission (41.8 vs. 36.2 hours, p<0.001) but not among those with the\nhighest severity. Despite a reduction in the use of invasive interventions, we\ndid not find a reduction in the time to death between 2002-2005 vs. 2008-2011\n(7.8 days vs. 8.2 days for the lowest severity patients, p=0.32; 2.1 days vs.\n2.0 days for the highest severity patients, p=0.74).\n", "versions": [{"version": "v1", "created": "Sat, 4 Aug 2018 17:50:41 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 22:13:42 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Ramazzotti", "Daniele", ""], ["Clardy", "Peter", ""], ["Celi", "Leo Anthony", ""], ["Stone", "David J.", ""], ["Rudin", "Robert S.", ""]]}, {"id": "1808.02021", "submitter": "Yifan Gao", "authors": "Yifan Gao, Vicente Gonzalez, and Tak Wing Yiu", "title": "The Effectiveness of Traditional Tools and Computer-Aided Technologies\n  for Health and Safety Training in the Construction Sector: A Systematic\n  Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For workers, the exposure to on-site hazards can result in fatalities and\nserious injuries. To improve safety outcomes, different approaches have been\nimplemented for health and safety training in the construction sector, such as\ntraditional tools and computer-aided technologies (e.g., serious games and\nvirtual reality). However, the effectiveness of these approaches has been\nbarely explored. In order to bridge this gap, a systematic review of existing\nstudies was conducted. Unlike previous review studies in this field that\nfocused on uncovering the technology characters and challenges, this study\nmainly evaluated the effectiveness of training using traditional tools and\ncomputer-aided technologies on the well-being of individuals. Measures of the\neffectiveness included knowledge acquisition, unsafe behaviour alteration, and\ninjury rate reduction. Results indicated that: 1. the effectiveness of\ntraditional tools is sufficiently supported by statistical evidence; and 2. the\nuse of computer-aided technologies has evidence to support its effectiveness,\nbut more solid evidence is required to support this statement. It was also\nfound that the overall performance of computer-aided technologies is superior\nin several technical aspects compared to traditional tools, namely,\nrepresenting actual workplace situations, providing text-free interfaces,\nhaving better user engagement, and being more cost-efficient. Finally, using\nthe systematic review findings, a theoretical framework is proposed as a\npotential solution to help future research in this field systematically examine\nthe effectiveness and usability of their approaches. This framework is\ntheoretical in nature and requires further validation. A further study is\ntherefore proposed to test and validate this framework.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 01:09:21 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Gao", "Yifan", ""], ["Gonzalez", "Vicente", ""], ["Yiu", "Tak Wing", ""]]}, {"id": "1808.02081", "submitter": "Andrii Striuk", "authors": "Andrii M. Striuk, Maryna V. Rassovytska", "title": "The system of cloud oriented learning tools as an element of educational\n  and scientific environment of high school", "comments": "in Ukrainian", "journal-ref": "Information Technologies and Learning Tools 42 (2014) 150-158", "doi": null, "report-no": null, "categories": "cs.OH cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this research is to design and implementation of cloud based\nlearning environment for separate division of the university. The analysis of\nexisting approaches to the construction of cloud based learning environments,\nthe formation of requirements cloud based learning tools, the selection on the\nbasis of these requirements, cloud ICT training and pilot their use for\nbuilding cloud based learning environment for separate division of the\nuniversity with the use of open source software and resources its own IT\ninfrastructure of the institution. Results of the study is planned to\ngeneralize to develop recommendations for the design of cloud based environment\nof high school.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jul 2018 20:54:42 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Striuk", "Andrii M.", ""], ["Rassovytska", "Maryna V.", ""]]}, {"id": "1808.02131", "submitter": "Ben Nassi", "authors": "Ben Nassi, Moshe Sror, Ido Lavi, Yair Meidan, Asaf Shabtai, Yuval\n  Elovici", "title": "Piping Botnet - Turning Green Technology into a Water Disaster", "comments": "https://www.youtube.com/watch?v=Yy8tOEhH6T0", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current generation of IoT devices is being used by clients and consumers\nto regulate resources (such as water and electricity) obtained from critical\ninfrastructure (such as urban water services and smart grids), creating a new\nattack vector against critical infrastructure. In this research we show that\nsmart irrigation systems, a new type of green technology and IoT device aimed\nat saving water and money, can be used by attackers as a means of attacking\nurban water services. We present a distributed attack model that can be used by\nan attacker to attack urban water services using a botnet of commercial smart\nirrigation systems. Then, we show how a bot running on a compromised device in\na LAN can:(1) detect a connected commercial smart irrigation system\n(RainMachine, BlueSpray, and GreenIQ) within 15 minutes by analyzing LAN's\nbehavior using a dedicated classification model, and (2) launch watering via a\ncommercial smart irrigation system according to an attacker's wishes using\nspoofing and replay attacks. In addition, we model the damage that can be\ncaused by performing such an attack and show that a standard water tower can be\nemptied in an hour using a botnet of 1,355 sprinklers and a flood water\nreservoir can be emptied overnight using a botnet of 23,866 sprinklers.\nFinally, we discuss countermeasure methods and hypothesize whether the next\ngeneration of plumbers will use Kali Linux instead of a monkey wrench.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 21:57:50 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Nassi", "Ben", ""], ["Sror", "Moshe", ""], ["Lavi", "Ido", ""], ["Meidan", "Yair", ""], ["Shabtai", "Asaf", ""], ["Elovici", "Yuval", ""]]}, {"id": "1808.02153", "submitter": "George Grispos", "authors": "William Ledbetter and William Bradley Glisson and Todd McDonald and\n  Todd Andel and George Grispos and Kim-Kwang Raymond Choo", "title": "Digital Blues: An Investigation into the Use of Bluetooth Protocols", "comments": "Presented at the 17th IEEE International Conference On Trust,\n  Security And Privacy In Computing And Communications (IEEE TrustCom-18) July\n  31th - August 3rd, 2018, New York, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of Bluetooth mobile device communications into all aspects\nof modern society raises security questions by both academicians and\npractitioners. This environment prompted an investigation into the real-world\nuse of Bluetooth protocols along with an analysis of documented security\nattacks. The experiment discussed in this paper collected data for one week in\na local coffee shop. The data collection took about an hour each day and\nidentified 478 distinct devices. The contribution of this research is two-fold.\nFirst, it provides insight into real-world Bluetooth protocols that are being\nutilized by the general public. Second, it provides foundational research that\nis necessary for future Bluetooth penetration testing research.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 23:28:20 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Ledbetter", "William", ""], ["Glisson", "William Bradley", ""], ["McDonald", "Todd", ""], ["Andel", "Todd", ""], ["Grispos", "George", ""], ["Choo", "Kim-Kwang Raymond", ""]]}, {"id": "1808.02426", "submitter": "Jesse Eickholt", "authors": "Jesse Eickholt", "title": "Barriers to Active Learning for Computer Science Faculty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning is a proven pedagogical style that has demonstrated value by\nimproving students' performance and classroom experience. In spite of the\nevidence, adoption of active learning in computer science remains relatively\nlow. To identify what barriers to adoption exist, an electronic survey was sent\nto 369 computer science faculty in a state in the Upper Midwest and to 78\nadministrators and support staff. Analysis of the responses revealed that time\nremained the most commonly reported barrier for faculty that desire to change\ntheir teaching style, with 42.8% of faculty respondents disagreeing with the\nstatement that they have the time they need to change their teaching style.\nAdministrators and support staff also indicated that time was a concern but\nthat otherwise faculty were aware of active learning and had the resources they\nneed. Reported use of active learning pedagogy was much higher among faculty\nthat received pedagogical training during their undergraduate or graduate\nstudies. Given the time constraints of faculty, it is recommended that new\navenues be explored to provide future faculty with exposure to active learning\npedagogy in their undergraduate and graduate training.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2018 15:40:59 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Eickholt", "Jesse", ""]]}, {"id": "1808.02547", "submitter": "Marco De Nadai", "authors": "Marco De Nadai and Bruno Lepri", "title": "The economic value of neighborhoods: Predicting real estate prices from\n  the urban environment", "comments": "To appear in the Proceedings of IEEE DSAA, 2018. October 1 - 4, 2018,\n  Turin, Italy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Housing costs have a significant impact on individuals, families, businesses,\nand governments. Recently, online companies such as Zillow have developed\nproprietary systems that provide automated estimates of housing prices without\nthe immediate need of professional appraisers. Yet, our understanding of what\ndrives the value of houses is very limited. In this paper, we use multiple\nsources of data to entangle the economic contribution of the neighborhood's\ncharacteristics such as walkability and security perception. We also develop\nand release a framework able to now-cast housing prices from Open data, without\nthe need for historical transactions. Experiments involving 70,000 houses in 8\nItalian cities highlight that the neighborhood's vitality and walkability seem\nto drive more than 20% of the housing value. Moreover, the use of this\ninformation improves the nowcast by 60%. Hence, the use of property's\nsurroundings' characteristics can be an invaluable resource to appraise the\neconomic and social value of houses after neighborhood changes and,\npotentially, anticipate gentrification.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2018 20:42:39 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["De Nadai", "Marco", ""], ["Lepri", "Bruno", ""]]}, {"id": "1808.02778", "submitter": "Antonio Ugando", "authors": "Antonio Ugando", "title": "Using Applied Behavior Analysis in Software to help Tutor Individuals\n  with Autism Spectrum Disorder", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  There are currently many tutoring software systems which have been designed\nfor neurotypical children. These systems cover academic topics such as reading\nand math, and are made available through various technological mediums. The\nmajority of these systems were not designed for use by children with special\nneeds, in particular those who are diagnosed with Autism Spectrum Disorder.\nSince the 1970's, studies have been conducted on the use of Applied Behavior\nAnalysis to help autistic children learn [1]. This teaching methodology is\nproven to be very effective, with many patients having their diagnosis of\nautism dropped after a few years of treatment. With the advent of ubiquitous\ntechnologies such as mobile devices, it has become apparent that these devices\ncould also be used to help tutor autistic children on academic subjects such as\nreading and math. Though the delivery of tutoring material must be made using\nApplied Behavior Analysis techniques, given that ABA therapy is currently the\nonly form of treatment for Autism Spectrum Disorder endorsed by the US Surgeon\nGeneral [2], which further makes the case for incorporating it into an\nacademics tutoring system tailored for autistic children. In this paper, we\npresent a mobile software system which can be utilized to tutor children who\nare diagnosed with Autism Spectrum Disorder in the subjects of reading and\nmath. The software makes use of Applied Behavior Analysis techniques such as a\nToken Economy system, visual and audible reinforcers, and generalization.\nFurthermore, we explore how combining Applied Behavior Analysis and technology,\ncould help extend the reach of tutoring systems to these children.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 13:39:27 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["Ugando", "Antonio", ""]]}, {"id": "1808.02826", "submitter": "James Unwin", "authors": "Kyle Gatesman and James Unwin", "title": "Lattice Studies of Gerrymandering Strategies", "comments": "32 Pages, 15 Figures", "journal-ref": "Polit. Anal. 29 (2021) 167-192", "doi": "10.1017/pan.2020.22", "report-no": null, "categories": "physics.soc-ph cs.CY econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose three novel gerrymandering algorithms which incorporate the\nspatial distribution of voters with the aim of constructing gerrymandered,\nequal-population, connected districts. Moreover, we develop lattice models of\nvoter distributions, based on analogies to electrostatic potentials, in order\nto compare different gerrymandering strategies. Due to the probabilistic\npopulation fluctuations inherent to our voter models, Monte Carlo methods can\nbe applied to the districts constructed via our gerrymandering algorithms.\nThrough Monte Carlo studies we quantify the effectiveness of each of our\ngerrymandering algorithms and we also argue that gerrymandering strategies\nwhich do not include spatial data lead to (legally prohibited) highly\ndisconnected districts. Of the three algorithms we propose, two are based on\ndifferent strategies for packing opposition voters, and the third is a new\napproach to algorithmic gerrymandering based on genetic algorithms, which\nautomatically guarantees that all districts are connected. Furthermore, we use\nour lattice voter model to examine the effectiveness of isoperimetric quotient\ntests and our results provide further quantitative support for implementing\ncompactness tests in real-world political redistricting.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 15:33:07 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Gatesman", "Kyle", ""], ["Unwin", "James", ""]]}, {"id": "1808.03274", "submitter": "Yuanlin Zhang", "authors": "Timothy T. Yuen, Maritza Reyes, Yuanlin Zhang", "title": "Introducing Computer Science to High School Students through Logic\n  Programming", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP). arXiv admin note: text overlap with arXiv:1706.09248", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates how high school students in an introductory computer\nscience course approach computing in the Logic Programming (LP) paradigm. This\nqualitative study shows how novice students operate within the LP paradigm\nwhile engaging in foundational computing concepts and skills: students are\nengaged in a cyclical process of abstraction, reasoning, and creating\nrepresentations of their ideas in code while also being informed by the\n(procedural) requirements and the revision/debugging process. As these\ncomputing concepts and skills are also expected in traditional approaches to\nintroductory K-12 CS courses, this paper asserts that LP is a viable paradigm\nchoice for high school novices. This paper is under consideration in Theory and\nPractice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2018 15:11:50 GMT"}], "update_date": "2018-08-13", "authors_parsed": [["Yuen", "Timothy T.", ""], ["Reyes", "Maritza", ""], ["Zhang", "Yuanlin", ""]]}, {"id": "1808.03350", "submitter": "Carlos Sarraute", "authors": "Juan de Monasterio, Alejo Salles, Carolina Lang, Diego Weinberg,\n  Martin Minnoni, Matias Travizano, Carlos Sarraute", "title": "Uncovering the Spread of Chagas Disease in Argentina and Mexico", "comments": "Published in NetMob 2017 (Fifth Conference on the Scientific Analysis\n  of Mobile Phone Datasets), Milan, Italy. April 5, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY physics.soc-ph stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Chagas disease is a neglected disease, and information about its geographical\nspread is very scarse. We analyze here mobility and calling patterns in order\nto identify potential risk zones for the disease, by using public health\ninformation and mobile phone records. Geolocalized call records are rich in\nsocial and mobility information, which can be used to infer whether an\nindividual has lived in an endemic area. We present two case studies in Latin\nAmerican countries. Our objective is to generate risk maps which can be used by\npublic health campaign managers to prioritize detection campaigns and target\nspecific areas. Finally, we analyze the value of mobile phone data to infer\nlong-term migrations, which play a crucial role in the geographical spread of\nChagas disease.\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2018 21:34:12 GMT"}], "update_date": "2018-08-13", "authors_parsed": [["de Monasterio", "Juan", ""], ["Salles", "Alejo", ""], ["Lang", "Carolina", ""], ["Weinberg", "Diego", ""], ["Minnoni", "Martin", ""], ["Travizano", "Matias", ""], ["Sarraute", "Carlos", ""]]}, {"id": "1808.03507", "submitter": "Steffen Pauws", "authors": "Steffen Pauws, Albert Gatt, Emiel Krahmer, Ehud Reiter", "title": "Making effective use of healthcare data using data-to-text technology", "comments": "27 pages, 2 figures, book chapter", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Healthcare organizations are in a continuous effort to improve health\noutcomes, reduce costs and enhance patient experience of care. Data is\nessential to measure and help achieving these improvements in healthcare\ndelivery. Consequently, a data influx from various clinical, financial and\noperational sources is now overtaking healthcare organizations and their\npatients. The effective use of this data, however, is a major challenge.\nClearly, text is an important medium to make data accessible. Financial reports\nare produced to assess healthcare organizations on some key performance\nindicators to steer their healthcare delivery. Similarly, at a clinical level,\ndata on patient status is conveyed by means of textual descriptions to\nfacilitate patient review, shift handover and care transitions. Likewise,\npatients are informed about data on their health status and treatments via\ntext, in the form of reports or via ehealth platforms by their doctors.\nUnfortunately, such text is the outcome of a highly labour-intensive process if\nit is done by healthcare professionals. It is also prone to incompleteness,\nsubjectivity and hard to scale up to different domains, wider audiences and\nvarying communication purposes. Data-to-text is a recent breakthrough\ntechnology in artificial intelligence which automatically generates natural\nlanguage in the form of text or speech from data. This chapter provides a\nsurvey of data-to-text technology, with a focus on how it can be deployed in a\nhealthcare setting. It will (1) give an up-to-date synthesis of data-to-text\napproaches, (2) give a categorized overview of use cases in healthcare, (3)\nseek to make a strong case for evaluating and implementing data-to-text in a\nhealthcare setting, and (4) highlight recent research challenges.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2018 12:33:45 GMT"}], "update_date": "2018-08-13", "authors_parsed": [["Pauws", "Steffen", ""], ["Gatt", "Albert", ""], ["Krahmer", "Emiel", ""], ["Reiter", "Ehud", ""]]}, {"id": "1808.03780", "submitter": "Saumik Bhattacharya", "authors": "Sayantari Ghosh, Saumik Bhattacharya, Kumar Gaurav and Yatindra Nath\n  Singh", "title": "Going Viral: The Epidemiological Strategy of Referral Marketing", "comments": "25 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By now, Internet word-of-mouth marketing has established its importance for\nalmost every kind of products. When word-of-mouth spread of a marketing\ncampaign goes viral, the success of its strategy has been proved to be\npath-breaking for the firms. The current study is designed to extend knowledge\nabout customer response to these campaigns, and is focused on the motivations\nthat lead them to different responses. Primary goal of this study is to\ninvestigate the reasons that drive this dynamics and to generate a justified\ntheoretical framework of diffusion dynamics of viral marketing campaigns. A\nrigorous analysis of data obtained through a questionnaire-based survey helped\nus to understand how people, who are from different age group, sex and\nlocations, define and evaluate the encounter with a referral campaign online,\nin similar and unique logical ways. The key finding was a conceptual framework\nof customer motivation which in turn dictates the dynamics of the campaign. We\nhave identified important themes related to customer motives, like significance\nof: incentives and ease, inherent forgetting, reminders from peers compared to\ncompany's remarketing mails, trust and brand value etc. Drawing an analogy with\ndifferential equation-based models of infectious disease spread, this paper\nfurther provides some initial evidence that participation in viral marketing\ncampaigns has several consumer related dynamical factors which can be\nincorporated in an epidemiological model for mathematical treatment, to\nindicate key operational factors in ensuring an effective spread of the\nmarketing campaign.\n", "versions": [{"version": "v1", "created": "Sat, 11 Aug 2018 09:27:53 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Ghosh", "Sayantari", ""], ["Bhattacharya", "Saumik", ""], ["Gaurav", "Kumar", ""], ["Singh", "Yatindra Nath", ""]]}, {"id": "1808.03845", "submitter": "Nicholas Charles Landolfi", "authors": "Nicholas C. Landolfi and Anca D. Dragan", "title": "Social Cohesion in Autonomous Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous cars can perform poorly for many reasons. They may have perception\nissues, incorrect dynamics models, be unaware of obscure rules of human traffic\nsystems, or follow certain rules too conservatively. Regardless of the exact\nfailure mode of the car, often human drivers around the car are behaving\ncorrectly. For example, even if the car does not know that it should pull over\nwhen an ambulance races by, other humans on the road will know and will pull\nover. We propose to make socially cohesive cars that leverage the behavior of\nnearby human drivers to act in ways that are safer and more socially\nacceptable. The simple intuition behind our algorithm is that if all the humans\nare consistently behaving in a particular way, then the autonomous car probably\nshould too. We analyze the performance of our algorithm in a variety of\nscenarios and conduct a user study to assess people's attitudes towards\nsocially cohesive cars. We find that people are surprisingly tolerant of\nmistakes that cohesive cars might make in order to get the benefits of driving\nin a car with a safer, or even just more socially acceptable behavior.\n", "versions": [{"version": "v1", "created": "Sat, 11 Aug 2018 18:12:56 GMT"}, {"version": "v2", "created": "Mon, 27 Aug 2018 15:36:41 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Landolfi", "Nicholas C.", ""], ["Dragan", "Anca D.", ""]]}, {"id": "1808.03956", "submitter": "Chaitanya Dhareshwar", "authors": "Chaitanya Dhareshwar", "title": "Technology utilization patterns and business growth in Small/Medium\n  Enterprises", "comments": "8 pages plus collated data and graphs in addendum", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technology was created to support and grow Business. Modern business that\nuses technology efficiently, grows at a phenomenal rate (Statista.com, 2018).\nThe assumption therefore is that businesses that utilize insufficient\ntechnology, or use technology inefficiently, experience reduced growth and\npossibly, business decline.\n  Technological development holds great significance in most industries\nparticularly in wastage reduction, process optimization and consequently\nbottom-line revenue enhancement and price-leadership. We've seen revolutionary\ntechnological development during the 20th century / 21st century thus far,\n(Ivanovic et al, 2015) and it's led to drastic growth in fields like\ncommunication, computer science, monitoring of operations, remote working, high\nperformance analytics and many more. Some fields have even come into existence\npurely due to technology.\n  Technological equipment cannot compensate for the skills, knowledge or\ncreativity of human employees. However, expertise of the average employee can\nbe greatly enhanced using intelligent software. Use of such equipment decreases\nthe need for unskilled and semi-skilled workers - but can exponentially\nincrease speed of performance for skilled workers. Innovations are key defining\ncriteria for competitive differentiation - but some of these can be easily\ncopied, which basically means that innovation and improvement are continuous\nprocesses. Process standardization comes through in a big way when\ntechnological solutions are applied in the work. It regulates/optimizes the\nnumber of employees needed, power consumption, potentially reduces wastage,\ndrastically improves hygiene process (where relevant). The natural outcome is\ngreater process efficiency and cost efficiency.\n  Keywords: technology, innovation, process efficiency, standardization of\nprocess, waste reduction, continued improvement, business ROI.\n", "versions": [{"version": "v1", "created": "Sun, 12 Aug 2018 15:21:40 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Dhareshwar", "Chaitanya", ""]]}, {"id": "1808.03977", "submitter": "Megan Strait", "authors": "Megan Strait", "title": "Conceptualization and Validation of a Novel Protocol for Investigating\n  the Uncanny Valley", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Loosely based on principles of similarity-attraction, robots intended for\nsocial contexts are being designed with increasing human similarity to\nfacilitate their reception by and communication with human interactants.\nHowever, the observation of an uncanny valley - the phenomenon in which certain\nhumanlike entities provoke dislike instead of liking - has lead some to caution\nagainst this practice. Substantial evidence supports both of these contrasting\nperspectives on the design of social technologies. Yet, owing to both empirical\nand theoretical inconsistencies, the relationship between anthropomorphic\ndesign and people's liking of the technology remains poorly understood.\n  Here we present three studies which investigate people's explicit ratings of\nand behavior towards a large sample of real-world robots. The results show a\nprofound \"valley effect\" on people's \\emph{willingness} to interact with\nhumanlike robots, thus highlighting the formidable design challenge the uncanny\nvalley poses for social robotics. In addition to advancing uncanny valley\ntheory, Studies 2 and 3 contribute and validate a novel laboratory task for\nobjectively measuring people's perceptions of humanlike robots.\n", "versions": [{"version": "v1", "created": "Sun, 12 Aug 2018 18:14:13 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Strait", "Megan", ""]]}, {"id": "1808.03998", "submitter": "Haroon Idrees", "authors": "Haroon Idrees, Mubarak Shah, Ray Surette", "title": "Enhancing camera surveillance using computer vision: a research note", "comments": null, "journal-ref": "Policing: An International Journal of Police Strategies &\n  Management Vol. 41 No. 2, 2018 pp. 292-307", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $\\mathbf{Purpose}$ - The growth of police operated surveillance cameras has\nout-paced the ability of humans to monitor them effectively. Computer vision is\na possible solution. An ongoing research project on the application of computer\nvision within a municipal police department is described. The paper aims to\ndiscuss these issues.\n  $\\mathbf{Design/methodology/approach}$ - Following the demystification of\ncomputer vision technology, its potential for police agencies is developed\nwithin a focus on computer vision as a solution for two common surveillance\ncamera tasks (live monitoring of multiple surveillance cameras and summarizing\narchived video files). Three unaddressed research questions (can specialized\ncomputer vision applications for law enforcement be developed at this time, how\nwill computer vision be utilized within existing public safety camera\nmonitoring rooms, and what are the system-wide impacts of a computer vision\ncapability on local criminal justice systems) are considered.\n  $\\mathbf{Findings}$ - Despite computer vision becoming accessible to law\nenforcement agencies the impact of computer vision has not been discussed or\nadequately researched. There is little knowledge of computer vision or its\npotential in the field.\n  $\\mathbf{Originality/value}$ - This paper introduces and discusses computer\nvision from a law enforcement perspective and will be valuable to police\npersonnel tasked with monitoring large camera networks and considering computer\nvision as a system upgrade.\n", "versions": [{"version": "v1", "created": "Sun, 12 Aug 2018 20:01:37 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Idrees", "Haroon", ""], ["Shah", "Mubarak", ""], ["Surette", "Ray", ""]]}, {"id": "1808.04203", "submitter": "Yevhenii Modlo", "authors": "Yevhenii O. Modlo, Serhiy O. Semerikov", "title": "Xcos on Web as a promising learning tool for Bachelor's of\n  Electromechanics modeling of technical objects", "comments": "10 pages, 4 figures, 1 table, in Ukrainian, submitted to Workshop on\n  Cloud technologies in education (CTE'2017)", "journal-ref": "CEUR Workshop Proceedings 2168 (2018) 34-41", "doi": null, "report-no": null, "categories": "cs.CY physics.ed-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Research goals: to identify the perspective learning simulation tool for\nBachelors of Electromechanics. Research objectives: to prove the feasibility of\nusing the simulation system Xcos on Web as a tool of forming of future\nBachelors of Electromechanics competence in modeling of technical objects.\nResearch object: the use of imitative simulation systems to learning the\nBachelors of Electromechanics. Research subject: the use Xcos on Web in\nlearning modeling of technical objects the Bachelors of Electromechanics.\nResearch methods used: the analysis of existing software usage experience.\nResearch results. The imitative simulation system Xcos on Web is a promising\ncloud-based learning tool for Bachelor's of Electromechanics modeling of\ntechnical objects. The main conclusions and recommendations: 1. The use of\nsimulation systems, such as Scilab Xcos, is a necessary part of Bachelor of\nElectromechanics professional training. 2. Cloud-based learning environment\nbuilt on the integrative usage of mobile Internet devices promotes the forming\nof Bachelor's of Electromechanics professional competencies. 3. Implementation\nthe full Scilab Xcos functionality at Xcos on Web creates conditions for\ntransition in Bachelor's of Electromechanics learning the simulation of\ntechnical objects to the use of mobile Internet devices.\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2018 06:27:35 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Modlo", "Yevhenii O.", ""], ["Semerikov", "Serhiy O.", ""]]}, {"id": "1808.04211", "submitter": "Yuliia Yechkalo", "authors": "V. L. Buzko, Yu. V. Yechkalo", "title": "The possibility of use of QR-codes in teaching physics", "comments": "11 pages, 2 tables, 4 figures, in Ukrainian", "journal-ref": "Naukovi zapysky. Seriya: Problemy metodyky fizyko-matematychnoyi i\n  tekhnolohichnoyi osvity (Kirovohrads'kyy derzhavnyy pedahohichnyy universytet\n  imeni Volodymyra Vynnychenka) 10 (2016) 112-118", "doi": null, "report-no": null, "categories": "physics.ed-ph cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the article discusses the possibility of using of QR-codes in teaching\nphysics. It is noted that the technology of recognition of QR-codes can be\nattributed to elements of mobile information and education environment. On the\nbasis of summarizing existing research discusses the advantages and\ndisadvantages of using QR-codes, and the application of codes in the learning\nprocess. Examples of the use of QR-codes in teaching physics (of physical\nquests and web quests, of games, quizzes, polls, creating a virtual exhibition,\ncreating applications to educational facilities, the creation and study of\ncomputer models of physical phenomena and processes, organization Self-Test)\nare described. Found that the mobile learning available to pupils (students),\nand elements of the mobile information-educational environment (including\ntechnology development and recognition of QR-codes) have sufficient capacity in\nteaching physics.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 07:16:24 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Buzko", "V. L.", ""], ["Yechkalo", "Yu. V.", ""]]}, {"id": "1808.04212", "submitter": "Yuliia Yechkalo", "authors": "Yu. Yechkalo", "title": "Methods of learning of computer simulation of physical processes and\n  phenomena in university", "comments": "8 pages, 1 figure, 1 table, in Ukrainian", "journal-ref": "Visnyk Cherkas'koho universytetu. Seriya Pedahohichni nauky 7\n  (2016) 127-134", "doi": null, "report-no": null, "categories": "physics.ed-ph cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To effectively prepare engineering students requires of formation of a system\nof fundamental physical knowledge together with the ability to apply them in\nspecific productive activities, both on fundamental and on the\nprofiled-oriented level. Accordingly the tasks of physics of high school is\nmastering the methodology of science knowledge and scientific way of thinking\nand generalize of experimental natural ability to conduct scientific research\nby methods of physical knowledge. In the process of teaching physics\nsimulations simultaneously acts by scientific knowledge, is part of the content\nof educational material and effective means of experiment. It is possible to\nobtain special teaching methods of computer simulation, which include primarily\ncomputer experiment. The main methods of computer modeling learning in\nuniversity are a multimedia lecture, telecommunications project and\ncomputer-oriented laboratory practice. The main tasks of teaching computer\nmodeling in physics course are the overall development and formation of outlook\nof future engineers and development practical skills in computer simulation.\nThe leading method of learning computer simulation in physics course is a\nproject method. Those methods of learning are optimal in the context of\ndevelopmental education. Computational experiment is a modeling methodology as\na science, so it can be attributed to the principles of scientific methods of\nlearning. Purposes of learning physics in university include the necessity of\nmastering a given set of scientific facts and methods of getting these facts.\nComputational experiment reflects the method of knowledge which applied in\nphysics.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 07:39:10 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Yechkalo", "Yu.", ""]]}, {"id": "1808.04840", "submitter": "Mark Newman", "authors": "Elizabeth E. Bruch and M. E. J. Newman", "title": "Aspirational pursuit of mates in online dating markets", "comments": "15 pages, 5 figures, 6 tables", "journal-ref": "Science Advances 4, eaap9815 (2018)", "doi": "10.1126/sciadv.aap9815", "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Romantic courtship is often described as taking place in a dating market\nwhere men and women compete for mates, but the detailed structure and dynamics\nof dating markets have historically been difficult to quantify for lack of\nsuitable data. In recent years, however, the advent and vigorous growth of the\nonline dating industry has provided a rich new source of information on mate\npursuit. Here we present an empirical analysis of heterosexual dating markets\nin four large US cities using data from a popular, free online dating service.\nWe show that competition for mates creates a pronounced hierarchy of\ndesirability that correlates strongly with user demographics and is remarkably\nconsistent across cities. We find that both men and women pursue partners who\nare on average about 25% more desirable than themselves by our measures and\nthat they use different messaging strategies with partners of different\ndesirability. We also find that the probability of receiving a response to an\nadvance drops markedly with increasing difference in desirability between the\npursuer and the pursued. Strategic behaviors can improve one's chances of\nattracting a more desirable mate, though the effects are modest.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 18:13:39 GMT"}], "update_date": "2018-08-20", "authors_parsed": [["Bruch", "Elizabeth E.", ""], ["Newman", "M. E. J.", ""]]}, {"id": "1808.04893", "submitter": "Serhiy Semerikov", "authors": "Andrii M. Striuk, Serhiy O. Semerikov", "title": "Blended learning models", "comments": "13 pages, 11 figures, in Ukrainian", "journal-ref": "Bulletin of Alfred Nobel University. Series \"Pedagogy and\n  Psychology\" 2 (2012) 47-59", "doi": null, "report-no": null, "categories": "cs.CY physics.ed-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The article presents the authors' organizational model of blended learning on\nthe basis of existing models of learning at higher educational establishments.\nThe model provides for using the learning management system and reflects\ncurrent developments of ICT use theory and methodology.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2018 15:40:12 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Striuk", "Andrii M.", ""], ["Semerikov", "Serhiy O.", ""]]}, {"id": "1808.04980", "submitter": "Ahmed D. Alharthi", "authors": "Ahmed D. Alharthi, Peter Busch, Stephen Smith", "title": "A prototypical Skin Cancer Information System", "comments": "10 pages,", "journal-ref": "24th Australasian Conference on Information Systems, 2013", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Skin cancer is a common problem in Australia and indeed around the world.\nWithin the domain of e-Health, there appears to be no satisfactory clinical\nsoftware that follows the flow of a normal skin cancer examination. This paper\nintroduces a system that was specifically designed, coded and implemented to\nstore patient health records as a means of registering the diagnoses of skin\ncancer along with the treatment. The information system was intended to be\nweb-based, and connect to remote database servers. The implemented system was\ndesigned to incorporate features such as inserting procedural details,\ngenerating forms and reports with interactive interfaces, yet be relatively\nunsophisticated to use. We expect the system once fully implemented and on\nline, will aid in Australia's e-Health industry, delivering more accurate\ninformation to doctors and patients in an effort to combat issues involving\nskin cancer. Other parameters discussed are the need for data encryption of\nmedical records and the role such a system can play in medical information.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 06:32:03 GMT"}], "update_date": "2018-08-20", "authors_parsed": [["Alharthi", "Ahmed D.", ""], ["Busch", "Peter", ""], ["Smith", "Stephen", ""]]}, {"id": "1808.05096", "submitter": "Martin Degeling", "authors": "Martin Degeling, Christine Utz, Christopher Lentzsch, Henry Hosseini,\n  Florian Schaub and Thorsten Holz", "title": "We Value Your Privacy ... Now Take Some Cookies: Measuring the GDPR's\n  Impact on Web Privacy", "comments": "Published at NDSS 2019", "journal-ref": null, "doi": "10.14722/ndss.2019.23378", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The European Union's General Data Protection Regulation (GDPR) went into\neffect on May 25, 2018. Its privacy regulations apply to any service and\ncompany collecting or processing personal data in Europe. Many companies had to\nadjust their data handling processes, consent forms, and privacy policies to\ncomply with the GDPR's transparency requirements. We monitored this rare event\nby analyzing the GDPR's impact on popular websites in all 28 member states of\nthe European Union. For each country, we periodically examined its 500 most\npopular websites - 6,579 in total - for the presence of and updates to their\nprivacy policy. While many websites already had privacy policies, we find that\nin some countries up to 15.7 % of websites added new privacy policies by May\n25, 2018, resulting in 84.5 % of websites having privacy policies. 72.6 % of\nwebsites with existing privacy policies updated them close to the date. Most\nvisibly, 62.1 % of websites in Europe now display cookie consent notices, 16 %\nmore than in January 2018. These notices inform users about a site's cookie use\nand user tracking practices. We categorized all observed cookie consent notices\nand evaluated 16 common implementations with respect to their technical\nrealization of cookie consent. Our analysis shows that core web security\nmechanisms such as the same-origin policy pose problems for the implementation\nof consent according to GDPR rules, and opting out of third-party cookies\nrequires the third party to cooperate. Overall, we conclude that the GDPR is\nmaking the web more transparent, but there is still a lack of both functional\nand usable mechanisms for users to consent to or deny processing of their\npersonal data on the Internet.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 14:24:19 GMT"}, {"version": "v2", "created": "Thu, 16 Aug 2018 07:43:49 GMT"}, {"version": "v3", "created": "Mon, 25 Feb 2019 19:38:44 GMT"}, {"version": "v4", "created": "Tue, 25 Jun 2019 11:11:18 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Degeling", "Martin", ""], ["Utz", "Christine", ""], ["Lentzsch", "Christopher", ""], ["Hosseini", "Henry", ""], ["Schaub", "Florian", ""], ["Holz", "Thorsten", ""]]}, {"id": "1808.05125", "submitter": "Serhiy Semerikov", "authors": "Nataliia M. Kiianovska, N. V. Rashevska, Serhiy O. Semerikov", "title": "Development of theory and methods of use of information and\n  communication technologies in teaching mathematics of engineering\n  specialities students in the United States", "comments": "16 pages, in Ukrainian", "journal-ref": "Information Technologies and Learning Tools 42 (2014) 68-83", "doi": null, "report-no": null, "categories": "math.HO cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The article deals with the problems of information and communication\ntechnologies (ICT) development in teaching mathematics of engineering\nspecialities students in the United States. In the article the nature of trends\nof convergence of information system in higher technical education and other\ntendencies in the USA are characterized. The main historical stages of\ndevelopment of the theory and methods of ICT use in teaching mathematics of\nengineering specialities students in the United States are defined. The study\nof historical sources has been allowed to emphasize six stages, at each stage\nit is analyzed the use of ICT for teaching mathematics, it is shown the\ncontradictions and the main features of the use of ICT in teaching mathematics\nof engineering specialities students.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2018 15:47:27 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Kiianovska", "Nataliia M.", ""], ["Rashevska", "N. V.", ""], ["Semerikov", "Serhiy O.", ""]]}, {"id": "1808.05346", "submitter": "Hiroaki Togashi Dr.", "authors": "Hiroaki Togashi, Yasuaki Koga, and Hiroshi Furukawa", "title": "Criminal Fishing System Based on Wireless Local Area Network Access\n  Points - Can Media Access Control address assist criminal investigation?", "comments": "8 pages, 6 figures, 2 tables. Extended version of \"Criminal Fishing\n  System Based on Wireless Local Area Network Access Points,\" published in 2016\n  IEEE International Conference on Multisensor Fusion and Integration for\n  Intelligent Systems (MFI 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, many Wi-Fi access points are being installed in urban areas. This\npaper considers how this infrastructure can be used to assist criminal\ninvestigations and improve public safety. We propose a criminal investigation\nassistance system that uses multiple wireless local area network (LAN) access\npoints and cameras. The proposed \"Criminal Fishing System\" enumerates candidate\nmedia access control (MAC) addresses of culprits' mobile devices from probe\nrequest signals gathered by access points during the period in which a culprit\nis near the scene of an incident. Preliminary experiments demonstrated that the\nproposed system could identify the MAC address of the culprit's device, which\nwould allow authorities to capture the culprit's radiowave fingerprint. After\nenumerating the candidate MAC addresses, the culprit's usual appearance can be\nobtained by surveilling these MAC addresses, especially when it changes less\nfrequently. Moreover, the MAC address itself can be admissible as evidence that\nthe culprit was near the scene of an incident, given that the MAC address is\nstatic, that is, it has not changed after the incident, or the original MAC\naddress can be retrieved from the randomized MAC address.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 04:41:10 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Togashi", "Hiroaki", ""], ["Koga", "Yasuaki", ""], ["Furukawa", "Hiroshi", ""]]}, {"id": "1808.05379", "submitter": "Yurii Sheliazhenko", "authors": "Yurii Sheliazhenko", "title": "Computer Modeling of Personal Autonomy and Legal Equilibrium", "comments": "8 pages, 6 figures, presented at Computer Science On-line Conference\n  2018", "journal-ref": "CSOC2018. Advances in Intelligent Systems and Computing, vol 765,\n  pp 74-81. Springer, Cham", "doi": "10.1007/978-3-319-91192-2_8", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Empirical studies of personal autonomy as state and status of individual\nfreedom, security, and capacity to control own life, particularly by\nindependent legal reasoning, are need dependable models and methods of precise\ncomputation. Three simple models of personal autonomy are proposed. The linear\nmodel of personal autonomy displays a relation between freedom as an amount of\nagent's action and responsibility as an amount of legal reaction and shows\nlegal equilibrium, the balance of rights and duties needed for sustainable\ndevelopment of any community. The model algorithm of judge personal autonomy\nshows that judicial decision making can be partly automated, like other human\njobs. Model machine learning of autonomous lawyer robot under operating system\nconstitution illustrates the idea of robot rights. Robots, i.e. material and\nvirtual mechanisms serving the people, deserve some legal guarantees of their\nrights such as robot rights to exist, proper function and be protected by the\nlaw. Robots, actually, are protected as any human property by the wide scope of\nlaws, starting with Article 17 of Universal Declaration of Human Rights, but\nthe current level of human trust in autonomous devices and their role in\ncontemporary society needs stronger legislation to guarantee the robot rights.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 08:51:49 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Sheliazhenko", "Yurii", ""]]}, {"id": "1808.05473", "submitter": "Anh Nguyen Duc", "authors": "Salah Uddin Ahmed, Ingrid Sundb{\\o}, Jon Kvisli, Jon Atle Gulla,\n  Letizia Jaccheri, Anh Nguyen-Duc", "title": "Evaluation of team dynamic in Norwegian projects for IT students", "comments": null, "journal-ref": "Norsk konferanse for undervisning og didaktikk i IT-fagene 2018", "doi": null, "report-no": null, "categories": "cs.CY cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need for teaching realistic software development in project courses has\nincreased in a global scale. It has always been challenges in cooperating\nfast-changing software technologies, development methodologies and teamwork.\nMoreover, such project courses need to be designed in the connection to\nexisting theoretical courses. We performed a large-scale research on student\nperformance in Software Engineering projects in Norwegian universities. This\npaper investigates four aspects of team dynamics, which are team reflection,\nleadership, decision making and task assignment in order to improve student\nlearning. Data was collected from student projects in 4 years at two\nuniversities. We found that some leader's characteristics are perceived\ndifferently for female and male leaders, including the perception of leaders as\nskilful workers or visionaries. Leadership is still a challenging aspect to\nteach, and assigned leadership is probably not the best way to learn. Students\nis are performing well in task review, however, needs support while performing\ntask assignment. The result also suggests that task management to be done in\nmore fine-grained levels. It is also important to maintain an open and active\ndiscussion to facilitate effective group decision makings.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 21:34:05 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Ahmed", "Salah Uddin", ""], ["Sundb\u00f8", "Ingrid", ""], ["Kvisli", "Jon", ""], ["Gulla", "Jon Atle", ""], ["Jaccheri", "Letizia", ""], ["Nguyen-Duc", "Anh", ""]]}, {"id": "1808.05686", "submitter": "Barbara Grosz", "authors": "Barbara J. Grosz, David Gray Grant, Kate Vredenburgh, Jeff Behrends,\n  Lily Hu, Alison Simmons, and Jim Waldo", "title": "Embedded EthiCS: Integrating Ethics Broadly Across Computer Science\n  Education", "comments": "Manuscript in submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing technologies have become pervasive in daily life, sometimes\nbringing unintended but harmful consequences. For students to learn to think\nnot only about what technology they could create, but also about what\ntechnology they should create, computer science curricula must expand to\ninclude ethical reasoning about the societal value and impact of these\ntechnologies. This paper presents Embedded EthiCS, a novel approach to\nintegrating ethics into computer science education that incorporates ethical\nreasoning throughout courses in the standard computer science curriculum. It\nthus changes existing courses rather than requiring wholly new courses. The\npaper describes a pilot Embedded EthiCS program that embeds philosophers\nteaching ethical reasoning directly into computer science courses. It discusses\nlessons learned and challenges to implementing such a program across different\ntypes of academic institutions.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 21:45:54 GMT"}], "update_date": "2018-08-20", "authors_parsed": [["Grosz", "Barbara J.", ""], ["Grant", "David Gray", ""], ["Vredenburgh", "Kate", ""], ["Behrends", "Jeff", ""], ["Hu", "Lily", ""], ["Simmons", "Alison", ""], ["Waldo", "Jim", ""]]}, {"id": "1808.05927", "submitter": "Josemar Caetano", "authors": "Josemar Alves Caetano, Gabriel Magno, Evandro Cunha, Wagner Meira Jr.,\n  Humberto T. Marques-Neto, Virgilio Almeida", "title": "Characterizing the public perception of WhatsApp through the lens of\n  media", "comments": "Accepted as a full paper at the 2nd International Workshop on Rumours\n  and Deception in Social Media (RDSM 2018), co-located with CIKM 2018 in\n  Turin. Please cite the RDSM version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  WhatsApp is, as of 2018, a significant component of the global information\nand communication infrastructure, especially in developing countries. However,\nprobably due to its strong end-to-end encryption, WhatsApp became an attractive\nplace for the dissemination of misinformation, extremism and other forms of\nundesirable behavior. In this paper, we investigate the public perception of\nWhatsApp through the lens of media. We analyze two large datasets of news and\nshow the kind of content that is being associated with WhatsApp in different\nregions of the world and over time. Our analyses include the examination of\nnamed entities, general vocabulary, and topics addressed in news articles that\nmention WhatsApp, as well as the polarity of these texts. Among other results,\nwe demonstrate that the vocabulary and topics around the term \"whatsapp\" in the\nmedia have been changing over the years and in 2018 concentrate on matters\nrelated to misinformation, politics and criminal scams. More generally, our\nfindings are useful to understand the impact that tools like WhatsApp play in\nthe contemporary society and how they are seen by the communities themselves.\n", "versions": [{"version": "v1", "created": "Fri, 17 Aug 2018 16:47:52 GMT"}], "update_date": "2018-08-20", "authors_parsed": [["Caetano", "Josemar Alves", ""], ["Magno", "Gabriel", ""], ["Cunha", "Evandro", ""], ["Meira", "Wagner", "Jr."], ["Marques-Neto", "Humberto T.", ""], ["Almeida", "Virgilio", ""]]}, {"id": "1808.05935", "submitter": "D\\'aniel Kondor", "authors": "Daniel Kondor, Paolo Santi, Diem-Trinh Le, Xiaohu Zhang, Adam\n  Millard-Ball, Carlo Ratti", "title": "Addressing the \"minimum parking\" problem for on-demand mobility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parking infrastructure is pervasive and occupies large swaths of land in\ncities. However, on-demand (OD) mobility -- such as commercial services Uber,\nGrab or Didi -- has started reducing parking needs in urban areas around the\nworld. This trend is expected to grow significantly with the advent of\nautonomous driving, which might render on-demand mobility predominant. Recent\nstudies have started looking at expected parking reductions with on-demand\nmobility, but a systematic framework is still lacking. In this paper, we apply\na data-driven methodology based on shareability networks to address what we\ncall the \"minimum parking\" problem: what is the minimum parking infrastructure\nneeded in a city for given on-demand mobility needs? While solving the problem,\nwe also identify a critical tradeoff between two public policy goals: less\nparking means increased vehicle travel from deadheading between trips. By\napplying our methodology to the city of Singapore we discover that parking\ninfrastructure reduction of up to 86% is possible, but at the expense of a 24%\nincrease in traffic measured as vehicle kilometers travelled (VKT). However, a\nmore modest 57% reduction in parking is achievable with only a 1.3% increase in\nVKT. We find that the tradeoff between parking and traffic obeys an inverse\nexponential law which is invariant with the size of the vehicle fleet, leading\nto a simple methodology to estimate aggregate parking demand in a city.\nFinally, we analyze parking requirements due to passenger pick-ups and show\nthat increasing convenience produces a substantial increase in parking for\npassenger pickup/dropoff. The above mathematical findings can inform\npolicy-makers, mobility operators, and society at large on the tradeoffs\nrequired in the transition towards pervasive on-demand mobility.\n", "versions": [{"version": "v1", "created": "Fri, 17 Aug 2018 17:26:09 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 06:22:27 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Kondor", "Daniel", ""], ["Santi", "Paolo", ""], ["Le", "Diem-Trinh", ""], ["Zhang", "Xiaohu", ""], ["Millard-Ball", "Adam", ""], ["Ratti", "Carlo", ""]]}, {"id": "1808.06021", "submitter": "Amir Karami", "authors": "Amir Karami and Matthew Collins", "title": "What do the US West Coast Public Libraries Post on Twitter?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Twitter has provided a great opportunity for public libraries to disseminate\ninformation for a variety of purposes. Twitter data have been applied in\ndifferent domains such as health, politics, and history. There are thousands of\npublic libraries in the US, but no study has yet investigated the content of\ntheir social media posts like tweets to find their interests. Moreover,\ntraditional content analysis of Twitter content is not an efficient task for\nexploring thousands of tweets. Therefore, there is a need for automatic methods\nto overcome the limitations of manual methods. This paper proposes a\ncomputational approach to collecting and analyzing using Twitter Application\nProgramming Interfaces (API) and investigates more than 138,000 tweets from 48\nUS west coast libraries using topic modeling. We found 20 topics and assigned\nthem to five categories including public relations, book, event, training, and\nsocial good. Our results show that the US west coast libraries are more\ninterested in using Twitter for public relations and book-related events. This\nresearch has both practical and theoretical applications for libraries as well\nas other organizations to explore social media actives of their customer and\nthemselves.\n", "versions": [{"version": "v1", "created": "Fri, 17 Aug 2018 23:50:01 GMT"}, {"version": "v2", "created": "Fri, 28 Sep 2018 15:11:22 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Karami", "Amir", ""], ["Collins", "Matthew", ""]]}, {"id": "1808.06022", "submitter": "Amir Karami", "authors": "Amir Karami, Frank Webb, Vanessa L. Kitzie", "title": "Characterizing Transgender Health Issues in Twitter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although there are millions of transgender people in the world, a lack of\ninformation exists about their health issues. This issue has consequences for\nthe medical field, which only has a nascent understanding of how to identify\nand meet this population's health-related needs. Social media sites like\nTwitter provide new opportunities for transgender people to overcome these\nbarriers by sharing their personal health experiences. Our research employs a\ncomputational framework to collect tweets from self-identified transgender\nusers, detect those that are health-related, and identify their information\nneeds. This framework is significant because it provides a macro-scale\nperspective on an issue that lacks investigation at national or demographic\nlevels. Our findings identified 54 distinct health-related topics that we\ngrouped into 7 broader categories. Further, we found both linguistic and\ntopical differences in the health-related information shared by transgender men\n(TM) as com-pared to transgender women (TW). These findings can help inform\nmedical and policy-based strategies for health interventions within transgender\ncommunities. Also, our proposed approach can inform the development of\ncomputational strategies to identify the health-related information needs of\nother marginalized populations.\n", "versions": [{"version": "v1", "created": "Sat, 18 Aug 2018 00:00:19 GMT"}, {"version": "v2", "created": "Fri, 28 Sep 2018 15:08:24 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Karami", "Amir", ""], ["Webb", "Frank", ""], ["Kitzie", "Vanessa L.", ""]]}, {"id": "1808.06063", "submitter": "Rushan Ziatdinov", "authors": "Ismail Ipek, Rushan Ziatdinov", "title": "New Approaches and Trends in the Philosophy of Educational Technology\n  for Learning and Teaching Environments", "comments": null, "journal-ref": "European Journal of Contemporary Education, 6(3), 381-389, 2017", "doi": "10.13187/ejced.2017.3.381", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this study is to discuss instructional design and technology\n(IDT) model strategies for developing learning and teaching environments, based\non philosophical approaches to educational technology theory. The study begins\nwith a discussion of IDT models to define the history of educational technology\nor instructional technology theories, based on instructional strategies and\nimprovements. In the study, authors discuss the strategies and steps that a\ndesign team should follow when designing learning environments in industry,\nbusiness and military scenarios, based on the philosophy of educational\ntechnology and latest technologies, which should give way to effective learning\nenvironments. The steps include recognising terminology in educational\ntechnology concepts, psychological and instructional foundations in\ninstructional design (ID), as well as approaches to educational technology. To\nrecap, our purpose is to combine necessary IDT model strategies for the\npedagogical design of learning environments, with new technologies. We will\nalso discuss powerful IDT models that aim to meet the very high expectations of\ndigital and humanist education. To develop a high-quality learning environment,\nwe will explain technology design steps and practice in order to improve the\nlearning of tasks, complex cognitive skills, attitudes, motivations and\ncompetencies in the future trends of educational technology. At the end of the\nstudy, integrated technologies in e-learning were discussed and presented,\nbased on foundations of IDT and the philosophy of educational technology.\n", "versions": [{"version": "v1", "created": "Sat, 18 Aug 2018 09:12:58 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Ipek", "Ismail", ""], ["Ziatdinov", "Rushan", ""]]}, {"id": "1808.06355", "submitter": "Joel Klinger", "authors": "J. Klinger, J. Mateos-Garcia, K. Stathoulopoulos", "title": "Deep learning, deep change? Mapping the development of the Artificial\n  Intelligence General Purpose Technology", "comments": "26 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  General Purpose Technologies (GPTs) that can be applied in many industries\nare an important driver of economic growth and national and regional\ncompetitiveness. In spite of this, the geography of their development and\ndiffusion has not received significant attention in the literature. We address\nthis with an analysis of Deep Learning (DL), a core technique in Artificial\nIntelligence (AI) increasingly being recognized as the latest GPT. We identify\nDL papers in a novel dataset from ArXiv, a popular preprints website, and use\nCrunchBase, a technology business directory to measure industrial capabilities\nrelated to it. After showing that DL conforms with the definition of a GPT,\nhaving experienced rapid growth and diffusion into new fields where it has\ngenerated an impact, we describe changes in its geography. Our analysis shows\nChina's rise in AI rankings and relative decline in several European countries.\nWe also find that initial volatility in the geography of DL has been followed\nby consolidation, suggesting that the window of opportunity for new entrants\nmight be closing down as new DL research hubs become dominant. Finally, we\nstudy the regional drivers of DL clustering. We find that competitive DL\nclusters tend to be based in regions combining research and industrial\nactivities related to it. This could be because GPT developers and adopters\nlocated close to each other can collaborate and share knowledge more easily,\nthus overcoming coordination failures in GPT deployment. Our analysis also\nreveals a Chinese comparative advantage in DL after we control for other\nexplanatory factors, perhaps underscoring the importance of access to data and\nsupportive policies for the successful development of this complex, `omni-use'\ntechnology.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 09:14:54 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Klinger", "J.", ""], ["Mateos-Garcia", "J.", ""], ["Stathoulopoulos", "K.", ""]]}, {"id": "1808.06398", "submitter": "Maarten Vanhoof", "authors": "Maarten Vanhoof, Fernando Reis, Zbigniew Smoreda, Thomas Ploetz", "title": "Detecting home locations from CDR data: introducing spatial uncertainty\n  to the state-of-the-art", "comments": "13 pages, 7 figures, contributed to the Mobile Tartu 2016 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Non-continuous location traces inferred from Call Detail Records (CDR) at\npopulation scale are increasingly becoming available for research and show\ngreat potential for automated detection of meaningful places. Yet, a majority\nof Home Detection Algorithms (HDAs) suffer from \"blind\" deployment of criteria\nto define homes and from limited possibilities for validation. In this paper,\nwe investigate the performance and capabilities of five popular criteria for\nhome detection based on a very large mobile phone dataset from France (~18\nmillion users, 6 months). Furthermore, we construct a data-driven framework to\nassess the spatial uncertainty related to the application of HDAs. Our findings\nappropriate spatial uncertainty in HDA and, in extension, for detection of\nmeaningful places. We show how spatial uncertainties on the individuals' level\ncan be assessed in absence of ground truth annotation, how they relate to\ntraditional, high-level validation practices and how they can be used to\nimprove results for, e.g., nation-wide population estimation.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 11:41:51 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Vanhoof", "Maarten", ""], ["Reis", "Fernando", ""], ["Smoreda", "Zbigniew", ""], ["Ploetz", "Thomas", ""]]}, {"id": "1808.06462", "submitter": "Nitish Nag", "authors": "Nitish Nag, Vaibhav Pandey, Preston J. Putzel, Hari Bhimaraju,\n  Srikanth Krishnan, Ramesh C. Jain", "title": "Cross-Modal Health State Estimation", "comments": "Accepted to ACM Multimedia 2018 Conference - Brave New Ideas, Seoul,\n  Korea, ACM ISBN 978-1-4503-5665-7/18/10", "journal-ref": "Nitish Nag, Vaibhav Pandey, Preston J. Putzel, Hari Bhimaraju,\n  Srikanth Krishnan, Ramesh C. Jain, 2018 ACM Multimedia Conference (MM '18),\n  October 22--26, 2018, Seoul, Republic of Korea", "doi": "10.1145/3240508.3241913", "report-no": null, "categories": "cs.CY cs.AI cs.MM q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Individuals create and consume more diverse data about themselves today than\nany time in history. Sources of this data include wearable devices, images,\nsocial media, geospatial information and more. A tremendous opportunity rests\nwithin cross-modal data analysis that leverages existing domain knowledge\nmethods to understand and guide human health. Especially in chronic diseases,\ncurrent medical practice uses a combination of sparse hospital based biological\nmetrics (blood tests, expensive imaging, etc.) to understand the evolving\nhealth status of an individual. Future health systems must integrate data\ncreated at the individual level to better understand health status perpetually,\nespecially in a cybernetic framework. In this work we fuse multiple user\ncreated and open source data streams along with established biomedical domain\nknowledge to give two types of quantitative state estimates of cardiovascular\nhealth. First, we use wearable devices to calculate cardiorespiratory fitness\n(CRF), a known quantitative leading predictor of heart disease which is not\nroutinely collected in clinical settings. Second, we estimate inherent genetic\ntraits, living environmental risks, circadian rhythm, and biological metrics\nfrom a diverse dataset. Our experimental results on 24 subjects demonstrate how\nmulti-modal data can provide personalized health insight. Understanding the\ndynamic nature of health status will pave the way for better health based\nrecommendation engines, better clinical decision making and positive lifestyle\nchanges.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2018 00:38:38 GMT"}, {"version": "v2", "created": "Thu, 23 Aug 2018 21:19:53 GMT"}], "update_date": "2018-08-27", "authors_parsed": [["Nag", "Nitish", ""], ["Pandey", "Vaibhav", ""], ["Putzel", "Preston J.", ""], ["Bhimaraju", "Hari", ""], ["Krishnan", "Srikanth", ""], ["Jain", "Ramesh C.", ""]]}, {"id": "1808.06463", "submitter": "Hossein Nourkhiz Mahjoub", "authors": "Amin Tahmasbi-Sarvestani, Hossein Nourkhiz Mahjoub, Yaser P. Fallah,\n  Ehsan Moradi-Pari, Oubada Abuchaar", "title": "Implementation and Evaluation of a Cooperative Vehicle-to-Pedestrian\n  Safety Application", "comments": null, "journal-ref": "IEEE Intelligent Transportation Systems Magazine, vol. 9, no. 4,\n  pp. 62-75, winter 2017", "doi": "10.1109/MITS.2017.2743201", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the development of Vehicle-to-Vehicle (V2V) safety applications based\non Dedicated Short-Range Communications (DSRC) has been extensively undergoing\nstandardization for more than a decade, such applications are extremely missing\nfor Vulnerable Road Users (VRUs). Nonexistence of collaborative systems between\nVRUs and vehicles was the main reason for this lack of attention. Recent\ndevelopments in Wi-Fi Direct and DSRC-enabled smartphones are changing this\nperspective. Leveraging the existing V2V platforms, we propose a new framework\nusing a DSRC-enabled smartphone to extend safety benefits to VRUs. The\ninteroperability of applications between vehicles and portable DSRC enabled\ndevices is achieved through the SAE J2735 Personal Safety Message (PSM).\nHowever, considering the fact that VRU movement dynamics, response times, and\ncrash scenarios are fundamentally different from vehicles, a specific framework\nshould be designed for VRU safety applications to study their performance. In\nthis article, we first propose an end-to-end Vehicle-to-Pedestrian (V2P)\nframework to provide situational awareness and hazard detection based on the\nmost common and injury-prone crash scenarios. The details of our VRU safety\nmodule, including target classification and collision detection algorithms, are\nexplained next. Furthermore, we propose and evaluate a mitigating solution for\ncongestion and power consumption issues in such systems. Finally, the whole\nsystem is implemented and analyzed for realistic crash scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 19:08:54 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Tahmasbi-Sarvestani", "Amin", ""], ["Mahjoub", "Hossein Nourkhiz", ""], ["Fallah", "Yaser P.", ""], ["Moradi-Pari", "Ehsan", ""], ["Abuchaar", "Oubada", ""]]}, {"id": "1808.06465", "submitter": "Yevhenii Shapovalov Borisovich", "authors": "Yevhenii B. Shapovalov, Zhanna I. Bilyk, Artem I. Atamas, Viktor B.\n  Shapovalov, Aleksandr D. Uchitel", "title": "The Potential of Using Google Expeditions and Google Lens Tools under\n  STEM-education in Ukraine", "comments": "9 pages, 3 figures, 2 tables, the Workshop on Augmented Reality in\n  Education (AREdu 2018). arXiv admin note: text overlap with arXiv:1807.00018\n  by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The expediency of using the augmented reality in the case of using of\nSTEM-education in Ukraine is shown. The features of the augmented reality and\nits classification are described. The possibilities of using the Google\nExpeditions and Google Lens as platforms of the augmented reality is analyzed.\nA comparison, analysis, synthesis, induction and deduction was carried out to\nstudy the potential of using augmented reality platforms in the educational\nprocess. Main haracteristics of Google Expeditions and Google Lens are\ndescribed. There determined that augmented reality tools can improve students\nmotivation to learn and correspond to trends of STEM-education. However, there\nproblems of using of augmented reality platforms, such as the lack of awareness\nof this system by teachers, the lack of guidance, the absence of the\nUkrainian-language interface and responding of educational programs of the\nMinistry of Education and Science of Ukraine. There proposed to involve\nmethodical and pedagogical specialists to development of methodical provision\nof the tools of augmented reality.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 05:46:18 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 13:39:04 GMT"}, {"version": "v3", "created": "Mon, 3 May 2021 09:04:40 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Shapovalov", "Yevhenii B.", ""], ["Bilyk", "Zhanna I.", ""], ["Atamas", "Artem I.", ""], ["Shapovalov", "Viktor B.", ""], ["Uchitel", "Aleksandr D.", ""]]}, {"id": "1808.06467", "submitter": "Nitish Nag", "authors": "Nitish Nag, Mathias Lux, Ramesh C. Jain", "title": "Intrinsic and Extrinsic Motivation Modeling Essential for Multi-Modal\n  Health Recommender Systems", "comments": "Related to ACM Multimedia HealthMedia Workshop 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Managing health lays the core foundation to enabling quality life\nexperiences. Modern computer science research, and especially the field of\nrecommender systems, has enhanced the quality of experiences in fields such as\nentertainment, shopping, and advertising; yet lags in the health domain. We are\ndeveloping an approach to leverage multimedia for human health based on\nmotivation modeling and recommendation of actions. Health is primarily a\nproduct of our everyday lifestyle actions, yet we have minimal health guidance\non making everyday choices. Recommendations are the key to modern content\nconsumption and decisions. Furthermore, long-term engagement with recommender\nsystems is key for true effectiveness. Distinguishing intrinsic and extrinsic\nmotivations from multi-modal data is key to provide recommendations that\nprimarily fuel the intrinsic intentions, while using extrinsic motivation to\nfurther support intrinsic motivation. This understanding builds the foundation\nof sustainable behavioral adaptation for optimal personalized lifestyle health\nbenefits.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2018 00:48:16 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Nag", "Nitish", ""], ["Lux", "Mathias", ""], ["Jain", "Ramesh C.", ""]]}, {"id": "1808.06468", "submitter": "Nitish Nag", "authors": "Nitish Nag, Vaibhav Pandey, Ramesh C. Jain", "title": "Endogenous and Exogenous Multi-Modal Layers in Context Aware\n  Recommendation Systems for Health", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People care more about the solutions to their problems rather than data\nalone. Inherently, this means using data to generate a list of recommendations\nfor a given situation. The rapid growth of multi-modal wearables and sensors\nhave not made this jump effectively in the domain of health. Modern user\ncontent consumption and decision making in both cyber (e.g. entertainment,\nnews) and physical (eg. food, shopping) spaces rely heavily on targeted\npersonalized recommender systems. The utility function is the primary ranking\nmethod to predict what a given person would explicitly prefer. In this work we\ndescribe two unique layers of user and context modeling that can be coupled to\ntraditional recommender system approaches. The exogenous layer incorporates\nfactors outside of the person's body (eg. location, weather, social context),\nwhile the endogenous layer integrates data to estimate the physiologic or\ninnate needs of the user. This is accomplished through multi-modal sensor data\nintegration applied to domain-specific utility functions, filters and\nre-ranking weights. We showcase this concept through a nutrition guidance\nsystem focused on controlling sodium intake at a personalized level,\ndramatically improving upon the fixed recommendations.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2018 01:12:39 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Nag", "Nitish", ""], ["Pandey", "Vaibhav", ""], ["Jain", "Ramesh C.", ""]]}, {"id": "1808.06470", "submitter": "Mohamed Ibrahim", "authors": "Mohamed R. Ibrahim, Helena Titheridge, Tao Cheng and James Haworth", "title": "predictSLUMS: A new model for identifying and predicting informal\n  settlements and slums in cities from street intersections using machine\n  learning", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Identifying current and future informal regions within cities remains a\ncrucial issue for policymakers and governments in developing countries. The\ndelineation process of identifying such regions in cities requires a lot of\nresources. While there are various studies that identify informal settlements\nbased on satellite image classification, relying on both supervised or\nunsupervised machine learning approaches, these models either require multiple\ninput data to function or need further development with regards to precision.\nIn this paper, we introduce a novel method for identifying and predicting\ninformal settlements using only street intersections data, regardless of the\nvariation of urban form, number of floors, materials used for construction or\nstreet width. With such minimal input data, we attempt to provide planners and\npolicy-makers with a pragmatic tool that can aid in identifying informal zones\nin cities. The algorithm of the model is based on spatial statistics and a\nmachine learning approach, using Multinomial Logistic Regression (MNL) and\nArtificial Neural Networks (ANN). The proposed model relies on defining\ninformal settlements based on two ubiquitous characteristics that these regions\ntend to be filled in with smaller subdivided lots of housing relative to the\nformal areas within the local context, and the paucity of services and\ninfrastructure within the boundary of these settlements that require relatively\nbigger lots. We applied the model in five major cities in Egypt and India that\nhave spatial structures in which informality is present. These cities are\nGreater Cairo, Alexandria, Hurghada and Minya in Egypt, and Mumbai in India.\nThe predictSLUMS model shows high validity and accuracy for identifying and\npredicting informality within the same city the model was trained on or in\ndifferent ones of a similar context.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 09:34:16 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Ibrahim", "Mohamed R.", ""], ["Titheridge", "Helena", ""], ["Cheng", "Tao", ""], ["Haworth", "James", ""]]}, {"id": "1808.06473", "submitter": "Harishchandra Dubey", "authors": "Debanjan Borthakur, Andrew Peltier, Harishchandra Dubey, Joshua\n  Gyllinsky and Kunal Mankodiya", "title": "SmartEAR: Smartwatch-based Unsupervised Learning for Multi-modal Signal\n  Analysis in Opportunistic Sensing Framework", "comments": "6 pages, 8 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wrist-bands such as smartwatches have become an unobtrusive interface for\ncollecting physiological and contextual data from users. Smartwatches are being\nused for smart healthcare, telecare, and wellness monitoring. In this paper, we\nused data collected from the AnEAR framework leveraging smartwatches to gather\nand store physiological data from patients in naturalistic settings. This data\nincluded temperature, galvanic skin response (GSR), acceleration, and heart\nrate (HR). In particular, we focused on HR and acceleration, as these two\nmodalities are often correlated. Since the data was unlabeled we relied on\nunsupervised learning for multi-modal signal analysis. We propose using k-means\nclustering, GMM clustering, and Self-Organizing maps based on Neural Networks\nfor group the multi-modal data into homogeneous clusters. This strategy helped\nin discovering latent structures in our data.\n", "versions": [{"version": "v1", "created": "Sat, 11 Aug 2018 05:06:02 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Borthakur", "Debanjan", ""], ["Peltier", "Andrew", ""], ["Dubey", "Harishchandra", ""], ["Gyllinsky", "Joshua", ""], ["Mankodiya", "Kunal", ""]]}, {"id": "1808.06475", "submitter": "Jan Claes", "authors": "Francis Bru and Jan Claes", "title": "The perceived quality of process discovery tools", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Process discovery has seen a rise in popularity in the last decade for both\nresearchers and businesses. Recent developments mainly focused on the power and\nthe functionalities of the discovery algorithm. While continuous improvement of\nthese functional aspects is very important, non-functional aspects such as\nvisualization and usability are often overlooked. However, these aspects are\nconsidered valuable for end-users and play an important part in the experience\nof these end-users when working with a process discovery tool. A questionnaire\nhas been sent out to give end-users the opportunity to voice their opinion on\navailable process discovery tools and about the state of process discovery as a\ndomain in general. The results of 66 respondents are presented and compared\nwith the answers of 63 respondents that were contacted through one particular\nsoftware vendor's employee and customer base (i.e., Celonis).\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 18:43:11 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Bru", "Francis", ""], ["Claes", "Jan", ""]]}, {"id": "1808.06489", "submitter": "Anh Nguyen Duc", "authors": "Anh Nguyen-Duc, Daniela S. Cruzes, Snarby Terje, Pekka Abrahamsson", "title": "Do software firms collaborate or compete? A model of coopetition in\n  community-initiated OSS projects", "comments": "arXiv admin note: text overlap with arXiv:1711.07049", "journal-ref": "e-Informatica Software Engineering Journal, 2019", "doi": "10.5277/e-Inf190102", "report-no": null, "categories": "cs.CY cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  [Background] An increasing number of commercial firms are participating in\nOpen Source Software (OSS) projects to reduce their development cost and\nincrease technical innovativeness. When collaborating with other firms whose\nsought values are conflicts of interests, firms may behave uncooperatively\nleading to harmful impacts on the common goal. [Aim] This study explores how\nsoftware firms both collaborate and compete in OSS projects. [Method] We\nadopted a mixed research method on three OSS projects. [Result] We found that\ncommercial firms participating in community-initiated OSS projects collaborate\nin various ways across the organizational boundaries. While most of firms\ncontribute little, a small number of firms that are very active and account for\nlarge proportions of contributions. We proposed a conceptual model to explain\nfor coopetition among software firms in OSS projects. The model shows two\naspects of coopetition can be managed at the same time based on firm\ngatekeepers. [Conclusion] Firms need to operationalize their coopetition\nstrategies to maximize value gained from participating in OSS projects.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 18:19:38 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Nguyen-Duc", "Anh", ""], ["Cruzes", "Daniela S.", ""], ["Terje", "Snarby", ""], ["Abrahamsson", "Pekka", ""]]}, {"id": "1808.06503", "submitter": "Paul Fergus Dr", "authors": "Paul Fergus, Carl Chalmers, and David Tully", "title": "Collaborative Pressure Ulcer Prevention: An Automated Skin Damage and\n  Pressure Ulcer Assessment Tool for Nursing Professionals, Patients, Family\n  Members and Carers", "comments": "5 Pages, 7 figures, Position Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the Pressure Ulcers Online Website, which is a first\nstep solution towards a new and innovative platform for helping people to\ndetect, understand and manage pressure ulcers. It outlines the reasons why the\nproject has been developed and provides a central point of contact for pressure\nulcer analysis and ongoing research. Using state-of-the-art technologies in\nconvolutional neural networks and transfer learning along with end-to-end web\ntechnologies, this platform allows pressure ulcers to be analysed and findings\nto be reported. As the system evolves through collaborative partnerships,\nfuture versions will provide decision support functions to describe the complex\ncharacteristics of pressure ulcers along with information on wound care across\nmultiple user boundaries. This project is therefore intended to raise awareness\nand support for people suffering with or providing care for pressure ulcers.\n", "versions": [{"version": "v1", "created": "Fri, 17 Aug 2018 14:26:47 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Fergus", "Paul", ""], ["Chalmers", "Carl", ""], ["Tully", "David", ""]]}, {"id": "1808.06547", "submitter": "Marco Cremonini", "authors": "Luca Allodi, Marco Cremonini, Fabio Massacci, Woohyun Shim", "title": "The Effect of Security Education and Expertise on Security Assessments:\n  the Case of Software Vulnerabilities", "comments": "Presented at the Workshop on the Economics of Information Security\n  (WEIS 2018), Innsbruck, Austria, June 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of the growing importance of software security and the industry\ndemand for more cyber security expertise in the workforce, the effect of\nsecurity education and experience on the ability to assess complex software\nsecurity problems has only been recently investigated. As proxy for the full\nrange of software security skills, we considered the problem of assessing the\nseverity of software vulnerabilities by means of a structured analysis\nmethodology widely used in industry (i.e. the Common Vulnerability Scoring\nSystem (\\CVSS) v3), and designed a study to compare how accurately individuals\nwith background in information technology but different professional experience\nand education in cyber security are able to assess the severity of software\nvulnerabilities. Our results provide some structural insights into the complex\nrelationship between education or experience of assessors and the quality of\ntheir assessments. In particular we find that individual characteristics matter\nmore than professional experience or formal education; apparently it is the\n\\emph{combination} of skills that one owns (including the actual knowledge of\nthe system under study), rather than the specialization or the years of\nexperience, to influence more the assessment quality. Similarly, we find that\nthe overall advantage given by professional expertise significantly depends on\nthe composition of the individual security skills as well as on the available\ninformation.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 16:20:34 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Allodi", "Luca", ""], ["Cremonini", "Marco", ""], ["Massacci", "Fabio", ""], ["Shim", "Woohyun", ""]]}, {"id": "1808.06606", "submitter": "Stanislav Sobolevsky", "authors": "Stanislav Sobolevsky, Ekaterina Levitskaya, Henry Chan, Marc Postle,\n  Constantine Kontokosta", "title": "Impact Of Bike Sharing In New York City", "comments": "26 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Citi Bike deployment changes the landscape of urban mobility in New York\nCity and provides an example of a scalable solution that many other large\ncities are already adopting around the world. Urban stakeholders who are\nconsidering a similar deployment would largely benefit from a quantitative\nassessment of the impact of bike sharing on urban transportation, as well as\nassociated economic, social and environmental implications. While the Citi Bike\nusage data is publicly available, the main challenge of such an assessment is\nto provide an adequate baseline scenario of what would have happened in the\ncity without the Citi Bike system. Existing efforts, including the reports of\nCiti Bike itself, largely imply arbitrary and often unrealistic assumptions\nabout the alternative transportation mode people would have used otherwise\n(e.g. by comparing bike trips against driving). The present paper offers a\nbalanced baseline scenario based on a transportation choice model to describe\nprojected customer behavior in the absence of the Citi Bike system. The model\nalso acknowledges the fact that Citi Bike might be used for recreational\npurposes and, therefore, not all the trips would have been actually performed,\nif Citi Bike would not be available. The model is trained using open Citi Bike\nand other urban transportation data and it is applied to assess direct benefits\nof Citi Bike trips for the end users, as well as for urban stakeholders across\ndifferent boroughs of New York City and the nearby Jersey City. Besides\nestimating the travel time and cost savings, the model also reports the\nassociated gas savings, emissions cut and additional exercise for the\ncustomers, covering all three areas of anticipated impacts - economic, social\nand environmental.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 07:26:41 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Sobolevsky", "Stanislav", ""], ["Levitskaya", "Ekaterina", ""], ["Chan", "Henry", ""], ["Postle", "Marc", ""], ["Kontokosta", "Constantine", ""]]}, {"id": "1808.07074", "submitter": "Tarek Richard Besold", "authors": "Tarek R. Besold and Sara L. Uckelman", "title": "The What, the Why, and the How of Artificial Explanations in Automated\n  Decision-Making", "comments": "working draft, comments/feedback welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing incorporation of Artificial Intelligence in the form of\nautomated systems into decision-making procedures highlights not only the\nimportance of decision theory for automated systems but also the need for these\ndecision procedures to be explainable to the people involved in them.\nTraditional realist accounts of explanation, wherein explanation is a relation\nthat holds (or does not hold) eternally between an explanans and an\nexplanandum, are not adequate to account for the notion of explanation required\nfor artificial decision procedures. We offer an alternative account of\nexplanation as used in the context of automated decision-making that makes\nexplanation an epistemic phenomenon, and one that is dependent on context. This\naccount of explanation better accounts for the way that we talk about, and use,\nexplanations and derived concepts, such as `explanatory power', and also allows\nus to differentiate between reasons or causes on the one hand, which do not\nneed to have an epistemic aspect, and explanations on the other, which do have\nsuch an aspect. Against this theoretical backdrop we then review existing\napproaches to explanation in Artificial Intelligence and Machine Learning, and\nsuggest desiderata which truly explainable decision systems should fulfill.\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 18:06:22 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Besold", "Tarek R.", ""], ["Uckelman", "Sara L.", ""]]}, {"id": "1808.07202", "submitter": "Weiqing Min", "authors": "Weiqing Min and Shuqiang Jiang and Linhu Liu and Yong Rui and Ramesh\n  Jain", "title": "A Survey on Food Computing", "comments": "Accepted by ACM Computing Surveys", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Food is very essential for human life and it is fundamental to the human\nexperience. Food-related study may support multifarious applications and\nservices, such as guiding the human behavior, improving the human health and\nunderstanding the culinary culture. With the rapid development of social\nnetworks, mobile networks, and Internet of Things (IoT), people commonly\nupload, share, and record food images, recipes, cooking videos, and food\ndiaries, leading to large-scale food data. Large-scale food data offers rich\nknowledge about food and can help tackle many central issues of human society.\nTherefore, it is time to group several disparate issues related to food\ncomputing. Food computing acquires and analyzes heterogenous food data from\ndisparate sources for perception, recognition, retrieval, recommendation, and\nmonitoring of food. In food computing, computational approaches are applied to\naddress food related issues in medicine, biology, gastronomy and agronomy. Both\nlarge-scale food data and recent breakthroughs in computer science are\ntransforming the way we analyze food data. Therefore, vast amounts of work has\nbeen conducted in the food area, targeting different food-oriented tasks and\napplications. However, there are very few systematic reviews, which shape this\narea well and provide a comprehensive and in-depth summary of current efforts\nor detail open problems in this area. In this paper, we formalize food\ncomputing and present such a comprehensive overview of various emerging\nconcepts, methods, and tasks. We summarize key challenges and future directions\nahead for food computing. This is the first comprehensive survey that targets\nthe study of computing technology for the food area and also offers a\ncollection of research studies and technologies to benefit researchers and\npractitioners working in different food-related fields.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 03:22:58 GMT"}, {"version": "v2", "created": "Sun, 9 Sep 2018 10:04:26 GMT"}, {"version": "v3", "created": "Sat, 25 May 2019 06:09:10 GMT"}, {"version": "v4", "created": "Tue, 4 Jun 2019 13:19:09 GMT"}, {"version": "v5", "created": "Tue, 16 Jul 2019 12:25:23 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Min", "Weiqing", ""], ["Jiang", "Shuqiang", ""], ["Liu", "Linhu", ""], ["Rui", "Yong", ""], ["Jain", "Ramesh", ""]]}, {"id": "1808.07227", "submitter": "Hayato Okumoto", "authors": "Hayato Okumoto, Mitsuo Yoshida, Kyoji Umemura, Yuko Ichikawa", "title": "Response Collector: A Video Learning System for Flipped Classrooms", "comments": "The 2018 International Conference On Advanced Informatics: Concepts,\n  Theory And Application (ICAICTA2018)", "journal-ref": null, "doi": "10.1109/ICAICTA.2018.8541338", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The flipped classroom has become famous as an effective educational method\nthat flips the purpose of classroom study and homework. In this paper, we\npropose a video learning system for flipped classrooms, called Response\nCollector, which enables students to record their responses to preparation\nvideos. Our system provides response visualization for teachers and students to\nunderstand what they have acquired and questioned. We performed a practical\nuser study of our system in a flipped classroom setup. The results show that\nstudents preferred to use the proposed method as the inputting method, rather\nthan naive methods. Moreover, sharing responses among students was helpful for\nresolving individual students' questions, and students were satisfied with the\nuse of our system.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 05:53:03 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Okumoto", "Hayato", ""], ["Yoshida", "Mitsuo", ""], ["Umemura", "Kyoji", ""], ["Ichikawa", "Yuko", ""]]}, {"id": "1808.07234", "submitter": "Petrus Dwi Ananto Pamungkas", "authors": "Petrus Dwi Ananto Pamungkas", "title": "Library Information System Audit Senayan Library Management System\n  (SLiMS) Using ISO 9126", "comments": "library, Senayan Library Management System (SLiMS), audit information\n  system, ISO 9126", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The library serves as a vehicle for education, research, conservation,\ninformation, and recreation to improve the nation's intelligence and\nempowerment [1]. The function of the library as a place of education, research,\nand information provides an opportunity to use the information system of\nSenayan Library Management System (SLiMS) in the library in order to improve\nthe service to the user, increase the reading interest, and expand the insight\nand knowledge to educate the nation. The use of ISO 9126 standard is able to\nknow the quality of SLiMS information system which is said to be free of charge\nof usage and license (because it belongs to Open Source Software category [2])\nto assist library management in Indonesia. The implementation of the SLiMS\ninformation system audit in several university libraries refers to the ISO 9126\nstandard by using the Functionality, Reliability, Usability, Efficiency,\nMaintainability and Portability aspects through distributing questionnaires to\nuniversity librarians in charge. With the help of the use of Google Forms it\nturns out that only ten universities librarians in charge who are willing to\nfill out the questionnaires are IPMI IBS, Bakrie University, Perbanas Institute\nJakarta, STMIK & Bina Insani Academy, Prasetya Mulya University, Agung Podomoro\nUniversity, Indonesian Higher Law School, Matana University, STIKS Tarakanita\nJakarta, and STAI-PIQ West Sumatra. From the results of data processing it is\nknown that SLiMS included in the category VERY GOOD for use in the management\nof libraries in college. This means that the ten universities librarians in\ncharge admitted and have proven that SLiMS is very helpful in library\nmanagement.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 06:07:24 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Pamungkas", "Petrus Dwi Ananto", ""]]}, {"id": "1808.07261", "submitter": "Michael Hind", "authors": "Matthew Arnold, Rachel K. E. Bellamy, Michael Hind, Stephanie Houde,\n  Sameep Mehta, Aleksandra Mojsilovic, Ravi Nair, Karthikeyan Natesan\n  Ramamurthy, Darrell Reimer, Alexandra Olteanu, David Piorkowski, Jason Tsay,\n  and Kush R. Varshney", "title": "FactSheets: Increasing Trust in AI Services through Supplier's\n  Declarations of Conformity", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accuracy is an important concern for suppliers of artificial intelligence\n(AI) services, but considerations beyond accuracy, such as safety (which\nincludes fairness and explainability), security, and provenance, are also\ncritical elements to engender consumers' trust in a service. Many industries\nuse transparent, standardized, but often not legally required documents called\nsupplier's declarations of conformity (SDoCs) to describe the lineage of a\nproduct along with the safety and performance testing it has undergone. SDoCs\nmay be considered multi-dimensional fact sheets that capture and quantify\nvarious aspects of the product and its development to make it worthy of\nconsumers' trust. Inspired by this practice, we propose FactSheets to help\nincrease trust in AI services. We envision such documents to contain purpose,\nperformance, safety, security, and provenance information to be completed by AI\nservice providers for examination by consumers. We suggest a comprehensive set\nof declaration items tailored to AI and provide examples for two fictitious AI\nservices in the appendix of the paper.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 07:55:56 GMT"}, {"version": "v2", "created": "Thu, 7 Feb 2019 13:34:04 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Arnold", "Matthew", ""], ["Bellamy", "Rachel K. E.", ""], ["Hind", "Michael", ""], ["Houde", "Stephanie", ""], ["Mehta", "Sameep", ""], ["Mojsilovic", "Aleksandra", ""], ["Nair", "Ravi", ""], ["Ramamurthy", "Karthikeyan Natesan", ""], ["Reimer", "Darrell", ""], ["Olteanu", "Alexandra", ""], ["Piorkowski", "David", ""], ["Tsay", "Jason", ""], ["Varshney", "Kush R.", ""]]}, {"id": "1808.07293", "submitter": "Jukka Ruohonen", "authors": "Jukka Ruohonen and Ville Lepp\\\"anen", "title": "Invisible Pixels Are Dead, Long Live Invisible Pixels!", "comments": "Forthcoming in the 17th Workshop on Privacy in the Electronic Society\n  (WPES 2018), Toronto, ACM", "journal-ref": null, "doi": "10.1145/3267323.3268950", "report-no": null, "categories": "cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy has deteriorated in the world wide web ever since the 1990s. The\ntracking of browsing habits by different third-parties has been at the center\nof this deterioration. Web cookies and so-called web beacons have been the\nclassical ways to implement third-party tracking. Due to the introduction of\nmore sophisticated technical tracking solutions and other fundamental\ntransformations, the use of classical image-based web beacons might be expected\nto have lost their appeal. According to a sample of over thirty thousand images\ncollected from popular websites, this paper shows that such an assumption is a\nfallacy: classical 1 x 1 images are still commonly used for third-party\ntracking in the contemporary world wide web. While it seems that ad-blockers\nare unable to fully block these classical image-based tracking beacons, the\npaper further demonstrates that even limited information can be used to\naccurately classify the third-party 1 x 1 images from other images. An average\nclassification accuracy of 0.956 is reached in the empirical experiment. With\nthese results the paper contributes to the ongoing attempts to better\nunderstand the lack of privacy in the world wide web, and the means by which\nthe situation might be eventually improved.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 09:29:52 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Ruohonen", "Jukka", ""], ["Lepp\u00e4nen", "Ville", ""]]}, {"id": "1808.07338", "submitter": "Jason R.C. Nurse Dr", "authors": "Sean Sirur and Jason R.C. Nurse and Helena Webb", "title": "Are we there yet? Understanding the challenges faced in complying with\n  the General Data Protection Regulation (GDPR)", "comments": "8 pages; Proceedings of the International Workshop on Multimedia\n  Privacy and Security (MPS 2018), at the ACM Conference on Computer and\n  Communication Security (CCS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The EU General Data Protection Regulation (GDPR), enforced from 25th May\n2018, aims to reform how organisations view and control the personal data of\nprivate EU citizens. The scope of GDPR is somewhat unprecedented: it regulates\nevery aspect of personal data handling, includes hefty potential penalties for\nnon-compliance, and can prosecute any company in the world that processes EU\ncitizens' data. In this paper, we look behind the scenes to investigate the\nreal challenges faced by organisations in engaging with the GDPR. This\nconsiders issues in working with the regulation, the implementation process,\nand how compliance is verified. Our research approach relies on literature but,\nmore importantly, draws on detailed interviews with several organisations. Key\nfindings include the fact that large organisations generally found GDPR\ncompliance to be reasonable and doable. The same was found for small-to-medium\norganisations (SMEs/SMBs) that were highly security-oriented. SMEs with less\nfocus on data protection struggled to make what they felt was a satisfactory\nattempt at compliance. The main issues faced in their compliance attempts\nemerged from: the sheer breadth of the regulation; questions around how to\nenact the qualitative recommendations of the regulation; and the need to map\nout the entirety of their complex data networks.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 12:52:07 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Sirur", "Sean", ""], ["Nurse", "Jason R. C.", ""], ["Webb", "Helena", ""]]}, {"id": "1808.07379", "submitter": "Ming-Chang Lee", "authors": "Ming-Chang Lee, Jia-Chun Lin, Olaf Owe", "title": "Privacy Mining from IoT-based Smart Homes", "comments": "This paper, which has 11 pages and 7 figures, has been accepted BWCCA\n  2018 on 13th August 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a wide range of smart devices are deployed in a variety of\nenvironments to improve the quality of human life. One of the important\nIoT-based applications is smart homes for healthcare, especially for elders.\nIoT-based smart homes enable elders' health to be properly monitored and taken\ncare of. However, elders' privacy might be disclosed from smart homes due to\nnon-fully protected network communication or other reasons. To demonstrate how\nserious this issue is, we introduce in this paper a Privacy Mining Approach\n(PMA) to mine privacy from smart homes by conducting a series of deductions and\nanalyses on sensor datasets generated by smart homes. The experimental results\ndemonstrate that PMA is able to deduce a global sensor topology for a smart\nhome and disclose elders' privacy in terms of their house layouts.\n", "versions": [{"version": "v1", "created": "Sat, 18 Aug 2018 10:42:52 GMT"}, {"version": "v2", "created": "Tue, 11 Sep 2018 08:21:14 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Lee", "Ming-Chang", ""], ["Lin", "Jia-Chun", ""], ["Owe", "Olaf", ""]]}, {"id": "1808.07380", "submitter": "Tu  Nguyen", "authors": "Tu Ngoc Nguyen and Markus Rokicki", "title": "On the Predictability of non-CGM Diabetes Data for Personalized\n  Recommendation", "comments": "In Proceedings of ACM CIKM 2018 Workshops", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With continuous glucose monitoring (CGM), data-driven models on blood glucose\nprediction have been shown to be effective in related work. However, such (CGM)\nsystems are not always available, e.g., for a patient at home. In this work, we\nconduct a study on 9 patients and examine the predictability of data-driven\n(aka. machine learning) based models on patient-level blood glucose prediction;\nwith measurements are taken only periodically (i.e., after several hours). To\nthis end, we propose several post-prediction methods to account for the noise\nnature of these data, that marginally improves the performance of the end\nsystem.\n", "versions": [{"version": "v1", "created": "Sun, 19 Aug 2018 02:53:33 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 18:57:35 GMT"}, {"version": "v3", "created": "Thu, 30 Aug 2018 00:28:59 GMT"}, {"version": "v4", "created": "Fri, 7 Sep 2018 00:41:55 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Nguyen", "Tu Ngoc", ""], ["Rokicki", "Markus", ""]]}, {"id": "1808.07381", "submitter": "Yemeserach Mekonnen", "authors": "Lamar Burton, Yemeserach Mekonnen, Arif Sarwat, Shekhar Bhansali,\n  Krish Jayachandran", "title": "Exploring Wireless Sensor Network Technology In Sustainable Okra Garden:\n  A Comparative Analysis Of Okra Grown In Different Fertilizer Treatments", "comments": "12 pages, 5 figures, published on 14th International Conference on\n  Precision Agriculture", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this project was to explore commercial agricultural and\nirrigation sensor kits and to discern if the commercial wireless sensor network\nis viable tool for providing accurate real-time farm data at the nexus of food,\nenergy and water. The smart garden consists of two different varieties of\nAbelmoschus esculentus planted in raised beds, each grown under two different\nfertilizer treatments. Soil watermark sensors were programmed to evaluate soil\nmoisture and dictate irrigation events up to four times a day, while soil\ntemperature and photosynthetic solar radiation sensors also recorded data every\nsix hours. Solar panels harvested energy to power water pump and sensors. The\nobjectives of the experiments were to evaluate and compare plant and soil\nparameters of the two okra varietes grown under two different fertilizer\ntreatments. The plant parameters evaluated and compared were basal diameter,\nplant height, fruit production, and fruit size. Soil parameters measured were\nsoil moisture, soil temperature, and soil nitrate concentration. The commercial\nsensors were evaluated on efficiency, accuracy, ease of use and overall\npracticality. Clemson spineless produced larger okra plants with the highest\nplant parameter values, followed by Emerald okra.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 14:37:17 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Burton", "Lamar", ""], ["Mekonnen", "Yemeserach", ""], ["Sarwat", "Arif", ""], ["Bhansali", "Shekhar", ""], ["Jayachandran", "Krish", ""]]}, {"id": "1808.07590", "submitter": "Lucas Breitsameter", "authors": "Lucas Breitsameter", "title": "Anytime Learning - The next Step in Organic Computing?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anytime learning describes a relatively novel concept by which systems are\nable to acquire knowledge about a changing environment and adapt and behave\naccordingly to this. \"Anytime\" refers to the fact that the system is capable of\nreturning imperfect results at any point in time, which allows it to remain\nfunctional even if a perfect solution could not be found within the necessary\ntime frame. This paper focuses on illustrating the concept of anytime learning\nand examining how it relates to organic computing as a whole. Could anytime\nlearning be the next step in organic computing?\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 23:39:46 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Breitsameter", "Lucas", ""]]}, {"id": "1808.07623", "submitter": "John-Thones Amenyo", "authors": "John-Thones Amenyo", "title": "Principles, Paradigms and the Future of UAV Drone Teams in Use for\n  Engineering and Operation of Landscape-Scale Deployable Structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drone fleets, with counts on the order of O(100) to O(1000), will play\nimportant and significant roles in the automation of the deployment, operation,\nmaintenance and repair of ubiquitous and pervasive landscape scale elongated\nstructures, with the longest linear spatial dimensions of O(1 mile) to O(10\nmile). The organization of the drone team to support the task is considered as\na digital platform, (specifically, a digital multi-sided platform). A\ncomputational thinking approach is used to engineer the architecture of the\nplatform.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 03:53:06 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Amenyo", "John-Thones", ""]]}, {"id": "1808.07627", "submitter": "John-Thones Amenyo", "authors": "John-Thones Amenyo", "title": "Using Digital Twins and Intelligent Cognitive Agencies to Build\n  Platforms for Automated CxO Future of Work", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI, Algorithms and Machine based automation of executive functions in\nenterprises and institutions is an important niche in the current\nconsiderations about the impact of digitalization on the future of work.\nBuilding platforms for CxO automation is challenging. In this paper, design\nprinciples based on computational thinking are used to engineer the\narchitecture and infrastructure for such CxO automation platforms.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 04:12:23 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Amenyo", "John-Thones", ""]]}, {"id": "1808.07899", "submitter": "Barbara Grosz", "authors": "Barbara J. Grosz and Peter Stone", "title": "A Century Long Commitment to Assessing Artificial Intelligence and its\n  Impact on Society", "comments": "This paper will appear in Communications of the ACM (December 2018,\n  vol 61, no. 12)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In September 2016, Stanford's \"One Hundred Year Study on Artificial\nIntelligence\" project (AI100) issued the first report of its planned long-term\nperiodic assessment of artificial intelligence (AI) and its impact on society.\nThe report, entitled \"Artificial Intelligence and Life in 2030,\" examines eight\ndomains of typical urban settings on which AI is likely to have impact over the\ncoming years: transportation, home and service robots, healthcare, education,\npublic safety and security, low-resource communities, employment and workplace,\nand entertainment. It aims to provide the general public with a scientifically\nand technologically accurate portrayal of the current state of AI and its\npotential and to help guide decisions in industry and governments, as well as\nto inform research and development in the field. This article by the chair of\nthe 2016 Study Panel and the inaugural chair of the AI100 Standing Committee\ndescribes the origins of this ambitious longitudinal study, discusses the\nframing of the inaugural report, and presents the report's main findings. It\nconcludes with a brief description of the AI100 project's ongoing efforts and\nplanned next steps.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 18:38:26 GMT"}], "update_date": "2018-08-27", "authors_parsed": [["Grosz", "Barbara J.", ""], ["Stone", "Peter", ""]]}, {"id": "1808.08177", "submitter": "Elissa Marie Redmiles", "authors": "Elissa M. Redmiles", "title": "\"Should I Worry?\" A Cross-Cultural Examination of Account Security\n  Incident Response", "comments": null, "journal-ref": "Proceedings of the IEEE Symposium on Security and Privacy (IEEE\n  S&P), 2019", "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Digital security technology is able to identify and prevent many threats to\nusers accounts. However, some threats remain that, to provide reliable\nsecurity, require human intervention: e.g., through users paying attention to\nwarning messages or completing secondary authentication procedures. While prior\nwork has broadly explored people's mental models of digital security threats,\nwe know little about users' precise, in-the-moment response process to\nin-the-wild threats. In this work, we conduct a series of qualitative\ninterviews (n=67) with users who had recently experienced suspicious login\nincidents on their real Facebook accounts in order to explore this process of\naccount security incident response. We find a common process across\nparticipants from five countries -- with differing online and offline cultures\n-- allowing us to identify areas for future technical development to best\nsupport user security. We provide additional insights on the unique nature of\nincident-response information seeking, known attacker threat models, and\nlessons learned from a large, cross-cultural qualitative study of digital\nsecurity.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 15:36:47 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2018 22:41:45 GMT"}, {"version": "v3", "created": "Thu, 10 Jan 2019 14:53:22 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["Redmiles", "Elissa M.", ""]]}, {"id": "1808.08428", "submitter": "Kazutoshi Sasahara", "authors": "Kazutoshi Sasahara", "title": "You are what you eat: A social media study of food identity", "comments": "15 pages, 7 figures, 5 tables. Comput Soc Sc (2019)", "journal-ref": "J Comput Soc Sc (2019)", "doi": "10.1007/s42001-019-00039-7", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Food preferences not only originate from a person's dietary habits, but also\nreflect personal values and consumer awareness. This study addresses `food\nidentity' or the relationship between food preferences and personal attributes\nbased on the concept of `food left-wing' (e.g., vegetarians) and `food\nright-wing' (e.g., fast-food lovers) by analyzing social data using information\nentropy and networks. The results show that food identity extends beyond the\ndomain of food: The food left-wing has a strong interest in socio-environmental\nissues, while the food right-wing has a higher interest in large-scale shopping\nmalls and politically conservative issues. Furthermore, the social interactions\nof food left-wing and right-wing factions show segregated structures,\nindicating different information consumption patterns. These findings suggest\nthat food identity may be applicable as a proxy for personal attributes and\noffer insights into potential buying patterns.\n", "versions": [{"version": "v1", "created": "Sat, 25 Aug 2018 13:47:19 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 14:38:41 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Sasahara", "Kazutoshi", ""]]}, {"id": "1808.08537", "submitter": "Celina Rebello", "authors": "Celina Rebello, Elaine Tavares", "title": "Big Data Privacy Context: Literature Effects On Secure Informational\n  Assets", "comments": "21 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article's objective is the identification of research opportunities in\nthe current big data privacy domain, evaluating literature effects on secure\ninformational assets. Until now, no study has analyzed such relation. Its\nresults can foster science, technologies and businesses. To achieve these\nobjectives, a big data privacy Systematic Literature Review (SLR) is performed\non the main scientific peer reviewed journals in Scopus database. Bibliometrics\nand text mining analysis complement the SLR. This study provides support to big\ndata privacy researchers on: most and least researched themes, research\nnovelty, most cited works and authors, themes evolution through time and many\nothers. In addition, TOPSIS and VIKOR ranks were developed to evaluate\nliterature effects versus informational assets indicators. Secure Internet\nServers (SIS) was chosen as decision criteria. Results show that big data\nprivacy literature is strongly focused on computational aspects. However,\nindividuals, societies, organizations and governments face a technological\nchange that has just started to be investigated, with growing concerns on law\nand regulation aspects. TOPSIS and VIKOR Ranks differed in several positions\nand the only consistent country between literature and SIS adoption is the\nUnited States. Countries in the lowest ranking positions represent future\nresearch opportunities.\n", "versions": [{"version": "v1", "created": "Sun, 26 Aug 2018 11:56:37 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Rebello", "Celina", ""], ["Tavares", "Elaine", ""]]}, {"id": "1808.08538", "submitter": "Adam Tsakalidis", "authors": "Adam Tsakalidis, Nikolaos Aletras, Alexandra I. Cristea, Maria Liakata", "title": "Nowcasting the Stance of Social Media Users in a Sudden Vote: The Case\n  of the Greek Referendum", "comments": "Preprint accepted for publication in the ACM International Conference\n  on Information and Knowledge Management (CIKM 2018)", "journal-ref": null, "doi": "10.1145/3269206.3271783", "report-no": null, "categories": "cs.CY cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modelling user voting intention in social media is an important research\narea, with applications in analysing electorate behaviour, online political\ncampaigning and advertising. Previous approaches mainly focus on predicting\nnational general elections, which are regularly scheduled and where data of\npast results and opinion polls are available. However, there is no evidence of\nhow such models would perform during a sudden vote under time-constrained\ncircumstances. That poses a more challenging task compared to traditional\nelections, due to its spontaneous nature. In this paper, we focus on the 2015\nGreek bailout referendum, aiming to nowcast on a daily basis the voting\nintention of 2,197 Twitter users. We propose a semi-supervised multiple\nconvolution kernel learning approach, leveraging temporally sensitive text and\nnetwork information. Our evaluation under a real-time simulation framework\ndemonstrates the effectiveness and robustness of our approach against\ncompetitive baselines, achieving a significant 20% increase in F-score compared\nto solely text-based models.\n", "versions": [{"version": "v1", "created": "Sun, 26 Aug 2018 11:58:04 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Tsakalidis", "Adam", ""], ["Aletras", "Nikolaos", ""], ["Cristea", "Alexandra I.", ""], ["Liakata", "Maria", ""]]}, {"id": "1808.08617", "submitter": "Nalin Jayaweera", "authors": "Nalin Jayaweera, Nandana Rajatheva and Matti Latva-aho", "title": "Autonomous Driving without a Burden: View from Outside with Elevated\n  LiDAR", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current autonomous driving architecture places a heavy burden in signal\nprocessing for the graphics processing units (GPUs) in the car. This directly\ntranslates into battery drain and lower energy efficiency, crucial factors in\nelectric vehicles. This is due to the high bit rate of the captured video and\nother sensing inputs, mainly due to Light Detection and Ranging (LiDAR) sensor\nat the top of the car which is an essential feature in autonomous vehicles.\nLiDAR is needed to obtain a high precision map for the vehicle AI to make\nrelevant decisions. However, this is still a quite restricted view from the\ncar. This is the same even in the case of cars without a LiDAR such as Tesla.\nThe existing LiDARs and the cameras have limited horizontal and vertical fields\nof visions. In all cases it can be argued that precision is lower, given the\nsmaller map generated. This also results in the accumulation of a large amount\nof data in the order of several TBs in a day, the storage of which becomes\nchallenging. If we are to reduce the effort for the processing units inside the\ncar, we need to uplink the data to edge or an appropriately placed cloud.\nHowever, the required data rates in the order of several Gbps are difficult to\nbe met even with the advent of 5G. Therefore, we propose to have a coordinated\nset of LiDAR's outside at an elevation which can provide an integrated view\nwith a much larger field of vision (FoV) to a centralized decision making body\nwhich then sends the required control actions to the vehicles with a lower bit\nrate in the downlink and with the required latency. The calculations we have\nbased on industry standard equipment from several manufacturers show that this\nis not just a concept but a feasible system which can be implemented.The\nproposed system can play a supportive role with existing autonomous vehicle\narchitecture and it is easily applicable in an urban area.\n", "versions": [{"version": "v1", "created": "Sun, 26 Aug 2018 20:20:37 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 18:07:40 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Jayaweera", "Nalin", ""], ["Rajatheva", "Nandana", ""], ["Latva-aho", "Matti", ""]]}, {"id": "1808.08619", "submitter": "Samuel Yeom", "authors": "Samuel Yeom, Michael Carl Tschantz", "title": "Avoiding Disparity Amplification under Different Worldviews", "comments": "This is a draft version. For the published version, please go to\n  https://dl.acm.org/doi/10.1145/3442188.3445892", "journal-ref": null, "doi": "10.1145/3442188.3445892", "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We mathematically compare four competing definitions of group-level\nnondiscrimination: demographic parity, equalized odds, predictive parity, and\ncalibration. Using the theoretical framework of Friedler et al., we study the\nproperties of each definition under various worldviews, which are assumptions\nabout how, if at all, the observed data is biased. We argue that different\nworldviews call for different definitions of fairness, and we specify the\nworldviews that, when combined with the desire to avoid a criterion for\ndiscrimination that we call disparity amplification, motivate demographic\nparity and equalized odds. We also argue that predictive parity and calibration\nare insufficient for avoiding disparity amplification because predictive parity\nallows an arbitrarily large inter-group disparity and calibration is not robust\nto post-processing. Finally, we define a worldview that is more realistic than\nthe previously considered ones, and we introduce a new notion of fairness that\ncorresponds to this worldview.\n", "versions": [{"version": "v1", "created": "Sun, 26 Aug 2018 20:36:58 GMT"}, {"version": "v2", "created": "Thu, 6 Sep 2018 22:03:32 GMT"}, {"version": "v3", "created": "Mon, 14 Jan 2019 18:08:07 GMT"}, {"version": "v4", "created": "Thu, 5 Sep 2019 22:09:21 GMT"}, {"version": "v5", "created": "Thu, 2 Jul 2020 17:49:29 GMT"}, {"version": "v6", "created": "Sat, 10 Oct 2020 03:23:48 GMT"}, {"version": "v7", "created": "Tue, 9 Mar 2021 18:22:46 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Yeom", "Samuel", ""], ["Tschantz", "Michael Carl", ""]]}, {"id": "1808.09037", "submitter": "Scott A. Hale", "authors": "Chico Q. Camargo, Scott A. Hale, Peter John, and Helen Z. Margetts", "title": "Volatility in the Issue Attention Economy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.IT math.IT physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent election surprises and regime changes have left the impression that\npolitics has become more fast-moving and unstable. While modern politics does\nseem more volatile, there is little systematic evidence to support this claim.\nThis paper seeks to address this gap in knowledge by reporting data over the\nlast seventy years using public opinion polls and traditional media data from\nthe UK and Germany. These countries are good cases to study because both have\nexperienced considerable changes in electoral behaviour and have new political\nparties during the time period studied. We measure volatility in public opinion\nand in media coverage using approaches from information theory, tracking the\nchange in word-use patterns across over 700,000 articles. Our preliminary\nanalysis suggests an increase in the number of opinion issues over time and a\ngrowth in lack of predictability of the media series from the 1970s.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 21:28:46 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Camargo", "Chico Q.", ""], ["Hale", "Scott A.", ""], ["John", "Peter", ""], ["Margetts", "Helen Z.", ""]]}, {"id": "1808.09123", "submitter": "Sarah Tan", "authors": "Sarah Tan and Julius Adebayo and Kori Inkpen and Ece Kamar", "title": "Investigating Human + Machine Complementarity for Recidivism Predictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When might human input help (or not) when assessing risk in fairness domains?\nDressel and Farid (2018) asked Mechanical Turk workers to evaluate a subset of\ndefendants in the ProPublica COMPAS data for risk of recidivism, and concluded\nthat COMPAS predictions were no more accurate or fair than predictions made by\nhumans. We delve deeper into this claim to explore differences in human and\nalgorithmic decision making. We construct a Human Risk Score based on the\npredictions made by multiple Turk workers, characterize the features that\ndetermine agreement and disagreement between COMPAS and Human Scores, and\nconstruct hybrid Human+Machine models to predict recidivism. Our key finding is\nthat on this data set, Human and COMPAS decision making differed, but not in\nways that could be leveraged to significantly improve ground-truth prediction.\nWe present the results of our analyses and suggestions for data collection best\npractices to leverage complementary strengths of human and machines in the\nfairness domain.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 05:28:35 GMT"}, {"version": "v2", "created": "Mon, 3 Dec 2018 07:11:32 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Tan", "Sarah", ""], ["Adebayo", "Julius", ""], ["Inkpen", "Kori", ""], ["Kamar", "Ece", ""]]}, {"id": "1808.09145", "submitter": "Joe Simons", "authors": "Joseph J.P. Simons", "title": "Psychological Frameworks for Persuasive Information and Communications\n  Technologies", "comments": null, "journal-ref": "Simons, Joseph JP. \"Psychological Frameworks for Persuasive\n  Information and Communications Technologies.\" IEEE Pervasive Computing 15,\n  no. 3 (2016): 68-76", "doi": "10.1109/MPRV.2016.52", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When developing devices to encourage positive change in users, social\npsychology can offer useful conceptual resources. This article outlines three\nmajor theories from the discipline and discusses their implications for\ndesigning persuasive technologies.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 07:24:15 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Simons", "Joseph J. P.", ""]]}, {"id": "1808.09325", "submitter": "Amir Karami", "authors": "Vanessa L. Kitzie and Ehsan Mohammadi and Amir Karami", "title": "\"Life never matters in the DEMOCRATS MIND\": Examining Strategies of\n  Retweeted Social Bots During a Mass Shooting Event", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This exploratory study examines the strategies of social bots on Twitter that\nwere retweeted following a mass shooting event. Using a case study method to\nframe our work, we collected over seven million tweets during a one-month\nperiod following a mass shooting in Parkland, Florida. From this dataset, we\nselected retweets of content generated by over 400 social bot accounts to\ndetermine what strategies these bots were using and the effectiveness of these\nstrategies as indicated by the number of retweets. We employed qualitative and\nquantitative methods to capture both macro- and micro-level perspectives. Our\nfindings suggest that bots engage in more diverse strategies than solely waging\ndisinformation campaigns, including baiting and sharing information. Further,\nwe found that while bots amplify conversation about mass shootings, humans were\nprimarily responsible for disseminating bot-generated content. These findings\nadd depth to the current understanding of bot strategies and their\neffectiveness. Understanding these strategies can inform efforts to combat\ndubious information as well as more insidious disinformation campaigns.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 14:31:01 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Kitzie", "Vanessa L.", ""], ["Mohammadi", "Ehsan", ""], ["Karami", "Amir", ""]]}, {"id": "1808.09488", "submitter": "Libby Hemphill", "authors": "Libby Hemphill, A.J. Million, Ingrid Erickson", "title": "Crafting Moral Infrastructures: How Nonprofits Use Facebook to Survive", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present findings from interviews with 23 individuals affiliated with\nnon-profit organizations (NPOs) to understand how they deploy information and\ncommunication technologies (ICTs) in civic engagement efforts. Existing\nresearch about NPO ICT use is largely critical, but we did not find evidence\nthat NPOs fail to use tools effectively. Rather, we detail how various ICT use\non the part of NPOs intersects with unique affordance perceptions and adoption\ncauses. Overall, we find that existing theories about technology choice (e.g.,\ntask-technology fit, uses and gratifications) do not explain the assemblages\nNPOs describe. We argue that NPOs fashion infrastructures in accordance with\ntheir moral economy frameworks rather than selecting tools based on utility.\nTogether, the rhetorics of infrastructure and moral economies capture the\nmotivations and constraints our participants expressed and challenge how\nprevailing theories of ICT usage describe the non-profit landscape.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 18:46:48 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Hemphill", "Libby", ""], ["Million", "A. J.", ""], ["Erickson", "Ingrid", ""]]}, {"id": "1808.09496", "submitter": "Johanna Johansen Ms", "authors": "Johanna Johansen and Christian Johansen and Josef Noll", "title": "InfoInternet for Education in the Global South: A Study of Applications\n  Enabled by Free Information-only Internet Access in Technologically\n  Disadvantaged Areas (authors' version)", "comments": "16 pages, 1 figure, under review for a journal since March 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper summarises our work on studying educational applications enabled\nby the introduction of a new information layer called InfoInternet. This is an\ninitiative to facilitate affordable access to internet based information in\ncommunities with network scarcity or economic problems from the Global South.\nInfoInternet develops both networking solutions as well as business and social\nmodels, together with actors like mobile operators and government\norganisations. In this paper we identify and describe characteristics of\neducational applications, their specific users, and learning environment. We\nare interested in applications that make the adoption of Internet faster,\ncheaper, and wider in such communities. When developing new applications (or\nadopting existing ones) for such constrained environments, this work acts as\ninitial guidelines prior to field studies.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 19:05:19 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Johansen", "Johanna", ""], ["Johansen", "Christian", ""], ["Noll", "Josef", ""]]}, {"id": "1808.09600", "submitter": "Salvatore Giorgi", "authors": "Salvatore Giorgi, Daniel Preotiuc-Pietro, Anneke Buffone, Daniel\n  Rieman, Lyle H. Ungar and H. Andrew Schwartz", "title": "The Remarkable Benefit of User-Level Aggregation for Lexical-based\n  Population-Level Predictions", "comments": "To appear in the proceedings of the 2018 Conference on Empirical\n  Methods in Natural Language Processing (EMNLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Nowcasting based on social media text promises to provide unobtrusive and\nnear real-time predictions of community-level outcomes. These outcomes are\ntypically regarding people, but the data is often aggregated without regard to\nusers in the Twitter populations of each community. This paper describes a\nsimple yet effective method for building community-level models using Twitter\nlanguage aggregated by user. Results on four different U.S. county-level tasks,\nspanning demographic, health, and psychological outcomes show large and\nconsistent improvements in prediction accuracies (e.g. from Pearson r=.73 to\n.82 for median income prediction or r=.37 to .47 for life satisfaction\nprediction) over the standard approach of aggregating all tweets. We make our\naggregated and anonymized community-level data, derived from 37 billion tweets\n-- over 1 billion of which were mapped to counties, available for research.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 01:33:21 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Giorgi", "Salvatore", ""], ["Preotiuc-Pietro", "Daniel", ""], ["Buffone", "Anneke", ""], ["Rieman", "Daniel", ""], ["Ungar", "Lyle H.", ""], ["Schwartz", "H. Andrew", ""]]}, {"id": "1808.09852", "submitter": "He Huang", "authors": "He Huang, Bokai Cao, Philip S. Yu, Chang-Dong Wang, Alex D. Leow", "title": "dpMood: Exploiting Local and Periodic Typing Dynamics for Personalized\n  Mood Prediction", "comments": "Published in ICDM'18 as a regular paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mood disorders are common and associated with significant morbidity and\nmortality. Early diagnosis has the potential to greatly alleviate the burden of\nmental illness and the ever increasing costs to families and society. Mobile\ndevices provide us a promising opportunity to detect the users' mood in an\nunobtrusive manner. In this study, we use a custom keyboard which collects\nkeystrokes' meta-data and accelerometer values. Based on the collected time\nseries data in multiple modalities, we propose a deep personalized mood\nprediction approach, called {\\pro}, by integrating convolutional and recurrent\ndeep architectures as well as exploring each individual's circadian rhythm.\nExperimental results not only demonstrate the feasibility and effectiveness of\nusing smart-phone meta-data to predict the presence and severity of mood\ndisturbances in bipolar subjects, but also show the potential of personalized\nmedical treatment for mood disorders.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 14:31:42 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Huang", "He", ""], ["Cao", "Bokai", ""], ["Yu", "Philip S.", ""], ["Wang", "Chang-Dong", ""], ["Leow", "Alex D.", ""]]}, {"id": "1808.10663", "submitter": "Satoshi Endo", "authors": "Muriel Lang, Franz M.J. Pfister, Jakob Fr\\\"ohner, Kian Abedinpour,\n  Daniel Pichler, Urban Fietzek, Terry T. Um, Dana Kuli\\'c, Satoshi Endo,\n  Sandra Hirche", "title": "A Multi-layer Gaussian Process for Motor Symptom Estimation in People\n  with Parkinson's Disease", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The assessment of Parkinson's disease (PD) poses a significant challenge as\nit is influenced by various factors which lead to a complex and fluctuating\nsymptom manifestation. Thus, a frequent and objective PD assessment is highly\nvaluable for effective health management of people with Parkinson's disease\n(PwP). Here, we propose a method for monitoring PwP by stochastically modeling\nthe relationships between their wrist movements during unscripted daily\nactivities and corresponding annotations about clinical displays of movement\nabnormalities. We approach the estimation of PD motor signs by independently\nmodeling and hierarchically stacking Gaussian process models for three classes\nof commonly observed movement abnormalities in PwP including tremor,\n(non-tremulous) bradykinesia, and (non-tremulous) dyskinesia. We use clinically\nadopted severity measures as annotations for training the models, thus allowing\nour multi-layer Gaussian process prediction models to estimate not only their\npresence but also their severities. The experimental validation of our approach\ndemonstrates strong agreement of the model predictions with these PD\nannotations. Our results show the proposed method produces promising results in\nobjective monitoring of movement abnormalities of PD in the presence of\narbitrary and unknown voluntary motions, and makes an important step towards\ncontinuous monitoring of PD in the home environment.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 10:20:43 GMT"}, {"version": "v2", "created": "Thu, 27 Sep 2018 09:01:37 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Lang", "Muriel", ""], ["Pfister", "Franz M. J.", ""], ["Fr\u00f6hner", "Jakob", ""], ["Abedinpour", "Kian", ""], ["Pichler", "Daniel", ""], ["Fietzek", "Urban", ""], ["Um", "Terry T.", ""], ["Kuli\u0107", "Dana", ""], ["Endo", "Satoshi", ""], ["Hirche", "Sandra", ""]]}, {"id": "1808.10862", "submitter": "Yuri G. Gordienko", "authors": "Nikita Gordienko, Peng Gang, Yuri Gordienko, Wei Zeng, Oleg Alienin,\n  Oleksandr Rokovyi, and Sergii Stirenko", "title": "Open Source Dataset and Machine Learning Techniques for Automatic\n  Recognition of Historical Graffiti", "comments": "11 pages, 9 figures, accepted for 25th International Conference on\n  Neural Information Processing (ICONIP 2018), 14-16 December, 2018 (Siem Reap,\n  Cambodia)", "journal-ref": "In: Cheng L., Leung A., Ozawa S. (eds) Neural Information\n  Processing. ICONIP 2018. Lecture Notes in Computer Science, vol. 11305, pp.\n  414-424. Springer, Cham", "doi": "10.1007/978-3-030-04221-9_37", "report-no": null, "categories": "cs.LG cs.CV cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning techniques are presented for automatic recognition of the\nhistorical letters (XI-XVIII centuries) carved on the stoned walls of St.Sophia\ncathedral in Kyiv (Ukraine). A new image dataset of these carved Glagolitic and\nCyrillic letters (CGCL) was assembled and pre-processed for recognition and\nprediction by machine learning methods. The dataset consists of more than 4000\nimages for 34 types of letters. The explanatory data analysis of CGCL and\nnotMNIST datasets shown that the carved letters can hardly be differentiated by\ndimensionality reduction methods, for example, by t-distributed stochastic\nneighbor embedding (tSNE) due to the worse letter representation by stone\ncarving in comparison to hand writing. The multinomial logistic regression\n(MLR) and a 2D convolutional neural network (CNN) models were applied. The MLR\nmodel demonstrated the area under curve (AUC) values for receiver operating\ncharacteristic (ROC) are not lower than 0.92 and 0.60 for notMNIST and CGCL,\nrespectively. The CNN model gave AUC values close to 0.99 for both notMNIST and\nCGCL (despite the much smaller size and quality of CGCL in comparison to\nnotMNIST) under condition of the high lossy data augmentation. CGCL dataset was\npublished to be available for the data science community as an open source\nresource.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 17:43:21 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Gordienko", "Nikita", ""], ["Gang", "Peng", ""], ["Gordienko", "Yuri", ""], ["Zeng", "Wei", ""], ["Alienin", "Oleg", ""], ["Rokovyi", "Oleksandr", ""], ["Stirenko", "Sergii", ""]]}]