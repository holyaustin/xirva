[{"id": "1801.00129", "submitter": "Marten Lohstroh", "authors": "Marten Lohstroh", "title": "Why the Equifax Breach Should Not Have Mattered", "comments": "Presented at the World Congress on Internet Security (WorldCIS) in\n  Cambridge, UK on Dec 12, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data security, which is concerned with the prevention of unauthorized access\nto computers, databases, and websites, helps protect digital privacy and ensure\ndata integrity. It is extremely difficult, however, to make security\nwatertight, and security breaches are not uncommon. The consequences of stolen\ncredentials go well beyond the leakage of other types of information because\nthey can further compromise other systems. This paper criticizes the practice\nof using clear-text identity attributes, such as Social Security or driver's\nlicense numbers -- which are in principle not even secret -- as acceptable\nauthentication tokens or assertions of ownership, and proposes a simple\nprotocol that straightforwardly applies public-key cryptography to make\nidentity claims verifiable, even when they are issued remotely via the\nInternet. This protocol has the potential of elevating the business practices\nof credit providers, rental agencies, and other service companies that have\nhitherto exposed consumers to the risk of identity theft, to where identity\ntheft becomes virtually impossible.\n", "versions": [{"version": "v1", "created": "Sat, 30 Dec 2017 12:57:06 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Lohstroh", "Marten", ""]]}, {"id": "1801.00317", "submitter": "Manoel Horta Ribeiro", "authors": "Manoel Horta Ribeiro, Pedro H. Calais, Yuri A. Santos, Virg\\'ilio A.\n  F. Almeida, Wagner Meira Jr", "title": "\"Like Sheep Among Wolves\": Characterizing Hateful Users on Twitter", "comments": "8 pages, 11 figures, to be presented at MIS2 Workshop @ WSDM'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hateful speech in Online Social Networks (OSNs) is a key challenge for\ncompanies and governments, as it impacts users and advertisers, and as several\ncountries have strict legislation against the practice. This has motivated work\non detecting and characterizing the phenomenon in tweets, social media posts\nand comments. However, these approaches face several shortcomings due to the\nnoisiness of OSN data, the sparsity of the phenomenon, and the subjectivity of\nthe definition of hate speech. This works presents a user-centric view of hate\nspeech, paving the way for better detection methods and understanding. We\ncollect a Twitter dataset of $100,386$ users along with up to $200$ tweets from\ntheir timelines with a random-walk-based crawler on the retweet graph, and\nselect a subsample of $4,972$ to be manually annotated as hateful or not\nthrough crowdsourcing. We examine the difference between user activity\npatterns, the content disseminated between hateful and normal users, and\nnetwork centrality measurements in the sampled graph. Our results show that\nhateful users have more recent account creation dates, and more statuses, and\nfollowees per day. Additionally, they favorite more tweets, tweet in shorter\nintervals and are more central in the retweet network, contradicting the \"lone\nwolf\" stereotype often associated with such behavior. Hateful users are more\nnegative, more profane, and use less words associated with topics such as hate,\nterrorism, violence and anger. We also identify similarities between\nhateful/normal users and their 1-neighborhood, suggesting strong homophily.\n", "versions": [{"version": "v1", "created": "Sun, 31 Dec 2017 17:08:14 GMT"}, {"version": "v2", "created": "Sun, 14 Jan 2018 15:21:13 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Ribeiro", "Manoel Horta", ""], ["Calais", "Pedro H.", ""], ["Santos", "Yuri A.", ""], ["Almeida", "Virg\u00edlio A. F.", ""], ["Meira", "Wagner", "Jr"]]}, {"id": "1801.00356", "submitter": "Amit Sheth", "authors": "Amit Sheth, Utkarshani Jaimini, Hong Yung Yip", "title": "How will the Internet of Things enable Augmented Personalized Health?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet-of-Things (IoT) is profoundly redefining the way we create, consume,\nand share information. Health aficionados and citizens are increasingly using\nIoT technologies to track their sleep, food intake, activity, vital body\nsignals, and other physiological observations. This is complemented by IoT\nsystems that continuously collect health-related data from the environment and\ninside the living quarters. Together, these have created an opportunity for a\nnew generation of healthcare solutions. However, interpreting data to\nunderstand an individual's health is challenging. It is usually necessary to\nlook at that individual's clinical record and behavioral information, as well\nas social and environmental information affecting that individual. Interpreting\nhow well a patient is doing also requires looking at his adherence to\nrespective health objectives, application of relevant clinical knowledge and\nthe desired outcomes.\n  We resort to the vision of Augmented Personalized Healthcare (APH) to exploit\nthe extensive variety of relevant data and medical knowledge using Artificial\nIntelligence (AI) techniques to extend and enhance human health to presents\nvarious stages of augmented health management strategies: self-monitoring,\nself-appraisal, self-management, intervention, and disease progress tracking\nand prediction. kHealth technology, a specific incarnation of APH, and its\napplication to Asthma and other diseases are used to provide illustrations and\ndiscuss alternatives for technology-assisted health management. Several\nprominent efforts involving IoT and patient-generated health data (PGHD) with\nrespect converting multimodal data into actionable information (big data to\nsmart data) are also identified. Roles of three components in an evidence-based\nsemantic perception approach- Contextualization, Abstraction, and\nPersonalization are discussed.\n", "versions": [{"version": "v1", "created": "Sun, 31 Dec 2017 21:18:16 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Sheth", "Amit", ""], ["Jaimini", "Utkarshani", ""], ["Yip", "Hong Yung", ""]]}, {"id": "1801.00528", "submitter": "Ronald Rivest", "authors": "Ronald L. Rivest", "title": "Bayesian Tabulation Audits: Explained and Extended", "comments": "49 pages, 3 figures Version 2 of the paper replaces use of the bare\n  Dirichlet model with the Dirichlet-multinomial, which is more standard and\n  works better in edge cases, such as when the sample is very large", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tabulation audits for an election provide statistical evidence that a\nreported contest outcome is \"correct\" (meaning that the tabulation of votes was\nproperly performed), or else the tabulation audit determines the correct\noutcome.\n  Stark proposed risk-limiting tabulation audits for this purpose; such audits\nare effective and are beginning to be used in practice.\n  We expand the study of election audits based on Bayesian methods, first\nintroduced by Rivest and Shen in 2012. (The risk-limiting audits proposed by\nStark are \"frequentist\" rather than Bayesian in character.)\n  We first provide a simplified presentation of Bayesian tabulation audits. A\nBayesian tabulation audit begins by drawing a random sample of the votes in\nthat contest, and tallying those votes. It then considers what effect\nstatistical variations of this tally have on the contest outcome. If such\nvariations almost always yield the previously-reported outcome, the audit\nterminates, accepting the reported outcome. Otherwise the audit is repeated\nwith an enlarged sample.\n  Bayesian audits are attractive because they work with any method for\ndetermining the winner (such as ranked-choice voting).\n  We then show how Bayesian audits may be extended to handle more complex\nsituations, such as auditing contests that \\emph{span multiple jurisdictions},\nor are otherwise \"stratified.\"\n  We highlight the auditing of such multiple-jurisdiction contests where some\nof the jurisdictions have an electronic cast vote record (CVR) for each cast\npaper vote, while the others do not. Complex situations such as this may arise\nnaturally when some counties in a state have upgraded to new equipment, while\nothers have not. Bayesian audits are able to handle such situations in a\nstraightforward manner.\n  We also discuss the benefits and relevant considerations for using Bayesian\naudits in practice.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jan 2018 00:00:15 GMT"}, {"version": "v2", "created": "Sun, 11 Feb 2018 23:41:18 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Rivest", "Ronald L.", ""]]}, {"id": "1801.00641", "submitter": "Xiao-Pu Han", "authors": "Pan Liu, Xiao-Pu Han, Linyuan L\\\"u", "title": "Triangle-mapping Analysis on Spatial Competition and Cooperation of\n  Chinese Cities", "comments": "The 43rd Annual Conference of the IEEE Industrial Electronics Society", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we empirically analyze the spatial distribution of Chinese\ncities using a method based on triangle transition. This method uses a regular\ntriangle mapping from the observed cities and its three neighboring cities to\nanalyze their distribution of mapping positions. We find that obvious\ncenter-gathering tendency for the relationship between cities and its nearest\nthree cities, indicating the spatial competition between cities. Moreover, we\nobserved the competitive trends between neighboring cities with similar\neconomic volume, and the remarkable cooperative tendency between neighboring\ncities with large difference on economy. The threshold of the ratio of the two\ncities' economic volume on the transition from competition to cooperation is\nabout 1.2. These findings are helpful in the understanding of the cities\neconomic relationship, especially in the study of competition and cooperation\nbetween cities.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jan 2018 13:38:00 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Liu", "Pan", ""], ["Han", "Xiao-Pu", ""], ["L\u00fc", "Linyuan", ""]]}, {"id": "1801.00779", "submitter": "Hao Li", "authors": "Zhijian Liu, Di Wu, Hongyu Wei, Guoqing Cao", "title": "Machine Learning for Building Energy and Indoor Environment: A\n  Perspective", "comments": "Submitted to a Interdisciplinary Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is a promising technique for many practical applications. In\nthis perspective, we illustrate the development and application for machine\nlearning. It is indicated that the theories and applications of machine\nlearning method in the field of energy conservation and indoor environment are\nnot mature, due to the difficulty of the determination for model structure with\nbetter prediction. In order to significantly contribute to the problems, we\nutilize the ANN model to predict the indoor culturable fungi concentration,\nwhich achieves the better accuracy and convenience. The proposal of hybrid\nmethod is further expand the application fields of machine learning method.\nFurther, ANN model based on HTS was successfully applied for the optimization\nof building energy system. We hope that this novel method could capture more\nattention from investigators via our introduction and perspective, due to its\npotential development with accuracy and reliability. However, its feasibility\nin other fields needs to be promoted further.\n", "versions": [{"version": "v1", "created": "Sun, 31 Dec 2017 02:06:30 GMT"}], "update_date": "2018-01-04", "authors_parsed": [["Liu", "Zhijian", ""], ["Wu", "Di", ""], ["Wei", "Hongyu", ""], ["Cao", "Guoqing", ""]]}, {"id": "1801.00912", "submitter": "Yun-Cheng Tsai", "authors": "Hsuan-Lei Shao, Sieh-Chuen Huang, Yun-Cheng Tsai", "title": "How the Taiwanese Do China Studies: Applications of Text Mining", "comments": "10 pages, 8 figures, 1 table", "journal-ref": "Journal of Data Mining & Digital Humanities, 2018 (May 4, 2018)\n  jdmdh:4470", "doi": "10.46298/jdmdh.4178", "report-no": null, "categories": "cs.DL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid evolution of cross-strait situation, \"Mainland China\" as a\nsubject of social science study has evoked the voice of \"Rethinking China\nStudy\" among intelligentsia recently. This essay tried to apply an automatic\ncontent analysis tool (CATAR) to the journal \"Mainland China Studies\"\n(1998-2015) in order to observe the research trends based on the clustering of\ntext from the title and abstract of each paper in the journal. The results\nshowed that the 473 articles published by the journal were clustered into seven\nsalient topics. From the publication number of each topic over time (including\n\"volume of publications\", \"percentage of publications\"), there are two major\ntopics of this journal while other topics varied over time widely. The\ncontribution of this study includes: 1. We could group each \"independent\" study\ninto a meaningful topic, as a small scale experiment verified that this topic\nclustering is feasible. 2. This essay reveals the salient research topics and\ntheir trends for the Taiwan journal \"Mainland China Studies\". 3. Various\ntopical keywords were identified, providing easy access to the past study. 4.\nThe yearly trends of the identified topics could be viewed as signature of\nfuture research directions.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jan 2018 06:18:14 GMT"}, {"version": "v2", "created": "Tue, 20 Mar 2018 00:53:27 GMT"}, {"version": "v3", "created": "Thu, 26 Apr 2018 08:32:10 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Shao", "Hsuan-Lei", ""], ["Huang", "Sieh-Chuen", ""], ["Tsai", "Yun-Cheng", ""]]}, {"id": "1801.01086", "submitter": "E. T. Tchao", "authors": "E. T. Tchao, Kwasi Diawuo, Christiana Selorm Aggor, Seth Djane Kotey", "title": "Ghanaian Consumers Online Privacy Concerns: Causes and its Effects on\n  E-Commerce Adoption", "comments": null, "journal-ref": null, "doi": "10.14569/IJACSA.2017.081120", "report-no": null, "categories": "cs.CY cs.NI cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Online privacy has gradually become a concern for internet users over the\nyears as a result of the interconnection of customers devices with other\ndevices supporting the internet technology. This research investigates and\ndiscusses the factors that influence the privacy concerns faced by online\nconsumers of internet services and the possible outcomes of these privacy\nconcerns on the African online market with Ghana being the primary focus.\nResults from this study indicated that only 10.1 percent of respondents felt\nthat the internet was safe for purchase and payment transaction in Ghana.\nHowever, respondents were willing to shop online if e-Commerce was the only\nmeans of getting their products. Respondents also had a high sense of perceived\nvulnerability and their perceived vulnerability to unauthorized data collection\nand misuse of personal information could affect Ghanaian e-Commerce platform\nadoption. The perceived ability of users of e-Commerce platforms in Ghana to\ncontrol data collection and its subsequent use by other third parties was also\nfound to negatively impact customers willingness to wholly transact and share\ntheir personal information online. The perceived vulnerability was found to be\naffected by the high levels of internet illiteracy whiles the perceived ability\nto control the collection of information and use was influenced by both the\ninternet literacy level as well as the level of social awareness of the\nGhanaian internet consumer.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 21:18:20 GMT"}], "update_date": "2018-01-04", "authors_parsed": [["Tchao", "E. T.", ""], ["Diawuo", "Kwasi", ""], ["Aggor", "Christiana Selorm", ""], ["Kotey", "Seth Djane", ""]]}, {"id": "1801.01921", "submitter": "Wenfei Xu", "authors": "Wenfei Xu (CARTO)", "title": "Urban Explorations: Analysis of Public Park Usage using Mobile GPS Data", "comments": "Presented at the Data For Good Exchange 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study analyzes mobile phone data derived from 10 million daily active\nusers across the United States to better understand the spatio-temporal\nactivity patterns of users in Central Park, New York. The aim of this initial\ninvestigation is to create quantifiable measures for understanding public space\nusage in regions of the city that have no natural data source for measuring\nactivity. We analyze the trip behaviors of users across time and different\nregions in the park to find patterns of co-location and shared time and, thus,\npotential social interaction. We find that regions with established amenities\nand points of interest exhibit a higher percentage of shared experiences,\nindicating that institutional amenities act as 'beacons' for users' experiences\nin the park.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 21:25:26 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Xu", "Wenfei", "", "CARTO"]]}, {"id": "1801.02027", "submitter": "Henry Kim", "authors": "Henry M. Kim, Marek Laskowski, Ning Nan", "title": "A First Step in the Co-Evolution of Blockchain and Ontologies: Towards\n  Engineering an Ontology of Governance at the Blockchain Protocol Level", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At the beginning of 2018, there is a growing belief that blockchain\ntechnologies constitute a revolutionary innovation in how we transfer value\nelectronically. In that vein, blockchain may be a suitable complement to\nontologies to achieve a big part of the vision of the semantic Web by Tim\nBerners-Lee. We believe that if this complementarity is to be achieved\nblockchain and ontologies must co-evolve. In this paper, we focus on what and\nhow to engineer models, methods, designs, and implementations for this\nco-evolution. As a first step in this co-evolution, we propose a conceptual\ndesign of a governance ontology represented as meta-data tags to be embedded\nand instantiated in a smart contract at the blockchain protocol level. We\ndevelop this design by examining and analyzing smart contracts from the\ninfamous The DAO experiment on the Ethereum blockchain. We believe there are\ntwo contributions of this paper: it serves to inform and implore the blockchain\nand ontology communities to recognize and collaborate with each other; and it\noutlines a roadmap for engineering artifacts to bridge the gap between\nblockchain community focus on protocol-level blockchain interoperability and\nthe ontology community focus on semantic-level interoperability.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jan 2018 15:02:13 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Kim", "Henry M.", ""], ["Laskowski", "Marek", ""], ["Nan", "Ning", ""]]}, {"id": "1801.02029", "submitter": "Henry Kim", "authors": "Henry Kim, Marek Laskowski", "title": "A Perspective on Blockchain Smart Contracts: Reducing Uncertainty and\n  Complexity in Value Exchange", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The blockchain constitutes a technology-based, rather than social or\nregulation based, means to lower uncertainty about one another in order to\nexchange value. However, its use may very well also lead to increased\ncomplexity resulting from having to subsume work that displaced intermediary\ninstitutions had performed. We present our perspective that smart contracts may\nbe used to mitigate this increased complexity. We further posit that smart\ncontracts can be delineated according to complexity: Smart contracts that can\nbe verified objectively without much uncertainty belong in an\ninter-organizational context; those that cannot be objectively verified belong\nin an intra-organizational context. We state that smart contracts that\nimplement a formal (e.g. mathematical or simulation) model are especially\nbeneficial for both contexts: They can be used to express and enforce\ninter-organizational agreements, and their basis in a common formalism may\nensure effective evaluation and comparison between different\nintra-organizational contracts. Finally, we present a case study of our\nperspective by describing Intellichain, which implements formal, agent-based\nsimulation model as a smart contract to provide epidemiological decision\nsupport.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jan 2018 15:08:50 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Kim", "Henry", ""], ["Laskowski", "Marek", ""]]}, {"id": "1801.02147", "submitter": "Lican Huang", "authors": "Lican Huang", "title": "Authorization Policies and Co-Operating Strategies of DSCloud Platform", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the services of DSCloud Platform is to provide the global directory\nservice to solve the problems of dispersed, difficult retrieved and isolated\ninformation. In this paper, we describe DSCloud Platform's authorization\npolicies and co-operating strategies for articles and comments, and usage\nscenery for co-editing posts and tables in the platform.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jan 2018 06:32:46 GMT"}, {"version": "v2", "created": "Sat, 13 Jan 2018 22:36:17 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Huang", "Lican", ""]]}, {"id": "1801.02383", "submitter": "Xianwen Wang", "authors": "Xianwen Wang, Yunxue Cui, Qingchun Li and Xinhui Guo", "title": "Social Media Attention Increases Article Visits: An Investigation on\n  Article-Level Referral Data of PeerJ", "comments": null, "journal-ref": "Frontiers in Research Metrics and Analytics, 2017", "doi": "10.3389/frma.2017.00011", "report-no": null, "categories": "cs.DL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to better understand the effect of social media in the dissemination\nof scholarly articles, employing the daily updated referral data of 110 PeerJ\narticles collected over a period of 345 days, we analyze the relationship\nbetween social media attention and article visitors directed by social media.\nOur results show that social media presence of PeerJ articles is high. About\n68.18% of the papers receive at least one tweet from Twitter accounts other\nthan @PeerJ, the official account of the journal. Social media attention\nincreases the dissemination of scholarly articles. Altmetrics could not only\nact as the complement of traditional citation measures but also play an\nimportant role in increasing the article downloads and promoting the impacts of\nscholarly articles. There also exists a significant correlation among the\nonline attention from different social media platforms. Articles with more\nFacebook shares tend to get more tweets. The temporal trends show that social\nattention comes immediately following publication but does not last long, so do\nthe social media directed article views.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 11:17:21 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Wang", "Xianwen", ""], ["Cui", "Yunxue", ""], ["Li", "Qingchun", ""], ["Guo", "Xinhui", ""]]}, {"id": "1801.02430", "submitter": "Mukhtiar Ali Unar Unar", "authors": "Shahram Najam Syed, Aamir Zeb Shaikh, Shabbar Naqvi", "title": "A Novel Hybrid Biometric Electronic Voting System: Integrating Finger\n  Print and Face Recognition", "comments": null, "journal-ref": "Mehran University Research Journal of Engineering and Technology,\n  Mehran University Research Journal of Engineering and Technology, 2018, 37\n  (1), pp.59-68.\n  http://publications.muet.edu.pk/index.php/muetrj/article/view/100/50", "doi": null, "report-no": null, "categories": "cs.CR cs.CY q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel hybrid design based electronic voting system is proposed, implemented\nand analyzed. The proposed system uses two voter verification techniques to\ngive better results in comparison to single identification based systems.\nFinger print and facial recognition based methods are used for voter\nidentification. Cross verification of a voter during an election process\nprovides better accuracy than single parameter identification method. The\nfacial recognition system uses Viola-Jones algorithm along with rectangular\nHaar feature selection method for detection and extraction of features to\ndevelop a biometric template and for feature extraction during the voting\nprocess. Cascaded machine learning based classifiers are used for comparing the\nfeatures for identity verification using GPCA (Generalized Principle Component\nAnalysis) and K-NN (K-Nearest Neighbor). It is accomplished through comparing\nthe Eigen-vectors of the extracted features with the biometric template\npre-stored in the election regulatory body database. The results of the\nproposed system show that the proposed cascaded design based system performs\nbetter than the systems using other classifiers or separate schemes i.e. facial\nor finger print based schemes. The proposed system will be highly useful for\nreal time applications due to the reason that it has 91% accuracy under nominal\nlight in terms of facial recognition. with bags of paper votes. The central\nstation compiles and publishes the names of winners and losers through\ntelevision and radio stations. This method is useful only if the whole process\nis completed in a transparent way. However, there are some drawbacks to this\nsystem. These include higher expenses, longer time to complete the voting\nprocess, fraudulent practices by the authorities administering elections as\nwell as malpractices by the voters [1]. These challenges result in manipulated\nelection results.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 07:57:29 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Syed", "Shahram Najam", ""], ["Shaikh", "Aamir Zeb", ""], ["Naqvi", "Shabbar", ""]]}, {"id": "1801.02507", "submitter": "Primavera De Filippi", "authors": "Primavera De Filippi (CERSA), Samer Hassan (UCM)", "title": "Blockchain Technology as a Regulatory Technology: From Code is Law to\n  Law is Code", "comments": null, "journal-ref": "First Monday, University of Illinois at Chicago Library, 2016", "doi": null, "report-no": null, "categories": "cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Code is law\" refers to the idea that, with the advent of digital technology,\ncode has progressively established itself as the predominant way to regulate\nthe behavior of Internet users. Yet, while computer code can enforce rules more\nefficiently than legal code, it also comes with a series of limitations, mostly\nbecause it is difficult to transpose the ambiguity and flexibility of legal\nrules into a formalized language which can be interpreted by a machine. With\nthe advent of blockchain technology and associated smart contracts, code is\nassuming an even stronger role in regulating people's interactions over the\nInternet, as many contractual transactions get transposed into smart contract\ncode. In this paper, we describe the shift from the traditional notion of \"code\nis law\" (i.e. code having the effect of law) to the new conception of \"law is\ncode\" (i.e. law being defined as code).\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 15:33:51 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["De Filippi", "Primavera", "", "CERSA"], ["Hassan", "Samer", "", "UCM"]]}, {"id": "1801.02672", "submitter": "Amit Chopra", "authors": "Munindar P. Singh and Amit K. Chopra", "title": "Violable Contracts and Governance for Blockchain Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine blockchain technologies, especially smart contracts, as a platform\nfor decentralized applications. By providing a basis for consensus, blockchain\npromises to upend business models that presuppose a central authority. However,\nblockchain suffers from major shortcomings arising from an over-regimented way\nof organizing computation that limits its prospects. We propose a\nsociotechnical, yet computational, perspective that avoids those shortcomings.\nA centerpiece of our vision is the notion of a declarative, violable contract\nin contradistinction to smart contracts. This new way of thinking enables\nflexible governance, by formalizing organizational structures; verification of\ncorrectness without obstructing autonomy; and a meaningful basis for trust.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 20:12:51 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["Singh", "Munindar P.", ""], ["Chopra", "Amit K.", ""]]}, {"id": "1801.03529", "submitter": "Safeeullah Soomro", "authors": "Nareena Soomro and Safeeullah Soomro", "title": "Autism Children's App using PECS", "comments": "Volume 2 Number 1", "journal-ref": "Annals of Emerging Technologies in Computing (AETiC) , 2018", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since autistic children suffers from learning disabilities and communication\nbarriers, this research aim to design, develop and evaluate an Android based\nmobile application (app) providing better learning environment with inclusion\nof graphical representation in a cost effective manner. This research evaluate\nvarious supporting technologies and finds Picture Exchange Communication System\n(PECS) to be better choice for integrating with the app. Evaluation results\nreveal that the inclusion of PECS helped the children suffering from Autistic\nSpectrum Disorder (ASD) to better communicate with others. The study included\nautistic children who do not speak, who are unintelligible and who are\nminimally effective communicators with their present communication system. The\nevolution results showed encouraging impacts of the Autism App in supporting\nautistic children to adapt to normal life and improve the standard of their\nlife.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 09:48:20 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Soomro", "Nareena", ""], ["Soomro", "Safeeullah", ""]]}, {"id": "1801.03533", "submitter": "Manish Raghavan", "authors": "Jon Kleinberg, Manish Raghavan", "title": "Selection Problems in the Presence of Implicit Bias", "comments": "ITCS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past two decades, the notion of implicit bias has come to serve as\nan important component in our understanding of discrimination in activities\nsuch as hiring, promotion, and school admissions. Research on implicit bias\nposits that when people evaluate others -- for example, in a hiring context --\ntheir unconscious biases about membership in particular groups can have an\neffect on their decision-making, even when they have no deliberate intention to\ndiscriminate against members of these groups. A growing body of experimental\nwork has pointed to the effect that implicit bias can have in producing adverse\noutcomes.\n  Here we propose a theoretical model for studying the effects of implicit bias\non selection decisions, and a way of analyzing possible procedural remedies for\nimplicit bias within this model. A canonical situation represented by our model\nis a hiring setting: a recruiting committee is trying to choose a set of\nfinalists to interview among the applicants for a job, evaluating these\napplicants based on their future potential, but their estimates of potential\nare skewed by implicit bias against members of one group. In this model, we\nshow that measures such as the Rooney Rule, a requirement that at least one of\nthe finalists be chosen from the affected group, can not only improve the\nrepresentation of this affected group, but also lead to higher payoffs in\nabsolute terms for the organization performing the recruiting. However,\nidentifying the conditions under which such measures can lead to improved\npayoffs involves subtle trade-offs between the extent of the bias and the\nunderlying distribution of applicant characteristics, leading to novel\ntheoretical questions about order statistics in the presence of probabilistic\nside information.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jan 2018 06:53:58 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Kleinberg", "Jon", ""], ["Raghavan", "Manish", ""]]}, {"id": "1801.03604", "submitter": "Chandra Khatri", "authors": "Ashwin Ram, Rohit Prasad, Chandra Khatri, Anu Venkatesh, Raefer\n  Gabriel, Qing Liu, Jeff Nunn, Behnam Hedayatnia, Ming Cheng, Ashish Nagar,\n  Eric King, Kate Bland, Amanda Wartick, Yi Pan, Han Song, Sk Jayadevan, Gene\n  Hwang, Art Pettigrue", "title": "Conversational AI: The Science Behind the Alexa Prize", "comments": "18 pages, 5 figures, Alexa Prize Proceedings Paper\n  (https://developer.amazon.com/alexaprize/proceedings), Alexa Prize University\n  Competition to advance Conversational AI", "journal-ref": "Alexa.Prize.Proceedings\n  https://developer.amazon.com/alexaprize/proceedings accessed (2018)-01-01", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CY cs.HC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational agents are exploding in popularity. However, much work remains\nin the area of social conversation as well as free-form conversation over a\nbroad range of domains and topics. To advance the state of the art in\nconversational AI, Amazon launched the Alexa Prize, a 2.5-million-dollar\nuniversity competition where sixteen selected university teams were challenged\nto build conversational agents, known as socialbots, to converse coherently and\nengagingly with humans on popular topics such as Sports, Politics,\nEntertainment, Fashion and Technology for 20 minutes. The Alexa Prize offers\nthe academic community a unique opportunity to perform research with a live\nsystem used by millions of users. The competition provided university teams\nwith real user conversational data at scale, along with the user-provided\nratings and feedback augmented with annotations by the Alexa team. This enabled\nteams to effectively iterate and make improvements throughout the competition\nwhile being evaluated in real-time through live user interactions. To build\ntheir socialbots, university teams combined state-of-the-art techniques with\nnovel strategies in the areas of Natural Language Understanding, Context\nModeling, Dialog Management, Response Generation, and Knowledge Acquisition. To\nsupport the efforts of participating teams, the Alexa Prize team made\nsignificant scientific and engineering investments to build and improve\nConversational Speech Recognition, Topic Tracking, Dialog Evaluation, Voice\nUser Experience, and tools for traffic management and scalability. This paper\noutlines the advances created by the university teams as well as the Alexa\nPrize team to achieve the common goal of solving the problem of Conversational\nAI.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 01:23:50 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Ram", "Ashwin", ""], ["Prasad", "Rohit", ""], ["Khatri", "Chandra", ""], ["Venkatesh", "Anu", ""], ["Gabriel", "Raefer", ""], ["Liu", "Qing", ""], ["Nunn", "Jeff", ""], ["Hedayatnia", "Behnam", ""], ["Cheng", "Ming", ""], ["Nagar", "Ashish", ""], ["King", "Eric", ""], ["Bland", "Kate", ""], ["Wartick", "Amanda", ""], ["Pan", "Yi", ""], ["Song", "Han", ""], ["Jayadevan", "Sk", ""], ["Hwang", "Gene", ""], ["Pettigrue", "Art", ""]]}, {"id": "1801.03622", "submitter": "Chandra Khatri", "authors": "Fenfei Guo, Angeliki Metallinou, Chandra Khatri, Anirudh Raju, Anu\n  Venkatesh, Ashwin Ram", "title": "Topic-based Evaluation for Conversational Bots", "comments": "10 Pages, 2 figures, 9 tables. NIPS 2017 Conversational AI workshop\n  paper.\n  http://alborz-geramifard.com/workshops/nips17-Conversational-AI/Main.html", "journal-ref": "Nips.Workshop.ConversationalAI 2017-12-08", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.HC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialog evaluation is a challenging problem, especially for non task-oriented\ndialogs where conversational success is not well-defined. We propose to\nevaluate dialog quality using topic-based metrics that describe the ability of\na conversational bot to sustain coherent and engaging conversations on a topic,\nand the diversity of topics that a bot can handle. To detect conversation\ntopics per utterance, we adopt Deep Average Networks (DAN) and train a topic\nclassifier on a variety of question and query data categorized into multiple\ntopics. We propose a novel extension to DAN by adding a topic-word attention\ntable that allows the system to jointly capture topic keywords in an utterance\nand perform topic classification. We compare our proposed topic based metrics\nwith the ratings provided by users and show that our metrics both correlate\nwith and complement human judgment. Our analysis is performed on tens of\nthousands of real human-bot dialogs from the Alexa Prize competition and\nhighlights user expectations for conversational bots.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 03:20:02 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Guo", "Fenfei", ""], ["Metallinou", "Angeliki", ""], ["Khatri", "Chandra", ""], ["Raju", "Anirudh", ""], ["Venkatesh", "Anu", ""], ["Ram", "Ashwin", ""]]}, {"id": "1801.03625", "submitter": "Chandra Khatri", "authors": "Anu Venkatesh, Chandra Khatri, Ashwin Ram, Fenfei Guo, Raefer Gabriel,\n  Ashish Nagar, Rohit Prasad, Ming Cheng, Behnam Hedayatnia, Angeliki\n  Metallinou, Rahul Goel, Shaohua Yang, Anirudh Raju", "title": "On Evaluating and Comparing Open Domain Dialog Systems", "comments": "10 pages, 5 tables. NIPS 2017 Conversational AI workshop.\n  http://alborz-geramifard.com/workshops/nips17-Conversational-AI/Main.html", "journal-ref": "NIPS.Workshop.ConversationalAI 2017-12-08\n  http://alborz-geramifard.com/workshops/nips17-Conversational-AI/Main.html\n  accessed 2018-01-01", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.HC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational agents are exploding in popularity. However, much work remains\nin the area of non goal-oriented conversations, despite significant growth in\nresearch interest over recent years. To advance the state of the art in\nconversational AI, Amazon launched the Alexa Prize, a 2.5-million dollar\nuniversity competition where sixteen selected university teams built\nconversational agents to deliver the best social conversational experience.\nAlexa Prize provided the academic community with the unique opportunity to\nperform research with a live system used by millions of users. The subjectivity\nassociated with evaluating conversations is key element underlying the\nchallenge of building non-goal oriented dialogue systems. In this paper, we\npropose a comprehensive evaluation strategy with multiple metrics designed to\nreduce subjectivity by selecting metrics which correlate well with human\njudgement. The proposed metrics provide granular analysis of the conversational\nagents, which is not captured in human ratings. We show that these metrics can\nbe used as a reasonable proxy for human judgment. We provide a mechanism to\nunify the metrics for selecting the top performing agents, which has also been\napplied throughout the Alexa Prize competition. To our knowledge, to date it is\nthe largest setting for evaluating agents with millions of conversations and\nhundreds of thousands of ratings from users. We believe that this work is a\nstep towards an automatic evaluation process for conversational AIs.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 03:30:00 GMT"}, {"version": "v2", "created": "Wed, 26 Dec 2018 20:15:08 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Venkatesh", "Anu", ""], ["Khatri", "Chandra", ""], ["Ram", "Ashwin", ""], ["Guo", "Fenfei", ""], ["Gabriel", "Raefer", ""], ["Nagar", "Ashish", ""], ["Prasad", "Rohit", ""], ["Cheng", "Ming", ""], ["Hedayatnia", "Behnam", ""], ["Metallinou", "Angeliki", ""], ["Goel", "Rahul", ""], ["Yang", "Shaohua", ""], ["Raju", "Anirudh", ""]]}, {"id": "1801.03648", "submitter": "Xavier Vilajosana", "authors": "Xavier Vilajosana, Cristina Cano, Borja Martinez, Pere Tuset, Joan\n  Meli\\`a, Ferran Adelantado", "title": "The Wireless Technology Landscape in the Manufacturing Industry: A\n  Reality Check", "comments": "5 pages", "journal-ref": "MMTC Communications - Frontiers, SPECIAL ISSUE ON Multiple\n  Wireless Technologies and IoT in Industry: Applications and Challenges, Vol.\n  12, No. 6, November 2017", "doi": null, "report-no": "01-A", "categories": "cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An upcoming industrial IoT revolution, supposedly led by the introduction of\nembedded sensing and computing, seamless communication and massive data\nanalytics within industrial processes [1], seems unquestionable today. Multiple\ntechnologies are being developed, and huge marketing efforts are being made to\nposition solutions in this industrial landscape. However, we have observed that\nindustrial wireless technologies are hardly being adopted by the manufacturing\nindustry. In this article, we try to understand the reasons behind this current\nlack of wireless technologies adoption by means of conducting visits to the\nmanufacturing industry and interviews with the maintenance and engineering\nteams in these industries. The manufacturing industry is very diverse and\nspecialized, so we have tried to cover some of the most representative cases:\nthe automotive sector, the pharmaceutical sector (blistering), machine-tool\nindustries (both consumer and aerospace sectors) and robotics. We have analyzed\nthe technology of their machinery, their application requirements and\nrestrictions, and identified a list of obstacles for wireless technology\nadoption. The most immediate obstacles we have found are the need to strictly\nfollow standards and certifications processes, as well as their prudence. But\nthe less obvious and perhaps even more limiting obstacles are their apparent\nlack of concern regarding low energy consumption or cost which, in contrast,\nare believed to be of utmost importance by wireless researchers and\npractitioners. In this reality-check article, we analyze the causes of this\ndifferent perception, we identify these obstacles and devise complementary\npaths to make wireless adoption by the industrial manufacturing sector a\nreality in the coming years.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 07:34:46 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Vilajosana", "Xavier", ""], ["Cano", "Cristina", ""], ["Martinez", "Borja", ""], ["Tuset", "Pere", ""], ["Meli\u00e0", "Joan", ""], ["Adelantado", "Ferran", ""]]}, {"id": "1801.04267", "submitter": "Luiz Capretz Dr.", "authors": "Muasaad Alrasheedi, Luiz Fernando Capretz, Arif Raza", "title": "Management's Perspective on Critical Success Factors Affecting Mobile\n  Learning in Higher Education Institutions - An Empirical Study", "comments": null, "journal-ref": "Volume 2015, pp. 1-22", "doi": "10.1177/0735633115620387", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile learning (m-Learning) is considered to be one of the fastest growing\nlearning platforms. The immense interest in m-Learning is attributed to the\nincredible rate of growth of mobile technology and its proliferation into every\naspect of modern life. Despite this, m-Learning has not experienced a similar\nadoption rate in the education sector, chiefly higher education. Researchers\nhave attempted to explain this anomaly by conducting several studies in the\narea. However, mostly the research in m-Learning is examined from the\nperspective of the students and educators. In this research, it is contended\nthat there is a third important stakeholder group whose opinion is equally\nimportant in determining the success of m-Learning: the university management.\nAlthough diversified by nature, heads of departments, deans, and IT system\nadministrators are nevertheless considered members of any university\nmanagement. The results of the research show that university commitment to\nm-Learning, university learning practices, and change management practices were\nthe factors critical to the success of m-Learning, from the university\nmanagement perspective.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jan 2018 18:57:10 GMT"}], "update_date": "2018-01-15", "authors_parsed": [["Alrasheedi", "Muasaad", ""], ["Capretz", "Luiz Fernando", ""], ["Raza", "Arif", ""]]}, {"id": "1801.04288", "submitter": "Luiz Capretz Dr.", "authors": "Muasaad Alrasheedi and Luiz Fernando Capretz", "title": "Determination of Critical Success Factors Affecting Mobile Learning: A\n  Meta-Analysis Approach", "comments": "41-51", "journal-ref": "Turkish Online Journal of Educational Technology, 14(2):41-51,\n  April 2015", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With rapid technological advancements, mobile learning (m-Learning) offers\nincredible opportunities, especially in the area of higher education. However,\nwhile interest in this area has been significant and several pilot studies have\nbeen conducted within universities, relatively less is known about how higher\neducational institutions can make efficient use of the m-Learning platform to\nsupport teaching and learning. Although there are numerous studies in the area,\nthe lack of this insight is mostly due to the fact that very little effort has\nbeen made to collate these studies and determine a common set of key success\nfactors that affect the acceptance of m-Learning within universities. This\nstudy conducts a systematic analysis of several studies conducted in the area\nof m-Learning to assess the critical success factors, by making use of the\nmeta-analysis technique. Our investigation has shown that the most important\nperceived advantages of m-Learning, from learner perspectives, are\ncollaboration during studies, the prospect of ubiquitous learning in space and\ntime, and user friendly application design.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jan 2018 19:02:17 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Alrasheedi", "Muasaad", ""], ["Capretz", "Luiz Fernando", ""]]}, {"id": "1801.04385", "submitter": "Kristina Lerman", "authors": "Nazanin Alipourfard, Peter G. Fennell, Kristina Lerman", "title": "Can you Trust the Trend: Discovering Simpson's Paradoxes in Social Data", "comments": "to appear in the Proceedings of WSDM-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate how Simpson's paradox affects analysis of trends in social\ndata. According to the paradox, the trends observed in data that has been\naggregated over an entire population may be different from, and even opposite\nto, those of the underlying subgroups. Failure to take this effect into account\ncan lead analysis to wrong conclusions. We present a statistical method to\nautomatically identify Simpson's paradox in data by comparing statistical\ntrends in the aggregate data to those in the disaggregated subgroups. We apply\nthe approach to data from Stack Exchange, a popular question-answering\nplatform, to analyze factors affecting answerer performance, specifically, the\nlikelihood that an answer written by a user will be accepted by the asker as\nthe best answer to his or her question. Our analysis confirms a known Simpson's\nparadox and identifies several new instances. These paradoxes provide novel\ninsights into user behavior on Stack Exchange.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jan 2018 05:49:23 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Alipourfard", "Nazanin", ""], ["Fennell", "Peter G.", ""], ["Lerman", "Kristina", ""]]}, {"id": "1801.04433", "submitter": "Heri Ramampiaro", "authors": "Georgios K. Pitsilis and Heri Ramampiaro and Helge Langseth", "title": "Detecting Offensive Language in Tweets Using Deep Learning", "comments": null, "journal-ref": "Applied Intelligence, 48(12), 4730-4742 (2018)", "doi": "10.1007/s10489-018-1242-y", "report-no": null, "categories": "cs.CL cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the important problem of discerning hateful content in\nsocial media. We propose a detection scheme that is an ensemble of Recurrent\nNeural Network (RNN) classifiers, and it incorporates various features\nassociated with user-related information, such as the users' tendency towards\nracism or sexism. These data are fed as input to the above classifiers along\nwith the word frequency vectors derived from the textual content. Our approach\nhas been evaluated on a publicly available corpus of 16k tweets, and the\nresults demonstrate its effectiveness in comparison to existing state of the\nart solutions. More specifically, our scheme can successfully distinguish\nracism and sexism messages from normal text, and achieve higher classification\nquality than current state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jan 2018 12:58:43 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Pitsilis", "Georgios K.", ""], ["Ramampiaro", "Heri", ""], ["Langseth", "Helge", ""]]}, {"id": "1801.04437", "submitter": "Rodrigo Costas", "authors": "Rodrigo Costas", "title": "Towards the social media studies of science: social media metrics,\n  present and future", "comments": "Spanish version:\n  http://revistas.bnjm.cu/index.php/anales/article/view/4172", "journal-ref": "Bibliotecas. Anales de Investigacion. 2017. 13(1), 1-5", "doi": null, "report-no": null, "categories": "cs.DL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we aim at providing a general reflection around the present and\nfuture of social media metrics (or altmetrics) and how they could evolve into a\nnew discipline focused on the study of the relationships and interactions\nbetween science and social media, in what could be seen as the social media\nstudies of science.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jan 2018 13:26:06 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Costas", "Rodrigo", ""]]}, {"id": "1801.04857", "submitter": "David Skillicorn", "authors": "D.B. Skillicorn, R. Billingsley, M.-A. Williams", "title": "The Design Space of Social Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the design space available for social robots in terms of a\nhierarchy of functional definitions: the essential properties in terms of a\nlocus of interaction, autonomy, intelligence, awareness of humans as possessors\nof mental state, and awareness of humans as social interactors. We also suggest\nthat the emphasis on physical embodiment in some segments of the social\nrobotics community has obscured commonalities with a class of agents that are\nidentical in all other respects. These definitions naturally suggest research\nissues, directions, and possibilities which we explore. Social robotics also\nlacks compelling 'killer apps' which we suggest would help focus the community\non a research agenda.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 16:01:57 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Skillicorn", "D. B.", ""], ["Billingsley", "R.", ""], ["Williams", "M. -A.", ""]]}, {"id": "1801.04966", "submitter": "Vahid Ahmadi", "authors": "Vahid Ahmadi", "title": "Algebraic Specifications of Wayfinding Using Cognitive Map", "comments": "I just realized that this paper has some similarities with another\n  paper of someone that I worked with and I did not know it was published\n  before. I believe it should not be online anymore. Sorry for any\n  inconvenience", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper outlines the formal representation of the environment in which it\nis assumed that a wayfinding process has been occurred through a street\nnetwork. Wayfinding is a process in which people navigate themselves from an\norigin to a destination by their common sense geospatial knowledge. Na\\\"ive\nGeography is a field of study that investigates the body of knowledge that\npeople have about the surrounding geospatial world and it deals with common\nsense knowledge of space. The image schemas which are needed for wayfinding\nwith boundary relations method have been extracted and represented formally\nwith algebraic specifications. These specifications are mentioned in the syntax\nof a functional programming language, Haskell. It allows us to execute written\nalgebraic specifications and provide conditions for rapid prototyping and\nformal checks on consistency. These formal specifications are implemented for\nmodeling street network of a part of Tehran, Capital city of Iran.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 19:53:24 GMT"}, {"version": "v2", "created": "Mon, 15 Oct 2018 01:19:10 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Ahmadi", "Vahid", ""]]}, {"id": "1801.05047", "submitter": "Anabel Quan-Haase", "authors": "Isioma Elueze, Anabel Quan-Haase", "title": "Privacy attitudes and concerns in the digital lives of older adults:\n  Westin's privacy attitude typology revisited", "comments": "39 pages, 2 tables, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  There is a growing literature on teenage and young adult users' attitudes\ntoward and concerns about online privacy, yet little is known about older\nadults and their unique experiences. As older adults join the digital world in\ngrowing numbers, we need to gain a better understanding of how they experience\nand navigate online privacy. This paper fills this research gap by examining 40\nin-depth interviews with older adults (65 and older) living in East York,\nToronto. We found Westin's typology to be a useful starting point for\nunderstanding privacy attitudes and concerns in this demographic. We expand\nWestin's typology and distinguish five categories: fundamentalist, intense\npragmatist, relaxed pragmatist, marginally concerned, and cynical expert. We\nfind that older adults are not a homogenous group composed of privacy\nfundamentalists; rather, there is considerable variability in terms of their\nprivacy attitudes, with only 13 per cent being fundamentalists. We also\nidentify a group of cynical experts who believe that online privacy breaches\nare inevitable. A large majority of older adults are marginally concerned, as\nthey see their online participation as limited and harmless. Older adults were\nalso grouped as either intense or relaxed pragmatists. We find that some\nprivacy concerns are shared by older adults across several categories, the most\ncommon being spam, unauthorized access to personal information, and information\nmisuse. We discuss theoretical implications based on the findings for our\nunderstanding of privacy in the context of older adults' digital lives and\ndiscuss implications for offering training appropriate for enhancing privacy\nliteracy in this age group.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 22:12:37 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Elueze", "Isioma", ""], ["Quan-Haase", "Anabel", ""]]}, {"id": "1801.05088", "submitter": "Chandra Khatri", "authors": "Chandra Khatri", "title": "Real-time Road Traffic Information Detection Through Social Media", "comments": "138 Pages, 21 Figures, 15 Tables. Masters Thesis in Computational\n  Science & Engineering Group @ Georgia Tech.\n  https://smartech.gatech.edu/bitstream/handle/1853/53889/KHATRI-THESIS-2015.pdf.\n  arXiv admin note: text overlap with arXiv:1703.03921 by other author", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In current study, a mechanism to extract traffic related information such as\ncongestion and incidents from textual data from the internet is proposed. The\ncurrent source of data is Twitter. As the data being considered is extremely\nlarge in size automated models are developed to stream, download, and mine the\ndata in real-time. Furthermore, if any tweet has traffic related information\nthen the models should be able to infer and extract this data.\n  Currently, the data is collected only for United States and a total of\n120,000 geo-tagged traffic related tweets are extracted, while six million\ngeo-tagged non-traffic related tweets are retrieved and classification models\nare trained. Furthermore, this data is used for various kinds of spatial and\ntemporal analysis. A mechanism to calculate level of traffic congestion,\nsafety, and traffic perception for cities in U.S. is proposed. Traffic\ncongestion and safety rankings for the various urban areas are obtained and\nthen they are statistically validated with existing widely adopted rankings.\nTraffic perception depicts the attitude and perception of people towards the\ntraffic.\n  It is also seen that traffic related data when visualized spatially and\ntemporally provides the same pattern as the actual traffic flows for various\nurban areas. When visualized at the city level, it is clearly visible that the\nflow of tweets is similar to flow of vehicles and that the traffic related\ntweets are representative of traffic within the cities. With all the findings\nin current study, it is shown that significant amount of traffic related\ninformation can be extracted from Twitter and other sources on internet.\nFurthermore, Twitter and these data sources are freely available and are not\nbound by spatial and temporal limitations. That is, wherever there is a user\nthere is a potential for data.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 01:26:33 GMT"}], "update_date": "2018-01-20", "authors_parsed": [["Khatri", "Chandra", ""]]}, {"id": "1801.05236", "submitter": "Joshua Gardner", "authors": "Josh Gardner, Christopher Brooks, Juan Miguel L. Andres, Ryan Baker", "title": "MORF: A Framework for Predictive Modeling and Replication At Scale With\n  Privacy-Restricted MOOC Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big data repositories from online learning platforms such as Massive Open\nOnline Courses (MOOCs) represent an unprecedented opportunity to advance\nresearch on education at scale and impact a global population of learners. To\ndate, such research has been hindered by poor reproducibility and a lack of\nreplication, largely due to three types of barriers: experimental, inferential,\nand data. We present a novel system for large-scale computational research, the\nMOOC Replication Framework (MORF), to jointly address these barriers. We\ndiscuss MORF's architecture, an open-source platform-as-a-service (PaaS) which\nincludes a simple, flexible software API providing for multiple modes of\nresearch (predictive modeling or production rule analysis) integrated with a\nhigh-performance computing environment. All experiments conducted on MORF use\nexecutable Docker containers which ensure complete reproducibility while\nallowing for the use of any software or language which can be installed in the\nlinux-based Docker container. Each experimental artifact is assigned a DOI and\nmade publicly available. MORF has the potential to accelerate and democratize\nresearch on its massive data repository, which currently includes over 200\nMOOCs, as demonstrated by initial research conducted on the platform. We also\nhighlight ways in which MORF represents a solution template to a more general\nclass of problems faced by computational researchers in other domains.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 13:06:12 GMT"}, {"version": "v2", "created": "Wed, 17 Jan 2018 13:10:38 GMT"}, {"version": "v3", "created": "Tue, 21 Aug 2018 22:16:21 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Gardner", "Josh", ""], ["Brooks", "Christopher", ""], ["Andres", "Juan Miguel L.", ""], ["Baker", "Ryan", ""]]}, {"id": "1801.05313", "submitter": "Subhashis Banerjee", "authors": "Subhashis Banerjee", "title": "Authorisation and access control architecture as a framework for data\n  and privacy protection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy protection in digital databases does not demand that data should not\nbe collected, stored or used, but that there should be guarantees that the data\ncan only be used for pre-approved and legitimate purposes. We argue that a data\nprotection law based on traditional understanding of privacy protection and\ndetection of privacy infringements is unlikely to be successful, and that what\nis required is a law based on an understanding of the architectural\nrequirements of authorisation, audit and access control in real-time. Despite\nthe protection principles being sound, privacy protection in digital databases\nhas been less than effective, anywhere, mainly because of weak enforcement\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 15:40:32 GMT"}, {"version": "v2", "created": "Thu, 18 Jan 2018 12:09:45 GMT"}, {"version": "v3", "created": "Sat, 27 Jan 2018 07:10:49 GMT"}, {"version": "v4", "created": "Mon, 16 Apr 2018 10:06:10 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Banerjee", "Subhashis", ""]]}, {"id": "1801.05564", "submitter": "Pablo Su\\'arez-Serrato", "authors": "E. Gallagher, P. Su\\'arez-Serrato, E.I. Velazquez Richards", "title": "Socialbots whitewashing contested elections; a case study from Honduras", "comments": null, "journal-ref": "Third International Congress on Information and Communication\n  Technology. Advances in Intelligent Systems and Computing, vol 797 (2019)", "doi": "10.1007/978-981-13-1165-9_50", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We analyze socialbots active tweeting in relation to Juan Orlando\nHern\\'andez, the recently re-elected president of Honduras. We find a clear\nbimodal separation between humans and bots, using Botometer and its\nclassifiers. Around one hundred separate communities of socialbots are\nidentified and visualized, detected through the analysis of temporally\ncoordinated retweets.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jan 2018 06:03:43 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Gallagher", "E.", ""], ["Su\u00e1rez-Serrato", "P.", ""], ["Richards", "E. I. Velazquez", ""]]}, {"id": "1801.05617", "submitter": "Gilles Jacobs", "authors": "Cynthia Van Hee, Gilles Jacobs, Chris Emmery, Bart Desmet, Els\n  Lefever, Ben Verhoeven, Guy De Pauw, Walter Daelemans and V\\'eronique Hoste", "title": "Automatic Detection of Cyberbullying in Social Media Text", "comments": "21 pages, 9 tables, under review", "journal-ref": null, "doi": "10.1371/journal.pone.0203794", "report-no": null, "categories": "cs.CL cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While social media offer great communication opportunities, they also\nincrease the vulnerability of young people to threatening situations online.\nRecent studies report that cyberbullying constitutes a growing problem among\nyoungsters. Successful prevention depends on the adequate detection of\npotentially harmful messages and the information overload on the Web requires\nintelligent systems to identify potential risks automatically. The focus of\nthis paper is on automatic cyberbullying detection in social media text by\nmodelling posts written by bullies, victims, and bystanders of online bullying.\nWe describe the collection and fine-grained annotation of a training corpus for\nEnglish and Dutch and perform a series of binary classification experiments to\ndetermine the feasibility of automatic cyberbullying detection. We make use of\nlinear support vector machines exploiting a rich feature set and investigate\nwhich information sources contribute the most for this particular task.\nExperiments on a holdout test set reveal promising results for the detection of\ncyberbullying-related posts. After optimisation of the hyperparameters, the\nclassifier yields an F1-score of 64% and 61% for English and Dutch\nrespectively, and considerably outperforms baseline systems based on keywords\nand word unigrams.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jan 2018 10:38:20 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Van Hee", "Cynthia", ""], ["Jacobs", "Gilles", ""], ["Emmery", "Chris", ""], ["Desmet", "Bart", ""], ["Lefever", "Els", ""], ["Verhoeven", "Ben", ""], ["De Pauw", "Guy", ""], ["Daelemans", "Walter", ""], ["Hoste", "V\u00e9ronique", ""]]}, {"id": "1801.05734", "submitter": "Xiao-Long Ren", "authors": "Leilei Wu, Zhuoming Ren, Xiao-Long Ren, Jianlin Zhang, Linyuan L\\\"u", "title": "Eliminating the effect of rating bias on reputation systems", "comments": "13 pages, 5 figures. All the authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY cs.IR cs.SI econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ongoing rapid development of the e-commercial and interest-base websites\nmake it more pressing to evaluate objects' accurate quality before\nrecommendation by employing an effective reputation system. The objects'\nquality are often calculated based on their historical information, such as\nselected records or rating scores, to help visitors to make decisions before\nwatching, reading or buying. Usually high quality products obtain a higher\naverage ratings than low quality products regardless of rating biases or\nerrors. However many empirical cases demonstrate that consumers may be misled\nby rating scores added by unreliable users or deliberate tampering. In this\ncase, users' reputation, i.e., the ability to rating trustily and precisely,\nmake a big difference during the evaluating process. Thus, one of the main\nchallenges in designing reputation systems is eliminating the effects of users'\nrating bias on the evaluation results. To give an objective evaluation of each\nuser's reputation and uncover an object's intrinsic quality, we propose an\niterative balance (IB) method to correct users' rating biases. Experiments on\ntwo online video-provided Web sites, namely MovieLens and Netflix datasets,\nshow that the IB method is a highly self-consistent and robust algorithm and it\ncan accurately quantify movies' actual quality and users' stability of rating.\nCompared with existing methods, the IB method has higher ability to find the\n\"dark horses\", i.e., not so popular yet good movies, in the Academy Awards.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jan 2018 16:24:03 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Wu", "Leilei", ""], ["Ren", "Zhuoming", ""], ["Ren", "Xiao-Long", ""], ["Zhang", "Jianlin", ""], ["L\u00fc", "Linyuan", ""]]}, {"id": "1801.05796", "submitter": "Ladislau B\\\"ol\\\"oni", "authors": "Ladislau B\\\"ol\\\"oni, Taranjeet Singh Bhatia, Saad Ahmad Khan, Jonathan\n  Streater and Stephen M. Fiore", "title": "Towards a computational model of social norms", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0195331", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a computational model of social norms based on identifying values\nthat a certain culture finds desirable such as dignity, generosity and\npoliteness. The model quantifies these values in the form of Culture-Sanctioned\nSocial Metrics (CSSMs) and treats social norms as the requirement to maximize\nthese metrics from the perspective of the self, peers and public. This model\ncan be used to create realistic social simulations, to explain or predict human\nbehavior in specific scenarios, or as a component of robots or agents that need\nto interact with humans in specific social-cultural settings. We validate the\nmodel by using it to represent a complex deception scenario and showing that it\ncan yield non-trivial insights such as the explanation of apparently irrational\nhuman behavior.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jan 2018 18:45:54 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["B\u00f6l\u00f6ni", "Ladislau", ""], ["Bhatia", "Taranjeet Singh", ""], ["Khan", "Saad Ahmad", ""], ["Streater", "Jonathan", ""], ["Fiore", "Stephen M.", ""]]}, {"id": "1801.05802", "submitter": "Abdallah El Ali", "authors": "Abdallah El Ali, Tim C Stratmann, Souneil Park, Johannes Sch\\\"oning,\n  Wilko Heuten, Susanne CJ Boll", "title": "Measuring, Understanding, and Classifying News Media Sympathy on Twitter\n  after Crisis Events", "comments": "In Proc. CHI 2018 Papers program. Please cite: El Ali, A., Stratmann,\n  T., Park, S., Sch\\\"oning, J., Heuten, W. & Boll, S. (2018). Measuring,\n  Understanding, and Classifying News Media Sympathy on Twitter after Crisis\n  Events. In Proceedings of the 2018 CHI Conference on Human Factors in\n  Computing Systems (CHI '18). ACM, New York, NY, USA. DOI:\n  https://doi.org/10.1145/3173574.3174130", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates bias in coverage between Western and Arab media on\nTwitter after the November 2015 Beirut and Paris terror attacks. Using two\nTwitter datasets covering each attack, we investigate how Western and Arab\nmedia differed in coverage bias, sympathy bias, and resulting information\npropagation. We crowdsourced sympathy and sentiment labels for 2,390 tweets\nacross four languages (English, Arabic, French, German), built a regression\nmodel to characterize sympathy, and thereafter trained a deep convolutional\nneural network to predict sympathy. Key findings show: (a) both events were\ndisproportionately covered (b) Western media exhibited less sympathy, where\neach media coverage was more sympathetic towards the country affected in their\nrespective region (c) Sympathy predictions supported ground truth analysis that\nWestern media was less sympathetic than Arab media (d) Sympathetic tweets do\nnot spread any further. We discuss our results in light of global news flow,\nTwitter affordances, and public perception impact.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 19:19:46 GMT"}, {"version": "v2", "created": "Thu, 15 Mar 2018 11:11:05 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Ali", "Abdallah El", ""], ["Stratmann", "Tim C", ""], ["Park", "Souneil", ""], ["Sch\u00f6ning", "Johannes", ""], ["Heuten", "Wilko", ""], ["Boll", "Susanne CJ", ""]]}, {"id": "1801.05831", "submitter": "Peter Krafft", "authors": "Peter M Krafft, Nicol\\'as Della Penna, Alex Pentland", "title": "An Experimental Study of Cryptocurrency Market Dynamics", "comments": "CHI 2018", "journal-ref": "Peter Krafft, Nicol\\'as Della Penna, Alex Pentland. (2018). An\n  Experimental Study of Cryptocurrency Market Dynamics. ACM CHI Conference on\n  Human Factors in Computing Systems (CHI)", "doi": "10.1145/3173574.3174179", "report-no": null, "categories": "cs.CY cs.HC cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As cryptocurrencies gain popularity and credibility, marketplaces for\ncryptocurrencies are growing in importance. Understanding the dynamics of these\nmarkets can help to assess how viable the cryptocurrnency ecosystem is and how\ndesign choices affect market behavior. One existential threat to\ncryptocurrencies is dramatic fluctuations in traders' willingness to buy or\nsell. Using a novel experimental methodology, we conducted an online experiment\nto study how susceptible traders in these markets are to peer influence from\ntrading behavior. We created bots that executed over one hundred thousand\ntrades costing less than a penny each in 217 cryptocurrencies over the course\nof six months. We find that individual \"buy\" actions led to short-term\nincreases in subsequent buy-side activity hundreds of times the size of our\ninterventions. From a design perspective, we note that the design choices of\nthe exchange we study may have promoted this and other peer influence effects,\nwhich highlights the potential social and economic impact of HCI in the design\nof digital institutions.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jan 2018 19:17:20 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2018 16:08:31 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Krafft", "Peter M", ""], ["Della Penna", "Nicol\u00e1s", ""], ["Pentland", "Alex", ""]]}, {"id": "1801.05916", "submitter": "Shuhua Liu", "authors": "Shuhua Monica Liu (1), Liting Pan (1), Xiaowei Chen (1) ((1)\n  Department of Public Administration, Fudan University, Shanghai, China)", "title": "Citation Analysis of Innovative ICT and Advances of Governance\n  (2008-2017)", "comments": "Corrected first author's name spelling and added authors' affiliation\n  in the metadata", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper opens by introducing the Internet Plus Government (IPG), a new\ngovernment initiative emerging in the last decade. To understand benefits and\nchallenges associated with this initiative worldwide, we conducted analyses on\nresearch articles published in the e-governance area between 2008 and 2017.\nContent analysis and citation analysis were performed on 2105 articles to\naddress three questions: (1) What types of new ICT have been adopted in the IPG\ninitiative in the past decade? (2) How did scholars investigate interactions\nbetween the new ICTs and governance core to IPG? (3) How did the new ICTs\ninteract and shape while also being shaped by the evolution of governance in\nthe past decade? Our analysis suggests that IPG initiative has enriched the\ngovernment information infrastructure. It presented opportunities to accumulate\nand use huge volume of data for better decision making and proactive\ngovernment-citizen interaction. At the same time, the advance of open data, the\nwidespread use of social media and the potential of data analytics also\ngenerated great pressure to address challenging questions and issues in the\ndomain of e-democracy.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jan 2018 02:57:25 GMT"}, {"version": "v2", "created": "Wed, 24 Jan 2018 12:32:25 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Liu", "Shuhua Monica", ""], ["Pan", "Liting", ""], ["Chen", "Xiaowei", ""]]}, {"id": "1801.06043", "submitter": "Sam Ganzfried", "authors": "Sam Ganzfried, Farzana Yusuf", "title": "Optimal Weighting for Exam Composition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A problem faced by many instructors is that of designing exams that\naccurately assess the abilities of the students. Typically these exams are\nprepared several days in advance, and generic question scores are used based on\nrough approximation of the question difficulty and length. For example, for a\nrecent class taught by the author, there were 30 multiple choice questions\nworth 3 points, 15 true/false with explanation questions worth 4 points, and 5\nanalytical exercises worth 10 points. We describe a novel framework where\nalgorithms from machine learning are used to modify the exam question weights\nin order to optimize the exam scores, using the overall class grade as a proxy\nfor a student's true ability. We show that significant error reduction can be\nobtained by our approach over standard weighting schemes, and we make several\nnew observations regarding the properties of the \"good\" and \"bad\" exam\nquestions that can have impact on the design of improved future evaluation\nmethods.\n", "versions": [{"version": "v1", "created": "Sun, 24 Dec 2017 05:35:47 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Ganzfried", "Sam", ""], ["Yusuf", "Farzana", ""]]}, {"id": "1801.06044", "submitter": "Liu Feng", "authors": "Feng Liu, Yong Shi, Peijia Lia", "title": "Analysis of the Relation between Artificial Intelligence and the\n  Internet from the Perspective of Brain Science", "comments": "6 pages,3 figures", "journal-ref": null, "doi": "10.1016/j.procs.2017.11.383", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) like deep learning, cloud AI computation has\nbeen advancing at a rapid pace since 2014. There is no doubt that the\nprosperity of AI is inseparable with the development of the Internet. However,\nthere has been little attention to the link between AI and the internet. This\npaper explores them with brain insights mainly from four views:1) How is the\ngeneral relation between artificial intelligence and Internet of Things, cloud\ncomputing, big data and Industrial Internet from the perspective of brain\nscience. 2) Construction of a new AI system model with the Internet and brain\nscience.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jan 2018 15:19:52 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Liu", "Feng", ""], ["Shi", "Yong", ""], ["Lia", "Peijia", ""]]}, {"id": "1801.06047", "submitter": "Christopher Birster", "authors": "Christopher A. Birster", "title": "Engagement in Foundational Computer Science Courses Through\n  Supplementary Content for Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Engaging students in teaching foundational Computer Science concepts is vital\nfor the student's continual success in more advanced topics in the field. An\nidea of a series of Jupyter notebooks was conceived as a way of using Bloom's\nTaxonomy to reinforce concepts taught in an introductory algorithms class. The\nidea of the notebook is to keep the student's engaged in the lesson and in turn\nmotivate them to persevere through the end of the course.\n", "versions": [{"version": "v1", "created": "Fri, 29 Dec 2017 16:38:41 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Birster", "Christopher A.", ""]]}, {"id": "1801.06048", "submitter": "Yuri G. Gordienko", "authors": "Yuri Gordienko, Sergii Stirenko, Yuriy Kochura, Oleg Alienin, Michail\n  Novotarskiy, Nikita Gordienko", "title": "Deep Learning for Fatigue Estimation on the Basis of Multimodal\n  Human-Machine Interactions", "comments": "12 pages, 10 figures, 1 table; presented at XXIX IUPAP Conference in\n  Computational Physics (CCP2017) July 9-13, 2017, Paris, University Pierre et\n  Marie Curie - Sorbonne (https://ccp2017.sciencesconf.org/program)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The new method is proposed to monitor the level of current physical load and\naccumulated fatigue by several objective and subjective characteristics. It was\napplied to the dataset targeted to estimate the physical load and fatigue by\nseveral statistical and machine learning methods. The data from peripheral\nsensors (accelerometer, GPS, gyroscope, magnetometer) and brain-computing\ninterface (electroencephalography) were collected, integrated, and analyzed by\nseveral statistical and machine learning methods (moment analysis, cluster\nanalysis, principal component analysis, etc.). The hypothesis 1 was presented\nand proved that physical activity can be classified not only by objective\nparameters, but by subjective parameters also. The hypothesis 2 (experienced\nphysical load and subsequent restoration as fatigue level can be estimated\nquantitatively and distinctive patterns can be recognized) was presented and\nsome ways to prove it were demonstrated. Several \"physical load\" and \"fatigue\"\nmetrics were proposed. The results presented allow to extend application of the\nmachine learning methods for characterization of complex human activity\npatterns (for example, to estimate their actual physical load and fatigue, and\ngive cautions and advice).\n", "versions": [{"version": "v1", "created": "Sat, 30 Dec 2017 17:49:03 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Gordienko", "Yuri", ""], ["Stirenko", "Sergii", ""], ["Kochura", "Yuriy", ""], ["Alienin", "Oleg", ""], ["Novotarskiy", "Michail", ""], ["Gordienko", "Nikita", ""]]}, {"id": "1801.06049", "submitter": "Jiaqi Cai", "authors": "Jiaqi Cai", "title": "Effects of Home Resources and School Environment on Eighth-Grade\n  Mathematics Achievement in Taiwan", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY physics.ed-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decades, researchers have explored the relationship among home\nresources, school environment, and students' mathematics achievement in a large\namount of studies. Many of them suggested that rich home resources for learning\nwere related to higher average academic achievement. Some also suggested that\nthe home background was closely associated with the learning environment, and\ntherefore, influenced students' achievements. Thus, this study hypothesized\nthat students who own more home resources would perform better than students\nwho possess fewer resources and that schools that have more socioeconomically\nadvantaged students, located in high-income neighborhoods, and possess more\ninstructional resources would have better mathematics performance. The study\nfocuses on eighth graders in Taiwan and explores the variance in mathematics\nachievement of students as a function of student and school level differences.\n", "versions": [{"version": "v1", "created": "Sun, 31 Dec 2017 00:56:56 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Cai", "Jiaqi", ""]]}, {"id": "1801.06050", "submitter": "Konstantinos Chorianopoulos", "authors": "Konstantinos Chorianopoulos", "title": "A taxonomy of video lecture styles", "comments": "14 pages, 5 figures", "journal-ref": "International Review of Research in Open and Distributed Learning,\n  19 (1) (2018)", "doi": "10.19173/irrodl.v19i1.2920", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many educational organizations are employing instructional video in their\npedagogy, but there is limited understanding of the possible presentation\nstyles. In practice, the presentation style of video lectures ranges from a\ndirect recording of classroom teaching with a stationary camera and screencasts\nwith voice-over, up to highly elaborate video post-production. Previous work\nevaluated the effectiveness of several presentation styles, but there has not\nbeen any consistent taxonomy, which would have made comparisons and\nmeta-analyses possible. In this article, we surveyed the research literature\nand we examined contemporary video-based courses, which have been produced by\ndiverse educational organizations and teachers across various academic\ndisciplines. We organized video lectures in two dimensions according to the\nlevel of human presence and according to the type of instructional media. In\naddition to organizing existing video lectures in a comprehensive way, the\nproposed taxonomy offers a design space that facilitates the choice of a\nsuitable presentation style, as well as the preparation of new ones.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jan 2018 22:20:58 GMT"}, {"version": "v2", "created": "Sun, 29 Dec 2019 10:11:47 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Chorianopoulos", "Konstantinos", ""]]}, {"id": "1801.06052", "submitter": "Amal Alblowie S", "authors": "Amal S. Alblawi", "title": "Big Data and Learning Analytics in Higher Education: Demystifying\n  Variety, Acquisition, Storage, NLP and Analytics", "comments": "6 pages , 2017 IEEE Conference on Big Data and Analytics (ICBDA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different sectors have sought to take advantage of opportunities to invest in\nbig data analytics and Natural language processing, in order to improve their\nproductivity and competitiveness. Current challenges facing the higher\neducation sector include a rapidly changing and evolving environment, which\nnecessitates the development of new ways of thinking. Interest has therefore\nincreased in analytics as part of the solution to many issues in higher\neducation, including the rate of student attrition and learner support. This\nstudy provides a comprehensive discussion of big data, learning analytics and\nuse of NLP in higher education. In addition, it introduces an integrated\nlearning analytics solution leveraging a distributed technology system capable\nof supporting academic authorities and advisors at educational institutions in\nmaking decisions concerning individual students.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jan 2018 22:26:17 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Alblawi", "Amal S.", ""]]}, {"id": "1801.06053", "submitter": "Shahriar Movafaghi Ph.D.", "authors": "Shahriar Movafaghi, Hassan Pournaghshband", "title": "Lab Based Curriculum for CIS and Related Technology", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The Computer Information System (CIS) is information and communication\ntechnology in support of business processes. In this paper, we present a\ntypical undergraduate computer information system curriculum examining the\ndegree of lab intensity and its effect on the course efficacy. A CIS program is\nusually part of the school of business as it is in support of business\nprocesses. We also explore the differences between a CIS curriculum and other\ncomputer related technology courses, such as Information Technology (IT),\nComputer Science (CS), and Software Engineering (SE). The curriculum is\ncomposed of several elements such as content and sequence of subjects,\nclassrooms equipped with computer projection, internet, and local network\naccess, and appropriate computing and software infrastructure. We will focus on\nthe importance and adequacy of labs for the CIS curriculum. The proposed CIS\ncurriculum works for a 4-year as well as a 3-year program. This paper provides\na recommendation for local and Federal Accreditation agencies and curriculum\ncommittees.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jan 2018 17:43:20 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Movafaghi", "Shahriar", ""], ["Pournaghshband", "Hassan", ""]]}, {"id": "1801.06055", "submitter": "Philipp M\\\"uller", "authors": "Philipp M\\\"uller, Michael Xuelin Huang, Andreas Bulling", "title": "Detecting Low Rapport During Natural Interactions in Small Groups from\n  Non-Verbal Behaviour", "comments": "12 pages, 6 figures", "journal-ref": "Proc. of the ACM International Conference on Intelligent User\n  Interfaces (2018) 153-164", "doi": "10.1145/3172944.3172969", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapport, the close and harmonious relationship in which interaction partners\nare \"in sync\" with each other, was shown to result in smoother social\ninteractions, improved collaboration, and improved interpersonal outcomes. In\nthis work, we are first to investigate automatic prediction of low rapport\nduring natural interactions within small groups. This task is challenging given\nthat rapport only manifests in subtle non-verbal signals that are, in addition,\nsubject to influences of group dynamics as well as inter-personal\nidiosyncrasies. We record videos of unscripted discussions of three to four\npeople using a multi-view camera system and microphones. We analyse a rich set\nof non-verbal signals for rapport detection, namely facial expressions, hand\nmotion, gaze, speaker turns, and speech prosody. Using facial features, we can\ndetect low rapport with an average precision of 0.7 (chance level at 0.25),\nwhile incorporating prior knowledge of participants' personalities can even\nachieve early prediction without a drop in performance. We further provide a\ndetailed analysis of different feature sets and the amount of information\ncontained in different temporal segments of the interactions.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 22:15:56 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["M\u00fcller", "Philipp", ""], ["Huang", "Michael Xuelin", ""], ["Bulling", "Andreas", ""]]}, {"id": "1801.06059", "submitter": "Muthiah Annamalai", "authors": "Muthiah Annamalai, T Shrinivasan", "title": "Tamil Open-Source Landscape - Opportunities and Challenges", "comments": "Tamil Internet Conference (INFITT) 2017, Toronto, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report in this paper, Tamil open-source software community is a vibrant\nplace with software developers, font designers, translators, voice-over\nartists, and general user testers, who come together for love of their\nlanguage, and promotion of critical thinking, and modern language usage in\nTamil. We identify a need for institutional support at various stages from\ngrooming software developers in Tamil, to marketing platform for Tamil\nsoftware. There is bright future for tamil software if we will meet challenges\nit brings with it.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 05:29:48 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Annamalai", "Muthiah", ""], ["Shrinivasan", "T", ""]]}, {"id": "1801.06368", "submitter": "Huy Kang Kim", "authors": "Eunjo Lee, Jiyoung Woo, Hyoungshick Kim, Huy Kang Kim", "title": "No Silk Road for Online Gamers!: Using Social Network Analysis to Unveil\n  Black Markets in Online Games", "comments": "10 pages, 11 figures, In Proceedings of the 27th International World\n  Wide Web Conference (WWW) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online game involves a very large number of users who are interconnected and\ninteract with each other via the Internet. We studied the characteristics of\nexchanging virtual goods with real money through processes called \"real money\ntrading (RMT).\" This exchange might influence online game user behaviors and\ncause damage to the reputation of game companies. We examined in-game\ntransactions to reveal RMT by constructing a social graph of virtual goods\nexchanges in an online game and identifying network communities of users.\n  We analyzed approximately 6,000,000 transactions in a popular online game and\ninferred RMT transactions by comparing the RMT transactions crawled from an\nout-game market. Our findings are summarized as follows: (1) the size of the\nRMT market could be approximately estimated; (2) professional RMT providers\ntypically form a specific network structure (either star-shape or chain) in the\ntrading network, which can be used as a clue for tracing RMT transactions; and\n(3) the observed RMT market has evolved over time into a monopolized market\nwith a small number of large-sized virtual goods providers.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 11:18:02 GMT"}], "update_date": "2018-01-22", "authors_parsed": [["Lee", "Eunjo", ""], ["Woo", "Jiyoung", ""], ["Kim", "Hyoungshick", ""], ["Kim", "Huy Kang", ""]]}, {"id": "1801.06400", "submitter": "Aydar Negimatzhanov", "authors": "Rinat Khatipov, Manuel Mazzara, Aydar Negimatzhanov, Victor Rivera,\n  Anvar Zakirov, Ilgiz Zamaleev", "title": "Hikester - the event management application", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today social networks and services are one of the most important part of our\neveryday life. Most of the daily activities, such as communicating with\nfriends, reading news or dating is usually done using social networks. However,\nthere are activities for which social networks do not yet provide adequate\nsupport. This paper focuses on event management and introduces \"Hikester\". The\nmain objective of this service is to provide users with the possibility to\ncreate any event they desire and to invite other users. \"Hikester\" supports the\ncreation and management of events like attendance of football matches, quest\nrooms, shared train rides or visit of museums in foreign countries. Here we\ndiscuss the project architecture as well as the detailed implementation of the\nsystem components: the recommender system, the spam recognition service and the\nparameters optimizer.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 13:37:03 GMT"}], "update_date": "2018-01-22", "authors_parsed": [["Khatipov", "Rinat", ""], ["Mazzara", "Manuel", ""], ["Negimatzhanov", "Aydar", ""], ["Rivera", "Victor", ""], ["Zakirov", "Anvar", ""], ["Zamaleev", "Ilgiz", ""]]}, {"id": "1801.06495", "submitter": "Yuri G. Gordienko", "authors": "Yu.Gordienko, Yu.Kochura, O.Alienin, O. Rokovyi, S. Stirenko, Peng\n  Gang, Jiang Hui, Wei Zeng", "title": "Dimensionality Reduction in Deep Learning for Chest X-Ray Analysis of\n  Lung Cancer", "comments": "6 pages, 14 figures", "journal-ref": "2018 Tenth International Conference on Advanced Computational\n  Intelligence (ICACI), Xiamen, 2018, pp. 878-883", "doi": "10.1109/ICACI.2018.8377579", "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficiency of some dimensionality reduction techniques, like lung\nsegmentation, bone shadow exclusion, and t-distributed stochastic neighbor\nembedding (t-SNE) for exclusion of outliers, is estimated for analysis of chest\nX-ray (CXR) 2D images by deep learning approach to help radiologists identify\nmarks of lung cancer in CXR. Training and validation of the simple\nconvolutional neural network (CNN) was performed on the open JSRT dataset\n(dataset #01), the JSRT after bone shadow exclusion - BSE-JSRT (dataset #02),\nJSRT after lung segmentation (dataset #03), BSE-JSRT after lung segmentation\n(dataset #04), and segmented BSE-JSRT after exclusion of outliers by t-SNE\nmethod (dataset #05). The results demonstrate that the pre-processed dataset\nobtained after lung segmentation, bone shadow exclusion, and filtering out the\noutliers by t-SNE (dataset #05) demonstrates the highest training rate and best\naccuracy in comparison to the other pre-processed datasets.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 17:15:25 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Gordienko", "Yu.", ""], ["Kochura", "Yu.", ""], ["Alienin", "O.", ""], ["Rokovyi", "O.", ""], ["Stirenko", "S.", ""], ["Gang", "Peng", ""], ["Hui", "Jiang", ""], ["Zeng", "Wei", ""]]}, {"id": "1801.06540", "submitter": "Santanu Bhattacharya", "authors": "Kabir Rustogi, Santanu Bhattacharya, Margaret Church and Ramesh Raskar", "title": "What is the right addressing scheme for India?", "comments": "6 pages, 5 figures and 3 tables. Published in the MIT Emerging Worlds\n  Site", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer generated addresses are coming to your neighborhood because most\nplaces in the world do not have an assigned meaningful street address. In\nIndia, 80% of the addresses are written with respect to a landmark which\ntypically lies between 50-1500 meters of the actual address; such addresses\nmake geolocating very challenging. Accuracy in geolocation is critical for\nemergency services to navigate quickly to reach you and for logistics\nindustries to improve on-time performance and efficient routing of the package\ncoming to your house. In this paper, we explore suggested addressing schemes\nfor India, to determine what use cases and potential technologies will have the\nbest adoption and therefore, greatest impact.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jan 2018 03:34:18 GMT"}, {"version": "v2", "created": "Sun, 28 Jan 2018 07:08:48 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Rustogi", "Kabir", ""], ["Bhattacharya", "Santanu", ""], ["Church", "Margaret", ""], ["Raskar", "Ramesh", ""]]}, {"id": "1801.06771", "submitter": "Kenji Saito", "authors": "Kenji Saito and Mitsuru Iwamura", "title": "How to Make a Digital Currency on a Blockchain Stable", "comments": "27 pages, 13 figures", "journal-ref": "Future Generation Computer Systems, Volume 100, 2019, Pages 58-69", "doi": "10.1016/j.future.2019.05.019", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin and other similar digital currencies on blockchains are not ideal\nmeans for payment, because their prices tend to go up in the long term (thus\npeople are incentivized to hoard those currencies), and to fluctuate widely in\nthe short term (thus people would want to avoid risks of losing values). The\nreason why those blockchain currencies based on proof of work are unstable may\nbe found in their designs that the supplies of currencies do not respond to\ntheir positive and negative demand shocks, as the authors have formulated in\nour past work. Continuing from our past work, this paper proposes minimal\nchanges to the design of blockchain currencies so that their market prices are\nautomatically stabilized, absorbing both positive and negative demand shocks of\nthe currencies by autonomously controlling their supplies. Those changes are:\n1) limiting re-adjustment of proof-of-work targets, 2) making mining rewards\nvariable according to the observed over-threshold changes of block intervals,\nand 3) enforcing negative interests to remove old coins in circulation. We have\nmade basic design checks and evaluations of these measures through simple\nsimulations. In addition to stabilization of prices, the proposed measures may\nhave effects of making those currencies preferred means for payment by\ndisincentivizing hoarding, and improving sustainability of the currency systems\nby making rewards to miners perpetual.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jan 2018 06:03:01 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 07:15:15 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Saito", "Kenji", ""], ["Iwamura", "Mitsuru", ""]]}, {"id": "1801.06863", "submitter": "Robert Gorwa", "authors": "Robert Gorwa, Douglas Guilbeault", "title": "Unpacking the Social Media Bot: A Typology to Guide Research and Policy", "comments": "Pre-publication version: please consult the final for page numbers\n  and references", "journal-ref": "Policy & Internet 2018", "doi": "10.1002/poi3.184", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Amidst widespread reports of digital influence operations during major\nelections, policymakers, scholars, and journalists have become increasingly\ninterested in the political impact of social media 'bots.' Most recently,\nplatform companies like Facebook and Twitter have been summoned to testify\nabout bots as part of investigations into digitally-enabled foreign\nmanipulation during the 2016 US Presidential election. Facing mounting pressure\nfrom both the public and from legislators, these companies have been instructed\nto crack down on apparently malicious bot accounts. But as this article\ndemonstrates, since the earliest writings on bots in the 1990s, there has been\nsubstantial confusion as to exactly what a 'bot' is and what exactly a bot\ndoes. We argue that multiple forms of ambiguity are responsible for much of the\ncomplexity underlying contemporary bot-related policy, and that before\nsuccessful policy interventions can be formulated, a more comprehensive\nunderstanding of bots --- especially how they are defined and measured --- will\nbe needed. In this article, we provide a history and typology of different\ntypes of bots, provide clear guidelines to better categorize political\nautomation and unpack the impact that it can have on contemporary technology\npolicy, and outline the main challenges and ambiguities that will face both\nresearchers and legislators concerned with bots in the future.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jan 2018 17:53:39 GMT"}, {"version": "v2", "created": "Sat, 28 Jul 2018 16:42:04 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Gorwa", "Robert", ""], ["Guilbeault", "Douglas", ""]]}, {"id": "1801.07011", "submitter": "Simon Gottschalk", "authors": "Simon Gottschalk, Elena Demidova, Viola Bernacchi, Richard Rogers", "title": "Ongoing Events in Wikipedia: A Cross-lingual Case Study", "comments": "Proceedings of the 2017 ACM on Web Science Conference", "journal-ref": null, "doi": "10.1145/3091478.3098879", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to effectively analyze information regarding ongoing events that\nimpact local communities across language and country borders, researchers often\nneed to perform multilingual data analysis. This analysis can be particularly\nchallenging due to the rapidly evolving event-centric data and the language\nbarrier. In this abstract we present preliminary results of a case study with\nthe goal to better understand how researchers interact with multilingual\nevent-centric information in the context of cross-cultural studies and which\nmethods and features they use.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 09:51:36 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Gottschalk", "Simon", ""], ["Demidova", "Elena", ""], ["Bernacchi", "Viola", ""], ["Rogers", "Richard", ""]]}, {"id": "1801.07138", "submitter": "Juli\\`a Minguill\\'on", "authors": "Juli\\`a Minguill\\'on, Eduard Aibar, Maura Lerga, Josep Llad\\'os,\n  Antoni Meseguer-Artola", "title": "Wikipedia in academia as a teaching tool: from averse to proactive\n  faculty profiles", "comments": "16 pages, 1 figure, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study concerned the active use of Wikipedia as a teaching tool in the\nclassroom in higher education, trying to identify different usage profiles and\ntheir characterization. A questionnaire survey was administrated to all\nfull-time and part-time teachers at the Universitat Oberta de Catalunya and the\nUniversitat Pompeu Fabra, both in Barcelona, Spain. The questionnaire was\ndesigned using the Technology Acceptance Model as a reference, including items\nabout teachers web 2.0 profile, Wikipedia usage, expertise, perceived\nusefulness, easiness of use, visibility and quality, as well as Wikipedia\nstatus among colleagues and incentives to use it more actively. Clustering and\nstatistical analysis were carried out using the k-medoids algorithm and\ndifferences between clusters were assessed by means of contingency tables and\ngeneralized linear models (logit). The respondents were classified in four\nclusters, from less to more likely to adopt and use Wikipedia in the classroom,\nnamely averse (25.4%), reluctant (17.9%), open (29.5%) and proactive (27.2%).\nProactive faculty are mostly men teaching part-time in STEM fields, mainly\nengineering, while averse faculty are mostly women teaching full-time in\nnon-STEM fields. Nevertheless, questionnaire items related to visibility,\nquality, image, usefulness and expertise determine the main differences between\nclusters, rather than age, gender or domain. Clusters involving a positive view\nof Wikipedia and at least some frequency of use clearly outnumber those with a\nstrictly negative stance. This goes against the common view that faculty\nmembers are mostly sceptical about Wikipedia. Environmental factors such as\nacademic culture and colleagues opinion are more important than faculty\npersonal characteristics, especially with respect to what they think about\nWikipedia quality.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 15:34:38 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Minguill\u00f3n", "Juli\u00e0", ""], ["Aibar", "Eduard", ""], ["Lerga", "Maura", ""], ["Llad\u00f3s", "Josep", ""], ["Meseguer-Artola", "Antoni", ""]]}, {"id": "1801.07168", "submitter": "Lachlan Urquhart Ph.D", "authors": "Lachlan Urquhart, Tom Lodge, Andy Crabtree", "title": "Demonstrably Doing Accountability in the Internet of Things", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the importance of accountability to data protection, and\nhow it can be built into the Internet of Things (IoT). The need to build\naccountability into the IoT is motivated by the opaque nature of distributed\ndata flows, inadequate consent mechanisms, and lack of interfaces enabling\nend-user control over the behaviours of internet-enabled devices. The lack of\naccountability precludes meaningful engagement by end-users with their personal\ndata and poses a key challenge to creating user trust in the IoT and the\nreciprocal development of the digital economy. The EU General Data Protection\nRegulation 2016 (GDPR) seeks to remedy this particular problem by mandating\nthat a rapidly developing technological ecosystem be made accountable. In doing\nso it foregrounds new responsibilities for data controllers, including data\nprotection by design and default, and new data subject rights such as the right\nto data portability. While GDPR is technologically neutral, it is nevertheless\nanticipated that realising the vision will turn upon effective technological\ndevelopment. Accordingly, this paper examines the notion of accountability, how\nit has been translated into systems design recommendations for the IoT, and how\nthe IoT Databox puts key data protection principles into practice.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 16:12:19 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Urquhart", "Lachlan", ""], ["Lodge", "Tom", ""], ["Crabtree", "Andy", ""]]}, {"id": "1801.07185", "submitter": "Lachlan Urquhart Ph.D", "authors": "Lachlan Urquhart", "title": "White Noise from the White Goods? Conceptual and Empirical Perspectives\n  on Ambient Domestic Computing", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within this chapter we consider the emergence of ambient domestic computing\nsystems, both conceptually and empirically. We critically assess visions of\npost-desktop computing, paying particular attention to one contemporary trend:\nthe internet of things (IoT). We examine the contested nature of this term,\nlooking at the historical trajectory of similar technologies, and the\nregulatory issues they can pose, particularly in the home. We also look to the\nemerging regulatory solution of privacy by design, unpacking practical\nchallenges it faces. The novelty of our contribution stems from a turn to\npractice through a set of empirical perspectives. We present findings that\ndocument the practical experiences and viewpoints of leading experts in\ntechnology law and design.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 16:30:51 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Urquhart", "Lachlan", ""]]}, {"id": "1801.07189", "submitter": "Lachlan Urquhart Ph.D", "authors": "Lachlan Urquhart, Neelima Sailaja, Derek McAuley", "title": "Realising the Right to Data Portability for the Domestic Internet of\n  Things", "comments": null, "journal-ref": "Personal and Ubiquitous Computing, Springer, 2017", "doi": "10.1007/s00779-017-1069-2", "report-no": null, "categories": "cs.HC cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an increasing role for the IT design community to play in regulation\nof emerging IT. Article 25 of the EU General Data Protection Regulation (GDPR)\n2016 puts this on a strict legal basis by establishing the need for information\nprivacy by design and default (PbD) for personal data-driven technologies.\nAgainst this backdrop, we examine legal, commercial and technical perspectives\naround the newly created legal right to data portability (RTDP) in GDPR. We are\nmotivated by a pressing need to address regulatory challenges stemming from the\nInternet of Things (IoT). We need to find channels to support the protection of\nthese new legal rights for users in practice. In Part I we introduce the\ninternet of things and information PbD in more detail. We briefly consider\nregulatory challenges posed by the IoT and the nature and practical challenges\nsurrounding the regulatory response of information privacy by design. In Part\nII, we look in depth at the legal nature of the RTDP, determining what it\nrequires from IT designers in practice but also limitations on the right and\nhow it relates to IoT. In Part III we focus on technical approaches that can\nsupport the realisation of the right. We consider the state of the art in data\nmanagement architectures, tools and platforms that can provide portability,\nincreased transparency and user control over the data flows. In Part IV, we\nbring our perspectives together to reflect on the technical, legal and business\nbarriers and opportunities that will shape the implementation of the RTDP in\npractice, and how the relationships may shape emerging IoT innovation and\nbusiness models. We finish with brief conclusions about the future for the RTDP\nand PbD in the IoT.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 16:49:18 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Urquhart", "Lachlan", ""], ["Sailaja", "Neelima", ""], ["McAuley", "Derek", ""]]}, {"id": "1801.07207", "submitter": "Lachlan Urquhart Ph.D", "authors": "Lachlan Urquhart, Derek McAuley", "title": "Avoiding the Internet of Insecure Industrial Things", "comments": null, "journal-ref": "Computer Law and Security Review, 2018", "doi": "10.1016/j.clsr.2017.12.004", "report-no": null, "categories": "cs.HC cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security incidents such as targeted distributed denial of service (DDoS)\nattacks on power grids and hacking of factory industrial control systems (ICS)\nare on the increase. This paper unpacks where emerging security risks lie for\nthe industrial internet of things, drawing on both technical and regulatory\nperspectives. Legal changes are being ushered by the European Union (EU)\nNetwork and Information Security (NIS) Directive 2016 and the General Data\nProtection Regulation 2016 (GDPR) (both to be enforced from May 2018). We use\nthe case study of the emergent smart energy supply chain to frame, scope out\nand consolidate the breadth of security concerns at play, and the regulatory\nresponses. We argue the industrial IoT brings four security concerns to the\nfore, namely: appreciating the shift from offline to online infrastructure;\nmanaging temporal dimensions of security; addressing the implementation gap for\nbest practice; and engaging with infrastructural complexity. Our goal is to\nsurface risks and foster dialogue to avoid the emergence of an Internet of\nInsecure Industrial Things\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 17:19:18 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Urquhart", "Lachlan", ""], ["McAuley", "Derek", ""]]}, {"id": "1801.07518", "submitter": "Adam Aviv", "authors": "Adam J. Aviv and Ravi Kuber", "title": "Towards Understanding Connections between Security/Privacy Attitudes and\n  Unlock Authentication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.HC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this study, we examine the ways in which user attitudes towards privacy\nand security relating to mobile devices and the data stored thereon may impact\nthe strength of unlock authentication, focusing on Android's graphical unlock\npatterns. We conducted an online study with Amazon Mechanical Turk ($N=750$)\nusing self-reported unlock authentication choices, as well as Likert scale\nagreement/disagreement responses to a set of seven privacy/security prompts. We\nthen analyzed the responses in multiple dimensions, including a straight\naverage of the Likert responses as well as using Principle Component Analysis\nto expose latent factors. We found that responses to two of the seven questions\nproved relevant and significant. These two questions considered attitudes\ntowards general concern for data stored on mobile devices, and attitudes\ntowards concerns for unauthorized access by known actors. Unfortunately, larger\nconclusions cannot be drawn on the efficacy of the broader set of questions for\nexposing connections between unlock authentication strength (Pearson Rank\n$r=-0.08$, $p<0.1$). However, both of our factor solutions exposed differences\nin responses for demographics groups, including age, gender, and residence\ntype. The findings of this study suggests that there is likely a link between\nperceptions of privacy/security on mobile devices and the perceived threats\ntherein, but more research is needed, particularly on developing better survey\nand measurement techniques of privacy/security attitudes that relate to mobile\ndevices specifically.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 12:54:26 GMT"}, {"version": "v2", "created": "Thu, 1 Feb 2018 13:34:17 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Aviv", "Adam J.", ""], ["Kuber", "Ravi", ""]]}, {"id": "1801.07593", "submitter": "Margaret Mitchell", "authors": "Brian Hu Zhang, Blake Lemoine, Margaret Mitchell", "title": "Mitigating Unwanted Biases with Adversarial Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is a tool for building models that accurately represent\ninput training data. When undesired biases concerning demographic groups are in\nthe training data, well-trained models will reflect those biases. We present a\nframework for mitigating such biases by including a variable for the group of\ninterest and simultaneously learning a predictor and an adversary. The input to\nthe network X, here text or census data, produces a prediction Y, such as an\nanalogy completion or income bracket, while the adversary tries to model a\nprotected variable Z, here gender or zip code.\n  The objective is to maximize the predictor's ability to predict Y while\nminimizing the adversary's ability to predict Z. Applied to analogy completion,\nthis method results in accurate predictions that exhibit less evidence of\nstereotyping Z. When applied to a classification task using the UCI Adult\n(Census) Dataset, it results in a predictive model that does not lose much\naccuracy while achieving very close to equality of odds (Hardt, et al., 2016).\nThe method is flexible and applicable to multiple definitions of fairness as\nwell as a wide range of gradient-based learning models, including both\nregression and classification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 06:45:23 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Zhang", "Brian Hu", ""], ["Lemoine", "Blake", ""], ["Mitchell", "Margaret", ""]]}, {"id": "1801.07759", "submitter": "Jukka Ruohonen", "authors": "Jukka Ruohonen and Ville Lepp\\\"anen", "title": "Whose Hands Are in the Finnish Cookie Jar?", "comments": "Proceedings of the European Intelligence and Security Informatics\n  Conference (EISIC 2017)", "journal-ref": null, "doi": "10.1109/EISIC.2017.25", "report-no": null, "categories": "cs.CR cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web cookies are ubiquitously used to track and profile the behavior of users.\nAlthough there is a solid empirical foundation for understanding the use of\ncookies in the global world wide web, thus far, limited attention has been\ndevoted for country-specific and company-level analysis of cookies. To patch\nthis limitation in the literature, this paper investigates persistent\nthird-party cookies used in the Finnish web. The exploratory results reveal\nsome similarities and interesting differences between the Finnish and the\nglobal web---in particular, popular Finnish web sites are mostly owned by media\ncompanies, which have established their distinct partnerships with online\nadvertisement companies. The results reported can be also reflected against\ncurrent and future privacy regulation in the European Union.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 20:33:00 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Ruohonen", "Jukka", ""], ["Lepp\u00e4nen", "Ville", ""]]}, {"id": "1801.07782", "submitter": "Simon Thorne", "authors": "Simon Thorne", "title": "The Role of Spreadsheets in Clinical Decision Support: A Survey of the\n  Medical Algorithms Company User Community", "comments": "13 pages, 6 Colour Figures", "journal-ref": "Proceedings of the EuSpRIG 2017 Conference \"Spreadsheet Risk\n  Management\", Imperial College, London, pp137-151 ISBN: 978-1-905404-54-4", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents and discusses the results of a small scoping survey of\nClinical Decision Support System (CDSS) users from the Medical Algorithms\nCompany website which hosts 24,000 different CDSS. These results are analysed,\ndiscussed, and compared with other similar studies and contribute to the wider\nunderstanding of how CDSS impact on clinical practice. The results show that\nCDSS provided by Medal are being used by clinical professionals in a variety of\nsettings, both as an operational tool and as a research and reference tool.\nWhilst these tools are implemented and executed in a database, the initial\nlogic is worked out on a spreadsheet. The paper describes that process and\nexamines some of the results of the survey.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 21:45:16 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Thorne", "Simon", ""]]}, {"id": "1801.07789", "submitter": "Abdul Rahman Sherzad", "authors": "Abdul Rahman Sherzad", "title": "Data is the Fuel of Organizations: Opportunities and Challenges in\n  Afghanistan", "comments": "This paper consists of 14 pages, and it includes 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DB", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, the author at first briefly outlines the value of data in\norganizations and the opportunities and challenges in Afghanistan. Then the\nauthor takes the Kankor (National University Entrance Exam) data, particularly\nnames of participants, locations, high schools and higher education\ninstitutions into account and explains how these data, that organizations in\nAfghanistan do not use for anything, can be useful in several cases and areas.\nThe application of these data is shown through cases such as Auto filling\nmissing values, identifying names of people, locations, and institutions from\nunstructured text, generating fake data to benchmark the database and web\napplication performance and appearance, comparing and matching high school data\nwith Kankor data, producing the top-n male and female names very common in\nAfghanistan or province-wise, and the data mining application in education and\nhigher education institutions.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 13:23:54 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Sherzad", "Abdul Rahman", ""]]}, {"id": "1801.07860", "submitter": "Eyal Oren", "authors": "Alvin Rajkomar, Eyal Oren, Kai Chen, Andrew M. Dai, Nissan Hajaj,\n  Peter J. Liu, Xiaobing Liu, Mimi Sun, Patrik Sundberg, Hector Yee, Kun Zhang,\n  Gavin E. Duggan, Gerardo Flores, Michaela Hardt, Jamie Irvine, Quoc Le, Kurt\n  Litsch, Jake Marcus, Alexander Mossin, Justin Tansuwan, De Wang, James\n  Wexler, Jimbo Wilson, Dana Ludwig, Samuel L. Volchenboum, Katherine Chou,\n  Michael Pearson, Srinivasan Madabushi, Nigam H. Shah, Atul J. Butte, Michael\n  Howell, Claire Cui, Greg Corrado, Jeff Dean", "title": "Scalable and accurate deep learning for electronic health records", "comments": "Published version from\n  https://www.nature.com/articles/s41746-018-0029-1", "journal-ref": "npj Digital Medicine 1:18 (2018)", "doi": "10.1038/s41746-018-0029-1", "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive modeling with electronic health record (EHR) data is anticipated\nto drive personalized medicine and improve healthcare quality. Constructing\npredictive statistical models typically requires extraction of curated\npredictor variables from normalized EHR data, a labor-intensive process that\ndiscards the vast majority of information in each patient's record. We propose\na representation of patients' entire, raw EHR records based on the Fast\nHealthcare Interoperability Resources (FHIR) format. We demonstrate that deep\nlearning methods using this representation are capable of accurately predicting\nmultiple medical events from multiple centers without site-specific data\nharmonization. We validated our approach using de-identified EHR data from two\nU.S. academic medical centers with 216,221 adult patients hospitalized for at\nleast 24 hours. In the sequential format we propose, this volume of EHR data\nunrolled into a total of 46,864,534,945 data points, including clinical notes.\nDeep learning models achieved high accuracy for tasks such as predicting\nin-hospital mortality (AUROC across sites 0.93-0.94), 30-day unplanned\nreadmission (AUROC 0.75-0.76), prolonged length of stay (AUROC 0.85-0.86), and\nall of a patient's final discharge diagnoses (frequency-weighted AUROC 0.90).\nThese models outperformed state-of-the-art traditional predictive models in all\ncases. We also present a case-study of a neural-network attribution system,\nwhich illustrates how clinicians can gain some transparency into the\npredictions. We believe that this approach can be used to create accurate and\nscalable predictions for a variety of clinical scenarios, complete with\nexplanations that directly highlight evidence in the patient's chart.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 05:06:43 GMT"}, {"version": "v2", "created": "Fri, 26 Jan 2018 18:57:00 GMT"}, {"version": "v3", "created": "Fri, 11 May 2018 12:16:50 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Rajkomar", "Alvin", ""], ["Oren", "Eyal", ""], ["Chen", "Kai", ""], ["Dai", "Andrew M.", ""], ["Hajaj", "Nissan", ""], ["Liu", "Peter J.", ""], ["Liu", "Xiaobing", ""], ["Sun", "Mimi", ""], ["Sundberg", "Patrik", ""], ["Yee", "Hector", ""], ["Zhang", "Kun", ""], ["Duggan", "Gavin E.", ""], ["Flores", "Gerardo", ""], ["Hardt", "Michaela", ""], ["Irvine", "Jamie", ""], ["Le", "Quoc", ""], ["Litsch", "Kurt", ""], ["Marcus", "Jake", ""], ["Mossin", "Alexander", ""], ["Tansuwan", "Justin", ""], ["Wang", "De", ""], ["Wexler", "James", ""], ["Wilson", "Jimbo", ""], ["Ludwig", "Dana", ""], ["Volchenboum", "Samuel L.", ""], ["Chou", "Katherine", ""], ["Pearson", "Michael", ""], ["Madabushi", "Srinivasan", ""], ["Shah", "Nigam H.", ""], ["Butte", "Atul J.", ""], ["Howell", "Michael", ""], ["Cui", "Claire", ""], ["Corrado", "Greg", ""], ["Dean", "Jeff", ""]]}, {"id": "1801.07948", "submitter": "Hayafumi Watanabe", "authors": "Hayafumi Watanabe", "title": "Empirical observations of ultraslow diffusion driven by the fractional\n  dynamics in languages: Dynamical statistical properties of word counts of\n  already popular words", "comments": null, "journal-ref": "Phys. Rev. E 98, 012308 (2018)", "doi": "10.1103/PhysRevE.98.012308", "report-no": null, "categories": "physics.soc-ph cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultraslow diffusion (i.e. logarithmic diffusion) has been extensively studied\ntheoretically, but has hardly been observed empirically. In this paper,\nfirstly, we find the ultraslow-like diffusion of the time-series of word counts\nof already popular words by analysing three different nationwide language\ndatabases: (i) newspaper articles (Japanese), (ii) blog articles (Japanese),\nand (iii) page views of Wikipedia (English, French, Chinese, and Japanese).\nSecondly, we use theoretical analysis to show that this diffusion is basically\nexplained by the random walk model with the power-law forgetting with the\nexponent $\\beta \\approx 0.5$, which is related to the fractional Langevin\nequation. The exponent $\\beta$ characterises the speed of forgetting and $\\beta\n\\approx 0.5$ corresponds to (i) the border (or thresholds) between the\nstationary and the nonstationary and (ii) the right-in-the-middle dynamics\nbetween the IID noise for $\\beta=1$ and the normal random walk for $\\beta=0$.\nThirdly, the generative model of the time-series of word counts of already\npopular words, which is a kind of Poisson process with the Poisson parameter\nsampled by the above-mentioned random walk model, can almost reproduce not only\nthe empirical mean-squared displacement but also the power spectrum density and\nthe probability density function.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 12:11:09 GMT"}, {"version": "v2", "created": "Sat, 27 Jan 2018 04:55:30 GMT"}, {"version": "v3", "created": "Sat, 24 Feb 2018 00:34:19 GMT"}, {"version": "v4", "created": "Wed, 27 Jun 2018 09:56:16 GMT"}, {"version": "v5", "created": "Fri, 29 Jun 2018 18:16:13 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Watanabe", "Hayafumi", ""]]}, {"id": "1801.08024", "submitter": "Grigori Fursin", "authors": "Grigori Fursin, Anton Lokhmotov, Dmitry Savenko and Eben Upton", "title": "A Collective Knowledge workflow for collaborative research into\n  multi-objective autotuning and machine learning techniques", "comments": "Interactive CK report: http://cKnowledge.org/rpi-crowd-tuning ; CK\n  repository with artifacts:\n  https://github.com/ctuning/ck-rpi-optimization-results ; FigShare data\n  archive: https://doi.org/10.6084/m9.figshare.5789007.v2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing efficient software and hardware has never been harder whether it\nis for a tiny IoT device or an Exascale supercomputer. Apart from the ever\ngrowing design and optimization complexity, there exist even more fundamental\nproblems such as lack of interdisciplinary knowledge required for effective\nsoftware/hardware co-design, and a growing technology transfer gap between\nacademia and industry.\n  We introduce our new educational initiative to tackle these problems by\ndeveloping Collective Knowledge (CK), a unified experimental framework for\ncomputer systems research and development. We use CK to teach the community how\nto make their research artifacts and experimental workflows portable,\nreproducible, customizable and reusable while enabling sustainable R&D and\nfacilitating technology transfer. We also demonstrate how to redesign\nmulti-objective autotuning and machine learning as a portable and extensible CK\nworkflow. Such workflows enable researchers to experiment with different\napplications, data sets and tools; crowdsource experimentation across diverse\nplatforms; share experimental results, models, visualizations; gradually expose\nmore design and optimization choices using a simple JSON API; and ultimately\nbuild upon each other's findings.\n  As the first practical step, we have implemented customizable compiler\nautotuning, crowdsourced optimization of diverse workloads across Raspberry Pi\n3 devices, reduced the execution time and code size by up to 40%, and applied\nmachine learning to predict optimizations. We hope such approach will help\nteach students how to build upon each others' work to enable efficient and\nself-optimizing software/hardware/model stack for emerging workloads.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 15:30:39 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Fursin", "Grigori", ""], ["Lokhmotov", "Anton", ""], ["Savenko", "Dmitry", ""], ["Upton", "Eben", ""]]}, {"id": "1801.08480", "submitter": "Prem Sewak Sudhish", "authors": "Prem Sewak Sudhish", "title": "An Integrated Soft Computing Approach to a Multi-biometric Security\n  Model", "comments": "Ph.D. thesis of Prem Sewak Sudhish, Dayalbagh Educational Institute.\n  The thesis has been formatted for duplex printing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The abstract of the thesis consists of three sections, videlicet,\n  Motivation\n  Chapter Organization\n  Salient Contributions.\n  The complete abstract is included with the thesis. The final section on\nSalient Contributions is reproduced below.\n  Salient Contributions\n  The research presents the following salient contributions:\n  i. A novel technique has been developed for comparing biographical\ninformation, by combining the average impact of Levenshtein,\nDamerau-Levenshtein, and editor distances. The impact is calculated as the\nratio of the edit distance to the maximum possible edit distance between two\nstrings of the same lengths as the given pair of strings. This impact lies in\nthe range [0, 1] and can easily be converted to a similarity (matching) score\nby subtracting the impact from unity.\n  ii. A universal soft computing framework is proposed for adaptively fusing\nbiometric and biographical information by making real-time decisions to\ndetermine after consideration of each individual identifier whether computation\nof matching scores and subsequent fusion of additional identifiers, including\nbiographical information is required. This proposed framework not only improves\nthe accuracy of the system by fusing less reliable information (e.g.\nbiographical information) only for instances where such a fusion is required,\nbut also improves the efficiency of the system by computing matching scores for\nvarious available identifiers only when this computation is considered\nnecessary.\n  iii. A scientific method for comparing efficiency of fusion strategies\nthrough a predicted effort to error trade-off curve.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jan 2018 16:54:16 GMT"}], "update_date": "2018-01-26", "authors_parsed": [["Sudhish", "Prem Sewak", ""]]}, {"id": "1801.08494", "submitter": "Joshua Gardner", "authors": "Josh Gardner, Christopher Brooks", "title": "Evaluating Predictive Models of Student Success: Closing the\n  Methodological Gap", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model evaluation -- the process of making inferences about the performance of\npredictive models -- is a critical component of predictive modeling research in\nlearning analytics. We survey the state of the practice with respect to model\nevaluation in learning analytics, which overwhelmingly uses only naive methods\nfor model evaluation or statistical tests which are not appropriate for\npredictive model evaluation. We conduct a critical comparison of both null\nhypothesis significance testing (NHST) and a preferred Bayesian method for\nmodel evaluation. Finally, we apply three methods -- the na{\\\"i}ve average\ncommonly used in learning analytics, NHST, and Bayesian -- to a predictive\nmodeling experiment on a large set of MOOC data. We compare 96 different\npredictive models, including different feature sets, statistical modeling\nalgorithms, and tuning hyperparameters for each, using this case study to\ndemonstrate the different experimental conclusions these evaluation techniques\nprovide.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 14:02:08 GMT"}, {"version": "v2", "created": "Wed, 13 Jun 2018 18:33:10 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Gardner", "Josh", ""], ["Brooks", "Christopher", ""]]}, {"id": "1801.08754", "submitter": "Clare Llewellyn", "authors": "Clare Llewellyn, Laura Cram, Adrian Favero, Robin L. Hill", "title": "For Whom the Bell Trolls: Troll Behaviour in the Twitter Brexit Debate", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a review into automated and malicious activity Twitter released a list of\naccounts that they believed were connected to state sponsored manipulation of\nthe 2016 American Election. This list details 2,752 accounts Twitter believed\nto be controlled by Russian operatives. In the absence of a similar list of\noperatives active within the debate on the 2016 UK referendum on membership of\nthe European Union (Brexit) we investigated the behaviour of the same American\nElection focused accounts in the production of content related to the UK-EU\nreferendum. We found that within our dataset we had Brexit-related content from\n419 of these accounts, leading to 3,485 identified tweets gathered between the\n29th August 2015 and 3rd October 2017. The behaviour of the accounts altered\nradically on the day of the referendum, shifting from generalised disruptive\ntweeting to retweeting each other in order to amplify content produced by other\ntroll accounts. We also demonstrate that, while these accounts are, in general,\ndesigned to resemble American citizens, accounts created in 2016 often\ncontained German locations and terms in the user profiles.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jan 2018 11:02:26 GMT"}], "update_date": "2018-01-29", "authors_parsed": [["Llewellyn", "Clare", ""], ["Cram", "Laura", ""], ["Favero", "Adrian", ""], ["Hill", "Robin L.", ""]]}, {"id": "1801.08825", "submitter": "Arnim Bleier", "authors": "Sebastian Stier and Arnim Bleier and Haiko Lietz and Markus Strohmaier", "title": "Election campaigning on social media: Politicians, audiences and the\n  mediation of political communication on Facebook and Twitter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although considerable research has concentrated on online campaigning, it is\nstill unclear how politicians use different social media platforms in political\ncommunication. Focusing on the German federal election campaign 2013, this\narticle investigates whether election candidates address the topics most\nimportant to the mass audience and to which extent their communication is\nshaped by the characteristics of Facebook and Twitter. Based on open-ended\nresponses from a representative survey conducted during the election campaign,\nwe train a human-interpretable Bayesian language model to identify political\ntopics. Applying the model to social media messages of candidates and their\ndirect audiences, we find that both prioritize different topics than the mass\naudience. The analysis also shows that politicians use Facebook and Twitter for\ndifferent purposes. We relate the various findings to the mediation of\npolitical communication on social media induced by the particular\ncharacteristics of audiences and sociotechnical environments.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jan 2018 14:33:12 GMT"}], "update_date": "2018-01-29", "authors_parsed": [["Stier", "Sebastian", ""], ["Bleier", "Arnim", ""], ["Lietz", "Haiko", ""], ["Strohmaier", "Markus", ""]]}, {"id": "1801.09454", "submitter": "Hiroya Maeda", "authors": "Hiroya Maeda, Yoshihide Sekimoto, Toshikazu Seto, Takehiro Kashiyama,\n  Hiroshi Omata", "title": "Road Damage Detection Using Deep Neural Networks with Images Captured\n  Through a Smartphone", "comments": "14 pages, 7 figures", "journal-ref": "Computer Aided Civil and Infrastructure Engineering, 2018", "doi": "10.1111/mice.12387", "report-no": null, "categories": "cs.CV cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Research on damage detection of road surfaces using image processing\ntechniques has been actively conducted, achieving considerably high detection\naccuracies. Many studies only focus on the detection of the presence or absence\nof damage. However, in a real-world scenario, when the road managers from a\ngoverning body need to repair such damage, they need to clearly understand the\ntype of damage in order to take effective action. In addition, in many of these\nprevious studies, the researchers acquire their own data using different\nmethods. Hence, there is no uniform road damage dataset available openly,\nleading to the absence of a benchmark for road damage detection. This study\nmakes three contributions to address these issues. First, to the best of our\nknowledge, for the first time, a large-scale road damage dataset is prepared.\nThis dataset is composed of 9,053 road damage images captured with a smartphone\ninstalled on a car, with 15,435 instances of road surface damage included in\nthese road images. In order to generate this dataset, we cooperated with 7\nmunicipalities in Japan and acquired road images for more than 40 hours. These\nimages were captured in a wide variety of weather and illuminance conditions.\nIn each image, we annotated the bounding box representing the location and type\nof damage. Next, we used a state-of-the-art object detection method using\nconvolutional neural networks to train the damage detection model with our\ndataset, and compared the accuracy and runtime speed on both, using a GPU\nserver and a smartphone. Finally, we demonstrate that the type of damage can be\nclassified into eight types with high accuracy by applying the proposed object\ndetection method. The road damage dataset, our experimental results, and the\ndeveloped smartphone application used in this study are publicly available\n(https://github.com/sekilab/RoadDamageDetector/).\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 11:25:20 GMT"}, {"version": "v2", "created": "Fri, 2 Feb 2018 03:23:24 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Maeda", "Hiroya", ""], ["Sekimoto", "Yoshihide", ""], ["Seto", "Toshikazu", ""], ["Kashiyama", "Takehiro", ""], ["Omata", "Hiroshi", ""]]}, {"id": "1801.09479", "submitter": "Loet Leydesdorff", "authors": "Jordan Comins and Loet Leydesdorff", "title": "Data-mining the Foundational Patents of Photovoltaic Materials: An\n  application of Patent Citation Spectroscopy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply Patent Citation Spectroscopy (PCS)--originally developed as\nReference Publication Year Spectroscopy for studying landmarks and milestones\nin scientific literature--to patent literature classified into the nine\nY-subclasses of the Cooperative Patent Classification (CPC) that describe\nmaterial photovoltaic technologies. For this study we extended the routine with\nthe option to use the advanced search queries at PatentsView. On the basis of\ntwo normalizations of the longitudinal distribution of the publication years of\nthe patents cited by the retrieved patents, the routine (at\nhttp://www.leydesdorff.net/comins/pcs/index.html) provides a best guess of the\nfoundational patent for the subject specified in the string. In five of the\nnine cases, we found corroborating evidence for the foundational character of\nthe patent indicated by the routine.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 12:41:06 GMT"}, {"version": "v2", "created": "Wed, 7 Feb 2018 07:35:58 GMT"}, {"version": "v3", "created": "Sun, 8 Apr 2018 17:57:39 GMT"}, {"version": "v4", "created": "Tue, 10 Apr 2018 04:40:25 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Comins", "Jordan", ""], ["Leydesdorff", "Loet", ""]]}, {"id": "1801.09524", "submitter": "Anastasios Noulas", "authors": "Anastasios Noulas and Colin Moffatt and Desislava Hristova and Bruno\n  Gon\\c{c}alves", "title": "Foursquare to The Rescue: Predicting Ambulance Calls Across Geographies", "comments": "10 pages, 9 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding how ambulance incidents are spatially distributed can shed\nlight to the epidemiological dynamics of geographic areas and inform healthcare\npolicy design. Here we analyze a longitudinal dataset of more than four million\nambulance calls across a region of twelve million residents in the North West\nof England. With the aim to explain geographic variations in ambulance call\nfrequencies, we employ a wide range of data layers including open government\ndatasets describing population demographics and socio-economic characteristics,\nas well as geographic activity in online services such as Foursquare. Working\nat a fine level of spatial granularity we demonstrate that daytime population\nlevels and the deprivation status of an area are the most important variables\nwhen it comes to predicting the volume of ambulance calls at an area.\nFoursquare check-ins on the other hand complement these government sourced\nindicators, offering a novel view to population nightlife and commercial\nactivity locally. We demonstrate how check-in activity can provide an edge when\npredicting certain types of emergency incidents in a multi-variate regression\nmodel.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 14:27:51 GMT"}, {"version": "v2", "created": "Fri, 2 Feb 2018 20:37:40 GMT"}, {"version": "v3", "created": "Mon, 26 Feb 2018 22:27:46 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Noulas", "Anastasios", ""], ["Moffatt", "Colin", ""], ["Hristova", "Desislava", ""], ["Gon\u00e7alves", "Bruno", ""]]}, {"id": "1801.09546", "submitter": "Michael Lash", "authors": "Michael T. Lash and Jason Slater and Philip M. Polgreen and Alberto M.\n  Segre", "title": "21 Million Opportunities: A 19 Facility Investigation of Factors\n  Affecting Hand Hygiene Compliance via Linear Predictive Models", "comments": "arXiv admin note: substantial text overlap with arXiv:1705.03540", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This large-scale study, consisting of 21.3 million hand hygiene opportunities\nfrom 19 distinct facilities in 10 different states, uses linear predictive\nmodels to expose factors that may affect hand hygiene compliance. We examine\nthe use of features such as temperature, relative humidity, influenza severity,\nday/night shift, federal holidays and the presence of new medical residents in\npredicting daily hand hygiene compliance; the investigation is undertaken using\nboth a \"global\" model to glean general trends, and facility-specific models to\nelicit facility-specific insights. The results suggest that colder temperatures\nand federal holidays have an adverse effect on hand hygiene compliance rates,\nand that individual cultures and attitudes regarding hand hygiene exist among\nfacilities.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jan 2018 04:40:59 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Lash", "Michael T.", ""], ["Slater", "Jason", ""], ["Polgreen", "Philip M.", ""], ["Segre", "Alberto M.", ""]]}, {"id": "1801.09781", "submitter": "Emilio Ferrara", "authors": "Anna Sapienza, Alessandro Bessi, Saranya Damodaran, Paulo Shakarian,\n  Kristina Lerman, Emilio Ferrara", "title": "Early Warnings of Cyber Threats in Online Discussions", "comments": null, "journal-ref": "2017 IEEE International Conference on Data Mining Workshops\n  (ICDMW), pp:667-674, 2017", "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a system for automatically generating warnings of imminent or\ncurrent cyber-threats. Our system leverages the communication of malicious\nactors on the darkweb, as well as activity of cyber security experts on social\nmedia platforms like Twitter. In a time period between September, 2016 and\nJanuary, 2017, our method generated 661 alerts of which about 84% were relevant\nto current or imminent cyber-threats. In the paper, we first illustrate the\nrationale and workflow of our system, then we measure its performance. Our\nanalysis is enriched by two case studies: the first shows how the method could\npredict DDoS attacks, and how it would have allowed organizations to prepare\nfor the Mirai attacks that caused widespread disruption in October 2016.\nSecond, we discuss the method's timely identification of various instances of\ndata breaches.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 22:10:16 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Sapienza", "Anna", ""], ["Bessi", "Alessandro", ""], ["Damodaran", "Saranya", ""], ["Shakarian", "Paulo", ""], ["Lerman", "Kristina", ""], ["Ferrara", "Emilio", ""]]}, {"id": "1801.09783", "submitter": "Emilio Ferrara", "authors": "Anna Sapienza, Hao Peng, Emilio Ferrara", "title": "Performance Dynamics and Success in Online Games", "comments": null, "journal-ref": "2017 IEEE International Conference on Data Mining Workshops\n  (ICDMW), pp:902-909, 2017", "doi": "10.1109/ICDMW.2017.124", "report-no": null, "categories": "cs.SI cs.CY cs.HC physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online data provide a way to monitor how users behave in social systems like\nsocial networks and online games, and understand which features turn an\nordinary individual into a successful one. Here, we propose to study individual\nperformance and success in Multiplayer Online Battle Arena (MOBA) games. Our\npurpose is to identify those behaviors and playing styles that are\ncharacteristic of players with high skill level and that distinguish them from\nother players. To this aim, we study Defense of the ancient 2 (Dota 2), a\npopular MOBA game. Our findings highlight three main aspects to be successful\nin the game: (i) players need to have a warm-up period to enhance their\nperformance in the game; (ii) having a long in-game experience does not\nnecessarily translate in achieving better skills; but rather, (iii) players\nthat reach high skill levels differentiate from others because of their\naggressive playing strategy, which implies to kill opponents more often than\ncooperating with teammates, and trying to give an early end to the match.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 22:15:36 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Sapienza", "Anna", ""], ["Peng", "Hao", ""], ["Ferrara", "Emilio", ""]]}, {"id": "1801.09946", "submitter": "Emiliano De Cristofaro", "authors": "Alexandros Mittos, Jeremy Blackburn, Emiliano De Cristofaro", "title": "\"23andMe confirms: I'm super white\" -- Analyzing Twitter Discourse On\n  Genetic Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in genomics is bringing genetic testing to the masses.\nParticipatory public initiatives are underway to sequence the genome of\nmillions of volunteers, and a new market is booming with a number of companies\nlike 23andMe and AncestryDNA offering affordable tests directly to consumers.\nConsequently, news, experiences, and views on genetic testing are increasingly\nshared and discussed online and on social networks like Twitter. In this paper,\nwe present a large-scale analysis of Twitter discourse on genetic testing. We\ncollect 302K tweets from 113K users, posted over 2.5 years, by using thirteen\nkeywords related to genetic testing companies and public initiatives as search\nkeywords. We study both the tweets and the users posting them along several\naxes, aiming to understand who tweets about genetic testing, what they talk\nabout, and how they use Twitter for that. Among other things, we find that\ntweets about genetic testing originate from accounts that overall appear to be\ninterested in digital health and technology. Also, marketing efforts as well as\nannouncements, such as the FDA's suspension of 23andMe's health reports,\ninfluence the type and the nature of user engagement.Finally, we report on\nusers who share screenshots of their results, and raise a few ethical and\nsocietal questions as we find evidence of groups associating genetic testing to\nracist ideologies.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 12:00:07 GMT"}, {"version": "v2", "created": "Fri, 20 Apr 2018 10:48:17 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Mittos", "Alexandros", ""], ["Blackburn", "Jeremy", ""], ["De Cristofaro", "Emiliano", ""]]}, {"id": "1801.10231", "submitter": "David Birch", "authors": "David Birch, David Lyford-Smith and Yike Guo", "title": "The Future of Spreadsheets in the Big Data Era", "comments": "13 Pages, 1 Table", "journal-ref": "Proceedings of the EuSpRIG 2017 Conference \"Spreadsheet Risk\n  Management\", Imperial College, London, pp1-13 ISBN: 978-1-905404-54-4", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The humble spreadsheet is the most widely used data storage, manipulation and\nmodelling tool. Its ubiquity over the past 30 years has seen its successful\napplication in every area of life. Surprisingly the spreadsheet has remained\nfundamentally unchanged over the past three decades. As spreadsheet technology\nenters its 4th decade a number of drivers of change are beginning to impact\nupon the spreadsheet. The rise of Big Data, increased end-user computing and\nmobile computing will undoubtedly increasingly shape the evolution and use of\nspreadsheet technology.\n  To explore the future of spreadsheet technology a workshop was convened with\nthe aim of \"bringing together academia and industry to examine the future\ndirection of spreadsheet technology and the consequences for users\". This paper\nrecords the views of the participants on the reasons for the success of the\nspreadsheet, the trends driving change and the likely directions of change for\nthe spreadsheet. We then set out key directions for further research in the\nevolution and use of spreadsheets. Finally we look at the implications of these\ntrends for the end users who after all are the reason for the remarkable\nsuccess of the spreadsheet.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 21:37:28 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["Birch", "David", ""], ["Lyford-Smith", "David", ""], ["Guo", "Yike", ""]]}, {"id": "1801.10295", "submitter": "Yining Hu", "authors": "Yining Hu, Ahsan Manzoor, Parinya Ekparinya, Madhusanka Liyanage,\n  Kanchana Thilakarathna, Guillaume Jourjon, Aruna Seneviratne, Mika E\n  Ylianttila", "title": "A Delay-Tolerant Payment Scheme Based on the Ethereum Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Banking as an essential service can be hard to access in remote, rural\nregions where the network connectivity is intermittent. Although micro-banking\nhas been made possible by SMS or USSD messages in some places, their security\nflaws and session-based nature prevent them from a wider adoption. Global level\ncryptocurrencies enable low-cost, secure and pervasive money transferring among\ndistributed peers, but are still limited in their ability to reach more people\nin remote communities.\n  We proposed to take advantage of the delay-tolerant nature of blockchains to\ndeliver banking services to remote communities that only connect to the broader\nInternet intermittently. Using a base station that offers connectivity within\nthe local area, regular transaction processing is solely handled by blockchain\nminers. The bank only joins to process currency exchange requests, reward\nminers and track user balances when the connection is available. By\ndistributing the verification and storage tasks among peers, our system design\nsaves on the overall deployment and operational costs without sacrificing the\nreliability and trustwor- thiness. Through theoretical and empirical analysis,\nwe provided insights to system design, tested its robustness against network\ndisturbances, and demonstrated the feasibility of implementation on\noff-the-shelf computers and mobile devices.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 04:29:20 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["Hu", "Yining", ""], ["Manzoor", "Ahsan", ""], ["Ekparinya", "Parinya", ""], ["Liyanage", "Madhusanka", ""], ["Thilakarathna", "Kanchana", ""], ["Jourjon", "Guillaume", ""], ["Seneviratne", "Aruna", ""], ["Ylianttila", "Mika E", ""]]}, {"id": "1801.10396", "submitter": "Emiliano De Cristofaro", "authors": "Savvas Zannettou, Jeremy Blackburn, Emiliano De Cristofaro, Michael\n  Sirivianos, Gianluca Stringhini", "title": "Understanding Web Archiving Services and Their (Mis)Use on Social Media", "comments": "Proceedings of the 12th International AAAI Conference on Web and\n  Social Media (ICWSM 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web archiving services play an increasingly important role in today's\ninformation ecosystem, by ensuring the continuing availability of information,\nor by deliberately caching content that might get deleted or removed. Among\nthese, the Wayback Machine has been proactively archiving, since 2001, versions\nof a large number of Web pages, while newer services like archive.is allow\nusers to create on-demand snapshots of specific Web pages, which serve as time\ncapsules that can be shared across the Web. In this paper, we present a\nlarge-scale analysis of Web archiving services and their use on social media,\nshedding light on the actors involved in this ecosystem, the content that gets\narchived, and how it is shared. We crawl and study: 1) 21M URLs from\narchive.is, spanning almost two years, and 2) 356K archive.is plus 391K Wayback\nMachine URLs that were shared on four social networks: Reddit, Twitter, Gab,\nand 4chan's Politically Incorrect board (/pol/) over 14 months. We observe that\nnews and social media posts are the most common types of content archived,\nlikely due to their perceived ephemeral and/or controversial nature. Moreover,\nURLs of archiving services are extensively shared on \"fringe\" communities\nwithin Reddit and 4chan to preserve possibly contentious content. Lastly, we\nfind evidence of moderators nudging or even forcing users to use archives,\ninstead of direct links, for news sources with opposing ideologies, potentially\ndepriving them of ad revenue.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 10:53:46 GMT"}, {"version": "v2", "created": "Mon, 9 Apr 2018 14:36:27 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Zannettou", "Savvas", ""], ["Blackburn", "Jeremy", ""], ["De Cristofaro", "Emiliano", ""], ["Sirivianos", "Michael", ""], ["Stringhini", "Gianluca", ""]]}, {"id": "1801.10408", "submitter": "Michael Veale", "authors": "Reuben Binns, Max Van Kleek, Michael Veale, Ulrik Lyngs, Jun Zhao and\n  Nigel Shadbolt", "title": "'It's Reducing a Human Being to a Percentage'; Perceptions of Justice in\n  Algorithmic Decisions", "comments": "14 pages, 3 figures, ACM Conference on Human Factors in Computing\n  Systems (CHI'18), April 21--26, Montreal, Canada", "journal-ref": null, "doi": "10.1145/3173574.3173951", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven decision-making consequential to individuals raises important\nquestions of accountability and justice. Indeed, European law provides\nindividuals limited rights to 'meaningful information about the logic' behind\nsignificant, autonomous decisions such as loan approvals, insurance quotes, and\nCV filtering. We undertake three experimental studies examining people's\nperceptions of justice in algorithmic decision-making under different scenarios\nand explanation styles. Dimensions of justice previously observed in response\nto human decision-making appear similarly engaged in response to algorithmic\ndecisions. Qualitative analysis identified several concerns and heuristics\ninvolved in justice perceptions including arbitrariness, generalisation, and\n(in)dignity. Quantitative analysis indicates that explanation styles primarily\nmatter to justice perceptions only when subjects are exposed to multiple\ndifferent styles---under repeated exposure of one style, scenario effects\nobscure any explanation effects. Our results suggests there may be no 'best'\napproach to explaining algorithmic decisions, and that reflection on their\nautomated nature both implicates and mitigates justice dimensions.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 11:31:46 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["Binns", "Reuben", ""], ["Van Kleek", "Max", ""], ["Veale", "Michael", ""], ["Lyngs", "Ulrik", ""], ["Zhao", "Jun", ""], ["Shadbolt", "Nigel", ""]]}]