[{"id": "2009.00172", "submitter": "Jack Downes Mr", "authors": "Jack Downes", "title": "LoRaWAN Temperature Sensors for Local Government Asset Management", "comments": "Technical Report, completed March 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this project is to investigate the suitability of using\nLoRaWAN technology to conduct temperature studies on local government assets in\nAustralian metropolitan and residential areas. Temperature sensing devices were\nintegrated into the existing LoRaWAN infrastructure at Curtin University with\ndata collected and stored on a remote server. Case studies were performed for\nthe City of Melville to address the suitability for such a system to provide\ninsights into heat islands and urban forests. Testing was completed on the\nCurtin University campus, replicating the climate conditions, asset types and,\ndense building and tree environment found in the City of Melville.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 01:35:01 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Downes", "Jack", ""]]}, {"id": "2009.00246", "submitter": "Patrick Kelley", "authors": "Ben Zevenbergen and Allison Woodruff and Patrick Gage Kelley", "title": "Explainability Case Studies", "comments": "5 pages, 1 table, 3 ancillary PDFs containing workshop materials.\n  CSCW 2020 Workshop on Ethics in Design", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Explainability is one of the key ethical concepts in the design of AI\nsystems. However, attempts to operationalize this concept thus far have tended\nto focus on approaches such as new software for model interpretability or\nguidelines with checklists. Rarely do existing tools and guidance incentivize\nthe designers of AI systems to think critically and strategically about the\nrole of explanations in their systems. We present a set of case studies of a\nhypothetical AI-enabled product, which serves as a pedagogical tool to empower\nproduct designers, developers, students, and educators to develop a holistic\nexplainability strategy for their own products.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 05:54:15 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 03:46:48 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Zevenbergen", "Ben", ""], ["Woodruff", "Allison", ""], ["Kelley", "Patrick Gage", ""]]}, {"id": "2009.00252", "submitter": "Mikaela Irene Fudolig", "authors": "Mikaela Irene D. Fudolig, Daniel Monsivais, Kunal Bhattacharya,\n  Hang-Hyun Jo, Kimmo Kaski", "title": "Internal migration and mobile communication patterns among pairs with\n  strong ties", "comments": "published version in EPJ Data Science", "journal-ref": "EPJ Data Science 10, 16 (2021)", "doi": "10.1140/epjds/s13688-021-00272-z", "report-no": null, "categories": "cs.SI cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using large-scale call detail records of anonymised mobile phone service\nsubscribers with demographic and location information, we investigate how a\nlong-distance residential move within the country affects the mobile\ncommunication patterns between an ego who moved and a frequently called alter\nwho did not move. By using clustering methods in analysing the call frequency\ntime series, we find that such ego-alter pairs are grouped into two clusters,\nthose with the call frequency increasing and those with the call frequency\ndecreasing after the move of the ego. This indicates that such residential\nmoves are correlated with a change in the communication pattern soon after\nmoving. We find that the pre-move calling behaviour is a relevant predictor for\nthe post-move calling behaviour. While demographic and location information can\nhelp in predicting whether the call frequency will rise or decay, they are not\nrelevant in predicting the actual call frequency volume. We also note that at\nfour months after the move, most of these close pairs maintain contact, even if\nthe call frequency is decreased.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 06:14:17 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 10:20:34 GMT"}, {"version": "v3", "created": "Tue, 6 Apr 2021 01:33:57 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Fudolig", "Mikaela Irene D.", ""], ["Monsivais", "Daniel", ""], ["Bhattacharya", "Kunal", ""], ["Jo", "Hang-Hyun", ""], ["Kaski", "Kimmo", ""]]}, {"id": "2009.00394", "submitter": "Fatemeh Jahedpari", "authors": "Fatemeh Jahedpari", "title": "Continuous Artificial Prediction Markets as a Syndromic Surveillance\n  Technique", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main goal of syndromic surveillance systems is early detection of an\noutbreak in a society using available data sources. In this paper, we discuss\nwhat are the challenges of syndromic surveillance systems and how continuous\nArtificial Prediction Market [Jahedpari et al., 2017] can effectively be\napplied to the problem of syndromic surveillance.\n  We use two well-known models of (i) Google Flu Trends, and (ii) the latest\nimprovement of Google Flu Trends model, named as GP [Lampos et al., 2015], as\nour case study and we show how c-APM can improve upon their performance. Our\nresults demonstrate that c-APM typically has a lower MAE to that of Google Flu\nTrends in each year. Though this difference is relatively small in some years\nlike 2004 and 2007, it is relatively large in most years and very large between\n2011 and 2013.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 12:51:48 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Jahedpari", "Fatemeh", ""]]}, {"id": "2009.00502", "submitter": "James Wright", "authors": "James Wright", "title": "Suspect AI: Vibraimage, Emotion Recognition Technology, and Algorithmic\n  Opacity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vibraimage is a digital system that quantifies a subject's mental and\nemotional state by analysing video footage of the movements of their head.\nVibraimage is used by police, nuclear power station operators, airport security\nand psychiatrists in Russia, China, Japan and South Korea, and has been\ndeployed at an Olympic Games, FIFA World Cup, and G7 Summit. Yet there is no\nreliable evidence that the technology is actually effective; indeed, many\nclaims made about its effects seem unprovable. What exactly does vibraimage\nmeasure, and how has it acquired the power to penetrate the highest profile and\nmost sensitive security infrastructure across Russia and Asia? I first trace\nthe development of the emotion recognition industry, before examining attempts\nby vibraimage's developers and affiliates scientifically to legitimate the\ntechnology, concluding that the disciplining power and corporate value of\nvibraimage is generated through its very opacity, in contrast to increasing\ndemands across the social sciences for transparency. I propose the term\n'suspect AI' to describe the growing number of systems like vibraimage that\nalgorithmically classify suspects / non-suspects, yet are themselves deeply\nsuspect. Popularising this term may help resist such technologies' reductivist\napproaches to 'reading' -- and exerting authority over -- emotion,\nintentionality and agency.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 15:03:52 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Wright", "James", ""]]}, {"id": "2009.00544", "submitter": "Kamwoo Lee", "authors": "Kamwoo Lee and Jeanine Braithwaite", "title": "High-Resolution Poverty Maps in Sub-Saharan Africa", "comments": "Changed an author's affiliation, updated the narrowing method for DHS\n  clusters leading to slight changes to all validation results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Up-to-date poverty maps are an important tool for policy makers, but until\nnow, have been prohibitively expensive to produce. We propose a generalizable\nprediction methodology to produce poverty maps at the village level using\ngeospatial data and machine learning algorithms. We tested the proposed method\nfor 25 Sub-Saharan African countries and validated them against survey data.\nThe proposed method can increase the validity of both single country and\ncross-country estimations leading to higher precision in poverty maps of 44\nSub-Saharan African countries than previously available. More importantly, our\ncross-country estimation enables the creation of poverty maps when it is not\npractical or cost-effective to field new national household surveys, as is the\ncase with many low- and middle-income countries.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 16:23:43 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 09:27:19 GMT"}, {"version": "v3", "created": "Sun, 13 Sep 2020 03:54:39 GMT"}, {"version": "v4", "created": "Mon, 28 Sep 2020 17:37:05 GMT"}, {"version": "v5", "created": "Mon, 10 May 2021 02:00:52 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Lee", "Kamwoo", ""], ["Braithwaite", "Jeanine", ""]]}, {"id": "2009.00549", "submitter": "Noptanit Chotisarn", "authors": "Noptanit Chotisarn, Junhua Lu, Libinzi Ma, Jingli Xu, Linhao Meng,\n  Bingru Lin, Ying Xu, Xiaonan Luo, Wei Chen", "title": "Bubble Storytelling with Automated Animation: A Brexit Hashtag Activism\n  Case Study", "comments": "Pre-print. Journal of Visualization, 2020", "journal-ref": null, "doi": "10.1007/s12650-020-00690-7", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Hashtag data are common and easy to acquire. Thus, they are widely used in\nstudies and visual data storytelling. For example, a recent story by China\nCentral Television Europe (CCTV Europe) depicts Brexit as a hashtag movement\ndisplayed on an animated bubble chart. However, creating such a story is\nusually laborious and tedious, because narrators have to switch between\ndifferent tools and discuss with different collaborators. To reduce the burden,\nwe develop a prototype system to help explore the bubbles' movement by\nautomatically inserting animations connected to the storytelling of the video\ncreators and the interaction of viewers to those videos. We demonstrate the\nusability of our method through both use cases and a semi-structured user\nstudy.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 16:28:46 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Chotisarn", "Noptanit", ""], ["Lu", "Junhua", ""], ["Ma", "Libinzi", ""], ["Xu", "Jingli", ""], ["Meng", "Linhao", ""], ["Lin", "Bingru", ""], ["Xu", "Ying", ""], ["Luo", "Xiaonan", ""], ["Chen", "Wei", ""]]}, {"id": "2009.00597", "submitter": "Marc B\\\"ohlen", "authors": "Marc B\\\"ohlen, Wawan Sujarwo", "title": "Return to Bali", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper gives an overview of the project Return to Bali that seeks to\ncreate a living dataset of ethnobotanically significant flora on the island of\nBali and new methods through which underrepresented forms of knowledge can be\ndocumented, shared and made compatible within the logics of machine learning\nwhile considering practical approaches to benefit multiple stakeholders and\npreventing unintended harm.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 17:38:18 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["B\u00f6hlen", "Marc", ""], ["Sujarwo", "Wawan", ""]]}, {"id": "2009.00679", "submitter": "Mohammed Alsuwaiket", "authors": "Mohammed Alsuwaiket, Christian Dawson, Firat Batmaz", "title": "Measuring the Credibility of Student Attendance Data in Higher Education\n  for Data Mining", "comments": "7 pages, 2 figures, 6 tables", "journal-ref": null, "doi": "10.18178/ijiet.2018.8.2.1020", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Educational Data Mining (EDM) is a developing discipline, concerned with\nexpanding the classical Data Mining (DM) methods and developing new methods for\ndiscovering the data that originate from educational systems. Student\nattendance in higher education has always been dealt with in a classical way,\neducators rely on counting the occurrence of attendance or absence building\ntheir knowledge about students as well as modules based on this count. This\nmethod is neither credible nor does it necessarily provide a real indication of\na student performance. This study tries to formulate the extracted knowledge in\na way that guarantees achieving accurate and credible results. Student\nattendance data, gathered from the educational system, were first cleaned in\norder to remove any randomness and noise, then various attributes were studied\nso as to highlight the most significant ones that affect the real attendance of\nstudents. The next step was to derive an equation that measures the Student\nAttendance Credibility (SAC) considering the attributes chosen in the previous\nstep. The reliability of the newly developed measure was then evaluated in\norder to examine its consistency. Finally, the J48 DM classification technique\nwas utilized in order to classify modules based on the strength of their SAC\nvalues. Results of this study were promising, and credibility values achieved\nusing the newly derived formula gave accurate, credible, and real indicators of\nstudent attendance, as well as accurate classification of modules based on the\ncredibility of student attendance on those modules.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 20:21:46 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Alsuwaiket", "Mohammed", ""], ["Dawson", "Christian", ""], ["Batmaz", "Firat", ""]]}, {"id": "2009.00802", "submitter": "Andrew Lohn", "authors": "Andrew J. Lohn", "title": "Estimating the Brittleness of AI: Safety Integrity Levels and the Need\n  for Testing Out-Of-Distribution Performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.CY cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Test, Evaluation, Verification, and Validation (TEVV) for Artificial\nIntelligence (AI) is a challenge that threatens to limit the economic and\nsocietal rewards that AI researchers have devoted themselves to producing. A\ncentral task of TEVV for AI is estimating brittleness, where brittleness\nimplies that the system functions well within some bounds and poorly outside of\nthose bounds. This paper argues that neither of those criteria are certain of\nDeep Neural Networks. First, highly touted AI successes (eg. image\nclassification and speech recognition) are orders of magnitude more\nfailure-prone than are typically certified in critical systems even within\ndesign bounds (perfectly in-distribution sampling). Second, performance falls\noff only gradually as inputs become further Out-Of-Distribution (OOD). Enhanced\nemphasis is needed on designing systems that are resilient despite\nfailure-prone AI components as well as on evaluating and improving OOD\nperformance in order to get AI to where it can clear the challenging hurdles of\nTEVV and certification.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 03:33:40 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Lohn", "Andrew J.", ""]]}, {"id": "2009.00803", "submitter": "Saad Wazir", "authors": "Hamza Ali Imran, Usama Mujahid, Saad Wazir, Usama Latif, Kiran Mehmood", "title": "Embedded Development Boards for Edge-AI: A Comprehensive Report", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The use of Deep Learning and Machine Learning is becoming pervasive day by\nday which is opening doors to new opportunities in every aspect of technology.\nIts application Ranges from Health-care to Self-driving Cars, Home Automation\nto Smart-agriculture, and Industry 4.0. Traditionally the majority of the\nprocessing for IoT applications is being done on a central cloud but that has\nits issues; which include latency, security, bandwidth, and privacy, etc. It is\nestimated that there will be around 20 Million IoT devices by 2020 which will\nincrease problems with sending data to the cloud and doing the processing\nthere. A new trend of processing the data on the edge of the network is\nemerging. The idea is to do processing as near the point of data production as\npossible. Doing processing on the nodes generating the data is called Edge\nComputing and doing processing on a layer between the cloud and the point of\ndata production is called Fog computing. There are no standard definitions for\nany of these, hence they are usually used interchangeably. In this paper, we\nhave reviewed the development boards available for running Artificial\nIntelligence algorithms on the Edge\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 03:34:05 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Imran", "Hamza Ali", ""], ["Mujahid", "Usama", ""], ["Wazir", "Saad", ""], ["Latif", "Usama", ""], ["Mehmood", "Kiran", ""]]}, {"id": "2009.01091", "submitter": "Marcelo Ponce", "authors": "Marcelo Ponce, Amit Sandhel", "title": "covid19.analytics: An R Package to Obtain, Analyze and Visualize Data\n  from the Coronavirus Disease Pandemic", "comments": "Version with updates matching ver 2.1 of the covi19.analytics package", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IR q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the emergence of a new pandemic worldwide, a novel strategy to approach\nit has emerged. Several initiatives under the umbrella of \"open science\" are\ncontributing to tackle this unprecedented situation. In particular, the \"R\nLanguage and Environment for Statistical Computing\" offers an excellent tool\nand ecosystem for approaches focusing on open science and reproducible results.\nHence it is not surprising that with the onset of the pandemic, a large number\nof R packages and resources were made available for researches working in the\npandemic. In this paper, we present an R package that allows users to access\nand analyze worldwide data from resources publicly available. We will introduce\nthe covid19.analytics package, focusing in its capabilities and presenting a\nparticular study case where we describe how to deploy the \"COVID19.ANALYTICS\nDashboard Explorer\".\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 14:05:10 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 16:59:03 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Ponce", "Marcelo", ""], ["Sandhel", "Amit", ""]]}, {"id": "2009.01209", "submitter": "Neil Ernst", "authors": "Neil A. Ernst and Jeffrey C. Carver and Daniel Mendez and Marco\n  Torchiano", "title": "Understanding Peer Review of Software Engineering Papers", "comments": "published in Empirical Software Engineering Journal. Replication\n  package at http://doi.org/10.5281/zenodo.4568517", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Peer review is a key activity intended to preserve the quality and integrity\nof scientific publications. However, in practice it is far from perfect.\n  We aim at understanding how reviewers, including those who have won awards\nfor reviewing, perform their reviews of software engineering papers to identify\nboth what makes a good reviewing approach and what makes a good paper.\n  We first conducted a series of in-person interviews with well-respected\nreviewers in the software engineering field. Then, we used the results of those\ninterviews to develop a questionnaire used in an online survey and sent out to\nreviewers from well-respected venues covering a number of software engineering\ndisciplines, some of whom had won awards for their reviewing efforts.\n  We analyzed the responses from the interviews and from 175 reviewers who\ncompleted the online survey (including both reviewers who had won awards and\nthose who had not). We report on several descriptive results, including: 45% of\naward-winners are reviewing 20+ conference papers a year, while 28% of\nnon-award winners conduct that many. 88% of reviewers are taking more than two\nhours on journal reviews. We also report on qualitative results. To write a\ngood review, the important criteria were it should be factual and helpful,\nranked above others such as being detailed or kind. The most important features\nof papers that result in positive reviews are clear and supported validation,\nan interesting problem, and novelty. Conversely, negative reviews tend to\nresult from papers that have a mismatch between the method and the claims and\nfrom those with overly grandiose claims.\n  The main recommendation for authors is to make the contribution of the work\nvery clear in their paper. In addition, reviewers viewed data availability and\nits consistency as being important.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 17:31:45 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 22:52:25 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Ernst", "Neil A.", ""], ["Carver", "Jeffrey C.", ""], ["Mendez", "Daniel", ""], ["Torchiano", "Marco", ""]]}, {"id": "2009.01215", "submitter": "Michael Lyons", "authors": "Michael J. Lyons", "title": "Excavating \"Excavating AI\": The Elephant in the Gallery", "comments": "15 pages, 4 figures", "journal-ref": null, "doi": "10.5281/zenodo.4037538", "report-no": null, "categories": "cs.CY cs.AI cs.CV cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two art exhibitions, \"Training Humans\" and \"Making Faces,\" and the\naccompanying essay \"Excavating AI: The politics of images in machine learning\ntraining sets\" by Kate Crawford and Trevor Paglen, are making substantial\nimpact on discourse taking place in the social and mass media networks, and\nsome scholarly circles. Critical scrutiny reveals, however, a\nself-contradictory stance regarding informed consent for the use of facial\nimages, as well as serious flaws in their critique of ML training sets. Our\nanalysis underlines the non-negotiability of informed consent when using human\ndata in artistic and other contexts, and clarifies issues relating to the\ndescription of ML training sets.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 17:42:06 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 17:07:10 GMT"}, {"version": "v3", "created": "Thu, 24 Dec 2020 01:27:53 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Lyons", "Michael J.", ""]]}, {"id": "2009.01229", "submitter": "Marialejandra Garcia-Corretjer", "authors": "Marialejandra Garcia Corretjer, David Miralles, and Raquel Ros", "title": "A Theoretical Approach for a Novel Model to Realizing Empathy", "comments": "47 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The first objective of this paper are to introduce a strong theoretical\nconcept as a proposed model that visualizes the process of realizing empathy,\nbased on the ample analysis of the collected work in the survey. Secondly, the\nintended purpose of this proposed model, is to create an initial blueprint that\nmay be applicable to a range of disciplines with clear must-have concepts\nimportant to consider for the realization of empathy between people and their\ntechnology.For this reason, after the model is explained, this paper\nexemplifies tools for its application and a couple of encouraging case study\nprojects that begin to integrate this model into their interactive experiments.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 17:21:49 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Corretjer", "Marialejandra Garcia", ""], ["Miralles", "David", ""], ["Ros", "Raquel", ""]]}, {"id": "2009.01231", "submitter": "E M Wasifur Rahman Chowdhury", "authors": "Wasifur Rahman, Sangwu Lee, Md. Saiful Islam, Victor Nikhil Antony,\n  Harshil Ratnu, Mohammad Rafayet Ali, Abdullah Al Mamun, Ellen Wagner, Stella\n  Jensen-Roberts, Max A. Little, Ray Dorsey, and Ehsan Hoque", "title": "Detecting Parkinson's Disease From an Online Speech-task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CY cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we envision a web-based framework that can help anyone,\nanywhere around the world record a short speech task, and analyze the recorded\ndata to screen for Parkinson's disease (PD). We collected data from 726 unique\nparticipants (262 PD, 38% female; 464 non-PD, 65% female; average age: 61) --\nfrom all over the US and beyond. A small portion of the data was collected in a\nlab setting to compare quality. The participants were instructed to utter a\npopular pangram containing all the letters in the English alphabet \"the quick\nbrown fox jumps over the lazy dog..\". We extracted both standard acoustic\nfeatures (Mel Frequency Cepstral Coefficients (MFCC), jitter and shimmer\nvariants) and deep learning based features from the speech data. Using these\nfeatures, we trained several machine learning algorithms. We achieved 0.75 AUC\n(Area Under The Curve) performance on determining presence of self-reported\nParkinson's disease by modeling the standard acoustic features through the\nXGBoost -- a gradient-boosted decision tree model. Further analysis reveal that\nthe widely used MFCC features and a subset of previously validated dysphonia\nfeatures designed for detecting Parkinson's from verbal phonation task\n(pronouncing 'ahh') contains the most distinct information. Our model performed\nequally well on data collected in controlled lab environment as well as 'in the\nwild' across different gender and age groups. Using this tool, we can collect\ndata from almost anyone anywhere with a video/audio enabled device,\ncontributing to equity and access in neurological care.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 21:16:24 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 01:14:48 GMT"}, {"version": "v3", "created": "Mon, 14 Dec 2020 01:35:03 GMT"}, {"version": "v4", "created": "Tue, 15 Dec 2020 21:08:05 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Rahman", "Wasifur", ""], ["Lee", "Sangwu", ""], ["Islam", "Md. Saiful", ""], ["Antony", "Victor Nikhil", ""], ["Ratnu", "Harshil", ""], ["Ali", "Mohammad Rafayet", ""], ["Mamun", "Abdullah Al", ""], ["Wagner", "Ellen", ""], ["Jensen-Roberts", "Stella", ""], ["Little", "Max A.", ""], ["Dorsey", "Ray", ""], ["Hoque", "Ehsan", ""]]}, {"id": "2009.01267", "submitter": "Jan Kallberg", "authors": "Jan Kallberg, Rosemary A. Burk, and Bhavani Thuraisingham", "title": "COVID-19: The Information Warfare Paradigm Shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In Kuhn's The Structure of Scientific Revolutions, the critical term is\nparadigm-shift when it suddenly becomes evident that earlier assumptions no\nlonger are correct and the plurality of the scientific community that studies\nthis domain accepts the change. These types of events can be scientific\nfindings or as in social science system shock that creates a punctured\nequilibrium that sets the stage in the developments. In information warfare,\nrecent years studies and government lines of efforts have been to engage fake\nnews, electoral interference, and fight extremist social media as the primary\ncombat theater in the information space, and the tools to influence a targeted\naudience. The COVID-19 pandemic generates a rebuttal of these assumptions. Even\nif fake news and extremist social media content may exploit fault lines in our\nsociety and create a civil disturbance, tensions between federal and local\ngovernment, and massive protests, it is still effects that impact a part of the\npopulation. What we have seen with COVID-19, as an indicator, is that what is\nrelated to public health is far more powerful to swing public sentiment and\ncreate reactions within the citizenry that are trigger impact at a larger\nmagnitude that has rippled through society in multiple directions.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 18:04:00 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Kallberg", "Jan", ""], ["Burk", "Rosemary A.", ""], ["Thuraisingham", "Bhavani", ""]]}, {"id": "2009.01334", "submitter": "Alessandro Fabris", "authors": "Alessandro Fabris, Alberto Purpura, Gianmaria Silvello, Gian Antonio\n  Susto", "title": "Gender Stereotype Reinforcement: Measuring the Gender Bias Conveyed by\n  Ranking Algorithms", "comments": "To appear in Information Processing & Management", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search Engines (SE) have been shown to perpetuate well-known gender\nstereotypes identified in psychology literature and to influence users\naccordingly. Similar biases were found encoded in Word Embeddings (WEs) learned\nfrom large online corpora. In this context, we propose the Gender Stereotype\nReinforcement (GSR) measure, which quantifies the tendency of a SE to support\ngender stereotypes, leveraging gender-related information encoded in WEs.\nThrough the critical lens of construct validity, we validate the proposed\nmeasure on synthetic and real collections. Subsequently, we use GSR to compare\nwidely-used Information Retrieval ranking algorithms, including lexical,\nsemantic, and neural models. We check if and how ranking algorithms based on\nWEs inherit the biases of the underlying embeddings. We also consider the most\ncommon debiasing approaches for WEs proposed in the literature and test their\nimpact in terms of GSR and common performance measures. To the best of our\nknowledge, GSR is the first specifically tailored measure for IR, capable of\nquantifying representational harms.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 20:45:04 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Fabris", "Alessandro", ""], ["Purpura", "Alberto", ""], ["Silvello", "Gianmaria", ""], ["Susto", "Gian Antonio", ""]]}, {"id": "2009.01359", "submitter": "Chao Fan", "authors": "Chao Fan, Xiangqi Jiang, Ali Mostafavi", "title": "Adaptive Reinforcement Learning Model for Simulation of Urban Mobility\n  during Crises", "comments": "20 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of this study is to propose and test an adaptive reinforcement\nlearning model that can learn the patterns of human mobility in a normal\ncontext and simulate the mobility during perturbations caused by crises, such\nas flooding, wildfire, and hurricanes. Understanding and predicting human\nmobility patterns, such as destination and trajectory selection, can inform\nemerging congestion and road closures raised by disruptions in emergencies.\nData related to human movement trajectories are scarce, especially in the\ncontext of emergencies, which places a limitation on applications of existing\nurban mobility models learned from empirical data. Models with the capability\nof learning the mobility patterns from data generated in normal situations and\nwhich can adapt to emergency situations are needed to inform emergency response\nand urban resilience assessments. To address this gap, this study creates and\ntests an adaptive reinforcement learning model that can predict the\ndestinations of movements, estimate the trajectory for each origin and\ndestination pair, and examine the impact of perturbations on humans' decisions\nrelated to destinations and movement trajectories. The application of the\nproposed model is shown in the context of Houston and the flooding scenario\ncaused by Hurricane Harvey in August 2017. The results show that the model can\nachieve more than 76\\% precision and recall. The results also show that the\nmodel could predict traffic patterns and congestion resulting from to urban\nflooding. The outcomes of the analysis demonstrate the capabilities of the\nmodel for analyzing urban mobility during crises, which can inform the public\nand decision-makers about the response strategies and resilience planning to\nreduce the impacts of crises on urban mobility.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 21:47:18 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Fan", "Chao", ""], ["Jiang", "Xiangqi", ""], ["Mostafavi", "Ali", ""]]}, {"id": "2009.01575", "submitter": "Stefano Bianchini", "authors": "Stefano Bianchini, Moritz M\\\"uller and Pierre Pelletier", "title": "Deep Learning in Science", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of the recent success of Artificial Intelligence (AI) has been spurred\non by impressive achievements within a broader family of machine learning\nmethods, commonly referred to as Deep Learning (DL). This paper provides\ninsights on the diffusion and impact of DL in science. Through a Natural\nLanguage Processing (NLP) approach on the arXiv.org publication corpus, we\ndelineate the emerging DL technology and identify a list of relevant search\nterms. These search terms allow us to retrieve DL-related publications from Web\nof Science across all sciences. Based on that sample, we document the DL\ndiffusion process in the scientific system. We find i) an exponential growth in\nthe adoption of DL as a research tool across all sciences and all over the\nworld, ii) regional differentiation in DL application domains, and iii) a\ntransition from interdisciplinary DL applications to disciplinary research\nwithin application domains. In a second step, we investigate how the adoption\nof DL methods affects scientific development. Therefore, we empirically assess\nhow DL adoption relates to re-combinatorial novelty and scientific impact in\nthe health sciences. We find that DL adoption is negatively correlated with\nre-combinatorial novelty, but positively correlated with expectation as well as\nvariance of citation performance. Our findings suggest that DL does not (yet?)\nwork as an autopilot to navigate complex knowledge landscapes and overthrow\ntheir structure. However, the 'DL principle' qualifies for its versatility as\nthe nucleus of a general scientific method that advances science in a\nmeasurable way.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 10:41:29 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 12:17:03 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Bianchini", "Stefano", ""], ["M\u00fcller", "Moritz", ""], ["Pelletier", "Pierre", ""]]}, {"id": "2009.01654", "submitter": "Arthur-Jozsef Molnar", "authors": "Iuliana Marin and Maria-Iuliana Bocicor and Arthur-Jozsef Molnar", "title": "Indoor Localization Techniques Within a Home Monitoring Platform", "comments": null, "journal-ref": "Damiani E., Spanoudakis G., Maciaszek L. (eds) Evaluation of Novel\n  Approaches to Software Engineering. ENASE 2019. Communications in Computer\n  and Information Science, vol 1172. Springer, Cham", "doi": "10.1007/978-3-030-40223-5_19", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper details a number of indoor localization techniques developed for\nreal-time monitoring of older adults. These were developed within the framework\nof the i-Light research project that was funded by the European Union. The\nproject targeted the development and initial evaluation of a configurable and\ncost-effective cyber-physical system for monitoring the safety of older adults\nwho are living in their own homes. Localization hardware consists of a number\nof custom-developed devices that replace existing luminaires. In addition to\nlighting capabilities, they measure the strength of a Bluetooth Low Energy\nsignal emitted by a wearable device on the user. Readings are recorded in real\ntime and sent to a software server for analysis. We present a comparative\nevaluation of the accuracy achieved by several server-side algorithms,\nincluding Kalman filtering, a look-back heuristic as well as a neural\nnetwork-based approach. It is known that approaches based on measuring signal\nstrength are sensitive to the placement of walls, construction materials used,\nthe presence of doors as well as existing furniture. As such, we evaluate the\nproposed approaches in two separate locations having distinct building\ncharacteristics. We show that the proposed techniques improve the accuracy of\nlocalization. As the final step, we evaluate our results against comparable\nexisting approaches.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 13:40:13 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Marin", "Iuliana", ""], ["Bocicor", "Maria-Iuliana", ""], ["Molnar", "Arthur-Jozsef", ""]]}, {"id": "2009.01713", "submitter": "Gili Rusak", "authors": "Gili Rusak, Lisa Yan", "title": "Unique Exams: Designing assessments for integrity and fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Educators have faced new challenges in effective course assessment during the\nrecent, unprecedented shift to remote online learning during the COVID-19\npandemic. In place of typical proctored, timed exams, instructors must now\nrethink their methodology for assessing course-level learning goals. Are exams\nappropriate---or even feasible---in this new online, open-internet learning\nenvironment? In this experience paper, we discuss the unique exams framework:\nour framework for upholding exam integrity and student privacy. In our\nProbability for Computer Scientists Course at an R1 University, we developed\nautogenerated, unique exams where each student had the same four problem\nskeletons with unique numeric variations per problem. Without changing the\nprocess of the traditional exam, unique exams provide a layer of security for\nboth students and instructors about exam reliability for any classroom\nenvironment---in-person or online. In addition to sharing our experience\ndesigning unique exams, we also present a simple end-to-end tool and example\nquestion templates for different CS subjects that other instructors can adapt\nto their own courses.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 14:44:00 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Rusak", "Gili", ""], ["Yan", "Lisa", ""]]}, {"id": "2009.01772", "submitter": "Erik Rye", "authors": "Erik Rye and Jeremy Blackburn and Robert Beverly", "title": "Reading In-Between the Lines: An Analysis of Dissenter", "comments": "Accepted at IMC 2020", "journal-ref": null, "doi": "10.1145/3419394.3423615", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efforts by content creators and social networks to enforce legal and\npolicy-based norms, e.g. blocking hate speech and users, has driven the rise of\nunrestricted communication platforms. One such recent effort is Dissenter, a\nbrowser and web application that provides a conversational overlay for any web\npage. These conversations hide in plain sight - users of Dissenter can see and\nparticipate in this conversation, whereas visitors using other browsers are\noblivious to their existence. Further, the website and content owners have no\npower over the conversation as it resides in an overlay outside their control.\n  In this work, we obtain a history of Dissenter comments, users, and the\nwebsites being discussed, from the initial release of Dissenter in Feb. 2019\nthrough Apr. 2020 (14 months). Our corpus consists of approximately 1.68M\ncomments made by 101k users commenting on 588k distinct URLs. We first analyze\nmacro characteristics of the network, including the user-base, comment\ndistribution, and growth. We then use toxicity dictionaries, Perspective API,\nand a Natural Language Processing model to understand the nature of the\ncomments and measure the propensity of particular websites and content to\nelicit hateful and offensive Dissenter comments. Using curated rankings of\nmedia bias, we examine the conditional probability of hateful comments given\nleft and right-leaning content. Finally, we study Dissenter as a social\nnetwork, and identify a core group of users with high comment toxicity.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 16:25:28 GMT"}, {"version": "v2", "created": "Sat, 26 Sep 2020 15:16:59 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Rye", "Erik", ""], ["Blackburn", "Jeremy", ""], ["Beverly", "Robert", ""]]}, {"id": "2009.01864", "submitter": "Christopher Gorham", "authors": "Christopher L Gorham", "title": "Developing Enterprise Cyber Situational Awareness", "comments": null, "journal-ref": "IJMIT (2020) Volume 12, Number 3", "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The topic will focus on the U.S. Department of Defense strategy towards\nimproving their network security defenses for the department and the steps they\nhave taken at the agency level where components under DOD such as The Defense\nInformation Systems Agency are working towards adding tools that provides\nadditional capabilities in the cyber space. This approach will be analyzed to\ndetermine if DOD goals address any of their vulnerabilities towards protecting\ntheir networks. One of the agencies under the DOD umbrella called The Defense\nInformation Systems Agency provides DOD a template on how to build a network\nthat relies upon layers of security to help it combat cyber attacks against its\nnetwork. Whether that provides an effective solution to DOD remains a question\ndue to the many components that operate under its direction. Managing these\nnetworks is the principle responsibilities for the Department of Defense.\nNevertheless, it does demonstrates that there are tools available to help DOD\nbuild an strong enterprise cyber network of situational awareness that\nstrengthens the ability to protect their network infrastructure.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 18:16:06 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Gorham", "Christopher L", ""]]}, {"id": "2009.01896", "submitter": "David Jurgens", "authors": "Hao Peng, Misha Teplitskiy, David Jurgens", "title": "Author Mentions in Science News Reveal Wide-Spread Ethnic Bias", "comments": "68 pages, 8 figures, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Media outlets play a key role in spreading scientific knowledge to the\ngeneral public and raising the profile of researchers among their peers. Yet,\ngiven time and space constraints, not all scholars can receive equal media\nattention, and journalists' choices of whom to mention are poorly understood.\nIn this study, we use a comprehensive dataset of 232,524 news stories from 288\nU.S.-based outlets covering 100,208 research papers across all sciences to\ninvestigate the rates at which scientists of different ethnicities are\nmentioned by name. We find strong evidence of ethnic biases in author mentions,\neven after controlling for a wide range of possible confounds. Specifically,\nauthors with non-British-origin names are significantly less likely to be\nmentioned or quoted than comparable British-origin named authors, even within\nthe stories of a particular news outlet covering a particular scientific venue\non a particular research topic. Instead, minority scholars are more likely to\nhave their names substituted with their role at their institution. This ethnic\nbias is consistent across all types of media outlets, with even larger\ndisparities in General-Interest outlets that tend to publish longer stories and\nhave dedicated editorial teams for accurately reporting science. Our findings\nreveal that the perceived ethnicity can substantially shape scientists' media\nattention, and, by our estimation, this bias has affected thousands of scholars\nunfairly.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 19:29:57 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Peng", "Hao", ""], ["Teplitskiy", "Misha", ""], ["Jurgens", "David", ""]]}, {"id": "2009.01902", "submitter": "Peng Hu", "authors": "Peng Hu", "title": "IoT-based Contact Tracing Systems for Infectious Diseases: Architecture\n  and Analysis", "comments": null, "journal-ref": "Proc. of The 2020 IEEE Global Communications Conference (GLOBECOM)", "doi": "10.1109/GLOBECOM42002.2020.9347957", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent COVID-19 pandemic has become a major threat to human health and\nwell-being. Non-pharmaceutical interventions such as contact tracing solutions\nare important to contain the spreads of COVID-19-like infectious diseases.\nHowever, current contact tracing solutions are fragmented with limited use of\nsensing technologies and centered on monitoring the interactions between\nindividuals without an analytical framework for evaluating effectiveness.\nTherefore, we need to first explore generic architecture for contact tracing in\nthe context of today's Internet of Things (IoT) technologies based on a broad\nrange of applicable sensors. A new architecture for IoT based solutions to\ncontact tracing is proposed and its overall effectiveness for disease\ncontainment is analyzed based on the traditional epidemiological models with\nthe simulation results. The proposed work aims to provide a framework for\nassisting future designs and evaluation of IoT-based contact tracing solutions\nand to enable data-driven collective efforts on combating current and future\ninfectious diseases.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 19:44:39 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 06:42:39 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Hu", "Peng", ""]]}, {"id": "2009.01960", "submitter": "Bilal Farooq", "authors": "Farah Samouh and Veronica Gluza and Shadi Djavadian and Seyed Mehdi\n  Meshkani and Bilal Farooq", "title": "Multimodal Autonomous Last Mile Delivery System Design and Application", "comments": "Accepted in the proceedings of 6th IEEE International Smart Cities\n  Conference, Sep 28 - Oct 1, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid increase in congestion, alternative solutions are needed to\nefficiently use the capacity of our existing networks. This paper focuses on\nexploring the emerging autonomous technologies for on-demand food delivery in\ncongested urban cities. Three different last mile food delivery systems are\nproposed in this study employing aerial and ground autonomous vehicles\ntechnologies. The three proposed systems are: robot delivery system, drone\ndelivery system and a hybrid delivery system. In the hybrid system the concept\nof hub-and-spoke network is explored in order to consolidate orders and reach\nmore destinations in less time. To investigate the performance of the three\nproposed delivery systems, they are applied to the city of Mississauga network,\nin an in-house agent-based simulation in MATLAB. 18 Scenarios are tested\ndiffering in terms of demand and fleet size. The results show that the hybrid\nrobot-drone delivery system performs the best with a fleet side of 25 robots\nand 15 drones and with an average preparation and delivery time less than the\nindividual robot and drone system by 48% and 42% respectively.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 23:41:35 GMT"}, {"version": "v2", "created": "Sat, 12 Sep 2020 21:12:58 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Samouh", "Farah", ""], ["Gluza", "Veronica", ""], ["Djavadian", "Shadi", ""], ["Meshkani", "Seyed Mehdi", ""], ["Farooq", "Bilal", ""]]}, {"id": "2009.02032", "submitter": "Rados{\\l}aw Michalski", "authors": "Mateusz Nurek, Rados{\\l}aw Michalski, Marian-Andrei Rizoiu", "title": "Hawkes-modeled telecommunication patterns reveal relationship dynamics\n  and personality traits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is not news that our mobile phones contain a wealth of private information\nabout us, and that is why we try to keep them secure. But even the traces of\nhow we communicate can also tell quite a bit about us. In this work, we start\nfrom the calling and texting history of 200 students enrolled in the Netsense\nstudy, and we link it to the type of relationships that students have with\ntheir peers, and even with their personality profiles. First, we show that a\nHawkes point process with a power-law decaying kernel can accurately model the\ncalling activity between peers. Second, we show that the fitted parameters of\nthe Hawkes model are predictive of the type of relationship and that the\ngeneralization error of the Hawkes process can be leveraged to detect changes\nin the relation types as they are happening. Last, we build descriptors for the\nstudents in the study by jointly modeling the communication series initiated by\nthem. We find that Hawkes-modeled telecommunication patterns can predict the\nstudents' Big5 psychometric traits almost as accurate as the user-filled\nsurveys pertaining to hobbies, activities, well-being, grades obtained, health\ncondition and the number of books they read. These results are significant, as\nthey indicate that information that usually resides outside the control of\nindividuals (such as call and text logs) reveal information about the\nrelationship they have, and even their personality traits.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 07:24:49 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 09:56:47 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Nurek", "Mateusz", ""], ["Michalski", "Rados\u0142aw", ""], ["Rizoiu", "Marian-Andrei", ""]]}, {"id": "2009.02043", "submitter": "Fredrik Olsson", "authors": "Fredrik Olsson, Magnus Sahlgren", "title": "Data Readiness for Natural Language Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document concerns data readiness in the context of machine learning and\nNatural Language Processing. It describes how an organization may proceed to\nidentify, make available, validate, and prepare data to facilitate automated\nanalysis methods. The contents of the document is based on the practical\nchallenges and frequently asked questions we have encountered in our work as an\napplied research institute with helping organizations and companies, both in\nthe public and private sectors, to use data in their business processes.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 07:53:43 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 12:03:58 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Olsson", "Fredrik", ""], ["Sahlgren", "Magnus", ""]]}, {"id": "2009.02093", "submitter": "Arthur-Jozsef Molnar", "authors": "Iuliana Marin and Maria Iuliana Bocicor and Arthur-Jozsef Molnar", "title": "Cyber-Physical Platform for Preeclampsia Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hypertension-related conditions are the most prevalent complications of\npregnancy worldwide. They manifest in up to 8% of cases and if left untreated,\ncan lead to serious detrimental effects. Early detection of their sudden onset\ncan help physicians alleviate the condition and improve outcomes for both\nwould-be mother and baby. Today's prevalence of smartphones and cost-effective\nwearable technology provide new opportunities for individualized medicine.\nExisting devices promote heart health, they monitor and encourage physical\nactivity and measure sleep quality. This builds interest and encourages users\nto require more advanced features. We believe these aspects form suitable\nconditions to create and market specialized wearable devices. The present paper\ndetails a cyber-physical system built around an intelligent bracelet for\nmonitoring hypertension-related conditions tailored to pregnant women. The\nbracelet uses a microfluidic layer that is compressed by the blood pressing\nagainst the arterial wall. Integrated sensors register the waveform and send it\nto the user's smartphone, where the systolic and diastolic values are\ndetermined. The system is currently developed under European Union research\nfunding, and includes a software server where data is stored and further\nprocessing is carried out through machine learning.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 10:15:00 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Marin", "Iuliana", ""], ["Bocicor", "Maria Iuliana", ""], ["Molnar", "Arthur-Jozsef", ""]]}, {"id": "2009.02126", "submitter": "Sanchari Das", "authors": "Sayar Karmakar, Sanchari Das", "title": "Evaluating the Impact of COVID-19 on Cyberbullying through Bayesian\n  Trend Analysis", "comments": "arXiv admin note: text overlap with arXiv:2008.13613", "journal-ref": "The European Interdisciplinary Cybersecurity Conference (EICC)\n  2020", "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COVID-19's impact has surpassed from personal and global health to our social\nlife. In terms of digital presence, it is speculated that during pandemic,\nthere has been a significant rise in cyberbullying. In this paper, we have\nexamined the hypothesis of whether cyberbullying and reporting of such\nincidents have increased in recent times. To evaluate the speculations, we\ncollected cyberbullying related public tweets (N=454,046) posted between\nJanuary 1st, 2020 -- June 7th, 2020. A simple visual frequentist analysis\nignores serial correlation and does not depict changepoints as such. To address\ncorrelation and a relatively small number of time points, Bayesian estimation\nof the trends is proposed for the collected data via an autoregressive Poisson\nmodel. We show that this new Bayesian method detailed in this paper can clearly\nshow the upward trend on cyberbullying-related tweets since mid-March 2020.\nHowever, this evidence itself does not signify a rise in cyberbullying but\nshows a correlation of the crisis with the discussion of such incidents by\nindividuals. Our work emphasizes a critical issue of cyberbullying and how a\nglobal crisis impacts social media abuse and provides a trend analysis model\nthat can be utilized for social media data analysis in general.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 00:01:32 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Karmakar", "Sayar", ""], ["Das", "Sanchari", ""]]}, {"id": "2009.02131", "submitter": "Wei Duan", "authors": "Wei Duan, Yancheng Ji, Yan Zhang, Guoan Zhang, Valerio Frascolla and\n  Xin Li", "title": "5G Technologies Based Remote E-Health: Architecture, Applications, and\n  Solutions", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, many countries are facing the problems of aging population,\nserious imbalance of medical resources supply and demand, as well as uneven\ngeographical distribution, resulting in a huge demand for remote e-health.\nParticularly, with invasions of COVID-19, the health of people and even social\nstability have been challenged unprecedentedly. To contribute to these urgent\nproblems, this article proposes a general architecture of the remote e-health,\nwhere the city hospital provides the technical supports and services for remote\nhospitals. Meanwhile, 5G technologies supported telemedicine is introduced to\nsatisfy the high-speed transmission of massive multimedia medical data, and\nfurther realize the sharing of medical resources. Moreover, to turn passivity\ninto initiative to prevent COVID-19, a broad area epidemic prevention and\ncontrol scheme is also investigated, especially for the remote areas. We\ndiscuss their principles and key features, and foresee the challenges,\nopportunities, and future research trends. Finally, a node value and content\npopularity based caching strategy is introduced to provide a preliminary\nsolution of the massive data storage and low-latency transmission.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 12:09:41 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Duan", "Wei", ""], ["Ji", "Yancheng", ""], ["Zhang", "Yan", ""], ["Zhang", "Guoan", ""], ["Frascolla", "Valerio", ""], ["Li", "Xin", ""]]}, {"id": "2009.02156", "submitter": "Andreas Kamilaris", "authors": "P. Papademas, E. Kamilari, M. Aspri, D. A Anagnostopoulos, P.\n  Mousikos, A. Kamilaris and D. Tsaltas", "title": "Investigation of the Cyprus donkey milk bacterial diversity by 16SrDNA\n  high-throughput sequencing in a Cyprus donkey farm", "comments": "Accepted for publication at Journal of Dairy Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interest in milk originating from donkeys is growing worldwide due to its\nclaimed functional and nutritional properties, especially for sensitive\npopulation groups, such as infants with cow milk protein allergy. The current\nstudy aimed to assess the microbiological quality of donkey milk produced in a\ndonkey farm in Cyprus using cultured-based and high-throughput sequencing (HTS)\ntechniques. The culture-based microbiological analysis showed very low\nmicrobial counts, while important food-borne pathogens were not detected in any\nsample. In addition, HTS was applied to characterize the bacterial communities\nof donkey milk samples. Donkey milk was mostly comprised of: Gram-negative\nProteobacteria, including Sphingomonas, Pseudomonas Mesorhizobium and\nAcinetobacter; lactic acid bacteria, including Lactobacillus and Streptococcus;\nthe endospores forming Clostridium; and the environmental genera Flavobacterium\nand Ralstonia, detected in lower relative abundances. The results of the study\nsupport existing findings that donkey milk contains mostly Gram-negative\nbacteria. Moreover, it raises questions regarding the contribution: a) of\nantimicrobial agents (i.e. lysozyme, peptides) in shaping the microbial\ncommunities and b) of the bacterial microbiota to the functional value of\ndonkey milk.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 12:42:54 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Papademas", "P.", ""], ["Kamilari", "E.", ""], ["Aspri", "M.", ""], ["Anagnostopoulos", "D. A", ""], ["Mousikos", "P.", ""], ["Kamilaris", "A.", ""], ["Tsaltas", "D.", ""]]}, {"id": "2009.02243", "submitter": "Lance Eliot", "authors": "Lance Eliot", "title": "Robustness and Overcoming Brittleness of AI-Enabled Legal\n  Micro-Directives: The Role of Autonomous Levels of AI Legal Reasoning", "comments": "21 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research by legal scholars suggests that the law might inevitably be\ntransformed into legal micro-directives consisting of legal rules that are\nderived from legal standards or that are otherwise produced automatically or\nvia the consequent derivations of legal goals and then propagated via\nautomation for everyday use as readily accessible lawful directives throughout\nsociety. This paper examines and extends the legal micro-directives theories in\nthree crucial respects: (1) By indicating that legal micro-directives are\nlikely to be AI-enabled and evolve over time in scope and velocity across the\nautonomous levels of AI Legal Reasoning, (2) By exploring the trade-offs\nbetween legal standards and legal rules as the imprinters of the\nmicro-directives, and (3) By illuminating a set of brittleness exposures that\ncan undermine legal micro-directives and proffering potential mitigating\nremedies to seek greater robustness in the instantiation and promulgation of\nsuch AI-powered lawful directives.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 05:09:03 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Eliot", "Lance", ""]]}, {"id": "2009.02483", "submitter": "Arthur-Jozsef Molnar", "authors": "Iuliana Marin and Maria Iuliana Bocicor and Arthur-Jozsef Molnar", "title": "Intelligent Luminaire based Real-time Indoor Positioning for Assisted\n  Living", "comments": null, "journal-ref": "In Proceedings of the 15th International Conference on Evaluation\n  of Novel Approaches to Software Engineering - Volume 1: ENASE 2020, ISBN\n  978-989-758-421-3, pages 548-555", "doi": "10.5220/0009578705480555", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an experimental evaluation on the accuracy of indoor\nlocalisation. The research was carried out as part of a European Union project\ntargeting the creation of ICT solutions for older adult care. Current\nexpectation is that advances in technology will supplement the human workforce\nrequired for older adult care, improve their quality of life and decrease\nhealthcare expenditure. The proposed approach is implemented in the form of a\nconfigurable cyber-physical system that enables indoor localization and\nmonitoring of older adults living at home or in residential buildings. Hardware\nconsists of custom developed luminaires with sensing, communication and\nprocessing capabilities. They replace the existing lighting infrastructure, do\nnot look out of place and are cost effective. The luminaires record the\nstrength of a Bluetooth signal emitted by a wearable device equipped by the\nmonitored user. The system's software server uses trilateration to calculate\nthe person's location based on known luminaire placement and recorded signal\nstrengths. However, multipath fading caused by the presence of walls, furniture\nand other objects introduces localisation errors. Our previous experiments\nshowed that room-level accuracy can be achieved using software-based filtering\nfor a stationary subject. Our current objective is to assess system accuracy in\nthe context of a moving subject, and ascertain whether room-level localization\nis feasible in real time.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 07:19:20 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Marin", "Iuliana", ""], ["Bocicor", "Maria Iuliana", ""], ["Molnar", "Arthur-Jozsef", ""]]}, {"id": "2009.02502", "submitter": "Arthur-Jozsef Molnar", "authors": "Maria Iuliana Bocicor and Maria Dasc\\u{a}lu and Agnieszka Gaczowska\n  and Sorin Hostiuc and Alin Moldoveanu and Antonio Molina and Arthur-Jozsef\n  Molnar and Ionu\\c{t} Negoi and Vlad Racovi\\c{t}\\u{a}", "title": "Technological Platform for the Prevention and Management of Healthcare\n  Associated Infections and Outbreaks", "comments": null, "journal-ref": "Damiani E., Spanoudakis G., Maciaszek L. (eds) Evaluation of Novel\n  Approaches to Software Engineering. ENASE 2017. Communications in Computer\n  and Information Science, vol 866. Springer, Cham", "doi": "10.1007/978-3-319-94135-6_4", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hospital acquired infections are infections that occur in patients during\nhospitalization, which were not present at the time of admission. They are\namong the most common adverse events in healthcare around the world, leading to\nincreased mortality and morbidity rates, prolonged hospitalization periods and\nconsiderable financial burden on both hospitals and patients. Preventive\nguidelines and regulations have been devised, however compliance to these is\nfrequently poor and there is much room for improvement. This paper presents the\nprototype of an extensible, configurable cyber-physical system, developed under\nEuropean Union funding, that will assist in the prevention of hospital\ninfections and outbreaks. Integrating a wireless sensor network for the\nsurveillance of clinical processes with configurable monitoring software built\naround a workflow engine as key component, our solution detects deviations from\nestablished hygiene practices and provides real-time information and alerts\nwhenever an infection risk is discovered. The platform is described from both\nhardware and software perspective, with emphasis on the wireless network's\nelements as well as the most important software components. Furthermore, two\nclinical workflows of different complexity, which are included in the system\nprototype are detailed. The finalized system is expected to facilitate the\ncreation and automated monitoring of clinical workflows that are associated\nwith over 90% of hospital infections.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 09:35:49 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Bocicor", "Maria Iuliana", ""], ["Dasc\u0103lu", "Maria", ""], ["Gaczowska", "Agnieszka", ""], ["Hostiuc", "Sorin", ""], ["Moldoveanu", "Alin", ""], ["Molina", "Antonio", ""], ["Molnar", "Arthur-Jozsef", ""], ["Negoi", "Ionu\u0163", ""], ["Racovi\u0163\u0103", "Vlad", ""]]}, {"id": "2009.02603", "submitter": "Lav Varshney", "authors": "Lav R. Varshney", "title": "Respect for Human Autonomy in Recommender Systems", "comments": "2 page position paper presented at 3rd FAccTRec Workshop on\n  Responsible Recommendation (RecSys 2020 Workshop)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems can influence human behavior in significant ways, in some\ncases making people more machine-like. In this sense, recommender systems may\nbe deleterious to notions of human autonomy. Many ethical systems point to\nrespect for human autonomy as a key principle arising from human rights\nconsiderations, and several emerging frameworks for AI include this principle.\nYet, no specific formalization has been defined. Separately, self-determination\ntheory shows that autonomy is an innate psychological need for people, and\nmoreover has a significant body of experimental work that formalizes and\nmeasures level of human autonomy. In this position paper, we argue that there\nis a need to specifically operationalize respect for human autonomy in the\ncontext of recommender systems. Moreover, that such an operational definition\ncan be developed based on well-established approaches from experimental\npsychology, which can then be used to design future recommender systems that\nrespect human autonomy.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 21:39:34 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Varshney", "Lav R.", ""]]}, {"id": "2009.02651", "submitter": "Ying Zhao", "authors": "Zengsheng Zhong, Shuirun Wei, Yeting Xu, Ying Zhao, Fangfang Zhou,\n  Feng Luo, and Ronghua Shi", "title": "SilkViser:A Visual Explorer of Blockchain-based Cryptocurrency\n  Transaction Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many blockchain-based cryptocurrencies provide users with online blockchain\nexplorers for viewing online transaction data. However, traditional blockchain\nexplorers mostly present transaction information in textual and tabular forms.\nSuch forms make understanding cryptocurrency transaction mechanisms difficult\nfor novice users (NUsers). They are also insufficiently informative for\nexperienced users (EUsers) to recognize advanced transaction information. This\nstudy introduces a new online cryptocurrency transaction data viewing tool\ncalled SilkViser. Guided by detailed scenario and requirement analyses, we\ncreate a series of appreciating visualization designs, such as paper\nledger-inspired block and blockchain visualizations and ancient copper\ncoin-inspired transaction visualizations, to help users understand\ncryptocurrency transaction mechanisms and recognize advanced transaction\ninformation. We also provide a set of lightweight interactions to facilitate\neasy and free data exploration. Moreover, a controlled user study is conducted\nto quantitatively evaluate the usability and effectiveness of SilkViser.\nResults indicate that SilkViser can satisfy the requirements of NUsers and\nEUsers. Our visualization designs can compensate for the inexperience of NUsers\nin data viewing and attract potential users to participate in cryptocurrency\ntransactions.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 05:54:11 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Zhong", "Zengsheng", ""], ["Wei", "Shuirun", ""], ["Xu", "Yeting", ""], ["Zhao", "Ying", ""], ["Zhou", "Fangfang", ""], ["Luo", "Feng", ""], ["Shi", "Ronghua", ""]]}, {"id": "2009.02661", "submitter": "Himanshu Buckchash", "authors": "Vipul Bansal, Himanshu Buckchash, Balasubramanian Raman", "title": "Computational Models for Academic Performance Estimation", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluation of students' performance for the completion of courses has been a\nmajor problem for both students and faculties during the work-from-home period\nin this COVID pandemic situation. To this end, this paper presents an in-depth\nanalysis of deep learning and machine learning approaches for the formulation\nof an automated students' performance estimation system that works on partially\navailable students' academic records. Our main contributions are (a) a large\ndataset with fifteen courses (shared publicly for academic research) (b)\nstatistical analysis and ablations on the estimation problem for this dataset\n(c) predictive analysis through deep learning approaches and comparison with\nother arts and machine learning algorithms. Unlike previous approaches that\nrely on feature engineering or logical function deduction, our approach is\nfully data-driven and thus highly generic with better performance across\ndifferent prediction tasks.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 07:31:37 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Bansal", "Vipul", ""], ["Buckchash", "Himanshu", ""], ["Raman", "Balasubramanian", ""]]}, {"id": "2009.02673", "submitter": "Praveen Damacharla", "authors": "Parashar Dhakal, Praveen Damacharla, Ahmad Y. Javaid, Hari K. Vege and\n  Vijay K. Devabhaktuni", "title": "IVACS: Intelligent Voice Assistant for Coronavirus Disease (COVID-19)\n  Self-Assessment", "comments": null, "journal-ref": "1st International Conference on Artificial Intelligence & Modern\n  Assistive Technology (ICAIMAT), Riyadh Saudi Arabia, November, 24-26, 2020", "doi": "10.1109/ICAIMAT51101.2020.9308013", "report-no": "9308013", "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At the time of writing this paper, the world has around eleven million cases\nof COVID-19, scientifically known as severe acute respiratory syndrome\ncorona-virus 2 (SARS-COV-2). One of the popular critical steps various health\norganizations are advocating to prevent the spread of this contagious disease\nis self-assessment of symptoms. Multiple organizations have already pioneered\nmobile and web-based applications for self-assessment of COVID-19 to reduce\nthis global pandemic's spread. We propose an intelligent voice-based assistant\nfor COVID-19 self-assessment (IVACS). This interactive assistant has been built\nto diagnose the symptoms related to COVID-19 using the guidelines provided by\nthe Centers for Disease Control and Prevention (CDC) and the World Health\nOrganization (WHO). The empirical testing of the application has been performed\nwith 22 human subjects, all volunteers, using the NASA Task Load Index (TLX),\nand subjects performance accuracy has been measured. The results indicate that\nthe IVACS is beneficial to users. However, it still needs additional research\nand development to promote its widespread application.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 08:48:08 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Dhakal", "Parashar", ""], ["Damacharla", "Praveen", ""], ["Javaid", "Ahmad Y.", ""], ["Vege", "Hari K.", ""], ["Devabhaktuni", "Vijay K.", ""]]}, {"id": "2009.02696", "submitter": "Giovanni Da San Martino", "authors": "G. Da San Martino, A. Barr\\'on-Cede\\~no, H. Wachsmuth, R. Petrov, P.\n  Nakov", "title": "SemEval-2020 Task 11: Detection of Propaganda Techniques in News\n  Articles", "comments": "37 pages, to be published in Proceedings of the 14th International\n  Workshop on Semantic Evaluation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the results and the main findings of SemEval-2020 Task 11 on\nDetection of Propaganda Techniques in News Articles. The task featured two\nsubtasks. Subtask SI is about Span Identification: given a plain-text document,\nspot the specific text fragments containing propaganda. Subtask TC is about\nTechnique Classification: given a specific text fragment, in the context of a\nfull document, determine the propaganda technique it uses, choosing from an\ninventory of 14 possible propaganda techniques. The task attracted a large\nnumber of participants: 250 teams signed up to participate and 44 made a\nsubmission on the test set. In this paper, we present the task, analyze the\nresults, and discuss the system submissions and the methods they used. For both\nsubtasks, the best systems used pre-trained Transformers and ensembles.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 10:05:43 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Martino", "G. Da San", ""], ["Barr\u00f3n-Cede\u00f1o", "A.", ""], ["Wachsmuth", "H.", ""], ["Petrov", "R.", ""], ["Nakov", "P.", ""]]}, {"id": "2009.02781", "submitter": "Thomas Bartz-Beielstein", "authors": "Thomas Bartz-Beielstein, Eva Bartz, Frederik Rehbach, Olaf Mersmann", "title": "Optimization of High-dimensional Simulation Models Using Synthetic Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulation models are valuable tools for resource usage estimation and\ncapacity planning. In many situations, reliable data is not available. We\nintroduce the BuB simulator, which requires only the specification of plausible\nintervals for the simulation parameters. By performing a surrogate-model based\noptimization, improved simulation model parameters can be determined.\nFurthermore, a detailed statistical analysis can be performed, which allows\ndeep insights into the most important model parameters and their interactions.\nThis information can be used to screen the parameters that should be further\ninvestigated. To exemplify our approach, a capacity and resource planning task\nfor a hospital was simulated and optimized. The study explicitly covers\ndifficulties caused by the COVID-19 pandemic. It can be shown, that even if\nonly limited real-world data is available, the BuB simulator can be\nbeneficially used to consider worst- and best-case scenarios. The BuB simulator\ncan be extended in many ways, e.g., by adding further resources (personal\nprotection equipment, staff, pharmaceuticals) or by specifying several cohorts\n(based on age, health status, etc.).\n  Keywords: Synthetic data, discrete-event simulation, surrogate-model-based\noptimization, COVID-19, machine learning, artificial intelligence, hospital\nresource planning, prediction tool, capacity planning.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 17:21:41 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Bartz-Beielstein", "Thomas", ""], ["Bartz", "Eva", ""], ["Rehbach", "Frederik", ""], ["Mersmann", "Olaf", ""]]}, {"id": "2009.02895", "submitter": "Maryam Abdirad", "authors": "Maryam Abdirad, Jamal Shahrabi", "title": "Detecting Informal Organization Through Data Mining Techniques", "comments": "18 pages, 2 figures, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the main topics in human resources management is the subject of\ninformal organizations in the organization such that recognizing and managing\nsuch informal organizations play an important role in the organizations. Some\nmanagers are trying to recognize the relations between informal organizations\nand being a member of them by which they could assist the formal organization\ndevelopment. Methods of recognizing informal organizations are complicated and\noccasionally even impossible. This study aims to provide a method for\nrecognizing such organizations using data mining techniques. This study\nclassifies indices of human resources influencing the creation of informal\norganizations, including individual, social, and work characteristics of an\norganizations employees. Then, a questionnaire was designed and distributed\namong employees. A database was created from obtained data. Applied data mining\ntechniques in this study are factor analysis, clustering by K-means,\nclassification by decision trees, and finally association rule mining by GRI\nalgorithm. At the end, a model is presented that is applicable for recognizing\nthe similar characteristics between people for optimal recognition of informal\norganizations and usage of this information.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 05:42:37 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Abdirad", "Maryam", ""], ["Shahrabi", "Jamal", ""]]}, {"id": "2009.03001", "submitter": "Alberto Gutierrez-Torre", "authors": "Alberto Gutierrez-Torre, Josep Ll. Berral, David Buchaca, Marc\n  Guevara, Albert Soret, David Carrera", "title": "Improving Maritime Traffic Emission Estimations on Missing Data with\n  CRBMs", "comments": "12 pages, 7 figures. Postprint accepted manuscript, find the full\n  version at Engineering Applications of Artificial Intelligence\n  (https://doi.org/10.1016/j.engappai.2020.103793)", "journal-ref": "Engineering Applications of Artificial Intelligence Volume 94,\n  September 2020, 103793", "doi": "10.1016/j.engappai.2020.103793", "report-no": null, "categories": "cs.CY cs.CE cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maritime traffic emissions are a major concern to governments as they heavily\nimpact the Air Quality in coastal cities. Ships use the Automatic\nIdentification System (AIS) to continuously report position and speed among\nother features, and therefore this data is suitable to be used to estimate\nemissions, if it is combined with engine data. However, important ship features\nare often inaccurate or missing. State-of-the-art complex systems, like CALIOPE\nat the Barcelona Supercomputing Center, are used to model Air Quality. These\nsystems can benefit from AIS based emission models as they are very precise in\npositioning the pollution. Unfortunately, these models are sensitive to missing\nor corrupted data, and therefore they need data curation techniques to\nsignificantly improve the estimation accuracy. In this work, we propose a\nmethodology for treating ship data using Conditional Restricted Boltzmann\nMachines (CRBMs) plus machine learning methods to improve the quality of data\npassed to emission models. Results show that we can improve the default methods\nproposed to cover missing data. In our results, we observed that using our\nmethod the models boosted their accuracy to detect otherwise undetectable\nemissions. In particular, we used a real data-set of AIS data, provided by the\nSpanish Port Authority, to estimate that thanks to our method, the model was\nable to detect 45% of additional emissions, of additional emissions,\nrepresenting 152 tonnes of pollutants per week in Barcelona and propose new\nfeatures that may enhance emission modeling.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 10:32:43 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 09:04:42 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Gutierrez-Torre", "Alberto", ""], ["Berral", "Josep Ll.", ""], ["Buchaca", "David", ""], ["Guevara", "Marc", ""], ["Soret", "Albert", ""], ["Carrera", "David", ""]]}, {"id": "2009.03005", "submitter": "Mohammed Al-Rawi", "authors": "Mohammed Al-Rawi and Joeran Beel", "title": "Towards an Interoperable Data Protocol Aimed at Linking the Fashion\n  Industry with AI Companies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fashion industry is looking forward to use artificial intelligence\ntechnologies to enhance their processes, services, and applications. Although\nthe amount of fashion data currently in use is increasing, there is a large gap\nin data exchange between the fashion industry and the related AI companies, not\nto mention the different structure used for each fashion dataset. As a result,\nAI companies are relying on manually annotated fashion data to build different\napplications. Furthermore, as of this writing, the terminology, vocabulary and\nmethods of data representation used to denote fashion items are still ambiguous\nand confusing. Hence, it is clear that the fashion industry and AI companies\nwill benefit from a protocol that allows them to exchange and organise fashion\ninformation in a unified way. To achieve this goal we aim (1) to define a\nprotocol called DDOIF that will allow interoperability of fashion data; (2) for\nDDOIF to contain diverse entities including extensive information on clothing\nand accessories attributes in the form of text and various media formats; and\n(3)To design and implement an API that includes, among other things, functions\nfor importing and exporting a file built according to the DDOIF protocol that\nstores all information about a single item of clothing. To this end, we\nidentified over 1000 class and subclass names used to name fashion items and\nuse them to build the DDOIF dictionary. We make DDOIF publicly available to all\ninterested users and developers and look forward to engaging more collaborators\nto improve and enrich it.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 10:40:09 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Al-Rawi", "Mohammed", ""], ["Beel", "Joeran", ""]]}, {"id": "2009.03011", "submitter": "Shaoshan Liu", "authors": "Shaoshan Liu", "title": "Critical Business Decision Making for Technology Startups -- A PerceptIn\n  Case Study", "comments": "to appear in IEEE Engineering Management Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AR cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most business decisions are made with analysis, but some are judgment calls\nnot susceptible to analysis due to time or information constraints. In this\narticle, we present a real-life case study of critical business decision making\nof PerceptIn, an autonomous driving technology startup. In early years of\nPerceptIn, PerceptIn had to make a decision on the design of computing systems\nfor its autonomous vehicle products. By providing details on PerceptIn's\ndecision process and the results of the decision, we hope to provide some\ninsights that can be beneficial to entrepreneurs and engineering managers in\ntechnology startups.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 10:52:20 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Liu", "Shaoshan", ""]]}, {"id": "2009.03015", "submitter": "Sahar Abdelnabi", "authors": "Sahar Abdelnabi and Mario Fritz", "title": "Adversarial Watermarking Transformer: Towards Tracing Text Provenance\n  with Data Hiding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in natural language generation have introduced powerful\nlanguage models with high-quality output text. However, this raises concerns\nabout the potential misuse of such models for malicious purposes. In this\npaper, we study natural language watermarking as a defense to help better mark\nand trace the provenance of text. We introduce the Adversarial Watermarking\nTransformer (AWT) with a jointly trained encoder-decoder and adversarial\ntraining that, given an input text and a binary message, generates an output\ntext that is unobtrusively encoded with the given message. We further study\ndifferent training and inference strategies to achieve minimal changes to the\nsemantics and correctness of the input text.\n  AWT is the first end-to-end model to hide data in text by automatically\nlearning -- without ground truth -- word substitutions along with their\nlocations in order to encode the message. We empirically show that our model is\neffective in largely preserving text utility and decoding the watermark while\nhiding its presence against adversaries. Additionally, we demonstrate that our\nmethod is robust against a range of attacks.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 11:01:24 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 12:21:27 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Abdelnabi", "Sahar", ""], ["Fritz", "Mario", ""]]}, {"id": "2009.03037", "submitter": "Gregory Porumbescu", "authors": "Gregory A. Porumbescu, Donald Moynihan, Jason Anastasopoulos, Asmus\n  Leth Olsen", "title": "Motivated Reasoning and Blame: Responses to Performance Framing and\n  Outgroup Triggers during COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To manage citizen evaluations of government performance, public officials use\nblame avoidance strategies when communicating performance information. We\nexamine two prominent presentational strategies: scapegoating and spinning,\nwhile testing how public responses vary depending on whether they are\nideologically aligned with the public official. We examine these relationships\nin the context of the COVID-19 pandemic, where the Trump administration sought\nto shift blame by scapegoating outgroups (by using the term \"Chinese virus\"),\nand framing performance information on COVID-19 testing in positive terms.\nUsing a novel pre-registered survey experiment that incorporates open and\nclose-ended items, we offer three main findings. First, there is clear evidence\nof motivated reasoning: conservatives rate the performance of the Trump\nadministration more positively and are more apt to blame prominent Democrats,\nChinese residents and the Chinese Government. Second, performance information\nframing was found to impact blame attribution among conservatives, but only for\nopen-ended responses. Third, while exposure to the term \"Chinese virus\"\nincreased blame assigned to Chinese residents among all participants,\nconservatives exposed to the term appeared to blame President Trump more,\nsuggesting repeated use of divisive blame shifting strategies may alienate even\nsupporters.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 12:49:00 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Porumbescu", "Gregory A.", ""], ["Moynihan", "Donald", ""], ["Anastasopoulos", "Jason", ""], ["Olsen", "Asmus Leth", ""]]}, {"id": "2009.03087", "submitter": "Josimar Chire Saire", "authors": "Josimar Edinson Chire Saire, Honorio Apaza Alanoca", "title": "Text Mining over Curriculum Vitae of Peruvian Professionals using\n  Official Scientific Site DINA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last decade, Peruvian government started to invest and promote\nScience and Technology through Concytec(National Council of Science and\nTechnology). Many programs are oriented to support research projects, expenses\nfor paper presentation, organization of conferences/ events and more. Concytec\ncreated a National Directory of Researchers(DINA) where professionals can\ncreate and add curriculum vitae, Concytec can provide official title of\nResearcher following some criterion for the evaluation. The actual paper aims\nto conduct an exploratory analysis over the curriculum vitae of Peruvian\nProfessionals using Data Mining Approach to understand Peruvian context.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 13:16:34 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Saire", "Josimar Edinson Chire", ""], ["Alanoca", "Honorio Apaza", ""]]}, {"id": "2009.03088", "submitter": "Liadh Kelly", "authors": "Liadh Kelly and Simone van der Burg and Aine Regan and Peter Mooney", "title": "Report on the 2019 Workshop on Smart Farming and Data Analytics (SFDAI)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 1st National workshop on Smart Farming and Data Analytics took place at\nMaynooth University in Ireland on June 12, 2019. The workshop included two\ninvited keynote presentations, invited talks and breakout group discussions.\nThe workshop attracted in the order of 50 participants, consisting of a mixture\nof computer scientists, general scientists, farmers, farm advisors, and\nagricultural business representatives. This allowed for lively discussion and\ncross-fertilization of ideas. And showed the significant interest in the smart\nfarming domain, the many research challenges faced in the space and the\npotential for data analytics and information retrieval here.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 13:17:18 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Kelly", "Liadh", ""], ["van der Burg", "Simone", ""], ["Regan", "Aine", ""], ["Mooney", "Peter", ""]]}, {"id": "2009.03164", "submitter": "Yulei Wu", "authors": "Yulei Wu, Hong-Ning Dai, Hao Wang, Kim-Kwang Raymond Choo", "title": "Blockchain-based Privacy Preservation for 5G-enabled Drone\n  Communications", "comments": "8 pages, 3 figure, accepted by IEEE Network", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  5G-enabled drones have potential applications in a variety of both military\nand civilian settings (e.g., monitoring and tracking of individuals in\ndemonstrations and/or enforcing of social / physical distancing during\npandemics such as COVID-19). Such applications generally involve the collection\nand dissemination of (massive) data from the drones to remote data centres for\nstorage and analysis, for example via 5G networks. Consequently, there are\nsecurity and privacy considerations underpinning 5G-enabled drone\ncommunications. We posit the potential of leveraging blockchain to facilitate\nprivacy preservation, and therefore in this article we will review existing\nblockchain-based solutions after introducing the architecture for 5G-enabled\ndrone communications and blockchain. We will also review existing legislation\nand data privacy regulations that need to be considered in the design of\nblockchain-based solutions, as well as identifying potential challenges and\nopen issues which will hopefully inform future research agenda.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 15:27:52 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Wu", "Yulei", ""], ["Dai", "Hong-Ning", ""], ["Wang", "Hao", ""], ["Choo", "Kim-Kwang Raymond", ""]]}, {"id": "2009.03183", "submitter": "Vincent Grari", "authors": "Vincent Grari, Oualid El Hajouji, Sylvain Lamprier, Marcin Detyniecki", "title": "Learning Unbiased Representations via R\\'enyi Minimization", "comments": "23 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, significant work has been done to include fairness\nconstraints in the training objective of machine learning algorithms. Many\nstate-of the-art algorithms tackle this challenge by learning a fair\nrepresentation which captures all the relevant information to predict the\noutput Y while not containing any information about a sensitive attribute S. In\nthis paper, we propose an adversarial algorithm to learn unbiased\nrepresentations via the Hirschfeld-Gebelein-Renyi (HGR) maximal correlation\ncoefficient. We leverage recent work which has been done to estimate this\ncoefficient by learning deep neural network transformations and use it as a\nminmax game to penalize the intrinsic bias in a multi dimensional latent\nrepresentation. Compared to other dependence measures, the HGR coefficient\ncaptures more information about the non-linear dependencies with the sensitive\nvariable, making the algorithm more efficient in mitigating bias in the\nrepresentation. We empirically evaluate and compare our approach and\ndemonstrate significant improvements over existing works in the field.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 15:48:24 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Grari", "Vincent", ""], ["Hajouji", "Oualid El", ""], ["Lamprier", "Sylvain", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "2009.03300", "submitter": "Dan Hendrycks", "authors": "Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika,\n  Dawn Song, Jacob Steinhardt", "title": "Measuring Massive Multitask Language Understanding", "comments": "ICLR 2021; the test and code is available at\n  https://github.com/hendrycks/test", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new test to measure a text model's multitask accuracy. The test\ncovers 57 tasks including elementary mathematics, US history, computer science,\nlaw, and more. To attain high accuracy on this test, models must possess\nextensive world knowledge and problem solving ability. We find that while most\nrecent models have near random-chance accuracy, the very largest GPT-3 model\nimproves over random chance by almost 20 percentage points on average. However,\non every one of the 57 tasks, the best models still need substantial\nimprovements before they can reach expert-level accuracy. Models also have\nlopsided performance and frequently do not know when they are wrong. Worse,\nthey still have near-random accuracy on some socially important subjects such\nas morality and law. By comprehensively evaluating the breadth and depth of a\nmodel's academic and professional understanding, our test can be used to\nanalyze models across many tasks and to identify important shortcomings.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 17:59:25 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 05:06:57 GMT"}, {"version": "v3", "created": "Tue, 12 Jan 2021 18:57:11 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Hendrycks", "Dan", ""], ["Burns", "Collin", ""], ["Basart", "Steven", ""], ["Zou", "Andy", ""], ["Mazeika", "Mantas", ""], ["Song", "Dawn", ""], ["Steinhardt", "Jacob", ""]]}, {"id": "2009.03619", "submitter": "Gillian Bolsover", "authors": "Gillian Bolsover", "title": "Black Lives Matter discourse on US social media during COVID: polarised\n  positions enacted in a new event", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Black Lives Matter has been a major force for social change in the US since\n2014, with social media playing a core role in the development and\nproliferation of the movement. The largest protests in US history occurred in\nlate May and early June 2020, following the death of George Floyd at the hands\nof Minneapolis police. This incident reignited widespread support for the BLM\nmovement. The protests were notable not only for their size but also that they\noccurred at a time the US was still struggling to control the spread of the\nCOVID-19 pandemic, with more than 20,000 new cases per day. With protest\nconditions and police crowd control tactics exacerbating disease spread and\nwith COVID disproportionately affecting minority populations, it was\nhypothesised that participation in and support for the protests would involve a\nbalancing act between the risks of systemic racism and of disease spread.\nHowever, social media data suggest that this was not the case, with discussion\nof the BLM movement replacing discussion of COVID on US social media. Neither\nsupporters or opposers of the BLM movement or protest action mentioned COVID as\na factor. Framings of the movement by BLM supporters largely replicated those\nof earlier studies, with new frames emerging surrounding the opposition the\nmovement has received from racism, police militarisation and President Donald\nTrump. Discourse evidenced worrying levels of polarisation, hate, incivility\nand conspiracy content and bore many similarities to previously studied COVID\ndiscourse. This suggests that George Floyd's death, as yet another example of\nan African American man killed by US police, was largely seen through\nestablished, polarised identity positions that made reactions to the incident\nand resulting protest largely a foregone conclusion, established and\narticulated without reference to the ongoing pandemic.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 09:56:16 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Bolsover", "Gillian", ""]]}, {"id": "2009.03681", "submitter": "Maxime De Bois", "authors": "Maxime De Bois, Hamdi Amroun, Mehdi Ammi", "title": "Energy Expenditure Estimation Through Daily Activity Recognition Using a\n  Smart-phone", "comments": null, "journal-ref": "2018 IEEE 4th World Forum on Internet of Things (WF-IoT)", "doi": "10.1109/WF-IoT.2018.8355097", "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a 3-step system that estimates the real-time energy\nexpenditure of an individual in a non-intrusive way. First, using the user's\nsmart-phone's sensors, we build a Decision Tree model to recognize his physical\nactivity (\\textit{running}, \\textit{standing}, ...). Then, we use the detected\nphysical activity, the time and the user's speed to infer his daily activity\n(\\textit{watching TV}, \\textit{going to the bathroom}, ...) through the use of\na reinforcement learning environment, the Partially Observable Markov Decision\nProcess framework. Once the daily activities are recognized, we translate this\ninformation into energy expenditure using the compendium of physical\nactivities. By successfully detecting 8 physical activities at 90\\%, we reached\nan overall accuracy of 80\\% in recognizing 17 different daily activities. This\nresult leads us to estimate the energy expenditure of the user with a mean\nerror of 26\\% of the expected estimation.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 12:26:18 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["De Bois", "Maxime", ""], ["Amroun", "Hamdi", ""], ["Ammi", "Mehdi", ""]]}, {"id": "2009.03777", "submitter": "Simson Garfinkel", "authors": "Simson L. Garfinkel and Philip Leclerc", "title": "Randomness Concerns When Deploying Differential Privacy", "comments": "12 pages plus 2 pages bibliography", "journal-ref": "19th Workshop on Privacy in the Electronic Society (WPES'20),\n  November 9, 2020, Virtual Event, USA", "doi": "10.1145/3411497.3420211", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The U.S. Census Bureau is using differential privacy (DP) to protect\nconfidential respondent data collected for the 2020 Decennial Census of\nPopulation & Housing. The Census Bureau's DP system is implemented in the\nDisclosure Avoidance System (DAS) and requires a source of random numbers. We\nestimate that the 2020 Census will require roughly 90TB of random bytes to\nprotect the person and household tables. Although there are critical\ndifferences between cryptography and DP, they have similar requirements for\nrandomness. We review the history of random number generation on deterministic\ncomputers, including von Neumann's \"middle-square\" method, Mersenne Twister\n(MT19937) (previously the default NumPy random number generator, which we\nconclude is unacceptable for use in production privacy-preserving systems), and\nthe Linux /dev/urandom device. We also review hardware random number generator\nschemes, including the use of so-called \"Lava Lamps\" and the Intel Secure Key\nRDRAND instruction. We finally present our plan for generating random bits in\nthe Amazon Web Services (AWS) environment using AES-CTR-DRBG seeded by mixing\nbits from /dev/urandom and the Intel Secure Key RDSEED instruction, a\ncompromise of our desire to rely on a trusted hardware implementation, the\nunease of our external reviewers in trusting a hardware-only implementation,\nand the need to generate so many random bits.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 15:28:40 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Garfinkel", "Simson L.", ""], ["Leclerc", "Philip", ""]]}, {"id": "2009.03822", "submitter": "Jeremy Blackburn", "authors": "Chen Ling and Utkucan Balc{\\i} and Jeremy Blackburn and Gianluca\n  Stringhini", "title": "A First Look at Zoombombing", "comments": "First two authors equally contributed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online meeting tools like Zoom and Google Meet have become central to our\nprofessional, educational, and personal lives. This has opened up new\nopportunities for large scale harassment. In particular, a phenomenon known as\nzoombombing has emerged, in which aggressors join online meetings with the goal\nof disrupting them and harassing their participants. In this paper, we conduct\nthe first data-driven analysis of calls for zoombombing attacks on social\nmedia. We identify ten popular online meeting tools and extract posts\ncontaining meeting invitations to these platforms on a mainstream social\nnetwork, Twitter, and on a fringe community known for organizing coordinated\nattacks against online users, 4chan. We then perform manual annotation to\nidentify posts that are calling for zoombombing attacks, and apply thematic\nanalysis to develop a codebook to better characterize the discussion\nsurrounding calls for zoombombing. During the first seven months of 2020, we\nidentify over 200 calls for zoombombing between Twitter and 4chan, and analyze\nthese calls both quantitatively and qualitatively. Our findings indicate that\nthe vast majority of calls for zoombombing are not made by attackers stumbling\nupon meeting invitations or bruteforcing their meeting ID, but rather by\ninsiders who have legitimate access to these meetings, particularly students in\nhigh school and college classes. This has important security implications,\nbecause it makes common protections against zoombombing, such as password\nprotection, ineffective. We also find instances of insiders instructing\nattackers to adopt the names of legitimate participants in the class to avoid\ndetection, making countermeasures like setting up a waiting room and vetting\nparticipants less effective. Based on these observations, we argue that the\nonly effective defense against zoombombing is creating unique join links for\neach participant.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 15:37:36 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Ling", "Chen", ""], ["Balc\u0131", "Utkucan", ""], ["Blackburn", "Jeremy", ""], ["Stringhini", "Gianluca", ""]]}, {"id": "2009.03829", "submitter": "Sooyeon Jeong", "authors": "Sooyeon Jeong, Sharifa Alghowinem, Laura Aymerich-Franch, Kika Arias,\n  Agata Lapedriza, Rosalind Picard, Hae Won Park and Cynthia Breazeal", "title": "A Robotic Positive Psychology Coach to Improve College Students'\n  Wellbeing", "comments": "8 pages, 5 figures, RO-MAN 2020, Best paper award", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A significant number of college students suffer from mental health issues\nthat impact their physical, social, and occupational outcomes. Various scalable\ntechnologies have been proposed in order to mitigate the negative impact of\nmental health disorders. However, the evaluation for these technologies, if\ndone at all, often reports mixed results on improving users' mental health. We\nneed to better understand the factors that align a user's attributes and needs\nwith technology-based interventions for positive outcomes. In psychotherapy\ntheory, therapeutic alliance and rapport between a therapist and a client is\nregarded as the basis for therapeutic success. In prior works, social robots\nhave shown the potential to build rapport and a working alliance with users in\nvarious settings. In this work, we explore the use of a social robot coach to\ndeliver positive psychology interventions to college students living in\non-campus dormitories. We recruited 35 college students to participate in our\nstudy and deployed a social robot coach in their room. The robot delivered\ndaily positive psychology sessions among other useful skills like delivering\nthe weather forecast, scheduling reminders, etc. We found a statistically\nsignificant improvement in participants' psychological wellbeing, mood, and\nreadiness to change behavior for improved wellbeing after they completed the\nstudy. Furthermore, students' personality traits were found to have a\nsignificant association with intervention efficacy. Analysis of the post-study\ninterview revealed students' appreciation of the robot's companionship and\ntheir concerns for privacy.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 15:51:11 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Jeong", "Sooyeon", ""], ["Alghowinem", "Sharifa", ""], ["Aymerich-Franch", "Laura", ""], ["Arias", "Kika", ""], ["Lapedriza", "Agata", ""], ["Picard", "Rosalind", ""], ["Park", "Hae Won", ""], ["Breazeal", "Cynthia", ""]]}, {"id": "2009.03868", "submitter": "Carlos Andujar", "authors": "Carlos Andujar", "title": "Procedural Generation of STEM Quizzes", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic quizzes are used extensively for summative and formative\nassessment. Current Learning Management Systems (LMS) allow instructors to\ncreate quizzes through a Graphical User Interface. Despite having a smooth\nlearning curve, question generation/editing process with such interfaces is\noften slow and the creation of question variants is mostly limited to random\nparameters. In this paper we argue that procedural question generation greatly\nfacilitates the task of creating varied, formative, up-to-date, adaptive\nquestion banks for STEM quizzes. We present and evaluate a proof-of-concept\nPython API for script-based question generation, and propose different question\ndesign patterns that greatly facilitate question authoring. The API supports\nquestions including mathematical formulas, dynamically generated images and\nvideos, as well as interactive content such as 3D model viewers. Output\nquestions can be imported in major LMS. For basic usage, the required\nprogramming skills are minimal. More advanced uses do require some programming\nknowledge, but at a level that is common in STEM instructors. A side advantage\nof our system is that the question bank is actually embedded in Python code,\nmaking collaboration, version control, and maintenance tasks very easy. We\ndemonstrate the benefits of script-based generation over traditional GUI-based\napproaches, in terms of question richness, authoring speed and content\nre-usability.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 17:15:16 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Andujar", "Carlos", ""]]}, {"id": "2009.03997", "submitter": "Krenare Pireva Nuci", "authors": "Anita Mirijamdotter, Krenare Pireva Nuci, Michele Gibney, Patrik Elm", "title": "The development and implementation of a PhD Program in ICT for the\n  Kosovo Education System", "comments": "10 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite ever accelerating workplace changes, including rapidly expanding\ntechnological access and fast improving information and communication systems,\nthe education system in Kosovo is not fully developed enough to provide a\nhigh-quality research-based education in Information and Communication\nTechnology. Coping simultaneously with varied national priorities, Kosovo, a\nsmall country with 2 million inhabitants and a national budget of only 2.3\nbillion, lacks the needed investments to fundamentally transform the quality of\nthe education system.\n  A funded ICT doctoral program would address todays workforce priorities and\nrequirements. The design and delivery of a national PhD program in ICT is\ncrucial for Kosovo in order to ensure competitive readiness within the regional\neducation systems and national economies of the West Balkans, and beyond. This\npaper argues the need for PhD programs and offers insights into a proposed\nproject, the aim of which is to put Kosovo on the map by offering a PhD in the\nICT field.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 21:04:05 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Mirijamdotter", "Anita", ""], ["Nuci", "Krenare Pireva", ""], ["Gibney", "Michele", ""], ["Elm", "Patrik", ""]]}, {"id": "2009.04013", "submitter": "Wanrong Zhang", "authors": "Wanrong Zhang, Olga Ohrimenko, Rachel Cummings", "title": "Attribute Privacy: Framework and Mechanisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensuring the privacy of training data is a growing concern since many machine\nlearning models are trained on confidential and potentially sensitive data.\nMuch attention has been devoted to methods for protecting individual privacy\nduring analyses of large datasets. However in many settings, global properties\nof the dataset may also be sensitive (e.g., mortality rate in a hospital rather\nthan presence of a particular patient in the dataset). In this work, we depart\nfrom individual privacy to initiate the study of attribute privacy, where a\ndata owner is concerned about revealing sensitive properties of a whole dataset\nduring analysis. We propose definitions to capture \\emph{attribute privacy} in\ntwo relevant cases where global attributes may need to be protected: (1)\nproperties of a specific dataset and (2) parameters of the underlying\ndistribution from which dataset is sampled. We also provide two efficient\nmechanisms and one inefficient mechanism that satisfy attribute privacy for\nthese settings. We base our results on a novel use of the Pufferfish framework\nto account for correlations across attributes in the data, thus addressing \"the\nchallenging problem of developing Pufferfish instantiations and algorithms for\ngeneral aggregate secrets\" that was left open by \\cite{kifer2014pufferfish}.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 22:38:57 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 23:23:04 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Zhang", "Wanrong", ""], ["Ohrimenko", "Olga", ""], ["Cummings", "Rachel", ""]]}, {"id": "2009.04035", "submitter": "Teruaki Hayashi", "authors": "Teruaki Hayashi, Nao Uehara, Daisuke Hase, Yukio Ohsawa", "title": "Data Requests and Scenarios for Data Design of Unobserved Events in\n  Corona-related Confusion Using TEEDA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Due to the global violence of the novel coronavirus, various industries have\nbeen affected and the breakdown between systems has been apparent. To\nunderstand and overcome the phenomenon related to this unprecedented crisis\ncaused by the coronavirus infectious disease (COVID-19), the importance of data\nexchange and sharing across fields has gained social attention. In this study,\nwe use the interactive platform called treasuring every encounter of data\naffairs (TEEDA) to externalize data requests from data users, which is a tool\nto exchange not only the information on data that can be provided but also the\ncall for data, what data users want and for what purpose. Further, we analyze\nthe characteristics of missing data in the corona-related confusion stemming\nfrom both the data requests and the providable data obtained in the workshop.\nWe also create three scenarios for the data design of unobserved events\nfocusing on variables.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 23:40:26 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Hayashi", "Teruaki", ""], ["Uehara", "Nao", ""], ["Hase", "Daisuke", ""], ["Ohsawa", "Yukio", ""]]}, {"id": "2009.04108", "submitter": "Punit Rathore", "authors": "Punit Rathore, Ali Zonoozi, Omid Geramifard, Tan Kian Lee", "title": "Understanding the Dynamics of Drivers' Locations for Passengers Pickup\n  Performance: A Case Study", "comments": "Submitted to IEEE Transactions on Inelligent Transportation Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the emergence of e-hailing taxi services, a growing number of scholars\nhave attempted to analyze the taxi trips data to gain insights from drivers'\nand passengers' flow patterns and understand different dynamics of urban public\ntransportation. Existing studies are limited to passengers' location analysis\ne.g., pick-up and drop-off points, in the context of maximizing the profits or\nbetter managing the resources for service providers. Moreover, taxi drivers'\nlocations at the time of pick-up requests and their pickup performance in the\nspatial-temporal domain have not been explored. In this paper, we analyze\ndrivers' and passengers' locations at the time of booking request in the\ncontext of drivers' pick-up performances. To facilitate our analysis, we\nimplement a modified and extended version of a co-clustering technique, called\nsco-iVAT, to obtain useful clusters and co-clusters from big relational data,\nderived from booking records of Grab ride-hailing service in Singapore. We also\nexplored the possibility of predicting timely pickup for a given booking\nrequest, without using entire trajectories data. Finally, we devised two\nscoring mechanisms to compute pickup performance score for all driver\ncandidates for a booking request. These scores could be integrated into a\nbooking assignment model to prioritize top-performing drivers for passenger\npickups.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 05:07:03 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Rathore", "Punit", ""], ["Zonoozi", "Ali", ""], ["Geramifard", "Omid", ""], ["Lee", "Tan Kian", ""]]}, {"id": "2009.04166", "submitter": "Ilya Komarov", "authors": "Sam Cunliffe, Ilya Komarov, Thomas Kuhr, Martin Ritter, and Francesco\n  Tenchini", "title": "User documentation and training at Belle II", "comments": null, "journal-ref": null, "doi": "10.1051/epjconf/202024508008", "report-no": null, "categories": "cs.CY hep-ex", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Belle II is a rapidly growing collaboration with members from one hundred and\nnineteen institutes spread around the globe. The software development team of\nthe experiment, as well as the software users, are very much decentralised.\nTogether with the active development of the software, such decentralisation\nmakes the adoption of the latest software releases by users an essential, but\nquite challenging task. To ensure the relevance of the documentation, we\nadopted the policy of in-code documentation and configured a website that\nallows us to tie the documentation to given releases. To prevent tutorials from\nbecoming outdated, we covered them by unit-tests. For the user support, we use\na question and answer service that not only reduces repetition of the same\nquestions but also turned out to be a place for discussions among the experts.\nA prototype of a metasearch engine for the different sources of documentation\nhas been developed. For training of the new users, we organise centralised\nStarterKit workshops attached to the collaboration meetings. The materials of\nthe workshops are later used for self-education and organisation of local\ntraining sessions.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 08:51:56 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Cunliffe", "Sam", ""], ["Komarov", "Ilya", ""], ["Kuhr", "Thomas", ""], ["Ritter", "Martin", ""], ["Tenchini", "Francesco", ""]]}, {"id": "2009.04198", "submitter": "Ashad Kabir", "authors": "Muhammad Ashad Kabir, Sowmen Rahman, Mohammad Mainul Islam, Sayed\n  Ahmed, Craig Laird", "title": "Mobile Apps for Foot Measurement: A Scoping Review", "comments": null, "journal-ref": "JMIR mHealth and uHealth, 2021", "doi": "10.2196/24202", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the proliferation of smart phone, a major growth in the use of apps\nrelated to the health category, specifically those concerned with foot health\ncan be observed. Although new, these apps are being used practically for\nscanning feet with an aim to providing accurate information about various\nproperties of the human foot. With the availability of many 'foot scanning and\nmeasuring apps' in the app stores, the need for an evaluation system for such\napps can be deemed necessary as little information regarding the evidence-based\nquality of these apps is available. To characterize the assessment of\nmeasurement techniques and essential software quality characteristics of mobile\nfoot measuring apps, and determine their effectiveness for potential use as\ncommercial professional tools for foot care health professionals such as\npedorthists, podiatrists, orthotists and so on, to assist in measuring foot for\ncustom shoes, and for individuals to enhance the awareness of foot health and\nhygiene and prevention of foot-related problems. An electronic search across\nAndroid and iOS app stores was conducted between July 2020 and August 2020 for\napps related to foot measurement. Mobile apps with stated goals of foot\nmeasurement and general foot health were identified and selected by three\nindependent raters and discrepancies regarding the selected apps were resolved\nvia a fourth rater. Evaluation inferences found all apps failing to meet even\nhalf of the measurement-specific criteria required for the proper manufacturing\nof custom-made footwear. 23% (6/26) of apps were found to utilize either\nexternal scanners or advanced algorithms to reconstruct 3D models of user foot\nthat can possibly be used for ordering custom-made footwear and medical casts\nfor fitting irregular foot sizes and shapes. Overall, current apps for foot\nmeasurement do not follow any specific guidelines for measurement purposes.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 10:32:34 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Kabir", "Muhammad Ashad", ""], ["Rahman", "Sowmen", ""], ["Islam", "Mohammad Mainul", ""], ["Ahmed", "Sayed", ""], ["Laird", "Craig", ""]]}, {"id": "2009.04383", "submitter": "Venkata Sriram Siddhardh Nadendla", "authors": "Mukund Telukunta and Venkata Sriram Siddhardh Nadendla", "title": "On the Identification of Fair Auditors to Evaluate Recommender Systems\n  based on a Novel Non-Comparative Fairness Notion", "comments": "10 pages, Accepted to FAccTRec-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision-support systems are information systems that offer support to\npeople's decisions in various applications such as judiciary, real-estate and\nbanking sectors. Lately, these support systems have been found to be\ndiscriminatory in the context of many practical deployments. In an attempt to\nevaluate and mitigate these biases, algorithmic fairness literature has been\nnurtured using notions of comparative justice, which relies primarily on\ncomparing two/more individuals or groups within the society that is supported\nby such systems. However, such a fairness notion is not very useful in the\nidentification of fair auditors who are hired to evaluate latent biases within\ndecision-support systems. As a solution, we introduce a paradigm shift in\nalgorithmic fairness via proposing a new fairness notion based on the principle\nof non-comparative justice. Assuming that the auditor makes fairness\nevaluations based on some (potentially unknown) desired properties of the\ndecision-support system, the proposed fairness notion compares the system's\noutcome with that of the auditor's desired outcome. We show that the proposed\nfairness notion also provides guarantees in terms of comparative fairness\nnotions by proving that any system can be deemed fair from the perspective of\ncomparative fairness (e.g. individual fairness and statistical parity) if it is\nnon-comparatively fair with respect to an auditor who has been deemed fair with\nrespect to the same fairness notions. We also show that the converse holds true\nin the context of individual fairness. A brief discussion is also presented\nregarding how our fairness notion can be used to identify fair and reliable\nauditors, and how we can use them to quantify biases in decision-support\nsystems.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 16:04:41 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Telukunta", "Mukund", ""], ["Nadendla", "Venkata Sriram Siddhardh", ""]]}, {"id": "2009.04597", "submitter": "Qiankun Zhong", "authors": "Qiankun Zhong, Seth Frey", "title": "Institutional Similarity Drives Cultural Similarity among Online\n  Communities", "comments": "39 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding online communities requires an appreciation of both structure\nand culture. But basic questions remain difficult to pose. How do these facets\ninteract and drive each other? Using data on the membership and governance\nstyles of 5,000 small-scale online communities, we construct empirical measures\nfor cross-server similarities in institutional structure and culture to explore\nthe influence of institutional environment on their culture, and the influence\nof culture on their institutional environment. To establish the influence of\nculture and institutions on each other, we construct networks of communities,\nlinking those that are more similar either in their members or governance. We\nthen use network analysis to assess the causal relationships between shared\nculture and institutions. Our result shows that while effects in both\ndirections are evident, there is a much stronger role for institutions on\nculture than culture on institutions. These processes are evident within\nadministrative and informational type rules.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 23:22:13 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Zhong", "Qiankun", ""], ["Frey", "Seth", ""]]}, {"id": "2009.04634", "submitter": "Satyam Mohla Mr.", "authors": "Satyam Mohla, Sidharth Mohla, Anupam Guha and Biplab Banerjee", "title": "Multimodal Noisy Segmentation based fragmented burn scars identification\n  in Amazon Rainforest", "comments": "5 pages, 5 figures. Accepted at IEEE International Conference on\n  Systems, Man and Cybernetics 2020. Earlier draft presented at Harvard CRCS AI\n  for Social Good Workshop 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY eess.IV", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Detection of burn marks due to wildfires in inaccessible rain forests is\nimportant for various disaster management and ecological studies. The\nfragmented nature of arable landscapes and diverse cropping patterns often\nthwart the precise mapping of burn scars. Recent advances in remote-sensing and\navailability of multimodal data offer a viable solution to this mapping\nproblem. However, the task to segment burn marks is difficult because of its\nindistinguishably with similar looking land patterns, severe fragmented nature\nof burn marks and partially labelled noisy datasets. In this work we present\nAmazonNET -- a convolutional based network that allows extracting of burn\npatters from multimodal remote sensing images. The network consists of UNet: a\nwell-known encoder decoder type of architecture with skip connections commonly\nused in biomedical segmentation. The proposed framework utilises stacked\nRGB-NIR channels to segment burn scars from the pastures by training on a new\nweakly labelled noisy dataset from Amazonia. Our model illustrates superior\nperformance by correctly identifying partially labelled burn scars and\nrejecting incorrectly labelled samples, demonstrating our approach as one of\nthe first to effectively utilise deep learning based segmentation models in\nmultimodal burn scar identification.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 02:04:50 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Mohla", "Satyam", ""], ["Mohla", "Sidharth", ""], ["Guha", "Anupam", ""], ["Banerjee", "Biplab", ""]]}, {"id": "2009.04640", "submitter": "Arjun Prakash", "authors": "Lauren Boswell, Arjun Prakash", "title": "On the Fairness of 'Fake' Data in Legal AI", "comments": "Submitted to the Artificial Intelligence Ethics Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The economics of smaller budgets and larger case numbers necessitates the use\nof AI in legal proceedings. We examine the concept of disparate impact and how\nbiases in the training data lead to the search for fairer AI. This paper seeks\nto begin the discourse on what such an implementation would actually look like\nwith a criticism of pre-processing methods in a legal context . We outline how\npre-processing is used to correct biased data and then examine the legal\nimplications of effectively changing cases in order to achieve a fairer outcome\nincluding the black box problem and the slow encroachment on legal precedent.\nFinally we present recommendations on how to avoid the pitfalls of\npre-processed data with methods that either modify the classifier or correct\nthe output in the final step.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 02:23:19 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 08:35:55 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Boswell", "Lauren", ""], ["Prakash", "Arjun", ""]]}, {"id": "2009.04661", "submitter": "Mike Teodorescu", "authors": "Lily Morse, Mike H.M. Teodorescu, Yazeed Awwad, Gerald Kane", "title": "A Framework for Fairer Machine Learning in Organizations", "comments": "35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increase in adoption of machine learning tools by organizations\nrisks of unfairness abound, especially when human decision processes in\noutcomes of socio-economic importance such as hiring, housing, lending, and\nadmissions are automated. We reveal sources of unfair machine learning, review\nfairness criteria, and provide a framework which, if implemented, would enable\nan organization to both avoid implementing an unfair machine learning model,\nbut also to avoid the common situation that as an algorithm learns with more\ndata it can become unfair over time. Issues of behavioral ethics in machine\nlearning implementations by organizations have not been thoroughly addressed in\nthe literature, because many of the necessary concepts are dispersed across\nthree literatures: ethics, machine learning, and management. Further, tradeoffs\nbetween fairness criteria in machine learning have not been addressed with\nregards to organizations. We advance the research by introducing an organizing\nframework for selecting and implementing fair algorithms in organizations.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 04:07:10 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Morse", "Lily", ""], ["Teodorescu", "Mike H. M.", ""], ["Awwad", "Yazeed", ""], ["Kane", "Gerald", ""]]}, {"id": "2009.04769", "submitter": "Rados{\\l}aw Michalski", "authors": "Rados{\\l}aw Michalski, Jaros{\\l}aw Jankowski, Piotr Br\\'odka", "title": "Effective Influence Spreading in Temporal Networks with Sequential\n  Seeding", "comments": "11 pages, 10 figures, reproductory code available", "journal-ref": "IEEE Access, Vol. 8, pp. 151208-151218 (2020)", "doi": "10.1109/access.2020.3016913", "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The spread of influence in networks is a topic of great importance in many\napplication areas. For instance, one would like to maximise the coverage,\nlimiting the budget for marketing campaign initialisation and use the potential\nof social influence. To tackle this and similar challenges, more than a decade\nago, researchers started to investigate the influence maximisation problem. The\nchallenge is to find the best set of initially activated seed nodes in order to\nmaximise the influence spread in networks. In typical approach we will activate\nall seeds in single stage, at the beginning of the process, while in this work\nwe introduce and evaluate a new approach for seeds activation in temporal\nnetworks based on sequential seeding. Instead of activating all nodes at the\nsame time, this method distributes the activations of seeds, leading to higher\nranges of influence spread. The results of experiments performed using real and\nrandomised networks demonstrate that the proposed method outperforms single\nstage seeding in 71% of cases by nearly 6% on average. Knowing that temporal\nnetworks are an adequate choice for modelling dynamic processes, the results of\nthis work can be interpreted as encouraging to apply temporal sequential\nseeding for real world cases, especially knowing that more sophisticated seed\nselection strategies can be implemented by using the seed activation strategy\nintroduced in this work.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 11:03:12 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Michalski", "Rados\u0142aw", ""], ["Jankowski", "Jaros\u0142aw", ""], ["Br\u00f3dka", "Piotr", ""]]}, {"id": "2009.04885", "submitter": "Emiliano De Cristofaro", "authors": "Antonis Papasavva, Jeremy Blackburn, Gianluca Stringhini, Savvas\n  Zannettou, Emiliano De Cristofaro", "title": "\"Is it a Qoincidence?\": An Exploratory Study of QAnon on Voat", "comments": null, "journal-ref": "Published in the Proceedings of 30th The Web Conference (WWW\n  2021). Please cite the WWW version", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online fringe communities offer fertile grounds for users seeking and sharing\nideas fueling suspicion of mainstream news and conspiracy theories. Among\nthese, the QAnon conspiracy theory emerged in 2017 on 4chan, broadly supporting\nthe idea that powerful politicians, aristocrats, and celebrities are closely\nengaged in a global pedophile ring. Simultaneously, governments are thought to\nbe controlled by \"puppet masters,\" as democratically elected officials serve as\na fake showroom of democracy.\n  This paper provides an empirical exploratory analysis of the QAnon community\non Voat.co, a Reddit-esque news aggregator, which has captured the interest of\nthe press for its toxicity and for providing a platform to QAnon followers.\nMore precisely, we analyze a large dataset from /v/GreatAwakening, the most\npopular QAnon-related subverse (the Voat equivalent of a subreddit), to\ncharacterize activity and user engagement. To further understand the discourse\naround QAnon, we study the most popular named entities mentioned in the posts,\nalong with the most prominent topics of discussion, which focus on US politics,\nDonald Trump, and world events. We also use word embeddings to identify\nnarratives around QAnon-specific keywords. Our graph visualization shows that\nsome of the QAnon-related ones are closely related to those from the Pizzagate\nconspiracy theory and so-called drops by \"Q.\" Finally, we analyze content\ntoxicity, finding that discussions on /v/GreatAwakening are less toxic than in\nthe broad Voat community.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 14:25:28 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 10:47:24 GMT"}, {"version": "v3", "created": "Tue, 20 Oct 2020 18:16:59 GMT"}, {"version": "v4", "created": "Sun, 14 Feb 2021 06:19:01 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Papasavva", "Antonis", ""], ["Blackburn", "Jeremy", ""], ["Stringhini", "Gianluca", ""], ["Zannettou", "Savvas", ""], ["De Cristofaro", "Emiliano", ""]]}, {"id": "2009.04916", "submitter": "Yogesh Simmhan", "authors": "Yogesh Simmhan, Tarun Rambha, Aakash Khochare, Shriram Ramesh, Animesh\n  Baranawal, John Varghese George, Rahul Atul Bhope, Amrita Namtirtha, Amritha\n  Sundararajan, Sharath Suresh Bhargav, Nihar Thakkar, Raj Kiran", "title": "GoCoronaGo: Privacy Respecting Contact Tracing for COVID-19 Management", "comments": "Pre-print of article to appear in the Journal of the Indian Institute\n  of Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic is imposing enormous global challenges in managing the\nspread of the virus. A key pillar to mitigation is contact tracing, which\ncomplements testing and isolation. Digital apps for contact tracing using\nBluetooth technology available in smartphones have gained prevalence globally.\nIn this article, we discuss various capabilities of such digital contact\ntracing, and its implication on community safety and individual privacy, among\nothers. We further describe the GoCoronaGo institutional contact tracing app\nthat we have developed, and the conscious and sometimes contrarian design\nchoices we have made. We offer a detailed overview of the app, backend platform\nand analytics, and our early experiences with deploying the app to over 1000\nusers within the Indian Institute of Science campus in Bangalore. We also\nhighlight research opportunities and open challenges for digital contact\ntracing and analytics over temporal networks constructed from them.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 14:59:59 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Simmhan", "Yogesh", ""], ["Rambha", "Tarun", ""], ["Khochare", "Aakash", ""], ["Ramesh", "Shriram", ""], ["Baranawal", "Animesh", ""], ["George", "John Varghese", ""], ["Bhope", "Rahul Atul", ""], ["Namtirtha", "Amrita", ""], ["Sundararajan", "Amritha", ""], ["Bhargav", "Sharath Suresh", ""], ["Thakkar", "Nihar", ""], ["Kiran", "Raj", ""]]}, {"id": "2009.04991", "submitter": "Sheshank Shankar", "authors": "Sheshank Shankar, Rishank Kanaparti, Ayush Chopra, Rohan Sukumaran,\n  Parth Patwa, Myungsun Kang, Abhishek Singh, Kevin P. McPherson, Ramesh Raskar", "title": "Proximity Sensing: Modeling and Understanding Noisy RSSI-BLE Signals and\n  Other Mobile Sensor Data for Digital Contact Tracing", "comments": "Accepted to IEEE/ICACT' 2021: International Conference on Advanced\n  Communication Technology. Also presented at the Machine Learning for Mobile\n  Health workshop at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As we await a vaccine, social-distancing via efficient contact tracing has\nemerged as the primary health strategy to dampen the spread of COVID-19. To\nenable efficient digital contact tracing, we present a novel system to estimate\npair-wise individual proximity, via a joint model of Bluetooth Low Energy (BLE)\nsignals with other on-device sensors (accelerometer, magnetometer, gyroscope).\nWe explore multiple ways of interpreting the sensor data stream (time-series,\nhistogram, etc) and use several statistical and deep learning methods to learn\nrepresentations for sensing proximity. We report the normalized Decision Cost\nFunction (nDCF) metric and analyze the differential impact of the various input\nsignals, as well as discuss various challenges associated with this task.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 03:01:52 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 18:09:01 GMT"}, {"version": "v3", "created": "Thu, 24 Dec 2020 20:07:30 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Shankar", "Sheshank", ""], ["Kanaparti", "Rishank", ""], ["Chopra", "Ayush", ""], ["Sukumaran", "Rohan", ""], ["Patwa", "Parth", ""], ["Kang", "Myungsun", ""], ["Singh", "Abhishek", ""], ["McPherson", "Kevin P.", ""], ["Raskar", "Ramesh", ""]]}, {"id": "2009.05328", "submitter": "Rihab Almutawa", "authors": "Rihab Fahd Al-Mutawa, Fathy Albouraey Eassa", "title": "A Smart Home System based on Internet of Things", "comments": null, "journal-ref": null, "doi": "10.14569/IJACSA.2020.0110234", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Internet of Things (IoT) describes a network infrastructure of\nidentifiable things that share data through the Internet. A smart home is one\nof the applications for the Internet of Things. In a smart home, household\nappliances could be monitored and controlled remotely. This raises a demand for\nreliable security solutions for IoT systems. Authorization and authentication\nare challenging IoT security operations that need to be considered. For\ninstance, unauthorized access, such as cyber-attacks, to a smart home system\ncould cause danger by controlling sensors and actuators, opening the doors for\na thief. This paper applies an extra layer of security of multi-factor\nauthentication to act as a prevention method for mitigating unauthorized\naccess. One of those factors is face recognition, as it has recently become\npopular due to its non-invasive biometric techniques, which is easy to use with\ncameras attached to most trending computers and smartphones. In this paper, the\ngaps in existing IoT smart home systems have been analyzed, and we have\nsuggested improvements for overcoming them by including necessary system\nmodules and enhancing user registration and log-in authentication. We propose\nsoftware architecture for implementing such a system. To the best of our\nknowledge, the existing IoT smart home management research does not support\nface recognition and liveness detection within the authentication operation of\ntheir suggested software architectures.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 10:34:48 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Al-Mutawa", "Rihab Fahd", ""], ["Eassa", "Fathy Albouraey", ""]]}, {"id": "2009.05394", "submitter": "Thippa Reddy Gadekallu", "authors": "Mohan Krishna Kagita, Navod Thilakarathne, Thippa Reddy Gadekallu, and\n  Praveen Kumar Reddy Maddikunta", "title": "A Review on Security and Privacy of Internet of Medical Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Medical Things (IoMT) are increasing the accuracy,\nreliability, and the production capability of electronic devices by playing a\nvery important part in the industry of healthcare. The available medical\nresources and services related to healthcare are working to get an\ninterconnection with each other by the digital healthcare system by the\ncontribution of the researchers. Sensors, wearable devices, medical devices,\nand clinical devices are all connected to form an ecosystem of the Internet of\nMedical Things. The different applications of healthcare are enabled by the\nInternet of Medical Things to reduce the healthcare costs, to attend the\nmedical responses on time and it also helps in increasing the quality of the\nmedical treatment. The healthcare industry is transformed by the Internet of\nMedical Things as it delivers targeted and personalized medical care and it\nalso seamlessly enables the communication of medical data. Devices used in the\nmedical field and their application are connected to the system of healthcare\nof Information technology with the help of the digital world.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 12:31:40 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Kagita", "Mohan Krishna", ""], ["Thilakarathne", "Navod", ""], ["Gadekallu", "Thippa Reddy", ""], ["Maddikunta", "Praveen Kumar Reddy", ""]]}, {"id": "2009.05400", "submitter": "Awais Ahmed Mr", "authors": "Yasir Nadeem, Awais Ahmed", "title": "Machine Learning and Data Science approach towards trend and predictors\n  analysis of CDC Mortality Data for the USA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The research on mortality is an active area of research for any country where\nthe conclusions are driven from the provided data and conditions. The domain\nknowledge is an essential but not a mandatory skill (though some knowledge is\nstill required) in order to derive conclusions based on data intuition using\nmachine learning and data science practices. The purpose of conducting this\nproject was to derive conclusions based on the statistics from the provided\ndataset and predict label(s) of the dataset using supervised or unsupervised\nlearning algorithms. The study concluded (based on a sample) life expectancy\nregardless of gender, and their central tendencies; Marital status of the\npeople also affected how frequent deaths were for each of them. The study also\nhelped in finding out that due to more categorical and numerical data, anomaly\ndetection or under-sampling could be a viable solution since there are\npossibilities of more class labels than the other(s). The study shows that\nmachine learning predictions aren't as viable for the data as it might be\napparent.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 12:46:57 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Nadeem", "Yasir", ""], ["Ahmed", "Awais", ""]]}, {"id": "2009.05560", "submitter": "Ancil Crayton", "authors": "Ancil Crayton, Jo\\~ao Fonseca, Kanav Mehra, Michelle Ng, Jared Ross,\n  Marcelo Sandoval-Casta\\~neda, Rachel von Gnechten", "title": "Narratives and Needs: Analyzing Experiences of Cyclone Amphan Using\n  Twitter Discourse", "comments": "6 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People often turn to social media to comment upon and share information about\nmajor global events. Accordingly, social media is receiving increasing\nattention as a rich data source for understanding people's social, political\nand economic experiences of extreme weather events. In this paper, we\ncontribute two novel methodologies that leverage Twitter discourse to\ncharacterize narratives and identify unmet needs in response to Cyclone Amphan,\nwhich affected 18 million people in May 2020.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 17:49:05 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Crayton", "Ancil", ""], ["Fonseca", "Jo\u00e3o", ""], ["Mehra", "Kanav", ""], ["Ng", "Michelle", ""], ["Ross", "Jared", ""], ["Sandoval-Casta\u00f1eda", "Marcelo", ""], ["von Gnechten", "Rachel", ""]]}, {"id": "2009.05615", "submitter": "Benjamin Bolling", "authors": "Benjamin Bolling", "title": "Computer-Aided Generation of N-shift RWS", "comments": "9 pages, 4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Generating schedules for shift workers is essential for many employers,\nwhether the employer is a small or a large industrial complex, research\nlaboratory, or other businesses involving shift works.\n  Previous methods for creating rotational workforce schedules included\ninteractions between the schedule maker and the algorithm, including defining\nthe length of sequences of consecutive days of working shifts.\n  In this method, an algorithm takes into account inputs (or constraints) from\nthe schedule maker and then presents the possible solutions (incl. that all\nshifts must be filled, working hours per week, minimal resting time, etc.) in a\nfirst phase. The schedule maker can then select which solutions are most\nfeasible to proceed with in the second phase, where the final schedules are\nthen constructed and exported.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 18:56:20 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 09:00:41 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Bolling", "Benjamin", ""]]}, {"id": "2009.05619", "submitter": "Josimar Chire Saire", "authors": "Josimar E. Chire-Saire", "title": "Characterizing Twitter Interaction during COVID-19 pandemic using\n  Complex Networks and Text Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The outbreak of covid-19 started many months ago, the reported origin was in\nWuhan Market, China. Fastly, this virus was propagated to other countries\nbecause the access to international travels is affordable and many countries\nhave a distance of some flight hours, besides borders were a constant flow of\npeople. By the other hand, Internet users have the habits of sharing content\nusing Social Networks and issues, problems, thoughts about Covdid-19 were not\nan exception. Therefore, it is possible to analyze Social Network interaction\nfrom one city, country to understand the impact generated by this global issue.\nSouth America is one region with developing countries with challenges to face\nrelated to Politics, Economy, Public Health and other. Therefore, the scope of\nthis paper is to analyze the interaction on Twitter of South American countries\nand characterize the flow of data through the users using Complex Network\nrepresentation and Text Mining. The preliminary experiments introduces the idea\nof existence of patterns, similar to Complex Systems. Besides, the degree\ndistribution confirm the idea of having a System and visualization of Adjacency\nMatrices show the presence of users' group publishing and interacting together\nduring the time, there is a possibility of identification of robots sending\nposts constantly.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 19:12:44 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Chire-Saire", "Josimar E.", ""]]}, {"id": "2009.05653", "submitter": "Jessica Van Brummelen", "authors": "Jessica Van Brummelen, Tommy Heng, Viktoriya Tabunshchyk", "title": "Teaching Tech to Talk: K-12 Conversational Artificial Intelligence\n  Literacy Curriculum and Development Tools", "comments": "8 pages, 4 figures, for associated video:\n  https://youtu.be/VGskt7mI4K8, for appendix:\n  https://gist.github.com/jessvb/1cd959e32415a6ad4389761c49b54bbf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With children talking to smart-speakers, smart-phones and even\nsmart-microwaves daily, it is increasingly important to educate students on how\nthese agents work-from underlying mechanisms to societal implications.\nResearchers are developing tools and curriculum to teach K-12 students broadly\nabout artificial intelligence (AI); however, few studies have evaluated these\ntools with respect to AI-specific learning outcomes, and even fewer have\naddressed student learning about AI-based conversational agents. We evaluate\nour Conversational Agent Interface for MIT App Inventor and workshop curriculum\nwith respect to eight AI competencies from the literature. Furthermore, we\nanalyze teacher (n=9) and student (n=47) feedback from workshops with the\ninterface and recommend that future work leverages design considerations from\nthe literature to optimize engagement, collaborates with teachers, and\naddresses a range of student abilities through pacing and opportunities for\nextension. We found students struggled most with the concepts of AI ethics and\nlearning, and recommend emphasizing these topics when teaching.\n  The appendix, including a demo video, can be found here:\nhttps://gist.github.com/jessvb/1cd959e32415a6ad4389761c49b54bbf\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 20:52:46 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Van Brummelen", "Jessica", ""], ["Heng", "Tommy", ""], ["Tabunshchyk", "Viktoriya", ""]]}, {"id": "2009.05708", "submitter": "Thippa Reddy Gadekallu", "authors": "Mohan Krishna Kagita, Navod Thilakarathne, Thippa Reddy Gadekallu,\n  Praveen Kumar Reddy Maddikunta, Saurabh Singh", "title": "A Review on Cyber Crimes on the Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) devices are rapidly becoming universal. The success\nof IoT cannot be ignored in the scenario today, along with its attacks and\nthreats on IoT devices and facilities are also increasing day by day. Cyber\nattacks become a part of IoT and affecting the life and society of users, so\nsteps must be taken to defend cyber seriously. Cybercrimes threaten the\ninfrastructure of governments and businesses globally and can damage the users\nin innumerable ways. With the global cybercrime damages predicted to cost up to\n6 trillion dollars annually on the global economy by cyber crime. Estimated of\n328 Million Dollar annual losses with the cyber attacks in Australia itself.\nVarious steps are taken to slow down these attacks but unfortunately not able\nto achieve success properly. Therefor secure IoT is the need of this time and\nunderstanding of attacks and threats in IoT structure should be studied. The\nreasons for cyber-attacks can be Countries having week cyber securities,\nCybercriminals use new technologies to attack, Cybercrime is possible with\nservices and other business schemes. MSP (Managed Service Providers) face\ndifferent difficulties in fighting with Cyber-crime. They have to ensure that\nsecurity of the customer as well as their security in terms of their servers,\ndevices, and systems. Hence, they must use effective, fast, and easily usable\nantivirus and antimalware tools.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 02:56:59 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Kagita", "Mohan Krishna", ""], ["Thilakarathne", "Navod", ""], ["Gadekallu", "Thippa Reddy", ""], ["Maddikunta", "Praveen Kumar Reddy", ""], ["Singh", "Saurabh", ""]]}, {"id": "2009.05716", "submitter": "Thippa Reddy Gadekallu", "authors": "Navod Neranjan Thilakarathne, Mohan Krishna Kagita, Thippa Reddy\n  Gadekallu, Praveen Kumar Reddy Maddikunta", "title": "The Adoption of ICT Powered Healthcare Technologies towards Managing\n  Global Pandemics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pandemic is an outbreak that happens over a large geographic area affecting a\ngreater portion of the population as new pathogens appear for which people have\nless immune and no vaccines are available. It can spread from person to person\nin a very short time, and in fact, the health workers are at greater risk of\ninfection because of the patients who carry the disease. In the 21st century,\nwhere everyone is connected through digital technologies, Information and\nCommunication Technology (ICT) plays a critical role in improving health care\nfor individuals and larger communities. ICT has currently been severed in a\nvariety of application domains which signifies its importance as a major\ntechnological paradigm, and it has drawn higher attention for its potential to\nalleviate the burden on healthcare systems caused by a rise in chronic\ndiseases, aging and increased population and pandemic situations. This paper\nsurveys and offers substantial knowledge about how effective ICT Healthcare\nstrategy can be used to manage global pandemics by presenting a four-phased\nframework, which can be deployed to alleviate the strain on healthcare during a\npandemic. In addition, we discuss how ICT powered technologies can be used\ntowards managing a pandemic during the transformation of simple disease\noutbreak into a global pandemic.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 03:21:09 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Thilakarathne", "Navod Neranjan", ""], ["Kagita", "Mohan Krishna", ""], ["Gadekallu", "Thippa Reddy", ""], ["Maddikunta", "Praveen Kumar Reddy", ""]]}, {"id": "2009.05718", "submitter": "Gadekallu Thippa Reddy", "authors": "Saqib Hakak, Wazir Zada Khan, Gulshan Amin Gilkar, Basem Assiri,\n  Mamoun Alazab, Sweta Bhattacharya, G Thippa Reddy", "title": "Recent advances in Blockchain Technology: A survey on Applications and\n  Challenges", "comments": "The journal we submitted doesn't allow the articles under review to\n  be submitted to arxiv", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of blockchain technology within a few years has attracted\nresearchers across the world. The prime reason for worldwide attention is\nundoubtedly due to its feature of immutability along with the decentralized\napproach of data protection. As this technology is progressing, lots of\ndevelopments in terms of identifying new applications, blockchain-based\nplatforms, consensus mechanisms, etc are taking place. Hence, in this article,\nan attempt has been made to review the recent advancements in blockchain\ntechnology. Furthermore, we have also explored the available blockchain\nplatforms, highlighted and explored future research directions and challenges.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 03:31:17 GMT"}, {"version": "v2", "created": "Sun, 6 Dec 2020 14:51:41 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Hakak", "Saqib", ""], ["Khan", "Wazir Zada", ""], ["Gilkar", "Gulshan Amin", ""], ["Assiri", "Basem", ""], ["Alazab", "Mamoun", ""], ["Bhattacharya", "Sweta", ""], ["Reddy", "G Thippa", ""]]}, {"id": "2009.05791", "submitter": "Petar Radanliev", "authors": "Petar Radanliev, David De Roure, Rob Walton, Max Van Kleek, Rafael\n  Mantilla Montalvo, Omar Santos, LaTreall Maddox, Stacy Cannady", "title": "COVID-19 what have we learned? The rise of social machines and connected\n  devices in pandemic management following the concepts of predictive,\n  preventive and personalised medicine", "comments": null, "journal-ref": "EPMA Journal 11, 311 332 (2020)", "doi": "10.1007/s13167-020-00218-x", "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A comprehensive bibliographic review with R statistical methods of the COVID\npandemic in PubMed literature and Web of Science Core Collection, supported\nwith Google Scholar search. In addition, a case study review of emerging new\napproaches in different regions, using medical literature, academic literature,\nnews articles and other reliable data sources. Public responses of mistrust\nabout privacy data misuse differ across countries, depending on the chosen\npublic communication strategy.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 13:26:54 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 21:26:57 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Radanliev", "Petar", ""], ["De Roure", "David", ""], ["Walton", "Rob", ""], ["Van Kleek", "Max", ""], ["Montalvo", "Rafael Mantilla", ""], ["Santos", "Omar", ""], ["Maddox", "LaTreall", ""], ["Cannady", "Stacy", ""]]}, {"id": "2009.05793", "submitter": "Petar Radanliev", "authors": "Petar Radanliev, David De Roure, Rob Walton", "title": "Data mining and analysis of scientific research data records on Covid 19\n  mortality, immunity, and vaccine development in the first wave of the Covid\n  19 pandemic", "comments": null, "journal-ref": "Volume 14, Issue 5, September October 2020,", "doi": "10.1016/j.dsx.2020.06.063", "report-no": null, "categories": "cs.CY cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we investigate the scientific research response from the early\nstages of the pandemic, and we review key findings on how the early warning\nsystems developed in previous epidemics responded to contain the virus. The\ndata records are analysed with commutable statistical methods, including R\nStudio, Bibliometrix package, and the Web of Science data mining tool. We\nidentified few different clusters, containing references to exercise,\ninflammation, smoking, obesity and many additional factors. From the analysis\non Covid-19 and vaccine, we discovered that although the USA is leading in\nvolume of scientific research on Covid 19 vaccine, the leading 3 research\ninstitutions (Fudan, Melbourne, Oxford) are not based in the USA. Hence, it is\ndifficult to predict which country would be first to produce a Covid 19\nvaccine.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 13:34:05 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Radanliev", "Petar", ""], ["De Roure", "David", ""], ["Walton", "Rob", ""]]}, {"id": "2009.05801", "submitter": "Philip Koopman", "authors": "Philip Koopman, Michael Wagner", "title": "Positive Trust Balance for Self-Driving Car Deployment", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The crucial decision about when self-driving cars are ready to deploy is\nlikely to be made with insufficient lagging metric data to provide high\nconfidence in an acceptable safety outcome. A Positive Trust Balance approach\ncan help with making a responsible deployment decision despite this\nuncertainty. With this approach, a reasonable initial expectation of safety is\nbased on a combination of a practicable amount of testing, engineering rigor,\nsafety culture, and a strong commitment to use post-deployment operational\nfeedback to further reduce uncertainty. This can enable faster deployment than\nwould be required by more traditional safety approaches by reducing the\nconfidence necessary at time of deployment in exchange for a more stringent\nrequirement for Safety Performance Indicator (SPI) field feedback in the\ncontext of a strong safety culture.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 14:23:47 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Koopman", "Philip", ""], ["Wagner", "Michael", ""]]}, {"id": "2009.05817", "submitter": "Zeyu Zhu", "authors": "Huimin Chen, Zeyu Zhu, Fanchao Qi, Yining Ye, Zhiyuan Liu, Maosong\n  Sun, Jianbin Jin", "title": "Country Image in COVID-19 Pandemic: A Case Study of China", "comments": null, "journal-ref": null, "doi": "10.1109/TBDATA.2020.3023459", "report-no": null, "categories": "cs.CY cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Country image has a profound influence on international relations and\neconomic development. In the worldwide outbreak of COVID-19, countries and\ntheir people display different reactions, resulting in diverse perceived images\namong foreign public. Therefore, in this study, we take China as a specific and\ntypical case and investigate its image with aspect-based sentiment analysis on\na large-scale Twitter dataset. To our knowledge, this is the first study to\nexplore country image in such a fine-grained way. To perform the analysis, we\nfirst build a manually-labeled Twitter dataset with aspect-level sentiment\nannotations. Afterward, we conduct the aspect-based sentiment analysis with\nBERT to explore the image of China. We discover an overall sentiment change\nfrom non-negative to negative in the general public, and explain it with the\nincreasing mentions of negative ideology-related aspects and decreasing\nmentions of non-negative fact-based aspects. Further investigations into\ndifferent groups of Twitter users, including U.S. Congress members, English\nmedia, and social bots, reveal different patterns in their attitudes toward\nChina. This study provides a deeper understanding of the changing image of\nChina in COVID-19 pandemic. Our research also demonstrates how aspect-based\nsentiment analysis can be applied in social science researches to deliver\nvaluable insights.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 15:54:51 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Chen", "Huimin", ""], ["Zhu", "Zeyu", ""], ["Qi", "Fanchao", ""], ["Ye", "Yining", ""], ["Liu", "Zhiyuan", ""], ["Sun", "Maosong", ""], ["Jin", "Jianbin", ""]]}, {"id": "2009.06047", "submitter": "Mohammad Arani", "authors": "Ahmad Sobhan Abir, Ishtiaq Ahmed Bhuiyan, Mohammad Arani, Md Mashum\n  Billal", "title": "Multi-Objective Optimization for Sustainable Closed-Loop Supply Chain\n  Network Under Demand Uncertainty: A Genetic Algorithm", "comments": "The current version of the paper has been accepted by the\n  International Conference on Data Analytics for Business and Industry.\n  http://data20.uob.edu.bh/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supply chain management has been concentrated on productive ways to manage\nflows through a sophisticated vendor, manufacturer, and consumer networks for\ndecades. Recently, energy and material rates have been greatly consumed to\nimprove the sector, making sustainable development the core problem for\nadvanced and developing countries. A new approach of supply chain management is\nproposed to maintain the economy along with the environment issue for the\ndesign of supply chain as well as the highest reliability in the planning\nhorizon to fulfill customers demand as much as possible. This paper aims to\noptimize a new sustainable closed-loop supply chain network to maintain the\nfinancial along with the environmental factor to minimize the negative effect\non the environment and maximize the average total number of products dispatched\nto customers to enhance reliability. The situation has been considered under\ndemand uncertainty with warehouse reliability. This approach has been suggested\nthe multi-objective mathematical model minimizing the total costs and total CO2\nemissions and maximize the reliability in handling for establishing the\nclosed-loop supply chain. Two optimization methods are used namely\nMulti-Objective Genetic Algorithm Optimization Method and Weighted Sum Method.\nTwo results have shown the optimality of this approach. This paper also showed\nthe optimal point using Pareto front for clear identification of optima. The\nresults are approved to verify the efficiency of the model and the methods to\nmaintain the financial, environmental, and reliability issues.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 17:31:13 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 16:09:24 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Abir", "Ahmad Sobhan", ""], ["Bhuiyan", "Ishtiaq Ahmed", ""], ["Arani", "Mohammad", ""], ["Billal", "Md Mashum", ""]]}, {"id": "2009.06192", "submitter": "Tianhao Wang", "authors": "Tianhao Wang, Johannes Rausch, Ce Zhang, Ruoxi Jia, Dawn Song", "title": "A Principled Approach to Data Valuation for Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a popular technique to train machine learning (ML)\nmodels on decentralized data sources. In order to sustain long-term\nparticipation of data owners, it is important to fairly appraise each data\nsource and compensate data owners for their contribution to the training\nprocess. The Shapley value (SV) defines a unique payoff scheme that satisfies\nmany desiderata for a data value notion. It has been increasingly used for\nvaluing training data in centralized learning. However, computing the SV\nrequires exhaustively evaluating the model performance on every subset of data\nsources, which incurs prohibitive communication cost in the federated setting.\nBesides, the canonical SV ignores the order of data sources during training,\nwhich conflicts with the sequential nature of FL. This paper proposes a variant\nof the SV amenable to FL, which we call the federated Shapley value. The\nfederated SV preserves the desirable properties of the canonical SV while it\ncan be calculated without incurring extra communication cost and is also able\nto capture the effect of participation order on data value. We conduct a\nthorough empirical study of the federated SV on a range of tasks, including\nnoisy label detection, adversarial participant detection, and data\nsummarization on different benchmark datasets, and demonstrate that it can\nreflect the real utility of data sources for FL and has the potential to\nenhance system robustness, security, and efficiency. We also report and analyze\n\"failure cases\" and hope to stimulate future research.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 04:37:54 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Wang", "Tianhao", ""], ["Rausch", "Johannes", ""], ["Zhang", "Ce", ""], ["Jia", "Ruoxi", ""], ["Song", "Dawn", ""]]}, {"id": "2009.06279", "submitter": "Andrew Tzer-Yeu Chen", "authors": "Andrew Tzer-Yeu Chen", "title": "How Fragmentation Can Undermine the Public Health Response to COVID-19", "comments": "7 pages, 5 figures, published by ACM Interactions (online at\n  https://interactions.acm.org/blog/view/how-fragmentation-can-undermine-the-public-health-response-to-covid-19,\n  in magazine in 2021)", "journal-ref": null, "doi": "10.1145/3448413", "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Responses to COVID-19 have largely been led by local, national, and\ninternational public health agencies, who have activated their pandemic plans\nand opened the epidemiological toolkit of modelling, testing, isolation and\nmovement restrictions, surveillance, and contact tracing. In the contemporary\ntech-heavy world, many assumed that the common manual process of human\ninvestigators and phone calls could or should be replaced by digital solutions.\nBut it's not as simple as \"add more technology\" - the complex way in which\nusers and societies interact with the technology has significant impacts on\neffectiveness. When efforts are not well co-ordinated, fragmentation in system\ndesign and user experience can negatively impact the public health response.\nThis article briefly covers the journey of how contact tracing registers and\ndigital diaries evolved in New Zealand during the COVID-19 pandemic, the\ninitial poor outcomes caused by the lack of central co-ordination, and the\nlater improvement.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 09:16:12 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 23:16:18 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Chen", "Andrew Tzer-Yeu", ""]]}, {"id": "2009.06341", "submitter": "Mohan Krishna Kagita", "authors": "Mohan Krishna Kagita, Navod Thilakarathne, Dharmendra Singh Rajput,\n  and Dr Surekha Lanka", "title": "A Detail Study of Security and Privacy issues of Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things, or IoT, refers to the billions of physical objects\naround the planet that are now connected to the Internet, many of which store\nand exchange the data without human interaction. In recent years the Internet\nof Things (IoT) has incredibly become a groundbreaking technical innovation\nthat has contributed to massive impact in the ways where all the information is\nhandled incorporate companies, computer devices, and even kitchen equipment and\nappliances, are designed and made. The main focus of this chapter is to\nsystematically review the security and privacy of the Internet of Things in the\npresent world. Most internet users are genuine, yet others are cybercriminals\nwith individual expectations of misusing information. With such possibilities,\nusers should know the potential security and privacy issues of IoT devices. IoT\ninnovations are applied on numerous levels in a system that we use daily in our\nday-to-day life. Data confidentiality is a significant issue. The\ninterconnection of various networks makes it impossible for users to assert\nextensive control of their data. Finally, this chapter discusses the IoT\nSecurity concerns in the literature and providing a critical review of the\ncurrent approach and proposed solutions on present issues on the Privacy\nprotection of IoT devices.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 11:58:22 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Kagita", "Mohan Krishna", ""], ["Thilakarathne", "Navod", ""], ["Rajput", "Dharmendra Singh", ""], ["Lanka", "Dr Surekha", ""]]}, {"id": "2009.06345", "submitter": "Yassine Himeur", "authors": "Yassine Himeur, Abdullah Alsalemi, Ayman Al-Kababji, Faycal Bensaali,\n  Abbes Amira", "title": "Data fusion strategies for energy efficiency in buildings: Overview,\n  challenges and novel orientations", "comments": null, "journal-ref": "Information Fusion, 2020, 64, 99-120", "doi": "10.1016/j.inffus.2020.07.003", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, tremendous interest has been devoted to develop data fusion\nstrategies for energy efficiency in buildings, where various kinds of\ninformation can be processed. However, applying the appropriate data fusion\nstrategy to design an efficient energy efficiency system is not\nstraightforward; it requires a priori knowledge of existing fusion strategies,\ntheir applications and their properties. To this regard, seeking to provide the\nenergy research community with a better understanding of data fusion strategies\nin building energy saving systems, their principles, advantages, and potential\napplications, this paper proposes an extensive survey of existing data fusion\nmechanisms deployed to reduce excessive consumption and promote sustainability.\nWe investigate their conceptualizations, advantages, challenges and drawbacks,\nas well as performing a taxonomy of existing data fusion strategies and other\ncontributing factors. Following, a comprehensive comparison of the\nstate-of-the-art data fusion based energy efficiency frameworks is conducted\nusing various parameters, including data fusion level, data fusion techniques,\nbehavioral change influencer, behavioral change incentive, recorded data,\nplatform architecture, IoT technology and application scenario. Moreover, a\nnovel method for electrical appliance identification is proposed based on the\nfusion of 2D local texture descriptors, where 1D power signals are transformed\ninto 2D space and treated as images. The empirical evaluation, conducted on\nthree real datasets, shows promising performance, in which up to 99.68%\naccuracy and 99.52% F1 score have been attained. In addition, various open\nresearch challenges and future orientations to improve data fusion based energy\nefficiency ecosystems are explored.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 12:04:30 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Himeur", "Yassine", ""], ["Alsalemi", "Abdullah", ""], ["Al-Kababji", "Ayman", ""], ["Bensaali", "Faycal", ""], ["Amira", "Abbes", ""]]}, {"id": "2009.06381", "submitter": "Anas Blasi", "authors": "Mohammed A. Alsuwaiket, Anas H. Blasi, Khawla Altarawneh", "title": "Refining Student Marks based on Enrolled Modules Assessment Methods\n  using Data Mining Techniques", "comments": "arXiv admin note: substantial text overlap with arXiv:2008.13255", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Choosing the right and effective way to assess students is one of the most\nimportant tasks of higher education. Many studies have shown that students tend\nto receive higher scores during their studies when assessed by different study\nmethods which include units that are fully assessed by varying the duration of\nstudy or a combination of courses and exams than by exams alone. Many\nEducational Data Mining studies process data in advance through traditional\ndata extraction, including the data preparation process. In this paper, we\npropose a different data preparation process by investigating more than 230000\nstudent records for the preparation of scores. The data have been processed\nthrough diverse stages in order to extract a categorical factor through which\nstudents module marks are refined during the data preparation stage. The\nresults of this work show that students final marks should not be isolated from\nthe nature of the enrolled module assessment methods. They must rather be\ninvestigated thoroughly and considered during EDM data preprocessing stage.\nMore generally, educational data should not be prepared in the same way normal\ndata are due to the differences in data sources, applications, and error types.\nThe effect of Module Assessment Index on the prediction process using Random\nForest and Naive Bayes classification techniques were investigated. It was\nshown that considering MAI as attribute increases the accuracy of predicting\nstudents second year averages based on their first year averages.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 19:47:45 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Alsuwaiket", "Mohammed A.", ""], ["Blasi", "Anas H.", ""], ["Altarawneh", "Khawla", ""]]}, {"id": "2009.06457", "submitter": "Punam Bedi", "authors": "Punam Bedi, Shivani, Pushkar Gole, Neha Gupta, Vinita Jindal", "title": "Projections for COVID-19 spread in India and its worst affected five\n  states using the Modified SEIRD and LSTM models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last leg of the year 2019 gave rise to a virus named COVID-19 (Corona\nVirus Disease 2019). Since the beginning of this infection in India, the\ngovernment implemented several policies and restrictions to curtail its spread\namong the population. As the time passed, these restrictions were relaxed and\npeople were advised to follow precautionary measures by themselves. These\ntimely decisions taken by the Indian government helped in decelerating the\nspread of COVID-19 to a large extent. Despite these decisions, the pandemic\ncontinues to spread and hence, there is an urgent need to plan and control the\nspread of this disease. This is possible by finding the future predictions\nabout the spread. Scientists across the globe are working towards estimating\nthe future growth of COVID-19. This paper proposes a Modified SEIRD\n(Susceptible-Exposed-Infected-Recovered-Deceased) model for projecting COVID-19\ninfections in India and its five states having the highest number of total\ncases. In this model, exposed compartment contains individuals which may be\nasymptomatic but infectious. Deep Learning based Long Short-Term Memory (LSTM)\nmodel has also been used in this paper to perform short-term projections. The\nprojections obtained from the proposed Modified SEIRD model have also been\ncompared with the projections made by LSTM for next 30 days. The\nepidemiological data up to 15th August 2020 has been used for carrying out\npredictions in this paper. These predictions will help in arranging adequate\nmedical infrastructure and providing proper preventive measures to handle the\ncurrent pandemic. The effect of different lockdowns imposed by the Indian\ngovernment has also been used in modelling and analysis in the proposed\nModified SEIRD model. The results presented in this paper will act as a beacon\nfor future policy-making to control the COVID-19 spread in India.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 07:38:10 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Bedi", "Punam", ""], ["Shivani", "", ""], ["Gole", "Pushkar", ""], ["Gupta", "Neha", ""], ["Jindal", "Vinita", ""]]}, {"id": "2009.06468", "submitter": "Sai Sri Sathya", "authors": "Ramesh Raskar and Sai Sri Sathya", "title": "Bluetooth based Proximity, Multi-hop Analysis and Bi-directional Trust:\n  Epidemics and More", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a trust layer on top of Bluetooth and similar\nwireless communication technologies that can form mesh networks. This layer as\na protocol enables computing trust scores based on proximity and bi-directional\ntransfer of messages in multiple hops across a network of mobile devices. We\ndescribe factors and an approach for determining these trust scores and\nhighlight its applications during epidemics such as COVID-19 through improved\ncontact-tracing, better privacy and verification for sensitive data sharing in\nthe numerous Bluetooth and GPS based mobile applications that are being\ndeveloped to track the spread.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 17:23:00 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Raskar", "Ramesh", ""], ["Sathya", "Sai Sri", ""]]}, {"id": "2009.06489", "submitter": "Sara Hooker", "authors": "Sara Hooker", "title": "The Hardware Lottery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hardware, systems and algorithms research communities have historically had\ndifferent incentive structures and fluctuating motivation to engage with each\nother explicitly. This historical treatment is odd given that hardware and\nsoftware have frequently determined which research ideas succeed (and fail).\nThis essay introduces the term hardware lottery to describe when a research\nidea wins because it is suited to the available software and hardware and not\nbecause the idea is superior to alternative research directions. Examples from\nearly computer science history illustrate how hardware lotteries can delay\nresearch progress by casting successful ideas as failures. These lessons are\nparticularly salient given the advent of domain specialized hardware which make\nit increasingly costly to stray off of the beaten path of research ideas. This\nessay posits that the gains from progress in computing are likely to become\neven more uneven, with certain research directions moving into the fast-lane\nwhile progress on others is further obstructed.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 14:49:10 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 22:58:12 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Hooker", "Sara", ""]]}, {"id": "2009.06516", "submitter": "Debabrota Basu", "authors": "Bishwamittra Ghosh, Debabrota Basu, Kuldeep S. Meel", "title": "Justicia: A Stochastic SAT Approach to Formally Verify Fairness", "comments": "24 pages, 7 figures, 5 theorems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As a technology ML is oblivious to societal good or bad, and thus, the field\nof fair machine learning has stepped up to propose multiple mathematical\ndefinitions, algorithms, and systems to ensure different notions of fairness in\nML applications. Given the multitude of propositions, it has become imperative\nto formally verify the fairness metrics satisfied by different algorithms on\ndifferent datasets. In this paper, we propose a \\textit{stochastic\nsatisfiability} (SSAT) framework, Justicia, that formally verifies different\nfairness measures of supervised learning algorithms with respect to the\nunderlying data distribution. We instantiate Justicia on multiple\nclassification and bias mitigation algorithms, and datasets to verify different\nfairness metrics, such as disparate impact, statistical parity, and equalized\nodds. Justicia is scalable, accurate, and operates on non-Boolean and compound\nsensitive attributes unlike existing distribution-based verifiers, such as\nFairSquare and VeriFair. Being distribution-based by design, Justicia is more\nrobust than the verifiers, such as AIF360, that operate on specific test\nsamples. We also theoretically bound the finite-sample error of the verified\nfairness measure.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 15:23:51 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Ghosh", "Bishwamittra", ""], ["Basu", "Debabrota", ""], ["Meel", "Kuldeep S.", ""]]}, {"id": "2009.06522", "submitter": "Damla Cay", "authors": "Damla Cay, Till Nagel, Asim Evren Yantac", "title": "ColVis: Collaborative Visualization Design Workshops for Diverse User\n  Groups", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding different types of users' needs can even be more critical in\ntoday's data visualization field, as exploratory visualizations for novice\nusers are becoming more widespread with an increasing amount of data sources.\nThe complexity of data-driven projects requires input from including\ninterdisciplinary expert and novice users. Our workshop framework helps taking\ndesign decisions collaboratively with experts and novice users, on different\nlevels such as outlining users and goals, identifying tasks, structuring data,\nand creating data visualization ideas. We conducted workshops for two different\ndata visualization projects. For each project, we conducted a workshop with\nproject stakeholders who are domain experts, then a second workshop with novice\nusers. We collected feedback from participants and used critical reflection on\nthe process. Later on, we created recommendations on how this workshop\nstructure can be used by others. Our main contributions are, (1) the workshop\nframework for designing data visualizations, (2) describing the outcomes and\nlessons learned from multiple workshops.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 15:34:40 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Cay", "Damla", ""], ["Nagel", "Till", ""], ["Yantac", "Asim Evren", ""]]}, {"id": "2009.06526", "submitter": "Pradipta Biswas", "authors": "Shashank Kumar, JeevithaShree DV and Pradipta Biswas", "title": "Accessibility evaluation of websites using WCAG tools and Cambridge\n  Simulator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is plethora of tools available for automatic evaluation of web\naccessibility with respect to WCAG. This paper compares a set of WCAG tools and\ntheir results in terms of ease of comprehension and implementation by web\ndevelopers. The paper highlights accessibility issues that cannot be captured\nonly through conformance to WCAG tools and propose additional methods to\nevaluate accessibility through an Inclusive User Model. We initially selected\nten WCAG tools from W3 website and used a set of these tools on the landing\npages of BBC and WHO websites. We compared their outcome in terms of\ncommonality, differences, amount of details and usability. Finally, we briefly\nintroduced the Inclusive User Model and demonstrated how simulation of user\ninteraction can capture usability and accessibility issues that are not\ndetected through WCAG analysis. The paper concludes with a proposal on a Common\nUser Profile format that can be used to compare and contrast accessibility\nsystems and services, and to simulate and personalize interaction for users\nwith different range of abilities.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 15:41:25 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Kumar", "Shashank", ""], ["DV", "JeevithaShree", ""], ["Biswas", "Pradipta", ""]]}, {"id": "2009.06602", "submitter": "Tavpritesh Sethi", "authors": "Raghav Awasthi, Keerat Kaur Guliani, Saif Ahmad Khan, Aniket\n  Vashishtha, Mehrab Singh Gill, Arshita Bhatt, Aditya Nagori, Aniket Gupta,\n  Ponnurangam Kumaraguru, Tavpritesh Sethi", "title": "VacSIM: Learning Effective Strategies for COVID-19 Vaccine Distribution\n  using Reinforcement Learning", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A COVID-19 vaccine is our best bet for mitigating the ongoing onslaught of\nthe pandemic. However, vaccine is also expected to be a limited resource. An\noptimal allocation strategy, especially in countries with access inequities and\ntemporal separation of hot-spots, might be an effective way of halting the\ndisease spread. We approach this problem by proposing a novel pipeline VacSIM\nthat dovetails Sequential Decision based RL models into a Contextual Bandits\napproach for optimizing the distribution of COVID-19 vaccine. Whereas the\nReinforcement Learning models suggest better actions and rewards, Contextual\nBandits allow online modifications that may need to be implemented on a\nday-to-day basis in the real world scenario. We evaluate this framework against\na naive allocation approach of distributing vaccine proportional to the\nincidence of COVID-19 cases in five different States across India and\ndemonstrate up to 9039 additional lives potentially saved and a significant\nincrease in the efficacy of limiting the spread over a period of 45 days\nthrough the VacSIM approach. We also propose novel evaluation strategies\nincluding standard compartmental model-based projections and a causality\npreserving evaluation of our model. Finally, we contribute a new Open-AI\nenvironment meant for the vaccine distribution scenario and open-source VacSIM\nfor wide testing and applications across the\nglobe(http://vacsim.tavlab.iiitd.edu.in:8000/).\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 17:37:13 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 10:21:29 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Awasthi", "Raghav", ""], ["Guliani", "Keerat Kaur", ""], ["Khan", "Saif Ahmad", ""], ["Vashishtha", "Aniket", ""], ["Gill", "Mehrab Singh", ""], ["Bhatt", "Arshita", ""], ["Nagori", "Aditya", ""], ["Gupta", "Aniket", ""], ["Kumaraguru", "Ponnurangam", ""], ["Sethi", "Tavpritesh", ""]]}, {"id": "2009.06672", "submitter": "Allen ONeill", "authors": "Allen ONeill", "title": "Data Quality Evaluation using Probability Models", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses an approach with machine-learning probability models to\nevaluate the difference between good and bad data quality in a dataset. A\ndecision tree algorithm is used to predict data quality based on no domain\nknowledge of the datasets under examination. It is shown that for the data\nexamined, the ability to predict the quality of data based on simple good/bad\npre-labelled learning examples is accurate, however in general it may not be\nsufficient for useful production data quality assessment.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 18:12:19 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["ONeill", "Allen", ""]]}, {"id": "2009.06675", "submitter": "David Broniatowski", "authors": "Lydia P. Gleaves, Reva Schwartz, David A. Broniatowski", "title": "The Role of Individual User Differences in Interpretable and Explainable\n  Machine Learning Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is increased interest in assisting non-expert audiences to effectively\ninteract with machine learning (ML) tools and understand the complex output\nsuch systems produce. Here, we describe user experiments designed to study how\nindividual skills and personality traits predict interpretability,\nexplainability, and knowledge discovery from ML generated model output. Our\nwork relies on Fuzzy Trace Theory, a leading theory of how humans process\nnumerical stimuli, to examine how different end users will interpret the output\nthey receive while interacting with the ML system. While our sample was small,\nwe found that interpretability -- being able to make sense of system output --\nand explainability -- understanding how that output was generated -- were\ndistinct aspects of user experience. Additionally, subjects were more able to\ninterpret model output if they possessed individual traits that promote\nmetacognitive monitoring and editing, associated with more detailed, verbatim,\nprocessing of ML output. Finally, subjects who are more familiar with ML\nsystems felt better supported by them and more able to discover new patterns in\ndata; however, this did not necessarily translate to meaningful insights. Our\nwork motivates the design of systems that explicitly take users' mental\nrepresentations into account during the design process to more effectively\nsupport end user requirements.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 18:15:00 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Gleaves", "Lydia P.", ""], ["Schwartz", "Reva", ""], ["Broniatowski", "David A.", ""]]}, {"id": "2009.06807", "submitter": "Alex Newhouse", "authors": "Kris McGuffie, Alex Newhouse", "title": "The Radicalization Risks of GPT-3 and Advanced Neural Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we expand on our previous research of the potential for abuse\nof generative language models by assessing GPT-3. Experimenting with prompts\nrepresentative of different types of extremist narrative, structures of social\ninteraction, and radical ideologies, we find that GPT-3 demonstrates\nsignificant improvement over its predecessor, GPT-2, in generating extremist\ntexts. We also show GPT-3's strength in generating text that accurately\nemulates interactive, informational, and influential content that could be\nutilized for radicalizing individuals into violent far-right extremist\nideologies and behaviors. While OpenAI's preventative measures are strong, the\npossibility of unregulated copycat technology represents significant risk for\nlarge-scale online radicalization and recruitment; thus, in the absence of\nsafeguards, successful and efficient weaponization that requires little\nexperimentation is likely. AI stakeholders, the policymaking community, and\ngovernments should begin investing as soon as possible in building social\nnorms, public policy, and educational initiatives to preempt an influx of\nmachine-generated disinformation and propaganda. Mitigation will require\neffective policy and partnerships across industry, government, and civil\nsociety.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 00:55:00 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["McGuffie", "Kris", ""], ["Newhouse", "Alex", ""]]}, {"id": "2009.06856", "submitter": "Anilesh Kollagunta Krishnaswamy", "authors": "Ashish Goel, Anilesh K. Krishnaswamy, Sukolsak Sakshuwong, Tanja\n  Aitamurto", "title": "Knapsack Voting for Participatory Budgeting", "comments": null, "journal-ref": null, "doi": "10.1145/3340230", "report-no": null, "categories": "cs.GT cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the question of aggregating the preferences of voters in the\ncontext of participatory budgeting. We scrutinize the voting method currently\nused in practice, underline its drawbacks, and introduce a novel scheme\ntailored to this setting, which we call \"Knapsack Voting\". We study its\nstrategic properties - we show that it is strategy-proof under a natural model\nof utility (a dis-utility given by the $\\ell_1$ distance between the outcome\nand the true preference of the voter), and \"partially\" strategy-proof under\ngeneral additive utilities. We extend Knapsack Voting to more general settings\nwith revenues, deficits or surpluses, and prove a similar strategy-proofness\nresult. To further demonstrate the applicability of our scheme, we discuss its\nimplementation on the digital voting platform that we have deployed in\npartnership with the local government bodies in many cities across the nation.\nFrom voting data thus collected, we present empirical evidence that Knapsack\nVoting works well in practice.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 03:58:03 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Goel", "Ashish", ""], ["Krishnaswamy", "Anilesh K.", ""], ["Sakshuwong", "Sukolsak", ""], ["Aitamurto", "Tanja", ""]]}, {"id": "2009.07057", "submitter": "Parthasarathy Suryanarayanan", "authors": "Parthasarathy Suryanarayanan, Ching-Huei Tsou, Ananya Poddar, Diwakar\n  Mahajan, Bharath Dandala, Piyush Madan, Anshul Agrawal, Charles Wachira,\n  Osebe Mogaka Samuel, Osnat Bar-Shira, Clifton Kipchirchir, Sharon Okwako,\n  William Ogallo, Fred Otieno, Timothy Nyota, Fiona Matu, Vesna Resende Barros,\n  Daniel Shats, Oren Kagan, Sekou Remy, Oliver Bent, Pooja Guhan, Shilpa\n  Mahatma, Aisha Walcott-Bryant, Divya Pathak, Michal Rosen-Zvi", "title": "WNTRAC: AI Assisted Tracking of Non-pharmaceutical Interventions\n  Implemented Worldwide for COVID-19", "comments": "Updated title (Artificial Intelligence => AI). Updated figures.\n  Referenced the open-sourced code repository in Code Availability section.\n  Updated figures in the Usage Notes section", "journal-ref": null, "doi": "10.1038/s41597-021-00878-y", "report-no": null, "categories": "cs.CY cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Coronavirus disease 2019 (COVID-19) global pandemic has transformed\nalmost every facet of human society throughout the world. Against an emerging,\nhighly transmissible disease with no definitive treatment or vaccine,\ngovernments worldwide have implemented non-pharmaceutical intervention (NPI) to\nslow the spread of the virus. Examples of such interventions include community\nactions (e.g. school closures, restrictions on mass gatherings), individual\nactions (e.g. mask wearing, self-quarantine), and environmental actions (e.g.\npublic facility cleaning). We present the Worldwide Non-pharmaceutical\nInterventions Tracker for COVID-19 (WNTRAC), a comprehensive dataset consisting\nof over 6,000 NPIs implemented worldwide since the start of the pandemic.\nWNTRAC covers NPIs implemented across 261 countries and territories, and\nclassifies NPI measures into a taxonomy of sixteen NPI types. NPI measures are\nautomatically extracted daily from Wikipedia articles using natural language\nprocessing techniques and manually validated to ensure accuracy and veracity.\nWe hope that the dataset is valuable for policymakers, public health leaders,\nand researchers in modeling and analysis efforts for controlling the spread of\nCOVID-19.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 18:06:20 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 14:07:07 GMT"}, {"version": "v3", "created": "Sat, 5 Dec 2020 17:39:22 GMT"}, {"version": "v4", "created": "Mon, 4 Jan 2021 19:12:48 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Suryanarayanan", "Parthasarathy", ""], ["Tsou", "Ching-Huei", ""], ["Poddar", "Ananya", ""], ["Mahajan", "Diwakar", ""], ["Dandala", "Bharath", ""], ["Madan", "Piyush", ""], ["Agrawal", "Anshul", ""], ["Wachira", "Charles", ""], ["Samuel", "Osebe Mogaka", ""], ["Bar-Shira", "Osnat", ""], ["Kipchirchir", "Clifton", ""], ["Okwako", "Sharon", ""], ["Ogallo", "William", ""], ["Otieno", "Fred", ""], ["Nyota", "Timothy", ""], ["Matu", "Fiona", ""], ["Barros", "Vesna Resende", ""], ["Shats", "Daniel", ""], ["Kagan", "Oren", ""], ["Remy", "Sekou", ""], ["Bent", "Oliver", ""], ["Guhan", "Pooja", ""], ["Mahatma", "Shilpa", ""], ["Walcott-Bryant", "Aisha", ""], ["Pathak", "Divya", ""], ["Rosen-Zvi", "Michal", ""]]}, {"id": "2009.07141", "submitter": "D. M. Anisuzzaman", "authors": "D. M. Anisuzzaman (1), Chuanbo Wang (1), Behrouz Rostami (2), Sandeep\n  Gopalakrishnan (3), Jeffrey Niezgoda (4), and Zeyun Yu (1) ((1) Department of\n  Computer Science, University of Wisconsin-Milwaukee, Milwaukee, WI, USA, (2)\n  Department of Electrical Engineering, University of Wisconsin-Milwaukee,\n  Milwaukee, WI, USA, (3) College of Nursing, University of\n  Wisconsin-Milwaukee, Milwaukee, WI, USA, (4) Jeffrey Niezgoda is with the AZH\n  Wound Center, Milwaukee, WI, USA.)", "title": "Image Based Artificial Intelligence in Wound Assessment: A Systematic\n  Review", "comments": "18 pages, 9 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Efficient and effective assessment of acute and chronic wounds can help wound\ncare teams in clinical practice to greatly improve wound diagnosis, optimize\ntreatment plans, ease the workload and achieve health related quality of life\nto the patient population. While artificial intelligence (AI) has found wide\napplications in health-related sciences and technology, AI-based systems remain\nto be developed clinically and computationally for high-quality wound care. To\nthis end, we have carried out a systematic review of intelligent image-based\ndata analysis and system developments for wound assessment. Specifically, we\nprovide an extensive review of research methods on wound measurement\n(segmentation) and wound diagnosis (classification). We also reviewed recent\nwork on wound assessment systems (including hardware, software, and mobile\napps). More than 250 articles were retrieved from various publication databases\nand online resources, and 115 of them were carefully selected to cover the\nbreadth and depth of most recent and relevant work to convey the current review\nto its fulfillment.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 14:52:14 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Anisuzzaman", "D. M.", ""], ["Wang", "Chuanbo", ""], ["Rostami", "Behrouz", ""], ["Gopalakrishnan", "Sandeep", ""], ["Niezgoda", "Jeffrey", ""], ["Yu", "Zeyun", ""]]}, {"id": "2009.07262", "submitter": "Abhishek Gupta", "authors": "Abhishek Gupta (1 and 2), Camylle Lanteigne (1 and 3), Victoria Heath\n  (1) ((1) Montreal AI Ethics Institute, (2) Microsoft, (3) Algora Lab)", "title": "Report prepared by the Montreal AI Ethics Institute (MAIEI) on\n  Publication Norms for Responsible AI", "comments": "Report submitted to Partnership on AI for inclusion in their work on\n  Publishing Norms for Responsible AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The history of science and technology shows that seemingly innocuous\ndevelopments in scientific theories and research have enabled real-world\napplications with significant negative consequences for humanity. In order to\nensure that the science and technology of AI is developed in a humane manner,\nwe must develop research publication norms that are informed by our growing\nunderstanding of AI's potential threats and use cases. Unfortunately, it's\ndifficult to create a set of publication norms for responsible AI because the\nfield of AI is currently fragmented in terms of how this technology is\nresearched, developed, funded, etc. To examine this challenge and find\nsolutions, the Montreal AI Ethics Institute (MAIEI) co-hosted two public\nconsultations with the Partnership on AI in May 2020. These meetups examined\npotential publication norms for responsible AI, with the goal of creating a\nclear set of recommendations and ways forward for publishers.\n  In its submission, MAIEI provides six initial recommendations, these include:\n1) create tools to navigate publication decisions, 2) offer a page number\nextension, 3) develop a network of peers, 4) require broad impact statements,\n5) require the publication of expected results, and 6) revamp the peer-review\nprocess. After considering potential concerns regarding these recommendations,\nincluding constraining innovation and creating a \"black market\" for AI\nresearch, MAIEI outlines three ways forward for publishers, these include: 1)\nstate clearly and consistently the need for established norms, 2) coordinate\nand build trust as a community, and 3) change the approach.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 17:51:40 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 07:50:39 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Gupta", "Abhishek", "", "1 and 2"], ["Lanteigne", "Camylle", "", "1 and 3"], ["Heath", "Victoria", "", "Montreal AI Ethics Institute"]]}, {"id": "2009.07727", "submitter": "Diego Kozlowski", "authors": "Diego Kozlowski, Viktoriya Semeshenko and Andrea Molinari", "title": "Latent Dirichlet Allocation Models for World Trade Analysis", "comments": null, "journal-ref": "PLOS ONE (2021) 16(2): e0245393", "doi": "10.1371/journal.pone.0245393", "report-no": null, "categories": "physics.soc-ph cs.CY econ.GN q-fin.EC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The international trade is one of the classic areas of study in economics.\nNowadays, given the availability of data, the tools used for the analysis can\nbe complemented and enriched with new methodologies and techniques that go\nbeyond the traditional approach. The present paper shows the application of the\nLatent Dirichlet Allocation Models, a well known technique from the area of\nNatural Language Processing, to search for latent dimensions in the product\nspace of international trade, and their distribution across countries over\ntime. We apply this technique to a dataset of countries' exports of goods from\n1962 to 2016. The findings show the possibility to generate higher level\nclassifications of goods based on the empirical evidence, and also allow to\nstudy the distribution of those classifications within countries. The latter\nshow interesting insights about countries' trade specialisation.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 14:56:15 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Kozlowski", "Diego", ""], ["Semeshenko", "Viktoriya", ""], ["Molinari", "Andrea", ""]]}, {"id": "2009.07776", "submitter": "Jelena Te\\v{s}i\\'c", "authors": "Lucas Rusnak and Jelena Te\\v{s}i\\'c", "title": "Characterizing Attitudinal Network Graphs through Frustration Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.IR cs.SY eess.SY math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attitudinal Network Graphs are signed graphs where edges capture an expressed\nopinion: two vertices connected by an edge can be agreeable (positive) or\nantagonistic (negative). A signed graph is called balanced if each of its\ncycles includes an even number of negative edges. Balance is often\ncharacterized by frustration index or by finding a single convergent balanced\nstate i.e. network consensus. In this paper, we propose to expand the measures\nof consensus from a single balanced state associated to the frustration index\nto the set of nearest balanced states. We introduce the frustration cloud as a\nset of all nearest balanced states, and use a graph balancing algorithm to find\nall nearest balanced states in deterministic way. Computational concerns are\naddressed by measuring consensus probabilistically, and we introduce new vertex\nand edge metrics to quantify status, agreement, and influence. We introduce new\nglobal measure of controversy for a given signed graph, and show that vertex\nstatus is a zero-sum game in the signed network. We propose an efficient\nscalable algorithm for calculating frustration cloud based measures in social\nnetwork and survey data of up to 80,000 vertices and half-a-million edges, and\nwe demonstrate the power of the proposed approach to provide discriminant\nfeatures for community discovery when compared to spectral clustering and to\nautomatically identify dominant vertices and anomalous decisions in the\nnetwork.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 16:14:16 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 01:46:07 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Rusnak", "Lucas", ""], ["Te\u0161i\u0107", "Jelena", ""]]}, {"id": "2009.07884", "submitter": "Eleanor Birrell", "authors": "Sean O'Connor, Ryan Nurwono, Aden Siebel, Eleanor Birrell", "title": "(Un)clear and (In)conspicuous: The right to opt-out of sale under CCPA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The California Consumer Privacy Act (CCPA) -- which began enforcement on July\n1, 2020 -- grants California users the affirmative right to opt-out of the sale\nof their personal information. In this work, we perform a series of\nobservational studies to understand how websites implement this right. We\nperform two manual analyses of the top 500 U.S. websites (one conducted in July\n2020 and a second conducted in January 2021) and classify how each site\nimplements this new requirement. We also perform an automated analysis of the\nTop 5000 U.S. websites. We find that the vast majority of sites that implement\nopt-out mechanisms do so with a Do Not Sell link rather than with a privacy\nbanner, and that many of the linked opt-out controls exhibit features such as\nnudging and indirect mechanisms (e.g., fillable forms). We then perform a pair\nof user studies with 4357 unique users (recruited from Google Ads and Amazon\nMechanical Turk) in which we observe how users interact with different opt-out\nmechanisms and evaluate how the implementation choices we observed -- exclusive\nuse of links, prevalent nudging, and indirect mechanisms -- affect the rate at\nwhich users exercise their right to opt-out of sale. We find that these design\nelements significantly deter interactions with opt-out mechanisms -- including\nreducing the opt-out rate for users who are uncomfortable with the sale of\ntheir information -- and that they reduce users' awareness of their ability to\nopt-out. Our results demonstrate the importance of regulations that provide\nclear implementation requirements in order empower users to exercise their\nprivacy rights.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 18:31:23 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 15:59:28 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["O'Connor", "Sean", ""], ["Nurwono", "Ryan", ""], ["Siebel", "Aden", ""], ["Birrell", "Eleanor", ""]]}, {"id": "2009.08002", "submitter": "Pushpendra Rana", "authors": "Pushpendra Rana and Lav R Varshney", "title": "Planting trees at the right places: Recommending suitable sites for\n  growing trees using algorithm fusion", "comments": "26 pages, 4 figures, 2 tables, 2 supplemental tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale planting of trees has been proposed as a low-cost natural\nsolution for carbon mitigation, but is hampered by poor selection of plantation\nsites, especially in developing countries. To aid in site selection, we develop\nthe ePSA (e-Plantation Site Assistant) recommendation system based on algorithm\nfusion that combines physics-based/traditional forestry science knowledge with\nmachine learning. ePSA assists forest range officers by identifying blank\npatches inside forest areas and ranking each such patch based on their tree\ngrowth potential. Experiments, user studies, and deployment results\ncharacterize the utility of the recommender system in shaping the long-term\nsuccess of tree plantations as a nature climate solution for carbon mitigation\nin northern India and beyond.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 01:17:13 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 08:08:46 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Rana", "Pushpendra", ""], ["Varshney", "Lav R", ""]]}, {"id": "2009.08005", "submitter": "Essam Rashed", "authors": "Sachiko Kodera, Akimasa Hirata, Fumiaki Miura, Essam A. Rashed,\n  Natsuko Hatsusaka, Naoki Yamamoto, Eri Kubo, Hiroshi Sasaki", "title": "Model-based approach for analyzing prevalence of nuclear cataracts in\n  elderly residents", "comments": "Submitted to Computers in Biology and Medicine", "journal-ref": "Computers in Biology and Medicine, 2020", "doi": "10.1016/j.compbiomed.2020.104009", "report-no": null, "categories": "physics.med-ph cs.CV cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent epidemiological studies have hypothesized that the prevalence of\ncortical cataracts is closely related to ultraviolet radiation. However, the\nprevalence of nuclear cataracts is higher in elderly people in tropical areas\nthan in temperate areas. The dominant factors inducing nuclear cataracts have\nbeen widely debated. In this study, the temperature increase in the lens due to\nexposure to ambient conditions was computationally quantified in subjects of\n50-60 years of age in tropical and temperate areas, accounting for differences\nin thermoregulation. A thermoregulatory response model was extended to consider\nelderly people in tropical areas. The time course of lens temperature for\ndifferent weather conditions in five cities in Asia was computed. The\ntemperature was higher around the mid and posterior part of the lens, which\ncoincides with the position of the nuclear cataract. The duration of higher\ntemperatures in the lens varied, although the daily maximum temperatures were\ncomparable. A strong correlation (adjusted R2 > 0.85) was observed between the\nprevalence of nuclear cataract and the computed cumulative thermal dose in the\nlens. We propose the use of a cumulative thermal dose to assess the prevalence\nof nuclear cataracts. Cumulative wet-bulb globe temperature, a new metric\ncomputed from weather data, would be useful for practical assessment in\ndifferent cities.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 01:35:58 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Kodera", "Sachiko", ""], ["Hirata", "Akimasa", ""], ["Miura", "Fumiaki", ""], ["Rashed", "Essam A.", ""], ["Hatsusaka", "Natsuko", ""], ["Yamamoto", "Naoki", ""], ["Kubo", "Eri", ""], ["Sasaki", "Hiroshi", ""]]}, {"id": "2009.08192", "submitter": "Yassine Himeur", "authors": "Yassine Himeur and Abdullah Alsalemi and Faycal Bensaali and Abbes\n  Amira", "title": "Building power consumption datasets: Survey, taxonomy and future\n  directions", "comments": "24 pages, 5 figures", "journal-ref": "Energy and Buildings, vol. 227, 2020, 110404", "doi": "10.1016/j.enbuild.2020.110404", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade, extended efforts have been poured into energy efficiency.\nSeveral energy consumption datasets were henceforth published, with each\ndataset varying in properties, uses and limitations. For instance, building\nenergy consumption patterns are sourced from several sources, including ambient\nconditions, user occupancy, weather conditions and consumer preferences. Thus,\na proper understanding of the available datasets will result in a strong basis\nfor improving energy efficiency. Starting from the necessity of a comprehensive\nreview of existing databases, this work is proposed to survey, study and\nvisualize the numerical and methodological nature of building energy\nconsumption datasets. A total of thirty-one databases are examined and compared\nin terms of several features, such as the geographical location, period of\ncollection, number of monitored households, sampling rate of collected data,\nnumber of sub-metered appliances, extracted features and release date.\nFurthermore, data collection platforms and related modules for data\ntransmission, data storage and privacy concerns used in different datasets are\nalso analyzed and compared. Based on the analytical study, a novel dataset has\nbeen presented, namely Qatar university dataset, which is an annotated power\nconsumption anomaly detection dataset. The latter will be very useful for\ntesting and training anomaly detection algorithms, and hence reducing wasted\nenergy. Moving forward, a set of recommendations is derived to improve datasets\ncollection, such as the adoption of multi-modal data collection, smart Internet\nof things data collection, low-cost hardware platforms and privacy and security\nmechanisms. In addition, future directions to improve datasets exploitation and\nutilization are identified, including the use of novel machine learning\nsolutions, innovative visualization tools and explainable recommender systems.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 10:19:21 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Himeur", "Yassine", ""], ["Alsalemi", "Abdullah", ""], ["Bensaali", "Faycal", ""], ["Amira", "Abbes", ""]]}, {"id": "2009.08210", "submitter": "Yassine Himeur", "authors": "Yassine Himeur, Abdullah Alsalemi, Faycal Bensaali, Abbes Amira", "title": "Efficient multi-descriptor fusion for non-intrusive appliance\n  recognition", "comments": "This article has been accepted in ISCAS 2020, Seville, Spain, 2020", "journal-ref": "IEEE International Symposium on Circuits and Systems (ISCAS 2020)", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consciousness about power consumption at the appliance level can assist user\nin promoting energy efficiency in households. In this paper, a superior\nnon-intrusive appliance recognition method that can provide particular\nconsumption footprints of each appliance is proposed. Electrical devices are\nwell recognized by the combination of different descriptors via the following\nsteps: (a) investigating the applicability along with performance comparability\nof several time-domain (TD) feature extraction schemes; (b) exploring their\ncomplementary features; and (c) making use of a new design of the ensemble\nbagging tree (EBT) classifier. Consequently, a powerful feature extraction\ntechnique based on the fusion of TD features is proposed, namely fTDF, aimed at\nimproving the feature discrimination ability and optimizing the recognition\ntask. An extensive experimental performance assessment is performed on two\ndifferent datasets called the GREEND and WITHED, where power consumption\nsignatures were gathered at 1 Hz and 44000 Hz sampling frequencies,\nrespectively. The obtained results revealed prime efficiency of the proposed\nfTDF based EBT system in comparison with other TD descriptors and machine\nlearning classifiers.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 11:11:41 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 13:00:05 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Himeur", "Yassine", ""], ["Alsalemi", "Abdullah", ""], ["Bensaali", "Faycal", ""], ["Amira", "Abbes", ""]]}, {"id": "2009.08281", "submitter": "Michael Lyons", "authors": "Michael Lyons and Kazunori Morikawa", "title": "A Linked Aggregate Code for Processing Faces (Revised Version)", "comments": "18 pages, 3 figures, 1 table", "journal-ref": null, "doi": "10.5281/zenodo.4034544", "report-no": null, "categories": "cs.CV cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A model of face representation, inspired by the biology of the visual system,\nis compared to experimental data on the perception of facial similarity. The\nface representation model uses aggregate primary visual cortex (V1) cell\nresponses topographically linked to a grid covering the face, allowing\ncomparison of shape and texture at corresponding points in two facial images.\nWhen a set of relatively similar faces was used as stimuli, this Linked\nAggregate Code (LAC) predicted human performance in similarity judgment\nexperiments. When faces of perceivable categories were used, dimensions such as\napparent sex and race emerged from the LAC model without training. The\ndimensional structure of the LAC similarity measure for the mixed category task\ndisplayed some psychologically plausible features but also highlighted\ndifferences between the model and the human similarity judgements. The human\njudgements exhibited a racial perceptual bias that was not shared by the LAC\nmodel. The results suggest that the LAC based similarity measure may offer a\nfertile starting point for further modelling studies of face representation in\nhigher visual areas, including studies of the development of biases in face\nperception.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 13:29:25 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Lyons", "Michael", ""], ["Morikawa", "Kazunori", ""]]}, {"id": "2009.08282", "submitter": "Yassine Himeur", "authors": "Yassine Himeur, Abdullah Alsalemi, Faycal Bensaali, Abbes Amira", "title": "Improving in-home appliance identification using\n  fuzzy-neighbors-preserving analysis based QR-decomposition", "comments": null, "journal-ref": "Fifth International Congress on Information and Communication\n  Technology (ICICT), London, UK, 2020", "doi": null, "report-no": null, "categories": "eess.SP cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new appliance identification scheme by introducing a\nnovel approach for extracting highly discriminative characteristic sets that\ncan considerably distinguish between various appliance footprints. In this\ncontext, a precise and powerful characteristic projection technique depending\non fuzzy-neighbors-preserving analysis based QR-decomposition (FNPA-QR) is\napplied on the extracted energy consumption time-domain features. The FNPA-QR\naims to diminish the distance among the between class features and increase the\ngap among features of dissimilar categories. Following, a novel bagging\ndecision tree (BDT) classifier is also designed to further improve the\nclassification accuracy. The proposed technique is then validated on three\nappliance energy consumption datasets, which are collected at both low and high\nfrequency. The practical results obtained point out the outstanding\nclassification rate of the time-domain based FNPA-QR and BDT.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 13:29:34 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Himeur", "Yassine", ""], ["Alsalemi", "Abdullah", ""], ["Bensaali", "Faycal", ""], ["Amira", "Abbes", ""]]}, {"id": "2009.08392", "submitter": "Joshua Garland", "authors": "Joshua Garland, Keyan Ghazi-Zahedi, Jean-Gabriel Young, Laurent\n  H\\'ebert-Dufresne, Mirta Galesic", "title": "Impact and dynamics of hate and counter speech online", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Citizen-generated counter speech is a promising way to fight hate speech and\npromote peaceful, non-polarized discourse. However, there is a lack of\nlarge-scale longitudinal studies of its effectiveness for reducing hate speech.\nWe investigate the effectiveness of counter speech using several different\nmacro- and micro-level measures of over 180,000 political conversations that\ntook place on German Twitter over four years. We report on the dynamic\ninteractions of hate and counter speech over time and provide insights into\nwhether, as in `classic' bullying situations, organized efforts are more\neffective than independent individuals in steering online discourse. Taken\ntogether, our results build a multifaceted picture of the dynamics of hate and\ncounter speech online. They suggest that organized hate speech produced changes\nin the public discourse. Counter speech, especially when organized, could help\nin curbing hate speech in online discussions.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 01:43:28 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 16:46:04 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Garland", "Joshua", ""], ["Ghazi-Zahedi", "Keyan", ""], ["Young", "Jean-Gabriel", ""], ["H\u00e9bert-Dufresne", "Laurent", ""], ["Galesic", "Mirta", ""]]}, {"id": "2009.08410", "submitter": "Konstantin Klemmer", "authors": "Konstantin Klemmer, Godwin Yeboah, Jo\\~ao Porto de Albuquerque,\n  Stephen A Jarvis", "title": "Population Mapping in Informal Settlements with High-Resolution\n  Satellite Imagery and Equitable Ground-Truth", "comments": "ML-IRL workshop at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a generalizable framework for the population estimation of dense,\ninformal settlements in low-income urban areas--so called 'slums'--using\nhigh-resolution satellite imagery. Precise population estimates are a crucial\nfactor for efficient resource allocations by government authorities and NGO's,\nfor instance in medical emergencies. We utilize equitable ground-truth data,\nwhich is gathered in collaboration with local communities: Through training and\ncommunity mapping, the local population contributes their unique domain\nknowledge, while also maintaining agency over their data. This practice allows\nus to avoid carrying forward potential biases into the modeling pipeline, which\nmight arise from a less rigorous ground-truthing approach. We contextualize our\napproach in respect to the ongoing discussion within the machine learning\ncommunity, aiming to make real-world machine learning applications more\ninclusive, fair and accountable. Because of the resource intensive ground-truth\ngeneration process, our training data is limited. We propose a gridded\npopulation estimation model, enabling flexible and customizable spatial\nresolutions. We test our pipeline on three experimental site in Nigeria,\nutilizing pre-trained and fine-tune vision networks to overcome data sparsity.\nOur findings highlight the difficulties of transferring common benchmark models\nto real-world tasks. We discuss this and propose steps forward.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 16:37:32 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Klemmer", "Konstantin", ""], ["Yeboah", "Godwin", ""], ["de Albuquerque", "Jo\u00e3o Porto", ""], ["Jarvis", "Stephen A", ""]]}, {"id": "2009.08577", "submitter": "Hallie Siegel", "authors": "T. Barfoot (1), J. Burgner-Kahrs (1), E. Diller (1), A. Garg (1), A.\n  Goldenberg (1), J. Kelly (1), X. Liu (1), H.E. Naguib (1), G. Nejat (1), A.P.\n  Schoellig (1), F. Shkurti (1), H. Siegel (1), Y. Sun (1), S.L. Waslander (1).\n  ((1) University of Toronto Robotics Institute)", "title": "Making Sense of the Robotized Pandemic Response: A Comparison of Global\n  and Canadian Robot Deployments and Success Factors", "comments": "104 pages, 18 figures, 13 tables. Corresponding Author: H Siegel", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From disinfection and remote triage, to logistics and delivery, countries\naround the world are making use of robots to address the unique challenges\npresented by the COVID-19 pandemic. Robots are being used to manage the\npandemic in Canada too, but relative to other regions, we have been more\ncautious in our adoption -- this despite the important role that robots of\nCanadian origin are now playing on the global stage. This white paper discusses\nwhy this is the case, and argues that strategic investment and support for the\nCanadian robotics industry are urgently needed to bring the benefits of\nrobotics home, where we have more control in shaping the future of this\ngame-changing technology. Such investments will not only serve to support\nCanada's current pandemic response and post pandemic recovery, but will also\nprepare this country to weather future crises. Without such support, Canada\nrisks falling behind other developed nations that are investing heavily in\nhardware automation at this time.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 01:14:49 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 15:27:37 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Barfoot", "T.", "", "University of Toronto Robotics Institute"], ["Burgner-Kahrs", "J.", "", "University of Toronto Robotics Institute"], ["Diller", "E.", "", "University of Toronto Robotics Institute"], ["Garg", "A.", "", "University of Toronto Robotics Institute"], ["Goldenberg", "A.", "", "University of Toronto Robotics Institute"], ["Kelly", "J.", "", "University of Toronto Robotics Institute"], ["Liu", "X.", "", "University of Toronto Robotics Institute"], ["Naguib", "H. E.", "", "University of Toronto Robotics Institute"], ["Nejat", "G.", "", "University of Toronto Robotics Institute"], ["Schoellig", "A. P.", "", "University of Toronto Robotics Institute"], ["Shkurti", "F.", "", "University of Toronto Robotics Institute"], ["Siegel", "H.", "", "University of Toronto Robotics Institute"], ["Sun", "Y.", "", "University of Toronto Robotics Institute"], ["Waslander", "S. L.", "", "University of Toronto Robotics Institute"], [".", "", ""]]}, {"id": "2009.08646", "submitter": "Rahim Rahmani", "authors": "Rahim Rahmani and Ramin Firouzi", "title": "Gateway Controller with Deep Sensing: Learning to be Autonomic in\n  Intelligent Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY cs.LG cs.NI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The Internet of Things(IoT) will revolutionize the Future Internet through\nubiquitous sensing. One of the challenges of having the hundreds of billions of\ndevices that are estimated to be deployed would be rise of an enormous amount\nof data, along with the devices ability to manage. This paper presents an\napproach as a controller solution and designed specifically for autonomous\nmanagement, connectivity and data interoperability in an IoT gateway. The\napproach supports distributed IoT nodes with both management and data\ninteroperability with other cloud-based solutions. The concept further allows\ngateways to easily collect and process interoperability of data from IoT\ndevices. We demonstrated the feasibility of the approach and evaluate its\nadvantages regarding deep sensing and autonomous enabled gateway as an edge\ncomputational intelligence.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 06:22:04 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Rahmani", "Rahim", ""], ["Firouzi", "Ramin", ""]]}, {"id": "2009.08976", "submitter": "Byungsoo Kim", "authors": "Byungsoo Kim, Hongseok Suh, Jaewe Heo, Youngduck Choi", "title": "AI-Driven Interface Design for Intelligent Tutoring System Improves\n  Student Engagement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An Intelligent Tutoring System (ITS) has been shown to improve students'\nlearning outcomes by providing a personalized curriculum that addresses\nindividual needs of every student. However, despite the effectiveness and\nefficiency that ITS brings to students' learning process, most of the studies\nin ITS research have conducted less effort to design the interface of ITS that\npromotes students' interest in learning, motivation and engagement by making\nbetter use of AI features. In this paper, we explore AI-driven design for the\ninterface of ITS describing diagnostic feedback for students' problem-solving\nprocess and investigate its impacts on their engagement. We propose several\ninterface designs powered by different AI components and empirically evaluate\ntheir impacts on student engagement through Santa, an active mobile ITS.\nControlled A/B tests conducted on more than 20K students in the wild show that\nAI-driven interface design improves the factors of engagement by up to 25.13%.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 10:32:01 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Kim", "Byungsoo", ""], ["Suh", "Hongseok", ""], ["Heo", "Jaewe", ""], ["Choi", "Youngduck", ""]]}, {"id": "2009.09049", "submitter": "Simon Razniewski", "authors": "Jesse Josua Benjamin, Claudia M\\\"uller-Birn, Simon Razniewski", "title": "Examining the Impact of Algorithm Awareness on Wikidata's Recommender\n  System Recoin", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The global infrastructure of the Web, designed as an open and transparent\nsystem, has a significant impact on our society. However, algorithmic systems\nof corporate entities that neglect those principles increasingly populated the\nWeb. Typical representatives of these algorithmic systems are recommender\nsystems that influence our society both on a scale of global politics and\nduring mundane shopping decisions. Recently, such recommender systems have come\nunder critique for how they may strengthen existing or even generate new kinds\nof biases. To this end, designers and engineers are increasingly urged to make\nthe functioning and purpose of recommender systems more transparent. Our\nresearch relates to the discourse of algorithm awareness, that reconsiders the\nrole of algorithm visibility in interface design. We conducted online\nexperiments with 105 participants using MTurk for the recommender system\nRecoin, a gadget for Wikidata. In these experiments, we presented users with\none of a set of three different designs of Recoin's user interface, each of\nthem exhibiting a varying degree of explainability and interactivity. Our\nfindings include a positive correlation between comprehension of and trust in\nan algorithmic system in our interactive redesign. However, our results are not\nconclusive yet, and suggest that the measures of comprehension, fairness,\naccuracy and trust are not yet exhaustive for the empirical study of algorithm\nawareness. Our qualitative insights provide a first indication for further\nmeasures. Our study participants, for example, were less concerned with the\ndetails of understanding an algorithmic calculation than with who or what is\njudging the result of the algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 20:06:53 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Benjamin", "Jesse Josua", ""], ["M\u00fcller-Birn", "Claudia", ""], ["Razniewski", "Simon", ""]]}, {"id": "2009.09065", "submitter": "Pankesh Patel", "authors": "Tapan Pathak and Vatsal Patel and Sarth Kanani and Shailesh Arya and\n  Pankesh Patel and Muhammad Intizar Ali and John Breslin", "title": "A Distributed Framework to Orchestrate Video Analytics Applications", "comments": "9", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The concept of the Internet of Things (IoT) is a reality now. This paradigm\nshift has caught everyones attention in a large class of applications,\nincluding IoT-based video analytics using smart doorbells. Due to its growing\napplication segments, various efforts exist in scientific literature and many\nvideo-based doorbell solutions are commercially available in the market.\nHowever, contemporary offerings are bespoke, offering limited composability and\nreusability of a smart doorbell framework. Second, they are monolithic and\nproprietary, which means that the implementation details remain hidden from the\nusers. We believe that a transparent design can greatly aid in the development\nof a smart doorbell, enabling its use in multiple application domains.\n  To address the above-mentioned challenges, we propose a distributed framework\nto orchestrate video analytics across Edge and Cloud resources. We investigate\ntrade-offs in the distribution of different software components over a\nbespoke/full system, where components over Edge and Cloud are treated\ngenerically. This paper evaluates the proposed framework as well as the\nstate-of-the-art models and presents comparative analysis of them on various\nmetrics (such as overall model accuracy, latency, memory, and CPU usage). The\nevaluation result demonstrates our intuition very well, showcasing that the\nAWS-based approach exhibits reasonably high object-detection accuracy, low\nmemory, and CPU usage when compared to the state-of-the-art approaches, but\nhigh latency.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 07:10:05 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Pathak", "Tapan", ""], ["Patel", "Vatsal", ""], ["Kanani", "Sarth", ""], ["Arya", "Shailesh", ""], ["Patel", "Pankesh", ""], ["Ali", "Muhammad Intizar", ""], ["Breslin", "John", ""]]}, {"id": "2009.09066", "submitter": "Awad Abdelhalim", "authors": "Awad Abdelhalim and Montasir Abbas", "title": "Vehicle Class, Speed, and Roadway Geometry Based Driver Behavior\n  Identification and Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the study of the impact that the class of the vehicle,\nleading heavy vehicles in particular, causes on the following vehicle's\nbehavior, specifically in terms of the bumper-to-bumper distance (gap) between\nthe following and leading vehicles. This was done by extracting and analyzing\ndifferent car-following episodes from the Next Generation Simulation (NGSIM)\ndataset for Interstate 80 (I 80) in Emeryville, California, USA. The results of\nthe statistical analysis are compared to that of the synthesized literature of\nresearch efforts that have been conducted on the topic, then are further\nassessed utilizing different behavioral clusters for the Gazis-Herman-Rothery\n(GHR) car-following model calibrated from naturalistic driving data. We assess\nthe similarities and differences in car-following behavior between drivers of\nthe same vehicle class, validating the results of the statistical analysis and\nhighlighting possible future implementations for improved modeling in\nmicroscopic simulation.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 19:45:39 GMT"}, {"version": "v2", "created": "Thu, 15 Jul 2021 11:25:03 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Abdelhalim", "Awad", ""], ["Abbas", "Montasir", ""]]}, {"id": "2009.09067", "submitter": "Antoine Mazieres", "authors": "Antoine Mazieres and Telmo Menezes and Camille Roth", "title": "Computational appraisal of gender representativeness in popular movies", "comments": "13 pages, 7 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gender representation in mass media has long been mainly studied by\nqualitatively analyzing content. This article illustrates how automated\ncomputational methods may be used in this context to scale up such empirical\nobservations and increase their resolution and significance. We specifically\napply a face and gender detection algorithm on a broad set of popular movies\nspanning more than three decades to carry out a large-scale appraisal of the\non-screen presence of women and men. Beyond the confirmation of a strong\nunder-representation of women, we exhibit a clear temporal trend towards a\nfairer representativeness. We further contrast our findings with respect to\nmovie genre, budget, and various audience-related features such as movie gross\nand user ratings. We lastly propose a fine description of significant\nasymmetries in the mise-en-sc\\`ene and mise-en-cadre of characters in relation\nto their gender and the spatial composition of a given frame.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 13:15:11 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 13:00:25 GMT"}, {"version": "v3", "created": "Wed, 12 May 2021 07:28:47 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Mazieres", "Antoine", ""], ["Menezes", "Telmo", ""], ["Roth", "Camille", ""]]}, {"id": "2009.09068", "submitter": "Norbert B\\'atfai Ph.D.", "authors": "Norbert B\\'atfai", "title": "Hacking with God: a Common Programming Language of Robopsychology and\n  Robophilosophy", "comments": "20 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note is a sketch of how the concept of robopsychology and robophilosophy\ncould be reinterpreted and repositioned in the spirit of the original vocation\nof psychology and philosophy. The notion of the robopsychology as a fictional\nscience and a fictional occupation was introduced by Asimov in the middle of\nthe last century. The robophilosophy, on the other hand, is only a few years\nold today. But at this moment, none of these new emerging disciplines focus on\nthe fundamental and overall issues of the development of artificial general\nintelligence. Instead, they focus only on issues that, although are extremely\nimportant, play a complementary role, such as moral or ethical ones, rather\nthan the big questions of life. We try to outline a conception in which the\nrobophilosophy and robopsychology will be able to play a similar leading rule\nin the progress of artificial intelligence than the philosophy and psychology\nhave done in the progress of human intelligence. To facilitate this, we outline\nthe idea of a visual artificial language and interactive theorem prover-based\ncomputer application called Prime Convo Assistant. The question to be decided\nin the future is whether we can develop such an application. And if so, can we\nbuild a computer game on it, or even an esport game? It may be an interesting\nquestion in order for this game will be able to transform human thinking on the\nwidest possible social scale and will be able to develop a standard\nmathematical logic-based communication channel between human and machine\nintelligence.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 11:59:12 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["B\u00e1tfai", "Norbert", ""]]}, {"id": "2009.09069", "submitter": "Vaibhav Sourirajan", "authors": "Vaibhav Sourirajan, Anas Belouali, Mary Ann Dutton, Matthew Reinhard,\n  Jyotishman Pathak", "title": "A Machine Learning Approach to Detect Suicidal Ideation in US Veterans\n  Based on Acoustic and Linguistic Features of Speech", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preventing Veteran suicide is a national priority. The US Department of\nVeterans Affairs (VA) collects, analyzes, and publishes data to inform suicide\nprevention strategies. Current approaches for detecting suicidal ideation\nmostly rely on patient self report which are inadequate and time consuming. In\nthis research study, our goal was to automate suicidal ideation detection from\nacoustic and linguistic features of an individual's speech using machine\nlearning (ML) algorithms. Using voice data collected from Veterans enrolled in\na large interventional study on Gulf War Illness at the Washington DC VA\nMedical Center, we conducted an evaluation of the performance of different ML\napproaches in achieving our objective. By fitting both classical ML and deep\nlearning models to the dataset, we identified the algorithms that were most\neffective for each feature set. Among classical machine learning algorithms,\nthe Support Vector Machine (SVM) trained on acoustic features performed best in\nclassifying suicidal Veterans. Among deep learning methods, the Convolutional\nNeural Network (CNN) trained on the linguistic features performed best. Our\nstudy shows that speech analysis in a machine learning pipeline is a promising\napproach for detecting suicidality among Veterans.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 00:01:45 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 17:36:49 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Sourirajan", "Vaibhav", ""], ["Belouali", "Anas", ""], ["Dutton", "Mary Ann", ""], ["Reinhard", "Matthew", ""], ["Pathak", "Jyotishman", ""]]}, {"id": "2009.09070", "submitter": "Tim Friede", "authors": "Sarah Friedrich, Gerd Antes, Sigrid Behr, Harald Binder, Werner\n  Brannath, Florian Dumpert, Katja Ickstadt, Hans Kestler, Johannes Lederer,\n  Heinz Leitg\\\"ob, Markus Pauly, Ansgar Steland, Adalbert Wilhelm, Tim Friede", "title": "Is there a role for statistics in artificial intelligence?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The research on and application of artificial intelligence (AI) has triggered\na comprehensive scientific, economic, social and political discussion. Here we\nargue that statistics, as an interdisciplinary scientific field, plays a\nsubstantial role both for the theoretical and practical understanding of AI and\nfor its future development. Statistics might even be considered a core element\nof AI. With its specialist knowledge of data evaluation, starting with the\nprecise formulation of the research question and passing through a study design\nstage on to analysis and interpretation of the results, statistics is a natural\npartner for other disciplines in teaching, research and practice. This paper\naims at contributing to the current discussion by highlighting the relevance of\nstatistical methodology in the context of AI development. In particular, we\ndiscuss contributions of statistics to the field of artificial intelligence\nconcerning methodological development, planning and design of studies,\nassessment of data quality and data collection, differentiation of causality\nand associations and assessment of uncertainty in results. Moreover, the paper\nalso deals with the equally necessary and meaningful extension of curricula in\nschools and universities.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 14:39:37 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Friedrich", "Sarah", ""], ["Antes", "Gerd", ""], ["Behr", "Sigrid", ""], ["Binder", "Harald", ""], ["Brannath", "Werner", ""], ["Dumpert", "Florian", ""], ["Ickstadt", "Katja", ""], ["Kestler", "Hans", ""], ["Lederer", "Johannes", ""], ["Leitg\u00f6b", "Heinz", ""], ["Pauly", "Markus", ""], ["Steland", "Ansgar", ""], ["Wilhelm", "Adalbert", ""], ["Friede", "Tim", ""]]}, {"id": "2009.09071", "submitter": "Saurabh Mishra", "authors": "Saurabh Mishra, Jack Clark, C. Raymond Perrault", "title": "Measurement in AI Policy: Opportunities and Challenges", "comments": "Workshop Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As artificial intelligence increasingly influences our world, it becomes\ncrucial to assess its technical progress and societal impact. This paper\nsurveys problems and opportunities in the measurement of AI systems and their\nimpact, based on a workshop held at Stanford University in the fall of 2019. We\nidentify six summary challenges inherent to measuring the progress and impact\nof AI, and summarize over 40 presentations and associated discussions from the\nworkshop. We hope this can inspire research agendas in this crucial area.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 05:37:40 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Mishra", "Saurabh", ""], ["Clark", "Jack", ""], ["Perrault", "C. Raymond", ""]]}, {"id": "2009.09072", "submitter": "Matthew Ross", "authors": "Blake VanBerlo, Matthew A. S. Ross, Jonathan Rivard and Ryan Booker", "title": "Interpretable Machine Learning Approaches to Prediction of Chronic\n  Homelessness", "comments": "14 pages, 7 figures, submitted to Engineering Applications of\n  Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a machine learning approach to predict chronic homelessness from\nde-identified client shelter records drawn from a commonly used Canadian\nhomelessness management information system. Using a 30-day time step, a dataset\nfor 6521 individuals was generated. Our model, HIFIS-RNN-MLP, incorporates both\nstatic and dynamic features of a client's history to forecast chronic\nhomelessness 6 months into the client's future. The training method was\nfine-tuned to achieve a high F1-score, giving a desired balance between high\nrecall and precision. Mean recall and precision across 10-fold cross validation\nwere 0.921 and 0.651 respectively. An interpretability method was applied to\nexplain individual predictions and gain insight into the overall factors\ncontributing to chronic homelessness among the population studied. The model\nachieves state-of-the-art performance and improved stakeholder trust of what is\nusually a \"black box\" neural network model through interpretable AI.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 15:02:30 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["VanBerlo", "Blake", ""], ["Ross", "Matthew A. S.", ""], ["Rivard", "Jonathan", ""], ["Booker", "Ryan", ""]]}, {"id": "2009.09073", "submitter": "Yu Yol Shin", "authors": "Jungwoo Cho, Yuyol Shin, Seyun Kim, Namwoo Kim, Soohwan Oh, Haechan\n  Cho, Yoonjin Yoon", "title": "Running the COVID-19 marathon: the behavioral adaptations in mobility\n  and facemask over 27 weeks of pandemic in Seoul, South Korea", "comments": "22 pages of manuscript, 19 pages of supplementary information", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Battle with COVID-19 turned out to be a marathon, not a sprint, and\nbehavioral adjustments have been unavoidable to stay viable. In this paper, we\nemploy a data-centric approach to investigate individual mobility adaptations\nand mask-wearing in Seoul, South Korea. We first identify six epidemic phases\nand two waves based on COVID-19 case count and its geospatial dispersion. The\nphase-specific linear models reveal the strong, self-driven mobility reductions\nin the first escalation and peak with a common focus on public transit use and\nless-essential weekend/afternoon trips. However, comparable reduction was not\npresent in the second wave, as the shifted focus from mobility to mask-wearing\nwas evident. Although no lockdowns and gentle nudge to wear mask seemed\ncounter-intuitive, simple and persistent communication on personal safety has\nbeen effective and sustainable to induce cooperative behavioral adaptations.\nOur phase-specific analyses and interpretation highlight the importance of\ntargeted response consistent with the fluctuating epidemic risk.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 09:21:39 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Cho", "Jungwoo", ""], ["Shin", "Yuyol", ""], ["Kim", "Seyun", ""], ["Kim", "Namwoo", ""], ["Oh", "Soohwan", ""], ["Cho", "Haechan", ""], ["Yoon", "Yoonjin", ""]]}, {"id": "2009.09075", "submitter": "Juan Carlos Olivares Rojas", "authors": "Juan C. Olivares-Rojas, Enrique Reyes-Archundia, Jos\\'e A.\n  Guti\\'errez-Gnecchi, Ismael Molina-Moreno", "title": "A Survey on Smart Metering Systems using Blockchain for E-Mobility", "comments": "2020 IEEE 4th Electric Vehicle International Symposium", "journal-ref": null, "doi": null, "report-no": "Tecnol\\'ogico Nacional de M\\'exico grants 7948.20-P and 8000.20-P", "categories": "cs.CY cs.CR eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Electricity is an essential comfort to support our daily activities. With the\ncompetitive increase and energy costs by the industry, new values and\nopportunities for delivering electricity to customers are produced. One of\nthese new opportunities is electric vehicles. With the arrival of electric\nvehicles, various challenges and opportunities are being presented in the\nelectric power system worldwide. For example, under the traditional electric\npower billing scheme, electric power has to be consumed where it is needed so\nthat end-users could not charge their electric vehicles at different points\n(e.g. a relative's house) if this the correct user is not billed (this due to\nthe high consumption of electrical energy that makes it expensive). To achieve\nelectric mobility, they must solve new challenges, such as the smart metering\nof energy consumption and the cybersecurity of these measurements. The present\nwork shows a study of the different smart metering technologies that use\nblockchain and other security mechanisms to achieve e-mobility.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 22:55:25 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Olivares-Rojas", "Juan C.", ""], ["Reyes-Archundia", "Enrique", ""], ["Guti\u00e9rrez-Gnecchi", "Jos\u00e9 A.", ""], ["Molina-Moreno", "Ismael", ""]]}, {"id": "2009.09076", "submitter": "Anis Zaman", "authors": "Anis Zaman, Boyu Zhang, Ehsan Hoque, Vincent Silenzio, Henry Kautz", "title": "The Relationship between Deteriorating Mental Health Conditions and\n  Longitudinal Behavioral Changes in Google and YouTube Usages among College\n  Students in the United States during COVID-19: Observational Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mental health problems among the global population are worsened during the\ncoronavirus disease (COVID-19). How individuals engage with online platforms\nsuch as Google Search and YouTube undergoes drastic shifts due to pandemic and\nsubsequent lockdowns. Such ubiquitous daily behaviors on online platforms have\nthe potential to capture and correlate with clinically alarming deteriorations\nin mental health profiles in a non-invasive manner. The goal of this study is\nto examine, among college students, the relationship between deteriorating\nmental health conditions and changes in user behaviors when engaging with\nGoogle Search and YouTube during COVID-19. This study recruited a cohort of 49\nstudents from a U.S. college campus during January 2020 (prior to the pandemic)\nand measured the anxiety and depression levels of each participant. This study\nfollowed up with the same cohort during May 2020 (during the pandemic), and the\nanxiety and depression levels were assessed again. The longitudinal Google\nSearch and YouTube history data were anonymized and collected. From\nindividual-level Google Search and YouTube histories, we developed 5 signals\nthat can quantify shifts in online behaviors during the pandemic. We then\nassessed the differences between groups with and without deteriorating mental\nhealth profiles in terms of these features. Significant features included\nlate-night online activities, continuous usages, and time away from the\ninternet, porn consumptions, and keywords associated with negative emotions,\nsocial activities, and personal affairs. Though further studies are required,\nour results demonstrated the feasibility of utilizing pervasive online data to\nestablish non-invasive surveillance systems for mental health conditions that\nbypasses many disadvantages of existing screening methods.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 00:54:57 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Zaman", "Anis", ""], ["Zhang", "Boyu", ""], ["Hoque", "Ehsan", ""], ["Silenzio", "Vincent", ""], ["Kautz", "Henry", ""]]}, {"id": "2009.09078", "submitter": "Tharindu Bandaragoda", "authors": "Tharindu Bandaragoda", "title": "Beyond Social Media Analytics: Understanding Human Behaviour and Deep\n  Emotion using Self Structuring Incremental Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis develops a conceptual framework considering social data as\nrepresenting the surface layer of a hierarchy of human social behaviours, needs\nand cognition which is employed to transform social data into representations\nthat preserve social behaviours and their causalities. Based on this framework\ntwo platforms were built to capture insights from fast-paced and slow-paced\nsocial data. For fast-paced, a self-structuring and incremental learning\ntechnique was developed to automatically capture salient topics and\ncorresponding dynamics over time. An event detection technique was developed to\nautomatically monitor those identified topic pathways for significant\nfluctuations in social behaviours using multiple indicators such as volume and\nsentiment. This platform is demonstrated using two large datasets with over 1\nmillion tweets. The separated topic pathways were representative of the key\ntopics of each entity and coherent against topic coherence measures. Identified\nevents were validated against contemporary events reported in news. Secondly\nfor the slow-paced social data, a suite of new machine learning and natural\nlanguage processing techniques were developed to automatically capture\nself-disclosed information of the individuals such as demographics, emotions\nand timeline of personal events. This platform was trialled on a large text\ncorpus of over 4 million posts collected from online support groups. This was\nfurther extended to transform prostate cancer related online support group\ndiscussions into a multidimensional representation and investigated the\nself-disclosed quality of life of patients (and partners) against time,\ndemographics and clinical factors. The capabilities of this extended platform\nhave been demonstrated using a text corpus collected from 10 prostate cancer\nonline support groups comprising of 609,960 prostate cancer discussions and\n22,233 patients.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 14:53:26 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Bandaragoda", "Tharindu", ""]]}, {"id": "2009.09079", "submitter": "J. G. Wolff", "authors": "J Gerard Wolff", "title": "Problems in AI research and how the SP System may help to solve them", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes problems in AI research and how the SP System (described\nin an appendix) may help to solve them. Most of the problems are described by\nleading researchers in AI in interviews with science writer Martin Ford, and\nreported by him in his book {\\em Architects of Intelligence}. These problems\nare: the need to bridge the divide between symbolic and non-symbolic kinds of\nknowledge and processing; the tendency of deep neural networks (DNNs) to make\nlarge and unexpected errors in recognition; the need to strengthen the\nrepresentation and processing of natural languages; the challenges of\nunsupervised learning; the need for a coherent account of generalisation; how\nto learn usable knowledge from a single exposure; how to achieve transfer\nlearning; how to increase the efficiency of AI processing; the need for\ntransparency in AI structures and processes; how to achieve varieties of\nprobabilistic reasoning; the need for more emphasis on top-down strategies; how\nto minimise the risk of accidents with self-driving vehicles; the need for\nstrong compositionality in AI knowledge; the challenges of commonsense\nreasoning and commonsense knowledge; establishing the importance of information\ncompression in AI research; establishing the importance of a biological\nperspective in AI research; establishing whether knowledge in the brain is\nrepresented in `distributed' or `localist' form; how to bypassing the limited\nscope for adaptation in deep neural networks; the need to develop `broad AI';\nand how to eliminate the problem of catastrophic forgetting.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 11:33:07 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 17:38:50 GMT"}, {"version": "v3", "created": "Sun, 28 Feb 2021 16:30:22 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Wolff", "J Gerard", ""]]}, {"id": "2009.09080", "submitter": "Carole Adam", "authors": "Robin Couret and Carole Adam and Martial Mermillod", "title": "Modelling risk-taking behaviour of avalanche accident victims", "comments": "Research Master thesis - M2 Cognitive Sciences, PHELMA, Univ.\n  Grenoble-Alpes. 15 pages, 2 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Each year, over 15000 requests for mountain rescue are counted in France.\nAvalanche accidents represent 39\\% of reports, and are therefore our focus in\nthis study. Modelling the behaviour of mountain accident victims is useful to\ndevelop more accurate rescue and prevention tools. Concretely, we observe the\ninterference of two heuristics (availability and familiarity) in decision\nmaking when choosing an itinerary in backcountry skiing. We developed a serious\ngame to evaluate their effect on the probability of engaging in a risky\nitinerary, while varying situational and environmental criteria in each\nparticipant (N = 278). The availability heuristic is operationalized by three\nsituations, an avalanche accident video, a backcountry skiing video and a\nneutral context. The familiarity heuristic is operationalized by two criteria,\nstrong and weak familiarity with the place. Results demonstrate the effects of\nboth heuristics. Measurements through our serious game are discussed in the\nperspective of developing an interactive prevention tool for mitigating the\nnegative effects of heuristics.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 08:10:48 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Couret", "Robin", ""], ["Adam", "Carole", ""], ["Mermillod", "Martial", ""]]}, {"id": "2009.09082", "submitter": "Barbora Kozlikova", "authors": "Krist\\'ina Z\\'akop\\v{c}anov\\'a, Marko \\v{R}eh\\'a\\v{c}ek, Jozef\n  B\\'atrna, Daniel Plakinger, Sergej Stoppel, Barbora Kozl\\'ikov\\'a", "title": "Visilant: Visual Support for the Exploration and Analytical Process\n  Tracking in Criminal Investigations", "comments": "Accepted for the IEEE VIS 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The daily routine of criminal investigators consists of a thorough analysis\nof highly complex and heterogeneous data of crime cases. Such data can consist\nof case descriptions, testimonies, criminal networks, spatial and temporal\ninformation, and virtually any other data that is relevant for the case.\nCriminal investigators work under heavy time pressure to analyze the data for\nrelationships, propose and verify several hypotheses, and derive conclusions,\nwhile the data can be incomplete or inconsistent and is changed and updated\nthroughout the investigation, as new findings are added to the case. Based on a\nfour-year intense collaboration with criminalists, we present a conceptual\ndesign for a visual tool supporting the investigation workflow and Visilant, a\nweb-based tool for the exploration and analysis of criminal data guided by the\nproposed design. Visilant aims to support namely the exploratory part of the\ninvestigation pipeline, from case overview, through exploration and hypothesis\ngeneration, to the case presentation. Visilant tracks the reasoning process and\nas the data is changing, it informs investigators which hypotheses are affected\nby the data change and should be revised. The tool was evaluated by senior\ncriminology experts within two sessions and their feedback is summarized in the\npaper. Additional supplementary material contains the technical details and\nexemplary case study.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 09:24:20 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Z\u00e1kop\u010danov\u00e1", "Krist\u00edna", ""], ["\u0158eh\u00e1\u010dek", "Marko", ""], ["B\u00e1trna", "Jozef", ""], ["Plakinger", "Daniel", ""], ["Stoppel", "Sergej", ""], ["Kozl\u00edkov\u00e1", "Barbora", ""]]}, {"id": "2009.09083", "submitter": "Martin Molina", "authors": "Martin Molina", "title": "What is an intelligent system?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The concept of intelligent system has emerged in information technology as a\ntype of system derived from successful applications of artificial intelligence.\nThe goal of this paper is to give a general description of an intelligent\nsystem, which integrates previous approaches and takes into account recent\nadvances in artificial intelligence. The paper describes an intelligent system\nin a generic way, identifying its main properties and functional components,\nand presents some common categories. The presented description follows a\npractical approach to be used by system engineers. Its generality and its use\nis illustrated with real-world system examples and related with artificial\nintelligence methods.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 21:23:49 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Molina", "Martin", ""]]}, {"id": "2009.09084", "submitter": "Irene Y. Chen", "authors": "Irene Y. Chen, Emily Alsentzer, Hyesun Park, Richard Thomas, Babina\n  Gosangi, Rahul Gujrathi, Bharti Khurana", "title": "Intimate Partner Violence and Injury Prediction From Radiology Reports", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Intimate partner violence (IPV) is an urgent, prevalent, and under-detected\npublic health issue. We present machine learning models to assess patients for\nIPV and injury. We train the predictive algorithms on radiology reports with 1)\nIPV labels based on entry to a violence prevention program and 2) injury labels\nprovided by emergency radiology fellowship-trained physicians. Our dataset\nincludes 34,642 radiology reports and 1479 patients of IPV victims and control\npatients. Our best model predicts IPV a median of 3.08 years before violence\nprevention program entry with a sensitivity of 64% and a specificity of 95%. We\nconduct error analysis to determine for which patients our model has especially\nhigh or low performance and discuss next steps for a deployed clinical risk\nmodel.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 17:20:37 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 16:26:58 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Chen", "Irene Y.", ""], ["Alsentzer", "Emily", ""], ["Park", "Hyesun", ""], ["Thomas", "Richard", ""], ["Gosangi", "Babina", ""], ["Gujrathi", "Rahul", ""], ["Khurana", "Bharti", ""]]}, {"id": "2009.09086", "submitter": "Maulik Kamdar", "authors": "Maulik R. Kamdar, Michael Carroll, Will Dowling, Linda Wogulis, Cailey\n  Fitzgerald, Matt Corkum, Danielle Walsh, David Conrad, Craig E. Stanley, Jr.,\n  Steve Ross, Dru Henke, Mevan Samarasinghe", "title": "Focused Clinical Query Understanding and Retrieval of Medical Snippets\n  powered through a Healthcare Knowledge Graph", "comments": "Under Review as a Podium Talk at the AMIA Informatics Summit 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Clinicians face several significant barriers to search and synthesize\naccurate, succinct, updated, and trustworthy medical information from several\nliterature sources during the practice of medicine and patient care. In this\ntalk, we will be presenting our research behind the development of a Focused\nClinical Search Service, powered by a Healthcare Knowledge Graph, to interpret\nthe query intent behind clinical search queries and retrieve relevant medical\nsnippets from a diverse corpus of medical literature.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 14:18:38 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Kamdar", "Maulik R.", ""], ["Carroll", "Michael", ""], ["Dowling", "Will", ""], ["Wogulis", "Linda", ""], ["Fitzgerald", "Cailey", ""], ["Corkum", "Matt", ""], ["Walsh", "Danielle", ""], ["Conrad", "David", ""], ["Stanley,", "Craig E.", "Jr."], ["Ross", "Steve", ""], ["Henke", "Dru", ""], ["Samarasinghe", "Mevan", ""]]}, {"id": "2009.09087", "submitter": "Joshua Vendrow", "authors": "Joshua Vendrow, Jamie Haddock, Deanna Needell, and Lorraine Johnson", "title": "Feature Selection on Lyme Disease Patient Survey Data", "comments": "9 pages, 8 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lyme disease is a rapidly growing illness that remains poorly understood\nwithin the medical community. Critical questions about when and why patients\nrespond to treatment or stay ill, what kinds of treatments are effective, and\neven how to properly diagnose the disease remain largely unanswered. We\ninvestigate these questions by applying machine learning techniques to a large\nscale Lyme disease patient registry, MyLymeData, developed by the nonprofit\nLymeDisease.org. We apply various machine learning methods in order to measure\nthe effect of individual features in predicting participants' answers to the\nGlobal Rating of Change (GROC) survey questions that assess the self-reported\ndegree to which their condition improved, worsened, or remained unchanged\nfollowing antibiotic treatment. We use basic linear regression, support vector\nmachines, neural networks, entropy-based decision tree models, and $k$-nearest\nneighbors approaches. We first analyze the general performance of the model and\nthen identify the most important features for predicting participant answers to\nGROC. After we identify the \"key\" features, we separate them from the dataset\nand demonstrate the effectiveness of these features at identifying GROC. In\ndoing so, we highlight possible directions for future study both mathematically\nand clinically.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 22:35:39 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Vendrow", "Joshua", ""], ["Haddock", "Jamie", ""], ["Needell", "Deanna", ""], ["Johnson", "Lorraine", ""]]}, {"id": "2009.09088", "submitter": "Rudresh Mishra", "authors": "Rudresh Mishra, Ricardo Rodriguez, Valentin Portillo", "title": "An AI based talent acquisition and benchmarking for job", "comments": "26 pages , 23 figures, This paper is yet to publish in conferences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In a recruitment industry, selecting a best CV from a particular job post\nwithin a pile of thousand CV's is quite challenging. Finding a perfect\ncandidate for an organization who can be fit to work within organizational\nculture is a difficult task. In order to help the recruiters to fill these gaps\nwe leverage the help of AI. We propose a methodology to solve these problems by\nmatching the skill graph generated from CV and Job Post. In this report our\napproach is to perform the business understanding in order to justify why such\nproblems arise and how we intend to solve these problems using natural language\nprocessing and machine learning techniques. We limit our project only to solve\nthe problem in the domain of the computer science industry.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 15:57:54 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Mishra", "Rudresh", ""], ["Rodriguez", "Ricardo", ""], ["Portillo", "Valentin", ""]]}, {"id": "2009.09102", "submitter": "Seung Ah Choi", "authors": "Seung Ah Choi", "title": "Amazon Fake Reviews", "comments": "23 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Often, there are suspicious Amazon reviews that seem to be excessively\npositive or have been created through a repeating algorithm. I moved to detect\nfake reviews on Amazon through semantic analysis in conjunction with meta data\nsuch as time, word choice, and the user who posted. I first came up with\nseveral instances that may indicate a review isn't genuine and constructed what\nthe algorithm would look like. Then I coded the algorithm and tested the\naccuracy of it using statistical analysis and analyzed it based on the six\nqualities of code.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 21:59:12 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Choi", "Seung Ah", ""]]}, {"id": "2009.09210", "submitter": "Jason R.C. Nurse Dr", "authors": "Richard Knight and Jason R. C. Nurse", "title": "A framework for effective corporate communication after cyber security\n  incidents", "comments": null, "journal-ref": "Computers & Security, Volume 99, December 2020", "doi": "10.1016/j.cose.2020.102036", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major cyber security incident can represent a cyber crisis for an\norganisation, in particular because of the associated risk of substantial\nreputational damage. As the likelihood of falling victim to a cyberattack has\nincreased over time, so too has the need to understand exactly what is\neffective corporate communication after an attack, and how best to engage the\nconcerns of customers, partners and other stakeholders. This research seeks to\ntackle this problem through a critical, multi-faceted investigation into the\nefficacy of crisis communication and public relations following a data breach.\nIt does so by drawing on academic literature, obtained through a systematic\nliterature review, and real-world case studies. Qualitative data analysis is\nused to interpret and structure the results, allowing for the development of a\nnew, comprehensive framework for corporate communication to support companies\nin their preparation and response to such events. The validity of this\nframework is demonstrated by its evaluation through interviews with senior\nindustry professionals, as well as a critical assessment against relevant\npractice and research. The framework is further refined based on these\nevaluations, and an updated version defined. This research represents the first\ngrounded, comprehensive and evaluated proposal for characterising effective\ncorporate communication after cyber security incidents.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 11:08:53 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Knight", "Richard", ""], ["Nurse", "Jason R. C.", ""]]}, {"id": "2009.09218", "submitter": "Emmanouil Koulas", "authors": "Emmanouil Koulas, Marios Anthopoulos, Sotiria Grammenou, Christos\n  Kaimakamis, Konstantinos Kousaris, Fotini-Rafailia Panavou, Orestis\n  Piskioulis, Syed Iftikhar H. Shah and Vasilios Peristeras", "title": "Misinformation and its stakeholders in Europe: a web-based analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of the internet and computational power in recent years allowed for\nthe exponential growth of misinformation phenomena. An issue that was a\nnon-issue a decade ago, became a challenge for societal cohesion. The emergence\nof this new threat has led many stakeholders, especially in Europe, to act in\norder to tackle this phenomenon. This paper provides in its first part a\nliterature review on misinformation in Europe, and in its second part a\nwebometrics analysis on the identified key stakeholders. In the results we\ndiscuss who those stakeholders are, what actions do they perform to limit\nmisinformation and whether those actions have an impact.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 12:24:53 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 22:07:08 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Koulas", "Emmanouil", ""], ["Anthopoulos", "Marios", ""], ["Grammenou", "Sotiria", ""], ["Kaimakamis", "Christos", ""], ["Kousaris", "Konstantinos", ""], ["Panavou", "Fotini-Rafailia", ""], ["Piskioulis", "Orestis", ""], ["Shah", "Syed Iftikhar H.", ""], ["Peristeras", "Vasilios", ""]]}, {"id": "2009.09295", "submitter": "Jack Horner", "authors": "Jack K. Horner and John F. Symons", "title": "Software Engineering Standards for Epidemiological Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many normative and technical questions involved in evaluating the\nquality of software used in epidemiological simulations. In this paper we\nanswer some of these questions and offer practical guidance to practitioners,\nfunders, scientific journals, and consumers of epidemiological research. The\nheart of our paper is a case study of the Imperial College London (ICL)\nCOVID-19 simulator. We contend that epidemiological simulators should be\nengineered and evaluated within the framework of safety-critical standards\ndeveloped by the consensus of the software engineering community for\napplications such as automotive and aircraft control.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 20:43:39 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Horner", "Jack K.", ""], ["Symons", "John F.", ""]]}, {"id": "2009.09326", "submitter": "Nicolas Araque", "authors": "Nicolas Araque, Germano Rojas, Maria Vitali", "title": "UniNet: Next Term Course Recommendation using Deep Learning", "comments": null, "journal-ref": null, "doi": "10.1109/ICACSIS51025.2020.9263144", "report-no": null, "categories": "cs.CY cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Course enrollment recommendation is a relevant task that helps university\nstudents decide what is the best combination of courses to enroll in the next\nterm. In particular, recommender system techniques like matrix factorization\nand collaborative filtering have been developed to try to solve this problem.\nAs these techniques fail to represent the time-dependent nature of academic\nperformance datasets we propose a deep learning approach using recurrent neural\nnetworks that aims to better represent how chronological order of course grades\naffects the probability of success. We have shown that it is possible to obtain\na performance of 81.10% on AUC metric using only grade information and that it\nis possible to develop a recommender system with academic student performance\nprediction. This is shown to be meaningful across different student GPA levels\nand course difficulties\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 00:07:45 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Araque", "Nicolas", ""], ["Rojas", "Germano", ""], ["Vitali", "Maria", ""]]}, {"id": "2009.09367", "submitter": "Huthaifa I. Ashqar", "authors": "Huthaifa I. Ashqar, Mohammed Elhenawy, Hesham A. Rakha, Mohammed\n  Almannaa, and Leanna House", "title": "Network and Station-Level Bike-Sharing System Prediction: A San\n  Francisco Bay Area Case Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper develops models for modeling the availability of bikes in the San\nFrancisco Bay Area Bike Share System applying machine learning at two levels:\nnetwork and station. Investigating BSSs at the station-level is the full\nproblem that would provide policymakers, planners, and operators with the\nneeded level of details to make important choices and conclusions. We used\nRandom Forest and Least-Squares Boosting as univariate regression algorithms to\nmodel the number of available bikes at the station-level. For the multivariate\nregression, we applied Partial Least-Squares Regression (PLSR) to reduce the\nneeded prediction models and reproduce the spatiotemporal interactions in\ndifferent stations in the system at the network-level. Although prediction\nerrors were slightly lower in the case of univariate models, we found that the\nmultivariate model results were promising for the network-level prediction,\nespecially in systems where there is a relatively large number of stations that\nare spatially correlated. Moreover, results of the station-level analysis\nsuggested that demographic information and other environmental variables were\nsignificant factors to model bikes in BSSs. We also demonstrated that the\navailable bikes modeled at the station-level at time t had a notable influence\non the bike count models. Station neighbors and prediction horizon times were\nfound to be significant predictors, with 15 minutes being the most effective\nprediction horizon time.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 06:46:41 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Ashqar", "Huthaifa I.", ""], ["Elhenawy", "Mohammed", ""], ["Rakha", "Hesham A.", ""], ["Almannaa", "Mohammed", ""], ["House", "Leanna", ""]]}, {"id": "2009.09435", "submitter": "Francisco Vargas", "authors": "Francisco Vargas and Ryan Cotterell", "title": "Exploring the Linear Subspace Hypothesis in Gender Bias Mitigation", "comments": null, "journal-ref": "Proceedings of the 2020 Conference on Empirical Methods in Natural\n  Language Processing", "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bolukbasi et al. (2016) presents one of the first gender bias mitigation\ntechniques for word embeddings. Their method takes pre-trained word embeddings\nas input and attempts to isolate a linear subspace that captures most of the\ngender bias in the embeddings. As judged by an analogical evaluation task,\ntheir method virtually eliminates gender bias in the embeddings. However, an\nimplicit and untested assumption of their method is that the bias sub-space is\nactually linear. In this work, we generalize their method to a kernelized,\nnon-linear version. We take inspiration from kernel principal component\nanalysis and derive a non-linear bias isolation technique. We discuss and\novercome some of the practical drawbacks of our method for non-linear gender\nbias mitigation in word embeddings and analyze empirically whether the bias\nsubspace is actually linear. Our analysis shows that gender bias is in fact\nwell captured by a linear subspace, justifying the assumption of Bolukbasi et\nal. (2016).\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 14:13:45 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 12:11:40 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Vargas", "Francisco", ""], ["Cotterell", "Ryan", ""]]}, {"id": "2009.09609", "submitter": "Shamik Roy", "authors": "Shamik Roy, Dan Goldwasser", "title": "Weakly Supervised Learning of Nuanced Frames for Analyzing Polarization\n  in News Media", "comments": "19 pages, 6 figures, Will appear in EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we suggest a minimally-supervised approach for identifying\nnuanced frames in news article coverage of politically divisive topics. We\nsuggest to break the broad policy frames suggested by Boydstun et al., 2014\ninto fine-grained subframes which can capture differences in political ideology\nin a better way. We evaluate the suggested subframes and their embedding,\nlearned using minimal supervision, over three topics, namely, immigration,\ngun-control and abortion. We demonstrate the ability of the subframes to\ncapture ideological differences and analyze political discourse in news media.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 04:29:54 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Roy", "Shamik", ""], ["Goldwasser", "Dan", ""]]}, {"id": "2009.09659", "submitter": "D\\'aniel Kondor", "authors": "Iva Bojic, D\\'aniel Kondor, Wei Tu, Ke Mai, Paolo Santi, Carlo Ratti", "title": "Identifying synergies in private and public transportation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore existing synergies between private and public\ntransportation as provided by taxi and bus services on the level of individual\ntrips. While these modes are typically separated for economic reasons, in a\nfuture with shared Autonomous Vehicles (AVs) providing cheap and efficient\ntransportation services, such distinctions will blur. Consequently,\noptimization based on real-time data will allow exploiting parallels in demand\nin a dynamic way, such as the proposed approach of the current work. New\noperational and pricing strategies will then evolve, providing service in a\nmore efficient way and utilizing a dynamic landscape of urban transportation.\nIn the current work, we evaluate existing parallels between individual bus and\ntaxi trips in two Asian cities and show how exploiting these synergies could\nlead to an increase in transportation service quality.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 07:53:40 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Bojic", "Iva", ""], ["Kondor", "D\u00e1niel", ""], ["Tu", "Wei", ""], ["Mai", "Ke", ""], ["Santi", "Paolo", ""], ["Ratti", "Carlo", ""]]}, {"id": "2009.09795", "submitter": "Dinh An Ho", "authors": "Dinh-An Ho and Oya Beyan", "title": "Biases in Data Science Lifecycle", "comments": "22 pages, 1 Figure, 1 Table arXiv admin note: text overlap with\n  arXiv:1901.10002, arXiv:1810.01943 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In recent years, data science has become an indispensable part of our\nsociety. Over time, we have become reliant on this technology because of its\nopportunity to gain value and new insights from data in any field - business,\nsocializing, research and society. At the same time, it raises questions about\nhow justified we are in placing our trust in these technologies. There is a\nrisk that such powers may lead to biased, inappropriate or unintended actions.\nTherefore, ethical considerations which might occur as the result of data\nscience practices should be carefully considered and these potential problems\nshould be identified during the data science lifecycle and mitigated if\npossible. However, a typical data scientist has not enough knowledge for\nidentifying these challenges and it is not always possible to include an ethics\nexpert during data science production. The aim of this study is to provide a\npractical guideline to data scientists and increase their awareness. In this\nwork, we reviewed different sources of biases and grouped them under different\nstages of the data science lifecycle. The work is still under progress. The aim\nof early publishing is to collect community feedback and improve the curated\nknowledge base for bias types and solutions.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 13:41:48 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 12:31:24 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Ho", "Dinh-An", ""], ["Beyan", "Oya", ""]]}, {"id": "2009.09837", "submitter": "Balagopal Ramdurai", "authors": "Balagopal Ramdurai", "title": "Detailed Review of Cloud based Mobile application for the stroke patient", "comments": "7 pages with review of existing studies, how telemedicine can help\n  stroke patients and reduce fatality", "journal-ref": "International Journal of Computer Trends and Technology\n  (IJCTT)2020", "doi": "10.14445/22312803", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the current years, due to the significant developments in technologies in\nalmost every domain, the standard of living has been improved. Emergence of\nlatest innovations, advanced machinery and equipment especially in the\nhealthcare domain, have simplified the diagonalizing process to a wide extent.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 13:22:42 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Ramdurai", "Balagopal", ""]]}, {"id": "2009.09914", "submitter": "Talayeh Aledavood", "authors": "Talayeh Aledavood, Ilkka Kivim\\\"aki, Sune Lehmann, and Jari Saram\\\"aki", "title": "A Non-negative Matrix Factorization Based Method for Quantifying Rhythms\n  of Activity and Sleep and Chronotypes Using Mobile Phone Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human activities follow daily, weekly, and seasonal rhythms. The emergence of\nthese rhythms is related to physiology and natural cycles as well as social\nconstructs. The human body and biological functions undergo near 24-hour\nrhythms (circadian rhythms). The frequency of these rhythms is more or less\nsimilar across people, but its phase is different. In the chronobiology\nliterature, based on the propensity to sleep at different hours of the day,\npeople are categorized into morning-type, evening-type, and intermediate-type\ngroups called \\textit{chronotypes}. This typology is typically based on\ncarefully designed questionnaires or manually crafted features drawing on data\non timings of people's activity. Here we develop a fully data-driven\n(unsupervised) method to decompose individual temporal activity patterns into\ncomponents. This has the advantage of not including any predetermined\nassumptions about sleep and activity hours, but the results are fully\ncontext-dependent and determined by the most prominent features of the activity\ndata. Using a year-long dataset from mobile phone screen usage logs of 400\npeople, we find four emergent temporal components: morning activity, night\nactivity, evening activity and activity at noon. Individual behavior can be\nreduced to weights on these four components. We do not observe any clear\nemergent categories of people based on the weights, but individuals are rather\nplaced on a continuous spectrum according to the timings of their activities.\nHigh loads on morning and night components highly correlate with going to bed\nand waking up times. Our work points towards a data-driven way of categorizing\npeople based on their full daily and weekly rhythms of activity and behavior,\nrather than focusing mainly on the timing of their sleeping periods.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 14:33:30 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Aledavood", "Talayeh", ""], ["Kivim\u00e4ki", "Ilkka", ""], ["Lehmann", "Sune", ""], ["Saram\u00e4ki", "Jari", ""]]}, {"id": "2009.09936", "submitter": "Michela Paganini", "authors": "Michela Paganini", "title": "Prune Responsibly", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Irrespective of the specific definition of fairness in a machine learning\napplication, pruning the underlying model affects it. We investigate and\ndocument the emergence and exacerbation of undesirable per-class performance\nimbalances, across tasks and architectures, for almost one million categories\nconsidered across over 100K image classification models that undergo a pruning\nprocess.We demonstrate the need for transparent reporting, inclusive of bias,\nfairness, and inclusion metrics, in real-life engineering decision-making\naround neural network pruning. In response to the calls for quantitative\nevaluation of AI models to be population-aware, we present neural network\npruning as a tangible application domain where the ways in which\naccuracy-efficiency trade-offs disproportionately affect underrepresented or\noutlier groups have historically been overlooked. We provide a simple,\nPareto-based framework to insert fairness considerations into value-based\noperating point selection processes, and to re-evaluate pruning technique\nchoices.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 04:43:11 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Paganini", "Michela", ""]]}, {"id": "2009.09987", "submitter": "Niloofar Bayat", "authors": "Niloofar Bayat, Cody Morrin, Yuheng Wang, Vishal Misra", "title": "Synthetic Control, Synthetic Interventions, and COVID-19 spread:\n  Exploring the impact of lockdown measures and herd immunity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The synthetic control method is an empirical methodology forcausal inference\nusing observational data. By observing thespread of COVID-19 throughout the\nworld, we analyze the dataon the number of deaths and cases in different\nregions usingthe power of prediction, counterfactual analysis, and\nsyntheticinterventions of the synthetic control and its extensions. Weobserve\nthat the number of deaths and cases in different re-gions would have been much\nsmaller had the lockdowns beenimposed earlier and had the re-openings been done\nlater, es-pecially among indoor bars and restaurants. We also analyzethe\nspeculated impact of herd immunity on the spread giventhe population of each\nregion and show that lockdown policieshave a very strong impact on the spread\nregardless of the levelof prior infections.\n  Our most up-to-date code, model, and data can be foundon github:\nhttps://github.com/niloofarbayat/COVID19-synthetic-control-analysis\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 16:12:52 GMT"}, {"version": "v2", "created": "Sat, 26 Sep 2020 18:15:54 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Bayat", "Niloofar", ""], ["Morrin", "Cody", ""], ["Wang", "Yuheng", ""], ["Misra", "Vishal", ""]]}, {"id": "2009.10050", "submitter": "Alan Lundgard", "authors": "Alan Lundgard", "title": "Measuring justice in machine learning", "comments": "Presented at the ACM Conference on Fairness, Accountability, and\n  Transparency (30 January 2020) and at the ACM SIGACCESS Conference on\n  Computers and Accessibility: Workshop on AI Fairness for People with\n  Disabilities (27 October 2019). Version v2: typos and formatting corrected", "journal-ref": null, "doi": "10.1145/3351095.3372838", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we build more just machine learning systems? To answer this question,\nwe need to know both what justice is and how to tell whether one system is more\nor less just than another. That is, we need both a definition and a measure of\njustice. Theories of distributive justice hold that justice can be measured (in\npart) in terms of the fair distribution of benefits and burdens across people\nin society. Recently, the field known as fair machine learning has turned to\nJohn Rawls's theory of distributive justice for inspiration and\noperationalization. However, philosophers known as capability theorists have\nlong argued that Rawls's theory uses the wrong measure of justice, thereby\nencoding biases against people with disabilities. If these theorists are right,\nis it possible to operationalize Rawls's theory in machine learning systems\nwithout also encoding its biases? In this paper, I draw on examples from fair\nmachine learning to suggest that the answer to this question is no: the\ncapability theorists' arguments against Rawls's theory carry over into machine\nlearning systems. But capability theorists don't only argue that Rawls's theory\nuses the wrong measure, they also offer an alternative measure. Which measure\nof justice is right? And has fair machine learning been using the wrong one?\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 17:46:11 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 16:52:42 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Lundgard", "Alan", ""]]}, {"id": "2009.10158", "submitter": "Lynsay Shepherd", "authors": "Jamie O'Hare and Lynsay A. Shepherd", "title": "Proposal of a Novel Bug Bounty Implementation Using Gamification", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite significant popularity, the bug bounty process has remained broadly\nunchanged since its inception, with limited implementation of gamification\naspects. Existing literature recognises that current methods generate intensive\nresource demands, and can encounter issues impacting program effectiveness.\nThis paper proposes a novel bug bounty process aiming to alleviate resource\ndemands and mitigate inherent issues. Through the additional crowdsourcing of\nreport verification where fellow hackers perform vulnerability verification and\nreproduction, the client organisation can reduce overheads at the cost of\nrewarding more participants. The incorporation of gamification elements\nprovides a substitute for monetary rewards, as well as presenting possible\nmitigation of bug bounty program effectiveness issues. Collectively, traits of\nthe proposed process appear appropriate for resource and budget-constrained\norganisations - such Higher Education institutions.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 20:11:53 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["O'Hare", "Jamie", ""], ["Shepherd", "Lynsay A.", ""]]}, {"id": "2009.10194", "submitter": "Colin M. Gray", "authors": "Colin M. Gray, Cristiana Santos, Nataliia Bielova, Michael Toth,\n  Damian Clifford", "title": "Dark Patterns and the Legal Requirements of Consent Banners: An\n  Interaction Criticism Perspective", "comments": "18 pages", "journal-ref": "Proceedings of the 2021 CHI Conference on Human Factors in\n  Computing Systems", "doi": "10.1145/3411764.3445779", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  User engagement with data privacy and security through consent banners has\nbecome a ubiquitous part of interacting with internet services. While previous\nwork has addressed consent banners from either interaction design, legal, and\nethics-focused perspectives, little research addresses the connections among\nmultiple disciplinary approaches, including tensions and opportunities that\ntranscend disciplinary boundaries. In this paper, we draw together perspectives\nand commentary from HCI, design, privacy and data protection, and legal\nresearch communities, using the language and strategies of \"dark patterns\" to\nperform an interaction criticism reading of three different types of consent\nbanners. Our analysis builds upon designer, interface, user, and social context\nlenses to raise tensions and synergies that arise together in complex,\ncontingent, and conflicting ways in the act of designing consent banners. We\nconclude with opportunities for transdisciplinary dialogue across legal,\nethical, computer science, and interactive systems scholarship to translate\nmatters of ethical concern into public policy.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 22:00:51 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 12:06:19 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Gray", "Colin M.", ""], ["Santos", "Cristiana", ""], ["Bielova", "Nataliia", ""], ["Toth", "Michael", ""], ["Clifford", "Damian", ""]]}, {"id": "2009.10228", "submitter": "Jessica Van Brummelen", "authors": "Xiaofei Zhou and Jessica Van Brummelen and Phoebe Lin", "title": "Designing AI Learning Experiences for K-12: Emerging Works, Future\n  Opportunities and a Design Framework", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) literacy is a rapidly growing research area and\na critical addition to K-12 education. However, support for designing tools and\ncurriculum to teach K-12 AI literacy is still limited. There is a need for\nadditional interdisciplinary human-computer interaction and education research\ninvestigating (1) how general AI literacy is currently implemented in learning\nexperiences and (2) what additional guidelines are required to teach AI\nliteracy in specifically K-12 learning contexts. In this paper, we analyze a\ncollection of K-12 AI and education literature to show how core competencies of\nAI literacy are applied successfully and organize them into an\neducator-friendly chart to enable educators to efficiently find appropriate\nresources for their classrooms. We also identify future opportunities and K-12\nspecific design guidelines, which we synthesized into a conceptual framework to\nsupport researchers, designers, and educators in creating K-12 AI learning\nexperiences.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:08:04 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Zhou", "Xiaofei", ""], ["Van Brummelen", "Jessica", ""], ["Lin", "Phoebe", ""]]}, {"id": "2009.10263", "submitter": "Juan Manuel Carrillo Garcia", "authors": "Juan Carrillo, Daniel Garijo, Mark Crowley, Rober Carrillo, Yolanda\n  Gil, Katherine Borda", "title": "Semantic Workflows and Machine Learning for the Assessment of Carbon\n  Storage by Urban Trees", "comments": "Previously published as part of the SciKnow 2019 Workshop, November\n  19th, 2019. Los Angeles, California, USA. Collocated with the tenth\n  International Conference on Knowledge Capture (K-CAP)", "journal-ref": "Proceedings of the Third International Workshop on Capturing\n  Scientific Knowledge co-located with the 10th International Conference on\n  Knowledge Capture (K-CAP 2019)", "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.CY eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Climate science is critical for understanding both the causes and\nconsequences of changes in global temperatures and has become imperative for\ndecisive policy-making. However, climate science studies commonly require\naddressing complex interoperability issues between data, software, and\nexperimental approaches from multiple fields. Scientific workflow systems\nprovide unparalleled advantages to address these issues, including\nreproducibility of experiments, provenance capture, software reusability and\nknowledge sharing. In this paper, we introduce a novel workflow with a series\nof connected components to perform spatial data preparation, classification of\nsatellite imagery with machine learning algorithms, and assessment of carbon\nstored by urban trees. To the best of our knowledge, this is the first study\nthat estimates carbon storage for a region in Africa following the guidelines\nfrom the Intergovernmental Panel on Climate Change (IPCC).\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 01:30:29 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Carrillo", "Juan", ""], ["Garijo", "Daniel", ""], ["Crowley", "Mark", ""], ["Carrillo", "Rober", ""], ["Gil", "Yolanda", ""], ["Borda", "Katherine", ""]]}, {"id": "2009.10278", "submitter": "Kovila  P.L. Coopamootoo", "authors": "Kovila P.L. Coopamootoo", "title": "Usage Patterns of Privacy-Enhancing Technologies", "comments": "To be published in the Proceedings of the 2020 ACM SIGSAC Conference\n  on Computer and Communications Security (CCS '20)", "journal-ref": null, "doi": "10.1145/3372297.3423347", "report-no": null, "categories": "cs.CY cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The steady reports of privacy invasions online paints a picture of the\nInternet growing into a more dangerous place. This is supported by reports of\nthe potential scale for online harms facilitated by the mass deployment of\nonline technology and the data-intensive web. While Internet users often\nexpress concern about privacy, some report taking actions to protect their\nprivacy online. We investigate the methods and technologies that individuals\nemploy to protect their privacy online. We conduct two studies, of N=180 and\nN=907, to elicit individuals' use of privacy methods online, within the US, the\nUK and Germany. We find that non-technology methods are among the most used\nmethods in the three countries. We identify distinct groupings of privacy\nmethods usage in a cluster map. The map shows that together with non-technology\nmethods of privacy protection, simple PETs that are integrated in services,\nform the most used cluster, whereas more advanced PETs form a different, least\nused cluster. We further investigate user perception and reasoning for mostly\nusing one set of PETs in a third study with N=183 participants. We do not find\na difference in perceived competency in protecting privacy online between\nadvanced and simpler PETs users. We compare use perceptions between advanced\nand simpler PETs and report on user reasoning for not using advanced PETs, as\nwell as support needed for potential use. This paper contributes to privacy\nresearch by eliciting use and perception of use across $43$ privacy methods,\nincluding $26$ PETs across three countries and provides a map of PETs usage.\nThe cluster map provides a systematic and reliable point of reference for\nfuture user-centric investigations across PETs. Overall, this research provides\na broad understanding of use and perceptions across a collection of PETs, and\ncan lead to future research for scaling use of PETs.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 02:17:37 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Coopamootoo", "Kovila P. L.", ""]]}, {"id": "2009.10317", "submitter": "Sirat Samyoun", "authors": "Sirat Samyoun, Sudipta Saha Shubha, Md Abu Sayeed Mondol, John A.\n  Stankovic", "title": "iWash: A Smartwatch Handwashing Quality Assessment and Reminder System\n  with Real-time Feedback in the Context of Infectious Disease", "comments": "19 pages, submitted in the Fifth IEEE/ACM Conference on Connected\n  Health: Applications, Systems and Engineering Technologies (CHASE 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Washing hands properly and frequently is the simplest and most cost-effective\ninterventions to prevent the spread of infectious diseases. People are often\nignorant about proper handwashing in different situations and do not know if\nthey wash hands properly. Smartwatches are found to be effective for assessing\nthe quality of handwashing. However, the existing smartwatch based systems are\nnot comprehensive enough in terms of achieving accuracy as well as reminding\npeople to handwash and providing feedback to the user about the quality of\nhandwashing. On-device processing is often required to provide real-time\nfeedback to the user, and so it is important to develop a system that runs\nefficiently on low-resource devices like smartwatches. However, none of the\nexisting systems for handwashing quality assessment are optimized for on-device\nprocessing. We present iWash, a comprehensive system for quality assessment and\ncontext-aware reminder for handwashing with real-time feedback using\nsmartwatches. iWash is a hybrid deep neural network based system that is\noptimized for on-device processing to ensure high accuracy with minimal\nprocessing time and battery usage. Additionally, it is a context-aware system\nthat detects when the user is entering home using a Bluetooth beacon and\nprovides reminders to wash hands. iWash also offers touch-free interaction\nbetween the user and the smartwatch that minimizes the risk of germ\ntransmission. We collected a real-life dataset and conducted extensive\nevaluations to demonstrate the performance of iWash. Compared to the existing\nhandwashing quality assessment systems, we achieve around 12% higher accuracy\nfor quality assessment, as well as we reduce the processing time and battery\nusage by around 37% and 10%, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 04:52:35 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Samyoun", "Sirat", ""], ["Shubha", "Sudipta Saha", ""], ["Mondol", "Md Abu Sayeed", ""], ["Stankovic", "John A.", ""]]}, {"id": "2009.10385", "submitter": "Juan Mateos-Garcia", "authors": "Joel Klinger, Juan Mateos-Garcia and Konstantinos Stathoulopoulos", "title": "A narrowing of AI research?", "comments": "Third version: Includes updated link to GitHub repo, updates in the\n  organisational level analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) is being hailed as the latest example of a\nGeneral Purpose Technology that could transform productivity and help tackle\nimportant societal challenges. This outcome is however not guaranteed: a myopic\nfocus on short-term benefits could lock AI into technologies that turn out to\nbe sub-optimal in the longer-run. Recent controversies about the dominance of\ndeep learning methods and private labs in AI research suggest that the field\nmay be getting narrower, but the evidence base is lacking. We seek to address\nthis gap with an analysis of the thematic diversity of AI research in arXiv, a\nwidely used pre-prints site. Having identified 110,000 AI papers in this\ncorpus, we use hierarchical topic modelling to estimate the thematic\ncomposition of AI research, and this composition to calculate various metrics\nof research diversity. Our analysis suggests that diversity in AI research has\nstagnated in recent years, and that AI research involving private sector\norganisations tends to be less diverse than research in academia. This appears\nto be driven by a small number of prolific and narrowly-focused technology\ncompanies. Diversity in academia is bolstered by smaller institutions and\nresearch groups that may have less incentives to race and lower levels of\ncollaboration with the private sector. We also find that private sector AI\nresearchers tend to specialise in data and computationally intensive deep\nlearning methods at the expense of research involving other (symbolic and\nstatistical) AI methods, and of research that considers the societal and\nethical implications of AI or applies it in domains like health. Our results\nsuggest that there may be a rationale for policy action to prevent a premature\nnarrowing of AI research that could reduce its societal benefits, but we note\nthe incentive, information and scale hurdles standing in the way of such\ninterventions.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 08:23:56 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 16:22:31 GMT"}, {"version": "v3", "created": "Tue, 17 Nov 2020 14:59:09 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Klinger", "Joel", ""], ["Mateos-Garcia", "Juan", ""], ["Stathoulopoulos", "Konstantinos", ""]]}, {"id": "2009.10461", "submitter": "Alec Kirkley", "authors": "Shihui Feng and Alec Kirkley", "title": "Online geolocalized emotion across US cities during the COVID crisis:\n  Universality, policy response, and connection with local mobility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the COVID-19 pandemic began to sweep across the US it elicited a wide\nspectrum of responses, both online and offline, across the population. To aid\nthe development of effective spatially targeted interventions in the midst of\nthis turmoil, it is important to understand the geolocalization of these online\nemotional responses, as well as their association with offline behavioral\nresponses. Here, we analyze around 13 million geotagged tweets in 49 cities\nacross the US from the first few months of the pandemic to assess regional\ndependence in online sentiments with respect to a few major topics, and how\nthese sentiments correlate with policy development and human mobility.\nSurprisingly, we observe universal trends in overall and topic-based sentiments\nacross cities over the time period studied, with variability primarily seen\nonly in the immediate impact of federal guidelines and local lockdown policies.\nWe also find that these local sentiments are highly correlated with and\npredictive of city-level mobility, while the correlations between sentiments\nand local cases and deaths are relatively weak. Our findings point to\nwidespread commonalities in the online public emotional responses to COVID\nacross the US, both temporally and relative to offline indicators, in contrast\nwith the high variability seen in early local containment policies. This study\nalso provides new insights into the use of social media data in crisis\nmanagement by integrating offline data to gain an in-depth understanding of\npublic emotional responses, policy development, and local mobility.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 11:32:46 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Feng", "Shihui", ""], ["Kirkley", "Alec", ""]]}, {"id": "2009.10548", "submitter": "Vishist Srivastava", "authors": "Vishist Srivastava, Prashant Yadav, Ajuni Singh", "title": "Football and externalities: Using mathematical modelling to predict the\n  changing fortunes of Newcastle United", "comments": "13 Pages, 4 figures, code snippets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Public Investment Fund (PIF), is Saudi Arabia's sovereign wealth fund. It\nis one of the world's largest sovereign wealth funds, with an estimated net\ncapital of $382 billion. It was established to invest funds on behalf of the\nGovernment of Saudi Arabia. Saudi Arabia is aiming to transfer the PIF from a\nmere local authority to the world's largest sovereign fund. Thus, PIF is\nworking to manage $400 billion worth of assets by 2020. It was with this Public\nInvestment Fund that Saudi Arabia decided to buy out the football club-\nNewcastle United FC- a mid-table club of the premier league. In this paper, we\naim to forecast the investment levels and the subsequent improve in the league\nposition of Newcastle United FC using the model of another premier league club-\nManchester City as the base. We employ the DiD approach of logistical\nregression through Python.\n  Keywords: Regression, Investment, Football, Forecasting\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 13:40:16 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Srivastava", "Vishist", ""], ["Yadav", "Prashant", ""], ["Singh", "Ajuni", ""]]}, {"id": "2009.10576", "submitter": "Irene Y. Chen", "authors": "Irene Y. Chen, Emma Pierson, Sherri Rose, Shalmali Joshi, Kadija\n  Ferryman, and Marzyeh Ghassemi", "title": "Ethical Machine Learning in Health Care", "comments": "Annual Reviews in Biomedical Data Science 2021", "journal-ref": null, "doi": "10.1146/annurev-biodatasci-092820-114757", "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The use of machine learning (ML) in health care raises numerous ethical\nconcerns, especially as models can amplify existing health inequities. Here, we\noutline ethical considerations for equitable ML in the advancement of health\ncare. Specifically, we frame ethics of ML in health care through the lens of\nsocial justice. We describe ongoing efforts and outline challenges in a\nproposed pipeline of ethical ML in health, ranging from problem selection to\npost-deployment considerations. We close by summarizing recommendations to\naddress these challenges.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 14:34:28 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 12:16:57 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 03:26:31 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Chen", "Irene Y.", ""], ["Pierson", "Emma", ""], ["Rose", "Sherri", ""], ["Joshi", "Shalmali", ""], ["Ferryman", "Kadija", ""], ["Ghassemi", "Marzyeh", ""]]}, {"id": "2009.10616", "submitter": "Anas Blasi", "authors": "Mohammad Awis Al Lababede, Anas H. Blasi, Mohammed A. Alsuwaiket", "title": "Mosques Smart Domes System using Machine Learning Algorithms", "comments": null, "journal-ref": null, "doi": "10.14569/IJACSA.2020.0110347", "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millions of mosques around the world are suffering some problems such as\nventilation and difficulty getting rid of bacteria, especially in rush hours\nwhere congestion in mosques leads to air pollution and spread of bacteria, in\naddition to unpleasant odors and to a state of discomfort during the pray\ntimes, where in most mosques there are no enough windows to ventilate the\nmosque well. This paper aims to solve these problems by building a model of\nsmart mosques domes using weather features and outside temperatures. Machine\nlearning algorithms such as k Nearest Neighbors and Decision Tree were applied\nto predict the state of the domes open or close. The experiments of this paper\nwere applied on Prophet mosque in Saudi Arabia, which basically contains twenty\nseven manually moving domes. Both machine learning algorithms were tested and\nevaluated using different evaluation methods. After comparing the results for\nboth algorithms, DT algorithm was achieved higher accuracy 98% comparing with\n95% accuracy for kNN algorithm. Finally, the results of this study were\npromising and will be helpful for all mosques to use our proposed model for\ncontrolling domes automatically.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 19:51:30 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Lababede", "Mohammad Awis Al", ""], ["Blasi", "Anas H.", ""], ["Alsuwaiket", "Mohammed A.", ""]]}, {"id": "2009.10617", "submitter": "Nkechi Ifeanyi-Reuben Dr.", "authors": "Odikwa Henry, Ifeanyi-Reuben Nkechi, Thom-Manuel Osaki Miller", "title": "An Enhanced Geo Location Technique for Social Network Communication\n  System", "comments": null, "journal-ref": "International Journal of Computer Science and Software Engineering\n  (IJCSSE), Volume 8, Issue 9, September 2019, Page: 214-223", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social networks have become very popular in recent years because of the\nincreasing large number and affordability of internet enabled gadgets such as\npersonal computers, mobile devices and internet tablets. It has been observed\nthat the tempo of fraud in social media these days is over alarming most\nespecially in Nigeria. As a result of this, there is need to fortify the social\nnetwork services in order to secure e-mail communication and reinforce data\nsecurity. This paper advocates for an advanced and secured approach for\nimproving communication in a social Network with the use of geo-location\ntechnique. The system was designed using an Object-Oriented software\ndevelopment methodology and implemented using the server-based scripting\nlanguage - PHP, Cascading Style Sheets (CSS) and back-end with MySQL. The\nproposed system will help the government and security agencies fight recent\nsecurity challenges in the country.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 19:57:44 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Henry", "Odikwa", ""], ["Nkechi", "Ifeanyi-Reuben", ""], ["Miller", "Thom-Manuel Osaki", ""]]}, {"id": "2009.10802", "submitter": "Dimitra Karanatsiou", "authors": "Dimitra Karanatsiou, Pavlos Sermpezis, Jon Gruda, Konstantinos\n  Kafetsios, Ilias Dimitriadis and Athena Vakali", "title": "My tweets bring all the traits to the yard: Predicting personality and\n  relational traits in Online Social Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Users in Online Social Networks (OSN) leaves traces that reflect their\npersonality characteristics. The study of these traces is important for a\nnumber of fields, such as a social science, psychology, OSN, marketing, and\nothers. Despite a marked increase on research in personality prediction on\nbased on online behavior the focus has been heavily on individual personality\ntraits largely neglecting relational facets of personality. This study aims to\naddress this gap by providing a prediction model for a holistic personality\nprofiling in OSNs that included socio-relational traits (attachment\norientations) in combination with standard personality traits. Specifically, we\nfirst designed a feature engineering methodology that extracts a wide range of\nfeatures (accounting for behavior, language, and emotions) from OSN accounts of\nusers. Then, we designed a machine learning model that predicts scores for the\npsychological traits of the users based on the extracted features. The proposed\nmodel architecture is inspired by characteristics embedded in psychological\ntheory, i.e, utilizing interrelations among personality facets, and leads to\nincreased accuracy in comparison with the state of the art approaches. To\ndemonstrate the usefulness of this approach, we applied our model to two\ndatasets, one of random OSN users and one of organizational leaders, and\ncompared their psychological profiles. Our findings demonstrate that the two\ngroups can be clearly separated by only using their psychological profiles,\nwhich opens a promising direction for future research on OSN user\ncharacterization and classification.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 20:30:56 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Karanatsiou", "Dimitra", ""], ["Sermpezis", "Pavlos", ""], ["Gruda", "Jon", ""], ["Kafetsios", "Konstantinos", ""], ["Dimitriadis", "Ilias", ""], ["Vakali", "Athena", ""]]}, {"id": "2009.10990", "submitter": "Rohun Kshirsagar", "authors": "Rohun Kshirsagar, Li-Yen Hsu, Vatshank Chaturvedi, Charles H.\n  Greenberg, Matthew McClelland, Anushadevi Mohan, Wideet Shende, Nicolas P.\n  Tilmans, Renzo Frigato, Min Guo, Ankit Chheda, Meredith Trotter, Shonket Ray,\n  Arnold Lee, Miguel Alvarado", "title": "Accurate and Interpretable Machine Learning for Transparent Pricing of\n  Health Insurance Plans", "comments": "Accepted for publication in The Thirty-Fifth AAAI Conference on\n  Artificial Intelligence (AAAI-21), in the Innovative Applications of\n  Artificial Intelligence track. This is the extended version with some\n  stylistic fixes from the first posting and complete author list", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Health insurance companies cover half of the United States population through\ncommercial employer-sponsored health plans and pay 1.2 trillion US dollars\nevery year to cover medical expenses for their members. The actuary and\nunderwriter roles at a health insurance company serve to assess which risks to\ntake on and how to price those risks to ensure profitability of the\norganization. While Bayesian hierarchical models are the current standard in\nthe industry to estimate risk, interest in machine learning as a way to improve\nupon these existing methods is increasing. Lumiata, a healthcare analytics\ncompany, ran a study with a large health insurance company in the United\nStates. We evaluated the ability of machine learning models to predict the per\nmember per month cost of employer groups in their next renewal period,\nespecially those groups who will cost less than 95\\% of what an actuarial model\npredicts (groups with \"concession opportunities\"). We developed a sequence of\ntwo models, an individual patient-level and an employer-group-level model, to\npredict the annual per member per month allowed amount for employer groups,\nbased on a population of 14 million patients. Our models performed 20\\% better\nthan the insurance carrier's existing pricing model, and identified 84\\% of the\nconcession opportunities. This study demonstrates the application of a machine\nlearning system to compute an accurate and fair price for health insurance\nproducts and analyzes how explainable machine learning models can exceed\nactuarial models' predictive accuracy while maintaining interpretability.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 08:07:33 GMT"}, {"version": "v2", "created": "Sat, 27 Feb 2021 22:47:22 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Kshirsagar", "Rohun", ""], ["Hsu", "Li-Yen", ""], ["Chaturvedi", "Vatshank", ""], ["Greenberg", "Charles H.", ""], ["McClelland", "Matthew", ""], ["Mohan", "Anushadevi", ""], ["Shende", "Wideet", ""], ["Tilmans", "Nicolas P.", ""], ["Frigato", "Renzo", ""], ["Guo", "Min", ""], ["Chheda", "Ankit", ""], ["Trotter", "Meredith", ""], ["Ray", "Shonket", ""], ["Lee", "Arnold", ""], ["Alvarado", "Miguel", ""]]}, {"id": "2009.11038", "submitter": "Taha Yasseri", "authors": "Vince J. Straub and Milena Tsvetkova and Taha Yasseri", "title": "The cost of coordination can exceed the benefit of collaboration in\n  performing complex tasks", "comments": "Under review; 26 pages + Supplementary Information", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.GT nlin.AO physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collective decision-making is ubiquitous when observing the behavior of\nintelligent agents, including humans. However, there are inconsistencies in our\ntheoretical understanding of whether there is a collective advantage from\ninteracting with group members of varying levels of competence in solving\nproblems of varying complexity. Moreover, most existing experiments have relied\non highly stylized tasks, reducing the generality of their results. The present\nstudy narrows the gap between experimental control and realistic settings,\nreporting the results from an analysis of collective problem-solving in the\ncontext of a real-world citizen science task environment in which individuals\nwith manipulated differences in task-relevant training collaborated on the\nWildcam Gorongosa task, hosted by The Zooniverse. We find that dyads gradually\nimprove in performance but do not experience a collective benefit compared to\nindividuals in most situations; rather, the cost of team coordination to\nefficiency and speed is consistently larger than the leverage of having a\npartner, even if they are expertly trained. It is only in terms of accuracy in\nthe most complex tasks that having an additional expert significantly improves\nperformance upon that of non-experts. Our findings have important theoretical\nand applied implications for collective problem-solving: to improve efficiency,\none could prioritize providing task-relevant training and relying on trained\nexperts working alone over interaction and to improve accuracy, one could\ntarget the expertise of selectively trained individuals.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 10:18:26 GMT"}, {"version": "v2", "created": "Sat, 2 Jan 2021 12:10:28 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Straub", "Vince J.", ""], ["Tsvetkova", "Milena", ""], ["Yasseri", "Taha", ""]]}, {"id": "2009.11087", "submitter": "Irene Y. Chen", "authors": "Irene Y. Chen, Shalmali Joshi, Marzyeh Ghassemi, and Rajesh Ranganath", "title": "Probabilistic Machine Learning for Healthcare", "comments": "Annual Reviews of Biomedical Data Science 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning can be used to make sense of healthcare data. Probabilistic\nmachine learning models help provide a complete picture of observed data in\nhealthcare. In this review, we examine how probabilistic machine learning can\nadvance healthcare. We consider challenges in the predictive model building\npipeline where probabilistic models can be beneficial including calibration and\nmissing data. Beyond predictive models, we also investigate the utility of\nprobabilistic machine learning models in phenotyping, in generative models for\nclinical use cases, and in reinforcement learning.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 12:14:05 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Chen", "Irene Y.", ""], ["Joshi", "Shalmali", ""], ["Ghassemi", "Marzyeh", ""], ["Ranganath", "Rajesh", ""]]}, {"id": "2009.11100", "submitter": "Jessica Van Brummelen", "authors": "Jessica Van Brummelen and Phoebe Lin", "title": "Engaging Teachers to Co-Design Integrated AI Curriculum for K-12\n  Classrooms", "comments": "12 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ed-ph cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) education is an increasingly popular topic area\nfor K-12 teachers. However, little research has investigated how AI education\ncan be designed to be more accessible to all learners. We organized co-design\nworkshops with 15 K-12 teachers to identify opportunities to integrate AI\neducation into core curriculum to leverage learners' interests. During the\nco-design workshops, teachers and researchers co-created lesson plans where AI\nconcepts were embedded into various core subjects. We found that K-12 teachers\nneed additional scaffolding in the curriculum to facilitate ethics and data\ndiscussions, and value supports for learner engagement, collaboration, and\nreflection. We identify opportunities for researchers and teachers to\ncollaborate to make AI education more accessible, and present an exemplar\nlesson plan that shows entry points for teaching AI in non-computing subjects.\nWe also reflect on co-designing with K-12 teachers in a remote setting.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:56:41 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Van Brummelen", "Jessica", ""], ["Lin", "Phoebe", ""]]}, {"id": "2009.11180", "submitter": "Lance Eliot", "authors": "Lance Eliot", "title": "AI and Legal Argumentation: Aligning the Autonomous Levels of AI Legal\n  Reasoning", "comments": "26 pages, 9 figures. arXiv admin note: text overlap with\n  arXiv:2009.02243", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Legal argumentation is a vital cornerstone of justice, underpinning an\nadversarial form of law, and extensive research has attempted to augment or\nundertake legal argumentation via the use of computer-based automation\nincluding Artificial Intelligence (AI). AI advances in Natural Language\nProcessing (NLP) and Machine Learning (ML) have especially furthered the\ncapabilities of leveraging AI for aiding legal professionals, doing so in ways\nthat are modeled here as CARE, namely Crafting, Assessing, Refining, and\nEngaging in legal argumentation. In addition to AI-enabled legal argumentation\nserving to augment human-based lawyering, an aspirational goal of this\nmulti-disciplinary field consists of ultimately achieving autonomously effected\nhuman-equivalent legal argumentation. As such, an innovative meta-approach is\nproposed to apply the Levels of Autonomy (LoA) of AI Legal Reasoning (AILR) to\nthe maturation of AI and Legal Argumentation (AILA), proffering a new means of\ngauging progress in this ever-evolving and rigorously sought domain.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 22:05:40 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Eliot", "Lance", ""]]}, {"id": "2009.11182", "submitter": "Tarik A. Rashid", "authors": "Chnoor M. Rahman and Tarik A. Rashid", "title": "A new evolutionary algorithm: Learner performance based behavior\n  algorithm", "comments": "17 pages. Egyptian Informatics Journal, 2020", "journal-ref": null, "doi": "10.1016/j.eij.2020.08.003", "report-no": null, "categories": "cs.CY cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A novel evolutionary algorithm called learner performance based behavior\nalgorithm (LPB) is proposed in this article. The basic inspiration of LPB\noriginates from the process of accepting graduated learners from high school in\ndifferent departments at university. In addition, the changes those learners\nshould do in their studying behaviors to improve their study level at\nuniversity. The most important stages of optimization; exploitation and\nexploration are outlined by designing the process of accepting graduated\nlearners from high school to university and the procedure of improving the\nlearner's studying behavior at university to improve the level of their study.\nTo show the accuracy of the proposed algorithm, it is evaluated against a\nnumber of test functions, such as traditional benchmark functions, CEC-C06 2019\ntest functions, and a real-world case study problem. The results of the\nproposed algorithm are then compared to the DA, GA, and PSO. The proposed\nalgorithm produced superior results in most of the cases and comparative in\nsome others. It is proved that the algorithm has a great ability to deal with\nthe large optimization problems comparing to the DA, GA, and PSO. The overall\nresults proved the ability of LPB in improving the initial population and\nconverging towards the global optima. Moreover, the results of the proposed\nwork are proved statistically.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 04:17:35 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Rahman", "Chnoor M.", ""], ["Rashid", "Tarik A.", ""]]}, {"id": "2009.11186", "submitter": "EPTCS", "authors": "Abeer Dyoub (University of L'Aquila, Italy), Stefania Costantini\n  (University of L'Aquila, Italy), Francesca A. Lisi (University of Bari \"A.\n  Moro\", Italy)", "title": "Logic Programming and Machine Ethics", "comments": "In Proceedings ICLP 2020, arXiv:2009.09158. Invited paper for the\n  ICLP2020 Panel on \"Machine Ethics\". arXiv admin note: text overlap with\n  arXiv:1909.08255", "journal-ref": "EPTCS 325, 2020, pp. 6-17", "doi": "10.4204/EPTCS.325.6", "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transparency is a key requirement for ethical machines. Verified ethical\nbehavior is not enough to establish justified trust in autonomous intelligent\nagents: it needs to be supported by the ability to explain decisions. Logic\nProgramming (LP) has a great potential for developing such perspective ethical\nsystems, as in fact logic rules are easily comprehensible by humans.\nFurthermore, LP is able to model causality, which is crucial for ethical\ndecision making.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:47:18 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Dyoub", "Abeer", "", "University of L'Aquila, Italy"], ["Costantini", "Stefania", "", "University of L'Aquila, Italy"], ["Lisi", "Francesca A.", "", "University of Bari \"A.\n  Moro\", Italy"]]}, {"id": "2009.11190", "submitter": "Ulrich Kerzel", "authors": "U. Kerzel", "title": "Enterprise AI Canvas -- Integrating Artificial Intelligence into\n  Business", "comments": "Accepted at \"Applied Artificial Intelligence UAAI\"", "journal-ref": null, "doi": "10.1080/08839514.2020.1826146", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) and Machine Learning have enormous potential to\ntransform businesses and disrupt entire industry sectors. However, companies\nwishing to integrate algorithmic decisions into their face multiple challenges:\nThey have to identify use-cases in which artificial intelligence can create\nvalue, as well as decisions that can be supported or executed automatically.\nFurthermore, the organization will need to be transformed to be able to\nintegrate AI based systems into their human work-force. Furthermore, the more\ntechnical aspects of the underlying machine learning model have to be discussed\nin terms of how they impact the various units of a business: Where do the\nrelevant data come from, which constraints have to be considered, how is the\nquality of the data and the prediction evaluated?\n  The Enterprise AI canvas is designed to bring Data Scientist and business\nexpert together to discuss and define all relevant aspects which need to be\nclarified in order to integrate AI based systems into a digital enterprise. It\nconsists of two parts where part one focuses on the business view and\norganizational aspects, whereas part two focuses on the underlying machine\nlearning model and the data it uses.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 07:30:56 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Kerzel", "U.", ""]]}, {"id": "2009.11647", "submitter": "Lance Eliot", "authors": "Lance Eliot", "title": "The Next Era of American Law Amid the Advent of Autonomous AI Legal\n  Reasoning", "comments": "20 pages, 8 figures. arXiv admin note: text overlap with\n  arXiv:1802.08722, arXiv:2009.02243, arXiv:2009.11180, arXiv:2008.12615,\n  arXiv:2008.10575, arXiv:2008.09507, arXiv:2008.07743", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Legal scholars have postulated that there have been three eras of American\nlaw to-date, consisting in chronological order of the initial Age of Discovery,\nthe Age of Faith, and then the Age of Anxiety. An open question that has\nreceived erudite attention in legal studies is what the next era, the fourth\nera, might consist of, and for which various proposals exist including examples\nsuch as the Age of Consent, the Age of Information, etc. There is no consensus\nin the literature as yet on what the fourth era is, and nor whether the fourth\nera has already begun or will instead emerge in the future. This paper examines\nthe potential era-elucidating impacts amid the advent of autonomous Artificial\nIntelligence Legal Reasoning (AILR), entailing whether such AILR will be an\nelement of a fourth era or a driver of a fourth, fifth, or perhaps the sixth\nera of American law. Also, a set of meta-characteristics about the means of\nidentifying a legal era changeover are introduced, along with an innovative\ndiscussion of the role entailing legal formalism versus legal realism in the\nemergence of the American law eras.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 18:22:57 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Eliot", "Lance", ""]]}, {"id": "2009.11654", "submitter": "Amanda Stent", "authors": "Tina Tseng and Amanda Stent and Domenic Maida", "title": "Best Practices for Managing Data Annotation Projects", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.34497.58727", "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Annotation is the labeling of data by human effort. Annotation is critical to\nmodern machine learning, and Bloomberg has developed years of experience of\nannotation at scale. This report captures a wealth of wisdom for applied\nannotation projects, collected from more than 30 experienced annotation project\nmanagers in Bloomberg's Global Data department.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 13:09:52 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Tseng", "Tina", ""], ["Stent", "Amanda", ""], ["Maida", "Domenic", ""]]}, {"id": "2009.11669", "submitter": "Bahman Rostami-Tabar", "authors": "Bahman Rostami-Tabar and Mohammad M Ali and Tao Hong and Rob J Hyndman\n  and Michael D Porter and Aris Syntetos", "title": "Forecasting for Social Good", "comments": "28 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forecasting plays a critical role in the development of organisational\nbusiness strategies. Despite a considerable body of research in the area of\nforecasting, the focus has largely been on the financial and economic outcomes\nof the forecasting process as opposed to societal benefits. Our motivation in\nthis study is to promote the latter, with a view to using the forecasting\nprocess to advance social and environmental objectives such as equality, social\njustice and sustainability. We refer to such forecasting practices as\nForecasting for Social Good (FSG) where the benefits to society and the\nenvironment take precedence over economic and financial outcomes. We\nconceptualise FSG and discuss its scope and boundaries in the context of the\n\"Doughnut theory\". We present some key attributes that qualify a forecasting\nprocess as FSG: it is concerned with a real problem, it is focused on advancing\nsocial and environmental goals and prioritises these over conventional measures\nof economic success, and it has a broad societal impact. We also position FSG\nin the wider literature on forecasting and social good practices. We propose an\nFSG maturity framework as the means to engage academics and practitioners with\nresearch in this area. Finally, we highlight that FSG: (i) cannot be distilled\nto a prescriptive set of guidelines, (ii) is scalable, and (iii) has the\npotential to make significant contributions to advancing social objectives.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 13:16:57 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Rostami-Tabar", "Bahman", ""], ["Ali", "Mohammad M", ""], ["Hong", "Tao", ""], ["Hyndman", "Rob J", ""], ["Porter", "Michael D", ""], ["Syntetos", "Aris", ""]]}, {"id": "2009.11677", "submitter": "Gavin Leech", "authors": "Dylan Holden-Sim and Gavin Leech and Laurence Aitchison", "title": "Legally grounded fairness objectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has identified a number of formally incompatible operational\nmeasures for the unfairness of a machine learning (ML) system. As these\nmeasures all capture intuitively desirable aspects of a fair system, choosing\n\"the one true\" measure is not possible, and instead a reasonable approach is to\nminimize a weighted combination of measures. However, this simply raises the\nquestion of how to choose the weights. Here, we formulate Legally Grounded\nFairness Objectives (LGFO), which uses signals from the legal system to\nnon-arbitrarily measure the social cost of a specific degree of unfairness. The\nLGFO is the expected damages under a putative lawsuit that might be awarded to\nthose who were wrongly classified, in the sense that the ML system made a\ndecision different to that which would have be made under the court's preferred\nmeasure. Notably, the two quantities necessary to compute the LGFO, the court's\npreferences about fairness measures, and the expected damages, are unknown but\nwell-defined, and can be estimated by legal advice. Further, as the damages\nawarded by the legal system are designed to measure and compensate for the harm\ncaused to an individual by an unfair classification, the LGFO aligns closely\nwith society's estimate of the social cost.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 13:30:03 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Holden-Sim", "Dylan", ""], ["Leech", "Gavin", ""], ["Aitchison", "Laurence", ""]]}, {"id": "2009.11771", "submitter": "Diego Saez-Trumper", "authors": "Oleksii Moskalenko, Denis Parra, and Diego Saez-Trumper", "title": "Scalable Recommendation of Wikipedia Articles to Editors Using\n  Representation Learning", "comments": null, "journal-ref": "ComplexRec 2020, Workshop on Recommendation in Complex Scenarios\n  at the ACM RecSys Conference on Recommender Systems (RecSys 2020)", "doi": null, "report-no": null, "categories": "cs.IR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wikipedia is edited by volunteer editors around the world. Considering the\nlarge amount of existing content (e.g. over 5M articles in English Wikipedia),\ndeciding what to edit next can be difficult, both for experienced users that\nusually have a huge backlog of articles to prioritize, as well as for newcomers\nwho that might need guidance in selecting the next article to contribute.\nTherefore, helping editors to find relevant articles should improve their\nperformance and help in the retention of new editors. In this paper, we address\nthe problem of recommending relevant articles to editors. To do this, we\ndevelop a scalable system on top of Graph Convolutional Networks and Doc2Vec,\nlearning how to represent Wikipedia articles and deliver personalized\nrecommendations for editors. We test our model on editors' histories,\npredicting their most recent edits based on their prior edits. We outperform\ncompetitive implicit-feedback collaborative-filtering methods such as WMRF\nbased on ALS, as well as a traditional IR-method such as content-based\nfiltering based on BM25. All of the data used on this paper is publicly\navailable, including graph embeddings for Wikipedia articles, and we release\nour code to support replication of our experiments. Moreover, we contribute\nwith a scalable implementation of a state-of-art graph embedding algorithm as\ncurrent ones cannot efficiently handle the sheer size of the Wikipedia graph.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 15:56:02 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Moskalenko", "Oleksii", ""], ["Parra", "Denis", ""], ["Saez-Trumper", "Diego", ""]]}, {"id": "2009.11792", "submitter": "Emiliano De Cristofaro", "authors": "Yuping Wang and Fatemeh Tahmasbi and Jeremy Blackburn and Barry\n  Bradlyn and Emiliano De Cristofaro and David Magerman and Savvas Zannettou\n  and Gianluca Stringhini", "title": "Understanding the Use of Fauxtography on Social Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the influence that image-based communication has on online discourse,\nthe role played by images in disinformation is still not well understood. In\nthis paper, we present the first large-scale study of fauxtography, analyzing\nthe use of manipulated or misleading images in news discussion on online\ncommunities. First, we develop a computational pipeline geared to detect\nfauxtography, and identify over 61k instances of fauxtography discussed on\nTwitter, 4chan, and Reddit. Then, we study how posting fauxtography affects\nengagement of posts on social media, finding that posts containing it receive\nmore interactions in the form of re-shares, likes, and comments. Finally, we\nshow that fauxtography images are often turned into memes by Web communities.\nOur findings show that effective mitigation against disinformation need to take\nimages into account, and highlight a number of challenges in dealing with\nimage-based disinformation.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 16:34:47 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 04:46:41 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Wang", "Yuping", ""], ["Tahmasbi", "Fatemeh", ""], ["Blackburn", "Jeremy", ""], ["Bradlyn", "Barry", ""], ["De Cristofaro", "Emiliano", ""], ["Magerman", "David", ""], ["Zannettou", "Savvas", ""], ["Stringhini", "Gianluca", ""]]}, {"id": "2009.11838", "submitter": "Khaled Abedrabboh", "authors": "Khaled Abedrabboh, Matthias Pilz, Zaid Al-Fagih, Othman S. Al-Fagih,\n  Jean-Christophe Nebel, Luluwah Al-Fagih", "title": "Game theory to enhance stock management of Personal Protective Equipment\n  (PPE) during the COVID-19 outbreak", "comments": "22 pages, 7 figures, published in PLOS ONE\n  https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0246110", "journal-ref": "PLOS ONE 16(2): e0246110 (2021)", "doi": "10.1371/journal.pone.0246110", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Since the outbreak of the COVID-19 pandemic, many healthcare facilities have\nsuffered from shortages in medical resources, particularly in Personal\nProtective Equipment (PPE). In this paper, we propose a game-theoretic approach\nto schedule PPE orders among healthcare facilities. In this PPE game, each\nindependent healthcare facility optimises its own storage utilisation in order\nto keep its PPE cost at a minimum. Such a model can reduce peak demand\nconsiderably when applied to a variable PPE consumption profile. Experiments\nconducted for NHS England regions using actual data confirm that the challenge\nof securing PPE supply during disasters such as COVID-19 can be eased if proper\nstock management procedures are adopted. These procedures can include early\nstockpiling, increasing storage capacities and implementing measures that can\nprolong the time period between successive infection waves, such as social\ndistancing measures. Simulation results suggest that the provision of PPE\ndedicated storage space can be a viable solution to avoid straining PPE supply\nchains in case a second wave of COVID-19 infections occurs.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 17:36:13 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 09:43:06 GMT"}, {"version": "v3", "created": "Tue, 2 Feb 2021 08:08:35 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Abedrabboh", "Khaled", ""], ["Pilz", "Matthias", ""], ["Al-Fagih", "Zaid", ""], ["Al-Fagih", "Othman S.", ""], ["Nebel", "Jean-Christophe", ""], ["Al-Fagih", "Luluwah", ""]]}, {"id": "2009.11867", "submitter": "Samuel Dooley", "authors": "Samuel Dooley, John P. Dickerson", "title": "The Affiliate Matching Problem: On Labor Markets where Firms are Also\n  Interested in the Placement of Previous Workers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.AI cs.CY cs.DS cs.GT q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many labor markets, workers and firms are connected via affiliative\nrelationships. A management consulting firm wishes to both accept the best new\nworkers but also place its current affiliated workers at strong firms.\nSimilarly, a research university wishes to hire strong job market candidates\nwhile also placing its own candidates at strong peer universities. We model\nthis affiliate matching problem in a generalization of the classic stable\nmarriage setting by permitting firms to state preferences over not just which\nworkers to whom they are matched, but also to which firms their affiliated\nworkers are matched. Based on results from a human survey, we find that\nparticipants (acting as firms) give preference to their own affiliate workers\nin surprising ways that violate some assumptions of the classical stable\nmarriage problem. This motivates a nuanced discussion of how stability could be\ndefined in affiliate matching problems; we give an example of a marketplace\nwhich admits a stable match under one natural definition of stability, and does\nnot for that same marketplace under a different, but still natural, definition.\nWe conclude by setting a research agenda toward the creation of a centralized\nclearing mechanism in this general setting.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 01:27:47 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Dooley", "Samuel", ""], ["Dickerson", "John P.", ""]]}, {"id": "2009.11901", "submitter": "Moayad Aloqaily", "authors": "Ismaeel Al Ridhawi and Moayad Aloqaily and Yaser Jararweh", "title": "An Incentive-Based Mechanism for Volunteer Computing using Blockchain", "comments": "22 pages, 12 Figures, 1 Table. Accepted. ACM Transaction On Internet\n  Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of fast communication media both at the core and at the edge has\nresulted in unprecedented numbers of sophisticated and intelligent wireless IoT\ndevices. Tactile Internet has enabled the interaction between humans and\nmachines within their environment to achieve revolutionized solutions both on\nthe move and in real-time. Many applications such as intelligent autonomous\nself-driving, smart agriculture and industrial solutions, and self-learning\nmultimedia content filtering and sharing have become attainable through\ncooperative, distributed and decentralized systems, namely, volunteer\ncomputing. This article introduces a blockchain-enabled resource sharing and\nservice composition solution through volunteer computing. Device resource,\ncomputing, and intelligence capabilities are advertised in the environment to\nbe made discoverable and available for sharing with the aid of blockchain\ntechnology. Incentives in the form of on-demand service availability are given\nto resource and service providers to ensure fair and balanced cooperative\nresource usage. Blockchains are formed whenever a service request is initiated\nwith the aid of fog and mobile edge computing (MEC) devices to ensure secure\ncommunication and service delivery for the participants. Using both volunteer\ncomputing techniques and tactile internet architectures, we devise a fast and\nreliable service provisioning framework that relies on a reinforcement learning\ntechnique. Simulation results show that the proposed solution can achieve high\nreward distribution, increased number of blockchain formations, reduced delays,\nand balanced resource usage among participants, under the premise of high IoT\ndevice availability.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 18:48:22 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Ridhawi", "Ismaeel Al", ""], ["Aloqaily", "Moayad", ""], ["Jararweh", "Yaser", ""]]}, {"id": "2009.12165", "submitter": "Juan Manuel Carrillo Garcia", "authors": "Juan Carrillo, Mark Crowley", "title": "Integration of Roadside Camera Images and Weather Data for Monitoring\n  Winter Road Surface Conditions", "comments": "For associated GitHub repository see\n  https://github.com/jmcarrillog/data-integration-for-road-monitoring", "journal-ref": "29th CARSP Conference, Calgary, Alberta, May 26-29, 2019", "doi": null, "report-no": null, "categories": "eess.SP cs.CY stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  During the winter season, real-time monitoring of road surface conditions is\ncritical for the safety of drivers and road maintenance operations. Previous\nresearch has evaluated the potential of image classification methods for\ndetecting road snow coverage by processing images from roadside cameras\ninstalled in RWIS (Road Weather Information System) stations. However, there\nare a limited number of RWIS stations across Ontario, Canada; therefore, the\nnetwork has reduced spatial coverage. In this study, we suggest improving\nperformance on this task through the integration of images and weather data\ncollected from the RWIS stations with images from other MTO (Ministry of\nTransportation of Ontario) roadside cameras and weather data from Environment\nCanada stations. We use spatial statistics to quantify the benefits of\nintegrating the three datasets across Southern Ontario, showing evidence of a\nsix-fold increase in the number of available roadside cameras and therefore\nimproving the spatial coverage in the most populous ecoregions in Ontario.\nAdditionally, we evaluate three spatial interpolation methods for inferring\nweather variables in locations without weather measurement instruments and\nidentify the one that offers the best tradeoff between accuracy and ease of\nimplementation.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 01:43:27 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Carrillo", "Juan", ""], ["Crowley", "Mark", ""]]}, {"id": "2009.12175", "submitter": "Anas Blasi", "authors": "Rawabi A. Aroud, Anas H. Blasi, Mohammed A. Alsuwaiket", "title": "Intelligent Risk Alarm for Asthma Patients using Artificial Neural\n  Networks", "comments": null, "journal-ref": null, "doi": "10.14569/IJACSA.2020.0110612", "report-no": null, "categories": "eess.SP cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asthma is a chronic disease of the airways of the lungs. It results in\ninflammation and narrowing of the respiratory passages, which prevents air flow\ninto the airways and leads to frequent bouts of shortness of breath with\nwheezing accompanied by coughing and phlegm after exposure to inhalation of\nsubstances that provoke allergic reactions or irritation of the respiratory\nsystem. Data mining in healthcare system is very important in diagnosing and\nunderstanding data, so data mining aims to solve basic problems in diagnosing\ndiseases due to the complexity of diagnosing asthma. Predicting chemicals in\nthe atmosphere is very important and one of the most difficult problems since\nthe last century. In this paper, the impact of chemicals on asthma patient will\nbe presented and discussed. Sensor system called MQ5 will be used to examine\nthe smoke and nitrogen content in the atmosphere. MQ5 will be inserted in a\nwristwatch that checks the smoke and nitrogen content in the patients place,\nthe system shall issue a warning alarm if this gas affects the person with\nasthma. It will be based on the Artificial Neural Networks (ANN) algorithm that\nhas been built using data that containing a set of chemicals such as carbon\nmonoxide, NMHC (GT) acid gas, C6H6 (GT) Gasoline, NOx (GT) Nitrogen Oxide, and\nNO2 (GT) Nitrogen Dioxide. The temperature and humidity will be also used as\nthey can negatively affect asthma patient. Finally, the rating model was\nevaluated and achieved 99.58% classification accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 17:48:52 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Aroud", "Rawabi A.", ""], ["Blasi", "Anas H.", ""], ["Alsuwaiket", "Mohammed A.", ""]]}, {"id": "2009.12425", "submitter": "Aparna Venkatesan", "authors": "Aparna Venkatesan (U. of San Francisco), David Begay (IEI and U. of\n  New Mexico), Adam J. Burgasser (UC San Diego), Isabel Hawkins (SF\n  Exploratorium), Ka'iu Kimura ('Imiloa Astronomy Center, Hawai'i), Nancy\n  Maryboy (IEI and U. of Washington), Laura Peticolas (Sonoma State U.)", "title": "Towards Inclusive Practices with Indigenous Knowledge", "comments": "3 pages formatted in Nature style, published as a Comment in DEI\n  focus issue in Nature Astronomy", "journal-ref": "Nature Astronomy, volume 3, 1035-1037 (2019)", "doi": null, "report-no": null, "categories": "physics.ed-ph astro-ph.IM cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Astronomy across world cultures is rooted in Indigenous Knowledge. We share\nmodels of partnering with indigenous communities involving Collaboration with\nIntegrity to co-create an inclusive scientific enterprise on Earth and in\nspace.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 20:30:38 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Venkatesan", "Aparna", "", "U. of San Francisco"], ["Begay", "David", "", "IEI and U. of\n  New Mexico"], ["Burgasser", "Adam J.", "", "UC San Diego"], ["Hawkins", "Isabel", "", "SF\n  Exploratorium"], ["Kimura", "Ka'iu", "", "'Imiloa Astronomy Center, Hawai'i"], ["Maryboy", "Nancy", "", "IEI and U. of Washington"], ["Peticolas", "Laura", "", "Sonoma State U."]]}, {"id": "2009.12470", "submitter": "Seth Frey", "authors": "Seth Frey and Nathan Schneider", "title": "Effective Voice: Beyond Exit and Affect in Online Communities", "comments": "~9000 words", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online communities provide ample opportunities for user self-expression but\ngenerally lack the means for average users to exercise direct control over\ncommunity policies. This paper sets out to identify a set of strategies and\ntechniques through which the voices of participants might be better heard\nthrough defined mechanisms for institutional governance. Drawing on Albert O.\nHirschman's distinction between \"exit\" and \"voice\" in institutional life, it\nintroduces a further distinction between two kinds of participation: effective\nvoice, as opposed to the far more widespread practices of affective voice.\nEffective voice is a form of individual or collective speech that brings about\na binding effect according to transparent processes. Platform developers and\nresearchers might explore this neglected form of voice by introducing\nmechanisms for authority and accountability, collective action, and community\nevolution.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 23:06:22 GMT"}, {"version": "v2", "created": "Sat, 20 Feb 2021 17:33:11 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Frey", "Seth", ""], ["Schneider", "Nathan", ""]]}, {"id": "2009.12471", "submitter": "Myounggyu Won", "authors": "Navid Mohammad Imran and Myounggyu Won", "title": "Reducing Operation Cost of LPWAN Roadside Sensors Using Cross Technology\n  Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-Power Wide-Area Network (LPWAN) is an emerging communication standard for\nInternet of Things (IoT) that has strong potential to support connectivity of a\nlarge number of roadside sensors with an extremely long communication range.\nHowever, the high operation cost to manage such a large-scale roadside sensor\nnetwork remains as a significant challenge. In this paper, we propose\nLOC-LPWAN, a novel optimization framework that is designed to reduce the\noperation cost using the cross technology communication (CTC). LOC-LPWAN allows\nroadside sensors to offload sensor data to passing vehicles that in turn\nforward the data to a LPWAN server using CTC aiming to reduce the data\nsubscription cost. LOC-LPWAN finds the optimal communication schedule between\nsensors and vehicles to maximize the throughput given an available budget of\nthe user. Furthermore, LOC-LPWAN optimizes the fairness among sensors by\nallowing sensors to transmit similar amounts of data and preventing certain\nsensors from dominating the opportunity for data transmissions. LOC-LPWAN also\nprovides an option that allows all sensor to transmit data within a specific\ndelay bound. Extensive numerical analysis performed with real-world taxi data\nconsisting of 40 vehicles with 24-hour trajectories demonstrate that LOC-LPWAN\nimproves the throughput by 72.6%, enhances the fairness by 65.7%, and reduces\nthe delay by 28.8% compared with a greedy algorithm given the same budget.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 23:20:20 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Imran", "Navid Mohammad", ""], ["Won", "Myounggyu", ""]]}, {"id": "2009.12542", "submitter": "Ashish Rajendra Kumar Sai", "authors": "Ashish Rajendra Sai, Jim Buckley, Brian Fitzgerald and Andrew Le Gear", "title": "Taxonomy of Centralization in Public Blockchain Systems: A Systematic\n  Literature Review", "comments": "Currently under review at ELS Information Processing and Management", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin introduced delegation of control over a monetary system from a select\nfew to all who participate in that system. This delegation is known as the\ndecentralization of controlling power and is a powerful security mechanism for\nthe ecosystem. After the introduction of Bitcoin, the field of cryptocurrency\nhas seen widespread attention from industry and academia, so much so that the\noriginal novel contribution of Bitcoin i.e. decentralization, may be\noverlooked, due to decentralizations assumed fundamental existence for the\nfunctioning of such cryptoassets. However recent studies have observed a trend\nof increased centralization in cryptocurrencies such as Bitcoin and Ethereum.\nAs this increased centralization has an impact the security of the blockchain,\nit is crucial that it is measured, towards adequate control. This research\nderives an initial taxonomy of centralization present in decentralized\nblockchains through rigorous synthesis using a systematic literature review.\nThis is followed by iterative refinement through expert interviews. We\nsystematically analyzed 89 research papers published between 2009 and 2019. Our\nstudy contributes to the existing body of knowledge by highlighting the\nmultiple definitions and measurements of centralization in the literature. We\nidentify different aspects of centralization and propose an encompassing\ntaxonomy of centralization concerns. This taxonomy is based on empirically\nobservable and measurable characteristics. It consists of 13 aspects of\ncentralization classified over six architectural layers Governance Network\nConsensus Incentive Operational and Application. We also discuss how the\nimplications of centralization can vary depending on the aspects studied. We\nbelieve that this review and taxonomy provides a comprehensive overview of\ncentralization in decentralized blockchains involving various\nconceptualizations and measures.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 08:58:48 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Sai", "Ashish Rajendra", ""], ["Buckley", "Jim", ""], ["Fitzgerald", "Brian", ""], ["Gear", "Andrew Le", ""]]}, {"id": "2009.12588", "submitter": "Rachit Agarwal", "authors": "Rachit Agarwal, Abhik Banerjee", "title": "Infection Risk Score: Identifying the risk of infection propagation\n  based on human contact", "comments": "Submitted to 1st ACM SIGSPATIAL International Workshop on Modeling\n  and Understanding the Spread of COVID-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A wide range of approaches have been applied to manage the spread of global\npandemic events such as COVID-19, which have met with varying degrees of\nsuccess. Given the large-scale social and economic impact coupled with the\nincreasing time span of the pandemic, it is important to not only manage the\nspread of the disease but also put extra efforts on measures that expedite\nresumption of social and economic life. It is therefore important to identify\nsituations that carry high risk, and act early whenever such situations are\nidentified. While a large number of mobile applications have been developed,\nthey are aimed at obtaining information that can be used for contact tracing,\nbut not at estimating the risk of social situations. In this paper, we\nintroduce an infection risk score that provides an estimate of the infection\nrisk arising from human contacts. Using a real-world human contact dataset, we\nshow that the proposed risk score can provide a realistic estimate of the level\nof risk in the population. We also describe how the proposed infection risk\nscore can be implemented on smartphones. Finally, we identify representative\nuse cases that can leverage the risk score to minimize infection propagation.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 13:25:06 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Agarwal", "Rachit", ""], ["Banerjee", "Abhik", ""]]}, {"id": "2009.12619", "submitter": "Ivan Iudice Ph.D.", "authors": "Donatella Darsena, Giacinto Gelli, Ivan Iudice, Francesco Verde", "title": "Safe and Reliable Public Transportation Systems (SALUTARY) in the\n  COVID-19 pandemic", "comments": "8 pages, 1 figure, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of the SALUTARY (Safe and Reliable Public Transportation Systems)\nsystem is to employ modern Information and Communication Technologies (ICT) to\nproactively tackle crowding situations in public transportation (PT) systems,as\na consequence of the limitations due to COVID-19 pandemic. In particular, it is\nproposed to adopt in the various segments of the PT system (buses/trams/trains,\nrailway/subway stations, and bus stops) suitable crowd detection techniques\nbased on Internet of Things (IoT) technologies, which measure in real-time the\nnumber of users, in order to: (i) monitor and predict crowding events; (ii)\nadapt in real-time PT system operations, i.e., modifying service frequency,\ntimetables, routes, and so on; (iii) inform the users by electronic displays\ninstalled in correspondence of the bus stops/stations and/or by mobile\ntransport applications. The SALUTARY system can be implemented incrementally,\nas an add-on to the Intelligent Transportation System (ITS) solution already in\nuse by major PT companies operating in urban areas. The system is designed as a\nflexible platform, which can be used to deliver, in addition to the innovative\ncrowd detection/management functionalities, also additional services, such as\non-line ticketing, vehicle access control and reservation in severely crowded\nsituations, and evolved crowd-aware route planning.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 15:25:46 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Darsena", "Donatella", ""], ["Gelli", "Giacinto", ""], ["Iudice", "Ivan", ""], ["Verde", "Francesco", ""]]}, {"id": "2009.12699", "submitter": "Mikhail Dmitrienko", "authors": "Mikhail Dmitrienko, Abhishek Singh, Patrick Erichsen, Ramesh Raskar", "title": "Proximity Inference with Wifi-Colocation during the COVID-19 Pandemic", "comments": "5 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a WiFi colocation methodology for digital contact\ntracing. The approach works by having a device scan and store nearby access\npoint information to perform proximity inference. We make our approach\nresilient to different practical scenarios by configuring a device to turn into\na hotspot if access points are unavailable, which makes the approach feasible\nin both dense urban areas and sparse rural places. We compare various\nshortcomings and advantages of this work over other conventional ways of doing\ndigital contact tracing. Preliminary results indicate the feasibility of our\napproach for determining proximity between users, which is relevant for\nimproving existing digital contact tracing and exposure notification\nimplementations.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 22:24:52 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 20:45:30 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Dmitrienko", "Mikhail", ""], ["Singh", "Abhishek", ""], ["Erichsen", "Patrick", ""], ["Raskar", "Ramesh", ""]]}, {"id": "2009.12853", "submitter": "Nicolas E. Diaz Ferreyra PhD", "authors": "Nicolas E. D\\'iaz Ferreyra, Esma A\\\"imeur, Hicham Hage, Maritta Heisel\n  and Catherine Garc\\'ia van Hoogstraten", "title": "Persuasion Meets AI: Ethical Considerations for the Design of Social\n  Engineering Countermeasures", "comments": "Accepted for publication at IC3K 2020", "journal-ref": null, "doi": "10.5220/0010142402040211", "report-no": null, "categories": "cs.CY cs.HC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy in Social Network Sites (SNSs) like Facebook or Instagram is closely\nrelated to people's self-disclosure decisions and their ability to foresee the\nconsequences of sharing personal information with large and diverse audiences.\nNonetheless, online privacy decisions are often based on spurious risk\njudgements that make people liable to reveal sensitive data to untrusted\nrecipients and become victims of social engineering attacks. Artificial\nIntelligence (AI) in combination with persuasive mechanisms like nudging is a\npromising approach for promoting preventative privacy behaviour among the users\nof SNSs. Nevertheless, combining behavioural interventions with high levels of\npersonalization can be a potential threat to people's agency and autonomy even\nwhen applied to the design of social engineering countermeasures. This paper\nelaborates on the ethical challenges that nudging mechanisms can introduce to\nthe development of AI-based countermeasures, particularly to those addressing\nunsafe self-disclosure practices in SNSs. Overall, it endorses the elaboration\nof personalized risk awareness solutions as i) an ethical approach to\ncounteract social engineering, and ii) as an effective means for promoting\nreflective privacy decisions.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 14:24:29 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Ferreyra", "Nicolas E. D\u00edaz", ""], ["A\u00efmeur", "Esma", ""], ["Hage", "Hicham", ""], ["Heisel", "Maritta", ""], ["van Hoogstraten", "Catherine Garc\u00eda", ""]]}, {"id": "2009.12913", "submitter": "Katina Kralevska", "authors": "Anton Hasselgren, Paul Kengfai Wan, Margareth Horn, Katina Kralevska,\n  Danilo Gligoroski, Arild Faxvaag", "title": "GDPR Compliance for Blockchain Applications in Healthcare", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The transparent and decentralized characteristics associated with blockchain\ncan be both appealing and problematic when applied to a healthcare use-case. As\nhealth data is highly sensitive, it is also highly regulated to ensure the\nprivacy of patients. At the same time, access to health data and\ninteroperability is in high demand. Regulatory frameworks such as GDPR and\nHIPAA are, amongst other objectives, meant to contribute to mitigating the risk\nof privacy violations in health data. Blockchain features can likely improve\ninteroperability and access control to health data, and at the same time,\npreserve or even increase, the privacy of patients. Blockchain applications\nshould address compliance with the current regulatory framework to increase\nreal-world feasibility. This exploratory work indicates that published\nproof-of-concepts in the health domain comply with GDRP, to an extent.\nBlockchain developers need to make design choices to be compliant with GDPR\nsince currently, none available blockchain platform can show compliance out of\nthe box.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 18:05:25 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Hasselgren", "Anton", ""], ["Wan", "Paul Kengfai", ""], ["Horn", "Margareth", ""], ["Kralevska", "Katina", ""], ["Gligoroski", "Danilo", ""], ["Faxvaag", "Arild", ""]]}, {"id": "2009.12923", "submitter": "Wasiq Khan Dr", "authors": "Wasiq Khan, Abir Hussain, Sohail Ahmed Khan, Mohammed Al-Jumailey,\n  Raheel Nawaz, Panos Liatsis", "title": "Analysing the impact of global demographic characteristics over the\n  COVID-19 spread using class rule mining and pattern matching", "comments": "Diversity in global death rate due to COVID-19 and Variant of Concern\n  202012/01 (VOC 202012/01)", "journal-ref": "Royal Society Open Science, 27 January 2021, Volume 8, Issue 1", "doi": "10.1098/rsos.201823", "report-no": null, "categories": "cs.LG cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Since the coronavirus disease (COVID-19) outbreak in December 2019, studies\nhave been addressing diverse aspects in relation to COVID-19 and Variant of\nConcern 202012/01 (VOC 202012/01) such as potential symptoms and predictive\ntools. However, limited work has been performed towards the modelling of\ncomplex associations between the combined demographic attributes and varying\nnature of the COVID-19 infections across the globe. This study presents an\nintelligent approach to investigate the multi-dimensional associations between\ndemographic attributes and COVID-19 global variations. We gather multiple\ndemographic attributes and COVID-19 infection data (by 8 January 2021) from\nreliable sources, which are then processed by intelligent algorithms to\nidentify the significant associations and patterns within the data. Statistical\nresults and experts' reports indicate strong associations between COVID-19\nseverity levels across the globe and certain demographic attributes, e.g.\nfemale smokers, when combined together with other attributes. The outcomes will\naid the understanding of the dynamics of disease spread and its progression,\nwhich in turn may support policy makers, medical specialists and society, in\nbetter understanding and effective management of the disease.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 18:43:18 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 06:54:37 GMT"}, {"version": "v3", "created": "Sun, 31 Jan 2021 11:07:45 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Khan", "Wasiq", ""], ["Hussain", "Abir", ""], ["Khan", "Sohail Ahmed", ""], ["Al-Jumailey", "Mohammed", ""], ["Nawaz", "Raheel", ""], ["Liatsis", "Panos", ""]]}, {"id": "2009.12979", "submitter": "Negar Mokhberian", "authors": "Negar Mokhberian, Andr\\'es Abeliuk, Patrick Cummings, Kristina Lerman", "title": "Moral Framing and Ideological Bias of News", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-60975-7_16", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  News outlets are a primary source for many people to learn what is going on\nin the world. However, outlets with different political slants, when talking\nabout the same news story, usually emphasize various aspects and choose their\nlanguage framing differently. This framing implicitly shows their biases and\nalso affects the reader's opinion and understanding. Therefore, understanding\nthe framing in the news stories is fundamental for realizing what kind of view\nthe writer is conveying with each news story. In this paper, we describe\nmethods for characterizing moral frames in the news. We capture the frames\nbased on the Moral Foundation Theory. This theory is a psychological concept\nwhich explains how every kind of morality and opinion can be summarized and\npresented with five main dimensions. We propose an unsupervised method that\nextracts the framing Bias and the framing Intensity without any external\nframing annotations provided. We validate the performance on an annotated\ntwitter dataset and then use it to quantify the framing bias and partisanship\nof news.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 23:36:14 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Mokhberian", "Negar", ""], ["Abeliuk", "Andr\u00e9s", ""], ["Cummings", "Patrick", ""], ["Lerman", "Kristina", ""]]}, {"id": "2009.13039", "submitter": "Yuncheng Jiang", "authors": "Hang Song, Yuncheng Jiang", "title": "The value chain of Industrial IoT and its reference framework for\n  digitalization", "comments": "16 pages, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nowadays, we are rapidly moving beyond bespoke detailed solutions tailored\nfor very specific problems, and we already build upon reusable and more general\npurpose infrastructures and tools, referring to them as IoT, Industrial\nIoT/Industry 4.0[1-3], etc. These are what will be discussed in this paper.\nWhen Industrial IoT (IIoT) is concerned about, the enormous innovation\npotential of IoT technologies are not only in the production of physical\ndevices, but also in all activities performed by manufacturing industries, both\nin the pre-production (ideation, design, prototyping) and in the\npost-production (sales, training, maintenance, recycling) phases . It is also\nknown that IIoT acquire and analyze data from connected devices, Cyber-Physical\nSystems (CPS), locations and people (e.g. operator); along with its\ncontemporary new terms, such as 5G, Edge computing, and other ICT technologies\nwith their applications[4] . More or less it is drawn upon on its combination\nwith relative monitoring devices and actuators from operational technology\n(OT). IIoT helps regulate and monitor industrial systems [2], and it\nintegrates/re-organize production resources flexibly, enhanced OT capability in\nthe smart value chains enabling distributed decision-making of production.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 03:21:30 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Song", "Hang", ""], ["Jiang", "Yuncheng", ""]]}, {"id": "2009.13250", "submitter": "Nathaniel Bastian PhD", "authors": "Tyler J. Shipp, Daniel J. Clouse, Michael J. De Lucia, Metin B.\n  Ahiskali, Kai Steverson, Jonathan M. Mullin, Nathaniel D. Bastian", "title": "Advancing the Research and Development of Assured Artificial\n  Intelligence and Machine Learning Capabilities", "comments": "Presented at AAAI FSS-20: Artificial Intelligence in Government and\n  Public Sector, Washington, DC, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CY cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) and machine learning (ML) have become\nincreasingly vital in the development of novel defense and intelligence\ncapabilities across all domains of warfare. An adversarial AI (A2I) and\nadversarial ML (AML) attack seeks to deceive and manipulate AI/ML models. It is\nimperative that AI/ML models can defend against these attacks. A2I/AML defenses\nwill help provide the necessary assurance of these advanced capabilities that\nuse AI/ML models. The A2I Working Group (A2IWG) seeks to advance the research\nand development of assured AI/ML capabilities via new A2I/AML defenses by\nfostering a collaborative environment across the U.S. Department of Defense and\nU.S. Intelligence Community. The A2IWG aims to identify specific challenges\nthat it can help solve or address more directly, with initial focus on three\ntopics: AI Trusted Robustness, AI System Security, and AI/ML Architecture\nVulnerabilities.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 20:12:14 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Shipp", "Tyler J.", ""], ["Clouse", "Daniel J.", ""], ["De Lucia", "Michael J.", ""], ["Ahiskali", "Metin B.", ""], ["Steverson", "Kai", ""], ["Mullin", "Jonathan M.", ""], ["Bastian", "Nathaniel D.", ""]]}, {"id": "2009.13300", "submitter": "Ananya Gangavarapu", "authors": "Ananya Gangavarapu, Ellie Daw, Abhishek Singh, Rohan Iyer, Gabriel\n  Harp, Sam Zimmerman, and Ramesh Raskar", "title": "Target Privacy Threat Modeling for COVID-19 Exposure Notification\n  Systems", "comments": "12 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The adoption of digital contact tracing (DCT) technology during the\nCOVID-19pandemic has shown multiple benefits, including helping to slow the\nspread of infectious disease and to improve the dissemination of accurate\ninformation. However, to support both ethical technology deployment and user\nadoption, privacy must be at the forefront. With the loss of privacy being a\ncritical threat, thorough threat modeling will help us to strategize and\nprotect privacy as digital contact tracing technologies advance. Various threat\nmodeling frameworks exist today, such as LINDDUN, STRIDE, PASTA, and NIST,\nwhich focus on software system privacy, system security, application security,\nand data-centric risk, respectively. When applied to the exposure notification\nsystem (ENS) context, these models provide a thorough view of the software side\nbut fall short in addressing the integrated nature of hardware, humans,\nregulations, and software involved in such systems. Our approach addresses\nENSsas a whole and provides a model that addresses the privacy complexities of\na multi-faceted solution. We define privacy principles, privacy threats,\nattacker capabilities, and a comprehensive threat model. Finally, we outline\nthreat mitigation strategies that address the various threats defined in our\nmodel\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 02:09:51 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Gangavarapu", "Ananya", ""], ["Daw", "Ellie", ""], ["Singh", "Abhishek", ""], ["Iyer", "Rohan", ""], ["Harp", "Gabriel", ""], ["Zimmerman", "Sam", ""], ["Raskar", "Ramesh", ""]]}, {"id": "2009.13302", "submitter": "Josimar Chire Saire", "authors": "Josimar Chire, Esteban Wilfredo Vilca Zuniga", "title": "Characterization of Covid-19 Dataset using Complex Networks and Image\n  Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to explore the structure of pattern behind covid-19 dataset.\nThe dataset includes medical images with positive and negative cases. A sample\nof 100 sample is chosen, 50 per each class. An histogram frequency is\ncalculated to get features using statistical measurements, besides a feature\nextraction using Grey Level Co-Occurrence Matrix (GLCM). Using both features\nare build Complex Networks respectively to analyze the adjacency matrices and\ncheck the presence of patterns. Initial experiments introduces the evidence of\nhidden patterns in the dataset for each class, which are visible using Complex\nNetworks representation.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 20:35:31 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Chire", "Josimar", ""], ["Zuniga", "Esteban Wilfredo Vilca", ""]]}, {"id": "2009.13375", "submitter": "Antonios Maronikolakis", "authors": "Antonis Maronikolakis, Hinrich Schutze, Mark Stevenson", "title": "Identifying Automatically Generated Headlines using Transformers", "comments": "NLP4IF 2021 Proceedings, NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  False information spread via the internet and social media influences public\nopinion and user activity, while generative models enable fake content to be\ngenerated faster and more cheaply than had previously been possible. In the not\nso distant future, identifying fake content generated by deep learning models\nwill play a key role in protecting users from misinformation. To this end, a\ndataset containing human and computer-generated headlines was created and a\nuser study indicated that humans were only able to identify the fake headlines\nin 47.8% of the cases. However, the most accurate automatic approach,\ntransformers, achieved an overall accuracy of 85.7%, indicating that content\ngenerated from language models can be filtered out accurately.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 14:48:27 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 11:52:01 GMT"}, {"version": "v3", "created": "Sun, 25 Apr 2021 09:39:20 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Maronikolakis", "Antonis", ""], ["Schutze", "Hinrich", ""], ["Stevenson", "Mark", ""]]}, {"id": "2009.13443", "submitter": "Mahmoud Yassien Shams El Den", "authors": "Amira. A. Elsonbaty and Mahmoud Shams", "title": "The Smart Parking Management System", "comments": "12 pages, 15 figures", "journal-ref": "International Journal of Computer Science & Information Technology\n  (IJCSIT) Vol 12, No 4, August 2020", "doi": "10.5121/ijcsit.2020.12405", "report-no": null, "categories": "cs.CY cs.AR cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With growing, Car parking increases with the number of car users. With the\nincreased use of smartphones and their applications, users prefer mobile\nphone-based solutions. This paper proposes the Smart Parking Management System\n(SPMS) that depends on Arduino parts, Android applications, and based on IoT.\nThis gave the client the ability to check available parking spaces and reserve\na parking spot. IR sensors are utilized to know if a car park space is allowed.\nIts area data are transmitted using the WI-FI module to the server and are\nrecovered by the mobile application which offers many options attractively and\nwith no cost to users and lets the user check reservation details. With IoT\ntechnology, the smart parking system can be connected wirelessly to easily\ntrack available locations.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 16:08:10 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Elsonbaty", "Amira. A.", ""], ["Shams", "Mahmoud", ""]]}, {"id": "2009.13626", "submitter": "Mohammad Arif Ul Alam", "authors": "Nandan Kulkarni, Christopher Compton, Jooseppi Luna, Mohammad Arif Ul\n  Alam", "title": "Monitoring My Dehydration: A Non-Invasive Dehydration Alert System Using\n  Electrodermal Activity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Staying hydrated and drinking fluids is extremely crucial to stay healthy and\nmaintaining even basic bodily functions. Studies have shown that dehydration\nleads to loss of productivity, cognitive impairment and mood in both men and\nwomen. However, there are no such an existing tool that can monitor dehydration\ncontinuously and provide alert to users before it affects on their health. In\nthis paper, we propose to utilize wearable Electrodermal Activity (EDA) sensors\nin conjunction with signal processing and machine learning techniques to\ndevelop first time ever a dehydration self-monitoring tool, \\emph{Monitoring My\nDehydration} (MMD), that can instantly detect the hydration level of human\nskin. Moreover, we develop an Android application over Bluetooth to connect\nwith wearable EDA sensor integrated wristband to track hydration levels of the\nusers real-time and instantly alert to the users when the hydration level goes\nbeyond the danger level. To validate our developed tool's performance, we\nrecruit 5 users, carefully designed the water intake routines to annotate the\ndehydration ground truth and trained state-of-art machine learning models to\npredict instant hydration level i.e., well-hydrated, hydrated, dehydrated and\nvery dehydrated. Our system provides an accuracy of 84.5% in estimating\ndehydration level with an sensitivity of 87.5% and a specificity of 90.3% which\nprovides us confidence of moving forward with our method for larger\nlongitudinal study.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 16:55:25 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Kulkarni", "Nandan", ""], ["Compton", "Christopher", ""], ["Luna", "Jooseppi", ""], ["Alam", "Mohammad Arif Ul", ""]]}, {"id": "2009.13650", "submitter": "Joseph Near", "authors": "Krystal Maughan, Joseph P. Near", "title": "Towards a Measure of Individual Fairness for Deep Learning", "comments": "Presented at MD4SG '20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has produced big advances in artificial intelligence, but\ntrained neural networks often reflect and amplify bias in their training data,\nand thus produce unfair predictions. We propose a novel measure of individual\nfairness, called prediction sensitivity, that approximates the extent to which\na particular prediction is dependent on a protected attribute. We show how to\ncompute prediction sensitivity using standard automatic differentiation\ncapabilities present in modern deep learning frameworks, and present\npreliminary empirical results suggesting that prediction sensitivity may be\neffective for measuring bias in individual predictions.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 21:53:21 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Maughan", "Krystal", ""], ["Near", "Joseph P.", ""]]}, {"id": "2009.13676", "submitter": "Mohamed Abdalla", "authors": "Mohamed Abdalla and Moustafa Abdalla", "title": "The Grey Hoodie Project: Big Tobacco, Big Tech, and the threat on\n  academic integrity", "comments": "Accepted to AIES-21", "journal-ref": null, "doi": "10.1145/3461702.3462563", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As governmental bodies rely on academics' expert advice to shape policy\nregarding Artificial Intelligence, it is important that these academics not\nhave conflicts of interests that may cloud or bias their judgement. Our work\nexplores how Big Tech can actively distort the academic landscape to suit its\nneeds. By comparing the well-studied actions of another industry (Big Tobacco)\nto the current actions of Big Tech we see similar strategies employed by both\nindustries. These strategies enable either industry to sway and influence\nacademic and public discourse. We examine the funding of academic research as a\ntool used by Big Tech to put forward a socially responsible public image,\ninfluence events hosted by and decisions made by funded universities, influence\nthe research questions and plans of individual scientists, and discover\nreceptive academics who can be leveraged. We demonstrate how Big Tech can\naffect academia from the institutional level down to individual researchers.\nThus, we believe that it is vital, particularly for universities and other\ninstitutions of higher learning, to discuss the appropriateness and the\ntradeoffs of accepting funding from Big Tech, and what limitations or\nconditions should be put in place.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 23:00:49 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 18:22:48 GMT"}, {"version": "v3", "created": "Mon, 4 Jan 2021 17:23:19 GMT"}, {"version": "v4", "created": "Tue, 27 Apr 2021 12:29:44 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Abdalla", "Mohamed", ""], ["Abdalla", "Moustafa", ""]]}, {"id": "2009.13871", "submitter": "Dario Garcia-Gasulla PhD", "authors": "Dario Garcia-Gasulla, Atia Cort\\'es, Sergio Alvarez-Napagao, Ulises\n  Cort\\'es", "title": "Signs for Ethical AI: A Route Towards Transparency", "comments": "27 pages, 7 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) has recently raised to the point where it has a\ndirect impact on the daily life of billions of people. This is the result of\nits application to sectors like finance, health, digital entertainment,\ntransportation, security and advertisement. Today, AI fuels some of the most\nsignificant economic and research institutions in the world, and the impact of\nAI in the near future seems difficult to predict or even bound. In contrast to\nall this power, society remains mostly ignorant of the capabilities,\nrequirements and standard practices of AI today. Society is becoming aware of\nthe dangers that come with that ignorance, and is rightfully asking for\nsolutions. To address this need, improving on current practices of interaction\nbetween people and AI systems, we propose a transparency scheme to be\nimplemented on any AI system open to the public. The scheme is based on two\nmain pillars: Data Privacy and AI Transparency. The first recognizes the\nrelevance of data for AI and is supported by GDPR, the most important\nlegislation on the topic. The second considers aspects of AI transparency yet\nto be regulated: AI capacity, purpose and source. Lacking legislation to build\nupon, we design this pillar based on fundamental ethical principles. For each\nof the two pillars, we define a three-level display. The first level is based\non visual signs, inspired by traffic signs managing the interaction between\npeople and cars, and designed for quick and universal interpretability. The\nsecond level uses a factsheet system, providing further detail while still\nabstracting the subject. The last level provides access to all available\ndetails. After detailing and exemplifying the proposed transparency scheme, we\ndefine a set of principles for creating transparent by design software, to be\nused during the integration of AI components on user-oriented services.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 08:49:44 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Garcia-Gasulla", "Dario", ""], ["Cort\u00e9s", "Atia", ""], ["Alvarez-Napagao", "Sergio", ""], ["Cort\u00e9s", "Ulises", ""]]}, {"id": "2009.13919", "submitter": "Alarith Uhde", "authors": "Holger Klapperich and Alarith Uhde and Marc Hassenzahl", "title": "Designing everyday automation with well-being in mind", "comments": "17 pages, 6 figures", "journal-ref": null, "doi": "10.1007/s00779-020-01452-w", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nowadays, automation not only permeates industry but also becomes a\nsubstantial part of our private, everyday lives. Driven by the idea of\nincreased convenience and more time for the \"important things in life,\"\nautomation relieves us from many daily chores - robots vacuum floors and\nautomated coffee makers produce supposedly barista-quality coffee on the press\nof a button. In many cases, these offers are embraced by people without further\nquestioning. However, while we save time by delegating more and more everyday\nactivities to automation, we also may lose chances for enjoyable and meaningful\nexperiences. In two field studies, we demonstrate that a manual process has\nexperiential benefits over more automated processes by using the example of\ncoffee-making. We present a way to account for potential experiential costs of\neveryday automation and strategies of how to design interaction with automation\nto reconcile experience with the advantages of a more and more powerful\nautomation.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 10:25:37 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Klapperich", "Holger", ""], ["Uhde", "Alarith", ""], ["Hassenzahl", "Marc", ""]]}, {"id": "2009.13929", "submitter": "Shahabodin Khadivizand", "authors": "Shahabodin Khadivi Zand", "title": "Towards Intelligent Risk-based Customer Segmentation in Banking", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Business Processes, i.e., a set of coordinated tasks and activities to\nachieve a business goal, and their continuous improvements are key to the\noperation of any organization. In banking, business processes are increasingly\ndynamic as various technologies have made dynamic processes more prevalent. For\nexample, customer segmentation, i.e., the process of grouping related customers\nbased on common activities and behaviors, could be a data-driven and\nknowledge-intensive process. In this paper, we present an intelligent\ndata-driven pipeline composed of a set of processing elements to move\ncustomers' data from one system to another, transforming the data into the\ncontextualized data and knowledge along the way. The goal is to present a novel\nintelligent customer segmentation process which automates the feature\nengineering, i.e., the process of using (banking) domain knowledge to extract\nfeatures from raw data via data mining techniques, in the banking domain. We\nadopt a typical scenario for analyzing customer transaction records, to\nhighlight how the presented approach can significantly improve the quality of\nrisk-based customer segmentation in the absence of feature engineering.As\nresult, our proposed method is able to achieve accuracy of 91% compared to\nclassical approaches in terms of detecting, identifying and classifying\ntransaction to the right classification.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 11:22:04 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Zand", "Shahabodin Khadivi", ""]]}, {"id": "2009.14258", "submitter": "Abeba Birhane", "authors": "Abeba Birhane, Olivia Guest", "title": "Towards decolonising computational sciences", "comments": "A version of this work will appear in the Danish Journal of Women,\n  Gender and Research (https://koensforskning.soc.ku.dk/english/kkof/) in\n  December 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article sets out our perspective on how to begin the journey of\ndecolonising computational fields, such as data and cognitive sciences. We see\nthis struggle as requiring two basic steps: a) realisation that the present-day\nsystem has inherited, and still enacts, hostile, conservative, and oppressive\nbehaviours and principles towards women of colour (WoC); and b) rejection of\nthe idea that centering individual people is a solution to system-level\nproblems. The longer we ignore these two steps, the more \"our\" academic system\nmaintains its toxic structure, excludes, and harms Black women and other\nminoritised groups. This also keeps the door open to discredited pseudoscience,\nlike eugenics and physiognomy. We propose that grappling with our fields'\nhistories and heritage holds the key to avoiding mistakes of the past. For\nexample, initiatives such as \"diversity boards\" can still be harmful because\nthey superficially appear reformatory but nonetheless center whiteness and\nmaintain the status quo. Building on the shoulders of many WoC's work, who have\nbeen paving the way, we hope to advance the dialogue required to build both a\ngrass-roots and a top-down re-imagining of computational sciences -- including\nbut not limited to psychology, neuroscience, cognitive science, computer\nscience, data science, statistics, machine learning, and artificial\nintelligence. We aspire for these fields to progress away from their stagnant,\nsexist, and racist shared past into carving and maintaining an ecosystem where\nboth a diverse demographics of researchers and scientific ideas that critically\nchallenge the status quo are welcomed.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 18:48:28 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Birhane", "Abeba", ""], ["Guest", "Olivia", ""]]}, {"id": "2009.14281", "submitter": "Giacomo Livan", "authors": "Sonja Tilly, Markus Ebner, Giacomo Livan", "title": "Macroeconomic forecasting through news, emotions and narrative", "comments": "12 pages, 2 figures, 9 tables", "journal-ref": "Expert Systems with Applications, Vol. 175 (2021)", "doi": "10.1016/j.eswa.2021.114760", "report-no": null, "categories": "cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study proposes a new method of incorporating emotions from newspaper\narticles into macroeconomic forecasts, attempting to forecast industrial\nproduction and consumer prices leveraging narrative and sentiment from global\nnewspapers. For the most part, existing research includes positive and negative\ntone only to improve macroeconomic forecasts, focusing predominantly on large\neconomies such as the US. These works use mainly anglophone sources of\nnarrative, thus not capturing the entire complexity of the multitude of\nemotions contained in global news articles. This study expands the existing\nbody of research by incorporating a wide array of emotions from newspapers\naround the world - extracted from the Global Database of Events, Language and\nTone (GDELT) - into macroeconomic forecasts. We present a thematic data\nfiltering methodology based on a bi-directional long short term memory neural\nnetwork (Bi-LSTM) for extracting emotion scores from GDELT and demonstrate its\neffectiveness by comparing results for filtered and unfiltered data. We model\nindustrial production and consumer prices across a diverse range of economies\nusing an autoregressive framework, and find that including emotions from global\nnewspapers significantly improves forecasts compared to three autoregressive\nbenchmark models. We complement our forecasts with an interpretability analysis\non distinct groups of emotions and find that emotions associated with happiness\nand anger have the strongest predictive power for the variables we predict.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 10:10:03 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 10:04:09 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Tilly", "Sonja", ""], ["Ebner", "Markus", ""], ["Livan", "Giacomo", ""]]}, {"id": "2009.14285", "submitter": "Manasi Mohandas", "authors": "Gaganjeet Reen, Manasi Mohandas and S Venkatesan", "title": "Decentralized Patient Centric e-Health Record Management System using\n  Blockchain and IPFS", "comments": null, "journal-ref": "2019 IEEE Conference on Information and Communication Technology,\n  Allahabad, India, 2019, pp. 1-7", "doi": "10.1109/CICT48419.2019.9066212", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic Health Records(EHR) are gaining a lot of popularity all over the\nworld. The current EHR systems however have their fair share of problems\nrelated to privacy and security. We have proposed a mechanism which provides a\nsolution to most of these problems. Using a permissioned Ethereum blockchain\nallows the hospitals and patients across the world to be connected to each\nother. Our mechanism uses a combination of symmetric and asymmetric key\ncryptography to ensure the secure storage and selective access of records. It\ngives patients full control over their health records and also allows them to\ngrant or revoke a hospital's access to his/her records. We have used IPFS(inter\nplanetary file system) to store records which has the advantage of being\ndistributed and ensures immutability of records. The proposed model also\nmaintains the statistics of diseases without violating the privacy of any\npatient.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 19:54:58 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Reen", "Gaganjeet", ""], ["Mohandas", "Manasi", ""], ["Venkatesan", "S", ""]]}, {"id": "2009.14313", "submitter": "Jonatas Santos De Souza J. S. de Souza", "authors": "Jonatas S. de Souza, Jair M. Abe, Luiz A. de Lima, Nilson A. de Souza", "title": "The General Law Principles for Protection the Personal Data and their\n  Importance", "comments": "12 pages, 5 figures, 7th International Conference on Computer\n  Science, Engineering and Information Technology (CSEIT 2020)", "journal-ref": "Computer Science & Information Technology (CS & IT), 2020", "doi": "10.5121/csit.2020.101110", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Rapid technological change and globalization have created new challenges when\nit comes to the protection and processing of personal data. In 2018, Brazil\npresented a new law that has the proposal to inform how personal data should be\ncollected and treated, to guarantee the security and integrity of the data\nholder. The purpose of this paper is to emphasize the principles of the General\nLaw on Personal Data Protection, informing real cases of leakage of personal\ndata and thus obtaining an understanding of the importance of gains that meet\nthe interests of Internet users on the subject and its benefits to the entire\nBrazilian society.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 21:28:14 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["de Souza", "Jonatas S.", ""], ["Abe", "Jair M.", ""], ["de Lima", "Luiz A.", ""], ["de Souza", "Nilson A.", ""]]}, {"id": "2009.14330", "submitter": "Ha Dao", "authors": "Ha Dao, Kensuke Fukuda", "title": "A machine learning approach for detecting CNAME cloaking-based tracking\n  on the Web", "comments": "This paper is going to be published in IEEE Globecom 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various in-browser privacy protection techniques have been designed to\nprotect end-users from third-party tracking. In an arms race against these\ncounter-measures, the tracking providers developed a new technique called CNAME\ncloaking based tracking to avoid issues with browsers that block third-party\ncookies and requests. To detect this tracking technique, browser extensions\nrequire on-demand DNS lookup APIs. This feature is however only supported by\nthe Firefox browser.\n  In this paper, we propose a supervised machine learning-based method to\ndetect CNAME cloaking-based tracking without the on-demand DNS lookup. Our goal\nis to detect both sites and requests linked to CNAME cloaking-related tracking.\nWe crawl a list of target sites and store all HTTP/HTTPS requests with their\nattributes. Then we label all instances automatically by looking up CNAME\nrecord of subdomain, and applying wildcard matching based on well-known\ntracking filter lists. After extracting features, we build a supervised\nclassification model to distinguish site and request related to CNAME\ncloaking-based tracking. Our evaluation shows that the proposed approach\noutperforms well-known tracking filter lists: F1 scores of 0.790 for sites and\n0.885 for requests. By analyzing the feature permutation importance, we\ndemonstrate that the number of scripts and the proportion of XMLHttpRequests\nare discriminative for detecting sites, and the length of URL request is\nhelpful in detecting requests. Finally, we analyze concept drift by using the\n2018 dataset to train a model and obtain a reasonable performance on the 2020\ndataset for detecting both sites and requests using CNAME cloaking-based\ntracking.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 22:33:19 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Dao", "Ha", ""], ["Fukuda", "Kensuke", ""]]}, {"id": "2009.14361", "submitter": "Angus Addlesee", "authors": "Angus Addlesee and Pierre Albert", "title": "Ethically Collecting Multi-Modal Spontaneous Conversations with People\n  that have Cognitive Impairments", "comments": "Published at LREC's Workshop on Legal and Ethical Issues in Human\n  Language Technologies 2020", "journal-ref": "LREC Workshop on Legal and Ethical Issues in Human Language\n  Technologies (2020) 15-20", "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to make spoken dialogue systems (such as Amazon Alexa or Google\nAssistant) more accessible and naturally interactive for people with cognitive\nimpairments, appropriate data must be obtainable. Recordings of multi-modal\nspontaneous conversations with vulnerable user groups are scarce however and\nthis valuable data is challenging to collect. Researchers that call for this\ndata are commonly inexperienced in ethical and legal issues around working with\nvulnerable participants. Additionally, standard recording equipment is insecure\nand should not be used to capture sensitive data. We spent a year consulting\nexperts on how to ethically capture and share recordings of multi-modal\nspontaneous conversations with vulnerable user groups. In this paper we provide\nguidance, collated from these experts, on how to ethically collect such data\nand we present a new system - \"CUSCO\" - to capture, transport and exchange\nsensitive data securely. This framework is intended to be easily followed and\nimplemented to encourage further publications of similar corpora. Using this\nguide and secure recording system, researchers can review and refine their\nethical measures.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 00:57:33 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Addlesee", "Angus", ""], ["Albert", "Pierre", ""]]}, {"id": "2009.14605", "submitter": "Sundong Kim", "authors": "Yuan Yuan and Muzhi Guan and Zhilun Zhou and Sundong Kim and Meeyoung\n  Cha and Depeng Jin and Yong Li", "title": "Disruption in the Chinese E-Commerce During COVID-19", "comments": "10 pages, 7 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The recent outbreak of the novel coronavirus (COVID-19) has infected millions\nof citizens worldwide and claimed many lives. This paper examines its impact on\nthe Chinese e-commerce market by analyzing behavioral changes seen from a large\nonline shopping platform. We first conduct a time series analysis to identify\nproduct categories that faced the most extensive disruptions. The time-lagged\nanalysis shows that behavioral patterns seen in shopping actions are highly\nresponsive to epidemic development. Based on these findings, we present a\nconsumer demand prediction method by encompassing the epidemic statistics and\nbehavioral features for COVID-19 related products. Experiment results\ndemonstrate that our predictions outperform existing baselines and further\nextend to the long-term and province-level forecasts. We discuss how our market\nanalysis and prediction can help better prepare for future pandemics by gaining\nan extra time to launch preventive steps.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 01:28:26 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 14:17:52 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Yuan", "Yuan", ""], ["Guan", "Muzhi", ""], ["Zhou", "Zhilun", ""], ["Kim", "Sundong", ""], ["Cha", "Meeyoung", ""], ["Jin", "Depeng", ""], ["Li", "Yong", ""]]}, {"id": "2009.14620", "submitter": "Lance Eliot", "authors": "Lance Eliot", "title": "Legal Judgment Prediction (LJP) Amid the Advent of Autonomous AI Legal\n  Reasoning", "comments": "39 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Legal Judgment Prediction (LJP) is a longstanding and open topic in the\ntheory and practice-of-law. Predicting the nature and outcomes of judicial\nmatters is abundantly warranted, keenly sought, and vigorously pursued by those\nwithin the legal industry and also by society as a whole. The tenuous act of\ngenerating judicially laden predictions has been limited in utility and\nexactitude, requiring further advancement. Various methods and techniques to\npredict legal cases and judicial actions have emerged over time, especially\narising via the advent of computer-based modeling. There has been a wide range\nof approaches attempted, including simple calculative methods to highly\nsophisticated and complex statistical models. Artificial Intelligence (AI)\nbased approaches have also been increasingly utilized. In this paper, a review\nof the literature encompassing Legal Judgment Prediction is undertaken, along\nwith innovatively proposing that the advent of AI Legal Reasoning (AILR) will\nhave a pronounced impact on how LJP is performed and its predictive accuracy.\nLegal Judgment Prediction is particularly examined using the Levels of Autonomy\n(LoA) of AI Legal Reasoning, plus, other considerations are explored including\nLJP probabilistic tendencies, biases handling, actor predictors, transparency,\njudicial reliance, legal case outcomes, and other crucial elements entailing\nthe overarching legal judicial milieu.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 00:12:42 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Eliot", "Lance", ""]]}, {"id": "2009.14675", "submitter": "Sarah LaRocca", "authors": "Neta Barkay, Curtiss Cobb, Roee Eilat, Tal Galili, Daniel Haimovich,\n  Sarah LaRocca, Katherine Morris, Tal Sarig", "title": "Weights and Methodology Brief for the COVID-19 Symptom Survey by\n  University of Maryland and Carnegie Mellon University, in Partnership with\n  Facebook", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Facebook is partnering with academic institutions to support COVID-19\nresearch. Currently, we are inviting Facebook app users in the United States to\ntake a survey collected by faculty at Carnegie Mellon University (CMU) Delphi\nResearch Center, and we are inviting Facebook app users in more than 200\ncountries or territories globally to take a survey collected by faculty at the\nUniversity of Maryland (UMD) Joint Program in Survey Methodology (JPSM). As\npart of this initiative, we are applying best practices from survey statistics\nto design and execute two components: (1) sampling design and (2) survey\nweights, which make the sample more representative of the general population.\nThis paper describes the methods we used in these efforts in order to allow\ndata users to execute their analyses using the weights.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 21:50:22 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 15:34:09 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Barkay", "Neta", ""], ["Cobb", "Curtiss", ""], ["Eilat", "Roee", ""], ["Galili", "Tal", ""], ["Haimovich", "Daniel", ""], ["LaRocca", "Sarah", ""], ["Morris", "Katherine", ""], ["Sarig", "Tal", ""]]}]