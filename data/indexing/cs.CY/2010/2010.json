[{"id": "2010.00092", "submitter": "Nikhil Vadgama", "authors": "Nikhil Vadgama, Paolo Tasca", "title": "An Analysis of Blockchain Adoption in Supply Chains Between 2010 and\n  2020", "comments": "20 pages, 11 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this research, the evolution of Distributed Ledger Technology (DLT) in\nsupply chains has been mapped from the inception of the technology until June\n2020, utilising primarily public data sources. Two hundred seventy-one\nblockchain projects operating in the supply chain have been analysed on\nparameters such as their inception dates, types of blockchain, stages reached,\nsectors applied to and type of organisation that founded the project. We\nconfirm generally understood trends in the blockchain market with the creation\nof projects following the general hype and funding levels in the industry. We\nobserve most activity in the Agriculture/Grocery sector and the\nFreight/Logistics sector. We see the shift of market interest from primarily\nprivate companies (startups) to public companies and consortia and the change\nin blockchain adoption from Ethereum to Hyperledger. Finally, we observe higher\nsuccess and lower failure rates for Hyperledger-based projects in comparison to\nEthereum-based projects.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 20:18:09 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Vadgama", "Nikhil", ""], ["Tasca", "Paolo", ""]]}, {"id": "2010.00358", "submitter": "Jose Berengueres Ph.D", "authors": "Jose Berengueres, Pavel Nesterov", "title": "A Survey of H-index, Stress, Tenure & Reference Management software use\n  in Academia", "comments": "IEEE Bigdata2020", "journal-ref": "IEEE Bigdata2020", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the findings of a survey that covered the topics of stress,\ncitation tool use habits, subjective happiness, h-index, research topic and\ntenure among a sample of 2286 authors of arxiv.org. Ph.D. students report the\nlowest subjective happiness score among all faculty roles, while tenured\nfaculty report the highest. Tenured faculty report the lowest levels of stress.\nUndergraduate and graduate students report the highest levels of stress.\nNon-tenured faculty report stress similar to postdocs. No association between\ncitation management tool usage and h-index was found. The average age at tenure\nstart is 34.9 years. In addition, no significant association between stress\nlevels and the research topic was found\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 12:44:37 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 10:46:08 GMT"}, {"version": "v3", "created": "Tue, 6 Oct 2020 12:32:33 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Berengueres", "Jose", ""], ["Nesterov", "Pavel", ""]]}, {"id": "2010.00543", "submitter": "Raj Shekhar", "authors": "Raj Shekhar (Institute of Public Policy, National Law School of India\n  University, Bengaluru)", "title": "Artificial Creations: Ascription, Ownership, Time-Specific Monopolies", "comments": "47 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creativity has always been synonymous with humans. No other living species\ncould boast of creativity as humans could. Even the smartest computers thrived\nonly on the ingenious imaginations of its coders. However, that is steadily\nchanging with highly advanced artificially intelligent systems that demonstrate\nincredible capabilities to autonomously (i.e., with minimal or no human input)\nproduce creative products that would ordinarily deserve intellectual property\nstatus if created by a human. These systems could be called artificial creators\nand their creative products artificial creations. The use of artificial\ncreators is likely to become a part of mainstream production practices in the\ncreative and innovation industries sooner than we realize. When they do,\nintellectual property regimes (that are inherently designed to reward human\ncreativity) must be sufficiently prepared to aptly respond to the phenomenon of\nwhat could be called artificial creativity. Needless to say, any such response\nmust be guided by considerations of public welfare. This study analyzes what\nthat response ought to look like by revisiting the determinants of intellectual\nproperty and critiquing its nature and modes. This understanding of\nintellectual property is then applied to investigate the determinants of\nintellectual property in artificial creations so as to determine the intrinsic\njustifications for intellectual property rewards for artificial creativity, and\naccordingly, develop general modalities for granting intellectual property\nstatus to artificial creations. Finally, the treatment of artificial works\n(i.e., copyrightable artificial creations) and artificial inventions (i.e.,\npatentable artificial creations) by current intellectual property regimes is\ncritiqued, and specific modalities for granting intellectual property status to\nartificial works and artificial inventions are developed.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 16:57:40 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Shekhar", "Raj", "", "Institute of Public Policy, National Law School of India\n  University, Bengaluru"]]}, {"id": "2010.00544", "submitter": "Imani Sherman", "authors": "Imani N. Sherman, Elissa M. Redmiles, Jack W. Stokes", "title": "Designing Indicators to Combat Fake Media", "comments": "26 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growth of misinformation technology necessitates the need to identify\nfake videos. One approach to preventing the consumption of these fake videos is\nprovenance which allows the user to authenticate media content to its original\nsource. This research designs and investigates the use of provenance indicators\nto help users identify fake videos. We first interview users regarding their\nexperiences with different misinformation modes (text, image, video) to guide\nthe design of indicators within users' existing perspectives. Then, we conduct\na participatory design study to develop and design fake video indicators.\nFinally, we evaluate participant-designed indicators via both expert\nevaluations and quantitative surveys with a large group of end-users. Our\nresults provide concrete design guidelines for the emerging issue of fake\nvideos. Our findings also raise concerns regarding users' tendency to\novergeneralize from misinformation warning messages, suggesting the need for\nfurther research on warning design in the ongoing fight against misinformation.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 16:58:12 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Sherman", "Imani N.", ""], ["Redmiles", "Elissa M.", ""], ["Stokes", "Jack W.", ""]]}, {"id": "2010.00590", "submitter": "Isaac Waller", "authors": "Isaac Waller and Ashton Anderson", "title": "Quantifying social organization and political polarization in online\n  platforms", "comments": "43 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimism about the Internet's potential to bring the world together has been\ntempered by concerns about its role in inflaming the 'culture wars'. Via mass\nselection into like-minded groups, online society may be becoming more\nfragmented and polarized, particularly with respect to partisan differences.\nHowever, our ability to measure the social makeup of online communities, and in\nturn understand the social organization of online platforms, is limited by the\npseudonymous, unstructured, and large-scale nature of digital discussion. We\ndevelop a neural embedding methodology to quantify the positioning of online\ncommunities along social dimensions by leveraging large-scale patterns of\naggregate behaviour. Applying our methodology to 5.1B Reddit comments made in\n10K communities over 14 years, we measure how the macroscale community\nstructure is organized with respect to age, gender, and U.S. political\npartisanship. Examining political content, we find Reddit underwent a\nsignificant polarization event around the 2016 U.S. presidential election, and\nremained highly polarized for years afterward. Contrary to conventional wisdom,\nhowever, individual-level polarization is rare; the system-level shift in 2016\nwas disproportionately driven by the arrival of new and newly political users.\nPolitical polarization on Reddit is unrelated to previous activity on the\nplatform, and is instead temporally aligned with external events. We also\nobserve a stark ideological asymmetry, with the sharp increase in 2016 being\nentirely attributable to changes in right-wing activity. Our methodology is\nbroadly applicable to the study of online interaction, and our findings have\nimplications for the design of online platforms, understanding the social\ncontexts of online behaviour, and quantifying the dynamics and mechanisms of\nonline polarization.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 17:59:40 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 00:58:42 GMT"}, {"version": "v3", "created": "Tue, 27 Jul 2021 22:15:43 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Waller", "Isaac", ""], ["Anderson", "Ashton", ""]]}, {"id": "2010.00624", "submitter": "Xavier-Lewis Palmer", "authors": "Lucas Potter, Orlando Ayala, and Xavier-Lewis Palmer", "title": "Biocybersecurity -- A Converging Threat as an Auxiliary to War", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biodefense is the discipline of ensuring biosecurity with respect to select\ngroups of organisms and limiting their spread. This field has increasingly been\nchallenged by novel threats from nature that have been weaponized such as SARS,\nAnthrax, and similar pathogens, but has emerged victorious through\ncollaboration of national and world health groups. However, it may come under\nadditional stress in the 21st century as the field intersects with the\ncyberworld -- a world where governments have already been struggling to keep up\nwith cyber attacks from small to state-level actors as cyberthreats have been\nrelied on to level the playing field in international disputes. Disruptions to\nmilitary logistics and economies through cyberattacks have been able to be done\nat a mere fraction of economic and moral costs through conventional military\nmeans, making it an increasingly tempting means of disruption. In the field of\nbiocybersecurity (BCS), the strengths within biotechnology and cybersecurity\nmerge, along with many of their vulnerabilities, and this could spell increased\ntrouble for biodefense, as novel threats can be synthesized and disseminated in\nways that fuse the routes of attacks seen in biosecurity and cybersecurity.\nHerein, we offer an exploration of how threats in the domain of\nbiocybersecurity may emerge through less foreseen routes as it might be an\nattractive auxiliary to conventional war. This is done through an analysis of\npotential payload and delivery methods to develop notional threat\nvectorizations. We conclude with several paradigms through which to view\nBCS-based threats.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 18:07:16 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Potter", "Lucas", ""], ["Ayala", "Orlando", ""], ["Palmer", "Xavier-Lewis", ""]]}, {"id": "2010.00643", "submitter": "Mohammad Javad Shayegan", "authors": "Mohammad Javad Shayegan, Mohadese Valizadeh", "title": "A Recommender System based on the analysis of personality traits in\n  Telegram social network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accessing people's personality traits has always been a challenging task. On\nthe other hand, acquiring personality traits based on behavioral data is one of\nthe growing interest of human beings. Numerous researches showed that people\nspend a large amount of time on social networks and show behaviors that create\nsome personality patterns in cyberspace. One of these social networks that have\nbeen widely welcomed in some countries, including Iran, is Telegram. The basis\nof this research is automatically identifying users' personalities based on\ntheir behavior on Telegram. For this purpose, messages from Telegram group\nusers are extracted, and then the personality traits of each member according\nto the NEO Personality Inventory are identified. For personality analysis, the\nstudy is employed three approaches, including; Cosine Similarity, Bayes, and\nMLP algorithms. Finally, this study provides a recommender system that uses the\nCosine similarity algorithm to explore and recommend relevant Telegram channels\nto members according to the extracted personalities. The results show a 65.42%\nsatisfaction rate for the recommender system based on the proposed personality\nanalysis.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 19:01:29 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Shayegan", "Mohammad Javad", ""], ["Valizadeh", "Mohadese", ""]]}, {"id": "2010.00678", "submitter": "Yan Shvartzshnaider", "authors": "Yan Shvartzshnaider, Ananth Balashankar, Vikas Patidar, Thomas Wies,\n  Lakshminarayanan Subramanian", "title": "Beyond The Text: Analysis of Privacy Statements through Syntactic and\n  Semantic Role Labeling", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper formulates a new task of extracting privacy parameters from a\nprivacy policy, through the lens of Contextual Integrity, an established social\ntheory framework for reasoning about privacy norms. Privacy policies, written\nby lawyers, are lengthy and often comprise incomplete and vague statements. In\nthis paper, we show that traditional NLP tasks, including the recently proposed\nQuestion-Answering based solutions, are insufficient to address the privacy\nparameter extraction problem and provide poor precision and recall. We describe\n4 different types of conventional methods that can be partially adapted to\naddress the parameter extraction task with varying degrees of success: Hidden\nMarkov Models, BERT fine-tuned models, Dependency Type Parsing (DP) and\nSemantic Role Labeling (SRL). Based on a detailed evaluation across 36\nreal-world privacy policies of major enterprises, we demonstrate that a\nsolution combining syntactic DP coupled with type-specific SRL tasks provides\nthe highest accuracy for retrieving contextual privacy parameters from privacy\nstatements. We also observe that incorporating domain-specific knowledge is\ncritical to achieving high precision and recall, thus inspiring new NLP\nresearch to address this important problem in the privacy domain.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 20:48:37 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Shvartzshnaider", "Yan", ""], ["Balashankar", "Ananth", ""], ["Patidar", "Vikas", ""], ["Wies", "Thomas", ""], ["Subramanian", "Lakshminarayanan", ""]]}, {"id": "2010.00753", "submitter": "Kate Donahue", "authors": "Kate Donahue and Jon Kleinberg", "title": "Model-sharing Games: Analyzing Federated Learning Under Voluntary\n  Participation", "comments": "Accepted at AAAI 2021. Supplemental code at\n  https://github.com/kpdonahue/model_sharing_games", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CY cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a setting where agents, each with access to their own\ndata source, combine models from local data to create a global model. If agents\nare drawing their data from different distributions, though, federated learning\nmight produce a biased global model that is not optimal for each agent. This\nmeans that agents face a fundamental question: should they choose the global\nmodel or their local model? We show how this situation can be naturally\nanalyzed through the framework of coalitional game theory.\n  We propose the following game: there are heterogeneous players with different\nmodel parameters governing their data distribution and different amounts of\ndata they have noisily drawn from their own distribution. Each player's goal is\nto obtain a model with minimal expected mean squared error (MSE) on their own\ndistribution. They have a choice of fitting a model based solely on their own\ndata, or combining their learned parameters with those of some subset of the\nother players. Combining models reduces the variance component of their error\nthrough access to more data, but increases the bias because of the\nheterogeneity of distributions.\n  Here, we derive exact expected MSE values for problems in linear regression\nand mean estimation. We then analyze the resulting game in the framework of\nhedonic game theory; we study how players might divide into coalitions, where\neach set of players within a coalition jointly construct model(s). We analyze\nthree methods of federation, modeling differing degrees of customization. In\nuniform federation, the agents collectively produce a single model. In\ncoarse-grained federation, each agent can weight the global model together with\ntheir local model. In fine-grained federation, each agent can flexibly combine\nmodels from all other agents in the federation. For each method, we analyze the\nstable partitions of players into coalitions.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 02:36:23 GMT"}, {"version": "v2", "created": "Sun, 18 Oct 2020 13:53:39 GMT"}, {"version": "v3", "created": "Thu, 17 Dec 2020 14:41:56 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Donahue", "Kate", ""], ["Kleinberg", "Jon", ""]]}, {"id": "2010.00822", "submitter": "Denae Ford", "authors": "Gede Artha Azriadi Prana, Denae Ford, Ayushi Rastogi, David Lo, Rahul\n  Purandare, Nachiappan Nagappan", "title": "Including Everyone, Everywhere: Understanding Opportunities and\n  Challenges of Geographic Gender-Inclusion in OSS", "comments": "13 pages, 13 tables, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The gender gap is a significant concern facing the software industry as the\ndevelopment becomes more geographically distributed. Widely shared reports\nindicate that gender differences may be specific to each country. However, how\ncomplete can these reports be with little to no research reflective of the Open\nSource Software (OSS) process and communities software is now commonly\ndeveloped in? Our study presents a multi-region geographical analysis of gender\ninclusion on GitHub. This mixed-methods approach includes quantitatively\ninvestigating differences in gender inclusion in projects across geographic\nregions and investigate these trends over time using data from contributions to\n21,456 project repositories. We also qualitatively understand the unique\nexperiences of developers contributing to these projects through strategically\ntargeted surveys. Our findings indicate that there are statistically\nsignificant differences in gender diversity between regions. Since 2014, there\nhas been a small and statistically significant improvement of gender diversity\namong software project contributors in Northern America and South-Eastern Asia\nbut negligible change elsewhere. We also find that most motivations and\nbarriers to contributions (e.g. lack of resources to contribute and poor\nworking environment) were shared across regions, however, some insightful\ndifferences, such as how to make projects more inclusive, did arise. From these\nfindings, we derive and present implications for tools that can foster\ninclusion in open source software communities and empower contributions from\neveryone, everywhere.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 07:40:43 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Prana", "Gede Artha Azriadi", ""], ["Ford", "Denae", ""], ["Rastogi", "Ayushi", ""], ["Lo", "David", ""], ["Purandare", "Rahul", ""], ["Nagappan", "Nachiappan", ""]]}, {"id": "2010.00883", "submitter": "Carlos Gaete", "authors": "Carlos Gaete-Morales, Martin Kittel, Alexander Roth and Wolf-Peter\n  Schill", "title": "DIETERpy: a Python framework for The Dispatch and Investment Evaluation\n  Tool with Endogenous Renewables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY physics.soc-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  DIETER is an open-source power sector model designed to analyze future\nsettings with very high shares of variable renewable energy sources. It\nminimizes overall system costs, including fixed and variable costs of various\ngeneration, flexibility and sector coupling options. Here we introduce DIETERpy\nthat builds on the existing model version, written in the General Algebraic\nModeling System (GAMS), and enhances it with a Python framework. This combines\nthe flexibility of Python regarding pre- and post-processing of data with a\nstraightforward algebraic formulation in GAMS and the use of efficient solvers.\nDIETERpy also offers a browser-based graphical user interface. The new\nframework is designed to be easily accessible as it enables users to run the\nmodel, alter its configuration, and define numerous scenarios without a deeper\nknowledge of GAMS. Code, data, and manuals are available in public repositories\nunder permissive licenses for transparency and reproducibility.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 09:27:33 GMT"}, {"version": "v2", "created": "Wed, 7 Apr 2021 14:18:58 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Gaete-Morales", "Carlos", ""], ["Kittel", "Martin", ""], ["Roth", "Alexander", ""], ["Schill", "Wolf-Peter", ""]]}, {"id": "2010.01031", "submitter": "Xiao Fan Liu", "authors": "Xiao Fan Liu, Xin-Jian Jiang, Si-Hao Liu, Chi Kong Tse", "title": "Knowledge Discovery in Cryptocurrency Transactions: A Survey", "comments": "60 pages, 217 refs, 6 tables, and 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryptocurrencies gain trust in users by publicly disclosing the full creation\nand transaction history. In return, the transaction history faithfully records\nthe whole spectrum of cryptocurrency user behaviors. This article analyzes and\nsummarizes the existing research on knowledge discovery in the cryptocurrency\ntransactions using data mining techniques. Specifically, we classify the\nexisting research into three aspects, i.e., transaction tracings and blockchain\naddress linking, the analyses of collective user behaviors, and the study of\nindividual user behaviors. For each aspect, we present the problems, summarize\nthe methodologies, and discuss major findings in the literature. Furthermore,\nan enumeration of transaction data parsing and visualization tools and services\nis also provided. Finally, we outline several future directions in this\nresearch area, such as the current rapid development of Decentralized Finance\n(De-Fi) and digital fiat money.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 14:38:08 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Liu", "Xiao Fan", ""], ["Jiang", "Xin-Jian", ""], ["Liu", "Si-Hao", ""], ["Tse", "Chi Kong", ""]]}, {"id": "2010.01101", "submitter": "Aria Khademi", "authors": "Christopher Seto and Aria Khademi and Corina Graif and Vasant G.\n  Honavar", "title": "Commuting Network Spillovers and COVID-19 Deaths Across US Counties", "comments": "Accepted for Presentation at The Population Association of America\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CY cs.LG q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study explored how population mobility flows form commuting networks\nacross US counties and influence the spread of COVID-19. We utilized 3-level\nmixed effects negative binomial regression models to estimate the impact of\nnetwork COVID-19 exposure on county confirmed cases and deaths over time. We\nalso conducted weighting-based analyses to estimate the causal effect of\nnetwork exposure. Results showed that commuting networks matter for COVID-19\ndeaths and cases, net of spatial proximity, socioeconomic, and demographic\nfactors. Different local racial and ethnic concentrations are also associated\nwith unequal outcomes. These findings suggest that commuting is an important\ncausal mechanism in the spread of COVID-19 and highlight the significance of\ninterconnected of communities. The results suggest that local level mitigation\nand prevention efforts are more effective when complemented by similar efforts\nin the network of connected places. Implications for research on inequality in\nhealth and flexible work arrangements are discussed.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 16:57:34 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 19:52:35 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Seto", "Christopher", ""], ["Khademi", "Aria", ""], ["Graif", "Corina", ""], ["Honavar", "Vasant G.", ""]]}, {"id": "2010.01309", "submitter": "Amirmohammad Kazemeini", "authors": "Amirmohammad Kazameini, Samin Fatehi, Yash Mehta, Sauleh Eetemadi,\n  Erik Cambria", "title": "Personality Trait Detection Using Bagged SVM over BERT Word Embedding\n  Ensembles", "comments": null, "journal-ref": "Proceedings of the The Fourth Widening Natural Language Processing\n  Workshop (2020)", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the automatic prediction of personality traits has received\nincreasing attention and has emerged as a hot topic within the field of\naffective computing. In this work, we present a novel deep learning-based\napproach for automated personality detection from text. We leverage state of\nthe art advances in natural language understanding, namely the BERT language\nmodel to extract contextualized word embeddings from textual data for automated\nauthor personality detection. Our primary goal is to develop a computationally\nefficient, high-performance personality prediction model which can be easily\nused by a large number of people without access to huge computation resources.\nOur extensive experiments with this ideology in mind, led us to develop a novel\nmodel which feeds contextualized embeddings along with psycholinguistic\nfeatures toa Bagged-SVM classifier for personality trait prediction. Our model\noutperforms the previous state of the art by 1.04% and, at the same time is\nsignificantly more computationally efficient to train. We report our results on\nthe famous gold standard Essays dataset for personality detection.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 09:25:51 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Kazameini", "Amirmohammad", ""], ["Fatehi", "Samin", ""], ["Mehta", "Yash", ""], ["Eetemadi", "Sauleh", ""], ["Cambria", "Erik", ""]]}, {"id": "2010.01414", "submitter": "Yassine Himeur", "authors": "Yassine Himeur and Abdullah Alsalemi and Faycal Bensaali and Abbes\n  Amira", "title": "Appliance identification using a histogram post-processing of 2D local\n  binary patterns for smart grid applications", "comments": "8 pages, 10 figures and 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying domestic appliances in the smart grid leads to a better power\nusage management and further helps in detecting appliance-level abnormalities.\nAn efficient identification can be achieved only if a robust feature extraction\nscheme is developed with a high ability to discriminate between different\nappliances on the smart grid. Accordingly, we propose in this paper a novel\nmethod to extract electrical power signatures after transforming the power\nsignal to 2D space, which has more encoding possibilities. Following, an\nimproved local binary patterns (LBP) is proposed that relies on improving the\ndiscriminative ability of conventional LBP using a post-processing stage. A\nbinarized eigenvalue map (BEVM) is extracted from the 2D power matrix and then\nused to post-process the generated LBP representation. Next, two histograms are\nconstructed, namely up and down histograms, and are then concatenated to form\nthe global histogram. A comprehensive performance evaluation is performed on\ntwo different datasets, namely the GREEND and WITHED, in which power data were\ncollected at 1 Hz and 44000 Hz sampling rates, respectively. The obtained\nresults revealed the superiority of the proposed LBP-BEVM based system in terms\nof the identification performance versus other 2D descriptors and existing\nidentification frameworks.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 19:23:30 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Himeur", "Yassine", ""], ["Alsalemi", "Abdullah", ""], ["Bensaali", "Faycal", ""], ["Amira", "Abbes", ""]]}, {"id": "2010.01462", "submitter": "Dimitar Nikolov", "authors": "Dimitar Nikolov, Alessandro Flammini, Filippo Menczer", "title": "Right and left, partisanship predicts (asymmetric) vulnerability to\n  misinformation", "comments": null, "journal-ref": "Harvard Kennedy School Misinformation Review, Volume 1, Issue 7,\n  2021", "doi": "10.37016/mr-2020-55", "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the relationship between partisanship, echo chambers, and\nvulnerability to online misinformation by studying news sharing behavior on\nTwitter. While our results confirm prior findings that online misinformation\nsharing is strongly correlated with right-leaning partisanship, we also uncover\na similar, though weaker trend among left-leaning users. Because of the\ncorrelation between a user's partisanship and their position within a partisan\necho chamber, these types of influence are confounded. To disentangle their\neffects, we perform a regression analysis and find that vulnerability to\nmisinformation is most strongly influenced by partisanship for both left- and\nright-leaning users.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 01:36:14 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2021 13:55:23 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Nikolov", "Dimitar", ""], ["Flammini", "Alessandro", ""], ["Menczer", "Filippo", ""]]}, {"id": "2010.01497", "submitter": "Shehroze Farooqi", "authors": "Shehroze Farooqi, \\'Alvaro Feal, Tobias Lauinger, Damon McCoy, Zubair\n  Shafiq, Narseo Vallina-Rodriguez", "title": "Understanding Incentivized Mobile App Installs on Google Play Store", "comments": null, "journal-ref": "ACM Internet Measurement Conference (2020)", "doi": "10.1145/3419394.3423662", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Incentivized\" advertising platforms allow mobile app developers to acquire\nnew users by directly paying users to install and engage with mobile apps\n(e.g., create an account, make in-app purchases). Incentivized installs are\nbanned by the Apple App Store and discouraged by the Google Play Store because\nthey can manipulate app store metrics (e.g., install counts, appearance in top\ncharts). Yet, many organizations still offer incentivized install services for\nAndroid apps. In this paper, we present the first study to understand the\necosystem of incentivized mobile app install campaigns in Android and its\nbroader ramifications through a series of measurements. We identify\nincentivized install campaigns that require users to install an app and perform\nin-app tasks targeting manipulation of a wide variety of user engagement\nmetrics (e.g., daily active users, user session lengths) and revenue. Our\nresults suggest that these artificially inflated metrics can be effective in\nimproving app store metrics as well as helping mobile app developers to attract\nfunding from venture capitalists. Our study also indicates lax enforcement of\nthe Google Play Store's existing policies to prevent these behaviors. It\nfurther motivates the need for stricter policing of incentivized install\ncampaigns. Our proposed measurements can also be leveraged by the Google Play\nStore to identify potential policy violations.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 07:27:28 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Farooqi", "Shehroze", ""], ["Feal", "\u00c1lvaro", ""], ["Lauinger", "Tobias", ""], ["McCoy", "Damon", ""], ["Shafiq", "Zubair", ""], ["Vallina-Rodriguez", "Narseo", ""]]}, {"id": "2010.01662", "submitter": "Hancheng Cao", "authors": "Zhilong Chen, Hancheng Cao, Yuting Deng, Xuan Gao, Jinghua Piao,\n  Fengli Xu, Yu Zhang, Yong Li", "title": "Learning from Home: A Mixed-Methods Analysis of Live Streaming Based\n  Remote Education Experience in Chinese Colleges During the COVID-19 Pandemic", "comments": "Zhilong Chen and Hancheng Cao contribute equally to this work;\n  Accepted to CHI 2021", "journal-ref": null, "doi": "10.1145/3411764.3445428", "report-no": null, "categories": "cs.CY cs.HC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 global pandemic and resulted lockdown policies have forced\neducation in nearly every country to switch from a traditional co-located\nparadigm to a pure online 'distance learning from home' paradigm. Lying in the\ncenter of this learning paradigm shift is the emergence and wide adoption of\ndistance communication tools and live streaming platforms for education. Here,\nwe present a mixed-methods study on live streaming based education experience\nduring the COVID-19 pandemic. We focus our analysis on Chinese higher\neducation, carried out semi-structured interviews on 30 students, and 7\ninstructors from diverse colleges and disciplines, meanwhile launched a\nlarge-scale survey covering 6291 students and 1160 instructors in one leading\nChinese university. Our study not only reveals important design guidelines and\ninsights to better support current remote learning experience during the\npandemic, but also provides valuable implications towards constructing future\ncollaborative education supporting systems and experience after pandemic.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 19:14:09 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2021 05:33:16 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Chen", "Zhilong", ""], ["Cao", "Hancheng", ""], ["Deng", "Yuting", ""], ["Gao", "Xuan", ""], ["Piao", "Jinghua", ""], ["Xu", "Fengli", ""], ["Zhang", "Yu", ""], ["Li", "Yong", ""]]}, {"id": "2010.01700", "submitter": "Emery Berger", "authors": "Breanna Devore-McDonald and Emery D. Berger", "title": "Mossad: Defeating Software Plagiarism Detection", "comments": "30 pages. To appear, OOPSLA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.NE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic software plagiarism detection tools are widely used in educational\nsettings to ensure that submitted work was not copied. These tools have grown\nin use together with the rise in enrollments in computer science programs and\nthe widespread availability of code on-line. Educators rely on the robustness\nof plagiarism detection tools; the working assumption is that the effort\nrequired to evade detection is as high as that required to actually do the\nassigned work.\n  This paper shows this is not the case. It presents an entirely automatic\nprogram transformation approach, Mossad, that defeats popular software\nplagiarism detection tools. Mossad comprises a framework that couples\ntechniques inspired by genetic programming with domain-specific knowledge to\neffectively undermine plagiarism detectors. Mossad is effective at defeating\nfour plagiarism detectors, including Moss and JPlag. Mossad is both fast and\neffective: it can, in minutes, generate modified versions of programs that are\nlikely to escape detection. More insidiously, because of its non-deterministic\napproach, Mossad can, from a single program, generate dozens of variants, which\nare classified as no more suspicious than legitimate assignments. A detailed\nstudy of Mossad across a corpus of real student assignments demonstrates its\nefficacy at evading detection. A user study shows that graduate student\nassistants consistently rate Mossad-generated code as just as readable as\nauthentic student code. This work motivates the need for both research on more\nrobust plagiarism detection tools and greater integration of naturally\nplagiarism-resistant methodologies like code review into computer science\neducation.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 22:02:38 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Devore-McDonald", "Breanna", ""], ["Berger", "Emery D.", ""]]}, {"id": "2010.01730", "submitter": "Shomik Jain", "authors": "Shomik Jain, Abby K. Wood", "title": "Facebook Political Ads And Accountability: Outside Groups Are Most\n  Negative, Especially When Disappearing Or Hiding Donors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of online political advertising has come with little\nregulation, allowing political advertisers on social media to avoid\naccountability. We analyze how transparency deficits caused by dark money and\ngroup impermanence relate to the sentiment of political ads on Facebook. We\nobtained 525,796 ads with FEC-registered advertisers from Facebook's ad library\nthat ran between August-November 2018. We compare ads run by candidates,\nparties, and outside groups, which we classify by (i) their donor transparency\n(dark money or disclosed) and (ii) the group's permanence (disappearing after\n2018 or re-registering). Ads run by dark money and disappearing outside groups\nwere more negative than transparent and re-registering groups, respectively.\nOutside groups as a whole also ran more negative ads than candidates and\nparties. These results suggest that transparency for political speech is\nassociated with advertising tone: the most negative advertising comes from\norganizations with less donor disclosure and permanence.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 00:53:43 GMT"}, {"version": "v2", "created": "Sun, 24 Jan 2021 00:21:42 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Jain", "Shomik", ""], ["Wood", "Abby K.", ""]]}, {"id": "2010.01973", "submitter": "Adam Aviv", "authors": "Hirak Ray and Flynn Wolf and Ravi Kuber and Adam J. Aviv", "title": "Why Older Adults (Don't) Use Password Managers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Password managers (PMs) are considered highly effective tools for increasing\nsecurity, and a recent study by Pearman et al. (SOUPS'19) highlighted the\nmotivations and barriers to adopting PMs. We expand these findings by\nreplicating Pearman et al.'s protocol and interview instrument applied to a\nsample of strictly older adults (>60 years of age), as the prior work focused\non a predominantly younger cohort. We conducted n=26 semi-structured interviews\nwith PM users, built-in browser/operating system PM users, and non-PM users.\nThe average participant age was 70.4 years. Using the same codebook from\nPearman et al., we showcase differences and similarities in PM adoption between\nthe samples, including fears of a single point of failure and the importance of\nhaving control over one's private information. Meanwhile, older adults were\nfound to have higher mistrust of cloud storage of passwords and cross-device\nsynchronization. We also highlight PM adoption motivators for older adults,\nincluding the power of recommendations from family members and the importance\nof education and outreach to improve familiarity.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 13:02:47 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Ray", "Hirak", ""], ["Wolf", "Flynn", ""], ["Kuber", "Ravi", ""], ["Aviv", "Adam J.", ""]]}, {"id": "2010.02086", "submitter": "Kailas Vodrahalli", "authors": "Kailas Vodrahalli, Roxana Daneshjou, Roberto A Novoa, Albert Chiou,\n  Justin M Ko, and James Zou", "title": "TrueImage: A Machine Learning Algorithm to Improve the Quality of\n  Telehealth Photos", "comments": "12 pages, 5 figures, Preprint of an article published in Pacific\n  Symposium on Biocomputing \\c{opyright} 2020 World Scientific Publishing Co.,\n  Singapore, http://psb.stanford.edu/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Telehealth is an increasingly critical component of the health care\necosystem, especially due to the COVID-19 pandemic. Rapid adoption of\ntelehealth has exposed limitations in the existing infrastructure. In this\npaper, we study and highlight photo quality as a major challenge in the\ntelehealth workflow. We focus on teledermatology, where photo quality is\nparticularly important; the framework proposed here can be generalized to other\nhealth domains. For telemedicine, dermatologists request that patients submit\nimages of their lesions for assessment. However, these images are often of\ninsufficient quality to make a clinical diagnosis since patients do not have\nexperience taking clinical photos. A clinician has to manually triage poor\nquality images and request new images to be submitted, leading to wasted time\nfor both the clinician and the patient. We propose an automated image\nassessment machine learning pipeline, TrueImage, to detect poor quality\ndermatology photos and to guide patients in taking better photos. Our\nexperiments indicate that TrueImage can reject 50% of the sub-par quality\nimages, while retaining 80% of good quality images patients send in, despite\nheterogeneity and limitations in the training data. These promising results\nsuggest that our solution is feasible and can improve the quality of\nteledermatology care.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 17:47:57 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Vodrahalli", "Kailas", ""], ["Daneshjou", "Roxana", ""], ["Novoa", "Roberto A", ""], ["Chiou", "Albert", ""], ["Ko", "Justin M", ""], ["Zou", "James", ""]]}, {"id": "2010.02150", "submitter": "Saurabh Gupta", "authors": "Saurabh Gupta, Huy H. Nguyen, Junichi Yamagishi and Isao Echizen", "title": "Viable Threat on News Reading: Generating Biased News Using Natural\n  Language Models", "comments": "11 pages, 4 figures, 6 tables, Accepted at NLP+CSS Workshop at EMNLP\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in natural language generation has raised serious\nconcerns. High-performance language models are widely used for language\ngeneration tasks because they are able to produce fluent and meaningful\nsentences. These models are already being used to create fake news. They can\nalso be exploited to generate biased news, which can then be used to attack\nnews aggregators to change their reader's behavior and influence their bias. In\nthis paper, we use a threat model to demonstrate that the publicly available\nlanguage models can reliably generate biased news content based on an input\noriginal news. We also show that a large number of high-quality biased news\narticles can be generated using controllable text generation. A subjective\nevaluation with 80 participants demonstrated that the generated biased news is\ngenerally fluent, and a bias evaluation with 24 participants demonstrated that\nthe bias (left or right) is usually evident in the generated articles and can\nbe easily identified.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 16:55:39 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Gupta", "Saurabh", ""], ["Nguyen", "Huy H.", ""], ["Yamagishi", "Junichi", ""], ["Echizen", "Isao", ""]]}, {"id": "2010.02252", "submitter": "Bahman Rostami-Tabar", "authors": "Bahman Rostami-Tabar and Juan F. Rendon-Sanchez", "title": "Forecasting COVID-19 daily cases using phone call data", "comments": "13 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need to forecast COVID-19 related variables continues to be pressing as\nthe epidemic unfolds. Different efforts have been made, with compartmental\nmodels in epidemiology and statistical models such as AutoRegressive Integrated\nMoving Average (ARIMA), Exponential Smoothing (ETS) or computing intelligence\nmodels. These efforts have proved useful in some instances by allowing decision\nmakers to distinguish different scenarios during the emergency, but their\naccuracy has been disappointing, forecasts ignore uncertainties and less\nattention is given to local areas. In this study, we propose a simple Multiple\nLinear Regression model, optimised to use call data to forecast the number of\ndaily confirmed cases. Moreover, we produce a probabilistic forecast that\nallows decision makers to better deal with risk. Our proposed approach\noutperforms ARIMA, ETS and a regression model without call data, evaluated by\nthree point forecast error metrics, one prediction interval and two\nprobabilistic forecast accuracy measures. The simplicity, interpretability and\nreliability of the model, obtained in a careful forecasting exercise, is a\nmeaningful contribution to decision makers at local level who acutely need to\norganise resources in already strained health services. We hope that this model\nwould serve as a building block of other forecasting efforts that on the one\nhand would help front-line personal and decision makers at local level, and on\nthe other would facilitate the communication with other modelling efforts being\nmade at the national level to improve the way we tackle this pandemic and other\nsimilar future challenges.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 18:07:07 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Rostami-Tabar", "Bahman", ""], ["Rendon-Sanchez", "Juan F.", ""]]}, {"id": "2010.02339", "submitter": "Ashiqur KhudaBukhsh Ashiqur Rahman KhudaBukhsh", "authors": "Ashiqur R. KhudaBukhsh, Rupak Sarkar, Mark S. Kamlet, Tom M. Mitchell", "title": "We Don't Speak the Same Language: Interpreting Polarization through\n  Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Polarization among US political parties, media and elites is a widely studied\ntopic. Prominent lines of prior research across multiple disciplines have\nobserved and analyzed growing polarization in social media. In this paper, we\npresent a new methodology that offers a fresh perspective on interpreting\npolarization through the lens of machine translation. With a novel proposition\nthat two sub-communities are speaking in two different \\emph{languages}, we\ndemonstrate that modern machine translation methods can provide a simple yet\npowerful and interpretable framework to understand the differences between two\n(or more) large-scale social media discussion data sets at the granularity of\nwords. Via a substantial corpus of 86.6 million comments by 6.5 million users\non over 200,000 news videos hosted by YouTube channels of four prominent US\nnews networks, we demonstrate that simple word-level and phrase-level\ntranslation pairs can reveal deep insights into the current political divide --\nwhat is \\emph{black lives matter} to one can be \\emph{all lives matter} to the\nother.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 21:16:30 GMT"}, {"version": "v2", "created": "Sun, 18 Oct 2020 07:34:20 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["KhudaBukhsh", "Ashiqur R.", ""], ["Sarkar", "Rupak", ""], ["Kamlet", "Mark S.", ""], ["Mitchell", "Tom M.", ""]]}, {"id": "2010.02387", "submitter": "Mayana Pereira", "authors": "Mayana Pereira, Rahul Dodhia and Richard Brown", "title": "Metadata-Based Detection of Child Sexual Abuse Material", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade, the scale of creation and distribution of child sexual\nabuse medias (CSAM) has exponentially increased. Technologies that aid law\nenforcement agencies worldwide to identify such crimes rapidly can potentially\nresult in the mitigation of child victimization, and the apprehending of\noffenders. Machine learning presents the potential to help law enforcement\nrapidly identify such material, and even block such content from being\ndistributed digitally. However, collecting and storing CSAM files to train\nmachine learning models has many ethical and legal constraints, creating a\nbarrier to the development of accurate computer vision-based models. With such\nrestrictions in place, the development of accurate machine learning classifiers\nfor CSAM identification based on file metadata becomes crucial.\n  In this work, we propose a system for CSAM identification on file storage\nsystems based solely on metadata - file paths. Our aim is to provide a tool\nthat is material type agnostic (image, video, PDF), and can potentially scans\nthousands of file storage systems in a short time. Our approach uses\nconvolutional neural networks, and achieves an accuracy of 97% and recall of\n94%. Additionally, we address the potential problem of offenders trying to\nevade detection by this model by evaluating the robustness of our model against\nadversarial modifications in the file paths.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 23:10:21 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Pereira", "Mayana", ""], ["Dodhia", "Rahul", ""], ["Brown", "Richard", ""]]}, {"id": "2010.02503", "submitter": "Sohini Roychowdhury", "authors": "Sohini Roychowdhury, Wenxi Li, Ebrahim Alareqi, Akhilesh Pandita, Ao\n  Liu, Joakim Soderberg", "title": "Categorizing Online Shopping Behavior from Cosmetics to Electronics: An\n  Analytical Framework", "comments": "10 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A success factor for modern companies in the age of Digital Marketing is to\nunderstand how customers think and behave based on their online shopping\npatterns. While the conventional method of gathering consumer insights through\nquestionnaires and surveys still form the bases of descriptive analytics for\nmarket intelligence units, we propose a machine learning framework to automate\nthis process. In this paper we present a modular consumer data analysis\nplatform that processes session level interaction records between users and\nproducts to predict session level, user journey level and customer behavior\nspecific patterns leading towards purchase events. We explore the computational\nframework and provide test results on two Big data sets-cosmetics and consumer\nelectronics of size 2GB and 15GB, respectively. The proposed system achieves\n97-99% classification accuracy and recall for user-journey level purchase\npredictions and categorizes buying behavior into 5 clusters with increasing\npurchase ratios for both data sets. Thus, the proposed framework is extendable\nto other large e-commerce data sets to obtain automated purchase predictions\nand descriptive consumer insights.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 06:16:44 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Roychowdhury", "Sohini", ""], ["Li", "Wenxi", ""], ["Alareqi", "Ebrahim", ""], ["Pandita", "Akhilesh", ""], ["Liu", "Ao", ""], ["Soderberg", "Joakim", ""]]}, {"id": "2010.02629", "submitter": "Soma Dhavala", "authors": "Chintan Donda, Sayan Dasgupta, Soma S Dhavala, Keyur Faldu, Aditi\n  Avasthi", "title": "A framework for predicting, interpreting, and improving Learning\n  Outcomes", "comments": "9 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has long been recognized that academic success is a result of both\ncognitive and non-cognitive dimensions acting together. Consequently, any\nintelligent learning platform designed to improve learning outcomes (LOs) must\nprovide actionable inputs to the learner in these dimensions. However,\noperationalizing such inputs in a production setting that is scalable is not\ntrivial. We develop an Embibe Score Quotient model (ESQ) to predict test scores\nbased on observed academic, behavioral and test-taking features of a student.\nESQ can be used to predict the future scoring potential of a student as well as\noffer personalized learning nudges, both critical to improving LOs. Multiple\nmachine learning models are evaluated for the prediction task. In order to\nprovide meaningful feedback to the learner, individualized Shapley feature\nattributions for each feature are computed. Prediction intervals are obtained\nby applying non-parametric quantile regression, in an attempt to quantify the\nuncertainty in the predictions. We apply the above modelling strategy on a\ndataset consisting of more than a hundred million learner interactions on the\nEmbibe learning platform. We observe that the Median Absolute Error between the\nobserved and predicted scores is 4.58% across several user segments, and the\ncorrelation between predicted and observed responses is 0.93. Game-like what-if\nscenarios are played out to see the changes in LOs, on counterfactual examples.\nWe briefly discuss how a rational agent can then apply an optimal policy to\naffect the learning outcomes by treating the above model like an Oracle.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 11:22:27 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 04:54:56 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Donda", "Chintan", ""], ["Dasgupta", "Sayan", ""], ["Dhavala", "Soma S", ""], ["Faldu", "Keyur", ""], ["Avasthi", "Aditi", ""]]}, {"id": "2010.02726", "submitter": "Lance Eliot", "authors": "Lance Eliot", "title": "Legal Sentiment Analysis and Opinion Mining (LSAOM): Assimilating\n  Advances in Autonomous AI Legal Reasoning", "comments": "26 pages, 8 figures. arXiv admin note: text overlap with\n  arXiv:2009.14620", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An expanding field of substantive interest for the theory of the law and the\npractice-of-law entails Legal Sentiment Analysis and Opinion Mining (LSAOM),\nconsisting of two often intertwined phenomena and actions underlying legal\ndiscussions and narratives: (1) Sentiment Analysis (SA) for the detection of\nexpressed or implied sentiment about a legal matter within the context of a\nlegal milieu, and (2) Opinion Mining (OM) for the identification and\nillumination of explicit or implicit opinion accompaniments immersed within\nlegal discourse. Efforts to undertake LSAOM have historically been performed by\nhuman hand and cognition, and only thinly aided in more recent times by the use\nof computer-based approaches. Advances in Artificial Intelligence (AI)\ninvolving especially Natural Language Processing (NLP) and Machine Learning\n(ML) are increasingly bolstering how automation can systematically perform\neither or both of Sentiment Analysis and Opinion Mining, all of which is being\ninexorably carried over into engagement within a legal context for improving\nLSAOM capabilities. This research paper examines the evolving infusion of AI\ninto Legal Sentiment Analysis and Opinion Mining and proposes an alignment with\nthe Levels of Autonomy (LoA) of AI Legal Reasoning (AILR), plus provides\nadditional insights regarding AI LSAOM in its mechanizations and potential\nimpact to the study of law and the practicing of law.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 04:15:21 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Eliot", "Lance", ""]]}, {"id": "2010.02973", "submitter": "Honglu Jiang", "authors": "Honglu Jiang, Jian Pei, Dongxiao Yu, Jiguo Yu, Bei Gong, Xiuzhen Cheng", "title": "Applications of Differential Privacy in Social Network Analysis: A\n  Survey", "comments": "50 pages,16 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy is effective in sharing information and preserving\nprivacy with a strong guarantee. As social network analysis has been\nextensively adopted in many applications, it opens a new arena for the\napplication of differential privacy. In this article, we provide a\ncomprehensive survey connecting the basic principles of differential privacy\nand applications in social network analysis. We present a concise review of the\nfoundations of differential privacy and the major variants and discuss how\ndifferential privacy is applied to social network analysis, including privacy\nattacks in social networks, types of differential privacy in social network\nanalysis, and a series of popular tasks, such as degree distribution analysis,\nsubgraph counting and edge weights. We also discuss a series of challenges for\nfuture studies.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 19:06:03 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2021 00:50:10 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Jiang", "Honglu", ""], ["Pei", "Jian", ""], ["Yu", "Dongxiao", ""], ["Yu", "Jiguo", ""], ["Gong", "Bei", ""], ["Cheng", "Xiuzhen", ""]]}, {"id": "2010.03021", "submitter": "Barbara Pernici", "authors": "Virginia Negri, Dario Scuratti, Stefano Agresti, Donya Rooein,\n  Gabriele Scalia, Amudha Ravi Shankar, Jose Luis Fernandez Marquez, Mark James\n  Carman, Barbara Pernici", "title": "Image-based Social Sensing: Combining AI and the Crowd to Mine\n  Policy-Adherence Indicators from Twitter", "comments": "10 pages, 9 figures, to be published in Proceedings of ICSE Software\n  Engineering in Society, May 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social Media provides a trove of information that, if aggregated and analysed\nappropriately can provide important statistical indicators to policy makers. In\nsome situations these indicators are not available through other mechanisms.\nFor example, given the ongoing COVID-19 outbreak, it is essential for\ngovernments to have access to reliable data on policy-adherence with regards to\nmask wearing, social distancing, and other hard-to-measure quantities. In this\npaper we investigate whether it is possible to obtain such data by aggregating\ninformation from images posted to social media. The paper presents VisualCit, a\npipeline for image-based social sensing combining recent advances in image\nrecognition technology with geocoding and crowdsourcing techniques. Our aim is\nto discover in which countries, and to what extent, people are following\nCOVID-19 related policy directives. We compared the results with the indicators\nproduced within the CovidDataHub behavior tracker initiative. Preliminary\nresults shows that social media images can produce reliable indicators for\npolicy makers.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 21:00:18 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 22:59:44 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Negri", "Virginia", ""], ["Scuratti", "Dario", ""], ["Agresti", "Stefano", ""], ["Rooein", "Donya", ""], ["Scalia", "Gabriele", ""], ["Shankar", "Amudha Ravi", ""], ["Marquez", "Jose Luis Fernandez", ""], ["Carman", "Mark James", ""], ["Pernici", "Barbara", ""]]}, {"id": "2010.03083", "submitter": "Olga Zagovora", "authors": "Olga Zagovora, Roberto Ulloa, Katrin Weller, Fabian Fl\\\"ock", "title": "'I Updated the <ref>': The Evolution of References in the English\n  Wikipedia and the Implications for Altmetrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With this work, we present a publicly available dataset of the history of all\nthe references (more than 55 million) ever used in the English Wikipedia until\nJune 2019. We have applied a new method for identifying and monitoring\nreferences in Wikipedia, so that for each reference we can provide data about\nassociated actions: creation, modifications, deletions, and reinsertions. The\nhigh accuracy of this method and the resulting dataset was confirmed via a\ncomprehensive crowdworker labelling campaign. We use the dataset to study the\ntemporal evolution of Wikipedia references as well as users' editing behaviour.\nWe find evidence of a mostly productive and continuous effort to improve the\nquality of references: (1) there is a persistent increase of reference and\ndocument identifiers (DOI, PubMedID, PMC, ISBN, ISSN, ArXiv ID), and (2) most\nof the reference curation work is done by registered humans (not bots or\nanonymous editors). We conclude that the evolution of Wikipedia references,\nincluding the dynamics of the community processes that tend to them should be\nleveraged in the design of relevance indexes for altmetrics, and our dataset\ncan be pivotal for such effort.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 23:26:12 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Zagovora", "Olga", ""], ["Ulloa", "Roberto", ""], ["Weller", "Katrin", ""], ["Fl\u00f6ck", "Fabian", ""]]}, {"id": "2010.03356", "submitter": "Pedro Garcia Lopez", "authors": "Pedro Garcia Lopez", "title": "Decentralize the feedback infrastructure!", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The decentralized architecture of Internet sparkled techno-utopian visions of\na virtual freedom space for humanity. Peer-to-peer systems, collaborative\ncreation (wikipedia), open source software (Linux), universal shared knowledge,\nand the hopes for disintermediation contributed to this major vision.\n  However, the reality is bleak: centralization is reigning in the cyberspace,\nwith huge technological corporations controlling our data, and\nre-intermediation and control are stronger than ever in the so-called \"sharing\"\neconomy. The Internet is also fragmented by countries, with many states\nimposing heavy controls to information and communication services.\n  The XXI century will witness the major clash between centralization and\ndecentralization in human history. And the major struggle will be around the\ncommunication and feedback technologies that will intermediate and govern every\ninteraction in our lives.\n  Unlike previous approaches that propose to socialize the feedback\ninfrastructure or to use anti-monopoly laws to break Big Tech companies, in\nthis article we advocate for the decentralization of the information and\ncommunication infrastructure. And the key to this decentralization is the\ncreation of standards enabling interoperability between data platforms. This\nwill in turn produce a true disintermediation from well established\ntechnological players and open competition to small third parties. In this\narticle, we sketch such a decentralized open infrastructure including\ncommunication, sharing, matchmaking, and reputation services that can be\nconstructed over open source technologies and standards.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 12:02:08 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 14:04:02 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 13:05:52 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Lopez", "Pedro Garcia", ""]]}, {"id": "2010.03362", "submitter": "Alexandrine Royer", "authors": "Alexandrine Royer", "title": "The Short Anthropological Guide to the Study of Ethical AI", "comments": "46 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Over the next few years, society as a whole will need to address what core\nvalues it wishes to protect when dealing with technology. Anthropology, a field\ndedicated to the very notion of what it means to be human, can provide some\ninteresting insights into how to cope and tackle these changes in our Western\nsociety and other areas of the world. It can be challenging for social science\npractitioners to grasp and keep up with the pace of technological innovation,\nwith many being unfamiliar with the jargon of AI. This short guide serves as\nboth an introduction to AI ethics and social science and anthropological\nperspectives on the development of AI. It intends to provide those unfamiliar\nwith the field with an insight into the societal impact of AI systems and how,\nin turn, these systems can lead us to rethink how our world operates.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 12:25:03 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Royer", "Alexandrine", ""]]}, {"id": "2010.03574", "submitter": "Chao-Chun Hsu", "authors": "Chao-Chun Hsu, Shantanu Karnwal, Sendhil Mullainathan, Ziad Obermeyer,\n  Chenhao Tan", "title": "Characterizing the Value of Information in Medical Notes", "comments": "15 pages, 12 figures, Findings of EMNLP 2020, code is available at\n  https://github.com/BoulderDS/value-of-medical-notes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models depend on the quality of input data. As electronic\nhealth records are widely adopted, the amount of data in health care is\ngrowing, along with complaints about the quality of medical notes. We use two\nprediction tasks, readmission prediction and in-hospital mortality prediction,\nto characterize the value of information in medical notes. We show that as a\nwhole, medical notes only provide additional predictive power over structured\ninformation in readmission prediction. We further propose a probing framework\nto select parts of notes that enable more accurate predictions than using all\nnotes, despite that the selected information leads to a distribution shift from\nthe training data (\"all notes\"). Finally, we demonstrate that models trained on\nthe selected valuable information achieve even better predictive performance,\nwith only 6.8% of all the tokens for readmission prediction.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 18:00:03 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 17:04:27 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Hsu", "Chao-Chun", ""], ["Karnwal", "Shantanu", ""], ["Mullainathan", "Sendhil", ""], ["Obermeyer", "Ziad", ""], ["Tan", "Chenhao", ""]]}, {"id": "2010.03629", "submitter": "Rudy Arthur", "authors": "Rudy Arthur", "title": "Studying the UK Job Market During the COVID-19 Crisis with Online Job\n  Ads", "comments": "33 pages, 20 figures", "journal-ref": null, "doi": "10.1371/journal.pone.0251431", "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 global pandemic and the lockdown policies enacted to mitigate it\nhave had profound effects on the labour market. Understanding these effects\nrequires us to obtain and analyse data in as close to real time as possible,\nespecially as rules change rapidly and local lockdowns are enacted. In this\nwork we study the UK labour market by analysing data from the online job board\nReed.co.uk. Using topic modelling and geo-inference methods we are able to\nbreak down the data by sector and geography. We also study how the salary,\ncontract type and mode of work have changed since the COVID-19 crisis hit the\nUK in March. Overall, vacancies were down by 60 to 70\\% in the first weeks of\nlockdown. By the end of the year numbers had recovered somewhat, but the total\njob ad deficit is measured to be over 40\\%. Broken down by sector, vacancies\nfor hospitality and graduate jobs are greatly reduced, while there were more\ncare work and nursing vacancies during lockdown. Differences by geography are\nless significant than between sectors, though there is some indication that\nlocal lockdowns stall recovery and less badly hit areas may have experienced a\nsmaller reduction in vacancies. There are also small but significant changes in\nthe salary distribution and number of full time and permanent jobs. In addition\nto these results, this work presents an open methodology that enables a rapid\nand detailed survey of the job market in these unsettled conditions and we\ndescribe a web application \\url{jobtrender.com} that allows others to query\nthis data set.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 19:56:16 GMT"}, {"version": "v2", "created": "Sun, 31 Jan 2021 14:02:19 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Arthur", "Rudy", ""]]}, {"id": "2010.03672", "submitter": "Bernardo Huberman", "authors": "Bernardo A. Huberman and Tad Hogg", "title": "Privacy and Data Balkanization: Circumventing the Barriers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid growth in digital data forms the basis for a wide range of new\nservices and research, e.g, large-scale medical studies. At the same time,\nincreasingly restrictive privacy concerns and laws are leading to significant\noverhead in arranging for sharing or combining different data sets to obtain\nthese benefits. For new applications, where the benefit of combined data is not\nyet clear, this overhead can inhibit organizations from even trying to\ndetermine whether they can mutually benefit from sharing their data. In this\npaper, we discuss techniques to overcome this difficulty by employing private\ninformation transfer to determine whether there is a benefit from sharing data,\nand whether there is room to negotiate acceptable prices. These techniques\ninvolve cryptographic protocols. While currently considered secure, these\nprotocols are potentially vulnerable to the development of quantum technology,\nparticularly for ensuring privacy over significant periods of time into the\nfuture. To mitigate this concern, we describe how developments in practical\nquantum technology can improve the security of these protocols.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 22:05:28 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Huberman", "Bernardo A.", ""], ["Hogg", "Tad", ""]]}, {"id": "2010.03677", "submitter": "Pradipta Banerjee", "authors": "Pradipta Banerjee, Subhrabrata Choudhury", "title": "Agent Based Computational Model Aided Approach to Improvise the\n  Inequality-Adjusted Human Development Index (IHDI) for Greater Parity in Real\n  Scenario Assessments", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To design, evaluate and tune policies for all-inclusive human development,\nthe primary requisite is to assess the true state of affairs of the society.\nStatistical indices like GDP, Gini Coefficients have been developed to\naccomplish the evaluation of the socio-economic systems. They have remained\nprevalent in the conventional economic theories but little do they have in the\noffing regarding true well-being and development of humans. Human Development\nIndex (HDI) and thereafter Inequality-adjusted Human Development Index (IHDI)\nhas been the path changing composite-index having the focus on human\ndevelopment. However, even though its fundamental philosophy has an\nall-inclusive human development focus, the composite-indices appear to be\nunable to grasp the actual assessment in several scenarios. This happens due to\nthe dynamic non-linearity of social-systems where superposition principle\ncannot be applied between all of its inputs and outputs of the system as the\nsystem's own attributes get altered upon each input. We would discuss the\napparent shortcomings and probable refinement of the existing index using an\nagent based computational system model approach.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 22:20:51 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Banerjee", "Pradipta", ""], ["Choudhury", "Subhrabrata", ""]]}, {"id": "2010.03805", "submitter": "Giulia Cisotto", "authors": "Sergio Martiradonna, Giulia Cisotto, Gennaro Boggia, Giuseppe Piro,\n  Lorenzo Vangelista, and Stefano Tomasin", "title": "Cascaded WLAN-FWA Networking and Computing Architecture for Pervasive\n  In-Home Healthcare", "comments": null, "journal-ref": null, "doi": "10.1109/MWC.001.2000330", "report-no": null, "categories": "cs.NI cs.CY cs.DC eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pervasive healthcare is a promising assisted-living solution for chronic\npatients. However, current cutting-edge communication technologies are not able\nto strictly meet the requirements of these applications, especially in the case\nof life-threatening events. To bridge this gap, this paper proposes a new\narchitecture to support indoor healthcare monitoring, with a focus on epileptic\npatients. Several novel elements are introduced. The first element is the\ncascading of a WLAN and a cellular network, where IEEE 802.11ax is used for the\nwireless local area network to collect physiological and environmental data\nin-home and 5G-enabled Fixed Wireless Access links transfer them to a remote\nhospital. The second element is the extension of the network slicing concept to\nthe WLAN, and the introduction of two new slice types to support both regular\nmonitoring and emergency handling. Moreover, the inclusion of local computing\ncapabilities at the WLAN router, together with a mobile edge computing\nresource, represents a further architectural enhancement. Local computation is\nrequired to trigger not only health-related alarms, but also the network\nslicing change in case of emergency: in fact, proper radio resource scheduling\nis necessary for the cascaded networks to handle healthcare traffic together\nwith other promiscuous everyday communication services. Numerical results\ndemonstrate the effectiveness of the proposed approach while highlighting the\nperformance gain achieved with respect to baseline solutions.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 07:16:00 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Martiradonna", "Sergio", ""], ["Cisotto", "Giulia", ""], ["Boggia", "Gennaro", ""], ["Piro", "Giuseppe", ""], ["Vangelista", "Lorenzo", ""], ["Tomasin", "Stefano", ""]]}, {"id": "2010.03806", "submitter": "Po-Shen Loh", "authors": "Po-Shen Loh", "title": "Flipping the Perspective in Contact Tracing", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a fundamentally different paradigm for contact tracing: for each\npositive case, do not only ask direct contacts to quarantine; instead, tell\neveryone how many relationships away the disease just struck (so, \"2\" is a\nclose physical contact of a close physical contact). This new approach, which\nhas already been deployed in a publicly downloadable app, brings a new tool to\nbear on pandemic control, powered by network theory. Like a weather satellite\nproviding early warning of incoming hurricanes, it empowers individuals to see\ntransmission approaching from far away, and incites behavior change to directly\navoid exposure. This flipped perspective engages natural self-interested\ninstincts of self-preservation, reducing reliance on altruism, and the\nresulting caution reduces pandemic spread in the social vicinity of each\ninfection. Consequently, our new system solves the behavior coordination\nproblem which has hampered many other app-based interventions to date. We also\nprovide a heuristic mathematical analysis that shows how our system already\nachieves critical mass from the user perspective at very low adoption\nthresholds (likely below 10% in some common types of communities as indicated\nempirically in the first practical deployment); after that point, the design of\nour system naturally accelerates further adoption, while also alerting even\nnon-users of the app. This article seeks to lay the theoretical foundation for\nour approach, and to open the area for further research along many dimensions.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 07:17:22 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 04:50:01 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Loh", "Po-Shen", ""]]}, {"id": "2010.03986", "submitter": "James Hickey", "authors": "Gareth P. Jones, James M. Hickey, Pietro G. Di Stefano, Charanpal\n  Dhanjal, Laura C. Stoddart and Vlasios Vasileiou", "title": "Metrics and methods for a systematic comparison of fairness-aware\n  machine learning algorithms", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding and removing bias from the decisions made by machine learning\nmodels is essential to avoid discrimination against unprivileged groups.\nDespite recent progress in algorithmic fairness, there is still no clear answer\nas to which bias-mitigation approaches are most effective. Evaluation\nstrategies are typically use-case specific, rely on data with unclear bias, and\nemploy a fixed policy to convert model outputs to decision outcomes. To address\nthese problems, we performed a systematic comparison of a number of popular\nfairness algorithms applicable to supervised classification. Our study is the\nmost comprehensive of its kind. It utilizes three real and four synthetic\ndatasets, and two different ways of converting model outputs to decisions. It\nconsiders fairness, predictive-performance, calibration quality, and speed of\n28 different modelling pipelines, corresponding to both fairness-unaware and\nfairness-aware algorithms. We found that fairness-unaware algorithms typically\nfail to produce adequately fair models and that the simplest algorithms are not\nnecessarily the fairest ones. We also found that fairness-aware algorithms can\ninduce fairness without material drops in predictive power. Finally, we found\nthat dataset idiosyncracies (e.g., degree of intrinsic unfairness, nature of\ncorrelations) do affect the performance of fairness-aware approaches. Our\nresults allow the practitioner to narrow down the approach(es) they would like\nto adopt without having to know in advance their fairness requirements.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 13:58:09 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Jones", "Gareth P.", ""], ["Hickey", "James M.", ""], ["Di Stefano", "Pietro G.", ""], ["Dhanjal", "Charanpal", ""], ["Stoddart", "Laura C.", ""], ["Vasileiou", "Vlasios", ""]]}, {"id": "2010.04025", "submitter": "Johannes Wachs", "authors": "Timur Bachschi, Aniko Hannak, Florian Lemmerich, Johannes Wachs", "title": "From Asking to Answering: Getting More Involved on Stack Overflow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Online knowledge platforms such as Stack Overflow and Wikipedia rely on a\nlarge and diverse contributor community. Despite efforts to facilitate\nonboarding of new users, relatively few users become core contributors,\nsuggesting the existence of barriers or hurdles that hinder full involvement in\nthe community. This paper investigates such issues on Stack Overflow, a widely\npopular question and answer community for computer programming. We document\nevidence of a \"leaky pipeline\", specifically that there are many active users\non the platform who never post an answer. Using this as a starting point, we\ninvestigate potential factors that can be linked to the transition of new\ncontributors from asking questions to posting answers. We find a user's\nindividual features, such as their tenure, gender, and geographic location, as\nwell as features of the subcommunity in which they are most active, such as its\nsize and the prevalence of negative social feedback, have a significant\nrelationship with their likelihood to post answers. By measuring and modeling\nthese relationships our paper presents a first look at the challenges and\nobstacles to user promotion along the pipeline of contributions in online\ncommunities.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 14:41:22 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Bachschi", "Timur", ""], ["Hannak", "Aniko", ""], ["Lemmerich", "Florian", ""], ["Wachs", "Johannes", ""]]}, {"id": "2010.04124", "submitter": "Mehak Maniktala", "authors": "Mehak Maniktala, Christa Cody, Amy Isvik, Nicholas Lytle, Min Chi,\n  Tiffany Barnes", "title": "Extending the Hint Factory for the assistance dilemma: A novel,\n  data-driven HelpNeed Predictor for proactive problem-solving help", "comments": null, "journal-ref": "Journal of Educational Data Mining 12 (4), 24-65, 2020", "doi": "10.5281/zenodo.4399683", "report-no": null, "categories": "cs.AI cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining when and whether to provide personalized support is a well-known\nchallenge called the assistance dilemma. A core problem in solving the\nassistance dilemma is the need to discover when students are unproductive so\nthat the tutor can intervene. Such a task is particularly challenging for\nopen-ended domains, even those that are well-structured with defined principles\nand goals. In this paper, we present a set of data-driven methods to classify,\npredict, and prevent unproductive problem-solving steps in the well-structured\nopen-ended domain of logic. This approach leverages and extends the Hint\nFactory, a set of methods that leverages prior student solution attempts to\nbuild data-driven intelligent tutors. We present a HelpNeed classification,\nthat uses prior student data to determine when students are likely to be\nunproductive and need help learning optimal problem-solving strategies. We\npresent a controlled study to determine the impact of an Adaptive pedagogical\npolicy that provides proactive hints at the start of each step based on the\noutcomes of our HelpNeed predictor: productive vs. unproductive. Our results\nshow that the students in the Adaptive condition exhibited better training\nbehaviors, with lower help avoidance, and higher help appropriateness (a higher\nchance of receiving help when it was likely to be needed), as measured using\nthe HelpNeed classifier, when compared to the Control. Furthermore, the results\nshow that the students who received Adaptive hints based on HelpNeed\npredictions during training significantly outperform their Control peers on the\nposttest, with the former producing shorter, more optimal solutions in less\ntime. We conclude with suggestions on how these HelpNeed methods could be\napplied in other well-structured open-ended domains.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 17:04:03 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Maniktala", "Mehak", ""], ["Cody", "Christa", ""], ["Isvik", "Amy", ""], ["Lytle", "Nicholas", ""], ["Chi", "Min", ""], ["Barnes", "Tiffany", ""]]}, {"id": "2010.04396", "submitter": "Faidra Monachou", "authors": "Nikhil Garg, Hannah Li, Faidra Monachou", "title": "Dropping Standardized Testing for Admissions: Differential Variance and\n  Access", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The University of California suspended through 2024 the requirement that\napplicants from California submit SAT scores, upending the major role\nstandardized testing has played in college admissions. We study the impact of\nsuch decisions and its interplay with other interventions such as affirmative\naction on admitted class composition.\n  We develop a theoretical framework to study the effect of requiring test\nscores on academic merit and diversity in college admissions. The model has a\ncollege and set of potential students. Each student an unobserved noisy skill\nlevel, and multiple observed application components and group membership. The\ncollege is Bayesian and maximizes an objective that depends on both diversity\nand merit. It estimates each applicant's true skill level using the observed\nfeatures, and then admits students with or without affirmative action.\n  We characterize the trade-off between the (potentially positive)\ninformational role of standardized testing in college admissions and its\n(negative) exclusionary nature. Dropping test scores may exacerbate disparities\nby decreasing the amount of information available for each applicant,\nespecially those from non-traditional backgrounds. However, if there are\nsubstantial barriers to testing, removing the test improves both academic merit\nand diversity by increasing the size of the applicant pool. The overall effect\nof testing depends on both the variance of the test score noise and the amount\nof people excluded by the test requirement.\n  Finally, using application and transcript data from the University of Texas\nat Austin, we demonstrate how an admissions committee could measure the\ntrade-off in practice.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 07:07:28 GMT"}, {"version": "v2", "created": "Sun, 11 Apr 2021 01:09:08 GMT"}, {"version": "v3", "created": "Mon, 3 May 2021 04:02:34 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Garg", "Nikhil", ""], ["Li", "Hannah", ""], ["Monachou", "Faidra", ""]]}, {"id": "2010.04458", "submitter": "Yelena Mejova", "authors": "Arthur Capozzi, Gianmarco De Francisci Morales, Yelena Mejova, Corrado\n  Monti, Andre Panisson, Daniela Paolotti", "title": "Facebook Ads: Politics of Migration in Italy", "comments": null, "journal-ref": "Social Informatics 2020", "doi": null, "report-no": "978-3-030-60975-7", "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Targeted online advertising is on the forefront of political communication,\nallowing hyper-local advertising campaigns around elections and issues. In this\nstudy, we employ a new resource for political ad monitoring -- Facebook Ads\nLibrary -- to examine advertising concerning the issue of immigration in Italy.\nA crucial topic in Italian politics, it has recently been a focus of several\npopulist movements, some of which have adopted social media as a powerful tool\nfor voter engagement. Indeed, we find evidence of targeting by the parties both\nin terms of geography and demographics (age and gender). For instance, Five\nStar Movement reaches a younger audience when advertising about immigration,\nwhile other parties' ads have a more male audience when advertising on this\nissue. We also notice a marked rise in advertising volume around elections, as\nwell as a shift to more general audience. Thus, we illustrate political\nadvertising targeting that likely has an impact on public opinion on a topic\ninvolving potentially vulnerable populations, and urge the research community\nto include online advertising in the monitoring of public discourse.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 09:32:31 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Capozzi", "Arthur", ""], ["Morales", "Gianmarco De Francisci", ""], ["Mejova", "Yelena", ""], ["Monti", "Corrado", ""], ["Panisson", "Andre", ""], ["Paolotti", "Daniela", ""]]}, {"id": "2010.04496", "submitter": "Alessandra Urbinati", "authors": "Alessandra Urbinati, Kyriaki Kalimeri, Andrea Bonanomi, Alessandro\n  Rosina, Ciro Cattuto, Daniela Paolotti", "title": "Young Adult Unemployment Through the Lens of Social Media: Italy as a\n  case study", "comments": "8 pages. Published in SocInfo 2020 Proceedings. Title update", "journal-ref": null, "doi": "10.1007/978-3-030-60975-7_28", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Youth unemployment rates are still in alerting levels for many countries,\namong which Italy. Direct consequences include poverty, social exclusion, and\ncriminal behaviours, while negative impact on the future employability and wage\ncannot be obscured. In this study, we employ survey data together with social\nmedia data, and in particular likes on Facebook Pages, to analyse personality,\nmoral values, but also cultural elements of the young unemployed population in\nItaly. Our findings show that there are small but significant differences in\npersonality and moral values, with the unemployed males to be less agreeable\nwhile females more open to new experiences. At the same time, unemployed have a\nmore collectivist point of view, valuing more in-group loyalty, authority, and\npurity foundations. Interestingly, topic modelling analysis did not reveal\nmajor differences in interests and cultural elements of the unemployed.\nUtilisation patterns emerged though; the employed seem to use Facebook to\nconnect with local activities, while the unemployed use it mostly as for\nentertainment purposes and as a source of news, making them susceptible to\nmis/disinformation. We believe these findings can help policymakers get a\ndeeper understanding of this population and initiatives that improve both the\nhard and the soft skills of this fragile population.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 10:56:04 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 17:35:26 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Urbinati", "Alessandra", ""], ["Kalimeri", "Kyriaki", ""], ["Bonanomi", "Andrea", ""], ["Rosina", "Alessandro", ""], ["Cattuto", "Ciro", ""], ["Paolotti", "Daniela", ""]]}, {"id": "2010.04508", "submitter": "Teresa Gomez-Diaz", "authors": "Teresa Gomez-Diaz and Tomas Recio", "title": "A policy and legal Open Science framework: a proposal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Our proposal of an Open Science definition as a political and legal framework\nwhere research outputs are shared and disseminated in order to be rendered\nvisible, accessible, reusable is developed, standing over the concepts enhanced\nby the Budapest Open Science Initiative (BOAI), and by the Free/Open Source\nSoftware (FOSS) and Open data movements. We elaborate this proposal through a\ndetailed analysis of some selected EC policies, laws and the role of research\nevaluation practices.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 11:44:37 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Gomez-Diaz", "Teresa", ""], ["Recio", "Tomas", ""]]}, {"id": "2010.04560", "submitter": "Yassine Himeur", "authors": "Yassine Himeur and Khalida Ghanem and Abdullah Alsalemi and Faycal\n  Bensaali and Abbes Amira", "title": "Artificial Intelligence based Anomaly Detection of Energy Consumption in\n  Buildings: A Review, Current Trends and New Perspectives", "comments": "11 Figures, 3 Tables", "journal-ref": "Applied Energy Volume 287, 1 April 2021, 116601", "doi": "10.1016/j.apenergy.2021.116601", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enormous amounts of data are being produced everyday by sub-meters and smart\nsensors installed in residential buildings. If leveraged properly, that data\ncould assist end-users, energy producers and utility companies in detecting\nanomalous power consumption and understanding the causes of each anomaly.\nTherefore, anomaly detection could stop a minor problem becoming overwhelming.\nMoreover, it will aid in better decision-making to reduce wasted energy and\npromote sustainable and energy efficient behavior. In this regard, this paper\nis an in-depth review of existing anomaly detection frameworks for building\nenergy consumption based on artificial intelligence. Specifically, an extensive\nsurvey is presented, in which a comprehensive taxonomy is introduced to\nclassify existing algorithms based on different modules and parameters adopted,\nsuch as machine learning algorithms, feature extraction approaches, anomaly\ndetection levels, computing platforms and application scenarios. To the best of\nthe authors' knowledge, this is the first review article that discusses anomaly\ndetection in building energy consumption. Moving forward, important findings\nalong with domain-specific problems, difficulties and challenges that remain\nunresolved are thoroughly discussed, including the absence of: (i) precise\ndefinitions of anomalous power consumption, (ii) annotated datasets, (iii)\nunified metrics to assess the performance of existing solutions, (iv) platforms\nfor reproducibility and (v) privacy-preservation. Following, insights about\ncurrent research trends are discussed to widen the applications and\neffectiveness of the anomaly detection technology before deriving future\ndirections attracting significant attention. This article serves as a\ncomprehensive reference to understand the current technological progress in\nanomaly detection of energy consumption based on artificial intelligence.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 13:28:34 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 19:50:14 GMT"}, {"version": "v3", "created": "Tue, 20 Oct 2020 11:20:35 GMT"}, {"version": "v4", "created": "Sun, 22 Nov 2020 23:27:52 GMT"}, {"version": "v5", "created": "Fri, 12 Feb 2021 15:14:52 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Himeur", "Yassine", ""], ["Ghanem", "Khalida", ""], ["Alsalemi", "Abdullah", ""], ["Bensaali", "Faycal", ""], ["Amira", "Abbes", ""]]}, {"id": "2010.04589", "submitter": "Xinyu Dong", "authors": "Xinyu Dong, Jianyuan Deng, Sina Rashidian, Kayley Abell-Hart, Wei Hou,\n  Richard N Rosenthal, Mary Saltz, Joel Saltz, Fusheng Wang", "title": "Identifying Risk of Opioid Use Disorder for Patients Taking Opioid\n  Medications with Deep Learning", "comments": "20 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The United States is experiencing an opioid epidemic, and there were more\nthan 10 million opioid misusers aged 12 or older each year. Identifying\npatients at high risk of Opioid Use Disorder (OUD) can help to make early\nclinical interventions to reduce the risk of OUD. Our goal is to predict OUD\npatients among opioid prescription users through analyzing electronic health\nrecords with machine learning and deep learning methods. This will help us to\nbetter understand the diagnoses of OUD, providing new insights on opioid\nepidemic. Electronic health records of patients who have been prescribed with\nmedications containing active opioid ingredients were extracted from Cerner\nHealth Facts database between January 1, 2008 and December 31, 2017. Long\nShort-Term Memory (LSTM) models were applied to predict opioid use disorder\nrisk in the future based on recent five encounters, and compared to Logistic\nRegression, Random Forest, Decision Tree and Dense Neural Network. Prediction\nperformance was assessed using F-1 score, precision, recall, and AUROC. Our\ntemporal deep learning model provided promising prediction results which\noutperformed other methods, with a F1 score of 0.8023 and AUCROC of 0.9369. The\nmodel can identify OUD related medications and vital signs as important\nfeatures for the prediction. LSTM based temporal deep learning model is\neffective on predicting opioid use disorder using a patient past history of\nelectronic health records, with minimal domain knowledge. It has potential to\nimprove clinical decision support for early intervention and prevention to\ncombat the opioid epidemic.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 14:18:07 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Dong", "Xinyu", ""], ["Deng", "Jianyuan", ""], ["Rashidian", "Sina", ""], ["Abell-Hart", "Kayley", ""], ["Hou", "Wei", ""], ["Rosenthal", "Richard N", ""], ["Saltz", "Mary", ""], ["Saltz", "Joel", ""], ["Wang", "Fusheng", ""]]}, {"id": "2010.04671", "submitter": "Kevin Lin", "authors": "Kevin Lin, Sumant Guha, Joe Spaniac, Andy Zheng", "title": "Nifty Web Apps: Build a Web App for Any Text-Based Programming\n  Assignment", "comments": "Special session submission in Proceedings of the 52nd ACM Technical\n  Symposium on Computer Science Education (SIGCSE '21); 2 pages; 1 figure", "journal-ref": null, "doi": "10.1145/3408877.3432580", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  While many students now interact with web apps across a variety of smart\ndevices, the vast majority of our Nifty Assignments still present traditional\nuser interfaces such as console input/output and desktop GUI. In this tutorial\nsession, participants will learn to build simple web apps for programming\nassignments that execute student-written code to dynamically respond to user\ninteractions resulting in a more modern app experience. Our approach requires\nup to 75% less code than similar desktop GUI apps while requiring few (if any)\nmodifications to existing assignments. Instructors and students alike can run\nand modify these web apps on their own computers or deploy their apps online\nfor access from any smart device at no cost. The tutorial presents examples\nfrom CS1 and CS2 courses in Python and Java, but the ideas apply generally.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 16:43:47 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 16:13:30 GMT"}, {"version": "v3", "created": "Fri, 13 Nov 2020 17:26:14 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Lin", "Kevin", ""], ["Guha", "Sumant", ""], ["Spaniac", "Joe", ""], ["Zheng", "Andy", ""]]}, {"id": "2010.04693", "submitter": "Yassine Himeur", "authors": "Christos Sardianos and Iraklis Varlamis and Christos Chronis and\n  George Dimitrakopoulos and Abdullah Alsalemi and Yassine Himeur and Faycal\n  Bensaali and Abbes Amira", "title": "Reshaping consumption habits by exploiting energy-related micro-moment\n  recommendations: A case study", "comments": "This paper will appear in Communications in Computer and Information\n  Science( CCIS) - Springer Book - [Smartgreens extension]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The environmental change and its effects, caused by human influences and\nnatural ecological processes over the last decade, prove that it is now more\nprudent than ever to transition to more sustainable models of energy\nconsumption behaviors. User energy consumption is inductively derived from the\ntime-to-time standards of living that shape the user's everyday consumption\nhabits. This work builds on the detection of repeated usage consumption\npatterns from consumption logs. It presents the structure and operation of an\nenergy consumption reduction system, which employs a set of sensors,\nsmart-meters and actuators in an office environment and targets specific user\nhabits. Using our previous research findings on the value of energy-related\nmicro-moment recommendations, the implemented system is an integrated solution\nthat avoids unnecessary energy consumption. With the use of a messaging API,\nthe system recommends to the user the proper energy saving action at the right\nmoment and gradually shapes user's habits. The solution has been implemented on\nthe Home Assistant open source platform, which allows the definition of\nautomations for controlling the office equipment. Experimental evaluation with\nseveral scenarios shows that the system manages first to reduce energy\nconsumption, and second, to trigger users' actions that could potentially urge\nthem to more sustainable energy consumption habits.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 17:29:56 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Sardianos", "Christos", ""], ["Varlamis", "Iraklis", ""], ["Chronis", "Christos", ""], ["Dimitrakopoulos", "George", ""], ["Alsalemi", "Abdullah", ""], ["Himeur", "Yassine", ""], ["Bensaali", "Faycal", ""], ["Amira", "Abbes", ""]]}, {"id": "2010.04736", "submitter": "Chenhao Tan", "authors": "Samuel Carton, Anirudh Rathore, Chenhao Tan", "title": "Evaluating and Characterizing Human Rationales", "comments": "14 pages, 15 figures, to appear in EMNLP 2020. Code is available at\n  https://github.com/BoulderDS/evaluating-human-rationales", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two main approaches for evaluating the quality of machine-generated\nrationales are: 1) using human rationales as a gold standard; and 2) automated\nmetrics based on how rationales affect model behavior. An open question,\nhowever, is how human rationales fare with these automatic metrics. Analyzing a\nvariety of datasets and models, we find that human rationales do not\nnecessarily perform well on these metrics. To unpack this finding, we propose\nimproved metrics to account for model-dependent baseline performance. We then\npropose two methods to further characterize rationale quality, one based on\nmodel retraining and one on using \"fidelity curves\" to reveal properties such\nas irrelevance and redundancy. Our work leads to actionable suggestions for\nevaluating and characterizing rationales.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 18:00:04 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Carton", "Samuel", ""], ["Rathore", "Anirudh", ""], ["Tan", "Chenhao", ""]]}, {"id": "2010.04830", "submitter": "Krasimir Yordzhev", "authors": "Adnan Sharaf Ali Yousef Al-Absi, Ivelina Peneva, Krasimir Yordzhev", "title": "Students Readiness for E-learning in the Universities in Yemen", "comments": null, "journal-ref": "Science and Technology Publishing, Vol. 1, Issue 8, 2017, 102-107", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The e-learning is an advanced version of traditional education. It is defined\nas a way of learning by using the communication mechanisms of modern computer\nnetworks and multimedia, including voice, image, and graphics and mechanisms to\nsearch electronic libraries, as well as web portals, whether in the context of\ndistance learning or in the classroom. The people who engage in the transition\nto web-supported education are the administrative staff, the faculty, and the\nstudents. They all have their needs and they all should meet specific\nrequirements in order to facilitate the transition. The article presents the\nresults of questionnaire research of the students readiness for e-learning in\nYemeni universities.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 22:32:56 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Al-Absi", "Adnan Sharaf Ali Yousef", ""], ["Peneva", "Ivelina", ""], ["Yordzhev", "Krasimir", ""]]}, {"id": "2010.04833", "submitter": "Pradipta Banerjee", "authors": "Pradipta Banerjee and Subhrabrata Choudhury", "title": "Pandemic Lessons -- Devising an assessment framework to analyse policies\n  for sustainability", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COVID-19 pandemic has sharply projected the globally persistent\nmulti-dimensional fundamental challenges in securing general socio-economic\nwellbeing of the society. The problems intensify with increasing population\ndensities and also vary with several socio-economic-geo-cultural activity\nparameters. These problems directly highlight the urgent need for accomplishing\nthe interdependent United Nations Sustainable Development Goals (SDGs) to\nensure that in future we do not enter into vicious loops of contracting newer\nzoonotic viruses and need not search for their vaccines while incurring\nsocio-economic havoc. Behavioural changes in human activities/responses are\nindispensable for achieving the interdependent SDGs. Using root cause analysis\napproach, we have developed a yearly assessment framework for viably analysing\nand identifying requisite region-specific downstream/upstream socio-economic\npolicies to reach the SDGs. The framework makes use of an infographic bar chart\nrepresentation based on the normalised values of 20 human activity/impact\nparameters classified under three categories as - negative, limiting and\npositive. With a holistic view encompassing the SDGs, we illustrate through\nthis framework the impact and urgent need of region-specific human behavioural\nreforms. This framework enables the foresight about policies regarding their\npotential in bringing down the negative parameter values to the desired zero\nlevel for accomplishing the SDGs through planetary health.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 22:39:10 GMT"}, {"version": "v2", "created": "Mon, 24 May 2021 14:59:47 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Banerjee", "Pradipta", ""], ["Choudhury", "Subhrabrata", ""]]}, {"id": "2010.04877", "submitter": "Josimar Chire Saire", "authors": "Josimar Edinson Chire Saire, Esteban Wilfredo Vilca Zu\\~niga", "title": "Analysis of Users Reaction around Impeachment in Peru using Twitter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Covid-19 pandemic generated many problems and show other hidden issues in\ncountries in South America. Every government analyzed his own context and\ndecided which health policies would be used. Peru is a country in the middle of\nSouth America region, the first reported case was on March 6. Besides, a\nlockdown was established in ground borders, sea and air. Peruvian government\nanalyzed the context and proposed many policies around health, economy,\nemployment, transport. But, these action were not enough for the existence of\nprevious lack of infrastructure in hospitals, as result of past governments. By\nthe other hand, a variety of politic parties in the Parliament and their search\nfor own interests, was evidenced during this pandemic period. Considering\nprevious condition of lack of success in health, economic policies, the\ndiscussion about possible impeachment started. Therefore, this work has the\nmain aim of finding evidence about what users were talking about and what was\nthe impact on Peruvian population using Twitter.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 02:27:41 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 01:08:37 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Saire", "Josimar Edinson Chire", ""], ["Zu\u00f1iga", "Esteban Wilfredo Vilca", ""]]}, {"id": "2010.04929", "submitter": "Zhu Tianhua", "authors": "Tianhua Zhu", "title": "Defining Computer Art: Methods, Themes, and the Aesthetic Problematic", "comments": "To appear on: China in Culture, vol. 1, no. 4, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The application of computer technology in the field of art has given rise to\nnovel modes of artistic practice, including media art, and it is a necessity to\nfind a commensurable conceptual fundament. Therefore, computer art starting\nfrom the 1950s reenters the view. To clarify the definition, major methods for\ndefining are reviewed, and it is argued that the thematic definition guided by\nsituational logic provides a feasible approach. There is a triad of themes: the\nrelationship between art and technology, the problem of machine creation, and\nthe ontology of art. Consisted of primitive and mutually supportive questions,\na logical space of questioning, i.e. a problematic, is formed as the basis for\nthe identity of computer art. Among them, the problem of the ontology of art is\nlocated at the logical starting point of questioning, and this problematic is\ntherefore an aesthetic one. The anticipation that computer art presents and\nresponds to the above-mentioned aesthetic problematic suggests the plausibility\nof computer art being a legitimate category of art.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 07:28:43 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Zhu", "Tianhua", ""]]}, {"id": "2010.05057", "submitter": "Depeng Xu", "authors": "Wei Du, Depeng Xu, Xintao Wu and Hanghang Tong", "title": "Fairness-aware Agnostic Federated Learning", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is an emerging framework that builds centralized machine\nlearning models with training data distributed across multiple devices. Most of\nthe previous works about federated learning focus on the privacy protection and\ncommunication cost reduction. However, how to achieve fairness in federated\nlearning is under-explored and challenging especially when testing data\ndistribution is different from training distribution or even unknown.\nIntroducing simple fairness constraints on the centralized model cannot achieve\nmodel fairness on unknown testing data. In this paper, we develop a\nfairness-aware agnostic federated learning framework (AgnosticFair) to deal\nwith the challenge of unknown testing distribution. We use kernel reweighing\nfunctions to assign a reweighing value on each training sample in both loss\nfunction and fairness constraint. Therefore, the centralized model built from\nAgnosticFair can achieve high accuracy and fairness guarantee on unknown\ntesting data. Moreover, the built model can be directly applied to local sites\nas it guarantees fairness on local data distributions. To our best knowledge,\nthis is the first work to achieve fairness in federated learning. Experimental\nresults on two real datasets demonstrate the effectiveness in terms of both\nutility and fairness under data shift scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 17:58:20 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Du", "Wei", ""], ["Xu", "Depeng", ""], ["Wu", "Xintao", ""], ["Tong", "Hanghang", ""]]}, {"id": "2010.05084", "submitter": "Benjamin Fish", "authors": "Benjamin Fish, Luke Stark", "title": "Reflexive Design for Fairness and Other Human Values in Formal Models", "comments": "Published in the proceedings of AIES 2021", "journal-ref": null, "doi": "10.1145/3461702.3462518", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms and other formal models purportedly incorporating human values\nlike fairness have grown increasingly popular in computer science. In response\nto sociotechnical challenges in the use of these models, designers and\nresearchers have taken widely divergent positions on how formal models\nincorporating aspects of human values should be used: encouraging their use,\nmoving away from them, or ignoring the normative consequences altogether. In\nthis paper, we seek to resolve these divergent positions by identifying the\nmain conceptual limits of formal modeling, and develop four reflexive\nvalues--value fidelity, appropriate accuracy, value legibility, and value\ncontestation--vital for incorporating human values adequately into formal\nmodels. We then provide a brief methodology for reflexively designing formal\nmodels incorporating human values.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 20:04:24 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 22:24:05 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Fish", "Benjamin", ""], ["Stark", "Luke", ""]]}, {"id": "2010.05137", "submitter": "Keshav Ganapathy", "authors": "David Tran, Alex Valtchanov, Keshav Ganapathy, Raymond Feng, Eric\n  Slud, Micah Goldblum, Tom Goldstein", "title": "An Open Review of OpenReview: A Critical Analysis of the Machine\n  Learning Conference Review Process", "comments": "19 pages, 6 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mainstream machine learning conferences have seen a dramatic increase in the\nnumber of participants, along with a growing range of perspectives, in recent\nyears. Members of the machine learning community are likely to overhear\nallegations ranging from randomness of acceptance decisions to institutional\nbias. In this work, we critically analyze the review process through a\ncomprehensive study of papers submitted to ICLR between 2017 and 2020. We\nquantify reproducibility/randomness in review scores and acceptance decisions,\nand examine whether scores correlate with paper impact. Our findings suggest\nstrong institutional bias in accept/reject decisions, even after controlling\nfor paper quality. Furthermore, we find evidence for a gender gap, with female\nauthors receiving lower scores, lower acceptance rates, and fewer citations per\npaper than their male counterparts. We conclude our work with recommendations\nfor future conference organizers.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 02:06:04 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 19:36:11 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Tran", "David", ""], ["Valtchanov", "Alex", ""], ["Ganapathy", "Keshav", ""], ["Feng", "Raymond", ""], ["Slud", "Eric", ""], ["Goldblum", "Micah", ""], ["Goldstein", "Tom", ""]]}, {"id": "2010.05470", "submitter": "Simone Raponi", "authors": "Gabriele Oligeri, Simone Raponi, Savio Sciancalepore, Roberto Di\n  Pietro", "title": "PAST-AI: Physical-layer Authentication of Satellite Transmitters via\n  Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physical-layer security is regaining traction in the research community, due\nto the performance boost introduced by deep learning classification algorithms.\nThis is particularly true for sender authentication in wireless communications\nvia radio fingerprinting. However, previous research efforts mainly focused on\nterrestrial wireless devices while, to the best of our knowledge, none of the\nprevious work took into consideration satellite transmitters. The satellite\nscenario is generally challenging because, among others, satellite radio\ntransducers feature non-standard electronics (usually aged and specifically\ndesigned for harsh conditions). Moreover, the fingerprinting task is\nspecifically difficult for Low-Earth Orbit (LEO) satellites (like the ones we\nfocus in this paper) since they orbit at about 800Km from the Earth, at a speed\nof around 25,000Km/h, thus making the receiver experiencing a down-link with\nunique attenuation and fading characteristics. In this paper, we propose\nPAST-AI, a methodology tailored to authenticate LEO satellites through\nfingerprinting of their IQ samples, using advanced AI solutions. Our\nmethodology is tested on real data -- more than 100M I/Q samples -- collected\nfrom an extensive measurements campaign on the IRIDIUM LEO satellites\nconstellation, lasting 589 hours. Results are striking: we prove that\nConvolutional Neural Networks (CNN) and autoencoders (if properly calibrated)\ncan be successfully adopted to authenticate the satellite transducers, with an\naccuracy spanning between 0.8 and 1, depending on prior assumptions. The\nproposed methodology, the achieved results, and the provided insights, other\nthan being interesting on their own, when associated to the dataset that we\nmade publicly available, will also pave the way for future research in the\narea.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 06:08:11 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Oligeri", "Gabriele", ""], ["Raponi", "Simone", ""], ["Sciancalepore", "Savio", ""], ["Di Pietro", "Roberto", ""]]}, {"id": "2010.05514", "submitter": "Luca Bedogni", "authors": "Luca Bedogni, Shakila Khan Rumi, Flora Salim", "title": "Modelling Memory for Individual Re-identification in Decentralised\n  Mobile Contact Tracing Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2020 the coronavirus outbreak changed the lives of people worldwide. After\nan initial time period in which it was unclear how to battle the virus, social\ndistancing has been recognised globally as an effective method to mitigate the\ndisease spread. This called for technological tools such as Mobile Contact\nTracing Applications (MCTA), which are used to digitally trace contacts among\npeople, and in case a positive case is found, people with the application\ninstalled which had been in contact will be notified. De-centralised MCTA may\nsuffer from a novel kind of privacy attack, based on the memory of the human\nbeings, which upon notification of the application can identify who is the\npositive individual responsible for the notification. Our results show that it\nis indeed possible to identify positive people among the group of contacts of a\nhuman being, and this is even easier when the sociability of the positive\nindividual is low. In practice, our simulation results show that identification\ncan be made with an accuracy of more than 90% depending on the scenario. We\nalso provide three mitigation strategies which can be implemented in\nde-centralised MCTA and analyse which of the three are more effective in\nlimiting this novel kind of attack.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 08:10:54 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 08:59:54 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Bedogni", "Luca", ""], ["Rumi", "Shakila Khan", ""], ["Salim", "Flora", ""]]}, {"id": "2010.05557", "submitter": "Yelena Mejova", "authors": "Yelena Mejova, V\\'ictor Suarez-Lled\\'o", "title": "Impact of Online Health Awareness Campaign: Case of National Eating\n  Disorders Association", "comments": null, "journal-ref": "Social Informatics 2020", "doi": "10.1007/978-3-030-60975-7_15", "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  National Eating Disorders Association conducts a NEDAwareness week every\nyear, during which it publishes content on social media and news aimed to raise\nawareness of eating disorders. Measuring the impact of these actions is vital\nfor maximizing the effectiveness of such interventions. This paper is an effort\nto model the change in behavior of users who engage with NEDAwareness content.\nWe find that, despite popular influencers being involved in the campaign, it is\ngovernmental and nonprofit accounts that attract the most retweets.\nFurthermore, examining the tweeting language of users engaged with this\ncontent, we find linguistic categories concerning women, family, and anxiety to\nbe mentioned more within the 15 days after the intervention, and categories\nconcerning affiliation, references to others, and positive emotion mentioned\nless. We conclude with actionable implications for future campaigns and\ndiscussion of the method's limitations.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 09:21:56 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Mejova", "Yelena", ""], ["Suarez-Lled\u00f3", "V\u00edctor", ""]]}, {"id": "2010.05809", "submitter": "Nader Sehatbakhsh", "authors": "Nader Sehatbakhsh, Ellie Daw, Onur Savas, Amin Hassanzadeh, Ian\n  McCulloh", "title": "Security and Privacy Considerations for Machine Learning Models Deployed\n  in the Government and Public Sector (white paper)", "comments": "5 pages", "journal-ref": "Proceedings of the AAAI Conference on Artificial Intelligence,\n  Fall Symposium Series (AAAI-FSS); 2019", "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning becomes a more mainstream technology, the objective for\ngovernments and public sectors is to harness the power of machine learning to\nadvance their mission by revolutionizing public services. Motivational\ngovernment use cases require special considerations for implementation given\nthe significance of the services they provide. Not only will these applications\nbe deployed in a potentially hostile environment that necessitates protective\nmechanisms, but they are also subject to government transparency and\naccountability initiatives which further complicates such protections.\n  In this paper, we describe how the inevitable interactions between a user of\nunknown trustworthiness and the machine learning models, deployed in\ngovernments and public sectors, can jeopardize the system in two major ways: by\ncompromising the integrity or by violating the privacy. We then briefly\noverview the possible attacks and defense scenarios, and finally, propose\nrecommendations and guidelines that once considered can enhance the security\nand privacy of the provided services.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 16:05:29 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Sehatbakhsh", "Nader", ""], ["Daw", "Ellie", ""], ["Savas", "Onur", ""], ["Hassanzadeh", "Amin", ""], ["McCulloh", "Ian", ""]]}, {"id": "2010.06019", "submitter": "Douglas Guilbeault R", "authors": "Douglas Guilbeault, Samuel Woolley and Joshua Becker", "title": "Probabilistic Social Learning Improves the Public's Detection of\n  Misinformation", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": "10.1371/journal.pone.0247487", "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The digital spread of misinformation is one of the leading threats to\ndemocracy, public health, and the global economy. Popular strategies for\nmitigating misinformation include crowdsourcing, machine learning, and media\nliteracy programs that require social media users to classify news in binary\nterms as either true or false. However, research on peer influence suggests\nthat framing decisions in binary terms can amplify judgment errors and limit\nsocial learning, whereas framing decisions in probabilistic terms can reliably\nimprove judgments. In this preregistered experiment, we compare online peer\nnetworks that collaboratively evaluate the veracity of news by communicating\neither binary or probabilistic judgments. Exchanging probabilistic estimates of\nnews veracity substantially improved individual and group judgments, with the\neffect of eliminating polarization in news evaluation. By contrast, exchanging\nbinary classifications reduced social learning and entrenched polarization. The\nbenefits of probabilistic social learning are robust to participants'\neducation, gender, race, income, religion, and partisanship.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 20:43:41 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 15:50:22 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Guilbeault", "Douglas", ""], ["Woolley", "Samuel", ""], ["Becker", "Joshua", ""]]}, {"id": "2010.06312", "submitter": "Vibhatha Abeykoon", "authors": "Vibhatha Abeykoon, Niranda Perera, Chathura Widanage, Supun\n  Kamburugamuve, Thejaka Amila Kanewala, Hasara Maithree, Pulasthi\n  Wickramasinghe, Ahmet Uyar and Geoffrey Fox", "title": "Data Engineering for HPC with Python", "comments": "9 pages, 11 images, Accepted in 9th Workshop on Python for\n  High-Performance and Scientific Computing (In conjunction with Supercomputing\n  20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CY cs.PF cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data engineering is becoming an increasingly important part of scientific\ndiscoveries with the adoption of deep learning and machine learning. Data\nengineering deals with a variety of data formats, storage, data extraction,\ntransformation, and data movements. One goal of data engineering is to\ntransform data from original data to vector/matrix/tensor formats accepted by\ndeep learning and machine learning applications. There are many structures such\nas tables, graphs, and trees to represent data in these data engineering\nphases. Among them, tables are a versatile and commonly used format to load and\nprocess data. In this paper, we present a distributed Python API based on table\nabstraction for representing and processing data. Unlike existing\nstate-of-the-art data engineering tools written purely in Python, our solution\nadopts high performance compute kernels in C++, with an in-memory table\nrepresentation with Cython-based Python bindings. In the core system, we use\nMPI for distributed memory computations with a data-parallel approach for\nprocessing large datasets in HPC clusters.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 11:53:11 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Abeykoon", "Vibhatha", ""], ["Perera", "Niranda", ""], ["Widanage", "Chathura", ""], ["Kamburugamuve", "Supun", ""], ["Kanewala", "Thejaka Amila", ""], ["Maithree", "Hasara", ""], ["Wickramasinghe", "Pulasthi", ""], ["Uyar", "Ahmet", ""], ["Fox", "Geoffrey", ""]]}, {"id": "2010.06403", "submitter": "Akhila Sri Manasa Venigalla", "authors": "Akhila Sri Manasa Venigalla and Sridhar Chimalakonda", "title": "EmoG- Towards Emojifying Gmail Conversations", "comments": "9 pages, 8 figures, 1 table, To appear in Proceedings of 54th Hawaii\n  International Conference on System Sciences, HICSS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Emails are one of the most frequently used medium of communication in the\npresent day across multiple domains including industry and educational\ninstitutions. Understanding sentiments being expressed in an email could have a\nconsiderable impact on the recipients' action or response to the email.\nHowever, it is difficult to interpret emotions of the sender from pure text in\nwhich emotions are not explicitly present. Researchers have tried to predict\ncustomer attrition by integrating emails in client-company environment with\nemotions. However, most of the existing works deal with static assessment of\nemail emotions. Presenting sentiments of emails dynamically to the reader could\nhelp in understanding senders' emotion and as well have an impact on readers'\naction. Hence, in this paper, we present EmoG as a Google Chrome Extension\nwhich is intended to support university students. It augments emails with\nemojis based on the sentiment being conveyed in the email, which might also\noffer faster overview of email sentiments and act as tags that could help in\nautomatic sorting and processing of emails. Currently, EmoG has been developed\nto support Gmail inbox on a Google Chrome browser, and could be extended to\nother inboxes and browsers with ease. We have conducted a user survey with 15\nuniversity students to understand the usefulness of EmoG and received positive\nfeedback.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 14:01:11 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 09:48:06 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Venigalla", "Akhila Sri Manasa", ""], ["Chimalakonda", "Sridhar", ""]]}, {"id": "2010.06455", "submitter": "Golshan Madraki", "authors": "Golshan Madraki, Isabella Grasso, Jacqueline Otala, Yu Liu, Jeanna\n  Matthews", "title": "Characterizing and Comparing COVID-19 Misinformation Across Languages,\n  Countries and Platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Misinformation/disinformation about COVID-19 has been rampant on social media\naround the world. In this study, we investigate COVID-19 misinformation/\ndisinformation on social media in multiple languages - Farsi (Persian),\nChinese, and English, about multiple countries - Iran, China, and the United\nStates (US), and on multiple platforms such as Twitter, Facebook, Instagram,\nWeibo, and WhatsApp. Misinformation, especially about a global pandemic, is a\nglobal problem yet it is common for studies of COVID-19 misinformation on\nsocial media to focus on a single language, like English, a single country,\nlike the US, or a single platform, like Twitter. We utilized opportunistic\nsampling to compile 200 specific items of viral and yet debunked misinformation\nacross these languages, countries and platforms emerged between January 1 and\nAugust 31. We then categorized this collection based both on the topics of the\nmisinformation and the underlying roots of that misinformation. Our\nmulti-cultural and multilingual team observed that the nature of COVID-19\nmisinformation on social media varied in substantial ways across different\nlanguages/countries depending on the cultures, beliefs/religions, popularity of\nsocial media, types of platforms, freedom of speech and the power of people\nversus governments. We observe that politics is at the root of most of the\ncollected misinformation across all three languages in this dataset. We further\nobserve the different impact of government restrictions on platforms and\nplatform restrictions on content in Iran, China, and the US and their impact on\na key question of our age: how do we control misinformation without silencing\nthe voices we need to hold governments accountable?\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 15:10:26 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 03:23:26 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Madraki", "Golshan", ""], ["Grasso", "Isabella", ""], ["Otala", "Jacqueline", ""], ["Liu", "Yu", ""], ["Matthews", "Jeanna", ""]]}, {"id": "2010.06657", "submitter": "Hancheng Cao", "authors": "Hancheng Cao, Mengjie Cheng, Zhepeng Cen, Daniel A. McFarland, Xiang\n  Ren", "title": "Will This Idea Spread Beyond Academia? Understanding Knowledge Transfer\n  of Scientific Concepts across Text Corpora", "comments": "EMNLP 2020 Findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What kind of basic research ideas are more likely to get applied in practice?\nThere is a long line of research investigating patterns of knowledge transfer,\nbut it generally focuses on documents as the unit of analysis and follow their\ntransfer into practice for a specific scientific domain. Here we study\ntranslational research at the level of scientific concepts for all scientific\nfields. We do this through text mining and predictive modeling using three\ncorpora: 38.6 million paper abstracts, 4 million patent documents, and 0.28\nmillion clinical trials. We extract scientific concepts (i.e., phrases) from\ncorpora as instantiations of \"research ideas\", create concept-level features as\nmotivated by literature, and then follow the trajectories of over 450,000 new\nconcepts (emerged from 1995-2014) to identify factors that lead only a small\nproportion of these ideas to be used in inventions and drug trials. Results\nfrom our analysis suggest several mechanisms that distinguish which scientific\nconcept will be adopted in practice, and which will not. We also demonstrate\nthat our derived features can be used to explain and predict knowledge transfer\nwith high accuracy. Our work provides greater understanding of knowledge\ntransfer for researchers, practitioners, and government agencies interested in\nencouraging translational research.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 19:46:59 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Cao", "Hancheng", ""], ["Cheng", "Mengjie", ""], ["Cen", "Zhepeng", ""], ["McFarland", "Daniel A.", ""], ["Ren", "Xiang", ""]]}, {"id": "2010.06667", "submitter": "Vinith Suriyakumar", "authors": "Vinith M. Suriyakumar, Nicolas Papernot, Anna Goldenberg, Marzyeh\n  Ghassemi", "title": "Chasing Your Long Tails: Differentially Private Prediction in Health\n  Care Settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models in health care are often deployed in settings where\nit is important to protect patient privacy. In such settings, methods for\ndifferentially private (DP) learning provide a general-purpose approach to\nlearn models with privacy guarantees. Modern methods for DP learning ensure\nprivacy through mechanisms that censor information judged as too unique. The\nresulting privacy-preserving models, therefore, neglect information from the\ntails of a data distribution, resulting in a loss of accuracy that can\ndisproportionately affect small groups. In this paper, we study the effects of\nDP learning in health care. We use state-of-the-art methods for DP learning to\ntrain privacy-preserving models in clinical prediction tasks, including x-ray\nclassification of images and mortality prediction in time series data. We use\nthese models to perform a comprehensive empirical investigation of the\ntradeoffs between privacy, utility, robustness to dataset shift, and fairness.\nOur results highlight lesser-known limitations of methods for DP learning in\nhealth care, models that exhibit steep tradeoffs between privacy and utility,\nand models whose predictions are disproportionately influenced by large\ndemographic groups in the training data. We discuss the costs and benefits of\ndifferentially private learning in health care.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 19:56:37 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Suriyakumar", "Vinith M.", ""], ["Papernot", "Nicolas", ""], ["Goldenberg", "Anna", ""], ["Ghassemi", "Marzyeh", ""]]}, {"id": "2010.06820", "submitter": "James Foulds", "authors": "Kamrun Naher Keya, Rashidul Islam, Shimei Pan, Ian Stockwell, James R.\n  Foulds", "title": "Equitable Allocation of Healthcare Resources with Fair Cox Models", "comments": "AAAI Fall Symposium on AI in Government and Public Sector (AAAI\n  FSS-20), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Healthcare programs such as Medicaid provide crucial services to vulnerable\npopulations, but due to limited resources, many of the individuals who need\nthese services the most languish on waiting lists. Survival models, e.g. the\nCox proportional hazards model, can potentially improve this situation by\npredicting individuals' levels of need, which can then be used to prioritize\nthe waiting lists. Providing care to those in need can prevent\ninstitutionalization for those individuals, which both improves quality of life\nand reduces overall costs. While the benefits of such an approach are clear,\ncare must be taken to ensure that the prioritization process is fair or\nindependent of demographic information-based harmful stereotypes. In this work,\nwe develop multiple fairness definitions for survival models and corresponding\nfair Cox proportional hazards models to ensure equitable allocation of\nhealthcare resources. We demonstrate the utility of our methods in terms of\nfairness and predictive accuracy on two publicly available survival datasets.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 06:08:15 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Keya", "Kamrun Naher", ""], ["Islam", "Rashidul", ""], ["Pan", "Shimei", ""], ["Stockwell", "Ian", ""], ["Foulds", "James R.", ""]]}, {"id": "2010.06984", "submitter": "Yunchi Zhu", "authors": "Yunchi Zhu, Zuohan Zhao, Chengda Tong, Xiaojun Xia", "title": "Small Private Online Judge: A New Tool for Empirical Education Research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper puts forward the concept of Small Private Online Judge (SPOJ).\nCompared with Massive Open Online Judge (MOOJ), SPOJ has advantages in\nstructured data acquisition of students' virtual behavior for its specific\nfunction and tight coupling with the classroom. SPOJ-based empirical education\nresearch can be conducted within \"Acquisition-Analysis-Application\" (3A)\nFramework. The case study of a SPOJ program clarifies the standard pattern of\nSPOJ-based 3A research and highlights the emergence of education-intelligence\nconcept. The challenges of SPOJ-based empirical education research and\nimplications of SPOJ are also discussed.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 04:58:45 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Zhu", "Yunchi", ""], ["Zhao", "Zuohan", ""], ["Tong", "Chengda", ""], ["Xia", "Xiaojun", ""]]}, {"id": "2010.06986", "submitter": "Sruthi Gorantla", "authors": "Sruthi Gorantla, Amit Deshpande, Anand Louis", "title": "On the Problem of Underranking in Group-Fair Ranking", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search and recommendation systems, such as search engines, recruiting tools,\nonline marketplaces, news, and social media, output ranked lists of content,\nproducts, and sometimes, people. Credit ratings, standardized tests, risk\nassessments output only a score, but are also used implicitly for ranking. Bias\nin such ranking systems, especially among the top ranks, can worsen social and\neconomic inequalities, polarize opinions, and reinforce stereotypes. On the\nother hand, a bias correction for minority groups can cause more harm if\nperceived as favoring group-fair outcomes over meritocracy. In this paper, we\nformulate the problem of underranking in group-fair rankings, which was not\naddressed in previous work. Most group-fair ranking algorithms post-process a\ngiven ranking and output a group-fair ranking. We define underranking based on\nhow close the group-fair rank of each item is to its original rank, and prove a\nlower bound on the trade-off achievable for simultaneous underranking and group\nfairness in ranking. We give a fair ranking algorithm that takes any given\nranking and outputs another ranking with simultaneous underranking and group\nfairness guarantees comparable to the lower bound we prove. Our algorithm works\nwith group fairness constraints for any number of groups. Our experimental\nresults confirm the theoretical trade-off between underranking and group\nfairness, and also show that our algorithm achieves the best of both when\ncompared to the state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 14:56:10 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 17:20:54 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Gorantla", "Sruthi", ""], ["Deshpande", "Amit", ""], ["Louis", "Anand", ""]]}, {"id": "2010.06988", "submitter": "Stefano Ermon", "authors": "Marshall Burke, Anne Driscoll, David B. Lobell, Stefano Ermon", "title": "Using satellite imagery to understand and promote sustainable\n  development", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate and comprehensive measurements of a range of sustainable development\noutcomes are fundamental inputs into both research and policy. We synthesize\nthe growing literature that uses satellite imagery to understand these\noutcomes, with a focus on approaches that combine imagery with machine\nlearning. We quantify the paucity of ground data on key human-related outcomes\nand the growing abundance and resolution (spatial, temporal, and spectral) of\nsatellite imagery. We then review recent machine learning approaches to\nmodel-building in the context of scarce and noisy training data, highlighting\nhow this noise often leads to incorrect assessment of models' predictive\nperformance. We quantify recent model performance across multiple sustainable\ndevelopment domains, discuss research and policy applications, explore\nconstraints to future progress, and highlight key research directions for the\nfield.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 05:20:00 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Burke", "Marshall", ""], ["Driscoll", "Anne", ""], ["Lobell", "David B.", ""], ["Ermon", "Stefano", ""]]}, {"id": "2010.06989", "submitter": "Fatima Zahra Yamani", "authors": "Fatima Zahra Yamani, Mohamed El Merouani", "title": "Review the Enterprise Resource Planning in Moroccan Healthcare\n  Organizations", "comments": null, "journal-ref": "IJCSI International Journal of Computer Science Issues, Volume 17,\n  Issue 2, March 2020", "doi": "10.5281/zenodo.3987129", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Hospital Information Systems (HIS) in Morocco take a central place in the\nprocess of patient care. An approach is made to analyze the current situation\nof the HIS within the institutions in order to bring an integral and generic\nvision, allowing the judicious articulation of the business and IT layers.\nCurrently, the Enterprise Resource Planning (ERP) implemented remains a system\nconsisting of several applications dedicated to specific areas. These systems\nhave become an indispensable element within any hospital. The goal of our study\nis to discover how the ERP has been used in Moroccan healthcare sector and how\nthese software should be implemented and used to improve healthcare services.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 20:55:04 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Yamani", "Fatima Zahra", ""], ["Merouani", "Mohamed El", ""]]}, {"id": "2010.07011", "submitter": "Jens Dittrich", "authors": "Jens Dittrich, Marcel Maltry", "title": "Database (Lecture) Streams on the Cloud: An Experience Report on\n  Teaching an Undergrad Database Lecture during a Pandemic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DB", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This is an experience report on teaching the undergrad lecture Big Data\nEngineering at Saarland University in summer term 2020 online. We describe our\nteaching philosophy, the tools used, what worked and what did not work. As we\nreceived extremely positive feedback from the students, in the future, we will\ncontinue to use the same teaching model for other lectures.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 11:08:06 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Dittrich", "Jens", ""], ["Maltry", "Marcel", ""]]}, {"id": "2010.07013", "submitter": "Carlos Molina-Jimenez", "authors": "Carlos Molina-Jimenez and Hazem Danny Al Nakib and Linmao Song and\n  Ioannis Sfyrakis and Jon Crowcroft", "title": "A Case for a Currencyless Economy Based on Bartering with Smart\n  Contracts", "comments": "The document consists of 22 pages in total, including references and\n  two figures. The author list has five authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We suggest the re-introduction of bartering to create a cryptocurrencyless,\ncurrencyless, and moneyless economy segment. We contend that a barter economy\nwould benefit enterprises, individuals, governments and societies. For\ninstance, the availability of an online peer-to-peer barter marketplace would\nconvert ordinary individuals into potential traders of both tangible and\ndigital items and services. For example, they will be able to barter files and\ndata that they collect. Equally motivating, they will be able to barter and\nre-introduce to the economy items that they no longer need such as, books,\ngarden tools, and bikes which are normally kept and wasted in garages and\nsheds. We argue that most of the pieces of technology needed for building a\nbarter system are now available, including blockchains, smart contracts,\ncryptography, secure multiparty computations and fair exchange protocols.\nHowever, additional research is needed to refine and integrate the pieces\ntogether. We discuss potential research directions.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 22:02:38 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Molina-Jimenez", "Carlos", ""], ["Nakib", "Hazem Danny Al", ""], ["Song", "Linmao", ""], ["Sfyrakis", "Ioannis", ""], ["Crowcroft", "Jon", ""]]}, {"id": "2010.07015", "submitter": "Sebastien Ducos", "authors": "Rafael Cestari, Sebastien Ducos (LIUPPA), Ernesto Exposito (LIUPPA)", "title": "iPaaS in Agriculture 4.0: An Industrial Case", "comments": null, "journal-ref": "WETICE'2020: 29th IEEE International Conference on Enabling\n  Technologies: Infrastructure for Collaborative Enterprises, 2020", "doi": null, "report-no": null, "categories": "cs.CY cs.MA cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current automation approaches in the Industry 4.0 have generated increased\ninterest in the utilization of Integration Platforms as a Service (iPaaS) cloud\narchitectures in order to unify and synchronize several systems, applications,\nand services in order to build smart solutions for automated and adaptive\nindustrial process management. Existing iPaaS solutions present several\nout-of-the-box connectors and automation engines for easier integration of\ncustomers' projects, but show issues regarding overall adaptation outside their\nscope, brand locking, and occasionally high prices. Moreover, existing\nplatforms fail to respond adequately to the needs of deploying multiple\ndecision models capable of offering automated or semi-automated management of\nprocesses, thanks to the integration of the large diversity of data and event\nsources as well as the different physical or logical action entities. With the\npopularization of open-source software and applications such as BPM Engines,\nMachine Learning libraries, and Integration suites and libraries, it is\npossible to develop a fully customizable and adaptable, open-source iPaaS that\ncan be used both in and outside industrial applications. In this paper, we\npropose a generic iPaaS architecture implemented on the basis of several open\nsource solutions boasting integration, interoperability, and automated\ndecision-making capabilities in the domain of Agriculture 4.0. A\nproof-of-concept based on these solutions is presented, as well as a case study\non MA{\\\"I}SADOUR's grain storage process with a comparison with the currently\nhuman-operated tasks.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 07:52:37 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Cestari", "Rafael", "", "LIUPPA"], ["Ducos", "Sebastien", "", "LIUPPA"], ["Exposito", "Ernesto", "", "LIUPPA"]]}, {"id": "2010.07016", "submitter": "Hamza Ahmad Madni Dr.", "authors": "Zain Mumtaz, Zeeshan Ilyas, Ahmed Sohaib, Saleem Ullah, Hamza Ahmad\n  Madni", "title": "Design and Implementation of User-Friendly and Low-Cost\n  Multiple-Application System for Smart City Using Microcontrollers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Our proposed system has seven main contributions, i.e., Smart street lights,\nSmart home, Bio-metric door and home security system, Intelligent traffic\nlights management and road security system, Private and smart parking,\nIntelligent accident management system and Smart information display/ notice\nboard system. Our prototypes / products employ Arduino UNO board, Node MCU,\nUltrasonic sensor, Fingerprint module, Servo motors, GSM, GPS, LEDs, Flame\nSensor, Bluetooth and Wi-Fi module etc. We are very confident that our proposed\nsystems are efficient, reliable, and cost-effective and can be easily tested\nand implemented on a large scale under real conditions.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 07:39:43 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Mumtaz", "Zain", ""], ["Ilyas", "Zeeshan", ""], ["Sohaib", "Ahmed", ""], ["Ullah", "Saleem", ""], ["Madni", "Hamza Ahmad", ""]]}, {"id": "2010.07017", "submitter": "Christopher Wild", "authors": "Wesley Burr, Fanny Chevalier, Christopher Collins, Alison L Gibbs,\n  Raymond Ng, Chris Wild", "title": "Computational Skills by Stealth in Secondary School Data Science", "comments": "38 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The unprecedented growth in the availability of data of all types and\nqualities and the emergence of the field of data science has provided an\nimpetus to finally realizing the implementation of the full breadth of the\nNolan and Temple Lang proposed integration of computing concepts into\nstatistics curricula at all levels in statistics and new data science programs\nand courses. Moreover, data science, implemented carefully, opens accessible\npathways to stem for students for whom neither mathematics nor computer science\nare natural affinities, and who would traditionally be excluded. We discuss a\nproposal for the stealth development of computational skills in students' first\nexposure to data science through careful, scaffolded exposure to computation\nand its power. The intent of this approach is to support students, regardless\nof interest and self-efficacy in coding, in becoming data-driven learners, who\nare capable of asking complex questions about the world around them, and then\nanswering those questions through the use of data-driven inquiry. This\ndiscussion is presented in the context of the International Data Science in\nSchools Project which recently published computer science and statistics\nconsensus curriculum frameworks for a two-year secondary school data science\nprogram, designed to make data science accessible to all.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 09:11:51 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Burr", "Wesley", ""], ["Chevalier", "Fanny", ""], ["Collins", "Christopher", ""], ["Gibbs", "Alison L", ""], ["Ng", "Raymond", ""], ["Wild", "Chris", ""]]}, {"id": "2010.07018", "submitter": "Nicholas Kluge Corr\\^ea", "authors": "Nicholas Kluge Corr\\^ea and Nythamar De Oliveira", "title": "Singularity and Coordination Problems: Pandemic Lessons from 2020", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  One of the strands of the Transhumanist movement, Singulitarianism, studies\nthe possibility that high-level artificial intelligence may be created in the\nfuture, debating ways to ensure that the interaction between human society and\nadvanced artificial intelligence can occur safely and beneficially. But how can\nwe guarantee this safe interaction? Are there any indications that a\nSingularity may be on the horizon? In trying to answer these questions, We'll\nmake a small introduction to the area of security research in artificial\nintelligence. We'll review some of the current paradigms in the development of\nautonomous intelligent systems and evidence that we can use to prospect the\ncoming of a possible technological Singularity. Finally, we will present a\nreflection using the COVID-19 pandemic, something that showed that our biggest\nproblem in managing existential risks is our lack of coordination skills as a\nglobal society.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 22:50:16 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Corr\u00eaa", "Nicholas Kluge", ""], ["De Oliveira", "Nythamar", ""]]}, {"id": "2010.07019", "submitter": "Teona Gelashvili", "authors": "Teona Gelashvili", "title": "Going Paperless -- Main Challenges in EDRMS Implementation -- Case of\n  Georgia", "comments": "65 pages, 6 chapters, 11 figures and 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  National governments are eager to incorporate information and communication\ntechnologies in their administrative agenda. Even though transformation from\ntraditional to digital methods seem attractive, there are obstacles which come\nalong with this change. Since countries are continuously implementing ICT-based\ntechnologies, the need for investigating the factors hindering their adoption\nbecomes crucial. The main objective of this study is to inquire Electronic\nDocuments and Records Management Systems (EDRMS) in the context of eGovernment.\nThe centre of the investigation is how EDRMS could raise efficiency in public\nservice delivery. Within the scope of this research, the associated challenges\nof the EDRMS implementation, possible ways to tackle those challenges and\nachieved benefits were analysed. For thorough examination, exploratory case\nstudy method was chosen, and the case of Georgia was investigated. For drawing\nconclusions and finding answers to the imposed questions qualitative approach\nwas selected. Different ICT adoption theories and case study examples were\nanalysed, among which the Estonian case was taken as a successful model.\nEmpirical data collection was also an integral part of the study during which\ninterviews with state officials, as well as experts, were conducted, and the\nquestionnaire among civil servants was distributed. As a result of the\nresearch, the main aspects of the EDRMS implementation were evaluated, and the\nprospect of the possible future study was imposed.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 06:37:53 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Gelashvili", "Teona", ""]]}, {"id": "2010.07022", "submitter": "Jonathan Kelly", "authors": "Alexis Morris and Hallie Siegel and Jonathan Kelly", "title": "Towards a Policy-as-a-Service Framework to Enable Compliant, Trustworthy\n  AI and HRI Systems in the Wild", "comments": "In Proceedings of the AAAI Fall Symposium on Artificial Intelligence\n  for Human-Robot Interaction: Trust & Explainability in Artificial\n  Intelligence for Human-Robot Interaction (AI-HRI'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC cs.RO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building trustworthy autonomous systems is challenging for many reasons\nbeyond simply trying to engineer agents that 'always do the right thing.' There\nis a broader context that is often not considered within AI and HRI: that the\nproblem of trustworthiness is inherently socio-technical and ultimately\ninvolves a broad set of complex human factors and multidimensional\nrelationships that can arise between agents, humans, organizations, and even\ngovernments and legal institutions, each with their own understanding and\ndefinitions of trust. This complexity presents a significant barrier to the\ndevelopment of trustworthy AI and HRI systems---while systems developers may\ndesire to have their systems 'always do the right thing,' they generally lack\nthe practical tools and expertise in law, regulation, policy and ethics to\nensure this outcome. In this paper, we emphasize the \"fuzzy\" socio-technical\naspects of trustworthiness and the need for their careful consideration during\nboth design and deployment. We hope to contribute to the discussion of\ntrustworthy engineering in AI and HRI by i) describing the policy landscape\nthat must be considered when addressing trustworthy computing and the need for\nusable trust models, ii) highlighting an opportunity for trustworthy-by-design\nintervention within the systems engineering process, and iii) introducing the\nconcept of a \"policy-as-a-service\" (PaaS) framework that can be readily applied\nby AI systems engineers to address the fuzzy problem of trust during the\ndevelopment and (eventually) runtime process. We envision that the PaaS\napproach, which offloads the development of policy design parameters and\nmaintenance of policy standards to policy experts, will enable runtime trust\ncapabilities intelligent systems in the wild.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 18:32:31 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Morris", "Alexis", ""], ["Siegel", "Hallie", ""], ["Kelly", "Jonathan", ""]]}, {"id": "2010.07023", "submitter": "David Leslie", "authors": "David Leslie", "title": "Understanding bias in facial recognition technologies", "comments": "49 pages", "journal-ref": null, "doi": "10.5281/zenodo.4050457", "report-no": null, "categories": "cs.CY cs.CV cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Over the past couple of years, the growing debate around automated facial\nrecognition has reached a boiling point. As developers have continued to\nswiftly expand the scope of these kinds of technologies into an almost\nunbounded range of applications, an increasingly strident chorus of critical\nvoices has sounded concerns about the injurious effects of the proliferation of\nsuch systems. Opponents argue that the irresponsible design and use of facial\ndetection and recognition technologies (FDRTs) threatens to violate civil\nliberties, infringe on basic human rights and further entrench structural\nracism and systemic marginalisation. They also caution that the gradual creep\nof face surveillance infrastructures into every domain of lived experience may\neventually eradicate the modern democratic forms of life that have long\nprovided cherished means to individual flourishing, social solidarity and human\nself-creation. Defenders, by contrast, emphasise the gains in public safety,\nsecurity and efficiency that digitally streamlined capacities for facial\nidentification, identity verification and trait characterisation may bring. In\nthis explainer, I focus on one central aspect of this debate: the role that\ndynamics of bias and discrimination play in the development and deployment of\nFDRTs. I examine how historical patterns of discrimination have made inroads\ninto the design and implementation of FDRTs from their very earliest moments.\nAnd, I explain the ways in which the use of biased FDRTs can lead\ndistributional and recognitional injustices. The explainer concludes with an\nexploration of broader ethical questions around the potential proliferation of\npervasive face-based surveillance infrastructures and makes some\nrecommendations for cultivating more responsible approaches to the development\nand governance of these technologies.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 20:45:46 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Leslie", "David", ""]]}, {"id": "2010.07025", "submitter": "Won Hee Ko", "authors": "Won Hee Ko, Michael G. Kent, Stefano Schiavon, Brendon Levitt,\n  Giovanni Betti", "title": "From concept to implementation: A review of evaluation methods on\n  view-out", "comments": "This article has been withdrawn by the authors because Section 7\n  needs to be expanded and clarified with a summary table that shows how the\n  view framework can be applied to real buildings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  View-out is one of the architectural design parameters that influence the\noccupants' health and well-being. This article conducts a critical literature\nreview on building standards, rating systems, and scientific studies that\nprovide evaluation methods and guidelines for quality view-out. Based on the\nliterature review, we identify primary variables for the quality of view-out,\ndescribe each variable's criteria, and propose recommendations for window\ndesign that ensure quality view-out.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 07:10:46 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 01:14:29 GMT"}, {"version": "v3", "created": "Wed, 11 Nov 2020 01:38:33 GMT"}, {"version": "v4", "created": "Mon, 1 Mar 2021 06:33:31 GMT"}, {"version": "v5", "created": "Thu, 4 Mar 2021 16:29:45 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Ko", "Won Hee", ""], ["Kent", "Michael G.", ""], ["Schiavon", "Stefano", ""], ["Levitt", "Brendon", ""], ["Betti", "Giovanni", ""]]}, {"id": "2010.07026", "submitter": "Thomas Matarazzo", "authors": "Thomas J. Matarazzo, D\\'aniel Kondor, Paolo Santi, Sebastiano Milardo,\n  Soheil S. Eshkevari, Shamim N. Pakzad, Carlo Ratti", "title": "Crowdsourcing Bridge Vital Signs with Smartphone Vehicle Trips", "comments": "17 pages, 9 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The efficacy of sensor data in modern bridge condition evaluations has been\nundermined by inaccessible technologies. While the links between vibrational\nproperties and structural health have been well established, high costs\nassociated with specialized sensor networks have prevented the integration of\nsuch data with bridge management systems. In the last decade, researchers\npredicted that crowd-sourced mobile sensor data, collected ubiquitously and\ncheaply, will revolutionize our ability to maintain existing infrastructure;\nyet no such applications have successfully overcome the challenge of extracting\nuseful information in the field with sufficient precision. Here we fill this\nknowledge gap by showing that critical physical properties of a real bridge can\nbe determined accurately from everyday vehicle trip data. We collected\nsmartphone data from controlled field experiments and UBER rides on the Golden\nGate Bridge and developed an analytical method to recover modal properties,\nwhich paves the way for scalable, cost-effective structural health monitoring\nbased on this abundant data class. Our results are consistent with a\ncomprehensive study on the Golden Gate Bridge. We assess the benefit of\ncontinuous monitoring with reliability models and show that the inclusion of\ncrowd-sourced data in a bridge maintenance plan can add over fourteen years of\nservice (30% increase) to a bridge without additional costs. These results\ncertify the immediate value of large-scale data sources for studying the health\nof existing infrastructure, whether the data are crowdsensed or generated by\norganized vehicle fleets such as ridesourcing companies or municipalities.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 12:39:43 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 14:37:21 GMT"}, {"version": "v3", "created": "Fri, 6 Nov 2020 17:59:17 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Matarazzo", "Thomas J.", ""], ["Kondor", "D\u00e1niel", ""], ["Santi", "Paolo", ""], ["Milardo", "Sebastiano", ""], ["Eshkevari", "Soheil S.", ""], ["Pakzad", "Shamim N.", ""], ["Ratti", "Carlo", ""]]}, {"id": "2010.07028", "submitter": "Awad Abdelhalim", "authors": "Ellis Kessler, Moeti Masiane, Awad Abdelhalim", "title": "Privacy Concerns Regarding Occupant Tracking in Smart Buildings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tracking of occupants within buildings has become a topic of interest in the\npast decade. Occupant tracking has been used in the public safety, energy\nconservation, and marketing fields. Various methods have been demonstrated\nwhich can track people outside of and inside buildings; including GPS,\nvisual-based tracking using surveillance cameras, and vibration-based tracking\nusing sensors such as accelerometers. In this work, those main systems for\ntracking occupants are compared and contrasted for the levels of detail they\ngive about where occupants are, as well as their respective privacy concerns\nand how identifiable the tracking information collected is to a specific\nperson. We discuss a case study using vibrations sensors mounted in Virginia\nTech's Goodwin Hall that was recently conducted, demonstrating that similar\nlevels of accuracy in occupant localization can be achieved to current methods,\nand highlighting the amount of identifying information in the vibration signals\ndataset. Finally, a method of transforming the vibration data to preserve\noccupant privacy was proposed and tested on the dataset. The results indicate\nthat our proposed method has successfully resulted in anonymizing the\noccupant's gender information which was previously identifiable from the\nvibration data, while minimally impacting the localization accuracy achieved\nwithout anonymization.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 23:33:11 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Kessler", "Ellis", ""], ["Masiane", "Moeti", ""], ["Abdelhalim", "Awad", ""]]}, {"id": "2010.07029", "submitter": "Juan M Garcia-Gomez", "authors": "Juan M Garcia-Gomez", "title": "Basic principles and concept design of a real-time clinical decision\n  support system for managing medical emergencies on missions to Mars", "comments": "35 pages, 1 figure, 3 tables, 60 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Space agencies and private companies prepare the beginning of human space\nexploration for the 2030s with missions to put the first human on the Mars\nsurface. The absence of gravity and radiation, along with distance, isolation\nand hostile environments, are expected to increase medical events where\npreviously unseen manifestations may arise. The current healthcare strategy\nbased on telemedicine and the possibility to stabilize and transport the\ninjured crewmember to a terrestrial definitive medical facility is not\napplicable in exploration class missions. Therefore, the need for deploying the\nfull autonomous capability to solve medical emergencies may guide the design of\nfuture onboard healthcare systems. We present ten basic principles and concept\ndesign of a software suite to bring onboard decision support to help the crew\ndealing with medical emergencies taking into consideration physiological\ndisturbances in space and spaceflight restrictions. 1) give real-time support\nfor emergency medical decision making, 2) give patient-specific advice for\nexecutive problem-solving, 3) take into account available information from life\nsupport and monitoring of crewmembers, 4) be fully autonomous from remote\nfacilities, 5) continuously adapt predictions to physiological disturbance and\nchanging conditions, 6) optimize emergency medical decision making in terms of\nmission fundamental priorities, 7) take into account medical supplies and\nequipment on board, 8) apply health standards for the level of care V, 9)\nimplement ethics responsibilities for spaceflights, and 10) apply ethical\nstandards for artificial intelligence. Based on these principles, we propose an\nautonomous clinical decision support system (CDSS) to provide real-time advice\nfor emergency medical interventions on board of space exploration missions.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 21:32:28 GMT"}, {"version": "v2", "created": "Sat, 27 Feb 2021 19:06:48 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Garcia-Gomez", "Juan M", ""]]}, {"id": "2010.07036", "submitter": "Seyedamin Pouriyeh", "authors": "Osama Shahid, Mohammad Nasajpour, Seyedamin Pouriyeh, Reza M. Parizi,\n  Meng Han, Maria Valero, Fangyu Li, Mohammed Aledhari, Quan Z. Sheng", "title": "Machine Learning Research Towards Combating COVID-19: Virus Detection,\n  Spread Prevention, and Medical Assistance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COVID-19 was first discovered in December 2019 and has continued to rapidly\nspread across countries worldwide infecting thousands and millions of people.\nThe virus is deadly, and people who are suffering from prior illnesses or are\nolder than the age of 60 are at a higher risk of mortality. Medicine and\nHealthcare industries have surged towards finding a cure, and different\npolicies have been amended to mitigate the spread of the virus. While Machine\nLearning (ML) methods have been widely used in other domains, there is now a\nhigh demand for ML-aided diagnosis systems for screening, tracking, and\npredicting the spread of COVID-19 and finding a cure against it. In this paper,\nwe present a journey of what role ML has played so far in combating the virus,\nmainly looking at it from a screening, forecasting, and vaccine perspectives.\nWe present a comprehensive survey of the ML algorithms and models that can be\nused on this expedition and aid with battling the virus.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 21:27:11 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Shahid", "Osama", ""], ["Nasajpour", "Mohammad", ""], ["Pouriyeh", "Seyedamin", ""], ["Parizi", "Reza M.", ""], ["Han", "Meng", ""], ["Valero", "Maria", ""], ["Li", "Fangyu", ""], ["Aledhari", "Mohammed", ""], ["Sheng", "Quan Z.", ""]]}, {"id": "2010.07038", "submitter": "David Conal Higgins", "authors": "David Higgins", "title": "OnRAMP for Regulating AI in Medical Products", "comments": "46 pages, 3 tables, 1 figure. Published in Advanced Intelligent\n  Systems, July 2021. (See DOI link)", "journal-ref": null, "doi": "10.1002/aisy.202100042", "report-no": null, "categories": "cs.CY cs.AI stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Medical Artificial Intelligence (AI) involves the application of machine\nlearning algorithms to biomedical datasets in order to improve medical\npractices. Products incorporating medical AI require certification before\ndeployment in most jurisdictions. To date, clear pathways for regulating\nmedical AI are still under development. Below the level of formal pathways lies\nthe actual practice of developing a medical AI solution. This Perspective\nproposes best practice guidelines for development compatible with the\nproduction of a regulatory package which, regardless of the formal regulatory\npath, will form a core component of a certification process. The approach is\npredicated on a statistical risk perspective, typical of medical device\nregulators, and a deep understanding of machine learning methodologies. These\nguidelines will allow all parties to communicate more clearly in the\ndevelopment of a common Good Machine Learning Practice (GMLP), and thus lead to\nthe enhanced development of both medical AI products and regulations.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 14:02:30 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 14:52:24 GMT"}, {"version": "v3", "created": "Mon, 9 Nov 2020 15:47:15 GMT"}, {"version": "v4", "created": "Mon, 30 Nov 2020 14:41:05 GMT"}, {"version": "v5", "created": "Mon, 1 Feb 2021 14:51:39 GMT"}, {"version": "v6", "created": "Mon, 26 Jul 2021 11:51:05 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Higgins", "David", ""]]}, {"id": "2010.07039", "submitter": "Pablo Dorta-Gonzalez", "authors": "Sara M. Gonz\\'alez-Betancor, Pablo Dorta-Gonz\\'alez", "title": "Risk of Interruption of Doctoral Studies and Mental Health in PhD\n  Students", "comments": "12 pages, 1 figure, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  PhD students report a higher prevalence of mental illness symptoms than\nhighly educated individuals in the general population. This situation presents\na serious problem for universities. Thus, the knowledge about this phenomenon\nis of great importance in decision-making. In this paper we use the Nature PhD\nsurvey 2019 and estimate several binomial logistic regression models to analyze\nthe risk of interrupting doctoral studies. This risk is measured through the\ndesire of change in either the supervisor or the area of expertise, or the wish\nof not pursue a PhD. Among the explanatory factors, we focus on the influence\nof anxiety/depression, discrimination, and bullying. As control variables we\nuse demographic characteristics and others related with the doctoral program.\nInsufficient contact time with supervisors, and exceeding time spent studying\n-crossing the 50-h week barrier-, are risk factors of PhD studies interruption,\nbut the most decisive risk factor is poor mental health. Universities should\ntherefore foster an environment of well-being, which allows the development of\nautonomy and resilience of their PhD students or, when necessary, which fosters\nthe development of conflict resolution skills.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 10:48:46 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Gonz\u00e1lez-Betancor", "Sara M.", ""], ["Dorta-Gonz\u00e1lez", "Pablo", ""]]}, {"id": "2010.07041", "submitter": "Leandros Maglaras A", "authors": "Maria Papathanasaki, Georgios Dimitriou, Leandros Maglaras, Ismini\n  Vasileiou, Helge Janicke", "title": "From Cyber Terrorism to Cyber Peacekeeping: Are we there yet?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Cyberspace nowadays, there is a burst of information that everyone has\naccess. However, apart from the advantages the Internet offers, it also hides\nnumerous dangers for both people and nations. Cyberspace has a dark side,\nincluding terrorism, bullying, and other types of violence. Cyberwarfare is a\nkind of virtual war that causes the same destruction that a physical war would\nalso do. In this article, we discuss what Cyberterrorism is and how it can lead\nto Cyberwarfare.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 19:55:40 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Papathanasaki", "Maria", ""], ["Dimitriou", "Georgios", ""], ["Maglaras", "Leandros", ""], ["Vasileiou", "Ismini", ""], ["Janicke", "Helge", ""]]}, {"id": "2010.07054", "submitter": "Deepak P", "authors": "Deepak P and Savitha Sam Abraham", "title": "Representativity Fairness in Clustering", "comments": "In 12th ACM Web Science Conference (WebSci 2020)", "journal-ref": null, "doi": "10.1145/3394231.3397910", "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incorporating fairness constructs into machine learning algorithms is a topic\nof much societal importance and recent interest. Clustering, a fundamental task\nin unsupervised learning that manifests across a number of web data scenarios,\nhas also been subject of attention within fair ML research. In this paper, we\ndevelop a novel notion of fairness in clustering, called representativity\nfairness. Representativity fairness is motivated by the need to alleviate\ndisparity across objects' proximity to their assigned cluster representatives,\nto aid fairer decision making. We illustrate the importance of representativity\nfairness in real-world decision making scenarios involving clustering and\nprovide ways of quantifying objects' representativity and fairness over it. We\ndevelop a new clustering formulation, RFKM, that targets to optimize for\nrepresentativity fairness along with clustering quality. Inspired by the\n$K$-Means framework, RFKM incorporates novel loss terms to formulate an\nobjective function. The RFKM objective and optimization approach guides it\ntowards clustering configurations that yield higher representativity fairness.\nThrough an empirical evaluation over a variety of public datasets, we establish\nthe effectiveness of our method. We illustrate that we are able to\nsignificantly improve representativity fairness at only marginal impact to\nclustering quality.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 21:50:06 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["P", "Deepak", ""], ["Abraham", "Savitha Sam", ""]]}, {"id": "2010.07055", "submitter": "Vladimir Simovic", "authors": "V. Simovic, M. Varga, V. Simovic", "title": "Croatian public companies for energy distribution and supply:\n  integration of information subsystems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research is about integration of information subsystems from:information\nsystem procurement, financial information system, information system security,\ntechnical information systems and legal information systems, and about their\nmutual dependence and close connections in Croatian public companies for energy\ndistribution and supply. Also, herewe research the main goals of procurement\ninformation system which must be achieved in every organization because\nprocurement process takes place in every public organization. Based on the\nmodel of the business technology matrix their processes can be executed by\nother companies engaged in similar activities. This research paper describes\nthe timing of the sub processes, also. The timing of sub processes needs to be\nreduced as much as possible to achieve the planned results at the exit of the\nsub processes so that the costs of running sub-processes are equal to or lower\nthan they had been so far, but with a higher quality output. We discuss\npossible threats to the information systems organization, and how to protect\nelectronic information in the process of restoration of electronic data base\nfor the financial information system. At the end the research paper we explain\nthe advantages and disadvantages of cloud computing, information security in\nthe event of possible applications of computing in the clouds and activities\nfor technical information system in the flow diagram.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 13:27:00 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Simovic", "V.", ""], ["Varga", "M.", ""], ["Simovic", "V.", ""]]}, {"id": "2010.07086", "submitter": "Muhammad Tahir", "authors": "Abdul Wahab Muzaffar, Muhammad Tahir, Muhammad Waseem Anwar, Qaiser\n  Chaudry, Shamaila Rasheed Mir, Yawar Rasheed", "title": "A Systematic Review of Online Exams Solutions in E-learning: Techniques,\n  Tools and Global Adoption", "comments": "41 pages, 7 figures, 13 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  E-learning in higher education is exponentially increased during the past\ndecade due to its inevitable benefits in critical situations like natural\ndisasters, and pandemic. The reliable, fair, and seamless execution of online\nexams in E-learning is highly significant. Particularly, online exams are\nconducted on E-learning platforms without the physical presence of students and\ninstructors at the same place. This poses several issues like integrity and\nsecurity during online exams. To address such issues, researchers frequently\nproposed different techniques and tools. However, a study summarizing and\nanalyzing latest developments, particularly in the area of online examination,\nis hard to find in the literature. In this article, an SLR for online\nexamination is performed to select and analyze 53 studies published during the\nlast five years. Subsequently, five leading online exams features targeted in\nthe selected studies are identified and underlying development approaches for\nthe implementation of online exams solutions are explored. Furthermore, 16\nimportant techniques and 11 datasets are presented. In addition, 21 online\nexams tools proposed in the selected studies are identified. Additionally, 25\nleading existing tools used in the selected studies are also presented.\nFinally, the participation of countries in online exam research is\ninvestigated. Key factors for the global adoption of online exams are\nidentified and investigated. This facilitates the selection of right online\nexam system for a particular country on the basis of existing E-learning\ninfrastructure and overall cost. To conclude, the findings of this article\nprovide a solid platform for the researchers and practitioners of the domain to\nselect appropriate features along with underlying development approaches, tools\nand techniques for the implementation of a particular online exams solution as\nper given requirements.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 14:45:56 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 19:47:26 GMT"}, {"version": "v3", "created": "Fri, 12 Feb 2021 23:18:46 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Muzaffar", "Abdul Wahab", ""], ["Tahir", "Muhammad", ""], ["Anwar", "Muhammad Waseem", ""], ["Chaudry", "Qaiser", ""], ["Mir", "Shamaila Rasheed", ""], ["Rasheed", "Yawar", ""]]}, {"id": "2010.07188", "submitter": "Ian Kennedy", "authors": "Ian Kennedy, Arosha Bandara, Blaine Price", "title": "Towards Increasing Trust In Expert Evidence Derived From Malware\n  Forensic Tools", "comments": "Article in press. Accepted by Journal of Digital Forensics, Security\n  and Law (JDFSL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following a series of high profile miscarriages of justice in the UK linked\nto questionable expert evidence, the post of the Forensic Science Regulator was\ncreated in 2008. The main objective of this role is to improve the standard of\npractitioner competences and forensic procedures. One of the key strategies\ndeployed to achieve this is the push to incorporate a greater level of\nscientific conduct in the various fields of forensic practice. Currently there\nis no statutory requirement for practitioners to become accredited to continue\nworking with the Criminal Justice System of England and Wales. However, the\nForensic Science Regulator is lobbying the UK Government to make this\nmandatory. This paper focuses upon the challenge of incorporating a scientific\nmethodology to digital forensic investigations where malicious software\n('malware') has been identified. One aspect of such a methodology is the\napproach followed to both select and evaluate the tools used to perform dynamic\nmalware analysis during an investigation. Based on the literature, legal,\nregulatory and practical needs we derive a set of requirements to address this\nchallenge. We present a framework, called the 'Malware Analysis Tool Evaluation\nFramework' (MATEF), to address this lack of methodology to evaluate software\ntools used to perform dynamic malware analysis during investigations involving\nmalware and discuss how it meets the derived requirements.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 16:01:53 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Kennedy", "Ian", ""], ["Bandara", "Arosha", ""], ["Price", "Blaine", ""]]}, {"id": "2010.07292", "submitter": "Hancheng Cao", "authors": "Hancheng Cao, Vivian Yang, Victor Chen, Yu Jin Lee, Lydia Stone,\n  N'godjigui Junior Diarrassouba, Mark E. Whiting, Michael S. Bernstein", "title": "My Team Will Go On: Differentiating High and Low Viability Teams through\n  Team Interaction", "comments": "CSCW 2020 Honorable Mention Award", "journal-ref": "Proc. ACM Hum.-Comput. Interact. 4, CSCW3, Article 230 (December\n  2020)", "doi": "10.1145/3432929", "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding team viability -- a team's capacity for sustained and future\nsuccess -- is essential for building effective teams. In this study, we\naggregate features drawn from the organizational behavior literature to train a\nviability classification model over a dataset of 669 10-minute text\nconversations of online teams. We train classifiers to identify teams at the\ntop decile (most viable teams), 50th percentile (above a median split), and\nbottom decile (least viable teams), then characterize the attributes of teams\nat each of these viability levels. We find that a lasso regression model\nachieves an accuracy of .74--.92 AUC ROC under different thresholds of\nclassifying viability scores. From these models, we identify the use of\nexclusive language such as `but' and `except', and the use of second person\npronouns, as the most predictive features for detecting the most viable teams,\nsuggesting that active engagement with others' ideas is a crucial signal of a\nviable team. Only a small fraction of the 10-minute discussion, as little as 70\nseconds, is required for predicting the viability of team interaction. This\nwork suggests opportunities for teams to assess, track, and visualize their own\nviability in real time as they collaborate.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 21:33:36 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 22:30:20 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Cao", "Hancheng", ""], ["Yang", "Vivian", ""], ["Chen", "Victor", ""], ["Lee", "Yu Jin", ""], ["Stone", "Lydia", ""], ["Diarrassouba", "N'godjigui Junior", ""], ["Whiting", "Mark E.", ""], ["Bernstein", "Michael S.", ""]]}, {"id": "2010.07295", "submitter": "Luz Adriana Mejia Casta\\~no", "authors": "Adriana Mejia Casta\\~no, Javier E Hernandez, Angie Mendez Llanos", "title": "Kids Today: Remote Education in the time of COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent COVID-19 breakup, it became necessary to implement remote\nclasses in schools and universities to safeguard health and life. However, many\nstudents (teachers and parents, also) face great difficulties accessing and\nstaying in class due to technology limitations, affecting their education.\nUsing several nationally representative datasets in Colombia, this article\ndocuments how the academic performance of students in their final high school\nyear is affected due to technologies, aggregated by municipalities. We conclude\nthat internet access strongly affects these results, and little improvement on\nthe internet/computer access will reflect better academic performance. Under\nthese conditions, belonging to an ethnic group or high rurality (non-geographic\ncentralized municipalities) has a negative impact. Policy implications are\ndiscussed.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 14:32:04 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Casta\u00f1o", "Adriana Mejia", ""], ["Hernandez", "Javier E", ""], ["Llanos", "Angie Mendez", ""]]}, {"id": "2010.07297", "submitter": "Evangelos Mitsakis", "authors": "Chrysostomos Mylonas, Charis Chalkiadakis, Alexandros Dolianitis,\n  Dimitris Tzanis, Evangelos Mitsakis", "title": "Assessing the Readiness of Greece for Autonomous Vehicle Technologies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the debate regarding the timeframe and rate of penetration of\nAutonomous Vehicles, their potential benefits and implications have been widely\nrecognized. Therefore, assessing the readiness of individual countries to adopt\nsuch technologies and adapt to their introduction is of particular importance.\nThis paper aims to enrich our understanding of EU readiness regarding the\nintroduction of autonomous vehicle technologies by assessing the case of\nGreece. Thus, through a literature review, the criteria upon which such an\nassessment should be based are established and analyzed. Subsequently, the case\nof Greece is assessed based on those criteria by finding relevant sources that\nsupport and justify any assessment. Regardless of the outcome concerning the\nreadiness of Greece, such an assessment should help identify areas in which\nfocus should be given in order to ensure a smoother transition to such\ntechnologies. This contribution is expected to assist policy makers in Greece.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 16:57:25 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Mylonas", "Chrysostomos", ""], ["Chalkiadakis", "Charis", ""], ["Dolianitis", "Alexandros", ""], ["Tzanis", "Dimitris", ""], ["Mitsakis", "Evangelos", ""]]}, {"id": "2010.07298", "submitter": "Evangelos Mitsakis", "authors": "Charis Chalkiadakis, Dimitris Tzanis, Evangelos Mitsakis", "title": "Enabling older citizens safe mobility. The ACTIVAGE approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We live in an ever-aging world. The percentage of older citizens increases in\nmodern societies as older citizens represent the 19.20% of the general\npopulation. In Greece, an increase of almost 7% of older citizens has been\nobserved in the last twenty years. As old age never comes alone, age-related\nimpairments should be considered in the effort to provide safe transport\nconditions for them. It is of importance that transportation services have to\nmeet the special requirements and needs of older citizens. European Union,\nthrough the ACTIVAGE project, aims at using the Internet of Things (IoT)\nsolutions in favor of older citizens. In the framework of this project, the\nACTIVAGE Safe Mobility Platform (ASMP) has been designed. Therefore, older\ncitizens and their relatives have access to information regarding their\ntravels. In the context of this study, an extensive description of the ASMP and\nthe services offered through it is provided.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 17:01:43 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Chalkiadakis", "Charis", ""], ["Tzanis", "Dimitris", ""], ["Mitsakis", "Evangelos", ""]]}, {"id": "2010.07299", "submitter": "Evangelos Mitsakis", "authors": "Areti Kotsi, Evangelos Mitsakis, Dimitris Tzanis", "title": "Overview of C-ITS Deployment Projects in Europe and USA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperative Intelligent Transportation Systems (C-ITS) are technologies that\nenable vehicles to communicate with each other and with the road\ninfrastructure. These innovative technologies enable road users and traffic\nmanagers to share useful information, assisting the coordination of their\nactions. During the last years various initiatives providing policy rules for\nC-ITS deployment and a large number of projects demonstrating C-ITS\nimplementation have taken place in Europe and USA. However, the identification\nof the status of C-ITS deployment remains ambiguous at binational level. The\npurpose of this paper is to provide an overview of the European and US\nmilestones, that have been reached so far in the field of C-ITS, by identifying\nand reporting the policy framework, as well as the projects concerning C-ITS\ndeployment in Europe and USA.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 17:07:28 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Kotsi", "Areti", ""], ["Mitsakis", "Evangelos", ""], ["Tzanis", "Dimitris", ""]]}, {"id": "2010.07343", "submitter": "Vishwali Mhasawade", "authors": "Vishwali Mhasawade and Rumi Chunara", "title": "Causal Multi-Level Fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic systems are known to impact marginalized groups severely, and\nmore so, if all sources of bias are not considered. While work in algorithmic\nfairness to-date has primarily focused on addressing discrimination due to\nindividually linked attributes, social science research elucidates how some\nproperties we link to individuals can be conceptualized as having causes at\nmacro (e.g. structural) levels, and it may be important to be fair to\nattributes at multiple levels. For example, instead of simply considering race\nas a causal, protected attribute of an individual, the cause may be distilled\nas perceived racial discrimination an individual experiences, which in turn can\nbe affected by neighborhood-level factors. This multi-level conceptualization\nis relevant to questions of fairness, as it may not only be important to take\ninto account if the individual belonged to another demographic group, but also\nif the individual received advantaged treatment at the macro-level. In this\npaper, we formalize the problem of multi-level fairness using tools from causal\ninference in a manner that allows one to assess and account for effects of\nsensitive attributes at multiple levels. We show importance of the problem by\nillustrating residual unfairness if macro-level sensitive attributes are not\naccounted for, or included without accounting for their multi-level nature.\nFurther, in the context of a real-world task of predicting income based on\nmacro and individual-level attributes, we demonstrate an approach for\nmitigating unfairness, a result of multi-level sensitive attributes.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 18:26:17 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 18:06:29 GMT"}, {"version": "v3", "created": "Wed, 12 May 2021 18:48:01 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Mhasawade", "Vishwali", ""], ["Chunara", "Rumi", ""]]}, {"id": "2010.07487", "submitter": "Alon Jacovi", "authors": "Alon Jacovi, Ana Marasovi\\'c, Tim Miller, Yoav Goldberg", "title": "Formalizing Trust in Artificial Intelligence: Prerequisites, Causes and\n  Goals of Human Trust in AI", "comments": "Accepted to ACM FAccT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trust is a central component of the interaction between people and AI, in\nthat 'incorrect' levels of trust may cause misuse, abuse or disuse of the\ntechnology. But what, precisely, is the nature of trust in AI? What are the\nprerequisites and goals of the cognitive mechanism of trust, and how can we\npromote them, or assess whether they are being satisfied in a given\ninteraction? This work aims to answer these questions. We discuss a model of\ntrust inspired by, but not identical to, sociology's interpersonal trust (i.e.,\ntrust between people). This model rests on two key properties of the\nvulnerability of the user and the ability to anticipate the impact of the AI\nmodel's decisions. We incorporate a formalization of 'contractual trust', such\nthat trust between a user and an AI is trust that some implicit or explicit\ncontract will hold, and a formalization of 'trustworthiness' (which detaches\nfrom the notion of trustworthiness in sociology), and with it concepts of\n'warranted' and 'unwarranted' trust. We then present the possible causes of\nwarranted trust as intrinsic reasoning and extrinsic behavior, and discuss how\nto design trustworthy AI, how to evaluate whether trust has manifested, and\nwhether it is warranted. Finally, we elucidate the connection between trust and\nXAI using our formalization.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 03:07:23 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2021 21:14:17 GMT"}, {"version": "v3", "created": "Wed, 20 Jan 2021 12:24:26 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Jacovi", "Alon", ""], ["Marasovi\u0107", "Ana", ""], ["Miller", "Tim", ""], ["Goldberg", "Yoav", ""]]}, {"id": "2010.07636", "submitter": "Hiruni Gunaratne", "authors": "Hiruni Gunaratne, Ingrid Pappel", "title": "Enhancement of the e-Invoicing Systems by Increasing the Efficiency of\n  Workflows via Disruptive Technologies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  E-invoicing is a rapidly growing e-service in Europe as well as in the world.\nIt is identified as a substantially significant element in progressing towards\nthe goals of Digital Economy in the European Union.\n  This thesis focuses on identifying inefficiencies in e-invoicing systems\ncurrently in use and the opportunities to apply emerging technologies such as\nartificial intelligence and robotic process automation, in order to increase\nefficiency and level of automatization. The study incorporates expert opinions\nand users perceptions in e-invoicing systems on the status quo and the\nnecessities for higher automation. We focus on e-invoicing systems in the\nBaltic region consisting of the countries Estonia, Latvia and Lithuania. Based\non the conducted research, the drawbacks in e-invoicing systems were identified\nrelated to operational, technological and information security related.\nFurthermore, the automation opportunities and general requirements for\nautomation were identified. The functionalities that can be improved are\ndiscovered as well discussed in this thesis and the advantages of using\nemerging technologies in the context are explained. Based on research outcomes\nwe propose a conceptual e-invoicing ecosystem and present recommenda-tions for\nits application along the future work needed in that field.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 10:09:25 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Gunaratne", "Hiruni", ""], ["Pappel", "Ingrid", ""]]}, {"id": "2010.07680", "submitter": "Pankesh Patel", "authors": "Bhavin Joshi and Tapan Pathak and Vatsal Patel and Sarth Kanani and\n  Pankesh Patel and Muhammad Intizar Ali and John Breslin", "title": "Demonstration of a Cloud-based Software Framework for Video Analytics\n  Application using Low-Cost IoT Devices", "comments": "arXiv admin note: substantial text overlap with arXiv:2009.09065", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CV cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The design of products and services such as a Smart doorbell, demonstrating\nvideo analytics software/algorithm functionality, is expected to address a new\nkind of requirements such as designing a scalable solution while considering\nthe trade-off between cost and accuracy; a flexible architecture to deploy new\nAI-based models or update existing models, as user requirements evolve; as well\nas seamlessly integrating different kinds of user interfaces and devices. To\naddress these challenges, we propose a smart doorbell that orchestrates video\nanalytics across Edge and Cloud resources. The proposal uses AWS as a base\nplatform for implementation and leverages Commercially Available\nOff-The-Shelf(COTS) affordable devices such as Raspberry Pi in the form of an\nEdge device.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 06:05:32 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Joshi", "Bhavin", ""], ["Pathak", "Tapan", ""], ["Patel", "Vatsal", ""], ["Kanani", "Sarth", ""], ["Patel", "Pankesh", ""], ["Ali", "Muhammad Intizar", ""], ["Breslin", "John", ""]]}, {"id": "2010.07833", "submitter": "Jonas H\\\"ochst", "authors": "Jonas H\\\"ochst, Alvar Penning, Patrick Lampe, Bernd Freisleben", "title": "PIMOD: A Tool for Configuring Single-Board Computer Operating System\n  Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer systems used in the field of humanitarian technology are often based\non general-purpose single-board computers, such as Raspberry Pis. While these\nsystems offer great flexibility for developers and users, configuration and\ndeployment either introduces overhead by executing scripts on multiple devices\nor requires deeper technical understanding when building operating system\nimages for such small computers from scratch. In this paper, we present PIMOD,\na software tool for configuring operating system images for single-board\ncomputer systems. We propose a simple yet comprehensive configuration language.\nIn a configuration profile, called Pifile, a small set of commands is used to\ndescribe the configuration of an operating system image. Virtualization\ntechniques are used during the execution of the profile in order to be\ndistribution and platform independent. Commands can be issued in the guest\noperating system, providing access to the distribution specific tools, e.g., to\nconfigure hardware parameters. The implementation of PIMOD is made public under\na free and open source license. PIMOD is evaluated in terms of user benefits,\nperformance compared to on-system configuration, and applicability across\ndifferent hardware platforms and operating systems.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 15:52:25 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["H\u00f6chst", "Jonas", ""], ["Penning", "Alvar", ""], ["Lampe", "Patrick", ""], ["Freisleben", "Bernd", ""]]}, {"id": "2010.07845", "submitter": "Hanjia Lyu", "authors": "Xupin Zhang, Hanjia Lyu, Jiebo Luo", "title": "Understanding the Hoarding Behaviors during the COVID-19 Pandemic using\n  Large Scale Social Media Data", "comments": "Accepted for publication into the working paper track and for\n  presentation at the International Conference on Social Computing,\n  Behavioral-Cultural Modeling & Prediction and Behavior Representation in\n  Modeling and Simulation (SBP-BRiMS), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic has affected people's lives around the world on an\nunprecedented scale. We intend to investigate hoarding behaviors in response to\nthe pandemic using large-scale social media data. First, we collect\nhoarding-related tweets shortly after the outbreak of the coronavirus. Next, we\nanalyze the hoarding and anti-hoarding patterns of over 42,000 unique Twitter\nusers in the United States from March 1 to April 30, 2020, and dissect the\nhoarding-related tweets by age, gender, and geographic location. We find the\npercentage of females in both hoarding and anti-hoarding groups is higher than\nthat of the general Twitter user population. Furthermore, using topic modeling,\nwe investigate the opinions expressed towards the hoarding behavior by\ncategorizing these topics according to demographic and geographic groups. We\nalso calculate the anxiety scores for the hoarding and anti-hoarding related\ntweets using a lexical approach. By comparing their anxiety scores with the\nbaseline Twitter anxiety score, we reveal further insights. The LIWC anxiety\nmean for the hoarding-related tweets is significantly higher than the baseline\nTwitter anxiety mean. Interestingly, beer has the highest calculated anxiety\nscore compared to other hoarded items mentioned in the tweets.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 16:02:25 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 17:53:34 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Zhang", "Xupin", ""], ["Lyu", "Hanjia", ""], ["Luo", "Jiebo", ""]]}, {"id": "2010.07848", "submitter": "Emil Wiedemann", "authors": "Philip Hacker, Emil Wiedemann, Meike Zehlike", "title": "Towards a Flexible Framework for Algorithmic Fairness", "comments": "forthcoming in INFORMATIK2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasingly, scholars seek to integrate legal and technological insights to\ncombat bias in AI systems. In recent years, many different definitions for\nensuring non-discrimination in algorithmic decision systems have been put\nforward. In this paper, we first briefly describe the EU law framework covering\ncases of algorithmic discrimination. Second, we present an algorithm that\nharnesses optimal transport to provide a flexible framework to interpolate\nbetween different fairness definitions. Third, we show that important normative\nand legal challenges remain for the implementation of algorithmic fairness\ninterventions in real-world scenarios. Overall, the paper seeks to contribute\nto the quest for flexible technical frameworks that can be adapted to varying\nlegal and normative fairness constraints.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 16:06:53 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Hacker", "Philip", ""], ["Wiedemann", "Emil", ""], ["Zehlike", "Meike", ""]]}, {"id": "2010.07868", "submitter": "Neave O'Clery Dr", "authors": "Fabian Ying and Neave O'Clery", "title": "Modelling COVID-19 transmission in supermarkets using an agent-based\n  model", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0249821", "report-no": null, "categories": "physics.soc-ph cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the outbreak of COVID-19 in early March 2020, UK supermarkets have\nimplemented different policies to reduce the virus transmission in stores to\nprotect both customers and staff, such as restricting the maximum number of\ncustomers in a store, changes to the store layout, or enforcing a mandatory\nface covering policy. To quantitatively assess these mitigation methods, we\nformulate an agent-based model of customer movement in a supermarket (which we\nrepresent by a network) with a simple virus transmission model based on the\namount of time a customer spends in close proximity to infectious customers. We\napply our model to synthetic store and shopping data to show how one can use\nour model to estimate the number of infections due to human-to-human contact in\nstores and how to model different store interventions. The source code is\nopenly available at https://github.com/fabianying/covid19-supermarket-abm. We\nencourage retailers to use the model to find the most effective store policies\nthat reduce virus transmission in stores and thereby protect both customers and\nstaff.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 16:44:36 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 18:51:45 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Ying", "Fabian", ""], ["O'Clery", "Neave", ""]]}, {"id": "2010.08182", "submitter": "Shengwen Li", "authors": "Junfang Gong, Shengwen Li, Xinyue Ye, Qiong Peng", "title": "Measuring the Dynamic Impact of High-Speed Railways on Urban\n  Interactions in China", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-speed rail (HSR) has become an important mode of inter-city\ntransportation between large cities. Inter-city interaction facilitated by HSR\ntends to play a more prominent role in promoting urban and regional economic\nintegration and development. Quantifying the impact of HSR's interaction on\ncities and people is therefore crucial for long-term urban and regional\ndevelopment planning and policy making. We develop an evaluation framework\nusing toponym information from social media as a proxy to estimate the dynamics\nof such interactions. This paper adopts two types of spatial information:\ntoponyms from social media posts, and the geographical location information\nembedded in social media posts. The framework highlights the asymmetric nature\nof social interaction among cities, and proposes a series of metrics to\nquantify such impact from multiple perspectives, including interaction\nstrength, spatial decay, and channel effect. The results show that HSRs not\nonly greatly expand the uneven distribution of inter-city connections, but also\nsignificantly reshape the interactions that occur along HSR routes through the\nchannel effect.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 06:06:47 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 08:05:31 GMT"}, {"version": "v3", "created": "Thu, 29 Oct 2020 00:01:29 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Gong", "Junfang", ""], ["Li", "Shengwen", ""], ["Ye", "Xinyue", ""], ["Peng", "Qiong", ""]]}, {"id": "2010.08478", "submitter": "Jayaraman J. Thiagarajan", "authors": "Jayaraman J. Thiagarajan, Peer-Timo Bremer, Rushil Anirudh, Timothy C.\n  Germann, Sara Y. Del Valle, Frederick H. Streitz", "title": "Machine Learning-Powered Mitigation Policy Optimization in\n  Epidemiological Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A crucial aspect of managing a public health crisis is to effectively balance\nprevention and mitigation strategies, while taking their socio-economic impact\ninto account. In particular, determining the influence of different\nnon-pharmaceutical interventions (NPIs) on the effective use of public\nresources is an important problem, given the uncertainties on when a vaccine\nwill be made available. In this paper, we propose a new approach for obtaining\noptimal policy recommendations based on epidemiological models, which can\ncharacterize the disease progression under different interventions, and a\nlook-ahead reward optimization strategy to choose the suitable NPI at different\nstages of an epidemic. Given the time delay inherent in any epidemiological\nmodel and the exponential nature especially of an unmanaged epidemic, we find\nthat such a look-ahead strategy infers non-trivial policies that adhere well to\nthe constraints specified. Using two different epidemiological models, namely\nSEIR and EpiCast, we evaluate the proposed algorithm to determine the optimal\nNPI policy, under a constraint on the number of daily new cases and the primary\nreward being the absence of restrictions.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 16:27:17 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Thiagarajan", "Jayaraman J.", ""], ["Bremer", "Peer-Timo", ""], ["Anirudh", "Rushil", ""], ["Germann", "Timothy C.", ""], ["Del Valle", "Sara Y.", ""], ["Streitz", "Frederick H.", ""]]}, {"id": "2010.08485", "submitter": "Samuel Raymond", "authors": "August G. Domel, Samuel J. Raymond, Chiara Giordano, Yuzhe Liu, Seyed\n  Abdolmajid Yousefsani, Michael Fanton, Ileana Pirozzi, Ali Kight, Brett\n  Avery, Athanasia Boumis, Tyler Fetters, Simran Jandu, William M Mehring, Sam\n  Monga, Nicole Mouchawar, India Rangel, Eli Rice, Pritha Roy, Sohrab Sami,\n  Heer Singh, Lyndia Wu, Calvin Kuo, Michael Zeineh, Gerald Grant, David B.\n  Camarillo", "title": "A New Open-Access Platform for Measuring and Sharing mTBI Data", "comments": "21 pages, 3 figures, 1 table", "journal-ref": "Sci Rep 11, 7501 (2021)", "doi": "10.1038/s41598-021-87085-2", "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite numerous research efforts, the precise mechanisms of concussion have\nyet to be fully uncovered. Clinical studies on high-risk populations, such as\ncontact sports athletes, have become more common and give insight on the link\nbetween impact severity and brain injury risk through the use of wearable\nsensors and neurological testing. However, as the number of institutions\noperating these studies grows, there is a growing need for a platform to share\nthese data to facilitate our understanding of concussion mechanisms and aid in\nthe development of suitable diagnostic tools. To that end, this paper puts\nforth two contributions: 1) a centralized, open-source platform for storing and\nsharing head impact data, in collaboration with the Federal Interagency\nTraumatic Brain Injury Research informatics system (FITBIR), and 2) a deep\nlearning impact detection algorithm (MiGNet) to differentiate between true head\nimpacts and false positives for the previously biomechanically validated\ninstrumented mouthguard sensor (MiG2.0), all of which easily interfaces with\nFITBIR. We report 96% accuracy using MiGNet, based on a neural network model,\nimproving on previous work based on Support Vector Machines achieving 91%\naccuracy, on an out of sample dataset of high school and collegiate football\nhead impacts. The integrated MiG2.0 and FITBIR system serve as a collaborative\nresearch tool to be disseminated across multiple institutions towards creating\na standardized dataset for furthering the knowledge of concussion biomechanics.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 16:37:52 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Domel", "August G.", ""], ["Raymond", "Samuel J.", ""], ["Giordano", "Chiara", ""], ["Liu", "Yuzhe", ""], ["Yousefsani", "Seyed Abdolmajid", ""], ["Fanton", "Michael", ""], ["Pirozzi", "Ileana", ""], ["Kight", "Ali", ""], ["Avery", "Brett", ""], ["Boumis", "Athanasia", ""], ["Fetters", "Tyler", ""], ["Jandu", "Simran", ""], ["Mehring", "William M", ""], ["Monga", "Sam", ""], ["Mouchawar", "Nicole", ""], ["Rangel", "India", ""], ["Rice", "Eli", ""], ["Roy", "Pritha", ""], ["Sami", "Sohrab", ""], ["Singh", "Heer", ""], ["Wu", "Lyndia", ""], ["Kuo", "Calvin", ""], ["Zeineh", "Michael", ""], ["Grant", "Gerald", ""], ["Camarillo", "David B.", ""]]}, {"id": "2010.08612", "submitter": "Hancheng Cao", "authors": "Zhilong Chen, Hancheng Cao, Fengli Xu, Mengjie Cheng, Tao Wang, Yong\n  Li", "title": "Understanding the Role of Intermediaries in Online Social E-commerce: An\n  Exploratory Study of Beidian", "comments": "In CSCW 2020", "journal-ref": null, "doi": "10.1145/3415185", "report-no": null, "categories": "cs.CY cs.HC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social e-commerce, as a new form of social computing based marketing\nplatforms, utilizes existing real-world social relationships for promotions and\nsales of products. It has been growing rapidly in recent years and attracted\ntens of millions of users in China. A key group of actors who enable market\ntransactions on these platforms are intermediaries who connect producers with\nconsumers by sharing information with and recommending products to their\nreal-world social contacts. Despite their crucial role, the nature and behavior\nof these intermediaries on these social e-commerce platforms has not been\nsystematically analyzed. Here we address this knowledge gap through a mixed\nmethod study. Leveraging 9 months' all-round behavior of about 40 million users\non Beidian -- one of the largest social e-commerce sites in China, alongside\nwith qualitative evidence from online forums and interviews, we examine\ncharacteristics of intermediaries, identify their behavioral patterns and\nuncover strategies and mechanisms that make successful intermediaries. We\ndemonstrate that intermediaries on social e-commerce sites act as local trend\ndetectors and \"social grocers\". Furthermore, successful intermediaries are\nhighly dedicated whenever best sellers appear and broaden items for promotion.\nTo the best of our knowledge, this paper presents the first large-scale\nanalysis on the emerging role of intermediaries in social e-commerce platforms,\nwhich provides potential insights for the design and management of social\ncomputing marketing platforms.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 20:07:35 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Chen", "Zhilong", ""], ["Cao", "Hancheng", ""], ["Xu", "Fengli", ""], ["Cheng", "Mengjie", ""], ["Wang", "Tao", ""], ["Li", "Yong", ""]]}, {"id": "2010.08743", "submitter": "Ismini Lourentzou", "authors": "Arkin Dharawat and Ismini Lourentzou and Alex Morales and ChengXiang\n  Zhai", "title": "Drink bleach or do what now? Covid-HeRA: A dataset for risk-informed\n  health decision making in the presence of COVID19 misinformation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the wide spread of inaccurate medical advice related to the 2019\ncoronavirus pandemic (COVID-19), such as fake remedies, treatments and\nprevention suggestions, misinformation detection has emerged as an open problem\nof high importance and interest for the NLP community. To combat potential harm\nof COVID19-related misinformation, we release Covid-HeRA, a dataset for health\nrisk assessment of COVID-19-related social media posts. More specifically, we\nstudy the severity of each misinformation story, i.e., how harmful a message\nbelieved by the audience can be and what type of signals can be used to\ndiscover high malicious fake news and detect refuted claims. We present a\ndetailed analysis, evaluate several simple and advanced classification models,\nand conclude with our experimental analysis that presents open challenges and\nfuture directions.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 08:34:57 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Dharawat", "Arkin", ""], ["Lourentzou", "Ismini", ""], ["Morales", "Alex", ""], ["Zhai", "ChengXiang", ""]]}, {"id": "2010.08814", "submitter": "Leo Ferres", "authors": "Luca Pappalardo, Leo Ferres, Manuel Sacasa, Ciro Cattuto, Loreto Bravo", "title": "An individual-level ground truth dataset for home location detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY physics.soc-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Home detection, assigning a phone device to its home antenna, is a ubiquitous\npart of most studies in the literature on mobile phone data. Despite its\nwidespread use, home detection relies on a few assumptions that are difficult\nto check without ground truth, i.e., where the individual that owns the device\nresides. In this paper, we provide an unprecedented evaluation of the accuracy\nof home detection algorithms on a group of sixty-five participants for whom we\nknow their exact home address and the antennas that might serve them. Besides,\nwe analyze not only Call Detail Records (CDRs) but also two other mobile phone\nstreams: eXtended Detail Records (XDRs, the ``data'' channel) and Control Plane\nRecords (CPRs, the network stream). These data streams vary not only in their\ntemporal granularity but also they differ in the data generation mechanism',\ne.g., CDRs are purely human-triggered while CPR is purely machine-triggered\nevents. Finally, we quantify the amount of data that is needed for each stream\nto carry out successful home detection for each stream. We find that the choice\nof stream and the algorithm heavily influences home detection, with an\nhour-of-day algorithm for the XDRs performing the best, and with CPRs\nperforming best for the amount of data needed to perform home detection. Our\nwork is useful for researchers and practitioners in order to minimize data\nrequests and to maximize the accuracy of home antenna location.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 15:41:27 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Pappalardo", "Luca", ""], ["Ferres", "Leo", ""], ["Sacasa", "Manuel", ""], ["Cattuto", "Ciro", ""], ["Bravo", "Loreto", ""]]}, {"id": "2010.08850", "submitter": "Alex Hanna", "authors": "Alex Hanna, Tina M. Park", "title": "Against Scale: Provocations and Resistances to Scale Thinking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  At the heart of what drives the bulk of innovation and activity in Silicon\nValley and elsewhere is scalability. This unwavering commitment to scalability\n-- to identify strategies for efficient growth -- is at the heart of what we\nrefer to as \"scale thinking.\" Whether people are aware of it or not, scale\nthinking is all-encompassing. It is not just an attribute of one's product,\nservice, or company, but frames how one thinks about the world (what\nconstitutes it and how it can be observed and measured), its problems (what is\na problem worth solving versus not), and the possible technological fixes for\nthose problems. This paper examines different facets of scale thinking and its\nimplication on how we view technology and collaborative work. We argue that\ntechnological solutions grounded in scale thinking are unlikely to be as\nliberatory or effective at deep, systemic change as their purveyors imagine.\nRather, solutions which resist scale thinking are necessary to undo the social\nstructures which lie at the heart of social inequality. We draw on recent work\non mutual aid networks and propose questions to ask of collaborative work\nsystems as a means to evaluate technological solutions and guide designers in\nidentifying sites of resistance to scale thinking.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 19:03:39 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 23:46:43 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Hanna", "Alex", ""], ["Park", "Tina M.", ""]]}, {"id": "2010.08866", "submitter": "Saraju Mohanty", "authors": "Sibi C. Sethuraman and Pranav Kompally and Saraju P. Mohanty and Uma\n  Choppali", "title": "MyWear: A Smart Wear for Continuous Body Vital Monitoring and Emergency\n  Alert", "comments": "25 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart healthcare which is built as healthcare Cyber-Physical System (H-CPS)\nfrom Internet-of-Medical-Things (IoMT) is becoming more important than before.\nMedical devices and their connectivity through Internet with alongwith the\nelectronics health record (EHR) and AI analytics making H-CPS possible.\nIoMT-end devices like wearables and implantables are key for H-CPS based smart\nhealthcare. Smart garment is a specific wearable which can be used for smart\nhealthcare. There are various smart garments that help users to monitor their\nbody vitals in real-time. Many commercially available garments collect the\nvital data and transmit it to the mobile application for visualization.\nHowever, these don't perform real-time analysis for the user to comprehend\ntheir health conditions. Also, such garments are not included with an alert\nsystem to alert users and contacts in case of emergency. In MyWear, we propose\na wearable body vital monitoring garment that captures physiological data and\nautomatically analyses such heart rate, stress level, muscle activity to detect\nabnormalities. A copy of the physiological data is transmitted to the cloud for\ndetecting any abnormalities in heart beats and predict any potential heart\nfailure in future. We also propose a deep neural network (DNN) model that\nautomatically classifies abnormal heart beat and potential heart failure. For\nimmediate assistance in such a situation, we propose an alert system that sends\nan alert message to nearby medical officials. The proposed MyWear has an\naverage accuracy of 96.9% and precision of 97.3% for detection of the\nabnormalities.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 21:11:20 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Sethuraman", "Sibi C.", ""], ["Kompally", "Pranav", ""], ["Mohanty", "Saraju P.", ""], ["Choppali", "Uma", ""]]}, {"id": "2010.09112", "submitter": "Ivan Homoliak Ph.D.", "authors": "Sarad Venugopalan, Ivan Homoliak, Zengpeng Li, Pawel Szalachowski", "title": "BBB-Voting: 1-out-of-k Blockchain-Based Boardroom Voting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voting is a means to agree on a collective decision based on available\nchoices (e.g., candidates), where participants (voters) agree to abide by their\noutcome. To improve some features of e-voting, decentralized solutions based on\na blockchain can be employed, where the blockchain represents a public bulletin\nboard that in contrast to a centralized bulletin board provides $100\\%$\navailability and censorship resistance. A blockchain ensures that all entities\nin the voting system have the same view of the actions made by others due to\nits immutable and append-only log. The existing blockchain-based boardroom\nvoting solution called Open Voting Network (OVN) provides the privacy of votes\nand perfect ballot secrecy, but it supports only two candidates. We present\nBBB-Voting, an equivalent blockchain-based approach for decentralized voting\nthan OVN, but in contrast to it, BBB-Voting supports 1-out-of-$k$ choices and\nprovides a fault tolerance mechanism that enables recovery from stalling\nparticipants. We provide a cost-optimized implementation using Ethereum, which\nwe compare with OVN and show that our work decreases the costs for voters by\n$13.5\\%$ in terms of gas consumption. Next, we outline the extension of our\nimplementation scaling to magnitudes higher number of participants than in a\nboardroom voting, while preserving the costs paid by the authority and\nparticipants -- we made proof-of-concept experiments with up to 1000\nparticipants.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 21:34:58 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 20:51:18 GMT"}, {"version": "v3", "created": "Thu, 15 Jul 2021 14:21:12 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Venugopalan", "Sarad", ""], ["Homoliak", "Ivan", ""], ["Li", "Zengpeng", ""], ["Szalachowski", "Pawel", ""]]}, {"id": "2010.09113", "submitter": "Amrita Bhattacharjee", "authors": "Amrita Bhattacharjee, Kai Shu, Min Gao, Huan Liu", "title": "Disinformation in the Online Information Ecosystem: Detection,\n  Mitigation and Challenges", "comments": "A Chinese version of this manuscript has been submitted to the\n  Journal of Computer Research and Development", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid increase in access to internet and the subsequent growth in\nthe population of online social media users, the quality of information posted,\ndisseminated and consumed via these platforms is an issue of growing concern. A\nlarge fraction of the common public turn to social media platforms and in\ngeneral the internet for news and even information regarding highly concerning\nissues such as COVID-19 symptoms. Given that the online information ecosystem\nis extremely noisy, fraught with misinformation and disinformation, and often\ncontaminated by malicious agents spreading propaganda, identifying genuine and\ngood quality information from disinformation is a challenging task for humans.\nIn this regard, there is a significant amount of ongoing research in the\ndirections of disinformation detection and mitigation. In this survey, we\ndiscuss the online disinformation problem, focusing on the recent 'infodemic'\nin the wake of the coronavirus pandemic. We then proceed to discuss the\ninherent challenges in disinformation research, and then elaborate on the\ncomputational and interdisciplinary approaches towards mitigation of\ndisinformation, after a short overview of the various directions explored in\ndetection efforts.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 21:44:23 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Bhattacharjee", "Amrita", ""], ["Shu", "Kai", ""], ["Gao", "Min", ""], ["Liu", "Huan", ""]]}, {"id": "2010.09121", "submitter": "Akira Matsui", "authors": "Akira Matsui, Daisuke Moriwaki", "title": "Online-to-Offline Advertisements as Field Experiments", "comments": "19 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online advertisements have become one of today's most widely used tools for\nenhancing businesses partly because of their compatibility with A/B testing.\nA/B testing allows sellers to find effective advertisement strategies such as\nad creatives or segmentations. Even though several studies propose a technique\nto maximize the effect of an advertisement, there is insufficient comprehension\nof the customers' offline shopping behavior invited by the online\nadvertisements. Herein, we study the difference in offline behavior between\ncustomers who received online advertisements and regular customers (i.e., the\ncustomers visits the target shop voluntary), and the duration of this\ndifference. We analyzed approximately three thousand users' offline behavior\nwith their 23.5 million location records through 31 A/B testings. We first\ndemonstrate the externality that customers with advertisements traverse larger\nareas than those without advertisements, and this spatial difference lasts\nseveral days after their shopping day. We then find a long-run effect of this\nexternality of advertising that a certain portion of the customers invited to\nthe offline shops revisit these shops. Finally, based on this revisit effect\nfindings, we utilize a causal machine learning model to propose a marketing\nstrategy to maximize the revisit ratio. Our results suggest that advertisements\ndraw customers who have different behavior traits from regular customers. This\nstudy's findings demonstrate that a simple analysis may underrate the effects\nof advertisements on businesses, and an analysis considering externality can\nattract potentially valuable customers.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 22:04:56 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 03:51:49 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Matsui", "Akira", ""], ["Moriwaki", "Daisuke", ""]]}, {"id": "2010.09463", "submitter": "Alesssandro Giuseppi", "authors": "Emilio Calvanese Strinati, Sergio Barbarossa, Taesang Choi, Antonio\n  Pietrabissa, Alessandro Giuseppi, Emanuele De Santis, Josep Vidal, Zdenek\n  Becvar, Thomas Haustein, Nicolas Cassiau, Francesca Costanzo, Junhyeong Kim,\n  Ilgyu Kim", "title": "6G in the Sky: On-Demand Intelligence at the Edge of 3D Networks", "comments": null, "journal-ref": "ETRI Journal 2020", "doi": "10.4218/etrij.2020-0205", "report-no": null, "categories": "cs.NI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  6G will exploit satellite, aerial and terrestrial platforms jointly to\nimprove radio access capability and to unlock the support of on-demand edge\ncloud services in the three dimensional space (3D) by incorporating Mobile Edge\nComputing (MEC) functionalities on aerial platforms and low orbit satellites.\nThis will extend the MEC support to devices and network elements in the sky and\nwill forge a space borne MEC enabling intelligent personalized and distributed\non demand services. 3D end users will experience the impression of being\nsurrounded by a distributed computer fulfilling their requests in apparently\nzero latency. In this paper, we consider an architecture providing\ncommunication, computation, and caching (C3) services on demand, anytime and\neverywhere in 3D space, building on the integration of conventional ground\n(terrestrial) base stations and flying (non-terrestrial) nodes. Given the\ncomplexity of the overall network, the C3 resources and the management of the\naerial devices need to be jointly orchestrated via AI-based algorithms,\nexploiting virtualized networks functions dynamically deployed in a distributed\nmanner across terrestrial and non-terrestrial nodes.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 13:07:57 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Strinati", "Emilio Calvanese", ""], ["Barbarossa", "Sergio", ""], ["Choi", "Taesang", ""], ["Pietrabissa", "Antonio", ""], ["Giuseppi", "Alessandro", ""], ["De Santis", "Emanuele", ""], ["Vidal", "Josep", ""], ["Becvar", "Zdenek", ""], ["Haustein", "Thomas", ""], ["Cassiau", "Nicolas", ""], ["Costanzo", "Francesca", ""], ["Kim", "Junhyeong", ""], ["Kim", "Ilgyu", ""]]}, {"id": "2010.09488", "submitter": "Abraham Woubie Zewoudie Dr.", "authors": "Abraham Woubie, Pablo P\\'erez Zarazaga, Tom B\\\"ackstr\\\"om", "title": "Users Perceptions about Teleconferencing Applications Collected through\n  Twitter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 outbreak disrupted different organizations, employees and\nstudents, who turned to teleconference applications to collaborate and\nsocialize even during the quarantine. Thus, the demand of teleconferencing\napplications surged with mobile application downloads reaching the highest\nnumber ever seen. However, some of the teleconference applications recently\nsuffered from several issues such as security, privacy, media quality,\nreliability, capacity and technical difficulties. Thus, in this work, we\nexplore the opinions of different users towards different teleconference\napplications. Firstly, posts on Twitter, known as tweets, about remote working\nand different teleconference applications are extracted using different\nkeywords. Then, the extracted tweets are passed to sentiment classifier to\nclassify the tweets into positive and negative. Afterwards, the most important\nfeatures of different teleconference applications are extracted and analyzed.\nFinally, we highlight the main strengths, drawbacks and challenges of different\nteleconference applications.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 06:57:27 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Woubie", "Abraham", ""], ["Zarazaga", "Pablo P\u00e9rez", ""], ["B\u00e4ckstr\u00f6m", "Tom", ""]]}, {"id": "2010.09642", "submitter": "Simone Raponi", "authors": "Muhammad Usman, Simone Raponi, Marwa Qaraqe, Gabriele Oligeri", "title": "KaFHCa: Key-establishment via Frequency Hopping Collisions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The massive deployment of IoT devices being utilized by home automation,\nindustrial and military scenarios demands for high security and privacy\nstandards to be achieved through innovative solutions. This paper proposes\nKaFHCa, a crypto-less protocol that generates shared secret keys by combining\nrandom frequency hopping collisions and source indistinguishability\nindependently of the radio channel status. While other solutions tie the secret\nbit rate generation to the current radio channel conditions, thus becoming\nunpractical in static environments, KaFHCa guarantees almost the same secret\nbitrate independently of the channel conditions. KaFHCa generates shared\nsecrets through random collisions of the transmitter and the receiver in the\nradio spectrum, and leverages on the fading phenomena to achieve source\nindistinguishability, thus preventing unauthorized eavesdroppers from inferring\nthe key. The proposed solution is (almost) independent of the adversary\nposition, works under the conservative assumption of channel fading ({\\sigma} =\n8dB), and is capable of generating a secret key of 128 bits with less than 564\ntransmissions.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 16:36:27 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 08:45:18 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Usman", "Muhammad", ""], ["Raponi", "Simone", ""], ["Qaraqe", "Marwa", ""], ["Oligeri", "Gabriele", ""]]}, {"id": "2010.09843", "submitter": "Sruti Bhagavatula", "authors": "Sruti Bhagavatula, Lujo Bauer, Apu Kapadia", "title": "What breach? Measuring online awareness of security incidents by\n  studying real-world browsing behavior", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Awareness about security and privacy risks is important for developing good\nsecurity habits. Learning about real-world security incidents and data breaches\ncan alert people to the ways in which their information is vulnerable online,\nthus playing a significant role in encouraging safe security behavior. This\npaper examines 1) how often people read about security incidents online, 2) of\nthose people, whether and to what extent they follow up with an action, e.g.,\nby trying to read more about the incident, and 3) what influences the\nlikelihood that they will read about an incident and take some action. We study\nthis by quantitatively examining real-world internet-browsing data from 303\nparticipants.\n  Our findings present a bleak view of awareness of security incidents. Only\n16% of participants visited any web pages related to six widely publicized\nlarge-scale security incidents; few read about one even when an incident was\nlikely to have affected them (e.g., the Equifax breach almost universally\naffected people with Equifax credit reports). We further found that more severe\nincidents as well as articles that constructively spoke about the incident\ninspired more action. We conclude with recommendations for specific future\nresearch and for enabling useful security incident information to reach more\npeople.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 20:34:19 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 01:35:29 GMT"}, {"version": "v3", "created": "Thu, 5 Nov 2020 00:16:26 GMT"}, {"version": "v4", "created": "Thu, 27 May 2021 18:36:25 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Bhagavatula", "Sruti", ""], ["Bauer", "Lujo", ""], ["Kapadia", "Apu", ""]]}, {"id": "2010.09850", "submitter": "Renata Georgia Raidou", "authors": "Marwin Schindler, Hsiang-Yun Wu, Renata Georgia Raidou", "title": "The Anatomical Edutainer", "comments": null, "journal-ref": null, "doi": "10.1109/VIS47514.2020.00007", "report-no": null, "categories": "cs.HC cs.CY cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physical visualizations (i.e., data representations by means of physical\nobjects) have been used for many centuries in medical and anatomical education.\nRecently, 3D printing techniques started also to emerge. Still, other medical\nphysicalizations that rely on affordable and easy-to-find materials are\nlimited, while smart strategies that take advantage of the optical properties\nof our physical world have not been thoroughly investigated. We propose the\nAnatomical Edutainer, a workflow to guide the easy, accessible, and affordable\ngeneration of physicalizations for tangible, interactive anatomical\nedutainment. The Anatomical Edutainer supports 2D printable and 3D foldable\nphysicalizations that change their visual properties (i.e., hues of the visible\nspectrum) under colored lenses or colored lights, to reveal distinct anatomical\nstructures through user interaction.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 10:40:12 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Schindler", "Marwin", ""], ["Wu", "Hsiang-Yun", ""], ["Raidou", "Renata Georgia", ""]]}, {"id": "2010.09853", "submitter": "Sruti Bhagavatula", "authors": "Sruti Bhagavatula, Lujo Bauer, Apu Kapadia", "title": "(How) Do people change their passwords after a breach?", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To protect against misuse of passwords compromised in a breach, consumers\nshould promptly change affected passwords and any similar passwords on other\naccounts. Ideally, affected companies should strongly encourage this behavior\nand have mechanisms in place to mitigate harm. In order to make recommendations\nto companies about how to help their users perform these and other\nsecurity-enhancing actions after breaches, we must first have some\nunderstanding of the current effectiveness of companies' post-breach practices.\nTo study the effectiveness of password-related breach notifications and\npractices enforced after a breach, we examine---based on real-world password\ndata from 249 participants---whether and how constructively participants\nchanged their passwords after a breach announcement.\n  Of the 249 participants, 63 had accounts on breached domains; only 33% of the\n63 changed their passwords and only 13% (of 63) did so within three months of\nthe announcement. New passwords were on average 1.3x stronger than old\npasswords (when comparing log10-transformed strength), though most were weaker\nor of equal strength. Concerningly, new passwords were overall more similar to\nparticipants' other passwords, and participants rarely changed passwords on\nother sites even when these were the same or similar to their password on the\nbreached domain. Our results highlight the need for more rigorous\npassword-changing requirements following a breach and more effective breach\nnotifications that deliver comprehensive advice.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 20:44:25 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Bhagavatula", "Sruti", ""], ["Bauer", "Lujo", ""], ["Kapadia", "Apu", ""]]}, {"id": "2010.09909", "submitter": "Russell Taylor", "authors": "Gregory Hager, Vijay Kumar, Robin Murphy, Daniela Rus, Russell Taylor", "title": "The Role of Robotics in Infectious Disease Crises", "comments": "25 pages (including title page)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent coronavirus pandemic has highlighted the many challenges faced by\nthe healthcare, public safety, and economic systems when confronted with a\nsurge in patients that require intensive treatment and a population that must\nbe quarantined or shelter in place. The most obvious and pressing challenge is\ntaking care of acutely ill patients while managing spread of infection within\nthe care facility, but this is just the tip of the iceberg if we consider what\ncould be done to prepare in advance for future pandemics. Beyond the obvious\nneed for strengthening medical knowledge and preparedness, there is a\ncomplementary need to anticipate and address the engineering challenges\nassociated with infectious disease emergencies. Robotic technologies are\ninherently programmable, and robotic systems have been adapted and deployed, to\nsome extent, in the current crisis for such purposes as transport, logistics,\nand disinfection. As technical capabilities advance and as the installed base\nof robotic systems increases in the future, they could play a much more\nsignificant role in future crises. This report is the outcome of a virtual\nworkshop co-hosted by the National Academy of Engineering (NAE) and the\nComputing Community Consortium (CCC) held on July 9-10, 2020. The workshop\nconsisted of over forty participants including representatives from the\nengineering/robotics community, clinicians, critical care workers, public\nhealth and safety experts, and emergency responders. It identifies key\nchallenges faced by healthcare responders and the general population and then\nidentifies robotic/technological responses to these challenges. Then it\nidentifies the key research/knowledge barriers that need to be addressed in\ndeveloping effective, scalable solutions. Finally, the report ends with the\nfollowing recommendations on how to implement this strategy.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 22:54:12 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Hager", "Gregory", ""], ["Kumar", "Vijay", ""], ["Murphy", "Robin", ""], ["Rus", "Daniela", ""], ["Taylor", "Russell", ""]]}, {"id": "2010.10015", "submitter": "Mrityunjay (MJ) Kumar", "authors": "Venkatesh Choppella, Viswanath Kasturi, Mrityunjay Kumar, Ojas Mohril", "title": "Algodynamics: Teaching Algorithms using Interactive Transition Systems", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of algorithms and data structures in computer science\ncurricula has been amply recognized. For many students, however, gaining a good\nunderstanding of algorithms remains a challenge.\n  Because of the automated nature of sequential algorithms. there is an\ninherent tension in directly applying the `learning by doing' approach. This\npartly explains the limitations of efforts like algorithm animation and code\ntracing.\n  Algodynamics, the approach we propose and advocate, situates algorithms\nwithin the framework of transition systems and their dynamics and offers an\nattractive approach for teaching algorithms. Algodynamics starts with the\npremise that the key ideas underlying an algorithm can be identified and\npackaged into interactive transition systems. The algorithm when `opened up',\nreveals a transition system, shorn of most control aspects, enriched instead\nwith interaction. The design of an algorithm can be carried out by constructing\na series of interactive systems, progressively trading interactivity with\nautomation. These transition systems constitute a family of notional machines.\n  We illustrate the algodynamics approach by considering Bubblesort. A sequence\nof five interactive transition systems culminate in the classic Bubblesort\nalgorithm. The exercise of constructing the individual systems also pays off\nwhen coding Bubblesort: a highly modular implementation whose primitives are\nborrowed from the transition systems. The transition systems used for\nBubblesort have been implemented as interactive experiments. These web based\nimplementations are easy to build. The simplicity and flexibility afforded by\nthe algodynamics framework makes it an attractive option to teach algorithms in\nan interactive way.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 04:38:49 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Choppella", "Venkatesh", ""], ["Kasturi", "Viswanath", ""], ["Kumar", "Mrityunjay", ""], ["Mohril", "Ojas", ""]]}, {"id": "2010.10028", "submitter": "David Pastor-Escuredo", "authors": "David Pastor-Escuredo and Ricardo Vinuesa", "title": "Towards and Ethical Framework in the Complex Digital Era", "comments": "arXiv admin note: text overlap with arXiv:2003.06530", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Since modernity, ethic has been progressively fragmented into specific\ncommunities of practice. The digital revolution enabled by AI and Data is\nbringing ethical wicked problems in the crossroads of technology and behavior.\nHowever, the need of a comprehensive and constructive ethical framework is\nemerging as digital platforms connect us globally. The unequal structure of the\nglobal system makes that dynamic changes and systemic problems impact more on\nthose that are most vulnerable. Ethical frameworks based only on the\nindividual-level are not longer sufficient. A new ethical vision must comprise\nthe understanding of the scales and complex interconnections of social systems.\nMany of these systems are internally fragile and very sensitive to external\nfactors and threats, which turns into unethical situations that require\nsystemic solutions. The high scale nature of digital technology that expands\nglobally has also an impact at the individual level having the risk to make\nhumans beings more homogeneous, predictable and ultimately controllable. To\npreserve the core of humanity ethic must take a stand to preserve and keep\npromoting individual rights and uniqueness and cultural heterogeneity tackling\nthe negative trends and impact of digitalization. Only combining human-centered\nand collectiveness-oriented digital development it will be possible to\nconstruct new social models and human-machine interactions that are ethical.\nThis vision requires science to enhance ethical frameworks and principles with\nthe actionable insights of relationships and properties of the social systems\nthat may not be evident and need to be quantified and understood to be solved.\nArtificial Intelligence is both a risk and and opportunity for an ethical\ndevelopment, thus we need a conceptual construct that drives towards a better\ndigitalizated world.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 15:28:04 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Pastor-Escuredo", "David", ""], ["Vinuesa", "Ricardo", ""]]}, {"id": "2010.10397", "submitter": "Manoel Horta Ribeiro", "authors": "Manoel Horta Ribeiro, Shagun Jhaver, Savvas Zannettou, Jeremy\n  Blackburn, Emiliano De Cristofaro, Gianluca Stringhini, Robert West", "title": "Does Platform Migration Compromise Content Moderation? Evidence from\n  r/The_Donald and r/Incels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When toxic online communities on mainstream platforms face moderation\nmeasures, such as bans, they may migrate to other platforms with laxer policies\nor set up their own dedicated website. Previous work suggests that, within\nmainstream platforms, community-level moderation is effective in mitigating the\nharm caused by the moderated communities. It is, however, unclear whether these\nresults also hold when considering the broader Web ecosystem. Do toxic\ncommunities continue to grow in terms of user base and activity on their new\nplatforms? Do their members become more toxic and ideologically radicalized? In\nthis paper, we report the results of a large-scale observational study of how\nproblematic online communities progress following community-level moderation\nmeasures. We analyze data from r/The_Donald} and r/Incels, two communities that\nwere banned from Reddit and subsequently migrated to their own standalone\nwebsites. Our results suggest that, in both cases, moderation measures\nsignificantly decreased posting activity on the new platform, reducing the\nnumber of posts, active users, and newcomers. In spite of that, users in one of\nthe studied communities (r/The_Donald) showed increases in signals associated\nwith toxicity and radicalization, which justifies concerns that the reduction\nin activity may come at the expense of a more toxic and radical community.\nOverall, our results paint a nuanced portrait of the consequences of\ncommunity-level moderation and can inform their design and deployment.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 16:03:06 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 07:34:32 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Ribeiro", "Manoel Horta", ""], ["Jhaver", "Shagun", ""], ["Zannettou", "Savvas", ""], ["Blackburn", "Jeremy", ""], ["De Cristofaro", "Emiliano", ""], ["Stringhini", "Gianluca", ""], ["West", "Robert", ""]]}, {"id": "2010.10407", "submitter": "A. Feder Cooper", "authors": "A. Feder Cooper", "title": "Where Is the Normative Proof? Assumptions and Contradictions in ML\n  Fairness Research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Across machine learning (ML) sub-disciplines researchers make mathematical\nassumptions to facilitate proof-writing. While such assumptions are necessary\nfor providing mathematical guarantees for how algorithms behave, they also\nnecessarily limit the applicability of these algorithms to different problem\nsettings. This practice is known--in fact, obvious--and accepted in ML\nresearch. However, similar attention is not paid to the normative assumptions\nthat ground this work. I argue such assumptions are equally as important,\nespecially in areas of ML with clear social impact, such as fairness. This is\nbecause, similar to how mathematical assumptions constrain applicability,\nnormative assumptions also limit algorithm applicability to certain problem\ndomains. I show that, in existing papers published in top venues, once\nnormative assumptions are clarified, it is often possible to get unclear or\ncontradictory results. While the mathematical assumptions and results are\nsound, the implicit normative assumptions and accompanying normative results\ncontraindicate using these methods in practical fairness applications.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 16:13:46 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 19:30:59 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2020 22:08:04 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Cooper", "A. Feder", ""]]}, {"id": "2010.10560", "submitter": "Varun Raj Kompella", "authors": "Varun Kompella, Roberto Capobianco, Stacy Jong, Jonathan Browne,\n  Spencer Fox, Lauren Meyers, Peter Wurman, Peter Stone", "title": "Reinforcement Learning for Optimization of COVID-19 Mitigation policies", "comments": "*Joint First Authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The year 2020 has seen the COVID-19 virus lead to one of the worst global\npandemics in history. As a result, governments around the world are faced with\nthe challenge of protecting public health, while keeping the economy running to\nthe greatest extent possible. Epidemiological models provide insight into the\nspread of these types of diseases and predict the effects of possible\nintervention policies. However, to date,the even the most data-driven\nintervention policies rely on heuristics. In this paper, we study how\nreinforcement learning (RL) can be used to optimize mitigation policies that\nminimize the economic impact without overwhelming the hospital capacity. Our\nmain contributions are (1) a novel agent-based pandemic simulator which, unlike\ntraditional models, is able to model fine-grained interactions among people at\nspecific locations in a community; and (2) an RL-based methodology for\noptimizing fine-grained mitigation policies within this simulator. Our results\nvalidate both the overall simulator behavior and the learned policies under\nrealistic conditions.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 18:40:15 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Kompella", "Varun", ""], ["Capobianco", "Roberto", ""], ["Jong", "Stacy", ""], ["Browne", "Jonathan", ""], ["Fox", "Spencer", ""], ["Meyers", "Lauren", ""], ["Wurman", "Peter", ""], ["Stone", "Peter", ""]]}, {"id": "2010.10580", "submitter": "Lu Cheng", "authors": "Lu Cheng, Ruocheng Guo, Kai Shu, Huan Liu", "title": "Causal Understanding of Fake News Dissemination on Social Media", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": "10.1145/3447548.3467321", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent years have witnessed remarkable progress towards computational fake\nnews detection. To mitigate its negative impact, we argue that it is critical\nto understand what user attributes potentially cause users to share fake news.\nThe key to this causal-inference problem is to identify confounders --\nvariables that cause spurious associations between treatments (e.g., user\nattributes) and outcome (e.g., user susceptibility). In fake news\ndissemination, confounders can be characterized by fake news sharing behavior\nthat inherently relates to user attributes and online activities. Learning such\nuser behavior is typically subject to selection bias in users who are\nsusceptible to share news on social media. Drawing on causal inference\ntheories, we first propose a principled approach to alleviating selection bias\nin fake news dissemination. We then consider the learned unbiased fake news\nsharing behavior as the surrogate confounder that can fully capture the causal\nlinks between user attributes and user susceptibility. We theoretically and\nempirically characterize the effectiveness of the proposed approach and find\nthat it could be useful in protecting society from the perils of fake news.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 19:37:04 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 23:14:07 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Cheng", "Lu", ""], ["Guo", "Ruocheng", ""], ["Shu", "Kai", ""], ["Liu", "Huan", ""]]}, {"id": "2010.10600", "submitter": "Tugrulcan Elmas", "authors": "Tu\\u{g}rulcan Elmas, Rebekah Overdorf, \\\"Omer Faruk Akg\\\"ul, Karl\n  Aberer", "title": "Misleading Repurposing on Twitter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Twitter allows users to change their screen name and other profile\nattributes, which allows a malicious user to change their account's identity or\npurpose while retaining their followers. We present the first large scale and\nprincipled study of this phenomenon of misleading account repurposing on\nTwitter. We analyze two large datasets to understand account repurposing. We\nfind 3,500 repurposed accounts in the Twitter Elections Integrity Datasets. We\nalso find more than 100,000 accounts that have more than 5,000 followers and\nwere active in the first six months of 2020 using Twitter's 1% real-time\nsample. We analyze a series of common features of repurposed accounts that give\nus insight into the mechanics of repurposing and into how accounts can come to\nbe repurposed. We also analyze three online markets that facilitate selling and\nbuying Twitter accounts to better understand the effect that repurposing has on\nthe Twitter account market. We provide the dataset of popular accounts that are\nflagged as repurposed by our framework.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 20:19:01 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Elmas", "Tu\u011frulcan", ""], ["Overdorf", "Rebekah", ""], ["Akg\u00fcl", "\u00d6mer Faruk", ""], ["Aberer", "Karl", ""]]}, {"id": "2010.10658", "submitter": "Peter Zelchenko", "authors": "Peter Zelchenko, Xiaohan Fu, Xiangqian Li, Alex Ivanov, Zhenyu Gu", "title": "Display object alignment may influence location recall in unexpected\n  ways", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a presumption in human-computer interaction that laying out menus\nand most other material in neat rows and columns helps users get work done. The\nrule has been so implicit in the field of design as to allow for no debate.\nHowever, the idea that perfect collinearity benefits creates an advantage for\nboth either search and or recall has rarely been tested. Drawing from separate\nbranches of cognitive literature, we tested a minimal brainstorming interface\nwith either aligned or eccentrically arranged layouts on 96 college students.\nIncidental exact recall of recently worked locations improved in the eccentric\ncondition. And in both conditions there were frequent near-miss recall errors\nto neighboring aligned objects and groups of objects. Further analysis found\nonly marginal performance advantages specifically for females with the\neccentric design. However, NASA-TLX subjective measures showed that in\neccentric, females reported higher performance, less effort, and yet also\nhigher frustration; while males reported lower performance with about the same\neffort, and lower frustration.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 22:51:53 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Zelchenko", "Peter", ""], ["Fu", "Xiaohan", ""], ["Li", "Xiangqian", ""], ["Ivanov", "Alex", ""], ["Gu", "Zhenyu", ""]]}, {"id": "2010.10992", "submitter": "Anay Mehrotra", "authors": "L. Elisa Celis, Chris Hays, Anay Mehrotra, Nisheeth K. Vishnoi", "title": "The Effect of the Rooney Rule on Implicit Bias in the Long Term", "comments": "Abstract shortened to satisfy the 1920 character limit", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A robust body of evidence demonstrates the adverse effects of implicit bias\nin various contexts--from hiring to health care. The Rooney Rule is an\nintervention developed to counter implicit bias and has been implemented in the\nprivate and public sectors. The Rooney Rule requires that a selection panel\ninclude at least one candidate from an underrepresented group in their\nshortlist of candidates. Recently, Kleinberg and Raghavan proposed a model of\nimplicit bias and studied the effectiveness of the Rooney Rule when applied to\na single selection decision. However, selection decisions often occur\nrepeatedly over time. Further, it has been observed that, given consistent\ncounterstereotypical feedback, implicit biases against underrepresented\ncandidates can change.\n  We consider a model of how a selection panel's implicit bias changes over\ntime given their hiring decisions either with or without the Rooney Rule in\nplace. Our main result is that, when the panel is constrained by the Rooney\nRule, their implicit bias roughly reduces at a rate that is the inverse of the\nsize of the shortlist--independent of the number of candidates, whereas without\nthe Rooney Rule, the rate is inversely proportional to the number of\ncandidates. Thus, when the number of candidates is much larger than the size of\nthe shortlist, the Rooney Rule enables a faster reduction in implicit bias,\nproviding an additional reason in favor of using it as a strategy to mitigate\nimplicit bias. Towards empirically evaluating the long-term effect of the\nRooney Rule in repeated selection decisions, we conduct an iterative candidate\nselection experiment on Amazon MTurk. We observe that, indeed, decision-makers\nsubject to the Rooney Rule select more minority candidates in addition to those\nrequired by the rule itself than they would if no rule is in effect, and do so\nwithout considerably decreasing the utility of candidates selected.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 13:33:00 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Celis", "L. Elisa", ""], ["Hays", "Chris", ""], ["Mehrotra", "Anay", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "2010.11046", "submitter": "Colin M. Gray", "authors": "Colin M. Gray, Jingle Chen, Shruthi Sai Chivukula, and Liyang Qu", "title": "End User Accounts of Dark Patterns as Felt Manipulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Manipulation defines many of our experiences as a consumer, including subtle\nnudges and overt advertising campaigns that seek to gain our attention and\nmoney. With the advent of digital services that can continuously optimize\nonline experiences to favor stakeholder requirements, increasingly designers\nand developers make use of \"dark patterns\"---forms of manipulation that prey on\nhuman psychology---to encourage certain behaviors and discourage others in ways\nthat present unequal value to the end user. In this paper, we provide an\naccount of end user perceptions of manipulation that builds on and extends\nnotions of dark patterns. We report on the results of a survey of users\nconducted in English and Mandarin Chinese (n=169), including follow-up\ninterviews from nine survey respondents. We used a card sorting method to\nsupport thematic analysis of responses from each cultural context, identifying\nboth qualitatively-supported insights to describe end users' felt experiences\nof manipulative products, and a continuum of manipulation. We further support\nthis analysis through a quantitative analysis of survey results and the\npresentation of vignettes from the interviews. We conclude with implications\nfor future research, considerations for public policy, and guidance on how to\nfurther empower and give users autonomy in their experiences with digital\nservices.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 14:55:09 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Gray", "Colin M.", ""], ["Chen", "Jingle", ""], ["Chivukula", "Shruthi Sai", ""], ["Qu", "Liyang", ""]]}, {"id": "2010.11300", "submitter": "Xueru Zhang", "authors": "Xueru Zhang, Ruibo Tu, Yang Liu, Mingyan Liu, Hedvig Kjellstr\\\"om, Kun\n  Zhang, Cheng Zhang", "title": "How Do Fair Decisions Fare in Long-term Qualification?", "comments": "Accepted to the 34th Conference on Neural Information Processing\n  Systems (NeurIPS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although many fairness criteria have been proposed for decision making, their\nlong-term impact on the well-being of a population remains unclear. In this\nwork, we study the dynamics of population qualification and algorithmic\ndecisions under a partially observed Markov decision problem setting. By\ncharacterizing the equilibrium of such dynamics, we analyze the long-term\nimpact of static fairness constraints on the equality and improvement of group\nwell-being. Our results show that static fairness constraints can either\npromote equality or exacerbate disparity depending on the driving factor of\nqualification transitions and the effect of sensitive attributes on feature\ndistributions. We also consider possible interventions that can effectively\nimprove group qualification or promote equality of group qualification. Our\ntheoretical results and experiments on static real-world datasets with\nsimulated dynamics show that our framework can be used to facilitate social\nscience studies.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 20:27:48 GMT"}], "update_date": "2020-10-24", "authors_parsed": [["Zhang", "Xueru", ""], ["Tu", "Ruibo", ""], ["Liu", "Yang", ""], ["Liu", "Mingyan", ""], ["Kjellstr\u00f6m", "Hedvig", ""], ["Zhang", "Kun", ""], ["Zhang", "Cheng", ""]]}, {"id": "2010.11411", "submitter": "Wesley Deng", "authors": "Hong Shen, Hanwen Wesley Deng, Aditi Chattopadhyay, Zhiwei Steven Wu,\n  Xu Wang, Haiyi Zhu", "title": "Value Cards: An Educational Toolkit for Teaching Social Impacts of\n  Machine Learning through Deliberation", "comments": "Updating authors' names", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there have been increasing calls for computer science curricula to\ncomplement existing technical training with topics related to Fairness,\nAccountability, Transparency, and Ethics. In this paper, we present Value Card,\nan educational toolkit to inform students and practitioners of the social\nimpacts of different machine learning models via deliberation. This paper\npresents an early use of our approach in a college-level computer science\ncourse. Through an in-class activity, we report empirical data for the initial\neffectiveness of our approach. Our results suggest that the use of the Value\nCards toolkit can improve students' understanding of both the technical\ndefinitions and trade-offs of performance metrics and apply them in real-world\ncontexts, help them recognize the significance of considering diverse social\nvalues in the development of deployment of algorithmic systems, and enable them\nto communicate, negotiate and synthesize the perspectives of diverse\nstakeholders. Our study also demonstrates a number of caveats we need to\nconsider when using the different variants of the Value Cards toolkit. Finally,\nwe discuss the challenges as well as future applications of our approach.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 03:27:19 GMT"}, {"version": "v2", "created": "Sat, 21 Nov 2020 08:45:37 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Shen", "Hong", ""], ["Deng", "Hanwen Wesley", ""], ["Chattopadhyay", "Aditi", ""], ["Wu", "Zhiwei Steven", ""], ["Wang", "Xu", ""], ["Zhu", "Haiyi", ""]]}, {"id": "2010.11541", "submitter": "Xun Liang", "authors": "Xun Liang, Qingfeng Guan, Keith C. Clarke, Shishi Liu, Bingyu Wang,\n  Yao Yao", "title": "Understanding the drivers of sustainable land expansion using a\n  patch-generating land use simulation (PLUS) model: A case study in Wuhan,\n  China", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cellular Automata (CA) are widely used to model the dynamics within complex\nland use and land cover (LULC) systems. Past CA model research has focused on\nimproving the technical modeling procedures, and only a few studies have sought\nto improve our understanding of the nonlinear relationships that underlie LULC\nchange. Many CA models lack the ability to simulate the detailed patch\nevolution of multiple land use types. This study introduces a patch-generating\nland use simulation (PLUS) model that integrates a land expansion analysis\nstrategy and a CA model based on multi-type random patch seeds. These were used\nto understand the drivers of land expansion and to investigate the landscape\ndynamics in Wuhan, China. The proposed model achieved a higher simulation\naccuracy and more similar landscape pattern metrics to the true landscape than\nother CA models tested. The land expansion analysis strategy also uncovered\nsome underlying transition rules, such as that grassland is most likely to be\nfound where it is not strongly impacted by human activities, and that deciduous\nforest areas tend to grow adjacent to arterial roads. We also projected the\nstructure of land use under different optimizing scenarios for 2035 by\ncombining the proposed model with multi-objective programming. The results\nindicate that the proposed model can help policymakers to manage future land\nuse dynamics and so to realize more sustainable land use patterns for future\ndevelopment. Software for PLUS has been made available at\nhttps://github.com/HPSCIL/Patch-generating_Land_Use_Simulation_Model\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 09:04:50 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 04:13:51 GMT"}, {"version": "v3", "created": "Thu, 5 Nov 2020 03:07:20 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Liang", "Xun", ""], ["Guan", "Qingfeng", ""], ["Clarke", "Keith C.", ""], ["Liu", "Shishi", ""], ["Wang", "Bingyu", ""], ["Yao", "Yao", ""]]}, {"id": "2010.11638", "submitter": "Kostantinos Papadamou Mr", "authors": "Kostantinos Papadamou and Savvas Zannettou and Jeremy Blackburn and\n  Emiliano De Cristofaro and Gianluca Stringhini and Michael Sirivianos", "title": "\"It is just a flu\": Assessing the Effect of Watch History on YouTube's\n  Pseudoscientific Video Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The role played by YouTube's recommendation algorithm in unwittingly\npromoting misinformation and conspiracy theories is not entirely understood.\nYet, this can have dire real-world consequences, especially when\npseudoscientific content is promoted to users at critical times, such as the\nCOVID-19 pandemic. In this paper, we set out to characterize and detect\npseudoscientific misinformation on YouTube. We collect 6.6K videos related to\nCOVID-19, the Flat Earth theory, as well as the anti-vaccination and anti-mask\nmovements. Using crowdsourcing, we annotate them as pseudoscience, legitimate\nscience, or irrelevant and train a deep learning classifier to detect\npseudoscientific videos with an accuracy of 0.79.\n  We quantify user exposure to this content on various parts of the platform\nand how this exposure changes based on the user's watch history. We find that\nYouTube suggests more pseudoscientific content regarding traditional\npseudoscientific topics (e.g., flat earth, anti-vaccination) than for emerging\nones (like COVID-19). At the same time, these recommendations are more common\non the search results page than on a user's homepage or in the recommendation\nsection when actively watching videos. Finally, we shed light on how a user's\nwatch history substantially affects the type of recommended videos.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 12:20:01 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 10:37:30 GMT"}, {"version": "v3", "created": "Sun, 17 Jan 2021 16:46:07 GMT"}, {"version": "v4", "created": "Tue, 18 May 2021 13:48:56 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Papadamou", "Kostantinos", ""], ["Zannettou", "Savvas", ""], ["Blackburn", "Jeremy", ""], ["De Cristofaro", "Emiliano", ""], ["Stringhini", "Gianluca", ""], ["Sirivianos", "Michael", ""]]}, {"id": "2010.11677", "submitter": "Paulo Henrique Alves MSc", "authors": "Paulo Henrique Alves, Isabella Z. Frajhof, Fernando A. Correia,\n  Clarisse de Souza, Helio Lopes", "title": "Second layer data governance for permissioned blockchains: the privacy\n  management challenge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Data privacy is a trending topic in the internet era. Given such importance,\nmany challenges emerged in order to collect, manage, process, and publish data.\nIn this sense, personal data have got attention, and many regulations emerged,\nsuch as GDPR in the European Union and LGPD in Brazil. This regulation model\naims to protect users' data from misusage and leakage and allow users to\nrequest an explanation from companies when needed. In pandemic situations, such\nas the COVID-19 and Ebola outbreak, the action related to sharing health data\nbetween different organizations is/ was crucial to develop a significant\nmovement to avoid the massive infection and decrease the number of deaths.\nHowever, the data subject, i.e., the users, should have the right to request\nthe purpose of data use, anonymization, and data deletion. In this sense,\npermissioned blockchain technology emerges to empower users to get their rights\nproviding data ownership, transparency, and security through an immutable,\nunified, and distributed database ruled by smart contracts. The governance\nmodel discussed in blockchain applications is usually regarding the first layer\ngovernance, i.e., public and permissioned models. However, this discussion is\ntoo superficial, and they do not cover compliance with the data regulations.\nTherefore, in order to organize the relationship between data owners and the\nstakeholders, i.e., companies and governmental entities, we developed a second\nlayer data governance model for permissioned blockchains based on the\nGovernance Analytical Framework principles applied in pandemic situations\npreserving the users' privacy and their duties. From the law perspective, we\nbased our model on the UE GDPR in regard to data privacy concerns.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 13:19:38 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Alves", "Paulo Henrique", ""], ["Frajhof", "Isabella Z.", ""], ["Correia", "Fernando A.", ""], ["de Souza", "Clarisse", ""], ["Lopes", "Helio", ""]]}, {"id": "2010.11945", "submitter": "Keegan McBride", "authors": "Lizaveta Miasayedava, Keegan McBride, Jeffrey Andrew Tuhtan", "title": "Automated Environmental Compliance Monitoring with IoT and Open\n  Government Data", "comments": "Manuscript Submitted to IEEE Internet of Things Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Negative environmental impacts on societies and ecosystems are frequently\ndriven by human activity and amplified by increasing climatic variability.\nProperly managing these impacts relies on a government's ability to ensure\nenvironmental regulatory compliance in the face of increasing uncertainty.\nWater flow rates are the most widely used evaluation metric for river\nregulatory compliance. Specifically, compliance thresholds are set by\ncalculating the minimum flow rates required by aquatic species such as fish.\nThese are then designated as the minimum \"environmental flows\" (eflows) for\neach river. In this paper, we explore how IoT-generated open government data\ncan be used to enhance the development of an automated IoT-based eflows\ncompliance system. To reduce development and operational costs, the proposed\nsolution relies on routinely collected river monitoring data. Our approach\nallows for any authority with similar data to rapidly develop, test and verify\na scalable solution for eflow regulatory compliance monitoring and evaluation.\nFurthermore, we demonstrate a real-world application of our system using open\ngovernment data from Estonia's national river monitoring network. The main\nnovelty of this work is that the proposed IoT-based system provides a simple\nevaluation tool that re-purposes IoT-generated open government data to evaluate\ncompliance and improve monitoring at a national scale. This work showcases a\nnew paradigm of IoT-based solutions using open government data and provides a\nreal-world example of how the solution can automatically evaluate environmental\ncompliance in increasingly uncertain environments.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 18:13:24 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Miasayedava", "Lizaveta", ""], ["McBride", "Keegan", ""], ["Tuhtan", "Jeffrey Andrew", ""]]}, {"id": "2010.12006", "submitter": "Yiming Xu", "authors": "Yiming Xu, Xiang Yan, Virginia P. Sisiopiku, Louis A. Merlin, Fangzhou\n  Xing, Xilei Zhao", "title": "Micromobility Trip Origin and Destination Inference Using General\n  Bikeshare Feed Specification (GBFS) Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Emerging micromobility services (e.g., e-scooters) have a great potential to\nenhance urban mobility but more knowledge on their usage patterns is needed.\nThe General Bikeshare Feed Specification (GBFS) data are a possible source for\nexamining micromobility trip patterns, but efforts are needed to infer trips\nfrom the GBFS data. Existing trip inference methods are usually based upon the\nassumption that the vehicle ID of a micromobility option (e-scooter or e-bike)\ndoes not change, and so they cannot deal with data with vehicle IDs that change\nover time. In this study, we propose a comprehensive package of algorithms to\ninfer trip origins and destinations from GBFS data with different types of\nvehicle ID. We implement the algorithms in Washington DC by analyzing one-week\n(last week of February 2020) of GBFS data published by six vendors, and we\nevaluate the inference accuracy of the proposed algorithms by R-squared, mean\nabsolute error, and sum absolute error. We find that the R-squared measure is\nlarger than 0.9 and the MAE measure is smaller than 2 when the algorithms are\nevaluated with a 400m*400m grid, and the absolute errors are relatively larger\nin the downtown area. The accuracy of the trip-inference algorithms is\nsufficiently high for most practical applications.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 02:49:10 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Xu", "Yiming", ""], ["Yan", "Xiang", ""], ["Sisiopiku", "Virginia P.", ""], ["Merlin", "Louis A.", ""], ["Xing", "Fangzhou", ""], ["Zhao", "Xilei", ""]]}, {"id": "2010.12012", "submitter": "Roghayeh Barmaki", "authors": "Zang Guo and Roghayeh Barmaki", "title": "Deep neural networks for collaborative learning analytics: Evaluating\n  team collaborations using student gaze point prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Automatic assessment and evaluation of team performance during collaborative\ntasks is key to the learning analytics and computer-supported cooperative work\nresearch. There is a growing interest in the use of gaze-oriented cues for\nevaluating the collaboration and cooperativeness of teams. However, collecting\ngaze data using eye-trackers is not always feasible due to time and cost\nconstraints. In this paper, we introduce an automated team assessment tool\nbased on gaze points and joint visual attention (JVA) information extracted by\ncomputer vision solutions. We then evaluate team collaborations in an\nundergraduate anatomy learning activity (N=60, 30 teams) as a test user-study.\nThe results indicate that higher JVA was positively associated with student\nlearning outcomes (r(30)=0.50,p<0.005). Moreover, teams who participated in two\nexperimental groups, and used interactive 3-D anatomy models, had higher JVA\n(F(1,28)=6.65,p<0.05) and better knowledge retention (F(1,28) =7.56,p<0.05)\nthan those in the control group. Also, no significant difference was observed\nbased on JVA for different gender compositions of teams. The findings from this\nwork offer implications in learning sciences and collaborative computing by\nproviding a novel mutual attention-based measure to objectively evaluate team\ncollaboration dynamics.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 02:07:29 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Guo", "Zang", ""], ["Barmaki", "Roghayeh", ""]]}, {"id": "2010.12015", "submitter": "Simon Kasif", "authors": "Simon Kasif", "title": "Artificial Tikkun Olam: AI Can Be Our Best Friend in Building an Open\n  Human-Computer Society", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technological advances of virtually every kind pose risks to society\nincluding fairness and bias. We review a long-standing wisdom that a widespread\npractical deployment of any technology may produce adverse side effects\nmisusing the knowhow. This includes AI but AI systems are not solely\nresponsible for societal risks. We describe some of the common and AI specific\nrisks in health industries and other sectors and propose both broad and\nspecific solutions. Each technology requires very specialized and informed\ntracking, monitoring and creative solutions. We postulate that AI systems are\nuniquely poised to produce conceptual and methodological solutions to both\nfairness and bias in automated decision-making systems. We propose a simple\nintelligent system quotient that may correspond to their adverse societal\nimpact and outline a multi-tier architecture for producing solutions of\nincreasing complexity to these risks. We also propose that universities may\nconsider forming interdisciplinary Study of Future Technology Centers to\ninvestigate and predict the fuller range of risks posed by technology and seek\nboth common and AI specific solutions using computational, technical,\nconceptual and ethical analysis\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 23:29:45 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Kasif", "Simon", ""]]}, {"id": "2010.12016", "submitter": "Matthew Leavitt", "authors": "Matthew L. Leavitt, Ari Morcos", "title": "Towards falsifiable interpretability research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods for understanding the decisions of and mechanisms underlying deep\nneural networks (DNNs) typically rely on building intuition by emphasizing\nsensory or semantic features of individual examples. For instance, methods aim\nto visualize the components of an input which are \"important\" to a network's\ndecision, or to measure the semantic properties of single neurons. Here, we\nargue that interpretability research suffers from an over-reliance on\nintuition-based approaches that risk-and in some cases have caused-illusory\nprogress and misleading conclusions. We identify a set of limitations that we\nargue impede meaningful progress in interpretability research, and examine two\npopular classes of interpretability methods-saliency and single-neuron-based\napproaches-that serve as case studies for how overreliance on intuition and\nlack of falsifiability can undermine interpretability research. To address\nthese concerns, we propose a strategy to address these impediments in the form\nof a framework for strongly falsifiable interpretability research. We encourage\nresearchers to use their intuitions as a starting point to develop and test\nclear, falsifiable hypotheses, and hope that our framework yields robust,\nevidence-based interpretability methods that generate meaningful advances in\nour understanding of DNNs.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 22:03:41 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Leavitt", "Matthew L.", ""], ["Morcos", "Ari", ""]]}, {"id": "2010.12019", "submitter": "Markian Hromiak", "authors": "Markian Hromiak", "title": "A New Charter of Ethics and Rights of Artificial Consciousness in a\n  Human World", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Taking the stance that artificially conscious agents should be given\nhuman-like rights, in this paper we attempt to define consciousness, aggregate\nexisting universal human rights, analyze robotic laws with roots in both\nreality and science fiction, and synthesize everything to create a new\nrobot-ethical charter. By restricting the problem-space of possible levels of\nconscious beings to human-like, we succeed in developing a working definition\nof consciousness for social strong AI which focuses on human-like creativity\nbeing exhibited as a third-person observable phenomenon. Creativity is then\nextrapolated to represent first-person functionality, fulfilling the\nfirst/third-person feature of consciousness. Next, several sources of existing\nrights and rules, both for humans and robots, are analyzed and, along with\nsupplementary informal reports, synthesized to create articles for an additive\ncharter which compliments the United Nation's Universal Declaration of Human\nRights. Finally, the charter is presented and the paper concludes with the\nconditions for amending the charter, as well as recommendations for further\ncharters.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 18:46:38 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 06:26:17 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Hromiak", "Markian", ""]]}, {"id": "2010.12020", "submitter": "Olasupo Ajayi", "authors": "Olasupo O. Ajayi, Antoine B. Bagula, Hloniphani M. Maluleke", "title": "Africa 3: A Continental Network Model to Enable the African Fourth\n  Industrial Revolution", "comments": "30 pages, 8 tables, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is widely recognised that collaboration can help fast-track the\ndevelopment of countries in Africa. Leveraging on the fourth industrial\nrevolution, Africa can achieve accelerated development in health care services,\neducational systems and socio-economic infrastructures. While a number of\nconceptual frameworks have been proposed for the African continent, many have\ndiscounted the Cloud infrastructure used for data storage and processing, as\nwell as the underlying network infrastructure upon which such frameworks would\nbe built. This work therefore presents a continental network model for\ninterconnecting nations in Africa through its data centres. The proposed model\nis based on a multilayer network engineering approach, which first groups\nAfrican countries into clusters of data centres using a hybrid combination of\nclustering techniques; then utilizes Ant Colony Optimization with Stench\nPheromone, that is modified to support variable evaporation rates, to find the\nideal network path(s) across the clusters and the continent as a whole. The\npropsoed model takes into consideration the geo-spatial location, population\nsizes, data centre counts and intercontinental submarine cable landings of each\nAfrican country, when clustering and routing. For bench-marking purposes, the\npath selection algorithm was tested on both the obtained clusters and African\nUnion's regional clusters.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 16:19:25 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Ajayi", "Olasupo O.", ""], ["Bagula", "Antoine B.", ""], ["Maluleke", "Hloniphani M.", ""]]}, {"id": "2010.12022", "submitter": "Adel Al-Dawood", "authors": "Adel Al-Dawood, Serene Alhajhussein, Svetlana Yarosh", "title": "Saudi Arabian Parents' Perception of Online Marital Matchmaking\n  Technologies", "comments": "31 pages, CSCW 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding a date or a spouse online is usually considered an individualistic\nendeavor in Western cultures. This presents a challenge for collectivist\nnon-Western cultures such as Saudi Arabia where choosing a spouse is viewed as\na union of two families with parents of both spouses being heavily involved.\nOur work aims to investigate how Saudi Arabian parents view the utilization of\ntechnology by their young adults to seek potential spouses online. We report\nour findings of interviews conducted with 16 Saudi Arabian parents (8 fathers,\n6 mothers and 1 couple). We generate qualitative themes that provide insights\nabout how parents wanted to preserve their values, integrate technology into\nthe traditional process and protect their young adults from potential harms.\nThese themes lead to implications for designing suitable marital matchmaking\ntechnologies in Saudi Arabia and opportunities for future work.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 18:35:22 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Al-Dawood", "Adel", ""], ["Alhajhussein", "Serene", ""], ["Yarosh", "Svetlana", ""]]}, {"id": "2010.12026", "submitter": "Niklas K\\\"uhl", "authors": "Niklas K\\\"uhl, Dominik Martin, Clemens Wolff, Melanie Volkamer", "title": "\"Healthy surveillance\": Designing a concept for privacy-preserving mask\n  recognition AI in the age of pandemics", "comments": "54th Annual Hawaii International Conference on System Sciences\n  (HICSS-54)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The obligation to wear masks in times of pandemics reduces the risk of\nspreading viruses. In case of the COVID-19 pandemic in 2020, many governments\nrecommended or even obligated their citizens to wear masks as an effective\ncountermeasure. In order to continuously monitor the compliance of this policy\nmeasure in public spaces like restaurants or tram stations by public\nauthorities, one scalable and automatable option depicts the application of\nsurveillance systems, i.e., CCTV. However, large-scale monitoring of mask\nrecognition does not only require a well-performing Artificial Intelligence,\nbut also ensure that no privacy issues are introduced, as surveillance is a\ndeterrent for citizens and regulations like General Data Protection Regulation\n(GDPR) demand strict regulations of such personal data. In this work, we show\nhow a privacy-preserving mask recognition artifact could look like, demonstrate\ndifferent options for implementation and evaluate performances. Our conceptual\ndeep-learning based Artificial Intelligence is able to achieve detection\nperformances between 95% and 99% in a privacy-friendly setting. On that basis,\nwe elaborate on the trade-off between the level of privacy preservation and\nArtificial Intelligence performance, i.e. the \"price of privacy\".\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 14:00:04 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["K\u00fchl", "Niklas", ""], ["Martin", "Dominik", ""], ["Wolff", "Clemens", ""], ["Volkamer", "Melanie", ""]]}, {"id": "2010.12027", "submitter": "Hong Sun", "authors": "Hong Sun, D\\\"orthe Arndt, Jos De Roo and Erik Mannens", "title": "Predicting future state for adaptive clinical pathway management", "comments": null, "journal-ref": null, "doi": "10.1016/j.jbi.2021.103750", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical decision support systems are assisting physicians in providing care\nto patients. However, in the context of clinical pathway management such\nsystems are rather limited as they only take the current state of the patient\ninto account and ignore the possible evolvement of that state in the future. In\nthe past decade, the availability of big data in the healthcare domain did open\na new era for clinical decision support. Machine learning technologies are now\nwidely used in the clinical domain, nevertheless, mostly as a tool for disease\nprediction. A tool that not only predicts future states, but also enables\nadaptive clinical pathway management based on these predictions is still in\nneed. This paper introduces weighted state transition logic, a logic to model\nstate changes based on actions planned in clinical pathways. Weighted state\ntransition logic extends linear logic by taking weights -- numerical values\nindicating the quality of an action or an entire clinical pathway -- into\naccount. It allows us to predict the future states of a patient and it enables\nadaptive clinical pathway management based on these predictions. We provide an\nimplementation of weighted state transition logic using semantic web\ntechnologies, which makes it easy to integrate semantic data and rules as\nbackground knowledge. Executed by a semantic reasoner, it is possible to\ngenerate a clinical pathway towards a target state, as well as to detect\npotential conflicts in the future when multiple pathways are coexisting. The\ntransitions from the current state to the predicted future state are traceable,\nwhich builds trust from human users on the generated pathway.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 13:05:22 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 20:38:27 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Sun", "Hong", ""], ["Arndt", "D\u00f6rthe", ""], ["De Roo", "Jos", ""], ["Mannens", "Erik", ""]]}, {"id": "2010.12031", "submitter": "Sachithra Lokuge", "authors": "Sachithra Lokuge", "title": "Theoretical opportunities for rural innovation and entrepreneurship\n  research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IT math.IT", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Even though rural entrepreneurship and innovation has been studied for\ndecades, the advent of social media, mobile, analytics, cloud computing and\ninternet of things - also referred as digital technologies - (Nambisan 2013,\nYoo et al. 2012) has provided new opportunities and challenges for this vast\ndiscipline. As a result, we see new business models, new processes, products\nand services offered using new digital technologies. Such changes challenge the\northodox view of IT entrepreneurship and innovation, opening new avenues for\nresearches and challenges the existing theoretical understanding. This book\nchapter is an attempt to understand the existing literature on rural innovation\nand entrepreneurship in information systems discipline and identify\nopportunities for rural entrepreneurship and innovation in the digital era.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 20:42:03 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Lokuge", "Sachithra", ""]]}, {"id": "2010.12032", "submitter": "Sachithra Lokuge", "authors": "Darshana Sedera and Sachithra Lokuge", "title": "Flaws in Flawlessness: Perfectionism as a New Technology Driven Mental\n  Disorder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IT math.IT", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Today, technologies, devices and systems play a major role in our lives.\nAnecdotal commentary suggests that such technologies and our interactions with\nthem create a false sense of perfectionism about life, events and its outcomes.\nWhile it is admirable to strive for better outcomes, constant and sometimes\nunrealistic expectations create a psychological condition commonly known as\nPerfectionism, the fear of not doing something right or the fear of not being\ngood enough. In this paper, based on the Diagnostic Statistical Manual of\nMental Disorders (DSM-III), we conceptualize digital perfectionism as an\nemerging disorder, that is specific to our increasing interactions with tools\nand technologies. By using a sample of 336 individuals, this study makes\nvaluable early insights on digital perfectionism, its conceptualization and its\neffects on the individuals.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 20:37:01 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Sedera", "Darshana", ""], ["Lokuge", "Sachithra", ""]]}, {"id": "2010.12034", "submitter": "Sachithra Lokuge", "authors": "Sachithra Lokuge, Darshana Sedera, Vanessa Cooper and Frada Burstein", "title": "Digital Transformation: Environmental Friend or Foe? Panel Discussion at\n  the Australasian Conference on Information Systems 2019", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The advent of digital technologies such as social media, mobile, analytics,\ncloud computing and internet-of-things has provided unique opportunities for\norganizations to engage in innovations that are affordable, easy-to-use,\neasy-to-learn and easy-to-implement. Transformations through such technologies\noften have positive impacts on business processes, products and services. As\nsuch, organizations have managed to increase productivity and efficiency,\nreduce cycle time and make substantial gains through digital transformation.\nSuch transformations have also been positively associated with reducing harmful\nenvironmental impacts by providing organizations alternative ways of\nundertaking their business activities. However, in recent times, especially\nwith an abundance of technologies being available at near-zero costs, questions\nregarding the potential negative impacts of digital transformation on the\nenvironment have arisen. The morass of the ubiquitous technologies around us\nnecessitates the continuing creation of large data centers, that are increasing\ntheir capacity yielding a negative impact on the environment. Considering this\ndialectical contradiction, a panel was conducted at the Australasian Conference\non Information Systems (ACIS) in Perth, Australia, in 2019. Its aim was to\ninvigorate the dialogue regarding the impact of digital transformation on\nenvironmental sustainability and suggested some directions for future research\nin this area.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 20:27:07 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Lokuge", "Sachithra", ""], ["Sedera", "Darshana", ""], ["Cooper", "Vanessa", ""], ["Burstein", "Frada", ""]]}, {"id": "2010.12036", "submitter": "Evangelos Mitsakis", "authors": "Georgia Aifantopoulou, Chrysostomos Mylonas, Alexandros Dolianitis,\n  Afroditi Stamelou, Vasileios Psonis, Evangelos Mitsakis", "title": "National Access Points for Intelligent Transport Systems Data: From\n  Conceptualization to Benefits Recognition and Exploitation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent Transport Systems (ITS) constitute a core representative of a\nparadigm shift in the transport sector. The extent to which the transport\nsector has adapted itself to this digital era relies considerably on the\navailability of suitable and reliable data. Currently, several data-related\nlimitations, such as the scarcity of available datasets, hinder the deployment\nof ITS services. Such limitations may be overcome with the deployment of\nproperly designed data exchange platforms that enable a seamless life-cycle of\ndata harvesting, processing, and sharing. The European Union recognizing the\npotential benefits of such platforms has, through the relevant Delegated\nRegulations, proposed the development of a National Access Point (NAP) by each\nindividual Member State. This paper aims to ascertain the role of a NAP within\nthe ITS ecosystem, to investigate methodologies used in designing such\nplatforms, and, through the drafting of an extended use case, showcase a NAP\noperational process and associate possible benefits with specific steps of it.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 17:13:00 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Aifantopoulou", "Georgia", ""], ["Mylonas", "Chrysostomos", ""], ["Dolianitis", "Alexandros", ""], ["Stamelou", "Afroditi", ""], ["Psonis", "Vasileios", ""], ["Mitsakis", "Evangelos", ""]]}, {"id": "2010.12037", "submitter": "Evangelos Mitsakis", "authors": "Charis Chalkiadakis, Panagiotis Iordanopoulos, Evangelos Mitsakis", "title": "Training Opportunities for Intelligent Transport Systems and Cooperative\n  Intelligent Transport Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent Transport Systems (ITS) and Cooperative Intelligent Transport\nSystems (C-ITS) are of high significance, mainly due to the benefits they have\nin terms of operation of the transport network. Despite ITS and C-ITS\nimportance in the operation of the transport network, there is a major\nknowledge gap regarding their development, way of operation and significance\nworldwide and especially among the responsible for their deployment public\nauthorities. In order for such fragmentations to be tackled, an online training\nplatform concerning the operation and impacts of ITS and C-ITS has been\ndesigned in the framework of the European Union Horizon 2020 funded CAPITAL\nproject. In order for the proper design of the CAPITAL Online Training\nPlatform, two main approaches have been studied: capacity building and massive\nopen online courses. The present study provides insight regarding the design\nand the context of the CAPITAL Online Training Platform.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 17:05:54 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Chalkiadakis", "Charis", ""], ["Iordanopoulos", "Panagiotis", ""], ["Mitsakis", "Evangelos", ""]]}, {"id": "2010.12038", "submitter": "Mohammad Arani", "authors": "Miguel Baritto, Md Mashum Billal, S. M. Muntasir Nasim, Rumana Afroz\n  Sultana, Mohammad Arani, Ahmed Jawad Qureshi", "title": "Supporting Tool for The Transition of Existing Small and Medium\n  Enterprises Towards Industry 4.0", "comments": "This paper is accepted by the \"International Conference on Data\n  Analytics for Business and Industry\", and it will be published by IEEE\n  Xplore. (http://data20.uob.edu.bh/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid growth of Industry 4.0 technologies such as big data, cloud\ncomputing, smart sensors, machine learning (ML), radio-frequency identification\n(RFID), robotics, 3D-printing, and Internet of Things (IoT) offers Small and\nMedium Enterprises (SMEs) the chance to improve productivity and efficiency,\nreduce cost and provide better customer experience, among other benefits. The\nmain purpose of this work is to propose a methodology to support SMEs managers\nin better understanding the specific requirements for the implementation of\nIndustry 4.0 solutions and the derived benefits within their firms. A proposed\nmethodology will be helpful for SMEs manager to take a decision regarding when\nand how to migrate to Industry 4.0.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 15:57:23 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Baritto", "Miguel", ""], ["Billal", "Md Mashum", ""], ["Nasim", "S. M. Muntasir", ""], ["Sultana", "Rumana Afroz", ""], ["Arani", "Mohammad", ""], ["Qureshi", "Ahmed Jawad", ""]]}, {"id": "2010.12042", "submitter": "Byungsoo Kim", "authors": "Dongmin Shin, Yugeun Shim, Hangyeol Yu, Seewoo Lee, Byungsoo Kim,\n  Youngduck Choi", "title": "SAINT+: Integrating Temporal Features for EdNet Correctness Prediction", "comments": "LAK 2021", "journal-ref": null, "doi": "10.1145/3448139.3448188", "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose SAINT+, a successor of SAINT which is a Transformer based\nknowledge tracing model that separately processes exercise information and\nstudent response information. Following the architecture of SAINT, SAINT+ has\nan encoder-decoder structure where the encoder applies self-attention layers to\na stream of exercise embeddings, and the decoder alternately applies\nself-attention layers and encoder-decoder attention layers to streams of\nresponse embeddings and encoder output. Moreover, SAINT+ incorporates two\ntemporal feature embeddings into the response embeddings: elapsed time, the\ntime taken for a student to answer, and lag time, the time interval between\nadjacent learning activities. We empirically evaluate the effectiveness of\nSAINT+ on EdNet, the largest publicly available benchmark dataset in the\neducation domain. Experimental results show that SAINT+ achieves\nstate-of-the-art performance in knowledge tracing with an improvement of 1.25%\nin area under receiver operating characteristic curve compared to SAINT, the\ncurrent state-of-the-art model in EdNet dataset.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 01:49:31 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2021 02:31:42 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Shin", "Dongmin", ""], ["Shim", "Yugeun", ""], ["Yu", "Hangyeol", ""], ["Lee", "Seewoo", ""], ["Kim", "Byungsoo", ""], ["Choi", "Youngduck", ""]]}, {"id": "2010.12418", "submitter": "Ahmed Al-Ali", "authors": "Ahmed Ghanim Al-Ali, Robert Phaal, Donald Sull", "title": "Deep Learning Framework for Measuring the Digital Strategy of Companies\n  from Earnings Calls", "comments": "Proceedings of The 28th International Conference on Computational\n  Linguistics, 9 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Companies today are racing to leverage the latest digital technologies, such\nas artificial intelligence, blockchain, and cloud computing. However, many\ncompanies report that their strategies did not achieve the anticipated business\nresults. This study is the first to apply state of the art NLP models on\nunstructured data to understand the different clusters of digital strategy\npatterns that companies are Adopting. We achieve this by analyzing earnings\ncalls from Fortune Global 500 companies between 2015 and 2019. We use\nTransformer based architecture for text classification which show a better\nunderstanding of the conversation context. We then investigate digital strategy\npatterns by applying clustering analysis. Our findings suggest that Fortune 500\ncompanies use four distinct strategies which are product led, customer\nexperience led, service led, and efficiency led. This work provides an\nempirical baseline for companies and researchers to enhance our understanding\nof the field.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 14:07:12 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 04:36:18 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Al-Ali", "Ahmed Ghanim", ""], ["Phaal", "Robert", ""], ["Sull", "Donald", ""]]}, {"id": "2010.12540", "submitter": "Mohamed Maher Mr", "authors": "Mohamed Maher (1), Perseverance Munga Ngoy (1), Aleksandrs Rebriks\n  (1), Cagri Ozcinar (1), Josue Cuevas (3), Rajasekhar Sanagavarapu (3),\n  Gholamreza Anbarjafari (1 and 2) ((1) iCV Lab, University of Tartu, Tartu,\n  Estonia, (2) Faculty of Engineering, Hasan Kalyoncu University, Gaziantep,\n  Turkey, (3) Rakuten Inc., Big Data Department, Machine Learning Group, Tokyo,\n  Japan)", "title": "Comprehensive Empirical Evaluation of Deep Learning Approaches for\n  Session-based Recommendation in E-Commerce", "comments": "48 pages, 17 figures, journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boosting sales of e-commerce services is guaranteed once users find more\nmatching items to their interests in a short time. Consequently, recommendation\nsystems have become a crucial part of any successful e-commerce services.\nAlthough various recommendation techniques could be used in e-commerce, a\nconsiderable amount of attention has been drawn to session-based recommendation\nsystems during the recent few years. This growing interest is due to the\nsecurity concerns in collecting personalized user behavior data, especially\nafter the recent general data protection regulations. In this work, we present\na comprehensive evaluation of the state-of-the-art deep learning approaches\nused in the session-based recommendation. In session-based recommendation, a\nrecommendation system counts on the sequence of events made by a user within\nthe same session to predict and endorse other items that are more likely to\ncorrelate with his/her preferences. Our extensive experiments investigate\nbaseline techniques (\\textit{e.g.,} nearest neighbors and pattern mining\nalgorithms) and deep learning approaches (\\textit{e.g.,} recurrent neural\nnetworks, graph neural networks, and attention-based networks). Our evaluations\nshow that advanced neural-based models and session-based nearest neighbor\nalgorithms outperform the baseline techniques in most of the scenarios.\nHowever, we found that these models suffer more in case of long sessions when\nthere exists drift in user interests, and when there is no enough data to model\ndifferent items correctly during training. Our study suggests that using hybrid\nmodels of different approaches combined with baseline algorithms could lead to\nsubstantial results in session-based recommendations based on dataset\ncharacteristics. We also discuss the drawbacks of current session-based\nrecommendation algorithms and further open research directions in this field.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 17:22:35 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Maher", "Mohamed", "", "1 and 2"], ["Ngoy", "Perseverance Munga", "", "1 and 2"], ["Rebriks", "Aleksandrs", "", "1 and 2"], ["Ozcinar", "Cagri", "", "1 and 2"], ["Cuevas", "Josue", "", "1 and 2"], ["Sanagavarapu", "Rajasekhar", "", "1 and 2"], ["Anbarjafari", "Gholamreza", "", "1 and 2"]]}, {"id": "2010.12641", "submitter": "Eleonora Losiouk", "authors": "Marco Casagrande, Mauro Conti, Eleonora Losiouk", "title": "Contact Tracing Made Un-relay-able", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated contact tracing is a key solution to control the spread of airborne\ntransmittable diseases: it traces contacts among individuals in order to alert\npeople about their potential risk of being infected. The current SARS-CoV-2\npandemic put a heavy strain on the healthcare system of many countries.\nGovernments chose different approaches to face the spread of the virus and the\ncontact tracing apps were considered the most effective ones. In particular, by\nleveraging on the Bluetooth Low-Energy technology, mobile apps allow to achieve\na privacy-preserving contact tracing of citizens. While researchers proposed\nseveral contact tracing approaches, each government developed its own national\ncontact tracing app.\n  In this paper, we demonstrate that many popular contact tracing apps (e.g.,\nthe ones promoted by the Italian, French, Swiss government) are vulnerable to\nrelay attacks. Through such attacks people might get misleadingly diagnosed as\npositive to SARS-CoV-2, thus being enforced to quarantine and eventually\nleading to a breakdown of the healthcare system. To tackle this vulnerability,\nwe propose a novel and lightweight solution that prevents relay attacks, while\nproviding the same privacy-preserving features as the current approaches. To\nevaluate the feasibility of both the relay attack and our novel defence\nmechanism, we developed a proof of concept against the Italian contact tracing\napp (i.e., Immuni). The design of our defence allows it to be integrated into\nany contact tracing app.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 20:03:31 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 16:56:56 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Casagrande", "Marco", ""], ["Conti", "Mauro", ""], ["Losiouk", "Eleonora", ""]]}, {"id": "2010.12710", "submitter": "Maria Phillips", "authors": "Debajyoti Datta, Maria Phillips, Jennifer Chiu, Ginger S. Watson,\n  James P. Bywater, Laura Barnes, and Donald Brown", "title": "Improving Classification through Weak Supervision in Context-specific\n  Conversational Agent Development for Teacher Education", "comments": "Preprint: Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning techniques applied to the Natural Language Processing (NLP)\ncomponent of conversational agent development show promising results for\nimproved accuracy and quality of feedback that a conversational agent can\nprovide. The effort required to develop an educational scenario specific\nconversational agent is time consuming as it requires domain experts to label\nand annotate noisy data sources such as classroom videos. Previous approaches\nto modeling annotations have relied on labeling thousands of examples and\ncalculating inter-annotator agreement and majority votes in order to model the\nnecessary scenarios. This method, while proven successful, ignores individual\nannotator strengths in labeling a data point and under-utilizes examples that\ndo not have a majority vote for labeling. We propose using a multi-task weak\nsupervision method combined with active learning to address these concerns.\nThis approach requires less labeling than traditional methods and shows\nsignificant improvements in precision, efficiency, and time-requirements than\nthe majority vote method (Ratner 2019). We demonstrate the validity of this\nmethod on the Google Jigsaw data set and then propose a scenario to apply this\nmethod using the Instructional Quality Assessment(IQA) to define the categories\nfor labeling. We propose using probabilistic modeling of annotator labeling to\ngenerate active learning examples to further label the data. Active learning is\nable to iteratively improve the training performance and accuracy of the\noriginal classification model. This approach combines state-of-the art labeling\ntechniques of weak supervision and active learning to optimize results in the\neducational domain and could be further used to lessen the data requirements\nfor expanded scenarios within the education domain through transfer learning.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 23:39:40 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Datta", "Debajyoti", ""], ["Phillips", "Maria", ""], ["Chiu", "Jennifer", ""], ["Watson", "Ginger S.", ""], ["Bywater", "James P.", ""], ["Barnes", "Laura", ""], ["Brown", "Donald", ""]]}, {"id": "2010.13026", "submitter": "Subodip Biswas", "authors": "Andreea Sistrunk, Vanessa Cedeno and Subhodip Biswas", "title": "On synthetic data generation for anomaly detection in complex social\n  networks", "comments": "Presented at AAAI FSS-20: Artificial Intelligence in Government and\n  Public Sector, Washington, DC, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the feasibility of synthetic data generation for\nmission-critical applications. The emphasis is on synthetic data generation for\nanomalous detection in complex social networks. In particular, the development\nof a heuristic generative model, capable of creating data for anomalous rare\nactivities in complex social networks is sought. To this end, lessons from\nsocial and political literature are applied to prototype a novel implementation\nof the Agent-based Modeling (ABM) framework, based on simple social\ninteractions between agents, for synthetic data generation in the context of\nterrorist profile desegregation. The conclusion offers directions for further\nverification, fine-tuning, and proposes future directions of work for the ABM\nprototype, as a complex-societal approach to synthetic data generation, by\nidentifying heuristic hyper-parameter tuning methodologies to further ensure\nthe generated data distribution is similar to the true distribution of the\noriginal data-sets. While a rigorous mathematical optimization for reducing the\ndistances in distributions is not offered in this work, we opine that this\nprototype of an autonomous-agent generative complex social model is useful for\nstudying and researching on pattern of life and anomaly detection where there\nis strict limitation or lack of sufficient data for using practical machine\nlearning solutions in mission-critical applications.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 03:53:19 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Sistrunk", "Andreea", ""], ["Cedeno", "Vanessa", ""], ["Biswas", "Subhodip", ""]]}, {"id": "2010.13168", "submitter": "Tenzin Singhay Bhotia", "authors": "Vaibhav Kumar, Tenzin Singhay Bhotia, Vaibhav Kumar", "title": "Fair Embedding Engine: A Library for Analyzing and Mitigating Gender\n  Bias in Word Embeddings", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-contextual word embedding models have been shown to inherit human-like\nstereotypical biases of gender, race and religion from the training corpora. To\ncounter this issue, a large body of research has emerged which aims to mitigate\nthese biases while keeping the syntactic and semantic utility of embeddings\nintact. This paper describes Fair Embedding Engine (FEE), a library for\nanalysing and mitigating gender bias in word embeddings. FEE combines various\nstate of the art techniques for quantifying, visualising and mitigating gender\nbias in word embeddings under a standard abstraction. FEE will aid\npractitioners in fast track analysis of existing debiasing methods on their\nembedding models. Further, it will allow rapid prototyping of new methods by\nevaluating their performance on a suite of standard metrics.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 17:31:12 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Kumar", "Vaibhav", ""], ["Bhotia", "Tenzin Singhay", ""], ["Kumar", "Vaibhav", ""]]}, {"id": "2010.13263", "submitter": "Mayank Singh", "authors": "Vivek Srivastava, Mayank Singh", "title": "PoliWAM: An Exploration of a Large Scale Corpus of Political Discussions\n  on WhatsApp Messenger", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  WhatsApp Messenger is one of the most popular channels for spreading\ninformation with a current reach of more than 180 countries and 2 billion\npeople. Its widespread usage has made it one of the most popular media for\ninformation propagation among masses during any socially engaging event. In the\nrecent past, several countries have witnessed its effectiveness and influence\nin political and social campaigns. We observe a high surge in information and\npropaganda flow during elections. To explore such activities, in this paper, we\ndiscuss challenges, methodology, and opportunities in data curation from\nWhatsApp for politics-based exploratory studies. As a use case, we study the\nperiod before, during, and after the Indian General Elections 2019,\nencompassing all major Indian political parties. We present several\ncomplementing insights into the investigative and sensational news stories from\nthe same period. Exploratory data analysis and experiments showcase several\nexciting results and future research opportunities. To facilitate reproducible\nresearch, we make the anonymized datasets available in the public domain.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 00:35:57 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Srivastava", "Vivek", ""], ["Singh", "Mayank", ""]]}, {"id": "2010.13276", "submitter": "Shah Miah Prof", "authors": "Atae Rezaei Aghdam, Jason Watson, Shah J Miah, Cynthia Cliff", "title": "Towards Empowering Diabetic Patients: A perspective on self-management\n  in the context of a group-based education program", "comments": "The paper has been accepted for publishing and presenting at the\n  Australasian Conference on Information Systems, Dec 2020, Wellington, NZ", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a novel framework for maximizing the effectiveness of the\nDiabetes Group Education Program, which could be generalized in any similar\nproblem context.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 01:45:29 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Aghdam", "Atae Rezaei", ""], ["Watson", "Jason", ""], ["Miah", "Shah J", ""], ["Cliff", "Cynthia", ""]]}, {"id": "2010.13438", "submitter": "Andrea Araldo", "authors": "Ado Adamou Abba Ari, Andrea Araldo, Andr\\'e De Palma, and Vincent\n  Gauthier", "title": "Pooling for First and Last Mile", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CY cs.SY econ.GN eess.SY q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Carpooling is a system in which drivers accept to add some limited detours to\ntheir habitual journeys to pick-up and drop-off other riders. Most research and\noperating platforms present carpooling as an alternative to fixed schedule\ntransit and only very little work has attempted to integrate it with\nfixed-schedule mass transit. The aim of this paper is to showcase the benefits\nof such integration, under the philosophy of Mobility as a Service (MaaS), in a\ndaily commuting scenario. We present an integrated mass transit plus carpooling\nsystem that, by design, constructs multimodal trips, including transit and\ncarpooling legs. To this aim, the system generates vehicle detours in order to\nserve transit stations. We evaluate the performance of this system via\nsimulation. We compare the ``Current'' System, where carpooling is an\nalternative to transit, to our ``Integrated'' System, where carpooling and\ntransit are integrated in a single system. We show that, by doing this, the\ntransportation accessibility greatly increases: about 40\\% less users remain\nwithout feasible travel options and the overall travel time decreases by about\n10\\%. We achieve this by requiring relatively small driver detours, thanks to a\nbetter utilization vehicle routes, with drivers' vehicles driving on average\nwith more riders on board. The simulation code is available open source.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 09:18:21 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Ari", "Ado Adamou Abba", ""], ["Araldo", "Andrea", ""], ["De Palma", "Andr\u00e9", ""], ["Gauthier", "Vincent", ""]]}, {"id": "2010.13462", "submitter": "Qiang Tang", "authors": "Qiang Tang", "title": "Another Look at Privacy-Preserving Automated Contact Tracing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the current COVID-19 pandemic, manual contact tracing has been proven very\nhelpful to reach close contacts of infected users and slow down virus\nspreading. To improve its scalability, a number of automated contact tracing\n(ACT) solutions have proposed and some of them have been deployed. Despite the\ndedicated efforts, security and privacy issues of these solutions are still\nopen and under intensive debate. In this paper, we examine the ACT concept from\na broader perspective, by focusing on not only security and privacy issues but\nalso functional issues such as interface, usability and coverage. We first\nelaborate on these issues and particularly point out the inevitable privacy\nleakages in existing BLE-based ACT solutions. Then, we propose a venue-based\nACT concept, which only monitors users' contacting history in\nvirus-spreading-prone venues and is able to incorporate different location\ntracking technologies such as BLE and WIFI. Finally, we instantiate the\nvenue-based ACT concept and show that our instantiation can mitigate most of\nthe issues we have identified in our analysis.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 09:59:15 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Tang", "Qiang", ""]]}, {"id": "2010.13494", "submitter": "Kenji Kobayashi", "authors": "Kenji Kobayashi, Yuri Nakao", "title": "One-vs.-One Mitigation of Intersectional Bias: A General Method to\n  Extend Fairness-Aware Binary Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the widespread adoption of machine learning in the real world, the\nimpact of the discriminatory bias has attracted attention. In recent years,\nvarious methods to mitigate the bias have been proposed. However, most of them\nhave not considered intersectional bias, which brings unfair situations where\npeople belonging to specific subgroups of a protected group are treated worse\nwhen multiple sensitive attributes are taken into consideration. To mitigate\nthis bias, in this paper, we propose a method called One-vs.-One Mitigation by\napplying a process of comparison between each pair of subgroups related to\nsensitive attributes to the fairness-aware machine learning for binary\nclassification. We compare our method and the conventional fairness-aware\nbinary classification methods in comprehensive settings using three approaches\n(pre-processing, in-processing, and post-processing), six metrics (the ratio\nand difference of demographic parity, equalized odds, and equal opportunity),\nand two real-world datasets (Adult and COMPAS). As a result, our method\nmitigates the intersectional bias much better than conventional methods in all\nthe settings. With the result, we open up the potential of fairness-aware\nbinary classification for solving more realistic problems occurring when there\nare multiple sensitive attributes.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 11:35:39 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Kobayashi", "Kenji", ""], ["Nakao", "Yuri", ""]]}, {"id": "2010.13552", "submitter": "\\\"Ozlem Salehi", "authors": "\\\"Ozlem Salehi, Zeki Seskir, \\.Ilknur Tepe", "title": "A Computer Science-Oriented Approach to Introduce Quantum Computing to a\n  New Audience", "comments": "Accepted to IEEE Transactions on Education", "journal-ref": null, "doi": "10.1109/TE.2021.3078552", "report-no": null, "categories": "physics.ed-ph cs.CY cs.ET quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contribution: In this study, an alternative educational approach for\nintroducing quantum computing to a wider audience is highlighted. The proposed\nmethodology considers quantum computing as a generalized probability theory\nrather than a field emanating from physics and utilizes quantum programming as\nan educational tool to reinforce the learning process.\n  Background: Quantum computing is a topic mainly rooted in physics, and it has\nbeen gaining rapid popularity in recent years. A need for extending the\neducational reach to groups outside of physics has also been becoming a\nnecessity.\n  Intended outcomes: This study aims to inform academics and organizations\ninterested in introducing quantum computing to a diverse group of participants\non an educational approach. It is intended that the proposed methodology would\nfacilitate people from diverse backgrounds to enter the field\n  Application design: The introductory quantum physics content is bypassed and\nthe quantum computing concepts are introduced through linear algebra instead.\nQuantum programming tasks are prepared in line with the content. Pre/post-test\ndesign method and Likert scale satisfaction surveys are utilized to measure\nknowledge acquisition and to evaluate the perception of the learning process by\nthe participants.\n  Findings: Conducted pre/post-test design survey shows that there is a\nstatistically significant increase in the basic knowledge levels of the\nparticipants on quantum computing concepts. Furthermore, no significant\ndifference in the gain scores is observed between the participants from\ndifferent STEM-related educational backgrounds. The majority of the\nparticipants were satisfied and provided positive feedback.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 16:15:34 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 19:38:45 GMT"}, {"version": "v3", "created": "Mon, 7 Dec 2020 18:05:38 GMT"}, {"version": "v4", "created": "Tue, 11 May 2021 20:29:35 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Salehi", "\u00d6zlem", ""], ["Seskir", "Zeki", ""], ["Tepe", "\u0130lknur", ""]]}, {"id": "2010.13561", "submitter": "Ben Hutchinson", "authors": "Ben Hutchinson, Andrew Smart, Alex Hanna, Emily Denton, Christina\n  Greer, Oddur Kjartansson, Parker Barnes, Margaret Mitchell", "title": "Towards Accountability for Machine Learning Datasets: Practices from\n  Software Engineering and Infrastructure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.DB cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rising concern for the societal implications of artificial intelligence\nsystems has inspired demands for greater transparency and accountability.\nHowever the datasets which empower machine learning are often used, shared and\nre-used with little visibility into the processes of deliberation which led to\ntheir creation. Which stakeholder groups had their perspectives included when\nthe dataset was conceived? Which domain experts were consulted regarding how to\nmodel subgroups and other phenomena? How were questions of representational\nbiases measured and addressed? Who labeled the data? In this paper, we\nintroduce a rigorous framework for dataset development transparency which\nsupports decision-making and accountability. The framework uses the cyclical,\ninfrastructural and engineering nature of dataset development to draw on best\npractices from the software development lifecycle. Each stage of the data\ndevelopment lifecycle yields a set of documents that facilitate improved\ncommunication and decision-making, as well as drawing attention the value and\nnecessity of careful data work. The proposed framework is intended to\ncontribute to closing the accountability gap in artificial intelligence\nsystems, by making visible the often overlooked work that goes into dataset\ncreation.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 01:57:42 GMT"}, {"version": "v2", "created": "Sat, 30 Jan 2021 00:12:54 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Hutchinson", "Ben", ""], ["Smart", "Andrew", ""], ["Hanna", "Alex", ""], ["Denton", "Emily", ""], ["Greer", "Christina", ""], ["Kjartansson", "Oddur", ""], ["Barnes", "Parker", ""], ["Mitchell", "Margaret", ""]]}, {"id": "2010.13691", "submitter": "Christopher Torres-Lugo", "authors": "Christopher Torres-Lugo, Kai-Cheng Yang, Filippo Menczer", "title": "The Manufacture of Partisan Echo Chambers by Follow Train Abuse on\n  Twitter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A growing body of evidence points to critical vulnerabilities of social\nmedia, such as the emergence of partisan echo chambers and the viral spread of\nmisinformation. We show that these vulnerabilities are amplified by abusive\nbehaviors associated with so-called \"follow trains\" on Twitter, in which long\nlists of like-minded accounts are mentioned for others to follow. We present\nthe first systematic analysis of a large U.S. hyper-partisan train network. We\nobserve an artificial inflation of influence: accounts heavily promoted by\nfollow trains profit from a median six-fold increase in daily follower growth.\nThis catalyzes the formation of highly clustered echo chambers, hierarchically\norganized around a dense core of active accounts. Train accounts also engage in\nother behaviors that violate platform policies: we find evidence of activity by\ninauthentic automated accounts and abnormal content deletion, as well as\namplification of toxic content from low-credibility and conspiratorial sources.\nSome train accounts have been active for years, suggesting that platforms need\nto pay greater attention to this kind of abuse.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 16:11:56 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 02:21:05 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Torres-Lugo", "Christopher", ""], ["Yang", "Kai-Cheng", ""], ["Menczer", "Filippo", ""]]}, {"id": "2010.14245", "submitter": "Christine Utz", "authors": "Christine Utz, Steffen Becker, Theodor Schnitzler, Florian M. Farke,\n  Franziska Herbert, Leonie Schaewitz, Martin Degeling, Markus D\\\"urmuth", "title": "Apps Against the Spread: Privacy Implications and User Acceptance of\n  COVID-19-Related Smartphone Apps on Three Continents", "comments": "22 pages, 1 figure, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic has fueled the development of smartphone applications\nto assist disease management. Many \"corona apps\" require widespread adoption to\nbe effective, which has sparked public debates about the privacy, security, and\nsocietal implications of government-backed health applications. We conducted a\nrepresentative online study in Germany (n = 1,003), the US (n = 1,003), and\nChina (n = 1,019) to investigate user acceptance of corona apps, using a\nvignette design based on the contextual integrity framework. We explored apps\nfor contact tracing, symptom checks, quarantine enforcement, health\ncertificates, and mere information. Our results provide insights into data\nprocessing practices that foster adoption and reveal significant differences\nbetween countries, with user acceptance being highest in China and lowest in\nthe US. Chinese participants prefer the collection of personalized data, while\nGerman and US participants favor anonymity. Across countries, contact tracing\nis viewed more positively than quarantine enforcement, and technical\nmalfunctions negatively impact user acceptance.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 12:41:34 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2021 11:31:08 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Utz", "Christine", ""], ["Becker", "Steffen", ""], ["Schnitzler", "Theodor", ""], ["Farke", "Florian M.", ""], ["Herbert", "Franziska", ""], ["Schaewitz", "Leonie", ""], ["Degeling", "Martin", ""], ["D\u00fcrmuth", "Markus", ""]]}, {"id": "2010.14389", "submitter": "Andrew Isaak PhD", "authors": "Constantin von Selasinsky and Andrew Jay Isaak", "title": "It's all in the (Sub-)title? Expanding Signal Evaluation in Crowdfunding\n  Research", "comments": "Proceedings of the Twenty-Eighth European Conference on Information\n  Systems (ECIS2020)", "journal-ref": null, "doi": null, "report-no": "56", "categories": "cs.SI cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on crowdfunding success that incorporates CATA (computer-aided text\nanalysis) is quickly advancing to the big leagues (e.g., Parhankangas and\nRenko, 2017; Anglin et al., 2018; Moss et al., 2018) and is often theoretically\nbased on information asymmetry, social capital, signaling or a combination\nthereof. Yet, current papers that explore crowdfunding success criteria fail to\ntake advantage of the full breadth of signals available and only very few such\npapers examine technology projects. In this paper, we compare and contrast the\nstrength of the entrepreneur's textual success signals to project backers\nwithin this category. Based on a random sample of 1,049 technology projects\ncollected from Kickstarter, we evaluate textual information not only from\nproject titles and descriptions but also from video subtitles. We find that\nincorporating subtitle information increases the variance explained by the\nrespective models and therefore their predictive capability for funding\nsuccess. By expanding the information landscape, our work advances the field\nand paves the way for more fine-grained studies of success signals in\ncrowdfunding and therefore for an improved understanding of investor\ndecision-making in the crowd.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 15:51:31 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["von Selasinsky", "Constantin", ""], ["Isaak", "Andrew Jay", ""]]}, {"id": "2010.14443", "submitter": "Ufuk Topcu", "authors": "Ufuk Topcu, Nadya Bliss, Nancy Cooke, Missy Cummings, Ashley Llorens,\n  Howard Shrobe, and Lenore Zuck", "title": "Assured Autonomy: Path Toward Living With Autonomous Systems We Can\n  Trust", "comments": "A Computing Community Consortium (CCC) workshop report, 28 pages", "journal-ref": null, "doi": null, "report-no": "ccc2020report_5", "categories": "cs.CY cs.AI cs.HC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The challenge of establishing assurance in autonomy is rapidly attracting\nincreasing interest in the industry, government, and academia. Autonomy is a\nbroad and expansive capability that enables systems to behave without direct\ncontrol by a human operator. To that end, it is expected to be present in a\nwide variety of systems and applications. A vast range of industrial sectors,\nincluding (but by no means limited to) defense, mobility, health care,\nmanufacturing, and civilian infrastructure, are embracing the opportunities in\nautonomy yet face the similar barriers toward establishing the necessary level\nof assurance sooner or later. Numerous government agencies are poised to tackle\nthe challenges in assured autonomy.\n  Given the already immense interest and investment in autonomy, a series of\nworkshops on Assured Autonomy was convened to facilitate dialogs and increase\nawareness among the stakeholders in the academia, industry, and government.\nThis series of three workshops aimed to help create a unified understanding of\nthe goals for assured autonomy, the research trends and needs, and a strategy\nthat will facilitate sustained progress in autonomy.\n  The first workshop, held in October 2019, focused on current and anticipated\nchallenges and problems in assuring autonomous systems within and across\napplications and sectors. The second workshop held in February 2020, focused on\nexisting capabilities, current research, and research trends that could address\nthe challenges and problems identified in workshop. The third event was\ndedicated to a discussion of a draft of the major findings from the previous\ntwo workshops and the recommendations.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 17:00:01 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Topcu", "Ufuk", ""], ["Bliss", "Nadya", ""], ["Cooke", "Nancy", ""], ["Cummings", "Missy", ""], ["Llorens", "Ashley", ""], ["Shrobe", "Howard", ""], ["Zuck", "Lenore", ""]]}, {"id": "2010.14445", "submitter": "James Scheibner", "authors": "James Scheibner, Jean Louis Raisaro, Juan Ram\\'on Troncoso-Pastoriza,\n  Marcello Ienca, Jacques Fellay, Effy Vayena, Jean-Pierre Hubaux", "title": "Revolutionizing Medical Data Sharing Using Advanced Privacy Enhancing\n  Technologies: Technical, Legal and Ethical Synthesis", "comments": "19 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multisite medical data sharing is critical in modern clinical practice and\nmedical research. The challenge is to conduct data sharing that preserves\nindividual privacy and data usability. The shortcomings of traditional\nprivacy-enhancing technologies mean that institutions rely on bespoke data\nsharing contracts. These contracts increase the inefficiency of data sharing\nand may disincentivize important clinical treatment and medical research. This\npaper provides a synthesis between two novel advanced privacy enhancing\ntechnologies (PETs): Homomorphic Encryption and Secure Multiparty Computation\n(defined together as Multiparty Homomorphic Encryption or MHE). These PETs\nprovide a mathematical guarantee of privacy, with MHE providing a performance\nadvantage over separately using HE or SMC. We argue MHE fulfills legal\nrequirements for medical data sharing under the General Data Protection\nRegulation (GDPR) which has set a global benchmark for data protection.\nSpecifically, the data processed and shared using MHE can be considered\nanonymized data. We explain how MHE can reduce the reliance on customized\ncontractual measures between institutions. The proposed approach can accelerate\nthe pace of medical research whilst offering additional incentives for\nhealthcare and research institutes to employ common data interoperability\nstandards.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 17:03:28 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Scheibner", "James", ""], ["Raisaro", "Jean Louis", ""], ["Troncoso-Pastoriza", "Juan Ram\u00f3n", ""], ["Ienca", "Marcello", ""], ["Fellay", "Jacques", ""], ["Vayena", "Effy", ""], ["Hubaux", "Jean-Pierre", ""]]}, {"id": "2010.14448", "submitter": "Xavier Ferrer Aran", "authors": "Xavier Ferrer-Aran, Tom van Nuenen, Natalia Criado, Jose M. Such", "title": "Discovering and Interpreting Conceptual Biases in Online Communities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language carries implicit human biases, functioning both as a reflection and\na perpetuation of stereotypes that people carry with them. Recently, ML-based\nNLP methods such as word embeddings have been shown to learn such language\nbiases with striking accuracy. This capability of word embeddings has been\nsuccessfully exploited as a tool to quantify and study human biases. However,\nprevious studies only consider a predefined set of conceptual biases to attest\n(e.g., whether gender is more or less associated with particular jobs), or just\ndiscover biased words without helping to understand their meaning at the\nconceptual level. As such, these approaches are either unable to find\nconceptual biases that have not been defined in advance, or the biases they\nfind are difficult to interpret and study. This makes existing approaches\nunsuitable to discover and interpret biases in online communities, as such\ncommunities may carry different biases than those in mainstream culture. This\npaper proposes a general, data-driven approach to automatically discover and\nhelp interpret conceptual biases encoded in word embeddings. We apply this\napproach to study the conceptual biases present in the language used in online\ncommunities and experimentally show the validity and stability of our method.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 17:07:12 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Ferrer-Aran", "Xavier", ""], ["van Nuenen", "Tom", ""], ["Criado", "Natalia", ""], ["Such", "Jose M.", ""]]}, {"id": "2010.14608", "submitter": "Thomas Weighill", "authors": "Jonathan Rodden, Thomas Weighill", "title": "Political Geography and Representation: A Case Study of Districting in\n  Pennsylvania", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This preprint offers a detailed look, both qualitative and quantitative, at\ndistricting with respect to recent voting patterns in one state: Pennsylvania.\nWe investigate how much the partisan playing field is tilted by political\ngeography. In particular we closely examine the role of scale. We find that\npartisan-neutral maps rarely give seats proportional to votes, and that making\nthe district size smaller tends to make it even harder to find a proportional\nmap. This preprint was prepared as a chapter in the forthcoming edited volume\nPolitical Geometry, an interdisciplinary collection of essays on redistricting.\n(mggg.org/gerrybook)\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 21:01:10 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 17:17:55 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Rodden", "Jonathan", ""], ["Weighill", "Thomas", ""]]}, {"id": "2010.14624", "submitter": "Gourab K Patro", "authors": "Gourab K Patro, Abhijnan Chakraborty, Niloy Ganguly, Krishna P.\n  Gummadi", "title": "On Fair Virtual Conference Scheduling: Achieving Equitable Participant\n  and Speaker Satisfaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The (COVID-19) pandemic-induced restrictions on travel and social gatherings\nhave prompted most conference organizers to move their events online. However,\nin contrast to physical conferences, virtual conferences face a challenge in\nefficiently scheduling talks, accounting for the availability of participants\nfrom different time-zones as well as their interests in attending different\ntalks. In such settings, a natural objective for the conference organizers\nwould be to maximize some global welfare measure, such as the total expected\naudience participation across all talks. However, we show that optimizing for\nglobal welfare could result in a schedule that is unfair to the stakeholders,\ni.e., the individual utilities for participants and speakers can be highly\nunequal. To address the fairness concerns, we formally define fairness notions\nfor participants and speakers, and subsequently derive suitable fairness\nobjectives for them. We show that the welfare and fairness objectives can be in\nconflict with each other, and there is a need to maintain a balance between\nthese objective while caring for them simultaneously. Thus, we propose a joint\noptimization framework that allows conference organizers to design talk\nschedules that balance (i.e., allow trade-offs) between global welfare,\nparticipant fairness and the speaker fairness objectives. We show that the\noptimization problem can be solved using integer linear programming, and\nempirically evaluate the necessity and benefits of such joint optimization\napproach in virtual conference scheduling.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 15:05:12 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Patro", "Gourab K", ""], ["Chakraborty", "Abhijnan", ""], ["Ganguly", "Niloy", ""], ["Gummadi", "Krishna P.", ""]]}, {"id": "2010.14903", "submitter": "Giovanni De Toni", "authors": "Giovanni De Toni, Cristian Consonni, Alberto Montresor", "title": "A general method for estimating the prevalence of\n  Influenza-Like-Symptoms with Wikipedia data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Influenza is an acute respiratory seasonal disease that affects millions of\npeople worldwide and causes thousands of deaths in Europe alone. Being able to\nestimate in a fast and reliable way the impact of an illness on a given country\nis essential to plan and organize effective countermeasures, which is now\npossible by leveraging unconventional data sources like web searches and\nvisits. In this study, we show the feasibility of exploiting information about\nWikipedia's page views of a selected group of articles and machine learning\nmodels to obtain accurate estimates of influenza-like illnesses incidence in\nfour European countries: Italy, Germany, Belgium, and the Netherlands. We\npropose a novel language-agnostic method, based on two algorithms, Personalized\nPageRank and CycleRank, to automatically select the most relevant Wikipedia\npages to be monitored without the need for expert supervision. We then show how\nour model is able to reach state-of-the-art results by comparing it with\nprevious solutions.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 11:44:44 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["De Toni", "Giovanni", ""], ["Consonni", "Cristian", ""], ["Montresor", "Alberto", ""]]}, {"id": "2010.14972", "submitter": "Thomas Weighill", "authors": "Larry Guth, Ari Nieh, Thomas Weighill", "title": "Three Applications of Entropy to Gerrymandering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CY math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This preprint is an exploration in how a single mathematical idea - entropy -\ncan be applied to redistricting in a number of ways. It's meant to be read not\nso much as a call to action for entropy, but as a case study illustrating one\nof the many ways math can inform our thinking on redistricting problems. This\npreprint was prepared as a chapter in the forthcoming edited volume Political\nGeometry, an interdisciplinary collection of essays on redistricting.\n(mggg.org/gerrybook)\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 13:34:07 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 17:30:43 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Guth", "Larry", ""], ["Nieh", "Ari", ""], ["Weighill", "Thomas", ""]]}, {"id": "2010.15052", "submitter": "Ryan Steed", "authors": "Ryan Steed and Aylin Caliskan", "title": "Image Representations Learned With Unsupervised Pre-Training Contain\n  Human-like Biases", "comments": "10 pages, 3 figures. Replaced example image completions of real\n  people with completions of artificial people", "journal-ref": null, "doi": "10.1145/3442188.3445932", "report-no": null, "categories": "cs.CY cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent advances in machine learning leverage massive datasets of unlabeled\nimages from the web to learn general-purpose image representations for tasks\nfrom image classification to face recognition. But do unsupervised computer\nvision models automatically learn implicit patterns and embed social biases\nthat could have harmful downstream effects? We develop a novel method for\nquantifying biased associations between representations of social concepts and\nattributes in images. We find that state-of-the-art unsupervised models trained\non ImageNet, a popular benchmark image dataset curated from internet images,\nautomatically learn racial, gender, and intersectional biases. We replicate 8\npreviously documented human biases from social psychology, from the innocuous,\nas with insects and flowers, to the potentially harmful, as with race and\ngender. Our results closely match three hypotheses about intersectional bias\nfrom social psychology. For the first time in unsupervised computer vision, we\nalso quantify implicit human biases about weight, disabilities, and several\nethnicities. When compared with statistical patterns in online image datasets,\nour findings suggest that machine learning models can automatically learn bias\nfrom the way people are stereotypically portrayed on the web.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 15:55:49 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2021 20:51:57 GMT"}, {"version": "v3", "created": "Wed, 27 Jan 2021 18:48:10 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Steed", "Ryan", ""], ["Caliskan", "Aylin", ""]]}, {"id": "2010.15203", "submitter": "Yunhe Feng", "authors": "Yunhe Feng, Dong Zhong, Peng Sun, Weijian Zheng, Qinglei Cao, Xi Luo,\n  Zheng Lu", "title": "Micromobility in Smart Cities: A Closer Look at Shared Dockless\n  E-Scooters via Big Social Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The micromobility is shaping first- and last-mile travels in urban areas.\nRecently, shared dockless electric scooters (e-scooters) have emerged as a\ndaily alternative to driving for short-distance commuters in large cities due\nto the affordability, easy accessibility via an app, and zero emissions.\nMeanwhile, e-scooters come with challenges in city management, such as traffic\nrules, public safety, parking regulations, and liability issues. In this paper,\nwe collected and investigated 5.8 million scooter-tagged tweets and 144,197\nimages, generated by 2.7 million users from October 2018 to March 2020, to take\na closer look at shared e-scooters via crowdsourcing data analytics. We\nprofiled e-scooter usages from spatial-temporal perspectives, explored\ndifferent business roles (i.e., riders, gig workers, and ridesharing\ncompanies), examined operation patterns (e.g., injury types, and parking\nbehaviors), and conducted sentiment analysis. To our best knowledge, this paper\nis the first large-scale systematic study on shared e-scooters using big social\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 19:59:45 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Feng", "Yunhe", ""], ["Zhong", "Dong", ""], ["Sun", "Peng", ""], ["Zheng", "Weijian", ""], ["Cao", "Qinglei", ""], ["Luo", "Xi", ""], ["Lu", "Zheng", ""]]}, {"id": "2010.15217", "submitter": "Noah Goodall", "authors": "Noah J. Goodall", "title": "Away from Trolley Problems and Toward Risk Management", "comments": "11 pages, 1 figure", "journal-ref": "Applied Artificial Intelligence 30(8), pp. 810-821 (2016)", "doi": "10.1080/08839514.2016.1229922", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As automated vehicles receive more attention from the media, there has been\nan equivalent increase in the coverage of the ethical choices a vehicle may be\nforced to make in certain crash situations with no clear safe outcome. Much of\nthis coverage has focused on a philosophical thought experiment known as the\n\"trolley problem,\" and substituting an automated vehicle for the trolley and\nthe car's software for the bystander. While this is a stark and straightforward\nexample of ethical decision making for an automated vehicle, it risks\nmarginalizing the entire field if it is to become the only ethical problem in\nthe public's mind. In this chapter, I discuss the shortcomings of the trolley\nproblem, and introduce more nuanced examples that involve crash risk and\nuncertainty. Risk management is introduced as an alternative approach, and its\nethical dimensions are discussed.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 20:27:50 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Goodall", "Noah J.", ""]]}, {"id": "2010.15300", "submitter": "Emaad Manzoor", "authors": "Emaad Manzoor, Nihar B. Shah", "title": "Uncovering Latent Biases in Text: Method and Application to Peer Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantifying systematic disparities in numerical quantities such as employment\nrates and wages between population subgroups provides compelling evidence for\nthe existence of societal biases. However, biases in the text written for\nmembers of different subgroups (such as in recommendation letters for male and\nnon-male candidates), though widely reported anecdotally, remain challenging to\nquantify. In this work, we introduce a novel framework to quantify bias in text\ncaused by the visibility of subgroup membership indicators. We develop a\nnonparametric estimation and inference procedure to estimate this bias. We then\nformalize an identification strategy to causally link the estimated bias to the\nvisibility of subgroup membership indicators, provided observations from time\nperiods both before and after an identity-hiding policy change. We identify an\napplication wherein \"ground truth\" bias can be inferred to evaluate our\nframework, instead of relying on synthetic or secondary data. Specifically, we\napply our framework to quantify biases in the text of peer reviews from a\nreputed machine learning conference before and after the conference adopted a\ndouble-blind reviewing policy. We show evidence of biases in the review ratings\nthat serves as \"ground truth\", and show that our proposed framework accurately\ndetects these biases from the review text without having access to the review\nratings.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 01:24:19 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Manzoor", "Emaad", ""], ["Shah", "Nihar B.", ""]]}, {"id": "2010.15346", "submitter": "Mohammad Ali", "authors": "Mohammad Ali", "title": "Developing Augmented Reality based Gaming Model to Teach Ethical\n  Education in Primary Schools", "comments": "4 Pages, 3 Figures, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Education sector is adopting new technologies for both teaching and learning\npedagogy. Augmented Reality (AR) is a new technology that can be used in the\neducational pedagogy to enhance the engagement with students. Students interact\nwith AR-based educational material for more visualization and explanation.\nTherefore, the use of AR in education is becoming more popular. However, most\nresearches narrate the use of AR technologies in the field of English, Maths,\nScience, Culture, Arts, and History education but the absence of ethical\neducation is visible. In our paper, we design the system and develop an\nAR-based mobile game model in the field of Ethical education for pre-primary\nstudents. Students from pre-primary require more interactive lessons than\ntheoretical concepts. So, we use AR technology to develop a game which offers\ninteractive procedures where students can learn with fun and engage with the\ncontext. Finally, we develop a prototype that works with our research\nobjective. We conclude our paper with future works.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 04:01:32 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Ali", "Mohammad", ""]]}, {"id": "2010.15577", "submitter": "Tetiana Vakaliuk", "authors": "Iryna S. Mintii, Svitlana V. Shokaliuk, Tetiana A. Vakaliuk, Mykhailo\n  M. Mintii, Vladimir N. Soloviev", "title": "Import test questions into Moodle LMS", "comments": null, "journal-ref": "Proceedings of the 6th Workshop on Cloud Technologies in Education\n  (CTE 2018), Kryvyi Rih, Ukraine, December 21, 2018. CEUR-WS.org, online\n  http://ceur-ws.org/Vol-2433/paper36.pdf", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of the study is to highlight the theoretical and methodological\naspects of preparing the test questions of the most common types in the form of\ntext files for further import into learning management system (LMS) Moodle. The\nsubject of the research is the automated filling of the Moodle LMS test\ndatabase. The objectives of the study: to analyze the import files of test\nquestions, their advantages and disadvantages; to develop guidelines for the\npreparation of test questions of common types in the form of text files for\nfurther import into Moodle LMS. The action algorithms for importing questions\nand instructions for submitting question files in such formats as Aiken, GIFT,\nMoodle XML, \"True/False\" questions, \"Multiple Choice\" (one of many and many of\nmany), \"Matching\", with an open answer - \"Numerical\" or \"Short answer\" and\n\"Essay\" are offered in this article. The formats for submitting questions,\nexamples of its designing and developed questions were demonstrated in view\nmode in Moodle LMS.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 09:39:45 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Mintii", "Iryna S.", ""], ["Shokaliuk", "Svitlana V.", ""], ["Vakaliuk", "Tetiana A.", ""], ["Mintii", "Mykhailo M.", ""], ["Soloviev", "Vladimir N.", ""]]}, {"id": "2010.15578", "submitter": "Niya Stoimenova", "authors": "Niya Stoimenova, Rebecca Price", "title": "Exploring the Nuances of Designing (with/for) Artificial Intelligence", "comments": null, "journal-ref": "Design Issues, 36(4), 45-55 (2020)", "doi": "10.1162/desi_a_00613", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Solutions relying on artificial intelligence are devised to predict data\npatterns and answer questions that are clearly defined, involve an enumerable\nset of solutions, clear rules, and inherently binary decision mechanisms. Yet,\nas they become exponentially implemented in our daily activities, they begin to\ntranscend these initial boundaries and to affect the larger sociotechnical\nsystem in which they are situated. In this arrangement, a solution is under\npressure to surpass true or false criteria and move to an ethical evaluation of\nright and wrong. Neither algorithmic solutions, nor purely humanistic ones will\nbe enough to fully mitigate undesirable outcomes in the narrow state of AI or\nits future incarnations. We must take a holistic view. In this paper we explore\nthe construct of infrastructure as a means to simultaneously address\nalgorithmic and societal issues when designing AI.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 20:34:35 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Stoimenova", "Niya", ""], ["Price", "Rebecca", ""]]}, {"id": "2010.15581", "submitter": "Nuruddin Ahmed Ahmed", "authors": "Nur Ahmed, Muntasir Wahed", "title": "The De-democratization of AI: Deep Learning and the Compute Divide in\n  Artificial Intelligence Research", "comments": "52 pages,13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Increasingly, modern Artificial Intelligence (AI) research has become more\ncomputationally intensive. However, a growing concern is that due to unequal\naccess to computing power, only certain firms and elite universities have\nadvantages in modern AI research. Using a novel dataset of 171394 papers from\n57 prestigious computer science conferences, we document that firms, in\nparticular, large technology firms and elite universities have increased\nparticipation in major AI conferences since deep learning's unanticipated rise\nin 2012. The effect is concentrated among elite universities, which are ranked\n1-50 in the QS World University Rankings. Further, we find two strategies\nthrough which firms increased their presence in AI research: first, they have\nincreased firm-only publications; and second, firms are collaborating primarily\nwith elite universities. Consequently, this increased presence of firms and\nelite universities in AI research has crowded out mid-tier (QS ranked 201-300)\nand lower-tier (QS ranked 301-500) universities. To provide causal evidence\nthat deep learning's unanticipated rise resulted in this divergence, we\nleverage the generalized synthetic control method, a data-driven counterfactual\nestimator. Using machine learning based text analysis methods, we provide\nadditional evidence that the divergence between these two groups - large firms\nand non-elite universities - is driven by access to computing power or compute,\nwhich we term as the \"compute divide\". This compute divide between large firms\nand non-elite universities increases concerns around bias and fairness within\nAI technology, and presents an obstacle towards \"democratizing\" AI. These\nresults suggest that a lack of access to specialized equipment such as compute\ncan de-democratize knowledge production.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 15:11:14 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Ahmed", "Nur", ""], ["Wahed", "Muntasir", ""]]}, {"id": "2010.15584", "submitter": "Xiaosong Li", "authors": "Ritu Arora (1), Xiaosong Li (2), Bonnie Hurwitz (3), Daniel Fay (4),\n  Dhabaleswar K. Panda (5), Edward Valeev (6), Shaowen Wang (7), Shirley Moore\n  (8), Sunita Chandrasekaran (9), Ting Cao (2), Holly Bik (10), Matthew Curry\n  (11), Tanzima Islam (12) ((1) Texas Advanced Computing Center, (2) University\n  of Washington, (3) University of Arizona, (4) Microsoft, (5) The Ohio State\n  University, (6) Virginia Tech University, (7) University of Illinois, (8) Oak\n  Ridge National Lab, (9) University of Delaware, (10) University of\n  California, Riverside, (11) Sandia National Lab, (12) Texas State University)", "title": "Future Directions of the Cyberinfrastructure for Sustained Scientific\n  Innovation (CSSI) Program", "comments": "This report was submitted in April 2020 to the National Science\n  Foundation (NSF)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The CSSI 2019 workshop was held on October 28-29, 2019, in Austin, Texas. The\nmain objectives of this workshop were to (1) understand the impact of the CSSI\nprogram on the community over the last 9 years, (2) engage workshop\nparticipants in identifying gaps and opportunities in the current CSSI\nlandscape, (3) gather ideas on the cyberinfrastructure needs and expectations\nof the community with respect to the CSSI program, and (4) prepare a report\nsummarizing the feedback gathered from the community that can inform the future\nsolicitations of the CSSI program. The workshop brought together different\nstakeholders interested in provisioning sustainable cyberinfrastructure that\ncan power discoveries impacting the various fields of science and technology\nand maintaining the nation's competitiveness in the areas such as scientific\nsoftware, HPC, networking, cybersecurity, and data/information science. The\nworkshop served as a venue for gathering the community-feedback on the current\nstate of the CSSI program and its future directions.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 19:41:04 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Arora", "Ritu", ""], ["Li", "Xiaosong", ""], ["Hurwitz", "Bonnie", ""], ["Fay", "Daniel", ""], ["Panda", "Dhabaleswar K.", ""], ["Valeev", "Edward", ""], ["Wang", "Shaowen", ""], ["Moore", "Shirley", ""], ["Chandrasekaran", "Sunita", ""], ["Cao", "Ting", ""], ["Bik", "Holly", ""], ["Curry", "Matthew", ""], ["Islam", "Tanzima", ""]]}, {"id": "2010.15585", "submitter": "Feras Batarseh", "authors": "Feras A. Batarseh and Munisamy Gopinath", "title": "Panel: Economic Policy and Governance during Pandemics using AI", "comments": "Presented at AAAI FSS-20: Artificial Intelligence in Government and\n  Public Sector (virtual)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The global food supply chain (starting at farms and ending with consumers)\nhas been seriously disrupted by many outlier events such as trade wars, the\nChina demand shock, natural disasters, and pandemics. Outlier events create\nuncertainty along the entire supply chain in addition to intervening policy\nresponses to mitigate their adverse effects. Artificial Intelligence (AI)\nmethods (i.e. machine/reinforcement/deep learning) provide an opportunity to\nbetter understand outcomes during outlier events by identifying regular,\nirregular and contextual components. Employing AI can provide guidance to\ndecision making suppliers, farmers, processors, wholesalers, and retailers\nalong the supply chain, and policy makers to facilitate welfare-improving\noutcomes. This panel discusses these issues.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 22:09:59 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Batarseh", "Feras A.", ""], ["Gopinath", "Munisamy", ""]]}, {"id": "2010.15588", "submitter": "Carlos Medel-Ram\\'irez", "authors": "Carlos Medel-Ramirez, Hilario Medel-Lopez", "title": "Impact of (SARS-CoV-2) COVID 19 on the indigenous language-speaking\n  population in Mexico", "comments": "20 pages, 1 figure, 2 maps", "journal-ref": null, "doi": "10.13140/RG.2.2.12730.82887/2", "report-no": null, "categories": "cs.CY stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The importance of the working document is that it allows the analysis of the\ninformation and the status of cases associated with (SARS-CoV-2) COVID-19 as\nopen data at the municipal, state and national level, with a daily record of\npatients, according to a age, sex, comorbidities, for the condition of\n(SARS-CoV-2) COVID-19 according to the following characteristics: a) Positive,\nb) Negative, c) Suspicious. Likewise, it presents information related to the\nidentification of an outpatient and / or hospitalized patient, attending to\ntheir medical development, identifying: a) Recovered, b) Deaths and c) Active,\nin Phase 3 and Phase 4, in the five main population areas speaker of indigenous\nlanguage in the State of Veracruz - Mexico. The data analysis is carried out\nthrough the application of a data mining algorithm, which provides the\ninformation, fast and timely, required for the estimation of Medical Care\nScenarios of (SARS-CoV-2) COVID-19, as well as for know the impact on the\nindigenous language-speaking population in Mexico.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 05:24:53 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Medel-Ramirez", "Carlos", ""], ["Medel-Lopez", "Hilario", ""]]}, {"id": "2010.15590", "submitter": "Fabrice Muhlenbach", "authors": "Fabrice Muhlenbach", "title": "Enjeux \\'ethiques de l'IA en sant\\'e : une humanisation du parcours de\n  soin par l'intelligence artificielle ?", "comments": "Preprint of a paper to appear in \"Soins Cadres\" journal, in French", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Considering the use of artificial intelligence for greater personalization of\npatient care and better management of human and material resources may seem\nlike an opportunity not to be missed. In order to offer a better humanization\nof the care pathway, artificial intelligence is a tool that decision-makers in\nthe hospital sector must appropriate by taking care of the new ethical issues\nand conflicts of values that this technology generates.\n  Envisager le recours \\`a l'intelligence artificielle pour une plus grande\npersonnalisation de la prise en charge du patient et une meilleure gestion des\nressources humaines et mat\\'erielles peut sembler une opportunit\\'e \\`a ne pas\nmanquer. Afin de proposer une meilleure humanisation du parcours de soin,\nl'intelligence artificielle est un outil que les d\\'ecideurs du milieu\nhospitalier doivent s'approprier en veillant aux nouveaux enjeux \\'ethiques et\nconflits de valeurs que cette technologie engendre.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 20:34:19 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Muhlenbach", "Fabrice", ""]]}, {"id": "2010.15601", "submitter": "Joseph Esquivel Esquivel", "authors": "Dr.Joseph A. Esquivel and Dr. James A. Esquivel", "title": "Using a Binary Classification Model to Predict the Likelihood of\n  Enrolment to the Undergraduate Program of a Philippine University", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent implementation of the K to 12 Program, academic institutions,\nspecifically, Colleges and Universities in the Philippines have been faced with\ndifficulties in determining projected freshmen enrollees vis-a-vis\ndecision-making factors for efficient resource management. Enrollment targets\ndirectly impacts success factors of Higher Education Institutions. This study\ncovered an analysis of various characteristics of freshmen applicants affecting\ntheir admission status in a Philippine university. A predictive model was\ndeveloped using Logistic Regression to evaluate the probability that an\nadmitted student will pursue to enroll in the Institution or not. The dataset\nused was acquired from the University Admissions Office. The office designed an\nonline application form to capture applicants' details. The online form was\ndistributed to all student applicants, and most often, students, tend to\nprovide incomplete information. Despite this fact, student characteristics, as\nwell as geographic and demographic data based on the students' location are\nsignificant predictors of enrollment decision. The results of the study show\nthat given limited information about prospective students, Higher Education\nInstitutions can implement machine learning techniques to supplement management\ndecisions and provide estimates of class sizes, in this way, it will allow the\ninstitution to optimize the allocation of resources and will have better\ncontrol over net tuition revenue.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 06:58:03 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Esquivel", "Dr. Joseph A.", ""], ["Esquivel", "Dr. James A.", ""]]}, {"id": "2010.15602", "submitter": "Junhua Liu", "authors": "Nachamma Sockalingam and Junhua Liu", "title": "Designing learning experiences for online teaching and learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Teaching is about constantly innovating strategies, ways and means to engage\ndiverse students in active and meaningful learning. In line with this, SUTD\nadopts various student-centric teaching and learning teaching methods and\napproaches. This means that our graduate/undergraduate instructors have to be\nready to teach using these student student-centric teaching and learning\npedagogies. In this article, I share my experiences of redesigning this\nteaching course that is typically conducted face-to-face to a synchronous\nonline course and also invite one of the participant in this course to reflect\non his experience as a student.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 07:03:49 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Sockalingam", "Nachamma", ""], ["Liu", "Junhua", ""]]}, {"id": "2010.15606", "submitter": "Unnikrishnan Menon", "authors": "Unnikrishnan Menon and Divyani Panda", "title": "Design and Evaluation of Electric Bus Systems for Metropolitan Cities", "comments": "8 pages, 5 figures, 3 tables", "journal-ref": "SSRG International Journal of Mechanical Engineering 7(10), 16-23\n  (2020)", "doi": "10.14445/23488360/IJME-V7I10P104", "report-no": "IJME-V7I10P104", "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decade, most of the metropolitan cities across the world have\nbeen witnessing a degrading trend in air quality index. Exhaust emission data\nobservations show that promotion of public transport could be a potential way\nout of this gridlock. Due to environmental concerns, numerous public transport\nauthorities harbor a great interest in introducing zero emission electric\nbuses. A shift from conventional diesel buses to electric buses comes with\nseveral benefits in terms of reduction in local pollution, noise, and fuel\nconsumption. This paper proposes the relevant vehicle technologies, powertrain,\nand charging systems, which, in combination, provides a comprehensive\nmethodology to design an Electric Bus that can be deployed in metropolitan\ncities to mitigate emission concerns.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 12:49:35 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Menon", "Unnikrishnan", ""], ["Panda", "Divyani", ""]]}, {"id": "2010.15607", "submitter": "Rizwan Ali", "authors": "Prazwal Chhabra, Rizwan Ali, Vikram Pudi", "title": "CRICTRS: Embeddings based Statistical and Semi Supervised Cricket Team\n  Recommendation System", "comments": "11 pages, 5 figures", "journal-ref": "International Conference on Machine Learning Techniques and NLP\n  (MLNLP 2020), October 24-25, 2020, Sydney, Australia", "doi": "10.5121/csit.2020.101207", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Team Recommendation has always been a challenging aspect in team sports. Such\nsystems aim to recommend a player combination best suited against the\nopposition players, resulting in an optimal outcome. In this paper, we propose\na semi-supervised statistical approach to build a team recommendation system\nfor cricket by modelling players into embeddings. To build these embeddings, we\ndesign a qualitative and quantitative rating system which considers the\nstrength of opposition also for evaluating player performance. The embeddings\nobtained, describes the strengths and weaknesses of the players based on past\nperformances of the player. We also embark on a critical aspect of team\ncomposition, which includes the number of batsmen and bowlers in the team. The\nteam composition changes over time, depending on different factors which are\ntough to predict, so we take this input from the user and use the player\nembeddings to decide the best possible team combination with the given team\ncomposition.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 15:35:44 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Chhabra", "Prazwal", ""], ["Ali", "Rizwan", ""], ["Pudi", "Vikram", ""]]}, {"id": "2010.15665", "submitter": "Noah Goodall", "authors": "Noah J. Goodall", "title": "Machine Ethics and Automated Vehicles", "comments": "12 pages", "journal-ref": "In: Meyer G., Beiker S. (eds) Road Vehicle Automation. Lecture\n  Notes in Mobility. Springer, Cham (2014)", "doi": "10.1007/978-3-319-05990-7_9", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Road vehicle travel at a reasonable speed involves some risk, even when using\ncomputer-controlled driving with failure-free hardware and perfect sensing. A\nfully-automated vehicle must continuously decide how to allocate this risk\nwithout a human driver's oversight. These are ethical decisions, particularly\nin instances where an automated vehicle cannot avoid crashing. In this chapter,\nI introduce the concept of moral behavior for an automated vehicle, argue the\nneed for research in this area through responses to anticipated critiques, and\ndiscuss relevant applications from machine ethics and moral modeling research.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 15:14:47 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Goodall", "Noah J.", ""]]}, {"id": "2010.15668", "submitter": "Arjun Anand V", "authors": "Arjun Anand V, Buvanasri A K, Meenakshi R, Dr. Karthika S, Ashok Kumar\n  Mohan", "title": "PeopleXploit -- A hybrid tool to collect public data", "comments": "8 pages, 3 images, ICCCSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the concept of Open Source Intelligence (OSINT) as an\nimportant application in intelligent profiling of individuals. With a variety\nof tools available, significant data shall be obtained on an individual as a\nconsequence of analyzing his/her internet presence but all of this comes at the\ncost of low relevance. To increase the relevance score in profiling,\nPeopleXploit is being introduced. PeopleXploit is a hybrid tool which helps in\ncollecting the publicly available information that is reliable and relevant to\nthe given input. This tool is used to track and trace the given target with\ntheir digital footprints like Name, Email, Phone Number, User IDs etc. and the\ntool will scan & search other associated data from public available records\nfrom the internet and create a summary report against the target. PeopleXploit\nprofiles a person using authorship analysis and finds the best matching guess.\nAlso, the type of analysis performed (professional/matrimonial/criminal entity)\nvaries with the requirement of the user.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 07:08:52 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Anand", "Arjun", "V"], ["K", "Buvanasri A", ""], ["R", "Meenakshi", ""], ["S", "Dr. Karthika", ""], ["Mohan", "Ashok Kumar", ""]]}, {"id": "2010.15669", "submitter": "Parth Shisode", "authors": "Parth Shisode", "title": "Using Twitter to Analyze Political Polarization During National Crises", "comments": "9 pages, 2 graphs, 2 equations, NIPS 2015 styling used as format\n  guidelines", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Democrats and Republicans have seemed to grow apart in the past three\ndecades. Since the United States as we know it today is undeniably bipartisan,\nthis phenomenon would not appear as a surprise to most. However, there are\ntriggers which can cause spikes in disagreements between Democrats and\nRepublicans at a higher rate than how the two parties have been growing apart\ngradually over time. This study has analyzed the idea that national events\nwhich generally are detrimental to all individuals can be one of those\ntriggers. By testing polarization before and after three events (Hurricane\nSandy [2012], N. Korea Missile Test Surge [2019], COVID-19 [2020]) using\nTwitter data, we show that a measurable spike in polarization occurs between\nthe Democrat and Republican party. In order to measure polarization, sentiments\nof Twitter users aligned to the Democrat and Republican parties are compared on\nidentical entities (events, people, locations, etc.). Using hundreds of\nthousands of data samples, a 2.8% increase in polarization was measured during\ntimes of crisis compared to times where no crises were occurring. Regardless of\nthe reasoning that the gap between political parties can increase so much\nduring times of suffering and stress, it is definitely alarming to see that\namong other aspects of life, the partisan gap worsens during detrimental\nnational events.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 04:46:42 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Shisode", "Parth", ""]]}, {"id": "2010.15670", "submitter": "Boyu Zhang", "authors": "Boyu Zhang, Anis Zaman, Rupam Acharyya, Ehsan Hoque, Vincent Silenzio,\n  Henry Kautz", "title": "Detecting Individuals with Depressive Disorder fromPersonal Google\n  Search and YouTube History Logs", "comments": "Machine Learning in Public Health (MLPH) at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Depressive disorder is one of the most prevalent mental illnesses among the\nglobal population. However, traditional screening methods require exacting\nin-person interviews and may fail to provide immediate interventions. In this\nwork, we leverage ubiquitous personal longitudinal Google Search and YouTube\nengagement logs to detect individuals with depressive disorder. We collected\nGoogle Search and YouTube history data and clinical depression evaluation\nresults from $212$ participants ($99$ of them suffered from moderate to severe\ndepressions). We then propose a personalized framework for classifying\nindividuals with and without depression symptoms based on mutual-exciting point\nprocess that captures both the temporal and semantic aspects of online\nactivities. Our best model achieved an average F1 score of $0.77 \\pm 0.04$ and\nan AUC ROC of $0.81 \\pm 0.02$.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 04:40:18 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Zhang", "Boyu", ""], ["Zaman", "Anis", ""], ["Acharyya", "Rupam", ""], ["Hoque", "Ehsan", ""], ["Silenzio", "Vincent", ""], ["Kautz", "Henry", ""]]}, {"id": "2010.15673", "submitter": "Bilal Farooq", "authors": "Nael Alsaleh and Bilal Farooq", "title": "Machine Learning Based Demand Modelling for On-Demand Transit Services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, with the advancements in information and communication\ntechnology, different emerging on-demand shared mobility services have been\nintroduced as innovative solutions in the low-density areas, including\non-demand transit (ODT), mobility-on-demand (MOD) transit, and crowdsourced\nmobility services. However, due to their infancy, there is a strong need to\nunderstand and model the demand for these services. In this study, we developed\ntrip production and distribution models for ODT services at Dissemination Areas\n(DA) level using four machine learning algorithms: Random Forest (RF), Bagging,\nArtificial Neural Network (ANN) and Deep Neural Network (DNN). The data used in\nthe modelling process were acquired from Belleville's ODT operational data and\n2016 census data. Bayesian optimalization approach was used to find the optimal\narchitecture of the adopted algorithms. Moreover, post-hoc model analysis was\nemployed to interpret the predictions and examine the importance of the\nexplanatory variables. The results showed that the land-use type was the most\nimportant variable in the trip production model. On the other hand, the\ndemographic characteristics of the trip destination were the most important\nvariables in the trip distribution model. Moreover, the results revealed that\nhigher trip distribution levels are expected between dissemination areas with\ncommercial/industrial land-use type and dissemination areas with high-density\nresidential land-use. Our findings suggest that the performance of ODT services\ncan be further enhanced by (a) locating idle vehicles in the neighbourhoods\nwith commercial/industrial land-use and (b) using the spatio-temporal demand\nmodels obtained in this work to continuously update the operating fleet size.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 20:48:10 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 15:22:43 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Alsaleh", "Nael", ""], ["Farooq", "Bilal", ""]]}, {"id": "2010.15922", "submitter": "Alessandro Pluchino", "authors": "R. R. Corsini, A. Costa, S. Fichera, A.Pluchino", "title": "A configurable agent-based simulation model for reducing patients'\n  waiting time in oncology departments", "comments": "39 pages, 3 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, the increase of demand and the progressive decrease of resources\nare causing higher patients' waiting time in many chemotherapy oncology\ndepartments. Therefore, enhancing the quality of health services is needed so\nas to avoid claims and disappointments. To this end, reducing the patients'\nwaiting times in the oncology units represents one of the main goals of any\nhealthcare manager. Simulation models are considered an effective tool for\nidentifying potential ways to improve the patient flow in an oncology unit.\nThis paper presents a new agent-based simulation model properly designed to be\nconfigurable and adaptable to the needs of the oncology departments that have\nto interact with an external pharmacy. In these cases, a courier service is\nneeded to deliver the therapies, collected in several batches, from the\npharmacy to the oncology department. A real oncology unit was studied through\nthe agent-based simulation and alternative scenarios were compared with the aim\nof selecting the ward configuration capable of reducing the patients' waiting\ntime.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 20:11:41 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 12:05:25 GMT"}, {"version": "v3", "created": "Fri, 4 Jun 2021 12:38:11 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Corsini", "R. R.", ""], ["Costa", "A.", ""], ["Fichera", "S.", ""], ["Pluchino", "A.", ""]]}, {"id": "2010.15939", "submitter": "Ekaterina Artemova", "authors": "Vitaly Ivanin and Ekaterina Artemova and Tatiana Batura and Vladimir\n  Ivanov and Veronika Sarkisyan and Elena Tutubalina and Ivan Smurov", "title": "RuREBus: a Case Study of Joint Named Entity Recognition and Relation\n  Extraction from e-Government Domain", "comments": "to appear in AIST 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show-case an application of information extraction methods, such as named\nentity recognition (NER) and relation extraction (RE) to a novel corpus,\nconsisting of documents, issued by a state agency. The main challenges of this\ncorpus are: 1) the annotation scheme differs greatly from the one used for the\ngeneral domain corpora, and 2) the documents are written in a language other\nthan English. Unlike expectations, the state-of-the-art transformer-based\nmodels show modest performance for both tasks, either when approached\nsequentially, or in an end-to-end fashion. Our experiments have demonstrated\nthat fine-tuning on a large unlabeled corpora does not automatically yield\nsignificant improvement and thus we may conclude that more sophisticated\nstrategies of leveraging unlabelled texts are demanded. In this paper, we\ndescribe the whole developed pipeline, starting from text annotation, baseline\ndevelopment, and designing a shared task in hopes of improving the baseline.\nEventually, we realize that the current NER and RE technologies are far from\nbeing mature and do not overcome so far challenges like ours.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 20:56:15 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Ivanin", "Vitaly", ""], ["Artemova", "Ekaterina", ""], ["Batura", "Tatiana", ""], ["Ivanov", "Vladimir", ""], ["Sarkisyan", "Veronika", ""], ["Tutubalina", "Elena", ""], ["Smurov", "Ivan", ""]]}, {"id": "2010.16004", "submitter": "Martin Weiss", "authors": "Prateek Gupta, Tegan Maharaj, Martin Weiss, Nasim Rahaman, Hannah\n  Alsdurf, Abhinav Sharma, Nanor Minoyan, Soren Harnois-Leblanc, Victor\n  Schmidt, Pierre-Luc St. Charles, Tristan Deleu, Andrew Williams, Akshay\n  Patel, Meng Qu, Olexa Bilaniuk, Ga\\'etan Marceau Caron, Pierre Luc Carrier,\n  Satya Ortiz-Gagn\\'e, Marc-Andre Rousseau, David Buckeridge, Joumana Ghosn,\n  Yang Zhang, Bernhard Sch\\\"olkopf, Jian Tang, Irina Rish, Christopher Pal,\n  Joanna Merckx, Eilif B. Muller, Yoshua Bengio", "title": "COVI-AgentSim: an Agent-based Model for Evaluating Methods of Digital\n  Contact Tracing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid global spread of COVID-19 has led to an unprecedented demand for\neffective methods to mitigate the spread of the disease, and various digital\ncontact tracing (DCT) methods have emerged as a component of the solution. In\norder to make informed public health choices, there is a need for tools which\nallow evaluation and comparison of DCT methods. We introduce an agent-based\ncompartmental simulator we call COVI-AgentSim, integrating detailed\nconsideration of virology, disease progression, social contact networks, and\nmobility patterns, based on parameters derived from empirical research. We\nverify by comparing to real data that COVI-AgentSim is able to reproduce\nrealistic COVID-19 spread dynamics, and perform a sensitivity analysis to\nverify that the relative performance of contact tracing methods are consistent\nacross a range of settings. We use COVI-AgentSim to perform cost-benefit\nanalyses comparing no DCT to: 1) standard binary contact tracing (BCT) that\nassigns binary recommendations based on binary test results; and 2) a\nrule-based method for feature-based contact tracing (FCT) that assigns a graded\nlevel of recommendation based on diverse individual features. We find all DCT\nmethods consistently reduce the spread of the disease, and that the advantage\nof FCT over BCT is maintained over a wide range of adoption rates.\nFeature-based methods of contact tracing avert more disability-adjusted life\nyears (DALYs) per socioeconomic cost (measured by productive hours lost). Our\nresults suggest any DCT method can help save lives, support re-opening of\neconomies, and prevent second-wave outbreaks, and that FCT methods are a\npromising direction for enriching BCT using self-reported symptoms, yielding\nearlier warning signals and a significantly reduced spread of the virus per\nsocioeconomic cost.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 00:47:01 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Gupta", "Prateek", ""], ["Maharaj", "Tegan", ""], ["Weiss", "Martin", ""], ["Rahaman", "Nasim", ""], ["Alsdurf", "Hannah", ""], ["Sharma", "Abhinav", ""], ["Minoyan", "Nanor", ""], ["Harnois-Leblanc", "Soren", ""], ["Schmidt", "Victor", ""], ["Charles", "Pierre-Luc St.", ""], ["Deleu", "Tristan", ""], ["Williams", "Andrew", ""], ["Patel", "Akshay", ""], ["Qu", "Meng", ""], ["Bilaniuk", "Olexa", ""], ["Caron", "Ga\u00e9tan Marceau", ""], ["Carrier", "Pierre Luc", ""], ["Ortiz-Gagn\u00e9", "Satya", ""], ["Rousseau", "Marc-Andre", ""], ["Buckeridge", "David", ""], ["Ghosn", "Joumana", ""], ["Zhang", "Yang", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Tang", "Jian", ""], ["Rish", "Irina", ""], ["Pal", "Christopher", ""], ["Merckx", "Joanna", ""], ["Muller", "Eilif B.", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2010.16309", "submitter": "Noah Goodall", "authors": "Noah Goodall", "title": "Ethical Decision Making During Automated Vehicle Crashes", "comments": "15 pages, 1 figure, 2 tables", "journal-ref": "Transportation Research Record: Journal of the Transportation\n  Research Board, No. 2424, 2014, pp. 58-65", "doi": "10.3141/2424-07", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automated vehicles have received much attention recently, particularly the\nDARPA Urban Challenge vehicles, Google's self-driving cars, and various others\nfrom auto manufacturers. These vehicles have the potential to significantly\nreduce crashes and improve roadway efficiency by automating the\nresponsibilities of the driver. Still, automated vehicles are expected to crash\noccasionally, even when all sensors, vehicle control components, and algorithms\nfunction perfectly. If a human driver is unable to take control in time, a\ncomputer will be responsible for pre-crash behavior. Unlike other automated\nvehicles--such as aircraft, where every collision is catastrophic, and guided\ntrack systems, which can only avoid collisions in one dimension--automated\nroadway vehicles can predict various crash trajectory alternatives and select a\npath with the lowest damage or likelihood of collision. In some situations, the\npreferred path may be ambiguous. This study investigates automated vehicle\ncrashing and concludes the following: (1) automated vehicles will almost\ncertainly crash, (2) an automated vehicle's decisions preceding certain crashes\nwill have a moral component, and (3) there is no obvious way to effectively\nencode complex human morals in software. A three-phase approach to developing\nethical crashing algorithms is presented, consisting of a rational approach, an\nartificial intelligence approach, and a natural language requirement. The\nphases are theoretical and should be implemented as the technology becomes\navailable.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 14:58:17 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Goodall", "Noah", ""]]}, {"id": "2010.16409", "submitter": "Yuzi He", "authors": "Yuzi He, Keith Burghardt, Siyi Guo, Kristina Lerman", "title": "Inherent Trade-offs in the Fair Allocation of Treatments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explicit and implicit bias clouds human judgement, leading to discriminatory\ntreatment of minority groups. A fundamental goal of algorithmic fairness is to\navoid the pitfalls in human judgement by learning policies that improve the\noverall outcomes while providing fair treatment to protected classes. In this\npaper, we propose a causal framework that learns optimal intervention policies\nfrom data subject to fairness constraints. We define two measures of treatment\nbias and infer best treatment assignment that minimizes the bias while\noptimizing overall outcome. We demonstrate that there is a dilemma of balancing\nfairness and overall benefit; however, allowing preferential treatment to\nprotected classes in certain circumstances (affirmative action) can\ndramatically improve the overall benefit while also preserving fairness. We\napply our framework to data containing student outcomes on standardized tests\nand show how it can be used to design real-world policies that fairly improve\nstudent test scores. Our framework provides a principled way to learn fair\ntreatment policies in real-world settings.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 17:55:00 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["He", "Yuzi", ""], ["Burghardt", "Keith", ""], ["Guo", "Siyi", ""], ["Lerman", "Kristina", ""]]}]