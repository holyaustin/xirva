[{"id": "1910.00312", "submitter": "Christof Paar", "authors": "Carina Wiesen and Steffen Becker and Marc Fyrbiak and Nils Albartus\n  and Malte Elson and Nikol Rummel and Christof Paar", "title": "Teaching Hardware Reverse Engineering: Educational Guidelines and\n  Practical Insights", "comments": null, "journal-ref": "2018 IEEE International Conference on Teaching, Assessment, and\n  Learning for Engineering (TALE)", "doi": "10.1109/TALE.2018.8615270", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since underlying hardware components form the basis of trust in virtually any\ncomputing system, security failures in hardware pose a devastating threat to\nour daily lives. Hardware reverse engineering is commonly employed by security\nengineers in order to identify security vulnerabilities, to detect IP\nviolations, or to conduct very-large-scale integration (VLSI) failure analysis.\nEven though industry and the scientific community demand experts with expertise\nin hardware reverse engineering, there is a lack of educational offerings, and\nexisting training is almost entirely unstructured and on the job. To the best\nof our knowledge, we have developed the first course to systematically teach\nstudents hardware reverse engineering based on insights from the fields of\neducational research, cognitive science, and hardware security. The\ncontribution of our work is threefold: (1) we propose underlying educational\nguidelines for practice-oriented courses which teach hardware reverse\nengineering; (2) we develop such a lab course with a special focus on\ngate-level netlist reverse engineering and provide the required tools to\nsupport it; (3) we conduct an educational evaluation of our pilot course. Based\non our results, we provide valuable insights on the structure and content\nnecessary to design and teach future courses on hardware reverse engineering.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 11:38:27 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Wiesen", "Carina", ""], ["Becker", "Steffen", ""], ["Fyrbiak", "Marc", ""], ["Albartus", "Nils", ""], ["Elson", "Malte", ""], ["Rummel", "Nikol", ""], ["Paar", "Christof", ""]]}, {"id": "1910.00460", "submitter": "Ivan Stankevich", "authors": "Konstantin Korishchenko, Ivan Stankevich, Nikolay Pilnik, Daria\n  Petrova", "title": "Usage-Based Vehicle Insurance: Driving Style Factors of Accident\n  Probability and Severity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CY cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper introduces an approach to telematics devices data application in\nautomotive insurance. We conduct a comparative analysis of different types of\ndevices that collect information on vehicle utilization and driving style of\nits driver, describe advantages and disadvantages of these devices and indicate\nthe most efficient from the insurer point of view. The possible formats of\ntelematics data are described and methods of their processing to a format\nconvenient for modelling are proposed. We also introduce an approach to\nclassify the accidents strength. Using all the available information, we\nestimate accident probability models for different types of accidents and\nidentify an optimal set of factors for each of the models. We assess the\nquality of resulting models using both in-sample and out-of-sample estimates.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 14:45:50 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 16:09:06 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Korishchenko", "Konstantin", ""], ["Stankevich", "Ivan", ""], ["Pilnik", "Nikolay", ""], ["Petrova", "Daria", ""]]}, {"id": "1910.00757", "submitter": "Himel Dev", "authors": "Himel Dev, Karrie Karahalios and Hari Sundaram", "title": "Quantifying Voter Biases in Online Platforms: An Instrumental Variable\n  Approach", "comments": "The 22nd ACM Conference on Computer-Supported Cooperative Work and\n  Social Computing (CSCW), 2019", "journal-ref": "Proceedings of the ACM on Human Computer Interaction, Vol. 3, No.\n  CSCW, Article 120. Publication date: November 2019", "doi": "10.1145/3359222", "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In content-based online platforms, use of aggregate user feedback (say, the\nsum of votes) is commonplace as the \"gold standard\" for measuring content\nquality. Use of vote aggregates, however, is at odds with the existing\nempirical literature, which suggests that voters are susceptible to different\nbiases -- reputation (e.g., of the poster), social influence (e.g., votes thus\nfar), and position (e.g., answer position). Our goal is to quantify, in an\nobservational setting, the degree of these biases in online platforms.\nSpecifically, what are the causal effects of different impression signals --\nsuch as the reputation of the contributing user, aggregate vote thus far, and\nposition of content -- on a participant's vote on content? We adopt an\ninstrumental variable (IV) framework to answer this question. We identify a set\nof candidate instruments, carefully analyze their validity, and then use the\nvalid instruments to reveal the effects of the impression signals on votes. Our\nempirical study using log data from Stack Exchange websites shows that the bias\nestimates from our IV approach differ from the bias estimates from the ordinary\nleast squares (OLS) method. In particular, OLS underestimates reputation bias\n(1.6--2.2x for gold badges) and position bias (up to 1.9x for the initial\nposition) and overestimates social influence bias (1.8--2.3x for initial\nvotes). The implications of our work include: redesigning user interface to\navoid voter biases; making changes to platforms' policy to mitigate voter\nbiases; detecting other forms of biases in online platforms.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 03:00:36 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Dev", "Himel", ""], ["Karahalios", "Karrie", ""], ["Sundaram", "Hari", ""]]}, {"id": "1910.00920", "submitter": "Genevieve Gorrell", "authors": "Genevieve Gorrell, Mehmet E. Bakir, Mark A. Greenwood, Ian Roberts and\n  Kalina Bontcheva", "title": "Race and Religion in Online Abuse towards UK Politicians: Working Paper", "comments": "This is an earlier version of a paper currently under review. This\n  version spans January to June 2019 whereas the paper under review covers\n  January to September 2019, as well as adding further analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Against a backdrop of tensions related to EU membership, we find levels of\nonline abuse toward UK MPs reach a new high. Race and religion have become\npressing topics globally, and in the UK this interacts with \"Brexit\" and the\nrise of social media to create a complex social climate in which much can be\nlearned about evolving attitudes. In 8 million tweets by and to UK MPs in the\nfirst half of 2019, religious intolerance scandals in the UK's two main\npolitical parties attracted significant attention. Furthermore, high profile\nethnic minority MPs started conversations on Twitter about race and religion,\nthe responses to which provide a valuable source of insight. We found a\nsignificant presence for disturbing racial and religious abuse. We also explore\nmetrics relating to abuse patterns, which may affect its impact. We find\n\"burstiness\" of abuse doesn't depend on race or gender, but individual factors\nmay lead to politicians having very different experiences online.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 12:58:26 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 13:59:23 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Gorrell", "Genevieve", ""], ["Bakir", "Mehmet E.", ""], ["Greenwood", "Mark A.", ""], ["Roberts", "Ian", ""], ["Bontcheva", "Kalina", ""]]}, {"id": "1910.01005", "submitter": "Maria Bada Dr", "authors": "Maria Bada, Basie von Solms and Ioannis Agrafiotis", "title": "Reviewing National Cybersecurity Awareness for Users and Executives in\n  Africa", "comments": "International Journal on Advances in Security, 10 pages", "journal-ref": null, "doi": null, "report-no": "vol 12 no 1 & 2", "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an unprecedented increase in cybercrime globally observed over the\nlast years. One of the regions driving this increase is Africa, where\nsignificant financial losses are reported. Yet, citizens of African countries\nare not aware of the risks present in cyberspace. The design and implementation\nof national awareness campaigns by African countries to address this problem\nare in their infancy state, mainly due to the absence of capacity building\nefforts. As part of the Global Cybersecurity Capacity Centre (GCSCC) programme,\nwe conducted a series of focus groups in six African countries, in order to\nassess their cybersecurity posture, a critical component of which is user and\nexecutive awareness of cyber risks. This paper is an extended version of\nprevious work where an initial analysis of awareness for cyber risk in African\ncountries was presented. In this extended version, we reflect on best practice\napproaches for developing national awareness campaigns and use these as a\nframework to analyse qualitative data from the focus groups. We discuss the\ncurrent state of African countries with regards to the implementation of\nnational cybersecurity awareness campaigns for. users and executives, the main\nobstacles in combating cybercrime and conclude with recommendations on how\nAfrican countries can identify and prioritise activities to increase their\ncapacity regarding cybersecurity awareness.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 15:09:30 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Bada", "Maria", ""], ["von Solms", "Basie", ""], ["Agrafiotis", "Ioannis", ""]]}, {"id": "1910.01165", "submitter": "Abhishek Pratap", "authors": "Abhishek Pratap, Elias Chaibub Neto, Phil Snyder, Carl Stepnowsky,\n  No\\'emie Elhadad, Daniel Grant, Matthew H. Mohebbi, Sean Mooney, Christine\n  Suver, John Wilbanks, Lara Mangravite, Patrick Heagerty, Pat Arean, Larsson\n  Omberg", "title": "Indicators of retention in remote digital health studies: A cross-study\n  evaluation of 100,000 participants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Digital technologies such as smartphones are transforming the way scientists\nconduct biomedical research using real-world data. Several remotely-conducted\nstudies have recruited thousands of participants over a span of a few months.\nUnfortunately, these studies are hampered by substantial participant attrition,\ncalling into question the representativeness of the collected data including\ngeneralizability of findings from these studies. We report the challenges in\nretention and recruitment in eight remote digital health studies comprising\nover 100,000 participants who participated for more than 850,000 days,\ncompleting close to 3.5 million remote health evaluations. Survival modeling\nsurfaced several factors significantly associated(P < 1e-16) with increase in\nmedian retention time i) Clinician referral(increase of 40 days), ii) Effect of\ncompensation (22 days), iii) Clinical conditions of interest to the study (7\ndays) and iv) Older adults(4 days). Additionally, four distinct patterns of\ndaily app usage behavior that were also associated(P < 1e-10) with participant\ndemographics were identified. Most studies were not able to recruit a\nrepresentative sample, either demographically or regionally. Combined together\nthese findings can help inform recruitment and retention strategies to enable\nequitable participation of populations in future digital health research.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 18:55:41 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Pratap", "Abhishek", ""], ["Neto", "Elias Chaibub", ""], ["Snyder", "Phil", ""], ["Stepnowsky", "Carl", ""], ["Elhadad", "No\u00e9mie", ""], ["Grant", "Daniel", ""], ["Mohebbi", "Matthew H.", ""], ["Mooney", "Sean", ""], ["Suver", "Christine", ""], ["Wilbanks", "John", ""], ["Mangravite", "Lara", ""], ["Heagerty", "Patrick", ""], ["Arean", "Pat", ""], ["Omberg", "Larsson", ""]]}, {"id": "1910.01170", "submitter": "Jessica Whittlestone", "authors": "Jess Whittlestone, Aviv Ovadya", "title": "The tension between openness and prudence in AI research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper explores the tension between openness and prudence in AI research,\nevident in two core principles of the Montr\\'eal Declaration for Responsible\nAI. While the AI community has strong norms around open sharing of research,\nconcerns about the potential harms arising from misuse of research are growing,\nprompting some to consider whether the field of AI needs to reconsider\npublication norms. We discuss how different beliefs and values can lead to\ndiffering perspectives on how the AI community should manage this tension, and\nexplore implications for what responsible publication norms in AI research\nmight look like in practice.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 19:09:43 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 14:51:59 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Whittlestone", "Jess", ""], ["Ovadya", "Aviv", ""]]}, {"id": "1910.01211", "submitter": "Gabriele Franch", "authors": "Gabriele Franch, Giuseppe Jurman, Luca Coviello, Marta Pendesini,\n  Cesare Furlanello", "title": "MASS-UMAP: Fast and accurate analog ensemble search in weather radar\n  archive", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of analogs - similar weather patterns - for weather forecasting and\nanalysis is an established method in meteorology. The most challenging aspect\nof using this approach in the context of operational radar applications is to\nbe able to perform a fast and accurate search for similar spatiotemporal\nprecipitation patterns in a large archive of historical records. In this\ncontext, sequential pairwise search is too slow and computationally expensive.\nHere we propose an architecture to significantly speed-up spatiotemporal analog\nretrieval by combining nonlinear geometric dimensionality reduction (UMAP) with\nthe fastest known Euclidean search algorithm for time series (MASS) to find\nradar analogs in constant time, independently of the desired temporal length to\nmatch and the number of extracted analogs. We compare UMAP with Principal\ncomponent analysis (PCA) and show that UMAP outperforms PCA for spatial MSE\nanalog search with proper settings. Moreover, we show that MASS is 20 times\nfaster than brute force search on the UMAP embeddings space. We test the\narchitecture on a real dataset and show that it enables precise and fast\noperational analog ensemble search through more than 2 years of radar archive\nin less than 5 seconds on a single workstation.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 17:32:51 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Franch", "Gabriele", ""], ["Jurman", "Giuseppe", ""], ["Coviello", "Luca", ""], ["Pendesini", "Marta", ""], ["Furlanello", "Cesare", ""]]}, {"id": "1910.01212", "submitter": "Vahid Moraveji Hashemi", "authors": "Vahid Moraveji Hashemi", "title": "Social Influence and Radicalization: A Social Data Analytics Study", "comments": "Master Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The confluence of technological and societal advances is changing the nature\nof global terrorism. For example, engagement with Web, social media, and smart\ndevices has the potential to affect the mental behavior of the individuals and\ninfluence extremist and criminal behaviors such as Radicalization. In this\ncontext, social data analytics (i.e., the discovery, interpretation, and\ncommunication of meaningful patterns in social data) and influence maximization\n(i.e., the problem of finding a small subset of nodes in a social network which\ncan maximize the propagation of influence) has the potential to become a vital\nasset to explore the factors involved in influencing people to participate in\nextremist activities.\n  To address this challenge, we study and analyze the recent work done in\ninfluence maximization and social data analytics from effectiveness, efficiency\nand scalability viewpoints. We introduce a social data analytics pipeline,\nnamely iRadical, to enable analysts engage with social data to explore the\npotential for online radicalization. In iRadical, we present algorithms to\nanalyse the social data as well as the user activity patterns to learn how\ninfluence flows in social networks. We implement iRadical as an extensible\narchitecture that is publicly available on GitHub and present the evaluation\nresults.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 02:36:59 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Hashemi", "Vahid Moraveji", ""]]}, {"id": "1910.01214", "submitter": "Gunther Jikeli", "authors": "Gunther Jikeli, Damir Cavar, Daniel Miehling", "title": "Annotating Antisemitic Online Content. Towards an Applicable Definition\n  of Antisemitism", "comments": null, "journal-ref": null, "doi": "10.5967/3r3m-na89", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online antisemitism is hard to quantify. How can it be measured in rapidly\ngrowing and diversifying platforms? Are the numbers of antisemitic messages\nrising proportionally to other content or is it the case that the share of\nantisemitic content is increasing? How does such content travel and what are\nreactions to it? How widespread is online Jew-hatred beyond infamous websites\nand fora, and closed social media groups? However, at the root of many\nmethodological questions is the challenge of finding a consistent way to\nidentify diverse manifestations of antisemitism in large datasets. What is\nmore, a clear definition is essential for building an annotated corpus that can\nbe used as a gold standard for machine learning programs to detect antisemitic\nonline content. We argue that antisemitic content has distinct features that\nare not captured adequately in generic approaches of annotation, such as hate\nspeech, abusive language, or toxic language. We discuss our experiences with\nannotating samples from our dataset that draw on a ten percent random sample of\npublic tweets from Twitter. We show that the widely used definition of\nantisemitism by the International Holocaust Remembrance Alliance can be applied\nsuccessfully to online messages if inferences are spelled out in detail and if\nthe focus is not on intent of the disseminator but on the message in its\ncontext. However, annotators have to be highly trained and knowledgeable about\ncurrent events to understand each tweet's underlying message within its\ncontext. The tentative results of the annotation of two of our small but\nrandomly chosen samples suggest that more than ten percent of conversations on\nTwitter about Jews and Israel are antisemitic or probably antisemitic. They\nalso show that at least in conversations about Jews, an equally high number of\ntweets denounce antisemitism, although these conversations do not necessarily\ncoincide.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 04:52:05 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Jikeli", "Gunther", ""], ["Cavar", "Damir", ""], ["Miehling", "Daniel", ""]]}, {"id": "1910.01290", "submitter": "Jonathan Zhu", "authors": "Tai-Quan Peng and Jonathan J. H. Zhu", "title": "Mobile Phone Use as Sequential Processes: From Discrete Behaviors to\n  Sessions of Behaviors and Trajectories of Sessions", "comments": "36 pages, 4 figures", "journal-ref": null, "doi": "10.1093/jcmc/zmz029", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile phone use is an unfolding process by nature. In this study, it is\nexplicated as two sequential processes: mobile sessions composed of an\nuninterrupted set of behaviors and mobile trajectories composed of mobile\nsessions and mobile-off time. A dataset of a five-month behavioral logfile of\nmobile application use by approximately 2,500 users in Hong Kong is used.\nMobile sessions are constructed and mined to uncover sequential characteristics\nand patterns in mobile phone use. Mobile trajectories are analyzed to examine\nintraindividual change and interindividual differences on mobile re-engagement\nas indicators of behavioral dynamics in mobile phone use. The study provides\nempirical support for and expands the boundaries of existing theories about\ncombinatorial use of information and communication technologies (ICTs).\nFinally, the understanding on mobile temporality is enhanced, that is, mobile\ntemporality is homogeneous across social sectors. Furthermore, mobile phones\nredefine, rather than blur, the boundary between private and public time.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 03:27:30 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Peng", "Tai-Quan", ""], ["Zhu", "Jonathan J. H.", ""]]}, {"id": "1910.01303", "submitter": "Roland Bouffanais", "authors": "Sun Sun Lim and Roland Bouffanais", "title": "From Senseless Swarms to Smart Mobs: Tuning Networks for Prosocial\n  Behaviour", "comments": "To appear in IEEE Technology and Society Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media have been seen to accelerate the spread of negative content such\nas disinformation and hate speech, often unleashing reckless herd mentality\nwithin networks, further aggravated by malicious entities using bots for\namplification. So far, the response to this emerging global crisis has centred\naround social media platform companies making reactive moves that appear to\nhave greater symbolic value than practical utility. These include taking down\npatently objectionable content or manually deactivating the accounts of bad\nactors, while leaving vast troves of negative content to circulate and\nperpetuate within social networks. Governments worldwide have thus sought to\nintervene using regulatory tools, with countries such as France, Germany and\nSingapore introducing laws to compel technology companies to take down or\ncorrect erroneous and harmful content. However, the relentless pace of\ntechnological progress enfeebles regulatory measures that seem fated for\nobsolescence.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 05:08:35 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 00:40:00 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Lim", "Sun Sun", ""], ["Bouffanais", "Roland", ""]]}, {"id": "1910.01363", "submitter": "Mareike Hartmann", "authors": "Mareike Hartmann and Yevgeniy Golovchenko and Isabelle Augenstein", "title": "Mapping (Dis-)Information Flow about the MH17 Plane Crash", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital media enables not only fast sharing of information, but also\ndisinformation. One prominent case of an event leading to circulation of\ndisinformation on social media is the MH17 plane crash. Studies analysing the\nspread of information about this event on Twitter have focused on small,\nmanually annotated datasets, or used proxys for data annotation. In this work,\nwe examine to what extent text classifiers can be used to label data for\nsubsequent content analysis, in particular we focus on predicting pro-Russian\nand pro-Ukrainian Twitter content related to the MH17 plane crash. Even though\nwe find that a neural classifier improves over a hashtag based baseline,\nlabeling pro-Russian and pro-Ukrainian content with high precision remains a\nchallenging problem. We provide an error analysis underlining the difficulty of\nthe task and identify factors that might help improve classification in future\nwork. Finally, we show how the classifier can facilitate the annotation task\nfor human annotators.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 09:00:58 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Hartmann", "Mareike", ""], ["Golovchenko", "Yevgeniy", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "1910.01582", "submitter": "Binxuan Huang", "authors": "Binxuan Huang, Kathleen M. Carley", "title": "Location Order Recovery in Trails with Low Temporal Resolution", "comments": "Accepted in IEEE Transactions on Network Science and Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers who study object movement problems related to topics like traffic\nflow analysis, patient monitoring, and software operation, need to know the\ncorrect order in which objects move. Here, we use the term trail to refer to a\nseries of movements by an object. This paper introduces a new missing data\nproblem that occurs when analyzing trails where there is inadequate temporal\nresolution on the events. The temporal resolution is inadequate when an object,\nwhich can only be in one place at one time, appears in the data to be in two or\nmore locations at once. We refer to this lack of resolution as a broken point.\nBroken points prevent us from knowing the correct order of movement. We propose\na three-phase framework for recovering the location order. Based on the Markov\ntransition network, we are able to find the route with the highest probability.\nOur results show that this framework can efficiently find the correct location\norder in trails with low temporal resolution. We also demonstrate that by\ncorrecting the location order, the criticality of locations can change\nsignificantly.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 15:12:29 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Huang", "Binxuan", ""], ["Carley", "Kathleen M.", ""]]}, {"id": "1910.01970", "submitter": "Jana Korunovska", "authors": "Jana Korunovska and Sarah Spiekermann", "title": "The Effects of Information and Communication Technology Use on Human\n  Energy and Fatigue: A Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Information and communication technologies (ICTs) are generally assumed to\nsave time and energy, yet user fatigue due to ICT use is assumed to be on the\nrise. The question about the effects of ICT use on human energy has sparked\nincreased research interest in recent years. however, the course is complicated\nby the fact that the conceptualization of human energy is extremely diverse.\nThe aim of this paper is therefore twofold. First, we provide a conceptual\nframework and classification for subjective energy concepts and reflect on the\ntheoretical embedding of technology within the theories on subjective energy.\nSecond, we review the leading empirical literature on the relationship between\nICT use and eight different subjective energy concepts prominent in different\ndisciplines. We also include the new phenomena of social networking sites (SNS)\nexhaustion and SNS fatigue. With this, we aim to consolidate the existing\nresearch, illuminate the gaps and provide a conceptual baseline for future\nresearch on the relationship between ICT use and subjective energy of ICT\nusers. We show that ICT use has predominantly negative effect on users' energy,\nespecially in organizational contexts, and show the main patterns and\nmechanisms through which technology drains as well as energizes users.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 14:38:44 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2021 07:58:48 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Korunovska", "Jana", ""], ["Spiekermann", "Sarah", ""]]}, {"id": "1910.02064", "submitter": "Henry M. Kim", "authors": "Henry M. Kim, Marek Laskowski, Michael Zargham, HJalmar Turesson, Matt\n  Barlin, Danil Kabanov", "title": "Token Economics in Real-Life: Cryptocurrency and Incentives Design for\n  Insolar Blockchain Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of how to set up cryptocurrency incentive mechanisms and to\noperationalize governance is token economics. Given the $250 billion market cap\nfor cryptocurrencies, there is compelling need to investigate this topic. In\nthis paper, we present facets of the token engineering process for a real-life\n80-person Swiss blockchain startup, Insolar. We show how Insolar used systems\nmodeling and simulation combined with cryptocurrency expertise to design a\nmechanism to incentivize enterprises and individual users to use their new\nMainNet public blockchain network. The study showed subsidy pools that\nincentivize application developers to develop on the network does indeed have\nthe desired positive effect on MainNet adoption. For a startup like Insolar\nwhose success hinge upon how well their model incentivizes various stakeholders\nto participate on their MainNet network versus that of numerous alternatives,\nthis token economics simulation analysis provides invaluable insights.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 17:44:17 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 20:01:36 GMT"}, {"version": "v3", "created": "Tue, 20 Oct 2020 20:18:23 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Kim", "Henry M.", ""], ["Laskowski", "Marek", ""], ["Zargham", "Michael", ""], ["Turesson", "HJalmar", ""], ["Barlin", "Matt", ""], ["Kabanov", "Danil", ""]]}, {"id": "1910.02109", "submitter": "Dianbo Liu Dr", "authors": "Dianbo Liu, Kathe Fox, Griffin Weber, Tim Miller", "title": "Confederated Machine Learning on Horizontally and Vertically Separated\n  Medical Data for Large-Scale Health System Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Health information is generally fragmented across silos. Though it is\ntechnically feasible to unite data for analysis in a manner that underpins a\nrapid learning healthcare system, privacy concerns and regulatory barriers\nlimit data centralization. Machine learning can be conducted in a federated\nmanner on patient datasets with the same set of variables, but separated across\nsites of care. But federated learning cannot handle the situation where\ndifferent data types for a given patient are separated vertically across\ndifferent organizations and when patient ID matching across different\ninstitutions is difficult. We call methods that enable machine learning model\ntraining on data separated by two or more degrees confederated machine\nlearning. We proposed and evaluated a confederated learning to training machine\nlearning model to stratify the risk of several diseases among when data are\nhorizontally separated by individual, vertically separated by data type, and\nseparated by identity without patient ID matching.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 19:14:46 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 02:46:02 GMT"}, {"version": "v3", "created": "Wed, 9 Dec 2020 17:42:03 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Liu", "Dianbo", ""], ["Fox", "Kathe", ""], ["Weber", "Griffin", ""], ["Miller", "Tim", ""]]}, {"id": "1910.02157", "submitter": "Xiao Chen", "authors": "Xiao Chen, Thomas Navidi, Ram Rajagopal", "title": "Energy Resource Control via Privacy Preserving Data", "comments": "8 pages", "journal-ref": null, "doi": "10.1016/j.epsr.2020.106719", "report-no": null, "categories": "eess.SY cs.CY cs.SY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Although the frequent monitoring of smart meters enables granular control\nover energy resources, it also increases the risk of leakage of private\ninformation such as income, home occupancy, and power consumption behavior that\ncan be inferred from the data by an adversary. We propose a method of releasing\nmodified smart meter data so specific private attributes are obscured while the\nutility of the data for use in an energy resource controller is preserved. The\nmethod achieves privatization by injecting noise conditional on the private\nattribute through a linear filter learned via a minimax optimization. The\noptimization contains the loss function of a classifier for the private\nattribute, which we maximize, and the energy resource controller's objective\nformulated as a canonical form optimization, which we minimize. We perform our\nexperiment on a dataset of household consumption with solar generation and\nanother from the Commission for Energy Regulation that contains household smart\nmeter data with sensitive attributes such as income and home occupancy. We\ndemonstrate that our method is able to significantly reduce the ability of an\nadversary to classify the private attribute while maintaining a similar\nobjective value for an energy storage controller.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 22:08:19 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 00:52:25 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Chen", "Xiao", ""], ["Navidi", "Thomas", ""], ["Rajagopal", "Ram", ""]]}, {"id": "1910.02290", "submitter": "Anna Kruspe", "authors": "Anna Kruspe", "title": "Few-shot tweet detection in emerging disaster events", "comments": "Accepted to AI+HADR workshop @ NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CY cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media sources can provide crucial information in crisis situations,\nbut discovering relevant messages is not trivial. Methods have so far focused\non universal detection models for all kinds of crises or for certain crisis\ntypes (e.g. floods). Event-specific models could implement a more focused\nsearch area, but collecting data and training new models for a crisis that is\nalready in progress is costly and may take too much time for a prompt response.\nAs a compromise, manually collecting a small amount of example messages is\nfeasible. Few-shot models can generalize to unseen classes with such a small\nhandful of examples, and do not need be trained anew for each event. We compare\nhow few-shot approaches (matching networks and prototypical networks) perform\nfor this task. Since this is essentially a one-class problem, we also\ndemonstrate how a modified one-class version of prototypical models can be used\nfor this application.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 16:25:56 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Kruspe", "Anna", ""]]}, {"id": "1910.02292", "submitter": "Joyce Nakatumba-Nabende Dr.", "authors": "Benjamin Akera, Joyce Nakatumba-Nabende, Jonathan Mukiibi, Ali\n  Hussein, Nathan Baleeta, Daniel Ssendiwala, Samiiha Nalwooga", "title": "Keyword Spotter Model for Crop Pest and Disease Monitoring from\n  Community Radio Data", "comments": "Presented at NeurIPS 2019 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In societies with well developed internet infrastructure, social media is the\nleading medium of communication for various social issues especially for\nbreaking news situations. In rural Uganda however, public community radio is\nstill a dominant means for news dissemination. Community radio gives audience\nto the general public especially to individuals living in rural areas, and thus\nplays an important role in giving a voice to those living in the broadcast\narea. It is an avenue for participatory communication and a tool relevant in\nboth economic and social development.This is supported by the rise to ubiquity\nof mobile phones providing access to phone-in or text-in talk shows. In this\npaper, we describe an approach to analysing the readily available community\nradio data with machine learning-based speech keyword spotting techniques. We\nidentify the keywords of interest related to agriculture and build models to\nautomatically identify these keywords from audio streams. Our contribution\nthrough these techniques is a cost-efficient and effective way to monitor food\nsecurity concerns particularly in rural areas. Through keyword spotting and\nradio talk show analysis, issues such as crop diseases, pests, drought and\nfamine can be captured and fed into an early warning system for stakeholders\nand policy makers.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 16:30:49 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Akera", "Benjamin", ""], ["Nakatumba-Nabende", "Joyce", ""], ["Mukiibi", "Jonathan", ""], ["Hussein", "Ali", ""], ["Baleeta", "Nathan", ""], ["Ssendiwala", "Daniel", ""], ["Nalwooga", "Samiiha", ""]]}, {"id": "1910.02376", "submitter": "Wei Ma", "authors": "Wei Ma, Sean Qian", "title": "High-Resolution Traffic Sensing with Autonomous Vehicles", "comments": "submitted to Transportation Research Part C: Emerging Technologies", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last decades have witnessed the breakthrough of autonomous vehicles\n(AVs), and the perception capabilities of AVs have been dramatically improved.\nVarious sensors installed on AVs, including, but are not limited to, LiDAR,\nradar, camera and stereovision, will be collecting massive data and perceiving\nthe surrounding traffic states continuously. In fact, a fleet of AVs can serve\nas floating (or probe) sensors, which can be utilized to infer traffic\ninformation while cruising around the roadway networks. In contrast,\nconventional traffic sensing methods rely on fixed traffic sensors such as loop\ndetectors, cameras and microwave vehicle detectors. Due to the high cost of\nconventional traffic sensors, traffic state data are usually obtained in a\nlow-frequency and sparse manner. In view of this, this paper leverages rich\ndata collected through AVs to propose the high-resolution traffic sensing\nframework. The proposed framework estimates the fundamental traffic state\nvariables, namely, flow, density and speed in high spatio-temporal resolution,\nand it is developed under different levels of AV perception capabilities and\nlow AV market penetration rate. The Next Generation Simulation (NGSIM) data is\nadopted to examine the accuracy and robustness of the proposed framework.\nExperimental results show that the proposed estimation framework achieves high\naccuracy even with low AV market penetration rate. Sensitivity analysis\nregarding AV penetration rate, sensor configuration, and perception accuracy\nwill also be studied. This study will help policymakers and private sectors\n(e.g Uber, Waymo) to understand the values of AVs, especially the values of\nmassive data collected by AVs, in traffic operation and management.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 05:07:29 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Ma", "Wei", ""], ["Qian", "Sean", ""]]}, {"id": "1910.02390", "submitter": "Amber Nigam", "authors": "Amber Nigam, Pragati Jaiswal, Uma Girkar, Teertha Arora, and Leo A.\n  Celi", "title": "Migration through Machine Learning Lens -- Predicting Sexual and\n  Reproductive Health Vulnerability of Young Migrants", "comments": "Accepted for Machine Learning for Health (ML4H) at NeurIPS 2019 -\n  Extended Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we have discussed initial findings and results of our\nexperiment to predict sexual and reproductive health vulnerabilities of\nmigrants in a data-constrained environment. Notwithstanding the limited\nresearch and data about migrants and migration cities, we propose a solution\nthat simultaneously focuses on data gathering from migrants, augmenting\nawareness of the migrants to reduce mishaps, and setting up a mechanism to\npresent insights to the key stakeholders in migration to act upon. We have\ndesigned a webapp for the stakeholders involved in migration: migrants, who\nwould participate in data gathering process and can also use the app for\ngetting to know safety and awareness tips based on analysis of the data\nreceived; public health workers, who would have an access to the database of\nmigrants on the app; policy makers, who would have a greater understanding of\nthe ground reality, and of the patterns of migration through machine-learned\nanalysis. Finally, we have experimented with different machine learning models\non an artificially curated dataset. We have shown, through experiments, how\nmachine learning can assist in predicting the migrants at risk and can also\nhelp in identifying the critical factors that make migration dangerous for\nmigrants. The results for identifying vulnerable migrants through machine\nlearning algorithms are statistically significant at an alpha of 0.05.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 07:09:13 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 03:56:45 GMT"}, {"version": "v3", "created": "Fri, 15 Nov 2019 20:14:39 GMT"}, {"version": "v4", "created": "Fri, 22 Nov 2019 10:00:02 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Nigam", "Amber", ""], ["Jaiswal", "Pragati", ""], ["Girkar", "Uma", ""], ["Arora", "Teertha", ""], ["Celi", "Leo A.", ""]]}, {"id": "1910.03014", "submitter": "Jeremy Frank", "authors": "Jeremy D. Frank", "title": "Artificial Intelligence: Powering Human Exploration of the Moon and Mars", "comments": "Presented at AAAI FSS-19: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decade, the NASA Autonomous Systems and Operations (ASO)\nproject has developed and demonstrated numerous autonomy enabling technologies\nemploying AI techniques. Our work has employed AI in three distinct ways to\nenable autonomous mission operations capabilities. Crew Autonomy gives\nastronauts tools to assist in the performance of each of these mission\noperations functions. Vehicle System Management uses AI techniques to turn the\nastronaut's spacecraft into a robot, allowing it to operate when astronauts are\nnot present, or to reduce astronaut workload. AI technology also enables\nAutonomous Robots as crew assistants or proxies when the crew are not present.\nWe first describe human spaceflight mission operations capabilities. We then\ndescribe the ASO project, and the development and demonstration performed by\nASO since 2011. We will describe the AI techniques behind each of these\ndemonstrations, which include a variety of symbolic automated reasoning and\nmachine learning based approaches. Finally, we conclude with an assessment of\nfuture development needs for AI to enable NASA's future Exploration missions.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 19:04:02 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Frank", "Jeremy D.", ""]]}, {"id": "1910.03206", "submitter": "Ashiqur KhudaBukhsh Ashiqur Rahman KhudaBukhsh", "authors": "Shriphani Palakodety, Ashiqur R. KhudaBukhsh, Jaime G. Carbonell", "title": "Voice for the Voiceless: Active Sampling to Detect Comments Supporting\n  the Rohingyas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Rohingya refugee crisis is one of the biggest humanitarian crises of\nmodern times with more than 600,000 Rohingyas rendered homeless according to\nthe United Nations High Commissioner for Refugees. While it has received\nsustained press attention globally, no comprehensive research has been\nperformed on social media pertaining to this large evolving crisis. In this\nwork, we construct a substantial corpus of YouTube video comments (263,482\ncomments from 113,250 users in 5,153 relevant videos) with an aim to analyze\nthe possible role of AI in helping a marginalized community. Using a novel\ncombination of multiple Active Learning strategies and a novel active sampling\nstrategy based on nearest-neighbors in the comment-embedding space, we\nconstruct a classifier that can detect comments defending the Rohingyas among\nlarger numbers of disparaging and neutral ones. We advocate that beyond the\nburgeoning field of hate-speech detection, automatic detection of\n\\emph{help-speech} can lend voice to the voiceless people and make the internet\nsafer for marginalized communities.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 04:17:33 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2020 19:33:00 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Palakodety", "Shriphani", ""], ["KhudaBukhsh", "Ashiqur R.", ""], ["Carbonell", "Jaime G.", ""]]}, {"id": "1910.03219", "submitter": "Kerry A Nice", "authors": "Kerry A. Nice, Gideon D.P.A. Aschwanden, Jasper S. Wijnands, Jason\n  Thompson, Haifeng Zhao, Mark Stevenson", "title": "The Nature of Human Settlement: Building an understanding of high\n  performance city design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an impending urban age where the majority of the world's population will\nlive in cities, it is critical that we improve our understanding of the\nstrengths and limitations of existing city designs to ensure they are safe,\nclean, can deliver health co-benefits and importantly, are sustainable into the\nfuture. To enable this, a systematic and efficient means of performing inter-\nand intra-city comparisons based on urban form is required. Until now, methods\nfor comparing cities have been limited by scalability, often reliant upon\nnon-standardised local input data that can be costly and difficult to obtain.\nTo address this, we have developed a unique approach to determine the mix,\ndistribution, and composition of neighbourhood types in cities based on\ndimensions of block size and regularity, sorted by a self-organising map. We\nillustrate the utility of the method to provide an understanding of the\nunderlying city morphology by overlaying spatially standardised city metrics\nsuch as air pollution and transport activity across a set of 1667 global cities\nwith populations exceeding 300,000. The unique approach reports associations\nbetween specific mixes of neighbourhood typologies and quantities of moving\nvehicles (r=0.97), impervious surfaces (r=0.86), and air pollution levels\n(aerosol optical depth r=0.58 and NO$_{2}$ r=0.57). What this illustrates, is\nthat this unique approach can identify the characteristics and neighbourhood\nmixes of well-performing urban areas while also producing unique `city\nfingerprints' that can be used to provide new metrics, insights, and drive\nimprovements in city design for the future.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 05:26:05 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Nice", "Kerry A.", ""], ["Aschwanden", "Gideon D. P. A.", ""], ["Wijnands", "Jasper S.", ""], ["Thompson", "Jason", ""], ["Zhao", "Haifeng", ""], ["Stevenson", "Mark", ""]]}, {"id": "1910.03220", "submitter": "Kerry A Nice", "authors": "Kerry A. Nice, Jason Thompson, Jasper S. Wijnands, Gideon D.P.A.\n  Aschwanden, Mark Stevenson", "title": "The 'Paris-end' of town? Urban typology through machine learning", "comments": null, "journal-ref": null, "doi": "10.3390/urbansci4020027", "report-no": null, "categories": "cs.CV cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The confluence of recent advances in availability of geospatial information,\ncomputing power, and artificial intelligence offers new opportunities to\nunderstand how and where our cities differ or are alike. Departing from a\ntraditional `top-down' analysis of urban design features, this project analyses\nmillions of images of urban form (consisting of street view, satellite imagery,\nand street maps) to find shared characteristics. A (novel) neural network-based\nframework is trained with imagery from the largest 1692 cities in the world and\nthe resulting models are used to compare within-city locations from Melbourne\nand Sydney to determine the closest connections between these areas and their\ninternational comparators. This work demonstrates a new, consistent, and\nobjective method to begin to understand the relationship between cities and\ntheir health, transport, and environmental consequences of their design. The\nresults show specific advantages and disadvantages using each type of imagery.\nNeural networks trained with map imagery will be highly influenced by the mix\nof roads, public transport, and green and blue space as well as the structure\nof these elements. The colours of natural and built features stand out as\ndominant characteristics in satellite imagery. The use of street view imagery\nwill emphasise the features of a human scaled visual geography of streetscapes.\nFinally, and perhaps most importantly, this research also answers the age-old\nquestion, ``Is there really a `Paris-end' to your city?''.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 05:26:33 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Nice", "Kerry A.", ""], ["Thompson", "Jason", ""], ["Wijnands", "Jasper S.", ""], ["Aschwanden", "Gideon D. P. A.", ""], ["Stevenson", "Mark", ""]]}, {"id": "1910.03270", "submitter": "Marco Guerini", "authors": "Y.L. Chung, E. Kuzmenko, S.S. Tekiroglu, M. Guerini", "title": "CONAN -- COunter NArratives through Nichesourcing: a Multilingual\n  Dataset of Responses to Fight Online Hate Speech", "comments": "Published as a long paper at ACL 2019", "journal-ref": "In Proceedings of ACL 2019 (pp. 2819-2829)", "doi": "10.18653/v1/P19-1271", "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although there is an unprecedented effort to provide adequate responses in\nterms of laws and policies to hate content on social media platforms, dealing\nwith hatred online is still a tough problem. Tackling hate speech in the\nstandard way of content deletion or user suspension may be charged with\ncensorship and overblocking. One alternate strategy, that has received little\nattention so far by the research community, is to actually oppose hate content\nwith counter-narratives (i.e. informed textual responses). In this paper, we\ndescribe the creation of the first large-scale, multilingual, expert-based\ndataset of hate speech/counter-narrative pairs. This dataset has been built\nwith the effort of more than 100 operators from three different NGOs that\napplied their training and expertise to the task. Together with the collected\ndata we also provide additional annotations about expert demographics, hate and\nresponse type, and data augmentation through translation and paraphrasing.\nFinally, we provide initial experiments to assess the quality of our data.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 08:33:56 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Chung", "Y. L.", ""], ["Kuzmenko", "E.", ""], ["Tekiroglu", "S. S.", ""], ["Guerini", "M.", ""]]}, {"id": "1910.03280", "submitter": "Gabriele D'Angelo", "authors": "Mirko Zichichi, Stefano Ferretti, Gabriele D'Angelo", "title": "A Distributed Ledger Based Infrastructure for Smart Transportation\n  System and Social Good", "comments": "Proceedings of the IEEE Consumer Communications and Networking\n  Conference 2020 (CCNC 2020)", "journal-ref": null, "doi": "10.1109/CCNC46108.2020.9045640", "report-no": null, "categories": "cs.CR cs.CY cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a system architecture to promote the development of smart\ntransportation systems. Thanks to the use of distributed ledgers and related\ntechnologies, it is possible to create, store and share data generated by users\nthrough their sensors, while moving. In particular, IOTA and IPFS are used to\nstore and certify data (and their related metadata) coming from sensors or by\nthe users themselves. Ethereum is exploited as the smart contract platform that\ncoordinates the data sharing and provisioning. The necessary privacy guarantees\nare provided by the usage of Zero Knowledge Proof. We show some results\nobtained from some use case scenarios that demonstrate how such technologies\ncan be integrated to build novel smart services and to promote social good in\nuser mobility.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 08:53:18 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 06:19:41 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Zichichi", "Mirko", ""], ["Ferretti", "Stefano", ""], ["D'Angelo", "Gabriele", ""]]}, {"id": "1910.03295", "submitter": "Xusheng Luo", "authors": "Xusheng Luo, Yonghua Yang, Kenny Q. Zhu, Yu Gong and Keping Yang", "title": "Conceptualize and Infer User Needs in E-commerce", "comments": "9 pages, 6 figures. Accepted by CIKM 2019 Applied Research Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding latent user needs beneath shopping behaviors is critical to\ne-commercial applications. Without a proper definition of user needs in\ne-commerce, most industry solutions are not driven directly by user needs at\ncurrent stage, which prevents them from further improving user satisfaction.\nRepresenting implicit user needs explicitly as nodes like \"outdoor barbecue\" or\n\"keep warm for kids\" in a knowledge graph, provides new imagination for various\ne- commerce applications. Backed by such an e-commerce knowledge graph, we\npropose a supervised learning algorithm to conceptualize user needs from their\ntransaction history as \"concept\" nodes in the graph and infer those concepts\nfor each user through a deep attentive model. Offline experiments demonstrate\nthe effectiveness and stability of our model, and online industry strength\ntests show substantial advantages of such user needs understanding.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 09:29:56 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Luo", "Xusheng", ""], ["Yang", "Yonghua", ""], ["Zhu", "Kenny Q.", ""], ["Gong", "Yu", ""], ["Yang", "Keping", ""]]}, {"id": "1910.03448", "submitter": "Francesco Rampazzo", "authors": "Katherine Hoffmann Pham, Francesco Rampazzo, and Leah R. Rosenzweig", "title": "Online Surveys and Digital Demography in the Developing World: Facebook\n  Users in Kenya", "comments": "Poster presented at the MIT Conference on Digital Experimentation,\n  November 1-2, 2019, Cambridge, MA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital platforms such as Facebook, Twitter, Wikipedia, and Amazon Mechanical\nTurk have transformed the study of human behavior and provided access to new\nsubject pools for academic research. In our study, we leverage the Facebook\nAdvertising Platform to conduct online surveys in the developing world. We\nassess the value of Facebook in Kenya, which has been chosen as a case study\nbecause it represents an average example of mobile and internet use on the\nAfrican continent, and because we were able to synchronize our data collection\nwith new rounds of the Afrobarometer survey and the 2019 national census. After\na brief comparison of the 'audience estimates' produced by the Facebook\nAdvertising Platform with population estimates from Kenya's 2009 census, we\npresent the results of an online survey pilot run in July 2019. We compare the\ncharacteristics of the 957 online respondents to those surveyed by the 2016\nAfrobarometer. We conclude with a discussion of next steps for the full scale\nstudy.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 15:14:29 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Pham", "Katherine Hoffmann", ""], ["Rampazzo", "Francesco", ""], ["Rosenzweig", "Leah R.", ""]]}, {"id": "1910.03496", "submitter": "\\'Alvaro Ibrain", "authors": "\\'Alvaro Ibrain Rodr\\'iguez and Lara Lloret Iglesias", "title": "Fake news detection using Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The evolution of the information and communication technologies has\ndramatically increased the number of people with access to the Internet, which\nhas changed the way the information is consumed. As a consequence of the above,\nfake news have become one of the major concerns because its potential to\ndestabilize governments, which makes them a potential danger to modern society.\nAn example of this can be found in the US. electoral campaign, where the term\n\"fake news\" gained great notoriety due to the influence of the hoaxes in the\nfinal result of these. In this work the feasibility of applying deep learning\ntechniques to discriminate fake news on the Internet using only their text is\nstudied. In order to accomplish that, three different neural network\narchitectures are proposed, one of them based on BERT, a modern language model\ncreated by Google which achieves state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 17:45:48 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 05:36:23 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Rodr\u00edguez", "\u00c1lvaro Ibrain", ""], ["Iglesias", "Lara Lloret", ""]]}, {"id": "1910.04071", "submitter": "Annika Reinke", "authors": "Lena Maier-Hein, Annika Reinke, Michal Kozubek, Anne L. Martel, Tal\n  Arbel, Matthias Eisenmann, Allan Hanbuary, Pierre Jannin, Henning M\\\"uller,\n  Sinan Onogur, Julio Saez-Rodriguez, Bram van Ginneken, Annette\n  Kopp-Schneider, Bennett Landman", "title": "BIAS: Transparent reporting of biomedical image analysis challenges", "comments": "2 Appendices - Appendix A: BIAS reporting guideline for biomedical\n  image analysis challenges, Appendix B: Glossary; 2 Supplements - Suppl 1:\n  Form for summarizing information on challenge organization, Suppl 2:\n  Structured description of a challenge design", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The number of biomedical image analysis challenges organized per year is\nsteadily increasing. These international competitions have the purpose of\nbenchmarking algorithms on common data sets, typically to identify the best\nmethod for a given problem. Recent research, however, revealed that common\npractice related to challenge reporting does not allow for adequate\ninterpretation and reproducibility of results. To address the discrepancy\nbetween the impact of challenges and the quality (control), the Biomedical I\nmage Analysis ChallengeS (BIAS) initiative developed a set of recommendations\nfor the reporting of challenges. The BIAS statement aims to improve the\ntransparency of the reporting of a biomedical image analysis challenge\nregardless of field of application, image modality or task category assessed.\nThis article describes how the BIAS statement was developed and presents a\nchecklist which authors of biomedical image analysis challenges are encouraged\nto include in their submission when giving a paper on a challenge into review.\nThe purpose of the checklist is to standardize and facilitate the review\nprocess and raise interpretability and reproducibility of challenge results by\nmaking relevant information explicit.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 15:30:33 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 06:27:03 GMT"}, {"version": "v3", "created": "Mon, 25 Nov 2019 12:26:11 GMT"}, {"version": "v4", "created": "Wed, 17 Jun 2020 06:58:41 GMT"}, {"version": "v5", "created": "Mon, 31 Aug 2020 13:04:02 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Maier-Hein", "Lena", ""], ["Reinke", "Annika", ""], ["Kozubek", "Michal", ""], ["Martel", "Anne L.", ""], ["Arbel", "Tal", ""], ["Eisenmann", "Matthias", ""], ["Hanbuary", "Allan", ""], ["Jannin", "Pierre", ""], ["M\u00fcller", "Henning", ""], ["Onogur", "Sinan", ""], ["Saez-Rodriguez", "Julio", ""], ["van Ginneken", "Bram", ""], ["Kopp-Schneider", "Annette", ""], ["Landman", "Bennett", ""]]}, {"id": "1910.04293", "submitter": "Thomas Dover", "authors": "Thomas P. Dover", "title": "Using NIST Special Publications (SP) 800-171r2 and 800-172/800-172A to\n  assess and evaluate the Cybersecurity posture of Information Systems in the\n  Healthcare sector", "comments": "Version 3. Update to August, 2020 version (2). Version 3 integrates\n  relevant information from NIST SP.800-172A (Assessing Enhanced Security\n  Requirements for Controlled Unclassified Information) published, April, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes how NIST Special Publications (SP) 800-171r2 (Protecting\nControlled but Unclassified Information in Nonfederal Systems and\nOrganizations), SP.800-172 (Enhanced Security Requirements for Protecting\nControlled Unclassified Information) and SP.800-172A (Assessing Enhanced\nSecurity Requirements for Controlled Unclassified Information) can be used to\nevaluate the cybersecurity posture of information systems and supporting\nframeworks relative to HIPAA and HITECH . It will demonstrate that provisions\nand baseline security requirements outlined in SP.800-171r2 and SP.800-172/172A\nfor the protection of Controlled Unclassified Information (CUI) can be applied\nto Electronic Protected Health Information (ePHI). An explanation of how these\npublications align with HIPAA and how this alignment suffices for evaluating IT\nenvironment security will be given along with the process and procedure for\nperforming such evaluation. Finally, the benefits of using this approach to\nsupport formal risk assessment will be presented.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 23:11:22 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 00:53:22 GMT"}, {"version": "v3", "created": "Sat, 8 Aug 2020 04:53:47 GMT"}, {"version": "v4", "created": "Wed, 5 May 2021 01:51:37 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Dover", "Thomas P.", ""]]}, {"id": "1910.04383", "submitter": "Dusko Pavlovic", "authors": "Dusko Pavlovic and Temra Pavlovic", "title": "Causality and deceit: Do androids watch action movies?", "comments": "29 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We seek causes through science, religion, and in everyday life. We get\nexcited when a big rock causes a big splash, and we get scared when it tumbles\nwithout a cause. But our causal cognition is usually biased. The 'why' is\ninfluenced by the 'who'. It is influenced by the 'self', and by 'others'. We\nshare rituals, we watch action movies, and we influence each other to believe\nin the same causes. Human mind is packed with subjectivity because shared\ncognitive biases bring us together. But they also make us vulnerable.\n  An artificial mind is deemed to be more objective than the human mind. After\nmany years of science-fiction fantasies about even-minded androids, they are\nnow sold as personal or expert assistants, as brand advocates, as policy or\ncandidate supporters, as network influencers. Artificial agents have been\nstunningly successful in disseminating artificial causal beliefs among humans.\nAs malicious artificial agents continue to manipulate human cognitive biases,\nand deceive human communities into ostensive but expansive causal illusions,\nthe hope for defending us has been vested into developing benevolent artificial\nagents, tasked with preventing and mitigating cognitive distortions inflicted\nupon us by their malicious cousins. Can the distortions of human causal\ncognition be corrected on a more solid foundation of artificial causal\ncognition?\n  In the present paper, we study a simple model of causal cognition, viewed as\na quest for causal models. We show that, under very mild and hard to avoid\nassumptions, there are always self-confirming causal models, which perpetrate\nself-deception, and seem to preclude a royal road to objectivity.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 06:24:18 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Pavlovic", "Dusko", ""], ["Pavlovic", "Temra", ""]]}, {"id": "1910.04656", "submitter": "Myounggyu Won", "authors": "Myounggyu Won", "title": "Intelligent Traffic Monitoring Systems for Vehicle Classification: A\n  Survey", "comments": "Published in IEEE Access", "journal-ref": "IEEE Access, vol. 8, pp. 73340-73358, 2020", "doi": "10.1109/ACCESS.2020.2987634", "report-no": null, "categories": "cs.CY eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A traffic monitoring system is an integral part of Intelligent Transportation\nSystems (ITS). It is one of the critical transportation infrastructures that\ntransportation agencies invest a huge amount of money to collect and analyze\nthe traffic data to better utilize the roadway systems, improve the safety of\ntransportation, and establish future transportation plans. With recent advances\nin MEMS, machine learning, and wireless communication technologies, numerous\ninnovative traffic monitoring systems have been developed. In this article, we\npresent a review of state-of-the-art traffic monitoring systems focusing on the\nmajor functionality--vehicle classification. We organize various vehicle\nclassification systems, examine research issues and technical challenges, and\ndiscuss hardware/software design, deployment experience, and system performance\nof vehicle classification systems. Finally, we discuss a number of critical\nopen problems and future research directions in an aim to provide valuable\nresources to academia, industry, and government agencies for selecting\nappropriate technologies for their traffic monitoring applications.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 15:40:40 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 19:06:20 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Won", "Myounggyu", ""]]}, {"id": "1910.04696", "submitter": "Diego Seco", "authors": "Miguel \\'Angel Bernab\\'e, Jacinto Estima, Mar\\'ia Ester Gonz\\'alez,\n  Carlos Granell, Carlos L\\'opez-V\\'azquez, Miguel R. Luaces, Bruno Martins,\n  Daniela Moctezuma, Diego Seco", "title": "IDEAIS: Smart Voice Assistants to Improve Interaction with SDIs", "comments": "This research has received funding from CYTED, Ibero-American Program\n  of Science and Technology for Development, GA No. 519RT0579", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A critical goal, is that organizations and citizens can easily access the\ngeographic information required for good governance. However, despite the\ncostly efforts of governments to create and implement Spatial Data\nInfrastructures (SDIs), this goal is far from being achieved. This is partly\ndue to the lack of usability of the geoportals through which the geographic\ninformation is accessed. In this position paper, we present IDEAIS, a research\nnetwork composed of multiple Ibero-American partners to address this usability\nissue through the use of Intelligent Systems, in particular Smart Voice\nAssistants, to efficiently recover and access geographic information.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 13:42:59 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Bernab\u00e9", "Miguel \u00c1ngel", ""], ["Estima", "Jacinto", ""], ["Gonz\u00e1lez", "Mar\u00eda Ester", ""], ["Granell", "Carlos", ""], ["L\u00f3pez-V\u00e1zquez", "Carlos", ""], ["Luaces", "Miguel R.", ""], ["Martins", "Bruno", ""], ["Moctezuma", "Daniela", ""], ["Seco", "Diego", ""]]}, {"id": "1910.04836", "submitter": "Shiwali Mohan", "authors": "Shiwali Mohan and Anusha Venkatakrishnan and Andrea Hartzler", "title": "Designing an AI Health Coach and Studying its Utility in Promoting\n  Regular Aerobic Exercise", "comments": null, "journal-ref": "ACM Transactions of Interactive Intelligent Syststems 10, 2,\n  Article 14 (May 2020), 30 pages", "doi": "10.1145/3366501", "report-no": null, "categories": "cs.HC cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our research aims to develop interactive, social agents that can coach people\nto learn new tasks, skills, and habits. In this paper, we focus on coaching\nsedentary, overweight individuals (i.e., trainees) to exercise regularly. We\nemploy adaptive goal setting in which the intelligent health coach generates,\ntracks, and revises personalized exercise goals for a trainee. The goals become\nincrementally more difficult as the trainee progresses through the training\nprogram. Our approach is model-based - the coach maintains a parameterized\nmodel of the trainee's aerobic capability that drives its expectation of the\ntrainee's performance. The model is continually revised based on trainee-coach\ninteractions. The coach is embodied in a smartphone application, NutriWalking,\nwhich serves as a medium for coach-trainee interaction. We adopt a task-centric\nevaluation approach for studying the utility of the proposed algorithm in\npromoting regular aerobic exercise. We show that our approach can adapt the\ntrainee program not only to several trainees with different capabilities, but\nalso to how a trainee's capability improves as they begin to exercise more.\nExperts rate the goals selected by the coach better than other plausible goals,\ndemonstrating that our approach is consistent with clinical recommendations.\nFurther, in a 6-week observational study with sedentary participants, we show\nthat the proposed approach helps increase exercise volume performed each week.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 20:07:15 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 17:58:21 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Mohan", "Shiwali", ""], ["Venkatakrishnan", "Anusha", ""], ["Hartzler", "Andrea", ""]]}, {"id": "1910.04865", "submitter": "Adewale Akinfaderin", "authors": "Adewale Akinfaderin and Olamilekan Wahab", "title": "NASS-AI: Towards Digitization of Parliamentary Bills using Document\n  Level Embedding and Bidirectional Long Short-Term Memory", "comments": "Presented at NeurIPS 2019 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been several reports in the Nigerian and International media about\nthe Senators and House of Representative Members of the Nigerian National\nAssembly (NASS) being the highest paid in the world. Despite this high-level of\nparliamentary compensation and a lack of oversight, most of the legislative\nduties like bills introduced and vote proceedings are shrouded in mystery\nwithout an open and annotated corpus. In this paper, we present results from\nongoing research on the categorization of bills introduced in the Nigerian\nparliament since the fourth republic (1999 - 2018). For this task, we employed\na multi-step approach which involves extracting text from scanned and embedded\npdfs with low to medium quality using Optical Character Recognition (OCR) tools\nand labeling them into eight categories. We investigate the performance of\ndocument level embedding for feature representation of the extracted texts\nbefore using a Bidirectional Long Short-Term Memory (Bi-LSTM) for our\nclassifier. The performance was further compared with other feature\nrepresentation and machine learning techniques. We believe that these results\nare well-positioned to have a substantial impact on the quest to meet the basic\nopen data charter principles.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 00:39:02 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Akinfaderin", "Adewale", ""], ["Wahab", "Olamilekan", ""]]}, {"id": "1910.04906", "submitter": "Mustafa Bilgic", "authors": "Vinesh Kannan, Matthew A. Shapiro, Mustafa Bilgic", "title": "Hindsight Analysis of the Chicago Food Inspection Forecasting Model", "comments": "Presented at AAAI FSS-19: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Chicago Department of Public Health (CDPH) conducts routine food\ninspections of over 15,000 food establishments to ensure the health and safety\nof their patrons. In 2015, CDPH deployed a machine learning model to schedule\ninspections of establishments based on their likelihood to commit critical food\ncode violations. The City of Chicago released the training data and source code\nfor the model, allowing anyone to examine the model. We provide the first\nindependent analysis of the model, the data, the predictor variables, the\nperformance metrics, and the underlying assumptions. We present a summary of\nour findings, share lessons learned, and make recommendations to address some\nof the issues our analysis unearthed.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 23:15:37 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Kannan", "Vinesh", ""], ["Shapiro", "Matthew A.", ""], ["Bilgic", "Mustafa", ""]]}, {"id": "1910.05077", "submitter": "Peter Klimek", "authors": "Peter Klimek, Michael Gyimesi, Herwig Ostermann, Stefan Thurner", "title": "A parameter-free population-dynamical approach to health workforce\n  supply forecasting of EU countries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many countries face challenges like impending retirement waves, negative\npopulation growth, or a suboptimal distribution of resources across medical\nsectors and fields in supplying their healthcare systems with adequate\nstaffing. An increasing number of countries therefore employs quantitative\napproaches in health workforce supply forecasting. However, these models are\noften of limited usability as they either require extensive individual-level\ndata or become too simplistic to capture key demographic or epidemiological\nfactors. We propose a novel population-dynamical and stock-flow-consistent\napproach to health workforce supply forecasting complex enough to address\ndynamically changing behaviors while requiring only publicly available\ntimeseries data for complete calibration. We apply the model to 21 European\ncountries to forecast the supply of generalist and specialist physicians until\n2040. Compared to staffing levels required to keep the physician density\nconstant at 2016 levels, in many countries we find a significant trend toward\ndecreasing density for generalist physicians at the expense of increasing\ndensities for specialists. These trends are exacerbated in many Southern and\nEastern European countries by expectations of negative population growth. For\nthe example of Austria we generalize our approach to a multi-professional,\nmulti-regional and multi-sectoral model and find a suboptimal distribution in\nthe supply of contracted versus non-contracted physicians. It is of the utmost\nimportance to devise tools for decision makers to influence the allocation and\nsupply of physicians across fields and sectors to combat imbalances.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 11:02:40 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Klimek", "Peter", ""], ["Gyimesi", "Michael", ""], ["Ostermann", "Herwig", ""], ["Thurner", "Stefan", ""]]}, {"id": "1910.05265", "submitter": "Chris Norval", "authors": "Chris Norval, Tristan Henderson", "title": "Automating dynamic consent decisions for the processing of social media\n  data in health research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media have become a rich source of data, particularly in health\nresearch. Yet, the use of such data raises significant ethical questions about\nthe need for the informed consent of those being studied. Consent mechanisms,\nif even obtained, are typically broad and inflexible, or place a significant\nburden on the participant. Machine learning algorithms show much promise for\nfacilitating a 'middle ground' approach: using trained models to predict and\nautomate granular consent decisions. Such techniques, however, raise a myriad\nof follow-on ethical and technical considerations. In this paper, we present an\nexploratory user study (n = 67) in which we find that we can predict the\nappropriate flow of health-related social media data with reasonable accuracy,\nwhile minimising undesired data leaks. We then attempt to deconstruct the\nfindings of this study, identifying and discussing a number of real-world\nimplications if such a technique were put into practice.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 15:57:00 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Norval", "Chris", ""], ["Henderson", "Tristan", ""]]}, {"id": "1910.05327", "submitter": "Andreas Mallas Mr.", "authors": "Andreas Mallas and Michalis Xenos", "title": "Gamification of In-Classroom Diagram Design for Science Students", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Merging the content of learning with the motivation of games can be a\nsuccessful combination, if done properly and supported by the appropriate tool.\nTowards this goal, we developed Diagramatic an environment used to gamify the\nin-classroom activity of designing diagrams during a lecture. Using Diagramatic\nthe professor, instead of lecturing about diagrams or showing examples of such\ndiagrams, can design short games where the students could play by competing\nduring the lecture. Diagramatic is a complete environment offering to the\nprofessor a design application to create games and a management application.\nThe management application is used for monitoring the games while students\nplay, as well as to present the results to the students after the end of each\ngame, or to evaluate these results after classroom time. The students may use\nthe mobile application on their mobiles to practice by designing diagrams\noutside of the classroom, as well as to play a game during classroom time, but\nonly after the professor starts this game. The environment handles the\ncommunication from students' mobiles to the professor's applications and vice\nversa, while the students submit their diagrams or receive the correct ones, so\nto proceed to follow up games. The current version of Diagramatic is tailored\nfor designing flow graphs used for path testing into a higher education\nsoftware engineering course, but the environment can be used in any similar\ncase requiring the design of diagrams (e.g. math, physics, chemistry).\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 17:43:21 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Mallas", "Andreas", ""], ["Xenos", "Michalis", ""]]}, {"id": "1910.05441", "submitter": "Morteza Karimzadeh", "authors": "Morteza Karimzadeh, Luke S. Snyder, David S. Ebert", "title": "Geovisual Analytics and Interactive Machine Learning for Situational\n  Awareness", "comments": null, "journal-ref": null, "doi": null, "report-no": "2019 US National Report, International Cartographic Association", "categories": "cs.HC cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The first responder community has traditionally relied on calls from the\npublic, officially-provided geographic information and maps for coordinating\nactions on the ground. The ubiquity of social media platforms created an\nopportunity for near real-time sensing of the situation (e.g. unfolding weather\nevents or crises) through volunteered geographic information. In this article,\nwe provide an overview of the design process and features of the Social Media\nAnalytics Reporting Toolkit (SMART), a visual analytics platform developed at\nPurdue University for providing first responders with real-time situational\nawareness. We attribute its successful adoption by many first responders to its\nuser-centered design, interactive (geo)visualizations and interactive machine\nlearning, giving users control over analysis.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 23:33:55 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Karimzadeh", "Morteza", ""], ["Snyder", "Luke S.", ""], ["Ebert", "David S.", ""]]}, {"id": "1910.05470", "submitter": "Christopher Kempes", "authors": "Ryan C. Taylor, Xiaofan Liang, Manfred D. Laubichler, Geoffrey B.\n  West, Christopher P. Kempes and Marion Dumas", "title": "The Scalability, Efficiency and Complexity of Universities and Colleges:\n  A New Lens for Assessing the Higher Educational System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY physics.ed-ph physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing need for affordable and accessible higher education is a major\nglobal challenge for the 21st century. Consequently, there is a need to develop\na deeper understanding of the functionality and taxonomy of universities and\ncolleges and, in particular, how their various characteristics change with\nsize. Scaling has been a powerful tool for revealing systematic regularities in\nsystems across a range of topics from physics and biology to cities, and for\nunderstanding the underlying principles of their organization and growth. Here,\nwe apply this framework to institutions of higher learning in the United States\nand show that, like organisms, ecosystems and cities, they scale in a\nsurprisingly systematic fashion following simple power law behavior. We analyze\nthe entire spectrum encompassing 5,802 institutions ranging from large research\nuniversities to small professional schools, organized in seven commonly used\nsectors, which reveal distinct regimes of institutional scaling behavior.\nMetrics include variation in expenditures, revenues, graduation rates and\nestimated economic added value, expressed as functions of total enrollment, our\nfundamental measure of size. Our results quantify how each regime of\ninstitution leverages specific economies of scale to address distinct\npriorities. Taken together, the scaling of features within a sector and shifts\nin scaling across sectors implies that there are generic mechanisms and\nconstraints shared by all sectors which lead to tradeoffs between their\ndifferent societal functions and roles. We particularly highlight the strong\ncomplementarity between public and private research universities, and community\nand state colleges, four sectors that display superlinear returns to scale.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 03:00:17 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Taylor", "Ryan C.", ""], ["Liang", "Xiaofan", ""], ["Laubichler", "Manfred D.", ""], ["West", "Geoffrey B.", ""], ["Kempes", "Christopher P.", ""], ["Dumas", "Marion", ""]]}, {"id": "1910.05596", "submitter": "Carolina Mattsson", "authors": "Carolina Mattsson", "title": "Networks of monetary flow at native resolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People and companies move money with every financial transaction they make.\nWe aim to understand how such activity gives rise to large-scale patterns of\nmonetary flow. In this work, we trace the movement of e-money through the\naccounts of a mobile money system using the provider's own transaction records.\nThe resulting transaction sequences---balance-respecting trajectories---are\ndata objects that represent observed monetary flows. Common sequential motifs\ncorrespond to known use-cases of mobile money: digital payments, digital\ntransfers, and money storage. We find that each activity creates a distinct\nnetwork structure within the system, and we uncover coordinated gaming of the\nmobile money provider's commission schedule. Moreover, we find that e-money\npasses through the system in anywhere from minutes to months. This pronounced\nheterogeneity, even within the same use-case, can inform the modeling of\nturnover in money supply. Our methodology relates economic activity at the\ntransaction level to large-scale patterns of monetary flow, broadening the\nscope of empirical study about the network and temporal structure of the\neconomy.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 16:39:07 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Mattsson", "Carolina", ""]]}, {"id": "1910.05664", "submitter": "Yonadav Shavit", "authors": "Yonadav Shavit, William S. Moses", "title": "Extracting Incentives from Black-Box Decisions", "comments": "Accepted to the NeurIPS 2019 Workshop on Robust AI in Financial\n  Services: Data, Fairness, Explainability, Trustworthiness, and Privacy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An algorithmic decision-maker incentivizes people to act in certain ways to\nreceive better decisions. These incentives can dramatically influence subjects'\nbehaviors and lives, and it is important that both decision-makers and\ndecision-recipients have clarity on which actions are incentivized by the\nchosen model. While for linear functions, the changes a subject is incentivized\nto make may be clear, we prove that for many non-linear functions (e.g. neural\nnetworks, random forests), classical methods for interpreting the behavior of\nmodels (e.g. input gradients) provide poor advice to individuals on which\nactions they should take. In this work, we propose a mathematical framework for\nunderstanding algorithmic incentives as the challenge of solving a Markov\nDecision Process, where the state includes the set of input features, and the\nreward is a function of the model's output. We can then leverage the many\ntoolkits for solving MDPs (e.g. tree-based planning, reinforcement learning) to\nidentify the optimal actions each individual is incentivized to take to improve\ntheir decision under a given model. We demonstrate the utility of our method by\nestimating the maximally-incentivized actions in two real-world settings: a\nrecidivism risk predictor we train using ProPublica's COMPAS dataset, and an\nonline credit scoring tool published by the Fair Isaac Corporation (FICO).\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 01:17:29 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Shavit", "Yonadav", ""], ["Moses", "William S.", ""]]}, {"id": "1910.05794", "submitter": "Bertie Vidgen Dr", "authors": "Bertie Vidgen, Taha Yasseri, Helen Margetts", "title": "Islamophobes are not all the same! A study of far right actors on\n  Twitter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY physics.soc-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Far-right actors are often purveyors of Islamophobic hate speech online,\nusing social media to spread divisive and prejudiced messages which can stir up\nintergroup tensions and conflict. Hateful content can inflict harm on targeted\nvictims, create a sense of fear amongst communities and stir up intergroup\ntensions and conflict. Accordingly, there is a pressing need to better\nunderstand at a granular level how Islamophobia manifests online and who\nproduces it. We investigate the dynamics of Islamophobia amongst followers of a\nprominent UK far right political party on Twitter, the British National Party.\nAnalysing a new data set of five million tweets, collected over a period of one\nyear, using a machine learning classifier and latent Markov modelling, we\nidentify seven types of Islamophobic far right actors, capturing qualitative,\nquantitative and temporal differences in their behaviour. Notably, we show that\na small number of users are responsible for most of the Islamophobia that we\nobserve. We then discuss the policy implications of this typology in the\ncontext of social media regulation.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 17:39:00 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 07:18:10 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Vidgen", "Bertie", ""], ["Yasseri", "Taha", ""], ["Margetts", "Helen", ""]]}, {"id": "1910.05807", "submitter": "Pascal Van Hentenryck", "authors": "William Espinoza and Matthew Howard and Julia Lane and Pascal Van\n  Hentenryck", "title": "Shared E-scooters: Business, Pleasure, or Transit?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shared e-scooters have become a familiar sight in many cities around the\nworld. Yet the role they play in the mobility space is still poorly understood.\nThis paper presents a study of the use of Bird e-scooters in the city of\nAtlanta. Starting with raw data which contains the location of available Birds\nover time, the study identifies trips and leverages the Google Places API to\nassociate each trip origin and destination with a Point of Interest (POI). The\nresulting trip data is then used to understand the role of e-scooters in\nmobility by clustering trips using 10 collections of POIs, including business,\nfood and recreation, parking, transit, health, and residential. The trips\nbetween these POI clusters reveal some surprising, albeit sensible, findings\nabout the role of e-scooters in mobility, as well as the time of the day where\nthey are most popular.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 18:35:07 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Espinoza", "William", ""], ["Howard", "Matthew", ""], ["Lane", "Julia", ""], ["Van Hentenryck", "Pascal", ""]]}, {"id": "1910.06073", "submitter": "Giorgio F. Signorini", "authors": "Giorgio F. Signorini", "title": "Open Source and Sustainability: the Role of Universities", "comments": "first draft of a contribution for Symposium On Sustainability In\n  University Campuses (SSUC- 2018) Florence, Italy, December 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  One important goal in sustainability is making technologies available to the\nmaximum possible number of individuals, and especially to those living in less\ndeveloped areas (Goal 9 of SDG). However, the diffusion of technical knowledge\nis hindered by a number of factors, among which the Intellectual Property\nRights (IPR) system plays a primary role. While opinions about the real effect\nof IPRs in stimulating and disseminating innovation differ, there is a growing\nnumber of authors arguing that a different approach may be more effective in\npromoting global development. The success of the Open Source (OS) model in the\nfield of software has led analysts to speculate whether this paradigm can be\nextended to other fields. Key to this model are both free access to knowledge\nand the right to use other people's results.\n  Abstract After reviewing the main features of the OS model, we explore\ndifferent areas where it can be profitably applied, such as hardware design and\nproduction; we finally discuss how academical institutions can (and should)\nhelp diffusing the OS philosophy and practice. Widespread use of OS software,\nfostering of research projects aimed to use and develop OS software and\nhardware, the use of open education tools, and a strong commitment to open\naccess publishing are some of the discussed examples.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 10:27:23 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Signorini", "Giorgio F.", ""]]}, {"id": "1910.06075", "submitter": "Joshua Fadaie", "authors": "Joshua Fadaie", "title": "The State of Modeling, Simulation, and Data Utilization within Industry:\n  An Autonomous Vehicles Perspective", "comments": "arXiv admin note: text overlap with arXiv:1711.03938 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aviation industry has a market driven need to maintain and develop\nenhanced simulation capabilities for a wide range of application domains. In\nparticular, the future growth and disruptive ability of smart cities,\nautonomous vehicles and in general, urban mobility, hinges on the development\nof state of the art simulation tools and the intelligent utilization of data.\nWhile aviation based companies have several historical and/or proprietary\nmission level simulation tools, there is much to learn from the current state\nof the art within other industries (tangential and competing in scope), as well\nas in academia. The purpose of this paper is to address and decompose the\nsimulation capabilities within the key players of the autonomous vehicle and\nself-driving car industry (Toyota, Waymo, BMW, Microsoft, NVIDIA, Uber, etc.),\nas well as several notable startups within the high fidelity 3D mapping and\nsimulation domain (Mapper, HERE, Cognata, etc.). While providing an overview of\nhow other companies are using simulation tools and reliable data-sets, this\npaper will also seek to address several important and related questions,\nnamely: the interaction between simulation and supporting tools/software, the\nintersection of simulation and the real world, the requirements and utilization\nof compute infrastructure, the appropriate levels of fidelity within\nsimulation, and how simulation tools are critical to future safety and V&V\nconcerns. In order for aviation based companies to adequately pursue disruptive\nmobility within real-world environments, be it in air or on the ground,\nmodeling and simulation tools for autonomous vehicles provide key insights into\nfuture development work and are essential technologies.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 17:26:01 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Fadaie", "Joshua", ""]]}, {"id": "1910.06076", "submitter": "Vahid Garousi", "authors": "Ay\\c{c}a Koluk{\\i}sa Tarhan, Vahid Garousi, Oktay Turetken, Mehmet\n  S\\\"oylemez, Sonia Garossi", "title": "Maturity assessment and maturity models in healthcare: A multivocal\n  literature review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Context: Maturity of practices and infrastructure in healthcare domain\ndirectly impacts the quality and efficiency of healthcare services. Therefore,\nvarious healthcare administrations (e.g., hospital management to nation-wide\nhealth authority) need to assess and improve their operational maturity.\n  Objective: This study aims to review and classify studies that propose/use\nmaturity assessment or maturity models (MMs) as a vehicle to achieve\noperational excellence in healthcare domain.\n  Method: To achieve this objective, we performed a Multivocal Literature\nReview (MLR) that is a form of Systematic Review and includes data from the\ngrey literature (e.g., white papers and online documents) in addition to\nformal, peer-reviewed literature.\n  Results: Based on 101 sources, 80 of which are from the peer-reviewed\nliterature and 21 are from the grey literature, we identified 68 different MMs\non, e.g., telemedicine, care pathways, and digital imaging. We reviewed them\nwith respect to various aspects including: types of research and contribution;\nlist of MMs proposed/used with their subject focuses; elements of\nmaturity/capability; and application scope or scale. In the synthesis of\nempirical benefits of using MMs, two were found significant: (1) Identifying\nissues and providing guidance for improvement in healthcare contexts; (2)\nImproving efficiency, effectiveness, performance, and productivity.\n  Conclusion: This MLR provides an overview of the landscape and serves as an\nindex to the vast body of knowledge in this area. Our review creates an\nopportunity to cope with the challenges in getting an overview of the\nstate-of-the-art and practice, choosing the most suitable models, or developing\nnew models with further specialties.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 09:19:06 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Tarhan", "Ay\u00e7a Koluk\u0131sa", ""], ["Garousi", "Vahid", ""], ["Turetken", "Oktay", ""], ["S\u00f6ylemez", "Mehmet", ""], ["Garossi", "Sonia", ""]]}, {"id": "1910.06078", "submitter": "Fangli Xu", "authors": "Fangli Xu, Lingfei Wu, KP Thai, Carol Hsu, Wei Wang, Richard Tong", "title": "MUTLA: A Large-Scale Dataset for Multimodal Teaching and Learning\n  Analytics", "comments": "3 pages, 1 figure, 2 tables workshop paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic analysis of teacher and student interactions could be very\nimportant to improve the quality of teaching and student engagement. However,\ndespite some recent progress in utilizing multimodal data for teaching and\nlearning analytics, a thorough analysis of a rich multimodal dataset coming for\na complex real learning environment has yet to be done. To bridge this gap, we\npresent a large-scale MUlti-modal Teaching and Learning Analytics (MUTLA)\ndataset. This dataset includes time-synchronized multimodal data records of\nstudents (learning logs, videos, EEG brainwaves) as they work in various\nsubjects from Squirrel AI Learning System (SAIL) to solve problems of varying\ndifficulty levels. The dataset resources include user records from the learner\nrecords store of SAIL, brainwave data collected by EEG headset devices, and\nvideo data captured by web cameras while students worked in the SAIL products.\nOur hope is that by analyzing real-world student learning activities, facial\nexpressions, and brainwave patterns, researchers can better predict engagement,\nwhich can then be used to improve adaptive learning selection and student\nlearning outcomes. An additional goal is to provide a dataset gathered from\nreal-world educational activities versus those from controlled lab environments\nto benefit the educational learning community.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 03:53:49 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Xu", "Fangli", ""], ["Wu", "Lingfei", ""], ["Thai", "KP", ""], ["Hsu", "Carol", ""], ["Wang", "Wei", ""], ["Tong", "Richard", ""]]}, {"id": "1910.06080", "submitter": "Felipe Gonz\\'alez", "authors": "Felipe Gonz\\'alez, Claudia L\\'opez, Carlos Castro", "title": "Development of Computational Thinking in High School Students: A Case\n  Study in Chile", "comments": "in Spanish. 37th International Conference of the Chilean Computer\n  Science Society (SCCC)", "journal-ref": null, "doi": "10.1109/SCCC.2018.8705239", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most efforts to incorporate computational thinking in K-12 education have\nbeen focused on students in their first cycles of school education and have\nused visual tools, such as Scratch and Alice. Fewer research projects have\nstudied the development of computational thinking in students in their last\nyears of school, who usually have not had early formal preparation to acquire\nthese skills. This study provides evidence of the effectiveness of teaching\nprogramming in C++ (a low-level language) to develop computational thinking in\nhigh school students in Chile. By applying a test before and after a voluntary\nC ++ programming workshop, the results show a significant improvement in\ncomputational thinking at the end of the workshop. However, we also observed\nthat there was a tendency to drop out of the workshop among students with lower\nlevels of initial computational thinking. Tenth-grade students obtained lower\nfinal scores than eleventh and twelfth-grade students. These results indicate\nthat teaching a low-level programming language is useful, but it has high\nentry-barriers.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 01:23:03 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Gonz\u00e1lez", "Felipe", ""], ["L\u00f3pez", "Claudia", ""], ["Castro", "Carlos", ""]]}, {"id": "1910.06092", "submitter": "Sofia Terzi", "authors": "Sofia Terzi, Konstantinos Votis, Dimitrios Tzovaras, Ioannis Stamelos,\n  Kelly Cooper", "title": "Blockchain 3.0 Smart Contracts in E-Government 3.0 Applications", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The adoption of Information Communication Technologies (ICT) and Web 3.0\ncontributes to the e-government sector by transforming how public\nadministrations provide advanced and innovative services to interact with\ncitizens. Blockchain (BC) and Artificial Intelligence (AI) disruptive\ntechnologies will reshape how we live, work, and interact with government\nsectors and industries. This paper presents how Blockchain 3.0 and Artificial\nIntelligence enhance robust, secure, scalable, and authenticity provenance\nsolutions. Two validation scenarios are analyzed to present how blockchain\nsmart contracts and AI agents support energy and health-oriented e-government\nservices.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 07:10:20 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Terzi", "Sofia", ""], ["Votis", "Konstantinos", ""], ["Tzovaras", "Dimitrios", ""], ["Stamelos", "Ioannis", ""], ["Cooper", "Kelly", ""]]}, {"id": "1910.06109", "submitter": "Asif Imran", "authors": "Asif Imran, Tevfik Kosar", "title": "Software Sustainability: A Systematic Literature Review and\n  Comprehensive Analysis", "comments": "none", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software Engineering is a constantly evolving subject area that faces new\nchallenges every day as it tries to automate newer business processes. One of\nthe key challenges to the success of a software solution is attaining\nsustainability. The inability of numerous software to sustain for the desired\ntime-length is caused by limited consideration given towards sustainability\nduring the stages of software development. This review aims to present a\ndetailed and inclusive study covering both the technical and non-technical\nchallenges and approaches of software sustainability. A systematic and\ncomprehensive literature review was conducted based on 107 relevant studies\nthat were selected using the Evidence-Based Software Engineering (EBSE)\ntechnique. The study showed that sustainability can be achieved by conducting\nspecific activities at the technical and non-technical levels. The technical\nlevel consists of software design, coding, and user experience attributes. The\nnon-technical level consists of documentation, sustainability manifestos,\ntraining of software engineers, funding software projects, and leadership\nskills of project managers to achieve sustainability. This paper groups the\nexisting research efforts based on the above aspects. Next, how those aspects\naffect open and closed source software is tabulated. Based on the findings of\nthis review, it is seen that both technical and non-technical sustainability\naspects are equally important, taking one into contention and ignoring the\nother will threaten the sustenance of software products.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 00:54:13 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Imran", "Asif", ""], ["Kosar", "Tevfik", ""]]}, {"id": "1910.06115", "submitter": "Muhammad Aslam Jarwar", "authors": "Muhammad Aslam Jarwar, Sajjad Ali, Ilyoung Chong", "title": "Microservices based Linked Data Quality Model for Buildings Energy\n  Management Services", "comments": null, "journal-ref": "Proceedings of Symposium of the Korean Institute of communications\n  and Information Sciences , 2019.1, 640- 643", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  During the production, distribution, and consumption of energy, a large\nquantity of data is generated. For efficiently using of energy resources other\nsupplementary data such as building information, weather, and environmental\ndata etc. are also collected and used. All these energy data and relevant data\nis published as linked data in order to enhance the reusability of data and\nmaximization of energy management services capability. However, the quality of\nthis linked data is questionable because of wear and tears of sensors,\nunreliable communication channels, and highly diversification of data sources.\nThe provision of high-quality energy management services requires high quality\nlinked data, which reduces billing cost and improve the quality of the living\nenvironment. Assessment and improvement methodologies for the quality of data\nalong with linked data needs to process very diverse data from highly diverse\ndata sources. Microservices based data-driven architecture has great\nsignificance to processes highly diverse linked data with modularity,\nscalability, and reliability. This paper proposed microservices based\narchitecture along with domain data and metadata ontologies to enhance and\nassess energy-related linked data quality.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 14:09:03 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Jarwar", "Muhammad Aslam", ""], ["Ali", "Sajjad", ""], ["Chong", "Ilyoung", ""]]}, {"id": "1910.06136", "submitter": "Grace Lewis", "authors": "Grace A. Lewis, Stephany Bellomo, and April Galyardt", "title": "Component Mismatches Are a Critical Bottleneck to Fielding AI-Enabled\n  Systems in the Public Sector", "comments": "Presented at AAAI FSS-19: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The use of machine learning or artificial intelligence (ML/AI) holds\nsubstantial potential toward improving many functions and needs of the public\nsector. In practice however, integrating ML/AI components into public sector\napplications is severely limited not only by the fragility of these components\nand their algorithms, but also because of mismatches between components of\nML-enabled systems. For example, if an ML model is trained on data that is\ndifferent from data in the operational environment, field performance of the ML\ncomponent will be dramatically reduced. Separate from software engineering\nconsiderations, the expertise needed to field an ML/AI component within a\nsystem frequently comes from outside software engineering. As a result,\nassumptions and even descriptive language used by practitioners from these\ndifferent disciplines can exacerbate other challenges to integrating ML/AI\ncomponents into larger systems. We are investigating classes of mismatches in\nML/AI systems integration, to identify the implicit assumptions made by\npractitioners in different fields (data scientists, software engineers,\noperations staff) and find ways to communicate the appropriate information\nexplicitly. We will discuss a few categories of mismatch, and provide examples\nfrom each class. To enable ML/AI components to be fielded in a meaningful way,\nwe will need to understand the mismatches that exist and develop practices to\nmitigate the impacts of these mismatches.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 13:35:24 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Lewis", "Grace A.", ""], ["Bellomo", "Stephany", ""], ["Galyardt", "April", ""]]}, {"id": "1910.06144", "submitter": "Javier S\\'anchez-Monedero", "authors": "Javier Sanchez-Monedero, Lina Dencik and Lilian Edwards", "title": "What does it mean to solve the problem of discrimination in hiring?\n  Social, technical and legal perspectives from the UK on automated hiring\n  systems", "comments": "12 pages", "journal-ref": "Conference on Fairness, Accountability, and Transparency (FAT*\n  '20), January 27-30, 2020, Barcelona, Spain", "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ability to get and keep a job is a key aspect of participating in society\nand sustaining livelihoods. Yet the way decisions are made on who is eligible\nfor jobs, and why, are rapidly changing with the advent and growth in uptake of\nautomated hiring systems (AHSs) powered by data-driven tools. Key concerns\nabout such AHSs include the lack of transparency and potential limitation of\naccess to jobs for specific profiles. In relation to the latter, however,\nseveral of these AHSs claim to detect and mitigate discriminatory practices\nagainst protected groups and promote diversity and inclusion at work. Yet\nwhilst these tools have a growing user-base around the world, such claims of\nbias mitigation are rarely scrutinised and evaluated, and when done so, have\nalmost exclusively been from a US socio-legal perspective. In this paper, we\nintroduce a perspective outside the US by critically examining how three\nprominent automated hiring systems (AHSs) in regular use in the UK, HireVue,\nPymetrics and Applied, understand and attempt to mitigate bias and\ndiscrimination. Using publicly available documents, we describe how their tools\nare designed, validated and audited for bias, highlighting assumptions and\nlimitations, before situating these in the socio-legal context of the UK. The\nUK has a very different legal background to the US in terms not only of hiring\nand equality law, but also in terms of data protection (DP) law. We argue that\nthis might be important for addressing concerns about transparency and could\nmean a challenge to building bias mitigation into AHSs definitively capable of\nmeeting EU legal standards. This is significant as these AHSs, especially those\ndeveloped in the US, may obscure rather than improve systemic discrimination in\nthe workplace.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 10:56:43 GMT"}, {"version": "v2", "created": "Fri, 17 Jan 2020 11:29:18 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Sanchez-Monedero", "Javier", ""], ["Dencik", "Lina", ""], ["Edwards", "Lilian", ""]]}, {"id": "1910.06213", "submitter": "Felipe Gonz\\'alez", "authors": "Felipe Gonz\\'alez, Yihan Yu, Andrea Figueroa, Claudia L\\'opez, Cecilia\n  Aragon", "title": "Global Reactions to the Cambridge Analytica Scandal: An Inter-Language\n  Social Media Study", "comments": "2019 World Wide Web Conference (WWW '19 Companion)", "journal-ref": null, "doi": "10.1145/3308560.3316456", "report-no": null, "categories": "cs.IR cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Currently, there is a limited understanding of how data privacy concerns vary\nacross the world. The Cambridge Analytica scandal triggered a wide-ranging\ndiscussion on social media about user data collection and use practices. We\nconducted an inter-language study of this online conversation to compare how\npeople speaking different languages react to data privacy breaches. We\ncollected tweets about the scandal written in Spanish and English between April\nand July 2018. We used the Meaning Extraction Method in both datasets to\nidentify their main topics. They reveal a similar emphasis on Zuckerberg's\nhearing in the US Congress and the scandal's impact on political issues.\nHowever, our analysis also shows that while English speakers tend to attribute\nresponsibilities to companies, Spanish speakers are more likely to connect them\nto people. These findings show the potential of inter-language comparisons of\nsocial media data to deepen the understanding of cultural differences in data\nprivacy perspectives.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 15:38:00 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Gonz\u00e1lez", "Felipe", ""], ["Yu", "Yihan", ""], ["Figueroa", "Andrea", ""], ["L\u00f3pez", "Claudia", ""], ["Aragon", "Cecilia", ""]]}, {"id": "1910.06262", "submitter": "Yannis Assael", "authors": "Yannis Assael, Thea Sommerschield, Jonathan Prag", "title": "Restoring ancient text using deep learning: a case study on Greek\n  epigraphy", "comments": null, "journal-ref": "Empirical Methods in Natural Language Processing (EMNLP) 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ancient history relies on disciplines such as epigraphy, the study of ancient\ninscribed texts, for evidence of the recorded past. However, these texts,\n\"inscriptions\", are often damaged over the centuries, and illegible parts of\nthe text must be restored by specialists, known as epigraphists. This work\npresents Pythia, the first ancient text restoration model that recovers missing\ncharacters from a damaged text input using deep neural networks. Its\narchitecture is carefully designed to handle long-term context information, and\ndeal efficiently with missing or corrupted character and word representations.\nTo train it, we wrote a non-trivial pipeline to convert PHI, the largest\ndigital corpus of ancient Greek inscriptions, to machine actionable text, which\nwe call PHI-ML. On PHI-ML, Pythia's predictions achieve a 30.1% character error\nrate, compared to the 57.3% of human epigraphists. Moreover, in 73.5% of cases\nthe ground-truth sequence was among the Top-20 hypotheses of Pythia, which\neffectively demonstrates the impact of this assistive method on the field of\ndigital epigraphy, and sets the state-of-the-art in ancient text restoration.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 16:43:00 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Assael", "Yannis", ""], ["Sommerschield", "Thea", ""], ["Prag", "Jonathan", ""]]}, {"id": "1910.06380", "submitter": "Colin Ife", "authors": "Colin C. Ife, Toby Davies, Steven J. Murdoch, and Gianluca Stringhini", "title": "Bridging Information Security and Environmental Criminology Research to\n  Better Mitigate Cybercrime", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cybercrime is a complex phenomenon that spans both technical and human\naspects. As such, two disjoint areas have been studying the problem from\nseparate angles: the information security community and the environmental\ncriminology one. Despite the large body of work produced by these communities\nin the past years, the two research efforts have largely remained disjoint,\nwith researchers on one side not benefitting from the advancements proposed by\nthe other. In this paper, we argue that it would be beneficial for the\ninformation security community to look at the theories and systematic\nframeworks developed in environmental criminology to develop better mitigations\nagainst cybercrime. To this end, we provide an overview of the research from\nenvironmental criminology and how it has been applied to cybercrime. We then\nsurvey some of the research proposed in the information security domain,\ndrawing explicit parallels between the proposed mitigations and environmental\ncriminology theories, and presenting some examples of new mitigations against\ncybercrime. Finally, we discuss the concept of cyberplaces and propose a\nframework in order to define them. We discuss this as a potential research\ndirection, taking into account both fields of research, in the hope of\nbroadening interdisciplinary efforts in cybercrime research\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 18:53:40 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Ife", "Colin C.", ""], ["Davies", "Toby", ""], ["Murdoch", "Steven J.", ""], ["Stringhini", "Gianluca", ""]]}, {"id": "1910.06469", "submitter": "Sheikh Rabiul Islam", "authors": "Qian Chen, Sheikh Rabiul Islam, Henry Haswell, Robert A. Bridges", "title": "Automated Ransomware Behavior Analysis: Pattern Extraction and Early\n  Detection", "comments": "The 2nd International Conference on Science of Cyber Security -\n  SciSec 2019; Springer's Lecture Notes in Computer Science (LNCS) series", "journal-ref": null, "doi": "10.13140/RG.2.2.12785.84326", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security operation centers (SOCs) typically use a variety of tools to collect\nlarge volumes of host logs for detection and forensic of intrusions. Our\nexperience, supported by recent user studies on SOC operators, indicates that\noperators spend ample time (e.g., hundreds of man-hours) on investigations into\nlogs seeking adversarial actions. Similarly, reconfiguration of tools to adapt\ndetectors for future similar attacks is commonplace upon gaining novel insights\n(e.g., through internal investigation or shared indicators). This paper\npresents an automated malware pattern-extraction and early detection tool,\ntesting three machine learning approaches: TF-IDF (term frequency-inverse\ndocument frequency), Fisher's LDA (linear discriminant analysis) and ET (extra\ntrees/extremely randomized trees) that can (1) analyze freshly discovered\nmalware samples in sandboxes and generate dynamic analysis reports (host logs);\n(2) automatically extract the sequence of events induced by malware given a\nlarge volume of ambient (un-attacked) host logs, and the relatively few logs\nfrom hosts that are infected with potentially polymorphic malware; (3) rank the\nmost discriminating features (unique patterns) of malware and from the learned\nbehavior detect malicious activity; and (4) allows operators to visualize the\ndiscriminating features and their correlations to facilitate malware forensic\nefforts. To validate the accuracy and efficiency of our tool, we design three\nexperiments and test seven ransomware attacks (i.e., WannaCry, DBGer, Cerber,\nDefray, GandCrab, Locky, and nRansom). The experimental results show that\nTF-IDF is the best of the three methods to identify discriminating features,\nand ET is the most time-efficient and robust approach.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 01:01:51 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Chen", "Qian", ""], ["Islam", "Sheikh Rabiul", ""], ["Haswell", "Henry", ""], ["Bridges", "Robert A.", ""]]}, {"id": "1910.06484", "submitter": "Benjamin Adams", "authors": "Benjamin Adams", "title": "Spatial Data Science: Closing the human-spatial computing-environment\n  loop", "comments": "2 pages, Spatial Data Science Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Over the last decade, the term spatial computing has grown to have two\ndifferent, though not entirely unrelated, definitions. The first definition of\nspatial computing stems from industry, where it refers primarily to new kinds\nof augmented, virtual, mixed-reality, and natural user interface technologies.\nA second definition coming out of academia takes a broader perspective that\nincludes active research in geographic information science as well as the\naforementioned novel UI technologies. Both senses reflect an ongoing shift\ntoward increased interaction with computing interfaces and sensors embedded in\nthe environment and how the use of these technologies influence how we behave\nand make sense of and even change the world we live in. Regardless of the\ndefinition, research in spatial computing is humming along nicely without the\nneed to identify new research agendas or new labels for communities of\nresearchers. However, as a field of research, it could be helpful to view\nspatial data science as the glue that coheres spatial computing with\nproblem-solving and learning in the real world into a more holistic discipline.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 02:19:19 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Adams", "Benjamin", ""]]}, {"id": "1910.06949", "submitter": "Yue Yang", "authors": "Qiong Tian, Yue Yang, Jiaqi Wen, Fan Ding and Jing He", "title": "How to Eliminate Detour Behaviors in E-hailing? Real-time Detecting and\n  Time-dependent Pricing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of information and communication technology (ICT),\ntaxi business becomes a typical electronic commerce mode. However, one\ntraditional problem still exists in taxi service, that greedy taxi drivers may\ndeliberately take unnecessary detours to overcharge passengers. The detection\nof these fraudulent behaviors is essential to ensure high-quality taxi service.\nIn this paper, we propose a novel framework for detecting and analyzing the\ndetour behaviors both in off-line database and among on-line trips. Applying\nour framework to real-world taxi data-set, a remarkable performance (AUC\nsurpasses 0.98) has been achieved in off-line classification. Meanwhile, we\nfurther extend the off-line methods to on-line detection, a warning mechanism\nis introduced to remind drivers and an excellent precision (AUC surpasses 0.90)\nalso has arrived in this phases. After conducting extensive experiments to\nverify the relationships between pricing regulations and detour behaviors, some\nquantitative pricing suggestions, including rising base fare and reducing\ndistance-based fare rate, are provided to eliminate detour behaviors from the\nlong term.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 17:43:32 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 01:50:51 GMT"}, {"version": "v3", "created": "Wed, 22 Jan 2020 17:22:17 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Tian", "Qiong", ""], ["Yang", "Yue", ""], ["Wen", "Jiaqi", ""], ["Ding", "Fan", ""], ["He", "Jing", ""]]}, {"id": "1910.07045", "submitter": "Stephane Gaiffas Pr", "authors": "Emmanuel Bacry, St\\'ephane Ga\\\"iffas, Fanny Leroy, Maryan Morel, Dinh\n  Phong Nguyen, Youcef Sebiat, Dian Sun", "title": "SCALPEL3: a scalable open-source library for healthcare claims databases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article introduces SCALPEL3, a scalable open-source framework for\nstudies involving Large Observational Databases (LODs). Its design eases\nmedical observational studies thanks to abstractions allowing concept\nextraction, high-level cohort manipulation, and production of data formats\ncompatible with machine learning libraries. SCALPEL3 has successfully been used\non the SNDS database (see Tuppin et al. (2017)), a huge healthcare claims\ndatabase that handles the reimbursement of almost all French citizens.\n  SCALPEL3 focuses on scalability, easy interactive analysis and helpers for\ndata flow analysis to accelerate studies performed on LODs. It consists of\nthree open-source libraries based on Apache Spark. SCALPEL-Flattening allows\ndenormalization of the LOD (only SNDS for now) by joining tables sequentially\nin a big table. SCALPEL-Extraction provides fast concept extraction from a big\ntable such as the one produced by SCALPEL-Flattening. Finally, SCALPEL-Analysis\nallows interactive cohort manipulations, monitoring statistics of cohort flows\nand building datasets to be used with machine learning libraries. The first two\nprovide a Scala API while the last one provides a Python API that can be used\nin an interactive environment. Our code is available on GitHub.\n  SCALPEL3 allowed to extract successfully complex concepts for studies such as\nMorel et al (2017) or studies with 14.5 million patients observed over three\nyears (corresponding to more than 15 billion healthcare events and roughly 15\nTeraBytes of data) in less than 49 minutes on a small 15 nodes HDFS cluster.\nSCALPEL3 provides a sharp interactive control of data processing through\nlegible code, which helps to build studies with full reproducibility, leading\nto improved maintainability and audit of studies performed on LODs.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 20:36:08 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2020 17:01:48 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Bacry", "Emmanuel", ""], ["Ga\u00efffas", "St\u00e9phane", ""], ["Leroy", "Fanny", ""], ["Morel", "Maryan", ""], ["Nguyen", "Dinh Phong", ""], ["Sebiat", "Youcef", ""], ["Sun", "Dian", ""]]}, {"id": "1910.07083", "submitter": "Utku Kose", "authors": "Utku Kose", "title": "Occurence of A Cyber Security Eco-System: A Nature Oriented Project and\n  Evaluation of An Indirect Social Experiment", "comments": "International Scientific and Vocational Studies Congress -\n  Engineering 2019, pp. 505-513, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Because of todays technological developments and the influence of digital\nsystems into every aspect of our lives, importance of cyber security improves\nmore and more day-by-day. Projects, educational processes and seminars realized\nfor this aim create and improve awareness among individuals and provide useful\ntools for growing equipped generations. The aim of this study is to focus on a\ncyber security eco-system, which was self-occurred within the interactive\neducational environment designed under the scope of TUBITAK 4004 Nature\nEducation and Science Schools Projects (with the name of A Cyber Security\nAdventure) with the use of important technologies such as virtual reality,\naugmented reality, and artificial intelligence. The eco-system occurred within\nthe interactive educational process where high school students took place\ncaused both students and the project team to experience an indirect social\nexperiment environment. In this sense, it is thought that the findings and\ncomments presented in the study will give important ideas to everyone involved\nin cyber security education, life-long learning processes, and the technology\nuse in software oriented educational tools.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 22:04:19 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Kose", "Utku", ""]]}, {"id": "1910.07381", "submitter": "Irene-Angelica Chounta", "authors": "Irene-Angelica Chounta", "title": "Using learning analytics to provide personalized recommendations for\n  finding peers", "comments": "4 pages, 1 figure, conference, CollabTech", "journal-ref": null, "doi": "10.13140/RG.2.2.36616.78081", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work aims to propose a method to support students in finding appropriate\npeers in collaborative and blended learning settings. The main goal of this\nresearch is to bridge the gap between pedagogical theory and data driven\npractice to provide personalized and adaptive guidance to students who engage\nin computer supported learning activities. The research hypothesis is that we\ncan use Learning Analytics to model students' cognitive state and to assess\nwhether the student is in the Zone of Proximal Development. Based on this\nassessment, we can plan how to provide scaffolding based on the principles of\nContingent Tutoring and how to form study groups based on the principles of the\nZone of Proximal Development.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 14:40:27 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Chounta", "Irene-Angelica", ""]]}, {"id": "1910.07494", "submitter": "Amarnath Gupta", "authors": "Xiaohan Wu, Benjamin L. Liebman, Rachel E. Stern, Margaret E. Roberts\n  and Amarnath Gupta", "title": "On Constructing a Knowledge Base of Chinese Criminal Cases", "comments": "submitted to JURIX 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are developing a knowledge base over Chinese judicial decision documents\nto facilitate landscape analyses of Chinese Criminal Cases. We view judicial\ndecision documents as a mixed-granularity semi-structured text where different\nlevels of the text carry different semantic constructs and entailments. We use\na combination of context-sensitive grammar, dependency parsing and discourse\nanalysis to extract a formal and interpretable representation of these\ndocuments. Our knowledge base is developed by constructing associations between\ndifferent elements of these documents. The interpretability is contributed in\npart by our formal representation of the Chinese criminal laws, also as\nsemi-structured documents. The landscape analyses utilize these two\nrepresentations and enable a law researcher to ask legal pattern analysis\nqueries.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 01:23:04 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Wu", "Xiaohan", ""], ["Liebman", "Benjamin L.", ""], ["Stern", "Rachel E.", ""], ["Roberts", "Margaret E.", ""], ["Gupta", "Amarnath", ""]]}, {"id": "1910.07563", "submitter": "Alun Preece", "authors": "Alun Preece, Dave Braines, Federico Cerutti, Tien Pham", "title": "Explainable AI for Intelligence Augmentation in Multi-Domain Operations", "comments": "Presented at AAAI FSS-19: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Central to the concept of multi-domain operations (MDO) is the utilization of\nan intelligence, surveillance, and reconnaissance (ISR) network consisting of\noverlapping systems of remote and autonomous sensors, and human intelligence,\ndistributed among multiple partners. Realising this concept requires\nadvancement in both artificial intelligence (AI) for improved distributed data\nanalytics and intelligence augmentation (IA) for improved human-machine\ncognition. The contribution of this paper is threefold: (1) we map the\ncoalition situational understanding (CSU) concept to MDO ISR requirements,\npaying particular attention to the need for assured and explainable AI to allow\nrobust human-machine decision-making where assets are distributed among\nmultiple partners; (2) we present illustrative vignettes for AI and IA in MDO\nISR, including human-machine teaming, dense urban terrain analysis, and\nenhanced asset interoperability; (3) we appraise the state-of-the-art in\nexplainable AI in relation to the vignettes with a focus on human-machine\ncollaboration to achieve more rapid and agile coalition decision-making. The\nunion of these three elements is intended to show the potential value of a CSU\napproach in the context of MDO ISR, grounded in three distinct use cases,\nhighlighting how the need for explainability in the multi-partner coalition\nsetting is key.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 18:23:49 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Preece", "Alun", ""], ["Braines", "Dave", ""], ["Cerutti", "Federico", ""], ["Pham", "Tien", ""]]}, {"id": "1910.07581", "submitter": "Mayank Agrawal", "authors": "Mayank Agrawal, Joshua C. Peterson, Thomas L. Griffiths", "title": "Scaling up Psychology via Scientific Regret Minimization: A Case Study\n  in Moral Decisions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Do large datasets provide value to psychologists? Without a systematic\nmethodology for working with such datasets, there is a valid concern that\nanalyses will produce noise artifacts rather than true effects. In this paper,\nwe offer a way to enable researchers to systematically build models and\nidentify novel phenomena in large datasets. One traditional approach is to\nanalyze the residuals of models---the biggest errors they make in predicting\nthe data---to discover what might be missing from those models. However, once a\ndataset is sufficiently large, machine learning algorithms approximate the true\nunderlying function better than the data, suggesting instead that the\npredictions of these data-driven models should be used to guide model-building.\nWe call this approach \"Scientific Regret Minimization\" (SRM) as it focuses on\nminimizing errors for cases that we know should have been predictable. We\ndemonstrate this methodology on a subset of the Moral Machine dataset, a public\ncollection of roughly forty million moral decisions. Using SRM, we found that\nincorporating a set of deontological principles that capture dimensions along\nwhich groups of agents can vary (e.g. sex and age) improves a computational\nmodel of human moral judgment. Furthermore, we were able to identify and\nindependently validate three interesting moral phenomena: criminal\ndehumanization, age of responsibility, and asymmetric notions of\nresponsibility.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 19:25:06 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 00:13:23 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Agrawal", "Mayank", ""], ["Peterson", "Joshua C.", ""], ["Griffiths", "Thomas L.", ""]]}, {"id": "1910.07728", "submitter": "Shiwali Mohan", "authors": "Shiwali Mohan", "title": "Exploring the Role of Common Model of Cognition in Designing Adaptive\n  Coaching Interactions for Health Behavior Change", "comments": "Accepted for publication in the ACM Transactions on Interactive\n  Intelligent Systems - https://dl.acm.org/journal/tiis", "journal-ref": "ACM Transactions of Interactive Intelligent Syststems 11, 1,\n  Article 1 (April 2021), 30 pages", "doi": "10.1145/3375790", "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our research aims to develop intelligent collaborative agents that are\nhuman-aware - they can model, learn, and reason about their human partner's\nphysiological, cognitive, and affective states. In this paper, we study how\nadaptive coaching interactions can be designed to help people develop\nsustainable healthy behaviors. We leverage the common model of cognition - CMC\n[26] - as a framework for unifying several behavior change theories that are\nknown to be useful in human-human coaching. We motivate a set of interactive\nsystem desiderata based on the CMC-based view of behavior change. Then, we\npropose PARCoach - an interactive system that addresses the desiderata.\nPARCoach helps a trainee pick a relevant health goal, set an implementation\nintention, and track their behavior. During this process, the trainee\nidentifies a specific goal-directed behavior as well as the situational context\nin which they will perform it. PARCcoach uses this information to send\nnotifications to the trainee, reminding them of their chosen behavior and the\ncontext. We report the results from a 4-week deployment with 60 participants.\nOur results support the CMC-based view of behavior change and demonstrate that\nthe desiderata for proposed interactive system design is useful in producing\nbehavior change.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 06:18:37 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 20:23:14 GMT"}, {"version": "v3", "created": "Fri, 11 Sep 2020 00:40:35 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Mohan", "Shiwali", ""]]}, {"id": "1910.07775", "submitter": "Louis Abraham", "authors": "Louis Abraham and Dominique Gu\\'egan", "title": "The other side of the Coin: Risks of the Libra Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Libra was presented as a cryptocurrency on June 18, 2019 by Facebook. On the\nsame day, Facebook announced plans for Calibra, a subsidiary in charge of the\ndevelopment of an electronic wallet and financial services. In view of the\nprimary risk of sovereignty posed by the creation of Libra, regulators and\nCentral Banks quickly took very clear positions against the project and\nexpressed a lot of questions focusing on regulation aspects and national\nsovereignty.\n  The purpose of this paper is to provide a holistic analysis of the project\nencompassing several aspects of its implementation and the issues it raises. We\naddress a set of questions that are part of the cryptocurrency environment and\nblockchain technology that support the Libra project. We describe the\ngovernance of the project based on two levels, one for the Association and the\nother for the Libra Blockchain. We identify the main risks considering at the\nsame time political, financial, economic, technological and ethical risks. We\nemphasize the difficulty to regulate such a project as it will depend on\nseveral countries whose legislations are very different. Finally, the future of\nthis kind of projects is discussed through the emergence of Central Bank\nDigital Currencies.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 08:55:27 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 23:52:25 GMT"}, {"version": "v3", "created": "Fri, 24 Jan 2020 09:47:41 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Abraham", "Louis", ""], ["Gu\u00e9gan", "Dominique", ""]]}, {"id": "1910.07870", "submitter": "Kush Varshney", "authors": "Sanghamitra Dutta, Dennis Wei, Hazar Yueksel, Pin-Yu Chen, Sijia Liu,\n  Kush R. Varshney", "title": "Is There a Trade-Off Between Fairness and Accuracy? A Perspective Using\n  Mismatched Hypothesis Testing", "comments": "This paper appears in the Proceedings of the 37th International\n  Conference on Machine Learning, pp. 2803--2813, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A trade-off between accuracy and fairness is almost taken as a given in the\nexisting literature on fairness in machine learning. Yet, it is not preordained\nthat accuracy should decrease with increased fairness. Novel to this work, we\nexamine fair classification through the lens of mismatched hypothesis testing:\ntrying to find a classifier that distinguishes between two ideal distributions\nwhen given two mismatched distributions that are biased. Using Chernoff\ninformation, a tool in information theory, we theoretically demonstrate that,\ncontrary to popular belief, there always exist ideal distributions such that\noptimal fairness and accuracy (with respect to the ideal distributions) are\nachieved simultaneously: there is no trade-off. Moreover, the same classifier\nyields the lack of a trade-off with respect to ideal distributions while\nyielding a trade-off when accuracy is measured with respect to the given\n(possibly biased) dataset. To complement our main result, we formulate an\noptimization to find ideal distributions and derive fundamental limits to\nexplain why a trade-off exists on the given biased dataset. We also derive\nconditions under which active data collection can alleviate the\nfairness-accuracy trade-off in the real world. Our results lead us to contend\nthat it is problematic to measure accuracy with respect to data that reflects\nbias, and instead, we should be considering accuracy with respect to ideal,\nunbiased data.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 12:59:25 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 20:03:48 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Dutta", "Sanghamitra", ""], ["Wei", "Dennis", ""], ["Yueksel", "Hazar", ""], ["Chen", "Pin-Yu", ""], ["Liu", "Sijia", ""], ["Varshney", "Kush R.", ""]]}, {"id": "1910.08380", "submitter": "Charles Telles Roberto", "authors": "Charles Roberto Telles", "title": "Work sharing as a metric and productivity indicator for administrative\n  workflows", "comments": "21 pages, 1 table, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.AO cs.CY math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Defining administrative workflow events as a nonlinear dynamics that assume a\nrandom ordered or disordered growth rate of information processing, a method\nhas been proposed for large-scale administrative systems that structures hybrid\nsystem variables (continuous or discrete) as iterated and attracted to a\nfixed-point event at which for all possible metric spaces solutions, the\nmodeling of variables from Lyapunov exponential stability point of view allows\nthe projection of system performance to be oriented, that is, the relationship\nbetween the number of agents and the number of administrative services within\nan administrative workflow environment.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 17:34:30 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Telles", "Charles Roberto", ""]]}, {"id": "1910.08534", "submitter": "Vivian Lai", "authors": "Vivian Lai, Jon Z. Cai, Chenhao Tan", "title": "Many Faces of Feature Importance: Comparing Built-in and Post-hoc\n  Feature Importance in Text Classification", "comments": "17 pages, 18 figures, EMNLP 2019, the code is available at\n  https://vivlai.github.io/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature importance is commonly used to explain machine predictions. While\nfeature importance can be derived from a machine learning model with a variety\nof methods, the consistency of feature importance via different methods remains\nunderstudied. In this work, we systematically compare feature importance from\nbuilt-in mechanisms in a model such as attention values and post-hoc methods\nthat approximate model behavior such as LIME. Using text classification as a\ntestbed, we find that 1) no matter which method we use, important features from\ntraditional models such as SVM and XGBoost are more similar with each other,\nthan with deep learning models; 2) post-hoc methods tend to generate more\nsimilar important features for two models than built-in methods. We further\ndemonstrate how such similarity varies across instances. Notably, important\nfeatures do not always resemble each other better when two models agree on the\npredicted label than when they disagree.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 17:59:59 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Lai", "Vivian", ""], ["Cai", "Jon Z.", ""], ["Tan", "Chenhao", ""]]}, {"id": "1910.08604", "submitter": "Todd Davies", "authors": "John Gastil and Todd Davies", "title": "Digital Democracy: Episode IV -- A New Hope, How a Corporation for\n  Public Software Could Transform Digital Engagement for Government and Civil\n  Society", "comments": "17 pages, 1 figure, 2 tables, to appear in Digital Government:\n  Research and Practice (DGOV)", "journal-ref": "Digital Government: Research and Practice (DGOV), 1(1):Article 6,\n  February 2020", "doi": "10.1145/3342194", "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though successive generations of digital technology have become increasingly\npowerful in the past twenty years, digital democracy has yet to realize its\npotential for deliberative transformation. The undemocratic exploitation of\nmassive social media systems continued this trend, but it only worsened an\nexisting problem of modern democracies, which were already struggling to\ndevelop deliberative infrastructure independent of digital technologies. There\nhave been many creative conceptions of civic tech, but implementation has\nlagged behind innovation. This essay argues for implementing one such vision of\ndigital democracy through the establishment of a public corporation. Modeled on\nthe Corporation for Public Broadcasting in the U.S., this entity would foster\nthe creation of new digital technology by providing a stable source of funding\nto nonprofit technologists, interest groups, civic organizations, government,\nresearchers, private companies, and the public. Funded entities would produce\nand maintain software infrastructure for public benefit. The concluding\nsections identify what circumstances might create and sustain such an entity.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 19:52:07 GMT"}, {"version": "v2", "created": "Sun, 15 Dec 2019 03:44:40 GMT"}, {"version": "v3", "created": "Tue, 3 Mar 2020 22:45:46 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Gastil", "John", ""], ["Davies", "Todd", ""]]}, {"id": "1910.08734", "submitter": "Leye Wang", "authors": "Xiao Han, Ruiqing Ding, Leye Wang, Hailiang Huang", "title": "CreditPrint: Credit Investigation via Geographic Footprints by Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Credit investigation is critical for financial services. Whereas, traditional\nmethods are often restricted as the employed data hardly provide sufficient,\ntimely and reliable information. With the prevalence of smart mobile devices,\npeoples' geographic footprints can be automatically and constantly collected\nnowadays, which provides an unprecedented opportunity for credit\ninvestigations. Inspired by the observation that locations are somehow related\nto peoples' credit level, this research aims to enhance credit investigation\nwith users' geographic footprints. To this end, a two-stage credit\ninvestigation framework is designed, namely CreditPrint. In the first stage,\nCreditPrint explores regions' credit characteristics and learns a credit-aware\nembedding for each region by considering both each region's individual\ncharacteristics and cross-region relationships with graph convolutional\nnetworks. In the second stage, a hierarchical attention-based credit assessment\nnetwork is proposed to aggregate the credit indications from a user's multiple\ntrajectories covering diverse regions. The results on real-life user mobility\ndatasets show that CreditPrint can increase the credit investigation accuracy\nby up to 10% compared to baseline methods.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 09:48:50 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Han", "Xiao", ""], ["Ding", "Ruiqing", ""], ["Wang", "Leye", ""], ["Huang", "Hailiang", ""]]}, {"id": "1910.08854", "submitter": "Cristian Canton Ferrer", "authors": "Brian Dolhansky, Russ Howes, Ben Pflaum, Nicole Baram, Cristian Canton\n  Ferrer", "title": "The Deepfake Detection Challenge (DFDC) Preview Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a preview of the Deepfakes Detection Challenge\n(DFDC) dataset consisting of 5K videos featuring two facial modification\nalgorithms. A data collection campaign has been carried out where participating\nactors have entered into an agreement to the use and manipulation of their\nlikenesses in our creation of the dataset. Diversity in several axes (gender,\nskin-tone, age, etc.) has been considered and actors recorded videos with\narbitrary backgrounds thus bringing visual variability. Finally, a set of\nspecific metrics to evaluate the performance have been defined and two existing\nmodels for detecting deepfakes have been tested to provide a reference\nperformance baseline. The DFDC dataset preview can be downloaded at:\ndeepfakedetectionchallenge.ai\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 22:35:52 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 18:47:35 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Dolhansky", "Brian", ""], ["Howes", "Russ", ""], ["Pflaum", "Ben", ""], ["Baram", "Nicole", ""], ["Ferrer", "Cristian Canton", ""]]}, {"id": "1910.09104", "submitter": "Inas Khayal", "authors": "Inas S. Khayal and Amro M. Farid", "title": "A Dynamic System Model for Personalized Healthcare Delivery and Managed\n  Individual Health Outcomes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.CY cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current healthcare system is facing an unprecedented chronic disease\nburden. This paper develops a healthcare dynamic model for personalized\nhealthcare delivery and managed individual health outcomes. It utilizes a\nhetero-functional graph theory rooted in Axiomatic Design for Large Flexible\nEngineering Systems and Petri nets. The dynamics of the model builds upon a\nrecently developed systems architecture for healthcare delivery which bears\nseveral analogies to the architecture of mass-customized production systems. At\nits essence, the model consists of two synchronized Petri nets; one for the\nhealthcare delivery system and another for individuals' health state evolution.\nThe model is demonstrated on two clinical case studies; one acute and another\nchronic. Together, the case studies show that the model applies equally to the\ncare of both acute and chronic conditions, transparently describes health\noutcomes and links them to the evolution of the healthcare delivery system and\nits associated costs.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 13:23:11 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Khayal", "Inas S.", ""], ["Farid", "Amro M.", ""]]}, {"id": "1910.09156", "submitter": "Loo Kang Wee", "authors": "Francisco Esquembre, F\\'elix J. Garc\\'ia Clemente, Rafael Chic\\'on,\n  Lawrence Wee, Leong Tze Kwang and Darren Tan", "title": "Easy Java/JavaScript Simulations as a tool for Learning Analytics", "comments": "7 pages, 4 figures, conference paper Shih, J. L. et al. (Eds.)\n  (2019). Proceedings of the 27th International Conference on Computers in\n  Education. Taiwan: Asia-Pacific Society for Computers in Education", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ed-ph cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper we introduce the new and planned features of Easy\nJava/JavaScript Simulations (EJS) to support Learning Analytics (LA) and\nEducational Data Mining (EDM) research and practice in the use of simulations\nfor the teaching and self-learning of natural sciences and engineering.\nSimulations created with EJS can now be easily embedded in a popular Learning\nManagement System using a new plug-in that allows creation of full-fledged\ninstructional units that also collect and record fine-grained,\ninstructional-savvy data of the students interaction with the simulation. The\nresulting data can then be mined to obtain information about students\nperformance, behaviors, or learning procedures with the intention to support\nstudent learning, provide instructors with timely information about student\nperformance, and also help optimize the pedagogic design of the simulations\nthemselves. We describe the current development and architecture, as well as\nfuture directions for testing and extending the current capabilities of EJS as\na modelling and authoring tool to support LA and EDM research and practice in\nthe use of simulations for teaching science, in particular in the context of\nthe increasingly popular online learning platforms.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 05:36:14 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Esquembre", "Francisco", ""], ["Clemente", "F\u00e9lix J. Garc\u00eda", ""], ["Chic\u00f3n", "Rafael", ""], ["Wee", "Lawrence", ""], ["Kwang", "Leong Tze", ""], ["Tan", "Darren", ""]]}, {"id": "1910.09444", "submitter": "Paul Duckworth", "authors": "Wolfgang Fr\\\"uhwirt and Paul Duckworth", "title": "Towards better healthcare: What could and should be automated?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While artificial intelligence (AI) and other automation technologies might\nlead to enormous progress in healthcare, they may also have undesired\nconsequences for people working in the field. In this interdisciplinary study,\nwe capture empirical evidence of not only what healthcare work could be\nautomated, but also what should be automated. We quantitatively investigate\nthese research questions by utilizing probabilistic machine learning models\ntrained on thousands of ratings, provided by both healthcare practitioners and\nautomation experts. Based on our findings, we present an analytical tool\n(Automatability-Desirability Matrix) to support policymakers and organizational\nleaders in developing practical strategies on how to harness the positive power\nof automation technologies, while accompanying change and empowering\nstakeholders in a participatory fashion.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 15:23:39 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Fr\u00fchwirt", "Wolfgang", ""], ["Duckworth", "Paul", ""]]}, {"id": "1910.09563", "submitter": "Chenhao Tan", "authors": "Kumar Bhargav Srinivasan, Cristian Danescu-Niculescu-Mizil, Lillian\n  Lee, Chenhao Tan", "title": "Content Removal as a Moderation Strategy: Compliance and Other Outcomes\n  in the ChangeMyView Community", "comments": "21 pages, 8 figures, accepted at CSCW 2019, the dataset is available\n  at https://chenhaot.com/papers/content-removal.html", "journal-ref": null, "doi": "10.1145/3359265", "report-no": null, "categories": "cs.CY cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Moderators of online communities often employ comment deletion as a tool. We\nask here whether, beyond the positive effects of shielding a community from\nundesirable content, does comment removal actually cause the behavior of the\ncomment's author to improve? We examine this question in a particularly\nwell-moderated community, the ChangeMyView subreddit.\n  The standard analytic approach of interrupted time-series analysis\nunfortunately cannot answer this question of causality because it fails to\ndistinguish the effect of having made a non-compliant comment from the effect\nof being subjected to moderator removal of that comment. We therefore leverage\na \"delayed feedback\" approach based on the observation that some users may\nremain active between the time when they posted the non-compliant comment and\nthe time when that comment is deleted. Applying this approach to such users, we\nreveal the causal role of comment deletion in reducing immediate noncompliance\nrates, although we do not find evidence of it having a causal role in inducing\nother behavior improvements. Our work thus empirically demonstrates both the\npromise and some potential limits of content removal as a positive moderation\nstrategy, and points to future directions for identifying causal effects from\nobservational data.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 18:00:04 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Srinivasan", "Kumar Bhargav", ""], ["Danescu-Niculescu-Mizil", "Cristian", ""], ["Lee", "Lillian", ""], ["Tan", "Chenhao", ""]]}, {"id": "1910.09618", "submitter": "Zachary Schutzman", "authors": "Tara Abrishami, Nestor Guillen, Parker Rule, Zachary Schutzman, Justin\n  Solomon, Thomas Weighill, Si Wu", "title": "Geometry of Graph Partitions via Optimal Transport", "comments": "30 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CY cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a distance metric between partitions of a graph using machinery\nfrom optimal transport. Our metric is built from a linear assignment problem\nthat matches partition components, with assignment cost proportional to\ntransport distance over graph edges. We show that our distance can be computed\nusing a single linear program without precomputing pairwise assignment costs\nand derive several theoretical properties of the metric. Finally, we provide\nexperiments demonstrating these properties empirically, specifically focusing\non its value for new problems in ensemble-based analysis of political\ndistricting plans.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 19:27:26 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Abrishami", "Tara", ""], ["Guillen", "Nestor", ""], ["Rule", "Parker", ""], ["Schutzman", "Zachary", ""], ["Solomon", "Justin", ""], ["Weighill", "Thomas", ""], ["Wu", "Si", ""]]}, {"id": "1910.09700", "submitter": "Victor Schmidt", "authors": "Alexandre Lacoste, Alexandra Luccioni, Victor Schmidt, Thomas Dandres", "title": "Quantifying the Carbon Emissions of Machine Learning", "comments": "Machine Learning Emissions Calculator:\n  https://mlco2.github.io/impact/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  From an environmental standpoint, there are a few crucial aspects of training\na neural network that have a major impact on the quantity of carbon that it\nemits. These factors include: the location of the server used for training and\nthe energy grid that it uses, the length of the training procedure, and even\nthe make and model of hardware on which the training takes place. In order to\napproximate these emissions, we present our Machine Learning Emissions\nCalculator, a tool for our community to better understand the environmental\nimpact of training ML models. We accompany this tool with an explanation of the\nfactors cited above, as well as concrete actions that individual practitioners\nand organizations can take to mitigate their carbon emissions.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 23:57:32 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 20:37:33 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Lacoste", "Alexandre", ""], ["Luccioni", "Alexandra", ""], ["Schmidt", "Victor", ""], ["Dandres", "Thomas", ""]]}, {"id": "1910.09861", "submitter": "Wouter Groeneveld", "authors": "Wouter Groeneveld, Hans Jacobs, Joost Vennekens, Kris Aerts", "title": "Non-cognitive abilities of exceptional software engineers: a Delphi\n  study", "comments": "9 pages. This is a pre-print of a paper that has been accepted for\n  publication in SIGCSE, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Important building blocks of software engineering concepts are without a\ndoubt technical. During the last decade, research and practical interest for\nnon-technicalities has grown, revealing the building blocks to be various\nskills and abilities beside pure technical knowledge. Multiple attempts to\ncategorise these blocks have been made, but so far little international studies\nhave been performed that identify skills by asking experts from both the\nindustrial and academic world: which abilities are needed for a developer to\nexcel in the software engineering industry? To answer this question, we\nperformed a Delphi study, inviting 36 experts from 11 different countries\nworld-wide, affiliated with 21 internationally renowned institutions. This\nstudy presents the 55 identified and ranked skills as classified in four major\nareas: communicative skills (empathy, actively listening, etc.), collaborative\nskills (sharing responsibility, learning from each other, etc.), problem\nsolving skills (verifying assumptions, solution-oriented thinking, etc.), and\npersonal skills (curiosity, being open to ideas, etc.), of which a comparison\nhas been made between opinions of technical experts, business experts, and\nacademics. We hope this work inspires educators and practitioners to adjust\ntheir training programs, mitigating the gap between the industry and the\nacademic world.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 09:37:59 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Groeneveld", "Wouter", ""], ["Jacobs", "Hans", ""], ["Vennekens", "Joost", ""], ["Aerts", "Kris", ""]]}, {"id": "1910.09865", "submitter": "Wouter Groeneveld", "authors": "Wouter Groeneveld, Joost Vennekens, Kris Aerts", "title": "Software Engineering Education Beyond the Technical: A Systematic\n  Literature Review", "comments": "13 pages. Published in Proceedings of the 47th SEFI Conference 2019;\n  2019. (SEFI - European Society for Engineering Education; Brussels)", "journal-ref": "Proceedings of the 47th SEFI Conference (2019) 1607-1622", "doi": null, "report-no": null, "categories": "cs.SE cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Higher education provides a solid theoretical and practical, but mostly\ntechnical, background for the aspiring software developer. Research, however,\nhas shown that graduates still fall short of the expectations of industry.\nThese deficiencies are not limited to technical shortcomings. The ever changing\nlandscape of 'lean' enterprise software development requires engineers to be\nequipped with abilities beyond the technical. How can higher education help\nstudents become great software developers in this context? As a first step\ntowards answering this question, we present the results of a systematic\nliterature review, focusing on noncognitive abilities, better known as 'soft\nskills'. Our results identify self-reflection, conflict resolution,\ncommunication, and teamwork as the top four taught skills. Internships and\ncapstone projects require more attention as a teaching aspect to facilitate the\nlearning of multiple skills, including creativity. Interdisciplinary teaching\nand group composition are other important factors that influence learning. By\nproviding novel insights on relationships between noncognitive abilities and\nteaching aspects, this work contributes to the continuous improvement of\nsoftware engineering curricula. These findings may also serve as a springboard\nfor further investigation of certain undervalued skills.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 09:49:55 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Groeneveld", "Wouter", ""], ["Vennekens", "Joost", ""], ["Aerts", "Kris", ""]]}, {"id": "1910.09956", "submitter": "Charlotte Blease Dr", "authors": "Charlotte Blease, Cosima Locher, Marisa Leon-Carlyle, P. Murali\n  Doraiswamy", "title": "Artificial Intelligence and the Future of Psychiatry: Qualitative\n  Findings from a Global Physician Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The potential for machine learning to disrupt the medical profession is the\nsubject of ongoing debate within biomedical informatics. This study aimed to\nexplore psychiatrists' opinions about the potential impact of innovations in\nartificial intelligence and machine learning on psychiatric practice. In Spring\n2019, we conducted a web-based survey of 791 psychiatrists from 22 countries\nworldwide. The survey measured opinions about the likelihood future technology\nwould fully replace physicians in performing ten key psychiatric tasks. This\nstudy involved qualitative descriptive analysis of written response to three\nopen-ended questions in the survey. Comments were classified into four major\ncategories in relation to the impact of future technology on\npatient-psychiatric interactions, the quality of patient medical care, the\nprofession of psychiatry, and health systems. Overwhelmingly, psychiatrists\nwere skeptical that technology could fully replace human empathy. Many\npredicted that 'man and machine' would increasingly collaborate in undertaking\nclinical decisions, with mixed opinions about the benefits and harms of such an\narrangement. Participants were optimistic that technology might improve\nefficiencies and access to care, and reduce costs. Ethical and regulatory\nconsiderations received limited attention. This study presents timely\ninformation of psychiatrists' view about the scope of artificial intelligence\nand machine learning on psychiatric practice. Psychiatrists expressed divergent\nviews about the value and impact of future technology with worrying omissions\nabout practice guidelines, and ethical and regulatory issues.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 13:25:18 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Blease", "Charlotte", ""], ["Locher", "Cosima", ""], ["Leon-Carlyle", "Marisa", ""], ["Doraiswamy", "P. Murali", ""]]}, {"id": "1910.10241", "submitter": "Seng Loke", "authors": "Seng W. Loke", "title": "Achieving Ethical Algorithmic Behaviour in the Internet-of-Things: a\n  Review", "comments": "46 PAGES", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet-of-Things is emerging as a vast inter-connected space of devices\nand things surrounding people, many of which are increasingly capable of\nautonomous action, from automatically sending data to cloud servers for\nanalysis, changing the behaviour of smart objects, to changing the physical\nenvironment. A wide range of ethical concerns has arisen in their usage and\ndevelopment in recent years. Such concerns are exacerbated by the increasing\nautonomy given to connected things. This paper reviews, via examples, the\nlandscape of ethical issues, and some recent approaches to address these\nissues, concerning connected things behaving autonomously, as part of the\nInternet-of-Things. We consider ethical issues in relation to device operations\nand accompanying algorithms. Examples of concerns include unsecured consumer\ndevices, data collection with health related Internet-of-Things, hackable\nvehicles and behaviour of autonomous vehicles in dilemma situations,\naccountability with Internet-of-Things systems, algorithmic bias, uncontrolled\ncooperation among things, and automation affecting user choice and control.\nCurrent ideas towards addressing a range of ethical concerns are reviewed and\ncompared, including programming ethical behaviour, whitebox algorithms,\nblackbox validation, algorithmic social contracts, enveloping IoT systems, and\nguidelines and code of ethics for IoT developers - a suggestion from the\nanalysis is that a multi-pronged approach could be useful, based on the context\nof operation and deployment.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 21:34:19 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Loke", "Seng W.", ""]]}, {"id": "1910.10253", "submitter": "Seng Loke", "authors": "Seng W. Loke", "title": "Towards Robotic Things in Society", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging are so-called smart things embedded with computational, sensing,\nnetworking and actuation capabilities, from smart bins to smart park benches,\nas well as the proliferation of autonomous vehicles and robots in an\nincreasingly wide range of applications. This is not only an increased in\nautomation affecting and hopefully improving daily life, but also calls for\nthinking about what a society saturated with such robotic things (i.e., smart\nthings and robots) might look like. This paper discusses five aspects of a\nvision of Internet connected robotic things (or Internet of Robotic Things\n(IoRT)) occupying and operating in public spaces, from streets, parks to\nshopping malls. We discuss, highlighting issues, with the notion of an\nentourage of drones and robots accompanying people in public places, the idea\nof creating environments or envelopes suitable for robot function, the idea of\nsocieties of robotic things, and governance for robotic things in public\nspaces.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 22:17:17 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Loke", "Seng W.", ""]]}, {"id": "1910.10255", "submitter": "Hanchen Wang", "authors": "Hanchen Wang, Nina Grgic-Hlaca, Preethi Lahoti, Krishna P. Gummadi,\n  Adrian Weller", "title": "An Empirical Study on Learning Fairness Metrics for COMPAS Data with\n  Human Supervision", "comments": "Accepted at NeurIPS 2019 HCML Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The notion of individual fairness requires that similar people receive\nsimilar treatment. However, this is hard to achieve in practice since it is\ndifficult to specify the appropriate similarity metric. In this work, we\nattempt to learn such similarity metric from human annotated data. We gather a\nnew dataset of human judgments on a criminal recidivism prediction (COMPAS)\ntask. By assuming the human supervision obeys the principle of individual\nfairness, we leverage prior work on metric learning, evaluate the performance\nof several metric learning methods on our dataset, and show that the learned\nmetrics outperform the Euclidean and Precision metric under various criteria.\nWe do not provide a way to directly learn a similarity metric satisfying the\nindividual fairness, but to provide an empirical study on how to derive the\nsimilarity metric from human supervisors, then future work can use this as a\ntool to understand human supervision.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 22:22:59 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 14:47:27 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Wang", "Hanchen", ""], ["Grgic-Hlaca", "Nina", ""], ["Lahoti", "Preethi", ""], ["Gummadi", "Krishna P.", ""], ["Weller", "Adrian", ""]]}, {"id": "1910.10258", "submitter": "Seng Loke", "authors": "Seng W. Loke", "title": "Robot-Friendly Cities", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots are increasingly tested in public spaces, towards a future where urban\nenvironments are not only for humans but for autonomous systems. While robots\nare promising, for convenience and efficiency, there are challenges associated\nwith building cities crowded with machines. This paper provides an overview of\nthe problems and some solutions, and calls for greater attention on this\nmatter.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 22:28:25 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Loke", "Seng W.", ""]]}, {"id": "1910.10660", "submitter": "Nikola Milo\\v{s}evi\\'c Dr", "authors": "Nikola Milosevic, Junfan Huang", "title": "Deep learning guided Android malware and anomaly detection", "comments": "First (draft) version of the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the past decade, the cyber-crime related to mobile devices has increased.\nMobile devices, especially the ones running on Android operating system are\nparticularly interesting to malware creators, as the users often keep the\nbiggest amount of personal information on their mobile devices, such as their\ncontacts, social media profiles, emails, and bank accounts. Both dynamic and\nstatic malware analysis is necessary to prevent and detect malware, as both\ntechniques have their benefits and shortcomings. In this paper, we propose a\ndeep learning technique that relies on LSTM and encoder-decoder neural network\narchitectures for dynamic malware analysis based on CPU, memory and battery\nusage. The proposed system is able to detect and notify users about anomalies\nin system that is likely consequence of malware behaviour. The method was\nimplemented as a part of OWASP Seraphimdroids anti-malware mechanism and\nnotifies users about anomalies on their devices. The method proved to perform\nwith an F1-score of 79.2%.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 16:34:41 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Milosevic", "Nikola", ""], ["Huang", "Junfan", ""]]}, {"id": "1910.10749", "submitter": "Yisroel Mirsky Dr.", "authors": "Naor Kalbo, Yisroel Mirsky, Asaf Shabtai, Yuval Elovici", "title": "The Security of IP-based Video Surveillance Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IP-based Surveillance systems protect industrial facilities, railways, gas\nstations, and even one's own home. Therefore, unauthorized access to these\nsystems has serious security implications. In this survey, we analyze the\nsystem's (1) threat agents, (2) attack goals, (3) practical attacks, (4)\npossible attack outcomes, and (5) provide example attack vectors.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 18:13:37 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Kalbo", "Naor", ""], ["Mirsky", "Yisroel", ""], ["Shabtai", "Asaf", ""], ["Elovici", "Yuval", ""]]}, {"id": "1910.10758", "submitter": "Arijit Das", "authors": "Arijit Das, Jaydeep Mandal, Zargham Danial, Alok Ranjan Pal, Diganta\n  Saha", "title": "A Novel Approach for Automatic Bengali Question Answering System using\n  Semantic Similarity Analysis", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding the semantically accurate answer is one of the key challenges in\nadvanced searching. In contrast to keyword-based searching, the meaning of a\nquestion or query is important here and answers are ranked according to\nrelevance. It is very natural that there is almost no common word between the\nquestion sentence and the answer sentence. In this paper, an approach is\ndescribed to find out the semantically relevant answers in the Bengali dataset.\nIn the first part of the algorithm, a set of statistical parameters like\nfrequency, index, part-of-speech (POS), etc. is matched between a question and\nthe probable answers. In the second phase, entropy and similarity are\ncalculated in different modules. Finally, a sense score is generated to rank\nthe answers. The algorithm is tested on a repository containing a total of\n275000 sentences. This Bengali repository is a product of Technology\nDevelopment for Indian Languages (TDIL) project sponsored by Govt. of India and\nprovided by the Language Research Unit of Indian Statistical Institute,\nKolkata. The shallow parser, developed by the LTRC group of IIIT Hyderabad is\nused for POS tagging. The actual answer is ranked as 1st in 82.3% cases. The\nactual answer is ranked within 1st to 5th in 90.0% cases. The accuracy of the\nsystem is coming as 97.32% and precision of the system is coming as 98.14%\nusing confusion matrix. The challenges and pitfalls of the work are reported at\nlast in this paper.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 18:24:55 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Das", "Arijit", ""], ["Mandal", "Jaydeep", ""], ["Danial", "Zargham", ""], ["Pal", "Alok Ranjan", ""], ["Saha", "Diganta", ""]]}, {"id": "1910.10830", "submitter": "Moses Adah Agana", "authors": "Moses Adah Agana and Bassey Igbo Ele", "title": "A Strategic Cyber Crime and Security Awareness Information System using\n  a Dedicated Portal", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A real time portal (www.ganamoscybersecure.org) to enlighten people on how to\nprotect their data in the web, the strategies adopted by cyber criminals to\nsucceed in exploiting their victims as well as the mistakes made by people and\norganizations that make them prone to the menace of cyber crime has been\ndesigned in this paper. Critical observations were made over time on the degree\nof awareness and attitudes of people and organizations in some parts of South\nAfrica and Nigeria towards information security. Interviews were conducted\nusing structured questionnaire to elicit information. The outcome showed that\nmost individuals and organizations lack adequate awareness on strategies\nadopted by cyber criminals, and pay little attention to securing their online\ndata. The application of the services provided by the portal designed would be\na sine qua non for contending with the menace of cyber crime.act:\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 22:41:02 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Agana", "Moses Adah", ""], ["Ele", "Bassey Igbo", ""]]}, {"id": "1910.11027", "submitter": "Martin Comis", "authors": "Martin Comis, Catherine Cleophas, Christina B\\\"using", "title": "Patients, Primary Care, and Policy: Simulation Modeling for Health Care\n  Decision Support", "comments": "Modifications w.r.t. the previous version: corrected typos; fixed a\n  bug in SiM-Care implementation; revised Section 4 using the updated SiM-Care\n  implementation; extended Section 3.7.3 to clearify walk-in behavior; extended\n  Section 3.7.2 to clearify the process of arranging follow-up visits; authors\n  are no longer arranged alphabetically", "journal-ref": "Health Care Management Science 2021", "doi": "10.1007/s10729-021-09556-2", "report-no": null, "categories": "cs.MA cs.CY cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Demand for health care is constantly increasing due to the ongoing\ndemographic change, while at the same time health service providers face\ndifficulties in finding skilled personnel. This creates pressure on health care\nsystems around the world, such that the efficient, nationwide provision of\nprimary health care has become one of society's greatest challenges. Due to the\ncomplexity of health care systems, unforeseen future events, and a frequent\nlack of data, analyzing and optimizing the performance of health care systems\nmeans tackling a wicked problem. To support this task for primary care, this\npaper introduces the hybrid agent-based simulation model SiM-Care. SiM-Care\nmodels the interactions of patients and primary care physicians on an\nindividual level. By tracking agent interactions, it enables modelers to assess\nmultiple key indicators such as patient waiting times and physician\nutilization. Based on these indicators, primary care systems can be assessed\nand compared. Moreover, changes in the infrastructure, patient behavior, and\nservice design can be directly evaluated. To showcase the opportunities offered\nby SiM-Care and aid model validation, we present a case study for a primary\ncare system in Germany. Specifically, we investigate the effects of an aging\npopulation, a decrease in the number of physicians, as well as the combined\neffects.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 11:03:23 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 15:02:18 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Comis", "Martin", ""], ["Cleophas", "Catherine", ""], ["B\u00fcsing", "Christina", ""]]}, {"id": "1910.11208", "submitter": "Zhiwen Hu", "authors": "Zhiwen Hu, Chuhan Wu, Zhongliang Yang, Yongfeng Huang", "title": "Legends of Nature and Editors-in-chief", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This year marks the 150th celebration of Nature. However, the understanding\nof the way the army of unsung editors-in-chief has strengthened and enriched\nthe integrity and quality of the journal under the umbrella of its original\nmission remains nominal rather than substantial. This paper scrutinizes the\nchief vehicle guided by Nature's doctrine with regard to the ways it has\nconflicted with the advancement of both science and social progress. We first\nrecast quantitative spatiotemporal analysis on the diachronic discourse of\nNature since its debut, which promises to articulate the unfolding\nchronological picture of Nature on a historical time scale, and pinpoint\noverdue corrective to the strongly-held but flawed notions on editors-in-chief\nof Nature. Our findings strongly indicate that the army of editors-in-chief\nhave never met with their fair share of identification, and they took on the\nchallenge guided by Nature's doctrine with extraordinary polymath, unparalleled\nenthusiasm and diverse characters.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 15:11:39 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Hu", "Zhiwen", ""], ["Wu", "Chuhan", ""], ["Yang", "Zhongliang", ""], ["Huang", "Yongfeng", ""]]}, {"id": "1910.11452", "submitter": "Ananth Balashankar", "authors": "Ananth Balashankar, Alyssa Lees", "title": "Fairness Sample Complexity and the Case for Human Intervention", "comments": "Where is the Human? Bridging the Gap Between AI and HCI, CHI Workshop\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the aim of building machine learning systems that incorporate standards\nof fairness and accountability, we explore explicit subgroup sample complexity\nbounds. The work is motivated by the observation that classifier predictions\nfor real world datasets often demonstrate drastically different metrics, such\nas accuracy, when subdivided by specific sensitive variable subgroups. The\nreasons for these discrepancies are varied and not limited to the influence of\nmitigating variables, institutional bias, underlying population distributions\nas well as sampling bias. Among the numerous definitions of fairness that\nexist, we argue that at a minimum, principled ML practices should ensure that\nclassification predictions are able to mirror the underlying sub-population\ndistributions. However, as the number of sensitive variables increase,\npopulations meeting at the intersectionality of these variables may simply not\nexist or may not be large enough to provide accurate samples for\nclassification. In these increasingly likely scenarios, we make the case for\nhuman intervention and applying situational and individual definitions of\nfairness. In this paper we present lower bounds of subgroup sample complexity\nfor metric-fair learning based on the theory of Probably Approximately Metric\nFair Learning. We demonstrate that for a classifier to approach a definition of\nfairness in terms of specific sensitive variables, adequate subgroup population\nsamples need to exist and the model dimensionality has to be aligned with\nsubgroup population distributions. In cases where this is not feasible, we\npropose an approach using individual fairness definitions for achieving\nalignment. We look at two commonly explored UCI datasets under this lens and\nsuggest human interventions for data collection for specific subgroups to\nachieve approximate individual fairness for linear hypotheses.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 23:10:59 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Balashankar", "Ananth", ""], ["Lees", "Alyssa", ""]]}, {"id": "1910.11601", "submitter": "Christine Michel", "authors": "Elena Codreanu (GRePS, SICAL), Christine Michel (SICAL), Marc-Eric\n  Bobillier-Chaumon (GRePS), Olivier Vigneau (WSE)", "title": "Assessing the Adoption of Virtual Learning Environments in Primary\n  Schools: An Activity Oriented Study of Teacher's Acceptance", "comments": null, "journal-ref": "Computers Supported Education, CCIS 739, Springer International\n  Publishing, pp. 513-531, 2017, 8th International Conference CSEDU 2016\n  Revised Selected Papers, 978-3-319-63184-4", "doi": "10.1007/978-3-319-63184-4_27", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article studies the conditions of use of a VLE (Virtual Learning\nEnvironment) by primary school teachers. It first presents a triangulated model\nto explore Virtual Learning Environments' adoption in primary schools. The\ntheoretical models cover three approaches: the social acceptance, the practical\nacceptance and the situated acceptance. The situated acceptance of teachers is\nstudied according to the model by using activity theory and qualitative methods\n(individual and collective interviews). Our study describes how teachers (8\nparticipants) perceived the role of the VLE in the evolution of their working\npractices (maintaining, transforming or restricting existent practices), in\ntheir relationship with parents and in the follow-up of their students.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 10:00:25 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Codreanu", "Elena", "", "GRePS, SICAL"], ["Michel", "Christine", "", "SICAL"], ["Bobillier-Chaumon", "Marc-Eric", "", "GRePS"], ["Vigneau", "Olivier", "", "WSE"]]}, {"id": "1910.11800", "submitter": "Alessia Amelio Dr.", "authors": "Radmila Jankovi\\'c, Ivan Mihajlovi\\'c, Alessia Amelio", "title": "Time Series Vector Autoregression Prediction of the Ecological Footprint\n  based on Energy Parameters", "comments": "8 pages, 3 figures, accepted at 5th Jubilee Virtual International\n  Conference on Science, Technology and Management in Energy (eNergetics 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY cs.DM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sustainability became the most important component of world development, as\ncountries worldwide fight the battle against the climate change. To understand\nthe effects of climate change, the ecological footprint, along with the\nbiocapacity should be observed. The big part of the ecological footprint, the\ncarbon footprint, is most directly associated with the energy, and specifically\nfuel sources. This paper develops a time series vector autoregression\nprediction model of the ecological footprint based on energy parameters. The\nobjective of the paper is to forecast the EF based solely on energy parameters\nand determine the relationship between the energy and the EF. The dataset\nincluded global yearly observations of the variables for the period 1971-2014.\nPredictions were generated for every variable that was used in the model for\nthe period 2015-2024. The results indicate that the ecological footprint of\nconsumption will continue increasing, as well as the primary energy consumption\nfrom different sources. However, the energy consumption from coal sources is\npredicted to have a declining trend.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 15:30:40 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Jankovi\u0107", "Radmila", ""], ["Mihajlovi\u0107", "Ivan", ""], ["Amelio", "Alessia", ""]]}, {"id": "1910.11922", "submitter": "Chris Emmery", "authors": "Chris Emmery, Ben Verhoeven, Guy De Pauw, Gilles Jacobs, Cynthia Van\n  Hee, Els Lefever, Bart Desmet, V\\'eronique Hoste, Walter Daelemans", "title": "Current Limitations in Cyberbullying Detection: on Evaluation Criteria,\n  Reproducibility, and Data Scarcity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The detection of online cyberbullying has seen an increase in societal\nimportance, popularity in research, and available open data. Nevertheless,\nwhile computational power and affordability of resources continue to increase,\nthe access restrictions on high-quality data limit the applicability of\nstate-of-the-art techniques. Consequently, much of the recent research uses\nsmall, heterogeneous datasets, without a thorough evaluation of applicability.\nIn this paper, we further illustrate these issues, as we (i) evaluate many\npublicly available resources for this task and demonstrate difficulties with\ndata collection. These predominantly yield small datasets that fail to capture\nthe required complex social dynamics and impede direct comparison of progress.\nWe (ii) conduct an extensive set of experiments that indicate a general lack of\ncross-domain generalization of classifiers trained on these sources, and openly\nprovide this framework to replicate and extend our evaluation criteria.\nFinally, we (iii) present an effective crowdsourcing method: simulating\nreal-life bullying scenarios in a lab setting generates plausible data that can\nbe effectively used to enrich real data. This largely circumvents the\nrestrictions on data that can be collected, and increases classifier\nperformance. We believe these contributions can aid in improving the empirical\npractices of future research in the field.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 20:15:38 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Emmery", "Chris", ""], ["Verhoeven", "Ben", ""], ["De Pauw", "Guy", ""], ["Jacobs", "Gilles", ""], ["Van Hee", "Cynthia", ""], ["Lefever", "Els", ""], ["Desmet", "Bart", ""], ["Hoste", "V\u00e9ronique", ""], ["Daelemans", "Walter", ""]]}, {"id": "1910.11927", "submitter": "Ajay Shrestha", "authors": "Ajay Kumar Shrestha, Julita Vassileva", "title": "User Data Sharing Frameworks: A Blockchain-Based Incentive Solution", "comments": "7 pages, 4 figure, 1 table, IEEE IEMCON 2019 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.DB cs.GT cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, there is no universal method to track who shared what, with whom,\nwhen and for what purposes in a verifiable way to create an individual\nincentive for data owners. A platform that allows data owners to control,\ndelete, and get rewards from sharing their data would be an important enabler\nof user data-sharing. We propose a usable blockchain- and smart contracts-based\nframework that allows users to store research data locally and share without\nlosing control and ownership of it. We have created smart contracts for\nbuilding automatic verification of the conditions for data access that also\nnaturally supports building up a verifiable record of the provenance,\nincentives for users to share their data and accountability of access. The\npaper presents a review of the existing work of research data sharing, the\nproposed blockchain-based framework and an evaluation of the framework by\nmeasuring the transaction cost for smart contracts deployment. The results show\nthat nodes responded quickly in all tested cases with a befitting transaction\ncost.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 20:39:43 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Shrestha", "Ajay Kumar", ""], ["Vassileva", "Julita", ""]]}, {"id": "1910.12073", "submitter": "Jillian Tompkins", "authors": "Jillian Tompkins", "title": "Disinformation Detection: A review of linguistic feature selection and\n  classification models in news veracity assessments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past couple of years, the topic of \"fake news\" and its influence\nover people's opinions has become a growing cause for concern. Although the\nspread of disinformation on the Internet is not a new phenomenon, the\nwidespread use of social media has exacerbated its effects, providing more\nchannels for dissemination and the potential to \"go viral.\" Nowhere was this\nmore evident than during the 2016 United States Presidential Election. Although\nthe current of disinformation spread via trolls, bots, and hyperpartisan media\noutlets likely reinforced existing biases rather than sway undecided voters,\nthe effects of this deluge of disinformation are by no means trivial. The\nconsequences range in severity from an overall distrust in news media, to an\nill-informed citizenry, and in extreme cases, provocation of violent action. It\nis clear that human ability to discern lies from truth is flawed at best. As\nsuch, greater attention has been given towards applying machine learning\napproaches to detect deliberately deceptive news articles. This paper looks at\nthe work that has already been done in this area.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 14:29:37 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Tompkins", "Jillian", ""]]}, {"id": "1910.12235", "submitter": "Seyede Fatemeh Noorani", "authors": "Seyede Fatemeh Noorani, Mohammad Hossein Manshaei, Mohammad Ali\n  Montazeri, Behnaz Omoomi", "title": "Fostering Peer Learning through a New Game-Theoretical Approach in a\n  Blended Learning Environment", "comments": "36 pages, 7 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obtaining knowledge and skill achievement through peer learning can lead to\nhigher academic achievement. However, peer learning implementation is not just\nabout putting students together and hoping for the best. At its worst-designed,\npeer learning may result in one person doing all the effort for instance, or\nmay fail to encourage the students to interact enough with the task and so\nenhance the task in hand. This study proposes a mechanism as well as an\ninstructional design to foster well-organized peer learning based on game\ntheory $(PD\\_PL)$. The proposed mechanism uses prisoner's dilemma and maps the\nstrategy and payoff concepts found in prisoner's dilemma onto a peer learning\natmosphere. PD\\_PL was implemented during several sessions of four university\ncourses and with 142 computer engineering students. %The results of the\npre-test and post-test exams of all the sessions were compared with R software\nthrough Paired Hotelling's T-Square analysis in order to investigate the\nimpacts of $PD\\_PL$ and the proposed instructional design on students' personal\nlearning. The study results indicated that PD\\_PL was beneficial and favourable\nto the students.\n  Further analysis showed that the $PD\\_PL$ had sometimes even enhanced\nlearning by up to $47.2\\%$.\n  %The results of a subjective evaluation showed that the majority of\nrespondents found $PD\\_PL$ to be an attractive and efficient tool for learning\nenhancement. %Everybody who is interested in designing peer learning programs\nand tools will find this study interesting.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 11:01:47 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Noorani", "Seyede Fatemeh", ""], ["Manshaei", "Mohammad Hossein", ""], ["Montazeri", "Mohammad Ali", ""], ["Omoomi", "Behnaz", ""]]}, {"id": "1910.12244", "submitter": "Yazan Boshmaf", "authors": "Yazan Boshmaf, Charitha Elvitigala, Husam Al Jawaheri, Primal\n  Wijesekera, Mashael Al Sabah", "title": "Investigating MMM Ponzi scheme on Bitcoin", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cybercriminals exploit cryptocurrencies to carry out illicit activities. In\nthis paper, we focus on Ponzi schemes that operate on Bitcoin and perform an\nin-depth analysis of MMM, one of the oldest and most popular Ponzi schemes.\nBased on 423K transactions involving 16K addresses, we show that: (1) Starting\nSep 2014, the scheme goes through three phases over three years. At its peak,\nMMM circulated more than 150M dollars a day, after which it collapsed by the\nend of Jun 2016. (2) There is a high income inequality between MMM members,\nwith the daily Gini index reaching more than 0.9. The scheme also exhibits a\nzero-sum investment model, in which one member's loss is another member's gain.\nThe percentage of victims who never made any profit has grown from 0% to 41% in\nfive months, during which the top-earning scammer has made 765K dollars in\nprofit. (3) The scheme has a global reach with 80 different member countries\nbut a highly-asymmetrical flow of money between them. While India and Indonesia\nhave the largest pairwise flow in MMM, members in Indonesia have received 12x\nmore money than they have sent to their counterparts in India.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 11:38:38 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 10:20:30 GMT"}, {"version": "v3", "created": "Thu, 7 Nov 2019 05:44:54 GMT"}, {"version": "v4", "created": "Mon, 18 Nov 2019 06:10:23 GMT"}, {"version": "v5", "created": "Sun, 1 Dec 2019 10:38:32 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Boshmaf", "Yazan", ""], ["Elvitigala", "Charitha", ""], ["Jawaheri", "Husam Al", ""], ["Wijesekera", "Primal", ""], ["Sabah", "Mashael Al", ""]]}, {"id": "1910.12444", "submitter": "Sarah Preum", "authors": "Sarah Masud Preum, Kate Clark, Ashley Davis, Konstantine\n  Khutsishvilli, Rupa S Valdez", "title": "Information Seeking and Information Processing Behaviors Among Type 2\n  Diabetics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective patient education is critical for managing Type 2 Diabetes Mellitus\n(T2DM), one of the most common chronic diseases in the United States. While\nsome studies focus on the information-seeking behavior of T2DM patients, other\nself-education behaviors including information processing and utilization are\nrarely explored in the context of T2DM. This study sought to assess two\nself-education behaviors of type 2 diabetics, namely, information seeking and\ninformation processing, to understand more about how these behaviors affect the\nself-management of this common chronic disease. Semi-structured interviews were\nconducted with 8 English speaking T2DM patients and qualitative content\nanalysis techniques were performed to analyze their responses. The information\nseeking and processing behaviors vary across individuals based on their\nprognosis of T2DM, information needs, and personal preferences. Patients are\noften dissatisfied with information from official sources, have difficulty\nevaluating the trustworthiness of information sources, and desire information\nthat is more personally relevant to them. Several participants identified a\nlack of personalized information as a key factor in the inability to adhere to\nT2DM management guidelines, which led them to experience increased glucose\nlevels, difficulty managing A1C levels, frustration, and anxiety. They\nmentioned that they followed trial and error based approaches to tailor\ninformation according to their needs and physiological conditions. Many\nparticipants identified conflicting or inconsistent information from different\nsources as a major barrier to information processing. The results of this study\nindicate a need for authentic, consistent, and individualized information for\ntype 2 diabetics.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 04:59:10 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Preum", "Sarah Masud", ""], ["Clark", "Kate", ""], ["Davis", "Ashley", ""], ["Khutsishvilli", "Konstantine", ""], ["Valdez", "Rupa S", ""]]}, {"id": "1910.12577", "submitter": "Chunxi Tan", "authors": "Ruijian Han, Kani Chen and Chunxi Tan", "title": "Curiosity-Driven Recommendation Strategy for Adaptive Learning via Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of recommendations strategies in the adaptive learning system\nfocuses on utilizing currently available information to provide\nindividual-specific learning instructions for learners. As a critical motivate\nfor human behaviors, curiosity is essentially the drive to explore knowledge\nand seek information. In a psychologically inspired view, we aim to incorporate\nthe element of curiosity for guiding learners to study spontaneously. In this\npaper, a curiosity-driven recommendation policy is proposed under the\nreinforcement learning framework, allowing for a both efficient and enjoyable\npersonalized learning mode. Given intrinsic rewards from a well-designed\npredictive model, we apply the actor-critic method to approximate the policy\ndirectly through neural networks. Numeric analyses with a large continuous\nknowledge state space and concrete learning scenarios are used to further\ndemonstrate the power of the proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 02:59:16 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Han", "Ruijian", ""], ["Chen", "Kani", ""], ["Tan", "Chunxi", ""]]}, {"id": "1910.12579", "submitter": "Abhishek Dubey", "authors": "Scott Eisele and Taha Eghtesad and Keegan Campanelli and Prakhar\n  Agrawal and Aron Laszka and Abhishek Dubey", "title": "Safe and Private Forward-Trading Platform for Transactive Microgrids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.DC cs.MA cs.SY eess.SP eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transactive microgrids have emerged as a transformative solution for the\nproblems faced by distribution system operators due to an increase in the use\nof distributed energy resources and rapid growth in renewable energy\ngeneration. Transactive microgrids are tightly coupled cyber and physical\nsystems, which require resilient and robust financial markets where\ntransactions can be submitted and cleared, while ensuring that erroneous or\nmalicious transactions cannot destabilize the grid. In this paper, we introduce\nTRANSAX, a novel decentralized platform for transactive microgrids. TRANSAX\nenables participants to trade in an energy futures market, which improves\nefficiency by finding feasible matches for energy trades, reducing the load on\nthe distribution system operator. TRANSAX provides privacy to participants by\nanonymizing their trading activity using a distributed mixing service, while\nalso enforcing constraints that limit trading activity based on safety\nrequirements, such as keeping power flow below line capacity. We show that\nTRANSAX can satisfy the seemingly conflicting requirements of efficiency,\nsafety, and privacy, and we demonstrate its performance using simulation\nresults\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 21:13:18 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Eisele", "Scott", ""], ["Eghtesad", "Taha", ""], ["Campanelli", "Keegan", ""], ["Agrawal", "Prakhar", ""], ["Laszka", "Aron", ""], ["Dubey", "Abhishek", ""]]}, {"id": "1910.12580", "submitter": "Wanita Sherchan", "authors": "Wanita Sherchan, Simon Harris, Sue Ann Chen, Nebula Alam, Khoi-Nguyen\n  Tran, Adam J. Makarucha, Christopher J. Butler", "title": "Assessing Regulatory Risk in Personal Financial Advice Documents: a\n  Pilot Study", "comments": "Presented at AAAI FSS-19: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assessing regulatory compliance of personal financial advice is currently a\ncomplex manual process. In Australia, only 5%- 15% of advice documents are\naudited annually and 75% of these are found to be non-compliant(ASI 2018b).\nThis paper describes a pilot with an Australian government regulation agency\nwhere Artificial Intelligence (AI) models based on techniques such natural\nlanguage processing (NLP), machine learning and deep learning were developed to\nmethodically characterise the regulatory risk status of personal financial\nadvice documents. The solution provides traffic light rating of advice\ndocuments for various risk factors enabling comprehensive coverage of documents\nin the review and allowing rapid identification of documents that are at high\nrisk of non-compliance with government regulations. This pilot serves as a case\nstudy of public-private partnership in developing AI systems for government and\npublic sector.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 05:50:10 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Sherchan", "Wanita", ""], ["Harris", "Simon", ""], ["Chen", "Sue Ann", ""], ["Alam", "Nebula", ""], ["Tran", "Khoi-Nguyen", ""], ["Makarucha", "Adam J.", ""], ["Butler", "Christopher J.", ""]]}, {"id": "1910.12581", "submitter": "Hassan Khosravi", "authors": "Solmaz Abdi, Hassan Khosravi, Shazia Sadiq, Dragan Gasevic", "title": "A Multivariate Elo-based Learner Model for Adaptive Educational Systems", "comments": "Published in the Proceedings of the 12th International Conference on\n  Educational Data Mining", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Elo rating system has been recognised as an effective method for\nmodelling students and items within adaptive educational systems. The existing\nElo-based models have the limiting assumption that items are only tagged with a\nsingle concept and are mainly studied in the context of adaptive testing\nsystems. In this paper, we introduce a multivariate Elo-based learner model\nthat is suitable for the domains where learning items can be tagged with\nmultiple concepts, and investigate its fit in the context of adaptive learning.\nTo evaluate the model, we first compare the predictive performance of the\nproposed model against the standard Elo-based model using synthetic and public\ndata sets. Our results from this study indicate that our proposed model has\nsuperior predictive performance compared to the standard Elo-based model, but\nthe difference is rather small. We then investigate the fit of the proposed\nmultivariate Elo-based model by integrating it into an adaptive learning system\nwhich incorporates the principles of open learner models (OLMs). The results\nfrom this study suggest that the availability of additional parameters derived\nfrom multivariate Elo-based models have two further advantages: guiding\nadaptive behaviour for the system and providing additional insight for students\nand instructors.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 02:47:44 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Abdi", "Solmaz", ""], ["Khosravi", "Hassan", ""], ["Sadiq", "Shazia", ""], ["Gasevic", "Dragan", ""]]}, {"id": "1910.12582", "submitter": "Padmanabhan Santhanam", "authors": "P. Santhanam, Eitan Farchi and Victor Pankratius", "title": "Engineering Reliable Deep Learning Systems", "comments": "Presented at AAAI FSS-19: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in artificial intelligence (AI) using deep learning\ntechniques has triggered its wide-scale use across a broad range of\napplications. These systems can already perform tasks such as natural language\nprocessing of voice and text, visual recognition, question-answering,\nrecommendations and decision support. However, at the current level of\nmaturity, the use of an AI component in mission-critical or safety-critical\napplications can have unexpected consequences. Consequently, serious concerns\nabout reliability, repeatability, trust, and maintainability of AI applications\nremain. As AI becomes pervasive despite its shortcomings, more systematic ways\nof approaching AI software development and certification are needed. These\nfundamental aspects establish the need for a discipline on \"AI Engineering\".\nThis paper presents the current perspective of relevant AI engineering concepts\nand some key challenges that need to be overcome to make significant progress\nin this important area.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 15:13:45 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Santhanam", "P.", ""], ["Farchi", "Eitan", ""], ["Pankratius", "Victor", ""]]}, {"id": "1910.12583", "submitter": "Miguel Luengo-Oroz", "authors": "Miguel Luengo-Oroz", "title": "Solidarity should be a core ethical principle of Artificial Intelligence", "comments": "This is a pre-print of an article published in Nature Machine\n  Intelligence. The final authenticated version is available online at:\n  https://doi.org/10.1038/s42256-019-0115-3", "journal-ref": "Nature Machine Intelligence, 1-11 (2019)", "doi": "10.1038/s42256-019-0115-3", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solidarity is one of the fundamental values at the heart of the construction\nof peaceful societies and present in more than one third of world's\nconstitutions. Still, solidarity is almost never included as a principle in\nethical guidelines for the development of AI. Solidarity as an AI principle (1)\nshares the prosperity created by AI, implementing mechanisms to redistribute\nthe augmentation of productivity for all; and shares the burdens, making sure\nthat AI does not increase inequality and no human is left behind. Solidarity as\nan AI principle (2) assesses the long term implications before developing and\ndeploying AI systems so no groups of humans become irrelevant because of AI\nsystems. Considering solidarity as a core principle for AI development will\nprovide not just an human-centric but a more humanity-centric approach to AI.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 15:21:42 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Luengo-Oroz", "Miguel", ""]]}, {"id": "1910.12586", "submitter": "Yongkai Wu", "authors": "Yongkai Wu, Lu Zhang, Xintao Wu, Hanghang Tong", "title": "PC-Fairness: A Unified Framework for Measuring Causality-based Fairness", "comments": "Accepted as a poster to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent trend of fair machine learning is to define fairness as\ncausality-based notions which concern the causal connection between protected\nattributes and decisions. However, one common challenge of all causality-based\nfairness notions is identifiability, i.e., whether they can be uniquely\nmeasured from observational data, which is a critical barrier to applying these\nnotions to real-world situations. In this paper, we develop a framework for\nmeasuring different causality-based fairness. We propose a unified definition\nthat covers most of previous causality-based fairness notions, namely the\npath-specific counterfactual fairness (PC fairness). Based on that, we propose\na general method in the form of a constrained optimization problem for bounding\nthe path-specific counterfactual fairness under all unidentifiable situations.\nExperiments on synthetic and real-world datasets show the correctness and\neffectiveness of our method.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 23:00:53 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Wu", "Yongkai", ""], ["Zhang", "Lu", ""], ["Wu", "Xintao", ""], ["Tong", "Hanghang", ""]]}, {"id": "1910.12591", "submitter": "David Solans", "authors": "David Solans, Christopher Tauchmann, Aideen Farrell, Karolin Kappler,\n  Hans-Hendrik Huber, Carlos Castillo, Kristian Kersting", "title": "Conflict and Cooperation: AI Research and Development in terms of the\n  Economy of Conventions", "comments": "Accepted at ICWSM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) and its relation with societies is increasingly\nbecoming an interesting object of study from the perspective of sociology and\nother disciplines. Theories such as the Economy of Conventions (EC) are usually\napplied in the context of interpersonal relations but there is still a clear\nlack of studies around how this and other theories can shed light on\ninteractions between human an autonomous systems. This work is focused into\nstudying a preliminary step that is a key enabler for the subsequent\ninteraction between machines and humans: how the processes of researching,\ndesigning and developing AI related systems reflect different moral registers,\nrepresented by conventions within the EC. Having a better understanding of\nthose conventions guiding the advances in AI is considered as the first and\nrequired advance to understand the conventions afterwards reflected by those\nautonomous systems in the interactions with societies. For this purpose, we\ndevelop an iterative tool based on active learning to label a data set from the\nfield of AI and Machine Learning (ML) research and present preliminary results\nof a supervised classifier trained on these conventions. To further demonstrate\nthe feasibility of the approach, the results are contrasted with a classifier\ntrained on software conventions.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 19:38:12 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 19:25:28 GMT"}, {"version": "v3", "created": "Thu, 5 Dec 2019 08:15:24 GMT"}, {"version": "v4", "created": "Tue, 1 Sep 2020 11:40:25 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Solans", "David", ""], ["Tauchmann", "Christopher", ""], ["Farrell", "Aideen", ""], ["Kappler", "Karolin", ""], ["Huber", "Hans-Hendrik", ""], ["Castillo", "Carlos", ""], ["Kersting", "Kristian", ""]]}, {"id": "1910.12596", "submitter": "Diego Saez-Trumper", "authors": "Diego Saez-Trumper", "title": "Online Disinformation and the Role of Wikipedia", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this study is to find key areas of research that can be useful to\nfight against disinformation on Wikipedia. To address this problem we perform a\nliterature review trying to answer three main questions: (i) What is\ndisinformation? (ii) What are the most popular mechanisms to spread online\ndisinformation? and (iii) Which are the mechanisms that are currently being\nused to fight against disinformation?. In all these three questions we take\nfirst a general approach, considering studies from different areas such as\njournalism and communications, sociology, philosophy, information and political\nsciences. And comparing those studies with the current situation on the\nWikipedia ecosystem. We conclude that in order to keep Wikipedia as free as\npossible from disinformation, it is necessary to help patrollers to early\ndetect disinformation and assess the credibility of external sources. More\nresearch is needed to develop tools that use state-of-the-art machine learning\ntechniques to detect potentially dangerous content, empowering patrollers to\ndeal with attacks that are becoming more complex and sophisticated.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 19:58:15 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Saez-Trumper", "Diego", ""]]}, {"id": "1910.12597", "submitter": "Richard Scruggs", "authors": "Richard Scruggs, Ryan S. Baker, Bruce M. McLaren", "title": "Extending Deep Knowledge Tracing: Inferring Interpretable Knowledge and\n  Predicting Post-System Performance", "comments": "8 pages, accepted to the International Conference on Computers in\n  Education", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent student knowledge modeling algorithms such as Deep Knowledge Tracing\n(DKT) and Dynamic Key-Value Memory Networks (DKVMN) have been shown to produce\naccurate predictions of problem correctness within the same learning system.\nHowever, these algorithms do not attempt to directly infer student knowledge.\nIn this paper we present an extension to these algorithms to also infer\nknowledge. We apply this extension to DKT and DKVMN, resulting in knowledge\nestimates that correlate better with a posttest than knowledge estimates from\nBayesian Knowledge Tracing (BKT), an algorithm designed to infer knowledge, and\nanother classic algorithm, Performance Factors Analysis (PFA). We also apply\nour extension to correctness predictions from BKT and PFA, finding that\nknowledge estimates produced with it correlate better with the posttest than\nBKT and PFA's standard knowledge estimates. These findings are significant\nsince the primary aim of education is to prepare students for later experiences\noutside of the immediate learning activity.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 14:21:20 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2020 19:33:54 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Scruggs", "Richard", ""], ["Baker", "Ryan S.", ""], ["McLaren", "Bruce M.", ""]]}, {"id": "1910.12601", "submitter": "Meixin Zhu", "authors": "Meixin Zhu, Jingyun Hu, Hao (Frank) Yang, Ziyuan Pu, and Yinhai Wang", "title": "Personalized Context-Aware Multi-Modal Transportation Recommendation", "comments": "KDD cup 2019 regular machine track solution", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study proposes to find the most appropriate transport modes with\nawareness of user preferences (e.g., costs, times) and trip characteristics\n(e.g., purpose, distance). The work was based on real-life trips obtained from\na map application. Several methods including gradient boosting tree, learning\nto rank, multinomial logit model, automated machine learning, random forest,\nand shallow neural network have been tried. For some methods, feature selection\nand over-sampling techniques were also tried. The results show that the best\nperforming method is a gradient boosting tree model with synthetic minority\nover-sampling technique (SMOTE). Also, results of the multinomial logit model\nshow that (1) an increase in travel cost would decrease the utility of all the\ntransportation modes; (2) people are less sensitive to the travel distance for\nthe metro mode or a multi-modal option that containing metro, i.e., compared to\nother modes, people would be more willing to tolerate long-distance metro\ntrips. This indicates that metro lines might be a good candidate for large\ncities.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 20:16:13 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Zhu", "Meixin", "", "Frank"], ["Hu", "Jingyun", "", "Frank"], ["Hao", "", "", "Frank"], ["Yang", "", ""], ["Pu", "Ziyuan", ""], ["Wang", "Yinhai", ""]]}, {"id": "1910.12603", "submitter": "Jonathan Passerat-Palmbach", "authors": "Jonathan Passerat-Palmbach and Tyler Farnan and Robert Miller and\n  Marielle S. Gross and Heather Leigh Flannery and Bill Gleim", "title": "A blockchain-orchestrated Federated Learning architecture for healthcare\n  consortia", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose a novel architecture for federated learning within healthcare\nconsortia. At the heart of the solution is a unique integration of privacy\npreserving technologies, built upon native enterprise blockchain components\navailable in the Ethereum ecosystem. We show how the specific characteristics\nand challenges of healthcare consortia informed our design choices, notably the\nconception of a new Secure Aggregation protocol assembled with a protected\nhardware component and an encryption toolkit native to Ethereum. Our\narchitecture also brings in a privacy preserving audit trail that logs events\nin the network without revealing identities.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 16:44:05 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Passerat-Palmbach", "Jonathan", ""], ["Farnan", "Tyler", ""], ["Miller", "Robert", ""], ["Gross", "Marielle S.", ""], ["Flannery", "Heather Leigh", ""], ["Gleim", "Bill", ""]]}, {"id": "1910.12611", "submitter": "Shaoxiong Ji", "authors": "Shaoxiong Ji and Shirui Pan and Xue Li and Erik Cambria and Guodong\n  Long and Zi Huang", "title": "Suicidal Ideation Detection: A Review of Machine Learning Methods and\n  Applications", "comments": "IEEE Transactions on Computational Social Systems", "journal-ref": "IEEE Transactions on Computational Social Systems, 8(1), 2021, pp.\n  214-226", "doi": "10.1109/TCSS.2020.3021467", "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suicide is a critical issue in modern society. Early detection and prevention\nof suicide attempts should be addressed to save people's life. Current suicidal\nideation detection methods include clinical methods based on the interaction\nbetween social workers or experts and the targeted individuals and machine\nlearning techniques with feature engineering or deep learning for automatic\ndetection based on online social contents. This paper is the first survey that\ncomprehensively introduces and discusses the methods from these categories.\nDomain-specific applications of suicidal ideation detection are reviewed\naccording to their data sources, i.e., questionnaires, electronic health\nrecords, suicide notes, and online user content. Several specific tasks and\ndatasets are introduced and summarized to facilitate further research. Finally,\nwe summarize the limitations of current work and provide an outlook of further\nresearch directions.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 02:10:42 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 11:04:42 GMT"}, {"version": "v3", "created": "Tue, 1 Sep 2020 09:49:48 GMT"}, {"version": "v4", "created": "Sun, 6 Sep 2020 06:12:03 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Ji", "Shaoxiong", ""], ["Pan", "Shirui", ""], ["Li", "Xue", ""], ["Cambria", "Erik", ""], ["Long", "Guodong", ""], ["Huang", "Zi", ""]]}, {"id": "1910.12617", "submitter": "Maria Spichkova", "authors": "Maria Spichkova, Johan van Zyl, Siddharth Sachdev, Ashish Bhardwaj,\n  Nirav Desai", "title": "Easy Mobile Meter Reading for Non-Smart Meters: Comparison of AWS\n  Rekognition and Google Cloud Vision Approaches", "comments": "Preprint. Accepted to the 14th International Conference on Evaluation\n  of Novel Approaches to Software Engineering (ENASE 2019). Final version\n  published by SCITEPRESS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electricity and gas meter reading is a time consuming task, which is done\nmanually in most cases. There are some approaches proposing use of smart meters\nthat report their readings automatically. However, this solution is expensive\nand requires (1) replacement of the existing meters, even when they are\nfunctional and new, and (2) large changes of the whole system dealing with the\nmeter readings. This paper presents results of a project on automation of the\nmeter reading process for the standard (non-smart) meters using computer vision\ntechniques, focusing on the comparison of two computer vision techniques,\nGoogle Cloud Vision and AWS Rekognition.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 03:22:20 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Spichkova", "Maria", ""], ["van Zyl", "Johan", ""], ["Sachdev", "Siddharth", ""], ["Bhardwaj", "Ashish", ""], ["Desai", "Nirav", ""]]}, {"id": "1910.12695", "submitter": "Ville Vakkuri", "authors": "Ville Vakkuri, Kai-Kristian Kemell and Pekka Abrahamsson", "title": "AI Ethics in Industry: A Research Framework", "comments": "This paper further discusses the research framework introduced in\n  \"Implementing Ethics in AI: Initial results of an industrial multiple case\n  study\" Vakkuri, Kemell & Abrahamsson (arXiv:1906.12307)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) systems exert a growing influence on our\nsociety. As they become more ubiquitous, their potential negative impacts also\nbecome evident through various real-world incidents. Following such early\nincidents, academic and public discussion on AI ethics has highlighted the need\nfor implementing ethics in AI system development. However, little currently\nexists in the way of frameworks for understanding the practical implementation\nof AI ethics. In this paper, we discuss a research framework for implementing\nAI ethics in industrial settings. The framework presents a starting point for\nempirical studies into AI ethics but is still being developed further based on\nits practical utilization.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 14:11:26 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 17:07:00 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Vakkuri", "Ville", ""], ["Kemell", "Kai-Kristian", ""], ["Abrahamsson", "Pekka", ""]]}, {"id": "1910.12854", "submitter": "Keith Burghardt", "authors": "Yuzi He and Keith Burghardt and Kristina Lerman", "title": "Learning Fair and Interpretable Representations via Linear\n  Orthogonalization", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To reduce human error and prejudice, many high-stakes decisions have been\nturned over to machine algorithms. However, recent research suggests that this\ndoes not remove discrimination, and can perpetuate harmful stereotypes. While\nalgorithms have been developed to improve fairness, they typically face at\nleast one of three shortcomings: they are not interpretable, their prediction\nquality deteriorates quickly compared to unbiased equivalents, and they are not\neasily transferable across models. To address these shortcomings, we propose a\ngeometric method that removes correlations between data and any number of\nprotected variables. Further, we can control the strength of debiasing through\nan adjustable parameter to address the trade-off between prediction quality and\nfairness. The resulting features are interpretable and can be used with many\npopular models, such as linear regression, random forest, and multilayer\nperceptrons. The resulting predictions are found to be more accurate and fair\ncompared to several state-of-the-art fair AI algorithms across a variety of\nbenchmark datasets. Our work shows that debiasing data is a simple and\neffective solution toward improving fairness.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 17:59:31 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 18:59:13 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["He", "Yuzi", ""], ["Burghardt", "Keith", ""], ["Lerman", "Kristina", ""]]}, {"id": "1910.12859", "submitter": "Christine Michel", "authors": "Elena Codreanu (SICAL, GRePS, WSE), Christine Michel (SICAL),\n  Marc-Eric Bobiller-Chaumon (GRePS), Olivier Vigneau (WSE)", "title": "A Triangulated Model to Assess Adoption of Virtual Learning\n  Environements in Primary Schools", "comments": "arXiv admin note: substantial text overlap with arXiv:1910.11601", "journal-ref": "CSEDU 2016 - Proceedings of the 8th International Conference on\n  Computer Supported Education, Apr 2016, Rome, Italy. pp.287-293", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of this paper is to highlight the existing theoretical\napproaches which study the issue of technology adoption, and to establish a\ntriangulated model to explore Virtual Learning Environments adoption in primary\nschools. We studied the process of adoption through the lens of two related\nprocesses: the technological acceptance and appropriation.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 10:05:04 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Codreanu", "Elena", "", "SICAL, GRePS, WSE"], ["Michel", "Christine", "", "SICAL"], ["Bobiller-Chaumon", "Marc-Eric", "", "GRePS"], ["Vigneau", "Olivier", "", "WSE"]]}, {"id": "1910.12895", "submitter": "Azra Bihorac", "authors": "Shounak Datta, Tyler J. Loftus, Matthew M. Ruppert, Chris Giordano,\n  Lasith Adhikari, Ying-Chih Peng, Yuanfang Ren, Benjamin Shickel, Zheng Feng,\n  Gloria Lipori, Gilbert R. Upchurch Jr., Xiaolin Li, Parisa Rashidi, Tezcan\n  Ozrazgat-Baslanti, and Azra Bihorac", "title": "Added Value of Intraoperative Data for Predicting Postoperative\n  Complications: Development and Validation of a MySurgeryRisk Extension", "comments": "46 pages,8 figures, 7 tables version 2: corrected typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To test the hypothesis that accuracy, discrimination, and precision in\npredicting postoperative complications improve when using both preoperative and\nintraoperative data input features versus preoperative data alone. Models that\npredict postoperative complications often ignore important intraoperative\nphysiological changes. Incorporation of intraoperative physiological data may\nimprove model performance. This retrospective cohort analysis included 52,529\ninpatient surgeries at a single institution during a 5 year period. Random\nforest machine learning models in the validated MySurgeryRisk platform made\npatient-level predictions for three postoperative complications and mortality\nduring hospital admission using electronic health record data and patient\nneighborhood characteristics. For each outcome, one model trained with\npreoperative data alone and one model trained with both preoperative and\nintraoperative data. Models were compared by accuracy, discrimination\n(expressed as AUROC), precision (expressed as AUPRC), and reclassification\nindices (NRI). Machine learning models incorporating both preoperative and\nintraoperative data had greater accuracy, discrimination, and precision than\nmodels using preoperative data alone for predicting all three postoperative\ncomplications (intensive care unit length of stay >48 hours, mechanical\nventilation >48 hours, and neurological complications including delirium) and\nin-hospital mortality (accuracy: 88% vs. 77%, AUROC: 0.93 vs. 0.87, AUPRC: 0.21\nvs. 0.15). Overall reclassification improvement was 2.9-10.0% for complications\nand 11.2% for in-hospital mortality. Incorporating both preoperative and\nintraoperative data significantly increased accuracy, discrimination, and\nprecision for machine learning models predicting postoperative complications.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 18:02:46 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 16:03:10 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Datta", "Shounak", ""], ["Loftus", "Tyler J.", ""], ["Ruppert", "Matthew M.", ""], ["Giordano", "Chris", ""], ["Adhikari", "Lasith", ""], ["Peng", "Ying-Chih", ""], ["Ren", "Yuanfang", ""], ["Shickel", "Benjamin", ""], ["Feng", "Zheng", ""], ["Lipori", "Gloria", ""], ["Upchurch", "Gilbert R.", "Jr."], ["Li", "Xiaolin", ""], ["Rashidi", "Parisa", ""], ["Ozrazgat-Baslanti", "Tezcan", ""], ["Bihorac", "Azra", ""]]}, {"id": "1910.12978", "submitter": "Luke Trinity", "authors": "Luke Trinity, Scott C. Merrill, Eric Clark, Christopher J. Koliba,\n  Asim Zia, Gabriela Bucini, Julia M. Smith", "title": "Effects of Social Cues on Biosecurity Compliance in Livestock\n  Facilities: Evidence from Experimental Simulations", "comments": "30 pages, 4 figures, 6 tables", "journal-ref": null, "doi": "10.3389/fvets.2020.00130", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disease outbreaks in U.S. animal livestock industries have economic impacts\nmeasured in hundreds of millions of dollars per year. Biosecurity, or\nprocedures intended to protect animals against disease, is known to be\neffective at reducing infection risk at facilities. Yet to the detriment of\nanimal health, humans do not always follow biosecurity protocols. Human\nbehavioral factors have been shown to influence willingness to follow\nbiosecurity protocols. Here we show how social cues may affect cooperation with\na biosecurity practice. Participants were immersed in a simulated swine\nproduction facility through a graphical user interface and prompted to make a\ndecision that addressed their willingness to comply with a biosecurity\npractice. We tested the effect of varying three experimental variables: (1) the\nrisk of acquiring an infection, (2) the delivery method of the infection risk\ninformation (numerical versus graphical), and (3) behavior of an automated\ncoworker in the facility. We provide evidence that participants changed their\nbehavior when they observed a simulated worker making a choice to follow or not\nfollow a biosecurity protocol, even though the simulated worker had no economic\neffect on the participants' payouts. These results advance the understanding of\nhuman behavioral effects on biosecurity protocol decisions; demonstrating that\nsocial cues need to be considered by livestock facility managers when\ndeveloping policies to make agricultural systems more disease resilient.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 21:32:00 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Trinity", "Luke", ""], ["Merrill", "Scott C.", ""], ["Clark", "Eric", ""], ["Koliba", "Christopher J.", ""], ["Zia", "Asim", ""], ["Bucini", "Gabriela", ""], ["Smith", "Julia M.", ""]]}, {"id": "1910.13122", "submitter": "Araz Taeihagh", "authors": "Hazel Si Min Lim, and Araz Taeihagh", "title": "Algorithmic decision-making in AVs: Understanding ethical and technical\n  concerns for smart cities", "comments": null, "journal-ref": "Sustainability, 2019, 11(20), 5791", "doi": "10.3390/su11205791", "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Autonomous Vehicles (AVs) are increasingly embraced around the world to\nadvance smart mobility and more broadly, smart, and sustainable cities.\nAlgorithms form the basis of decision-making in AVs, allowing them to perform\ndriving tasks autonomously, efficiently, and more safely than human drivers and\noffering various economic, social, and environmental benefits. However,\nalgorithmic decision-making in AVs can also introduce new issues that create\nnew safety risks and perpetuate discrimination. We identify bias, ethics, and\nperverse incentives as key ethical issues in the AV algorithms' decision-making\nthat can create new safety risks and discriminatory outcomes. Technical issues\nin the AVs' perception, decision-making and control algorithms, limitations of\nexisting AV testing and verification methods, and cybersecurity vulnerabilities\ncan also undermine the performance of the AV system. This article investigates\nthe ethical and technical concerns surrounding algorithmic decision-making in\nAVs by exploring how driving decisions can perpetuate discrimination and create\nnew safety risks for the public. We discuss steps taken to address these\nissues, highlight the existing research gaps and the need to mitigate these\nissues through the design of AV's algorithms and of policies and regulations to\nfully realise AVs' benefits for smart and sustainable cities.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 07:50:02 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Lim", "Hazel Si Min", ""], ["Taeihagh", "Araz", ""]]}, {"id": "1910.13268", "submitter": "Kush Varshney", "authors": "Newton M. Kinyanjui, Timothy Odonga, Celia Cintas, Noel C. F. Codella,\n  Rameswar Panda, Prasanna Sattigeri, and Kush R. Varshney", "title": "Estimating Skin Tone and Effects on Classification Performance in\n  Dermatology Datasets", "comments": "NeurIPS 2019 Workshop on Fair ML for Health", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in computer vision and deep learning have led to\nbreakthroughs in the development of automated skin image analysis. In\nparticular, skin cancer classification models have achieved performance higher\nthan trained expert dermatologists. However, no attempt has been made to\nevaluate the consistency in performance of machine learning models across\npopulations with varying skin tones. In this paper, we present an approach to\nestimate skin tone in benchmark skin disease datasets, and investigate whether\nmodel performance is dependent on this measure. Specifically, we use individual\ntypology angle (ITA) to approximate skin tone in dermatology datasets. We look\nat the distribution of ITA values to better understand skin color\nrepresentation in two benchmark datasets: 1) the ISIC 2018 Challenge dataset, a\ncollection of dermoscopic images of skin lesions for the detection of skin\ncancer, and 2) the SD-198 dataset, a collection of clinical images capturing a\nwide variety of skin diseases. To estimate ITA, we first develop segmentation\nmodels to isolate non-diseased areas of skin. We find that the majority of the\ndata in the the two datasets have ITA values between 34.5{\\deg} and 48{\\deg},\nwhich are associated with lighter skin, and is consistent with\nunder-representation of darker skinned populations in these datasets. We also\nfind no measurable correlation between performance of machine learning model\nand ITA values, though more comprehensive data is needed for further\nvalidation.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 13:48:17 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Kinyanjui", "Newton M.", ""], ["Odonga", "Timothy", ""], ["Cintas", "Celia", ""], ["Codella", "Noel C. F.", ""], ["Panda", "Rameswar", ""], ["Sattigeri", "Prasanna", ""], ["Varshney", "Kush R.", ""]]}, {"id": "1910.13518", "submitter": "Michael Bar-Sinai", "authors": "Michael Bar-Sinai, Michal Tadjer, Mor Vilozni", "title": "Computer Assisted Access to Justice via Formal Jurisprudence Modeling", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses an internet-based system for enabling people to\nself-assess their legal rights in a given situation, and a development\nmethodology for such systems. The assessment process is based on a formal model\nof the relevant jurisprudence, exposed to the user through an interview. The\nmodel consists of a multi-dimensional space whose dimensions represent\northogonal jurisprudence aspects, and a decision graph that guides the user\nthrough that space. Self-assessment systems can revolutionize the way legal aid\norganizations help their clients, as they allow these organizations to deliver\npersonalized help at internet scales. The proposed approach is validated\nthrough an implementation of a model for workers' rights when their employment\nends. This model, describing Israeli law and developed in cooperation with a\nworker rights NGO, was ratified by external experts as accurate enough to be\nuseful in real cases.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 20:16:35 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 19:01:54 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Bar-Sinai", "Michael", ""], ["Tadjer", "Michal", ""], ["Vilozni", "Mor", ""]]}, {"id": "1910.13607", "submitter": "Atoosa Kasirzadeh", "authors": "Atoosa Kasirzadeh", "title": "Mathematical decisions and non-causal elements of explainable AI", "comments": "A shorter version of this paper was presented at the NeurIPS 2019,\n  Human-Centric Machine Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The social implications of algorithmic decision-making in sensitive contexts\nhave generated lively debates among multiple stakeholders, such as moral and\npolitical philosophers, computer scientists, and the public. Yet, the lack of a\ncommon language and a conceptual framework for an appropriate bridging of the\nmoral, technical, and political aspects of the debate prevents the discussion\nto be as effective as it can be. Social scientists and psychologists are\ncontributing to this debate by gathering a wealth of empirical data, yet a\nphilosophical analysis of the social implications of algorithmic\ndecision-making remains comparatively impoverished. In attempting to address\nthis lacuna, this paper argues that a hierarchy of different types of\nexplanations for why and how an algorithmic decision outcome is achieved can\nestablish the relevant connection between the moral and technical aspects of\nalgorithmic decision-making. In particular, I offer a multi-faceted conceptual\nframework for the explanations and the interpretations of algorithmic\ndecisions, and I claim that this framework can lay the groundwork for a focused\ndiscussion among multiple stakeholders about the social implications of\nalgorithmic decision-making, as well as AI governance and ethics more\ngenerally.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 00:58:44 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 07:08:33 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Kasirzadeh", "Atoosa", ""]]}, {"id": "1910.13635", "submitter": "Md Masuduzzaman", "authors": "Kazi Sadia, Md. Masuduzzaman, Rajib Kumar Paul, and Anik Islam", "title": "Blockchain Based Secured E-voting by Using the Assistance of Smart\n  Contract", "comments": "The paper has been accepted and presented in Springer IETE\n  International Conference on Blockchain Technology (IC-BCT 2019),29-30 March\n  2019,Mumbai, India. It's in Press now", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voting is a very important issue which can be beneficial in term of choosing\nthe right leader in an election. A good leader can bring prosperity to a\ncountry and also can lead the country in the right direction every time.\nHowever, elections are surrounds with ballot forgery, coercion and multiple\nvoting issues. Moreover, while giving votes, a person has to wait in a long\nqueue and it is a very time consuming process. Blockchain is a distributed\ndatabase in which data are shared with the participant of the node and each\nparticipant holds the same copy of the data. Blockchain has properties like\ndistributed, pseudonymous, data integrity etc. In the paper, a fully\ndecentralized evoting system based on blockchain technology is proposed. This\nprotocol utilizes smart contract into the evoting system to deal with security\nissues, accuracy and voters privacy during the vote. The protocol results in a\ntransparent, non editable and independently verifiable procedure that discards\nall the intended fraudulent activities occurring during the election process by\nremoving the least participation of the third party and enabling voters right\nduring the election. Both transparency and coercion are obtained at the same\ntime.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 02:47:27 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Sadia", "Kazi", ""], ["Masuduzzaman", "Md.", ""], ["Paul", "Rajib Kumar", ""], ["Islam", "Anik", ""]]}, {"id": "1910.13930", "submitter": "Xilei Zhao", "authors": "Xilei Zhao, Zhengze Zhou, Xiang Yan, Pascal Van Hentenryck", "title": "Distilling Black-Box Travel Mode Choice Model for Behavioral\n  Interpretation", "comments": "17 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has proved to be very successful for making predictions in\ntravel behavior modeling. However, most machine-learning models have complex\nmodel structures and offer little or no explanation as to how they arrive at\nthese predictions. Interpretations about travel behavior models are essential\nfor decision makers to understand travelers' preferences and plan policy\ninterventions accordingly. Therefore, this paper proposes to apply and extend\nthe model distillation approach, a model-agnostic machine-learning\ninterpretation method, to explain how a black-box travel mode choice model\nmakes predictions for the entire population and subpopulations of interest.\nModel distillation aims at compressing knowledge from a complex model (teacher)\ninto an understandable and interpretable model (student). In particular, the\npaper integrates model distillation with market segmentation to generate more\ninsights by accounting for heterogeneity. Furthermore, the paper provides a\ncomprehensive comparison of student models with the benchmark model (decision\ntree) and the teacher model (gradient boosting trees) to quantify the fidelity\nand accuracy of the students' interpretations.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 15:29:58 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Zhao", "Xilei", ""], ["Zhou", "Zhengze", ""], ["Yan", "Xiang", ""], ["Van Hentenryck", "Pascal", ""]]}, {"id": "1910.13965", "submitter": "Javier Del Ser Dr.", "authors": "Giovanni Perrone, Massimo Vecchio, Javier Del Ser, Fabio Antonelli,\n  Vivart Kapoor", "title": "The Internet of Things: a Survey and Outlook", "comments": "34 pages, chapter included in the book \"Sensors in the Age of the\n  Internet of Things: Technologies and applications\", IET Library, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent history has witnessed disruptive advances in disciplines related\nto information and communication technologies that have laid a rich\ntechnological ecosystem for the growth and maturity of latent paradigms in this\ndomain. Among them, sensor networks have evolved from the originally conceived\nset-up where hundreds of nodes with sensing and actuating functionalities were\ndeployed to capture information from their environment and act accordingly\n(coining the so-called wireless sensor network concept) to the provision of\nsuch functionalities embedded in quotidian objects that communicate and work\ntogether to collaboratively accomplish complex tasks based on the information\nthey acquire by sensing the environment. This is nowadays a reality, embracing\nthe original idea of an Internet of things (IoT) forged in the late twentieth\ncentury, yet featuring unprecedented scales, capabilities and applications\nignited by new radio interfaces, communication protocols and intelligent\ndata-based models. This chapter examines the latest findings reported in the\nliterature around these topics, with a clear focus on IoT communications,\nprotocols and platforms, towards ultimately identifying opportunities and\ntrends that will be at the forefront of IoT-related research in the near\nfuture.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 16:34:30 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Perrone", "Giovanni", ""], ["Vecchio", "Massimo", ""], ["Del Ser", "Javier", ""], ["Antonelli", "Fabio", ""], ["Kapoor", "Vivart", ""]]}, {"id": "1910.13983", "submitter": "Michiel Bakker", "authors": "Michiel A. Bakker, Duy Patrick Tu, Humberto River\\'on Vald\\'es,\n  Krishna P. Gummadi, Kush R. Varshney, Adrian Weller, Alex Pentland", "title": "DADI: Dynamic Discovery of Fair Information with Adversarial\n  Reinforcement Learning", "comments": "Accepted at NeurIPS 2019 HCML Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a framework for dynamic adversarial discovery of information\n(DADI), motivated by a scenario where information (a feature set) is used by\nthird parties with unknown objectives. We train a reinforcement learning agent\nto sequentially acquire a subset of the information while balancing accuracy\nand fairness of predictors downstream. Based on the set of already acquired\nfeatures, the agent decides dynamically to either collect more information from\nthe set of available features or to stop and predict using the information that\nis currently available. Building on previous work exploring adversarial\nrepresentation learning, we attain group fairness (demographic parity) by\nrewarding the agent with the adversary's loss, computed over the final feature\nset. Importantly, however, the framework provides a more general starting point\nfor fair or private dynamic information discovery. Finally, we demonstrate\nempirically, using two real-world datasets, that we can trade-off fairness and\npredictive performance\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 16:54:22 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Bakker", "Michiel A.", ""], ["Tu", "Duy Patrick", ""], ["Vald\u00e9s", "Humberto River\u00f3n", ""], ["Gummadi", "Krishna P.", ""], ["Varshney", "Kush R.", ""], ["Weller", "Adrian", ""], ["Pentland", "Alex", ""]]}, {"id": "1910.14210", "submitter": "Samuel Deng", "authors": "Samuel Deng and Achille Varzi", "title": "Methodological Blind Spots in Machine Learning Fairness: Lessons from\n  the Philosophy of Science and Computer Science", "comments": "Accepted for submission in: Workshop on Human-Centric Machine\n  Learning at the 33rd Conference on Neural Information ProcessingSystems\n  (NeurIPS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the ML fairness literature, there have been few investigations through the\nviewpoint of philosophy, a lens that encourages the critical evaluation of\nbasic assumptions. The purpose of this paper is to use three ideas from the\nphilosophy of science and computer science to tease out blind spots in the\nassumptions that underlie ML fairness: abstraction, induction, and measurement.\nThrough this investigation, we hope to warn of these methodological blind spots\nand encourage further interdisciplinary investigation in fair-ML through the\nframework of philosophy.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 02:02:31 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Deng", "Samuel", ""], ["Varzi", "Achille", ""]]}, {"id": "1910.14273", "submitter": "Xiaoxue Li", "authors": "Xiaoxue Li, Yanan Cao, Yanmin Shang, Yangxi Li, Yanbing Liu, Jianlong\n  Tan", "title": "RLINK: Deep Reinforcement Learning for User Identity Linkage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User identity linkage is a task of recognizing the identities of the same\nuser across different social networks (SN). Previous works tackle this problem\nvia estimating the pairwise similarity between identities from different SN,\npredicting the label of identity pairs or selecting the most relevant identity\npair based on the similarity scores. However, most of these methods ignore the\nresults of previously matched identities, which could contribute to the linkage\nin following matching steps. To address this problem, we convert user identity\nlinkage into a sequence decision problem and propose a reinforcement learning\nmodel to optimize the linkage strategy from the global perspective. Our method\nmakes full use of both the social network structure and the history matched\nidentities, and explores the long-term influence of current matching on\nsubsequent decisions. We conduct experiments on different types of datasets,\nthe results show that our method achieves better performance than other\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 06:21:33 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Li", "Xiaoxue", ""], ["Cao", "Yanan", ""], ["Shang", "Yanmin", ""], ["Li", "Yangxi", ""], ["Liu", "Yanbing", ""], ["Tan", "Jianlong", ""]]}, {"id": "1910.14415", "submitter": "Joshua Ellul", "authors": "Joshua Ellul and Gordon Pace", "title": "Blockchain and the Common Good Reimagined", "comments": "This paper was prepared for The Common Good in the Digital Age\n  conference held in the Vatican City State, between 26-28 September 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Blockchain, Smart Contracts and Distributed Ledger Technology (DLT) are being\ntouted to revolutionise digital services - through decentralisation.\nCryptocurrencies, self-sovereign identities, decentralised certificate\nregistries, and transparent voting systems are but a few applications which\npromise to empower endusers and provide assurances that neither data nor the\nassociated computational logic have been tampered with.\n  Decentralisation, disintermediation, transparency, verifiability,\nauditability, openness, inclusion, tamper-proof, immutability are just some of\nthe buzz words that continue to be swung around in the promotion of the\nbenefits brought about by Blockchain-based systems to the users. The rhetoric\nused creates parallels between the features brought about through blockchains\nand values that many try to uphold, for example honesty, openness,\ntransparency, teamwork and unchanging truth.\n  In this paper a number of blockchain applications aimed at supporting\ninitiatives for common good are highlighted. This is followed by a discussion\non technology de/centralisation and a thought experiment used to raise\nquestions regarding the use of decentralised technology in terms of social\nimplications.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 12:16:53 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Ellul", "Joshua", ""], ["Pace", "Gordon", ""]]}, {"id": "1910.14651", "submitter": "Marc Faddoul", "authors": "Marc Faddoul", "title": "Which Factors Impact Engagement on News Articles on Facebook?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media is increasingly being used as a news-platform. To reach their\nintended audience, newspapers need for their articles to be well ranked by\nFacebook's news-feed algorithm. The number of likes, shares and other reactions\ndetermine the lead scoring criteria. This paper will try to assess how the\nreaction volume is impacted by the following criteria: (1) Delay between event\nand post release; (2) Time of the day the post is published; and (3) Post\nformat: video, photo or text. To isolate the effect of the publication time and\npost format on a post, we need to control for the news-event and the publishing\nnewspaper. For that end, a news-aggregator is designed and implemented, to\ngroup together posts that relate to the same news-event. This tool gave some\nspin-off results, allowing the ability to map newspapers by similarity and to\ndetect some topic omissions.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 17:41:31 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Faddoul", "Marc", ""]]}]