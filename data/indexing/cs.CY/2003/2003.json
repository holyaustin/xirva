[{"id": "2003.00118", "submitter": "Suat Mercan", "authors": "Dominik Danko, Suat Mercan, Mumin Cebe Kemal Akkaya", "title": "Assuring the Integrity of Videos from Wireless-based IoT Devices using\n  Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain technology has drawn attention fromvarious communities. The\nunderlying consensus mechanism inBlockchain enables a myriad of applications\nfor the integrityassurance of stored data. In this paper, we utilize\nBlockchaintechnology to verify the authenticity of a video captured by\nastreaming IoT device for forensic investigation purposes. Theproposed approach\ncomputes the hash of video frames beforethey leave the IoT device and are\ntransferred to a remote basestation. To guarantee the transmission, we ensure\nthat this hashis sent through a TCP-based connection. The hash is then storedon\nmultiple nodes on a permissioned blockchain platform. Incase the video is\nmodified, the discrepancy will be detected byinvestigating the previously\nstored hash on the blockchain andcomparing it with the hash of the existing\nframe in question.In this work, we present the prototype as proof-of-concept\nwithexperiment results. The system has been tested on a RaspberryPi with\ndifferent quality of videos to evaluate performance. Theresults show that the\nconcept can be implemented with moderatevideo resolutions.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 23:36:13 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Danko", "Dominik", ""], ["Mercan", "Suat", ""], ["Akkaya", "Mumin Cebe Kemal", ""]]}, {"id": "2003.00201", "submitter": "Chaehan So", "authors": "Chaehan So", "title": "What Emotions Make One or Five Stars? Understanding Ratings of Online\n  Product Reviews by Sentiment Analysis and XAI", "comments": "To be published in: Lecture Notes in Artificial Intelligence, 1st\n  International Conference on Artificial Intelligence in HCI, AI-HCI, Held as\n  Part of HCI International 2020, Kopenhagen, Denmark, July 19-24, Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When people buy products online, they primarily base their decisions on the\nrecommendations of others given in online reviews. The current work analyzed\nthese online reviews by sentiment analysis and used the extracted sentiments as\nfeatures to predict the product ratings by several machine learning algorithms.\nThese predictions were disentangled by various meth-ods of explainable AI (XAI)\nto understand whether the model showed any bias during prediction. Study 1\nbenchmarked these algorithms (knn, support vector machines, random forests,\ngradient boosting machines, XGBoost) and identified random forests and XGBoost\nas best algorithms for predicting the product ratings. In Study 2, the analysis\nof global feature importance identified the sentiment joy and the emotional\nvalence negative as most predictive features. Two XAI visualization methods,\nlocal feature attributions and partial dependency plots, revealed several\nincorrect prediction mechanisms on the instance-level. Performing the\nbenchmarking as classification, Study 3 identified a high no-information rate\nof 64.4% that indicated high class imbalance as underlying reason for the\nidentified problems. In conclusion, good performance by machine learning\nalgorithms must be taken with caution because the dataset, as encountered in\nthis work, could be biased towards certain predictions. This work demonstrates\nhow XAI methods reveal such prediction bias.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 07:39:35 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["So", "Chaehan", ""]]}, {"id": "2003.00326", "submitter": "Marc Canellas", "authors": "Marc Canellas and Rachel Haga", "title": "Unsafe At Any Level: NHTSA's levels of automation are a liability for\n  autonomous vehicle design and regulation", "comments": "This is a post-peer-review, pre-copyedit version of an article\n  published in Communications of the ACM, March 2020, Vol. 63 No. 3, Pages\n  31-34. The final authenticated version is available online at:\n  http://dx.doi.org/10.1145/3342102. The contents of this Viewpoint are solely\n  the responsibility of the authors", "journal-ref": "Commun. ACM 63, 3 (March 2020), 31-34 (2020)", "doi": "10.1145/3342102", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Walter Huang, a 38-year-old Apple Inc. engineer, died on March 23, 2018,\nafter his Tesla Model X crashed into a highway barrier in Mountain View,\nCalifornia. Tesla immediately disavowed responsibility for the accident. \"The\nfundamental premise of both moral and legal liability is a broken promise, and\nthere was none here: [Mr. Huang] was well aware that the Autopilot was not\nperfect [and the] only way for this accident to have occurred is if Mr. Huang\nwas not paying attention to the road, despite the car providing multiple\nwarnings to do so.\" This is the standard response from Tesla and Uber, the\nmanufacturers of the automated vehicles involved in the six fatal accidents to\ndate: the automated vehicle isn't perfect, the driver knew it wasn't perfect,\nand if only the driver had been paying attention and heeded the vehicle's\nwarnings, the accident would never have occurred.\n  However, as researchers focused on human-automation interaction in aviation\nand military operations, we cannot help but wonder if there really are no\nbroken promises and no legal liabilities. Science has a critical role in\ndetermining legal liability, and courts appropriately rely on scientists and\nengineers to determine whether an accident, or harm, was foreseeable.\nSpecifically, a designer could be found liable if, at the time of the accident,\nscientists knew there was a systematic relationship between the accident and\nthe designer's untaken precaution.\n  Nearly 70 years of research provides an undeniable answer: It is\ninsufficient, inappropriate, and dangerous to automate everything you can and\nleave the rest to the human. There is a systematic relationship between the\ndesign of automated vehicles and the types of accidents that are occurring now\nand will inevitably continue to occur in the future. These accidents were not\nunforeseeable and the drivers were not exclusively to blame.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 18:22:35 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Canellas", "Marc", ""], ["Haga", "Rachel", ""]]}, {"id": "2003.00923", "submitter": "Yelena Mejova", "authors": "Yelena Mejova and Kyriaki Kalimeri", "title": "Advertisers Jump on Coronavirus Bandwagon: Politics, News, and Business", "comments": "Preprint. Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the age of social media, disasters and epidemics usher not only a\ndevastation and affliction in the physical world, but also prompt a deluge of\ninformation, opinions, prognoses and advice to billions of internet users. The\ncoronavirus epidemic of 2019-2020, or COVID-19, is no exception, with the World\nHealth Organization warning of a possible \"infodemic\" of fake news. In this\nstudy, we examine the alternative narratives around the coronavirus outbreak\nthrough advertisements promoted on Facebook, the largest social media platform\nin the US. Using the new Facebook Ads Library, we discover advertisers from\npublic health and non-profit sectors, alongside those from news media,\npolitics, and business, incorporating coronavirus into their messaging and\nagenda. We find the virus used in political attacks, donation solicitations,\nbusiness promotion, stock market advice, and animal rights campaigning. Among\nthese, we find several instances of possible misinformation, ranging from\nbioweapons conspiracy theories to unverifiable claims by politicians. As we\nmake the dataset available to the community, we hope the advertising domain\nwill become an important part of quality control for public health\ncommunication and public discourse in general.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 14:07:56 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Mejova", "Yelena", ""], ["Kalimeri", "Kyriaki", ""]]}, {"id": "2003.00935", "submitter": "C. Maria Keet", "authors": "George Rautenbach and C. Maria Keet", "title": "Toward equipping Artificial Moral Agents with multiple ethical theories", "comments": "technical report; 33 pages, 11 figures, 2 tables, 4 code listings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Moral Agents (AMA's) is a field in computer science with the\npurpose of creating autonomous machines that can make moral decisions akin to\nhow humans do. Researchers have proposed theoretical means of creating such\nmachines, while philosophers have made arguments as to how these machines ought\nto behave, or whether they should even exist. Of the currently theorised AMA's,\nall research and design has been done with either none or at most one specified\nnormative ethical theory as basis. This is problematic because it narrows down\nthe AMA's functional ability and versatility which in turn causes moral\noutcomes that a limited number of people agree with (thereby undermining an\nAMA's ability to be moral in a human sense). As solution we design a\nthree-layer model for general normative ethical theories that can be used to\nserialise the ethical views of people and businesses for an AMA to use during\nreasoning. Four specific ethical norms (Kantianism, divine command theory,\nutilitarianism, and egoism) were modelled and evaluated as proof of concept for\nnormative modelling. Furthermore, all models were serialised to XML/XSD as\nproof of support for computerisation.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 14:33:22 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Rautenbach", "George", ""], ["Keet", "C. Maria", ""]]}, {"id": "2003.01238", "submitter": "Andr\\'es P\\'aez", "authors": "Andr\\'es P\\'aez", "title": "Robot Mindreading and the Problem of Trust", "comments": "2020 Convention of the Society for the Study of Artificial\n  Intelligence and Simulation of Behavior", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper raises three questions regarding the attribution of beliefs,\ndesires, and intentions to robots. The first one is whether humans in fact\nengage in robot mindreading. If they do, this raises a second question: does\nrobot mindreading foster trust towards robots? Both of these questions are\nempirical, and I show that the available evidence is insufficient to answer\nthem. Now, if we assume that the answer to both questions is affirmative, a\nthird and more important question arises: should developers and engineers\npromote robot mindreading in view of their stated goal of enhancing\ntransparency? My worry here is that by attempting to make robots more\nmind-readable, they are abandoning the project of understanding automatic\ndecision processes. Features that enhance mind-readability are prone to make\nthe factors that determine automatic decisions even more opaque than they\nalready are. And current strategies to eliminate opacity do not enhance\nmind-readability. The last part of the paper discusses different ways to\nanalyze this apparent trade-off and suggests that a possible solution must\nadopt tolerable degrees of opacity that depend on pragmatic factors connected\nto the level of trust required for the intended uses of the robot.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 22:55:42 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["P\u00e1ez", "Andr\u00e9s", ""]]}, {"id": "2003.01279", "submitter": "Nataniel Ruiz", "authors": "Nataniel Ruiz, Sarah Adel Bargal, Stan Sclaroff", "title": "Disrupting Deepfakes: Adversarial Attacks Against Conditional Image\n  Translation Networks and Facial Manipulation Systems", "comments": "Accepted at CVPR 2020 Workshop on Adversarial Machine Learning in\n  Computer Vision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Face modification systems using deep learning have become increasingly\npowerful and accessible. Given images of a person's face, such systems can\ngenerate new images of that same person under different expressions and poses.\nSome systems can also modify targeted attributes such as hair color or age.\nThis type of manipulated images and video have been coined Deepfakes. In order\nto prevent a malicious user from generating modified images of a person without\ntheir consent we tackle the new problem of generating adversarial attacks\nagainst such image translation systems, which disrupt the resulting output\nimage. We call this problem disrupting deepfakes. Most image translation\narchitectures are generative models conditioned on an attribute (e.g. put a\nsmile on this person's face). We are first to propose and successfully apply\n(1) class transferable adversarial attacks that generalize to different\nclasses, which means that the attacker does not need to have knowledge about\nthe conditioning class, and (2) adversarial training for generative adversarial\nnetworks (GANs) as a first step towards robust image translation networks.\nFinally, in gray-box scenarios, blurring can mount a successful defense against\ndisruption. We present a spread-spectrum adversarial attack, which evades blur\ndefenses. Our open-source code can be found at\nhttps://github.com/natanielruiz/disrupting-deepfakes.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 01:18:16 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 18:18:14 GMT"}, {"version": "v3", "created": "Mon, 27 Apr 2020 19:58:25 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Ruiz", "Nataniel", ""], ["Bargal", "Sarah Adel", ""], ["Sclaroff", "Stan", ""]]}, {"id": "2003.01380", "submitter": "Bernadette Spieler", "authors": "Bernadette Spieler and Naomi Pfaff and Stefania Makrygiannaki and\n  Wolfgang Slany", "title": "The Magic Word: A Coding Tutorial-Game to Engage Female Teenagers in App\n  Design", "comments": "Constructionism 2020, Dublin/Ireland May, 24-25, 2020, 12 figures, 9\n  pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Educational games are commonly used to motivate students and provide enhanced\nlearning opportunities. Apps and mobile games play an increasingly important\nrole in education and smartphones are part of the daily lives of most female\nteenagers: Half of mobile gamers are women and 64% of women prefer smartphones\nto other platforms. However, gender differences in playing behaviour and\npreferences raises concerns about potential gender inequalities when games are\ndeveloped for education. In order to develop a tutorial game that suits the\nfemale target group and provides challenging tasks to solve, girls were\ninvolved at a very early stage of the development cycle and the idea was\ndeveloped on the basis of surveys and focus group discussions. A first\nprototype of the game has been tested in a mixed-gender group to get feedback\nabout the learning content, the worked examples, and the whole structure of the\ngame. Finally, a tutorial game with six worked examples has been released in\nour Luna&Cat app, a programming tool that has been designed for our female\ntarget group in particular.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 07:56:57 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 14:00:10 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Spieler", "Bernadette", ""], ["Pfaff", "Naomi", ""], ["Makrygiannaki", "Stefania", ""], ["Slany", "Wolfgang", ""]]}, {"id": "2003.01593", "submitter": "Benjamin Finley", "authors": "Abhishek Kumar, Benjamin Finley, Tristan Braud, Sasu Tarkoma, Pan Hui", "title": "Marketplace for AI Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence shows promise for solving many practical societal\nproblems in areas such as healthcare and transportation. However, the current\nmechanisms for AI model diffusion such as Github code repositories, academic\nproject webpages, and commercial AI marketplaces have some limitations; for\nexample, a lack of monetization methods, model traceability, and model\nauditabilty. In this work, we sketch guidelines for a new AI diffusion method\nbased on a decentralized online marketplace. We consider the technical,\neconomic, and regulatory aspects of such a marketplace including a discussion\nof solutions for problems in these areas. Finally, we include a comparative\nanalysis of several current AI marketplaces that are already available or in\ndevelopment. We find that most of these marketplaces are centralized commercial\nmarketplaces with relatively few models.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 15:27:30 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Kumar", "Abhishek", ""], ["Finley", "Benjamin", ""], ["Braud", "Tristan", ""], ["Tarkoma", "Sasu", ""], ["Hui", "Pan", ""]]}, {"id": "2003.02253", "submitter": "Katherine Hoffmann Pham", "authors": "Katherine Hoffmann Pham and Miguel Luengo-Oroz", "title": "From plague to coronavirus: On the value of ship traffic data for\n  epidemic modeling", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In addition to moving people and goods, ships can spread disease. Ship\ntraffic may complement air traffic as a source of import risk, and cruise ships\n- with large passenger volumes and multiple stops - are potential hotspots, in\nparticular for diseases with long incubation periods. Vessel trajectory data\nfrom ship Automatic Identification Systems (AIS) is available online and it is\npossible to extract and analyze this data. We illustrate this in the case of\nthe current coronavirus epidemic, in which hundreds of infected individuals\nhave traveled in ships captured in the AIS dataset. This real time and\nhistorical data should be included in epidemiological models of disease to\ninform the corresponding operational response.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 18:47:48 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Pham", "Katherine Hoffmann", ""], ["Luengo-Oroz", "Miguel", ""]]}, {"id": "2003.02312", "submitter": "Goda Klumbyte", "authors": "Goda Klumbyte, Claude Draude, Loren Britton", "title": "Re-Imagining HCI: New Materialist Philosophy and Figurations as Tool for\n  Design", "comments": "7 pages, 1 figure, paper was presented at the workshop 'Standing on\n  the Shoulders of Giants: Exploring the Intersection of Philosophy and HCI',\n  ACM CHI Conference on Human Factors in Computing Systems, 4-9 May 2019,\n  Glasgow, UK", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we interrogate the practices of imagining in human-computer\ninteraction (HCI), particularly in scenario building (SBE) and persona\nconstruction. We discuss the philosophical premises of HCI imaginings in\nrationalism, cognitivism and phenomenology, and we propose (feminist) new\nmaterialist philosophy as an enriching perspective that helps generate a\nholistic, relational perspective of users, imaginaries and technologies. In the\nend we explore the method of figurations as a potential tool for HCI design.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 20:11:26 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Klumbyte", "Goda", ""], ["Draude", "Claude", ""], ["Britton", "Loren", ""]]}, {"id": "2003.02488", "submitter": "Pawel Drozdowski", "authors": "P. Drozdowski, C. Rathgeb, A. Dantcheva, N. Damer, C. Busch", "title": "Demographic Bias in Biometrics: A Survey on an Emerging Challenge", "comments": "15 pages, 3 figures, 3 tables. Submitted to IEEE Transactions on\n  Technology and Society. Update after first round of peer review", "journal-ref": "IEEE Transactions on Technology and Society 1, no. 2 (2020):\n  89-103", "doi": "10.1109/TTS.2020.2992344", "report-no": null, "categories": "cs.CY cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systems incorporating biometric technologies have become ubiquitous in\npersonal, commercial, and governmental identity management applications. Both\ncooperative (e.g. access control) and non-cooperative (e.g. surveillance and\nforensics) systems have benefited from biometrics. Such systems rely on the\nuniqueness of certain biological or behavioural characteristics of human\nbeings, which enable for individuals to be reliably recognised using automated\nalgorithms.\n  Recently, however, there has been a wave of public and academic concerns\nregarding the existence of systemic bias in automated decision systems\n(including biometrics). Most prominently, face recognition algorithms have\noften been labelled as \"racist\" or \"biased\" by the media, non-governmental\norganisations, and researchers alike.\n  The main contributions of this article are: (1) an overview of the topic of\nalgorithmic bias in the context of biometrics, (2) a comprehensive survey of\nthe existing literature on biometric bias estimation and mitigation, (3) a\ndiscussion of the pertinent technical and social matters, and (4) an outline of\nthe remaining challenges and future work items, both from technological and\nsocial points of view.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 09:07:59 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 08:18:24 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Drozdowski", "P.", ""], ["Rathgeb", "C.", ""], ["Dantcheva", "A.", ""], ["Damer", "N.", ""], ["Busch", "C.", ""]]}, {"id": "2003.02763", "submitter": "Daniel Ish", "authors": "Daniel Ish, Andrew Lohn, Christian Curriden", "title": "A Quantitative History of A.I. Research in the United States and China", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by recent interest in the status and consequences of competition\nbetween the U.S. and China in A.I. research, we analyze 60 years of abstract\ndata scraped from Scopus to explore and quantify trends in publications on A.I.\ntopics from institutions affiliated with each country. We find the total volume\nof publications produced in both countries grows with a remarkable regularity\nover tens of years. While China initially experienced faster growth in\npublication volume than the U.S., growth slowed in China when it reached parity\nwith the U.S. and the growth rates of both countries are now similar. We also\nsee both countries undergo a seismic shift in topic choice around 1990, and\nconnect this to an explosion of interest in neural network methods. Finally, we\nsee evidence that between 2000 and 2010, China's topic choice tended to lag\nthat of the U.S. but that in recent decades the topic portfolios have come into\ncloser alignment.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 16:55:31 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 14:35:39 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Ish", "Daniel", ""], ["Lohn", "Andrew", ""], ["Curriden", "Christian", ""]]}, {"id": "2003.02899", "submitter": "Innar Liiv", "authors": "Priit Ulmas and Innar Liiv", "title": "Segmentation of Satellite Imagery using U-Net Models for Land Cover\n  Classification", "comments": "Submitted to IEEE Access; 11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The focus of this paper is using a convolutional machine learning model with\na modified U-Net structure for creating land cover classification mapping based\non satellite imagery. The aim of the research is to train and test\nconvolutional models for automatic land cover mapping and to assess their\nusability in increasing land cover mapping accuracy and change detection. To\nsolve these tasks, authors prepared a dataset and trained machine learning\nmodels for land cover classification and semantic segmentation from satellite\nimages. The results were analysed on three different land classification\nlevels. BigEarthNet satellite image archive was selected for the research as\none of two main datasets. This novel and recent dataset was published in 2019\nand includes Sentinel-2 satellite photos from 10 European countries made in\n2017 and 2018. As a second dataset the authors composed an original set\ncontaining a Sentinel-2 image and a CORINE land cover map of Estonia. The\ndeveloped classification model shows a high overall F\\textsubscript{1} score of\n0.749 on multiclass land cover classification with 43 possible image labels.\nThe model also highlights noisy data in the BigEarthNet dataset, where images\nseem to have incorrect labels. The segmentation models offer a solution for\ngenerating automatic land cover mappings based on Sentinel-2 satellite images\nand show a high IoU score for land cover classes such as forests, inland waters\nand arable land. The models show a capability of increasing the accuracy of\nexisting land classification maps and in land cover change detection.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 20:07:48 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Ulmas", "Priit", ""], ["Liiv", "Innar", ""]]}, {"id": "2003.02910", "submitter": "Katalin Feher", "authors": "Katalin Feher", "title": "Expected participation and mentality of smart citizen in smart cities", "comments": "18 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": "KOFOP 2.1.2 -- VEKOP -- 15-2016-00001", "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose is to investigate the expected participation and mentality of\nsmart citizens in smart cities. The key question is the role of the human\nfactor in smart environments globally studied through a research corpus of 150\ndocuments including mainstream summaries trend reports, white papers and\nvisions of business, governmental and university research cooperations reaching\na wide audience of the subject. Foremost, a short review of the changing\nscholarly trends is presented as a theoretical framework. Concerning its key\nideas, the corpus based findings are recapped and analysed by content networks\nand the most referred city strategies. Besides, a critical approach reveal\nfurther required factors and risks to investigate. The ultimate goal is to\nunderstand how the smart city landscape is shaped by citizen-based strategies,\nopen data, empowerment and responsibility. Accordingly, the paper closes with\nfurther considerations regarding the importance of anonymous open data,\nadvantages of neighbourhood-based implementations, aspects of permanent and\ntemporary citizen-engagements, interpretation of metaphors or upcoming\ntechnologies, and also, privacy and ethical issues. The results provide the\npolicy development and the emerging scholarly interest with a framework study.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 20:37:25 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Feher", "Katalin", ""]]}, {"id": "2003.02973", "submitter": "Kazuhiro Seki", "authors": "Kazuhiro Seki and Yusuke Ikuta", "title": "S-APIR: News-based Business Sentiment Index", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes our work on developing a new business sentiment index\nusing daily newspaper articles. We adopt a recurrent neural network (RNN) with\nGated Recurrent Units to predict the business sentiment of a given text. An RNN\nis initially trained on Economy Watchers Survey and then fine-tuned on news\ntexts for domain adaptation. Also, a one-class support vector machine is\napplied to filter out texts deemed irrelevant to business sentiment. Moreover,\nwe propose a simple approach to temporally analyzing how much and when any\ngiven factor influences the predicted business sentiment. The validity and\nutility of the proposed approaches are empirically demonstrated through a\nseries of experiments on Nikkei Newspaper articles published from 2013 to 2018.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 00:18:50 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Seki", "Kazuhiro", ""], ["Ikuta", "Yusuke", ""]]}, {"id": "2003.03044", "submitter": "Franck Dernoncourt", "authors": "Edward T. Moseley, Joy T. Wu, Jonathan Welt, John Foote, Patrick D.\n  Tyler, David W. Grant, Eric T. Carlson, Sebastian Gehrmann, Franck\n  Dernoncourt and Leo Anthony Celi", "title": "A Corpus for Detecting High-Context Medical Conditions in Intensive Care\n  Patient Notes Focusing on Frequently Readmitted Patients", "comments": "Accepted at LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A crucial step within secondary analysis of electronic health records (EHRs)\nis to identify the patient cohort under investigation. While EHRs contain\nmedical billing codes that aim to represent the conditions and treatments\npatients may have, much of the information is only present in the patient\nnotes. Therefore, it is critical to develop robust algorithms to infer\npatients' conditions and treatments from their written notes. In this paper, we\nintroduce a dataset for patient phenotyping, a task that is defined as the\nidentification of whether a patient has a given medical condition (also\nreferred to as clinical indication or phenotype) based on their patient note.\nNursing Progress Notes and Discharge Summaries from the Intensive Care Unit of\na large tertiary care hospital were manually annotated for the presence of\nseveral high-context phenotypes relevant to treatment and risk of\nre-hospitalization. This dataset contains 1102 Discharge Summaries and 1000\nNursing Progress Notes. Each Discharge Summary and Progress Note has been\nannotated by at least two expert human annotators (one clinical researcher and\none resident physician). Annotated phenotypes include treatment non-adherence,\nchronic pain, advanced/metastatic cancer, as well as 10 other phenotypes. This\ndataset can be utilized for academic and industrial research in medicine and\ncomputer science, particularly within the field of medical natural language\nprocessing.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 05:56:49 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Moseley", "Edward T.", ""], ["Wu", "Joy T.", ""], ["Welt", "Jonathan", ""], ["Foote", "John", ""], ["Tyler", "Patrick D.", ""], ["Grant", "David W.", ""], ["Carlson", "Eric T.", ""], ["Gehrmann", "Sebastian", ""], ["Dernoncourt", "Franck", ""], ["Celi", "Leo Anthony", ""]]}, {"id": "2003.03099", "submitter": "Brian Castellani", "authors": "Corey Schimpf and Brian Castellani", "title": "COMPLEX-IT: A Case-Based Modeling and Scenario Simulation Platform for\n  Social Inquiry", "comments": null, "journal-ref": "Journal of Open Research Software (2020) 8:25", "doi": "10.5334/jors.298", "report-no": null, "categories": "cs.MS cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COMPLEX-IT is a case-based, mixed-methods platform for social inquiry into\ncomplex data/systems, designed to increase non-expert access to the tools of\ncomputational social science (i.e., cluster analysis, artificial intelligence,\ndata visualization, data forecasting, and scenario simulation). In particular,\nCOMPLEX-IT aids social inquiry though a heavy emphasis on learning about the\ncomplex data/system under study, which it does by (a) identifying and\nforecasting major and minor clusters/trends; (b) visualizing their complex\ncausality; and (c) simulating scenarios for potential interventions. COMPLEX-IT\nis accessible through the web or can be run locally and is powered by R and the\nShiny web framework.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 09:27:10 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Schimpf", "Corey", ""], ["Castellani", "Brian", ""]]}, {"id": "2003.03219", "submitter": "Orad Reshef", "authors": "Orad Reshef, Igor Aharonovich, Andrea Armani, Sylvain Gigan, Rachel\n  Grange, Mikhail A. Kats and Riccardo Sapienza", "title": "How to organize an online conference", "comments": "Updated some of the text and added a figure", "journal-ref": "Nature Reviews Materials 5, 253-256 (2020)", "doi": "10.1038/s41578-020-0194-0", "report-no": null, "categories": "cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On January 13th 2020, the inaugural Photonics Online Meetup (POM) brought\ntogether more than 1100 researchers to discuss the latest advances in\nphotonics. Or rather, it didn't, because the meeting was completely delocalized\nwith the speakers, organizers, and attendees scattered across six continents\nand hundreds of locations, connected via a video-conferencing tool and social\nmedia. Despite this \"delocalisation,\" the meeting retained many characteristics\nof a traditional conference: invited and contributed talks with follow-up\nquestions and discussion, and a poster session. However, unlike with\ntraditional conferences, all attendees avoided air travel, high registration\ncosts (it was completely free), CO2 emission, or visa issues. Surely the impact\non families was minimized as well, though participants in inconvenient time\nzones had to wake up early or stay up late. In this Comment, we highlight the\nkey steps that enabled this event, offering tips and advice, to aid the\norganisation of similar Online Meetups.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 03:18:31 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 02:33:29 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Reshef", "Orad", ""], ["Aharonovich", "Igor", ""], ["Armani", "Andrea", ""], ["Gigan", "Sylvain", ""], ["Grange", "Rachel", ""], ["Kats", "Mikhail A.", ""], ["Sapienza", "Riccardo", ""]]}, {"id": "2003.03318", "submitter": "Marc Faddoul", "authors": "Marc Faddoul, Guillaume Chaslot and Hany Farid", "title": "A Longitudinal Analysis of YouTube's Promotion of Conspiracy Videos", "comments": "8 pages, 3 figures. This paper was first released on March 2nd, 2020\n  along with a coverage from the New York Times available at\n  https://www.nytimes.com/interactive/2020/03/02/technology/youtube-conspiracy-theory.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conspiracy theories have flourished on social media, raising concerns that\nsuch content is fueling the spread of disinformation, supporting extremist\nideologies, and in some cases, leading to violence. Under increased scrutiny\nand pressure from legislators and the public, YouTube announced efforts to\nchange their recommendation algorithms so that the most egregious conspiracy\nvideos are demoted and demonetized. To verify this claim, we have developed a\nclassifier for automatically determining if a video is conspiratorial (e.g.,\nthe moon landing was faked, the pyramids of Giza were built by aliens, end of\nthe world prophecies, etc.). We coupled this classifier with an emulation of\nYouTube's watch-next algorithm on more than a thousand popular informational\nchannels to obtain a year-long picture of the videos actively promoted by\nYouTube. We also obtained trends of the so-called filter-bubble effect for\nconspiracy theories.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 17:31:30 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Faddoul", "Marc", ""], ["Chaslot", "Guillaume", ""], ["Farid", "Hany", ""]]}, {"id": "2003.03466", "submitter": "Philipp Drewe-Boss", "authors": "Philipp Drewe-Boss, Dirk Enders, Jochen Walker, Uwe Ohler", "title": "Deep learning for prediction of population health costs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate prediction of healthcare costs is important for optimally managing\nhealth costs. However, methods leveraging the medical richness from data such\nas health insurance claims or electronic health records are missing. Here, we\ndeveloped a deep neural network to predict future cost from health insurance\nclaims records. We applied the deep network and a ridge regression model to a\nsample of 1.4 million German insurants to predict total one-year health care\ncosts. Both methods were compared to Morbi-RSA models with various performance\nmeasures and were also used to predict patients with a change in costs and to\nidentify relevant codes for this prediction. We showed that the neural network\noutperformed the ridge regression as well as all Morbi-RSA models for cost\nprediction. Further, the neural network was superior to ridge regression in\npredicting patients with cost change and identified more specific codes. In\nsummary, we showed that our deep neural network can leverage the full\ncomplexity of the patient records and outperforms standard approaches. We\nsuggest that the better performance is due to the ability to incorporate\ncomplex interactions in the model and that the model might also be used for\npredicting other health phenotypes.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 23:33:39 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Drewe-Boss", "Philipp", ""], ["Enders", "Dirk", ""], ["Walker", "Jochen", ""], ["Ohler", "Uwe", ""]]}, {"id": "2003.03541", "submitter": "Devansh Saxena", "authors": "Devansh Saxena, Karla Badillo-Urquiola, Pamela J. Wisniewski, and\n  Shion Guha", "title": "A Human-Centered Review of the Algorithms used within the U.S. Child\n  Welfare System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The U.S. Child Welfare System (CWS) is charged with improving outcomes for\nfoster youth; yet, they are overburdened and underfunded. To overcome this\nlimitation, several states have turned towards algorithmic decision-making\nsystems to reduce costs and determine better processes for improving CWS\noutcomes. Using a human-centered algorithmic design approach, we synthesize 50\npeer-reviewed publications on computational systems used in CWS to assess how\nthey were being developed, common characteristics of predictors used, as well\nas the target outcomes. We found that most of the literature has focused on\nrisk assessment models but does not consider theoretical approaches (e.g.,\nchild-foster parent matching) nor the perspectives of caseworkers (e.g., case\nnotes). Therefore, future algorithms should strive to be context-aware and\ntheoretically robust by incorporating salient factors identified by past\nresearch. We provide the HCI community with research avenues for developing\nhuman-centered algorithms that redirect attention towards more equitable\noutcomes for CWS.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 09:16:12 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Saxena", "Devansh", ""], ["Badillo-Urquiola", "Karla", ""], ["Wisniewski", "Pamela J.", ""], ["Guha", "Shion", ""]]}, {"id": "2003.03699", "submitter": "Depeng Xu", "authors": "Depeng Xu, Wei Du and Xintao Wu", "title": "Removing Disparate Impact of Differentially Private Stochastic Gradient\n  Descent on Model Accuracy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When we enforce differential privacy in machine learning, the utility-privacy\ntrade-off is different w.r.t. each group. Gradient clipping and random noise\naddition disproportionately affect underrepresented and complex classes and\nsubgroups, which results in inequality in utility loss. In this work, we\nanalyze the inequality in utility loss by differential privacy and propose a\nmodified differentially private stochastic gradient descent (DPSGD), called\nDPSGD-F, to remove the potential disparate impact of differential privacy on\nthe protected group. DPSGD-F adjusts the contribution of samples in a group\ndepending on the group clipping bias such that differential privacy has no\ndisparate impact on group utility. Our experimental evaluation shows how group\nsample size and group clipping bias affect the impact of differential privacy\nin DPSGD, and how adaptive clipping for each group helps to mitigate the\ndisparate impact caused by differential privacy in DPSGD-F.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 02:06:15 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 21:04:37 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Xu", "Depeng", ""], ["Du", "Wei", ""], ["Wu", "Xintao", ""]]}, {"id": "2003.04155", "submitter": "Derek Ruths", "authors": "Derek Ruths, Caitrin Armstrong", "title": "The Residence History Inference Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of online user traces for studies of human mobility has received\nsignificant attention in recent years. This growing body of work, and the more\ngeneral importance of human migration patterns to government and industry,\nmotivates the need for a formalized approach to the computational modeling of\nhuman mobility - in particular how and when individuals change their place of\nresidence - from online traces. Prior work on this topic has skirted the\nunderlying computational modeling of residence inference, focusing on migration\npatterns themselves. As a result, to our knowledge, all prior work has employed\nheuristics to compute something like residence histories. Here, we formalize\nthe residence assignment problem, which seeks, under constraints associated\nwith the minimum length-of-stay at a residence, the most parsimonious sequence\nof residence periods and places that explains the movement history of an\nindividual. Here we provide an exact solution for this problem and establish\nits algorithmic complexity. Because the calculation of optimal residence\nhistories (under the assumptions of the model) is tractable, we believe that\nthis method will be a valuable tool for future work on this topic.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 14:02:08 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Ruths", "Derek", ""], ["Armstrong", "Caitrin", ""]]}, {"id": "2003.04275", "submitter": "Antonio Candelieri", "authors": "Antonio Candelieri, Riccardo Perego, Ilaria Giordani, Andrea Ponti,\n  Francesco Archetti", "title": "Modelling Human Active Search in Optimizing Black-box Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modelling human function learning has been the subject of in-tense research\nin cognitive sciences. The topic is relevant in black-box optimization where\ninformation about the objective and/or constraints is not available and must be\nlearned through function evaluations. In this paper we focus on the relation\nbetween the behaviour of humans searching for the maximum and the probabilistic\nmodel used in Bayesian Optimization. As surrogate models of the unknown\nfunction both Gaussian Processes and Random Forest have been considered: the\nBayesian learning paradigm is central in the development of active learning\napproaches balancing exploration/exploitation in uncertain conditions towards\neffective generalization in large decision spaces. In this paper we analyse\nexperimentally how Bayesian Optimization compares to humans searching for the\nmaximum of an unknown 2D function. A set of controlled experiments with 60\nsubjects, using both surrogate models, confirm that Bayesian Optimization\nprovides a general model to represent individual patterns of active learning in\nhumans\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 17:34:24 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Candelieri", "Antonio", ""], ["Perego", "Riccardo", ""], ["Giordani", "Ilaria", ""], ["Ponti", "Andrea", ""], ["Archetti", "Francesco", ""]]}, {"id": "2003.04794", "submitter": "Marius Miron", "authors": "Marius Miron, Song\\\"ul Tolan, Emilia G\\'omez, Carlos Castillo", "title": "Addressing multiple metrics of group fairness in data-driven decision\n  making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The Fairness, Accountability, and Transparency in Machine Learning (FAT-ML)\nliterature proposes a varied set of group fairness metrics to measure\ndiscrimination against socio-demographic groups that are characterized by a\nprotected feature, such as gender or race.Such a system can be deemed as either\nfair or unfair depending on the choice of the metric. Several metrics have been\nproposed, some of them incompatible with each other.We do so empirically, by\nobserving that several of these metrics cluster together in two or three main\nclusters for the same groups and machine learning methods. In addition, we\npropose a robust way to visualize multidimensional fairness in two dimensions\nthrough a Principal Component Analysis (PCA) of the group fairness metrics.\nExperimental results on multiple datasets show that the PCA decomposition\nexplains the variance between the metrics with one to three components.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 15:13:05 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Miron", "Marius", ""], ["Tolan", "Song\u00fcl", ""], ["G\u00f3mez", "Emilia", ""], ["Castillo", "Carlos", ""]]}, {"id": "2003.04799", "submitter": "Franziska Tachtler", "authors": "Franziska Tachtler, Toni Michel, Petr Slov\\'ak, Geraldine Fitzpatrick", "title": "Supporting the Supporters of Unaccompanied Migrant Youth: Designing for\n  Social-ecological Resilience", "comments": "10 pages (excluding references), 1 figure. To appear in the\n  Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems\n  (CHI'20), April 25--30, 2020, Honolulu, HI, USA", "journal-ref": "Proceedings of the 2020 CHI Conference on Human Factors in\n  Computing Systems (CHI'20)", "doi": "10.1145/3313831.3376458", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unaccompanied migrant youth, fleeing to a new country without their parents,\nare exposed to mental health risks. Resilience interventions mitigate such\nrisks, but access can be hindered by systemic and personal barriers. While much\nwork has recently addressed designing technology to promote mental health, none\nhas focused on the needs of these populations. This paper presents the results\nof interviews with 18 professional/ volunteer support workers and 5\nunaccompanied migrant youths, followed by three design workshops. The results\npoint to the diverse systems that can facilitate youths' resilience\ndevelopment. The relationship between the youth and volunteers acting as\nmentors is particularly important for increasing resilience but comes with\nchallenges. This suggests the relevance of a social-ecological model of\nresilience with a focus on designing technology to support the mentors in order\nto help them better support the youth. We conclude by mapping out the design\nspace for mentor support.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 15:24:07 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Tachtler", "Franziska", ""], ["Michel", "Toni", ""], ["Slov\u00e1k", "Petr", ""], ["Fitzpatrick", "Geraldine", ""]]}, {"id": "2003.04843", "submitter": "Flavio Cirillo", "authors": "Flavio Cirillo, David G\\'omez, Luis Diez, Ignacio Elicegui Maestro,\n  Thomas Barrie Juel Gilbert, Reza Akhavan", "title": "Smart City IoT Services Creation through Large Scale Collaboration", "comments": "8 pages, 9 figures, 4 Tables, to be published in IEEE IoT Journal", "journal-ref": null, "doi": "10.1109/JIOT.2020.2978770", "report-no": null, "categories": "cs.CY cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart cities solutions are often monolithically implemented, from sensors\ndata handling through to the provided services. The same challenges are\nregularly faced by different developers, for every new solution in a new city.\nExpertise and know-how can be re-used and the effort shared. In this article we\npresent the methodologies to minimize the efforts of implementing new smart\ncity solutions and maximizing the sharing of components. The final target is to\nhave a live technical community of smart city application developers. The\nresults of this activity comes from the implementation of 35 city services in\n27 cities between Europe and South Korea. To share efforts, we encourage\ndevelopers to devise applications using a modular approach. Single-function\ncomponents that are re-usable by other city services are packaged and published\nas standalone components, named Atomic Services. We identify 15 atomic services\naddressing smart city challenges in data analytics, data evaluation, data\nintegration, data validation, and visualization. 38 instances of the atomic\nservices are already operational in several smart city services. We detail in\nthis article, as atomic service examples, some data predictor components.\nFurthermore, we describe real-world atomic services usage in the scenarios of\nSantander and three Danish cities. The resulting atomic services also generate\na side market for smart city solutions, allowing expertise and know-how to be\nre-used by different stakeholders.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 16:43:13 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Cirillo", "Flavio", ""], ["G\u00f3mez", "David", ""], ["Diez", "Luis", ""], ["Maestro", "Ignacio Elicegui", ""], ["Gilbert", "Thomas Barrie Juel", ""], ["Akhavan", "Reza", ""]]}, {"id": "2003.04915", "submitter": "Renan Souza", "authors": "Raphael Thiago, Renan Souza, L. Azevedo, E. Soares, Rodrigo Santos,\n  Wallas Santos, Max De Bayser, M. Cardoso, M. Moreno, and Renato Cerqueira", "title": "Managing Data Lineage of O&G Machine Learning Models: The Sweet Spot for\n  Shale Use Case", "comments": "Author preprint of paper accepted at the 2020 European Association of\n  Geoscientists and Engineers (EAGE) Digitalization Conference and Exhibition", "journal-ref": "2020 European Association of Geoscientists and Engineers (EAGE)\n  Digitalization Conference and Exhibition", "doi": null, "report-no": null, "categories": "cs.DB cs.CY cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) has increased its role, becoming essential in several\nindustries. However, questions around training data lineage, such as \"where has\nthe dataset used to train this model come from?\"; the introduction of several\nnew data protection legislation; and, the need for data governance\nrequirements, have hindered the adoption of ML models in the real world. In\nthis paper, we discuss how data lineage can be leveraged to benefit the ML\nlifecycle to build ML models to discover sweet-spots for shale oil and gas\nproduction, a major application in the Oil and Gas O&G Industry.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 18:10:16 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Thiago", "Raphael", ""], ["Souza", "Renan", ""], ["Azevedo", "L.", ""], ["Soares", "E.", ""], ["Santos", "Rodrigo", ""], ["Santos", "Wallas", ""], ["De Bayser", "Max", ""], ["Cardoso", "M.", ""], ["Moreno", "M.", ""], ["Cerqueira", "Renato", ""]]}, {"id": "2003.04975", "submitter": "Zahra Shekarchi", "authors": "Zahra Shekarchi, Yang Xu", "title": "A Computational Investigation on Denominalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language has been a dynamic system and word meanings always have been changed\nover times. Every time a novel concept or sense is introduced, we need to\nassign it a word to express it. Also, some changes have happened because the\nresult of a change can be more desirable for humans, or cognitively easier to\nbe used by humans. Finding the patterns of these changes is interesting and can\nreveal some facts about human cognitive evolution. As we have enough resources\nfor studying this problem, it is a good idea to work on the problem through\ncomputational modeling, and that can make the work easier and possible to be\nstudied on large scale. In this work, we want to study the nouns which have\nbeen used as verbs after some years of their emergence as nouns and find some\ncommonalities among these nouns. In other words, we are interested in finding\nwhat potential requirements are essential for this change.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 22:28:00 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Shekarchi", "Zahra", ""], ["Xu", "Yang", ""]]}, {"id": "2003.05043", "submitter": "Vuong M. Ngo", "authors": "Vuong M. Ngo and M-Tahar Kechadi", "title": "Crop Knowledge Discovery Based on Agricultural Big Data Integration", "comments": "5 pages", "journal-ref": "ICMLSC-2020", "doi": null, "report-no": null, "categories": "cs.DB cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, the agricultural data can be generated through various sources,\nsuch as: Internet of Thing (IoT), sensors, satellites, weather stations,\nrobots, farm equipment, agricultural laboratories, farmers, government agencies\nand agribusinesses. The analysis of this big data enables farmers, companies\nand agronomists to extract high business and scientific knowledge, improving\ntheir operational processes and product quality. However, before analysing this\ndata, different data sources need to be normalised, homogenised and integrated\ninto a unified data representation. In this paper, we propose an agricultural\ndata integration method using a constellation schema which is designed to be\nflexible enough to incorporate other datasets and big data models. We also\napply some methods to extract knowledge with the view to improve crop yield;\nthese include finding suitable quantities of soil properties, herbicides and\ninsecticides for both increasing crop yield and protecting the environment.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 00:13:17 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Ngo", "Vuong M.", ""], ["Kechadi", "M-Tahar", ""]]}, {"id": "2003.05063", "submitter": "Sara Morsy", "authors": "Sara Morsy and George Karypis", "title": "Context-aware Non-linear and Neural Attentive Knowledge-based Models for\n  Grade Prediction", "comments": "arXiv admin note: substantial text overlap with arXiv:1904.11858", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grade prediction for future courses not yet taken by students is important as\nit can help them and their advisers during the process of course selection as\nwell as for designing personalized degree plans and modifying them based on\ntheir performance. One of the successful approaches for accurately predicting a\nstudent's grades in future courses is Cumulative Knowledge-based Regression\nModels (CKRM). CKRM learns shallow linear models that predict a student's\ngrades as the similarity between his/her knowledge state and the target course.\nHowever, prior courses taken by a student can have \\black{different\ncontributions when estimating a student's knowledge state and towards each\ntarget course, which} cannot be captured by linear models. Moreover, CKRM and\nother grade prediction methods ignore the effect of concurrently-taken courses\non a student's performance in a target course. In this paper, we propose\ncontext-aware non-linear and neural attentive models that can potentially\nbetter estimate a student's knowledge state from his/her prior course\ninformation, as well as model the interactions between a target course and\nconcurrent courses. Compared to the competing methods, our experiments on a\nlarge real-world dataset consisting of more than $1.5$M grades show the\neffectiveness of the proposed models in accurately predicting students' grades.\nMoreover, the attention weights learned by the neural attentive model can be\nhelpful in better designing their degree plans.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 20:20:48 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Morsy", "Sara", ""], ["Karypis", "George", ""]]}, {"id": "2003.05109", "submitter": "Teruaki Hayashi", "authors": "Teruaki Hayashi, Yukio Ohsawa", "title": "Variable-Based Network Analysis of Datasets on Data Exchange Platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, data exchange platforms have emerged in the digital economy to\nenable better resource allocation in a data-driven society, which requires\ncross-organizational data collaborations. Understanding the characteristics of\nthe data on these platforms is important for their application; however, the\nstructures of such platforms have not been extensively investigated. In this\nstudy, we apply a network approach with a novel variable-based structural\nanalysis to the metadata of datasets on two data platform services. It was\nnoted that the structures of the data networks are locally dense and highly\nassortative, similar to human-related net-works. Even though the data on these\nplatforms are designed and collected differently, depending on the use\nobjectives, the variables of heterogeneous data exhibit a power distribution,\nand the data networks exhibit multi-scaling behavior. Furthermore, we found\nthat the data collection strategies of the platforms are related to the variety\nof variables, density of the networks, and their robustness from the viewpoint\nof sustainability and social acceptability of the data platforms.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 04:42:30 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Hayashi", "Teruaki", ""], ["Ohsawa", "Yukio", ""]]}, {"id": "2003.05151", "submitter": "Jukka Ruohonen", "authors": "Jukka Ruohonen and Kalle Hjerppe", "title": "Predicting the Amount of GDPR Fines", "comments": null, "journal-ref": "Proceedings of the First International Workshop \"CAiSE for Legal\n  Documents\" (COUrT 2020), Grenoble (online), CEUR-WS, pp. 3-14,\n  http://ceur-ws.org/Vol-2690/COUrT-paper1.pdf", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The General Data Protection Regulation (GDPR) was enforced in 2018. After\nthis enforcement, many fines have already been imposed by national data\nprotection authorities in the European Union (EU). This paper examines the\nindividual GDPR articles referenced in the enforcement decisions, as well as\npredicts the amount of enforcement fines with available meta-data and text\nmining features extracted from the enforcement decision documents. According to\nthe results, articles related to the general principles, lawfulness, and\ninformation security have been the most frequently referenced ones. Although\nthe amount of fines imposed vary across the articles referenced, these three\nparticular articles do not stand out. Furthermore, good predictions are\nattainable even with simple machine learning techniques for regression\nanalysis. Basic meta-data (such as the articles referenced and the country of\norigin) yields slightly better performance compared to the text mining\nfeatures.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 08:05:02 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 12:34:25 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Ruohonen", "Jukka", ""], ["Hjerppe", "Kalle", ""]]}, {"id": "2003.05268", "submitter": "Chaehan So", "authors": "Chaehan So", "title": "Human-in-the-Loop Design Cycles -- A Process Framework that Integrates\n  Design Sprints, Agile Processes, and Machine Learning with Humans", "comments": "To be published in: Lecture Notes in Artificial Intelligence, 1st\n  International Conference on Artificial Intelligence in HCI, AI-HCI, Held as\n  Part of HCI International 2020, Kopenhagen, Denmark, July 19-24, Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Demands on more transparency of the backbox nature of machine learning models\nhave led to the recent rise of human-in-the-loop in machine learning, i.e.\nprocesses that integrate humans in the training and application of machine\nlearning models. The present work argues that this process requirement does not\nrepresent an obstacle but an opportunity to optimize the design process. Hence,\nthis work proposes a new process framework, Human-in-the-learning-loop (HILL)\nDesign Cycles - a design process that integrates the structural elements of\nagile and design thinking process, and controls the training of a machine\nlearning model by the human in the loop. The HILL Design Cycles process\nreplaces the qualitative user testing by a quantitative psychometric\nmeasurement instrument for design perception. The generated user feedback\nserves to train a machine learning model and to instruct the subsequent design\ncycle along four design dimensions (novelty, energy, simplicity, tool). Mapping\nthe four-dimensional user feedback into user stories and priorities, the design\nsprint thus transforms the user feedback directly into the implementation\nprocess. The human in the loop is a quality engineer who scrutinizes the\ncollected user feedback to prevents invalid data to enter machine learning\nmodel training.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 07:35:35 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["So", "Chaehan", ""]]}, {"id": "2003.05530", "submitter": "Alarith Uhde", "authors": "Holger Klapperich, Alarith Uhde, and Marc Hassenzahl", "title": "Understanding and Designing Automation with Peoples' Wellbeing in Mind", "comments": "7 pages, 4 figures", "journal-ref": "Extended Abstracts of the 2019 CHI Conference on Human Factors in\n  Computing Systems", "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, automation not only dominates industry but becomes more and more a\npart of our private, everyday lives. Following the notion of increased\nconvenience and more time for the \"important things in life\", automation\nrelieves us from many daily household chores - robots vacuum floors and\nautomated coffeemakers produce supposedly barista-quality coffee on the press\nof a button. In many cases these offers are embraced by people without further\nquestioning. Of course, automation frees us from many unloved activities, but\nwe may also lose something by delegating more and more everyday activities to\nautomation. In a series of four studies, we explored the experiential costs of\neveryday automation and strategies of how to design technology to reconcile\nexperience with the advantages of ever more powerful automation.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 21:31:35 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Klapperich", "Holger", ""], ["Uhde", "Alarith", ""], ["Hassenzahl", "Marc", ""]]}, {"id": "2003.05533", "submitter": "Alarith Uhde", "authors": "Matthias Laschke and Alarith Uhde and Marc Hassenzahl", "title": "Positive Work Practices. Opportunities and Challenges in Designing\n  Meaningful Work-related Technology", "comments": "5 pages, to be published in Extended Abstracts of the 2020 CHI\n  Conference on Human Factors in Computing Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Work is a rich source of meaning. However, beyond organizational changes,\nmost approaches in the research field of Meaningful Work neglected the power of\nwork-related technology to increase meaning. Using two cases as examples, this\npaper proposes a wellbeing-driven approach to the design of work-related\ntechnology. Despite the positive results of our cases, we argue that the use of\ntechnology as a means of increasing meaning in the workplace is still in its\ninfancy.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 21:38:53 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Laschke", "Matthias", ""], ["Uhde", "Alarith", ""], ["Hassenzahl", "Marc", ""]]}, {"id": "2003.05719", "submitter": "Sindhu Kutty", "authors": "Sindhu Kutty, Mark Guzdial", "title": "Undergraduate Student Research With Low Faculty Cost", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Undergraduates are unlikely to even consider graduate research in Computer\nScience if they do not know what Computer Science research is. Many programs\naimed at introducing undergraduate to research are structured like graduate\nresearch programs, with a small number of undergraduates working with a faculty\nadvisor. Further, females, under-represented minorities, and first generation\nstudents may be too intimidated or the idea of research may be too amorphous,\nso that they miss out on these programs. As a consequence, we lose out on\nopportunities for greater diversity in CS research. We have started a pilot\nprogram in our department where a larger number of students (close to two\ndozen) work with a single faculty member as part of a research group focused on\nMachine Learning and related areas. The goal of this program is not to convince\nstudents to pursue a research career but rather to enable them to make a more\ninformed decision about what role they would like research to play in their\nfuture. In order to evaluate our approach, we elicited student experience via\ntwo anonymized exit surveys. Students report that they develop a better\nunderstanding of what research in Computer Science is. Their interest in\nresearch was increased as was their reported confidence in their ability to do\nresearch, although not all students wanted to further pursue computer science\nresearch opportunities. Given the reported experience of female students, this\nprogram can offer a starting point for greater diversity in CS research.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 23:54:09 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Kutty", "Sindhu", ""], ["Guzdial", "Mark", ""]]}, {"id": "2003.05720", "submitter": "Eleni Maria Kalogeraki", "authors": "Spyridon Papastergiou, Haralambos Mouratidis, Eleni-Maria Kalogeraki", "title": "Cyber Security Incident Handling, Warning and Response System for the\n  European Critical Information Infrastructures (CyberSANE)", "comments": null, "journal-ref": "Engineering Applications of Neural Networks -20th International\n  Conference (EANN2019) Proceedings. Communications in Computer and Information\n  Science (vol.1000) 476-487 Springer Cham", "doi": "10.1007/978-3-030-20257-6_41", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to enhance the security and resilience of Critical\nInformation Infrastructures (CIIs) by providing a dynamic collaborative,\nwarning and response system (CyberSANE system) supporting and guiding security\nofficers and operators (e.g. Incident Response professionals) to recognize,\nidentify, dynamically analyse, forecast, treat and respond to their threats and\nrisks and handle their daily cyber incidents. The proposed solution provides a\nfirst of a kind approach for handling cyber security incidents in the digital\nenvironments with highly interconnected, complex and diverse nature.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 15:25:40 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Papastergiou", "Spyridon", ""], ["Mouratidis", "Haralambos", ""], ["Kalogeraki", "Eleni-Maria", ""]]}, {"id": "2003.05873", "submitter": "Viet-Thi Tran", "authors": "Philippe Ravaud, Franck le Ouay, Etienne Depaulis, Alexandre Huckert,\n  Bruno Vegreville and Viet-Thi Tran", "title": "Reconfiguring health services to reduce the workload of caregivers\n  during the COVID-19 outbreak using an open-source scalable platform for\n  remote digital monitoring and coordination of care in hospital Command\n  Centres", "comments": "4 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Covid-19 outbreak threatens to saturate healthcare systems in most\nWestern countries. We describe how digital technologies may be used to\nautomatically and remotely monitor patients at home. Patients answer simple\nself-reported questionnaires and their data is transmitted, in real time, to a\nCommand Centre in the nearest reference hospital. Patient reported data are\nautomatically filtered by algorithms to identify those with early warning\nsigns. Open-source code of all software components required to deploy the\nremote digital monitoring platform and Command Centres is available.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 16:08:09 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Ravaud", "Philippe", ""], ["Ouay", "Franck le", ""], ["Depaulis", "Etienne", ""], ["Huckert", "Alexandre", ""], ["Vegreville", "Bruno", ""], ["Tran", "Viet-Thi", ""]]}, {"id": "2003.05980", "submitter": "Zichao Wang", "authors": "Zichao Wang, Sebastian Tschiatschek, Simon Woodhead, Jose Miguel\n  Hernandez-Lobato, Simon Peyton Jones, Richard G. Baraniuk, Cheng Zhang", "title": "Educational Question Mining At Scale: Prediction, Analysis and\n  Personalization", "comments": "Accepted at AAAI-EAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online education platforms enable teachers to share a large number of\neducational resources such as questions to form exercises and quizzes for\nstudents. With large volumes of available questions, it is important to have an\nautomated way to quantify their properties and intelligently select them for\nstudents, enabling effective and personalized learning experiences. In this\nwork, we propose a framework for mining insights from educational questions at\nscale. We utilize the state-of-the-art Bayesian deep learning method, in\nparticular partial variational auto-encoders (p-VAE), to analyze real students'\nanswers to a large collection of questions. Based on p-VAE, we propose two\nnovel metrics that quantify question quality and difficulty, respectively, and\na personalized strategy to adaptively select questions for students. We apply\nour proposed framework to a real-world dataset with tens of thousands of\nquestions and tens of millions of answers from an online education platform.\nOur framework not only demonstrates promising results in terms of statistical\nmetrics but also obtains highly consistent results with domain experts'\nevaluation.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 19:07:49 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 04:04:32 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Wang", "Zichao", ""], ["Tschiatschek", "Sebastian", ""], ["Woodhead", "Simon", ""], ["Hernandez-Lobato", "Jose Miguel", ""], ["Jones", "Simon Peyton", ""], ["Baraniuk", "Richard G.", ""], ["Zhang", "Cheng", ""]]}, {"id": "2003.06199", "submitter": "Takashi Okumura", "authors": "Ikki Ohmukai, Yasunori Yamamoto, Maori Ito, Takashi Okumura", "title": "Tracing patients' PLOD with mobile phones: Mitigation of epidemic risks\n  through patients' locational open data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the cases when public health authorities confirm a patient with highly\ncontagious disease, they release the summaries about patient locations and\ntravel information. However, due to privacy concerns, these releases do not\ninclude the detailed data and typically comprise the information only about\ncommercial facilities and public transportation used by the patients. We\naddressed this problem and proposed to release the patient location data as\nopen data represented in a structured form of the information described in\npress releases. Therefore, residents would be able to use these data for\nautomated estimation of the potential risks of contacts combined with the\nlocation information stored in their mobile phones. This paper proposes the\ndesign of the open data based on Resource Description Framework (RDF), and\nperforms a preliminary evaluation of the first draft of the specification\nfollowed by a discussion on possible future directions.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 11:00:26 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Ohmukai", "Ikki", ""], ["Yamamoto", "Yasunori", ""], ["Ito", "Maori", ""], ["Okumura", "Takashi", ""]]}, {"id": "2003.06507", "submitter": "Gabriel Lima", "authors": "Gabriel Lima, Meeyoung Cha, Chihyung Jeon, Kyungsin Park", "title": "The Punishment Gap: The Infeasible Public Attribution of Punishment to\n  AI and Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper revisits the debate around the legal personhood of AI and robots,\nwhich has been highly sensitive yet important in the face of broad adoption of\nautonomous and self-learning systems. We conducted a survey ($N$=3,315) to\nunderstand lay people's perceptions of this topic and analyzed how they would\nassign responsibility, awareness, and punishment to AI, robots, humans, and\nvarious entities that could be held liable under existing doctrines. Even\nthough people did not recognize any mental state for automated agents, they\nstill attributed punishment and responsibility to these entities. While the\nparticipants mostly agreed AI systems could be reformed given punishment, they\ndid not believe such punishment would achieve its retributive and deterrence\nfunctions. Moreover, participants were also unwilling to grant automated agents\nessential punishment preconditions, namely physical independence or assets. We\nterm this contradiction the punishment gap. We also observe the same punishment\ngap on a demographically representative sample of U.S. residents ($N$=244). We\ndiscuss implications of these findings for how legal and social decisions could\ninfluence how the public attributes responsibility and punishment to automated\nagents.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 23:19:58 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2021 02:55:49 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Lima", "Gabriel", ""], ["Cha", "Meeyoung", ""], ["Jeon", "Chihyung", ""], ["Park", "Kyungsin", ""]]}, {"id": "2003.06530", "submitter": "David Pastor-Escuredo", "authors": "David Pastor-Escuredo", "title": "Ethics in the digital era", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Ethics is an ancient matter for human kind, from the origin of civilizations\nethics have been related with the most relevant human concerns and determined\ncultures. Ethics was initially related to religion, politics and philosophy to\nthen be fragmented into specific communities of practice. The undergoing\ndigital revolution enabled by Artificial Intelligence and Data are bringing\nethical wicked problems in the social application of these technologies.\nHowever, a broader perspective is also necessary. We now face global and highly\ndynamics challenges that affect groups and individuals, specially those that\nare most vulnerable. Individual-oriented ethics are no longer sufficient, the\nnew ethic has to consider the several scales in which the current complex\nsociety is organized and the interconnections between different systems. Ethics\nshould also give a response to the systemic changes in behavior produced by\nexternal factors and threats. Furthermore, AI and digital technologies are\nglobal and make us more connected and smart but also more homogeneous,\npredictable and ultimately controllable. Ethic must take a stand to preserve\nand keep promoting individuals rights and uniqueness and cultural\nheterogeneity. Digital technologies have to the foundation for new models of\nsociety and help ensure ethical individual and collective values. For these\nreasons science has to be at the core of the new ethic as it helps understand\nthe complex world. Finally, AI has advanced through the ambition to humanize\nmatter, so we should expect ethics to give a response to the future status of\nmachines and their interactions with humans.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 01:32:11 GMT"}, {"version": "v2", "created": "Sun, 22 Mar 2020 21:06:07 GMT"}, {"version": "v3", "created": "Mon, 11 May 2020 03:27:08 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Pastor-Escuredo", "David", ""]]}, {"id": "2003.06695", "submitter": "Mojtaba Noghabaei", "authors": "Gilmarie O'Neill, Matthew Ball, Yujing Liu, Mojtaba Noghabaei, and\n  Kevin Han", "title": "Toward Automated Virtual Assembly for Prefabricated Construction:\n  Construction Sequencing through Simulated BIM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To adhere to the stringent time and budget requirements of construction\nprojects, contractors are utilizing prefabricated construction methods to\nexpedite the construction process. Prefabricated construction methods require\nan adequate schedule and understanding by the contractors and constructors to\nbe successful. The specificity of prefabricated construction often leads to\ninefficient scheduling and costly rework time. The designer, contractor, and\nconstructors must have a strong understanding of the assembly process to\nexperience the full benefits of the method. At the root of understanding the\nassembly process is visualizing how the process is intended to be performed.\nCurrently, a virtual construction model is used to explain and better visualize\nthe construction process. However, creating a virtual construction model is\ncurrently time consuming and requires experienced personnel. The proposed\nsimulation of the virtual assembly will increase the automation of virtual\nconstruction modeling by implementing the data available in a building\ninformation modeling (BIM) model. This paper presents various factors (i.e.,\nformalization of construction sequence based on the level of development (LOD))\nthat needs to be addressed for the development of automated virtual assembly.\nTwo case studies are presented to demonstrate these factors.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 20:17:33 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["O'Neill", "Gilmarie", ""], ["Ball", "Matthew", ""], ["Liu", "Yujing", ""], ["Noghabaei", "Mojtaba", ""], ["Han", "Kevin", ""]]}, {"id": "2003.06846", "submitter": "Li LiXiang", "authors": "Lixiang Li, Zihang Yang, Zhongkai Dang, Cui Meng, Jingze Huang, Hao\n  Tian Meng, Deyu Wang, Guanhua Chen, Jiaxuan Zhang, Haipeng Peng", "title": "Propagation analysis and prediction of the COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on the official data modeling, this paper studies the transmission\nprocess of the Corona Virus Disease 2019 (COVID-19). The error between the\nmodel and the official data curve is within 3%. At the same time, it realized\nforward prediction and backward inference of the epidemic situation, and the\nrelevant analysis help relevant countries to make decisions.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 15:08:57 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Li", "Lixiang", ""], ["Yang", "Zihang", ""], ["Dang", "Zhongkai", ""], ["Meng", "Cui", ""], ["Huang", "Jingze", ""], ["Meng", "Hao Tian", ""], ["Wang", "Deyu", ""], ["Chen", "Guanhua", ""], ["Zhang", "Jiaxuan", ""], ["Peng", "Haipeng", ""]]}, {"id": "2003.06857", "submitter": "Tugrulcan Elmas", "authors": "Tu\\u{g}rulcan Elmas, Kristina Hardi, Rebekah Overdorf, Karl Aberer", "title": "Can Celebrities Burst Your Bubble?", "comments": "5 pages, 3 figures, accepted for non-archival track of IID2020,\n  workshop in WWW2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Polarization is a growing, global problem. As such, many social media based\nsolutions have been proposed in order to reduce it. In this study, we propose a\nnew solution that recommends topics to celebrities to encourage them to join a\npolarized debate and increase exposure to contrarian content - bursting the\nfilter bubble. Using a state-of-the art model that quantifies the degree of\npolarization, this paper makes a first attempt to empirically answer the\nquestion: Can celebrities burst filter bubbles? We use a case study to analyze\nhow people react when celebrities are involved in a controversial topic and\nconclude with a list possible research directions.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 15:53:27 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 01:03:04 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Elmas", "Tu\u011frulcan", ""], ["Hardi", "Kristina", ""], ["Overdorf", "Rebekah", ""], ["Aberer", "Karl", ""]]}, {"id": "2003.06862", "submitter": "Nelson Bore K", "authors": "Nelson Bore, Andrew Kinai, Peninah Waweru, Isaac Wambugu, Juliet\n  Mutahi, Everlyne Kemunto, Reginald Bryant, Komminist Weldemariam", "title": "ADW: Blockchain-enabled Small-scale Farm Digitization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Farm records hold the static, temporal, and longitudinal details of the\nfarms. For small-scale farming, the ability to accurately capture these records\nplays a critical role in formalizing and digitizing the agriculture industry.\nReliable exchange of these record through a trusted platform could unlock\ncritical and valuable insights to different stakeholders across the value chain\nin agriculture eco-system. Lately, there has been increasing attention on\ndigitization of small scale farming with the objective of providing farm-level\ntransparency, accountability, visibility, access to farm loans, etc. using\nthese farm records. However, most solutions proposed so far have the\nshortcoming of providing detailed, reliable and trusted small-scale farm\ndigitization information in real time. To address these challenges, we present\na system, called Agribusiness Digital Wallet (ADW), which leverages blockchain\nto formalize the interactions and enable seamless data flow in small-scale\nfarming ecosystem. Utilizing instrumentation of farm tractors, we demonstrate\nthe ability to utilize farm activities to create trusted electronic field\nrecords (EFR) with automated valuable insights. Using ADW, we processed several\nthousands of small-scale farm-level activity events for which we also performed\nautomated farm boundary detection of a number of farms in different\ngeographies.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 16:15:20 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Bore", "Nelson", ""], ["Kinai", "Andrew", ""], ["Waweru", "Peninah", ""], ["Wambugu", "Isaac", ""], ["Mutahi", "Juliet", ""], ["Kemunto", "Everlyne", ""], ["Bryant", "Reginald", ""], ["Weldemariam", "Komminist", ""]]}, {"id": "2003.07019", "submitter": "Manikandan Ravikiran", "authors": "Manikandan Ravikiran", "title": "Key Phrase Classification in Complex Assignments", "comments": "v1 preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Complex assignments typically consist of open-ended questions with large and\ndiverse content in the context of both classroom and online graduate programs.\nWith the sheer scale of these programs comes a variety of problems in peer and\nexpert feedback, including rogue reviews. As such with the hope of identifying\nimportant contents needed for the review, in this work we present a very first\nwork on key phrase classification with a detailed empirical study on\ntraditional and most recent language modeling approaches. From this study, we\nfind that the task of classification of key phrases is ambiguous at a human\nlevel producing Cohen's kappa of 0.77 on a new data set. Both pretrained\nlanguage models and simple TFIDF SVM classifiers produce similar results with a\nformer producing average of 0.6 F1 higher than the latter. We finally derive\npractical advice from our extensive empirical and model interpretability\nresults for those interested in key phrase classification from educational\nreports in the future.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 04:25:37 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Ravikiran", "Manikandan", ""]]}, {"id": "2003.07049", "submitter": "Marian-Andrei Rizoiu", "authors": "Paul X. McCarthy, Xian Gong, Sina Eghbal, Daniel S. Falster,\n  Marian-Andrei Rizoiu", "title": "Evolution of diversity and dominance of companies in online activity", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0249993", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Ever since the web began, the number of websites has been growing\nexponentially. These websites cover an ever-increasing range of online services\nthat fill a variety of social and economic functions across a growing range of\nindustries. Yet the networked nature of the web, combined with the economics of\npreferential attachment, increasing returns and global trade, suggest that over\nthe long run a small number of competitive giants are likely to dominate each\nfunctional market segment, such as search, retail and social media. Here we\nperform a large scale longitudinal study to quantify the distribution of\nattention given in the online environment to competing organisations. In two\nlarge online social media datasets, containing more than 10 billion posts and\nspanning more than a decade, we tally the volume of external links posted\ntowards the organisations' main domain name as a proxy for the online attention\nthey receive. We also use the Common Crawl dataset -- which contains the\nlinkage patterns between more than a billion different websites -- to study the\npatterns of link concentration over the past three years across the entire web.\nLastly, we showcase the linking between economic, financial and market data by\nexploring the relationships between online attention on social media and the\ngrowth in enterprise value in the electric carmaker Tesla. Our analysis shows\nthat despite the fact that we observe consistent growth in all the macro\nindicators -- the total amount of online attention, in the number of\norganisations with an online presence, and in the functions they perform -- we\nalso observe that a smaller number of organisations account for an\never-increasing proportion of total user attention, usually with one large\nplayer dominating each function. These results highlight how evolution of the\nonline economy involves innovation, diversity, and then competitive dominance.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 07:06:56 GMT"}, {"version": "v2", "created": "Thu, 1 Apr 2021 22:48:00 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["McCarthy", "Paul X.", ""], ["Gong", "Xian", ""], ["Eghbal", "Sina", ""], ["Falster", "Daniel S.", ""], ["Rizoiu", "Marian-Andrei", ""]]}, {"id": "2003.07074", "submitter": "Tavpritesh Sethi", "authors": "Rohan Pandey, Vaibhav Gautam, Ridam Pal, Harsh Bandhey, Lovedeep Singh\n  Dhingra, Himanshu Sharma, Chirag Jain, Kanav Bhagat, Arushi, Lajjaben Patel,\n  Mudit Agarwal, Samprati Agrawal, Rishabh Jalan, Akshat Wadhwa, Ayush Garg,\n  Vihaan Misra, Yashwin Agrawal, Bhavika Rana, Ponnurangam Kumaraguru,\n  Tavpritesh Sethi", "title": "A Machine Learning Application for Raising WASH Awareness in the Times\n  of COVID-19 Pandemic", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Background: The COVID-19 pandemic has uncovered the potential of digital\nmisinformation in shaping the health of nations. The deluge of unverified\ninformation that spreads faster than the epidemic itself is an unprecedented\nphenomenon that has put millions of lives in danger. Mitigating this Infodemic\nrequires strong health messaging systems that are engaging, vernacular,\nscalable, effective and continuously learn the new patterns of misinformation.\n  Objective: We created WashKaro, a multi-pronged intervention for mitigating\nmisinformation through conversational AI, machine translation and natural\nlanguage processing. WashKaro provides the right information matched against\nWHO guidelines through AI, and delivers it in the right format in local\nlanguages.\n  Methods: We theorize (i) an NLP based AI engine that could continuously\nincorporate user feedback to improve relevance of information, (ii) bite sized\naudio in the local language to improve penetrance in a country with skewed\ngender literacy ratios, and (iii) conversational but interactive AI engagement\nwith users towards an increased health awareness in the community. Results: A\ntotal of 5026 people who downloaded the app during the study window, among\nthose 1545 were active users. Our study shows that 3.4 times more females\nengaged with the App in Hindi as compared to males, the relevance of\nAI-filtered news content doubled within 45 days of continuous machine learning,\nand the prudence of integrated AI chatbot Satya increased thus proving the\nusefulness of an mHealth platform to mitigate health misinformation.\n  Conclusion: We conclude that a multi-pronged machine learning application\ndelivering vernacular bite-sized audios and conversational AI is an effective\napproach to mitigate health misinformation.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 08:51:40 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2020 09:14:47 GMT"}, {"version": "v3", "created": "Fri, 30 Oct 2020 15:49:04 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Pandey", "Rohan", ""], ["Gautam", "Vaibhav", ""], ["Pal", "Ridam", ""], ["Bandhey", "Harsh", ""], ["Dhingra", "Lovedeep Singh", ""], ["Sharma", "Himanshu", ""], ["Jain", "Chirag", ""], ["Bhagat", "Kanav", ""], ["Arushi", "", ""], ["Patel", "Lajjaben", ""], ["Agarwal", "Mudit", ""], ["Agrawal", "Samprati", ""], ["Jalan", "Rishabh", ""], ["Wadhwa", "Akshat", ""], ["Garg", "Ayush", ""], ["Misra", "Vihaan", ""], ["Agrawal", "Yashwin", ""], ["Rana", "Bhavika", ""], ["Kumaraguru", "Ponnurangam", ""], ["Sethi", "Tavpritesh", ""]]}, {"id": "2003.07096", "submitter": "Ahmed Maalel Dr", "authors": "Ahmed Maalel and Henda Ben Gh\\'ezala", "title": "Towards a Collaborative Approach to Decision Making Based on Ontology\n  and Multi-Agent System Application to crisis management", "comments": "6 pages, 4 figures", "journal-ref": "Procedia Computer Science 164 193,198 (2019)", "doi": "10.1016/j.procs.2019.12.172", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The coordination and cooperation of all the stakeholders involved is a\ndecisive point for the control and the resolution of problems. In the\ninsecurity events, the resolution should refer to a plan that defines a general\nframework of the procedures to be undertaken and the instructions to be\ncomplied with; also, a more precise process must be defined by the actors to\ndeal with the case represented by the particular problem of the current\nsituation. Indeed, this process has to cope with a dynamic, unstable and\nunpredictable environment, due to the heterogeneity and multiplicity of\nstakeholders, and finally due to their possible geographical distribution. In\nthis article, we will present the first steps of validation of a collaborative\ndecision-making approach in the context of crisis situations such as road\naccidents. This approach is based on ontologies and multi-agent systems.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 10:17:04 GMT"}], "update_date": "2020-06-14", "authors_parsed": [["Maalel", "Ahmed", ""], ["Gh\u00e9zala", "Henda Ben", ""]]}, {"id": "2003.07279", "submitter": "David Pastor-Escuredo", "authors": "David Pastor-Escuredo, Enrique Frias-Martinez", "title": "Flow descriptors of human mobility networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Mobile phone data has enabled the timely and fine-grained study human\nmobility. Call Detail Records, generated at call events, allow building\ndescriptions of mobility at different resolutions and with different spatial,\ntemporal and social granularity. Individual trajectories are the basis for\nlong-term observation of mobility patterns and identify factors of human\ndynamics. Here we propose a systematic analysis to characterize mobility\nnetwork flows and topology and assess their impact into individual traces.\nDiscrete flow-based descriptors are used to classify and understand human\nmobility patterns at multiple scales. This framework is suitable to assess\nurban planning, optimize transportation, measure the impact of external events\nand conditions, monitor internal dynamics and profile users according to their\nmovement patterns.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 15:27:00 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Pastor-Escuredo", "David", ""], ["Frias-Martinez", "Enrique", ""]]}, {"id": "2003.07370", "submitter": "Vivian Lai", "authors": "Vivian Lai, Samuel Carton, Chenhao Tan", "title": "Harnessing Explanations to Bridge AI and Humans", "comments": "4 pages, CHI 2020 Fair & Responsible AI Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are increasingly integrated into societally critical\napplications such as recidivism prediction and medical diagnosis, thanks to\ntheir superior predictive power. In these applications, however, full\nautomation is often not desired due to ethical and legal concerns. The research\ncommunity has thus ventured into developing interpretable methods that explain\nmachine predictions. While these explanations are meant to assist humans in\nunderstanding machine predictions and thereby allowing humans to make better\ndecisions, this hypothesis is not supported in many recent studies. To improve\nhuman decision-making with AI assistance, we propose future directions for\nclosing the gap between the efficacy of explanations and improvement in human\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 18:00:02 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Lai", "Vivian", ""], ["Carton", "Samuel", ""], ["Tan", "Chenhao", ""]]}, {"id": "2003.07595", "submitter": "Dennis Assenmacher", "authors": "Lena Clever, Dennis Assenmacher, Kilian M\\\"uller, Moritz Vinzent\n  Seiler, Dennis M. Riehle, Mike Preuss, Christian Grimme", "title": "FakeYou! -- A Gamified Approach for Building and Evaluating Resilience\n  Against Fake News", "comments": "accepted for Disinformation in Open Online Media - 2nd\n  Multidisciplinary International Symposium, MISDOOM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays fake news are heavily discussed in public and political debates.\nEven though the phenomenon of intended false information is rather old,\nmisinformation reaches a new level with the rise of the internet and\nparticipatory platforms. Due to Facebook and Co., purposeful false information\n- often called fake news - can be easily spread by everyone. Because of a high\ndata volatility and variety in content types (text, images,...) debunking of\nfake news is a complex challenge. This is especially true for automated\napproaches, which are prone to fail validating the veracity of the information.\nThis work focuses on an a gamified approach to strengthen the resilience of\nconsumers towards fake news. The game FakeYou motivates its players to\ncritically analyze headlines regarding their trustworthiness. Further, the game\nfollows a \"learning by doing strategy\": by generating own fake headlines, users\nshould experience the concepts of convincing fake headline formulations. We\nintroduce the game itself, as well as the underlying technical infrastructure.\nA first evaluation study shows, that users tend to use specific stylistic\ndevices to generate fake news. Further, the results indicate, that creating\ngood fakes and identifying correct headlines are challenging and hard to learn.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 09:24:22 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Clever", "Lena", ""], ["Assenmacher", "Dennis", ""], ["M\u00fcller", "Kilian", ""], ["Seiler", "Moritz Vinzent", ""], ["Riehle", "Dennis M.", ""], ["Preuss", "Mike", ""], ["Grimme", "Christian", ""]]}, {"id": "2003.07621", "submitter": "Erik-Jan van Kesteren", "authors": "Laura Boeschoten, Erik-Jan van Kesteren, Ayoub Bagheri, Daniel L.\n  Oberski", "title": "Fair inference on error-prone outcomes", "comments": "Online supplementary code is available at\n  https://dx.doi.org/10.5281/zenodo.3708150", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fair inference in supervised learning is an important and active area of\nresearch, yielding a range of useful methods to assess and account for fairness\ncriteria when predicting ground truth targets. As shown in recent work,\nhowever, when target labels are error-prone, potential prediction unfairness\ncan arise from measurement error. In this paper, we show that, when an\nerror-prone proxy target is used, existing methods to assess and calibrate\nfairness criteria do not extend to the true target variable of interest. To\nremedy this problem, we suggest a framework resulting from the combination of\ntwo existing literatures: fair ML methods, such as those found in the\ncounterfactual fairness literature on the one hand, and, on the other,\nmeasurement models found in the statistical literature. We discuss these\napproaches and their connection resulting in our framework. In a healthcare\ndecision problem, we find that using a latent variable model to account for\nmeasurement error removes the unfairness detected previously.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 10:31:59 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Boeschoten", "Laura", ""], ["van Kesteren", "Erik-Jan", ""], ["Bagheri", "Ayoub", ""], ["Oberski", "Daniel L.", ""]]}, {"id": "2003.07671", "submitter": "Tao Gu", "authors": "Sasitharan Balasubramaniam, Dmitri Botvich, Tao Gu, William Donnelly", "title": "Chemotaxis and Quorum Sensing inspired Device Interaction supporting\n  Social Networking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conference and social events provides an opportunity for people to interact\nand develop formal contacts with various groups of individuals. In this paper,\nwe propose an efficient interaction mechanism in a pervasive computing\nenvironment that provide recommendation to users of suitable locations within a\nconference or expo hall to meet and interact with individuals of similar\ninterests. The proposed solution is based on evaluation of context information\nto deduce each user's interests as well as bioinspired self-organisation\nmechanism to direct users towards appropriate locations.Simulation results have\nalso been provided to validate our proposed solution.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 12:27:57 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Balasubramaniam", "Sasitharan", ""], ["Botvich", "Dmitri", ""], ["Gu", "Tao", ""], ["Donnelly", "William", ""]]}, {"id": "2003.07672", "submitter": "Rateb Jabbar Mr.", "authors": "Rateb Jabbar, Mohammed Shinoy, Mohamed Kharbeche, Khalifa Al-Khalifa,\n  Moez Krichenz and Kamel Barkaouiy", "title": "Urban Traffic Monitoring and Modeling System: An IoT Solution for\n  Enhancing Road Safety", "comments": "6 pages, 6 figures, conference IINTEC'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Qatar expects more than a million visitors during the 2022 World Cup, which\nwill pose significant challenges. The high number of people will likely cause a\nrise in road traffic congestion, vehicle crashes, injuries and deaths. To\ntackle this problem, Naturalistic Driver Behavior can be utilised which will\ncollect and analyze data to estimate the current Qatar traffic system,\nincluding traffic data infrastructure, safety planning, and engineering\npractices and standards. In this paper, an IoT based solution to facilitate\nsuch a study in Qatar is proposed. Different data points from a driver are\ncollected and recorded in an unobtrusive manner, such as trip data, GPS\ncoordinates, compass heading, minimum, average, and maximum speed and his\ndriving behavior, including driver's drowsiness level. Analysis of these data\npoints will help in prediction of crashes and road infrastructure improvements\nto reduce such events. It will also be used for drivers risk assessment and to\ndetect extreme road user behaviors. A framework that will help to visualize and\nmanage this data is also proposed, along with a Deep Learning-based application\nthat detects drowsy driving behavior that netted an 82 percent accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 23:57:47 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Jabbar", "Rateb", ""], ["Shinoy", "Mohammed", ""], ["Kharbeche", "Mohamed", ""], ["Al-Khalifa", "Khalifa", ""], ["Krichenz", "Moez", ""], ["Barkaouiy", "Kamel", ""]]}, {"id": "2003.07674", "submitter": "Michael Brunner", "authors": "Michael Brunner, Clemens Sauerwein, Michael Felderer and Ruth Breu", "title": "Risk Management Practices in Information Security: Exploring the Status\n  Quo in the DACH Region", "comments": null, "journal-ref": "Computers & Security 92 (2020)", "doi": "10.1016/j.cose.2020.101776", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information security management aims at ensuring proper protection of\ninformation values and information processing systems (i.e. assets).\nInformation security risk management techniques are incorporated to deal with\nthreats and vulnerabilities that impose risks to information security\nproperties of these assets. This paper investigates the current state of risk\nmanagement practices being used in information security management in the DACH\nregion (Germany, Austria, Switzerland). We used an anonymous online survey\ntargeting strategic and operative information security and risk managers and\ncollected data from 26 organizations. We analyzed general practices,\ndocumentation artifacts, patterns of stakeholder collaboration as well as tool\ntypes and data sources used by enterprises to conduct information security\nmanagement activities. Our findings show that the state of practice of\ninformation security risk management is in need of improvement. Current\nindustrial practice heavily relies on manual data collection and complex\npotentially subjective decision processes with multiple stakeholders involved.\nDedicated risk management tools and methods are used selectively and neglected\nin favor of general-purpose documentation tools and direct communication\nbetween stakeholders. In light of our results we propose guidelines for the\ndevelopment of risk management practices that are better aligned with the\ncurrent operational situation in information security management.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 10:11:44 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Brunner", "Michael", ""], ["Sauerwein", "Clemens", ""], ["Felderer", "Michael", ""], ["Breu", "Ruth", ""]]}, {"id": "2003.07678", "submitter": "Charles Lu", "authors": "Charles Lu, Julia Strout, Romane Gauriau, Brad Wright, Fabiola Bezerra\n  De Carvalho Marcruz, Varun Buch, Katherine Andriole", "title": "An Overview and Case Study of the Clinical AI Model Development Life\n  Cycle for Healthcare Systems", "comments": "Accepted for oral presentation at ICLR 2020, AI for Affordable\n  Healthcare workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Healthcare is one of the most promising areas for machine learning models to\nmake a positive impact. However, successful adoption of AI-based systems in\nhealthcare depends on engaging and educating stakeholders from diverse\nbackgrounds about the development process of AI models. We present a broadly\naccessible overview of the development life cycle of clinical AI models that is\ngeneral enough to be adapted to most machine learning projects, and then give\nan in-depth case study of the development process of a deep learning based\nsystem to detect aortic aneurysms in Computed Tomography (CT) exams. We hope\nother healthcare institutions and clinical practitioners find the insights we\nshare about the development process useful in informing their own model\ndevelopment efforts and to increase the likelihood of successful deployment and\nintegration of AI in healthcare.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 21:35:13 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 19:45:26 GMT"}, {"version": "v3", "created": "Thu, 26 Mar 2020 21:03:35 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Lu", "Charles", ""], ["Strout", "Julia", ""], ["Gauriau", "Romane", ""], ["Wright", "Brad", ""], ["Marcruz", "Fabiola Bezerra De Carvalho", ""], ["Buch", "Varun", ""], ["Andriole", "Katherine", ""]]}, {"id": "2003.07679", "submitter": "Justin Weisz", "authors": "Stephanie Houde, Vera Liao, Jacquelyn Martino, Michael Muller, David\n  Piorkowski, John Richards, Justin Weisz, Yunfeng Zhang", "title": "Business (mis)Use Cases of Generative AI", "comments": "IUI 2020 Workshop on Human-AI Co-Creation with Generative Models", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative AI is a class of machine learning technology that learns to\ngenerate new data from training data. While deep fakes and media-and\nart-related generative AI breakthroughs have recently caught people's attention\nand imagination, the overall area is in its infancy for business use. Further,\nlittle is known about generative AI's potential for malicious misuse at large\nscale. Using co-creation design fictions with AI engineers, we explore the\nplausibility and severity of business misuse cases.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 14:24:59 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Houde", "Stephanie", ""], ["Liao", "Vera", ""], ["Martino", "Jacquelyn", ""], ["Muller", "Michael", ""], ["Piorkowski", "David", ""], ["Richards", "John", ""], ["Weisz", "Justin", ""], ["Zhang", "Yunfeng", ""]]}, {"id": "2003.07680", "submitter": "Po-Ming Law", "authors": "Po-Ming Law, Sana Malik, Fan Du, Moumita Sinha", "title": "Designing Tools for Semi-Automated Detection of Machine Learning Biases:\n  An Interview Study", "comments": "Proceedings of the CHI 2020 Workshop on Detection and Design for\n  Cognitive Biases in People and Computing Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models often make predictions that bias against certain\nsubgroups of input data. When undetected, machine learning biases can\nconstitute significant financial and ethical implications. Semi-automated tools\nthat involve humans in the loop could facilitate bias detection. Yet, little is\nknown about the considerations involved in their design. In this paper, we\nreport on an interview study with 11 machine learning practitioners for\ninvestigating the needs surrounding semi-automated bias detection tools. Based\non the findings, we highlight four considerations in designing to guide system\ndesigners who aim to create future tools for bias detection.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 00:18:58 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 01:41:40 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Law", "Po-Ming", ""], ["Malik", "Sana", ""], ["Du", "Fan", ""], ["Sinha", "Moumita", ""]]}, {"id": "2003.07681", "submitter": "Heriberto Acosta-Maestre", "authors": "Latifa Jackson and Heriberto Acosta Maestre", "title": "The Data Science Fire Next Time: Innovative strategies for mentoring in\n  data science", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ed-ph cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As data mining research and applications continue to expand in to a variety\nof fields such as medicine, finance, security, etc., the need for talented and\ndiverse individuals is clearly felt. This is particularly the case as Big Data\ninitiatives have taken off in the federal, private and academic sectors,\nproviding a wealth of opportunities, nationally and internationally. The\nBroadening Participation in Data Mining (BPDM) workshop was created more than 7\nyears ago with the goal of fostering mentorship, guidance, and connections for\nminority and underrepresented groups in the data science and machine learning\ncommunity, while also enriching technical aptitude and exposure for a group of\ntalented students. To date it has impacted the lives of more than 330\nunderrepresented trainees in data science. We provide a venue to connect\ntalented students with innovative researchers in industry, academia,\nprofessional societies, and government. Our mission is to facilitate\nmeaningful, lasting relationships between BPDM participants to ultimately\nincrease diversity in data mining. This most recent workshop took place at\nHoward University in Washington, DC in February 2019. Here we report on the\nmentoring strategies that we undertook at the 2019 BPDM and how those were\nreceived.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 03:40:38 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Jackson", "Latifa", ""], ["Maestre", "Heriberto Acosta", ""]]}, {"id": "2003.07683", "submitter": "Chaehan So", "authors": "Chaehan So", "title": "Who Wins the Game of Thrones? How Sentiments Improve the Prediction of\n  Candidate Choice", "comments": "To be published in IEEE conference proceedings: International\n  Conference on Artificial Intelligence in Information and Communication,\n  ICAIIC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyzes how candidate choice prediction improves by different\npsychological predictors. To investigate this question, it collected an\noriginal survey dataset featuring the popular TV series \"Game of Thrones\". The\nrespondents answered which character they anticipated to win in the final\nepisode of the series, and explained their choice of the final candidate in\nfree text from which sentiments were extracted. These sentiments were compared\nto feature sets derived from candidate likeability and candidate personality\nratings. In our benchmarking of 10-fold cross-validation in 100 repetitions,\nall feature sets except the likeability ratings yielded a 10-11% improvement in\naccuracy on the holdout set over the base model. Treating the class imbalance\nwith synthetic minority oversampling (SMOTE) increased holdout set performance\nby 20-34% but surprisingly not testing set performance. Taken together, our\nstudy provides a quantified estimation of the additional predictive value of\npsychological predictors. Likeability ratings were clearly outperformed by the\nfeature sets based on personality, emotional valence, and basic emotions.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 04:30:28 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["So", "Chaehan", ""]]}, {"id": "2003.07684", "submitter": "Austin Hounsel", "authors": "Austin Hounsel, Jordan Holland, Ben Kaiser, Kevin Borgolte, Nick\n  Feamster, Jonathan Mayer", "title": "Identifying Disinformation Websites Using Infrastructure Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Platforms have struggled to keep pace with the spread of disinformation.\nCurrent responses like user reports, manual analysis, and third-party fact\nchecking are slow and difficult to scale, and as a result, disinformation can\nspread unchecked for some time after being created. Automation is essential for\nenabling platforms to respond rapidly to disinformation. In this work, we\nexplore a new direction for automated detection of disinformation websites:\ninfrastructure features. Our hypothesis is that while disinformation websites\nmay be perceptually similar to authentic news websites, there may also be\nsignificant non-perceptual differences in the domain registrations, TLS/SSL\ncertificates, and web hosting configurations. Infrastructure features are\nparticularly valuable for detecting disinformation websites because they are\navailable before content goes live and reaches readers, enabling early\ndetection. We demonstrate the feasibility of our approach on a large corpus of\nlabeled website snapshots. We also present results from a preliminary real-time\ndeployment, successfully discovering disinformation websites while highlighting\nunexplored challenges for automated disinformation detection.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 18:40:54 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 20:08:22 GMT"}, {"version": "v3", "created": "Sun, 2 Aug 2020 20:07:04 GMT"}, {"version": "v4", "created": "Fri, 4 Sep 2020 17:41:03 GMT"}, {"version": "v5", "created": "Mon, 28 Sep 2020 22:53:39 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Hounsel", "Austin", ""], ["Holland", "Jordan", ""], ["Kaiser", "Ben", ""], ["Borgolte", "Kevin", ""], ["Feamster", "Nick", ""], ["Mayer", "Jonathan", ""]]}, {"id": "2003.07687", "submitter": "Maiia Marienko", "authors": "Mariya P. Shyshkina, Maiia V. Marienko", "title": "Augmented reality as a tool for open science platform by research\n  collaboration in virtual teams", "comments": "10 pages, Proceedings of the 2nd International Workshop on Augmented\n  Reality in Education", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The provision of open science is defined as a general policy aimed at\novercoming the barriers that hinder the implementation of the European Research\nArea (ERA). An open science foundation seeks to capture all the elements needed\nfor the functioning of ERA: research data, scientific instruments, ICT services\n(connections, calculations, platforms, and specific studies such as portals).\nManaging shared resources for the community of scholars maximizes the benefits\nto society. In the field of digital infrastructure, this has already\ndemonstrated great benefits. It is expected that applying this principle to an\nopen science process will improve management by funding organizations in\ncollaboration with stakeholders through mechanisms such as public consultation.\nThis will increase the perception of joint ownership of the infrastructure. It\nwill also create clear and non-discriminatory access rules, along with a sense\nof joint ownership that stimulates a higher level of participation,\ncollaboration and social reciprocity. The article deals with the concept of\nopen science. The concept of the European cloud of open science and its\nstructure are presented. According to the study, it has been shown that the\nstructure of the cloud of open science includes an augmented reality as an\nopen-science platform. An example of the practical application of this tool is\nthe general description of MaxWhere, developed by Hungarian scientists, and is\na platform of aggregates of individual 3D spaces.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 07:32:07 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Shyshkina", "Mariya P.", ""], ["Marienko", "Maiia V.", ""]]}, {"id": "2003.07690", "submitter": "Sakshi Mishra", "authors": "Sakshi Mishra, Andrew Glaws, Dylan Cutler, Stephen Frank, Muhammad\n  Azam, Farzam Mohammadi, Jean-Simon Venne", "title": "A Unified Architecture for Data-Driven Metadata Tagging of Building\n  Automation Systems", "comments": "19 pages, 9 figures, accepted for publication in Automation in\n  Construction", "journal-ref": null, "doi": "10.1016/j.autcon.2020.103411", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents a Unified Architecture for automated point tagging of\nBuilding Automation System data, based on a combination of data-driven\napproaches. Advanced energy analytics applications-including fault detection\nand diagnostics and supervisory control-have emerged as a significant\nopportunity for improving the performance of our built environment. Effective\napplication of these analytics depends on harnessing structured data from the\nvarious building control and monitoring systems, but typical Building\nAutomation System implementations do not employ any standardized metadata\nschema. While standards such as Project Haystack and Brick Schema have been\ndeveloped to address this issue, the process of structuring the data, i.e.,\ntagging the points to apply a standard metadata schema, has, to date, been a\nmanual process. This process is typically costly, labor-intensive, and\nerror-prone. In this work we address this gap by proposing a UA that automates\nthe process of point tagging by leveraging the data accessible through\nconnection to the BAS, including time series data and the raw point names. The\nUA intertwines supervised classification and unsupervised clustering techniques\nfrom machine learning and leverages both their deterministic and probabilistic\noutputs to inform the point tagging process. Furthermore, we extend the UA to\nembed additional input and output data-processing modules that are designed to\naddress the challenges associated with the real-time deployment of this\nautomation solution. We test the UA on two datasets for real-life buildings: 1.\ncommercial retail buildings and 2. office buildings from the National Renewable\nEnergy Laboratory campus. The proposed methodology correctly applied 85-90\npercent and 70-75 percent of the tags in each of these test scenarios,\nrespectively.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 00:35:01 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 18:27:29 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Mishra", "Sakshi", ""], ["Glaws", "Andrew", ""], ["Cutler", "Dylan", ""], ["Frank", "Stephen", ""], ["Azam", "Muhammad", ""], ["Mohammadi", "Farzam", ""], ["Venne", "Jean-Simon", ""]]}, {"id": "2003.07691", "submitter": "Brian Dickinson", "authors": "Brian Dickinson, Gourab Ghoshal, Xerxes Dotiwalla, Adam Sadilek, Henry\n  Kautz", "title": "Inferring Nighttime Satellite Imagery from Human Mobility", "comments": "9 pages, 3 figures, presented at the 34th AAAI conference on\n  Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nighttime lights satellite imagery has been used for decades as a uniform,\nglobal source of data for studying a wide range of socioeconomic factors.\nRecently, another more terrestrial source is producing data with similarly\nuniform global coverage: anonymous and aggregated smart phone location. This\ndata, which measures the movement patterns of people and populations rather\nthan the light they produce, could prove just as valuable in decades to come.\nIn fact, since human mobility is far more directly related to the socioeconomic\nvariables being predicted, it has an even greater potential. Additionally,\nsince cell phone locations can be aggregated in real time while preserving\nindividual user privacy, it will be possible to conduct studies that would\npreviously have been impossible because they require data from the present. Of\ncourse, it will take quite some time to establish the new techniques necessary\nto apply human mobility data to problems traditionally studied with satellite\nimagery and to conceptualize and develop new real time applications. In this\nstudy we demonstrate that it is possible to accelerate this process by\ninferring artificial nighttime satellite imagery from human mobility data,\nwhile maintaining a strong differential privacy guarantee. We also show that\nthese artificial maps can be used to infer socioeconomic variables, often with\ngreater accuracy than using actual satellite imagery. Along the way, we find\nthat the relationship between mobility and light emissions is both nonlinear\nand varies considerably around the globe. Finally, we show that models based on\nhuman mobility can significantly improve our understanding of society at a\nglobal scale.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 14:25:11 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Dickinson", "Brian", ""], ["Ghoshal", "Gourab", ""], ["Dotiwalla", "Xerxes", ""], ["Sadilek", "Adam", ""], ["Kautz", "Henry", ""]]}, {"id": "2003.07703", "submitter": "David Bounie", "authors": "Val\\'erie Beaudouin (SES), Isabelle Bloch (IMAGES), David Bounie (IP\n  Paris, ECOGE, SES), St\\'ephan Cl\\'emen\\c{c}on (LPMA), Florence d'Alch\\'e-Buc,\n  James Eagan (DIVA), Winston Maxwell, Pavlo Mozharovskyi (IRMAR), Jayneel\n  Parekh", "title": "Flexible and Context-Specific AI Explainability: A Multidisciplinary\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent enthusiasm for artificial intelligence (AI) is due principally to\nadvances in deep learning. Deep learning methods are remarkably accurate, but\nalso opaque, which limits their potential use in safety-critical applications.\nTo achieve trust and accountability, designers and operators of machine\nlearning algorithms must be able to explain the inner workings, the results and\nthe causes of failures of algorithms to users, regulators, and citizens. The\noriginality of this paper is to combine technical, legal and economic aspects\nof explainability to develop a framework for defining the \"right\" level of\nexplain-ability in a given context. We propose three logical steps: First,\ndefine the main contextual factors, such as who the audience of the explanation\nis, the operational context, the level of harm that the system could cause, and\nthe legal/regulatory framework. This step will help characterize the\noperational and legal needs for explanation, and the corresponding social\nbenefits. Second, examine the technical tools available, including post hoc\napproaches (input perturbation, saliency maps...) and hybrid AI approaches.\nThird, as function of the first two steps, choose the right levels of global\nand local explanation outputs, taking into the account the costs involved. We\nidentify seven kinds of costs and emphasize that explanations are socially\nuseful only when total social benefits exceed costs.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 09:12:06 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Beaudouin", "Val\u00e9rie", "", "SES"], ["Bloch", "Isabelle", "", "IMAGES"], ["Bounie", "David", "", "IP\n  Paris, ECOGE, SES"], ["Cl\u00e9men\u00e7on", "St\u00e9phan", "", "LPMA"], ["d'Alch\u00e9-Buc", "Florence", "", "DIVA"], ["Eagan", "James", "", "DIVA"], ["Maxwell", "Winston", "", "IRMAR"], ["Mozharovskyi", "Pavlo", "", "IRMAR"], ["Parekh", "Jayneel", ""]]}, {"id": "2003.07904", "submitter": "Chao Yan", "authors": "Chao Yan, Ziqi Zhang, Steve Nyemba, Bradley A. Malin", "title": "Generating Electronic Health Records with Multiple Data Types and\n  Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sharing electronic health records (EHRs) on a large scale may lead to privacy\nintrusions. Recent research has shown that risks may be mitigated by simulating\nEHRs through generative adversarial network (GAN) frameworks. Yet the methods\ndeveloped to date are limited because they 1) focus on generating data of a\nsingle type (e.g., diagnosis codes), neglecting other data types (e.g.,\ndemographics, procedures or vital signs) and 2) do not represent constraints\nbetween features. In this paper, we introduce a method to simulate EHRs\ncomposed of multiple data types by 1) refining the GAN model, 2) accounting for\nfeature constraints, and 3) incorporating key utility measures for such\ngeneration tasks. Our analysis with over $770,000$ EHRs from Vanderbilt\nUniversity Medical Center demonstrates that the new model achieves higher\nperformance in terms of retaining basic statistics, cross-feature correlations,\nlatent structural properties, feature constraints and associated patterns from\nreal data, without sacrificing privacy.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 19:25:16 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 22:01:37 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Yan", "Chao", ""], ["Zhang", "Ziqi", ""], ["Nyemba", "Steve", ""], ["Malin", "Bradley A.", ""]]}, {"id": "2003.07940", "submitter": "Luca Mazzola", "authors": "Luca Mazzola, Alexander Denzler and Ramon Christen", "title": "Towards a Peer-to-Peer Energy Market: an Overview", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work focuses on the electric power market, comparing the status quo with\nthe recent trend towards the increase in distributed self-generation\ncapabilities by prosumers. Starting from the existing tension between the\nintrinsically hierarchical current structure of the electricity distribution\nnetwork and the substantially distributed and self-organising nature of the\nself-generation, we explore the limitations imposed by the current conditions.\nInitially, we introduce a potential multi-layered architecture for a\nPeer-to-Peer (P2P) energy market, discussing the fundamental aspects of local\nproduction and local consumption as part of a microgrid. Secondly, we analyse\nthe consequent changes for the different users' roles, also in connection with\nsome incentive models connected with the decentralisation of the power\nproduction. To give a full picture to the reader, we also scrutinise relevant\nelements of energy trading, such as Smart Contract and grid stability. Thirdly,\nwe present an example of a typical P2P settlement, showcasing the role of all\nthe previously analysed aspects. To conclude, we performed a review of relevant\nactivities in this domain, to showcase where existing projects are going and\nwhat are the most important themes covered. Being this a work in progress, many\nopen questions are still on the table and will be addressed in the next stages\nof the research. Eventually, by providing a reference model as base for further\ndiscussions and improvements, we would like to engage ourselves in a dialog\nwith the different users and the broad community, oriented towards a more fair\nand ecological-friendly solution for the electricity market of the future.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 20:32:10 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2020 20:02:37 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Mazzola", "Luca", ""], ["Denzler", "Alexander", ""], ["Christen", "Ramon", ""]]}, {"id": "2003.08006", "submitter": "Khawar Islam Mr", "authors": "Khawar Islam and Akhter Raza", "title": "Forecasting Crime Using ARIMA Model", "comments": "Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data mining is the process in which we extract the different patterns and\nuseful Information from large dataset. According to London police, crimes are\nimmediately increases from beginning of 2017 in different borough of London. No\nuseful information is available for prevent crime on future basis. We forecasts\ncrime rates in London borough by extracting large dataset of crime in London\nand predicted number of crimes in future. We used time series ARIMA model for\nforecasting crimes in London. By giving 5 years of data to ARIMA model\nforecasting 2 years crime data. Comparatively, with exponential smoothing ARIMA\nmodel has higher fitting values. A real dataset of crimes reported by London\npolice collected from its website and other resources. Our main concept is\ndivided into four parts. Data extraction (DE), data processing (DP) of\nunstructured data, visualizing model in IBM SPSS. DE extracts crime data from\nweb sources during 2012 for the 2016 year. DP integrates and reduces data and\ngive them predefined attributes. Crime prediction is analyzed by applying some\ncalculation, calculated their moving average, difference, and auto-regression.\nForecasted Model gives 80% correct values, which is formed to be an accurate\nmodel. This work helps for London police in decision-making against crime.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 01:32:55 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Islam", "Khawar", ""], ["Raza", "Akhter", ""]]}, {"id": "2003.08119", "submitter": "Nicola Rieke", "authors": "Nicola Rieke, Jonny Hancox, Wenqi Li, Fausto Milletari, Holger Roth,\n  Shadi Albarqouni, Spyridon Bakas, Mathieu N. Galtier, Bennett Landman, Klaus\n  Maier-Hein, Sebastien Ourselin, Micah Sheller, Ronald M. Summers, Andrew\n  Trask, Daguang Xu, Maximilian Baust, M. Jorge Cardoso", "title": "The Future of Digital Health with Federated Learning", "comments": "This is a pre-print version of\n  https://www.nature.com/articles/s41746-020-00323-1", "journal-ref": "npj Digital Medicine volume 3, Article number: 119 (2020)", "doi": "10.1038/s41746-020-00323-1", "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven Machine Learning has emerged as a promising approach for building\naccurate and robust statistical models from medical data, which is collected in\nhuge volumes by modern healthcare systems. Existing medical data is not fully\nexploited by ML primarily because it sits in data silos and privacy concerns\nrestrict access to this data. However, without access to sufficient data, ML\nwill be prevented from reaching its full potential and, ultimately, from making\nthe transition from research to clinical practice. This paper considers key\nfactors contributing to this issue, explores how Federated Learning (FL) may\nprovide a solution for the future of digital health and highlights the\nchallenges and considerations that need to be addressed.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 09:40:56 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2021 17:53:03 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Rieke", "Nicola", ""], ["Hancox", "Jonny", ""], ["Li", "Wenqi", ""], ["Milletari", "Fausto", ""], ["Roth", "Holger", ""], ["Albarqouni", "Shadi", ""], ["Bakas", "Spyridon", ""], ["Galtier", "Mathieu N.", ""], ["Landman", "Bennett", ""], ["Maier-Hein", "Klaus", ""], ["Ourselin", "Sebastien", ""], ["Sheller", "Micah", ""], ["Summers", "Ronald M.", ""], ["Trask", "Andrew", ""], ["Xu", "Daguang", ""], ["Baust", "Maximilian", ""], ["Cardoso", "M. Jorge", ""]]}, {"id": "2003.08154", "submitter": "Sven Banisch", "authors": "Sven Banisch and Felix Gaisbauer and Eckehard Olbrich", "title": "How social feedback processing in the brain shapes collective opinion\n  processes in the era of social media", "comments": "Odycceus Research (www.odycceus.eu)", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY cs.MA cs.NE nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What are the mechanisms by which groups with certain opinions gain public\nvoice and force others holding a different view into silence? And how does\nsocial media play into this? Drawing on recent neuro-scientific insights into\nthe processing of social feedback, we develop a theoretical model that allows\nto address these questions. The model captures phenomena described by spiral of\nsilence theory of public opinion, provides a mechanism-based foundation for it,\nand allows in this way more general insight into how different group structures\nrelate to different regimes of collective opinion expression. Even strong\nmajorities can be forced into silence if a minority acts as a cohesive whole.\nThe proposed framework of social feedback theory (SFT) highlights the need for\nsociological theorising to understand the societal-level implications of\nfindings in social and cognitive neuroscience.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 11:06:34 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Banisch", "Sven", ""], ["Gaisbauer", "Felix", ""], ["Olbrich", "Eckehard", ""]]}, {"id": "2003.08444", "submitter": "Benjamin Horne", "authors": "Maur\\'icio Gruppi and Benjamin D. Horne and Sibel Adal{\\i}", "title": "NELA-GT-2019: A Large Multi-Labelled News Dataset for The Study of\n  Misinformation in News Articles", "comments": "Updated dataset for paper NELA-GT-2018: A Large Multi-Labelled News\n  Dataset for The Study of Misinformation in News Articles, originally\n  published at ICWSM in 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an updated version of the NELA-GT-2018 dataset\n(N{\\o}rregaard, Horne, and Adal{\\i} 2019), entitled NELA-GT-2019. NELA-GT-2019\ncontains 1.12M news articles from 260 sources collected between January 1st\n2019 and December 31st 2019. Just as with NELA-GT-2018, these sources come from\na wide range of mainstream news sources and alternative news sources. Included\nwith the dataset are source-level ground truth labels from 7 different\nassessment sites covering multiple dimensions of veracity. The NELA-GT-2019\ndataset can be found at: https://doi.org/10.7910/DVN/O7FWPO\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 19:18:21 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2020 21:29:51 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Gruppi", "Maur\u00edcio", ""], ["Horne", "Benjamin D.", ""], ["Adal\u0131", "Sibel", ""]]}, {"id": "2003.08474", "submitter": "Karel Mundnich", "authors": "Karel Mundnich, Brandon M. Booth, Michelle L'Hommedieu, Tiantian Feng,\n  Benjamin Girault, Justin L'Hommedieu, Mackenzie Wildman, Sophia Skaaden,\n  Amrutha Nadarajan, Jennifer L. Villatte, Tiago H. Falk, Kristina Lerman,\n  Emilio Ferrara, and Shrikanth Narayanan", "title": "TILES-2018, a longitudinal physiologic and behavioral data set of\n  hospital workers", "comments": "57 pages, 9 figures, journal paper", "journal-ref": "Sci Data 7, 354 (2020)", "doi": "10.1038/s41597-020-00655-3", "report-no": null, "categories": "eess.SP cs.CY cs.HC stat.AP", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We present a novel longitudinal multimodal corpus of physiological and\nbehavioral data collected from direct clinical providers in a hospital\nworkplace. We designed the study to investigate the use of off-the-shelf\nwearable and environmental sensors to understand individual-specific constructs\nsuch as job performance, interpersonal interaction, and well-being of hospital\nworkers over time in their natural day-to-day job settings. We collected\nbehavioral and physiological data from $n = 212$ participants through\nInternet-of-Things Bluetooth data hubs, wearable sensors (including a\nwristband, a biometrics-tracking garment, a smartphone, and an audio-feature\nrecorder), together with a battery of surveys to assess personality traits,\nbehavioral states, job performance, and well-being over time. Besides the\ndefault use of the data set, we envision several novel research opportunities\nand potential applications, including multi-modal and multi-task behavioral\nmodeling, authentication through biometrics, and privacy-aware and\nprivacy-preserving machine learning.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 21:07:16 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 19:09:17 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Mundnich", "Karel", ""], ["Booth", "Brandon M.", ""], ["L'Hommedieu", "Michelle", ""], ["Feng", "Tiantian", ""], ["Girault", "Benjamin", ""], ["L'Hommedieu", "Justin", ""], ["Wildman", "Mackenzie", ""], ["Skaaden", "Sophia", ""], ["Nadarajan", "Amrutha", ""], ["Villatte", "Jennifer L.", ""], ["Falk", "Tiago H.", ""], ["Lerman", "Kristina", ""], ["Ferrara", "Emilio", ""], ["Narayanan", "Shrikanth", ""]]}, {"id": "2003.08512", "submitter": "Amee Trivedi", "authors": "Amee Trivedi, Jeremy Gummeson, Prashant Shenoy", "title": "Empirical Characterization of Mobility of Multi-Device Internet Users", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the mobility of humans and their devices is a fundamental\nproblem in mobile computing. While there has been much work on empirical\nanalysis of human mobility using mobile device data, prior work has largely\nassumed devices to be independent and has not considered the implications of\nmodern Internet users owning multiple mobile devices that exhibit correlated\nmobility patterns. Also, prior work has analyzed mobility at the spatial scale\nof the underlying mobile dataset and has not analyzed mobility characteristics\nat different spatial scales and its implications on system design. In this\npaper, we empirically analyze the mobility of modern Internet users owning\nmultiple devices at multiple spatial scales using a large campus WiFi dataset.\nFirst, our results show that mobility of multiple devices belonging to a user\nneeds to be analyzed and modeled as a group, rather than independently, and\nthat there are substantial differences in the correlations exhibited by device\ntrajectories across users that also need to be considered. Second, our analysis\nshows that the mobility of users shows different characteristics at different\nspatial scales such as within and across buildings. Third, we demonstrate the\nimplications of these results by presenting generative models that highlight\nthe importance of considering the spatial scale of mobility as well as\nmulti-device mobility. More broadly, our empirical results point to the need\nfor new modeling research to fully capture the nuances of mobility of modern\nmulti-device users.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 23:50:35 GMT"}, {"version": "v2", "created": "Sun, 17 May 2020 23:16:44 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Trivedi", "Amee", ""], ["Gummeson", "Jeremy", ""], ["Shenoy", "Prashant", ""]]}, {"id": "2003.08530", "submitter": "Michael Chesser", "authors": "Michael Chesser, Asangi Jayatilaka, Renuka Visvanathan, Christophe\n  Fumeaux, Alanson Sample, Damith C. Ranasinghe", "title": "Super Low Resolution RF Powered Accelerometers for Alerting on\n  Hospitalized Patient Bed Exits", "comments": null, "journal-ref": "2019 IEEE International Conference on Pervasive Computing and\n  Communications (PerCom), Kyoto, Japan, 2019, pp. 1-10", "doi": "10.1109/PERCOM.2019.8767398", "report-no": null, "categories": "cs.CY cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Falls have serious consequences and are prevalent in acute hospitals and\nnursing homes caring for older people. Most falls occur in bedrooms and near\nthe bed. Technological interventions to mitigate the risk of falling aim to\nautomatically monitor bed-exit events and subsequently alert healthcare\npersonnel to provide timely supervisions. We observe that frequency-domain\ninformation related to patient activities exist predominantly in very low\nfrequencies. Therefore, we recognise the potential to employ a low resolution\nacceleration sensing modality in contrast to powering and sensing with a\nconventional MEMS (Micro Electro Mechanical System) accelerometer.\nConsequently, we investigate a batteryless sensing modality with low cost\nwirelessly powered Radio Frequency Identification (RFID) technology with the\npotential for convenient integration into clothing, such as hospital gowns. We\ndesign and build a passive accelerometer-based RFID sensor\nembodiment---ID-Sensor---for our study. The sensor design allows deriving ultra\nlow resolution acceleration data from the rate of change of unique RFID tag\nidentifiers in accordance with the movement of a patient's upper body. We\ninvestigate two convolutional neural network architectures for learning from\nraw RFID-only data streams and compare performance with a traditional shallow\nclassifier with engineered features. We evaluate performance with 23\nhospitalized older patients. We demonstrate, for the first time and to the best\nof knowledge, that: i) the low resolution acceleration data embedded in the RF\npowered ID-Sensor data stream can provide a practicable method for activity\nrecognition; and ii) highly discriminative features can be efficiently learned\nfrom the raw RFID-only data stream using a fully convolutional network\narchitecture.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 00:58:30 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Chesser", "Michael", ""], ["Jayatilaka", "Asangi", ""], ["Visvanathan", "Renuka", ""], ["Fumeaux", "Christophe", ""], ["Sample", "Alanson", ""], ["Ranasinghe", "Damith C.", ""]]}, {"id": "2003.08567", "submitter": "Praneeth Vepakomma", "authors": "Ramesh Raskar, Isabel Schunemann, Rachel Barbar, Kristen Vilcans, Jim\n  Gray, Praneeth Vepakomma, Suraj Kapa, Andrea Nuzzo, Rajiv Gupta, Alex Berke,\n  Dazza Greenwood, Christian Keegan, Shriank Kanaparti, Robson Beaudry, David\n  Stansbury, Beatriz Botero Arcila, Rishank Kanaparti, Vitor Pamplona,\n  Francesco M Benedetti, Alina Clough, Riddhiman Das, Kaushal Jain, Khahlil\n  Louisy, Greg Nadeau, Vitor Pamplona, Steve Penrod, Yasaman Rajaee, Abhishek\n  Singh, Greg Storm, John Werner", "title": "Apps Gone Rogue: Maintaining Personal Privacy in an Epidemic", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Containment, the key strategy in quickly halting an epidemic, requires rapid\nidentification and quarantine of the infected individuals, determination of\nwhom they have had close contact with in the previous days and weeks, and\ndecontamination of locations the infected individual has visited. Achieving\ncontainment demands accurate and timely collection of the infected individual's\nlocation and contact history. Traditionally, this process is labor intensive,\nsusceptible to memory errors, and fraught with privacy concerns. With the\nrecent almost ubiquitous availability of smart phones, many people carry a tool\nwhich can be utilized to quickly identify an infected individual's contacts\nduring an epidemic, such as the current 2019 novel Coronavirus crisis.\nUnfortunately, the very same first-generation contact tracing tools have been\nused to expand mass surveillance, limit individual freedoms and expose the most\nprivate details about individuals. We seek to outline the different\ntechnological approaches to mobile-phone based contact-tracing to date and\nelaborate on the opportunities and the risks that these technologies pose to\nindividuals and societies. We describe advanced security enhancing approaches\nthat can mitigate these risks and describe trade-offs one must make when\ndeveloping and deploying any mass contact-tracing technology. With this paper,\nour aim is to continue to grow the conversation regarding contact-tracing for\nepidemic and pandemic containment and discuss opportunities to advance this\nspace. We invite feedback and discussion.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 04:22:24 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Raskar", "Ramesh", ""], ["Schunemann", "Isabel", ""], ["Barbar", "Rachel", ""], ["Vilcans", "Kristen", ""], ["Gray", "Jim", ""], ["Vepakomma", "Praneeth", ""], ["Kapa", "Suraj", ""], ["Nuzzo", "Andrea", ""], ["Gupta", "Rajiv", ""], ["Berke", "Alex", ""], ["Greenwood", "Dazza", ""], ["Keegan", "Christian", ""], ["Kanaparti", "Shriank", ""], ["Beaudry", "Robson", ""], ["Stansbury", "David", ""], ["Arcila", "Beatriz Botero", ""], ["Kanaparti", "Rishank", ""], ["Pamplona", "Vitor", ""], ["Benedetti", "Francesco M", ""], ["Clough", "Alina", ""], ["Das", "Riddhiman", ""], ["Jain", "Kaushal", ""], ["Louisy", "Khahlil", ""], ["Nadeau", "Greg", ""], ["Pamplona", "Vitor", ""], ["Penrod", "Steve", ""], ["Rajaee", "Yasaman", ""], ["Singh", "Abhishek", ""], ["Storm", "Greg", ""], ["Werner", "John", ""]]}, {"id": "2003.08580", "submitter": "Nikita Samarin", "authors": "Nikita Samarin, Alisa Frik, Sean Brooks, Coye Cheshire, Serge Egelman", "title": "Surveying Vulnerable Populations: A Case Study of Civil Society\n  Organizations", "comments": "[v2] Appears in the Workshop on Inclusive Privacy and Security (WIPS)\n  co-located with Symposium on Usable Privacy and Security (SOUPS) 2020; [v1]\n  Appears in the Networked Privacy Workshop co-located with ACM Conference on\n  Human Factors in Computing Systems (CHI) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compared to organizations in other sectors, civil society organizations\n(CSOs) are particularly vulnerable to security and privacy threats, as they\nlack adequate resources and expertise to defend themselves. At the same time,\ntheir security needs and practices have not gained much attention among\nresearchers, and existing solutions designed for the average users do not\nconsider the contexts in which CSO employees operate. As part of our\npreliminary work, we conducted an anonymous online survey with 102 CSO\nemployees to collect information about their perceived risks of different\nsecurity and privacy threats, and their self-reported mitigation strategies.\nThe design of our preliminary survey accounted for the unique requirements of\nour target population by establishing trust with respondents, using\nanonymity-preserving incentive strategies, and distributing the survey with the\nhelp of a trusted intermediary. However, by carefully examining our methods and\nthe feedback received from respondents, we uncovered several issues with our\nmethodology, including the length of the survey, the framing of the questions,\nand the design of the recruitment email. We hope that the discussion presented\nin this paper will inform and assist researchers and practitioners working on\nunderstanding and improving the security and privacy of CSOs.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 05:30:21 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 21:01:40 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Samarin", "Nikita", ""], ["Frik", "Alisa", ""], ["Brooks", "Sean", ""], ["Cheshire", "Coye", ""], ["Egelman", "Serge", ""]]}, {"id": "2003.08800", "submitter": "Fang Zhu", "authors": "Fang Zhu, Qian Zhang, Hao Chen, Guocheng Shi, Chen Wen, Zhongqun Zhu,\n  and Huiwen Chen", "title": "Cardiovascular risk and work stress in biomedical researchers in China:\n  An observational, big data study protocol", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Introduction: Internet technologies could strengthen data collection and\nintegration and have been used extensively in public health research. It is\nnecessary to apply this technology to further investigate the behaviour and\nhealth of biomedical researchers. A browser-based extension was developed by\nresearchers and clinicians to promote the collection and analysis of\nresearchers' behavioural and psychological data. This protocol illustrates an\nobservational study aimed at (1) characterising the health status of biomedical\nresearchers in China and assessing work stress, job satisfaction, role\nconflict, role ambiguity, and family support; (2) identifying the association\nbetween work, behaviour, and health; and (3) investigating the association\nbetween behaviour and mental status. Our findings will contribute to the\nunderstanding of the influences of job, work environment, and family support on\nthe mental and physical health of biomedical researchers. Methods and analysis:\nThis is a prospective observational study; all candidates will be recruited\nfrom China. Participants will install an extension on their Internet browsers,\nwhich will collect data when they are accessing PubMed. A web-based survey will\nbe sent to the user interfaces every 6 months that will involve\nsociodemographic variables, perceived stress scale, job satisfaction scale,\nrole conflict and ambiguity scale, and family support scale. Machine-learning\nalgorithms will analyse the data generated during daily access. Ethics and\ndissemination: This study received ethical approval from the ethics committee\nof the Shanghai Children's Medical Centre (reference number SCMCIRB-K2018082).\nStudy results will be disseminated through peer-reviewed publications and\nconference presentations.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 14:15:32 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Zhu", "Fang", ""], ["Zhang", "Qian", ""], ["Chen", "Hao", ""], ["Shi", "Guocheng", ""], ["Wen", "Chen", ""], ["Zhu", "Zhongqun", ""], ["Chen", "Huiwen", ""]]}, {"id": "2003.08835", "submitter": "Massimo Stella", "authors": "Massimo Stella", "title": "Text-mining forma mentis networks reconstruct public perception of the\n  STEM gender gap in social media", "comments": "5 figures", "journal-ref": null, "doi": "10.7717/peerj-cs.295", "report-no": null, "categories": "cs.SI cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mindset reconstruction maps how individuals structure and perceive knowledge,\na map unfolded here by investigating language and its cognitive reflection in\nthe human mind, i.e. the mental lexicon. Textual forma mentis networks (TFMN)\nare glass boxes introduced for extracting, representing and understanding\nmindsets' structure, in Latin \"forma mentis\", from textual data. Combining\nnetwork science, psycholinguistics and Big Data, TFMNs successfully identified\nrelevant concepts, without supervision, in benchmark texts. Once validated,\nTFMNs were applied to the case study of the gender gap in science, which was\nstrongly linked to distorted mindsets by recent studies. Focusing over social\nmedia perception and online discourse, this work analysed 10,000 relevant\ntweets. \"Gender\" and \"gap\" elicited a mostly positive perception, with a\ntrustful/joyous emotional profile and semantic associates that: celebrated\nsuccessful female scientists, related gender gap to wage differences, and hoped\nfor a future resolution. The perception of \"woman\" highlighted discussion about\nsexual harassment and stereotype threat (a form of implicit cognitive bias)\nrelative to women in science \"sacrificing personal skills for success\". The\nreconstructed perception of \"man\" highlighted social users' awareness of the\nmyth of male superiority in science. No anger was detected around \"person\",\nsuggesting that gap-focused discourse got less tense around genderless terms.\nNo stereotypical perception of \"scientist\" was identified online, differently\nfrom real-world surveys. The overall analysis identified the online discourse\nas promoting a mostly stereotype-free, positive/trustful perception of gender\ndisparity, aware of implicit/explicit biases and projected to closing the gap.\nTFMNs opened new ways for investigating perceptions in different groups,\noffering detailed data-informed grounding for policy making.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 13:39:23 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Stella", "Massimo", ""]]}, {"id": "2003.08942", "submitter": "Christine Bauer", "authors": "Christine Bauer and Katharina Sophie Schmid and Christine Strauss", "title": "An Open Model for Researching the Role of Culture in Online\n  Self-Disclosure", "comments": "10 pages, 1 figure, 51st Hawaii International Conference on System\n  Sciences (HICSS 2018), Waikoloa, Big Island, HI, USA; nominated for best\n  paper award", "journal-ref": "Proceedings of the 51st Hawaii International Conference on System\n  Sciences (HICSS 2018), 3-6 January, Waikoloa, Big Island, HI, USA, pp\n  3637-3646", "doi": "10.24251/HICSS.2018.460", "report-no": null, "categories": "cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The analysis of consumers' personal information (PI) is a significant source\nto learn about consumers. In online settings, many consumers disclose PI\nabundantly -- this is particularly true for information provided on social\nnetwork services. Still, people manage the privacy level they want to maintain\nby disclosing by disclosing PI accordingly. In addition, studies have shown\nthat consumers' online self-disclosure (OSD) differs across cultures.\nTherefore, intelligent systems should consider cultural issues when collecting,\nprocessing, storing or protecting data from consumers. However, existing\nstudies typically rely on a comparison of two cultures, providing valuable\ninsights but not drawing a comprehensive picture. We introduce an open research\nmodel for cultural OSD research, based on the privacy calculus theory. Our open\nresearch model incorporates six cultural dimensions, six predictors, and 24\nstructured propositions. It represents a comprehensive approach that provides a\nbasis to explain possible cultural OSD phenomena in a systematic way.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 16:57:34 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Bauer", "Christine", ""], ["Schmid", "Katharina Sophie", ""], ["Strauss", "Christine", ""]]}, {"id": "2003.08990", "submitter": "Kovila  P.L. Coopamootoo", "authors": "Kovila P.L. Coopamootoo", "title": "Dis-Empowerment Online: An Investigation of Privacy-Sharing Perceptions\n  & Method Preferences", "comments": "Kovila P.L. Coopamootoo, Dis-Empowerment Online - An Investigation of\n  Privacy-Sharing Perceptions & Method Preferences: Proceedings of AsiaUSEC'20,\n  Financial Cryptography and Data Security 2020 (FC). February 14, 2020 Kota\n  Kinabalu, Sabah, Malaysia Springer, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While it is often claimed that users are empowered via online technologies,\nthere is also a general feeling of privacy dis-empowerment. We investigate the\nperception of privacy and sharing empowerment online, as well as the use of\nprivacy technologies, via a cross-national online study with N=907\nparticipants. We find that perception of privacy empowerment differs from that\nof sharing across dimensions of meaningfulness, competence and choice. We find\nsimilarities and differences in privacy method preference between the US, UK\nand Germany. We also find that non-technology methods of privacy protection are\namong the most preferred methods, while more advanced and standalone privacy\ntechnologies are least preferred.. By mapping the perception of privacy\ndis-empowerment into patterns of privacy behavior online, and clarifying the\nsimilarities and distinctions in privacy technology use, this paper provides an\nimportant foundation for future research and the design of privacy\ntechnologies. The findings may be used across disciplines to develop more\nuser-centric privacy technologies, that support and enable the user.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 19:17:55 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Coopamootoo", "Kovila P. L.", ""]]}, {"id": "2003.09241", "submitter": "Nida Khan", "authors": "Nida Khan, Tabrez Ahmad, Anass Patel and Radu State", "title": "Blockchain Governance: An Overview and Prediction of Optimal Strategies\n  using Nash Equilibrium", "comments": "Accepted for publication in AUEIRC-Springer 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain governance is a subject of ongoing research and an\ninterdisciplinary view of blockchain governance is vital to aid in further\nresearch for establishing a formal governance framework for this nascent\ntechnology. In this paper, the position of blockchain governance within the\nhierarchy of Institutional governance is discussed. Blockchain governance is\nanalyzed from the perspective of IT governance using Nash equilibrium to\npredict the outcome of different governance decisions. A payoff matrix for\nblockchain governance is created and simulation of different strategy profiles\nis accomplished for computation of all Nash equilibria. The paper elaborates\nupon payoff matrices for different kinds of blockchain governance, which are\nused in the proposition of novel mathematical formulae usable to predict the\nbest governance strategy that minimizes the occurrence of a hard fork as well\nas predicts the behavior of the majority during protocol updates. The paper\nalso includes validation of the proposed formulae using real Ethereum data.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 12:51:52 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Khan", "Nida", ""], ["Ahmad", "Tabrez", ""], ["Patel", "Anass", ""], ["State", "Radu", ""]]}, {"id": "2003.09312", "submitter": "Nitish Nag", "authors": "Nitish Nag", "title": "Health State Estimation", "comments": "Ph.D. Dissertation @ University of California, Irvine", "journal-ref": "Proquest 2020, 307 pages", "doi": null, "report-no": "27743502", "categories": "cs.AI cs.CY cs.HC q-bio.QM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Life's most valuable asset is health. Continuously understanding the state of\nour health and modeling how it evolves is essential if we wish to improve it.\nGiven the opportunity that people live with more data about their life today\nthan any other time in history, the challenge rests in interweaving this data\nwith the growing body of knowledge to compute and model the health state of an\nindividual continually. This dissertation presents an approach to build a\npersonal model and dynamically estimate the health state of an individual by\nfusing multi-modal data and domain knowledge. The system is stitched together\nfrom four essential abstraction elements: 1. the events in our life, 2. the\nlayers of our biological systems (from molecular to an organism), 3. the\nfunctional utilities that arise from biological underpinnings, and 4. how we\ninteract with these utilities in the reality of daily life. Connecting these\nfour elements via graph network blocks forms the backbone by which we\ninstantiate a digital twin of an individual. Edges and nodes in this graph\nstructure are then regularly updated with learning techniques as data is\ncontinuously digested. Experiments demonstrate the use of dense and\nheterogeneous real-world data from a variety of personal and environmental\nsensors to monitor individual cardiovascular health state. State estimation and\nindividual modeling is the fundamental basis to depart from disease-oriented\napproaches to a total health continuum paradigm. Precision in predicting health\nrequires understanding state trajectory. By encasing this estimation within a\nnavigational approach, a systematic guidance framework can plan actions to\ntransition a current state towards a desired one. This work concludes by\npresenting this framework of combining the health state and personal graph\nmodel to perpetually plan and assist us in living life towards our goals.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 21:06:32 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Nag", "Nitish", ""]]}, {"id": "2003.09322", "submitter": "Iqbal H. Sarker", "authors": "Sohrab Hossain, Ahmed Abtahee, Imran Kashem, Mohammed Moshiul Hoque\n  and Iqbal H. Sarker", "title": "Crime Prediction Using Spatio-Temporal Data", "comments": "International Conference on Computing Science, Communication and\n  Security (COMS2), 2020. Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A crime is a punishable offence that is harmful for an individual and his\nsociety. It is obvious to comprehend the patterns of criminal activity to\nprevent them. Research can help society to prevent and solve crime activates.\nStudy shows that only 10 percent offenders commits 50 percent of the total\noffences. The enforcement team can respond faster if they have early\ninformation and pre-knowledge about crime activities of the different points of\na city. In this paper, supervised learning technique is used to predict crimes\nwith better accuracy. The proposed system predicts crimes by analyzing data-set\nthat contains records of previously committed crimes and their patterns. The\nsystem stands on two main algorithms - i) decision tree, and ii) k-nearest\nneighbor. Random Forest algorithm and Adaboost are used to increase the\naccuracy of the prediction. Finally, oversampling is used for better accuracy.\nThe proposed system is feed with a criminal-activity data set of twelve years\nof San Francisco city.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 16:19:19 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Hossain", "Sohrab", ""], ["Abtahee", "Ahmed", ""], ["Kashem", "Imran", ""], ["Hoque", "Mohammed Moshiul", ""], ["Sarker", "Iqbal H.", ""]]}, {"id": "2003.09466", "submitter": "Rachel Cummings", "authors": "Qiaomei Li and Rachel Cummings and Yonatan Mintz", "title": "Optimal Local Explainer Aggregation for Interpretable Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key challenge for decision makers when incorporating black box machine\nlearned models into practice is being able to understand the predictions\nprovided by these models. One proposed set of methods is training surrogate\nexplainer models which approximate the more complex model. Explainer methods\nare generally classified as either local or global, depending on what portion\nof the data space they are purported to explain. The improved coverage of\nglobal explainers usually comes at the expense of explainer fidelity. One way\nof trading off the advantages of both approaches is to aggregate several local\nexplainers into a single explainer model with improved coverage. However, the\nproblem of aggregating these local explainers is computationally challenging,\nand existing methods only use heuristics to form these aggregations.\n  In this paper we propose a local explainer aggregation method which selects\nlocal explainers using non-convex optimization. In contrast to other heuristic\nmethods, we use an integer optimization framework to combine local explainers\ninto a near-global aggregate explainer. Our framework allows a decision-maker\nto directly tradeoff coverage and fidelity of the resulting aggregation through\nthe parameters of the optimization problem. We also propose a novel local\nexplainer algorithm based on information filtering. We evaluate our algorithmic\nframework on two healthcare datasets---the Parkinson's Progression Marker\nInitiative (PPMI) data set and a geriatric mobility dataset---which is\nmotivated by the anticipated need for explainable precision medicine. Our\nmethod outperforms existing local explainer aggregation methods in terms of\nboth fidelity and coverage of classification and improves on fidelity over\nexisting global explainer methods, particularly in multi-class settings where\nstate-of-the-art methods achieve 70% and ours achieves 90%.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 19:02:11 GMT"}, {"version": "v2", "created": "Sun, 15 Nov 2020 21:18:10 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Li", "Qiaomei", ""], ["Cummings", "Rachel", ""], ["Mintz", "Yonatan", ""]]}, {"id": "2003.09494", "submitter": "Mojtaba Noghabaei", "authors": "Mojtaba Noghabaei, and Kevin Han", "title": "Hazard recognition in an immersive virtual environment: Framework for\n  the simultaneous analysis of visual search and EEG patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanaged hazards in dangerous construction environments proved to be one of\nthe main sources of injuries and accidents. Hazard recognition is crucial to\nachieve effective safety management and reduce injuries and fatalities in\nhazardous job sites. Still, there has been lack of effort that can efficiently\nassist workers in improving their hazard recognition skills. This study\npresents virtual safety training in an Immersive Virtual Environment (IVE) to\nenhance worker's hazard recognition skills. A worker wearing a Virtual Reality\n(VR) device, that is equipped with an eye-tracker, virtually recognizes hazards\non simulated construction sites while a brainwave-sensing device records brain\nactivities. This platform can analyze the overall performance of the workers in\na visual hazard recognition task and identify hazards that need additional\nintervention for each worker. This study provides novel insights on how a\nworker's brain and eye act simultaneously during a visual hazard recognition\nprocess. The presented method can take current safety training programs into\nanother level by providing personalized feedback to the workers.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 20:12:38 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Noghabaei", "Mojtaba", ""], ["Han", "Kevin", ""]]}, {"id": "2003.09501", "submitter": "Omar Reyad", "authors": "Omar Reyad", "title": "Novel Coronavirus COVID-19 Strike on Arab Countries and Territories: A\n  Situation Report I", "comments": "3 pages, 2 figures, 1 table, Situation Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The novel Coronavirus (COVID-19) is an infectious disease caused by a new\nvirus called COVID-19 or 2019-nCoV that first identified in Wuhan, China. The\ndisease causes respiratory illness (such as the flu) with other symptoms such\nas a cough, fever, and in more severe cases, difficulty breathing. This new\nCoronavirus seems to be very infectious and has spread quickly and globally. In\nthis work, information about COVID-19 is provided and the situation in Arab\ncountries and territories regarding the COVID-19 strike is presented. The next\nfew weeks main expectations is also given.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 21:23:03 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Reyad", "Omar", ""]]}, {"id": "2003.09670", "submitter": "Zitao Liu", "authors": "Hang Li, Wenbiao Ding, Zitao Liu", "title": "Identifying At-Risk K-12 Students in Multimodal Online Environments: A\n  Machine Learning Approach", "comments": "The 13th International Conference on Educational Data Mining (EDM\n  2020), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid emergence of K-12 online learning platforms, a new era of\neducation has been opened up. It is crucial to have a dropout warning framework\nto preemptively identify K-12 students who are at risk of dropping out of the\nonline courses. Prior researchers have focused on predicting dropout in Massive\nOpen Online Courses (MOOCs), which often deliver higher education, i.e.,\ngraduate level courses at top institutions. However, few studies have focused\non developing a machine learning approach for students in K-12 online courses.\nIn this paper, we develop a machine learning framework to conduct accurate\nat-risk student identification specialized in K-12 multimodal online\nenvironments. Our approach considers both online and offline factors around\nK-12 students and aims at solving the challenges of (1) multiple modalities,\ni.e., K-12 online environments involve interactions from different modalities\nsuch as video, voice, etc; (2) length variability, i.e., students with\ndifferent lengths of learning history; (3) time sensitivity, i.e., the dropout\nlikelihood is changing with time; and (4) data imbalance, i.e., only less than\n20\\% of K-12 students will choose to drop out the class. We conduct a wide\nrange of offline and online experiments to demonstrate the effectiveness of our\napproach. In our offline experiments, we show that our method improves the\ndropout prediction performance when compared to state-of-the-art baselines on a\nreal-world educational dataset. In our online experiments, we test our approach\non a third-party K-12 online tutoring platform for two months and the results\nshow that more than 70\\% of dropout students are detected by the system.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 14:34:36 GMT"}, {"version": "v2", "created": "Sat, 30 May 2020 14:04:45 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Li", "Hang", ""], ["Ding", "Wenbiao", ""], ["Liu", "Zitao", ""]]}, {"id": "2003.09761", "submitter": "Tae Yoon Lee", "authors": "Devon Graham, Satish Kumar Sarraf, Taylor Lundy, Ali MohammadMehr,\n  Sara Uppal, Tae Yoon Lee, Hedayat Zarkoob, Scott Duke Kominers, Kevin\n  Leyton-Brown", "title": "Smarter Parking: Using AI to Identify Parking Inefficiencies in\n  Vancouver", "comments": "All the authors contributed equally. This paper is an outcome of\n  https://www.cs.ubc.ca/~kevinlb/teaching/cs532l%20-%202018-19/index.html. To\n  be submitted to a journal in transportation or urban planning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On-street parking is convenient, but has many disadvantages: on-street spots\ncome at the expense of other road uses such as traffic lanes, transit lanes,\nbike lanes, or parklets; drivers looking for parking contribute substantially\nto traffic congestion and hence to greenhouse gas emissions; safety is reduced\nboth due to the fact that drivers looking for spots are more distracted than\nother road users and that people exiting parked cars pose a risk to cyclists.\nThese social costs may not be worth paying when off-street parking lots are\nnearby and have surplus capacity. To see where this might be true in downtown\nVancouver, we used artificial intelligence techniques to estimate the amount of\ntime it would take drivers to both park on and off street for destinations\nthroughout the city. For on-street parking, we developed (1) a deep-learning\nmodel of block-by-block parking availability based on data from parking meters\nand audits and (2) a computational simulation of drivers searching for an\non-street spot. For off-street parking, we developed a computational simulation\nof the time it would take drivers drive from their original destination to the\nnearest city-owned off-street lot and then to queue for a spot based on traffic\nand lot occupancy data. Finally, in both cases we also computed the time it\nwould take the driver to walk from their parking spot to their original\ndestination. We compared these time estimates for destinations in each block of\nVancouver's downtown core and each hour of the day. We found many areas where\noff street would actually save drivers time over searching the streets for a\nspot, and many more where the time cost for parking off street was small. The\nidentification of such areas provides an opportunity for the city to repurpose\nvaluable curbside space for community-friendly uses more in line with its\ntransportation goals.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 22:34:57 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Graham", "Devon", ""], ["Sarraf", "Satish Kumar", ""], ["Lundy", "Taylor", ""], ["MohammadMehr", "Ali", ""], ["Uppal", "Sara", ""], ["Lee", "Tae Yoon", ""], ["Zarkoob", "Hedayat", ""], ["Kominers", "Scott Duke", ""], ["Leyton-Brown", "Kevin", ""]]}, {"id": "2003.09920", "submitter": "Roman Rolon", "authors": "R.E. Rolon, I.E. Gareis, L.D. Larrateguy, L.E. Di Persia, R.D. Spies\n  and H.L. Rufiner", "title": "Automatic scoring of apnea and hypopnea events using blood oxygen\n  saturation signals", "comments": "15 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The obstructive sleep apnea-hypopnea (OSAH) syndrome is a very common and\nfrequently undiagnosed sleep disorder. It is characterized by repeated events\nof partial (hypopnea) or total (apnea) obstruction of the upper airway while\nsleeping. This study makes use of a previously developed method called DAS-KSVD\nfor multiclass structured dictionary learning to automatically detect\nindividual events of apnea and hypopnea using only blood oxygen saturation\nsignals. The method uses a combined discriminant measure which is capable of\nefficiently quantifying the degree of discriminability of each one of the atoms\nin a dictionary. DAS-KSVD was applied to detect and classify apnea and hypopnea\nevents from signals obtained from the Sleep Heart Health Study database. For\nmoderate to severe OSAH screening, a receiver operating characteristic curve\nanalysis of the results shows an area under the curve of 0.957 and diagnostic\nsensitivity and specificity of 87.56% and 88.32%, respectively. These results\nrepresent improvements as compared to most state-of-the-art procedures. Hence,\nthe method could be used for screening OSAH syndrome more reliably and\nconveniently, using only a pulse oximeter.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 15:17:20 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 13:15:40 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Rolon", "R. E.", ""], ["Gareis", "I. E.", ""], ["Larrateguy", "L. D.", ""], ["Di Persia", "L. E.", ""], ["Spies", "R. D.", ""], ["Rufiner", "H. L.", ""]]}, {"id": "2003.09963", "submitter": "Mohammed Ibrahim", "authors": "Mohammed Salah Ibrahim and Doaa Waleed Al-Dulaimee", "title": "Design Multimedia Expert Diagnosing Diseases System Using Fuzzy Logic\n  (MEDDSFL)", "comments": "arXiv admin: text overlap with arXiv:1006.4544, arXiv:1401.0245 by\n  other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we designed an efficient expert system to diagnose diseases for\nhuman beings. The system depended on several clinical features for different\ndiseases which will be used as knowledge base for this system. We used fuzzy\nlogic system which is one of the most expert systems techniques that used in\nbuilding knowledge base of expert systems. Fuzzy logic will be used to\ninference the results of disease diagnosing. We also provided the system with\nmultimedia such as videos, pictures and information for most of disease that\nhave been achieved in our system. The system implemented using Matlab ToolBox\nand fifteen diseases were studied. Five cases for normal, affected and\nunaffected people's different diseases have been tested on this system. The\nresults show that system was able to predict the status whether a human has a\ndisease or not accurately. All system results are reported in tables and\ndiscussed in detail.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 18:28:13 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Ibrahim", "Mohammed Salah", ""], ["Al-Dulaimee", "Doaa Waleed", ""]]}, {"id": "2003.09996", "submitter": "Lionel Robert", "authors": "Suresh Kumaar Jayaraman, Dawn M. Tilbury, X. Jessie Yang, Anuj K.\n  Pradhan, Lionel P. Robert Jr", "title": "Analysis and Prediction of Pedestrian Crosswalk Behavior during\n  Automated Vehicle Interactions", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For safe navigation around pedestrians, automated vehicles (AVs) need to plan\ntheir motion by accurately predicting pedestrians trajectories over long time\nhorizons. Current approaches to AV motion planning around crosswalks predict\nonly for short time horizons (1-2 s) and are based on data from pedestrian\ninteractions with human-driven vehicles (HDVs). In this paper, we develop a\nhybrid systems model that uses pedestrians gap acceptance behavior and constant\nvelocity dynamics for long-term pedestrian trajectory prediction when\ninteracting with AVs. Results demonstrate the applicability of the model for\nlong-term (> 5 s) pedestrian trajectory prediction at crosswalks. Further we\ncompared measures of pedestrian crossing behaviors in the immersive virtual\nenvironment (when interacting with AVs) to that in the real world (results of\npublished studies of pedestrians interacting with HDVs), and found similarities\nbetween the two. These similarities demonstrate the applicability of the hybrid\nmodel of AV interactions developed from an immersive virtual environment (IVE)\nfor real-world scenarios for both AVs and HDVs.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 21:28:39 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Jayaraman", "Suresh Kumaar", ""], ["Tilbury", "Dawn M.", ""], ["Yang", "X. Jessie", ""], ["Pradhan", "Anuj K.", ""], ["Robert", "Lionel P.", "Jr"]]}, {"id": "2003.09998", "submitter": "Lionel Robert", "authors": "Suresh Kumaar Jayaraman, Lionel P. Robert Jr., Xi Jessie Yang, Anuj K.\n  Pradhan, Dawn M. Tilbury", "title": "Efficient Behavior-aware Control of Automated Vehicles at Crosswalks\n  using Minimal Information Pedestrian Prediction Model", "comments": "7 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For automated vehicles (AVs) to reliably navigate through crosswalks, they\nneed to understand pedestrians crossing behaviors. Simple and reliable\npedestrian behavior models aid in real-time AV control by allowing the AVs to\npredict future pedestrian behaviors. In this paper, we present a Behavior aware\nModel Predictive Controller (B-MPC) for AVs that incorporates long-term\npredictions of pedestrian crossing behavior using a previously developed\npedestrian crossing model. The model incorporates pedestrians gap acceptance\nbehavior and utilizes minimal pedestrian information, namely their position and\nspeed, to predict pedestrians crossing behaviors. The BMPC controller is\nvalidated through simulations and compared to a rule-based controller. By\nincorporating predictions of pedestrian behavior, the B-MPC controller is able\nto efficiently plan for longer horizons and handle a wider range of pedestrian\ninteraction scenarios than the rule-based controller. Results demonstrate the\napplicability of the controller for safe and efficient navigation at crossing\nscenarios.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 21:34:38 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Jayaraman", "Suresh Kumaar", ""], ["Robert", "Lionel P.", "Jr."], ["Yang", "Xi Jessie", ""], ["Pradhan", "Anuj K.", ""], ["Tilbury", "Dawn M.", ""]]}, {"id": "2003.10222", "submitter": "Michele Urbani", "authors": "Marco Faggian, Michele Urbani, Luca Zanotto", "title": "Proximity: a recipe to break the outbreak", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a mobile app solution to help the containment of an epidemic\noutbreak by keeping track of possible infections in the incubation period. We\nconsider the particular case of an infection which primarily spreads among\npeople through proximal contact, via respiratory droplets. This smartphone\napplication will work offline and will be able to detect other devices in close\nproximity and list all the interactions in an anonymous and encrypted way. If\nan app user is tested positive and so is certified as infected, the application\nnotifies immediately the potential contagion to the devices in the list and\nsuggests to start a voluntary quarantine and undergo a medical test. We believe\nthis solution may be useful in particular in the current COVID-19 pandemic and\nmoreover could be used to prevent similar events in the future.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 12:33:28 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 21:34:36 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Faggian", "Marco", ""], ["Urbani", "Michele", ""], ["Zanotto", "Luca", ""]]}, {"id": "2003.10303", "submitter": "David Conal Higgins", "authors": "David Higgins and Vince I. Madai", "title": "From Bit To Bedside: A Practical Framework For Artificial Intelligence\n  Product Development In Healthcare", "comments": "30 pages, 4 figures", "journal-ref": "Advanced Intelligent Systems, 2020, 2000052", "doi": "10.1002/aisy.202000052", "report-no": null, "categories": "cs.CY cs.AI cs.HC stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Artificial Intelligence (AI) in healthcare holds great potential to expand\naccess to high-quality medical care, whilst reducing overall systemic costs.\nDespite hitting the headlines regularly and many publications of\nproofs-of-concept, certified products are failing to breakthrough to the\nclinic. AI in healthcare is a multi-party process with deep knowledge required\nin multiple individual domains. The lack of understanding of the specific\nchallenges in the domain is, therefore, the major contributor to the failure to\ndeliver on the big promises. Thus, we present a decision perspective framework,\nfor the development of AI-driven biomedical products, from conception to market\nlaunch. Our framework highlights the risks, objectives and key results which\nare typically required to proceed through a three-phase process to the market\nlaunch of a validated medical AI product. We focus on issues related to\nClinical validation, Regulatory affairs, Data strategy and Algorithmic\ndevelopment. The development process we propose for AI in healthcare software\nstrongly diverges from modern consumer software development processes. We\nhighlight the key time points to guide founders, investors and key stakeholders\nthroughout their relevant part of the process. Our framework should be seen as\na template for innovation frameworks, which can be used to coordinate team\ncommunications and responsibilities towards a reasonable product development\nroadmap, thus unlocking the potential of AI in medicine.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 14:42:18 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Higgins", "David", ""], ["Madai", "Vince I.", ""]]}, {"id": "2003.10340", "submitter": "Maxime Lenormand", "authors": "Maxime Lenormand, Horacio Samaniego, Julio C. Chaves, Vinicius F.\n  Vieira, Moacyr A. H. B. da Silva and Alexandre G. Evsukoff", "title": "Entropy as a measure of attractiveness and socioeconomic complexity in\n  Rio de Janeiro metropolitan area", "comments": "11 pages, 8 figures + Appendix", "journal-ref": "Entropy 22, 368 (2020)", "doi": "10.3390/e22030368", "report-no": null, "categories": "physics.soc-ph cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Defining and measuring spatial inequalities across the urban environment\nremains a complex and elusive task that has been facilitated by the increasing\navailability of large geolocated databases. In this study, we rely on a mobile\nphone dataset and an entropy-based metric to measure the attractiveness of a\nlocation in the Rio de Janeiro Metropolitan Area (Brazil) as the diversity of\nvisitors' location of residence. The results show that the attractiveness of a\ngiven location measured by entropy is an important descriptor of the\nsocioeconomic status of the location, and can thus be used as a proxy for\ncomplex socioeconomic indicators.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 15:58:56 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Lenormand", "Maxime", ""], ["Samaniego", "Horacio", ""], ["Chaves", "Julio C.", ""], ["Vieira", "Vinicius F.", ""], ["da Silva", "Moacyr A. H. B.", ""], ["Evsukoff", "Alexandre G.", ""]]}, {"id": "2003.10400", "submitter": "John Cummins", "authors": "John Cummins and Christopher Clack", "title": "Transforming Commercial Contracts through Computable Contracting", "comments": "14 pages, 5 figures, 3 pages of references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Contracts are an essential and fundamental component of commerce and society,\nserving to clarify agreement between multiple parties. While digital\ntechnologies have helped to automate many activities associated with\ncontracting, the contracts themselves continue, in the main, to be in the form\nof unstructured, natural-language text. This limits the scope for improvements\nin productivity and automation, as well as the emergence of new business\nmodels. To this end, this paper examines the concept of computable contracts as\nobjects that are understandable by both humans and computers, and goes on to\npresent a framework that unifies a range of technologies and approaches that\ncollectively will help to make computable contracting a reality.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 17:20:42 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 11:59:06 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Cummins", "John", ""], ["Clack", "Christopher", ""]]}, {"id": "2003.10504", "submitter": "Alvi Md Ishmam", "authors": "Alvi Md Ishmam, Md Raihan Mia", "title": "Challenges of Bridging the Gap between Mass People and Welfare\n  Organizations in Bangladesh", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing for the development of marginalized communities is a big deal of\nchallenges for researchers. Different social organizations are working to\ndevelop the conditions of a specialized marginalized community namely Street\nChildren, one of the most underprivileged communities in Bangladesh. However,\nlack of proper engagement among different social welfare organizations, donors,\nand the mass community limits the goal of the development of street children.\nDeveloping a virtual organization hub can eliminate communication gap as well\nas the information gap by involving people of all communities. However, some\nhuman imposed stigmas may often limit the rate of success of potential virtual\ncomputing solutions intended for organizations working with the marginalized\ncommunities, which we also face in our case. After a partial successful\ndeployment, the design itself needs to be self comprehensive and trustworthy in\norder to overcome the stigmas that demand a reasonable amount of time.\nMoreover, after a wide scalable deployment, it is yet to be investigated\nwhether the design of our computational solution can attain the goal for the\nfacilitation of the organizations so that those organizations can become more\neffective for the development of street children than before.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 19:28:49 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 18:41:24 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Ishmam", "Alvi Md", ""], ["Mia", "Md Raihan", ""]]}, {"id": "2003.10508", "submitter": "Xiaozan Lyu", "authors": "Xiaozan Lyu and Rodrigo Costas", "title": "How do academic topics shift across altmetric sources? A case study of\n  the research area of Big Data", "comments": null, "journal-ref": null, "doi": "10.1007/s11192-020-03415-7", "report-no": null, "categories": "cs.DL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Taking the research area of Big Data as a case study, we propose an approach\nfor exploring how academic topics shift through the interactions among\naudiences across different altmetric sources. Data used is obtained from Web of\nScience (WoS) and Altmetric.com, with a focus on Blog, News, Policy, Wikipedia,\nand Twitter. Author keywords from publications and terms from online events are\nextracted as the main topics of the publications and the online discussion of\ntheir audiences at Altmetric. Different measures are applied to determine the\n(dis)similarities between the topics put forward by the publication authors and\nthose by the online audiences. Results show that overall there are substantial\ndifferences between the two sets of topics around Big Data scientific research.\nThe main exception is Twitter, where high-frequency hashtags in tweets have a\nstronger concordance with the author keywords in publications. Among the online\ncommunities, Blogs and News show a strong similarity in the terms commonly\nused, while Policy documents and Wikipedia articles exhibit the strongest\ndissimilarity in considering and interpreting Big Data related research.\nSpecifically, the audiences not only focus on more easy-to-understand academic\ntopics related to social or general issues, but also extend them to a broader\nrange of topics in their online discussions. This study lays the foundations\nfor further investigations about the role of online audiences in the\ntransformation of academic topics across altmetric sources, and the degree of\nconcern and reception of scholarly contents by online communities.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 19:37:36 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Lyu", "Xiaozan", ""], ["Costas", "Rodrigo", ""]]}, {"id": "2003.10531", "submitter": "Tao Gu", "authors": "Haibo Ye, Tao Gu, Xianping Tao, Jian Lu", "title": "Crowdsourced Smartphone Sensing for Localization in Metro Trains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional fingerprint based localization techniques mainly rely on\ninfrastructure support such as RFID, Wi-Fi or GPS. They operate by war-driving\nthe entire space which is both time-consuming and labor-intensive. In this\npaper, we present MLoc, a novel infrastructure-free localization system to\nlocate mobile users in a metro line. It does not rely on any Wi-Fi\ninfrastructure, and does not need to war-drive the metro line. Leveraging\ncrowdsourcing, we collect accelerometer,magnetometer and barometer readings on\nsmartphones, and analyze these sensor data to extract patterns. Through\nadvanced data manipulating techniques, we build the pattern map for the entire\nmetro line, which can then be used for localization. We conduct field studies\nto demonstrate the accuracy, scalability, and robustness of M-Loc. The results\nof our field studies in 3 metro lines with 55 stations show that M-Loc achieves\nan accuracy of 93% when travelling 3 stations, 98% when travelling 5 stations.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 06:22:03 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Ye", "Haibo", ""], ["Gu", "Tao", ""], ["Tao", "Xianping", ""], ["Lu", "Jian", ""]]}, {"id": "2003.10534", "submitter": "Somalee Datta", "authors": "Somalee Datta, Jose Posada, Garrick Olson, Wencheng Li, Ciaran\n  O'Reilly, Deepa Balraj, Joseph Mesterhazy, Joseph Pallas, Priyamvada Desai,\n  Nigam Shah", "title": "A new paradigm for accelerating clinical data science at Stanford\n  Medicine", "comments": "Total of 44 pages. Main has total of 18 pages including references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DB cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stanford Medicine is building a new data platform for our academic research\ncommunity to do better clinical data science. Hospitals have a large amount of\npatient data and researchers have demonstrated the ability to reuse that data\nand AI approaches to derive novel insights, support patient care, and improve\ncare quality. However, the traditional data warehouse and Honest Broker\napproaches that are in current use, are not scalable. We are establishing a new\nsecure Big Data platform that aims to reduce time to access and analyze data.\nIn this platform, data is anonymized to preserve patient data privacy and made\navailable preparatory to Institutional Review Board (IRB) submission.\nFurthermore, the data is standardized such that analysis done at Stanford can\nbe replicated elsewhere using the same analytical code and clinical concepts.\nFinally, the analytics data warehouse integrates with a secure data science\ncomputational facility to support large scale data analytics. The ecosystem is\ndesigned to bring the modern data science community to highly sensitive\nclinical data in a secure and collaborative big data analytics environment with\na goal to enable bigger, better and faster science.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 16:21:42 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Datta", "Somalee", ""], ["Posada", "Jose", ""], ["Olson", "Garrick", ""], ["Li", "Wencheng", ""], ["O'Reilly", "Ciaran", ""], ["Balraj", "Deepa", ""], ["Mesterhazy", "Joseph", ""], ["Pallas", "Joseph", ""], ["Desai", "Priyamvada", ""], ["Shah", "Nigam", ""]]}, {"id": "2003.10838", "submitter": "Ali Yekkehkhany", "authors": "Du Su, Ali Yekkehkhany, Yi Lu, Wenmiao Lu", "title": "Prob2Vec: Mathematical Semantic Embedding for Problem Retrieval in\n  Adaptive Tutoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new application of embedding techniques for problem retrieval in\nadaptive tutoring. The objective is to retrieve problems whose mathematical\nconcepts are similar. There are two challenges: First, like sentences, problems\nhelpful to tutoring are never exactly the same in terms of the underlying\nconcepts. Instead, good problems mix concepts in innovative ways, while still\ndisplaying continuity in their relationships. Second, it is difficult for\nhumans to determine a similarity score that is consistent across a large enough\ntraining set. We propose a hierarchical problem embedding algorithm, called\nProb2Vec, that consists of abstraction and embedding steps. Prob2Vec achieves\n96.88\\% accuracy on a problem similarity test, in contrast to 75\\% from\ndirectly applying state-of-the-art sentence embedding methods. It is\ninteresting that Prob2Vec is able to distinguish very fine-grained differences\namong problems, an ability humans need time and effort to acquire. In addition,\nthe sub-problem of concept labeling with imbalanced training data set is\ninteresting in its own right. It is a multi-label problem suffering from\ndimensionality explosion, which we propose ways to ameliorate. We propose the\nnovel negative pre-training algorithm that dramatically reduces false negative\nand positive ratios for classification, using an imbalanced training data set.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 00:16:14 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Su", "Du", ""], ["Yekkehkhany", "Ali", ""], ["Lu", "Yi", ""], ["Lu", "Wenmiao", ""]]}, {"id": "2003.10998", "submitter": "Artur Strzelecki", "authors": "Artur Strzelecki", "title": "The Second Worldwide Wave of Interest in Coronavirus since the COVID-19\n  Outbreaks in South Korea, Italy and Iran: A Google Trends Study", "comments": "4 pages, 1 figure, 2 tables", "journal-ref": "Brain, Behavior, and Immunity 88 (2020) 950-951", "doi": "10.1016/j.bbi.2020.04.042", "report-no": null, "categories": "cs.CY cs.IR econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent emergence of a new coronavirus, COVID-19, has gained extensive\ncoverage in public media and global news. As of 24 March 2020, the virus has\ncaused viral pneumonia in tens of thousands of people in Wuhan, China, and\nthousands of cases in 184 other countries and territories. This study explores\nthe potential use of Google Trends (GT) to monitor worldwide interest in this\nCOVID-19 epidemic. GT was chosen as a source of reverse engineering data, given\nthe interest in the topic. Current data on COVID-19 is retrieved from (GT)\nusing one main search topic: Coronavirus. Geographical settings for GT are\nworldwide, China, South Korea, Italy and Iran. The reported period is 15\nJanuary 2020 to 24 March 2020. The results show that the highest worldwide peak\nin the first wave of demand for information was on 31 January 2020. After the\nfirst peak, the number of new cases reported daily rose for 6 days. A second\nwave started on 21 February 2020 after the outbreaks were reported in Italy,\nwith the highest peak on 16 March 2020. The second wave is six times as big as\nthe first wave. The number of new cases reported daily is rising day by day.\nThis short communication gives a brief introduction to how the demand for\ninformation on coronavirus epidemic is reported through GT.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 17:33:59 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 07:23:37 GMT"}, {"version": "v3", "created": "Tue, 28 Jul 2020 13:41:20 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Strzelecki", "Artur", ""]]}, {"id": "2003.11059", "submitter": "Satya Narayan Shukla", "authors": "Satya Narayan Shukla, Benjamin M. Marlin", "title": "Integrating Physiological Time Series and Clinical Notes with Deep\n  Learning for Improved ICU Mortality Prediction", "comments": "Presented at ACM Conference on Health, Inference and Learning\n  (Workshop Track), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intensive Care Unit Electronic Health Records (ICU EHRs) store multimodal\ndata about patients including clinical notes, sparse and irregularly sampled\nphysiological time series, lab results, and more. To date, most methods\ndesigned to learn predictive models from ICU EHR data have focused on a single\nmodality. In this paper, we leverage the recently proposed\ninterpolation-prediction deep learning architecture(Shukla and Marlin 2019) as\na basis for exploring how physiological time series data and clinical notes can\nbe integrated into a unified mortality prediction model. We study both early\nand late fusion approaches and demonstrate how the relative predictive value of\nclinical text and physiological data change over time. Our results show that a\nlate fusion approach can provide a statistically significant improvement in\nmortality prediction performance over using individual modalities in isolation.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 18:25:49 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 21:00:52 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Shukla", "Satya Narayan", ""], ["Marlin", "Benjamin M.", ""]]}, {"id": "2003.11139", "submitter": "Milena Tsvetkova", "authors": "Ji Eun Kim and Milena Tsvetkova", "title": "Large-scale network analysis reveals cheating spreads through\n  victimization and observation", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Antisocial behavior such as negative gossip, cheating, or bullying can be\ncontagious, spreading from individual to individual and rippling through social\nnetworks. Previous experimental research has suggested that individuals who\neither experience or observe antisocial behavior become more likely to behave\nantisocially. Here, we distinguish between victimization and observation using\nan observational study. We apply temporal network analysis on large-scale\ndigital trace data to study the spread of cheating in online gaming. We analyze\n1,146,941 matches of the multiplayer online game PlayerUnknown's Battlegrounds,\nin which up to 100 players compete individually or in teams against strangers.\nWe identify temporal motifs in which a player who is killed by or observes\ncheaters starts cheating, and evaluate the extent to which these motifs would\nappear if we preserve the team and interaction structure but assume an\nalternative sequence of events. The results suggest that social contagion is\nonly likely to exist for those who both experience and observe cheating\nmultiple times. The findings point to strategies for targeted interventions to\nstem the spread of cheating and antisocial behavior in online communities,\nschools, organizations, and sports.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 22:38:07 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Kim", "Ji Eun", ""], ["Tsvetkova", "Milena", ""]]}, {"id": "2003.11157", "submitter": "Peter Reiner", "authors": "Anthony Aguirre, Gaia Dempsey, Harry Surden, and Peter B. Reiner", "title": "AI loyalty: A New Paradigm for Aligning Stakeholder Interests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When we consult with a doctor, lawyer, or financial advisor, we generally\nassume that they are acting in our best interests. But what should we assume\nwhen it is an artificial intelligence (AI) system that is acting on our behalf?\nEarly examples of AI assistants like Alexa, Siri, Google, and Cortana already\nserve as a key interface between consumers and information on the web, and\nusers routinely rely upon AI-driven systems like these to take automated\nactions or provide information. Superficially, such systems may appear to be\nacting according to user interests. However, many AI systems are designed with\nembedded conflicts of interests, acting in ways that subtly benefit their\ncreators (or funders) at the expense of users. To address this problem, in this\npaper we introduce the concept of AI loyalty. AI systems are loyal to the\ndegree that they are designed to minimize, and make transparent, conflicts of\ninterest, and to act in ways that prioritize the interests of users. Properly\ndesigned, such systems could have considerable functional and competitive - not\nto mention ethical - advantages relative to those that do not. Loyal AI\nproducts hold an obvious appeal for the end-user and could serve to promote the\nalignment of the long-term interests of AI developers and customers. To this\nend, we suggest criteria for assessing whether an AI system is sufficiently\ntransparent about conflicts of interest, and acting in a manner that is loyal\nto the user, and argue that AI loyalty should be considered during the\ntechnological design process alongside other important values in AI ethics such\nas fairness, accountability privacy, and equity. We discuss a range of\nmechanisms, from pure market forces to strong regulatory frameworks, that could\nsupport incorporation of AI loyalty into a variety of future AI systems.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 23:55:59 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Aguirre", "Anthony", ""], ["Dempsey", "Gaia", ""], ["Surden", "Harry", ""], ["Reiner", "Peter B.", ""]]}, {"id": "2003.11159", "submitter": "Josimar Chire Saire", "authors": "Josimar E. Chire Saire and Roberto C. Navarro", "title": "What is the people posting about symptoms related to Coronavirus in\n  Bogota, Colombia?", "comments": "The paper has 3 pages, two columns. If the paper does not fit\n  Information Networks field, you may suggest one", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last months, there is an increasing alarm about a new mutation of\ncoronavirus, covid-19 coined by World Health Organization(WHO) with an impact\nin many areas: economy, health, politics and others. This situation was\ndeclared a pandemic by WHO, because of the fast expansion over many countries.\nAt the same time, people is using Social Networks to express what they think,\nfeel or experiment, so this people are Social Sensors and helps to analyze what\nis happening in their city. The objective of this paper is analyze the\npublications of Colombian people living in Bogota with a radius of 50 km using\nText Mining techniques from symptomatology approach. The results support the\nunderstanding of the spread in Colombia related to symptoms of covid19.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 00:07:50 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Saire", "Josimar E. Chire", ""], ["Navarro", "Roberto C.", ""]]}, {"id": "2003.11320", "submitter": "Christopher Starke", "authors": "Christopher Starke, Marco Luenich", "title": "Artificial Intelligence for EU Decision-Making. Effects on Citizens\n  Perceptions of Input, Throughput and Output Legitimacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A lack of political legitimacy undermines the ability of the European Union\nto resolve major crises and threatens the stability of the system as a whole.\nBy integrating digital data into political processes, the EU seeks to base\ndecision-making increasingly on sound empirical evidence. In particular,\nartificial intelligence systems have the potential to increase political\nlegitimacy by identifying pressing societal issues, forecasting potential\npolicy outcomes, informing the policy process, and evaluating policy\neffectiveness. This paper investigates how citizens perceptions of EU input,\nthroughput, and output legitimacy are influenced by three distinct\ndecision-making arrangements. First, independent human decision-making, HDM,\nSecond, independent algorithmic decision-making, ADM, and, third, hybrid\ndecision-making by EU politicians and AI-based systems together. The results of\na pre-registered online experiment with 572 respondents suggest that existing\nEU decision-making arrangements are still perceived as the most democratic -\ninput legitimacy. However, regarding the decision-making process itself -\nthroughput legitimacy - and its policy outcomes - output legitimacy, no\ndifference was observed between the status quo and hybrid decision-making\ninvolving both ADM and democratically elected EU institutions. Where ADM\nsystems are the sole decision-maker, respondents tend to perceive these as\nillegitimate. The paper discusses the implications of these findings for EU\nlegitimacy and data-driven policy-making.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 10:56:28 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Starke", "Christopher", ""], ["Luenich", "Marco", ""]]}, {"id": "2003.11336", "submitter": "Joseph Bullock", "authors": "Joseph Bullock, Alexandra Luccioni, Katherine Hoffmann Pham, Cynthia\n  Sin Nga Lam, Miguel Luengo-Oroz", "title": "Mapping the Landscape of Artificial Intelligence Applications against\n  COVID-19", "comments": "39 pages, v2: much larger to reflect the significant increase in the\n  size of the body of literature, v3: uploaded with JAIR page numbers and\n  references", "journal-ref": "Journal of Artificial Intelligence Research 69 (2020) 807-845", "doi": "10.1613/jair.1.12162", "report-no": null, "categories": "cs.CY cs.AI cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COVID-19, the disease caused by the SARS-CoV-2 virus, has been declared a\npandemic by the World Health Organization, which has reported over 18 million\nconfirmed cases as of August 5, 2020. In this review, we present an overview of\nrecent studies using Machine Learning and, more broadly, Artificial\nIntelligence, to tackle many aspects of the COVID-19 crisis. We have identified\napplications that address challenges posed by COVID-19 at different scales,\nincluding: molecular, by identifying new or existing drugs for treatment;\nclinical, by supporting diagnosis and evaluating prognosis based on medical\nimaging and non-invasive measures; and societal, by tracking both the epidemic\nand the accompanying infodemic using multiple data sources. We also review\ndatasets, tools, and resources needed to facilitate Artificial Intelligence\nresearch, and discuss strategic considerations related to the operational\nimplementation of multidisciplinary partnerships and open science. We highlight\nthe need for international cooperation to maximize the potential of AI in this\nand future pandemics.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 12:30:33 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 16:50:22 GMT"}, {"version": "v3", "created": "Mon, 11 Jan 2021 14:35:21 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Bullock", "Joseph", ""], ["Luccioni", "Alexandra", ""], ["Pham", "Katherine Hoffmann", ""], ["Lam", "Cynthia Sin Nga", ""], ["Luengo-Oroz", "Miguel", ""]]}, {"id": "2003.11340", "submitter": "Kashyap Thimmaraju", "authors": "Kashyap Thimmaraju, Julian Fietkau and Fatemeh Ganji", "title": "Towards an Insightful Computer Security Seminar", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe our experience in designing and evaluating our\ngraduate level computer security seminar course. In particular, our seminar is\ndesigned with two goals in mind. First, to instil critical thinking by teaching\ngraduate students how to read, review and present scientific literature.\nSecond, to learn about the state-of-the-art in computer security and privacy\nresearch by reviewing proceedings from one of the top four security and privacy\nconferences including IEEE Symposium on Security and Privacy (Oakland SP),\nUSENIX Security, Network and Distributed System Security Symposium (NDSS) and\nACM Conference on Computer and Communications Security (CCS). The course\nentails each student to i) choose a specific technical session from the most\nrecent conference, ii) review and present three papers from the chosen session\nand iii) analyze the relationship between the chosen papers from the session.\nTo evaluate the course, we designed a set of questions to understand the\nmotivation and decisions behind the students' choices as well as to evaluate\nand improve the quality of the course. Our key insights from the evaluation are\nthe following: The three most popular topics of interest were Privacy, Web\nSecurity and Authentication, ii) 33% of the students chose the sessions based\non the title of papers and iii) when providing an encouraging environment,\nstudents enjoy and engage in discussions.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 11:40:58 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Thimmaraju", "Kashyap", ""], ["Fietkau", "Julian", ""], ["Ganji", "Fatemeh", ""]]}, {"id": "2003.11515", "submitter": "Amy X. Lu", "authors": "Haoran Zhang, Amy X. Lu, Mohamed Abdalla, Matthew McDermott, Marzyeh\n  Ghassemi", "title": "Hurtful Words: Quantifying Biases in Clinical Contextual Word Embeddings", "comments": "Accepted at ACM CHIL 2020 (Spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we examine the extent to which embeddings may encode\nmarginalized populations differently, and how this may lead to a perpetuation\nof biases and worsened performance on clinical tasks. We pretrain deep\nembedding models (BERT) on medical notes from the MIMIC-III hospital dataset,\nand quantify potential disparities using two approaches. First, we identify\ndangerous latent relationships that are captured by the contextual word\nembeddings using a fill-in-the-blank method with text from real clinical notes\nand a log probability bias score quantification. Second, we evaluate\nperformance gaps across different definitions of fairness on over 50 downstream\nclinical prediction tasks that include detection of acute and chronic\nconditions. We find that classifiers trained from BERT representations exhibit\nstatistically significant differences in performance, often favoring the\nmajority group with regards to gender, language, ethnicity, and insurance\nstatus. Finally, we explore shortcomings of using adversarial debiasing to\nobfuscate subgroup information in contextual word embeddings, and recommend\nbest practices for such deep embedding models in clinical settings.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 23:21:14 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Zhang", "Haoran", ""], ["Lu", "Amy X.", ""], ["Abdalla", "Mohamed", ""], ["McDermott", "Matthew", ""], ["Ghassemi", "Marzyeh", ""]]}, {"id": "2003.11746", "submitter": "Jim Samuel", "authors": "Yana Samuel, Jean George and Jim Samuel", "title": "Beyond STEM, How Can Women Engage Big Data, Analytics, Robotics and\n  Artificial Intelligence? An Exploratory Analysis of Confidence and\n  Educational Factors in the Emerging Technology Waves Influencing the Role of,\n  and Impact Upon, Women", "comments": "Cite As: Samuel, Y., George, J. & Samuel, J., (2018). Beyond STEM,\n  How Can Women Engage Big Data, Analytics, Robotics and Artificial\n  Intelligence? An Exploratory Analysis of Confidence and Educational Factors\n  in the Emerging Technology Waves Influencing the Role of, and Impact Upon,\n  Women. 2018 Annual Proceedings of Northeast Decision Sciences Institute\n  (NEDSI) Conference, Rhode Island, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of the rapidly advancing global technological environment, the\nprofessional participation of women in technology, big data, analytics,\nartificial intelligence and information systems related domains remains\nproportionately low. Furthermore, it is of no less concern that the number of\nwomen in leadership in these domains are in even lower proportions. In spite of\nnumerous initiatives to improve the participation of women in technological\ndomains, there is an increasing need to gain additional insights into this\nphenomenon especially since it occurs in nations and geographies which have\nseen a sharp rise in overall female education, without such increase\ntranslating into a corresponding spurt in information systems and technological\nroles for women. The present paper presents findings from an exploratory\nanalysis and outlines a framework to gain insights into educational factors in\nthe emerging technology waves influencing the role of, and impact upon, women.\nWe specifically identify ways for learning and self-efficacy as key factors,\nwhich together lead us to the Advancement of Women in Technology (AWT) insights\nframework. Based on the AWT framework, we also proposition principles that can\nbe used to encourage higher professional engagement of women in emerging and\nadvanced technologies. Key Words- Women's Education, Technology, Artificial\nIntelligence, Knowing, Confidence, Self-Efficacy, Learning.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 05:12:42 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Samuel", "Yana", ""], ["George", "Jean", ""], ["Samuel", "Jim", ""]]}, {"id": "2003.11906", "submitter": "Yelena Mejova", "authors": "Alessandro Cossard, Gianmarco De Francisci Morales, Kyriaki Kalimeri,\n  Yelena Mejova, Daniela Paolotti, Michele Starnini", "title": "Falling into the Echo Chamber: the Italian Vaccination Debate on Twitter", "comments": null, "journal-ref": "International AAAI Conference on Web and Social Media (ICWSM) 2020", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reappearance of measles in the US and Europe, a disease considered\neliminated in early 2000s, has been accompanied by a growing debate on the\nmerits of vaccination on social media. In this study we examine the extent to\nwhich the vaccination debate on Twitter is conductive to potential outreach to\nthe vaccination hesitant. We focus on Italy, one of the countries most affected\nby the latest measles outbreaks. We discover that the vaccination skeptics, as\nwell as the advocates, reside in their own distinct \"echo chambers\". The\nstructure of these communities differs as well, with skeptics arranged in a\ntightly connected cluster, and advocates organizing themselves around few\nauthoritative hubs. At the center of these echo chambers we find the ardent\nsupporters, for which we build highly accurate network- and content-based\nclassifiers (attaining 95% cross-validated accuracy). Insights of this study\nprovide several avenues for potential future interventions, including\nnetwork-guided targeting, accounting for the political context, and monitoring\nof alternative sources of information.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 13:55:50 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Cossard", "Alessandro", ""], ["Morales", "Gianmarco De Francisci", ""], ["Kalimeri", "Kyriaki", ""], ["Mejova", "Yelena", ""], ["Paolotti", "Daniela", ""], ["Starnini", "Michele", ""]]}, {"id": "2003.12132", "submitter": "Xavier-Lewis Palmer", "authors": "Xavier-Lewis Palmer, Lucas Potter, and Saltuk Karahan", "title": "On the Emerging Area of Biocybersecurity and Relevant Considerations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Biocybersecurity is a novel space for the 21st century that meets our\ninnovations in biotechnology and computing head on. Within this space, many\nconsiderations are open for and demand consideration as groups endeavor to\ndevelop products and policies that adequately ensure asset management and\nprotection. Herein, simplified and brief exploration is given followed by some\nsurface discussion of impacts. These impacts concern the end user, ethical and\nlegal considerations, international proceedings, business, and limitations. It\nis hoped that this will be helpful in future considerations towards\nbiocybersecurity policy developments and implementations.\n  Notice: This article has been queued for publication in the Proceedings of\nthe 2020 Future of Information and Communication Conference (FICC)\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 03:44:51 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Palmer", "Xavier-Lewis", ""], ["Potter", "Lucas", ""], ["Karahan", "Saltuk", ""]]}, {"id": "2003.12133", "submitter": "Alina Arseniev-Koehler", "authors": "Alina Arseniev-Koehler and Jacob G. Foster", "title": "Machine learning as a model for cultural learning: Teaching an algorithm\n  what it means to be fat", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As we navigate our cultural environment, we learn cultural biases, like those\naround gender, social class, health, and body weight. It is unclear, however,\nexactly how public culture becomes private culture. In this paper, we provide a\ntheoretical account of such cultural learning. We propose that neural word\nembeddings provide a parsimonious and cognitively plausible model of the\nrepresentations learned from natural language. Using neural word embeddings, we\nextract cultural schemata about body weight from New York Times articles. We\nidentify several cultural schemata that link obesity to gender, immorality,\npoor health, and low socioeconomic class. Such schemata may be subtly but\npervasively activated in public culture; thus, language can chronically\nreproduce biases. Our findings reinforce ongoing concerns that machine learning\ncan also encode, and reproduce, harmful human biases.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 00:47:51 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 22:58:22 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Arseniev-Koehler", "Alina", ""], ["Foster", "Jacob G.", ""]]}, {"id": "2003.12141", "submitter": "Francesco Fusco", "authors": "Bradley Eck, Francesco Fusco, Robert Gormally, Mark Purcell, Seshu\n  Tirupathi", "title": "Scalable Deployment of AI Time-series Models for IoT", "comments": null, "journal-ref": "Workshop AI for Internet of Things, IJCAI 2019", "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IBM Research Castor, a cloud-native system for managing and deploying large\nnumbers of AI time-series models in IoT applications, is described. Modelling\ncode templates, in Python and R, following a typical machine-learning workflow\nare supported. A knowledge-based approach to managing model and time-series\ndata allows the use of general semantic concepts for expressing feature\nengineering tasks. Model templates can be programmatically deployed against\nspecific instances of semantic concepts, thus supporting model reuse and\nautomated replication as the IoT application grows. Deployed models are\nautomatically executed in parallel leveraging a serverless cloud computing\nframework. The complete history of trained model versions and rolling-horizon\npredictions is persisted, thus enabling full model lineage and traceability.\nResults from deployments in real-world smart-grid live forecasting applications\nare reported. Scalability of executing up to tens of thousands of AI modelling\ntasks is also evaluated.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 14:27:25 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Eck", "Bradley", ""], ["Fusco", "Francesco", ""], ["Gormally", "Robert", ""], ["Purcell", "Mark", ""], ["Tirupathi", "Seshu", ""]]}, {"id": "2003.12143", "submitter": "Lei Fang", "authors": "Peter Fang", "title": "Coronavirus Geographic Dissemination at Chicago and its Potential\n  Proximity to Public Commuter Rail", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The community spread of coronavirus at great Chicago area has severely\nthreatened the residents health, family and normal activities. CDC daily\nupdates on infected cases on County level are not satisfying to address publics\nconcern on virus spread. On March 20th, NBC5 published case information of 435\ncoronavirus infections. The data is relative comprehensive and of high value\nfor understanding on the virus spread patterns at Chicago. Data engineering,\nnatural language processing and Google map technology are applied to organize\nthe data and retrieve geographic information of the virus. The analysis shows\ncommunity spread in Chicago areas has a potential proximity relation with\npublic commuter rail. Residents nearby major public commuter rails need limit\noutdoor activities during the outbreak and even the post-peak time.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 13:37:06 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Fang", "Peter", ""]]}, {"id": "2003.12232", "submitter": "Yujie Fan", "authors": "Yanfang Ye, Shifu Hou, Yujie Fan, Yiyue Qian, Yiming Zhang, Shiyu Sun,\n  Qian Peng, Kenneth Laparo", "title": "$\\alpha$-Satellite: An AI-driven System and Benchmark Datasets for\n  Hierarchical Community-level Risk Assessment to Help Combat COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The novel coronavirus and its deadly outbreak have posed grand challenges to\nhuman society: as of March 26, 2020, there have been 85,377 confirmed cases and\n1,293 reported deaths in the United States; and the World Health Organization\n(WHO) characterized coronavirus disease (COVID-19) - which has infected more\nthan 531,000 people with more than 24,000 deaths in at least 171 countries - a\nglobal pandemic. A growing number of areas reporting local sub-national\ncommunity transmission would represent a significant turn for the worse in the\nbattle against the novel coronavirus, which points to an urgent need for\nexpanded surveillance so we can better understand the spread of COVID-19 and\nthus better respond with actionable strategies for community mitigation. By\nadvancing capabilities of artificial intelligence (AI) and leveraging the\nlarge-scale and real-time data generated from heterogeneous sources (e.g.,\ndisease related data from official public health organizations, demographic\ndata, mobility data, and user geneated data from social media), in this work,\nwe propose and develop an AI-driven system (named $\\alpha$-Satellite}, as an\ninitial offering, to provide hierarchical community-level risk assessment to\nassist with the development of strategies for combating the fast evolving\nCOVID-19 pandemic. More specifically, given a specific location (either user\ninput or automatic positioning), the developed system will automatically\nprovide risk indexes associated with it in a hierarchical manner (e.g., state,\ncounty, city, specific location) to enable individuals to select appropriate\nactions for protection while minimizing disruptions to daily life to the extent\npossible. The developed system and the generated benchmark datasets have been\nmade publicly accessible through our website. The system description and\ndisclaimer are also available in our website.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 04:44:53 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Ye", "Yanfang", ""], ["Hou", "Shifu", ""], ["Fan", "Yujie", ""], ["Qian", "Yiyue", ""], ["Zhang", "Yiming", ""], ["Sun", "Shiyu", ""], ["Peng", "Qian", ""], ["Laparo", "Kenneth", ""]]}, {"id": "2003.12309", "submitter": "Karishma Sharma", "authors": "Karishma Sharma, Sungyong Seo, Chuizheng Meng, Sirisha Rambhatla, Yan\n  Liu", "title": "COVID-19 on Social Media: Analyzing Misinformation in Twitter\n  Conversations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ongoing Coronavirus (COVID-19) pandemic highlights the\ninter-connectedness of our present-day globalized world. With social distancing\npolicies in place, virtual communication has become an important source of\n(mis)information. As increasing number of people rely on social media platforms\nfor news, identifying misinformation and uncovering the nature of online\ndiscourse around COVID-19 has emerged as a critical task. To this end, we\ncollected streaming data related to COVID-19 using the Twitter API, starting\nMarch 1, 2020. We identified unreliable and misleading contents based on\nfact-checking sources, and examined the narratives promoted in misinformation\ntweets, along with the distribution of engagements with these tweets. In\naddition, we provide examples of the spreading patterns of prominent\nmisinformation tweets. The analysis is presented and updated on a publically\naccessible dashboard (https://usc-melady.github.io/COVID-19-Tweet-Analysis) to\ntrack the nature of online discourse and misinformation about COVID-19 on\nTwitter from March 1 - June 5, 2020. The dashboard provides a daily list of\nidentified misinformation tweets, along with topics, sentiments, and emerging\ntrends in the COVID-19 Twitter discourse. The dashboard is provided to improve\nvisibility into the nature and quality of information shared online, and\nprovide real-time access to insights and information extracted from the\ndataset.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 09:48:24 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 16:42:46 GMT"}, {"version": "v3", "created": "Fri, 8 May 2020 19:12:29 GMT"}, {"version": "v4", "created": "Thu, 22 Oct 2020 03:03:29 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Sharma", "Karishma", ""], ["Seo", "Sungyong", ""], ["Meng", "Chuizheng", ""], ["Rambhatla", "Sirisha", ""], ["Liu", "Yan", ""]]}, {"id": "2003.12347", "submitter": "Patrick Vinck", "authors": "Nuria Oliver, Emmanuel Letouz\\'e, Harald Sterly, S\\'ebastien\n  Delataille, Marco De Nadai, Bruno Lepri, Renaud Lambiotte, Richard Benjamins,\n  Ciro Cattuto, Vittoria Colizza, Nicolas de Cordes, Samuel P. Fraiberger, Till\n  Koebe, Sune Lehmann, Juan Murillo, Alex Pentland, Phuong N Pham, Fr\\'ed\\'eric\n  Pivetta, Albert Ali Salah, Jari Saram\\\"aki, Samuel V. Scarpino, Michele\n  Tizzoni, Stefaan Verhulst, Patrick Vinck", "title": "Mobile phone data and COVID-19: Missing an opportunity?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes how mobile phone data can guide government and public\nhealth authorities in determining the best course of action to control the\nCOVID-19 pandemic and in assessing the effectiveness of control measures such\nas physical distancing. It identifies key gaps and reasons why this kind of\ndata is only scarcely used, although their value in similar epidemics has\nproven in a number of use cases. It presents ways to overcome these gaps and\nkey recommendations for urgent action, most notably the establishment of mixed\nexpert groups on national and regional level, and the inclusion and support of\ngovernments and public authorities early on. It is authored by a group of\nexperienced data scientists, epidemiologists, demographers and representatives\nof mobile network operators who jointly put their work at the service of the\nglobal effort to combat the COVID-19 pandemic.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 12:01:30 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Oliver", "Nuria", ""], ["Letouz\u00e9", "Emmanuel", ""], ["Sterly", "Harald", ""], ["Delataille", "S\u00e9bastien", ""], ["De Nadai", "Marco", ""], ["Lepri", "Bruno", ""], ["Lambiotte", "Renaud", ""], ["Benjamins", "Richard", ""], ["Cattuto", "Ciro", ""], ["Colizza", "Vittoria", ""], ["de Cordes", "Nicolas", ""], ["Fraiberger", "Samuel P.", ""], ["Koebe", "Till", ""], ["Lehmann", "Sune", ""], ["Murillo", "Juan", ""], ["Pentland", "Alex", ""], ["Pham", "Phuong N", ""], ["Pivetta", "Fr\u00e9d\u00e9ric", ""], ["Salah", "Albert Ali", ""], ["Saram\u00e4ki", "Jari", ""], ["Scarpino", "Samuel V.", ""], ["Tizzoni", "Michele", ""], ["Verhulst", "Stefaan", ""], ["Vinck", "Patrick", ""]]}, {"id": "2003.12375", "submitter": "Bryan Ford", "authors": "Bryan Ford", "title": "Democratic Value and Money for Decentralized Digital Society", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical monetary systems regularly subject the most vulnerable majority of\nthe world's population to debilitating financial shocks, and have manifestly\nallowed uncontrolled global inequality over the long term. Given these basic\nfailures, how can we avoid asking whether mainstream macroeconomic principles\nare actually compatible with democratic principles such as equality or the\nprotection of human rights and dignity? This idea paper takes a constructive\nlook at this question, by exploring how alternate monetary principles might\nresult in a form of money more compatible with democratic principles -- dare we\ncall it \"democratic money\"? In this alternative macroeconomic philosophy, both\nthe supply of and the demand for money must be rooted in people, so as to give\nall people both equal opportunities for economic participation. Money must be\ndesigned around equality, not only across all people alive at a given moment,\nbut also across past and future generations of people, guaranteeing that our\ndescendants cannot be enslaved by their ancestors' economic luck or misfortune.\nDemocratic money must reliably give all people a means to enable everyday\ncommerce, investment, and value creation in good times and bad, and must impose\nhard limits on financial inequality. Democratic money must itself be governed\ndemocratically, and must economically facilitate the needs of citizens in a\ndemocracy for trustworthy and unbiased information with which to make wise\ncollective decisions. An intriguing approach to implementing and deploying\ndemocratic money is via a cryptocurrency built on a proof-of-personhood\nfoundation, giving each opt-in human participant one equal unit of stake. Such\na cryptocurrency would have both interesting similarities to, and important\ndifferences from, a Universal Basic Income (UBI) denominated in an existing\ncurrency.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 09:30:47 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Ford", "Bryan", ""]]}, {"id": "2003.12393", "submitter": "Bryan Ford", "authors": "Bryan Ford", "title": "A Liquid Perspective on Democratic Choice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The idea of liquid democracy responds to a widely-felt desire to make\ndemocracy more \"fluid\" and continuously participatory. Its central premise is\nto enable users to employ networked technologies to control and delegate voting\npower, to approximate the ideal of direct democracy in a scalable fashion that\naccounts for time and attention limits. There are many potential definitions,\nmeanings, and ways to implement liquid democracy, however, and many distinct\npurposes to which it might be deployed. This paper develops and explores the\n\"liquid\" notion and what it might mean for purposes of enhancing voter choice\nby spreading voting power, improving proportional representation systems,\nsimplifying or aiding voters in their choice, or scaling direct democracy\nthrough specialization. The goal of this paper is to disentangle and further\ndevelop some of the many concepts and goals that liquid democracy ideas often\nembody, to explore their justification with respect to existing democratic\ntraditions such as transferable voting and political parties, and to explore\npotential risks in liquid democracy systems and ways to address them.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 09:43:01 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Ford", "Bryan", ""]]}, {"id": "2003.12569", "submitter": "Yoichi Yamazaki", "authors": "Kazuaki Takeuchi, Yoichi Yamazaki, and Kentaro Yoshifuji", "title": "Avatar Work: Telework for Disabled People Unable to Go Outside by Using\n  Avatar Robots \"OriHime-D\" and Its Verification", "comments": "8 pages, 16 figures, accepted to the 2020 ACM/IEEE International\n  Conference on Human-Robot Interaction (HRI '20 Companion) at alt.HRI session,\n  2020", "journal-ref": "In Companion of the 2020 ACM/IEEE International Conference on\n  Human-Robot Interaction (HRI '20 Companion), March, 2020, 8pages", "doi": "10.1145/3371382.3380737", "report-no": null, "categories": "cs.RO cs.CY cs.HC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we propose a telework \"avatar work\" that enables people with\ndisabilities to engage in physical works such as customer service in order to\nrealize an inclusive society, where we can do anything if we have free mind,\neven though we are bedridden. In avatar work, disabled people can remotely\nengage in physical work by operating a proposed robot \"OriHime-D\" with a mouse\nor gaze input depending on their own disabilities. As a social implementation\ninitiative of avatar work, we have opened a two-week limited avatar robot cafe\nand have evaluated remote employment by people with disabilities using\nOriHime-D. As the results by 10 people with disabilities, we have confirmed\nthat the proposed avatar work leads to mental fulfillment for people with\ndisparities, and can be designed with adaptable workload. In addition, we have\nconfirmed that the work content of the experimental cafe is appropriate for\npeople with a variety of disabilities seeking social participation. This study\ncontributes to fulfillment all through life and lifetime working, and at the\nsame time leads to a solution to the employment shortage problem.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 12:44:47 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Takeuchi", "Kazuaki", ""], ["Yamazaki", "Yoichi", ""], ["Yoshifuji", "Kentaro", ""]]}, {"id": "2003.13030", "submitter": "Miguel Guevara", "authors": "Paulina Hurtado-Arenas, Miguel R. Guevara", "title": "A bibliometric analysis of research based on the Roy Adaptation Model: a\n  contribution to Nursing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.DL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Objective. To perform a modern bibliometric analysis of the research based on\nthe Roy Adaptation Model, a founding nursing model proposed by Sor Callista Roy\nin the1970s. Method. A descriptive and longitudinal study. We used information\nfrom the two dominant scientific databases, Web Of Science and SCOPUS. We\nobtained 137 publications from the Core Collection of WoS, and 338 publications\nfrom SCOPUS. We conducted our analysis using the software Bibliometrix, an\nR-package specialized in creating bibliometric analyses from a perspective of\ndescriptive statistics and network analysis, including co-citation, co-keyword\noccurrence and collaboration networks. Results. Our quantitative results show\nthe main actors around the research based on the model and the founding\nliterature or references on which this research was based. We analyze the main\nkeywords and how they are linked. Furthermore, we present the most prolific\nauthors both in number of publications and in centrality in the network of\ncoauthors. We present the most central institutions in the global network of\ncollaboration. Conclusions. We highlight the relevance of this theoretical\nmodel in nursing and detail its evolution. The United States is the dominant\ncountry in production of documents on the topic, and the University of\nMassachusetts Boston and Boston College are the most influential institutions.\nThe network of collaboration also describes clusters in Mexico, Turkey and\nSpain. Our findings are useful to acquire a general vision of the field.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 14:02:16 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Hurtado-Arenas", "Paulina", ""], ["Guevara", "Miguel R.", ""]]}, {"id": "2003.13604", "submitter": "Elisa Bertino", "authors": "Elisa Bertino, Syed Rafiul Hussain, and Omar Chowdhury", "title": "5G Security and Privacy: A Research Roadmap", "comments": "A Computing Community Consortium (CCC) white paper, 8 pages", "journal-ref": null, "doi": null, "report-no": "ccc2020whitepaper_1", "categories": "cs.CY cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cellular networks represent a critical infrastructure and their security is\nthus crucial. 5G - the latest generation of cellular networks - combines\ndifferent technologies to increase capacity, reduce latency, and save energy.\nDue to its complexity and scale, however, ensuring its security is extremely\nchallenging. In this white paper, we outline recent approaches supporting\nsystematic analyses of 4G LTE and 5G protocols and their related defenses and\nintroduce an initial security and privacy roadmap, covering different research\nchallenges, including formal and comprehensive analyses of cellular protocols\nas defined by the standardization groups, verification of the software\nimplementing the protocols, the design of robust defenses, and application and\ndevice security.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 16:36:43 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Bertino", "Elisa", ""], ["Hussain", "Syed Rafiul", ""], ["Chowdhury", "Omar", ""]]}, {"id": "2003.13629", "submitter": "Glen MacLachlan", "authors": "Glen MacLachlan, Jason Hurlburt, Marco Suarez, Kai Leung Wong, William\n  Burke, Terrence Lewis, Andrew Gallo, Jaroslav Flidr, Raoul Gabiam, Janis\n  Nicholas, Brian Ensor", "title": "Building a Shared Resource HPC Center Across University Schools and\n  Institutes: A Case Study", "comments": "5 pages, 2 tables. Submitted to SC16 and XSEDE16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past several years, The George Washington University has recruited a\nsignificant number of researchers in a wide variety of domains requiring the\navailability of advanced computational resources. We discuss the challenges and\nobstacles encountered planning and establishing a first-time high performance\ncomputing center at the university level and present a set of solutions that\nwill be useful for any university developing a fledgling high performance\ncomputing center. We focus on justification and cost model, strategies for\ndetermining anticipated use cases, planning appropriate resources, staffing,\nuser engagement, and metrics for gauging success.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 17:03:48 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 16:48:22 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["MacLachlan", "Glen", ""], ["Hurlburt", "Jason", ""], ["Suarez", "Marco", ""], ["Wong", "Kai Leung", ""], ["Burke", "William", ""], ["Lewis", "Terrence", ""], ["Gallo", "Andrew", ""], ["Flidr", "Jaroslav", ""], ["Gabiam", "Raoul", ""], ["Nicholas", "Janis", ""], ["Ensor", "Brian", ""]]}, {"id": "2003.13670", "submitter": "Mayank Varia", "authors": "Ran Canetti, Ari Trachtenberg, and Mayank Varia", "title": "Anonymous Collocation Discovery: Harnessing Privacy to Tame the\n  Coronavirus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Successful containment of the Coronavirus pandemic rests on the ability to\nquickly and reliably identify those who have been in close proximity to a\ncontagious individual. Existing tools for doing so rely on the collection of\nexact location information of individuals over lengthy time periods, and\ncombining this information with other personal information. This unprecedented\nencroachment on individual privacy at national scales has created an outcry and\nrisks rejection of these tools.\n  We propose an alternative: an extremely simple scheme for providing\nfine-grained and timely alerts to users who have been in the close vicinity of\nan infected individual. Crucially, this is done while preserving the anonymity\nof all individuals, and without collecting or storing any personal information\nor location history. Our approach is based on using short-range communication\nmechanisms, like Bluetooth, that are available in all modern cell phones. It\ncan be deployed with very little infrastructure, and incurs a relatively low\nfalse-positive rate compared to other collocation methods. We also describe a\nnumber of extensions and tradeoffs.\n  We believe that the privacy guarantees provided by the scheme will encourage\nquick and broad voluntary adoption. When combined with sufficient testing\ncapacity and existing best practices from healthcare professionals, we hope\nthat this may significantly reduce the infection rate.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 17:54:26 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 11:51:40 GMT"}, {"version": "v3", "created": "Wed, 1 Apr 2020 17:52:47 GMT"}, {"version": "v4", "created": "Fri, 3 Apr 2020 22:13:00 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Canetti", "Ran", ""], ["Trachtenberg", "Ari", ""], ["Varia", "Mayank", ""]]}, {"id": "2003.13762", "submitter": "Ashok Goel", "authors": "William Broniec, Sungeun An, Spencer Rugaber, Ashok K. Goel", "title": "Using VERA to explain the impact of social distancing on the spread of\n  COVID-19", "comments": "6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COVID-19 continues to spread across the country and around the world. Current\nstrategies for managing the spread of COVID-19 include social distancing. We\npresent VERA, an interactive AI tool, that first enables users to specify\nconceptual models of the impact of social distancing on the spread of COVID-19.\nThen, VERA automatically spawns agent-based simulations from the conceptual\nmodels, and, given a data set, automatically fills in the values of the\nsimulation parameters from the data. Next, the user can view the simulation\nresults, and, if needed, revise the simulation parameters and run another\nexperimental trial, or build an alternative conceptual model. We describe the\nuse VERA to develop a SIR model for the spread of COVID-19 and its relationship\nwith healthcare capacity.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 19:22:07 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Broniec", "William", ""], ["An", "Sungeun", ""], ["Rugaber", "Spencer", ""], ["Goel", "Ashok K.", ""]]}, {"id": "2003.13808", "submitter": "Riccardo Fogliato", "authors": "Riccardo Fogliato, Max G'Sell, Alexandra Chouldechova", "title": "Fairness Evaluation in Presence of Biased Noisy Labels", "comments": "Accepted at International Conference on Artificial Intelligence and\n  Statistics (AISTATS), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Risk assessment tools are widely used around the country to inform decision\nmaking within the criminal justice system. Recently, considerable attention has\nbeen devoted to the question of whether such tools may suffer from racial bias.\nIn this type of assessment, a fundamental issue is that the training and\nevaluation of the model is based on a variable (arrest) that may represent a\nnoisy version of an unobserved outcome of more central interest (offense). We\npropose a sensitivity analysis framework for assessing how assumptions on the\nnoise across groups affect the predictive bias properties of the risk\nassessment model as a predictor of reoffense. Our experimental results on two\nreal world criminal justice data sets demonstrate how even small biases in the\nobserved labels may call into question the conclusions of an analysis based on\nthe noisy outcome.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 20:47:00 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Fogliato", "Riccardo", ""], ["G'Sell", "Max", ""], ["Chouldechova", "Alexandra", ""]]}, {"id": "2003.13861", "submitter": "Toby Walsh", "authors": "Toby Walsh", "title": "A Pebble in the AI Race", "comments": "To appear in the Druk Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bhutan is sometimes described as \\a pebble between two boulders\", a small\ncountry caught between the two most populous nations on earth: India and China.\nThis pebble is, however, about to be caught up in a vortex: the transformation\nof our economic, political and social orders by new technologies like\nArtificial Intelligence. What can a small nation like Bhutan hope to do in the\nface of such change? What should the nation do, not just to weather this storm,\nbut to become a better place in which to live?\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 23:11:50 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Walsh", "Toby", ""]]}, {"id": "2003.14159", "submitter": "Bj\\\"orn Friedrich", "authors": "Bj\\\"orn Friedrich, J\\\"urgen Bauer, Andreas Hein", "title": "Detecting impending malnutrition of elderly people in domestic smart\n  home environments", "comments": "Insufficient quality", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proper nutrition is very important for the well-being and independence of\nelderly people. A significant loss of body weight or a decrease of the Body\nMass Index respectively is an indicator for malnutrition. A continuous\nmonitoring of the BMI enables doctors and nutritionists to intervene on\nimpending malnutrition. However, continuous monitoring of the BMI by\nprofessionals is not applicable and self-monitoring not reliable. In this\narticle a method for monitoring the trend of the BMI based on ambient sensors\nis introduced. The ambient sensors are used to measure the time a person spends\nfor preparing meals at home. When the trend of the average time for 4 weeks\nchanges, so does the trend of the BMI for those 4 weeks. Both values show a\nvery strong correlation. Thus, the average time for preparing a meal is a\nsuitable indicator for doctors and nutritionists to examine the patient\nfurther, become aware of an impending malnutrition, and intervene at an early\nstage of malnutrition. The method has been tested on a real-world dataset\ncollected during a 10-month field study with 20 participants of an age of about\n85 years.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 12:53:31 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 10:06:01 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Friedrich", "Bj\u00f6rn", ""], ["Bauer", "J\u00fcrgen", ""], ["Hein", "Andreas", ""]]}, {"id": "2003.14228", "submitter": "Michael Warren", "authors": "Michael S. Warren and Samuel W. Skillman", "title": "Mobility Changes in Response to COVID-19", "comments": "6 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In response to the COVID-19 pandemic, both voluntary changes in behavior and\nadministrative restrictions on human interactions have occurred. These actions\nare intended to reduce the transmission rate of the severe acute respiratory\nsyndrome coronavirus 2 (SARS-CoV-2). We use anonymized and/or de-identified\nmobile device locations to measure mobility, a statistic representing the\ndistance a typical member of a given population moves in a day. Results\nindicate that a large reduction in mobility has taken place, both in the US and\nglobally. In the United States, large mobility reductions have been detected\nassociated with the onset of the COVID-19 threat and specific government\ndirectives. Mobility data at the US admin1 (state) and admin2 (county) level\nhave been made freely available under a Creative Commons Attribution (CC BY\n4.0) license via the GitHub repository\nhttps://github.com/descarteslabs/DL-COVID-19/\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 14:03:30 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Warren", "Michael S.", ""], ["Skillman", "Samuel W.", ""]]}, {"id": "2003.14263", "submitter": "Paula Gordaliza", "authors": "Philippe Besse, Eustasio del Barrio, Paula Gordaliza, Jean-Michel\n  Loubes and Laurent Risser", "title": "A survey of bias in Machine Learning through the prism of Statistical\n  Parity for the Adult Data Set", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications based on Machine Learning models have now become an\nindispensable part of the everyday life and the professional world. A critical\nquestion then recently arised among the population: Do algorithmic decisions\nconvey any type of discrimination against specific groups of population or\nminorities? In this paper, we show the importance of understanding how a bias\ncan be introduced into automatic decisions. We first present a mathematical\nframework for the fair learning problem, specifically in the binary\nclassification setting. We then propose to quantify the presence of bias by\nusing the standard Disparate Impact index on the real and well-known Adult\nincome data set. Finally, we check the performance of different approaches\naiming to reduce the bias in binary classification outcomes. Importantly, we\nshow that some intuitive methods are ineffective. This sheds light on the fact\ntrying to make fair machine learning models may be a particularly challenging\ntask, in particular when the training observations contain a bias.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 14:48:36 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 11:16:10 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Besse", "Philippe", ""], ["del Barrio", "Eustasio", ""], ["Gordaliza", "Paula", ""], ["Loubes", "Jean-Michel", ""], ["Risser", "Laurent", ""]]}, {"id": "2003.14370", "submitter": "Laura Alessandretti", "authors": "Ulf Aslak, Laura Alessandretti", "title": "Infostop: Scalable stop-location detection in multi-user mobility data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data-driven research in mobility has prospered in recent years, providing\nsolutions to real-world challenges including forecasting epidemics and planning\ntransportation. These advancements were facilitated by computational tools\nenabling the analysis of large-scale data-sets of digital traces. One of the\nchallenges when pre-processing spatial trajectories is the so-called stop\nlocation detection, that entails the reduction of raw time series to sequences\nof destinations where an individual was stationary. The most widely adopted\nsolution to this problem was proposed by Hariharan and Toyama (2004) and\ninvolves filtering out non-stationary measurements, then applying agglomerative\nclustering on the stationary points. This state-of-the-art solution, however,\nsuffers of two limitations: (i) frequently visited places located very close\n(such as adjacent buildings) are likely to be merged into a unique location,\ndue to inherent measurement noise, (ii) traces for multiple users can not be\nanalysed simultaneously, thus the definition of destination is not shared\nacross users. In this paper, we describe the Infostop algorithm that overcomes\nthe limitations of the state-of-the-art solution by leveraging the flow-based\nnetwork community detection algorithm Infomap. We test Infostop for a\npopulation of $\\sim 1000$ individuals with highly overlapping mobility. We show\nthat the size of locations detected by Infostop saturates for increasing number\nof users and that time complexity grows slower than for previous solutions. We\ndemonstrate that Infostop can be used to easily infer social meetings. Finally,\nwe provide an open-source implementation of Infostop, written in Python and\nC++, that has a simple API and can be used both for labeling time-ordered\ncoordinate sequences (GPS or otherwise), and unordered sets of spatial points.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 17:02:19 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Aslak", "Ulf", ""], ["Alessandretti", "Laura", ""]]}, {"id": "2003.14412", "submitter": "Michiel Bakker", "authors": "Alex Berke, Michiel Bakker, Praneeth Vepakomma, Kent Larson, Alex\n  'Sandy' Pentland", "title": "Assessing Disease Exposure Risk with Location Data: A Proposal for\n  Cryptographic Preservation of Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Governments and researchers around the world are implementing digital contact\ntracing solutions to stem the spread of infectious disease, namely COVID-19.\nMany of these solutions threaten individual rights and privacy. Our goal is to\nbreak past the false dichotomy of effective versus privacy-preserving contact\ntracing. We offer an alternative approach to assess and communicate users' risk\nof exposure to an infectious disease while preserving individual privacy. Our\nproposal uses recent GPS location histories, which are transformed and\nencrypted, and a private set intersection protocol to interface with a\nsemi-trusted authority.\n  There have been other recent proposals for privacy-preserving contact\ntracing, based on Bluetooth and decentralization, that could further eliminate\nthe need for trust in authority. However, solutions with Bluetooth are\ncurrently limited to certain devices and contexts while decentralization adds\ncomplexity. The goal of this work is two-fold: we aim to propose a\nlocation-based system that is more privacy-preserving than what is currently\nbeing adopted by governments around the world, and that is also practical to\nimplement with the immediacy needed to stem a viral outbreak.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 17:56:30 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 17:38:06 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Berke", "Alex", ""], ["Bakker", "Michiel", ""], ["Vepakomma", "Praneeth", ""], ["Larson", "Kent", ""], ["Pentland", "Alex 'Sandy'", ""]]}]