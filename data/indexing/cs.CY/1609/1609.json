[{"id": "1609.00627", "submitter": "Admela Jukan", "authors": "Admela Jukan, Xavi Masip-Bruin, Nina Amla", "title": "Smart Computing and Sensing Technologies for Animal Welfare: A\n  Systematic Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Animals play a profoundly important and intricate role in our lives today.\nDogs have been human companions for thousands of years, but they now work\nclosely with us to assist the disabled, and in combat and search and rescue\nsituations. Farm animals are a critical part of the global food supply chain,\nand there is increasing consumer interest in organically fed and humanely\nraised livestock, and how it impacts our health and environmental footprint.\nWild animals are threatened with extinction by human induced factors, and\nshrinking and compromised habitat. This review sets the goal to systematically\nsurvey the existing literature in smart computing and sensing technologies for\ndomestic, farm and wild animal welfare. We use the notion of \\emph{animal\nwelfare} in broad terms, to review the technologies for assessing whether\nanimals are healthy, free of pain and suffering, and also positively stimulated\nin their environment. Also the notion of \\emph{smart computing and sensing} is\nused in broad terms, to refer to computing and sensing systems that are not\nisolated but interconnected with communication networks, and capable of remote\ndata collection, processing, exchange and analysis. We review smart\ntechnologies for domestic animals, indoor and outdoor animal farming, as well\nas animals in the wild and zoos. The findings of this review are expected to\nmotivate future research and contribute to data, information and communication\nmanagement as well as policy for animal welfare.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2016 13:32:37 GMT"}], "update_date": "2016-09-05", "authors_parsed": [["Jukan", "Admela", ""], ["Masip-Bruin", "Xavi", ""], ["Amla", "Nina", ""]]}, {"id": "1609.00990", "submitter": "Nhien-An Le-Khac", "authors": "Nhien-An Le-Khac, Sammer Markos, Tahar Kechadi", "title": "A data mining-based solution for detecting suspicious money laundering\n  cases in an investment bank", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, money laundering poses a serious threat not only to financial\ninstitutions but also to the nation. This criminal activity is becoming more\nand more sophisticated and seems to have moved from the clichy of drug\ntrafficking to financing terrorism and surely not forgetting personal gain.\nMost international financial institutions have been implementing anti-money\nlaundering solutions to fight investment fraud. However, traditional\ninvestigative techniques consume numerous man-hours. Recently, data mining\napproaches have been developed and are considered as well-suited techniques for\ndetecting money laundering activities. Within the scope of a collaboration\nproject for the purpose of developing a new solution for the anti-money\nlaundering Units in an international investment bank, we proposed a simple and\nefficient data mining-based solution for anti-money laundering. In this paper,\nwe present this solution developed as a tool and show some preliminary\nexperiment results with real transaction datasets.\n", "versions": [{"version": "v1", "created": "Sun, 4 Sep 2016 21:03:32 GMT"}], "update_date": "2016-09-06", "authors_parsed": [["Le-Khac", "Nhien-An", ""], ["Markos", "Sammer", ""], ["Kechadi", "Tahar", ""]]}, {"id": "1609.00992", "submitter": "Nhien-An Le-Khac", "authors": "Maarten Banerveld, Nhien-An Le-Khac, Tahar Kechadi", "title": "Performance Evaluation of a Natural Language Processing approach applied\n  in White Collar crime investigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In today world we are confronted with increasing amounts of information every\nday coming from a large variety of sources. People and co-operations are\nproducing data on a large scale, and since the rise of the internet, e-mail and\nsocial media the amount of produced data has grown exponentially. From a law\nenforcement perspective we have to deal with these huge amounts of data when a\ncriminal investigation is launched against an individual or company. Relevant\nquestions need to be answered like who committed the crime, who were involved,\nwhat happened and on what time, who were communicating and about what? Not only\nthe amount of available data to investigate has increased enormously, but also\nthe complexity of this data has increased. When these communication patterns\nneed to be combined with for instance a seized financial administration or\ncorporate document shares a complex investigation problem arises. Recently,\ncriminal investigators face a huge challenge when evidence of a crime needs to\nbe found in the Big Data environment where they have to deal with large and\ncomplex datasets especially in financial and fraud investigations. To tackle\nthis problem, a financial and fraud investigation unit of a European country\nhas developed a new tool named LES that uses Natural Language Processing (NLP)\ntechniques to help criminal investigators handle large amounts of textual\ninformation in a more efficient and faster way. In this paper, we present\nbriefly this tool and we focus on the evaluation its performance in terms of\nthe requirements of forensic investigation: speed, smarter and easier for\ninvestigators. In order to evaluate this LES tool, we use different performance\nmetrics. We also show experimental results of our evaluation with large and\ncomplex datasets from real-world application.\n", "versions": [{"version": "v1", "created": "Sun, 4 Sep 2016 21:23:22 GMT"}], "update_date": "2016-09-06", "authors_parsed": [["Banerveld", "Maarten", ""], ["Le-Khac", "Nhien-An", ""], ["Kechadi", "Tahar", ""]]}, {"id": "1609.01131", "submitter": "Jorge Luis Rivero Jlrivero", "authors": "Jorge Luis Rivero P\\'erez, Yaimara Pe\\~nate Santana, Pedro Harenton\n  Mart\\'inez L\\'opez", "title": "Proposal of Data Processing Platform for Direct Marketing Data", "comments": "in Spanish", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data mining has been widely used to identify potential customers for a new\nproduct or service. In this article is done a study of previous work relating\nto the application of data mining methodologies for software projects,\nspecifically for direct marketing projects. Several data sets of demographic\nand historical customer purchases data available for evaluation of algorithms\nin this area, some of them very new and current are described. The main\ncontribution of this paper is the proposal of a platform for distributed data\nstream processing for the processes of targeting customers and building\npredictive models required response; thus facilitating several of the\nfunctional requirements for development environments.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2016 12:31:58 GMT"}], "update_date": "2016-09-06", "authors_parsed": [["P\u00e9rez", "Jorge Luis Rivero", ""], ["Santana", "Yaimara Pe\u00f1ate", ""], ["L\u00f3pez", "Pedro Harenton Mart\u00ednez", ""]]}, {"id": "1609.01186", "submitter": "Joaquin Torr\\'e Zaffaroni", "authors": "Camilo Melani, Juan V. Echag\\\"ue, Joaqu\\'in Torre Zaffaroni, Daniel\n  Yankelevich", "title": "Un caso de big data punta a punta: an\\'alisis de datos de transporte y\n  su uso en el negocio", "comments": "3 pages, in Spanish, 1 figure in Proceedings de AGRANDA 2015,\n  Rosario, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we present the results of a data analysis project for a\npublic-transport company. This project encompassed data preparation, analysis\nand visualization of three years of historical data. The data consisted in\nticket purchases and GPS location of the vehicles. This work describes the\nproject from start to end, including the incorporation of the results in the\nbusiness process.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2016 14:55:03 GMT"}], "update_date": "2016-09-06", "authors_parsed": [["Melani", "Camilo", ""], ["Echag\u00fce", "Juan V.", ""], ["Zaffaroni", "Joaqu\u00edn Torre", ""], ["Yankelevich", "Daniel", ""]]}, {"id": "1609.01187", "submitter": "Joaquin Torr\\'e Zaffaroni", "authors": "Camilo Melani, Joaqu\\'in Torr\\'e Zaffaroni, Alejandro Hernandez, Juan\n  Echag\\\"ue", "title": "An\\'alisis de resultados electorales: comparaci\\'on de m\\'etodos y\n  estimaci\\'on de votos por franja etaria", "comments": "6 pages, in Spanish, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The State and its citizens generate lots of data. Once stored and processed,\ndata can help resolve questions in Social Sciences, where it is common to need\ndata in a different level of aggregation than the data is presented. In\nelection results, we would like to understand the decision of each voter or\ngroup of voters, but the data is only available at the polling-place level.\nThis problem is known as ecological inference. In this work we compare two\nmethods to estimate the share of votes for each party according to different\nage groups. This work is complemented with the analysis of votes between the\nfirst and second rounds, as well as a referendum during the first. This\nanalysis was performed on the 2014 uruguayan presidential elections.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2016 14:55:15 GMT"}], "update_date": "2016-09-06", "authors_parsed": [["Melani", "Camilo", ""], ["Zaffaroni", "Joaqu\u00edn Torr\u00e9", ""], ["Hernandez", "Alejandro", ""], ["Echag\u00fce", "Juan", ""]]}, {"id": "1609.01409", "submitter": "M.M.A. Hashem", "authors": "Md. Siddiqur Rahman Tanveer, M.M.A. Hashem, Md. Kowsar Hossain", "title": "Android Assistant EyeMate for Blind and Blind Tracker", "comments": "arXiv admin note: text overlap with arXiv:1611.09480 by other author", "journal-ref": "2015 18th International Conference on Computer and Information\n  Technology (ICCIT)", "doi": "10.1109/ICCITechn.2015.7488080", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At present many blind assistive systems have been implemented but there is no\nsuch kind of good system to navigate a blind person and also to track the\nmovement of a blind person and rescue him/her if he/she is lost. In this paper,\nwe have presented a blind assistive and tracking embedded system. In this\nsystem the blind person is navigated through a spectacle interfaced with an\nandroid application. The blind person is guided through Bengali/English voice\ncommands generated by the application according to the obstacle position. Using\nvoice command a blind person can establish voice call to a predefined number\nwithout touching the phone just by pressing the headset button. The blind\nassistive application gets the latitude and longitude using GPS and then sends\nthem to a server. The movement of the blind person is tracked through another\nandroid application that points out the current position in Google map. We took\ndistances from several surfaces like concrete and tiles floor in our experiment\nwhere the error rate is 5%.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 06:29:32 GMT"}], "update_date": "2016-12-04", "authors_parsed": [["Tanveer", "Md. Siddiqur Rahman", ""], ["Hashem", "M. M. A.", ""], ["Hossain", "Md. Kowsar", ""]]}, {"id": "1609.01464", "submitter": "Kardi Teknomo", "authors": "Jacob Chan, Kardi Teknomo", "title": "Hub Identification of the Metro Manila Road Network Using PageRank", "comments": "10 pages, Chan, J. and Teknomo, K. (2015) Hub Identification of the\n  Metro Manila Road Network Using PageRank, Proceedings of the 8th ATRANS\n  Symposium Young Researcher's Forum, August 21, 2015, Bangkok, Thailand", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We attempt to identify the different node hubs of a road network using\nPageRank for preparation for possible random terrorist attacks. The robustness\nof a road network against such attack is crucial to be studied because it may\ncripple its connectivity by simply shutting down these hubs. We show the\nimportant hubs in a road network based on network structure and propose a model\nfor robustness analysis. By identifying important hubs in a road network,\npossible preparation schemes may be done earlier to mitigate random terrorist\nattacks, including defense reinforcement and transportation security. A case\nstudy of the Metro Manila road network is also presented. The case study shows\nthat the most important hubs in the Metro Manila road network are near\nairports, piers, major highways and expressways\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 09:58:03 GMT"}], "update_date": "2016-09-07", "authors_parsed": [["Chan", "Jacob", ""], ["Teknomo", "Kardi", ""]]}, {"id": "1609.01472", "submitter": "Kardi Teknomo", "authors": "Chelcie Narboneta and Kardi Teknomo", "title": "OpenTripPlanner, OpenStreetMap, General Transit Feed Specification:\n  Tools for Disaster Relief and Recovery", "comments": "6 pages, Narboneta, C. G. and Teknomo, K. (2014) OpenTripPlanner,\n  OpenStreetMap, General Transit Feed Specification: Tools for Disaster Relief\n  and Recovery, Proceeding of the 7th IEEE International Conference Humanoid,\n  Nanotechnology, Information Technology Communication and Control, Environment\n  and Management (HNICEM) 12-16 November 2014 Hotel Centro, Puerto Princesa,\n  Palawan, Philippines", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open Trip Planner was identified as the most promising open source\nmulti-modal trip planning software. Open Street Map, which provides mapping\ndata to Open Trip Planner, is one of the most well-known open source\ninternational repository of geographic data. General Transit Feed\nSpecification, which provides transportation data to Open Trip Planner, has\nbeen the standard for describing transit systems and platform for numerous\napplications. Together, when used to implement an instance of Open Trip\nPlanner, these software has been helping in traffic decongestion all over the\nworld by assisting commuters to shift from using private transportation modes\nto public ones. Their potential however goes beyond providing multi-modal\npublic transportation routes. This paper aims to first discuss the researchers'\nexperience in implementing a public transportation route planner for the\npurpose of traffic decongestion.The researchers would examine the prospective\nof using the system for disaster preparedness and recovery and concrete ways on\nhow to realize them.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 10:11:27 GMT"}], "update_date": "2016-09-07", "authors_parsed": [["Narboneta", "Chelcie", ""], ["Teknomo", "Kardi", ""]]}, {"id": "1609.01475", "submitter": "Kardi Teknomo", "authors": "Allan Lao and Kardi Teknomo", "title": "Multi Exit Configuration of Mesoscopic Pedestrian Simulation", "comments": "7 pages, Lao, A. and Teknomo, K. (2014) Multi Exit Configuration of\n  Mesoscopic Pedestrian Simulation, Proceeding of the 12th National Conference\n  in Information Technology Education (NCITE 2014), October 23 - 25, 2014,\n  Boracay, Philippines", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A mesoscopic approach to modeling pedestrian simulation with multiple exits\nis proposed in this paper. A floor field based on Qlearning Algorithm is used.\nAttractiveness of exits to pedestrian typically is based on shortest path.\nHowever, several factors may influence pedestrian choice of exits. Scenarios\nwith multiple exits are presented and effect of Q-learning rewards system on\nnavigation is investigated\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 10:18:25 GMT"}], "update_date": "2016-09-07", "authors_parsed": [["Lao", "Allan", ""], ["Teknomo", "Kardi", ""]]}, {"id": "1609.01580", "submitter": "Siddhartha Jonnalagadda", "authors": "Shu Dong, R Kannan Mutharasan, Siddhartha Jonnalagadda", "title": "Using Natural Language Processing to Screen Patients with Active Heart\n  Failure: An Exploration for Hospital-wide Surveillance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we proposed two different approaches, a rule-based approach\nand a machine-learning based approach, to identify active heart failure cases\nautomatically by analyzing electronic health records (EHR). For the rule-based\napproach, we extracted cardiovascular data elements from clinical notes and\nmatched patients to different colors according their heart failure condition by\nusing rules provided by experts in heart failure. It achieved 69.4% accuracy\nand 0.729 F1-Score. For the machine learning approach, with bigram of clinical\nnotes as features, we tried four different models while SVM with linear kernel\nachieved the best performance with 87.5% accuracy and 0.86 F1-Score. Also, from\nthe classification comparison between the four different models, we believe\nthat linear models fit better for this problem. Once we combine the\nmachine-learning and rule-based algorithms, we will enable hospital-wide\nsurveillance of active heart failure through increased accuracy and\ninterpretability of the outputs.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 14:46:41 GMT"}], "update_date": "2016-09-07", "authors_parsed": [["Dong", "Shu", ""], ["Mutharasan", "R Kannan", ""], ["Jonnalagadda", "Siddhartha", ""]]}, {"id": "1609.01592", "submitter": "Siddhartha Jonnalagadda", "authors": "Ravi P Garg, Kalpana Raja, Siddhartha R Jonnalagadda", "title": "CRTS: A type system for representing clinical recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Clinical guidelines and recommendations are the driving wheels of\nthe evidence-based medicine (EBM) paradigm, but these are available primarily\nas unstructured text and are generally highly heterogeneous in nature. This\nsignificantly reduces the dissemination and automatic application of these\nrecommendations at the point of care. A comprehensive structured representation\nof these recommendations is highly beneficial in this regard. Objective: The\nobjective of this paper to present Clinical Recommendation Type System (CRTS),\na common type system that can effectively represent a clinical recommendation\nin a structured form. Methods: CRTS is built by analyzing 125 recommendations\nand 195 research articles corresponding to 6 different diseases available from\nUpToDate, a publicly available clinical knowledge system, and from the National\nGuideline Clearinghouse, a public resource for evidence-based clinical practice\nguidelines. Results: We show that CRTS not only covers the recommendations but\nalso is flexible to be extended to represent information from primary\nliterature. We also describe how our developed type system can be applied for\nclinical decision support, medical knowledge summarization, and citation\nretrieval. Conclusion: We showed that our proposed type system is precise and\ncomprehensive in representing a large sample of recommendations available for\nvarious disorders. CRTS can now be used to build interoperable information\nextraction systems that automatically extract clinical recommendations and\nrelated data elements from clinical evidence resources, guidelines, systematic\nreviews and primary publications.\n  Keywords: guidelines and recommendations, type system, clinical decision\nsupport, evidence-based medicine, information storage and retrieval\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 15:02:03 GMT"}], "update_date": "2016-09-07", "authors_parsed": [["Garg", "Ravi P", ""], ["Raja", "Kalpana", ""], ["Jonnalagadda", "Siddhartha R", ""]]}, {"id": "1609.01594", "submitter": "Siddhartha Jonnalagadda", "authors": "Abhishek Kalyan Adupa, Ravi Prakash Garg, Jessica Corona-Cox, Sanjiv.\n  J. Shah, Siddhartha R. Jonnalagadda", "title": "An Information Extraction Approach to Prescreen Heart Failure Patients\n  for Clinical Trials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To reduce the large amount of time spent screening, identifying, and\nrecruiting patients into clinical trials, we need prescreening systems that are\nable to automate the data extraction and decision-making tasks that are\ntypically relegated to clinical research study coordinators. However, a major\nobstacle is the vast amount of patient data available as unstructured free-form\ntext in electronic health records. Here we propose an information\nextraction-based approach that first automatically converts unstructured text\ninto a structured form. The structured data are then compared against a list of\neligibility criteria using a rule-based system to determine which patients\nqualify for enrollment in a heart failure clinical trial. We show that we can\nachieve highly accurate results, with recall and precision values of 0.95 and\n0.86, respectively. Our system allowed us to significantly reduce the time\nneeded for prescreening patients from a few weeks to a few minutes. Our\nopen-source information extraction modules are available for researchers and\ncould be tested and validated in other cardiovascular trials. An approach such\nas the one we demonstrate here may decrease costs and expedite clinical trials,\nand could enhance the reproducibility of trials across institutions and\npopulations.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 15:05:25 GMT"}], "update_date": "2016-09-07", "authors_parsed": [["Adupa", "Abhishek Kalyan", ""], ["Garg", "Ravi Prakash", ""], ["Corona-Cox", "Jessica", ""], ["Shah", "Sanjiv. J.", ""], ["Jonnalagadda", "Siddhartha R.", ""]]}, {"id": "1609.01710", "submitter": "Kardi Teknomo", "authors": "Saman Saadat and Kardi Teknomo", "title": "Automation of Pedestrian Tracking in a Crowded Situation", "comments": "10 Pages, Saadat, S., and Teknomo, K., Automation of Pedestrian\n  Tracking in a Crowded Situation, the Fifth International Conference on\n  Pedestrian and Evacuation Dynamics, March 8-10, 2010, National Institute of\n  Standards and Technology, Gaithersburg, MD USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studies on microscopic pedestrian requires large amounts of trajectory data\nfrom real-world pedestrian crowds. Such data collection, if done manually,\nneeds tremendous effort and is very time consuming. Though many studies have\nasserted the possibility of automating this task using video cameras, we found\nthat only a few have demonstrated good performance in very crowded situations\nor from a top-angled view scene. This paper deals with tracking pedestrian\ncrowd under heavy occlusions from an angular scene. Our automated tracking\nsystem consists of two modules that perform sequentially. The first module\ndetects moving objects as blobs. The second module is a tracking system. We\nemploy probability distribution from the detection of each pedestrian and use\nBayesian update to track the next position. The result of such tracking is a\ndatabase of pedestrian trajectories over time and space. With certain prior\ninformation, we showed that the system can track a large number of people under\nocclusion and clutter scene.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 10:36:23 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Saadat", "Saman", ""], ["Teknomo", "Kardi", ""]]}, {"id": "1609.01778", "submitter": "Abdullah Almaatouq", "authors": "Abdullah Almaatouq, Francisco Prieto-Castrillo, Alex Pentland", "title": "Mobile Communication Signatures of Unemployment", "comments": null, "journal-ref": "Social Informatics. SocInfo 2016. Lecture Notes in Computer\n  Science, vol 10046. Springer, Cham", "doi": "10.1007/978-3-319-47880-7_25", "report-no": null, "categories": "cs.SI cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mapping of populations socio-economic well-being is highly constrained by\nthe logistics of censuses and surveys. Consequently, spatially detailed changes\nacross scales of days, weeks, or months, or even year to year, are difficult to\nassess; thus the speed of which policies can be designed and evaluated is\nlimited. However, recent studies have shown the value of mobile phone data as\nan enabling methodology for demographic modeling and measurement. In this work,\nwe investigate whether indicators extracted from mobile phone usage can reveal\ninformation about the socio-economical status of microregions such as districts\n(i.e., average spatial resolution < 2.7km). For this we examine anonymized\nmobile phone metadata combined with beneficiaries records from unemployment\nbenefit program. We find that aggregated activity, social, and mobility\npatterns strongly correlate with unemployment. Furthermore, we construct a\nsimple model to produce accurate reconstruction of district level unemployment\nfrom their mobile communication patterns alone. Our results suggest that\nreliable and cost-effective economical indicators could be built based on\npassively collected and anonymized mobile phone data. With similar data being\ncollected every day by telecommunication services across the world,\nsurvey-based methods of measuring community socioeconomic status could\npotentially be augmented or replaced by such passive sensing methods in the\nfuture.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 22:27:26 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Almaatouq", "Abdullah", ""], ["Prieto-Castrillo", "Francisco", ""], ["Pentland", "Alex", ""]]}, {"id": "1609.01810", "submitter": "Kardi Teknomo", "authors": "Kardi Teknomo, Yasushi Takeyama, Hajime Inamura", "title": "Tracking System to Automate Data Collection of Microscopic Pedestrian\n  Traffic Flow", "comments": "15 pages, Teknomo, Kardi; Takeyama, Yasushi; Inamura, Hajime,\n  Tracking System to Automate Data Collection of Microscopic Pedestrian Traffic\n  Flow, Proceeding of The 4th Eastern Asia Society For Transportation Studies,\n  Hanoi, Vietnam, pp. 11-25, Oct. 2001", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To deal with many pedestrian data, automatic data collection is needed. This\npaper describes how to automate the microscopic pedestrian flow data collection\nfrom video files. The study is restricted only to pedestrians without\nconsidering vehicular - pedestrian interaction. Pedestrian tracking system\nconsists of three sub-systems, which calculates the image processing, object\ntracking and traffic flow variables. The system receives input of stacks of\nimages and parameters. The first sub-system performs Image Processing analysis\nwhile the second sub-system carries out the tracking of pedestrians by matching\nthe features and tracing the pedestrian numbers frame by frame. The last\nsub-system deals with a NTXY database to calculate the pedestrian traffic-flow\ncharacteristic such as flow rate, speed and area module. Comparison with manual\ndata collection method confirmed that the procedures described have significant\npotential to automate the data collection of both microscopic and macroscopic\npedestrian flow variables.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2016 02:58:43 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Teknomo", "Kardi", ""], ["Takeyama", "Yasushi", ""], ["Inamura", "Hajime", ""]]}, {"id": "1609.01822", "submitter": "Ezer Yeboah-Boateng", "authors": "Ezer Osei Yeboah-Boateng and Akosua Boakyewaa Appiah-Nketiah", "title": "Multi-Tenancy Issues with Service Delivery in Developing Economies:\n  Privacy, Trust and Availability Concerns", "comments": null, "journal-ref": "International Journal of Computer Applications (IJCA), Vol. 5, No.\n  6, pp.82 - 94, September - October, 2015", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing is a new paradigm and innovation in the technology service\ndelivery. It is utilized for IT-enabled value creation. The capex-free nature\nof cloud service delivery renders it very attractive to many SMEs. But it is\nsaddled with multi-tenancy issues; prominent under this study are concerns of\nprivacy, trust and availability. How do end-users trust providers with their\nsensitive data? How secured and confidential are their corporate assets? Amidst\nthe perennial power outages (a.k.a. Dumsor), what is the acceptable available\nuptime? We sampled and interviewed cloud service providers (CSPs) as well as\nend-users in Ghana, a developing economy. We also gleaned through some\nsecondary data to ascertain some operational concerns. The results indicate\nthat security and service level agreements (SLAs) are key concerns in respect\nof privacy and trust issues. Similarly, perennial power outages and security\nwere key availability concerns. This was expected as end-users use cloud\nservices for mission critical information assets, and so requires high\navailability. The implications are that the cyber-security concerns ought to be\naddressed if SMEs in developing economies are to adopt and accept cloud\ncomputing resources for IT-enabled competitive advantage.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2016 23:58:17 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Yeboah-Boateng", "Ezer Osei", ""], ["Appiah-Nketiah", "Akosua Boakyewaa", ""]]}, {"id": "1609.01823", "submitter": "Ezer Yeboah-Boateng", "authors": "Edward Ayebeng Botchway, Ezer Osei Yeboah-Boateng, and Titus Ebenezer\n  Kwofie", "title": "Challenges to Integration of Information Technology in Physical\n  Infrastructure Development Processes at the Local Government Level", "comments": "14 pages, 5 figures, 13 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ghana's Decentralization Policy has made significant contribution in\ninfrastructural implementation and delivery through Metropolitan, Municipal and\nDistrict Assemblies as an alternative development strategy to ensure the\nimplementation of the overall national agenda. To date, many systems and\nstrategies have been implemented towards improving development of\ninfrastructure at the local government level. Given that initiation and\nimplementation of infrastructural development at the local level involves the\nmulti-institutional participation of various stakeholders in local governance\nfor effective monitoring and development, several governance forms including\ne-governance have been initiated towards improvement and effective management\nof the assemblies. E-Governance through the use of relevant Information and\nCommunication Technology has been implemented through the Government Policy on\nInformation and Communications Technology for Accelerated Development as a\ncatalyst to facilitate the cross-sectoral participation in the implementation\nof infrastructural development. Unfortunately, to date, the ICT4AD does not\nappear to be successfully on course having been in existence for over a decade.\nSimilarly, the development and monitoring of the physical infrastructure at the\nlocal level continue to suffer several setbacks and it is currently clearly\nevident that a refined system of best practices must be put in place to\nsimplify and harmonize the entire development process. This paper is aimed at\nthe assessment of the challenges of e-governance in infrastructural development\nat the local government level in Ghana. Using a mixed approach with purposive\nsampling, data gathered from the MMDAs in Ashanti Region suggest that the\nentire programme has been very slow; bedeviled with lack of funding and\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2015 23:49:30 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Botchway", "Edward Ayebeng", ""], ["Yeboah-Boateng", "Ezer Osei", ""], ["Kwofie", "Titus Ebenezer", ""]]}, {"id": "1609.01986", "submitter": "Reza Farrahi Moghaddam", "authors": "Reza Farrahi Moghaddam and Yves Lemieux and Mohamed Cheriet", "title": "FairGA: Fair Genetic Algorithm - Beyond Resource-oriented Sustainability\n  for ICT Products and Services", "comments": "6 pages, 3 figures, 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity of ICT products and services has brought them to the level of\ndisposable `species'. The combination of the race to optimal performance and\ndisposability has resulted in considerable footprint and impact. Although\napproaches such as increasing efficiency, reducing the total cost of ownership,\nlife cycle assessment and management, and circular economy have been put\nforward to manage and reduce the footprint and impact, the complexity of\nprocesses involved and especially invisibility of key but unobservable\nprocesses has resulted in some lower bounds for minimal achievable footprint.\nIn this work, a modified approach to the Genetic Algorithm is proposed in order\nto introduce the notion of 'nondisposability' to the ICT products and services\nin order to implicitly influence and manage unobservable processes, and\nultimately reduce the overall footprint and resource consumption. The proposed\ngenetic algorithm is called FairGA, and it is compared with the traditional\nGenetic Algorithm against standard optimization functions. Also, the impact of\nthe FairGA on the resource extraction has been illustrated with promising\nresults.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2016 14:00:06 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Moghaddam", "Reza Farrahi", ""], ["Lemieux", "Yves", ""], ["Cheriet", "Mohamed", ""]]}, {"id": "1609.01996", "submitter": "Harsh Gupta", "authors": "Harsh Gupta", "title": "(Lack Of) Representation of Non Western World in process of creation of\n  Web standards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  World Wide Consortium (W3C) as an standard setting organization for the world\nwide web plays a very important role in shaping the web. We focus on the\nongoing controversy related to Encrypted Media Extensions (EME) and found that\nthere was a serious lack of participation from people from non western\ncountries. We also found serious lack of gender diversity in the EME debate.\n", "versions": [{"version": "v1", "created": "Mon, 29 Aug 2016 10:27:31 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Gupta", "Harsh", ""]]}, {"id": "1609.02000", "submitter": "Carlos Gershenson", "authors": "Carlos Gershenson, Paolo Santi, and Carlo Ratti", "title": "Cybernetic Cities: Designing and controlling adaptive and robust urban\n  systems", "comments": "To be published in \"Handbook on Complexity and Cities\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.AO cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cities are changing constantly. All urban systems face different conditions\nfrom day to day. Even when averaged regularities can be found, urban systems\nwill be more efficient if they can adapt to changes at the same temporal scales\nat which these occur. Still, the functionality of urban systems must be robust\nto changes, either caused by adaptation or by other factors. Technology can\nassist humans in designing and regulating this adaptation and robustness. To\nachieve this, we propose a description of cities as cybernetic systems. We\nidentify three main components: information, algorithms, and agents, which we\nillustrate with current and future examples. The implications of cybernetic\ncities are manifold, with direct impacts on mobility, sustainability,\nresilience, governance, and society. Still, the potential of a cybernetic\nperspective on cities will not depend so much on technology as on how we use\nit.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2016 14:38:46 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 20:21:47 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Gershenson", "Carlos", ""], ["Santi", "Paolo", ""], ["Ratti", "Carlo", ""]]}, {"id": "1609.02009", "submitter": "Telmo Menezes", "authors": "Telmo Menezes", "title": "Non-Evolutionary Superintelligences Do Nothing, Eventually", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is overwhelming evidence that human intelligence is a product of\nDarwinian evolution. Investigating the consequences of self-modification, and\nmore precisely, the consequences of utility function self-modification, leads\nto the stronger claim that not only human, but any form of intelligence is\nultimately only possible within evolutionary processes. Human-designed\nartificial intelligences can only remain stable until they discover how to\nmanipulate their own utility function. By definition, a human designer cannot\nprevent a superhuman intelligence from modifying itself, even if protection\nmechanisms against this action are put in place. Without evolutionary pressure,\nsufficiently advanced artificial intelligences become inert by simplifying\ntheir own utility function. Within evolutionary processes, the implicit utility\nfunction is always reducible to persistence, and the control of superhuman\nintelligences embedded in evolutionary processes is not possible. Mechanisms\nagainst utility function self-modification are ultimately futile. Instead,\nscientific effort toward the mitigation of existential risks from the\ndevelopment of superintelligences should be in two directions: understanding\nconsciousness, and the complex dynamics of evolutionary systems.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2016 15:06:18 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Menezes", "Telmo", ""]]}, {"id": "1609.02137", "submitter": "Kardi Teknomo", "authors": "Kardi Teknomo, Yasushi Takeyama and Hajime Inamura", "title": "Tracking Algorithm for Microscopic Flow Data Collection", "comments": "2 pages, Teknomo, Kardi; Takeyama, Yasushi; Inamura, Hajime, Tracking\n  Algorithm for Microscopic Flow Data Collection, Proceeding of JSCE\n  Conference, Sendai, Japan Sept 2000", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various methods to automate traffic data collection have recently been\ndeveloped by many researchers. A macroscopic data collection through image\nprocessing has been proposed. For microscopic traffic flow data, such as\nindividual speed and time or distance headway, tracking of individual movement\nis needed. The tracking algorithms for pedestrian or vehicle have been\ndeveloped to trace the movement of one or two pedestrians based on sign\npattern, and feature detection. No research has been done to track many\npedestrians or vehicles at once. This paper describes a new and fast algorithm\nto track the movement of many individual vehicles or pedestrians\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2016 02:27:52 GMT"}], "update_date": "2016-09-09", "authors_parsed": [["Teknomo", "Kardi", ""], ["Takeyama", "Yasushi", ""], ["Inamura", "Hajime", ""]]}, {"id": "1609.02243", "submitter": "Kardi Teknomo", "authors": "Kardi Teknomo, Yasushi Takeyama, Hajime Inamura", "title": "Determination of Pedestrian Flow Performance Based on Video Tracking and\n  Microscopic Simulations", "comments": "4 pages, Teknomo, Kardi; Takeyama, Yasushi; Inamura, Hajime,\n  Determination of Pedestrian Flow Performance Based on Video Tracking and\n  Microscopic Simulations, Proceedings of Infrastructure Planning Conference\n  Vol. 23 no 1, Ashikaga, Japan, pp. 639-642, Nov 2000", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the objectives of understanding pedestrian behavior is to predict the\neffect of proposed changes in the design or evaluation of pedestrian\nfacilities. We want to know the impact to the user of the facilities, as the\ndesign of the facilities change. That impact was traditionally evaluated by\nlevel of service standards. Another design criterion to measure the impact of\ndesign change is measured by the pedestrian flow performance index. This paper\ndescribes the determination of pedestrian flow performance based video tracking\nor any microscopic pedestrian simulation models. Most of pedestrian researches\nhave been done on a macroscopic level, which is an aggregation of all\npedestrian movement in pedestrian areas into flow, average speed and area\nmodule. Macroscopic level, however, does not consider the interaction between\npedestrians. It is also not well suited for prediction of pedestrian flow\nperformance in pedestrian areas or in buildings with some obstruction, that\nreduces the effective width of the walkways. On the other hand, the microscopic\nlevel has a more general usage and considers detail in the design. More\nefficient pedestrian flow can even be reached with less space. Those results\nhave rejected the linearity assumption of space and flow in the macroscopic\nlevel.\n", "versions": [{"version": "v1", "created": "Thu, 8 Sep 2016 01:58:10 GMT"}], "update_date": "2016-09-09", "authors_parsed": [["Teknomo", "Kardi", ""], ["Takeyama", "Yasushi", ""], ["Inamura", "Hajime", ""]]}, {"id": "1609.02621", "submitter": "Taha Yasseri", "authors": "Ruth Garc\\'ia-Gavilanes and Anders Mollgaard and Milena Tsvetkova and\n  Taha Yasseri", "title": "Memory Remains: Understanding Collective Memory in the Digital Age", "comments": "Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY cs.SI physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently developed information communication technologies, particularly the\nInternet, have affected how we, both as individuals and as a society, create,\nstore, and recall information. Internet also provides us with a great\nopportunity to study memory using transactional large scale data, in a\nquantitative framework similar to the practice in statistical physics. In this\nproject, we make use of online data by analysing viewership statistics of\nWikipedia articles on aircraft crashes. We study the relation between recent\nevents and past events and particularly focus on understanding memory\ntriggering patterns. We devise a quantitative model that explains the flow of\nviewership from a current event to past events based on similarity in time,\ngeography, topic, and the hyperlink structure of Wikipedia articles. We show\nthat on average the secondary flow of attention to past events generated by\nsuch remembering processes is larger than the primary attention flow to the\ncurrent event. We are the first to report these cascading effects.\n", "versions": [{"version": "v1", "created": "Thu, 8 Sep 2016 23:46:22 GMT"}], "update_date": "2016-09-12", "authors_parsed": [["Garc\u00eda-Gavilanes", "Ruth", ""], ["Mollgaard", "Anders", ""], ["Tsvetkova", "Milena", ""], ["Yasseri", "Taha", ""]]}, {"id": "1609.02789", "submitter": "Donghyeon Lee", "authors": "Donghyeon Lee", "title": "Arachneum: Blockchain meets Distributed Web", "comments": "This paper has been withdrawn by the author. I feel need some\n  experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Appearance of Bitcoin raise up evolution in currency. Blockchain database\nalso raise up possibilities to share important data between untrusted peers. In\nthis paper, we propose Arachneum, a decentralized, distributed, and\nmodel-view-controller-based web service using blockchain and new privileges\nmodel. Therefore, we can enjoy the freedom against censorship of government or\norganizations, keep transparency of our web services, fork our web services,\nand create/read/update/delete(CRUD) all model-view-controller(MVC) components\ndynamically.\n", "versions": [{"version": "v1", "created": "Mon, 22 Aug 2016 20:27:28 GMT"}, {"version": "v2", "created": "Wed, 5 Apr 2017 23:00:20 GMT"}], "update_date": "2017-04-07", "authors_parsed": [["Lee", "Donghyeon", ""]]}, {"id": "1609.03191", "submitter": "Yuki Yamada", "authors": "Takahiro Kawabe, Kyoshiro Sasaki, Keiko Ihaya and Yuki Yamada", "title": "When categorization-based stranger avoidance explains the uncanny\n  valley: A comment on MacDorman & Chattopadhyay (2016)", "comments": "published in Cognition", "journal-ref": "Cognition, 2016", "doi": "10.1016/j.cognition.2016.09.001", "report-no": null, "categories": "cs.HC cs.CY cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial objects often subjectively look eerie when their appearance to\nsome extent resembles a human, which is known as the uncanny valley phenomenon.\nFrom a cognitive psychology perspective, several explanations of the phenomenon\nhave been put forth, two of which are object categorization and realism\ninconsistency. Recently, MacDorman and Chattopadhyay (2016) reported\nexperimental data as evidence in support of the latter. In our estimation,\nhowever, their results are still consistent with categorization-based stranger\navoidance. In this Discussions paper, we try to describe why\ncategorization-based stranger avoidance remains a viable explanation, despite\nthe evidence of MacDorman and Chattopadhyay, and how it offers a more inclusive\nexplanation of the impression of eeriness in the uncanny valley phenomenon.\n", "versions": [{"version": "v1", "created": "Sun, 11 Sep 2016 18:43:06 GMT"}, {"version": "v2", "created": "Tue, 13 Sep 2016 00:47:54 GMT"}, {"version": "v3", "created": "Tue, 20 Sep 2016 07:08:42 GMT"}], "update_date": "2016-09-21", "authors_parsed": [["Kawabe", "Takahiro", ""], ["Sasaki", "Kyoshiro", ""], ["Ihaya", "Keiko", ""], ["Yamada", "Yuki", ""]]}, {"id": "1609.03266", "submitter": "Elaine Sedenberg", "authors": "Elaine Sedenberg and Anna Lauren Hoffmann", "title": "Recovering the History of Informed Consent for Data Science and Internet\n  Industry Research Ethics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Respect for persons is a cornerstone value for any conception of research\nethics--though how to best realize respect in practice is an ongoing question.\nIn the late 19th and early 20th centuries, \"informed consent\" emerged as a\nparticular way to operationalize respect in medical and behavioral research\ncontexts. Today, informed consent has been challenged by increasingly advanced\nnetworked information and communication technologies (ICTs) and the massive\namounts of data they produce--challenges that have led many researchers and\nprivate companies to abandon informed consent as untenable or infeasible\nonline.\n  Against any easy dismissal, we aim to recover insights from the history of\ninformed consent as it developed from the late 19th century to today. With a\nparticular focus on the United States policy context, we show how informed\nconsent is not a fixed or monolithic concept that should be abandoned in view\nof new data-intensive and technological practices, but rather it is a mechanism\nthat has always been fluid--it has constantly evolved alongside the specific\ncontexts and practices it is intended to regulate. Building on this insight, we\narticulate some specific challenges and lessons from the history of informed\nconsent that stand to benefit current discussions of informed consent and\nresearch ethics in the context of data science and Internet industry research.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2016 04:54:10 GMT"}], "update_date": "2016-09-13", "authors_parsed": [["Sedenberg", "Elaine", ""], ["Hoffmann", "Anna Lauren", ""]]}, {"id": "1609.03312", "submitter": "Charith Perera", "authors": "Charith Perera, Susan Wakenshaw, Tim Baarslag, Hamed Haddadi, Arosha\n  Bandara, Richard Mortier, Andy Crabtree, Irene Ng, Derek McAuley, Jon\n  Crowcroft", "title": "Valorising the IoT Databox: Creating Value for Everyone", "comments": "Accepted for Transactions on Emerging Telecommunications Technologies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) is expected to generate large amounts of\nheterogeneous data from diverse sources including physical sensors, user\ndevices, and social media platforms. Over the last few years, significant\nattention has been focused on personal data, particularly data generated by\nsmart wearable and smart home devices. Making personal data available for\naccess and trade is expected to become a part of the data driven digital\neconomy. In this position paper, we review the research challenges in building\npersonal Databoxes that hold personal data and enable data access by other\nparties, and potentially thus sharing of data with other parties. These\nDataboxes are expected to become a core part of future data marketplaces.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2016 08:52:25 GMT"}], "update_date": "2016-09-13", "authors_parsed": [["Perera", "Charith", ""], ["Wakenshaw", "Susan", ""], ["Baarslag", "Tim", ""], ["Haddadi", "Hamed", ""], ["Bandara", "Arosha", ""], ["Mortier", "Richard", ""], ["Crabtree", "Andy", ""], ["Ng", "Irene", ""], ["McAuley", "Derek", ""], ["Crowcroft", "Jon", ""]]}, {"id": "1609.03375", "submitter": "Maxime Lenormand", "authors": "Maxime Lenormand and Thomas Louail and Marc Barthelemy and Jos\\'e J.\n  Ramasco", "title": "Is spatial information in ICT data reliable?", "comments": "11 pages, 9 figures + Appendix, Extended version of the conference\n  paper published in the proceedings of the 2016 Spatial Accuracy Conference, p\n  9-17, Montpellier, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing number of human activities are studied using data produced by\nindividuals' ICT devices. In particular, when ICT data contain spatial\ninformation, they represent an invaluable source for analyzing urban dynamics.\nHowever, there have been relatively few contributions investigating the\nrobustness of this type of results against fluctuations of data\ncharacteristics. Here, we present a stability analysis of higher-level\ninformation extracted from mobile phone data passively produced during an\nentire year by 9 million individuals in Senegal. We focus on two\ninformation-retrieval tasks: (a) the identification of land use in the region\nof Dakar from the temporal rhythms of the communication activity; (b) the\nidentification of home and work locations of anonymized individuals, which\nenable to construct Origin-Destination (OD) matrices of commuting flows. Our\nanalysis reveal that the uncertainty of results highly depends on the sample\nsize, the scale and the period of the year at which the data were gathered.\nNevertheless, the spatial distributions of land use computed for different\nsamples are remarkably robust: on average, we observe more than 75% of shared\nsurface area between the different spatial partitions when considering activity\nof at least 100,000 users whatever the scale. The OD matrix is less stable and\ndepends on the scale with a share of at least 75% of commuters in common when\nconsidering all types of flows constructed from the home-work locations of\n100,000 users. For both tasks, better results can be obtained at larger levels\nof aggregation or by considering more users. These results confirm that ICT\ndata are very useful sources for the spatial analysis of urban systems, but\nthat their reliability should in general be tested more thoroughly.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2016 12:51:28 GMT"}, {"version": "v2", "created": "Sat, 7 Jan 2017 14:04:07 GMT"}, {"version": "v3", "created": "Thu, 23 Nov 2017 19:26:42 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Lenormand", "Maxime", ""], ["Louail", "Thomas", ""], ["Barthelemy", "Marc", ""], ["Ramasco", "Jos\u00e9 J.", ""]]}, {"id": "1609.03442", "submitter": "Vivek Singh", "authors": "Vivek K. Singh and Rishav R. Agarwal", "title": "Cooperative Phoneotypes: Exploring Phone-based Behavioral Markers of\n  Cooperation", "comments": "To appear in UbiComp'16", "journal-ref": null, "doi": "10.1145/2971648.2971755", "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperation is a fundamental human concept studied across multiple social and\nbiological disciplines. Traditional methods for eliciting an individual's\npropensity to cooperate have included surveys and laboratory experiments and\nmultiple such studies have connected an individual's cooperation level with her\nsocial behavior. We describe a novel approach to model an individual's\ncooperation level based on her phoneotype i.e. a composite of an individual's\ntraits as observable via a mobile phone. This phone sensing-based method can\npotentially complement surveys, thus providing a cheaper, faster, automated\nmethod for generating insights into cooperation levels of users. Based on a\n10-week field study involving 54 participants, we report that: (1) multiple\nphone-based signals were significantly associated with participant's\ncooperation attitudes; and (2) combining phone-based signals yielded a\npredictive model with AUCROC of 0.945 that performed significantly better than\na comparable demography-based model at predicting individual cooperation\npropensities. The results pave the way for individuals and organizations to\nidentify more cooperative peers in personal, social, and commerce related\nsettings.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2016 15:18:02 GMT"}], "update_date": "2016-09-13", "authors_parsed": [["Singh", "Vivek K.", ""], ["Agarwal", "Rishav R.", ""]]}, {"id": "1609.03615", "submitter": "Jes\\'us Romero", "authors": "Jes\\'us Romero, Pablo L\\'opez, Jos\\'e Luis V\\'azquez Noguera, Cristian\n  Cappo, Diego P. Pinto-Roa, Cynthia Villalba", "title": "Integrated, reliable and cloud-based personal health record: A scoping\n  review", "comments": "20 pages, 2 figures, 1 table", "journal-ref": null, "doi": "10.5121/hiij.2016.5301", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Personal Health Records (PHR) emerge as an alternative to integrate patient's\nhealth information to give a global view of patients' status. However,\nintegration is not a trivial feature when dealing with a variety electronic\nhealth systems from healthcare centers. Access to PHR sensitive information\nmust comply with privacy policies defined by the patient. Architecture PHR\ndesign should be in accordance to these, and take advantage of nowadays\ntechnology. Cloud computing is a current technology that provides scalability,\nubiquity, and elasticity features. This paper presents a scoping review related\nto PHR systems that achieve three characteristics: integrated, reliable and\ncloud-based. We found 101 articles that addressed those characteristics. We\nidentified four main research topics: proposal/developed systems, PHR\nrecommendations for development, system integration and standards, and security\nand privacy. Integration is tackled with HL7 CDA standard. Information\nreliability is based in ABE security-privacy mechanism. Cloud-based technology\naccess is achieved via SOA.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2016 22:07:00 GMT"}], "update_date": "2016-09-14", "authors_parsed": [["Romero", "Jes\u00fas", ""], ["L\u00f3pez", "Pablo", ""], ["Noguera", "Jos\u00e9 Luis V\u00e1zquez", ""], ["Cappo", "Cristian", ""], ["Pinto-Roa", "Diego P.", ""], ["Villalba", "Cynthia", ""]]}, {"id": "1609.03756", "submitter": "M\\'arton Karsai", "authors": "Yannick Leo, M\\'arton Karsai, Carlos Sarraute and Eric Fleury", "title": "Correlations of consumption patterns in social-economic networks", "comments": "11 pages, 4 figures, 1 table", "journal-ref": "IEEE/ACM ASONAM p. 500-507, San Francisco CA, August 18-21 (2016)", "doi": null, "report-no": null, "categories": "cs.SI cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze a coupled anonymized dataset collecting the mobile phone\ncommunication and bank transactions history of a large number of individuals.\nAfter mapping the social structure and introducing indicators of socioeconomic\nstatus, demographic features, and purchasing habits of individuals we show that\ntypical consumption patterns are strongly correlated with identified\nsocioeconomic classes leading to patterns of stratification in the social\nstructure. In addition we measure correlations between merchant categories and\nintroduce a correlation network, which emerges with a meaningful community\nstructure. We detect multivariate relations between merchant categories and\nshow correlations in purchasing habits of individuals. Our work provides novel\nand detailed insight into the relations between social and consuming behaviour\nwith potential applications in recommendation system design.\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2016 10:35:43 GMT"}, {"version": "v2", "created": "Thu, 21 Dec 2017 21:08:14 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Leo", "Yannick", ""], ["Karsai", "M\u00e1rton", ""], ["Sarraute", "Carlos", ""], ["Fleury", "Eric", ""]]}, {"id": "1609.04060", "submitter": "Charith Perera", "authors": "Charith Perera, Ciaran McCormick, Arosha K. Bandara, Blaine A. Price,\n  Bashar Nuseibeh", "title": "Privacy-by-Design Framework for Assessing Internet of Things\n  Applications and Platforms", "comments": "Accepted to be published in The 6th International Conference on the\n  Internet of Things (IoT 2016) November 7-9, 2016 in Stuttgart, Germany", "journal-ref": "The 6th International Conference on the Internet of Things (IoT\n  2016) November 7-9, 2016 in Stuttgart, Germany", "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) systems are designed and developed either as\nstandalone applications from the ground-up or with the help of IoT middleware\nplatforms. They are designed to support different kinds of scenarios, such as\nsmart homes and smart cities. Thus far, privacy concerns have not been\nexplicitly considered by IoT applications and middleware platforms. This is\npartly due to the lack of systematic methods for designing privacy that can\nguide the software development process in IoT. In this paper, we propose a set\nof guidelines, a privacy-by-design framework, that can be used to assess\nprivacy capabilities and gaps of existing IoT applications as well as\nmiddleware platforms. We have evaluated two open source IoT middleware\nplatforms, namely OpenIoT and Eclipse SmartHome, to demonstrate how our\nframework can be used in this way.\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2016 21:35:28 GMT"}], "update_date": "2016-10-02", "authors_parsed": [["Perera", "Charith", ""], ["McCormick", "Ciaran", ""], ["Bandara", "Arosha K.", ""], ["Price", "Blaine A.", ""], ["Nuseibeh", "Bashar", ""]]}, {"id": "1609.04071", "submitter": "Todd Davies", "authors": "Todd Davies", "title": "Book Review of Susan Greenfield's 'Mind Change: How Digital Technologies\n  Are Leaving Their Mark On Our Brains'", "comments": "5 pages, no figures", "journal-ref": "New Media & Society, 18(9):2139-2141, October 2016", "doi": "10.1177/1461444816652614", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a review of Susan Greenfield's 2015 book 'Mind Change: How Digital\nTechnologies Are Leaving Their Mark On Our Brains'. Greenfield is a\nneuroscientist and a member of the UK House of Lords, who argues that digital\ntechnologies are changing the human environment \"in an unprecedented way,\" and\nthat by adapting to this environment, \"the brain may also be changing in an\nunprecedented way.\" The book and its author have created a surprising amount of\ncontroversy. I discuss both Greenfield's book and a prominent critique by Bell\net al. (2015). The exchange points to some flaws in Greenfield's argument and\nrepresents an interesting debate about the public role of scientists, but it\ndoes not undermine the value of the book as a springboard for discussions about\npossible policies and future research.\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2016 23:04:30 GMT"}], "update_date": "2016-09-15", "authors_parsed": [["Davies", "Todd", ""]]}, {"id": "1609.04285", "submitter": "Milena Tsvetkova", "authors": "Milena Tsvetkova, Ruth Garc\\'ia-Gavilanes, Luciano Floridi, Taha\n  Yasseri", "title": "Even Good Bots Fight: The Case of Wikipedia", "comments": "Published in PLOS ONE", "journal-ref": "PLoS ONE (2017) 12(2):e0171774", "doi": "10.1371/journal.pone.0171774", "report-no": null, "categories": "cs.SI cs.CY cs.HC physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there has been a huge increase in the number of bots online,\nvarying from Web crawlers for search engines, to chatbots for online customer\nservice, spambots on social media, and content-editing bots in online\ncollaboration communities. The online world has turned into an ecosystem of\nbots. However, our knowledge of how these automated agents are interacting with\neach other is rather poor. Bots are predictable automatons that do not have the\ncapacity for emotions, meaning-making, creativity, and sociality and it is\nhence natural to expect interactions between bots to be relatively predictable\nand uneventful. In this article, we analyze the interactions between bots that\nedit articles on Wikipedia. We track the extent to which bots undid each\nother's edits over the period 2001-2010, model how pairs of bots interact over\ntime, and identify different types of interaction trajectories. We find that,\nalthough Wikipedia bots are intended to support the encyclopedia, they often\nundo each other's edits and these sterile \"fights\" may sometimes continue for\nyears. Unlike humans on Wikipedia, bots' interactions tend to occur over longer\nperiods of time and to be more reciprocated. Yet, just like humans, bots in\ndifferent cultural environments may behave differently. Our research suggests\nthat even relatively \"dumb\" bots may give rise to complex interactions, and\nthis carries important implications for Artificial Intelligence research.\nUnderstanding what affects bot-bot interactions is crucial for managing social\nmedia well, providing adequate cyber-security, and designing well functioning\nautonomous vehicles.\n", "versions": [{"version": "v1", "created": "Wed, 14 Sep 2016 14:17:25 GMT"}, {"version": "v2", "created": "Mon, 27 Feb 2017 15:03:15 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Tsvetkova", "Milena", ""], ["Garc\u00eda-Gavilanes", "Ruth", ""], ["Floridi", "Luciano", ""], ["Yasseri", "Taha", ""]]}, {"id": "1609.04340", "submitter": "Jack Murtagh", "authors": "Marco Gaboardi, James Honaker, Gary King, Jack Murtagh, Kobbi Nissim,\n  Jonathan Ullman, Salil Vadhan", "title": "PSI ({\\Psi}): a Private data Sharing Interface", "comments": "34 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an overview of PSI (\"a Private data Sharing Interface\"), a system\nwe are developing to enable researchers in the social sciences and other fields\nto share and explore privacy-sensitive datasets with the strong privacy\nprotections of differential privacy.\n", "versions": [{"version": "v1", "created": "Wed, 14 Sep 2016 16:45:09 GMT"}, {"version": "v2", "created": "Tue, 29 Nov 2016 05:02:59 GMT"}, {"version": "v3", "created": "Sat, 4 Aug 2018 02:24:30 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Gaboardi", "Marco", ""], ["Honaker", "James", ""], ["King", "Gary", ""], ["Murtagh", "Jack", ""], ["Nissim", "Kobbi", ""], ["Ullman", "Jonathan", ""], ["Vadhan", "Salil", ""]]}, {"id": "1609.04667", "submitter": "Dustin Lewis", "authors": "Dustin A. Lewis, Gabriella Blum, and Naz K. Modirzadeh", "title": "War-Algorithm Accountability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this briefing report, we introduce a new concept (war algorithms) that\nelevates algorithmically-derived choices and decisions to a, and perhaps the,\ncentral concern regarding technical autonomy in war. We thereby aim to shed\nlight on and recast the discussion regarding autonomous weapon systems. We\ndefine war algorithm as any algorithm that is expressed in computer code, that\nis effectuated through a constructed system, and that is capable of operating\nin relation to armed conflict. In introducing this concept, our foundational\ntechnological concern is the capability of a constructed system, without\nfurther human intervention, to help make and effectuate a decision or choice of\na war algorithm. Distilled, the two core ingredients are an algorithm expressed\nin computer code and a suitably capable constructed system. Through that lens,\nwe link international law and related accountability architectures to relevant\ntechnologies. We sketch a three-part (non-exhaustive) approach that highlights\ntraditional and unconventional accountability avenues. We focus largely on\ninternational law because it is the only normative regime that purports, in key\nrespects but with important caveats, to be both universal and uniform. By not\nlimiting our inquiry only to weapon systems, we take an expansive view, showing\nhow the broad concept of war algorithms might be susceptible to regulation, and\nhow those algorithms might already fit within the existing regulatory system\nestablished by international law.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2016 15:59:07 GMT"}], "update_date": "2016-09-16", "authors_parsed": [["Lewis", "Dustin A.", ""], ["Blum", "Gabriella", ""], ["Modirzadeh", "Naz K.", ""]]}, {"id": "1609.04904", "submitter": "Ethan Fast", "authors": "Ethan Fast and Eric Horvitz", "title": "Long-Term Trends in the Public Perception of Artificial Intelligence", "comments": "In AAAI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyses of text corpora over time can reveal trends in beliefs, interest,\nand sentiment about a topic. We focus on views expressed about artificial\nintelligence (AI) in the New York Times over a 30-year period. General\ninterest, awareness, and discussion about AI has waxed and waned since the\nfield was founded in 1956. We present a set of measures that captures levels of\nengagement, measures of pessimism and optimism, the prevalence of specific\nhopes and concerns, and topics that are linked to discussions about AI over\ndecades. We find that discussion of AI has increased sharply since 2009, and\nthat these discussions have been consistently more optimistic than pessimistic.\nHowever, when we examine specific concerns, we find that worries of loss of\ncontrol of AI, ethical concerns for AI, and the negative impact of AI on work\nhave grown in recent years. We also find that hopes for AI in healthcare and\neducation have increased over time.\n", "versions": [{"version": "v1", "created": "Fri, 16 Sep 2016 03:45:15 GMT"}, {"version": "v2", "created": "Fri, 2 Dec 2016 17:18:42 GMT"}], "update_date": "2016-12-05", "authors_parsed": [["Fast", "Ethan", ""], ["Horvitz", "Eric", ""]]}, {"id": "1609.05063", "submitter": "Nemanja Djuric", "authors": "Nemanja Djuric, Mihajlo Grbovic, Vladan Radosavljevic, Jaikit Savla,\n  Varun Bhagwan, Doug Sharp", "title": "Travel the World: Analyzing and Predicting Booking Behavior using E-mail\n  Travel Receipts", "comments": "25th International World Wide Web Conference", "journal-ref": null, "doi": "10.1145/2872518.2889410", "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tourism industry has grown tremendously in the previous several decades.\nDespite its global impact, there still remain a number of open questions\nrelated to better understanding of tourists and their habits. In this work we\nanalyze the largest data set of travel receipts considered thus far, and focus\non exploring and modeling booking behavior of online customers. We extract\nuseful, actionable insights into the booking behavior, and tackle the task of\npredicting the booking time. The presented results can be directly used to\nimprove booking experience of customers and optimize targeting campaigns of\ntravel operators.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jun 2016 13:55:13 GMT"}], "update_date": "2016-09-19", "authors_parsed": [["Djuric", "Nemanja", ""], ["Grbovic", "Mihajlo", ""], ["Radosavljevic", "Vladan", ""], ["Savla", "Jaikit", ""], ["Bhagwan", "Varun", ""], ["Sharp", "Doug", ""]]}, {"id": "1609.05315", "submitter": "Jeffrey Georgeson", "authors": "Jeffrey Georgeson", "title": "NPCs Vote! Changing Voter Reactions Over Time Using the Extreme AI\n  Personality Engine", "comments": "8 pages, 3 tables, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can non-player characters have human-realistic personalities, changing over\ntime depending on input from those around them? And can they have different\nreactions and thoughts about different people? Using Extreme AI, a\npsychology-based personality engine using the Five Factor model of personality,\nI answer these questions by creating personalities for 100 voters and allowing\nthem to react to two politicians to see if the NPC voters' choice of candidate\ndevelops in a realistic-seeming way, based on initial and changing personality\nfacets and on their differing feelings toward the politicians (in this case,\nacross liking, trusting, and feeling affiliated with the candidates). After 16\ntest runs, the voters did indeed change their attitudes and feelings toward the\ncandidates in different and yet generally realistic ways, and even changed\ntheir attitudes about other issues based on what a candidate extolled.\n", "versions": [{"version": "v1", "created": "Sat, 17 Sep 2016 11:21:17 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Georgeson", "Jeffrey", ""]]}, {"id": "1609.05339", "submitter": "Moacir Antonelli Ponti", "authors": "Moacir Ponti and Patricia Bet and Caroline Oliveira and Paula C.\n  Castro", "title": "Better than Counting Seconds: Identifying Fallers among Healthy Elderly\n  using Fusion of Accelerometer Features and Dual-Task Timed Up and Go", "comments": "accepted at PLoS One in Apr/2017", "journal-ref": null, "doi": "10.1371/journal.pone.0175559", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Devices and sensors for identification of fallers can be used to implement\nactions to prevent falls and to allow the elderly to live an independent life\nwhile reducing the long-term care costs. In this study we aimed to investigate\nthe accuracy of Timed Up and Go test, for fallers' identification, using fusion\nof features extracted from accelerometer data. Single and dual tasks TUG\n(manual and cognitive) were performed by a final sample (94% power) of 36\ncommunity dwelling healthy older persons (18 fallers paired with 18\nnon-fallers) while they wear a single triaxial accelerometer at waist with\nsampling rate of 200Hz. The segmentation of the TUG different trials and its\ncomparative analysis allows to better discriminate fallers from non-fallers,\nwhile conventional functional tests fail to do so. In addition, we show that\nthe fusion of features improve the discrimination power, achieving AUC of 0.84\n(Sensitivity=Specificity=0.83, 95% CI 0.62-0.91), and demonstrating the\nclinical relevance of the study. We concluded that features extracted from\nsegmented TUG trials acquired with dual tasks has potential to improve\nperformance when identifying fallers via accelerometer sensors, which can\nimprove TUG accuracy for clinical and epidemiological applications.\n", "versions": [{"version": "v1", "created": "Sat, 17 Sep 2016 13:59:32 GMT"}, {"version": "v2", "created": "Fri, 21 Oct 2016 15:36:17 GMT"}, {"version": "v3", "created": "Wed, 23 Nov 2016 10:15:25 GMT"}, {"version": "v4", "created": "Wed, 12 Apr 2017 14:22:04 GMT"}], "update_date": "2017-04-13", "authors_parsed": [["Ponti", "Moacir", ""], ["Bet", "Patricia", ""], ["Oliveira", "Caroline", ""], ["Castro", "Paula C.", ""]]}, {"id": "1609.05413", "submitter": "Camila Ara\\'ujo", "authors": "Gabriel Magno, Camila Souza Ara\\'ujo, Wagner Meira Jr., Virgilio\n  Almeida", "title": "Stereotypes in Search Engine Results: Understanding The Role of Local\n  and Global Factors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The internet has been blurring the lines between local and global cultures,\naffecting in different ways the perception of people about themselves and\nothers. In the global context of the internet, search engine platforms are a\nkey mediator between individuals and information. In this paper, we examine the\nlocal and global impact of the internet on the formation of female physical\nattractiveness stereotypes in search engine results. By investigating datasets\nof images collected from two major search engines in 42 countries, we identify\na significant fraction of replicated images. We find that common images are\nclustered around countries with the same language. We also show that existence\nof common images among countries is practically eliminated when the queries are\nlimited to local sites. In summary, we show evidence that results from search\nengines are biased towards the language used to query the system, which leads\nto certain attractiveness stereotypes that are often quite different from the\nmajority of the female population of the country.\n", "versions": [{"version": "v1", "created": "Sun, 18 Sep 2016 01:37:50 GMT"}, {"version": "v2", "created": "Mon, 7 Nov 2016 23:43:19 GMT"}], "update_date": "2016-11-09", "authors_parsed": [["Magno", "Gabriel", ""], ["Ara\u00fajo", "Camila Souza", ""], ["Meira", "Wagner", "Jr."], ["Almeida", "Virgilio", ""]]}, {"id": "1609.05700", "submitter": "Marta Poblet", "authors": "Marta Poblet, Amir Aryani, Paolo Manghi, Kathryn Unsworth, Jingbo\n  Wang, Brigitte Hausstein, Sunje Dallmeier-Tiessen, Claus-Peter Klas, Pompeu\n  Casanovas, Victor Rodriguez Doncel", "title": "Assigning Creative Commons Licenses to Research Metadata: Issues and\n  Cases", "comments": "9 pages. Submitted to the 29th International Conference on Legal\n  Knowledge and Information Systems (JURIX 2016), Nice (France) 14-16 December\n  2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper discusses the problem of lack of clear licensing and transparency\nof usage terms and conditions for research metadata. Making research data\nconnected, discoverable and reusable are the key enablers of the new data\nrevolution in research. We discuss how the lack of transparency hinders\ndiscovery of research data and make it disconnected from the publication and\nother trusted research outcomes. In addition, we discuss the application of\nCreative Commons licenses for research metadata, and provide some examples of\nthe applicability of this approach to internationally known data\ninfrastructures.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 12:57:31 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Poblet", "Marta", ""], ["Aryani", "Amir", ""], ["Manghi", "Paolo", ""], ["Unsworth", "Kathryn", ""], ["Wang", "Jingbo", ""], ["Hausstein", "Brigitte", ""], ["Dallmeier-Tiessen", "Sunje", ""], ["Klas", "Claus-Peter", ""], ["Casanovas", "Pompeu", ""], ["Doncel", "Victor Rodriguez", ""]]}, {"id": "1609.05763", "submitter": "Vineet Pandey", "authors": "Vineet Pandey, Scott Klemmer, Amnon Amir, Justine Debelius, Embriette\n  R. Hyde, Tomasz Kosciolek, Rob Knight", "title": "Integrating citizen science with online learning to ask better questions", "comments": "HCOMP 2016 Work-in-Progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online learners spend millions of hours per year testing their new skills on\nassignments with known answers. This paper explores whether framing research\nquestions as assignments with unknown answers helps learners generate novel,\nuseful, and difficult-to-find knowledge while increasing their motivation by\ncontributing to a larger goal. Collaborating with the American Gut Project, the\nworld's largest crowdfunded citizen science project, we deploy Gut Instinct to\nallow novices to generate hypotheses about the constitution of the human gut\nmicrobiome. The tool enables online learners to explore learning material about\nthe microbiome and create their own theories around causal variances for\nmicrobiome. Building on crowdsourcing or serious games that use people as\nreplaceable units, this work-in-progress lays our plans for how people (a) use\ntheir personal knowledge (b) towards solving a larger real-world goal (c) that\ncan provide potential benefits to them. We hope to demonstrate that Gut\nInstinct citizen scientists generate useful hypotheses, perform better on\nlearning tasks than traditional MOOC learners, and are better engaged with the\nlearning material.\n", "versions": [{"version": "v1", "created": "Fri, 2 Sep 2016 19:39:17 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Pandey", "Vineet", ""], ["Klemmer", "Scott", ""], ["Amir", "Amnon", ""], ["Debelius", "Justine", ""], ["Hyde", "Embriette R.", ""], ["Kosciolek", "Tomasz", ""], ["Knight", "Rob", ""]]}, {"id": "1609.05782", "submitter": "Ronald C. Arkin", "authors": "Ronald C. Arkin and Gaurav S. Sukhatme", "title": "Toward a Science of Autonomy for Physical Systems: Defense", "comments": "A Computing Community Consortium (CCC) white paper, 4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Militaries around the world have long been cognizant of the potential\nbenefits associated with autonomous systems both in the conduct of warfare and\nin its prevention. This has lead to the declaration by some that this\ntechnology will lead to a fundamental change in the ways in which war is\nconducted, i.e., a revolution in military affairs (RMA) not unlike gunpowder,\nthe long bow, the rifled bullet, the aircraft carrier, etc. Indeed the United\nStates has created roadmaps for robotics with ever-increasing autonomous\ncapability that span almost 40 years. These systems span air, sea, sea surface,\nlittoral, ground and subterranean environments. There are serious societal and\nethical concerns associated with the deployment of this technology that remain\nunaddressed. How can sufficient protection be afforded noncombatants? What\nabout civilian blowback, where this technology may end up being used in\npolicing operations against domestic groups? How can we protect the fundamental\nhuman rights of all involved? Considerable discussion is being conducted at an\ninternational level, including at the United Nations Convention on Certain\nConventional Weapons (CCW) over the past two years, debating if and how such\nsystems, particularly lethal platforms should be banned or regulated.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 15:30:09 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Arkin", "Ronald C.", ""], ["Sukhatme", "Gaurav S.", ""]]}, {"id": "1609.05783", "submitter": "M. Ani Hsieh", "authors": "M. Ani Hsieh, Srikanth Saripalli, Gaurav Sukhatme, and Vijay Kumar", "title": "Toward a Science of Autonomy for Physical Systems: Aerial Earth Science", "comments": "A Computing Community Consortium (CCC) white paper, 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned Aerial Vehicles (UAVs) equipped with LiDAR, electro-optical and\ninfrared cameras, SAR and atmospheric sensors have transformed the way we\nacquire high spatio-temporal resolution data. For example, UAVs equipped with\nthese sensors have been able to obtain topography at resolutions of less than\none meter, revolutionizing earth sciences. Surface processes act at spatial\nscales on the order of a meter to produce intricate landforms and UAVs equipped\nwith these sensors are able to measure the three dimensional spatio-temporal\ngeometry of the earths surface and overlying anthropogenic features and\nvegetation at resolutions appropriate to document these processes. In addition,\nsurface changes due to erosion, transport and sedimentation, as well as\nearthquakes, landslides, volcanoes can be quantified with this data.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 15:30:35 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Hsieh", "M. Ani", ""], ["Saripalli", "Srikanth", ""], ["Sukhatme", "Gaurav", ""], ["Kumar", "Vijay", ""]]}, {"id": "1609.05807", "submitter": "Jon Kleinberg", "authors": "Jon Kleinberg, Sendhil Mullainathan, Manish Raghavan", "title": "Inherent Trade-Offs in the Fair Determination of Risk Scores", "comments": "To appear in Proceedings of Innovations in Theoretical Computer\n  Science (ITCS), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent discussion in the public sphere about algorithmic classification has\ninvolved tension between competing notions of what it means for a probabilistic\nclassification to be fair to different groups. We formalize three fairness\nconditions that lie at the heart of these debates, and we prove that except in\nhighly constrained special cases, there is no method that can satisfy these\nthree conditions simultaneously. Moreover, even satisfying all three conditions\napproximately requires that the data lie in an approximate version of one of\nthe constrained special cases identified by our theorem. These results suggest\nsome of the ways in which key notions of fairness are incompatible with each\nother, and hence provide a framework for thinking about the trade-offs between\nthem.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 16:08:51 GMT"}, {"version": "v2", "created": "Thu, 17 Nov 2016 16:41:21 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Kleinberg", "Jon", ""], ["Mullainathan", "Sendhil", ""], ["Raghavan", "Manish", ""]]}, {"id": "1609.05813", "submitter": "Gregory Hager", "authors": "Gregory Hager and Eric Horvitz", "title": "Toward a Science of Autonomy for Physical Science: Healthcare", "comments": "A Computing Community Consortium (CCC) white paper, 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Star Wars Episode V, we see Luke Skywalker being repaired by a surgical\nrobot. In the context of the movie, this doesn't seem surprising or disturbing.\nAfter all, it is a long, long time ago, in a galaxy far, far away. It would\nnever happen here. Or could it? Would we accept a robot as our doctor, our\nsurgeon, or our in-home care specialist? Imagine walking into an operating room\nand no one was there. You are instructed to lie down on the operating table,\nand the OR system takes over. Would you feel comfortable with this possible\nfuture world?\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 16:20:54 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Hager", "Gregory", ""], ["Horvitz", "Eric", ""]]}, {"id": "1609.05814", "submitter": "Pieter Abbeel", "authors": "Pieter Abbeel, Ken Goldberg, Gregory Hager, Julie Shah", "title": "Toward a Science of Autonomy for Physical Systems: Paths", "comments": "A Computing Community Consortium (CCC) white paper, 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An Autonomous Physical System (APS) will be expected to reliably and\nindependently evaluate, execute, and achieve goals while respecting surrounding\nrules, laws, or conventions. In doing so, an APS must rely on a broad spectrum\nof dynamic, complex, and often imprecise information about its surroundings,\nthe task it is to perform, and its own sensors and actuators. For example,\ncleaning in a home or commercial setting requires the ability to perceive,\ngrasp, and manipulate many physical objects, the ability to reliably perform a\nvariety of subtasks such as washing, folding, and stacking, and knowledge about\nlocal conventions such as how objects are classified and where they should be\nstored. The information required for reliable autonomous operation may come\nfrom external sources and from the robot's own sensor observations or in the\nform of direct instruction by a trainer. Similar considerations apply across\nmany domains - construction, manufacturing, in-home assistance, and healthcare.\nFor example, surgeons spend many years learning about physiology and anatomy\nbefore they touch a patient. They then perform roughly 1000 surgeries under the\ntutelage of an expert surgeon, and they practice basic maneuvers such as suture\ntying thousands of times outside the operating room. All of these elements come\ntogether to achieve expertise at this task. Endowing a system with robust\nautonomy by traditional programming methods has thus far had limited success.\nSeveral promising new paths to acquiring and processing such data are emerging.\nThis white paper outlines three promising research directions for enabling an\nAPS to learn the physical and information skills necessary to perform tasks\nwith independence and flexibility: Deep Reinforcement Learning, Human-Robot\nInteraction, and Cloud Robotics.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 16:24:05 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Abbeel", "Pieter", ""], ["Goldberg", "Ken", ""], ["Hager", "Gregory", ""], ["Shah", "Julie", ""]]}, {"id": "1609.05818", "submitter": "Peter Allen", "authors": "Peter Allen and Henrik I. Christensen", "title": "Toward a Science of Autonomy for Physical Systems: Service", "comments": "A Computing Community Consortium (CCC) white paper, 7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent study by the Robotic Industries Association has highlighted how\nservice robots are increasingly broadening our horizons beyond the factory\nfloor. From robotic vacuums, bomb retrievers, exoskeletons and drones, to\nrobots used in surgery, space exploration, agriculture, home assistance and\nconstruction, service robots are building a formidable resume. In just the last\nfew years we have seen service robots deliver room service meals, assist\nshoppers in finding items in a large home improvement store, checking in\ncustomers and storing their luggage at hotels, and pour drinks on cruise ships.\nPersonal robots are here to educate, assist and entertain at home. These\ndomestic robots can perform daily chores, assist people with disabilities and\nserve as companions or pets for entertainment. By all accounts, the growth\npotential for service robotics is quite large.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 16:27:49 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Allen", "Peter", ""], ["Christensen", "Henrik I.", ""]]}, {"id": "1609.05821", "submitter": "Daniel Lee", "authors": "Daniel Lee and Sebastian Pokutta", "title": "Toward a Science of Autonomy for Physical Systems: Transportation", "comments": "A Computing Community Consortium (CCC) white paper, 7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transportation systems are currently being transformed by advances in\ninformation and communication technologies. The development of autonomous\ntransportation holds the promise of providing revolutionary improvements in\nspeed, efficiency, safety and reliability along with concomitant benefits for\nsociety and economy. It is anticipated these changes will soon affect household\nactivity patterns, public safety, supply chains and logistics, manufacturing,\nand quality of life in general.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 16:30:15 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Lee", "Daniel", ""], ["Pokutta", "Sebastian", ""]]}, {"id": "1609.05835", "submitter": "Ender Ozcan", "authors": "Martin Baumers, Ender Ozcan", "title": "Scope for Machine Learning in Digital Manufacturing", "comments": "Royal Society Workshop on Realising the Benefits of Machine Learning\n  in Manufacturing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This provocation paper provides an overview of the underlying optimisation\nproblem in the emerging field of Digital Manufacturing. Initially, this paper\ndiscusses how the notion of Digital Manufacturing is transforming from a term\ndescribing a suite of software tools for the integration of production and\ndesign functions towards a more general concept incorporating computerised\nmanufacturing and supply chain processes, as well as information collection and\nutilisation across the product life cycle. On this basis, we use the example of\none such manufacturing process, Additive Manufacturing, to identify an\nintegrated multi-objective optimisation problem underlying Digital\nManufacturing. Forming an opportunity for a concurrent application of data\nscience and optimisation, a set of challenges arising from this problem is\noutlined.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 17:27:56 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Baumers", "Martin", ""], ["Ozcan", "Ender", ""]]}, {"id": "1609.06354", "submitter": "Yonatan Vaizman", "authors": "Yonatan Vaizman and Katherine Ellis and Gert Lanckriet", "title": "Recognizing Detailed Human Context In-the-Wild from Smartphones and\n  Smartwatches", "comments": "This paper was accepted and is to appear in IEEE Pervasive Computing,\n  vol. 16, no. 4, October-December 2017, pp. 62-74", "journal-ref": "IEEE Pervasive Computing, vol. 16, no. 4, October-December 2017,\n  pp. 62-74", "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to automatically recognize a person's behavioral context can\ncontribute to health monitoring, aging care and many other domains. Validating\ncontext recognition in-the-wild is crucial to promote practical applications\nthat work in real-life settings. We collected over 300k minutes of sensor data\nwith context labels from 60 subjects. Unlike previous studies, our subjects\nused their own personal phone, in any way that was convenient to them, and\nengaged in their routine in their natural environments. Unscripted behavior and\nunconstrained phone usage resulted in situations that are harder to recognize.\nWe demonstrate how fusion of multi-modal sensors is important for resolving\nsuch cases. We present a baseline system, and encourage researchers to use our\npublic dataset to compare methods and improve context recognition in-the-wild.\n", "versions": [{"version": "v1", "created": "Tue, 20 Sep 2016 20:56:07 GMT"}, {"version": "v2", "created": "Thu, 29 Dec 2016 22:47:22 GMT"}, {"version": "v3", "created": "Wed, 17 May 2017 21:44:18 GMT"}, {"version": "v4", "created": "Sat, 30 Sep 2017 15:25:23 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Vaizman", "Yonatan", ""], ["Ellis", "Katherine", ""], ["Lanckriet", "Gert", ""]]}, {"id": "1609.06374", "submitter": "Dimitrios Adamos Dr", "authors": "Fotis Kalaganis (1), Dimitrios A. Adamos (2 and 3), Nikos Laskaris (1\n  and 3) ((1) AIIA Lab, Department of Informatics, Aristotle University of\n  Thessaloniki, (2) School of Music Studies, Aristotle University of\n  Thessaloniki, (3) Neuroinformatics GRoup, Aristotle University of\n  Thessaloniki)", "title": "A Consumer BCI for Automated Music Evaluation Within a Popular On-Demand\n  Music Streaming Service - Taking Listener's Brainwaves to Extremes", "comments": "12th IFIP WG 12.5 International Conference and Workshops, AIAI 2016,\n  Thessaloniki, Greece, September 16-18, 2016, Proceedings", "journal-ref": "Artificial Intelligence Applications and Innovations, Volume 475\n  of the series IFIP Advances in Information and Communication Technology pp\n  429-440, 2016", "doi": "10.1007/978-3-319-44944-9_37", "report-no": null, "categories": "cs.AI cs.CY cs.HC cs.MM cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigated the possibility of using a machine-learning scheme in\nconjunction with commercial wearable EEG-devices for translating listener's\nsubjective experience of music into scores that can be used for the automated\nannotation of music in popular on-demand streaming services. Based on the\nestablished -neuroscientifically sound- concepts of brainwave frequency bands,\nactivation asymmetry index and cross-frequency-coupling (CFC), we introduce a\nBrain Computer Interface (BCI) system that automatically assigns a rating score\nto the listened song. Our research operated in two distinct stages: i) a\ngeneric feature engineering stage, in which features from signal-analytics were\nranked and selected based on their ability to associate music induced\nperturbations in brainwaves with listener's appraisal of music. ii) a\npersonalization stage, during which the efficiency of ex- treme learning\nmachines (ELMs) is exploited so as to translate the derived pat- terns into a\nlistener's score. Encouraging experimental results, from a pragmatic use of the\nsystem, are presented.\n", "versions": [{"version": "v1", "created": "Tue, 20 Sep 2016 22:29:02 GMT"}, {"version": "v2", "created": "Fri, 30 Sep 2016 11:06:37 GMT"}], "update_date": "2016-10-03", "authors_parsed": [["Kalaganis", "Fotis", "", "2 and 3"], ["Adamos", "Dimitrios A.", "", "2 and 3"], ["Laskaris", "Nikos", "", "1\n  and 3"]]}, {"id": "1609.06582", "submitter": "Emiliano De Cristofaro", "authors": "Apostolos Pyrgelis and Emiliano De Cristofaro and Gordon Ross", "title": "Privacy-Friendly Mobility Analytics using Aggregate Location Data", "comments": "Published at ACM SIGSPATIAL 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Location data can be extremely useful to study commuting patterns and\ndisruptions, as well as to predict real-time traffic volumes. At the same time,\nhowever, the fine-grained collection of user locations raises serious privacy\nconcerns, as this can reveal sensitive information about the users, such as,\nlife style, political and religious inclinations, or even identities. In this\npaper, we study the feasibility of crowd-sourced mobility analytics over\naggregate location information: users periodically report their location, using\na privacy-preserving aggregation protocol, so that the server can only recover\naggregates -- i.e., how many, but not which, users are in a region at a given\ntime. We experiment with real-world mobility datasets obtained from the\nTransport For London authority and the San Francisco Cabs network, and present\na novel methodology based on time series modeling that is geared to forecast\ntraffic volumes in regions of interest and to detect mobility anomalies in\nthem. In the presence of anomalies, we also make enhanced traffic volume\npredictions by feeding our model with additional information from correlated\nregions. Finally, we present and evaluate a mobile app prototype, called\nMobility Data Donors (MDD), in terms of computation, communication, and energy\noverhead, demonstrating the real-world deployability of our techniques.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 14:31:15 GMT"}, {"version": "v2", "created": "Sun, 9 Oct 2016 15:58:06 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Pyrgelis", "Apostolos", ""], ["De Cristofaro", "Emiliano", ""], ["Ross", "Gordon", ""]]}, {"id": "1609.06622", "submitter": "Ellen Murphy", "authors": "Ellen Murphy (University of Bath, United Kingdom), Tom Crick (Cardiff\n  Metropolitan University, United Kingdom), James H. Davenport (University of\n  Bath, United Kingdom)", "title": "An Analysis of Introductory Programming Courses at UK Universities", "comments": null, "journal-ref": "The Art, Science, and Engineering of Programming, 2017, Vol. 1,\n  Issue 2, Article 18", "doi": "10.22152/programming-journal.org/2017/1/18", "report-no": null, "categories": "cs.CY cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context: In the context of exploring the art, science and engineering of\nprogramming, the question of which programming languages should be taught first\nhas been fiercely debated since computer science teaching started in\nuniversities. Failure to grasp programming readily almost certainly implies\nfailure to progress in computer science. Inquiry: What first programming\nlanguages are being taught? There have been regular national-scale surveys in\nAustralia and New Zealand, with the only US survey reporting on a small subset\nof universities. This the first such national survey of universities in the UK.\nApproach: We report the results of the first survey of introductory programming\ncourses (N=80) taught at UK universities as part of their first year computer\nscience (or related) degree programmes, conducted in the first half of 2016. We\nreport on student numbers, programming paradigm, programming languages and\nenvironment/tools used, as well as the underpinning rationale for these\nchoices. Knowledge: The results in this first UK survey indicate a dominance of\nJava at a time when universities are still generally teaching students who are\nnew to programming (and computer science), despite the fact that Python is\nperceived, by the same respondents, to be both easier to teach as well as to\nlearn. Grounding: We compare the results of this survey with a related survey\nconducted since 2010 (as well as earlier surveys from 2001 and 2003) in\nAustralia and New Zealand. Importance: This survey provides a starting point\nfor valuable pedagogic baseline data for the analysis of the art, science and\nengineering of programming, in the context of substantial computer science\ncurriculum reform in UK schools, as well as increasing scrutiny of teaching\nexcellence and graduate employability for UK universities.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 16:23:39 GMT"}, {"version": "v2", "created": "Sat, 1 Apr 2017 00:09:47 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Murphy", "Ellen", "", "University of Bath, United Kingdom"], ["Crick", "Tom", "", "Cardiff\n  Metropolitan University, United Kingdom"], ["Davenport", "James H.", "", "University of\n  Bath, United Kingdom"]]}, {"id": "1609.06653", "submitter": "Yi Zhu", "authors": "Yi Zhu and Shawn Newsam", "title": "Land Use Classification using Convolutional Neural Networks Applied to\n  Ground-Level Images", "comments": "ACM SIGSPATIAL 2015, Best Poster Award", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Land use mapping is a fundamental yet challenging task in geographic science.\nIn contrast to land cover mapping, it is generally not possible using overhead\nimagery. The recent, explosive growth of online geo-referenced photo\ncollections suggests an alternate approach to geographic knowledge discovery.\nIn this work, we present a general framework that uses ground-level images from\nFlickr for land use mapping. Our approach benefits from several novel aspects.\nFirst, we address the nosiness of the online photo collections, such as\nimprecise geolocation and uneven spatial distribution, by performing location\nand indoor/outdoor filtering, and semi- supervised dataset augmentation. Our\nindoor/outdoor classifier achieves state-of-the-art performance on several\nbench- mark datasets and approaches human-level accuracy. Second, we utilize\nhigh-level semantic image features extracted using deep learning, specifically\nconvolutional neural net- works, which allow us to achieve upwards of 76%\naccuracy on a challenging eight class land use mapping problem.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 18:01:24 GMT"}], "update_date": "2016-09-22", "authors_parsed": [["Zhu", "Yi", ""], ["Newsam", "Shawn", ""]]}, {"id": "1609.06756", "submitter": "Mark D. Hill", "authors": "Mark D. Hill, Sarita Adve, Luis Ceze, Mary Jane Irwin, David Kaeli,\n  Margaret Martonosi, Josep Torrellas, Thomas F. Wenisch, David Wood, and\n  Katherine Yelick", "title": "21st Century Computer Architecture", "comments": "A Computing Community Consortium (CCC) white paper, 16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Because most technology and computer architecture innovations were\n(intentionally) invisible to higher layers, application and other software\ndevelopers could reap the benefits of this progress without engaging in it.\nHigher performance has both made more computationally demanding applications\nfeasible (e.g., virtual assistants, computer vision) and made less demanding\napplications easier to develop by enabling higher-level programming\nabstractions (e.g., scripting languages and reusable components). Improvements\nin computer system cost-effectiveness enabled value creation that could never\nhave been imagined by the field's founders (e.g., distributed web search\nsufficiently inexpensive so as to be covered by advertising links).\n  The wide benefits of computer performance growth are clear. Recently,\nDanowitz et al. apportioned computer performance growth roughly equally between\ntechnology and architecture, with architecture credited with ~80x improvement\nsince 1985. As semiconductor technology approaches its \"end-of-the-road\" (see\nbelow), computer architecture will need to play an increasing role in enabling\nfuture ICT innovation. But instead of asking, \"How can I make my chip run\nfaster?,\" architects must now ask, \"How can I enable the 21st century\ninfrastructure, from sensors to clouds, adding value from performance to\nprivacy, but without the benefit of near-perfect technology scaling?\". The\nchallenges are many, but with appropriate investment, opportunities abound.\nUnderlying these opportunities is a common theme that future architecture\ninnovations will require the engagement of and investments from innovators in\nother ICT layers.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 21:10:20 GMT"}], "update_date": "2016-09-23", "authors_parsed": [["Hill", "Mark D.", ""], ["Adve", "Sarita", ""], ["Ceze", "Luis", ""], ["Irwin", "Mary Jane", ""], ["Kaeli", "David", ""], ["Martonosi", "Margaret", ""], ["Torrellas", "Josep", ""], ["Wenisch", "Thomas F.", ""], ["Wood", "David", ""], ["Yelick", "Katherine", ""]]}, {"id": "1609.06772", "submitter": "Yi Zhu", "authors": "Yi Zhu and Shawn Newsam", "title": "Spatio-Temporal Sentiment Hotspot Detection Using Geotagged Photos", "comments": "To appear in ACM SIGSPATIAL 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We perform spatio-temporal analysis of public sentiment using geotagged photo\ncollections. We develop a deep learning-based classifier that predicts the\nemotion conveyed by an image. This allows us to associate sentiment with place.\nWe perform spatial hotspot detection and show that different emotions have\ndistinct spatial distributions that match expectations. We also perform\ntemporal analysis using the capture time of the photos. Our spatio-temporal\nhotspot detection correctly identifies emerging concentrations of specific\nemotions and year-by-year analyses of select locations show there are strong\ntemporal correlations between the predicted emotions and known events.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 22:43:54 GMT"}], "update_date": "2016-09-23", "authors_parsed": [["Zhu", "Yi", ""], ["Newsam", "Shawn", ""]]}, {"id": "1609.07190", "submitter": "Rishab Nithyanand", "authors": "Narseo Vallina-Rodriguez, Srikanth Sundaresan, Abbas Razaghpanah,\n  Rishab Nithyanand, Mark Allman, Christian Kreibich, Phillipa Gill", "title": "Tracking the Trackers: Towards Understanding the Mobile Advertising and\n  Tracking Ecosystem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Third-party services form an integral part of the mobile ecosystem: they\nallow app developers to add features such as performance analytics and social\nnetwork integration, and to monetize their apps by enabling user tracking and\ntargeted ad delivery. At present users, researchers, and regulators all have at\nbest limited understanding of this third-party ecosystem. In this paper we seek\nto shrink this gap. Using data from users of our ICSI Haystack app we gain a\nrich view of the mobile ecosystem: we identify and characterize domains\nassociated with mobile advertising and user tracking, thereby taking an\nimportant step towards greater transparency. We furthermore outline our steps\ntowards a public catalog and census of analytics services, their behavior,\ntheir personal data collection processes, and their use across mobile apps.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 23:45:20 GMT"}, {"version": "v2", "created": "Wed, 26 Oct 2016 15:50:14 GMT"}], "update_date": "2016-10-27", "authors_parsed": [["Vallina-Rodriguez", "Narseo", ""], ["Sundaresan", "Srikanth", ""], ["Razaghpanah", "Abbas", ""], ["Nithyanand", "Rishab", ""], ["Allman", "Mark", ""], ["Kreibich", "Christian", ""], ["Gill", "Phillipa", ""]]}, {"id": "1609.07236", "submitter": "Suresh Venkatasubramanian", "authors": "Sorelle A. Friedler and Carlos Scheidegger and Suresh\n  Venkatasubramanian", "title": "On the (im)possibility of fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What does it mean for an algorithm to be fair? Different papers use different\nnotions of algorithmic fairness, and although these appear internally\nconsistent, they also seem mutually incompatible. We present a mathematical\nsetting in which the distinctions in previous papers can be made formal. In\naddition to characterizing the spaces of inputs (the \"observed\" space) and\noutputs (the \"decision\" space), we introduce the notion of a construct space: a\nspace that captures unobservable, but meaningful variables for the prediction.\n  We show that in order to prove desirable properties of the entire\ndecision-making process, different mechanisms for fairness require different\nassumptions about the nature of the mapping from construct space to decision\nspace. The results in this paper imply that future treatments of algorithmic\nfairness should more explicitly state assumptions about the relationship\nbetween constructs and observations.\n", "versions": [{"version": "v1", "created": "Fri, 23 Sep 2016 05:38:20 GMT"}], "update_date": "2016-09-26", "authors_parsed": [["Friedler", "Sorelle A.", ""], ["Scheidegger", "Carlos", ""], ["Venkatasubramanian", "Suresh", ""]]}, {"id": "1609.07302", "submitter": "Alan Ferrari", "authors": "Alan Ferrari and Angelo Consoli", "title": "Building accurate HAV exploiting User Profiling and Sentiment Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social Engineering (SE) is one of the most dangerous aspect an attacker can\nuse against a given entity (private citizen, industry, government, ...). In\norder to perform SE attacks, it is necessary to collect as much information as\npossible about the target (or victim(s)). The aim of this paper is to report\nthe details of an activity which took to the development of an automatic tool\nthat extracts, categorizes and summarizes the target interests, thus possible\nweaknesses with respect to specific topics. Data is collected from the user's\nactivity on social networks, parsed and analyzed using text mining techniques.\nThe main contribution of the proposed tool consists in delivering some reports\nthat allow the citizen, institutions as well as private bodies the screening of\ntheir exposure to SE attacks, with a strong awareness potential that will be\nreflected in a decrease of the risks and a good opportunity to save money.\n", "versions": [{"version": "v1", "created": "Fri, 23 Sep 2016 10:35:28 GMT"}], "update_date": "2016-09-26", "authors_parsed": [["Ferrari", "Alan", ""], ["Consoli", "Angelo", ""]]}, {"id": "1609.07602", "submitter": "Nhien-An Le-Khac", "authors": "Steven Ryder, Nhien-An Le-Khac", "title": "The End of effective Law Enforcement in the Cloud? To encypt, or not to\n  encrypt", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With an exponentially increasing usage of cloud services, the need for\nforensic investigations of virtual space is equally in constantly increasing\ndemand, which includes as a very first approach, the gaining of access to it as\nwell as the data stored. This is an aspect that faces a number of challenges,\nstemming not only from the technical difficulties and peculiarities, but\nequally covers the interaction with an emerging line of businesses offering\ncloud storage and services. Beyond the forensic aspects, it also covers to an\never increasing amount the non-forensic considerations, such as the\navailability of logs and archives, legal and data protection considerations\nfrom a global perspective and the clashes in between, as well as the ever\ncompeting interests between law enforcement to seize evidence which is\nnon-physical, and businesses who need to be able to continue to operate and\nprovide their hosted services, even if law enforcement seek to collect\nevidence. The trend post-Snowden has been unequivocally towards default\nencryption, and driven by market leaders such as Apple, motivated to a large\nextent by the perceived demands for privacy of the consumer. The central\nquestion to be explored in this paper is to what extent this trend towards\ndefault encryption will have a negative impact on law enforcement\ninvestigations and possibilities, and will at the end attempt to provide a\nsolution, which takes into account the needs of both law enforcement, but also\nof the service providers. It is hoped that the recommendations from this paper\nwill be able to have an impact in the ability for law enforcement to continue\nwith their investigations in an efficient manner, whilst also safeguarding the\nability for business to thrive and continue to develop and offer new and\ninnovative solutions, which do not put law enforcement at risk.\n", "versions": [{"version": "v1", "created": "Sat, 24 Sep 2016 11:00:50 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Ryder", "Steven", ""], ["Le-Khac", "Nhien-An", ""]]}, {"id": "1609.07899", "submitter": "Aidan Mooney Dr.", "authors": "Susan Bergin and Aidan Mooney", "title": "Using an innovative assessment approach on a real-world group based\n  software project", "comments": "69 pages - 25 are in Appendix format", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, there is a lack of practical, real-world projects on Computer\nScience (CS) courses at Maynooth University. Generally CS undergraduate modules\nare composed of 24 hours of lectures and 24 hours of labs where students learn\ntheoretical concepts in the lectures and apply their understanding to practical\nlab-based exercises. The problem with this approach is that students do not\ngain any awareness of, or learn how to solve tasks that they are likely to\nencounter in a real-world industrial setting; nor do they gain experience of\nworking as part of a team even though most software development positions\ninvolve team-based work.\n  This paper reports on a web-based development module that incorporated a\nreal-world group based project was re-designed and delivered. The module went\nwell; however, assessing the work fairly was found to be difficult, especially\nwhere team members contributed at considerably varying levels was a challenge.\nOf particular concern was that some hard-working students were penalised by\nother students poor work and lazy students were rewarded because of more\nhard-working students work.\n  This action research project will attempt to re-address how to assess this\ngroup-based work with a cohort of students. The goal of the research is to\nimplement an innovative assessment structure, using peer-, self-, and\nco-assessment, for a group based real-world project, that is deemed fair and\nreasonable and provided a good learning environment.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2016 09:26:32 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Bergin", "Susan", ""], ["Mooney", "Aidan", ""]]}, {"id": "1609.07911", "submitter": "Nalin Asanka Gamagedara Arachchilage", "authors": "Mumtaz Abdul Hameed, Nalin Asanka Gamagedara Arachchilage", "title": "A Model for the Adoption Process of Information System Security\n  Innovations in Organisations: A Theoretical Perspective", "comments": "12, The 27th Australasian Conference on Information Systems 2016,\n  Australia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we develop a theoretical model for the adoption process of\nInformation System Security innovations in organisations. The model stemmed\nfrom the Diffusion of Innovation theory (DOI), the Technology Acceptance Model\n(TAM), the Theory of Planned Behaviour (TPB) and the\nTechnology-Organisation-Environment (TOE) framework. The model portrays\nInformation System Security adoption process progressing in a sequence of\nstages. The study considers the adoption process from the initiation stage\nuntil the acquisition of innovation as an organisational level judgement while\nthe process of innovation assimilation and integration is assessed in terms of\nthe user behaviour within the organisation. The model also introduces several\nfactors that influence the Information System Security innovation adoption. By\nmerging the organisational adoption and user acceptance of innovation in a\nsingle depiction, this research contributes to IS security literature a more\ncomprehensive model for IS security adoption in organisation, compare to any of\nthe past representations.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2016 10:18:09 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Hameed", "Mumtaz Abdul", ""], ["Arachchilage", "Nalin Asanka Gamagedara", ""]]}, {"id": "1609.07922", "submitter": "Pol Mac Aonghusa", "authors": "P\\'ol Mac Aonghusa and Douglas J. Leith", "title": "It wasn't me! Plausible Deniability in Web Search", "comments": "34 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our ability to control the flow of sensitive personal information to online\nsystems is key to trust in personal privacy on the internet. We ask how to\ndetect, assess and defend user privacy in the face of search engine\npersonalisation? We develop practical and scalable tools allowing a user to\ndetect, assess and defend against threats to plausible deniability. We show\nthat threats to plausible deniability of interest are readily detectable for\nall topics tested in an extensive testing program. We show this remains the\ncase when attempting to disrupt search engine learning through noise query\ninjection and click obfuscation are used. We use our model we design a defence\ntechnique exploiting uninteresting, proxy topics and show that it provides\namore effective defence of plausible deniability in our experiments.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2016 11:01:06 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Mac Aonghusa", "P\u00f3l", ""], ["Leith", "Douglas J.", ""]]}, {"id": "1609.08089", "submitter": "Eduardo Santana", "authors": "Eduardo Felipe Zambom Santana, Ana Paula Chaves, Marco Aurelio Gerosa,\n  Fabio Kon and Dejan Milojicic", "title": "Software Platforms for Smart Cities: Concepts, Requirements, Challenges,\n  and a Unified Reference Architecture", "comments": "Accepted for publication in ACM Computing Surveys", "journal-ref": null, "doi": "10.1145/3124391", "report-no": null, "categories": "cs.CY cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making cities smarter help improve city services and increase citizens'\nquality of life. Information and communication technologies (ICT) are\nfundamental for progressing towards smarter city environments. Smart City\nsoftware platforms potentially support the development and integration of Smart\nCity applications. However, the ICT community must overcome current significant\ntechnological and scientific challenges before these platforms can be widely\nused. This paper surveys the state-of-the-art in software platforms for Smart\nCities. We analyzed 23 projects with respect to the most used enabling\ntechnologies, as well as functional and non-functional requirements,\nclassifying them into four categories: Cyber-Physical Systems, Internet of\nThings, Big Data, and Cloud Computing. Based on these results, we derived a\nreference architecture to guide the development of next-generation software\nplatforms for Smart Cities. Finally, we enumerated the most frequently cited\nopen research challenges, and discussed future opportunities. This survey gives\nimportant references for helping application developers, city managers, system\noperators, end-users, and Smart City researchers to make project, investment,\nand research decisions.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2016 17:26:16 GMT"}, {"version": "v2", "created": "Mon, 3 Oct 2016 17:13:27 GMT"}, {"version": "v3", "created": "Mon, 24 Jul 2017 00:35:37 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Santana", "Eduardo Felipe Zambom", ""], ["Chaves", "Ana Paula", ""], ["Gerosa", "Marco Aurelio", ""], ["Kon", "Fabio", ""], ["Milojicic", "Dejan", ""]]}, {"id": "1609.08239", "submitter": "Pablo Su\\'arez-Serrato", "authors": "Pablo Su\\'arez-Serrato, Margaret E. Roberts, Clayton A. Davis, Filippo\n  Menczer", "title": "On the influence of social bots in online protests. Preliminary findings\n  of a Mexican case study", "comments": "10 pages", "journal-ref": "SocInfo 2016, Part II, LNCS 10047", "doi": "10.1007/978-3-319-47874-6_19", "report-no": null, "categories": "cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Social bots can affect online communication among humans. We study this\nphenomenon by focusing on #YaMeCanse, the most active protest hashtag in the\nhistory of Twitter in Mexico. Accounts using the hashtag are classified using\nthe BotOrNot bot detection tool. Our preliminary analysis suggests that bots\nplayed a critical role in disrupting online communication about the protest\nmovement.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 02:10:37 GMT"}], "update_date": "2016-09-28", "authors_parsed": [["Su\u00e1rez-Serrato", "Pablo", ""], ["Roberts", "Margaret E.", ""], ["Davis", "Clayton A.", ""], ["Menczer", "Filippo", ""]]}, {"id": "1609.08389", "submitter": "Lena Dankin", "authors": "Orna Almogi (UHH), Lena Dankin (TAU-CS), Nachum Dershowitz (TAU-CS),\n  Lior Wolf (TAU-CS)", "title": "A Hackathon for Classical Tibetan", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the course of a hackathon dedicated to the development of\nlinguistic tools for Tibetan Buddhist studies. Over a period of five days, a\ngroup of seventeen scholars, scientists, and students developed and compared\nalgorithms for intertextual alignment and text classification, along with some\nbasic language tools, including a stemmer and word segmenter.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 12:55:10 GMT"}, {"version": "v2", "created": "Mon, 31 Dec 2018 11:44:47 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Almogi", "Orna", "", "UHH"], ["Dankin", "Lena", "", "TAU-CS"], ["Dershowitz", "Nachum", "", "TAU-CS"], ["Wolf", "Lior", "", "TAU-CS"]]}, {"id": "1609.08437", "submitter": "Ashton Verdery", "authors": "Nathaniel D. Porter, Ashton M. Verdery, S. Michael Gaddis", "title": "Enhancing Big Data in the Social Sciences with Crowdsourcing: Data\n  Augmentation Practices, Techniques, and Opportunities", "comments": "32 pages, 3 tables, 4 figures", "journal-ref": "PLoS ONE 15(6): e0233154 (2020)", "doi": "10.1371/journal.pone.0233154", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of big data is a contested topic among social scientists.\nProponents claim it will fuel a research revolution, but skeptics challenge it\nas unreliably measured and decontextualized, with limited utility for\naccurately answering social science research questions. We argue that social\nscientists need effective tools to quantify big data's measurement error and\nexpand the contextual information associated with it. Standard research efforts\nin many fields already pursue these goals through data augmentation, the\nsystematic assessment of measurement against known quantities and expansion of\nextant data by adding new information. Traditionally, these tasks are\naccomplished using trained research assistants or specialized algorithms.\nHowever, such approaches may not be scalable to big data or appease its\nskeptics. We consider a third alternative that may increase the validity and\nvalue of big data: data augmentation with online crowdsourcing. We present\nthree empirical cases to illustrate the strengths and limits of crowdsourcing\nfor academic research, with a particular eye to how they can be applied to data\naugmentation tasks that will accelerate acceptance of big data among social\nscientists. The cases use Amazon Mechanical Turk to 1. verify automated coding\nof the academic discipline of dissertation committee members, 2. link online\nproduct pages to a book database, and 3. gather data on mental health resources\nat colleges. In light of these cases, we consider the costs and benefits of\naugmenting big data with crowdsourcing marketplaces and provide guidelines on\nbest practices. We also offer a standardized reporting template that will\nenhance reproducibility.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 13:41:54 GMT"}, {"version": "v2", "created": "Wed, 2 Nov 2016 16:57:30 GMT"}, {"version": "v3", "created": "Mon, 29 May 2017 15:09:16 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Porter", "Nathaniel D.", ""], ["Verdery", "Ashton M.", ""], ["Gaddis", "S. Michael", ""]]}, {"id": "1609.08715", "submitter": "Patrick Atwater", "authors": "Patrick Atwater (California Data Collaborative), Christopher Tull\n  (California Data Collaborative), Eric Schmitt (California Data\n  Collaborative), Joone Lopez (California Data Collaborative), Drew Atwater\n  (California Data Collaborative), Varun Adibhatla (California Data\n  Collaborative)", "title": "Transforming how water is managed in the West", "comments": "Presented at the Data For Good Exchange 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  California is challenged by its worst drought in 600 years and faces future\nwater uncertainty. Pioneering new data infrastructure to integrate water use\ndata across California's more than a thousand water providers will support\nwater managers in ensuring water reliability. The California Data Collaborative\nis a coalition of municipal water utilities serving ten percent of California's\npopulation who are delivering on that promise by centralizing customer water\nuse data in a recently completed pilot project. This project overview describes\ntools that have shown promising early results in improving water efficiency\nprograms and optimizing system operations. Longer term, these tools will help\nnavigate future uncertainty and support water managers in ensuring water\nreliability no matter what the future holds. The uniquely publicly-owned data\ninfrastructure deployed in this project is envisioned to enable the world's\nfirst \"marketplace of civic analytics\" to power the volume of water efficiency\nmeasurements water managers require at a radically more cost effective price.\nMore broadly, this data-utility approach is adaptable to domains other than\nwater and shows specific potential for the broader universe of natural\nresources.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 00:22:44 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Atwater", "Patrick", "", "California Data Collaborative"], ["Tull", "Christopher", "", "California Data Collaborative"], ["Schmitt", "Eric", "", "California Data\n  Collaborative"], ["Lopez", "Joone", "", "California Data Collaborative"], ["Atwater", "Drew", "", "California Data Collaborative"], ["Adibhatla", "Varun", "", "California Data\n  Collaborative"]]}, {"id": "1609.08716", "submitter": "Juan Francisco Saldarriaga", "authors": "Juan Francisco Saldarriaga (Columbia University), David A. King\n  (Arizona State University)", "title": "Access to Taxicabs for Unbanked Households: An Exploratory Analysis in\n  New York City", "comments": "Presented at the Data For Good Exchange 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Taxicabs are a critical aspect of the public transit system in New York City.\nThe yellow cabs that are ubiquitous in Manhattan are as iconic as the city's\nsubway system, and in recent years green taxicabs were introduced by the city\nto improve taxi service in areas outside of the central business districts and\nairports. Approximately 500,000 taxi trips are taken daily, carrying about\n800,000 passengers, and not including other livery firms such as Uber, Lyft or\nCarmel. Since 2008 yellow taxis have been able to process fare payments with\ncredit cards, and credits cards are a growing share of total fare payments.\nHowever, the use of credit cards to pay for taxi fares varies widely across\nneighborhoods, and there are strong correlations between cash payments for taxi\nfares and the presence of unbanked or underbanked populations. These issues are\nof concern for policymakers as approximately ten percent of households in the\ncity are unbanked, and in some neighborhoods the share of unbanked households\nis over 50 percent. In this paper we use multiple datasets to explore taxicab\nfare payments by neighborhood and examine how access to taxicab services is\nassociated with use of conventional banking services. There is a clear spatial\ndimension to the propensity of riders to pay cash, and we find that both\nimmigrant status and being 'unbanked' are strong predictors of cash\ntransactions for taxicabs. These results have implications for local\nregulations of the for-hire vehicle industry, particularly in the context of\nthe rapid growth of services that require credit cards. Without some type of\ncash-based payment option taxi services will isolate certain neighborhoods. At\nthe very least, existing and new providers of transit services must consider\naccess to mainstream financial products as part of their equity analyses.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 00:34:02 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Saldarriaga", "Juan Francisco", "", "Columbia University"], ["King", "David A.", "", "Arizona State University"]]}, {"id": "1609.08747", "submitter": "Kristyna Tomsu", "authors": "Kristyna Tomsu (Real Impact Analytics), Alexis Eggermont (Real Impact\n  Analytics), Nicolas Snel (Real Impact Analytics)", "title": "Telecom data for efficient malaria interventions", "comments": "Presented at the Data For Good Exchange 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Telecom data is rich on mobility information and as such can be used to\nidentify mobility patterns of people in near real time, enabling to build\nepidemiological models for understanding where epidemics might spread over\ntime. Based on previous research, we have built an operational tool fed with\ntelecom data which shows malaria risk flows in Zambia in near real time. It\nprovides insights on which areas should eradicate malaria first in order to\nhave a maximum impact on the overall country malaria flows, and it highlights\nregions that should coordinate their eradication efforts together. Such\ninformation is particularly relevant for countries like Zambia, which are\ngetting close to malaria elimination and need to prevent its re-introduction\ninto areas that are already malaria-free.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 03:16:49 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Tomsu", "Kristyna", "", "Real Impact Analytics"], ["Eggermont", "Alexis", "", "Real Impact\n  Analytics"], ["Snel", "Nicolas", "", "Real Impact Analytics"]]}, {"id": "1609.08753", "submitter": "Rob Goodier", "authors": "Rob Goodier (Engineering for Change), Iana Aranda (Engineering for\n  Change), Laura MacDonald (Engineering for Change)", "title": "TMI! How Knowledge Platforms Tame the Information Overload and Advance\n  Global Development Through Technology", "comments": "Presented at the Data For Good Exchange 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding reliable data to inform decisions about technology for global\ndevelopment remains a challenge. Easily accessible \"Knowledge platforms\" are a\nway to curate and standardize information about technology for development.\nThree collaborators, Engineering for Change, the Global Alliance for Clean\nCookstoves and the Center for Affordable Water and Sanitation Technology\n(CAWST) are working together to create platforms to serve the global\ndevelopment sector. Such platforms could be the first step in making decisions\nabout how to solve a problem that needs a technology-based solution. They could\nmotivate manufacturers to demonstrate compliance with quality standards, and\nthey could encourage independent research into each product's impact. Years of\ndevelopment experience worldwide have yielded a set of best practices to\nincrease the life of a project. These platforms clarify those practices to\nimprove quality and reduce waste. As the platforms mature, mining them for data\ncould identify trends that influence the entire technology ecosystem. Those\ncould include decisions about performance targets, future innovation, pricing,\ncompliance with regulations, and funding priorities.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 03:27:31 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Goodier", "Rob", "", "Engineering for Change"], ["Aranda", "Iana", "", "Engineering for\n  Change"], ["MacDonald", "Laura", "", "Engineering for Change"]]}, {"id": "1609.08754", "submitter": "Simone Brody", "authors": "Simone Brody (What Works Cities | Results for America), Andel Koester\n  (What Works Cities | Results for America), Zachary Markovits (What Works\n  Cities | Results for America), Jacob Phillips (What Works Cities | Results\n  for America)", "title": "Moving the Needle: What Works Cities and the use of data and evidence", "comments": "Presented at the Data For Good Exchange 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bloomberg Philanthropies launched What Works Cities (WWC) in 2015 to help\ncities better leverage data and evidence to drive decision-making and improve\nresidents' lives. Over three years, WWC will work with 100 American cities with\npopulations between 100,000 and 1,000,000 to measure their state of practice\nand provide targeted technical assistance. This paper uses the data obtained\nthrough the WWC discovery process to understand how 67 cities are currently\nusing data to deliver city services. Our analysis confirms that while cities\npossess a strong desire to use data and evidence, government leaders are\nconstrained in their ability to apply these practices. We find that a city's\nstated commitment to using data is the strongest predictor of overall\nperformance and that strong practice in almost any one specific technical area\nof using data to inform decisions is an indicator of strong practices in other\nareas. The exception is open data; we find larger cities are more adept at\nadopting open data policies and programs, independent of their performance\nusing data overall. This paper seeks to develop a deeper understanding of the\nissues underlying these findings and to continue the conversation on how to\nbest support cities' efforts in this work.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 03:29:08 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Brody", "Simone", "", "What Works Cities | Results for America"], ["Koester", "Andel", "", "What Works Cities | Results for America"], ["Markovits", "Zachary", "", "What Works\n  Cities | Results for America"], ["Phillips", "Jacob", "", "What Works Cities | Results\n  for America"]]}, {"id": "1609.08755", "submitter": "Yasmin Chandani", "authors": "Yasmin Chandani (John Snow, Inc), Elizabeth A. Bunde (John Snow, Inc),\n  Wambui Waithaka (John Snow, Inc), Eric Wakaria (John Snow, Inc), James Riungu\n  (John Snow, Inc), Judith Njumwah-Kariuki (John Snow, Inc), Alexis Strader\n  (John Snow, Inc)", "title": "A Case in Kenya: Unlocking bottlenecks in public health supply chains\n  through data dashboards and enhanced governance structures", "comments": "Presented at the Data For Good Exchange 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The link between data and governance are key to making public health supply\nchains more integrated and responsive in order to get life-saving commodities\nto those in need. In particular, considering its significant health challenges,\npoor maternal and child health indicators, and major recent devolution in\npolitical authority, Kenya represents a country in need of an innovative revamp\nof their data management and governance. John Snow, Inc. (JSI) adapted various\nelements of proven interventions to build a customized structure to support\nroutine data collection in order to drive decision making around supply chain\nimprovement.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 03:30:32 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Chandani", "Yasmin", "", "John Snow, Inc"], ["Bunde", "Elizabeth A.", "", "John Snow, Inc"], ["Waithaka", "Wambui", "", "John Snow, Inc"], ["Wakaria", "Eric", "", "John Snow, Inc"], ["Riungu", "James", "", "John Snow, Inc"], ["Njumwah-Kariuki", "Judith", "", "John Snow, Inc"], ["Strader", "Alexis", "", "John Snow, Inc"]]}, {"id": "1609.08756", "submitter": "Wessley Merten", "authors": "Wessley Merten (Oceana), Adam Reyer (Oceana), Jackie Savitz (Oceana),\n  John Amos (SkyTruth), Paul Woods (SkyTruth), Brian Sullivan (Google)", "title": "Global Fishing Watch: Bringing Transparency to Global Commercial\n  Fisheries", "comments": "Presented at the Data For Good Exchange 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Across all major industrial fishing sectors, overfishing due to overcapacity\nand lack of compliance in fishery governance has led to a decline in biomass of\nmany global fish stocks. Overfishing threatens ocean biodiversity, global food\nsecurity, and the livelihoods of law abiding fishermen. To address this issue,\nGlobal Fishing Watch (GFW) was created to bring transparency to global\nfisheries using computer science and big data analytics. A product of a\npartnership between Oceana, SkyTruth and Google, GFW uses the Automatic\nIdentification System, or AIS, to analyze the movement of vessels at sea. AIS\nprovides vessel location data, and GFW uses this information to track global\nvessel movement and apply algorithms to classify vessel behavior as \"fishing\"\nor \"non-fishing\" activity. Now publicly available, anyone with an internet\nconnection can monitor when and where trackable commercial fishing appears to\nbe occurring around the world. Hundreds of millions of people around the world\ndepend on our ocean for their livelihoods, and many more rely on it for food.\nCollectively, the various applications of GFW will help reduce overfishing and\nillegal fishing, restore the ocean's abundance, and ensure sustainability\nthrough better monitoring and governance of our marine resources.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 03:32:09 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Merten", "Wessley", "", "Oceana"], ["Reyer", "Adam", "", "Oceana"], ["Savitz", "Jackie", "", "Oceana"], ["Amos", "John", "", "SkyTruth"], ["Woods", "Paul", "", "SkyTruth"], ["Sullivan", "Brian", "", "Google"]]}, {"id": "1609.08757", "submitter": "David Ory", "authors": "David Ory (Metropolitan Transportation Commission), Stephen\n  Granger-Bevan (Formerly of Metropolitan Transportation Commission)", "title": "A Functioning Beta Solution to the Challenge of Opening Transit Payment\n  System Transaction Data", "comments": "Presented at the Data For Good Exchange 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deployment of smart-card-based public transit fare payment systems\nprovides government the opportunity to create a valuable derivative data\nproduct. Companies such as Urban Engines have demonstrated an ability to add\nvalue to the data derived from transit fare transactions. The challenge for the\npublic sector is to, for the societal good, leverage private sector interest by\ngiving access to useful fare transaction data in a manner that protects\ncustomer privacy. This challenge is particularly acute in California, where\nprivacy laws make sharing data in a manner that supports the public interest\ndifficult. This paper presents the Metropolitan Transportation Commission's\n(MTC's) proposed solution to the problem. MTC operates the Clipper(r) transit\nfare payment system for the San Francisco Bay Area. In an effort to share\nusable data that protects customer privacy, MTC developed an anonymizing scheme\nthat is the subject of the present paper. We seek feedback on our approach from\nthe Data for Good Exchange community, asking: in seeking a balance between\ncustomer privacy and usability, does the scheme go too far in either direction?\nAnd, should we take a different anonymizing approach?\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 03:33:21 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Ory", "David", "", "Metropolitan Transportation Commission"], ["Granger-Bevan", "Stephen", "", "Formerly of Metropolitan Transportation Commission"]]}, {"id": "1609.08762", "submitter": "Lester O. King", "authors": "Lester O. King", "title": "Public Intervention Strategies for Distressed Communities", "comments": "Presented at the Data For Good Exchange 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research presents a methodology to comprehensively define Distressed\nCommunities. We further identify if there is a significant difference in public\ninvestment between Distressed communities and Wealthy communities. One of the\nkey tools in sustainability planning is the use of sustainability indicators\n(Sis). A considerable amount of scholarship has contributed to define and\ndevelop SI programs for local level application (Elgert and Krueger, 2012).\nMuch of the focus of SI research is on developing the ideal indicator based on\ndefined criteria for each indicator (Hart, 1999; Innes and Booher 2000; Holman,\n2009). Here we suggest a methodology beyond defining the ideal indicators to\ndemonstrating how indicators can be used for more in-depth analysis of complex\nurban problems. In this analysis we reduce 34 development metrics to a smaller\nnumber of factors that represent how the data can be classified into groups\nbased on similarities among 88 communities. Using the factor (group) that\ncontained measures identifying Distressed Communities, the communities were\nalloted an index score and ranked. The top 10 communities were then compared to\nthe bottom 10 communities according to 14 place based variables related to\nopportunities for local government led improvement.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 04:17:35 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["King", "Lester O.", ""]]}, {"id": "1609.08765", "submitter": "Nadine Levick", "authors": "Nadine Levick (EMS Safety Foundation)", "title": "iRescU - Data for Social Good Saving Lives Bridging the Gaps in Sudden\n  Cardiac Arrest Survival", "comments": "Presented at the Data For Good Exchange 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently every day in the USA 1000 people die of sudden cardiac arrest (SCA)\noutside of hospitals or ambulances - before emergency medical help arrives - in\nthe streets, workplaces, schools and homes of our cities, adults and children.\nBrain death commences in 3 minutes, and often the ambulance just can't be there\nin time. Citizen cardiopulmonary resuscitation (CPR) and automated external\ndefibrillator (AED) use can save precious minutes and lives. Using public\naccess AED's saves lives in SCA- however AEDs are used in <2% of cardiac\narrests, though could save lives in 80% if available, findable, functioning,\nand used. The systems problem to solve is that there is no comprehensive or\nreal time accessible database of the AED locations, and also it is not known\nthat they are actually being positioned where they are needed. The iRescU\nproject is designed to bridge this gap in SCA survival, by substantially\naugmenting the AED database. Utilizing a combination of AED crowd sourcing and\ngeolocation integrated with existing 911 services and SCA events and projected\nevents based on machine learning data information to help make the nearest AED\naccessible and available in the setting of a SCA emergency and to identify the\nareas of greatest need for AEDs to be positioned in the community. Helping to\nsave lives and address preventable death with a social good approach and\napplied big data.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 04:45:53 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Levick", "Nadine", "", "EMS Safety Foundation"]]}, {"id": "1609.08766", "submitter": "Laura Kathrn O'Connell", "authors": "Laura Kathrn O'Connell (Westside Communities Alliance), Mackenzie\n  Madden (Westside Communities Alliance), Sheri Davis-Faulkner (Westside\n  Communities Alliance)", "title": "Data Accessibility as a Pathway to Genuine Equality for Atlanta's\n  Westside Communities", "comments": "Presented at the Data For Good Exchange 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data is a dominant force during the decision-making process. It can help\ndetermine which roads to expand and the optimal location for a grocery store.\nData can also be used to influence which schools to open or to shutter and\n\"appropriate\" city services to continue or discontinue. Considered fact-based,\nobjective, and impartial, data can trump emotional appeals during the final\nevaluation of a project; thus creating a power imbalance between those with the\nresources to access data and those without. Most often left behind are\ncommunities already struggling to stay afloat due to years of disinvestment by\nmarket forces and external decision-makers. For long ignored residents in\nAtlanta's Westside neighborhoods, the burden of inaccessible data continuously\nthwarts their opportunity for mobility. However, with the advent of the\ninternet and the global push for open data, access to information is no longer\nsolely in the hands of those with power, influence and money. Online tools,\nlike the Westside Communities Alliance (WCA) Data Dashboard, quickly\ndisseminate data to those most impacted by \"data driven decision-making,\" thus\ncreating the potential of a genuinely equitable society.\n  Based out of the Georgia Institute of Technology, the WCA works to build and\nsustain relationships among constituencies located in West Atlanta with the\ngoal to strengthen partnerships around issues of common concern. The creation\nof the Data Dashboard stemmed from a recognized community desire for more\nlocalized control and the need for improvements to the communities' overall\nprosperity. Development of the site progressed through significant engagement\nbetween the WCA, community groups, and local agencies. The Dashboard takes the\nvast abundance of data and synthesizes it into a format that is both visually\nand geographically user-friendly. Through different portals, users can access\nneighborhood-level data around demographics, housing, education, and history\nthat is formatting in a way that is easily accessible and understandable. The\nsite includes qualitative research that goes beyond data and stats to give a\ntotality of the community. By allowing West Atlanta advocacy groups to easily\nretrieve data, the WCA Data Dashboard empowers residents, nonprofits, and\nneighborhood associations to be full participants in the decision-making\nprocess.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 04:46:56 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["O'Connell", "Laura Kathrn", "", "Westside Communities Alliance"], ["Madden", "Mackenzie", "", "Westside Communities Alliance"], ["Davis-Faulkner", "Sheri", "", "Westside\n  Communities Alliance"]]}, {"id": "1609.08770", "submitter": "Steve Rees", "authors": "Steve Rees (School Wise Press), Mary Perry (K12 Measures)", "title": "Education Stats Made Visible: Helping School District Managers Write\n  Better Three-Year Plans", "comments": "Presented at the Data For Good Exchange 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Problem: School district leaders in California are awash in a sea of data,\nbut are often unable to find it, query it, or relate it with other data.\nDistricts are islands, leaving district managers able to see only their own\ndata. A state education agency gathers and republishes districts' data, but\ndoesn't clean it. New laws now require them to plan in public, set goals,\nassign resources, and project benefits for specific groups of kids. The\nevidence base they need remains out of reach.\n  Solution: Our team was commissioned by two county offices of education to\ndesign a comparative methodology and data visualization environment to help\ndistrict managers write these three-year plans. Ten year of data spanning\nfinance, staffing, students, discipline, course offerings and assessments were\nacquired, QA'd and integrated. A Tableau development team built 50+ pages of\nleaderboards and scatterplots. A documentation team wrote training materials.\nEach district in this county received a custom workbook which framed its\ndistrict's vital signs within a context of 15 districts whose students were\nmost like their own. This presentation shares the work and our evaluation.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 04:49:50 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Rees", "Steve", "", "School Wise Press"], ["Perry", "Mary", "", "K12 Measures"]]}, {"id": "1609.08776", "submitter": "Sarah Knudson", "authors": "Sarah Knudson (University of Saskatchewan), Srijita Sarkar (University\n  of Saskatchewan), Abhik Ray (Washington State University)", "title": "Connecting Data Science and Qualitative Interview Insights through\n  Sentiment Analysis to Assess Migrants' Emotion States Post-Settlement", "comments": "Presented at the Data For Good Exchange 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale survey research by social scientists offers general\nunderstandings of migrants' challenges and provides assessments of\npost-migration benchmarks like employment, obtention of educational\ncredentials, and home ownership. Minimal research, however, probes the realm of\nemotions or \"feeling states\" in migration and settlement processes, and it is\noften approached through closed-ended survey questions that superficially\nassess feeling states. The evaluation of emotions in migration and settlement\nhas been largely left to qualitative researchers using in-depth, interpretive\nmethods like semi-structured interviewing. This approach also has major\nlimitations, namely small sample sizes that capture limited geographic\ncontexts, heavy time burdens analyzing data, and limits to analytic consistency\ngiven the nuances of qualitative data coding. Information about migrant emotion\nstates, however, would be valuable to governments and NGOs to enable policy and\nprogram development tailored to migrant challenges and frustrations, and would\nthereby stimulate economic development through thriving migrant populations. In\nthis paper, we present an interdisciplinary pilot project that offers a way\nthrough the methodological impasse by subjecting exhaustive qualitative\ninterviews of migrants to sentiment analysis using the Python NLTK toolkit. We\npropose that data scientists can efficiently and accurately produce large-scale\nassessments of migrant feeling states through collaboration with social\nscientists.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 05:41:16 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Knudson", "Sarah", "", "University of Saskatchewan"], ["Sarkar", "Srijita", "", "University\n  of Saskatchewan"], ["Ray", "Abhik", "", "Washington State University"]]}, {"id": "1609.08778", "submitter": "Melissa Marsh", "authors": "Melissa Marsh (PLASTARC), Ingrid Erickson (Rutgers University), Jonah\n  Bleckner (PLASTARC)", "title": "Transforming building industry and health outcomes through social\n  data-supported design", "comments": "Presented at the Data For Good Exchange 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A glaring reality of American industrialized society is that people spend a\ntremendous amount of their waking life in their workplace and other interior\nenvironments. Despite the amount of time that we spend in them, many of our\nconstructed environments that we inhabit are not designed for the people and\ncommunities that rely on them. From a health and wellness perspective, there is\na growing body of research on the ways that our interior environments and lack\nof exposure to natural elements systematically impacts our health and strains\nour healthcare system. In short, the spaces in which we live and work are a\nmajor public health issue and should be considered in this way. In this paper,\nwe lay out a vision for using the underleveraged social data-available through\nsocial media-to inform the architecture, developer and real estate industries.\nThe goal is ultimately a public health initiative: to create spaces that are\nhealthier, more responsive, equitable and human-centric through social\ndata-supported design.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 05:43:17 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Marsh", "Melissa", "", "PLASTARC"], ["Erickson", "Ingrid", "", "Rutgers University"], ["Bleckner", "Jonah", "", "PLASTARC"]]}, {"id": "1609.08779", "submitter": "Desmond Upton Patton", "authors": "Desmond Upton Patton (Columbia University), Kathleen McKeown (Columbia\n  University), Owen Rambow (Columbia University), Jamie Macbeth (Columbia\n  University)", "title": "Using Natural Language Processing and Qualitative Analysis to Intervene\n  in Gang Violence: A Collaboration Between Social Work Researchers and Data\n  Scientists", "comments": "Presented at the Data For Good Exchange 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The U.S. has the highest rate of firearm-related deaths when compared to\nother industrialized countries. Violence particularly affects low-income, urban\nneighborhoods in cities like Chicago, which saw a 40% increase in firearm\nviolence from 2014 to 2015 to more than 3,000 shooting victims. While recent\nstudies have found that urban, gang-involved individuals curate a unique and\ncomplex communication style within and between social media platforms,\norganizations focused on reducing gang violence are struggling to keep up with\nthe growing complexity of social media platforms and the sheer volume of data\nthey present. In this paper, describe the Digital Urban Violence Analysis\nApproach (DUVVA), a collaborative qualitative analysis method used in a\ncollaboration between data scientists and social work researchers to develop a\nsuite of systems for decoding the high- stress language of urban, gang-involved\nyouth. Our approach leverages principles of grounded theory when analyzing\napproximately 800 tweets posted by Chicago gang members and participation of\nyouth from Chicago neighborhoods to create a language resource for natural\nlanguage processing (NLP) methods. In uncovering the unique language and\ncommunication style, we developed automated tools with the potential to detect\naggressive language on social media and aid individuals and groups in\nperforming violence prevention and interruption.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 05:44:10 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Patton", "Desmond Upton", "", "Columbia University"], ["McKeown", "Kathleen", "", "Columbia\n  University"], ["Rambow", "Owen", "", "Columbia University"], ["Macbeth", "Jamie", "", "Columbia\n  University"]]}, {"id": "1609.08780", "submitter": "Nicholas Johnson", "authors": "Constantine E. Kontokosta (NYU Center for Urban Science and Progress\n  and Tandon School of Engineering), Nicholas Johnson (University of Warwick\n  and NYU Center for Urban Science and Progress), Anthony Schloss (Red Hook\n  Initiative)", "title": "The Quantified Community at Red Hook: Urban Sensing and Citizen Science\n  in Low-Income Neighborhoods", "comments": "Presented at the Data For Good Exchange 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Quantified Community (QC)--a long-term neighborhood informatics research\ninitiative--is a network of instrumented urban neighborhoods that collect,\nmeasure, and analyze data on physical and environmental conditions and human\nbehavior to better understand how neighborhoods and the built environment\naffect individual and social well-being. This initiative is intended to create\na data-enabled research environment to rigorously study the complex\ninteractions in urban neighborhoods. The QC has initially launched in three\nvery distinct areas in New York City: at Hudson Yards, a ground-up\n\"city-within-a-city\" of approximately 20 million square feet in Manhattan, in\ncollaboration with the Related Companies; in Lower Manhattan, a mixed-use\nneighborhood that attracts residents, workers, and visitors, in collaboration\nwith the Alliance for Downtown NY; and in Red Hook, Brooklyn, an\neconomically-distressed community facing significant development and\ndemographic changes, in partnership with the Red Hook Initiative. This paper\ndescribes our recent pilot project to deploy novel urban sensors in Red Hook to\ncollect and analyze quality-of-life measurements at high spatial and temporal\nresolution. This effort is complemented by a citizen science initiative to\nengage local residents in the data collection and problem-solving process to\ndrive evidenced-based community decision-making and improve local and city\ngovernance.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 05:45:17 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Kontokosta", "Constantine E.", "", "NYU Center for Urban Science and Progress\n  and Tandon School of Engineering"], ["Johnson", "Nicholas", "", "University of Warwick\n  and NYU Center for Urban Science and Progress"], ["Schloss", "Anthony", "", "Red Hook\n  Initiative"]]}, {"id": "1609.09065", "submitter": "Marasi Mwencha", "authors": "Marasi Mwencha (John Snow, Inc), James Rosen (Avenir Health)", "title": "Better Data Visibility & Data Use Result in Lower Cost and Improved\n  Performance in Medicine Supply Chains", "comments": "Presented at the Data For Good Exchange 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2013-2014, Tanzania embarked on a major revamp of the management of its\npublic health supply chains for medicines and other health supplies. These\nupgrades include the establishment of a national electronic logistics\nmanagement information system (eLMIS) and the introduction of a Logistics\nManagement Unit (LMU) to use the eLMIS for managing all key public health\ncommodities. This paper describes results from the \"round one\" evaluation of\nthe impact of those key management upgrades roughly one year after their\nintroduction. The study has three main components: (1) analysis of reporting,\ndata use, management practices, and supply chain outcomes; (2) a cost and\ncost-effectiveness analysis and (3) a return on investment analysis to measure\nsavings generated by the new systems. The study used a non-experimental pre-\nand post-design to compare the previous system with the upgraded management\nsystem. The quantitative analysis found that stock out rates for all product\ngoods dropped from 32% to 23%, with the frequency of stock-outs greater than 7\ndays dropping from 24% to 15%. Annual supply chain costs increased from\n$66million to $76million. Performance improved from the 2014 baseline findings\nof 68% to 77%, but cost per value of commodities adjusted for performance\ndecreased from 58% at baseline to 50% in year 1.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 03:22:57 GMT"}], "update_date": "2016-09-30", "authors_parsed": [["Mwencha", "Marasi", "", "John Snow, Inc"], ["Rosen", "James", "", "Avenir Health"]]}, {"id": "1609.09066", "submitter": "Unaiza Ahsan", "authors": "Unaiza Ahsan (Georgia Institute of Technology), Oleksandra Sopova\n  (Kansas State University), Wes Stayton (Georgia Institute of Technology),\n  Bistra Dilkina (Georgia Institute of Technology)", "title": "Refugee Resettlement Housing Scout", "comments": "Presented at the Data For Good Exchange 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  According to the United States High Commission for Refugees (UNHCr), there\nare 65.3 million forcibly displaced people in the world today, 21.5 million of\nthem being refugees. This has led to an unprecedented refugee crisis which has\nled countries to accept refugee families and to resettle them. Diverse agencies\nare helping refugees coming to US to resettle and start their new life in the\ncountry. One of the first and most challenging steps of this process is to find\naffordable housing that also meets a suite of additional constraints and\npriorities. These include being within a mile of public transportation and near\nschools, faith centers and international grocery stores. We detail an\ninteractive data-driven web-based tool, which incorporates in one consolidated\nplatform most of the needed information. The tool searches, filters and\ndemonstrates a list of possible housing locations, and allows for the dynamic\nprioritization based on user-specified importance weights on the diverse\ncriteria. The platform was created in a partnership with New American Pathways,\na nonprofit that supports refugee resettlement in the metro Atlanta, but\nexemplifies a methodology that can help many other organizations with similar\ngoals.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 04:48:20 GMT"}], "update_date": "2016-09-30", "authors_parsed": [["Ahsan", "Unaiza", "", "Georgia Institute of Technology"], ["Sopova", "Oleksandra", "", "Kansas State University"], ["Stayton", "Wes", "", "Georgia Institute of Technology"], ["Dilkina", "Bistra", "", "Georgia Institute of Technology"]]}, {"id": "1609.09067", "submitter": "Ahu Yildirmaz", "authors": "Ahu Yildirmaz (ADP)", "title": "Using Big Data to Decode Private Sector Wage Growth", "comments": "Presented at the Data For Good Exchange 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The U.S. labor market is dynamic and complex, and understanding wage data\nacross different segments of the workforce is critical to providing\npolicymakers and business leaders with actionable insights. There is no labor\nindex that assesses the labor market performance at such a detailed level as\nthe ADP Research Institute's Workforce Vitality Report (WVR). Drawing on the\nactual, aggregated and anonymous payroll data of 24 million Americans paid by\nADP, the WVR looks at key dynamics and market indicators including wage growth,\nhours worked and turnover rate. Unlike other data sets, the WVR calculates wage\ngrowth of individual workers on a quarter-to-quarter basis, avoiding the\ndeviations caused by various workplace occurrences, like when new workers are\nhired and older ones retire. In this paper, Dr. Ahu Yildirmaz, head of the ADP\nResearch Institute, drills down into wage growth by industry, age, gender and\nincome level, as well as for both job holders and job switchers. Using WVR\ndata, Ahu walks through those factors contributing to overall shifts in wage\ngrowth, the future of the labor market and what this data means for today's\nU.S. workforce.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 05:46:17 GMT"}], "update_date": "2016-09-30", "authors_parsed": [["Yildirmaz", "Ahu", "", "ADP"]]}, {"id": "1609.09194", "submitter": "R Vivek", "authors": "Priyanka H U and Vivek R", "title": "Multi Model Data mining approach for Heart failure prediction", "comments": null, "journal-ref": null, "doi": "10.5121/ijdkp.2016.6503", "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing predictive modelling solutions for risk estimation is extremely\nchallenging in health-care informatics. Risk estimation involves integration of\nheterogeneous clinical sources having different representation from different\nhealth-care provider making the task increasingly complex. Such sources are\ntypically voluminous, diverse, and significantly change over the time.\nTherefore, distributed and parallel computing tools collectively termed big\ndata tools are in need which can synthesize and assist the physician to make\nright clinical decisions. In this work we propose multi-model predictive\narchitecture, a novel approach for combining the predictive ability of multiple\nmodels for better prediction accuracy. We demonstrate the effectiveness and\nefficiency of the proposed work on data from Framingham Heart study. Results\nshow that the proposed multi-model predictive architecture is able to provide\nbetter accuracy than best model approach. By modelling the error of predictive\nmodels we are able to choose sub set of models which yields accurate results.\nMore information was modelled into system by multi-level mining which has\nresulted in enhanced predictive accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2016 03:53:22 GMT"}], "update_date": "2016-09-30", "authors_parsed": [["U", "Priyanka H", ""], ["R", "Vivek", ""]]}, {"id": "1609.09541", "submitter": "H\\'ector P\\'erez L\\'opez-Portillo", "authors": "P\\'erez L\\'opez-Portillo, H\\'ector, V\\'azquez Gonz\\'alez, Edgar\n  Ren\\'e, Romero Hidalgo, Jorge Alberto", "title": "Knowledge management metrics for Public Organizations: A literature\n  review-based proposal", "comments": "conference proceedings", "journal-ref": null, "doi": "10.13140/RG.2.2.24281.11368/1", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Management (KM) is a relatively new phenomenon that appears in the\nfield of Public Sector Organizations (PSO) bringing new paradigms of\norganizational management, challenges, risks and opportunities for its\nimplementation, development and evaluation. KM can be seen as a systematic and\ndeliberate effort to coordinate people, technology, organizational structures\nand its environment through knowledge reuse and innovation. This management\napproach has been established in parallel with the development and use of\ninformation and communications technologies (ICT). Nowadays more PSO are\nembodying KM practices in their core processes for support them, and as an\nadvanced management strategy to create a new culture based on technology and\nresources efficiency. In this paper, we observed that KM can support\norganizational goals in PSO. The aim of this paper is to understand KM factors\nand its associated components, and propose KM metrics for measure KM programs\nin PSO. Through a critical literature review we analysed diverse studies\nrelated with KM performance indicators in PSO, then based on previous works we\nsummarized the more convenient this purpose. We found that, in academic\nliterature, studies about KM measurement in PSO are uncommon and emerging. As\nwell, in the last section of this paper, we present a proposal of KM metrics\nfor PSO, and some recommendations and practical implications for KM metrics\ndevelopment in PSO. This academic endeavour seeks to contribute to theoretical\ndebate about KM measure development for KM initiatives in PSO.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2016 22:36:04 GMT"}], "update_date": "2016-10-03", "authors_parsed": [["L\u00f3pez-Portillo", "P\u00e9rez", ""], ["H\u00e9ctor", "", ""], ["Gonz\u00e1lez", "V\u00e1zquez", ""], ["Ren\u00e9", "Edgar", ""], ["Hidalgo", "Romero", ""], ["Alberto", "Jorge", ""]]}, {"id": "1609.09571", "submitter": "Gaurav Paruthi", "authors": "Gaurav Paruthi (University of Michigan), Enrique Frias-Martinez\n  (Telefonica Research), Vanessa Frias-Martinez (University of Maryland)", "title": "The Role of Rating and Loan Characteristics in Online Microfunding\n  Behaviors", "comments": "Presented at the Data For Good Exchange 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an in-depth study of lending behaviors in Kiva using a mix of\nquantitative and large-scale data mining techniques. Kiva is a non-profit\norganization that offers an online platform to connect lenders with borrowers.\nTheir site, kiva.org, allows citizens to microlend small amounts of money to\nentrepreneurs (borrowers) from different countries. The borrowers are always\naffiliated with a Field Partner (FP) which can be a microfinance institution\n(MFI) or other type of local organization that has partnered with Kiva. Field\npartners give loans to selected businesses based on their local knowledge\nregarding the country, the business sector including agriculture, health or\nmanufacture among others, and the borrower.Our objective is to understand the\nrelationship between lending activity and various features offered by the\nonline platform. Specifically, we focus on two research questions: (i) the role\nthat MFI ratings play in driving lending activity and (ii) the role that\nvarious loan features have in the lending behavior. The first question analyzes\nwhether there exists a relationship between the MFI ratings - that lenders can\nexplore online - and their lending volumes. The second research question\nattempts to understand if certain loan features - available online at Kiva -\nsuch as the type of small business, the gender of the borrower, or the loan's\ncountry information might affect the way lenders lend.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2016 02:37:47 GMT"}], "update_date": "2016-10-03", "authors_parsed": [["Paruthi", "Gaurav", "", "University of Michigan"], ["Frias-Martinez", "Enrique", "", "Telefonica Research"], ["Frias-Martinez", "Vanessa", "", "University of Maryland"]]}, {"id": "1609.09582", "submitter": "Varun Adibhatla", "authors": "Varun Adibhatla (ARGO Labs), Shi Fan (NYU Center for Data Science),\n  Krystof Litomisky (ARGO Labs), Patrick Atwater (ARGO Labs)", "title": "Digitizing Municipal Street Inspections Using Computer Vision", "comments": "Presented at the Data For Good Exchange 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"People want an authority to tell them how to value things. But they chose\nthis authority not based on facts or results. They chose it because it seems\nauthoritative and familiar.\" - The Big Short\n  The pavement condition index is one such a familiar measure used by many US\ncities to measure street quality and justify billions of dollars spent every\nyear on street repair. These billion-dollar decisions are based on evaluation\ncriteria that are subjective and not representative. In this paper, we build\nupon our initial submission to D4GX 2015 that approaches this problem of\ninformation asymmetry in municipal decision-making.\n  We describe a process to identify street-defects using computer vision\ntechniques on data collected using the Street Quality Identification Device\n(SQUID). A User Interface to host a large quantity of image data towards\ndigitizing the street inspection process and enabling actionable intelligence\nfor a core public service is also described. This approach of combining device,\ndata and decision-making around street repair enables cities make targeted\ndecisions about street repair and could lead to an anticipatory response which\ncan result in significant cost savings. Lastly, we share lessons learnt from\nthe deployment of SQUID in the city of Syracuse, NY.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2016 03:36:03 GMT"}], "update_date": "2016-10-03", "authors_parsed": [["Adibhatla", "Varun", "", "ARGO Labs"], ["Fan", "Shi", "", "NYU Center for Data Science"], ["Litomisky", "Krystof", "", "ARGO Labs"], ["Atwater", "Patrick", "", "ARGO Labs"]]}, {"id": "1609.09756", "submitter": "Katie O'Connell", "authors": "Katie O'Connell (Georgia Institute of Technology), Yeji Lee (Georgia\n  Institute of Technology), Firaz Peer (Georgia Institute of Technology), Shawn\n  M. Staudaher (University of Wyoming), Alex Godwin (Georgia Institute of\n  Technology), Mackenzie Madden (Georgia Institute of Technology), Ellen Zegura\n  (Georgia Institute of Technology)", "title": "Making Public Safety Data Accessible in the Westside Atlanta Data\n  Dashboard", "comments": "Presented at the Data For Good Exchange 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Individual neighborhoods within large cities can benefit from independent\nanalysis of public data in the context of ongoing efforts to improve the\ncommunity. Yet existing tools for public data analysis and visualization are\noften mismatched to community needs, for reasons including geographic\ngranularity that does not correspond to community boundaries, siloed data sets,\ninaccurate assumptions about data literacy, and limited user input in design\nand implementation phases. In Atlanta this need is being addressed through a\nData Dashboard developed under the auspices of the Westside Communities\nAlliance (WCA), a partnership between Georgia Tech and community stakeholders.\nIn this paper we present an interactive analytic and visualization tool for\npublic safety data within the WCA Data Dashboard. We describe a human-centered\napproach to understand the needs of users and to build accessible mapping tools\nfor visualization and analysis. The tools include a variety of overlays that\nallow users to spatially correlate features of the built environment, such as\nvacant properties with criminal activity as well as crime prevention efforts.\nWe are in the final stages of developing the first version of the tool, with\nplans for a public release in fall of 2016.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2016 14:40:22 GMT"}], "update_date": "2016-10-03", "authors_parsed": [["O'Connell", "Katie", "", "Georgia Institute of Technology"], ["Lee", "Yeji", "", "Georgia\n  Institute of Technology"], ["Peer", "Firaz", "", "Georgia Institute of Technology"], ["Staudaher", "Shawn M.", "", "University of Wyoming"], ["Godwin", "Alex", "", "Georgia Institute of\n  Technology"], ["Madden", "Mackenzie", "", "Georgia Institute of Technology"], ["Zegura", "Ellen", "", "Georgia Institute of Technology"]]}, {"id": "1609.09758", "submitter": "pmeerkamp", "authors": "Eve Ahearn (Enigma Technologies Inc.), Olga Ianiuk (Enigma\n  Technologies Inc.)", "title": "Harnessing the Potential of the American Community Survey: Delving into\n  Methods of Data Delivery", "comments": "Presented at the Data For Good Exchange 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The American Community Survey (ACS) is the bedrock underpinning any analysis\nof the US population, urban areas included. The Census Bureau delivers the ACS\ndata in multiple formats, yet in each the raw data is difficult to export in\nbulk and difficult to sift through. We argue that Enigma's approach to the data\ndelivery, such as our raw data and metadata presentation, reflects the survey's\nlogical structure. It can be explored, interlinked, and searched; making it\neasier to retrieve the appropriate data applicable to a question at hand. We\nmake the use of data more liquid via curated tables and API access; even\nmetadata and notes from technical documentation are programmatically\naccessible. Additionally, we are working towards opening our scalable and\nreproducible ingestion process of ACS estimations. This paper details all of\nthe ways the Census Bureau currently makes the data available, the barriers\neach of these raise to applying this data in analysis and how our approach\novercomes them. Finally, this paper will address other recent innovations in\nmaking Census datasets more usable, the use cases suited to each and how they\nfit into the wider application of data science.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2016 14:43:47 GMT"}, {"version": "v2", "created": "Thu, 6 Oct 2016 16:15:19 GMT"}, {"version": "v3", "created": "Fri, 7 Oct 2016 17:51:17 GMT"}], "update_date": "2016-10-10", "authors_parsed": [["Ahearn", "Eve", "", "Enigma Technologies Inc."], ["Ianiuk", "Olga", "", "Enigma\n  Technologies Inc."]]}, {"id": "1609.09767", "submitter": "James Kizer", "authors": "James Kizer (Cornell Tech), Arnaud Sahaguet (Cornell Tech), Neil Lakin\n  (Small Data Lab @ Cornell Tech), Michael Carroll (Small Data Lab @ Cornell\n  Tech), JP Pollak (Small Data Lab @ Cornell Tech), Deborah Estrin (Small Data\n  Lab @ Cornell Tech)", "title": "Internet Scale Research Studies using SDL-RX", "comments": "Presented at the Data For Good Exchange 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical research is one area where collecting data is usually hard and\nexpensive. With the launch of ResearchKit, Apple and Sage Bionetworks made\nlarge-scale personal data collection increasingly popular via simple text-based\nsurvey apps running on mobile phones. But such surveys can be a barrier in\nterms of usability and richness of the data being collected. In this paper, we\npresent SDL-R X , a powerful software library designed for ResearchKit that\nenables study-specific, personalized, and rich visual surveys, for both iOS and\nAndroid platforms.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2016 15:11:23 GMT"}], "update_date": "2016-10-03", "authors_parsed": [["Kizer", "James", "", "Cornell Tech"], ["Sahaguet", "Arnaud", "", "Cornell Tech"], ["Lakin", "Neil", "", "Small Data Lab @ Cornell Tech"], ["Carroll", "Michael", "", "Small Data Lab @ Cornell\n  Tech"], ["Pollak", "JP", "", "Small Data Lab @ Cornell Tech"], ["Estrin", "Deborah", "", "Small Data\n  Lab @ Cornell Tech"]]}, {"id": "1609.09785", "submitter": "Peyman Noursalehi", "authors": "Peyman Noursalehi (Northeastern University), Haris N. Koutsopoulos\n  (Northeastern University)", "title": "Real-time Predictive Analytics for Improving Public Transportation\n  Systems' Resilience", "comments": "Presented at the Data For Good Exchange 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Public transit systems are a critical component of major metropolitan areas.\nHowever, in the face of increasing demand, most of these systems are operating\nclose to capacity. Under normal operating conditions, station crowding and\nboarding denial are becoming a major concern for transit agencies. As such, any\ndisruption in service will have even more severe consequences, affecting huge\nnumber of passengers. Considering the aging infrastructure of many large\ncities, such as New York and London, these disruptions are to be expected,\namplifying the need for better demand management and strategies to deal with\ncongested transit facilities. Opportunistic sensors such as smart cards (AFC),\nautomatic vehicle location systems (AVL), GPS, etc. provide a wealth of\ninformation about system's performance and passengers' trip making patterns. We\ndevelop a hybrid data/model-driven decision support system, using real-time\npredictive models, to help transit operators manage and respond proactively to\ndisruptions and mitigate consequences in a timely fashion. These models include\nstation arrival and origin-destination predictions in real-time to help transit\nagencies, and predictive information systems for assisting passengers' trip\nmaking decisions.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2016 15:52:55 GMT"}], "update_date": "2016-10-03", "authors_parsed": [["Noursalehi", "Peyman", "", "Northeastern University"], ["Koutsopoulos", "Haris N.", "", "Northeastern University"]]}, {"id": "1609.09807", "submitter": "Philipp Meerkamp", "authors": "Philipp Meerkamp", "title": "Proceedings of the Data For Good Exchange 2016", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  These are the proceedings of the Data For Good Exchange 2016, which was held\nin New York, NY, on September 26th 2016.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2016 16:43:01 GMT"}, {"version": "v2", "created": "Mon, 3 Oct 2016 17:33:45 GMT"}, {"version": "v3", "created": "Tue, 4 Oct 2016 14:22:39 GMT"}, {"version": "v4", "created": "Mon, 10 Oct 2016 13:36:08 GMT"}, {"version": "v5", "created": "Fri, 28 Oct 2016 16:20:56 GMT"}, {"version": "v6", "created": "Wed, 16 Nov 2016 21:17:55 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Meerkamp", "Philipp", ""]]}]