[{"id": "0803.0159", "submitter": "Grenville Croll", "authors": "V.R. Vemula, David Ball, Simon Thorne", "title": "Towards a Spreadsheet Engineering", "comments": "12 Pages, One Figure", "journal-ref": "Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2006 53-64\n  ISBN:1-905617-08-9", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we report some on-going focused research, but are further keen\nto set it in the context of a proposed bigger picture, as follows. There is a\ncertain depressing pattern about the attitude of industry to spreadsheet error\nresearch and a certain pattern about conferences highlighting these issues. Is\nit not high time to move on from measuring spreadsheet errors to developing an\narmoury of disciplines and controls? In short, we propose the need to\nrigorously lay the foundations of a spreadsheet engineering discipline.\nClearly, multiple research teams would be required to tackle such a big task.\nThis suggests the need for both national and international collaborative\nresearch, since any given group can only address a small segment of the whole.\nThere are already a small number of examples of such on-going international\ncollaborative research. Having established the need for a directed research\neffort, the rest of the paper then attempts to act as an exemplar in\ndemonstrating and applying this focus. With regard to one such of research, in\na recent paper, Panko (2005) stated that: \"...group development and testing\nappear to be promising areas to pursue\". Of particular interest to us are some\ngaps in the published research record on techniques to reduce errors. We\nfurther report on the topics: techniques for cross-checking, time constraints\neffects, and some aspects of developer perception.\n", "versions": [{"version": "v1", "created": "Mon, 3 Mar 2008 00:56:03 GMT"}], "update_date": "2008-03-10", "authors_parsed": [["Vemula", "V. R.", ""], ["Ball", "David", ""], ["Thorne", "Simon", ""]]}, {"id": "0803.0476", "submitter": "Renaud Lambiotte", "authors": "Vincent D. Blondel, Jean-Loup Guillaume, Renaud Lambiotte and Etienne\n  Lefebvre", "title": "Fast unfolding of communities in large networks", "comments": "6 pages, 5 figures, 1 table; new version with new figures in order to\n  clarify our method, where we look more carefully at the role played by the\n  ordering of the nodes and where we compare our method with that of Wakita and\n  Tsurumi", "journal-ref": "J. Stat. Mech. (2008) P10008", "doi": "10.1088/1742-5468/2008/10/P10008", "report-no": null, "categories": "physics.soc-ph cond-mat.stat-mech cs.CY cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple method to extract the community structure of large\nnetworks. Our method is a heuristic method that is based on modularity\noptimization. It is shown to outperform all other known community detection\nmethod in terms of computation time. Moreover, the quality of the communities\ndetected is very good, as measured by the so-called modularity. This is shown\nfirst by identifying language communities in a Belgian mobile phone network of\n2.6 million customers and by analyzing a web graph of 118 million nodes and\nmore than one billion links. The accuracy of our algorithm is also verified on\nad-hoc modular networks. .\n", "versions": [{"version": "v1", "created": "Tue, 4 Mar 2008 15:29:44 GMT"}, {"version": "v2", "created": "Fri, 25 Jul 2008 09:52:42 GMT"}], "update_date": "2008-12-01", "authors_parsed": [["Blondel", "Vincent D.", ""], ["Guillaume", "Jean-Loup", ""], ["Lambiotte", "Renaud", ""], ["Lefebvre", "Etienne", ""]]}, {"id": "0803.1360", "submitter": "Nadja Kutz", "authors": "Nadja Kutz", "title": "On the need for a global academic internet platform", "comments": "22 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article collects arguments for the necessity of a global academic\ninternet platform, which is organized as a kind of ``global scientific\nparliament''. With such a constitution educational and research institutions\nwill have direct means for communicating scientific results, as well as a\nplatform for representing academia and scientific life in the public.\n", "versions": [{"version": "v1", "created": "Mon, 10 Mar 2008 08:42:43 GMT"}], "update_date": "2008-03-11", "authors_parsed": [["Kutz", "Nadja", ""]]}, {"id": "0803.1748", "submitter": "Grenville Croll", "authors": "Yusuf Jafry, Fredrika Sidoroff, Roger Chi", "title": "A Computational Framework for the Near Elimination of Spreadsheet Risk", "comments": "9 pages, 3 colour figures", "journal-ref": "Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2006 85-93\n  ISBN:1-905617-08-9", "doi": null, "report-no": null, "categories": "cs.SE cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Risk Integrated's Enterprise Spreadsheet Platform (ESP), a\ntechnical approach to the near-elimination of spreadsheet risk in the\nenterprise computing environment, whilst maintaining the full flexibility of\nspreadsheets for modelling complex financial structures and processes. In its\nBasic Mode of use, the system comprises a secure and robust centralised\nspreadsheet management framework. In Advanced Mode, the system can be viewed as\na robust computational framework whereby users can \"submit jobs\" to the\nspreadsheet, and retrieve the results from the computations, but with no direct\naccess to the underlying spreadsheet. An example application, Monte Carlo\nsimulation, is presented to highlight the benefits of this approach with regard\nto mitigating spreadsheet risk in complex, mission-critical, financial\ncalculations.\n", "versions": [{"version": "v1", "created": "Wed, 12 Mar 2008 11:22:12 GMT"}], "update_date": "2008-03-13", "authors_parsed": [["Jafry", "Yusuf", ""], ["Sidoroff", "Fredrika", ""], ["Chi", "Roger", ""]]}, {"id": "0803.1754", "submitter": "Grenville Croll", "authors": "Simon Thorne, David Ball, Zoe Lawson", "title": "A Novel Approach to Formulae Production and Overconfidence Measurement\n  to Reduce Risk in Spreadsheet Modelling", "comments": "12 pages, 7 figures", "journal-ref": "Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2004 71-83\n  ISBN 1 902724 94 1", "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on formulae production in spreadsheets has established the practice\nas high risk yet unrecognised as such by industry. There are numerous software\napplications that are designed to audit formulae and find errors. However these\nare all post creation, designed to catch errors before the spreadsheet is\ndeployed. As a general conclusion from EuSpRIG 2003 conference it was decided\nthat the time has come to attempt novel solutions based on an understanding of\nhuman factors. Hence in this paper we examine one such possibility namely a\nnovel example driven modelling approach. We discuss a control experiment that\ncompares example driven modelling against traditional approaches over several\nprogressively more difficult tests. The results are very interesting and\ncertainly point to the value of further investigation of the example driven\npotential. Lastly we propose a method for statistically analysing the problem\nof overconfidence in spreadsheet modellers.\n", "versions": [{"version": "v1", "created": "Wed, 12 Mar 2008 11:47:41 GMT"}], "update_date": "2008-03-13", "authors_parsed": [["Thorne", "Simon", ""], ["Ball", "David", ""], ["Lawson", "Zoe", ""]]}, {"id": "0803.1862", "submitter": "Grenville Croll", "authors": "Simon Thorne, David Ball", "title": "Exploring Human Factors in Spreadsheet Development", "comments": "11 pages, 3 figures, 2 tables", "journal-ref": "Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2005 161-172\n  ISBN:1-902724-16-X", "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider human factors and their impact on spreadsheet\ndevelopment in strategic decision-making. This paper brings forward research\nfrom many disciplines both directly related to spreadsheets and a broader\nspectrum from psychology to industrial processing. We investigate how human\nfactors affect a simplified development cycle and what the potential\nconsequences are.\n", "versions": [{"version": "v1", "created": "Wed, 12 Mar 2008 22:09:59 GMT"}], "update_date": "2008-03-14", "authors_parsed": [["Thorne", "Simon", ""], ["Ball", "David", ""]]}, {"id": "0803.3231", "submitter": "Grenville Croll", "authors": "Victoria Lemieux", "title": "Archiving: The Overlooked Spreadsheet Risk", "comments": "16 Pages. Recovered by OCR from paper conference proceedings", "journal-ref": "Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2005 213-226\n  ISBN:1-902724-16-X", "doi": null, "report-no": null, "categories": "cs.SE cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper maintains that archiving has been overlooked as a key spreadsheet\ninternal control. The case of failed Jamaican commercial banks demonstrates how\npoor archiving can lead to weaknesses in spreadsheet control that contribute to\noperational risk. In addition, the Sarbanes-0xley Act contains a number of\nprovisions that require tighter control over the archiving of spreadsheets. To\nmitigate operational risks and achieve compliance with the records-related\nprovisions of Sarbanes-Oxley, the author argues that organisations should\nintroduce records management programmes that provide control over the archiving\nof spreadsheets. At a minimum, spreadsheet archiving controls should identify\nand ensure compliance with retention requirements, support document production\nin the event of regulatory inquiries or litigation, and prevent unauthorised\ndestruction of records.\n", "versions": [{"version": "v1", "created": "Fri, 21 Mar 2008 21:35:40 GMT"}], "update_date": "2008-03-25", "authors_parsed": [["Lemieux", "Victoria", ""]]}, {"id": "0803.3482", "submitter": "Tad Hogg", "authors": "Tad Hogg and Gabor Szabo", "title": "Diversity of Online Community Activities", "comments": "14 pages", "journal-ref": null, "doi": "10.1209/0295-5075/86/38003", "report-no": null, "categories": "cs.CY cs.HC physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web sites where users create and rate content as well as form networks with\nother users display long-tailed distributions in many aspects of behavior.\nUsing behavior on one such community site, Essembly, we propose and evaluate\nplausible mechanisms to explain these behaviors. Unlike purely descriptive\nmodels, these mechanisms rely on user behaviors based on information available\nlocally to each user. For Essembly, we find the long-tails arise from large\ndifferences among user activity rates and qualities of the rated content, as\nwell as the extensive variability in the time users devote to the site. We show\nthat the models not only explain overall behavior but also allow estimating the\nquality of content from their early behaviors.\n", "versions": [{"version": "v1", "created": "Tue, 25 Mar 2008 00:23:05 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Hogg", "Tad", ""], ["Szabo", "Gabor", ""]]}, {"id": "0803.4018", "submitter": "Jose Javier Ramasco", "authors": "Bruno Goncalves, Jose J. Ramasco", "title": "Human dynamics revealed through Web analytics", "comments": "7 pages, 8 figures", "journal-ref": "Physical Review E 78, 026123 (2008)", "doi": "10.1103/PhysRevE.78.026123", "report-no": null, "categories": "cs.HC cond-mat.stat-mech cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When the World Wide Web was first conceived as a way to facilitate the\nsharing of scientific information at the CERN (European Center for Nuclear\nResearch) few could have imagined the role it would come to play in the\nfollowing decades. Since then, the increasing ubiquity of Internet access and\nthe frequency with which people interact with it raise the possibility of using\nthe Web to better observe, understand, and monitor several aspects of human\nsocial behavior. Web sites with large numbers of frequently returning users are\nideal for this task. If these sites belong to companies or universities, their\nusage patterns can furnish information about the working habits of entire\npopulations. In this work, we analyze the properly anonymized logs detailing\nthe access history to Emory University's Web site. Emory is a medium size\nuniversity located in Atlanta, Georgia. We find interesting structure in the\nactivity patterns of the domain and study in a systematic way the main forces\nbehind the dynamics of the traffic. In particular, we show that both linear\npreferential linking and priority based queuing are essential ingredients to\nunderstand the way users navigate the Web.\n", "versions": [{"version": "v1", "created": "Thu, 27 Mar 2008 21:19:54 GMT"}, {"version": "v2", "created": "Wed, 21 May 2008 17:39:20 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Goncalves", "Bruno", ""], ["Ramasco", "Jose J.", ""]]}]