[{"id": "1909.00045", "submitter": "Chuanmin Mi", "authors": "Chunmin Mi, Runjie Xu, Ching-Torng Lin, Run Yu Meng", "title": "An active smartphone authentication method based on daily cyclical\n  activity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smartphones have become an important tool for people's daily lives, which\nbrings higher security requirements in high-risk application areas, for\nexample, mobile payment. Although the combination of physical password,\nfingerprint and facial recognition have improved the security to a certain\nextent, there still exists a high risk of being decrepted. This paper attempts\nan algorithm which is more suitable for studying human partial periodic\nactivity, namely Prophet algorithm. This algorithm has strong robustness for\nmissing data and trend change, and can deal with outliers well. The\nexperimental results on the UniMiB SHAR DATA show that the user simply needs to\ndo 5 cycles of specified actions to realize the prediction of the next time\nseries. The Error analysis of cross validation was applied to 4 different\nindicators, and the Mean Squared Error of the optimal result \"Jumping\" behavior\nwas only 8.20%. With these appealing features, The main contribution of this\npaper is to propose a smart phone user identification system based on\nbehavioral activity cycle, which can be replicated in other behavioral studies.\nAnother outstanding feature of such a system is the capability of fitting\nmodels using small data set by exploiting behavioral characteristics derived\nfrom periodicity and thus reducing dependence on sensor scanning frequency,\ntherefore the system balances among energy consumption, data quantity and\nfitting accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 19:33:18 GMT"}, {"version": "v2", "created": "Sun, 8 Mar 2020 08:11:30 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Mi", "Chunmin", ""], ["Xu", "Runjie", ""], ["Lin", "Ching-Torng", ""], ["Meng", "Run Yu", ""]]}, {"id": "1909.00056", "submitter": "Nicolas Papernot", "authors": "Dan Boneh and Andrew J. Grotto and Patrick McDaniel and Nicolas\n  Papernot", "title": "How Relevant is the Turing Test in the Age of Sophisbots?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Popular culture has contemplated societies of thinking machines for\ngenerations, envisioning futures from utopian to dystopian. These futures are,\narguably, here now-we find ourselves at the doorstep of technology that can at\nleast simulate the appearance of thinking, acting, and feeling. The real\nquestion is: now what?\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 20:18:18 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Boneh", "Dan", ""], ["Grotto", "Andrew J.", ""], ["McDaniel", "Patrick", ""], ["Papernot", "Nicolas", ""]]}, {"id": "1909.00066", "submitter": "Amanda Coston", "authors": "Amanda Coston, Alan Mishler, Edward H. Kennedy, Alexandra Chouldechova", "title": "Counterfactual Risk Assessments, Evaluation, and Fairness", "comments": "To appear in ACM FAT* 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic risk assessments are increasingly used to help humans make\ndecisions in high-stakes settings, such as medicine, criminal justice and\neducation. In each of these cases, the purpose of the risk assessment tool is\nto inform actions, such as medical treatments or release conditions, often with\nthe aim of reducing the likelihood of an adverse event such as hospital\nreadmission or recidivism. Problematically, most tools are trained and\nevaluated on historical data in which the outcomes observed depend on the\nhistorical decision-making policy. These tools thus reflect risk under the\nhistorical policy, rather than under the different decision options that the\ntool is intended to inform. Even when tools are constructed to predict risk\nunder a specific decision, they are often improperly evaluated as predictors of\nthe target outcome.\n  Focusing on the evaluation task, in this paper we define counterfactual\nanalogues of common predictive performance and algorithmic fairness metrics\nthat we argue are better suited for the decision-making context. We introduce a\nnew method for estimating the proposed metrics using doubly robust estimation.\nWe provide theoretical results that show that only under strong conditions can\nfairness according to the standard metric and the counterfactual metric\nsimultaneously hold. Consequently, fairness-promoting methods that target\nparity in a standard fairness metric may --- and as we show empirically, do ---\ninduce greater imbalance in the counterfactual analogue. We provide empirical\ncomparisons on both synthetic data and a real world child welfare dataset to\ndemonstrate how the proposed method improves upon standard practice.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 20:47:20 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 15:15:16 GMT"}, {"version": "v3", "created": "Fri, 10 Jan 2020 14:08:46 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Coston", "Amanda", ""], ["Mishler", "Alan", ""], ["Kennedy", "Edward H.", ""], ["Chouldechova", "Alexandra", ""]]}, {"id": "1909.00077", "submitter": "Lun Wang", "authors": "Lun Wang and Joseph P. Near and Neel Somani and Peng Gao and Andrew\n  Low and David Dao and Dawn Song", "title": "Data Capsule: A New Paradigm for Automatic Compliance with Data Privacy\n  Regulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing pace of data collection has led to increasing awareness of\nprivacy risks, resulting in new data privacy regulations like General data\nProtection Regulation (GDPR). Such regulations are an important step, but\nautomatic compliance checking is challenging. In this work, we present a new\nparadigm, Data Capsule, for automatic compliance checking of data privacy\nregulations in heterogeneous data processing infrastructures. Our key insight\nis to pair up a data subject's data with a policy governing how the data is\nprocessed. Specified in our formal policy language: PrivPolicy, the policy is\ncreated and provided by the data subject alongside the data, and is associated\nwith the data throughout the life-cycle of data processing (e.g., data\ntransformation by data processing systems, data aggregation of multiple data\nsubjects' data). We introduce a solution for static enforcement of privacy\npolicies based on the concept of residual policies, and present a novel\nalgorithm based on abstract interpretation for deriving residual policies in\nPrivPolicy. Our solution ensures compliance automatically, and is designed for\ndeployment alongside existing infrastructure. We also design and develop\nPrivGuard, a reference data capsule manager that implements all the\nfunctionalities of Data Capsule paradigm.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 21:58:07 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Wang", "Lun", ""], ["Near", "Joseph P.", ""], ["Somani", "Neel", ""], ["Gao", "Peng", ""], ["Low", "Andrew", ""], ["Dao", "David", ""], ["Song", "Dawn", ""]]}, {"id": "1909.00130", "submitter": "Zahra Namazian Miss", "authors": "Zahra Namazian, Emad Roghanian", "title": "A decision problem for bank branch site selection: A GIS Mapping\n  perspective with Maximal Covering Location Problem: A case study of Isfahan,\n  Iran", "comments": null, "journal-ref": null, "doi": "10.1504/IJSOM.2021.116106", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most significant decision-making processes is the site selection.\nIf the site correctly selected, the access for the best customers as well as\nthe greatest market potential would be guaranteed. Bank branch optimal location\nis one of the most significant strategic issues in the competitive market\nespecially for private banks because of the global competition and high\ncustomer expectations. This study presents a Geographic Information System\n(GIS) based model for locating suitable sites for making new branches by using\ndata sources. Also, Maximal Covering Location Problem (MCLP) was used to select\nbranches that the maximum demand might be reached within a pre-specified target\ntravel time. The model was implemented for Ansar bank in Isfahan, Iran. The\ncriteria were restricted through demographic attributes, competition,\ntransportation, flexibility and cost in GIS mapping approach. Finally, the\nresults illustrated the efficiency and applicability of the proposed integrated\nmethod.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 05:13:43 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Namazian", "Zahra", ""], ["Roghanian", "Emad", ""]]}, {"id": "1909.00413", "submitter": "Hong-Ning Dai Prof.", "authors": "Hong-Ning Dai and Hao Wang and Guangquan Xu and Jiafu Wan and Muhammad\n  Imran", "title": "Big Data Analytics for Manufacturing Internet of Things: Opportunities,\n  Challenges and Enabling Technologies", "comments": "14 pages, 6 figures, 3 tables", "journal-ref": "Enterprise Information Systems, 2019", "doi": "10.1080/17517575.2019.1633689", "report-no": null, "categories": "cs.CY cs.AI cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The recent advances in information and communication technology (ICT) have\npromoted the evolution of conventional computer-aided manufacturing industry to\nsmart data-driven manufacturing. Data analytics in massive manufacturing data\ncan extract huge business values while can also result in research challenges\ndue to the heterogeneous data types, enormous volume and real-time velocity of\nmanufacturing data. This paper provides an overview on big data analytics in\nmanufacturing Internet of Things (MIoT). This paper first starts with a\ndiscussion on necessities and challenges of big data analytics in manufacturing\ndata of MIoT. Then, the enabling technologies of big data analytics of\nmanufacturing data are surveyed and discussed. Moreover, this paper also\noutlines the future directions in this promising area.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 14:53:16 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Dai", "Hong-Ning", ""], ["Wang", "Hao", ""], ["Xu", "Guangquan", ""], ["Wan", "Jiafu", ""], ["Imran", "Muhammad", ""]]}, {"id": "1909.00464", "submitter": "Kathleen Gregory", "authors": "Kathleen Gregory, Paul Groth, Andrea Scharnhorst, Sally Wyatt", "title": "Lost or found? Discovering data needed for research", "comments": "Harvard Data Science Review (2020)", "journal-ref": null, "doi": "10.1162/99608f92.e38165eb", "report-no": null, "categories": "cs.DL cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Finding data is a necessary precursor to being able to reuse data, although\nrelatively little large-scale empirical evidence exists about how researchers\ndiscover, make sense of and (re)use data for research. This study presents\nevidence from the largest known survey investigating how researchers discover\nand use data that they do not create themselves. We examine the data needs and\ndiscovery strategies of respondents, propose a typology for data reuse and\nprobe the role of social interactions and literature search in data discovery.\nWe consider how data communities can be conceptualized according to data uses\nand propose practical applications of our findings for designers of data\ndiscovery systems and repositories. Specifically, we consider how to design for\na diversity of practices, how communities of use can serve as an entry point\nfor design and the role of metadata in supporting both sensemaking and social\ninteractions.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 19:56:00 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 12:35:48 GMT"}, {"version": "v3", "created": "Thu, 2 Apr 2020 16:07:10 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Gregory", "Kathleen", ""], ["Groth", "Paul", ""], ["Scharnhorst", "Andrea", ""], ["Wyatt", "Sally", ""]]}, {"id": "1909.00554", "submitter": "Yoshifumi Seki", "authors": "Yoshifumi Seki, Mitsuo Yoshida", "title": "Analysis of Bias in Gathering Information Between User Attributes in\n  News Application", "comments": "8 pages, 13 figure, IEEE BigData 2018 Workshop : The 3rd\n  International Workshop on Application of Big Data for Computational Social\n  Science (ABCSS2018)", "journal-ref": null, "doi": "10.1109/bigdata.2018.8622482", "report-no": null, "categories": "cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the process of information gathering on the web, confirmation bias is\nknown to exist, exemplified in phenomena such as echo chambers and filter\nbubbles. Our purpose is to reveal how people consume news and discuss these\nphenomena. In web services, we are able to use action logs of a service to\ninvestigate these phenomena. However, many existing studies about these\nphenomena are conducted via questionnaires, and there are few studies using\naction logs. In this paper, we attempt to discover biases of information\ngathering due to differences in user demographic attributes, such as age and\ngender, from the behavior log of the news distribution service. First, we\nsummarized the actions in the service for each user attribute and showed the\ndifference of user behavior depending on the attributes. Next, the degree of\ncorrelation between the attributes was measured using the correlation\ncoefficient, and a strong correlation was found to exist in the browsing\ntendency of the news articles between the attributes. Then, the bias of\nkeywords between attributes was discovered, keywords with bias in behavior\namong the attributes were found using parameters of regression analysis. Since\nthese discovered keywords are almost explainable by big news, our proposed\nmethod is effective in detecting biased keywords.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 05:44:59 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Seki", "Yoshifumi", ""], ["Yoshida", "Mitsuo", ""]]}, {"id": "1909.00699", "submitter": "Federica Paganelli", "authors": "Federica Paganelli, Georgios Mylonas, Giovanni Cuffaro, and Ilaria\n  Nesi", "title": "Experiences from Using Gamification and IoT-based Educational Tools in\n  High Schools towards Energy Savings", "comments": "to be presented at 2019 European Conference on Ambient Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Raising awareness among young people, and especially students, on the\nrelevance of behavior change for achieving energy savings is increasingly being\nconsidered as a key enabler towards long-term and cost-effective energy\nefficiency policies. However, the way to successfully apply educational\ninterventions focused on such targets inside schools is still an open question.\nIn this paper, we present our approach for enabling IoT-based energy savings\nand sustainability awareness lectures and promoting data-driven energy-saving\nbehaviors focused on a high school audience. We present our experiences toward\nthe successful application of sets of educational tools and software over a\nreal-world Internet of Things (IoT) deployment. We discuss the use of\ngamification and competition as a very effective end-user engagement mechanism\nfor school audiences. We also present the design of an IoT-based hands-on lab\nactivity, integrated within a high school computer science curricula utilizing\nIoT devices and data produced inside the school building, along with the\nNode-RED platform. We describe the tools used, the organization of the\neducational activities and related goals. We report on the experience carried\nout in both directions in a high school in Italy and conclude by discussing the\nresults in terms of achieved energy savings within an observation period.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 12:55:18 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Paganelli", "Federica", ""], ["Mylonas", "Georgios", ""], ["Cuffaro", "Giovanni", ""], ["Nesi", "Ilaria", ""]]}, {"id": "1909.00704", "submitter": "Giancarlo Ruffo", "authors": "Francesco Bergadano, Roberto Bertilone, Daniela Paolotti, Giancarlo\n  Ruffo", "title": "Learning Real Estate Automated Valuation Models from Heterogeneous Data\n  Sources", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real estate appraisal is a complex and important task, that can be made more\nprecise and faster with the help of automated valuation tools. Usually the\nvalue of some property is determined by taking into account both structural and\ngeographical characteristics. However, while geographical information is easily\nfound, obtaining significant structural information requires the intervention\nof a real estate expert, a professional appraiser. In this paper we propose a\nWeb data acquisition methodology, and a Machine Learning model, that can be\nused to automatically evaluate real estate properties. This method uses data\nfrom previous appraisal documents, from the advertised prices of similar\nproperties found via Web crawling, and from open data describing the\ncharacteristics of a corresponding geographical area. We describe a case study,\napplicable to the whole Italian territory, and initially trained on a data set\nof individual homes located in the city of Turin, and analyze prediction and\npractical applicability.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 13:16:51 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Bergadano", "Francesco", ""], ["Bertilone", "Roberto", ""], ["Paolotti", "Daniela", ""], ["Ruffo", "Giancarlo", ""]]}, {"id": "1909.00805", "submitter": "Liu Yimeng", "authors": "Yimeng Liu, Zhiwen Yu, Bin Guo, Qi Han, Jiangbin Su, Jiahao Liao", "title": "CrowdOS: A Ubiquitous Operating System for Crowdsourcing and Mobile\n  Crowd Sensing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.OS cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rise of crowdsourcing and mobile crowdsensing techniques, a large\nnumber of crowdsourcing applications or platforms (CAP) have appeared. In the\nmean time, CAP-related models and frameworks based on different research\nhypotheses are rapidly emerging, and they usually address specific issues from\na certain perspective. Due to different settings and conditions, different\nmodels are not compatible with each other. However, CAP urgently needs to\ncombine these techniques to form a unified framework. In addition, these models\nneeds to be learned and updated online with the extension of crowdsourced data\nand task types, thus requiring a unified architecture that integrates lifelong\nlearning concepts and breaks down the barriers between different modules. This\npaper draws on the idea of ubiquitous operating systems and proposes a novel OS\n(CrowdOS), which is an abstract software layer running between native OS and\napplication layer. In particular, based on an in-depth analysis of the complex\ncrowd environment and diverse characteristics of heterogeneous tasks, we\nconstruct the OS kernel and three core frameworks including Task Resolution and\nAssignment Framework (TRAF), Integrated Resource Management (IRM), and Task\nResult quality Optimization (TRO). In addition, we validate the usability of\nCrowdOS, module correctness and development efficiency. Our evaluation further\nreveals TRO brings enormous improvement in efficiency and a reduction in energy\nconsumption.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 17:28:05 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Liu", "Yimeng", ""], ["Yu", "Zhiwen", ""], ["Guo", "Bin", ""], ["Han", "Qi", ""], ["Su", "Jiangbin", ""], ["Liao", "Jiahao", ""]]}, {"id": "1909.00855", "submitter": "Roger Turner", "authors": "Roger Turner", "title": "Defining and Adopting an End User Computing Policy: A Case Study", "comments": "25 Pages, 12 Colour Figures. 1 Table. First presented at the EuSpRIG\n  2018 Conference at Imperial College, London. Revised and updated following a\n  further presentation at the EuSpRIG 2019 Conference also at Imperial College,\n  London", "journal-ref": "Proceedings of the EuSpRIG 2019 Conference \"Spreadsheet Risk\n  Management\", Browns, Covent Garden, London, pp27-38, ISBN: 978-1-905404-56-8", "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End User Computing carries significant risks if not well controlled. This\npaper is a case study of the introduction of an updated End User Computing\npolicy at the Wesleyan Assurance Society. The paper outlines the plan and\nidentifies various challenges. The paper explains how these challenges were\novercome. We wrote an End User Computing Risk Assessment Application which\ncalculates a risk rating band based on the Complexity, Materiality and Control\n(or lack of it) pertaining to any given application and the basis of assessment\nis given in this paper. The policy uses a risk based approach for assessing and\nmitigating against the highest risks first and obtaining the quickest benefit.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 20:36:10 GMT"}, {"version": "v2", "created": "Sun, 22 Nov 2020 23:39:04 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Turner", "Roger", ""]]}, {"id": "1909.00871", "submitter": "Rowan Hall Maudslay", "authors": "Rowan Hall Maudslay, Hila Gonen, Ryan Cotterell, Simone Teufel", "title": "It's All in the Name: Mitigating Gender Bias with Name-Based\n  Counterfactual Data Substitution", "comments": "Correction to proof in appendix and minor changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper treats gender bias latent in word embeddings. Previous mitigation\nattempts rely on the operationalisation of gender bias as a projection over a\nlinear subspace. An alternative approach is Counterfactual Data Augmentation\n(CDA), in which a corpus is duplicated and augmented to remove bias, e.g. by\nswapping all inherently-gendered words in the copy. We perform an empirical\ncomparison of these approaches on the English Gigaword and Wikipedia, and find\nthat whilst both successfully reduce direct bias and perform well in tasks\nwhich quantify embedding quality, CDA variants outperform projection-based\nmethods at the task of drawing non-biased gender analogies by an average of 19%\nacross both corpora. We propose two improvements to CDA: Counterfactual Data\nSubstitution (CDS), a variant of CDA in which potentially biased text is\nrandomly substituted to avoid duplication, and the Names Intervention, a novel\nname-pairing technique that vastly increases the number of words being treated.\nCDA/S with the Names Intervention is the only approach which is able to\nmitigate indirect gender bias: following debiasing, previously biased words are\nsignificantly less clustered according to gender (cluster purity is reduced by\n49%), thus improving on the state-of-the-art for bias mitigation.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 21:33:03 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 19:37:55 GMT"}, {"version": "v3", "created": "Wed, 5 Feb 2020 12:11:16 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Maudslay", "Rowan Hall", ""], ["Gonen", "Hila", ""], ["Cotterell", "Ryan", ""], ["Teufel", "Simone", ""]]}, {"id": "1909.00955", "submitter": "Kien Nguyen", "authors": "Kien Nguyen, Jingyun Yang, Yijun Lin, Jianfa Lin, Yao-Yi Chiang, Cyrus\n  Shahabi", "title": "Los Angeles Metro Bus Data Analysis Using GPS Trajectory and Schedule\n  Data (Demo Paper)", "comments": "SIGSPATIAL'18, demo paper, 4 pages", "journal-ref": "26th ACM SIGSPATIAL International Conference on Advances in\n  Geographic Information Systems (SIGSPATIAL '18), 2018", "doi": "10.1145/3274895.3274911", "report-no": null, "categories": "cs.DB cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the widespread installation of location-enabled devices on public\ntransportation, public vehicles are generating massive amounts of trajectory\ndata in real time. However, using these trajectory data for meaningful analysis\nrequires careful considerations in storing, managing, processing, and\nvisualizing the data. Using the location data of the Los Angeles Metro bus\nsystem, along with publicly available bus schedule data, we conduct a data\nprocessing and analyses study to measure the performance of the public\ntransportation system in Los Angeles utilizing a number of metrics including\ntravel-time reliability, on-time performance, bus bunching, and travel-time\nestimation. We demonstrate the visualization of the data analysis results\nthrough an interactive web-based application. The developed algorithms and\nsystem provide powerful tools to detect issues and improve the efficiency of\npublic transportation systems.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 05:01:44 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Nguyen", "Kien", ""], ["Yang", "Jingyun", ""], ["Lin", "Yijun", ""], ["Lin", "Jianfa", ""], ["Chiang", "Yao-Yi", ""], ["Shahabi", "Cyrus", ""]]}, {"id": "1909.01020", "submitter": "Mattia Antonini", "authors": "Mattia Antonini, Massimo Vecchio, Fabio Antonelli", "title": "Fog Computing Architectures: a Reference for Practitioners", "comments": "Accepted for Publication in IEEE Internet of Things Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Soon after realizing that Cloud Computing could indeed help several\nindustries overcome classical product-centric approaches in favor of more\naffordable service-oriented business models, we are witnessing the rise of a\nnew disruptive computing paradigm, namely Fog Computing. Essentially, Fog\nComputing can be considered as an evolution of Cloud Computing, in the sense\nthat the former extends the latter to the edge of the network (that is, where\nthe connected devices -- the things -- are) without discontinuity, realizing\nthe so-called \"cloud-to-thing continuum\". Since its infancy, Fog Computing has\nbeen considered as a necessity within several Internet of Things (IoT) domains\n(one for all: Industrial IoT) and, more generally, wherever embedded artificial\nintelligence and/or more advanced distributed capabilities were required. Fog\nComputing cannot be considered only a fancy buzzword: according to separate,\nauthoritative analyses its global market will reach $18 billion by 2022, while\nnearly 45% of the world's data will be moved to the network edge by 2025. In\nthis paper, we take stock of the situation, summarizing the most modern and\nmature Fog Computing initiatives from standardization, commercial, and\nopen-source communities perspectives.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 09:37:28 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Antonini", "Mattia", ""], ["Vecchio", "Massimo", ""], ["Antonelli", "Fabio", ""]]}, {"id": "1909.01086", "submitter": "Tajul Rosli Razak Mr", "authors": "Tajul Rosli Razak, Abdul Hapes Mohammed, Noorfaizalfarid Mohd Noor,\n  Muhamad Arif Hashim", "title": "Automated Data Integration, Cleaning and Analysis Using Data Mining and\n  SPSS Tool For Technical School in Malaysia", "comments": null, "journal-ref": "International Journal of Computer Science and Security (IJCSS\n  2012)", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study aims to integrate, clean and analysis through automated data\nmining techniques. Using data mining (DM) techniques is one of the processes of\ntransferring raw data from current educational system to meaningful information\nthat can be used to help the school community to make a right decision to\nachieve much better results. This proved DM provides means to assist both\neducators and students, and improve the quality of education. The result and\nfindings in the study show that automated system will give the same result\ncompare with manual system of integration and analysis and also could be used\nby the management to make faster and more efficient decision in order to map or\nplan efficient teaching approach for students in the future.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 08:38:13 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Razak", "Tajul Rosli", ""], ["Mohammed", "Abdul Hapes", ""], ["Noor", "Noorfaizalfarid Mohd", ""], ["Hashim", "Muhamad Arif", ""]]}, {"id": "1909.01091", "submitter": "Projjal Gipta", "authors": "Projjal Gupta", "title": "Usage of Permissioned Blockchain Architecture for Big Data in Electronic\n  Medical Records", "comments": "4 pages, 3 figures, 3 Code Objects", "journal-ref": null, "doi": "10.13140/RG.2.2.26981.35048", "report-no": null, "categories": "cs.CY cs.CR cs.DB cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the advent of blockchain technology, multiple research avenues and\nplatforms for dialogue have opened up. However technology transfer to the pubic\nhas not been implemented, such that regular public can access and make use of\nsecure and decentralized software. Most blockchain solutions till date deal\nwith financial applications or monetary transactions, which may not be helpful\nor be accessible to the general public, especially the lower levels of the\nfinancial society. Medi-Chain is a people-first medical blockchain with a\nusable desktop application and interface which makes use of cutting-edge\nblockchain technology along with BFT consensus protocols to ensure highly\nsecure and private medical data records. This paper aims to bring about a\nchange in how blockchains-as-a-service is perceived and how adoption of new\ntechnology is largely based on usability and ease of adoption.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 10:06:57 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Gupta", "Projjal", ""]]}, {"id": "1909.01095", "submitter": "Jonas Schuett", "authors": "Jonas Schuett", "title": "A Legal Definition of AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When policy makers want to regulate AI, they must first define what AI is.\nHowever, legal definitions differ significantly from definitions of other\ndisciplines. They are working definitions. Courts must be able to determine\nprecisely whether or not a concrete system is considered AI by the law. In this\npaper we examine how policy makers should define the material scope of AI\nregulations. We argue that they should not use the term \"artificial\nintelligence\" for regulatory purposes because there is no definition of AI\nwhich meets the requirements for legal definitions. Instead, they should define\ncertain designs, use cases or capabilities following a risk-based approach. The\ngoal of this paper is to help policy makers who work on AI regulations.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 20:54:42 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Schuett", "Jonas", ""]]}, {"id": "1909.01202", "submitter": "Karanpreet Singh", "authors": "Karanpreet Singh and Rajen Bhatt", "title": "Personalizing Smartwatch Based Activity Recognition Using Transfer\n  Learning", "comments": "6 Pages, 6 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smartwatches are increasingly being used to recognize human daily life\nactivities. These devices may employ different kind of machine learning (ML)\nsolutions. One of such ML models is Gradient Boosting Machine (GBM) which has\nshown an excellent performance in the literature. The GBM can be trained on\navailable data set before it is deployed on any device. However, this data set\nmay not represent every kind of human behavior in real life. For example, a ML\nmodel to detect elder and young persons running activity may give different\nresults because of differences in their activity patterns. This may result in\ndecrease in the accuracy of activity recognition. Therefore, a transfer\nlearning based method is proposed in which user-specific performance can be\nimproved significantly by doing on-device calibration of GBM by just tuning its\nparameters without retraining its estimators. Results show that this method can\nsignificantly improve the user-based accuracy for activity recognition.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 14:13:49 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Singh", "Karanpreet", ""], ["Bhatt", "Rajen", ""]]}, {"id": "1909.01362", "submitter": "Jonathan Chang", "authors": "Jonathan P. Chang and Cristian Danescu-Niculescu-Mizil", "title": "Trouble on the Horizon: Forecasting the Derailment of Online\n  Conversations as they Develop", "comments": "To appear in Proceedings of EMNLP 2019. Data and code to be released\n  as part of the Cornell Conversational Analysis Toolkit (convokit.cornell.edu)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.HC physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online discussions often derail into toxic exchanges between participants.\nRecent efforts mostly focused on detecting antisocial behavior after the fact,\nby analyzing single comments in isolation. To provide more timely notice to\nhuman moderators, a system needs to preemptively detect that a conversation is\nheading towards derailment before it actually turns toxic. This means modeling\nderailment as an emerging property of a conversation rather than as an isolated\nutterance-level event.\n  Forecasting emerging conversational properties, however, poses several\ninherent modeling challenges. First, since conversations are dynamic, a\nforecasting model needs to capture the flow of the discussion, rather than\nproperties of individual comments. Second, real conversations have an unknown\nhorizon: they can end or derail at any time; thus a practical forecasting model\nneeds to assess the risk in an online fashion, as the conversation develops. In\nthis work we introduce a conversational forecasting model that learns an\nunsupervised representation of conversational dynamics and exploits it to\npredict future derailment as the conversation develops. By applying this model\nto two new diverse datasets of online conversations with labels for antisocial\nevents, we show that it outperforms state-of-the-art systems at forecasting\nderailment.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 18:00:05 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Chang", "Jonathan P.", ""], ["Danescu-Niculescu-Mizil", "Cristian", ""]]}, {"id": "1909.01474", "submitter": "Solomia Fedushko", "authors": "Solomiia Fedushko, Sofia Kolos", "title": "Effective Strategies for Using Hashtags in Online Communication", "comments": "9 pages, 8 figures", "journal-ref": "International Journal of Computing and Related Technologies,\n  Volume 2, Issue 2, 2019", "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The features of use of hashtags among students of Lviv were investigated. The\nlist of optimal strategies for using these communicative tools for personal\nbranding is determined. The effective strategy for using hashtags in online\ncommunication for the personal and company branding is considered. The results\nof calculation of effectiveness of hashtags related to #education is\ncalculated. The reports of using hashtag #education in social networks is\npresented.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 22:20:24 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Fedushko", "Solomiia", ""], ["Kolos", "Sofia", ""]]}, {"id": "1909.01495", "submitter": "Bibek Paudel", "authors": "Bibek Paudel, Abraham Bernstein", "title": "Cross-Cutting Political Awareness through Diverse News Recommendations", "comments": "European Symposium Series on Societal Challenges in Computational\n  Social Science, Zurich, Switzerland, September 2nd-4th, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The suggestions generated by most existing recommender systems are known to\nsuffer from a lack of diversity, and other issues like popularity bias. As a\nresult, they have been observed to promote well-known \"blockbuster\" items, and\nto present users with \"more of the same\" choices that entrench their existing\nbeliefs and biases. This limits users' exposure to diverse viewpoints and\npotentially increases political polarization. To promote the diversity of\nviews, we developed a novel computational framework that can identify the\npolitical leanings of users and the news items they share on online social\nnetworks. Based on such information, our system can recommend news items that\npurposefully expose users to different viewpoints and increase the diversity of\ntheir information \"diet.\" Our research on recommendation diversity and\npolitical polarization helps us to develop algorithms that measure each user's\nreaction %to diverse viewpoints and adjust the recommendation accordingly. The\nresult is an approach that exposes users to a variety of political views and\nwill, hopefully, broaden their acceptance (not necessarily the agreement) of\nvarious opinions.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 23:09:25 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Paudel", "Bibek", ""], ["Bernstein", "Abraham", ""]]}, {"id": "1909.01677", "submitter": "Solomia Fedushko", "authors": "Solomia Fedushko, Olha Trach, Zoryana Kunch, Yaryna Turchyn, Ulyana\n  Yarka", "title": "Modelling the Behavior Classification of Social News Aggregations Users", "comments": "15 pages, 2 figures", "journal-ref": "CEUR Workshop Proceedings. Vol 2392: Proceedings of the 1st\n  International Workshop on Control, Optimisation and Analytical Processing of\n  Social Networks, COAPSN-2019, 2019", "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with actual fuzzy logic approach for modelling the behavior\nclassification of social news aggregations users. The peculiarities of the\nstructure of informational content of communities on the basis of social news\naggregations are explored. A formal model of social news aggregation model has\nbeen developed, which includes user of the social news aggregation on the basis\nof fuzzy measures of its characteristics. The method of behavioral\nclassification of users and methods for structuring sections and discussions of\nsocial news aggregations are developed. The methods for determining the main\ncharacteristics of the users of the social news aggregation: activeness,\ncreativeness, attractiveness, reactiveness, loyalty, is developed. Method for\ndefining characteristics and classification of social news aggregations users\nis presented.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 10:18:25 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Fedushko", "Solomia", ""], ["Trach", "Olha", ""], ["Kunch", "Zoryana", ""], ["Turchyn", "Yaryna", ""], ["Yarka", "Ulyana", ""]]}, {"id": "1909.01681", "submitter": "Solomia Fedushko", "authors": "Artem Zakharchenko, Yuliia Maksimtsova, Valentyn Iurchenko, Viktoriya\n  Shevchenko, Solomiia Fedushko", "title": "Under the Conditions of Non-Agenda Ownership: Social Media Users in the\n  2019 Ukrainian Presidential Elections Campaign", "comments": "21 pages, 8 figures", "journal-ref": "CEUR Workshop Proceedings. Vol 2392: Proceedings of the 1st\n  International Workshop on Control, Optimisation and Analytical Processing of\n  Social Networks, COAPSN-2019, 2019", "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Owing to its history and challenging circumstances, social networks community\nin Ukraine is a very interesting polygon for the study of communications in the\nconstantly changing environment, especially in the political discourse. This\nunique environment requires three dimensions to ascertain the political\nposition of its participant. But 2019 presidential elections made this object\neven more spectacular. The winner of elections comedian Volodymyr Zelenskyi\nreached 73% of votes without any issue ownership, with empty agenda, and this\ninfluenced the electoral content of social networks and their authors behavior.\nWe saw, that the issue ownership by other candidates succeeds in making their\nissues more salient in social networks. But the new phenomena, the non-agenda\nownership, overcome any ideological influence, especially under the conditions\nof punishment mechanism applied to old politicians. Analyzing social media\ncontent and users behavior in the period between two rounds of elections, we\nfound considerable overlaps between this campaign and the 2016 Trump campaign.\nWe approved the widespread of filter bubbles, negative campaign messages, fake\nnews and conspiracy theories. Active and powerful core of Ukrainian Facebook\nthat was responsible for the Revolution of dignity now became less significant\nand even turns into the huge filter bubble of active people. We also proved\nthat manipulations and fake news in the environment of private groups may be as\nmuch powerful as in a case of classical communication based around the opinion\nleaders.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 10:30:03 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Zakharchenko", "Artem", ""], ["Maksimtsova", "Yuliia", ""], ["Iurchenko", "Valentyn", ""], ["Shevchenko", "Viktoriya", ""], ["Fedushko", "Solomiia", ""]]}, {"id": "1909.01806", "submitter": "Esdras Bispo Jr", "authors": "Esdras Lins Bispo Jr", "title": "Epistemological Issues in Educational Data Mining", "comments": "10 pages, in Portuguese. Brazilian Symposium on Computers in\n  Education", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Educational Data Mining (EDM) shows interesting scientific results lately.\nHowever, little has been discussed about philosophical questions regarding the\ntype of knowledge produced in this area. This paper aims to present two\nepistemological issues in EDM: (i) a question of ontological nature about the\ncontent of the knowledge obtained; and (ii) a question of deontological nature,\nabout the guidelines and principles adopted by the researcher in education, to\nthe detriment of the results of his own research. In the end, some\nconsiderations and guidelines are outlined as a result of the discussion of the\nissues raised.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 13:56:31 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Bispo", "Esdras Lins", "Jr"]]}, {"id": "1909.02126", "submitter": "Aida Mostafazadeh Davani", "authors": "Aida Mostafazadeh Davani, Leigh Yeh, Mohammad Atari, Brendan Kennedy,\n  Gwenyth Portillo-Wightman, Elaine Gonzalez, Natalie Delong, Rhea Bhatia,\n  Arineh Mirinjian, Xiang Ren, Morteza Dehghani", "title": "Reporting the Unreported: Event Extraction for Analyzing the Local\n  Representation of Hate Crimes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Official reports of hate crimes in the US are under-reported relative to the\nactual number of such incidents. Further, despite statistical approximations,\nthere are no official reports from a large number of US cities regarding\nincidents of hate. Here, we first demonstrate that event extraction and\nmulti-instance learning, applied to a corpus of local news articles, can be\nused to predict instances of hate crime. We then use the trained model to\ndetect incidents of hate in cities for which the FBI lacks statistics. Lastly,\nwe train models on predicting homicide and kidnapping, compare the predictions\nto FBI reports, and establish that incidents of hate are indeed under-reported,\ncompared to other types of crimes, in local press.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 21:45:51 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Davani", "Aida Mostafazadeh", ""], ["Yeh", "Leigh", ""], ["Atari", "Mohammad", ""], ["Kennedy", "Brendan", ""], ["Portillo-Wightman", "Gwenyth", ""], ["Gonzalez", "Elaine", ""], ["Delong", "Natalie", ""], ["Bhatia", "Rhea", ""], ["Mirinjian", "Arineh", ""], ["Ren", "Xiang", ""], ["Dehghani", "Morteza", ""]]}, {"id": "1909.02638", "submitter": "Christine Utz", "authors": "Christine Utz and Martin Degeling and Sascha Fahl and Florian Schaub\n  and Thorsten Holz", "title": "(Un)informed Consent: Studying GDPR Consent Notices in the Field", "comments": "18 pages, 6 figures, 2019 ACM SIGSAC Conference on Computer and\n  Communications Security (CCS '19), November 11-15, 2019, London, United\n  Kingdom", "journal-ref": null, "doi": "10.1145/3319535.3354212", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the adoption of the General Data Protection Regulation (GDPR) in May\n2018 more than 60 % of popular websites in Europe display cookie consent\nnotices to their visitors. This has quickly led to users becoming fatigued with\nprivacy notifications and contributed to the rise of both browser extensions\nthat block these banners and demands for a solution that bundles consent across\nmultiple websites or in the browser.\n  In this work, we identify common properties of the graphical user interface\nof consent notices and conduct three experiments with more than 80,000 unique\nusers on a German website to investigate the influence of notice position, type\nof choice, and content framing on consent. We find that users are more likely\nto interact with a notice shown in the lower (left) part of the screen. Given a\nbinary choice, more users are willing to accept tracking compared to mechanisms\nthat require them to allow cookie use for each category or company\nindividually. We also show that the wide-spread practice of nudging has a large\neffect on the choices users make. Our experiments show that seemingly small\nimplementation decisions can substantially impact whether and how people\ninteract with consent notices. Our findings demonstrate the importance for\nregulation to not just require consent, but also provide clear requirements or\nguidance for how this consent has to be obtained in order to ensure that users\ncan make free and informed choices.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 21:17:55 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 14:34:16 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Utz", "Christine", ""], ["Degeling", "Martin", ""], ["Fahl", "Sascha", ""], ["Schaub", "Florian", ""], ["Holz", "Thorsten", ""]]}, {"id": "1909.02914", "submitter": "Naveed  Ul Hassan", "authors": "Naveed UL Hassan, Chau Yuen, and Dusit Niyato", "title": "Blockchain Technologies for Smart Energy Systems: Fundamentals,\n  Challenges and Solutions", "comments": "Submitted to IEEE Industrial Electronics Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we discuss the integration of blockchain in smart energy\nsystems. We present various blockchain technology solutions, review important\nblockchain platforms, and several blockchain based smart energy projects in\ndifferent smart energy domains. The majority of blockchain platforms with\nembedded combination of blockchain technology solutions are computing- and\nresource- intensive, and hence not entirely suitable for smart energy\napplications. We consider the requirements of smart energy systems and\naccordingly identify appropriate blockchain technology solutions for smart\nenergy applications. Our analysis can help in the development of flexible\nblockchain platforms for smart energy systems.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 13:55:14 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Hassan", "Naveed UL", ""], ["Yuen", "Chau", ""], ["Niyato", "Dusit", ""]]}, {"id": "1909.03029", "submitter": "Dinesh Samuel Sathia Raj Mr.", "authors": "Dinesh Samuel Sathia Raj, Vijayakumar V, Bharat Rawal and Longzhi Yang", "title": "Analysis of Big Data Technology for Health Care Services", "comments": "Accepted at the International Conference on Intelligent Technologies\n  and Applications(INTAP) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning and other big data technologies have over time become very\npowerful and accurate. There are algorithms and models developed that have near\nhuman accuracy in their task. In health care, the amount of data available is\nmassive and hence, these technologies have a great scope in health care. This\npaper reviews a few interesting contributions to the field specifically to\nmedical imaging, genomics and patient health records.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 16:47:47 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Raj", "Dinesh Samuel Sathia", ""], ["V", "Vijayakumar", ""], ["Rawal", "Bharat", ""], ["Yang", "Longzhi", ""]]}, {"id": "1909.03032", "submitter": "Dustin Tanksley", "authors": "Dustin Tanksley, Donald C. Wunsch II", "title": "Reproducibility via Crowdsourced Reverse Engineering: A Neural Network\n  Case Study With DeepMind's Alpha Zero", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reproducibility of scientific findings are an important hallmark of\nquality and integrity in research. The scientific method requires hypotheses to\nbe subjected to the most crucial tests, and for the results to be consistent\nacross independent trials. Therefore, a publication is expected to provide\nsufficient information for an objective evaluation of its methods and claims.\nThis is particularly true for research supported by public funds, where\ntransparency of findings are a form of return on public investment.\nUnfortunately, many publications fall short of this mark for various reasons,\nincluding unavoidable ones such as intellectual property protection and\nnational security of the entity creating those findings. This is a particularly\nimportant and documented problem in medical research, and in machine learning.\nFortunately for those seeking to overcome these difficulties, the internet\nmakes it easier to share experiments, and allows for crowd-sourced reverse\nengineering. A case study of this capability in neural networks research is\npresented in this paper. The significant success of reverse-engineering the\nimportant accomplishments of DeepMind's Alpha Zero exemplifies the leverage\nthat can be achieved by a concerted effort to reproduce results.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 03:37:01 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 19:09:21 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Tanksley", "Dustin", ""], ["Wunsch", "Donald C.", "II"]]}, {"id": "1909.03033", "submitter": "Michael Mahoney", "authors": "Michael W. Mahoney", "title": "The Difficulties of Addressing Interdisciplinary Challenges at the\n  Foundations of Data Science", "comments": "Appearing in SIAM News, SIGACT News, etc", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The National Science Foundation's Transdisciplinary Research in Principles of\nData Science (TRIPODS) program aims to integrate three areas central to the\nfoundations of data by uniting the statistics, mathematics, and theoretical\ncomputer science research communities. The program aims to provide a model for\nfunding cross-cutting research and facilitating interactions among the three\ndisciplines. Challenges associated with orchestrating fruitful interactions are\ndescribed.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 06:07:26 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Mahoney", "Michael W.", ""]]}, {"id": "1909.03036", "submitter": "Michael Kl\\\"as", "authors": "Rasmus Adler, Mohammed Naveed Akram, Pascal Bauer, Patrik Feth, Pascal\n  Gerber, Andreas Jedlitschka, Lisa J\\\"ockel, Michael Kl\\\"as, Daniel Schneider", "title": "Hardening of Artificial Neural Networks for Use in Safety-Critical\n  Applications -- A Mapping Study", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context: Across different domains, Artificial Neural Networks (ANNs) are used\nmore and more in safety-critical applications in which erroneous outputs of\nsuch ANN can have catastrophic consequences. However, the development of such\nneural networks is still immature and good engineering practices are missing.\nWith that, ANNs are in the same position as software was several decades ago.\nToday, standards for functional safety, such as ISO 26262 in the automotive\ndomain, require the application of a collection of proven engineering\nprinciples and methods in the creation of software to increase its quality and\nreduce failure rates to an acceptable level. Objective: In the future, such a\nset of proven engineering methods needs to be established for the development\nof Artificial Neural Networks to allow their use in safety-critical\napplications. Method: This work takes a step in this direction by conducting a\nmapping study to extract challenges faced in the development of ANNs for\nsafety-critical applications and to identify methods that have been used for\nthe hardening of ANNs in such settings. Results: We extracted ten different\nchallenges found to be repeatedly reported in the literature regarding the use\nof ANNs in critical contexts. All of these challenges are addressed by\nengineering methods, of which we identified 54 in our study that can be used\nfor the hardening of networks. Conclusions: Various methods have been proposed\nto overcome the specific challenges of using ANNs in safety-critical\napplications. On the path towards defining best practices, we envision that\nfuture software engineering will need to focus on further investigating these\nmethods and increasing the maturity and understanding of existing approaches,\nwith the goal to develop clear guidance for proper engineering of high-quality\nANNs.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 09:36:24 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Adler", "Rasmus", ""], ["Akram", "Mohammed Naveed", ""], ["Bauer", "Pascal", ""], ["Feth", "Patrik", ""], ["Gerber", "Pascal", ""], ["Jedlitschka", "Andreas", ""], ["J\u00f6ckel", "Lisa", ""], ["Kl\u00e4s", "Michael", ""], ["Schneider", "Daniel", ""]]}, {"id": "1909.03040", "submitter": "Maksim Jenihhin", "authors": "Maksim Jenihhin, Matteo Sonza Reorda, Aneesh Balakrishnan, Dan\n  Alexandrescu", "title": "Challenges of Reliability Assessment and Enhancement in Autonomous\n  Systems", "comments": "The 32nd IEEE International Symposium on Defect and Fault Tolerance\n  in VLSI and Nanotechnology Systems (DFT'19), October 2 - October 4, 2019,\n  ESA-ESTEC and TU Delft, Netherlands", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The gigantic complexity and heterogeneity of today's advanced cyber-physical\nsystems and systems of systems is multiplied by the use of avant-garde\ncomputing architectures to employ artificial intelligence based autonomy in the\nsystem. Here, the overall system's reliability comes along with requirements\nfor fail-safe, fail-operational modes specific to the target applications of\nthe autonomous system and adopted HW architectures. The paper makes an overview\nof reliability challenges for intelligence implementation in autonomous systems\nenabled by HW backbones such as neuromorphic architectures, approximate\ncomputing architectures, GPUs, tensor processing units (TPUs) and SoC FPGAs.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 19:01:41 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Jenihhin", "Maksim", ""], ["Reorda", "Matteo Sonza", ""], ["Balakrishnan", "Aneesh", ""], ["Alexandrescu", "Dan", ""]]}, {"id": "1909.03041", "submitter": "Nick Patterson Dr", "authors": "Nick Patterson, Rolando Trujillo Rasua, Michael Hobbs, Guy\n  Wood-Bradley, Judy Currey, Elicia Lanham", "title": "Chunked Lectures: A new model for conducting online lectures within\n  Information Technology higher education", "comments": "10 pages", "journal-ref": "Berlin International Academic Conference 2019", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The primary aim of this study in this paper aside from presenting student\npreference survey data and analytics data with relation to learning videos, is\nto address the attention span issues with our cohort of Information Technology\nstudents specifically and propose a new model being chunked lectures for\ndelivering online lectures within the Information Technology discipline which\nmay manage attention span more effectively and thus may also increase\ncomprehension and retention of knowledge.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 06:48:01 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Patterson", "Nick", ""], ["Rasua", "Rolando Trujillo", ""], ["Hobbs", "Michael", ""], ["Wood-Bradley", "Guy", ""], ["Currey", "Judy", ""], ["Lanham", "Elicia", ""]]}, {"id": "1909.03110", "submitter": "Joseph Spitzer", "authors": "Joseph Spitzer, Joydeep Biswas, and Arjun Guha", "title": "Making High-Performance Robots Safe and Easy to Use for an Introduction\n  to Computing", "comments": "8 pages, 7 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.PL cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots are a popular platform for introducing computing and artificial\nintelligence to novice programmers. However, programming state-of-the-art\nrobots is very challenging, and requires knowledge of concurrency, operation\nsafety, and software engineering skills, which can take years to teach. In this\npaper, we present an approach to introducing computing that allows students to\nsafely and easily program high-performance robots. We develop a platform for\nstudents to program RoboCup Small Size League robots using JavaScript. The\nplatform 1) ensures physical safety at several levels of abstraction, 2) allows\nstudents to program robots using the JavaScript in the browser, without the\nneed to install software, and 3) presents a simplified JavaScript semantics\nthat shields students from confusing language features. We discuss our\nexperience running a week-long workshop using this platform, and analyze over\n3,000 student-written program revisions to provide empirical evidence that our\napproach does help students.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 20:00:07 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 01:36:06 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Spitzer", "Joseph", ""], ["Biswas", "Joydeep", ""], ["Guha", "Arjun", ""]]}, {"id": "1909.03166", "submitter": "Vivek Gupta", "authors": "Vivek Gupta, Pegah Nokhiz, Chitradeep Dutta Roy, Suresh\n  Venkatasubramanian", "title": "Equalizing Recourse across Groups", "comments": "13 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The rise in machine learning-assisted decision-making has led to concerns\nabout the fairness of the decisions and techniques to mitigate problems of\ndiscrimination. If a negative decision is made about an individual (denying a\nloan, rejecting an application for housing, and so on) justice dictates that we\nbe able to ask how we might change circumstances to get a favorable decision\nthe next time. Moreover, the ability to change circumstances (a better\neducation, improved credentials) should not be limited to only those with\naccess to expensive resources. In other words, \\emph{recourse} for negative\ndecisions should be considered a desirable value that can be equalized across\n(demographically defined) groups. This paper describes how to build models that\nmake accurate predictions while still ensuring that the penalties for a\nnegative outcome do not disadvantage different groups disproportionately. We\nmeasure recourse as the distance of an individual from the decision boundary of\na classifier. We then introduce a regularized objective to minimize the\ndifference in recourse across groups. We explore linear settings and further\nextend recourse to non-linear settings as well as model-agnostic settings where\nthe exact distance from boundary cannot be calculated. Our results show that we\ncan successfully decrease the unfairness in recourse while maintaining\nclassifier performance.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 01:50:06 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Gupta", "Vivek", ""], ["Nokhiz", "Pegah", ""], ["Roy", "Chitradeep Dutta", ""], ["Venkatasubramanian", "Suresh", ""]]}, {"id": "1909.03290", "submitter": "Lav Varshney", "authors": "Lav R. Varshney, Nitish Shirish Keskar, Richard Socher", "title": "Pretrained AI Models: Performativity, Mobility, and Change", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paradigm of pretrained deep learning models has recently emerged in\nartificial intelligence practice, allowing deployment in numerous societal\nsettings with limited computational resources, but also embedding biases and\nenabling unintended negative uses. In this paper, we treat pretrained models as\nobjects of study and discuss the ethical impacts of their sociological\nposition. We discuss how pretrained models are developed and compared under the\ncommon task framework, but that this may make self-regulation inadequate.\nFurther how pretrained models may have a performative effect on society that\nexacerbates biases. We then discuss how pretrained models move through actor\nnetworks as a kind of computationally immutable mobile, but that users also act\nas agents of technological change by reinterpreting them via fine-tuning and\ntransfer. We further discuss how users may use pretrained models in malicious\nways, drawing a novel connection between the responsible innovation and\nuser-centered innovation literatures. We close by discussing how this\nsociological understanding of pretrained models can inform AI governance\nframeworks for fairness, accountability, and transparency.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 15:40:22 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Varshney", "Lav R.", ""], ["Keskar", "Nitish Shirish", ""], ["Socher", "Richard", ""]]}, {"id": "1909.03470", "submitter": "Moshe BenBassat Professor", "authors": "Moshe BenBassat", "title": "Disease Labeling via Machine Learning is NOT quite the same as Medical\n  Diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key step in medical diagnosis is giving the patient a universally\nrecognized label (e.g. Appendicitis) which essentially assigns the patient to a\nclass(es) of patients with similar body failures. However, two patients having\nthe same disease label(s) with high probability may still have differences in\ntheir feature manifestation patterns implying differences in the required\ntreatments. Additionally, in many cases, the labels of the primary diagnoses\nleave some findings unexplained. Medical diagnosis is only partially about\nprobability calculations for label X or Y. Diagnosis is not complete until the\npatient overall situation is clinically understood to the level that enables\nthe best therapeutic decisions. Most machine learning models are data centric\nmodels, and evidence so far suggest they can reach expert level performance in\nthe disease labeling phase. Nonetheless, like any other mathematical technique,\nthey have their limitations and applicability scope. Primarily, data centric\nalgorithms are knowledge blind and lack anatomy and physiology knowledge that\nphysicians leverage to achieve complete diagnosis. This article advocates to\ncomplement them with intelligence to overcome their inherent limitations as\nknowledge blind algorithms. Machines can learn many things from data, but data\nis not the only source that machines can learn from. Historic patient data only\ntells us what the possible manifestations of a certain body failure are.\nAnatomy and physiology knowledge tell us how the body works and fails. Both are\nneeded for complete diagnosis. The proposed Double Deep Learning approach,\nalong with the initiative for Medical Wikipedia for Smart Machines, leads to AI\ndiagnostic support solutions for complete diagnosis beyond the limited data\nonly labeling solutions we see today. AI for medicine will forever be limited\nuntil their intelligence also integrates anatomy and physiology.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 13:54:00 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["BenBassat", "Moshe", ""]]}, {"id": "1909.03486", "submitter": "Dakuo Wang", "authors": "Yaoli Mao, Dakuo Wang, Michael Muller, Kush R. Varshney, Ioana\n  Baldini, Casey Dugan, AleksandraMojsilovi\\'c", "title": "How Data Scientists Work Together With Domain Experts in Scientific\n  Collaborations: To Find The Right Answer Or To Ask The Right Question?", "comments": null, "journal-ref": null, "doi": "10.1145/3361118", "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years there has been an increasing trend in which data scientists\nand domain experts work together to tackle complex scientific questions.\nHowever, such collaborations often face challenges. In this paper, we aim to\ndecipher this collaboration complexity through a semi-structured interview\nstudy with 22 interviewees from teams of bio-medical scientists collaborating\nwith data scientists. In the analysis, we adopt the Olsons' four-dimensions\nframework proposed in Distance Matters to code interview transcripts. Our\nfindings suggest that besides the glitches in the collaboration readiness,\ntechnology readiness, and coupling of work dimensions, the tensions that exist\nin the common ground building process influence the collaboration outcomes, and\nthen persist in the actual collaboration process. In contrast to prior works'\ngeneral account of building a high level of common ground, the breakdowns of\ncontent common ground together with the strengthen of process common ground in\nthis process is more beneficial for scientific discovery. We discuss why that\nis and what the design suggestions are, and conclude the paper with future\ndirections and limitations.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 15:48:35 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Mao", "Yaoli", ""], ["Wang", "Dakuo", ""], ["Muller", "Michael", ""], ["Varshney", "Kush R.", ""], ["Baldini", "Ioana", ""], ["Dugan", "Casey", ""], ["AleksandraMojsilovi\u0107", "", ""]]}, {"id": "1909.03567", "submitter": "Andi Peng", "authors": "Andi Peng, Besmira Nushi, Emre Kiciman, Kori Inkpen, Siddharth Suri,\n  Ece Kamar", "title": "What You See Is What You Get? The Impact of Representation Criteria on\n  Human Bias in Hiring", "comments": "This paper has been accepted for publication at HCOMP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although systematic biases in decision-making are widely documented, the ways\nin which they emerge from different sources is less understood. We present a\ncontrolled experimental platform to study gender bias in hiring by decoupling\nthe effect of world distribution (the gender breakdown of candidates in a\nspecific profession) from bias in human decision-making. We explore the\neffectiveness of \\textit{representation criteria}, fixed proportional display\nof candidates, as an intervention strategy for mitigation of gender bias by\nconducting experiments measuring human decision-makers' rankings for who they\nwould recommend as potential hires. Experiments across professions with varying\ngender proportions show that balancing gender representation in candidate\nslates can correct biases for some professions where the world distribution is\nskewed, although doing so has no impact on other professions where human\npersistent preferences are at play. We show that the gender of the\ndecision-maker, complexity of the decision-making task and over- and\nunder-representation of genders in the candidate slate can all impact the final\ndecision. By decoupling sources of bias, we can better isolate strategies for\nbias mitigation in human-in-the-loop systems.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 23:52:23 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Peng", "Andi", ""], ["Nushi", "Besmira", ""], ["Kiciman", "Emre", ""], ["Inkpen", "Kori", ""], ["Suri", "Siddharth", ""], ["Kamar", "Ece", ""]]}, {"id": "1909.03679", "submitter": "D\\'aniel Kondor", "authors": "D\\'aniel Kondor, Xiaohu Zhang, Malika Meghjani, Paolo Santi, Jinhua\n  Zhao, Carlo Ratti", "title": "Estimating the potential for shared autonomous scooters", "comments": null, "journal-ref": "IEEE Transactions on Intelligent Transportation Systems, 2021", "doi": "10.1109/TITS.2020.3047141", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent technological developments have shown significant potential for\ntransforming urban mobility. Considering first- and last-mile travel and short\ntrips, the rapid adoption of dockless bike-share systems showed the possibility\nof disruptive change, while simultaneously presenting new challenges, such as\nfleet management or the use of public spaces. In this paper, we evaluate the\noperational characteristics of a new class of shared vehicles that are being\nactively developed in the industry: scooters with self-repositioning\ncapabilities. We do this by adapting the methodology of shareability networks\nto a large-scale dataset of dockless bike-share usage, giving us estimates of\nideal fleet size under varying assumptions of fleet operations. We show that\nthe availability of self-repositioning capabilities can help achieve up to 10\ntimes higher utilization of vehicles than possible in current bike-share\nsystems. We show that actual benefits will highly depend on the availability of\ndedicated infrastructure, a key issue for scooter and bicycle use. Based on our\nresults, we envision that technological advances can present an opportunity to\nrethink urban infrastructures and how transportation can be effectively\norganized in cities.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 07:39:58 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 06:03:11 GMT"}, {"version": "v3", "created": "Sat, 1 Feb 2020 09:27:50 GMT"}, {"version": "v4", "created": "Mon, 20 Jul 2020 10:06:10 GMT"}, {"version": "v5", "created": "Wed, 7 Oct 2020 14:59:28 GMT"}, {"version": "v6", "created": "Fri, 29 Jan 2021 00:51:25 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Kondor", "D\u00e1niel", ""], ["Zhang", "Xiaohu", ""], ["Meghjani", "Malika", ""], ["Santi", "Paolo", ""], ["Zhao", "Jinhua", ""], ["Ratti", "Carlo", ""]]}, {"id": "1909.03753", "submitter": "Simon Duque Anton", "authors": "Simon D. Duque Anton, Anna Pia Lohfink, and Hans Dieter Schotten", "title": "Discussing the Feasibility of Acoustic Sensors for Side Channel-aided\n  Industrial Intrusion Detection: An Essay", "comments": null, "journal-ref": null, "doi": "10.1145/3360664.3360667", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fourth industrial revolution leads to an increased use of embedded\ncomputation and intercommunication in an industrial environment. While reducing\ncost and effort for set up, operation and maintenance, and increasing the time\nto operation or market respectively as well as the efficiency, this also\nincreases the attack surface of enterprises. Industrial enterprises have become\ntargets of cyber criminals in the last decade, reasons being espionage but also\npolitically motivated. Infamous attack campaigns as well as easily available\nmalware that hits industry in an unprepared state create a large threat\nlandscape. As industrial systems often operate for many decades and are\ndifficult or impossible to upgrade in terms of security, legacy-compatible\nindustrial security solutions are necessary in order to create a security\nparameter. One plausible approach in industry is the implementation and\nemployment of side-channel sensors. Combining readily available sensor data\nfrom different sources via different channels can provide an enhanced insight\nabout the security state. In this work, a data set of an experimental\nindustrial set up containing side channel sensors is discussed conceptually and\ninsights are derived.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 10:48:56 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Anton", "Simon D. Duque", ""], ["Lohfink", "Anna Pia", ""], ["Schotten", "Hans Dieter", ""]]}, {"id": "1909.03851", "submitter": "Marinella Petrocchi", "authors": "Alessandro Balestrucci, Rocco De Nicola, Marinella Petrocchi, Catia\n  Trubiani", "title": "Do you really follow them? Automatic detection of credulous Twitter\n  users", "comments": "8 pages, 2 tables. Accepted for publication at IDEAL 2019 (20th\n  International Conference on Intelligent Data Engineering and Automated\n  Learning, Manchester, UK, 14-16 November, 2019). The present version is the\n  accepted version, and it is not the final published version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online Social Media represent a pervasive source of information able to reach\na huge audience. Sadly, recent studies show how online social bots (automated,\noften malicious accounts, populating social networks and mimicking genuine\nusers) are able to amplify the dissemination of (fake) information by orders of\nmagnitude. Using Twitter as a benchmark, in this work we focus on what we\ndefine credulous users, i.e., human-operated accounts with a high percentage of\nbots among their followings. Being more exposed to the harmful activities of\nsocial bots, credulous users may run the risk of being more influenced than\nother users; even worse, although unknowingly, they could become spreaders of\nmisleading information (e.g., by retweeting bots). We design and develop a\nsupervised classifier to automatically recognize credulous users. The best\ntested configuration achieves an accuracy of 93.27% and AUC-ROC of 0.93, thus\nleading to positive and encouraging results.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 13:38:02 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Balestrucci", "Alessandro", ""], ["De Nicola", "Rocco", ""], ["Petrocchi", "Marinella", ""], ["Trubiani", "Catia", ""]]}, {"id": "1909.04251", "submitter": "Jing Qian", "authors": "Jing Qian, Anna Bethke, Yinyin Liu, Elizabeth Belding, William Yang\n  Wang", "title": "A Benchmark Dataset for Learning to Intervene in Online Hate Speech", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Countering online hate speech is a critical yet challenging task, but one\nwhich can be aided by the use of Natural Language Processing (NLP) techniques.\nPrevious research has primarily focused on the development of NLP methods to\nautomatically and effectively detect online hate speech while disregarding\nfurther action needed to calm and discourage individuals from using hate speech\nin the future. In addition, most existing hate speech datasets treat each post\nas an isolated instance, ignoring the conversational context. In this paper, we\npropose a novel task of generative hate speech intervention, where the goal is\nto automatically generate responses to intervene during online conversations\nthat contain hate speech. As a part of this work, we introduce two\nfully-labeled large-scale hate speech intervention datasets collected from Gab\nand Reddit. These datasets provide conversation segments, hate speech labels,\nas well as intervention responses written by Mechanical Turk Workers. In this\npaper, we also analyze the datasets to understand the common intervention\nstrategies and explore the performance of common automatic response generation\nmethods on these new datasets to provide a benchmark for future research.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 03:00:58 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Qian", "Jing", ""], ["Bethke", "Anna", ""], ["Liu", "Yinyin", ""], ["Belding", "Elizabeth", ""], ["Wang", "William Yang", ""]]}, {"id": "1909.04323", "submitter": "Hao Lin", "authors": "Qi Zhou and Hao Lin", "title": "Investigating the completeness and omission roads of OpenStreetMap data\n  in Hubei, China by comparing with Street Map and Street View", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  OpenStreetMap (OSM) is a free map of the world which can be edited by global\nvolunteers. Existing studies have showed that completeness of OSM road data in\nsome developing countries (e.g. China) is much lower, resulting in concern in\nutilizing the data in various applications. But very few have focused on\ninvestigating what types of road are still poorly mapped. This study aims not\nonly to investigate the completeness of OSM road datasets in China but also to\ninvestigate what types of road (called omission roads) have not been mapped,\nwhich is achieved by referring to both Street Map and Street View. 16\nprefecture-level divisions in the urban areas of Hubei (China) were used as\nstudy areas. Results showed that: (1) the completeness for most\nprefecture-level divisions was at a low-to-medium level; most roads (in the\nStreet Map), however, with traffic conditions had already been mapped well. (2)\nMost of the omission OSM roads were either private roads, or public roads not\nhaving yet been named and with only one single lane, indicating their lack of\nimportance in the urban road network. We argue that although the OSM road\ndatasets in China are incomplete, they may still be used for several\napplications.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 07:03:34 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Zhou", "Qi", ""], ["Lin", "Hao", ""]]}, {"id": "1909.04377", "submitter": "Olga Bondarenko", "authors": "Olga V. Bondarenko, Olena V. Pakhomova, Vladimir I. Zaselskiy", "title": "The use of cloud technologies when studying geography by higher school\n  students", "comments": null, "journal-ref": "CEUR Workshop Proceedings 2433 (2018) 377-390", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article is devoted to the topical issue of the cloud technologies\nimplementation in educational process in general and when studying geography,\nin particular. The authors offer a selection of online services which can\ncontribute to the effective acquisition of geographical knowledge in higher\nschool. The publication describes such cloud technologies as Gapminder,\nDESA,Datawrapper.de, Time.Graphics, HP Reveal, MOZAIK education, Settera\nOnline, Click-that-hood, Canva, Paint Instant. It is also made some theoretical\ngeneralization of their economic, technical, technological, didactic advantages\nand disadvantages. Visual examples of application are provided in the article.\nThe authors make notice that in the long run the technologies under study\nshould become a valuable educational tool of creation virtual information and\neducation environments connected into common national, and then global,\neducational space.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 09:58:52 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Bondarenko", "Olga V.", ""], ["Pakhomova", "Olena V.", ""], ["Zaselskiy", "Vladimir I.", ""]]}, {"id": "1909.04381", "submitter": "Olga Bondarenko", "authors": "Ihor Kholoshyn, Iryna Varfolomyeyeva, Olena Hanchuk, Olga Bondarenko,\n  Andrey Pikilnyak", "title": "Pedagogical techniques of Earth remote sensing data application into\n  modern school practice", "comments": null, "journal-ref": "CEUR Workshop Proceedings 2433 (2018) 391-402", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article dwells upon the Earth remote sensing data as one of the basic\ndirections of Geo-Information Science, a unique source of information on\nprocesses and phenomena occurring in almost all spheres of the Earth geographic\nshell (atmosphere, hydrosphere, lithosphere, etc.). The authors argue that the\nuse of aerospace images by means of the information and communication\ntechnologies involvement in the learning process allows not only to increase\nthe information context value of learning, but also contributes to the\nformation of students' cognitive interest in such disciplines as geography,\nbiology, history, physics, computer science, etc. It has been grounded that\nremote sensing data form students' spatial, temporal and qualitative concepts,\nsensory support for the perception, knowledge and explanation of the specifics\nof objects and phenomena of geographical reality, which, in its turn, provides\nan increase in the level of educational achievements. The techniques of\naerospace images application into the modern school practice have been analyzed\nand illustrated in the examples: from using them as visual aids, to realization\nof practical and research orientation of training on the basis of remote\nsensing data. Particular attention is paid to the practical component of the\nEarth remote sensing implementation into the modern school practice with the\nhelp of information and communication technologies.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 10:06:41 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Kholoshyn", "Ihor", ""], ["Varfolomyeyeva", "Iryna", ""], ["Hanchuk", "Olena", ""], ["Bondarenko", "Olga", ""], ["Pikilnyak", "Andrey", ""]]}, {"id": "1909.04388", "submitter": "Olga Bondarenko", "authors": "Ihor Kholoshyn, Olga Bondarenko, Olena Hanchuk, Ekaterina Shmeltser", "title": "Cloud ArcGIS Online as an innovative tool for developing geoinformation\n  competence with future geography teachers", "comments": null, "journal-ref": "CEUR Workshop Proceedings 2433 (2018) 403-412", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article dwells upon the scientifically relevant problem of using\ncloud-based GIS-technologies when training future geography teachers (based on\nArcGIS Online application). The authors outline the basic principles for\nimplementing ArcGIS Online in the educational process (interdisciplinary\nintegration, the sequence of individualization in training, communicability,\ndistance education and regional studies), and provide an example of an\ninteractive map created with the help of the specified cloud GIS, since this\nkind of map is the most popular a form of research by geography students. In\nthe article it is noted that integration of ArcGIS Online into the educational\nprocess allows the teacher to follow a clear pedagogical strategy, taking into\naccount possible variants of its use (demonstration, direct mastering of GIS in\na computer class and independent work in an individual mode). Considering cloud\nGIS as a new stage in the development of geoinformational education, the\nauthors emphasize their key benefits (round-the-clock access, work with GIS\npackage in the cloud, the ability to use other maps as well as the creation of\ntheir own maps and webapplications) and disadvantages (monetization of\nservices, underestimation of the GIS role in the curriculum of the higher\nschool, the lack of Ukrainian content, etc.).\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 10:14:19 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Kholoshyn", "Ihor", ""], ["Bondarenko", "Olga", ""], ["Hanchuk", "Olena", ""], ["Shmeltser", "Ekaterina", ""]]}, {"id": "1909.04724", "submitter": "Iqbal H. Sarker", "authors": "Iqbal H. Sarker, Alan Colman, Jun Han, A.S.M. Kayes and Paul Watters", "title": "CalBehav: A Machine Learning based Personalized Calendar Behavioral\n  Model using Time-Series Smartphone Data", "comments": "16 pages, double column", "journal-ref": "The Computer Journal, Section C: Computational Intelligence,\n  Machine Learning and Data Analytics, Publisher: Oxford University Press, UK,\n  2019", "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The electronic calendar is a valuable resource nowadays for managing our\ndaily life appointments or schedules, also known as events, ranging from\nprofessional to highly personal. Researchers have studied various types of\ncalendar events to predict smartphone user behavior for incoming mobile\ncommunications. However, these studies typically do not take into account\nbehavioral variations between individuals. In the real world, smartphone users\ncan differ widely from each other in how they respond to incoming\ncommunications during their scheduled events. Moreover, an individual user may\nrespond the incoming communications differently in different contexts subject\nto what type of event is scheduled in her personal calendar. Thus, a static\ncalendar-based behavioral model for individual smartphone users does not\nnecessarily reflect their behavior to the incoming communications. In this\npaper, we present a machine learning based context-aware model that is\npersonalized and dynamically identifies individual's dominant behavior for\ntheir scheduled events using logged time-series smartphone data, and shortly\nname as ``CalBehav''. The experimental results based on real datasets from\ncalendar and phone logs, show that this data-driven personalized model is more\neffective for intelligently managing the incoming mobile communications\ncompared to existing calendar-based approaches.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 08:26:11 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Sarker", "Iqbal H.", ""], ["Colman", "Alan", ""], ["Han", "Jun", ""], ["Kayes", "A. S. M.", ""], ["Watters", "Paul", ""]]}, {"id": "1909.05118", "submitter": "Alan Lundgard", "authors": "Alan Lundgard, Crystal Lee, Arvind Satyanarayan", "title": "Sociotechnical Considerations for Accessible Visualization Design", "comments": null, "journal-ref": "IEEE Trans. Visualization & Comp. Graphics (Proc. InfoVis), 2020", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accessibility--the process of designing for people with disabilities\n(PWD)--is an important but under-explored challenge in the visualization\nresearch community. Without careful attention, and if PWD are not included as\nequal participants throughout the process, there is a danger of perpetuating a\nvision-first approach to accessible design that marginalizes the lived\nexperience of disability (e.g., by creating overly simplistic \"sensory\ntranslations\" that map visual to non-visual modalities in a one-to-one\nfashion). In this paper, we present a set of sociotechnical considerations for\nresearch in accessible visualization design, drawing on literature in\ndisability studies, tactile information systems, and participatory methods. We\nidentify that using state-of-the-art technologies may introduce more barriers\nto access than they remove, and that expectations of research novelty may not\nproduce outcomes well-aligned with the needs of disability communities.\nInstead, to promote a more inclusive design process, we emphasize the\nimportance of clearly communicating goals, following existing accessibility\nguidelines, and treating PWD as equal participants who are compensated for\ntheir specialized skills. To illustrate how these considerations can be applied\nin practice, we discuss a case study of an inclusive design workshop held in\ncollaboration with the Perkins School for the Blind.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 15:11:43 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Lundgard", "Alan", ""], ["Lee", "Crystal", ""], ["Satyanarayan", "Arvind", ""]]}, {"id": "1909.05167", "submitter": "Kacper Sokol", "authors": "Kacper Sokol, Raul Santos-Rodriguez, Peter Flach", "title": "FAT Forensics: A Python Toolbox for Algorithmic Fairness, Accountability\n  and Transparency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms can take important decisions, sometimes legally\nbinding, about our everyday life. In most cases, however, these systems and\ndecisions are neither regulated nor certified. Given the potential harm that\nthese algorithms can cause, qualities such as fairness, accountability and\ntransparency of predictive systems are of paramount importance. Recent\nliterature suggested voluntary self-reporting on these aspects of predictive\nsystems -- e.g., data sheets for data sets -- but their scope is often limited\nto a single component of a machine learning pipeline, and producing them\nrequires manual labour. To resolve this impasse and ensure high-quality, fair,\ntransparent and reliable machine learning systems, we developed an open source\ntoolbox that can inspect selected fairness, accountability and transparency\naspects of these systems to automatically and objectively report them back to\ntheir engineers and users. We describe design, scope and usage examples of this\nPython toolbox in this paper. The toolbox provides functionality for inspecting\nfairness, accountability and transparency of all aspects of the machine\nlearning process: data (and their features), models and predictions. It is\navailable to the public under the BSD 3-Clause open source licence.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 16:11:44 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Sokol", "Kacper", ""], ["Santos-Rodriguez", "Raul", ""], ["Flach", "Peter", ""]]}, {"id": "1909.05189", "submitter": "Aaron Halfaker", "authors": "Aaron Halfaker and R. Stuart Geiger", "title": "ORES: Lowering Barriers with Participatory Machine Learning in Wikipedia", "comments": "29 pages + 3 pages appendix. Currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Algorithmic systems---from rule-based bots to machine learning\nclassifiers---have a long history of supporting the essential work of content\nmoderation and other curation work in peer production projects. From\ncounter-vandalism to task routing, basic machine prediction has allowed open\nknowledge projects like Wikipedia to scale to the largest encyclopedia in the\nworld, while maintaining quality and consistency. However, conversations about\nhow quality control should work and what role algorithms should play have\ngenerally been led by the expert engineers who have the skills and resources to\ndevelop and modify these complex algorithmic systems. In this paper, we\ndescribe ORES: an algorithmic scoring service that supports real-time scoring\nof wiki edits using multiple independent classifiers trained on different\ndatasets. ORES decouples several activities that have typically all been\nperformed by engineers: choosing or curating training data, building models to\nserve predictions, auditing predictions, and developing interfaces or automated\nagents that act on those predictions. This meta-algorithmic system was designed\nto open up socio-technical conversations about algorithms in Wikipedia to a\nbroader set of participants. In this paper, we discuss the theoretical\nmechanisms of social change ORES enables and detail case studies in\nparticipatory machine learning around ORES from the 5 years since its\ndeployment.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 16:40:03 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 14:19:58 GMT"}, {"version": "v3", "created": "Thu, 20 Aug 2020 14:35:49 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Halfaker", "Aaron", ""], ["Geiger", "R. Stuart", ""]]}, {"id": "1909.05282", "submitter": "David C. Parkes", "authors": "David C. Parkes, Rakesh V. Vohra, and other workshop participants", "title": "Algorithmic and Economic Perspectives on Fairness", "comments": "A Computing Community Consortium (CCC) workshop report, 20 pages", "journal-ref": null, "doi": null, "report-no": "ccc2019report_4", "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic systems have been used to inform consequential decisions for at\nleast a century. Recidivism prediction dates back to the 1920s. Automated\ncredit scoring dates began in the middle of the last century, but the last\ndecade has witnessed an acceleration in the adoption of prediction algorithms.\nThey are deployed to screen job applicants for the recommendation of products,\npeople, and content, as well as in medicine (diagnostics and decision aids),\ncriminal justice, facial recognition, lending and insurance, and the allocation\nof public services. The prominence of algorithmic methods has led to concerns\nregarding their systematic unfairness in their treatment of those whose\nbehavior they are predicting. These concerns have found their way into the\npopular imagination through news accounts and general interest books. Even when\nthese algorithms are deployed in domains subject to regulation, it appears that\nexisting regulation is poorly equipped to deal with this issue. The word\n'fairness' in this context is a placeholder for three related equity concerns.\nFirst, such algorithms may systematically discriminate against individuals with\na common ethnicity, religion, or gender, irrespective of whether the relevant\ngroup enjoys legal protections. The second is that these algorithms fail to\ntreat people as individuals. Third, who gets to decide how algorithms are\ndesigned and deployed. These concerns are present when humans, unaided, make\npredictions.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 18:15:37 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Parkes", "David C.", ""], ["Vohra", "Rakesh V.", ""], ["participants", "other workshop", ""]]}, {"id": "1909.05801", "submitter": "Emiliano De Cristofaro", "authors": "Aravindh Raman, Sagar Joglekar, Emiliano De Cristofaro, Nishanth\n  Sastry, and Gareth Tyson", "title": "Challenges in the Decentralised Web: The Mastodon Case", "comments": null, "journal-ref": "Proceedings of 19th ACM Internet Measurement Conference (IMC 2019)", "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Decentralised Web (DW) has recently seen a renewed momentum, with a\nnumber of DW platforms like Mastodon, Peer-Tube, and Hubzilla gaining\nincreasing traction. These offer alternatives to traditional social networks\nlike Twitter, YouTube, and Facebook, by enabling the operation of web\ninfrastructure and services without centralised ownership or control. Although\ntheir services differ greatly, modern DW platforms mostly rely on two key\ninnovations: first, their open source software allows anybody to setup\nindependent servers (\"instances\") that people can sign-up to and use within a\nlocal community; and second, they build on top of federation protocols so that\ninstances can mesh together, in a peer-to-peer fashion, to offer a globally\nintegrated platform. In this paper, we present a measurement-driven exploration\nof these two innovations, using a popular DW microblogging platform (Mastodon)\nas a case study. We focus on identifying key challenges that might disrupt\ncontinuing efforts to decentralise the web, and empirically highlight a number\nof properties that are creating natural pressures towards recentralisation.\nFinally, our measurements shed light on the behaviour of both administrators\n(i.e., people setting up instances) and regular users who sign-up to the\nplatforms, also discussing a few techniques that may address some of the issues\nobserved.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 17:00:34 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Raman", "Aravindh", ""], ["Joglekar", "Sagar", ""], ["De Cristofaro", "Emiliano", ""], ["Sastry", "Nishanth", ""], ["Tyson", "Gareth", ""]]}, {"id": "1909.06342", "submitter": "Umang Bhatt", "authors": "Umang Bhatt, Alice Xiang, Shubham Sharma, Adrian Weller, Ankur Taly,\n  Yunhan Jia, Joydeep Ghosh, Ruchir Puri, Jos\\'e M. F. Moura, Peter Eckersley", "title": "Explainable Machine Learning in Deployment", "comments": "ACM Conference on Fairness, Accountability, and Transparency 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable machine learning offers the potential to provide stakeholders\nwith insights into model behavior by using various methods such as feature\nimportance scores, counterfactual explanations, or influential training data.\nYet there is little understanding of how organizations use these methods in\npractice. This study explores how organizations view and use explainability for\nstakeholder consumption. We find that, currently, the majority of deployments\nare not for end users affected by the model but rather for machine learning\nengineers, who use explainability to debug the model itself. There is thus a\ngap between explainability in practice and the goal of transparency, since\nexplanations primarily serve internal stakeholders rather than external ones.\nOur study synthesizes the limitations of current explainability techniques that\nhamper their use for end users. To facilitate end user interaction, we develop\na framework for establishing clear goals for explainability. We end by\ndiscussing concerns raised regarding explainability.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 17:35:53 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 18:30:09 GMT"}, {"version": "v3", "created": "Fri, 22 May 2020 17:31:01 GMT"}, {"version": "v4", "created": "Fri, 10 Jul 2020 13:53:00 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Bhatt", "Umang", ""], ["Xiang", "Alice", ""], ["Sharma", "Shubham", ""], ["Weller", "Adrian", ""], ["Taly", "Ankur", ""], ["Jia", "Yunhan", ""], ["Ghosh", "Joydeep", ""], ["Puri", "Ruchir", ""], ["Moura", "Jos\u00e9 M. F.", ""], ["Eckersley", "Peter", ""]]}, {"id": "1909.06677", "submitter": "Charles Marx", "authors": "Charles T. Marx, Flavio du Pin Calmon, Berk Ustun", "title": "Predictive Multiplicity in Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction problems often admit competing models that perform almost equally\nwell. This effect challenges key assumptions in machine learning when competing\nmodels assign conflicting predictions. In this paper, we define predictive\nmultiplicity as the ability of a prediction problem to admit competing models\nwith conflicting predictions. We introduce formal measures to evaluate the\nseverity of predictive multiplicity and develop integer programming tools to\ncompute them exactly for linear classification problems. We apply our tools to\nmeasure predictive multiplicity in recidivism prediction problems. Our results\nshow that real-world datasets may admit competing models that assign wildly\nconflicting predictions, and motivate the need to measure and report predictive\nmultiplicity in model development.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 21:12:04 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 08:39:47 GMT"}, {"version": "v3", "created": "Mon, 13 Jul 2020 05:10:08 GMT"}, {"version": "v4", "created": "Wed, 16 Sep 2020 04:58:29 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Marx", "Charles T.", ""], ["Calmon", "Flavio du Pin", ""], ["Ustun", "Berk", ""]]}, {"id": "1909.06713", "submitter": "Bogdana Rakova", "authors": "Bogdana Rakova, Rumman Chowdhury", "title": "Human self-determination within algorithmic sociotechnical systems", "comments": "9 pages, 3 figures. To appear in the Proceedings of the\n  Human-Centered AI: Trustworthiness of AI Models & Data (HAI) track at AAAI\n  Fall Symposium, DC, November 7-9, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In order to investigate the protection of human self-determination within\nalgorithmic sociotechnical systems, we study the relationships between the\nconcepts of mutability, bias, feedback loops, and power dynamics. We focus on\nthe interactions between people and algorithmic systems in the case of\nRecommender Systems (RS) and provide novel theoretical analysis informed by\nhuman-in-the-loop system design and Supervisory Control, in order to question\nthe dynamics in our interactions with RSs. We explore what meaningful\nreliability monitoring means in the context of RSs and elaborate on the need\nfor metrics that encompass human-algorithmic interaction. We derive a metric we\ncall a barrier-to-exit which is a proxy to the amount of effort a user needs to\nexpend in order for the system to recognize their change in preference. Our\ngoal is to highlight the assumptions and limitations of RSs and introduce a\nhuman-centered method of combating deterministic design.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 02:19:23 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Rakova", "Bogdana", ""], ["Chowdhury", "Rumman", ""]]}, {"id": "1909.06799", "submitter": "Tom Blount", "authors": "Tom Blount and Callum Spawforth", "title": "Pathos in Play: How Game Designers Evoke Negative Emotions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much in the same way that people enjoy, from time to time, the pathos of\nconsuming a tragic film or piece of literature, designers of digital games are\nincreasingly including elements within their games that evoke uncomfortable or\nnegative emotions in their audience, allowing players to introspect and explore\n\"adult\" themes and topics, including loss, regret, powerlessness,\nmental-health, and mortality. In this paper we examine a number of recent games\nas case studies and explore the way in which they use their mechanics to evoke\nfeelings of discomfort in their players, and the way in which pathos serves\nplay. Through this, we highlight a number of different techniques used by game\ndesigners and conclude by proposing further work in this space to determine\nexactly why players are drawn to these types of games, and to explore the ways\nin which research in this field could be used to drive yet more emotive and\nempathetic games.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 13:34:12 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Blount", "Tom", ""], ["Spawforth", "Callum", ""]]}, {"id": "1909.06856", "submitter": "Casper Hansen", "authors": "Christian Hansen, Casper Hansen, Stephen Alstrup, Christina Lioma", "title": "Modelling End-of-Session Actions in Educational Systems", "comments": "In proceedings of EDM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the problem of modelling when students end their\nsession in an online mathematics educational system. Being able to model this\naccurately will help us optimize the way content is presented and consumed.\nThis is done by modelling the probability of an action being the last in a\nsession, which we denote as the End-of-Session probability. We use log data\nfrom a system where students can learn mathematics through various kinds of\nlearning materials, as well as multiple types of exercises, such that a student\nsession can consist of many different activities. We model the End-of-Session\nprobability by a deep recurrent neural network in order to utilize the long\nterm temporal aspect, which we experimentally show is central for this task.\nUsing a large scale dataset of more than 70 million student actions, we obtain\nan AUC of 0.81 on an unseen collection of students. Through a detailed error\nanalysis, we observe that our model is robust across different session\nstructures and across varying session lengths.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 18:39:58 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Hansen", "Christian", ""], ["Hansen", "Casper", ""], ["Alstrup", "Stephen", ""], ["Lioma", "Christina", ""]]}, {"id": "1909.06857", "submitter": "Lesandro Ponciano", "authors": "Lesandro Ponciano", "title": "HCI Support Card: Creating and Using a Support Card for Education in\n  Human-Computer Interaction", "comments": "Workshop on HCI Education (WEIHC '19)", "journal-ref": "Extended Proceedings of the 18th Brazilian Symposium on Human\n  Factors in Computing Systems, October 21--25, 2019, Vit\\'oria - ES, Brazil", "doi": "10.5753/ihc.2019.8409", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Support cards summarise a set of core information about a subject. The\nperiodic table of chemical elements and the mathematical tables are well-known\nexamples of support cards for didactic purposes. Technology professionals also\nuse support cards for recalling information such as syntactic details of\nprogramming languages or harmonic colour palettes for designing user\ninterfaces. While support cards have proved useful in many contexts, little is\nknown about its didactic use in the Human-Computer Interaction (HCI) field. To\nfill this gap, this study proposes and evaluates a process for creating and\nusing an HCI support card. The process considers the interdisciplinary nature\nof the field, covering the syllabus, curriculum, textbooks, and students'\nperception about HCI topics. The evaluation is based on case studies of\ncreating and using a card during a semester in two undergraduate courses:\nSoftware Engineering and Information Systems. Results show that a support card\ncan help students in following the lessons, remembering and integrating the\ndifferent topics studied in the classroom. The card guides the students in\nbuilding their cognitive maps, mind maps, and concept maps to study\nhuman-computer interaction. It fosters students' curiosity and permanent\nengagement with the HCI topics. The card usefulness goes beyond the HCI\nclassroom, being also used by students in their professional activities and\nother academic disciplines, fostering an interdisciplinary application of HCI\ntopics.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 18:47:16 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Ponciano", "Lesandro", ""]]}, {"id": "1909.07131", "submitter": "Mohammad Aliannejadi", "authors": "Mohammad Aliannejadi and Dimitrios Rafailidis and Fabio Crestani", "title": "A Joint Two-Phase Time-Sensitive Regularized Collaborative Ranking Model\n  for Point of Interest Recommendation", "comments": "To appear in IEEE Transactions on Knowledge and Data Engineering\n  (TKDE)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The popularity of location-based social networks (LBSNs) has led to a\ntremendous amount of user check-in data. Recommending points of interest (POIs)\nplays a key role in satisfying users' needs in LBSNs. While recent work has\nexplored the idea of adopting collaborative ranking (CR) for recommendation,\nthere have been few attempts to incorporate temporal information for POI\nrecommendation using CR. In this article, we propose a two-phase CR algorithm\nthat incorporates the geographical influence of POIs and is regularized based\non the variance of POIs popularity and users' activities over time. The\ntime-sensitive regularizer penalizes user and POIs that have been more\ntime-sensitive in the past, helping the model to account for their long-term\nbehavioral patterns while learning from user-POI interactions. Moreover, in the\nfirst phase, it attempts to rank visited POIs higher than the unvisited ones,\nand at the same time, apply the geographical influence. In the second phase,\nour algorithm tries to rank users' favorite POIs higher on the recommendation\nlist. Both phases employ a collaborative learning strategy that enables the\nmodel to capture complex latent associations from two different perspectives.\nExperiments on real-world datasets show that our proposed time-sensitive\ncollaborative ranking model beats state-of-the-art POI recommendation methods.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 11:33:14 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Aliannejadi", "Mohammad", ""], ["Rafailidis", "Dimitrios", ""], ["Crestani", "Fabio", ""]]}, {"id": "1909.07143", "submitter": "Geoffrey Goodell", "authors": "Agnieszka Rychwalska, Geoffrey Goodell, Magdalena\n  Roszczynska-Kurasinska", "title": "Data management for platform-mediated public services: Challenges and\n  best practices", "comments": "19 pages", "journal-ref": null, "doi": "10.24908/ss.v19i1.13986", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data harvesting and profiling have become a de facto business model for many\nbusinesses in the digital economy. The surveillance of individual persons\nthrough their use of private sector platforms has a well-understood effect on\npersonal autonomy and democratic institutions. In this article, we explore the\nconsequences of implementing data-rich services in the public sector and\nspecifically the dangers inherent to undermining the universality of the reach\nof public services, the implicit endorsement of the platform operators by\ngovernment, and the inability of members of the public to avoid using the\nplatforms in practice. We propose a set of good practices in the form of design\nprinciples that infrastructure services can adopt to mitigate the risks, and we\nspecify a set of design primitives that can be used to support the development\nof infrastructure that follows the principles. We argue that providers of\npublic infrastructure should adopt a practice of critical assessment of the\nconsequences of their technology choices.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 12:11:10 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 20:06:09 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 21:46:30 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Rychwalska", "Agnieszka", ""], ["Goodell", "Geoffrey", ""], ["Roszczynska-Kurasinska", "Magdalena", ""]]}, {"id": "1909.07316", "submitter": "Luke Snyder", "authors": "Luke S. Snyder, Morteza Karimzadeh, Christina Stober, and David S.\n  Ebert", "title": "Situational Awareness Enhanced through Social Media Analytics: A Survey\n  of First Responders", "comments": "8 pages, IEEE International Symposium on Technologies for Homeland\n  Security", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media data has been increasingly used to facilitate situational\nawareness during events and emergencies such as natural disasters. While\nresearchers have investigated several methods to summarize, visualize or mine\nthe data for analysis, first responders have not been able to fully leverage\nresearch advancements largely due to the gap between academic research and\ndeployed, functional systems. In this paper, we explore the opportunities and\nbarriers for the effective use of social media data from first responders'\nperspective. We present the summary of several detailed interviews with first\nresponders on their use of social media for situational awareness. We further\nassess the impact of SMART-a social media visual analytics system-on first\nresponder operations.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 16:20:10 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Snyder", "Luke S.", ""], ["Karimzadeh", "Morteza", ""], ["Stober", "Christina", ""], ["Ebert", "David S.", ""]]}, {"id": "1909.07353", "submitter": "David Ott", "authors": "David Ott, Christopher Peikert, and other workshop participants", "title": "Identifying Research Challenges in Post Quantum Cryptography Migration\n  and Cryptographic Agility", "comments": "A Computing Community Consortium (CCC) workshop report, 30 pages", "journal-ref": null, "doi": null, "report-no": "ccc2019report_5", "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The implications of sufficiently large quantum computers for widely used\npublic-key cryptography is well-documented and increasingly discussed by the\nsecurity community. An April 2016 report by the National Institute of Standards\nand Technology (NIST), notably, calls out the need for new standards to replace\ncryptosystems based on integer factorization and discrete logarithm problems,\nwhich have been shown to be vulnerable to Shor's quantum algorithm for prime\nfactorization. Specifically, widely used RSA, ECDSA, ECDH, and DSA\ncryptosystems will need to be replaced by post-quantum cryptography (PQC)\nalternatives (also known as quantum-resistant or quantum-safe cryptography).\nFailure to transition before sufficiently powerful quantum computers are\nrealized will jeopardize the security of public key cryptosystems which are\nwidely deployed within communication protocols, digital signing mechanisms,\nauthentication frameworks, and more. To avoid this, NIST has actively led a PQC\nstandardization effort since 2016, leveraging a large and international\nresearch community.\n  On January 31-February 1, 2019, the Computing Community Consortium (CCC) held\na workshop in Washington, D.C. to discuss research challenges associated with\nPQC migration. Entitled, \"Identifying Research Challenges in Post Quantum\nCryptography Migration and Cryptographic Agility\", participants came from three\ndistinct yet related communities: cryptographers contributing to the NIST PQC\nstandards effort, applied cryptographers with expertise in creating\ncryptographic solutions and implementing cryptography in real-world settings,\nand industry practitioners with expertise in deploying cryptographic standards\nwithin products and compute infrastructures. Discussion centered around two key\nthemes: identifying constituent challenges in PQC migration and imagining a new\nscience of \"cryptographic agility\".\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 17:38:14 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Ott", "David", ""], ["Peikert", "Christopher", ""], ["participants", "other workshop", ""]]}, {"id": "1909.07370", "submitter": "Awais Ashfaq", "authors": "Awais Ashfaq, Slawomir Nowaczyk", "title": "Machine learning in healthcare -- a system's perspective", "comments": "ACM SIGKDD Workshop on Epidemiology meets Data Mining and Knowledge\n  Discovery (epiDAMIK), August 2019 Anchorage, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A consequence of the fragmented and siloed healthcare landscape is that\npatient care (and data) is split along multitude of different facilities and\ncomputer systems and enabling interoperability between these systems is hard.\nThe lack interoperability not only hinders continuity of care and burdens\nproviders, but also hinders effective application of Machine Learning (ML)\nalgorithms. Thus, most current ML algorithms, designed to understand patient\ncare and facilitate clinical decision-support, are trained on limited datasets.\nThis approach is analogous to the Newtonian paradigm of Reductionism in which a\nsystem is broken down into elementary components and a description of the whole\nis formed by understanding those components individually. A key limitation of\nthe reductionist approach is that it ignores the component-component\ninteractions and dynamics within the system which are often of prime\nsignificance in understanding the overall behaviour of complex adaptive systems\n(CAS). Healthcare is a CAS.\n  Though the application of ML on health data have shown incremental\nimprovements for clinical decision support, ML has a much a broader potential\nto restructure care delivery as a whole and maximize care value. However, this\nML potential remains largely untapped: primarily due to functional limitations\nof Electronic Health Records (EHR) and the inability to see the healthcare\nsystem as a whole. This viewpoint (i) articulates the healthcare as a complex\nsystem which has a biological and an organizational perspective, (ii) motivates\nwith examples, the need of a system's approach when addressing healthcare\nchallenges via ML and, (iii) emphasizes to unleash EHR functionality - while\nduly respecting all ethical and legal concerns - to reap full benefits of ML.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 06:13:53 GMT"}, {"version": "v2", "created": "Sun, 19 Jan 2020 21:50:27 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Ashfaq", "Awais", ""], ["Nowaczyk", "Slawomir", ""]]}, {"id": "1909.07371", "submitter": "Fernan Villa", "authors": "Diana Medina, Grissa Maturana, Fern\\'an Villa, Carlos Mario Zapata", "title": "A prototype for a serious digital game to teach linguistic ontologies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The objective of ontologies is to increase the compression of a given domain\nby eliminating interpretation problems. Among kinds of ontologies are\nlinguistics ontologies which are ontologies used to simplify the interface\nbetween domain knowledge and linguistic components. Digital games have received\nincreasing interest from educators in recent years for their potential to\nenhance the language learning and linguistic learning experience. Within the\nliterature are games to teach ontologies of a specific domain, and games that\nuse ontologies to facilitate the understanding of a given domain. Other\neducational games teach linguistics or vocabulary in contexts in which language\nis useful and meaningful. Although games help to understand difficult topics,\nthe use of games that seek to meet the learning objectives of linguistics is\nnot very popular and those focused on teaching linguistic ontologies are\nscarce. To solve the lack of the recreational resource for teaching linguistics\nin this document a prototype of a digital game called onto-ling is proposed.\nThe goal is for the player to learn the relationship between concepts according\nto semantics, types of concepts and relationships through a game of levels.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 05:27:15 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 17:35:15 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Medina", "Diana", ""], ["Maturana", "Grissa", ""], ["Villa", "Fern\u00e1n", ""], ["Zapata", "Carlos Mario", ""]]}, {"id": "1909.07372", "submitter": "Prayitno Prayitno", "authors": "Karisma Trinanda Putra, Jing-Doo Wang, Eko Prasetyo, Prayitno", "title": "Modeling Traffic Congestion with Spatiotemporal Big Data for An\n  Intelligent Freeway Monitoring System", "comments": "The article was published without the co-Author's notice, and it is\n  withdrawn due to his objection", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traffic congestion is a complex, nonlinear spatiotemporal modeling problem.\nBy collecting and analyzing a vast quantity and different categories of\ninformation, traffic flow, and road congestion can be predicted and controlled\non an intelligent transportation system. This report provides an analysis of\ntraveling time across Taiwan from North to South, vice versa. We analyze\ntraffic in a national freeway between Tainan and Kaohsiung section, which\nrepresents the common trip of the population in Southern Taiwan. The data is\nrecorded using the Electronic Toll Collection System (ETC) provided by Ministry\nof Transportation in Taiwan. We use MapReduce framework to process data into a\nsmaller task which can be distributed on several computer clusters to speed up\nthe process. The results show that the spatiotemporal model of traffic flow is\nstrongly influenced by direction, working hour, and holidays with a recurring\npattern for each week. The distinctive pattern inside the spatiotemporal\ndataset can be used on an AI-powered decision-making system for future\ndevelopment.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 07:26:39 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 21:30:34 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Putra", "Karisma Trinanda", ""], ["Wang", "Jing-Doo", ""], ["Prasetyo", "Eko", ""], ["Prayitno", "", ""]]}, {"id": "1909.07438", "submitter": "Emil Pricop", "authors": "Emil Pricop", "title": "On the design of an innovative solution for increasing hazardous\n  materials transportation safety", "comments": "Paper presented at the 17th International Conference on System\n  Theory, Control and Computing (ICSTCC 2013), Sinaia, Romania - 11-13 October\n  2013", "journal-ref": "Proceedings of the 7th International Conference on System Theory,\n  Control and Computing (ICSTCC 2013)", "doi": "10.1109/ICSTCC.2013.6689029", "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transportation of hazardous materials represent a high risk operation all\nover the world. Flammable substances such as oil, kerosene, hydrocarbons,\nammonium nitrate or toxic products are shipped every day on busy roads by\ntrucks. An innovative solution for increasing hazardous materials\ntransportation safety is presented in this paper. The solution integrates three\nsystems: one mounted on the truck that can alert authorities in case of an\naccident, one portable system for quick identification of the carried\nsubstances and intervention method and a component for real-time road\nmonitoring. The proposed solution is based on RFID card with a special memory\nstructure presented in this paper\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 06:45:51 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Pricop", "Emil", ""]]}, {"id": "1909.07444", "submitter": "Ephrem Admasu Yekun", "authors": "Ephrem Admasu Yekun and Abrahaley Teklay", "title": "Student Performance Prediction with Optimum Multilabel Ensemble Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the important measures of quality of education is the performance of\nstudents in the academic settings. Nowadays, abundant data is stored in\neducational institutions about students which can help to discover insight on\nhow students are learning and how to improve their performance ahead of time\nusing data mining techniques. In this paper, we developed a student performance\nprediction model that predicts the performance of high school students for the\nnext semester for five courses. We modeled our prediction system as a\nmulti-label classification task and used support vector machine (SVM), Random\nForest (RF), K-nearest Neighbors (KNN), and Mult-layer perceptron (MLP) as\nbase-classifiers to train our model. We further improved the performance of the\nprediction model using state-of-the-art partitioning schemes to divide the\nlabel space into smaller spaces and use Label Powerset (LP) transformation\nmethod to transform each labelset into a multi-class classification task. The\nproposed model achieved better performance in terms of different evaluation\nmetrics when compared to other multi-label learning tasks such as binary\nrelevance and classifier chains.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 11:59:26 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Yekun", "Ephrem Admasu", ""], ["Teklay", "Abrahaley", ""]]}, {"id": "1909.07462", "submitter": "Simon Thorne", "authors": "Simon Thorne and Jamie Hancock", "title": "A Case Study of Spreadsheet Use within the Finance and Academic Registry\n  units within a Higher Education Institution", "comments": "15 Pages, 20 Tables", "journal-ref": "Proceedings of the EuSpRIG 2019 Conference \"Spreadsheet Risk\n  Management\", Browns, Covent Garden, London, pp61-78, ISBN: 978-1-905404-56-8", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the findings of a case study of spreadsheet use in a\nhigher education institution in the UK. The paper considers the use of\nspreadsheets in two units of the organisation, academic registry and finance.\nSpreadsheet use is explored in terms of importance, training, experience,\npurpose, techniques deployed, size of spreadsheets created and sharing of\nspreadsheets. The implications of the results are then considered in terms of\naccurate reporting to external funding bodies such the funding councils,\ninternal data integrity and internal data efficiencies. The results show a\nlarge volume of spreadsheets being created and used, that the profile of\nspreadsheet developers is typical of other studies of spreadsheet use and the\nneed for the organisation to have clear principles and guidelines for the\ndevelopment of spreadsheet models in the organisation to ensure data integrity,\nreduce duplication of effort and to optimise the use of spreadsheets to meet\nthe institutions goals.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 19:50:37 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Thorne", "Simon", ""], ["Hancock", "Jamie", ""]]}, {"id": "1909.07523", "submitter": "Lianwei Wu", "authors": "Lianwei Wu, Yuan Rao, Ambreen Nazir, Haolin Jin", "title": "Discovering Differential Features: Adversarial Learning for Information\n  Credibility Evaluation", "comments": "Information Sciences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A series of deep learning approaches extract a large number of credibility\nfeatures to detect fake news on the Internet. However, these extracted features\nstill suffer from many irrelevant and noisy features that restrict severely the\nperformance of the approaches. In this paper, we propose a novel model based on\nAdversarial Networks and inspirited by the Shared-Private model (ANSP), which\naims at reducing common, irrelevant features from the extracted features for\ninformation credibility evaluation. Specifically, ANSP involves two tasks: one\nis to prevent the binary classification of true and false information for\ncapturing common features relying on adversarial networks guided by\nreinforcement learning. Another extracts credibility features (henceforth,\nprivate features) from multiple types of credibility information and compares\nwith the common features through two strategies, i.e., orthogonality\nconstraints and KL-divergence for making the private features more\ndifferential. Experiments first on two six-label LIAR and Weibo datasets\ndemonstrate that ANSP achieves the state-of-the-art performance, boosting the\naccuracy by 2.1%, 3.1%, respectively and then on four-label Twitter16 validate\nthe robustness of the model with 1.8% performance improvements.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 23:53:59 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Wu", "Lianwei", ""], ["Rao", "Yuan", ""], ["Nazir", "Ambreen", ""], ["Jin", "Haolin", ""]]}, {"id": "1909.07683", "submitter": "Palakorn Achananuparp", "authors": "Yue Liu, Helena Lee, Palakorn Achananuparp, Ee-Peng Lim, Tzu-Ling\n  Cheng, Shou-De Lin", "title": "Characterizing and Predicting Repeat Food Consumption Behavior for\n  Just-in-Time Interventions", "comments": "To appear in the Proceedings of Digital Public Health 2019", "journal-ref": null, "doi": "10.1145/3357729.3357736", "report-no": null, "categories": "cs.IR cs.CY cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human beings are creatures of habit. In their daily life, people tend to\nrepeatedly consume similar types of food items over several days and\noccasionally switch to consuming different types of items when the consumptions\nbecome overly monotonous. However, the novel and repeat consumption behaviors\nhave not been studied in food recommendation research. More importantly, the\nability to predict daily eating habits of individuals is crucial to improve the\neffectiveness of food recommender systems in facilitating healthy lifestyle\nchange. In this study, we analyze the patterns of repeat food consumptions\nusing large-scale consumption data from a popular online fitness community\ncalled MyFitnessPal (MFP), conduct an offline evaluation of various\nstate-of-the-art algorithms in predicting the next-day food consumption, and\nanalyze their performance across different demographic groups and contexts. The\nexperiment results show that algorithms incorporating the\nexploration-and-exploitation and temporal dynamics are more effective in the\nnext-day recommendation task than most state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 09:51:24 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Liu", "Yue", ""], ["Lee", "Helena", ""], ["Achananuparp", "Palakorn", ""], ["Lim", "Ee-Peng", ""], ["Cheng", "Tzu-Ling", ""], ["Lin", "Shou-De", ""]]}, {"id": "1909.07685", "submitter": "Allan Gr{\\o}nlund", "authors": "Lars Arge, Allan Gr{\\o}nlund, Svend Christian Svendsen, Jonas Tranberg", "title": "Learning to Find Hydrological Corrections", "comments": "27th ACM SIGSPATIAL International Conference on Advances in\n  Geographic Information Systems (ACM SIGSPATIAL 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High resolution Digital Elevation models, such as the (Big) grid terrain\nmodel of Denmark with more than 200 billion measurements, is a basic\nrequirement for water flow modelling and flood risk analysis. However, a large\nnumber of modifications often need to be made to even very accurate terrain\nmodels, such as the Danish model, before they can be used in realistic flow\nmodeling. These modifications include removal of bridges, which otherwise will\nact as dams in flow modeling, and inclusion of culverts that transport water\nunderneath roads. In fact, the danish model is accompanied by a detailed set of\nhydrological corrections for the digital elevation model. However, producing\nthese hydrological corrections is a very slow an expensive process, since it is\nto a large extent done manually and often with local input. This also means\nthat corrections can be of varying quality. In this paper we propose a new\nalgorithmic apporach based on machine learning and convolutional neural\nnetworks for automatically detecting hydrological corrections for such large\nterrain data. Our model is able to detect most hydrological corrections known\nfor the danish model and quite a few more that should have been included in the\noriginal list.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 09:54:38 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Arge", "Lars", ""], ["Gr\u00f8nlund", "Allan", ""], ["Svendsen", "Svend Christian", ""], ["Tranberg", "Jonas", ""]]}, {"id": "1909.07881", "submitter": "Palakorn Achananuparp", "authors": "Helena Lee, Palakorn Achananuparp, Yue Liu, Ee-Peng Lim, Lav R.\n  Varshney", "title": "Estimating Glycemic Impact of Cooking Recipes via Online Crowdsourcing\n  and Machine Learning", "comments": "To appear in the Proceedings of Digital Public Health 2019 as short\n  paper", "journal-ref": null, "doi": "10.1145/3357729.3357748", "report-no": null, "categories": "cs.CY cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consumption of diets with low glycemic impact is highly recommended for\ndiabetics and pre-diabetics as it helps maintain their blood glucose levels.\nHowever, laboratory analysis of dietary glycemic potency is time-consuming and\nexpensive. In this paper, we explore a data-driven approach utilizing online\ncrowdsourcing and machine learning to estimate the glycemic impact of cooking\nrecipes. We show that a commonly used healthiness metric may not always be\neffective in determining recipes suitable for diabetics, thus emphasizing the\nimportance of the glycemic-impact estimation task. Our best classification\nmodel, trained on nutritional and crowdsourced data obtained from Amazon\nMechanical Turk (AMT), can accurately identify recipes which are unhealthful\nfor diabetics.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 15:14:51 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Lee", "Helena", ""], ["Achananuparp", "Palakorn", ""], ["Liu", "Yue", ""], ["Lim", "Ee-Peng", ""], ["Varshney", "Lav R.", ""]]}, {"id": "1909.07929", "submitter": "Kaylea Champion", "authors": "Kaylea Champion, Nora McDonald, Stephanie Bankes, Joseph Zhang, Rachel\n  Greenstadt, Andrea Forte, Benjamin Mako Hill", "title": "A Forensic Qualitative Analysis of Contributions to Wikipedia from\n  Anonymity Seeking Users", "comments": null, "journal-ref": null, "doi": "10.1145/3359155", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  By choice or by necessity, some contributors to commons-based peer production\nsites use privacy-protecting services to remain anonymous. As anonymity\nseekers, users of the Tor network have been cast both as ill-intentioned\nvandals and as vulnerable populations concerned with their privacy. In this\nstudy, we use a dataset drawn from a corpus of Tor edits to Wikipedia to\nuncover the character of Tor users' contributions. We build in-depth narrative\ndescriptions of Tor users' actions and conduct a thematic analysis that places\ntheir editing activity into seven broad groups. We find that although their use\nof a privacy-protecting service marks them as unusual within Wikipedia, the\ncharacter of many Tor users' contributions is in line with the expectations and\nnorms of Wikipedia. However, our themes point to several important places where\nlack of trust promotes disorder, and to contributions where risks to\ncontributors, service providers, and communities are unaligned.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 16:51:09 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Champion", "Kaylea", ""], ["McDonald", "Nora", ""], ["Bankes", "Stephanie", ""], ["Zhang", "Joseph", ""], ["Greenstadt", "Rachel", ""], ["Forte", "Andrea", ""], ["Hill", "Benjamin Mako", ""]]}, {"id": "1909.08106", "submitter": "Shashank Srikanth", "authors": "Shashank Srikanth, Aanshul Sadaria, Himanshu Bhatia, Kanay Gupta,\n  Pratik Jain, Ponnurangam Kumaraguru", "title": "Don't cross that stop line: Characterizing Traffic Violations in\n  Metropolitan Cities", "comments": "9 pages, Pre-Print submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In modern metropolitan cities, the task of ensuring safe roads is of\nparamount importance. Automated systems of e-challans (Electronic\ntraffic-violation receipt) are now being deployed across cities to record\ntraffic violations and to issue fines. In the present study, an automated\ne-challan system established in Ahmedabad (Gujarat, India) has been analyzed\nfor characterizing user behaviour, violation types as well as finding spatial\nand temporal patterns in the data. We describe a method of collecting e-challan\ndata from the e-challan portal of Ahmedabad traffic police and create a dataset\nof over 3 million e-challans. The dataset was first analyzed to characterize\nuser behaviour with respect to repeat offenses and fine payment. We demonstrate\nthat a lot of users repeat their offenses (traffic violation) frequently and\nare less likely to pay fines of higher value. Next, we analyze the data from a\nspatial and temporal perspective and identify certain spatio-temporal patterns\npresent in our dataset. We find that there is a drastic increase/decrease in\nthe number of e-challans issued during the festival days and identify a few\nhotspots in the city that have high intensity of traffic violations. In the\nend, we propose a set of 5 features to model recidivism in traffic violations\nand train multiple classifiers on our dataset to evaluate the effectiveness of\nour proposed features. The proposed approach achieves 95% accuracy on the\ndataset.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 21:15:53 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 16:50:38 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Srikanth", "Shashank", ""], ["Sadaria", "Aanshul", ""], ["Bhatia", "Himanshu", ""], ["Gupta", "Kanay", ""], ["Jain", "Pratik", ""], ["Kumaraguru", "Ponnurangam", ""]]}, {"id": "1909.08219", "submitter": "Seung Bin Baik", "authors": "Keum Gang Cha, Soo-Ryeon Lee, Jung-Woo Lee, Seung Bin Baik", "title": "Performance of Recommender Systems: Based on Content Navigator and\n  Collaborative Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the world of big data, many people find it difficult to access the\ninformation they need quickly and accurately. In order to overcome this,\nresearch on the system that recommends information accurately to users is\ncontinuously conducted. Collaborative Filtering is one of the famous algorithms\namong the most used in the industry. However, collaborative filtering is\ndifficult to use in online systems because user recommendation is highly\nvolatile in recommendation quality and requires computation using large\nmatrices. To overcome this problem, this paper proposes a method similar to\ndatabase queries and a clustering method (Contents Navigator) originating from\na complex network.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 05:58:34 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Cha", "Keum Gang", ""], ["Lee", "Soo-Ryeon", ""], ["Lee", "Jung-Woo", ""], ["Baik", "Seung Bin", ""]]}, {"id": "1909.08740", "submitter": "Philipe Melo", "authors": "Philipe de Freitas Melo, Carolina Coimbra Vieira, Kiran Garimella,\n  Pedro O. S. Vaz de Melo, Fabr\\'icio Benevenuto", "title": "Can WhatsApp Counter Misinformation by Limiting Message Forwarding?", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  WhatsApp is the most popular messaging app in the world. The closed nature of\nthe app, in addition to the ease of transferring multimedia and sharing\ninformation to large-scale groups make WhatsApp unique among other platforms,\nwhere an anonymous encrypted messages can become viral, reaching multiple users\nin a short period of time. The personal feeling and immediacy of messages\ndirectly delivered to the user's phone on WhatsApp was extensively abused to\nspread unfounded rumors and create misinformation campaigns during recent\nelections in Brazil and India. WhatsApp has been deploying measures to mitigate\nthis problem, such as reducing the limit for forwarding a message to at most\nfive users at once. Despite the welcomed effort to counter the problem, there\nis no evidence so far on the real effectiveness of such restrictions. In this\nwork, we propose a methodology to evaluate the effectiveness of such measures\non the spreading of misinformation circulating on WhatsApp. We use an\nepidemiological model and real data gathered from WhatsApp in Brazil, India and\nIndonesia to assess the impact of limiting virality features in this kind of\nnetwork. Our results suggest that the current efforts deployed by WhatsApp can\noffer significant delays on the information spread, but they are ineffective in\nblocking the propagation of misinformation campaigns through public groups when\nthe content has a high viral nature.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 23:53:24 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 14:51:16 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Melo", "Philipe de Freitas", ""], ["Vieira", "Carolina Coimbra", ""], ["Garimella", "Kiran", ""], ["de Melo", "Pedro O. S. Vaz", ""], ["Benevenuto", "Fabr\u00edcio", ""]]}, {"id": "1909.08839", "submitter": "Irawan Nurhas", "authors": "Irawan Nurhas, Jan Pawlowski, Stefan Geisler", "title": "Towards humane digitization: a wellbeing-driven process of personas\n  creation", "comments": "8 Pages, CHIuXiD '19: Proceedings of the 5th International ACM\n  In-Cooperation HCI and UX Conference", "journal-ref": null, "doi": "10.1145/3328243.3328247", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital transformation is a process of digitizing the working and living\nenvironment in which people are at the center of digitization. In this paper,\nwe present a personas-based guideline for system developers on how the\nhumanization of digital transformation integrates into the design process. The\nproposed guideline uses the positive personas from the beginning as a basis for\nthe transformation of the working environment into the digital form. We used\nthe literature research as a preliminary study for the process of\nwellbeing-driven digital transformation design, consisting of questions for\nstructuring the required information in the positive personas as well as a\npotential method that could be integrated into the wellbeing-based design\nprocess.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 07:55:17 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Nurhas", "Irawan", ""], ["Pawlowski", "Jan", ""], ["Geisler", "Stefan", ""]]}, {"id": "1909.09141", "submitter": "Elliot Creager", "authors": "Elliot Creager, David Madras, Toniann Pitassi, Richard Zemel", "title": "Causal Modeling for Fairness in Dynamical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many application areas---lending, education, and online recommenders, for\nexample---fairness and equity concerns emerge when a machine learning system\ninteracts with a dynamically changing environment to produce both immediate and\nlong-term effects for individuals and demographic groups. We discuss causal\ndirected acyclic graphs (DAGs) as a unifying framework for the recent\nliterature on fairness in such dynamical systems. We show that this formulation\naffords several new directions of inquiry to the modeler, where causal\nassumptions can be expressed and manipulated. We emphasize the importance of\ncomputing interventional quantities in the dynamical fairness setting, and show\nhow causal assumptions enable simulation (when environment dynamics are known)\nand off-policy estimation (when dynamics are unknown) of intervention on short-\nand long-term outcomes, at both the group and individual levels.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 20:21:56 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 17:43:02 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Creager", "Elliot", ""], ["Madras", "David", ""], ["Pitassi", "Toniann", ""], ["Zemel", "Richard", ""]]}, {"id": "1909.09774", "submitter": "Deepank Verma", "authors": "Deepank Verma, Arnab Jana", "title": "LULC classification methodology based on simple Convolutional Neural\n  Network to map complex urban forms at finer scale: Evidence from Mumbai", "comments": "28 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The satellite imagery classification task is fundamental to spatial knowledge\ndiscovery. Several image classification methods are used to create standardized\nLand use and Land cover (LULC) maps, which facilitate research on spatial and\necological processes and human activities. Local Climate Zones (LCZ)\nclassification maps are an example of standardized maps which have been widely\nused to demarcate the homogeneity in built and natural character in the cities.\nThe LCZ classification scheme is primarily focused on urban climate-related\nresearch, in which 17 climate zones are mapped in a city area with the 100-150m\nspatial resolution. Each zone exhibits physical properties related to urban\nform and functions essential for thermal behavior studies. Extending this\nwidely adopted approach to create LULC maps at finer resolution using the LCZ\nmapping scheme would benefit the allied domains of urban planning,\ntransportation, and water resources management. This study proposes a novel\nsolution to generate classification maps with a 10-band Sentinel-2B dataset and\nConvolutional Neural Networks (CNN) at the 10m spatial resolution. The\nclassification benefits from CNNs property to preserve local structures in the\nimage datasets. The proposed CNN model outperforms traditional machine learning\nmodels such as Artificial Neural Network, Random Forests, and Support Vector\nMachines. The overall accuracy and kappa statistic of the CNN model trained on\n14 urban and natural classes are 82 percent and 0.81, respectively. The study\nalso discusses the utility of the model for specialized remote sensing tasks\nsuch as change detection, identification of slum settlements, and mapping\npervious/impervious layers in urban settlements with higher accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 05:00:29 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 06:50:30 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Verma", "Deepank", ""], ["Jana", "Arnab", ""]]}, {"id": "1909.09942", "submitter": "Shujun Li", "authors": "Yang Lu, Shujun Li, Athina Ioannou and Iis Tussyadiah", "title": "From Data Disclosure to Privacy Nudges: A Privacy-aware and User-centric\n  Personal Data Management Framework", "comments": "18 pages, 6 figures, accepted to DependSys 2019 (5th International\n  Conference on Dependability in Sensor, Cloud, and Big Data Systems and\n  Applications), to be held from November 12-15, 2019 in Guangzhou, China, to\n  be published in a volume of Communications in Computer and Information\n  Science by Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.HC cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Although there are privacy-enhancing tools designed to protect users' online\nprivacy, it is surprising to see a lack of user-centric solutions allowing\nprivacy control based on the joint assessment of privacy risks and benefits,\ndue to data disclosure to multiple platforms. In this paper, we propose a\nconceptual framework to fill the gap: aiming at the user-centric privacy\nprotection, we show the framework can not only assess privacy risks in using\nonline services but also the added values earned from data disclosure. Through\nfollowing a human-in-the-loop approach, it is expected the framework provides a\npersonalized solution via preference learning, continuous privacy assessment,\nbehavior monitoring and nudging. Finally, we describe a case study towards\n\"leisure travelers\" and several future areas to be studied in the ongoing\nproject.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 05:55:56 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Lu", "Yang", ""], ["Li", "Shujun", ""], ["Ioannou", "Athina", ""], ["Tussyadiah", "Iis", ""]]}, {"id": "1909.10005", "submitter": "Gourab K Patro", "authors": "Gourab K Patro, Abhijnan Chakraborty, Niloy Ganguly, Krishna P.\n  Gummadi", "title": "Incremental Fairness in Two-Sided Market Platforms: On Smoothly Updating\n  Recommendations", "comments": "To Appear In the Proceedings of 34th AAAI Conference on Artificial\n  Intelligence (AAAI), New York, USA, Feb 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Major online platforms today can be thought of as two-sided markets with\nproducers and customers of goods and services. There have been concerns that\nover-emphasis on customer satisfaction by the platforms may affect the\nwell-being of the producers. To counter such issues, few recent works have\nattempted to incorporate fairness for the producers. However, these studies\nhave overlooked an important issue in such platforms -- to supposedly improve\ncustomer utility, the underlying algorithms are frequently updated, causing\nabrupt changes in the exposure of producers. In this work, we focus on the\nfairness issues arising out of such frequent updates, and argue for incremental\nupdates of the platform algorithms so that the producers have enough time to\nadjust (both logistically and mentally) to the change. However, naive\nincremental updates may become unfair to the customers. Thus focusing on\nrecommendations deployed on two-sided platforms, we formulate an ILP based\nonline optimization to deploy changes incrementally in n steps, where we can\nensure smooth transition of the exposure of items while guaranteeing a minimum\nutility for every customer. Evaluations over multiple real world datasets show\nthat our proposed mechanism for platform updates can be efficient and fair to\nboth the producers and the customers in two-sided platforms.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 13:39:22 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 13:06:45 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Patro", "Gourab K", ""], ["Chakraborty", "Abhijnan", ""], ["Ganguly", "Niloy", ""], ["Gummadi", "Krishna P.", ""]]}, {"id": "1909.10476", "submitter": "Binil Starly", "authors": "Binil Starly, Atin Angrish, Paul Cohen", "title": "Research Directions in Democratizing Innovation through Design\n  Automation, One-Click Manufacturing Services and Intelligent Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CV cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The digitalization of manufacturing has created opportunities for consumers\nto customize products that fit their individualized needs which in turn would\ndrive demand for manufacturing services. However, this pull-based manufacturing\nsystem production of extremely low quantity and limitless variety for products\nis expensive to implement. New emerging technology in design automation driven\nby data-driven computational design, manufacturing-as-a-service marketplaces\nand digitally enabled micro-factories holds promise towards democratization of\ninnovation. In this paper, scientific, technology and infrastructure challenges\nare identified and if solved, the impact of these emerging technologies on\nproduct innovation and future factory organization is discussed.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 16:56:08 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Starly", "Binil", ""], ["Angrish", "Atin", ""], ["Cohen", "Paul", ""]]}, {"id": "1909.10614", "submitter": "Shiwali Mohan", "authors": "Shiwali Mohan, Hesham Rakha, Matthew Klenk", "title": "Acceptable Planning: Influencing Individual Behavior to Reduce\n  Transportation Energy Expenditure of a City", "comments": null, "journal-ref": "Journal of Artificial Intelligence Research 66 (2019) 555-587", "doi": "10.1613/jair.1.11352", "report-no": null, "categories": "cs.AI cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our research aims at developing intelligent systems to reduce the\ntransportation-related energy expenditure of a large city by influencing\nindividual behavior. We introduce COPTER - an intelligent travel assistant that\nevaluates multi-modal travel alternatives to find a plan that is acceptable to\na person given their context and preferences. We propose a formulation for\nacceptable planning that brings together ideas from AI, machine learning, and\neconomics. This formulation has been incorporated in COPTER that produces\nacceptable plans in real-time. We adopt a novel empirical evaluation framework\nthat combines human decision data with a high fidelity multi-modal\ntransportation simulation to demonstrate a 4\\% energy reduction and 20\\% delay\nreduction in a realistic deployment scenario in Los Angeles, California, USA.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 20:55:18 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Mohan", "Shiwali", ""], ["Rakha", "Hesham", ""], ["Klenk", "Matthew", ""]]}, {"id": "1909.10941", "submitter": "Samer Chehade", "authors": "Samer Chehade (M2S, Tech-CICO), Nada Matta (Tech-CICO), Jean-Baptiste\n  Pothin (M2S), R\\'emi Cogranne (LM2S)", "title": "Data Interpretation Support in Rescue Operations: Application for French\n  Firefighters", "comments": null, "journal-ref": "2018 IEEE/ACS 15th International Conference on Computer Systems\n  and Applications (AICCSA), Oct 2018, Aqaba, Jordan", "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work aims at developing a system that supports French firefighters in\ndata interpretation during rescue operations. An application ontology is\nproposed based on existing crisis management ones and operational expertise\ncollection. After that, a knowledge-based system will be developed and\nintegrated in firefighters' environment. Our first studies are shown in this\npaper.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 14:09:26 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Chehade", "Samer", "", "M2S, Tech-CICO"], ["Matta", "Nada", "", "Tech-CICO"], ["Pothin", "Jean-Baptiste", "", "M2S"], ["Cogranne", "R\u00e9mi", "", "LM2S"]]}, {"id": "1909.11029", "submitter": "Iqbal H. Sarker", "authors": "Iqbal H. Sarker, A.S.M. Kayes, Md Hasan Furhad, Mohammad Mainul Islam\n  and Md Shohidul Islam", "title": "E-MIIM: An Ensemble Learning based Context-Aware Mobile Telephony Model\n  for Intelligent Interruption Management", "comments": "10 pages", "journal-ref": "Journal: AI and Society, Springer Nature, 2019", "doi": "10.1007/s00146-019-00898-8", "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, mobile telephony interruptions in our daily life activities are\ncommon because of the inappropriate ringing notifications of incoming phone\ncalls in different contexts. Such interruptions may impact on the work\nattention not only for the mobile phone owners but also the surrounding people.\nDecision tree is the most popular machine learning classification technique\nthat is used in existing context-aware mobile intelligent interruption\nmanagement (MIIM) model to overcome such issues. However, a single decision\ntree based context-aware model may cause overfitting problem and thus decrease\nthe prediction accuracy of the inferred model. Therefore, in this paper, we\npropose an ensemble machine learning based context-aware mobile telephony model\nfor the purpose of intelligent interruption management by taking into account\nmulti-dimensional contexts and name it \"E-MIIM\". The experimental results on\nindividuals' real life mobile telephony datasets show that our E-MIIM model is\nmore effective and outperforms existing MIIM model for predicting and managing\nindividual's mobile telephony interruptions based on their relevant contextual\ninformation.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 21:36:33 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Sarker", "Iqbal H.", ""], ["Kayes", "A. S. M.", ""], ["Furhad", "Md Hasan", ""], ["Islam", "Mohammad Mainul", ""], ["Islam", "Md Shohidul", ""]]}, {"id": "1909.11166", "submitter": "Aaron Yi Ding", "authors": "Aaron Yi Ding, Gianluca Limon De Jesus, Marijn Janssen", "title": "Ethical Hacking for IoT Security: A First Look into Bug Bounty Programs\n  and Responsible Disclosure", "comments": "Pre-print version for conference publication at ICTRS 2019", "journal-ref": null, "doi": "10.1145/3357767.3357774", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The security of the Internet of Things (IoT) has attracted much attention due\nto the growing number of IoT-oriented security incidents. IoT hardware and\nsoftware security vulnerabilities are exploited affecting many companies and\npersons. Since the causes of vulnerabilities go beyond pure technical measures,\nthere is a pressing demand nowadays to demystify IoT \"security complex\" and\ndevelop practical guidelines for both companies, consumers, and regulators. In\nthis paper, we present an initial study targeting an unexplored sphere in IoT\nby illuminating the potential of crowdsource ethical hacking approaches for\nenhancing IoT vulnerability management. We focus on Bug Bounty Programs (BBP)\nand Responsible Disclosure (RD), which stimulate hackers to report\nvulnerability in exchange for monetary rewards. We carried out a qualitative\ninvestigation supported by literature survey and expert interviews to explore\nhow BBP and RD can facilitate the practice of identifying, classifying,\nprioritizing, remediating, and mitigating IoT vulnerabilities in an effective\nand cost-efficient manner. Besides deriving tangible guidelines for IoT\nstakeholders, our study also sheds light on a systematic integration path to\ncombine BBP and RD with existing security practices (e.g., penetration test) to\nfurther boost overall IoT security.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 20:48:10 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Ding", "Aaron Yi", ""], ["De Jesus", "Gianluca Limon", ""], ["Janssen", "Marijn", ""]]}, {"id": "1909.11190", "submitter": "Vedran Sekara Mr.", "authors": "Vedran Sekara, Elisa Omodei, Laura Healy, Jan Beise, Claus Hansen,\n  Danzhen You, Saskia Blume and Manuel Garcia-Herranz", "title": "Mobile Phone Data for Children on the Move: Challenges and Opportunities", "comments": "13 pages, book chapter", "journal-ref": null, "doi": "10.1007/978-3-030-12554-7_3", "report-no": null, "categories": "physics.soc-ph cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, 95% of the global population has 2G mobile phone coverage and the\nnumber of individuals who own a mobile phone is at an all time high. Mobile\nphones generate rich data on billions of people across different societal\ncontexts and have in the last decade helped redefine how we do research and\nbuild tools to understand society. As such, mobile phone data has the potential\nto revolutionize how we tackle humanitarian problems, such as the many suffered\nby refugees all over the world. While promising, mobile phone data and the new\ncomputational approaches bring both opportunities and challenges. Mobile phone\ntraces contain detailed information regarding people's whereabouts, social\nlife, and even financial standing. Therefore, developing and adopting\nstrategies that open data up to the wider humanitarian and international\ndevelopment community for analysis and research while simultaneously protecting\nthe privacy of individuals is of paramount importance. Here we outline the\nchallenging situation of children on the move and actions UNICEF is pushing in\nhelping displaced children and youth globally, and discuss opportunities where\nmobile phone data can be used. We identify three key challenges: data access,\ndata and algorithmic bias, and operationalization of research, which need to be\naddressed if mobile phone data is to be successfully applied in humanitarian\ncontexts.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 21:19:11 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Sekara", "Vedran", ""], ["Omodei", "Elisa", ""], ["Healy", "Laura", ""], ["Beise", "Jan", ""], ["Hansen", "Claus", ""], ["You", "Danzhen", ""], ["Blume", "Saskia", ""], ["Garcia-Herranz", "Manuel", ""]]}, {"id": "1909.11272", "submitter": "Zijian Wang", "authors": "Zijian Wang and Christopher Potts", "title": "TalkDown: A Corpus for Condescension Detection in Context", "comments": "To appear at EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Condescending language use is caustic; it can bring dialogues to an end and\nbifurcate communities. Thus, systems for condescension detection could have a\nlarge positive impact. A challenge here is that condescension is often\nimpossible to detect from isolated utterances, as it depends on the discourse\nand social context. To address this, we present TalkDown, a new labeled dataset\nof condescending linguistic acts in context. We show that extending a\nlanguage-only model with representations of the discourse improves performance,\nand we motivate techniques for dealing with the low rates of condescension\noverall. We also use our model to estimate condescension rates in various\nonline communities and relate these differences to differing community norms.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 03:39:00 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Wang", "Zijian", ""], ["Potts", "Christopher", ""]]}, {"id": "1909.11341", "submitter": "Shintaro Uchiyama", "authors": "Shintaro Uchiyama, Hayato Okumoto, Mitsuo Yoshida, Yuko Ichikawa and\n  Kyoji Umemura", "title": "Usefulness of Instructor Annotations on Flipped Learning Preparation\n  Video System", "comments": "The 2019 International Conference on Advanced Informatics: Concepts,\n  Theory and Applications", "journal-ref": null, "doi": "10.1109/ICAICTA.2019.8904173", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flipped learning is a method that flips in/out class activities to make\nlectures learner-centered. In flipped learning, comments from learners on\npreparation material are useful information for instructors to consider before\ndeciding in-class topics. Thus, we arrive at the notion that receiving comments\nfrom instructors will be effective for learners watching the video. By\nincluding annotations from instructors, we propose to improve the quality of\ncontent for learners and thus enhance learners' motivation and study\nsatisfaction. To achieve this, we introduced \"Steering Mark,\" a tool that\nenables learners to easily grasp the overall structure of a video, to the video\nlearning system. We examined the effectiveness and influence of Steering Mark\nthrough an experiment with 34 undergraduate learners. As a result, Steering\nMark was found to be useful in improving the quality of video content for\nlearners.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 08:36:42 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Uchiyama", "Shintaro", ""], ["Okumoto", "Hayato", ""], ["Yoshida", "Mitsuo", ""], ["Ichikawa", "Yuko", ""], ["Umemura", "Kyoji", ""]]}, {"id": "1909.11766", "submitter": "Lionel Robert", "authors": "Qiaoning Zhang, Connor Esterwood, X. Jessie Yang, Lionel P. Robert Jr", "title": "An Automated Vehicle (AV) like Me? The Impact of Personality\n  Similarities and Differences between Humans and AVs", "comments": "4 pages, 2 figures, 2019 AAAI Fall Symposium on Artificial\n  Intelligence for Human-Robot Interaction", "journal-ref": null, "doi": null, "report-no": "AI-HRI/2019/01", "categories": "cs.HC cs.AI cs.CY cs.RO", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  To better understand the impacts of similarities and dissimilarities in human\nand AV personalities we conducted an experimental study with 443 individuals.\nGenerally, similarities in human and AV personalities led to a higher\nperception of AV safety only when both were high in specific personality\ntraits. Dissimilarities in human and AV personalities also yielded a higher\nperception of AV safety, but only when the AV was higher than the human in a\nparticular personality trait.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 13:51:28 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Zhang", "Qiaoning", ""], ["Esterwood", "Connor", ""], ["Yang", "X. Jessie", ""], ["Robert", "Lionel P.", "Jr"]]}, {"id": "1909.11869", "submitter": "Joshua Kroll", "authors": "Deirdre K. Mulligan, Joshua A. Kroll, Nitin Kohli, Richmond Y. Wong", "title": "This Thing Called Fairness: Disciplinary Confusion Realizing a Value in\n  Technology", "comments": "36 pages", "journal-ref": "Proc. ACM Hum.-Comput. Interact. 3, CSCW, Article 119 (November\n  2019)", "doi": "10.1145/3359221", "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The explosion in the use of software in important sociotechnical systems has\nrenewed focus on the study of the way technical constructs reflect policies,\nnorms, and human values. This effort requires the engagement of scholars and\npractitioners from many disciplines. And yet, these disciplines often\nconceptualize the operative values very differently while referring to them\nusing the same vocabulary. The resulting conflation of ideas confuses\ndiscussions about values in technology at disciplinary boundaries. In the\nservice of improving this situation, this paper examines the value of shared\nvocabularies, analytics, and other tools that facilitate conversations about\nvalues in light of these disciplinary specific conceptualizations, the role\nsuch tools play in furthering research and practice, outlines different\nconceptions of \"fairness\" deployed in discussions about computer systems, and\nprovides an analytic tool for interdisciplinary discussions and collaborations\naround the concept of fairness. We use a case study of risk assessments in\ncriminal justice applications to both motivate our effort--describing how\nconflation of different concepts under the banner of \"fairness\" led to\nunproductive confusion--and illustrate the value of the fairness analytic by\ndemonstrating how the rigorous analysis it enables can assist in identifying\nkey areas of theoretical, political, and practical misunderstanding or\ndisagreement, and where desired support alignment or collaboration in the\nabsence of consensus.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 03:55:20 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Mulligan", "Deirdre K.", ""], ["Kroll", "Joshua A.", ""], ["Kohli", "Nitin", ""], ["Wong", "Richmond Y.", ""]]}, {"id": "1909.12262", "submitter": "Eren Aksoy", "authors": "Martin Cooney, Jacob Pihl, Hanna Larsson, Abbas Orand, Eren Erdal\n  Aksoy", "title": "Exercising with an \"Iron Man\": Design for a Robot Exercise Coach for\n  Persons with Dementia", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Socially assistive robots are increasingly being designed to interact with\nhumans in various therapeutical scenarios. We believe that one useful scenario\nis providing exercise coaching for Persons with Dementia (PwD), which involves\nunique challenges related to memory and communication. We present a design for\na robot that can seek to help a PWD to conduct exercises by recognizing\nbehaviors and providing feedback, in an online, multimodal, and engaging way.\nAdditionally, in line with a mid-fidelity prototyping approach, we report on\nsome feedback from an exploratory user study using a Baxter robot, which\nprovided some confirmation of the usefulness of the general scenario;\nfurthermore, the results suggested the degree of a robot's feedback could be\ntailored to provide impressions of attentiveness or fun. Limitations and\npossibilities for future improvement are outlined, touching on deep learning\nand haptic feedback, toward informing next designs.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 17:17:35 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Cooney", "Martin", ""], ["Pihl", "Jacob", ""], ["Larsson", "Hanna", ""], ["Orand", "Abbas", ""], ["Aksoy", "Eren Erdal", ""]]}, {"id": "1909.12393", "submitter": "Egon L\\\"uftenegger", "authors": "Egon L\\\"uftenegger and Selver Softic", "title": "Service-Dominant Business Model Financial Validation: Cost-Benefit\n  Analysis with Business Processes and Service- Dominant Business Models", "comments": "Proceedings of 30th Central European Conference on Information and\n  Intelligent Systems (CECIIS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present our software-supported method for analyzing the\neconomic feasibility of business models. The method integrates the business\nmodels and business processes perspectives for analyzing how a company\nappropriates the financial cost and benefits. In this method, we use the\nService-Dominant Business Model Radar to specify business models, then\ntranslate the specified business model into a business process for analyzing\nthe financial feasibility of a business model. At the final step in our method,\nwe use the generated business process in the previous step with a\nsoftware-based tool, The Cost-Benefit Tracker, for analyzing the economic\npotential of the business model. We designed and developed the Cost-Benefit\nTracker as a simple software-based BPMN 2.0 tool by integrating the concepts of\nthe Service-Dominant Business Model Radar tightly. As a result, the software is\nsimple and straightforward to use than enterprise BPMN 2.0 software. Hence,\nentrepreneurs can use the presented software-supported method to financially\nevaluate business model concepts specified with the Service-Dominant Business\nModel Radar.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 21:07:54 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["L\u00fcftenegger", "Egon", ""], ["Softic", "Selver", ""]]}, {"id": "1909.12454", "submitter": "Scott Ruoti", "authors": "Scott Ruoti, Ben Kaiser, Arkady Yerukhimovich, Jeremy Clark, Robert\n  Cunningham", "title": "SoK: Blockchain Technology and Its Potential Use Cases", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin's success has led to significant interest in its underlying\ncomponents, particularly Blockchain technology. Over 10 years after Bitcoin's\ninitial release, the community still suffers from a lack of clarity regarding\nwhat properties defines Blockchain technology, its relationship to similar\ntechnologies, and which of its proposed use-cases are tenable and which are\nlittle more than hype. In this paper we answer four common questions regarding\nBlockchain technology: (1) what exactly is Blockchain technology, (2) what\ncapabilities does it provide, and (3) what are good applications for Blockchain\ntechnology, and (4) how does it relate to other approache distributed\ntechnologies (e.g., distributed databases). We accomplish this goal by using\ngrounded theory (a structured approach to gathering and analyzing qualitative\ndata) to thoroughly analyze a large corpus of literature on Blockchain\ntechnology. This method enables us to answer the above questions while limiting\nresearcher bias, separating thought leadership from peddled hype and\nidentifying open research questions related to Blockchain technology. The\naudience for this paper is broad as it aims to help researchers in a variety of\nareas come to a better understanding of Blockchain technology and identify\nwhether it may be of use in their own research.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 01:27:52 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Ruoti", "Scott", ""], ["Kaiser", "Ben", ""], ["Yerukhimovich", "Arkady", ""], ["Clark", "Jeremy", ""], ["Cunningham", "Robert", ""]]}, {"id": "1909.12622", "submitter": "Jan Ka{\\ss}el", "authors": "Maryam Foradi, Jan Ka{\\ss}el, Johannes Pein, Gregory R. Crane", "title": "Multi-Modal Citizen Science: From Disambiguation to Transcription of\n  Classical Literature", "comments": null, "journal-ref": "Proceedings of the 30th ACM Conference on Hypertext and Social\n  Media - HT 2019, 49-53. Hof, Germany: ACM Press", "doi": "10.1145/3342220.3343667", "report-no": null, "categories": "cs.CL cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The engagement of citizens in the research projects, including Digital\nHumanities projects, has risen in prominence in recent years. This type of\nengagement not only leads to incidental learning of participants but also\nindicates the added value of corpus enrichment via different types of\nannotations undertaken by users generating so-called smart texts. Our work\nfocuses on the continuous task of adding new layers of annotation to Classical\nLiterature. We aim to provide more extensive tools for readers of smart texts,\nenhancing their reading comprehension and at the same time empowering the\nlanguage learning by introducing intellectual tasks, i.e., linking, tagging,\nand disambiguation. The current study adds a new mode of annotation-audio\nannotations-to the extensively annotated corpus of poetry by the Persian poet\nHafiz. By proposing tasks with three different difficulty levels, we estimate\nthe users' ability of providing correct annotations in order to rate their\nanswers in further stages of the project, where no ground truth data is\navailable. While proficiency in Persian is beneficial, annotators with no\nknowledge of Persian are also able to add annotations to the corpus.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 11:19:21 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Foradi", "Maryam", ""], ["Ka\u00dfel", "Jan", ""], ["Pein", "Johannes", ""], ["Crane", "Gregory R.", ""]]}, {"id": "1909.12838", "submitter": "Alberto Barbado Gonzalez", "authors": "Richard Benjamins, Alberto Barbado, Daniel Sierra", "title": "Responsible AI by Design in Practice", "comments": "9 pages, 3 tables. Proceedings of the Human-Centered AI:\n  Trustworthiness of AI Models & Data (HAI) track at AAAI Fall Symposium, DC,\n  November 7-9, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recently, a lot of attention has been given to undesired consequences of\nArtificial Intelligence (AI), such as unfair bias leading to discrimination, or\nthe lack of explanations of the results of AI systems. There are several\nimportant questions to answer before AI can be deployed at scale in our\nbusinesses and societies. Most of these issues are being discussed by experts\nand the wider communities, and it seems there is broad consensus on where they\ncome from. There is, however, less consensus on, and experience with how to\npractically deal with those issues in organizations that develop and use AI,\nboth from a technical and organizational perspective. In this paper, we discuss\nthe practical case of a large organization that is putting in place a\ncompany-wide methodology to minimize the risk of undesired consequences of AI.\nWe hope that other organizations can learn from this and that our experience\ncontributes to making the best of AI while minimizing its risks.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 16:28:01 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 15:28:49 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Benjamins", "Richard", ""], ["Barbado", "Alberto", ""], ["Sierra", "Daniel", ""]]}, {"id": "1909.12905", "submitter": "Eric Clark", "authors": "Eric M. Clark, Scott C. Merrill, Luke Trinity, Gabriela Bucini,\n  Nicholas Cheney, Ollin Langle-Chimal, Trisha Shrum, Christopher Koliba, Asim\n  Zia, and Julia M. Smith", "title": "Using Digital Field Experiments To Elicit Risk Mitigation Behavioral\n  Strategies For Disease Management Across Agricultural Production Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Failing to mitigate propagation of disease spread can result in dire economic\nconsequences for agricultural networks. Pathogens like Porcine Epidemic\nDiarrhea virus, can quickly spread among producers. Biosecurity is designed to\nprevent infection transmission. When considering biosecurity investments,\nmanagement must balance the cost of protection versus the consequences of\ncontracting an infection. Thus, an examination of the decision making processes\nassociated with investment in biosecurity is important for enhancing system\nwide biosecurity. Data gathered from digital field experiments can provide\ninsights into behavioral strategies and inform the development of decision\nsupport systems. We created an online digital experiment to simulate outbreak\nscenarios among swine production supply chains, where participants were tasked\nwith making biosecurity investment decisions. In Experiment One, we quantified\nthe risk associated with each participant's decisions and delineated three\ndominant categories of risk attitudes: risk averse, risk tolerant, and\nopportunistic. Each risk class exhibited unique approaches in reaction to risk\nand disease information. We also tested how information uncertainty affects\nrisk aversion, by varying the amount of visibility of the infection as well as\nthe amount of biosecurity implemented across the system. We found evidence that\nmore visibility in the number of infected sites increases risk averse\nbehaviors, while more visibility in the amount of neighboring biosecurity\nincreased risk taking behaviors. In Experiment Two, we were surprised to find\nno evidence for differences in behavior of livestock specialists compared to\nAmazon Mechanical Turk participants. Our findings provide support for using\ndigital field experiments to study how risk communication affects behavior,\nwhich can provide insights towards more effective messaging strategies.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 20:04:09 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 12:00:48 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Clark", "Eric M.", ""], ["Merrill", "Scott C.", ""], ["Trinity", "Luke", ""], ["Bucini", "Gabriela", ""], ["Cheney", "Nicholas", ""], ["Langle-Chimal", "Ollin", ""], ["Shrum", "Trisha", ""], ["Koliba", "Christopher", ""], ["Zia", "Asim", ""], ["Smith", "Julia M.", ""]]}, {"id": "1909.12913", "submitter": "Prabin Sharma", "authors": "Prabin Sharma, Shubham Joshi, Subash Gautam, Sneha Maharjan, Vitor\n  Filipe, Manuel J. C. S. Reis", "title": "Student Engagement Detection Using Emotion Analysis, Eye Tracking and\n  Head Movement with Machine Learning", "comments": "9 pages, 9 Figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the increase of distance learning, in general, and e-learning, in\nparticular, having a system capable of determining the engagement of students\nis of primordial importance, and one of the biggest challenges, both for\nteachers, researchers and policy makers. Here, we present a system to detect\nthe engagement level of the students. It uses only information provided by the\ntypical built-in web-camera present in a laptop computer, and was designed to\nwork in real time. We combine information about the movements of the eyes and\nhead, and facial emotions to produce a concentration index with three classes\nof engagement: \"very engaged\", \"nominally engaged\" and \"not engaged at all\".\nThe system was tested in a typical e-learning scenario, and the results show\nthat it correctly identifies each period of time where students were \"very\nengaged\", \"nominally engaged\" and \"not engaged at all\". Additionally, the\nresults also show that the students with best scores also have higher\nconcentration indexes.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 15:46:48 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 09:28:54 GMT"}, {"version": "v3", "created": "Mon, 28 Sep 2020 16:56:12 GMT"}, {"version": "v4", "created": "Sat, 26 Dec 2020 19:05:15 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Sharma", "Prabin", ""], ["Joshi", "Shubham", ""], ["Gautam", "Subash", ""], ["Maharjan", "Sneha", ""], ["Filipe", "Vitor", ""], ["Reis", "Manuel J. C. S.", ""]]}, {"id": "1909.12926", "submitter": "Dave Cliff", "authors": "Bradley Miles and Dave Cliff", "title": "A Cloud-Native Globally Distributed Financial Exchange Simulator for\n  Studying Real-World Trading-Latency Issues at Planetary Scale", "comments": "10 pages, 5 figures. To be presented at the European Modelling and\n  Simulation Symposium (EMSS2019) Lisbon, Portugal, 18th-20th September 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a new public-domain open-source simulator of an electronic\nfinancial exchange, and of the traders that interact with the exchange, which\nis a truly distributed and cloud-native system that been designed to run on\nwidely available commercial cloud-computing services, and in which various\ncomponents can be placed in specified geographic regions around the world,\nthereby enabling the study of planetary-scale latencies in contemporary\nautomated trading systems. Our simulator allows an exchange server to be\nlaunched in the cloud, specifying a particular geographic zone for the cloud\nhosting service; automated-trading clients which attach to the exchange can\nthen also be launched in the cloud, in the same geographic zone and/or in\ndifferent zones anywhere else on the planet, and those clients are then subject\nto the real-world latencies introduced by planetary-scale cloud communication\ninterconnections. In this paper we describe the design and implementation of\nour simulator, called DBSE, which is based on a previous public-domain\nsimulator, extended in ways that are partly inspired by the architecture of the\nreal-world Jane Street Exchange. DBSE relies fundamentally on UDP and TCP\nnetwork communications protocols and implements a subset of the FIX de facto\nstandard protocol for financial information exchange. We show results from an\nexample in which the exchange server is remotely launched on a cloud facility\nlocated in London (UK), with trader clients running in Ohio (USA) and Sydney\n(Australia). We close with discussion of how our simulator could be further\nused to study planetary-scale latency arbitrage in financial markets.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 07:20:49 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Miles", "Bradley", ""], ["Cliff", "Dave", ""]]}, {"id": "1909.12934", "submitter": "Mansi M", "authors": "G. Hall, M. Mansi, I. Makrant", "title": "Novel method for handling Ethereum attack", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CY cs.SE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Block-chain world is very dynamic and there is need for strong governance and\nunderlying technology architecture to be robust to face challenges. This paper\nconsiders Ethereum, a leading block chain. We deep dive into the nature of this\nblock chain, wherein for software upgrades forks are performed. They types of\nforks and impact is discussed. A specific Ethereum hack led to a hard fork and\nfocus is provided on understanding the hack and overcoming it from a novel\napproach. The current model has been unable to handle multiple Ethereum\nattacks. Thus the current approach is compared against a novel approach\nproviding a security and scaling solution. Here the architecture draws upon\ncombining block-chain layers into operating system level. The approach can have\ntremendous benefits to block chain world and improve the way decentralized\napplication teams perform. The benefits of the novel architecture is discussed.\nThe approach helps safe guard block chain projects, making them safer and chain\nagnostic.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 17:05:59 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 06:51:23 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Hall", "G.", ""], ["Mansi", "M.", ""], ["Makrant", "I.", ""]]}, {"id": "1909.12935", "submitter": "Yi Zeng", "authors": "Yi Zeng, Enmeng Lu, Yinqian Sun, Ruochen Tian", "title": "Responsible Facial Recognition and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Facial recognition is changing the way we live in and interact with our\nsociety. Here we discuss the two sides of facial recognition, summarizing\npotential risks and current concerns. We introduce current policies and\nregulations in different countries. Very importantly, we point out that the\nrisks and concerns are not only from facial recognition, but also realistically\nvery similar to other biometric recognition technology, including but not\nlimited to gait recognition, iris recognition, fingerprint recognition, voice\nrecognition, etc. To create a responsible future, we discuss possible\ntechnological moves and efforts that should be made to keep facial recognition\n(and biometric recognition in general) developing for social good.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 15:27:06 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Zeng", "Yi", ""], ["Lu", "Enmeng", ""], ["Sun", "Yinqian", ""], ["Tian", "Ruochen", ""]]}, {"id": "1909.12938", "submitter": "Akhil Gupta", "authors": "Akhil Gupta", "title": "Time Series Modeling for Dream Team in Fantasy Premier League", "comments": "International Conference on Sports Engineering (ICSE'17)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The performance of football players in English Premier League varies largely\nfrom season to season and for different teams. It is evident that a method\ncapable of forecasting and analyzing the future of these players on-field\nantics shall assist the management to a great extent. In a simulated\nenvironment like the Fantasy Premier League, enthusiasts from all over the\nworld participate and manage the players catalogue for the entire season. Due\nto the dynamic nature of points system, there is no known approach for the\nformulation of a dream team. This study aims to tackle this problem by using a\nhybrid of Autoregressive Integrated Moving Average (ARIMA) and Recurrent Neural\nNetworks (RNNs) for time series prediction of player points and subsequent\nmaximization of total points using Linear Programming (LPP). Given the player\npoints for the past three seasons, the predictions have been made for the\ncurrent season by modeling differently for ARIMA and RNN, and then creating an\nensemble of the same. Prior to that, proper data preprocessing techniques were\ndeployed to enhance the efficacy of the prepared model. Constraints on the type\nof players like goalkeepers, defenders, midfielders and forwards along with the\ntotal budget were effectively optimized using LPP approach. The validation of\nthe proposed team was done with the performance in upcoming season, where the\nplayers outperform as expected, and helped in strengthening the feasibility of\nthe solution. Likewise, the proposed approach can be extended to English\nPremier League by official managers on-field.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 20:20:04 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Gupta", "Akhil", ""]]}, {"id": "1909.12940", "submitter": "Ashiqur KhudaBukhsh Ashiqur Rahman KhudaBukhsh", "authors": "Shriphani Palakodety, Ashiqur R. KhudaBukhsh, Jaime G. Carbonell", "title": "Hope Speech Detection: A Computational Analysis of the Voice of Peace", "comments": "Minor edits", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent Pulwama terror attack (February 14, 2019, Pulwama, Kashmir)\ntriggered a chain of escalating events between India and Pakistan adding\nanother episode to their 70-year-old dispute over Kashmir. The present era of\nubiquitious social media has never seen nuclear powers closer to war. In this\npaper, we analyze this evolving international crisis via a substantial corpus\nconstructed using comments on YouTube videos (921,235 English comments posted\nby 392,460 users out of 2.04 million overall comments by 791,289 users on 2,890\nvideos). Our main contributions in the paper are three-fold. First, we present\nan observation that polyglot word-embeddings reveal precise and accurate\nlanguage clusters, and subsequently construct a document\nlanguage-identification technique with negligible annotation requirements. We\ndemonstrate the viability and utility across a variety of data sets involving\nseveral low-resource languages. Second, we present an analysis on temporal\ntrends of pro-peace and pro-war intent observing that when tensions between the\ntwo nations were at their peak, pro-peace intent in the corpus was at its\nhighest point. Finally, in the context of heated discussions in a politically\ntense situation where two nations are at the brink of a full-fledged war, we\nargue the importance of automatic identification of user-generated web content\nthat can diffuse hostility and address this prediction task, dubbed\n\\emph{hope-speech detection}.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 04:22:20 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 20:21:37 GMT"}, {"version": "v3", "created": "Tue, 28 Jan 2020 22:37:43 GMT"}, {"version": "v4", "created": "Mon, 24 Feb 2020 05:11:46 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Palakodety", "Shriphani", ""], ["KhudaBukhsh", "Ashiqur R.", ""], ["Carbonell", "Jaime G.", ""]]}, {"id": "1909.12946", "submitter": "Toyotaro Suzumura Prof", "authors": "Toyotaro Suzumura, Yi Zhou, Natahalie Baracaldo, Guangnan Ye, Keith\n  Houck, Ryo Kawahara, Ali Anwar, Lucia Larise Stavarache, Yuji Watanabe, Pablo\n  Loyola, Daniel Klyashtorny, Heiko Ludwig, Kumar Bhaskaran", "title": "Towards Federated Graph Learning for Collaborative Financial Crimes\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.LG cs.SI q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial crime is a large and growing problem, in some way touching almost\nevery financial institution. Financial institutions are the front line in the\nwar against financial crime and accordingly, must devote substantial human and\ntechnology resources to this effort. Current processes to detect financial\nmisconduct have limitations in their ability to effectively differentiate\nbetween malicious behavior and ordinary financial activity. These limitations\ntend to result in gross over-reporting of suspicious activity that necessitate\ntime-intensive and costly manual review. Advances in technology used in this\ndomain, including machine learning based approaches, can improve upon the\neffectiveness of financial institutions' existing processes, however, a key\nchallenge that most financial institutions continue to face is that they\naddress financial crimes in isolation without any insight from other firms.\nWhere financial institutions address financial crimes through the lens of their\nown firm, perpetrators may devise sophisticated strategies that may span across\ninstitutions and geographies. Financial institutions continue to work\nrelentlessly to advance their capabilities, forming partnerships across\ninstitutions to share insights, patterns and capabilities. These public-private\npartnerships are subject to stringent regulatory and data privacy requirements,\nthereby making it difficult to rely on traditional technology solutions. In\nthis paper, we propose a methodology to share key information across\ninstitutions by using a federated graph learning platform that enables us to\nbuild more accurate machine learning models by leveraging federated learning\nand also graph learning approaches. We demonstrated that our federated model\noutperforms local model by 20% with the UK FCA TechSprint data set. This new\nplatform opens up a door to efficiently detecting global money laundering\nactivity.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 21:31:14 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 22:32:23 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Suzumura", "Toyotaro", ""], ["Zhou", "Yi", ""], ["Baracaldo", "Natahalie", ""], ["Ye", "Guangnan", ""], ["Houck", "Keith", ""], ["Kawahara", "Ryo", ""], ["Anwar", "Ali", ""], ["Stavarache", "Lucia Larise", ""], ["Watanabe", "Yuji", ""], ["Loyola", "Pablo", ""], ["Klyashtorny", "Daniel", ""], ["Ludwig", "Heiko", ""], ["Bhaskaran", "Kumar", ""]]}, {"id": "1909.12949", "submitter": "Iqbal H. Sarker", "authors": "Iqbal H. Sarker and Khaled Salah", "title": "AppsPred: Predicting Context-Aware Smartphone Apps using Random Forest\n  Learning", "comments": "28 pages", "journal-ref": "Journal: Internet of Things (IoT): Engineering Cyber-Physical\n  Human Systems, Elsevier, 2019", "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the popularity of context-awareness in the Internet of Things (IoT)\nand the recent advanced features in the most popular IoT device, i.e.,\nsmartphone, modeling and predicting personalized usage behavior based on\nrelevant contexts can be highly useful in assisting them to carry out daily\nroutines and activities. Usage patterns of different categories smartphone apps\nsuch as social networking, communication, entertainment, or daily life services\nrelated apps usually vary greatly between individuals. People use these apps\ndifferently in different contexts, such as temporal context, spatial context,\nindividual mood and preference, work status, Internet connectivity like Wifi?\nstatus, or device related status like phone profile, battery level etc. Thus,\nwe consider individuals' apps usage as a multi-class context-aware problem for\npersonalized modeling and prediction. Random Forest learning is one of the most\npopular machine learning techniques to build a multi-class prediction model.\nTherefore, in this paper, we present an effective context-aware smartphone apps\nprediction model, and name it \"AppsPred\" using random forest machine learning\ntechnique that takes into account optimal number of trees based on such\nmulti-dimensional contexts to build the resultant forest. The effectiveness of\nthis model is examined by conducting experiments on smartphone apps usage\ndatasets collected from individual users. The experimental results show that\nour AppsPred significantly outperforms other popular machine learning\nclassification approaches like ZeroR, Naive Bayes, Decision Tree, Support\nVector Machines, Logistic Regression while predicting smartphone apps in\nvarious context-aware test cases.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 11:43:37 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Sarker", "Iqbal H.", ""], ["Salah", "Khaled", ""]]}, {"id": "1909.13256", "submitter": "Jason R.C. Nurse Dr", "authors": "Maria Bada and Jason R. C. Nurse", "title": "The Social and Psychological Impact of Cyber-Attacks", "comments": "21 pages", "journal-ref": "Benson, Vladlena and McAlaney, John, eds. (2019). Emerging Cyber\n  Threats and Cognitive Vulnerabilities. pp. 73-92", "doi": "10.1016/B978-0-12-816203-3.00004-6", "report-no": null, "categories": "cs.CY cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-attacks have become as commonplace as the Internet itself. Each year,\nindustry reports, media outlets and academic articles highlight this increased\nprevalence, spanning both the amount and variety of attacks and cybercrimes. In\nthis article, we seek to further advance discussions on cyber threats,\ncognitive vulnerabilities and cyberpsychology through a critical reflection on\nthe social and psychological aspects related to cyber-attacks. In particular,\nwe are interested in understanding how members of the public perceive and\nengage with risk and how they are impacted during and after a cyber-attack has\noccurred. This research focuses on key cognitive issues relevant to\ncomprehending public reactions to malicious cyber events including risk\nperception, protection motivation, culture, and attacker characteristics (e.g.,\nattacker identity, target identity and scale of attack). To consider the\napplicability of our findings, we investigate two significant cyber-attacks\nover the last few years, namely the WannaCry attack of 2017 and the Lloyds\nBanking Group attack in the same year.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 11:11:57 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Bada", "Maria", ""], ["Nurse", "Jason R. C.", ""]]}, {"id": "1909.13304", "submitter": "Nigel Bosch", "authors": "Nigel Bosch", "title": "Identifying supportive student factors for mindset interventions: A\n  two-model machine learning approach", "comments": "28 pages, 4 figures, 3 tables", "journal-ref": null, "doi": "10.1016/j.compedu.2021.104190", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Growth mindset interventions foster students' beliefs that their abilities\ncan grow through effort and appropriate strategies. However, not every student\nbenefits from such interventions - yet research identifying which student\nfactors support growth mindset interventions is sparse. In this study, we\nutilized machine learning methods to predict growth mindset effectiveness in a\nnationwide experiment in the U.S. with over 10,000 students. These methods\nenable analysis of arbitrarily-complex interactions between combinations of\nstudent-level predictor variables and intervention outcome, defined as the\nimprovement in grade point average (GPA) during the transition to high school.\nWe utilized two separate machine learning models: one to control for complex\nrelationships between 51 student-level predictors and GPA, and one to predict\nthe change in GPA due to the intervention. We analyzed the trained models to\ndiscover which features influenced model predictions most, finding that prior\nacademic achievement, blocked navigations (attempting to navigate through the\nintervention software too quickly), self-reported reasons for learning, and\nrace/ethnicity were the most important predictors in the model for predicting\nintervention effectiveness. As in previous research, we found that the\nintervention was most effective for students with prior low academic\nachievement. Unique to this study, we found that blocked navigations predicted\nan intervention effect as low as 0.185 GPA points (on a 0-4 scale) less than\nthe mean. This was a notable negative prediction given that the mean\nintervention effect in our sample was just 0.026 GPA points, though few\nstudents (4.4%) experienced a substantial number of blocked navigation events.\nWe also found that some minoritized students were predicted to benefit less (or\neven not at all) from the intervention.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 15:41:51 GMT"}, {"version": "v2", "created": "Sat, 13 Mar 2021 00:47:13 GMT"}, {"version": "v3", "created": "Fri, 26 Mar 2021 23:50:40 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Bosch", "Nigel", ""]]}, {"id": "1909.13443", "submitter": "Nalin Chhibber", "authors": "Nalin Chhibber, Edith Law", "title": "Using Conversational Agents To Support Learning By Teaching", "comments": "7 pages, 2 figures, Presented at Conversational Agents Workshop, CHI\n  2019 (Glasgow, UK)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational agents are becoming increasingly popular for supporting and\nfacilitating learning. Conventional pedagogical agents are designed to play the\nrole of human teachers by giving instructions to the students. In this paper,\nwe investigate the use of conversational agents to support the\n'learning-by-teaching' paradigm where the agent receives instructions from\nstudents. In particular, we introduce Curiosity Notebook: an educational\napplication that harvests conversational interventions to facilitate students'\nlearning. Recognizing such interventions can not only help in engaging students\nwithin learning interactions, but also provide a deeper insight into the\nintricacies involved in designing conversational agents for educational\npurposes.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 03:40:59 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Chhibber", "Nalin", ""], ["Law", "Edith", ""]]}]